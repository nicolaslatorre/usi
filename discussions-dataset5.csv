28768,A,"Simple Object to Database Product I've been taking a look at some different products for .NET which propose to speed up development time by providing a way for business objects to map seamlessly to an automatically generated database. I've never had a problem writing a data access layer but I'm wondering if this type of product will really save the time it claims. I also worry that I will be giving up too much control over the database and make it harder to track down any data level problems. Do these type of products make it better or worse in the already tough case that the database and business object structure must change? For example: Object Relation Mapping from Dev Express In essence is it worth it? Will I save ""THAT"" much time effort and future bugs? I was discussing this with a friend over the weekend and it seems like the gains you make on ease of storage are lost if you need to be able to query the database outside of the application. My understanding is that these databases work by storing your object data in a de-normalized fashion. This makes it fast to retrieve entire sets of objects but if you need to select data from a perspective that doesn't match your object model the odbms might have a hard time getting at the particular data you want.  There are lots of choices of ORMs. Linq to Sql nHibernate. For pure object databases there is db4o. It depends on the application but for a high volume enterprise application I would not go this route. You need more control of your data.  I've found iBatis from the Apache group to be an excellent solution to this problem. My team is currently using iBatis to map all of our calls from Java to our MySQL backend. It's been a huge benefit as it's easy to manage all of our SQL queries and procedures because they're all located in XML files not in our code. Separating SQL from your code no matter what the language is a great help. Additionally iBatis allows you to write your own data mappers to map data to and from your objects to the DB. We wanted this flexibility as opposed to a Hibernate type solution that does everything for you but also (IMO) limits your ability to perform complex queries. There is a .NET version of iBatis as well.  I've recently set up ActiveRecord from the Castle Project for an app. It was pretty easy to get going. After creating a new app with it I even used MyGeneration to script out class files for a legacy app that ActiveRecord could use in a pretty short time. It uses NHibernate to interact with the database but takes away all the xml mapping that comes with NHibernate. The nice thing is though if necessary you already have NHibernate in your project you can use its full power if you have some special cases. I'd suggest taking a look at it.  I have used SubSonic and EntitySpaces. Once you get the hang of them I beleive they can save you time but as complexity of your app and volume of data grow you may outgrow these tools. You start to lose time trying to figure out if something like a performance issue is related to the ORM or to your code. So to answer your question I think it depends. I tend to agree with Eric on this high volume enterprise apps are not a good place for general purpose ORMs but in standard fare smaller CRUD type apps you might see some saved time.",c# .net database orm
18505,A,"Sending a mouse click to a button in the taskbar using C# In an application that I am currently working on a requirement is to bring a window of an external application to the foreground. Making Win32 API calls such as BringWindowToTop and SetForeground window do not work all the time. This is due to some restrictions within Windows XP. What I would like to do instead is send simulate a mouse click the window's button on the taskbar which I am hoping will bring the window to the front. Does anyone know how this is possible? It's possible. But it's extremely sketchy. Your application may also break with the next version of Windows since it's undocumented. What you need to do is find the window handle of the taskbar then find the window handle of the child window representing the button then send it a WM_MOUSEDOWN (I think) message. Here's a bit on finding the window handle of the taskbar: http://www.codeproject.com/ FWIW the restrictions on BringWindowToTop/SetForeground are there because it's irritating when a window steals focus. That may not matter if you're working on a corporate environment. Just keep it in mind. :)  I used this in a program where I needed to simulate clicks and mouse movements; Global Mouse and Keyboard Library  To be honest I've never had an issue bringing a window to the foreground on XP/Vista/2003/2000. You need to make sure you do the following: Check if IsIconic (minimized) If #1 results in true then call ShowWindow passing SW_RESTORE Then call SetForegroundWindow I've never had problems that I can think of doing it with those steps.  Check out the section ""How to steal focus on 2K/XP"" at http://www.codeproject.com/KB/dialog/dlgboxtricks.aspx as this is exactly what you need. I wouldn't go the taskbar route as the taskbar could be hidden or simply not there.",c# .net windows winapi
7990,A,"Printing from a .NET Service I am working on a project right now that involves receiving a message from another application formatting the contents of that message and sending it to a printer. Technology of choice is C# windows service. The output could be called a report I suppose but a reporting engine is not necessary. A simple templating engine like StringTemplate or even XSLT outputting HTML would be fine. The problem I'm having is finding a free way to print this kind of output from a service. Since it seems that it will work I'm working on a prototype using Microsoft's RDLC populating a local report and then rendering it as an image to a memory stream which I will then print. Issues with that are: Multi-page printing will be a big headache. Still have to use PrintDocument to print the memory stream which is unsupported in a Windows Service (though it may work - haven't gotten that far with the prototype yet) If the data coming across changes I have to change the dataset and the class that the data is being deserialized into. bad bad bad. Has anyone had to do anything remotely like this? Any advice? I already posed a question about printing HTML without user input and after wasting about 3 days on that I have come to the conclusion that it cannot be done at least not with any freely available tool. All help is appreciated. EDIT: We are on version 2.0 of the .NET framework. I think we are going to go the third party route. I like the XSL -> HTML -> PDF -> Printer flow... Winnovative's HTML to PDF looks good for the first part but I'm running into a block finding a good PDF printing solution... any suggestions? Ideally the license would be on a developer basis not on a deployed runtime basis.  In answer to your question about PDF printing I have not found an elegant solution. I was ""shell"" ing out to Adobe which was unreliable and required a user to be logged in at all times. To fix this specific problem I requested that the files we process (invoices) be formatted as multi-page Tiff files instead which can be split apart and printed using native .NET printing functions. Adobe's position seems to be ""get the user to view the file in Adobe Reader and they can click print"". Useless. I am still keen to find a good way of producing quality reports which can be output from the web server...  Printing using System.Drawing.Printing is not supported by MS as per Yann Trevin's response. However you might be able to use the new WPF-based System.Printing (I think)  Printing from a Windows service is really painful. It seems to work... sometimes... but finally it craches or throws an exception from time to time without any clear reason. It's really hopeless. Officially it's even not supported without any explanation nor any proposal for an alternate solution. Recently I have been confronted to the problem and after several unsuccessful trials and experimentations I came finally with two viable solutions: Write your own printing DLL using the Win32 API (in C/C++ for instance) then use it from your service with P/Invoke (works fine) Write your own printing COM+ component then uses it from your service. I have chosen this solution with success recently (but it was third party COM+ component not own written) It works absolutely fine too. GDI+ was never designed/tested to work in service context. Thats why it does not work. You should use GDI and it function to draw. Refer to this document to find equivalent Win32 calls : http://msdn.microsoft.com/en-us/library/aa302340.aspx#win32map_printingfunctions  I've done it. It's a pain in the A*s. The problem is that printing requires that GDI engine to be in place which normally means that you have to have the desktop which only loads when you're logged in. If you're attempting to do this from a Service on a Server then you normally aren't logged in. So first you can't run as the normal service user but instead as a real user that has interactive login rights. Then you have to tweak the service registry entries (I forget how at the moment would have to find the code which I can do tonight if you're really interested). Finally you have to pray. Your biggest long term headache will be with print drivers. If you are running as a service without a logged in user some print drivers like to pop up dialogs from time to time. What happens when your printer is out of toner? Or out of paper? The driver may pop up a dialog that will never be seen and hold up the printer queue because nobody is logged in!  We are using DevExpress' XtraReports to print from a service without any problems. Their report model is similar to that of Windows Forms so you could dynamically insert text elements and then issue the print command.  Printing from a service is a bad idea. Network printers are connected ""per-user"". You can mark the service to be run as a particular user but I'd consider that a bad security practice. You might be able to connect to a local printer but I'd still hesitate before going this route. The best option is to have the service store the data and have a user-launched application do the printing by asking the service for the data. Or a common location that the data is stored like a database. If you need to have the data printed as regular intervals setup a Task event thru the Task Scheduler. Launching a process from a service will require knowing the user name and password which again is bad security practice. As for the printing itself use a third-party tool to generate the report will be the easiest.  This may not be what you're looking for but if I needed to do this quick&dirty I would: Create a separate WPF application (so I could use the built-in document handling) Give the service the ability to interact with the desktop (note that you don't actually have to show anything on the desktop or be logged in for this to work) Have the service run the application and give it the data to print. You could probably also jigger this to print from a web browser that you run from the service (though I'd recommend building your own shell IE rather than using a full browser). For a more detailed (also free) solution your best bet is probably to manually format the document yourself (using GDI+ to do the layout for you). This is tedious error prone time consuming and wastes a lot of paper during development but also gives you the most control over what's going to the printer.  Trust me you will spend more money trying to search/develop a solution for this as compared to buying a third party component. Do not reinvent the wheel and go for the paid solution. Printing is a complex problem and I would love to see the day when better framework support is added for this.  To answer your first question this can be fairly straight forward depending on the data. We have a variety of Service-based applications that do exactly what you are asking. Typically we parse the incoming file and wrap our own Postscript or PCL around it. If you layout is fairly simple then there are some very basic PCL codes you can wrap it with to provide the font/print layup you want (I'd be more then happy to give you some guidance here offline). One you have a print ready file you can send it to a UNC printer that is shared directly to a locally installed printer or even to the IP of the device (RAW or LPR type data). If however you are going down the PDF path the simplest method is to send the PDF output to a printer that supports direct PDF printing (many do now). In this case you just send the PDF to the device and away it prints. The other option is to launch Ghostscript which should be free for your needs (check the licensing as they have a few different version some GNU some GPL etc.) and either use it's built in print function or simply convert to Postscript and send to the device. I've used Ghostscript many times in Service apps but not a huge fan as you will basically be shelling out and executing a command line app to do the conversion. That being said it's a stable app that does tend to fail gracefully  If you can output to post script some printers will print anything that gets FTPed to a certain directory on them. We used this to get past the print credits that our university exposed on us but if your service outputs to a ps then you can just ftp the ps file to the printer.",c# .net windows-services printing
19589,A,"Loading System.ServiceModel configuration section using ConfigurationManager Using C# .NET 3.5 and WCF I'm trying to write out some of the WCF configuration in a client application (the name of the server the client is connecting to). The obvious way is to use ConfigurationManager to load the configuration section and write out the data I need. var serviceModelSection = ConfigurationManager.GetSection(""system.serviceModel""); Appears to always return null. var serviceModelSection = ConfigurationManager.GetSection(""appSettings""); Works perfectly. The configuration section is present in the App.config but for some reason ConfigurationManager refuses to load the system.ServiceModel section. I want to avoid manually loading the xxx.exe.config file and using XPath but if I have to resort to that I will. Just seems like a bit of a hack. Any suggestions? The <system.serviceModel> element is for a configuration section group not a section. You'll need to use System.ServiceModel.Configuration.ServiceModelSectionGroup.GetSectionGroup() to get the whole group.  http://mostlytech.blogspot.com/2007/11/programmatically-enumerate-wcf.html // Automagically find all client endpoints defined in app.config ClientSection clientSection = ConfigurationManager.GetSection(""system.serviceModel/client"") as ClientSection; ChannelEndpointElementCollection endpointCollection = clientSection.ElementInformation.Properties[string.Empty].Value as ChannelEndpointElementCollection; List<string> endpointNames = new List<string>(); foreach (ChannelEndpointElement endpointElement in endpointCollection) { endpointNames.Add(endpointElement.Name); } // use endpointNames somehow ... Appears to work well. this worked for me today Worked for me thanks! the confusing line for endpointCollection = clientSection.ElementInformation.Properties[string.Empty].Value as ChannelEndpointElementCollection; should be simplified to clientSection.Endpoints;  GetSectionGroup() does not support no parameters (under framework 3.5). Instead use: Configuration config = System.Configuration.ConfigurationManager.OpenExeConfiguration(ConfigurationUserLevel.None); ServiceModelSectionGroup group = System.ServiceModel.Configuration.ServiceModelSectionGroup.GetSectionGroup(config);  Thanks to the other posters this is the function I developed to get the URI of a named endpoint. It also creates a listing of the endpoints in use and which actual config file was being used when debugging: Private Function GetEndpointAddress(name As String) As String Debug.Print(""--- GetEndpointAddress ---"") Dim address As String = ""Unknown"" Dim appConfig As Configuration = ConfigurationManager.OpenExeConfiguration(ConfigurationUserLevel.None) Debug.Print(""app.config: "" & appConfig.FilePath) Dim serviceModel As ServiceModelSectionGroup = ServiceModelSectionGroup.GetSectionGroup(appConfig) Dim bindings As BindingsSection = serviceModel.Bindings Dim endpoints As ChannelEndpointElementCollection = serviceModel.Client.Endpoints For i As Integer = 0 To endpoints.Count - 1 Dim endpoint As ChannelEndpointElement = endpoints(i) Debug.Print(""Endpoint: "" & endpoint.Name & "" - "" & endpoint.Address.ToString) If endpoint.Name = name Then address = endpoint.Address.ToString End If Next Debug.Print(""--- GetEndpointAddress ---"") Return address End Function  This is what I was looking for thanks to @marxidad for the pointer.  public static string GetServerName() { string serverName = ""Unknown""; Configuration appConfig = ConfigurationManager.OpenExeConfiguration(ConfigurationUserLevel.None); ServiceModelSectionGroup serviceModel = ServiceModelSectionGroup.GetSectionGroup(appConfig); BindingsSection bindings = serviceModel.Bindings; ChannelEndpointElementCollection endpoints = serviceModel.Client.Endpoints; for(int i=0; i<endpoints.Count; i++) { ChannelEndpointElement endpointElement = endpoints[i]; if (endpointElement.Contract == ""MyContractName"") { serverName = endpointElement.Address.Host; } } return serverName; }",c# .net xml wcf configurationmanager
20952,A,"Is there a way to get a System.Configuration.Configuration instance based on arbitrary xml? I'm trying to unit test a custom ConfigurationSection I've written and I'd like to load some arbitrary configuration XML into a System.Configuration.Configuration for each test (rather than put the test configuration xml in the Tests.dll.config file. That is I'd like to do something like this: Configuration testConfig = new Configuration(""<?xml version=\""1.0\""?><configuration>...</configuration>""); MyCustomConfigSection section = testConfig.GetSection(""mycustomconfigsection""); Assert.That(section != null); However it looks like ConfigurationManager will only give you Configuration instances that are associated with an EXE file or a machine config. Is there a way to load arbitrary XML into a Configuration instance? Looking at the members of the class I'd say the answer is probably no*. I'm not sure why you'd want to do this anyway rather than create your own XML configuration file. *That's no excluding messy reflection hacks  There is actually a way I've discovered.... You need to define a new class inheriting from your original configuration section as follows: public class MyXmlCustomConfigSection : MyCustomConfigSection { public MyXmlCustomConfigSection (string configXml) { XmlTextReader reader = new XmlTextReader(new StringReader(configXml)); DeserializeSection(reader); } } You can then instantiate your ConfigurationSection object as follows: string configXml = ""<?xml version=\""1.0\""?><configuration>...</configuration>""; MyCustomConfigSection config = new MyXmlCustomConfigSection(configXml); Hope it helps someone :-) props for actually answering his question.  I think what you're looking for is ConfigurationManager.OpenMappedExeConfiguration It allows you to open a configuration file that you specify with a file path (wrapped inside a ExeConfigurationFileMap) If what the other poster said is true and you don't wish to create a whole new XML file for testing then I'd recommend you put your Configuration edits in the Test method itself then run your tests against the freshly changed configuration data.",c# .net testing configuration configurationmanager
17387,A,"Privatizing a BlogEngine.Net Installation I have a blogengine.net install that requires privatization. I'm doing research work at the moment but I have to keep my blog/journal private until certain conditions are met. How can I privatize my blogEngine.net install so that readers must log in to read my posts? I use this extension. Just save the file as RequireLogin.cs in your App_Code\Extensions folder and make sure the extension is activated. using System; using System.Data; using System.Configuration; using System.Web; using System.Web.Security; using System.Web.UI; using System.Web.UI.HtmlControls; using System.Web.UI.WebControls; using System.Web.UI.WebControls.WebParts; using BlogEngine.Core; using BlogEngine.Core.Web.Controls; using System.Collections.Generic; /// <summary> /// Summary description for PostSecurity /// </summary> [Extension(""Checks to see if a user can see this blog post."" ""1.0"" ""<a href=\""http://www.lavablast.com\"">LavaBlast.com</a>"")] public class RequireLogin { static protected ExtensionSettings settings = null; public RequireLogin() { Post.Serving += new EventHandler<ServingEventArgs>(Post_Serving); ExtensionSettings s = new ExtensionSettings(""RequireLogin""); // describe specific rules for entering parameters s.Help = ""Checks to see if the user has any of those roles before displaying the post. ""; s.Help += ""You can associate a role with a specific category. ""; s.Help += ""All posts having this category will require that the user have the role. ""; s.Help += ""A parameter with only a role without a category will enable to filter all posts to this role. ""; ExtensionManager.ImportSettings(s); settings = ExtensionManager.GetSettings(""PostSecurity""); } protected void Post_Serving(object sender ServingEventArgs e) { MembershipUser user = Membership.GetUser(); if(HttpContext.Current.Request.RawUrl.Contains(""syndication.axd"")) { return; } if (user == null) { HttpContext.Current.Response.Redirect(""~/Login.aspx""); } } }  I would think it's possible to do this in the web config file by doing something like the following: <system.web> <authorization> <allow roles=""Admin"" /> <deny users=""*"" /> </authorization> </system.web> thanks for the answer but this didn't work :( see http://www.codeplex.com/blogengine/Thread/View.aspx?ThreadId=33705  We created a simple tool that gives certain users access to certain posts according to their ASP.NET Membership Roles to acheive a somewhat similar result. http://blog.lavablast.com/post/2008/08/BlogEnginenet-Post-Security.aspx  From: BlogEngine.NET 2.5 - Private Blogs If you go into the control panel Users tab Roles sub-tab (right side) for ""Anonymous"" on the right-side Tools area hover over that and select ""Rights"". You are now on the Rights page for the Anonymous role. Uncheck everything in particular ""View Public Posts"". HOWEVER you do need to keep at least one item checked otherwise everything reverts back to the default. For example you could keep ""View Ratings on Posts"" checked. Then Save. Then anyone who is not logged in should automatically be redirected to the Login page no matter where what page they try to enter the site at. Exactly what I needed thanks.  lomaxx's answer didn't work so I decided to avoid making blogengine.net perform auth for readers. on iis i disabled anonymous access and added a guest users to the win2k3 user list.",c# .net asp.net blogs
16833,A,"How do you download and extract a gzipped file with C#? I need to periodically download extract and save the contents of http://data.dot.state.mn.us/dds/det_sample.xml.gz to disk. Anyone have experience downloading gzipped files with C#? Just use the HttpWebRequest class in the System.Net namespace to request the file and download it. Then use GZipStream class in the System.IO.Compression namespace to extract the contents to the location you specify. They provide examples.  Try the SharpZipLib a C# based library for compressing and uncompressing files using gzip/zip. Sample usage can be found on this blog post: using ICSharpCode.SharpZipLib.Zip; FastZip fz = new FastZip(); fz.ExtractZip(zipFile targetDirectory"""");  Here is a post I wrote last year that shows how to decompress a gzip file using C# and the built-in GZipStream class. http://blogs.msdn.com/miah/archive/2007/09/05/zipping-files.aspx As for downloading it you can use the standard WebRequest or WebClient classes in .NET. +1 The link was helpful to me just now using compression for the first time. Nice useful concise blog entry.  The GZipStream class might be what you want.  You can use WebClient in System.Net to download: WebClient Client = new WebClient (); Client.DownloadFile(""http://data.dot.state.mn.us/dds/det_sample.xml.gz"" "" C:\mygzipfile.gz""); then use #ziplib to extract Edit: or GZipStream... forgot about that one",c# .net gzip
8763,A,"Best way to play MIDI sounds using C# I'm trying to rebuild an old metronome application that was originally written using MFC in C++ to be written in .NET using C#. One of the issues I'm running into is playing the midi files that are used to represent the metronome ""clicks"". I've found a few articles online about playing MIDI in .NET but most of them seem to rely on custom libraries that someone has cobbled together and made available. I'm not averse to using these but I'd rather understand for myself how this is being done since it seems like it should be a mostly trivial exercise. So am I missing something? Or is it just difficult to use MIDI inside of a .NET application? For completeness cross platform and file format support I would use FMOD.  System.Media.SoundPlayer is a good simple way of playing WAV files. WAV files have some advantages over MIDI one of them being that you can control precisely what each instrument sounds like (rather than relying on the computer's built-in synthesizer).  You can use the media player: using WMPLib; //... WindowsMediaPlayer wmp = new WindowsMediaPlayer(); wmp.URL = Path.Combine(Application.StartupPath ""Resources/mymidi1.mid""); wmp.controls.play();  For extensive MIDI and Wave manipulation in .NET I think hands down NAudio is the solution (Also available via NuGet).  Sorry this question is a little old now but the following worked for me (somewhat copied from Win32 - Midi looping with MCISendString): [DllImport(""winmm.dll"")] static extern Int32 mciSendString(String command StringBuilder buffer Int32 bufferSize IntPtr hwndCallback); public static void playMidi(String fileName String alias) { mciSendString(""open "" + fileName + "" type sequencer alias "" + alias new StringBuilder() 0 new IntPtr()); mciSendString(""play "" + alias new StringBuilder() 0 new IntPtr()); } public static void stopMidi(String alias) { mciSendString(""stop "" + alias null 0 new IntPtr()); mciSendString(""close "" + alias null 0 new IntPtr()); } A full listing of command strings is given here. The cool part about this is you can just use different things besides sequencer to play different things say waveaudio for playing .wav files. I can't figure out how to get it to play .mp3 though. Also note that the stop and close command must be sent on the same thread that the open and play commands were sent on otherwise they will have no effect and the file will remain open. For example: [DllImport(""winmm.dll"")] static extern Int32 mciSendString(String command StringBuilder buffer Int32 bufferSize IntPtr hwndCallback); public static Dictionary<String bool> playingMidi = new Dictionary<String bool>(); public static void PlayMidi(String fileName String alias) { if (playingMidi.ContainsKey(alias)) throw new Exception(""Midi with alias '"" + alias + ""' is already playing""); playingMidi.Add(alias false); Thread stoppingThread = new Thread(() => { StartAndStopMidiWithDelay(fileName alias); }); stoppingThread.Start(); } public static void StopMidiFromOtherThread(String alias) { if (!playingMidi.ContainsKey(alias)) return; playingMidi[alias] = true; } public static bool isPlaying(String alias) { return playingMidi.ContainsKey(alias); } private static void StartAndStopMidiWithDelay(String fileName String alias) { mciSendString(""open "" + fileName + "" type sequencer alias "" + alias null 0 new IntPtr()); mciSendString(""play "" + alias null 0 new IntPtr()); StringBuilder result = new StringBuilder(100); mciSendString(""set "" + alias + "" time format milliseconds"" null 0 new IntPtr()); mciSendString(""status "" + alias + "" length"" result 100 new IntPtr()); int midiLengthInMilliseconds; Int32.TryParse(result.ToString() out midiLengthInMilliseconds); Stopwatch timer = new Stopwatch(); timer.Start(); while(timer.ElapsedMilliseconds < midiLengthInMilliseconds && !playingMidi[alias]) { } timer.Stop(); StopMidi(alias); } private static void StopMidi(String alias) { if (!playingMidi.ContainsKey(alias)) throw new Exception(""Midi with alias '"" + alias + ""' is already stopped""); // Execute calls to close and stop the player on the same thread as the play and open calls mciSendString(""stop "" + alias null 0 new IntPtr()); mciSendString(""close "" + alias null 0 new IntPtr()); playingMidi.Remove(alias); }  I can't claim to know much about it but I don't think it's that straightforward - Carl Franklin of DotNetRocks fame has done a fair bit with it - have you seen his DNRTV?  I'm working on a C# MIDI application at the moment and the others are right - you need to use p/invoke for this. I'm rolling my own as that seemed more appropriate for the application (I only need a small subset of MIDI functionality) but for your purposes the C# MIDI Toolkit might be a better fit. It is at least the best .NET MIDI library I found and I searched extensively before starting the project. Leslie's MIDI Toolkit is definitely the most comprehensive C# solution to playing recording MIDI. I have used it for a very complex project and it worked well.  I think you'll need to p/invoke out to the windows api to be able to play midi files from .net. This codeproject article does a good job on explaining how to do this: vb.net article to play midi files To rewrite this is c# you'd need the following import statement for mciSendString: [DllImport(""winmm.dll"")] static extern Int32 mciSendString(String command StringBuilder buffer Int32 bufferSize IntPtr hwndCallback); Hope this helps - good luck!  A recent addition is MIDI.NET that supports Midi Ports Midi Files and SysEx.",c# .net midi
17612,A,"How do you place a file in recycle bin instead of delete? Programmatic solution of course... You need to delve into unmanaged code. Here's a static class that I've been using: public static class Recycle { private const int FO_DELETE = 3; private const int FOF_ALLOWUNDO = 0x40; private const int FOF_NOCONFIRMATION = 0x0010; [StructLayout(LayoutKind.Sequential CharSet = CharSet.Auto Pack = 1)] public struct SHFILEOPSTRUCT { public IntPtr hwnd; [MarshalAs(UnmanagedType.U4)] public int wFunc; public string pFrom; public string pTo; public short fFlags; [MarshalAs(UnmanagedType.Bool)] public bool fAnyOperationsAborted; public IntPtr hNameMappings; public string lpszProgressTitle; } [DllImport(""shell32.dll"" CharSet = CharSet.Auto)] static extern int SHFileOperation(ref SHFILEOPSTRUCT FileOp); public static void DeleteFileOperation(string filePath) { SHFILEOPSTRUCT fileop = new SHFILEOPSTRUCT(); fileop.wFunc = FO_DELETE; fileop.pFrom = filePath + '\0' + '\0'; fileop.fFlags = FOF_ALLOWUNDO | FOF_NOCONFIRMATION; SHFileOperation(ref fileop); } } Addendum: Tsk tsk @ Jeff for ""using Microsoft.VisualBasic"" in C# code. Tsk tsk @ MS for putting all the goodies in VisualBasic namespace. I guess this is one of the areas where VB is just better than C#...besides it's not ""not C#"" just because it's in the VB namespace - an object is an object not to use it just because it's in a namespace you don't like the name of is a little ridiculous don't you think?... ...if the namespace was Microsoft.UsefulUtilities you wouldn't have an reservations about using them so what's the difference? It's not about the namespace of course but that you have to link in VB libraries to use that namespace. Should be obvious.  http://www.daveamenta.com/2008-05/c-delete-a-file-to-the-recycle-bin/ From above: using Microsoft.VisualBasic; string path = @""c:\myfile.txt""; FileIO.FileSystem.DeleteDirectory(path FileIO.UIOption.OnlyErrorDialogs RecycleOption.SendToRecycleBin); I'd use DeleteFile instead of DeleteDirectory to be more clear. +1 for thinking outside the box and referencing a disliked namespace rather than resorting to ugly unmanaged code. What do these FileIO classes and methods have to do with Visual Basic? Putting them in Microsoft.VisualBasic makes absolutely no sense to me. I must be missing something. @I. J. Kennedy If I had to guess it might have been that the Visual basic team implanted the feature and rather than muck around with it the .NET team decided to leave the functionality where it was. any solution without using ""Microsoft.VisualBasic"" ? Is there any way to not show the UI at all? (i.e. raise an exception instead of showing an error dialog) Yeah I'm looking for one without having to use the Visual Basic DLL  The best way I have found is to use the VB function FileSystem.DeleteFile. Microsoft.VisualBasic.FileIO.FileSystem.DeleteFile(file.FullName Microsoft.VisualBasic.FileIO.UIOption.OnlyErrorDialogs Microsoft.VisualBasic.FileIO.RecycleOption.SendToRecycleBin); It requires adding Microsoft.VisualBasic as a reference but this is part of the .NET framework and so isn't an extra dependency. Alternate solutions require a P/Invoke to SHFileOperation as well as defining all the various structures/constants. Including Microsoft.VisualBasic is much neater by comparison.",c# .net c++ windows io
4157,A,"ConfigurationManager.AppSettings Performance Concerns I plan to be storing all my config settings in my application's app.config section (using the ConfigurationManager.AppSettings class). As the user changes settings using the app's UI (clicking checkboxes choosing radio buttons etc.) I plan to be writing those changes out to the AppSettings. At the same time while the program is running I plan to be accessing the AppSettings constantly from a process that will be constantly processing data. Changes to settings via the UI need to affect the data processing in real-time which is why the process will be accessing the AppSettings constantly. Is this a good idea with regard to performance? Using AppSettings is supposed to be ""the right way"" to store and access configuration settings when writing .Net apps but I worry that this method wasn't intended for a constant load (at least in terms of settings being constantly read). If anyone has experience with this I would greatly appreciate the input. Update: I should probably clarify a few points. This is not a web application so connecting a database to the application might be overkill simply for storing configuration settings. This is a Windows Forms application. According to the MSDN documention the ConfigurationManager is for storing not just application level settings but user settings as well. (Especially important if for instance the application is installed as a partial-trust application.) Update 2: I accepted lomaxx's answer because Properties does indeed look like a good solution without having to add any additional layers to my application (such as a database). When using Properties it already does all the caching that others suggested. This means any changes and subsequent reads are all done in memory making it extremely fast. Properties only writes the changes to disk when you explicitly tell it to. This means I can make changes to the config settings on-the-fly at run time and then only do a final save out to disk when the program exits. Just to verify it would actually be able to handle the load I need I did some testing on my laptop and was able to do 750000 reads and 7500 writes per second using Properties. That is so far above and beyond what my application will ever even come close to needing that I feel quite safe in using Properties without impacting performance. Could I ask why you're not saving the user's settings in a database? Generally I save application settings that are changed very infrequently in the appSettings section (the default email address error logs are sent to the number of minutes after which you are automatically logged out etc.) The scope of this really is at the application not at the user and is generally used for deployment settings.  I would not use config files for storing user data. Use a db.  one thing I would look at doing is caching the appsettings on a read then flushing the settings from the cache on the write which should minimize the amount of actual load the server has to deal with for processing the appSettings. Also if possible look at breaking the appSettings up into configSections so you can read write and cache related settings. Having said all that I would seriously consider looking at storing these values in a database as you seem to actually be storing user preferences and not application settings.  since you're using a winforms app if it's in .net 2.0 there's actually a user settings system (called Properties) that is designed for this purpose. This article on MSDN has a pretty good introduction into this If you're still worried about performance then take a look at SQL Compact Edition which is similar to SQLite but is the Microsoft offering which I've found plays very nicely with winforms and there's even the ability to make it work with Linq  Someone correct me if I'm wrong but I don't think that AppSettings is typically meant to be used for these type of configuration settings. Normally you would only put in settings that remain fairly static (database connection strings file paths etc.). If you want to store customizable user settings it would be better to create a separate preferences file or ideally store those settings in a database.  The appSettings isn't really meant for what you are trying to do. When your .NET application starts it reads in the app.config file and caches its contents in memory. For that reason after you write to the app.config file you'll have to somehow force the runtime to re-parse the app.config file so it can cache the settings again. This is unnecessary The best approach would be to use a database to store your configuration settings. Barring the use of a database you could easily setup an external XML configuration file. When your application starts you could cache its contents in a NameValueCollection object or HashTable object. As you change/add settings you would do it to that cached copy. When your application shuts down or at an appropriate time interval you can write the cache contents back out to file.  I should probably clarify a few points. This is not a web application so connecting a database to the application might be overkill simply for storing configuration settings. This is a Windows Forms application. According to the MSDN documention the ConfigurationManager is for storing not just application level settings but user settings as well. (Especially important if for instance the application is installed as a partial-trust application.)  Dylan Don't use the application config file for this purpose use a SQL DB (SQLite MySQL MSSQL whatever) because you'll have to worry less about concurrency issues during reads and writes to the config file. You'll also have better flexibility in the type of data you want to store. The appSettings section is just a key/value list which you may outgrow as time passes and as the app matures. You could use custom config sections but then you're into a new problem area when it comes to the design.  Check out SQLite it seems like a good option for this particular scenario.",c# .net performance configuration properties
20061,A,Store data from a C# application I've recently taken up learning some C# and wrote a Yahtzee clone. My next step (now that the game logic is in place and functioning correctly) is to integrate some method of keeping stats across all the games played. My question is this how should I go about storing this information? My first thought would be to use a database and I have a feeling that's the answer I'll get... if that's the case can you point me to a good resource for creating and accessing a database from a C# application? Storing in an XML file actually makes more sense to me but I thought if I suggested that I'd get torn apart ;). I'm used to building web applications and for those text files are generally frowned upon. So going with an XML file what classes should I be looking at that would allow for easy manipulation? A database may be overkill - have you thought about just storing the scores in a file? If you decide to go with a database you might consider SQLite which you can distribute just like a file. There's an open source .NET provider - System.Data.SQLite - that includes everything you need to get started. Accessing and reading from a database in .NET is quite easy - take a look at this question for sample code.  I would recommend just using a database. I would recommend using LINQ or an ORM tool to interact with the database. For learning LINQ I would take a look at Scott Guthrie's posts. I think there are 9 of them all together. I linked part 1 below. If you want to go with an ORM tool say nhibernate then I would recommend checking out the Summer of nHibernate screencasts. They are a really good learning resource for nhibernate. I disagree with using XML. With reporting stats on a lot of data you can't beat using a relational database. Yeah XML is lightweight but there are a lot of choices for light weight relational databases also besides going with a full blown service based implementation. (i.e. SQL Server Compact SQLite etc...) Scott Guthrie on LINQ Summer of nHibernate No idea why you've been down-voted so much. In this case I wouldn't myself go to a database (even the lightweight ones you have described) but your point is valid and one day the original poster may have added enough to his stats to make a DB a more usable option (+1 to try and uncondemn this)  Here is one idea: use Xml Serialization. Design your GameStats data structure and optionally use Xml attributes to influence the schema as you like. I like to use this method for small data sets because its quick and easy and all I need to do is design and manipulate the data structure.  using (FileStream fs = new FileStream(....)) { // Read in stats XmlSerializer xs = new XmlSerializer(typeof(GameStats)); GameStats stats = (GameStats)xs.Deserialize(fs); // Manipulate stats here ... // Write out game stats XmlSerializer xs = new XmlSerializer(typeof(GameStats)); xs.Serialize(fs stats); fs.Close(); }  A database would probably be overkill for something like this - start with storing your information in an XML doc (or series of XML docs if there's a lot of data). You get all that nifty XCopy deployment stuff you can still use LINQ and it would be a smooth transition to a database if you decided later you really needed performant relational query logic.  I don't know if a database is necessarily what you want. That may be overkill for storing stats for a simple game like that. Databases are good; but you should not automatically use one in every situation (I'm assuming that this is a client application not an online game). Personally for a game that exists only on the user's computer I would just store the stats in a file (XML or binary - choice depends on whether you want it to be human-readable or not).  For this situation the [Serializable] attribute on a nicely modelled Stats class and XmlSerializer are the way to go IMO.  SQL Express from MS is a great free lightweight version of their SQL Server database. You could try that if you go the DB route. Alternatively you could simply create datasets within the application and serialize them to xml or you could use something like the newly minted Entity Framework that shipped with .NET 3.5 SP1  I'd recommend saving your data in simple POCOs and either serializing them to xml or a binary file like Brian did above. If you're hot for a database I'd suggest Sql Server Compact Edition or VistaDB. Both are hosted inproc within your application.  You can either use the System::Xml namespace or the System::Data namespace. The first gives you raw XML the latter gives you a handy wrapper to the XML.,c# .net
25458,A,"How costly is .NET reflection? I constantly hear how bad reflection is to use. While I generally avoid reflection and rarely find situations where it is impossible to solve my problem without it I was wondering... For those who have used reflection in applications have you measured performance hits and is it really so bad? You might also want to check out this question. http://stackoverflow.com/questions/224232/what-is-the-cost-of-reflection Use the api at fasterflect.codeplex.com. It will speed up reflection by like 500x for getters/setters/invokers and some other stuff. Source and info on how it works is there too if you need to extend it. How does this info check out in 2014? Anything changed in these 4 years? I think you will find that the answer is it depends. It's not a big deal if you want to put it in your task-list application. It is a big deal if you want to put it in Facebook's persistence library.  Reflection does not drastically slow the performance of your app. You may be able to do certain things quicker by not using reflection but if Reflection is the easiest way to achieve some functionality then use it. You can always refactor you code away from Reflection if it becomes a perf problem.  As with all things in programming you have to balance performance cost with with any benefit gained. Reflection is an invaluable tool when used with care. I created a O/R mapping library in C# which used reflection to do the bindings. This worked fantastically well. Most of the reflection code was only executed once so any performance hit was quite small but the benefits were great. If I were writing a new fandangled sorting algorithm I would probably not use reflection since it would probably scale poorly. I appreciate that I haven't exactly answered your question here. My point is that it doesn't really matter. Use reflection where appropriate. It's just another language feature that you need to learn how and when to use.  It is. But that depends on what you're trying to do. I use reflection to dynamically load assemblies (plugins) and its performance ""penalty"" is not a problem since the operation is something I do during startup of the application. However if you're reflecting inside a series of nested loops with reflection calls on each I'd say you should revisit your code :) For ""a couple of time"" operations reflection is perfectly acceptable and you won't notice any delay or problem with it. It's a very powerful mechanism and it is even used by .NET so I don't see why you shouldn't give it a try.  In his talk The Performance of Everyday Things Jeff Richter shows that calling a method by reflection is about 1000 times slower than calling it normally. Jeff's tip: if you need to call the method multiple times use reflection once to find it then assign it to a delegate and then call the delegate. I have attended Devscovery too and concur with these results for .NET 3.5. Recompiling the Devscovery performance benchmark program for .NET 4 shows massive improvement! The cost drops down to 100 times slower. Using reflection for typeof() lookups are unchanged between .NET 3.5 and .NET 4.  Reflection is costly because of the many checks the runtime must make whenever you make a request for a method that matches a list of parameters. Somewhere deep inside code exists that loops over all methods for a type verifies its visibility checks the return type and also checks the type of each and every parameter. All of this stuff costs time. When you execute that method internally theres some code that does stuff like checking you passed a compatible list of parameters before executing the actual target method. If possible it is always recommended that one caches the method handle if one is going to continually reuse it in the future. Like all good programming tips it often makes sense to avoid repeating oneself. In this case it would be wasteful to continually lookup the method with certain parameters and then execute it each and everytime. Poke around the source and take a look at whats being done.  Reflection can have noticeable impact on performance if you use it for frequent object creation. I've developed application based on Composite UI Application Block which is relying on reflection heavily. There was a noticeable performance degradation related with objects creation via reflection. However in most cases there are no problems with reflection usage. If your only need is to inspect some assembly I would recommend Mono.Cecil which is very lightweight and fast  Reflection performance will depend on the implementation (repetitive calls should be cached eg: entity.GetType().GetProperty(""PropName"")). Since most of the reflection I see on a day to day basis is used to populate entities from data readers or other repository type structures I decided to benchmark performance specifically on reflection when it is used to get or set an objects properties. I devised a test which I think is fair since it caches all the repeating calls and only times the actual SetValue or GetValue call. All the source code for the performance test is in bitbucket at: https://bitbucket.org/grenade/accessortest. Scrutiny is welcome and encouraged. The conclusion I have come to is that it isn't practical and doesn't provide noticeable performance improvements to remove reflection in a data access layer that is returning less than 100000 rows at a time when the reflection implementation is done well. The graph above demonstrates the output of my little benchmark and shows that mechanisms that outperform reflection only do so noticeably after the 100000 cycles mark. Most DALs only return several hundred or perhaps thousands of rows at a time and at these levels reflection performs just fine. Not necessarily. Your DAL conversions may only be on a few thousand items but multiply that by concurrent users using your application (if it's web) and it may add up just as if you'd convert million items. If particular method is 100-times slower it will be that much slower on small and big sets. Slower is slower. @grenade Good information for single access DAL.  Not massively. I've never had an issue with it in desktop development unless as Martin states you're using it in a silly location. I've heard a lot of people have utterly irrational fears about its performance in desktop development. In the Compact Framework (which I'm usually in) though it's pretty much anethema and should be avoided like the plague in most cases. I can still get away with using it infrequently but I have to be really careful with its application which is way less fun. :( +1 for teaching me a new word: anathema. Also for mention of irrational fears. I fear programmers who fear irrationally - it shows that they don't really know what they're doing and just basing what they do on what other people tell them. *cough cargo cult cough* Ahhhh Cargo Cult. Now there is a fine example of curious human behaviour.  As with everything it's all about assessing the situation. In DotNetNuke there's a fairly core component called FillObject that uses reflection to populate objects from datarows. This is a fairly common scenario and there's an article on MSDN Using Reflection to Bind Business Objects to ASP.NET Form Controls that covers the performance issues. Performance aside one thing I don't like about using reflection in that particular scenario is that it tends to reduce the ability to understand the code at a quick glance which for me doesn't seem worth the effort when you consider you also lose compile time safety as opposed to strongly typed datasets or something like LINQ to SQL.  My most pertinent experience was writing code to compare any two data entities of the same type in a large object model property-wise. Got it working tried it ran like a dog obviously. I was despondent then overnight realised that wihout changing the logic I could use the same algorithm to auto-generate methods for doing the comparison but statically accessing the properties. It took no time at all to adapt the code for this purpose and I had the ability to do deep property-wise comparison of entities with static code that could be updated at the click of a button whenever the object model changed. My point being: In conversations with colleagues since I have several times pointed out that their use of reflection could be to autogenerate code to compile rather than perform runtime operations and this is often worth considering. Considering that Visual Studio has such an excellent template support it is a practical way to use code generation  It's bad enough that you have to be worried even about reflection done internally by the .NET libraries for performance-critical code. The following example is obsolete - true at the time (2008) but long ago fixed in more recent CLR versions. Reflection in general is still a somewhat costly thing though! Case in point: You should never use a member declared as ""Object"" in a lock (C#) / SyncLock (VB.NET) statement in high-performance code. Why? Because the CLR can't lock on a value type which means that it has to do a run-time reflection type check to see whether or not your Object is actually a value type instead of a reference type. to be fair a reflection type check is fast. For such 'performance critical code' should you really be using .NET to begin with? @Seph: Dynamic/reflection portions of .NET no. But usual C#/.NET why not? C++ vs C# speedups are marginal at application layer (C++ is still a few % faster on intensive math routines). And I'm guessing you're not suggesting assembly ... A quick test shows that locking on a boxed struct (like object x = 5; lock (x)) works just fine. I also ran some tests to see if there is a performance difference between locking on ""object"" vs locking on a more specific ""object"". I ran 100 million iterations of locking/math/unlocking where the math was just a single simple addition in order to maximize the time spent locking/unlocking. They perform identically no matter what declared type you lock on. A boxed value type (ie. object) can be locked on. @BryceWagner is correct. ""The CLR can't lock on a value type"" actually means that if you tried e.g. `lock(53)` then the `int` would be boxed and the object produced locked on which would be different to the object locked on by another call and hence not really lock anything. Doing `private lockObj = 53` and then `lock(lockObj)` would work perfectly well. The ""run-time reflection type check` bit of this answer is just plain nonsense. To be fair (to me) it is more accurate to say that the answer is ""obsolete"" rather than ""plain nonsense"". My remarks about the behavior of lock(obj) WERE accurate at the time they were written but that implementation-specific behavior of the CLR is long gone.  If you're not in a loop don't worry about it.",c# .net performance reflection
192,A,"Floating Point Number parsing: Is there a Catch All algorithm? One of the fun parts of multi-cultural programming is number formats. Americans use 10000.50 Germans use 10.00050 French use 10 00050 My first approach would be to take the string parse it backwards until I encounter a separator and use this as my decimal separator. There is an obvious flaw with that: 10.000 would be interpreted as 10. Another approach: if the string contains 2 different non-numeric characters use the last one as the decimal separator and discard the others. If I only have one check if it occurs more than once and discard it if it does. If it only appears once check if it has 3 digits after it. If yes discard it otherwise use it as decimal separator. The obvious ""best solution"" would be to detect the User's culture or Browser but that does not work if you have a Frenchman using an en-US Windows/Browser. Does the .net Framework contain some mythical black magic floating point parser that is better than Double.(Try)Parse() in trying to auto-detect the number format? I don't know the ASP.NET side of the problem but .NET has a pretty powerful class: System.Globalization.CultureInfo. You can use the following code to parse a string containing a double value: double d = double.Parse(""100.20"" CultureInfo.CurrentCulture); // -- OR -- double d = double.Parse(""100.20"" CultureInfo.CurrentUICulture); If ASP.NET somehow (i.e. using HTTP Request headers) passes current user's CultureInfo to either CultureInfo.CurrentCulture or CultureInfo.CurrentUICulture these will work fine.  You can't please everyone. If I enter ten as 10.000 and someone enters ten thousand as 10.000 you cannot handle that without some knowledge of the culture of the input. Detect the culture somehow (browser system setting - what is the use case? ASP? Internal app or open to the world?) or provide an example of the expected formatting and use the most lenient parser you can. Probably something like: double d = Double.Parse(""5000.00"" NumberStyles.Any CultureInfo.InvariantCulture);  The difference between 12.345 in French and English is a factor of 1000. If you supply an expected range where max < 1000*min you can easily guess. Take for example the height of a person (including babies and children) in mm. By using a range of 200-3000 an input of 1.800 or 1800 can unambiguously be interpreted as 1 meter and 80 centimeters whereas an input of 912.300 or 912300 can unambiguously be interpreted as 91 centimeters and 2.3 millimeters.  I think the best you can do in this case is to take their input and then show them what you think they meant. If they disagree show them the format you're expecting and get them to enter it again.",c# .net asp.net internationalization globalization
20611,A,"Removing nodes from an XmlDocument The following code should find the appropriate project tag and remove it from the XmlDocument however when I test it it says: The node to be removed is not a child of this node. Does anyone know the proper way to do this? public void DeleteProject (string projectName) { string ccConfigPath = ConfigurationManager.AppSettings[""ConfigPath""]; XmlDocument configDoc = new XmlDocument(); configDoc.Load(ccConfigPath); XmlNodeList projectNodes = configDoc.GetElementsByTagName(""project""); for (int i = 0; i < projectNodes.Count; i++) { if (projectNodes[i].Attributes[""name""] != null) { if (projectName == projectNodes[i].Attributes[""name""].InnerText) { configDoc.RemoveChild(projectNodes[i]); configDoc.Save(ccConfigPath); } } } } UPDATE Fixed. I did two things: XmlNode project = configDoc.SelectSingleNode(""//project[@name='"" + projectName + ""']""); Replaced the For loop with an XPath query which wasn't for fixing it just because it was a better approach. The actual fix was: project.ParentNode.RemoveChild(project); Thanks Pat and Chuck for this suggestion. I was looking for just this thing. I spent a half a day looking for xml stuff on the internet and half a minute on SO. Yet another reason why Jeff and Joel were on to something. Looks like you need to select the parent node of projectNodes[i] before calling RemoveChild.  Is it possible that the project nodes aren't child nodes but grandchildren or lower? GetElementsByTagName will give you elements from anywhere in the child element tree IIRC.  Instead of configDoc.RemoveChild(projectNodes[i]); try projectNodes[i].parentNode.RemoveChild(projectNodes[i]);  When you get sufficiently annoyed by writing it the long way (for me that was fairly soon) you can use a helper extension method provided below. Yay new technology! public static class Extensions { ... public static XmlNode RemoveFromParent(this XmlNode node) { return (node == null) ? null : node.ParentNode.RemoveChild(node); } } ... //some_long_node_expression.parentNode.RemoveChild(some_long_node_expression); some_long_node_expression.RemoveFromParent();  It would be handy to see a sample of the XML file you're processing but my guess would be that you have something like this <Root> <Blah> <project>...</project> </Blah> </Root> The error message seems to be because you're trying to remove from the grandparent rather than the direct parent of the project node  try configDoc.DocumentElement.RemoveChild(projectNodes[i]);",c# .net xml xmldocument
15828,A,"Reading Excel files from C# Is there a free or open source library to read Excel files (.xls) directly from a C# program? It does not need to be too fancy just to select a worksheet and read the data as strings. So far I've been using Export to Unicode text function of Excel and parsing the resulting (tab-delimited) file but I'd like to eliminate the manual step. Will that work in ASP.NET? You can try using this open source solution that makes dealing with Excel a lot more cleaner. http://excelwrapperdotnet.codeplex.com/  SpreadsheetGear is awesome. Yes it's an expense but compared to twiddling with these other solutions it's worth the cost. It is fast reliable very comprehensive and I have to say after using this product in my fulltime software job for over a year and a half their customer support is fantastic! Hard to justify when there are so many simple and effective ways (for free) of reading from and writing to Excel.  Late to the party but I'm a fan of LinqToExcel  If you have multiple tables in the same worksheet you can give each table an object name and read the table using the OleDb method as shown here: http://vbktech.wordpress.com/2011/05/10/c-net-reading-and-writing-to-multiple-tables-in-the-same-microsoft-excel-worksheet/  ExcelMapper is an open source tool (http://code.google.com/p/excelmapper/) that can be used to read Excel worksheets as Strongly Typed Objects. It supports both xls and xlsx formats.  While you did specifically ask for .xls implying the older file formats for the OpenXML formats (e.g. xlsx) I highly recommend the OpenXML SDK (http://msdn.microsoft.com/en-us/library/bb448854.aspx) A++++ would let some other poor sombitch write it for me again. No thanks the OpenXml API is awful! @Quoo disagree completely.  I recommend the FileHelpers Library which is a free and easy to use .NET library to import/export data from EXCEL fixed length or delimited records in files strings or streams + More. The Excel Data Link Documentation Section http://filehelpers.sourceforge.net/example_exceldatalink.html I won't down you but I recently started using FileHelpers and was shocked at how ... crappy it is. For instance the only way to map columns in a csv to properties... excuse me FIELDS of a model is *to create the fields in the order of the columns*. I don't know about you but I wouldn't rely on a quirk of the compiler for one of the most central design considerations of my f8king framework.  Excel Package is an open-source (GPL) component for reading/writing Excel 2007 files. I used it on a small project and the API is straightforward. Works with XLSX only (Excel 200&) not with XLS. The source code also seems well-organized and easy to get around (if you need to expand functionality or fix minor issues as I did). At first I tried the ADO.Net (Excel connection string) approach but it was fraught with nasty hacks -- for instance if second row contains a number it will return ints for all fields in the column below and quietly drop any data that doesn't fit.  I just used ExcelLibrary to load an .xls spreadsheet into a DataSet. Worked great for me.  If it is just simple data contained in the Excel file you can read the data via ADO.NET. See the connection strings listed here: http://www.connectionstrings.com/?carrier=excel2007 or http://www.connectionstrings.com/?carrier=excel -Ryan Update: then you can just read the worksheet via something like select * from [Sheet1$] This way is by far the fastest. Of course that's not true Stingy. You have to sift through all the data and write crappy DB code (hand craft your models map columns to properties yadda yadda). The quickest way is to let *some other poor SOB do this for you*. That's why people use frameworks instead of writing everything from the bottom up. Besides that I have had times where it didn't give me the right results due to localization problems... the neverending fight of seperators Worthless method! Truncates text columns to 255 characters when read. Beware! See: http://stackoverflow.com/questions/1519288/jet-engine-255-character-truncation ACE engine does same thing! Triynko it has been a super long time since I used this method but IIRC you can get around the 255 char limit by defining an ODBC DSN for the spreadsheet and then define the columns as longer in length and then use the DSN to connect to the spreadsheet. It's a pain to do that but I believe that gets around that. Be aware that using ADO.NET to read data from exel requires Microsoft Access or Microsoft Access Database Engine Redistributable installed. The driver will also guess at the columns types based on the first several rows. If you have a column with what looks like integers in the first rows you will encounter an error when you hit a non-integer (e.g. a float a string) This also will not work at ALL if you are running in a 64 bit process. http://forums.asp.net/p/1128266/1781961.aspx  Excel Data Reader is the way to go! It´s Open Source at http://exceldatareader.codeplex.com/ and actively developed. We been using it for reading Tabular (and sometimes not so tabular) worksheets for a couple of years now (In a financial application). Works like a charm to read unit test data from human-readable sheets. Just avoid the feature of trying to return DateTime's as for Excel DateTime's are just double numbers. There is already mention of exceldatareader here http://stackoverflow.com/questions/15828/reading-excel-files-from-c/3665991#3665991 .Why do you think we need another answer. You should comment the link not to create long thread garbage  var fileName = string.Format(""{0}\\fileNameHere"" Directory.GetCurrentDirectory()); var connectionString = string.Format(""Provider=Microsoft.Jet.OLEDB.4.0; data source={0}; Extended Properties=Excel 8.0;"" fileName); var adapter = new OleDbDataAdapter(""SELECT * FROM [workSheetNameHere$]"" connectionString); var ds = new DataSet(); adapter.Fill(ds ""anyNameHere""); DataTable data = ds.Tables[""anyNameHere""]; This is what I usually use. It is a little different because I usually stick a AsEnumerable() at the edit of the tables: var data = ds.Tables[""anyNameHere""].AsEnumerable(); as this lets me use LINQ to search and build structs from the fields. var query = data.Where(x => x.Field<string>(""phoneNumber"") != string.Empty).Select(x => new MyContact { firstName= x.Field<string>(""First Name"") lastName = x.Field<string>(""Last Name"") phoneNumber =x.Field<string>(""Phone Number"") }); If seems like the Select in this approach tries to guess the data type of the column and force upon that guessed data type. For example if you have a column with mostly double values it won't like you passing x.Field but expects x.Field. IS this true? Just looked it up on MSDN. Looks like the is just used to attempt to cast the contents in the column to a type. In this example and just casting the data in the columns to strings. If you wanted a double you would need to call double.Parse(x.Field(""Cost"") or something like that. Field is an extension method for DataRow and it looks like there aren't an non generic versions. Does adding a double.Parse to the Linq query slow it down much? Not that I have noticed. I haven't done any real performance on this. For our uses it isn't being done a lot. +1 for the Linq twist - I LOVE LINQ!! Note that if you're reading `xlsx` you need to use this connection string instead: `string.Format(""Provider=Microsoft.ACE.OLEDB.12.0;Data Source={0}; Extended Properties=Excel 12.0;"" fileName)` Sadly the Jet.OLEDB driver is not 64-bit compatible; you will need to switch to target x86 rather than Any CPU (if you still want to go ahead with this method). Alternatively install the 64-bit ACE driver and change the conn string to use this driver (as indicated by Andreas) - http://www.microsoft.com/en-us/download/details.aspx?displaylang=en&id=13255 Cannot install the 64 bit ACE driver if the target machine has a 32 bit version of office installed. If this helps anyone the Jet driver works fine in Win7 64bit... as long as I actually have the document open in Excel.  Take.io Spreadsheet will do this work for you and at no charge. Just take a look at this. This is a really great little library. It just converts everything into Lists of Lists of strings which is just fine for the kind of work I needed it for.  SmartXLS is another excel spreadsheet component which support most features of excel Chartsformulas engines and can read/write the excel2007 openxml format.  Not free but with the latest Office there's a very nice automation .Net API. (there has been an API for a long while but was nasty COM) You can do everything you want / need in code all while the Office app remains a hidden background process. @Anonymous-type I did read the question and was offering a helpful alternative to a desired OSS implementation ... because well I was pretty sure there was nothing available. And judging by the accepted answer a requirement of having Office installed is not an issue. sorry but i don't think you even read the question.  Just did a quick demo project that required managing some excel files. The .NET component from GemBox software was adequate for my needs. It has a free version with a few limitations. http://www.gemboxsoftware.com/GBSpreadsheet.htm FYI: I tried it and it didn't meet my need to be able to read an encrypted file.  How about Excel Data Reader? http://exceldatareader.codeplex.com/ I've used in it anger in a production environment to pull large amounts of data from a variety of Excel files into SQL Server Compact. It works very well and it's rather robust. I'll second Excel Data Reader; it has also led to the incredibly useful Excel Data Driven Tests library which uses NUnit 2.5's TestCaseSource attribute to make data-driven tests using Excel spreadsheets ridiculously easy. Just beware that Resharper doesn't yet support TestCaseSource so you have to use the NUnit runner. Unfortunately there are some issues with this library that we've just encountered. Firstly we've had some currency fields coming out as dates. Secondly it is crashing if the workbook has any empty sheets in it. So although it was very easy to integrate we are now re-evaluating whether to keep using this library. It does not seem to be being actively developed. It also assumes the presence of some optional elements in xlsx file that cause it to fail to read the data if they're absent. We're having problems with Excel files coming from SQL Server Reporting Services. They just don't work unless you open them and save them (even unedited). @RichieHindle: what optional elements are you talking about (hoping this might help me with my SSRS Excel files)? @Peter: I think it was a missing `` element in the `` that was causing trouble for me. @RichieHindle: ah I think that has been solved now. Thanks As an update to my comment above. We did keep going with this library and in fact I and another guy have become developers on the project and it is now actively being worked on again. The issues I mentioned have now been fixed as has open office support and hopefully SSRS (need someone to test it).  The ADO.NET approach is quick and easy but it has a few quirks which you should be aware of especially regarding how DataTypes are handled. This excellent article will help you avoid some common pitfalls: http://blog.lab49.com/archives/196 You answered my question (in the form of a comment above).  The .NET component Excel Reader .NET may satisfy your requirement. It's good enought for reading XLSX and XLS files. So try it from: http://www.devtriogroup.com/ExcelReader  I did a lot of reading from Excel files in C# a while ago and we used two approaches: The COM API where you access Excel's objects directly and manipulate them through methods and properties The ODBC driver that allows to use Excel like a database. The latter approach was much faster: reading a big table with 20 columns and 200 lines would take 30 seconds via COM and half a second via ODBC. So I would recommend the database approach if all you need is the data. Cheers Carl  We use ClosedXML in rather large systems. Free Easy to install Straight forward coding Very responsive support Developer team is extremly open to new suggestions. Often new features and bug fixes are implemented within the same week  I know that people have been making an Excel ""extension"" for this purpose. You more or less make a button in Excel that says ""Export to Program X"" and then export and send off the data in a format the program can read. http://msdn.microsoft.com/en-us/library/ms186213.aspx should be a good place to start. Good luck  If it's just tabular data. I would recommend file data helpers by Marcos Melli which can be downloaded here. That's a great library!  Here's some code I wrote in C# using .NET 1.1 a few years ago. Not sure if this would be exactly what you need (and may not be my best code :)). using System; using System.Data; using System.Data.OleDb; namespace ExportExcelToAccess { /// <summary> /// Summary description for ExcelHelper. /// </summary> public sealed class ExcelHelper { private const string CONNECTION_STRING = ""Provider=Microsoft.Jet.OLEDB.4.0;Data Source=<FILENAME>;Extended Properties=\""Excel 8.0;HDR=Yes;\"";""; public static DataTable GetDataTableFromExcelFile(string fullFileName ref string sheetName) { OleDbConnection objConnection = new OleDbConnection(); objConnection = new OleDbConnection(CONNECTION_STRING.Replace(""<FILENAME>"" fullFileName)); DataSet dsImport = new DataSet(); try { objConnection.Open(); DataTable dtSchema = objConnection.GetOleDbSchemaTable(OleDbSchemaGuid.Tables null); if( (null == dtSchema) || ( dtSchema.Rows.Count <= 0 ) ) { //raise exception if needed } if( (null != sheetName) && (0 != sheetName.Length)) { if( !CheckIfSheetNameExists(sheetName dtSchema) ) { //raise exception if needed } } else { //Reading the first sheet name from the Excel file. sheetName = dtSchema.Rows[0][""TABLE_NAME""].ToString(); } new OleDbDataAdapter(""SELECT * FROM ["" + sheetName + ""]"" objConnection ).Fill(dsImport); } catch (Exception) { //raise exception if needed } finally { // Clean up. if(objConnection != null) { objConnection.Close(); objConnection.Dispose(); } } return dsImport.Tables[0]; #region Commented code for importing data from CSV file. // string strConnectionString = ""Provider=Microsoft.Jet.OLEDB.4.0;"" +""Data Source="" + System.IO.Path.GetDirectoryName(fullFileName) +"";"" +""Extended Properties=\""Text;HDR=YES;FMT=Delimited\""""; // // System.Data.OleDb.OleDbConnection conText = new System.Data.OleDb.OleDbConnection(strConnectionString); // new System.Data.OleDb.OleDbDataAdapter(""SELECT * FROM "" + System.IO.Path.GetFileName(fullFileName).Replace(""."" ""#"") conText).Fill(dsImport); // return dsImport.Tables[0]; #endregion } /// <summary> /// This method checks if the user entered sheetName exists in the Schema Table /// </summary> /// <param name=""sheetName"">Sheet name to be verified</param> /// <param name=""dtSchema"">schema table </param> private static bool CheckIfSheetNameExists(string sheetName DataTable dtSchema) { foreach(DataRow dataRow in dtSchema.Rows) { if( sheetName == dataRow[""TABLE_NAME""].ToString() ) { return true; } } return false; } } } This code needs some Resharper love Couldn't agree more Cherian. This code is many years old... before I even was proficient with Resharper :) The code is ugly but it shows how to get the sheet names great! This gets the job done. Thanks!  you could write an excel spreadsheet that loads a given excel spreadsheet and saves it as csv (rather than doing it manually). then you could automate that from c#. and once its in csv the c# program can grok that. (also if someone asks you to program in excel it's best to pretend you don't know how) (edit: ah yes rob and ryan are both right)  Koogra is an open-source component written in C# that reads and writes Excel files. I think this link needs updated... http://koogra.sourceforge.net/ Oops! Very wrong url! Fixed now Doesn't look particularly active any more compared to say NPOI  The solution that we used needed to: Allow Reading/Writing of Excel produced files Be Fast in performance (not like using COMs) Be MS Office Independent (needed to be usable without clients having MS Office installed) Be Free or Open Source (but actively developed) There are several choices but we found NPoi (.NET port of Java's long existing Poi open source project) to be the best: http://npoi.codeplex.com/ It also allows working with .doc and .ppt file formats  This is what I used for Excel 2003: Dictionary<string string> props = new Dictionary<string string>(); props[""Provider""] = ""Microsoft.Jet.OLEDB.4.0""; props[""Data Source""] = repFile; props[""Extended Properties""] = ""Excel 8.0""; StringBuilder sb = new StringBuilder(); foreach (KeyValuePair<string string> prop in props) { sb.Append(prop.Key); sb.Append('='); sb.Append(prop.Value); sb.Append(';'); } string properties = sb.ToString(); using (OleDbConnection conn = new OleDbConnection(properties)) { conn.Open(); DataSet ds = new DataSet(); string columns = String.Join("""" columnNames.ToArray()); using (OleDbDataAdapter da = new OleDbDataAdapter( ""SELECT "" + columns + "" FROM ["" + worksheet + ""$]"" conn)) { DataTable dt = new DataTable(tableName); da.Fill(dt); ds.Tables.Add(dt); } } very clean code! worksheet isn't defined... seems a bit odd to me after clearly defining everything else.  Lately partly to get better at LINQ.... I've been using Excel's automation API to save the file as XML Spreadsheet and then get process that file using LINQ to XML. XML Spreadsheet is a fairly clean format :) But like excel files.... can we protect xml files with password? I would suspect you can protect it from Excel but not from man with compiler...like anything...it's just bytes. @gsvirdi post a seperate question on Excel file security this question is on performance.  I want to show a simple method to read xls/xlsx file with .NET. I hope that the following will be helpful for you.  private DataTable ReadExcelToTable(string path) { //Connection String string connstring = ""Provider=Microsoft.ACE.OLEDB.12.0;Data Source="" + path + "";Extended Properties='Excel 8.0;HDR=NO;IMEX=1';""; //the same name //string connstring = Provider=Microsoft.JET.OLEDB.4.0;Data Source="" + path + //"";Extended Properties='Excel 8.0;HDR=NO;IMEX=1';""; using(OleDbConnection conn = new OleDbConnection(connstring)) { conn.Open(); //Get All Sheets Name DataTable sheetsName = conn.GetOleDbSchemaTable(OleDbSchemaGuid.Tablesnew object[]{nullnullnull""Table""}); //Get the First Sheet Name string firstSheetName = sheetsName.Rows[0][2].ToString(); //Query String string sql = string.Format(""SELECT * FROM [{0}]""firstSheetName); OleDbDataAdapter ada =new OleDbDataAdapter(sqlconnstring); DataSet set = new DataSet(); ada.Fill(set); return set.Tables[0]; } } Code is from article: http://www.c-sharpcorner.com/uploadfile/d2dcfc/read-excel-file-with-net/. You can get more details from it. It **was** helpful especially the part about reading the sheetnames.  Forgive me if I am off-base here but isn't this what the Office PIA's are for? Yes but that would involve creating an Excel.Application instance loading the xls file etc. If the requirement is purely to read some data from the file then it's much easier and far more lightweight to use one of the ADO.NET methods described in the other answers. Too slow using Office PIA as the baseline everything else is faster - even just using an Object array passed from .Value2 property. Which is still using the PIA.  SpreadsheetGear for .NET is an Excel compatible spreadsheet component for .NET. You can see what our customers say about performance on the right hand side of our product page. You can try it yourself with the free fully-functional evaluation.",c# .net excel ms-office
9173,A,"Lingering assembly dependency in C# .NET My C# project - we'll call it the SuperUI - used to make use of a class from an external assembly. Now it doesn't but the compiler won't let me build the project without the assembly reference in place. Let me elaborate. This project used to throw and catch a custom exception class - the SuperException - which was derived from the standard System.Exception and lived in a separate precompiled assembly SuperAssembly.DLL which I referenced. Eventually I decided this was a pointless exercise and replaced all SuperExceptions with a System.SuitableStandardException in each case. I removed the reference to SuperException.DLL but am now met with the following on trying to compile the project: The type 'SuperException' is defined in an assembly that is not referenced. You must add a reference to assembly 'SuperException Version=1.1.0.0 (...)' The source file referenced by the error doesn't seem relevant; it's the project namespace that gets highlighted in the IDE. Now here's the thing: All uses of SuperException have been eliminated from the project's code. Compared to another project that compiles fine without a reference to SuperException.DLL I only reference one more assembly - and that references nothing that my project doesn't reference itself. While it's possible that any of these dependencies could throw SuperExceptions I'm only catching the base Exception class and in any case... the other project builds fine! I've done Visual Studio's ""Clean Solution"" and cleared everything out by hand many times. It's not the end of the world to include this reference I just don't see why it's necessary any more. Nrrrgg. Any pointers welcome! I agree with the other comments here.. There is a reference in plain text somewhere ! I have had similar problems in the past where searching through the project files returned nothing turns out it was in some other file that wasn't automatically picked up in the search. I don't think that creating a new project is the solution here.. You need to be positive that NONE of the references in your dependency tree use SuperException.. NONE I have never experienced this to the point where I have needed to literally wipe the project I have always found the reference somewhere. Ensure you are searching every file. EDIT: Just a point to add if the location pointed to by the error seems random that can often mean there is a mismatch between the compiled source and the source code file.. Is this a ASP.NET application? I have had it before where the compiled DLL's haven't been replaced on a rebuild in the ASP.NET temp folder causing things to get.. Interesting when debugging :)  I’ve had a very similar assembly reference issue that was happening when my C# library had a dependent C++/CLI assembly. The problem that was I was inheriting a public class from that C++/CLI assembly in my C# assembly library. That meant that the inheritance chain was spanning across multiple assemblies. I was hoping that any client would be smart enough to indirectly load the C++/CLI assembly any time the C# library needed it but that was not the case even at compile time. I got rid of this problem by breaking the inheritance between the classes that were spanning across those two assembly libraries and using aggregation instead. My client was finally happy and did not require the C++/CLI assembly as a dependency anymore. In your word you would probably have to make sure that SuitableStandardException does not inherit from SuperException in order to eliminate the SuperException.DLL as a reference. Use encapsulation instead of inheritance and create a SuperException data member in your new SuitableStandardException. If that does not solve it you might have more classes spanning inheritance across some assemblies in your case SuperAssembly.DLL and superException.dll. If you can't find all of them try this trick: Make all your public members and classes in SuperAssembly.DLL internal. In the SuperAssembly.DLL make friends with SuperException.DLL: [assembly:InternalsVisibleTo(""SuperException PublicKey=0024000004800000....)] Make sure that they build and remove the SuperAssembly.DLL reference from any client that already references SuperException.DLL.  This is where tools like Resharper really pay off -- a simple Find Usages usually tells me of such ""ghost dependencies"" several times. Maybe you could go to your definition of the SuperException class and try to Find All References(). You might also want to investigate if the assembly SuperException is has a circular dependency on your main assembly (e.g. main assembly depends on exception assembly depends on main assembly...).  grep your project folder. It could be a hidden reference in your project or a project that your project references. Cleanse with Notepad if needed.  Thanks for your answers so far. I've tried every suggestion (except one) to no avail. The suggestion I haven't tried is to create a new project and add all my stuff to it the thought of which really tests my will to live. ;) I may try this tomorrow if I can be bothered. Thanks again.  If you reference any types that inherits from SuperException (even if the type defined in another assembly) you need a reference to the assembly that SuperException is defined in. Seconded on that. You might not be referencing SuperException but you might be referencing SpecializedSuperException which is derived from or somehow otherwise uses SuperException - your grep of the project for SuperException won't be catching it though. Try have a hack with the trial of NDepend  There is really nothing very mysterious about VS projects nowadays - it's all text files etc. SOMETHING must reference that class/dll and that something must be part of your project. Have you really grep'd or findstr'd the whole solution tree every single file for a reference to that exception?  Try creating a new project and adding all your classes to it.  This sounds pretty strange. Here's what I would check next: Check that there's nothing lingering in your Properties/AssemblyInfo.cs file. Check that there's nothing lingering in your SuperUI.csproj file. Delete all references and re-add them.  Since it's a compiler error there must be a reference or use of SuperException somewhere in the project. Do a find/replace in the entire project or solution for that type and remove every reference (it's possible you already did this). If you reference any types that inherits from SuperException (even if the type defined in another assembly) you need a reference to the assembly that SuperException is defined in. Take the line that the compiler is showing the error on and start tracing the inheritance tree of the objects used on that line you might find the source of it that way.  grep -R SuperException * in the base of your project (get grep from somewhere first) just to be sure.  I don't think this is a code issue. What I can see happening is that one of your existing references probably rely on that type in their own types which you are probably creating in your application. If that is the case you do need that reference even if you don't explicitly use the type and even though the other referenced assembly has its own reference. You sometimes get that issue with 3rd party components which need references to types that you haven't referenced. The compiler is obviously seeing something in one of your existing referenced assemblies and is expecting you to referenced the dependent one. Try searching the other referenced assemblies for the SuperException with Reflector to verify that they aren't referencing the assembly.  Exit Visual Studio Delete the bin and obj Folders in your solution directory Restart and see what happens  It's likely a transitive reference where some type method call returns an instance of SuperException boxed (""downcast"") as e.g. Exception but from inspecting the code in the transitively included code i.e. code from your external method calls the compiler knows that you need to be able to have information about that type at some point. Resharper would tell you where it's the case that you need to add a reference and you could use Lütz Roeder's aka RedGate's Reflector to scan compiled IL for a reference to this type in two ways: 1) use the search-facility 2) open each public type you're using and for that one which requires the ""ghost"" assembly it will ask you to specify its location. This most often happends to me when I reference Castle.Windsor but not Castle.MicroKernel. :p",c# .net dependencies
9472,A,"WCF Backward Compatibility Issue I have a WCF service that I have to reference from a .net 2.0 project. I have tried to reference it using the ""add web reference"" method but it messes up the params. For example I have a method in the service that expects a char[] to be passed in but when I add the web reference the method expects an int[]. So then I tried to setup svcutil and it worked... kind of. I could only get the service class to compile by adding a bunch of .net 3.0 references to my 2.0 project. This didn't sit well with the architect so I've had to can it (and probably for the best too). So I was wondering if anyone has any pointers or resources on how I can setup a .net 2.0 project to reference a WCF service. One of those instances that you need to edit the WSDL. For a start a useful tool http://codeplex.com/storm  Thanks for the resource. It certainly helped me test out the webservice but it didn't much help with using the WCF service in my .net 2.0 application. What I eventually ended up doing was going back to the architects and explaining that the 3.0 dll's that I needed to reference got compiled back to run on the 2.0 CLR. We don't necessarily like the solution but we're going to go with it for now as there doesn't seem to be too many viable alternatives  What binding are you using - I think if you stick to the basicHttp binding you should be able to generate a proxy using the ""add web reference"" approach from a .net 2 project? Perhaps if you post the contract/interface definition it might help? Cheers Richard  I was using the basicHttp binding but the problem was actually with the XMLSerializer. It doesn't properly recognize the wsdl generated by WCF (even with basicHttp bindings) for anything other than basic value types. We got around this by added the reference to the 3.0 dll's and using the datacontract serializer.",c# .net wcf
18421,A,"Best way to bind Windows Forms properties to ApplicationSettings in C#? In a desktop application needing some serious re-factoring I have several chunks of code that look like this: private void LoadSettings() { WindowState = Properties.Settings.Default.WindowState; Location = Properties.Settings.Default.WindowLocation; ... } private void SaveSettings() { Properties.Settings.Default.WindowState = WindowState; Properties.Settings.Default.WindowLocation = Location; ... } What's the best way to replace this? Project-imposed constraints: Visual Studio 2005 C# / .NET 2.0 Windows Forms Update Thanks Tundey that looks like the way to go. For posterity I've also found two useful tutorials: ""Windows Forms User Settings in C#"" and ""Exploring Secrets of Persistent Application Settings"". I've asked a follow-up question about using this technique to bind a form's Size here. I separated them out to help people who search for similar issues. If you open your windows form in the designer look in the properties box. The first item should be ""(ApplicationSetting)"". Under that is ""(PropertyBinding)"". That's where you'll find the option to do exactly what you want.",c# .net
6301,A,"Why is Array.Length an int and not an uint Why is Array.Length an int and not an uint. This bothers me (just a bit) because a length value can never by negative. This also forced me to use an int for a length-property on my own class because when you specify an int-value this needs to be cast explicity... So the ultimate question is: is there any use for an unsigned int (uint)? Even Microsoft seems not to use them. Despite the issues raised below I think it should change to UInt. @alan2here making such a change would break almost all code out there so it wont happen if you ask me! Many reasons: uint is not CLS compliant thus making a built in type (array) dependent on it would have been problematic The runtime as originally designed prohibits any object on the heap occupying more than 2GB of memory. Since the maximum sized array that would less than or equal to this limit would be new byte[int.MaxValue] it would be puzzling to people to be able to generate positive but illegal array lengths. Note that this limitation has been somewhat removed in the 4.5 release though the standard Length as int remains. Historically C# inherits much of its syntax and convention from C and C++. In those arrays are simply pointer arithmetic so negative array indexing was possible (though normally illegal and dangerous). Since much existing code assumes that the array index is negative this would have been a factor On a related note the use of signed integers for array indexes in C/C++ means that interop with these languages and unmanaged functions would require the use of ints in those circumstances anyway which may confuse due to the inconsistency. The BinarySearch implementation (a very useful component of many algorithms) relies on being able to use the negative range of the int to indicate that the value was not found and the location at which such a value should be inserted to maintain sorting. When operating on an array it is likely that you would want to take a negative offset of an existing index. If you used an offset which would take you past the start of the array using unit then the wrap around behaviour would make your index possibly legal (in that it is positive). With an int the result would be illegal (but safe since the runtime would guard against reading invalid memory) If nothing on the heap can be over 2Gb then almost all arrays of length int.MaxValue are illegal since most types are larger than 1 byte. indeed but ((uint)(int.MaxValue)) + 1 would be guaranteed wrong for *anything*. int is itself far from perfect but the balance of things makes it legit to stay with int as the type. Starting out with be an explict ArrayIndex type (essentially size_t) that would translate cleanly and safely to an int as needed perhaps would make it easier in future to make really use allowing for > 2GB arrays in future with less pain. But pragmatics say java has same problem so why take the risk This is very informative. In Windows Communication Foundation as of .NET 4.0 - the largest values were 2147483647 for `maxArrayLength` and `maxBytesPerRead` which retrospectively makes a lot of sense with this information. Connecting the dots...  Unsigned int isn't CLS compliant and would therefore restrict usage of the property to those languages that do implement a UInt. Update: See here: Framework 1.1 http://msdn.microsoft.com/en-us/library/hfa3fa08(VS.71).aspx Framework 2.0 http://msdn.microsoft.com/en-us/library/hfa3fa08(VS.80).aspx  I think it also might have to do with simplifying things on a lower level since Array.Length will of course be added to a negative number at some point if Array.Length were unsigned and added to a negative int (two's complement) there could be messy results. Please give an example? `uint lenght = 3;int x = -4;Console.WriteLine(x+lenght);` yields -1 just fine.  Typically integer values are signed unless you explicitly need an unsigned value. It's just the way they are used. I may not agree with that choice but that's just the way it is. For the time being with todays typical memory constraints if your array or similar data structure needs an UInt32 length you should consider other data structures. With an array of bytes Int32 will give you 2GB of values ""but that's just the way it is."" -- no things are never just the way they are. There's always a design decision being made and it always pays to ask why. One might learn something from the pros and cons or engage the designer (in some cases) in a discussion about the them. Always ask questions! :)  Looks like nobody provided answer to ""the ultimate question"". I believe primary use of unsigned ints is to provide easier interfacing with external systems (P/Invoke and the like) and to cover needs of various languages being ported to .NET. Unsigned types are essential when concatenating multiple smaller values to produce a larger one. One can combine two UInt16's to make a UInt32 by computing `(HighPart << 16) + LowPart` and one may split a UInt32 into two UInt16's via `(Uint16)(Value >> 16)` and `(Uint16)(Value & 65535)`. Such operations would be very inconvenient if `LowPart` had to be a signed type. That having been said interactions between signed and unsigned types are often confusing and problematical. Unsigned types should in many ways be considered a world of their own.",c# .net int uint
13060,A,"What do ref val and out mean on method parameters? I'm looking for a clear concise and accurate answer. Ideally as the actual answer although links to good explanations welcome. This also applies to VB.Net but the keywords are different - ByRef and ByVal. This article ""Parameter passing in C#"" is the most complete explanation I've read so far.  out means that the parameter will be initialised by the method: int result; //not initialised if( int.TryParse( ""123"" out result ) ) //result is now 123 else //if TryParse failed result has still be // initialised to its default value (0) ref will force the underlying reference to be passed: void ChangeMyClass1( MyClass input ) { input.MyProperty = ""changed by 1""; input = null; //can't see input anymore ... // I've only nulled my local scope's reference } void ChangeMyClass2( ref MyClass input ) { input.MyProperty = ""changed by 2""; input = null; //the passed reference is now null too. } MyClass tester = new MyClass { MyProperty = ""initial value"" }; ChangeMyClass1( tester ); // now tester.MyProperty is ""changed by 1"" ChangeMyClass2( ref tester ); // now tester is null  One of my own questions at stackoverflow handles this topic too. It handles about ""pass by reference"" and ""pass by value"" in different types of languages c# is included so maybe you can find some extra information there as well. Basically it comes down to: ref: the parameter with the ref keyword will be passed by reference out: the parameter with the out keyword will be treated as an output parameter but that's really the most basic answer you can give as it is a little more complex than it is stated here  By default (in C#) passing an object to a function actually passes a copy of the reference to that object. Changing the parameter itself only changes the value in the parameter and not the variable that was specified. void Test1(string param) { param = ""new value""; } string s1 = ""initial value""; Test1(s1); // s1 == ""initial value"" Using out or ref passes a reference to the variable specified in the call to the function. Any changes to the value of an out or ref parameter will be passed back to the caller. Both out and ref behave identically except for one slight difference: ref parameters are required to be initialised before calling while out parameters can be uninitialised. By extension ref parameters are guaranteed to be initialised at the start of the method while out parameters are treated as uninitialised. void Test2(ref string param) { param = ""new value""; } void Test3(out string param) { // Use of param here will not compile param = ""another value""; } string s2 = ""initial value""; string s3; Test2(ref s2); // s2 == ""new value"" // Test2(ref s3); // Passing ref s3 will not compile Test3(out s2); // s2 == ""another value"" Test3(out s3); // s3 == ""another value"" Edit: As dp points out the difference between out and ref is only enforced by the C# compiler not by the CLR. As far as I know VB has no equivalent for out and implements ref (as ByRef) only matching the support of the CLR. ""copy of the reference to that object"" or ""reference to the copy of that object"" ?  One additional note about ref vs. out: The distinction between the two is enforced by the C# compiler. The CLR does not distinguish between between out and ref. This means that you cannot have two methods whose signatures differ only by an out or ref void foo(int value) {} // Only one of the following would be allowed // valid to overload with ref void foo(ref int value) {} // OR with out void foo(out int value) {}",c# .net vb.net
6184,A,"How do I make event callbacks into my win forms thread safe? When you subscribe to an event on an object from within a form you are essentially handing over control of your callback method to the event source. You have no idea whether that event source will choose to trigger the event on a different thread. The problem is that when the callback is invoked you cannot assume that you can make update controls on your form because sometimes those controls will throw an expection if the event callback was called on a thread different than the thread the form was run on. To simplify Simon's code a bit you could use the built in generic Action delegate. It saves peppering your code with a bunch of delegate types you don't really need. Also in .NET 3.5 they added a params parameter to the Invoke method so you don't have to define a temporary array. void SomethingHappened(object sender EventArgs ea) { if (InvokeRequired) { Invoke(new Action<object EventArgs>(SomethingHappened) sender ea); return; } textBox1.Text = ""Something happened""; }  I'm a bit late to this topic but you might want to take a look at the Event-Based Asynchronous Pattern. When implemented properly it guarantees that events are always raised from the UI thread. Here's a brief example that only allows one concurrent invocation; supporting multiple invocations/events requires a little bit more plumbing. using System; using System.ComponentModel; using System.Threading; using System.Windows.Forms; namespace WindowsFormsApplication1 { public class MainForm : Form { private TypeWithAsync _type; [STAThread()] public static void Main() { Application.EnableVisualStyles(); Application.Run(new MainForm()); } public MainForm() { _type = new TypeWithAsync(); _type.DoSomethingCompleted += DoSomethingCompleted; var panel = new FlowLayoutPanel() { Dock = DockStyle.Fill }; var btn = new Button() { Text = ""Synchronous"" }; btn.Click += SyncClick; panel.Controls.Add(btn); btn = new Button { Text = ""Asynchronous"" }; btn.Click += AsyncClick; panel.Controls.Add(btn); Controls.Add(panel); } private void SyncClick(object sender EventArgs e) { int value = _type.DoSomething(); MessageBox.Show(string.Format(""DoSomething() returned {0}."" value)); } private void AsyncClick(object sender EventArgs e) { _type.DoSomethingAsync(); } private void DoSomethingCompleted(object sender DoSomethingCompletedEventArgs e) { MessageBox.Show(string.Format(""DoSomethingAsync() returned {0}."" e.Value)); } } class TypeWithAsync { private AsyncOperation _operation; // synchronous version of method public int DoSomething() { Thread.Sleep(5000); return 27; } // async version of method public void DoSomethingAsync() { if (_operation != null) { throw new InvalidOperationException(""An async operation is already running.""); } _operation = AsyncOperationManager.CreateOperation(null); ThreadPool.QueueUserWorkItem(DoSomethingAsyncCore); } // wrapper used by async method to call sync version of method matches WaitCallback so it // can be queued by the thread pool private void DoSomethingAsyncCore(object state) { int returnValue = DoSomething(); var e = new DoSomethingCompletedEventArgs(returnValue); _operation.PostOperationCompleted(RaiseDoSomethingCompleted e); } // wrapper used so async method can raise the event; matches SendOrPostCallback private void RaiseDoSomethingCompleted(object args) { OnDoSomethingCompleted((DoSomethingCompletedEventArgs)args); } private void OnDoSomethingCompleted(DoSomethingCompletedEventArgs e) { var handler = DoSomethingCompleted; if (handler != null) { handler(this e); } } public EventHandler<DoSomethingCompletedEventArgs> DoSomethingCompleted; } public class DoSomethingCompletedEventArgs : EventArgs { private int _value; public DoSomethingCompletedEventArgs(int value) : base() { _value = value; } public int Value { get { return _value; } } } } I think it's a bit misleading to say 'it guarantees that events are always raised from the UI thread'. Wouldn't it be more accurate to say that it ensures that the event handler is executed on the same SynchronizationContext / thread on which the task was created? (Which might not be the UI thread / SynchronizationContext)  As the lazy programmer I have a very lazy method of doing this. What I do is simply this. private void DoInvoke(MethodInvoker del) { if (InvokeRequired) { Invoke(del); } else { del(); } } //example of how to call it private void tUpdateLabel(ToolStripStatusLabel lbl String val) { DoInvoke(delegate { lbl.Text = val; }); } You could inline the DoInvoke inside your function or hide it within separate function to do the dirty work for you. Just keep in mind you can pass functions directly into the DoInvoke method. private void directPass() { DoInvoke(this.directInvoke); } private void directInvoke() { textLabel.Text = ""Directly passed.""; } I'm all for lazy programming :) If you're using .NET 3.5 or higher you can use `Action` or `Action` along with lambda expressions: `Doinvoke(() => textLabel.Text = ""Something"")`  In many simple cases you can use the MethodInvoker delegate and avoid the need to create your own delegate type.  I use anonymous methods a lot in this scenario: void SomethingHappened(object sender EventArgs ea) { MethodInvoker del = delegate{ textBox1.Text = ""Something happened""; }; InvokeRequired ? Invoke( del ) : del(); }  Here are the salient points: You can't make UI control calls from a different thread than the one they were created on (the form's thread). Delegate invocations (ie event hooks) are triggered on the same thread as the object that is firing the event. So if you have a separate ""engine"" thread doing some work and have some UI watching for state changes which can be reflected in the UI (such as a progress bar or whatever) you have a problem. The engine fire's an object changed event which has been hooked by the Form. But the callback delegate that the Form registered with the engine gets called on the engine's thread… not on the Form's thread. And so you can't update any controls from that callback. Doh! BeginInvoke comes to the rescue. Just use this simple coding model in all your callback methods and you can be sure that things are going to be okay: private delegate void EventArgsDelegate(object sender EventArgs ea); void SomethingHappened(object sender EventArgs ea) {  //  // Make sure this callback is on the correct thread  //  if (this.InvokeRequired)  {  this.Invoke(new EventArgsDelegate(SomethingHappened) new object[] { sender ea });  return;  }  //  // Do something with the event such as update a control  //  textBox1.Text = ""Something happened""; } It's quite simple really. Use InvokeRequired to find out if this callback happened on the correct thread. If not then reinvoke the callback on the correct thread with the same parameters. You can reinvoke a method by using the Invoke (blocking) or BeginInvoke (non-blocking) methods. The next time the function is called InvokeRequired returns false because we are now on the correct thread and everybody is happy. This is a very compact way of addressing this problem and making your Forms safe from multi-threaded event callbacks. I can see places where a separate ""event bus"" to handle synchronization could be useful but in many cases it would seem easiest for the end user of something like a progress-indicator class if the class simply exposed a MinimumUpdateInterval property. @Supercat... event throttling is an important topic for many applications but it is not something that should be part of the UI layer. A separate event proxy bus should be created to receive queue combine and resend events at appropriate intervals. Any subscriber to the event bus should not know that event throttling is occurring. I generally prefer BeginInvoke to Invoke but there's a caveat: one must avoid queueing up too many events. I use an updateRequired variable which is set to 1 when a BeginInvoke would happen and only perform the BeginInvoke if it had been zero (using Interlocked.Exchange). The display handler has a while loop that clears updateRequired and if it wasn't zero does an update and loops. In some cases a timer is added to further limit update frequency (to avoid having code spend all its time updating the progress readout instead of doing real work) but that's more complicated.",c# .net winforms multithreading events
27455,A,"Does Mono support System.Drawing and System.Drawing.Printing? I'm attempting to use Mono to load a bitmap and print it on Linux but I'm getting an exception. Does Mono support printing on Linux? The code/exception are below: EDIT: No longer getting the exception but I'm still curious what kind of support there is. Leaving the code for posterity or something. private void btnPrintTest_Click(object sender EventArgs e) { _printDocTest.DefaultPageSettings.Landscape = true; _printDocTest.DefaultPageSettings.Margins = new Margins(50505050); _printDocTest.Print(); } void _printDocTest_PrintPage(object sender PrintPageEventArgs e) { var bmp = new Bitmap(""test.bmp""); // Determine center of graph var xCenter = e.MarginBounds.X + (e.MarginBounds.Width - bmp.Width) / 2; var yCenter = e.MarginBounds.Y + (e.MarginBounds.Height - bmp.Height) / 2; e.Graphics.DrawImage(bmp xCenter yCenter); e.HasMorePages = false; } Oh..oops looks like I was just specifying the file path wrong (changed it to open the file first then load it into a bitmap). Got it working now -- nothing to see here move along. According to System.Drawing is now complete and in addition to being the underlying rendering engine for Windows.Forms it has also been tested for using third party controls that heavily depend on it.  From the Mono docs I think yes: Managed.Windows.Forms (aka System.Windows.Forms): A complete and cross platform System.Drawing based Winforms implementation. It also useful if you run the Mono Migration Analyzer first.",c# .net linux printing mono
9376,A,"ILMerge Best Practices Do you use ILMerge? Do you use ILMerge to merge multiple assemblies to ease deployment of dll's? Have you found problems with deployment/versioning in production after ILMerging assemblies together? I'm looking for some advice in regards to using ILMerge to reduce deployment friction if that is even possible. I recently had issue where I had ilmerged assembly in the assembly i had some classes these were being called via reflection in Umbraco opensource CMS. The information to make the call via reflection was taken from db table that had assembly name and namespace of class that implemented and interface. The issue was that the reflection call would fail when dll was il merged however if dll was separate it all worked fine. I think issue may be similar to the one longeasy is having?  We just started using ILMerge in our solutions that are redistributed and used in our other projects and so far so good. Everything seems to work okay. We even obfuscated the packaged assembly directly. We are considering doing the same with the MS Enterprise Library assemblies. The only real issue I see with it is versioning of individual assemblies from the package.  It seems to me like the #1 ILMerge Best Practice is Don't Use ILMerge. Instead use SmartAssembly. One reason for this is that the #2 ILMerge Best Practice is to always run PEVerify after you do an ILMerge because ILMerge does not guarantee it will correctly merge assemblies into a valid executable. Other ILMerge disadvantages: when merging it strips XML Comments (if I cared about this I would use an obfuscation tool) it doesn't correctly handle creating a corresponding .pdb file Another tool worth paying attention to is Mono.Cecil and the Mono.Linker [2] tool. [2]: http:// www.mono-project.com/Linker ""it doesn't correctly handle creating a corresponding .pdb file"" - under what conditions is this true? I've watched ILMerge generate merged pdb's and used them without issue. When any of the assemblies you want to merge does not already have a .pdb. Also SmartAssembly correctly handles WPF resources such as BAML.  We ran into problems when merging DLLs that have resources in the same namespace. In the merging process one of the resource namespaces was renamed and thus the resources couldn't be located. Maybe we're just doing something wrong there still investigating the issue.  I know this is an old question but we not only use ILMerge to reduce the number of dependencies but also to internalise the ""internal"" dependencies (eg automapper restsharp etc) that are used by the utility. This means they are completely abstracted away and the project using the merged utility doesn't need to know about them. This again reduces the required references in the project and allows it to use / update its own version of the same external library if required.  I use ILMerge for almost all of my different applications. I have it integrated right into the release build process so what I end up with is one exe per application with no extra dll's. You can't ILMerge any C++ assemblies that have native code. You also can't ILMerge any assemblies that contain XAML for WPF (at least I haven't had any success with that). It complains at runtime that the resources cannot be located. I did write a wrapper executable for ILMerge where I pass in the startup exe name for the project I want to merge and an output exe name and then it reflects the dependent assemblies and calls ILMerge with the appropriate command line parameters. It is much easier now when I add new assemblies to the project I don't have to remember to update the build script. How did you do that release build integration? @Svish -- http://www.hanselman.com/blog/MixingLanguagesInASingleAssemblyInVisualStudioSeamlesslyWithILMergeAndMSBuild.aspx Here's a potential workaround for ILMerge + XAML: http://richarddingwall.name/2009/05/14/wpf-how-to-combine-mutliple-assemblies-into-a-single-exe/ http://roman.st/Article/ILMerge-and-GeneratedInternalTypeHelper - Another Workaround for ILMerge + XAML [ILRepack](https://github.com/gluck/il-repack) is an open source alternative and (to some extend) supports WPF repacking.  We use ILMerge on quite a few projects. The Web Service Software Factory for example produces something like 8 assemblies as its output. We merge all of those DLLs into a single DLL so that the service host will only have to reference one DLL. It makes life somewhat easier but it's not a big deal either.  For Console Apps Here is the basic ""Post Build String"" for Visual Studio 2010 SP1 using .NET 4.0. I am building a console .exe with all of the sub-.dll files included in it. ""$(SolutionDir)ILMerge\ILMerge.exe"" /out:""$(TargetDir)$(TargetName).all.exe"" ""$(TargetDir)$(TargetName).exe"" ""$(TargetDir)*.dll"" /target:exe /targetplatform:v4C:\Windows\Microsoft.NET\Framework64\v4.0.30319 /wildcards Basic hints The output is a file ""AssemblyName.all.exe"" which combines all sub-dlls into one .exe. Notice the ""ILMerge\"" directory. You need to either copy the ILMerge utility into your solution directory (so you can distribute the source without having to worry about documenting the install of ILMerge) or change the this path to point to where ILMerge.exe resides. Advanced hints: If you have problems with it not working turn on ""Output"" and select ""Show output from: Build"". Check the exact command that Visual Studio actually generated and see if there was any errors. Update This script replaces all .exe + .dll files with a single combined .exe. It also keeps the debugging .pdb file intact. To use paste this into your ""Post Build"" step under the ""Build Events"" tab in a C# project and make sure you adjust the path in the first line to point to the ILMerge.exe: rem Create a single .exe that combines the root .exe and all subassemblies. ""$(SolutionDir)ILMerge\ILMerge.exe"" /out:""$(TargetDir)$(TargetName).all.exe"" ""$(TargetDir)$(TargetName).exe"" ""$(TargetDir)*.dll"" /target:exe /targetplatform:v4C:\Windows\Microsoft.NET\Framework64\v4.0.30319 /wildcards rem Remove all subassemblies. del *.dll rem Remove all .pdb files (except the new combined pdb we just created). ren ""$(TargetDir)$(TargetName).all.pdb"" ""$(TargetName).all.pdb.temp"" del *.pdb ren ""$(TargetDir)$(TargetName).all.pdb.temp"" ""$(TargetName).all.pdb"" rem Delete the original non-combined .exe. del ""$(TargetDir)$(TargetName).exe"" rem Rename the combined .exe and .pdb to the original project name we started with. ren ""$(TargetDir)$(TargetName).all.pdb"" ""$(TargetName).pdb"" ren ""$(TargetDir)$(TargetName).all.exe"" ""$(TargetName).exe"" exit 0 See http://stackoverflow.com/questions/2961357/using-ilmerge-with-net-4-libraries  We use ILMerge on the Microsoft application blocks - instead of 12 seperate DLL files we have a single file that we can upload to our client areas plus the file system structure is alot neater. After merging the files I had to edit the visual studio project list remove the 12 seperate assmeblies and add the single file as a reference otherwise it would complain that it couldnt find the specific assembly. Im not too sure how this would work on post deployment though could be worth giving it a try. +1 for sharing your own experience.",c# .net deployment ilmerge
27757,A,"How can I discover the ""path"" of an embedded resource? I am storing a PNG as an embedded resource in an assembly. From within the same assembly I have some code like this: Bitmap image = new Bitmap(typeof(MyClass) ""Resources.file.png""); The file named ""file.png"" is stored in the ""Resources"" folder (within Visual Studio) and is marked as an embedded resource. The code fails with an exception saying: Resource MyNamespace.Resources.file.png cannot be found in class MyNamespace.MyClass I have identical code (in a different assembly loading a different resource) which works. So I know the technique is sound. My problem is I end up spending a lot of time trying to figure out what the correct path is. If I could simply query (eg. in the debugger) the assembly to find the correct path that would save me a load of headaches. I' guessing that your class is in a different namespace. The canonical way to solve this would be to use the resources class and a strongly typed resource: ProjectNamespace.Properties.Resources.file Use the IDE's resource manager to add resources. You are right my class is in a different namespace. It seems that the Resources folder lives under the namespace specified as the default namespace in the project configuration which for various reasons isn't the namespace that this class is part of. I suspect you're correct also about using a different approach entirely but as I need to be consistent with legacy code that's beyond my control.  The name of the resource is the name space plus the ""pseudo"" name space of the path to the file. The ""pseudo"" name space is made by the sub folder structure using \ (backslashes) instead of . (dots). public static Stream GetResourceFileStream(String nameSpace String filePath) { String pseduoName = filePath.Replace('\\' '.'); Assembly assembly = Assembly.GetExecutingAssembly(); return assembly.GetManifestResourceStream(nameSpace + ""."" + pseduoName); } The following call: GetResourceFileStream(""my.namespace"" ""resources\\xml\\my.xml"") will return the stream of my.xml located in the folder-structure resources\xml in the name space: my.namespace. Also dashes ('-') in the folders are replaced with underscores ('_'). There might be other symbols as well. I'd like to see how the compiler is doing it so we can use the same method.  I find myself forgetting how to do this every time as well so I just wrap the two one-liners that I need in a little class: public class Utility { /// <summary> /// Takes the full name of a resource and loads it in to a stream. /// </summary> /// <param name=""resourceName"">Assuming an embedded resource is a file /// called info.png and is located in a folder called Resources it /// will be compiled in to the assembly with this fully qualified /// name: Full.Assembly.Name.Resources.info.png. That is the string /// that you should pass to this method.</param> /// <returns></returns> public static Stream GetEmbeddedResourceStream(string resourceName) { return Assembly.GetExecutingAssembly().GetManifestResourceStream(resourceName); } /// <summary> /// Get the list of all emdedded resources in the assembly. /// </summary> /// <returns>An array of fully qualified resource names</returns> public static string[] GetEmbeddedResourceNames() { return Assembly.GetExecutingAssembly().GetManifestResourceNames(); } }  This will get you a string array of all the resources: System.Reflection.Assembly.GetExecutingAssembly().GetManifestResourceNames(); Pretty useful! Thanks!",c# .net resources
21965,A,Programmatically encrypting a config-file in .NET Could somebody please do a rundown of how to programmatically encrypt a config-file in .NET preferably in C#. What I would like to do is do some kind of check on an application's startup to see if a section is unprotected and if it is then encrypt it. This for both settings and connection-strings. Also if anyone could list the types of encryption-providers and what is the difference between them. I don't know if the code for doing this in a normal WinForms-application is transparent to doing this in ASP.NET. To summarize the answers and what I've found so far here are some good links to answer this question: Encrypting Configuration Information in ASP.NET 2.0 Applications - 4GuysFromRolla.com How To: Encrypt Configuration Sections in ASP.NET 2.0 Using DPAPI - MSDN Please feel free to complement with other links maybe some to WinForms- or WPF-applications.  @TK: a hashing algo can only be 'guessed' not reverse engineered. One can only reconstruct the input to a hash value by completely guessing the input (apart from collisions that is) This can be done by a rainbow crack for example (see an implementation of a rainbow cracker here) I would say that a 3rd party encryption tool is not safer than the .NET framework encryption algorithms these libraries just help you doing your job faster  I haven't used it myself but the Microsoft Enterprise library has good encryption support that will possibly suit your needs: http://msdn.microsoft.com/en-us/library/cc309503.aspx  Encrypting .NET configuration files through code How To: Encrypt Configuration Sections in ASP.NET 2.0 Using DPAPI  The solution at below site working fine for me. http://www.a2zmenu.com/Blogs/CSharp/How-to-encrypt-configuration-file.aspx  There is a good article from 4 guys about Encrypting Configuration Information in ASP.NET 2.0 Applications Hope this helps,c# .net configuration encryption configuration-files
29157,A,"How do I make a PictureBox use Nearest Neighbor resampling? I am using StretchImage because the box is resizable with splitters. It looks like the default is some kind of smooth bilinear filtering causing my image to be blurry and have moire patterns. so there is no actual way to do this? in some easy fashion? @Luiscencio: that's what it looks like. You'll have to do it yourself with a new Bitmap of the appropriate size and then Graphics.DrawImage You should mark JYelton answer. :) I suspect you're going to have to do the resizing manually thru the Image class and DrawImage function and respond to the resize events on the PictureBox.  When resizing an image in .net the System.Drawing.Drawing2D.InterpolationMode offers the following resize methods: Bicubic Bilinear High HighQualityBicubic HighQualityBilinear Low NearestNeighbor Default I don't see how this addresses the OP's question.  I did a MSDN search and turns out there's an article on this which is not very detailed but outlines that you should use the paint event. http://msdn.microsoft.com/en-us/library/k0fsyd4e.aspx I edited a commonly available image zooming example to use this feature see below Edited from: http://www.dotnetcurry.com/ShowArticle.aspx?ID=196&AspxAutoDetectCookieSupport=1 Hope this helps  private void Form1_Load(object sender EventArgs e) { // set image location imgOriginal = new Bitmap(Image.FromFile(@""C:\images\TestImage.bmp"")); picBox.Image = imgOriginal; // set Picture Box Attributes picBox.SizeMode = PictureBoxSizeMode.StretchImage; // set Slider Attributes zoomSlider.Minimum = 1; zoomSlider.Maximum = 5; zoomSlider.SmallChange = 1; zoomSlider.LargeChange = 1; zoomSlider.UseWaitCursor = false; SetPictureBoxSize(); // reduce flickering this.DoubleBuffered = true; } // picturebox size changed triggers paint event private void SetPictureBoxSize() { Size s = new Size(Convert.ToInt32(imgOriginal.Width * zoomSlider.Value) Convert.ToInt32(imgOriginal.Height * zoomSlider.Value)); picBox.Size = s; } // looks for user trackbar changes private void trackBar1_Scroll(object sender EventArgs e) { if (zoomSlider.Value > 0) { SetPictureBoxSize(); } } // redraws image using nearest neighbour resampling private void picBox_Paint_1(object sender PaintEventArgs e) { e.Graphics.InterpolationMode = InterpolationMode.NearestNeighbor; e.Graphics.DrawImage( imgOriginal new Rectangle(0 0 picBox.Width picBox.Height) // destination rectangle 0 0 // upper-left corner of source rectangle imgOriginal.Width // width of source rectangle imgOriginal.Height // height of source rectangle GraphicsUnit.Pixel); } What event is wired up to your picBox_Paint_1 method? it would be in some other part of your code. Yeah it's in the form designer code: this.picBox.Paint += new System.Windows.Forms.PaintEventHandler(this.picBox_Paint_1);  I needed this functionality also. I made a class that inherits PictureBox overrides OnPaint and adds a property to allow the interpolation mode to be set: /// <summary> /// Inherits from PictureBox; adds Interpolation Mode Setting /// </summary> public class PictureBoxWithInterpolationMode : PictureBox { public InterpolationMode InterpolationMode { get; set; } protected override void OnPaint(PaintEventArgs paintEventArgs) { paintEventArgs.Graphics.InterpolationMode = InterpolationMode; base.OnPaint(paintEventArgs); } } Very nice. I think PanAndZoomPictureBox of EmguCV do the same. Are you aware of any performance issue doing it? I haven't had any measurable performance differences changing the interpolation mode in this way. Humm good. Jared Updike should mark your answer! :) Lovely answer. I suggest posters be a bit more complete with their code i.e. add a using `System.Drawing.Drawing2D` or put the full namespace in front of the InterpolationMode declaration.",c# .net winforms gdi+ picturebox
12045,A,Unit testing a timer based application? I am currently writing a simple timer based mini app in C# that performs an action n times every k seconds. I am trying to adopt a test driven development style so my goal is to unit test all parts of the app. So my question is: Is there a good way to unit test a timer based class? The problem as I see it is that there is a big risk that the tests will take uncomfortably long to execute since they must wait so and so long for the desired actions to happen. Especially if one wants realistic data (seconds) instead of using the minimal time resolution allowed by the framework (1 ms?). I am using a mock object for the action to register the number of times the action was called and so that the action takes practically no time. Len Holgate has a series of 20 articles on testing timer based code.  I think what I would do in this case is test the code that actually executes when the timer ticks rather than the entire sequence. What you really need to decide is whether it is worthwhile for you to test the actual behaviour of the application (for example if what happens after every tick changes drastically from one tick to another) or whether it is sufficient (that is to say the action is the same every time) to just test your logic. Since the timer's behaviour is guaranteed never to change it's either going to work properly (ie you've configured it right) or not; it seems to be to be wasted effort to include that in your test if you don't actually need to. The only problem I see with your approach is that you ll probably have to expose something that happens everytime the polls happens is that a good idea? ie exposing something that you don't have to just for tests. An alternative might be internal (and InternalsVisibleTo) but a lot of people don't like that either  What I have done is to mock the timer and also the current system time that my events could be triggered immediately but as far as the code under test was concerned time elapsed was seconds.  I agree with Danny insofar as it probably makes sense from a unit-testing perspective to simply forget about the timer mechanism and just verify that the action itself works as expected. I would also say that I disagree in that it's wasted effort to include the configuration of the timer in an automated test suite of some kind. There are a lot of edge cases when it comes to working with timing applications and it's very easy to create a false sense of security by only testing the things that are easy to test. I would recommend having a suite of tests that runs the timer as well as the real action. This suite will probably take a while to run and would likely not be something you would run all the time on your local machine. But setting these types of things up on a nightly automated build can really help root out bugs before they become too hard to find and fix. So in short my answer to your question is don't worry about writing a few tests that do take a long time to run. Unit test what you can and make that test suite run fast and often but make sure to supplement that with integration tests that run less frequently but cover more of the application and its configuration.,c# .net unit-testing timer
19353,A,"Detecting audio silence in WAV files using C# I'm tasked with building a .NET client app to detect silence in a WAV files. Is this possible with the built-in Windows APIs? Or alternately any good libraries out there to help with this? If you want to efficiently calculate the average power over a sliding window: square each sample then add it to a running total. Subtract the squared value from N samples previous. Then move to the next step. This is the simplest form of a CIC Filter. Parseval's Theorem tells us that this power calculation is applicable to both time and frequency domains. Also you may want to add Hysteresis to the system to avoid switching on&off rapidly when power level is dancing about the threshold level.  Audio analysis is a difficult thing requiring a lot of complex math (think Fourier Transforms). The question you have to ask is ""what is silence"". If the audio that you are trying to edit is captured from an analog source the chances are that there isn't any silence... they will only be areas of soft noise (line hum ambient background noise etc). All that said an algorithm that should work would be to determine a minimum volume (amplitude) threshold and duration (say <10dbA for more than 2 seconds) and then simply do a volume analysis of the waveform looking for areas that meet this criteria (with perhaps some filters for millisecond spikes). I've never written this in C# but this CodeProject article looks interesting; it describes C# code to draw a waveform... that is the same kind of code which could be used to do other amplitude analysis. Link is dead. This is 6 years later.  Use Sox. It can remove leading and trailing silences but you'll have to call it as an exe from your app.  http://www.codeproject.com/Articles/19590/WAVE-File-Processor-in-C This has all the code necessary to strip silence and mix wave files. Enjoy.  See code below from Detecting audio silence in WAV files using C# private static void SkipSilent(string fileName short silentLevel) { WaveReader wr = new WaveReader(File.OpenRead(fileName)); IntPtr format = wr.ReadFormat(); WaveWriter ww = new WaveWriter(File.Create(fileName + "".wav"") AudioCompressionManager.FormatBytes(format)); int i = 0; while (true) { byte[] data = wr.ReadData(i 1); if (data.Length == 0) { break; } if (!AudioCompressionManager.CheckSilent(format data silentLevel)) { ww.WriteData(data); } } ww.Close(); wr.Close(); } The code above is using Alvas.Audio The code above requires a third party library (Alvas Audio) which is not exactly cheap.  I don't think you'll find any built-in APIs for detection of silence. But you can always use good ol' math/discreete signal processing to find out loudness. Here's a small example: http://msdn.microsoft.com/en-us/magazine/cc163341.aspx",c# .net audio
10644,A,"Any decent C# profilers out there? I urgently need a C# profiler. Although I'm not averse to paying for one something which is free or at least with a trial version would be ideal since it takes time to raise a purchase order. Any recommendations? possible duplicate of [What Are Some Good .NET Profilers?](http://stackoverflow.com/questions/3927/what-are-some-good-net-profilers) It says a lot about SO that a reason for censoring a question is that it's ""likely to solicit debate"". The current release of SharpDevelop (3.1.1) has a nice integrated profiler. It's quite fast and integrates very well into the SharpDevelop IDE and its NUnit runner. Results are displayed in a flexible Tree/List style (use LINQ to create your own selection). Doublecliking the displayed method jumps directly into the source code.  Although not very good to profile memory usage the profiler included in some versions of Visual Studio does a very good job of profiling execution speed. one way to get to the VS2010 profiler is after a solution is loaded from the ""Debug"" menu find ""Start Performance Analysis"". Details of it's capabilities are at http://msdn.microsoft.com/query/dev10.query?appId=Dev10IDEF1&l=EN-US&k=k(VS.PERFORMANCE.WIZARD.METHODPAGE)&rd=true  The EQATEC profiler is very good and is completely free. It's easy to setup and use and doesn't seem to add too much of an overhead to the application. I've just started using it today and have already found a couple of bottlenecks I wouldn't have spotted otherwise. Not free for a commercial license (but still cheap $200). Yes it looks like they have changed the licencing for the latest version and started charging for commercial use. I'd still highly recommend it though. Update - it looks like they have changed the licence terms again to make it free for commercial use for standard .NET applications (but not CF or Silverlight) The license terms have changed again in release 3.6: it's now free for **all** platforms including CF and Silverlight with a restriction on the number of DLLs that can be instrumented in one session. Agreed it's very easy to use as well I tried out both Equatec and RedGate Ants. I didn't found something like in ants to show which line of code does it used for which amount of time. Is there some hidden setting to see code lines? No longer free and has been bought out by Telerik :( :'((( was looking for a free tool...  We use Ants profiler where I work. It gives very detailed information in a simple manner.  I found the .NET Memory Profiler yesterday and I must say that I'm very impressed by it. I'm going to order my license today.  AQTime (both perf and memory) or ANTS (v4 performance profiler or v5 beta memory profiler) here.  Patrick Smacchia's awesome NDepend is excellent for providing static analysis. I would thoroughly recommend NDepend for static analysis but just be warned that you'll probably need to put aside a day or two to actually analyse the truckload of information that it provides as well as work out what all the stats actually mean in terms of your code.  I have had good luck with the .NET memory profiler  I maintain a comprehensive list of profilers for .NET on SharpToolbox.com. You'll find there the tools suggested here and more each with a short description of what it proposes. This seems out of date (redgate entries are quite stale) Harry thank you for pointing this out. The information about all RedGate products are now up-to-date. http://sharptoolbox.com/authors/red-gate-software  I used Ants profiler on a large c# project a year and a half ago. It really performed very nicely for what it cost and even outperformed a few of the more expensive competitors. It calculates cost on with almost a line by line resolution. I like ANTS too. It is from Redgate.  Currently don't use them a buddy of mine raves about Ants profiler. I know its a for-pay product not sure how expensive. If you happen to staff an MVP you might be able to leverage that to get a license for free. MVP's get the license to redgate products for free its a loop hole that gets you in if you have people on your team who are MVP's making the cost a non-issue. can you provide a bit more detail on the whole MVP thing? thanks Do you have a link describing this loophole and how to capitalize on it?  EQATEC profiler did the job here.  I'll second red gate's ANTS profiler. I've used it to track down some really troubling performance issues and it was dead simple to use (low learning curve) and presented nice detailed data in a way that was easy to understand. The price tag is worth it but it isn't free ...  I have used AQtime and it has never let me down. I am sure there is a trial version. AQTime has a huge benefit over ANTs in that it supports unmanaged code.  You can try the following: nprof (free but kinda old) ProfileSharp (open source) .Net Memory Profiler (really good for memory leaks there's a trial version) Edit: Nprof has been replaced with SlimTune and works with .Net 4.0 applications I've played around with ProfileSharp. It's absolutely awful. nprof is .Net 1.1 only I think. If you can compile to .Net 1.1 then it may still be useful to profile it and then recompile to .Net 2 for release. However this isn't possible if you start using .Net2 features such as generics and nullable types. Agree with Matthew ProfileSharp is terrible couldn't get it to profile even the simplest command line exe. Don't waste your time Development on nprof seems to have picked up recently. I've used .Net Memory Profiler to find a memory leak; it's pretty good. It's got my seal of approval! That website for ProfileSharp seems like spam. ???  SlimTune looks to be very promising. http://code.google.com/p/slimtune/  We use .NET Memory Profiler. Its kinda ugly but very useful for finding dangling references. I originally tried Red Gate's ANTS profiler which is very sexy but from a memory leak point of view it sucks for the following reasons: 1) Its ridiculously slow. It was taking half an hour to get the application into a state to start recording (takes 20 seconds without red-gate). 2) Red Gate needs to run its own tool on its own tool. It was using 900MB of memory by the time I finished two snapshots! It then crashed :( However the timing component of Red Gate ANTS was impressive. Just don't bother with the memory profiler unless you are dealing with a trivial (small footprint) application. Have you tried v4 of both? It's much better all-round now :)  dotTrace from JetBrains is widely used. Patrick Smacchia's awesome NDepend is excellent for providing static analysis. dotTrace is truly an excellent profiler extremely easy to use. dotTrace 3.1 does not work with .NET 4. We have to wait for dotTrace 4.0. As an update both dotTrace 4 Performance and dotTrace 3.5 Memory do support .NET 4.  It's interesting that no-one mentions that there's one in the higher-end versions of Visual Studio - I've always found that to be good enough for execution profiling. For memory profiling I use Memory Profiler which has already been mentioned but isn't what I would generally describe as 'a profiler'. What kind of profiling were you trying to do?  What's your objective? Is it your objective to locate specific statements and get a rough idea of what they are contributing to your total execution time so you can find ways to do them differently? For that I swear by this method.",c# .net profiling profiler
4664,A,"Should the folders in a solution match the namespace? Should the folders in a solution match the namespace? In one of my teams projects we have a class library that has many sub-folders in the project. Project Name and Namespace: MyCompany.Project.Section. Within this project there are several folders that match the namespace section: Folder Vehicles has classes in the MyCompany.Project.Section.Vehicles namespace Folder Clothing has classes in theMyCompany.Project.Section.Clothing namespace etc. Inside this same project is another rogue folder Folder BusinessObjects has classes in the MyCompany.Project.Section namespace There are a few cases like this where folders are made for ""organizational convenience"". My question is: What's the standard? In class libraries do the folders usually match the namespace structure or is it a mixed bag? @lassevk: I agree with these rules and have one more to add. When I have nested classes I still split them out one per file. Like this: // ----- Foo.cs partial class Foo { // Foo implementation here } and // ----- Foo.Bar.cs partial class Foo { class Bar { // Foo.Bar implementation here } }  I think the standard within .NET is to try to do it when possible but not to create unnecessarily deep structures just to adhere to it as a hard rule. None of my projects follow the namespace == structure rule 100% of the time sometimes its just cleaner/better to break out from such rules. In Java you don't have a choice. I'd call that a classic case of what works in theory vs what works in practice.  I'd say yes. First it will be easier to find the actual code files by following down the namespaces (say when somebody e-mails you a naked exception call stack). If you let your folders go out of sync with namespaces finding files in big codebases becomes getting tiring. Second VS will generate new classes you create in folders with the same namespace of its parent folder structure. If you decide to swim against this it will be just one more plumbing job to do daily when adding new files. Of course this goes without saying that one should be conservative about how deep xis folder/namespace hierarchy goes.  Yes they should only leads to confusion otherwise.  Also note that if you use the built-in templates to add classes to a folder it will by default be put in a namespace that reflects the folder hierarchy. The classes will be easier to find and that alone should be reasons good enough. The rules we follow are: Project/assembly name is the same as the root namespace except for the .dll ending Only exception to the above rule is a project with a .Core ending the .Core is stripped off Folders equals namespaces One type per file (class struct enum delegate etc.) makes it easy to find the right file +1 for _""Only exception to the above rule is a project with a .Core ending the .Core is stripped off""_ alone. I have a `MyProject.Core.dll` assembly and all classes begin with `MyProject.Core`. Stripping off the `.Core` suffix makes much more sense.",c# .net namespaces
17125,A,"What are real life applications of yield? I know what yield does and I've seen a few examples but I can't think of real life applications have you used it to solve some specific problem? (Ideally some problem that cannot be solved some other way) I realise this is an old question (pre Jon Skeet?) but I have been considering this question myself just lately. Unfortunately the current answers here (in my opinion) don't mention the most obvious advantage of the yield statement. The biggest benefit of the yield statement is that it allows you to iterate over very large lists with much more efficient memory usage then using say a standard list. For example let's say you have a database query that returns 1 million rows. You could retrieve all rows using a DataReader and store them in a List therefore requiring list_size * row_size bytes of memory. Or you could use the yield statement to create an Iterator and only ever store one row in memory at a time. In effect this gives you the ability to provide a ""streaming"" capability over large sets of data. Moreover in the code that uses the Iterator you use a simple foreach loop and can decide to break out from the loop as required. If you do break early you have not forced the retrieval of the entire set of data when you only needed the first 5 rows (for example). Regarding: Ideally some problem that cannot be solved some other way The yield statement does not give you anything you could not do using your own custom iterator implementation but it saves you needing to write the often complex code needed. There are very few problems (if any) that can't solved more than one way. Here are a couple of more recent questions and answers that provide more detail: http://stackoverflow.com/questions/384392/yield-keyword-value-added http://stackoverflow.com/questions/317619/is-yield-useful-outside-of-linq  One interesting use is as a mechanism for asynchronous programming esp for tasks that take multiple steps and require the same set of data in each step. Two examples of this would be Jeffery Richters AysncEnumerator Part 1 and Part 2. The Concurrency and Coordination Runtime (CCR) also makes use of this technique CCR Iterators.  You can also use yield return to treat a series of function results as a list. For instance consider a company that pays its employees every two weeks. One could retrieve a subset of payroll dates as a list using this code: void Main() { var StartDate = DateTime.Parse(""01/01/2013""); var EndDate = DateTime.Parse(""06/30/2013""); foreach (var d in GetPayrollDates(StartDate EndDate)) { Console.WriteLine(d); } } // Calculate payroll dates in the given range. // Assumes the first date given is a payroll date. IEnumerable<DateTime> GetPayrollDates(DateTime startDate DateTime endDate int daysInPeriod = 14) { var thisDate = startDate; while (thisDate < endDate) { yield return thisDate; thisDate = thisDate.AddDays(daysInPeriod); } }  Using yield can prevent downcasting to a concrete type. This is handy to ensure that the consumer of the collection doesn't manipulate it.  LINQ's operators on the Enumerable class are implemented as iterators that are created with the yield statement. It allows you to chain operations like Select() and Where() without actually enumerating anything until you actually use the enumerator in a loop typically by using the foreach statement. Also since only one value is computed when you call IEnumerator.MoveNext() if you decide to stop mid-collection you'll save the performance hit of calculating all of the results. Iterators can also be used to implement other kinds of lazy evaluation where expressions are evaluated only when you need it. You can also use yield for more fancy stuff like coroutines.  Another good use for yield is to perform a function on the elements of an IEnumerable and to return a result of a different type for example: public delegate T SomeDelegate(K obj); public IEnumerable<T> DoActionOnList(IEnumerable<K> list SomeDelegate action) { foreach (var i in list) yield return action(i); }  actually I use it in a non traditional way on my site IdeaPipe public override IEnumerator<T> GetEnumerator() { // goes through the collection and only returns the ones that are visible for the current user // this is done at this level instead of the display level so that ideas do not bleed through // on services foreach (T idea in InternalCollection) if (idea.IsViewingAuthorized) yield return idea; } so basically it checks if viewing the idea is currently authorized and if it is it returns the idea. If it isn't it is just skipped. This allows me to cache the Ideas but still display the ideas to the users that are authorized. Else I would have to re pull them each time based on permissions when they are only re-ranked every 1 hour.",c# .net yield
26809,A,"What is the best way to deal with DBNull's I frequently have problems dealing with DataRows returned from SqlDataAdapters. When I try to fill in an object using code like this: DataRow row = ds.Tables[0].Rows[0]; string value = (string)row; What is the best way to deal with DBNull's in this type of situation. close: [most-efficient-way-to-check-for-dbnull-and-then-assign-to-a-variable](http://stackoverflow.com/questions/221582/most-efficient-way-to-check-for-dbnull-and-then-assign-to-a-variable) It is worth mentioning that DBNull.Value.ToString() equals String.Empty You can use this to your advantage: DataRow row = ds.Tables[0].Rows[0]; string value = row[""name""].ToString(); However that only works for Strings for everything else I would use the linq way or a extension method. For myself I have written a little extension method that checks for DBNull and even does the casting via Convert.ChangeType(...) int value = row.GetValueOrDefault<int>(""count""); int value = row.GetValueOrDefault<int>(""count"" 15);  Add a reference to System.Data.DataSetExtensions that adds Linq support for querying data tables. This would be something like: string value = ( from row in ds.Tables[0].Rows select row.Field<string>(0) ).FirstOrDefault(); +1: this answer should be more upvoted and probably also accepted - definitely row.Field(""column_name"") is the most efficient readable and clean solution for dealing with null (DBNull.Value). There is also row.SetField(""column_name"" value) for writing value to row.  DBNull implements .ToString() like everything else. No need to do anything. Instead of the hard cast call the object's .ToString() method. DataRow row = ds.Tables[0].Rows[0]; string value; if (row[""fooColumn""] == DBNull.Value) { value = string.Empty; } else { value = Convert.ToString(row[""fooColumn""]); } this becomes: DataRow row = ds.Tables[0].Rows[0]; string value = row.ToString() DBNull.ToString() returns string.Empty I would imagine this is the best practice you're looking for This doesn't work if the value isn't a string though. I was looking for a general case answer. I agree yeah it's good if it's strings keeps it simple but other types wouldn't work e.g. tryng to do bool.Parse(row[""fooColumn""].ToString()).  Brad Abrams posted something related just a couple of days ago http://blogs.msdn.com/brada/archive/2009/02/09/framework-design-guidelines-system-dbnull.aspx In Summary ""AVOID using System.DBNull. Prefer Nullable instead."" And here is my two cents (of untested code :) ) // Or if (row[""fooColumn""] == DBNull.Value) if (row.IsNull[""fooColumn""]) { // use a null for strings and a Nullable for value types // if it is a value type and null is invalid throw a // InvalidOperationException here with some descriptive text. // or dont check for null at all and let the cast exception below bubble value = null; } else { // do a direct cast here. dont use ""as"" ""convert"" ""parse"" or ""tostring"" // as all of these will swallow the case where is the incorect type. // (Unless it is a string in the DB and really do want to convert it) value = (string)row[""fooColumn""]; } And one question... Any reason you are not using an ORM? We are using ORM now. At the time we weren't *Any reason you are not using an ORM?* I use raw ADO .NET for performance. Try to merge 1 million records with EF or NH.  I usually write my own ConvertDBNull class that wraps the built-in Convert class. If the value is DBNull it will return null if its a reference type or the default value if its a value type. Example: - ConvertDBNull.ToInt64(object obj) returns Convert.ToInt64(obj) unless obj is DBNull in which case it will return 0.  If you aren't using nullable types the best thing to do is check to see if the column's value is DBNull. If it is DBNull then set your reference to what you use for null/empty for the corresponding datatype. DataRow row = ds.Tables[0].Rows[0]; string value; if (row[""fooColumn""] == DBNull.Value) { value = string.Empty; } else { value = Convert.ToString(row[""fooColumn""]); } As Manu said you can create a convert class with an overloaded convert method per type so you don't have to pepper your code with if/else blocks. I will however stress that nullable types is the better route to go if you can use them. The reasoning is that with non-nullable types you are going to have to resort to ""magic numbers"" to represent null. For example if you are mapping a column to an int variable how are you going to represent DBNull? Often you can't use 0 because 0 has a valid meaning in most programs. Often I see people map DBNull to int.MinValue but that could potentially be problematic too. My best advice is this: For columns that can be null in the database use nullable types. For columns that cannot be null in the database use regular types. Nullable types were made to solve this problem. That being said if you are on an older version of the framework or work for someone who doesn't grok nullable types the code example will do the trick. The line if(row[""fooColumn""] == DBNull.Value) works but isn't correct. It isn't defined DBNull.Value should be implemented as a Singleton pattern. A better line would be: if(row[""fooColumn""] is DBNull) @doekman - Actually DBNull *is* a singleton class. To quote MSDN: ""DBNull is a singleton class which means only this [DBNull.Value] instance of this class can exist."" http://msdn.microsoft.com/en-us/library/system.dbnull.value.aspx If you want treat dbnull as empty string row[""fooColumn""].ToString() will do it.  For some reason I've had problems with doing a check against DBNull.Value so I've done things slightly different and leveraged a property within the DataRow object: if (row.IsNull[""fooColumn""]) { value = string.Empty(); } { else { value = row[""fooColumn""].ToString; }  If you have control of the query that is returning the results you can use ISNULL() to return non-null values like this: SELECT ISNULL(name'') AS name ISNULL(age 0) AS age FROM names If your situation can tolerate these magic values to substitute for NULL taking this approach can fix the issue through your entire app without cluttering your code.  I always found it clear concise and problem free using a version of the If/Else check only with the ternary operator. Keeps everything on one row including assigning a default value if the column is null. So assuming a nullable Int32 column named ""MyCol"" where we want to return -99 if the column is null but return the integer value if the column is not null: return row[""MyCol""] == DBNull.Value ? -99 : Convert.ToInt32(Row[""MyCol""]); It is the same method as the If/Else winner above - But I've found if you're reading multiple columns in from a datareader it's a real bonus having all the column-read lines one under another lined up as it's easier to spot errors: Object.ID = DataReader[""ID""] == DBNull.Value ? -99 : Convert.ToInt32(DataReader[""ID""]); Object.Name = DataReader[""Name""] == DBNull.Value ? ""None"" : Convert.ToString(DataReader[""Name""]); Object.Price = DataReader[""Price""] == DBNull.Value ? 0.0 : Convert.ToFloat(DataReader[""Price""]);  You should also look at the extension methods. Here are some examples to deal with this scenerio. Recommended read  If you are concerned with getting DBNull when expecting strings one option is to convert all the DBNull values in the DataTable into empty string. It is quite simple to do it but it would add some overhead especially if you are dealing with large DataTables. Check this link that shows how to do it if you are interested Someties it is important to know the difference between a Null and an empty string though. For example setting a value to an empty string as opposed to a value just never being set.  You can also test with Convert.IsDBNull (MSDN).  Nullable types are good but only for types that are not nullable to begin with. To make a type ""nullable"" append a question mark to the type for example: int? value = 5; I would also recommend using the ""as"" keyword instead of casting. You can only use the ""as"" keyword on nullable types so make sure you're casting things that are already nullable (like strings) or you use nullable types as mentioned above. The reasoning for this is If a type is nullable the ""as"" keyword returns null if a value is DBNull. It's ever-so-slightly faster than casting though only in certain cases. This on its own is never a good enough reason to use as but coupled with the reason above it's useful. I'd recommend doing something like this DataRow row = ds.Tables[0].Rows[0]; string value = row as string; In the case above if row comes back as DBNull then value will become null instead of throwing an exception. Be aware that if your DB query changes the columns/types being returned using as will cause your code to silently fail and make values simple null instead of throwing the appropriate exception when incorrect data is returned so it is recommended that you have tests in place to validate your queries in other ways to ensure data integrity as your codebase evolves.  Often when working with DataTables you have to deal with this cases where the row field can be either null or DBNull normally I deal with that like this: string myValue = (myDataTable.Rows[i][""MyDbNullableField""] as string) ?? string.Empty; The 'as' operator returns null for invalid cast's like DBNull to string and the '??' returns the term to the right of the expression if the first is null.",c# .net sql-server
24734,A,"SelectNodes not working on stackoverflow feed I'm trying to add support for stackoverflow feeds in my rss reader but SelectNodes and SelectSingleNode have no effect. This is probably something to do with ATOM and xml namespaces that I just don't understand yet. I have gotten it to work by removing all attributes from the feed tag but that's a hack and I would like to do it properly. So how do you use SelectNodes with atom feeds? Here's a snippet of the feed. <?xml version=""1.0"" encoding=""utf-8""?> <feed xmlns=""http://www.w3.org/2005/Atom"" xmlns:creativeCommons=""http://backend.userland.com/creativeCommonsRssModule"" xmlns:thr=""http://purl.org/syndication/thread/1.0""> <title type=""html"">StackOverflow.com - Questions tagged: c</title> <link rel=""self"" href=""http://stackoverflow.com/feeds/tag/c"" type=""application/atom+xml"" /> <subtitle>Check out the latest from StackOverflow.com</subtitle> <updated>2008-08-24T12:25:30Z</updated> <id>http://stackoverflow.com/feeds/tag/c</id> <creativeCommons:license>http://www.creativecommons.org/licenses/by-nc/2.5/rdf</creativeCommons:license> <entry> <id>http://stackoverflow.com/questions/22901/what-is-the-best-way-to-communicate-with-a-sql-server</id> <title type=""html"">What is the best way to communicate with a SQL server?</title> <category scheme=""http://stackoverflow.com/feeds/tag/c/tags"" term=""c"" /><category scheme=""http://stackoverflow.com/feeds/tag/c/tags"" term=""c++"" /><category scheme=""http://stackoverflow.com/feeds/tag/c/tags"" term=""sql"" /><category scheme=""http://stackoverflow.com/feeds/tag/c/tags"" term=""mysql"" /><category scheme=""http://stackoverflow.com/feeds/tag/c/tags"" term=""database"" /> <author><name>Ed</name></author> <link rel=""alternate"" href=""http://stackoverflow.com/questions/22901/what-is-the-best-way-to-communicate-with-a-sql-server"" /> <published>2008-08-22T05:09:04Z</published> <updated>2008-08-23T04:52:39Z</updated> <summary type=""html"">&lt;p&gt;I am going to be using c/c++ and would like to know the best way to talk to a MySQL server. Should I use the library that comes with the server installation? Are they any good libraries I should consider other than the official one?&lt;/p&gt;</summary> <link rel=""replies"" type=""application/atom+xml"" href=""http://stackoverflow.com/feeds/question/22901/answers"" thr:count=""2""/> <thr:total>2</thr:total> </entry> </feed> The Solution XmlDocument doc = new XmlDocument(); XmlNamespaceManager nsmgr = new XmlNamespaceManager(doc.NameTable); nsmgr.AddNamespace(""atom"" ""http://www.w3.org/2005/Atom""); doc.Load(feed); // successful XmlNodeList itemList = doc.DocumentElement.SelectNodes(""atom:entry"" nsmgr); Does -> nsmgr.AddNamespace(""atom"" ""http://www.w3.org/2005/Atom""); <- actually connect over the internet to that url to get the schema? if so what happens if it can't connect to that url? You might need to add a XmlNamespaceManager. XmlDocument document = new XmlDocument(); XmlNamespaceManager nsmgr = new XmlNamespaceManager(document.NameTable); nsmgr.AddNamespace(""creativeCommons"" ""http://backend.userland.com/creativeCommonsRssModule""); // AddNamespace for other namespaces too. document.Load(feed); It is needed if you want to call SelectNodes on a document that uses them. What error are you seeing?  Don't confuse the namespace names in the XML file with the namespace names for your namespace manager. They're both shortcuts and they don't necessarily have to match. So you can register ""http://www.w3.org/2005/Atom"" as ""atom"" and then do a SelectNodes for ""atom:entry"".  I just want to use.. XmlNodeList itemList = xmlDoc.DocumentElement.SelectNodes(""entry""); but what namespace do the entry tags fall under? I would assume xmlns=""http://www.w3.org/2005/Atom"" but it has no title so how would I add that namespace? XmlDocument document = new XmlDocument(); XmlNamespaceManager nsmgr = new XmlNamespaceManager(document.NameTable); nsmgr.AddNamespace("""" ""http://www.w3.org/2005/Atom""); document.Load(feed); Something like that?  You've guessed correctly: you're asking for nodes not in a namespace but these nodes are in a namespace. Description of the problem and solution: http://weblogs.asp.net/wallen/archive/2003/04/02/4725.aspx",c# .net rss atom
19933,A,"How to copy a file in C# I want to copy a file from A to B in C#. How do I do that? System.IO.File.Copy  A simple example for copying one file and several files public class SimpleFileCopy static void Main() { string fileName = ""test.txt""; string sourcePath = @""C:\Users\Public\TestFolder""; string targetPath = @""C:\Users\Public\TestFolder\SubDir"";` // Use Path class to manipulate file and directory paths. string sourceFile = System.IO.Path.Combine(sourcePath fileName); string destFile = System.IO.Path.Combine(targetPath fileName); // To copy a folder's contents to a new location: // Create a new target folder if necessary. if (!System.IO.Directory.Exists(targetPath)) { System.IO.Directory.CreateDirectory(targetPath); } // To copy a file to another location and // overwrite the destination file if it already exists. System.IO.File.Copy(sourceFile destFile true); // To copy all the files in one directory to another directory. // Get the files in the source folder. (To recursively iterate through // all subfolders under the current directory see // ""How to: Iterate Through a Directory Tree."") // Note: Check for target path was performed previously // in this code example. if (System.IO.Directory.Exists(sourcePath)) { string[] files = System.IO.Directory.GetFiles(sourcePath); // Copy the files and overwrite destination files if they already exist. foreach (string s in files) { // Use static Path methods to extract only the file name from the path. fileName = System.IO.Path.GetFileName(s); destFile = System.IO.Path.Combine(targetPath fileName); System.IO.File.Copy(s destFile true); } } else { Console.WriteLine(""Source path does not exist!""); } // Keep console window open in debug mode. Console.WriteLine(""Press any key to exit.""); Console.ReadKey(); }}`  The File.Copy method: MSDN Link  Without any error handling code: File.Copy(path path2);  Use the FileInfo class. FileInfo fi = new FileInfo(""a.txt""); fi.CopyTo(""b.txt"");",c# .net
2483,A,"Casting: (NewType) vs. Object as NewType Possible Duplicate: Casting vs using the 'as' keyword in the CLR What is actually the difference between these two casts? SomeClass sc = (SomeClass)SomeObject; SomeClass sc2 = SomeObject as SomeClass; Normally they should both be explicit casts to the specified type? See also http://stackoverflow.com/questions/496096/casting-vs-using-the-as-keyword-in-the-clr. This one was first but that one has a good answer. You have posted the second oldest question that is a duplicate of another (the first one is locked)! Congratulations I guess? Which is funny because this one was posted 3 months earlier :) But the other one has more detailed answers. It's like the difference between Parse and TryParse. You use TryParse when you expect it might fail but when you have strong assurance it won't fail you use Parse.  To expand on Rytmis's comment you can't use the as keyword for structs (Value Types) as they have no null value.  The former will throw an exception if the source type can't be cast to the target type. The latter will result in sc2 being a null reference but no exception. [Edit] My original answer is certainly the most pronounced difference but as Eric Lippert points out it's not the only one. Other differences include: You can't use the 'as' operator to cast to a type that doesn't accept 'null' as a value You can't use 'as' to convert things like numbers to a different representation (float to int for example). And finally using 'as' vs. the cast operator you're also saying ""I'm not sure if this will succeed.""  Also note that you can only use the as keyword with a reference type or a nullable type ie: double d = 5.34; int i = d as int; will not compile double d = 5.34; int i = (int)d; will compile. because a casting does not convert  Here is a good way to remember the process that each of them follow that I use when trying to decide which is better for my circumstance. DateTime i = (DateTime)value; // is like doing DateTime i = value is DateTime ? value as DateTime : throw new Exception(...); and the next should be easy to guess what it does DateTime i = value as DateTime; in the first case if the value cannot be cast than an exception is thrown in the second case if the value cannot be cast i is set to null. So in the first case a hard stop is made if the cast fails in the second cast a soft stop is made and you might encounter a NullReferenceException later on.  And for the sake of completeness Eric Lippert has a blog post about the difference and some caveats.  They'll throw different exceptions. () : NullReferenceException as : InvalidCastException Which could help for debugging. The ""as"" keyword attempts to cast the object and if the cast fails null is returned silently. The () cast operator will throw an exception immediately if the cast fails. ""Only use the C# ""as"" keyword where you are expecting the cast to fail in a non-exceptional case. If you are counting on a cast to succeed and are unprepared to receive any object that would fail you should use the () cast operator so that an appropriate and helpful exception is thrown."" For code examples and a further explanation: http://blog.nerdbank.net/2008/06/when-not-to-use-c-keyword.html (-1) as won't throw an InvalidCastException.  Typecasting using ""as"" is of course much faster when the cast fails as it avoids the expense of throwing an exception. But it is not faster when the cast succeeds. The graph at http://www.codeproject.com/KB/cs/csharpcasts.aspx is misleading because it doesn't explain what it's measuring. The bottom line is: If you expect the cast to succeed (i.e. a failure would be exceptional) use a cast. If you don't know if it will succeed use the ""as"" operator and test the result for null.  Don't forget that as only works on classes. You mean reference types and nullable value types like int? (taken from Lippert's blog linked above)  For those of you with VB.NET experience (type) is the same as DirectCast and ""as type"" is the same as TryCast.  A difference between the two approaches is that the the first ((SomeClass)obj) may cause a type converter to be called.  The parenthetical cast throws an exception if the cast attempt fails. The ""as"" cast returns null if the cast attempt fails.  All of this applies to reference types value types cannot use the as keyword as they cannot be null. //if I know that SomeObject is an instance of SomeClass SomeClass sc = (SomeClass) someObject; //if SomeObject *might* be SomeClass SomeClass sc2 = someObject as SomeClass; The cast syntax is quicker but only when successful it's much slower to fail. Best practice is to use as when you don't know the type: //we need to know what someObject is SomeClass sc; SomeOtherClass soc; //use as to find the right type if( ( sc = someObject as SomeClass ) != null ) { //do something with sc } else if ( ( soc = someObject as SomeOtherClass ) != null ) { //do something with soc } However if you are absolutely sure that someObject is an instance of SomeClass then use cast. In .Net 2 or above generics mean that you very rarely need to have an un-typed instance of a reference class so the latter is less often used.  Well the 'as' operator ""helps"" you bury your problem way lower because when it is provided an incompatible instance it will return null maybe you'll pass that to a method which will pass it to another and so on and finally you'll get a NullReferenceException which will make your debugging harder. Don't abuse it. The direct cast operator is better in 99% of the cases.",c# .net
17533,A,"Request Windows Vista UAC elevation if path is protected? For my C# app I don't want to always prompt for elevation on application start but if they choose an output path that is UAC protected then I need to request elevation. So how do I check if a path is UAC protected and then how do I request elevation mid-execution? Thanks. If your secondary drive has it's own file permissions like say you have an other copy of windows installed on it. It will prompt. It will also prompt if files are in use which sometimes occurs if you have windows explorer open to the same directory and the file selected with a file previewer displaying the contents... there are some other oddities but generally you get asked for file permission if the file is in use or it's a sensitive directory. If you do loop the FolderBrowserDialog  make sure to notify the user why so they dont get mad at your app. Note: it does stink there is no .net way of asking for permission maybe p/invoke the win32 api...? P/Invoking wouldn't change anything; the rules for UAC are the same whether you're managed or native. It's COM external process or bust.  UAC can elevate object based on their GUID this would (In theory) mean that any class with a GUID can be elevated The UACDemo should also show how to do this  The best way to detect if they are unable to perform an action is to attempt it and catch the UnauthorizedAccessException. However as @DannySmurf correctly points out you can only elevate a COM object or separate process. There is a demonstration application within the Windows SDK Cross Technology Samples called UAC Demo. This demonstration application shows a method of executing actions with an elevated process. It also demonstrates how to find out if a user is currently an administrator. Nice reference to UAC demo exactly what I needed. Thanks very much. Wish I could give more rep sometimes! @Ryan You're welcome. I'm a little frustrated how hard UAC seems to be in a managed environment. Feel free to browse my user profile and upvote my other questions! :) Thanks Matias. Fixed the post now. BTW the exception name is UnauthorizedAccessException with z in Unauthorized. Just that ;)  I'm not sure if it is of any help for you but you can take a look at this blog post: http://haishibai.blogspot.com/2010/01/tiy-try-out-windows-7-uac-using-c-part_26.html  Requesting elevation mid-execution requires that you either: Use a COM control that's elevated which will put up a prompt Start a second process that is elevated from the start. In .NET there is currently no way to elevate a running process; you have to do one of the hackery things above but all that does is give the user the appearance that the current process is being elevated. The only way I can think of to check if a path is UAC elevated is to try to do some trivial write to it while you're in an un-elevated state catch the exception elevate and try again. Note that this is not a .NET limitation -- it's a general limitation of the User Account Control system. Note that is not a UAC limitation -- it's a general limitation of the security model in Windows NT (a running process cannot change its security token). Note that it is a good thing - otherwise malicious attacker could inject code into pre-elevation process and this code would be elevated together with this process.  You may want to notify the user that the path is protected and ask them to output the file to a ""safer"" area. This way your app will not need elevation. I'm sure it depends on your users and what you are trying to do however I don't think it's too much to kindly let the user know you don't feel ok dumping xyz into the Windows/System32 folder.",c# .net windows-vista uac elevated-privileges
6557,A,"In C# why can't a List object be stored in a List variable It seems that a List object cannot be stored in a List variable in C# and can't even be explicitly cast that way. List<string> sl = new List<string>(); List<object> ol; ol = sl; results in Cannot implicitly convert type System.Collections.Generic.List<string> to System.Collections.Generic.List<object> And then... List<string> sl = new List<string>(); List<object> ol; ol = (List<object>)sl; results in Cannot convert type System.Collections.Generic.List<string> to System.Collections.Generic.List<object> Of course you can do it by pulling everything out of the string list and putting it back in one at a time but it is a rather convoluted solution. This is gonna change with C# 4.0 so you might wanna lookup covariance and contravariance. It will allow such things in a type safe manner. More or less duplicate: http://stackoverflow.com/questions/317335/why-can-i-not-return-a-listfoo-if-asked-for-a-listifoo John> C#4 will not allow this. Think about ol.Add(new object()); Mike - I believe contravariance isn't allowed in C# either See Generic type parameter variance in the CLR for some more info.  Such covariance on generics is not supported but you can actually do this with arrays: object[] a = new string[] {""spam"" ""eggs""}; C# performs runtime checks to prevent you from putting say an int into a.  That's actually so that you don't try to put any odd ""object"" in your ""ol"" list variant (as List<object> would seem to allow) - because your code would crash then (because the list really is List<string> and will only accept String type objects). That's why you can't cast your variable to a more general specification. On Java it's the other way around you don't have generics and instead everything is List of object at runtime and you really can stuff any strange object in your supposedly-strictly typed List. Search for ""Reified generics"" to see a wider discussion of java's problem...  The reason is that a generic class like List<> is for most purposes treated externally as a normal class. e.g. when you say List<string>() the compiler says ListString() (which contains strings). [Technical folk: this is an extremely plain-English-ified version of what's going on] Consequently obviously the compiler can't be smart enough to convert a ListString to a ListObject by casting the items of its internal collection. That's why there's extension methods for IEnumerable like Convert() that allow you to easily supply conversion for the items stored inside a collection which could be as simple as casting from one to another.  You cannot cast between generic types with different type parameters. Specialized generic types don't form part of the same inheritance tree and so are unrelated types. To do this pre-NET 3.5: List<string> sl = new List<string>(); // Add strings to sl List<object> ol = new List<object>(); foreach(string s in sl) { ol.Add((object)s); // The cast is performed implicitly even if omitted } Using Linq: var sl = new List<string>(); // Add strings to sl var ol = new List<object>(sl.Cast<object>()); // OR var ol = sl.Cast<object>().ToList(); // OR (note that the cast to object here is required) var ol = sl.Select(s => (object)s).ToList();  I have a: private List<Leerling> Leerlingen = new List<Leerling>(); And I was going to fill it with data collected in an List<object> What finally worked for me was this one: Leerlingen = (List<Leerling>)_DeserialiseerLeerlingen._TeSerialiserenObjecten.Cast<Leerling>(); .Cast it to the type you want to get an IEnumerable from that type then typecast the IEnemuerable to the List<> you want.  Yes you can from .NET 3.5: List<string> sl = new List<string>(); List<object> ol = sl.Cast<object>().ToList();  I think that this (contravariance) will actually be supported in C# 4.0. http://blogs.msdn.com/charlie/archive/2008/10/27/linq-farm-covariance-and-contravariance-in-visual-studio-2010.aspx  If you're using .NET 3.5 have a look at the Enumerable.Cast method. It's an extension method so you can call it directly on the List. List<string> sl = new List<string>(); IEnumerable<object> ol; ol = sl.Cast<object>(); It's not exactly what you asked for but should do the trick. Edit: As noted by Zooba you can then call ol.ToList() to get a List  Here is another pre-.NET 3.5 solution for any IList whose contents can be cast implicitly. public IList<B> ConvertIList<D B>(IList<D> list) where D : B { List<B> newList = new List<B>(); foreach (D item in list) { newList.Add(item); } return newList; } (Based on Zooba's example)  This has a lot to do with covariance e.g. generic types are considered as parameters and if the parameters do not resolve properly to a more specific type then the operation fails. The implication of such is that you really cannot cast to a more general type like object. And as stated by Rex the List object won't convert each object for you. You might want to try the ff code instead: List<string> sl = new List<string>(); //populate sl List<object> ol = new List<object>(sl); or: List<object> ol = new List<object>(); ol.AddRange(sl); ol will (theoretically) copy all the contents of sl without problems.  Think of it this way if you were to do such a cast and then add an object of type Foo to the list the list of strings is no longer consistent. If you were to iterate the first reference you would get a class cast exception because once you hit the Foo instance the Foo could not be converted to string! As a side note I think it would be more significant whether or not you can do the reverse cast: List<object> ol = new List<object>(); List<string> sl; sl = (List<string>)ol; I haven't used C# in a while so I don't know if that is legal but that sort of cast is actually (potentially) useful. In this case you are going from a more general class (object) to a more specific class (string) that extends from the general one. In this way if you add to the list of strings you are not violating the list of objects. Does anybody know or can test if such a cast is legal in C#? I think your example suffers from the same problem. What happens if ol has something in it that is not a string? The problem is some methods on List would work fine such as adding/inserting. But iterating might be a real problem. Eric Lippert has a great series of blog posts about this topic: why it might work to add covariance and contravariance contraints to generic methods but may never work the way we'd like at the class level. http://is.gd/3kQc @ChrisAmmerman: If `ol` had something in it that's not a string I suppose I would expect the cast to fail at runtime. But where you really would run into trouble is if the cast succeeded and *then* something were added to `ol` that's not a string. Because `sl` references the same object now your `List` would contain a non-string. The `Add` is the problem which I guess justifies why this code won't compile but it will compile if you change `List ol` to `IEnumerable ol` which doesn't have an `Add`. (I checked this in C# 4.) With that change it compiles but throws an `InvalidCastException` because the runtime type of `ol` is still `List`.",c# .net generics covariance type-safety
13170,A,"A ThreadStateException occures when trying to restart a thread From time to time I get a System.Threading.ThreadStateException when attempting to restart a thread. The code in question is as follows: // Make sure the thread is done stopping while (this.mThread.ThreadState == ThreadState.Running) { Thread.Sleep(0); } // Respawn a thread if the current one is stopped or doesn't exist if (this.mThread == null || this.mThread.ThreadState == ThreadState.Stopped) { this.mThread = new Thread(new ParameterizedThreadStart(Monitor)); } // Start the thread if (check) { this.mThread.Start(60000); } else { this.mThread.Start(0); } So two questions - is this the correct way of doing things and it is is there a way to prevent the error from occurring? It's possible for a thread to be in more than one state at once therefore the ThreadState property is actually a bitmap of possible states. So testing for equality with just one state will not give you the right result. You would need to do something like: if((mThread.ThreadState & ThreadState.Running) != 0) However checking thread state is the wrong to do anything. I'm not entirely clear what you're trying to achieve but I will guess that you're waiting for a thread to terminate before restarting it. In that case you should do: mThread.Join(); mThread = new Thread(new ParameterizedThreadStart(Monitor)); if(check) mThread.Start(60000); else mThread.Start(0); Although if you describe the problem you're trying to solve in more detail I'm almost certain there will be a better solution. Waiting around for a thread to end just to restart it again doesn't seem that efficient to me. Perhaps you just need some kind of inter-thread communication? John.  A ThreadStateException is thrown because you're trying to start a thread that's not in a startable state. The most likely situations would be that it's already running or that it has fully exited. There are potentially a couple things that might be happening. First is the thread might have transitioned from Running to StopRequested which isn't fully stopped yet so your logic doesn't create a new thread and you're trying to start a thread which has just finished running or is about to finish running (neither of which is a valid state for restarting). The other possibility is that the thread was aborted. Threads which are aborted go to the Aborted state not the Stopped state and of course are also not valid for restarting. Really the only kind of thread that is still alive that can be ""restarted"" is one that's suspended. You might want to use this conditional instead: if (this.mThread == null || this.mThread.ThreadState != ThreadState.Suspended)  The problem is that you have code that first checks if it should create a new thread object and another piece of code that determines wether to start the thread object. Due to race conditions and similar things your code might end up trying to call .Start on an existing thread object. Considering you don't post the details behind the check variable it's impossible to know what might trigger this behavior. You should reorganize your code so that .Start is guaranteed to only be called on new objects. In short you should put the Start method into the same if-statement as the one that creates a new thread object. Personally I would try to reorganize the entire code so that I didn't need to create another thread but wrap the code inside the thread object inside a loop so that the thread just keeps on going.",c# .net multithreading exception
8966,A,"Using C#/WIA version 2.0 on Vista to Scan I want to implement a paperless filing system and was looking to use WIA with C# for the image acquisition. There are quite a few sample projects on CodeProject etc. However after downloading every one of them that I can find I have run into a problem. In each and every one of them the reference to WIALib is broken. When I go to add ""Microsoft Windows Image Acquisition"" as a reference the only version available on my development workstation (also the machine that will run this) is 2.0. Unfortunately every one of these sample projects appear to have been coded against 1.x. The reference goes in as ""WIA"" instead of ""WIALib"". I took a shot just changing the namespace import but clearly the API is drastically different. Is there any information on either implementing v2.0 or on upgrading one of these existing sample projects out there? Quick question. Do you absolutely need WIA? Or can you get by with Twain? If Twain is OK I might have some code to donate. It doesn't need to be WIA. I was mostly looking at the WIA setup because it offers the same basic interface for different scanners. I've got 3 scanners on this machine and the TWAIN drivers/software for all of them suck (like blocking the screen during scanning). For document management I'm really looking for simple 200dpi grayscale scans so most of the stuff in the TWAIN drivers is overkill. That said asking here was part of my last attempt to figure out how to do it in WIA before moving on to TWAIN.  Update: I'm adding this separately since its a different answer (a year later). I learnt XP has WIA 1.0 and Vista onward has WIA2.0. You can however install WIA 2.0 for Windows XP Sp1+ from here. I then also made a small library with code I found somewhere on the interweb here it also has the ability to scan multiple pages: http://adfwia.codeplex.com/  Another note: You have to download the WIA 2.0 dll from Microsoft.com and then browse to the dll and add it to your project.  To access WIA you'll need to add a reference to the COM library ""Microsoft Windows Image Acquisition Library v2.0"" (wiaaut.dll). add a ""using WIA;"" const string wiaFormatJPEG = ""{B96B3CAE-0728-11D3-9D7B-0000F81EF32E}""; CommonDialogClass wiaDiag = new CommonDialogClass(); WIA.ImageFile wiaImage = null; wiaImage = wiaDiag.ShowAcquireImage( WiaDeviceType.UnspecifiedDeviceType WiaImageIntent.GrayscaleIntent WiaImageBias.MaximizeQuality wiaFormatJPEG true true false); WIA.Vector vector = wiaImage.FileData; (System.Drawing) Image i = Image.FromStream(new MemoryStream((byte[])vector.get_BinaryData())); i.Save(filename) Thats a basic way works with my flatbed/doc feeder. If you need more than one document/page at a time though there is probably a better way to do it (from what I could see this only handles one image at a time although I'm not entirely sure). While it is a WIA v1 doc Scott Hanselman's Coding4Fun article on WIA does contain some more info on how to do it for multiple pages I think (I'm yet to go further than that myself) If its for a paperless office system you might want also check out MODI (Office Document Imaging) to do all the OCR for you. I'll give this a shot. I""m not messing with OCR because I haven't seen any of the systems get anywhere close enough on my stuff to be more useful than just doing some decent metadata and tagging. This should give me most of what I need as once it's referenced I can dig through the API. Instead of that magic GUID you can use System.Drawing.Imaging.ImageFormat.Jpeg.Guid.ToString(""B""). Or you can use the guid defined in Interop.WIA.dll. FormatID.wiaFormatJPEG The code above will throw an exception with the message ""Exception from HRESULT: 0x80210015"" if there aren't any valid WIA devices available. You can check for devices using: WIA.DeviceManagerClass wiaDM = new DeviceManagerClass(); if (wiaDM == null || wiaDM.DeviceInfos == null || wiaDM.DeviceInfos.Count == 0) // No devices  Heres how to target WIA 1.0 also so you can ship your app to Windows Xp. Something I was desperately looking for!! http://stackoverflow.com/questions/678844/how-to-develop-using-wia-1-under-vista",c# .net .net-3.5 wia image-scanner
11288,A,"WPF - Sorting a composite collection So WPF doesn't support standard sorting or filtering behavior for views of CompositeCollections so what would be a best practice for solving tihs problem. There are two or more object collections of different types. You want to combine them into a single sortable and filterable collection (withing having to manually implement sort or filter). One of the approaches I've considered is to create a new object collection with only a few core properties including the ones that I would want the collection sorted on and an object instance of each type. class MyCompositeObject { enum ObjectType; DateTime CreatedDate; string SomeAttribute; myObjectType1 Obj1; myObjectType2 Obj2; { class MyCompositeObjects : List<MyCompositeObject> { } And then loop through my two object collectiosn to build the new composite collection. Obviously this is a bit of a brute force method but it would work. I'd get all the default view sorting and filtering behavior on my new composite object collection and I'd be able to put a data template on it to display my list items properly depending on which type is actually stored in that composite item. What suggestions are there for doing this in a more elegant way? Update: I found a much more elegant solution: class MyCompositeObject { DateTime CreatedDate; string SomeAttribute; Object Obj1; { class MyCompositeObjects : List<MyCompositeObject> { } I found that due to reflection the specific type stored in Obj1 is resolved at runtime and the type specific DataTemplate is applied as expected!  Have you looked at CollectionViewSource and ICollectionView? With those classes you're able to customize grouping sorting and filtering. I'm not sure if it applies to CompositeCollections though. Have you ever tried? I tried and failed. Would love to see some code or links anything. ageektrapped: No it doesn't which is the problem.  ""Brute force"" method you mention is actually ideal solution. Mind you all objects are in RAM there is no I/O bottleneck so you can pretty much sort and filter millions of objects in less than a second on any modern computer. The most elegant way to work with collections is System.Linq namespace in .NET 3.5 Thanks - I also considered LINQ to objects but my concern there is loss of flexibility for typed data templates which I need to display the objects in my list. If you can't predict at this moment how people will sort and filter your object collection then you should look at System.Linq.Expressions namespace to build your lambda expressions on demand during runtime (first you let user to build expression then compile run and at the end you use reflection namespace to enumerate through results). It's more tricky to wrap your head around it but invaluable feature probably (to me definitively) even more ground-breaking feature than LINQ itself. lubos: Thanks - I also considered LINQ to objects but my concern there is loss of flexibility for typed data templates which I need to display the objects in my list.  itowlson answers a simple and powerful answer that solves all your pain. take a look and vote on his answer. Nevermind do whatever works best for you. There are sometimes cases that you do want to use a CompositeCollection and sort it out. From the answer itself: ""Regarding filtering sorting and grouping as per Aron's answer these are not available on a view over a CompositeCollection."" the accepted answer above works perfectly without all the Composite Collection fuss.  I'm not yet very familiar with WPF but I see this as a question about sorting and filtering List<T> collections. (withing having to manually implement sort or filter) Would you reconsider implementing your own sort or filter functions? In my experience it is easy to use. The examples below use an anonymous delegate but you could easily define your own method or a class to implement a complex sort or filter. Such a class could even have properties to configure and change the sort and filter dynamically. Use List<T>.Sort(Comparison<T> comparison) with your custom compare function: // Sort according to the value of SomeAttribute List<MyCompositeObject> myList = ...; myList.Sort(delegate(MyCompositeObject a MyCompositeObject b) { // return -1 if a < b // return 0 if a == b // return 1 if a > b return a.SomeAttribute.CompareTo(b.SomeAttribute); }; A similar approach for getting a sub-collection of items from the list. Use List<T>.FindAll(Predicate<T> match) with your custom filter function: // Select all objects where myObjectType1 and myObjectType2 are not null myList.FindAll(delegate(MyCompositeObject a) { // return true to include 'a' in the sub-collection return (a.myObjectType1 != null) && (a.myObjectType2 != null); } Brian: Once MyCompositeObject is built I get sorting and filtering for free as part of an ICollectionView.. The crux of the problem is dealing with the separate object type collections and treating them as one collection. Composite collections are the answer for creating the collection but not the sorting filtering.",c# .net wpf data-binding collections
11762,A,"CryptographicException: Padding is invalid and cannot be removed I needed some simple string encryption so I wrote the following code (with a great deal of ""inspiration"" from here):  // create and initialize a crypto algorithm private static SymmetricAlgorithm getAlgorithm(string password) { SymmetricAlgorithm algorithm = Rijndael.Create(); Rfc2898DeriveBytes rdb = new Rfc2898DeriveBytes( password new byte[] { 0x530x6f0x640x690x750x6d0x20 // salty goodness 0x430x680x6c0x6f0x720x690x640x65 } ); algorithm.Padding = PaddingMode.ISO10126; algorithm.Key = rdb.GetBytes(32); algorithm.IV = rdb.GetBytes(16); return algorithm; } /* * encryptString * provides simple encryption of a string with a given password */ public static string encryptString(string clearText string password) { SymmetricAlgorithm algorithm = getAlgorithm(password); byte[] clearBytes = System.Text.Encoding.Unicode.GetBytes(clearText); MemoryStream ms = new MemoryStream(); CryptoStream cs = new CryptoStream(ms algorithm.CreateEncryptor() CryptoStreamMode.Write); cs.Write(clearBytes 0 clearBytes.Length); cs.Close(); return Convert.ToBase64String(ms.ToArray()); } /* * decryptString * provides simple decryption of a string with a given password */ public static string decryptString(string cipherText string password) { SymmetricAlgorithm algorithm = getAlgorithm(password); byte[] cipherBytes = Convert.FromBase64String(cipherText); MemoryStream ms = new MemoryStream(); CryptoStream cs = new CryptoStream(ms algorithm.CreateDecryptor() CryptoStreamMode.Write); cs.Write(cipherBytes 0 cipherBytes.Length); cs.Close(); return System.Text.Encoding.Unicode.GetString(ms.ToArray()); } The code appears to work fine except that when decrypting data with an incorrect key I get a CryptographicException - ""Padding is invalid and cannot be removed"" - on the cs.Close() line in decryptString. example code:  string password1 = ""password""; string password2 = ""letmein""; string startClearText = ""The quick brown fox jumps over the lazy dog""; string cipherText = encryptString(startClearText password1); string endClearText = decryptString(cipherText password2); // exception thrown My question is is this to be expected? I would have thought that decrypting with the wrong password would just result in nonsense output rather than an exception. This saved me so much time with your comment: `""The code appears to work fine except that when decrypting data with an incorrect key""` I _swore_ I had copied the keys but looking 2x I didn't. Hopefully this helps someone else before looking at the padding mechanism or changing code. Although this have been already answered I think it would be a good idea to explain why it is to be expected. A padding scheme is usually applied because most cryptographic filters are not semantically secure and to prevent some forms of cryptoatacks. For example usually in RSA the OAEP padding scheme is used which prevents some sorts of attacks (such as a chosen plaintext attack or blinding). A padding scheme appends some (usually) random garbage to the message m before the message is sent. In the OAEP method for example two Oracles are used (this is a simplistic explanation): Given the size of the modulus you padd k1 bits with 0 and k0 bits with a random number. Then by applying some transformation to the message you obtain the padded message wich is encrypted and sent. That provides you with a randomization for the messages and with a way to test if the message is garbage or not. As the padding scheme is reversible when you decrypt the message whereas you can't say anything about the integrity of the message itself you can in fact make some assertion about the padding and thus you can know if the message has been correctly decrypted or you're doing something wrong (i.e someone has tampered with the message or you're using the wrong key) Jorge thanks for the explanation. I'm seeing the same behavior as described the data that is decrypted is correct. am I supposed to eat this exception or (hopefully) there is something I'm doing incorrectly that I can correct? what is going wrong when the exception is thrown? all the posts I've read seem to be written by people who are more interested in making the exception going away. in my case I want my usage to be correct :)  If you want your usage to be correct you should add authentication to your ciphertext so that you can verify that it is the correct pasword or that the ciphertext hasn't been modified. The padding you are using ISO10126 will only throw an exception if the last byte doesn't decrypt as one of 16 valid values for padding (0x01-0x10). So you have a 1/16 chance of it NOT throwing the exception with the wrong password where if you authenticate it you have a deterministic way to tell if your decryption is valid. Implementing crypto deceptively easy but rather is easy to make mistakes. For example you use a fixed salt for for you key and iv derivation that means every ciphertext encrypted with the same password will reuse it's IV with that key that breaks semantic security with CBC mode the IV needs to be both unpredictable and unique for a given key. For that reason I have a code snippet that I try to keep reviewed and up to date (comments issues welcome): Modern Examples of Symmetric Authenticated Encryption of a string C#. If you use it's AESThenHMAC.AesSimpleDecryptWithPassword(ciphertext password) when the wrong password is used null is returned if the ciphertext or iv has been modified post encryption null is returned you will never get junk data back or a padding exception.  I experienced a similar ""Padding is invalid and cannot be removed."" exception but in my case the key IV and padding were correct. It turned out that flushing the crypto stream is all that was missing. Like this:  MemoryStream msr3 = new MemoryStream(); CryptoStream encStream = new CryptoStream(msr3 RijndaelAlg.CreateEncryptor() CryptoStreamMode.Write); encStream.Write(bar2 0 bar2.Length); // unless we flush the stream we would get ""Padding is invalid and cannot be removed."" exception when decoding encStream.FlushFinalBlock(); byte[] bar3 = msr3.ToArray(); This did it for me! The same should do the `encStream.Close();`.  Yes this is to be expected or at least its exactly what happens when our crypto routines get non-decryptable data  There may be some unread bytes in the CryptoStream. Closing before reading the stream completely was causing the error in my program.",c# .net exception encryption
8348,A,"Using unhandled exceptions instead of Contains()? Imagine an object you are working with has a collection of other objects associated with it for example the Controls collection on a WinForm. You want to check for a certain object in the collection but the collection doesn't have a Contains() method. There are several ways of dealing with this. Implement your own Contains() method by looping through all items in the collection to see if one of them is what you are looking for. This seems to be the ""best practice"" approach. I recently came across some code where instead of a loop there was an attempt to access the object inside a try statement as follows: try { Object aObject = myCollection[myObject]; } catch(Exception e) { //if this is thrown then the object doesn't exist in the collection } My question is how poor of a programming practice do you consider the second option be and why? How is the performance of it compared to a loop through the collection? The latter is an acceptable solution. Although I would definitely catch on the specific exception (ElementNotFound?) that the collection throws in that case. Speedwise it depends on the common case. If you're more likely to find the element than not the exception solution will be faster. If you're more likely to fail then it would depend on size of the collection and its iteration speed. Either way you'd want to measure against normal use to see if this is actually a bottle neck before worrying about speed like this. Go for clarity first and the latter solution is far more clear than the former.  The general rule of thumb is to avoid using exceptions for control flow unless the circumstances that will trigger the exception are ""exceptional"" -- e.g. extremely rare! If this is something that will happen normally and regularly it definitely should not be handled as an exception. Exceptions are very very slow due to all the overhead involved so there can be performance reasons as well if it's happening often enough.  In general using exception handling for program flow and logic is bad practice. I personally feel that the latter option is unacceptable use of exceptions. Given the features of languages commonly used these days (such as Linq and lambdas in C# for example) there's no reason not to write your own Contains() method. As a final thought these days most collections do have a contains method already. So I think for the most part this is a non-issue.  Take a look at this blog post from Krzystof: http://blogs.msdn.com/kcwalina/archive/2008/07/17/ExceptionalError.aspx Exceptions should be used for communicating error conditions but they shouldn't be used as control logic (especially when there are far simpler ways to determine a condition such as Contains). Part of the issue is that exceptions while not expensive to throw are expensive to catch and all exceptions are caught at some point.  Exceptions should be exceptional. Something like 'The collection is missing because the database has fallen out from underneath it' is exceptional Something like 'the key is not present' is normal behaviour for a dictionary. For your specific example of a winforms Control collection the Controls property has a ContainsKey method which is what you're supposed to use. There's no ContainsValue because when dealing with dictionaries/hashtables there's no fast way short of iterating through the entire collection of checking if something is present so you're really discouraged from doing that. As for WHY Exceptions should be exceptional it's about 2 things Indicating what your code is trying to do. You want to have your code match what it is trying to achieve as closely as possible so it is readable and maintainable. Exception handling adds a bunch of extra cruft which gets in the way of this purpose Brevity of code. You want your code to do what it's doing in the most direct way so it is readable and maintainable. Again the cruft added by exception handling gets in the way of this.  I would have to think about it more as to how much I like it... my gut instinct is eh not so much... EDIT: Ryan Fox's comments on the exceptional case is perfect I concur As for performance it depends on the indexer on the collection. C# lets you override the indexer operator so if it is doing a for loop like the contains method you would write then it will be just as slow (with maybe a few nanoseconds slower due to the try/catch... but nothing to worry about unless that code itself is within a huge loop). If the indexer is O(1) (or even O(log(n))... or anything faster than O(n)) then the try/catch solution would be faster of course. Also I am assuming the indexer is throwing the exception if it is returning null you could of course just check for null and not use the try/catch.  I would have to say that this is pretty bad practice. Whilst some people might be happy to say that looping through the collection is less efficient to throwing an exception there is an overhead to throwing an exception. I would also question why you are using a collection to access an item by key when you would be better suited to using a dictionary or hashtable. My main problem with this code however is that regardless of the type of exception thrown you are always going to be left with the same result. For example an exception could be thrown because the object doesn't exist in the collection or because the collection itself is null or because you can't cast myCollect[myObject] to aObject. All of these exceptions will get handled in the same way which may not be your intention. These are a couple of nice articles on when and where it is usally considered acceptable to throw exceptions: Foundations of Programming Throwing exceptions in c# I particularly like this quote from the second article: It is important that exceptions are thrown only when an unexpected or invalid activity occurs that prevents a method from completing its normal function. Exception handling introduces a small overhead and lowers performance so should not be used for normal program flow instead of conditional processing. It can also be difficult to maintain code that misuses exception handling in this way.  If while writing your code you expect this object to be in the collection and then during runtime you find that it isn't I would call that an exceptional case and it is proper to use an exception. However if you're simply testing for the existence of an object and you find that it is not there this is not exceptional. Using an exception in this case is not proper. The analysis of the runtime performance depends on the actual collection being used and the method if searching for it. That shouldn't matter though. Don't let the illusion of optimization fool you into writing confusing code.",c# .net error-handling
1760,A,".NET Unit Testing packages? Getting back into a bit more .NET after a few-years of not using it full-time and wondering what the good unit testing packages are these days. I'm familiar with NUnit (a few years ago) and have played briefly around with IronRuby with the goal of getting something like rspec going but don't know much beyond that. I realise I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-) Suggestions? wow an incredibly useful question with lots of upvotes that hasn't been ""closed as not constructive""... the SO fun police must have fallen asleep on their shift I have made a small example of testing a .net lib using ironRuby: http://khebbie.dk/post/2008/08/Example-of-using-ironRubys-mini_rspec-library.aspx Thanks for that. I've actually played around with this extensively myself. Unfortunately IronRuby isn't capable of running full rspec yet only mspec which is a lot more cut down. Even so it's nicer than nunit/etc :-)  Stick to NUnit. Don't go anywhere near MSTest. NUnit + ReSharper is an absolute joy to work with. Why should you stear away from MSTest? I'd appreciate if you'd actually bothered to share WHY you wanna stear away from it. And R# works with MSTest as well (with the Gallio plugin). Hi Kjetil. It's mainly for three reasons. 1. The meta-data that the MS tests create. Why? Reflect like NUnit. 2. The test runner is horrid. 3. NUnit does everything better - why change. I did for a while but then changed back. I also very much concur with the accepted answer. MS test is slow and clunky. Why repeat what's already been answered? I've also encountered various bugs with the MS test ""runner"". Basically VS leaves it running in the background and under certain circumstances tests you ran 10 minutes ago can interfere with the one you're about to run right now :-(  I like MbUnit er Gallio. Most importantly to me is having good tools support inside Visual Studio. For that I use Resharper which has an MbUnit test runner. A lot of folks seem to like TestDriven.NET as their test runner as well.  There are so many it's crazy. Crazy good I guess. For the conservative types (me) NUnit is still available and still more than capable. For the Microsoft-types MSTest is adequate but slow and clunky compared to Nunit. It also lacks code coverage without paying the big bucks for the pricey versions of Visual Studio. There's also MbUnit. It's like NUnit but has nifty features like RowTest (run the same test with different parameters) and Rollback (put the database back like you found it after a test) And finally xUnit.net is the trendy option with some attitude. Oh and TestDriven.NET will give you IDE integration for both Nunit and MBunit. I'm sure they're all just fine. I'd steer away from MSTest though unless you just enjoy the convenience of having everything in one IDE out of the box. Scott Hanselman has a podcast on this very topic. +1 note NUnit 2.5 has the nice RowTest features plus Combinatorial testing of arguments etc. The difference between MSTest and NUnit are not that big if you ask me. It mostly boils down to preferred syntax and if you use TesteDriven.Net which also supports MSTest the performance is pretty much the same. Aye NUnit 2.5 has RowTest features via the [TestCase] attribute.  I like TestDriven.NET (even though I use ReSharper) and I'm pretty happy with XUnit.net. It uses Facts instead of Tests which many people dislike but I like the difference in terminology. It's useful to think of a collection of automatically provable Facts about your software and see which ones you violate when you make a change. Be aware that Visual Studio 2008 Professional (and above) now comes with integrated Unit Testing (it used to be available only with the Team System Editions) and may be suitable for your needs.  I used to use NUnit but now tend to use MbUnit for two key features: 1. The RowTest feature allows you to easily run the same test on different sets of parameters which is important if you really want thorough coverage. 2. The Rollback feature allows you to run tests against your database while rolling back changes after every test keeping your database in exactly the same state every time. And it's as easy as adding the [Rollback] attribute. Another nice aspect of MbUnit is that its syntax is nearly identical to NUnit so if you have a whole test bed already in place under NUnit you can just switch out the references without the need to change any (very much?) code.  This is an old question but you might find it interesting that Gallio v3.1 now supports RSpec via IronRuby.  This is really a personal opinion on my part (I guess that's redundant since it is a forum). NUnit MSTest ect all do pretty mutch the same thing. However I find NMock indispensable. NMock or any mocking package is not unit testing but it makes it so much easier to do unit testing that it mught as well be.  I use the following: TestDriven.NET - Unit Testing add on for Visual Studio Typemock Isolator- Mocking framework for .Net Unit Testing NUnit - An open source unit testing framework that is in C#.  We use NUnit and MBUnit here. We use TestDriven.NET to run the unit tests from within Visual Studio. We use the excellent highly recommended RhinoMocks as a mock framework.  xUnit.net looks like it provides a slightly different approach to N/MB/MS/Unit which is interesting. In my search for an rspec-like solution (because I LOVE the rspec) I also came across NSpec which looks a bit wordy but combined with the NSpec Extensions addon to use C#3 extension methods it looks pretty nice. You may want to look at this NSpec (http://nspec.org). It's almost identical to RSpec.  I used to use NUnit but I switched to MbUnit since it has more features. I love RowTest. It lets you parametrize your tests. NUnit does have a litter bit better tool support though. I am using ReSharper to run MbUnit Tests. I've had problems with TestDriven.NET running my SetUp methods for MbUnit.",c# .net unit-testing testing
15066,A,"Cycle Button Background Images in C# I have a form in C# that has a button that when clicked I want the background image to cycle through a set of images (which I have as resources to the project). The images are named '1' '2' etc. and each time I click the button I want its background image to increment to the next one and go back to ""_1"" when it gets to the highest. Is there a way to do this? I tried getting button1.BackgroundImage.ToString() but that yields System.Drawing.Bitmap instead of Resources._1 like I was thinking it would (in which case I could just get the last character and switch on that to change the background to the appropriate new image). Thanks for your help. class YourClass { private IEnumerator<Image> enumerator; YourClass(IEnumerable<Image> images) { enumerator = (from i in Enumerable.Range(0 int.Max) from image in images select image).GetEnumerator(); enumerator.MoveNext(); } public Image CurrentImage { get { return enumerator.Current; } } public void OnButtonClick() { enumerator.MoveNext(); } } You can use this code as a backing class for your control under the assumption that user wont click the button more than two billion times. Just note that once this class is created you cannot modify given image list outside. If you want to do such things you need to implement disposable pattern and dispose the enumerator accordingly.  You could subclass Button and override the BackgroundImage property so you can better keep track of the current resource that represents the image. You might also override the onclick method to internally handle cycling to the next image though that might be a little weird if the resources are handled outside of your derived button class.  Why don't you just put the images in an array?",c# .net winforms
1304,A,"How to check for file lock? Is there any way to check whether a file is locked without using a try/catch block? Right now the only way I know of is to just open the file and catch any System.IO.IOException. The trouble is that an IOException could be thrown for many reasons other than a locked file. This is an old question and all of the old answers are incomplete or wrong. I added a complete and correct answer. Then between the two lines another process could easily lock the file giving you the same problem you were trying to avoid to begin with: exceptions. However this way you would know that the problem is temporary and to retry later. (E.g. you could write a thread that if encountering a lock while trying to write keeps retrying until the lock is gone.) The IOException on the other hand is not by itself specific enough that locking is the cause of the IO failure. There could be reasons that aren't temporary.  A variation of DixonD's excellent answer (above).  public static bool TryOpen( string path FileMode fileMode FileAccess fileAccess FileShare fileShare TimeSpan timeout out Stream stream) { var endTime = DateTime.Now + timeout; while (DateTime.Now < endTime) { if (TryOpen(path fileMode fileAccess fileShare out stream)) return true; } stream = null; return false; } public static bool TryOpen( string path FileMode fileMode FileAccess fileAccess FileShare fileShare out Stream stream) { try { stream = File.Open(path fileMode fileAccess fileShare); return true; } catch (IOException e) { if (!FileIsLocked(e)) throw; stream = null; return false; } } private const uint HRFileLocked = 0x80070020; private const uint HRPortionOfFileLocked = 0x80070021; private static bool FileIsLocked(IOException ioException) { var errorCode = (uint)Marshal.GetHRForException(ioException); return errorCode == HRFileLocked || errorCode == HRPortionOfFileLocked; } Usage:  private void Sample(string filePath) { Stream stream = null; try { var timeOut = TimeSpan.FromSeconds(1); if (!TryOpen( filePath FileMode.Open FileAccess.ReadWrite FileShare.ReadWrite timeOut out stream)) return; // Use stream... } finally { if (stream != null) stream.Close(); } } This is the only practical solution so far. And it works. Boooyyyyy... You better put some Thread.Sleep(200) in there and get off my CPU! What part do you want to sleep? Why? @Tristan I guess Paul Knopf meant to use Thread.Sleep between access tries.  You can see if the file is locked by trying to read or lock it yourself first. Please see my answer here for more information.  No unfortunately and if you think about it that information would be worthless anyway since the file could become locked the very next second (read: short timespan). Why specifically do you need to know if the file is locked anyway? Knowing that might give us some other way of giving you good advice. If your code would look like this: if not locked then open and update file Then between the two lines another process could easily lock the file giving you the same problem you were trying to avoid to begin with: exceptions. If file is locked we can wait some time and try again. If it is another kind of issue with file access then we should just propagate exception. Yes but the standalone check for whether a file is locked is useless the only correct way to do this is to try to open the file for the purpose you need the file and then handle the lock problem at that point. And then as you say wait or deal with it in another way. You could argue the same for access rights though it would of course be more unlikely. @LasseV.Karlsen Another benefit of doing a preemptive check is that you can notify the user before attempting a possible long operation and interrupting mid-way. The lock occurring mid-way is still possible of course and needs to be handled but in many scenarios this would help the user experience considerably. @Bart Please elaborate where is that method defined can you provide a link to it? And please note that my answer was posted 3rd quarter 2008 different .NET runtime and all but still.... What is `File.ReadWaitForUnlock`? I think the best to do is a File.ReadWaitForUnlock(file timeout) method. and returns null or the FileStream depending on success. I'm following the logic right here? @LasseV.Karlsen checkout my answer for what I ended up using based on your answer. ReadWaitForUnlock is my own method changed to TryOpenRead at the end. It is now possible to get the process that is locking a file. See http://stackoverflow.com/a/20623302/141172  You can also check if any process is using this file and show a list of programs you must close to continue like an installer does. public static string GetFileProcessName(string filePath) { Process[] procs = Process.GetProcesses(); string fileName = Path.GetFileName(filePath); foreach (Process proc in procs) { if (proc.MainWindowHandle != new IntPtr(0) && !proc.HasExited) { ProcessModule[] arr = new ProcessModule[proc.Modules.Count]; foreach (ProcessModule pm in proc.Modules) { if (pm.ModuleName == fileName) return proc.ProcessName; } } } return null; } This can only tell which process keeps an _executable module_ (dll) locked. It will not tell you which process has locked say your xml file.  Here's a variation of DixonD's code that adds number of seconds to wait for file to unlock and try again:  public bool IsFileLocked(string filePath int secondsToWait) { bool isLocked = true; int i = 0; while (isLocked && ((i < secondsToWait) || (secondsToWait == 0))) { try { using (File.Open(filePath FileMode.Open)) { } return false; } catch (IOException e) { var errorCode = Marshal.GetHRForException(e) & ((1 << 16) - 1); isLocked = errorCode == 32 || errorCode == 33; i++; if (secondsToWait !=0) new System.Threading.ManualResetEvent(false).WaitOne(1000); } } return isLocked; } if (!IsFileLocked(file 10)) { ... } else { throw new Exception(...); } Well I was doing a kind of the same thing in my original answer till somebody decided to simplify it:) http://stackoverflow.com/posts/3202085/revisions  Instead of using interop you can use the .NET FileStream class methods Lock and Unlock: FileStream.Lock http://msdn.microsoft.com/en-us/library/system.io.filestream.lock.aspx FileStream.Unlock http://msdn.microsoft.com/en-us/library/system.io.filestream.unlock.aspx This is really the correct answer as it gives the user the ability to not just lock/unlock files but sections of the files as well. All of the ""You can't do that without transactions"" comments may raise a valid concern but are not useful since they're pretending that the functionality isn't there or is somehow hidden when it's not. Actually this is not a solution because you cannot create an instance of FileStream if the file is locked. (an exception will be thrown)  You could call LockFile via interop on the region of file you are interested in. This will not throw an exception if it succeeds you will have a lock on that portion of the file (which is held by your process) that lock will be held until you call UnlockFile or your process dies.  What I ended up doing is: internal void LoadExternalData() { FileStream file; if (TryOpenRead(""filepath/filename"" 5 out file)) { using (file) using (StreamReader reader = new StreamReader(file)) { // do something } } } internal bool TryOpenRead(string path int timeout out FileStream file) { bool isLocked = true; bool condition = true; do { try { file = File.OpenRead(path); return true; } catch (IOException e) { var errorCode = Marshal.GetHRForException(e) & ((1 << 16) - 1); isLocked = errorCode == 32 || errorCode == 33; condition = (isLocked && timeout > 0); if (condition) { // we only wait if the file is locked. If the exception is of any other type there's no point on keep trying. just return false and null; timeout--; new System.Threading.ManualResetEvent(false).WaitOne(1000); } } } while (condition); file = null; return false; } You should consider a Using block for file Use `System.Threading.Thread.Sleep(1000)` instead of `new System.Threading.ManualResetEvent(false).WaitOne(1000)`  When I faced with a similar problem I finished with the following code: public bool IsFileLocked(string filePath) { try { using (File.Open(filePath FileMode.Open)){} } catch (IOException e) { var errorCode = Marshal.GetHRForException(e) & ((1 << 16) - 1); return errorCode == 32 || errorCode == 33; } return false; } +1 Just what i needed for my issue :-) Oh it seems that I haven't read that question has part ""...without using a try catch block""( Thanks for the code! it helps me :D too bad opening sqlite db used by firefox will leave program hang waiting for just the exception to be thrown @kite: There is a better way now http://stackoverflow.com/a/20623302/141172 What if between `return false` and your attempt to open the file again something else snatches it up? Race conditions ahoy!  The other answers rely on old information. This one provides a better solution. Long ago it was impossible to reliably get the list of processes locking a file because Windows simply did not track that information. To support the Restart Manager API that information is now tracked. I put together code that takes the path of a file and returns a List<Process> of all processes that are locking that file. static public class FileUtil { [StructLayout(LayoutKind.Sequential)] struct RM_UNIQUE_PROCESS { public int dwProcessId; public System.Runtime.InteropServices.ComTypes.FILETIME ProcessStartTime; } const int RmRebootReasonNone = 0; const int CCH_RM_MAX_APP_NAME = 255; const int CCH_RM_MAX_SVC_NAME = 63; enum RM_APP_TYPE { RmUnknownApp = 0 RmMainWindow = 1 RmOtherWindow = 2 RmService = 3 RmExplorer = 4 RmConsole = 5 RmCritical = 1000 } [StructLayout(LayoutKind.Sequential CharSet = CharSet.Unicode)] struct RM_PROCESS_INFO { public RM_UNIQUE_PROCESS Process; [MarshalAs(UnmanagedType.ByValTStr SizeConst = CCH_RM_MAX_APP_NAME + 1)] public string strAppName; [MarshalAs(UnmanagedType.ByValTStr SizeConst = CCH_RM_MAX_SVC_NAME + 1)] public string strServiceShortName; public RM_APP_TYPE ApplicationType; public uint AppStatus; public uint TSSessionId; [MarshalAs(UnmanagedType.Bool)] public bool bRestartable; } [DllImport(""rstrtmgr.dll"" CharSet = CharSet.Unicode)] static extern int RmRegisterResources(uint pSessionHandle UInt32 nFiles string[] rgsFilenames UInt32 nApplications [In] RM_UNIQUE_PROCESS[] rgApplications UInt32 nServices string[] rgsServiceNames); [DllImport(""rstrtmgr.dll"" CharSet = CharSet.Auto)] static extern int RmStartSession(out uint pSessionHandle int dwSessionFlags string strSessionKey); [DllImport(""rstrtmgr.dll"")] static extern int RmEndSession(uint pSessionHandle); [DllImport(""rstrtmgr.dll"")] static extern int RmGetList(uint dwSessionHandle out uint pnProcInfoNeeded ref uint pnProcInfo [In Out] RM_PROCESS_INFO[] rgAffectedApps ref uint lpdwRebootReasons); /// <summary> /// Find out what process(es) have a lock on the specified file. /// </summary> /// <param name=""path"">Path of the file.</param> /// <returns>Processes locking the file</returns> /// <remarks>See also: /// http://msdn.microsoft.com/en-us/library/windows/desktop/aa373661(v=vs.85).aspx /// http://wyupdate.googlecode.com/svn-history/r401/trunk/frmFilesInUse.cs (no copyright in code at time of viewing) /// /// </remarks> static public List<Process> WhoIsLocking(string path) { uint handle; string key = Guid.NewGuid().ToString(); List<Process> processes = new List<Process>(); int res = RmStartSession(out handle 0 key); if (res != 0) throw new Exception(""Could not begin restart session. Unable to determine file locker.""); try { const int ERROR_MORE_DATA = 234; uint pnProcInfoNeeded = 0 pnProcInfo = 0 lpdwRebootReasons = RmRebootReasonNone; string[] resources = new string[] { path }; // Just checking on one resource. res = RmRegisterResources(handle (uint)resources.Length resources 0 null 0 null); if (res != 0) throw new Exception(""Could not register resource.""); //Note: there's a race condition here -- the first call to RmGetList() returns // the total number of process. However when we call RmGetList() again to get // the actual processes this number may have increased. res = RmGetList(handle out pnProcInfoNeeded ref pnProcInfo null ref lpdwRebootReasons); if (res == ERROR_MORE_DATA) { // Create an array to store the process results RM_PROCESS_INFO[] processInfo = new RM_PROCESS_INFO[pnProcInfoNeeded]; pnProcInfo = pnProcInfoNeeded; // Get the list res = RmGetList(handle out pnProcInfoNeeded ref pnProcInfo processInfo ref lpdwRebootReasons); if (res == 0) { processes = new List<Process>((int)pnProcInfo); // Enumerate all of the results and add them to the // list to be returned for (int i = 0; i < pnProcInfo; i++) { try { processes.Add(Process.GetProcessById(processInfo[i].Process.dwProcessId)); } // catch the error -- in case the process is no longer running catch (ArgumentException) { } } } else throw new Exception(""Could not list processes locking resource.""); } else if (res != 0) throw new Exception(""Could not list processes locking resource. Failed to get size of result.""); } finally { RmEndSession(handle); } return processes; } } The only answer here that actually answers the OP question... nice!",c# .net io filelock
21715,A,"List or BusinessObjectCollection? Prior to C# generics everyone would code collections for their business objects by creating a collection base that implemented IEnumerable IE: public class CollectionBase : IEnumerable and then would derive their Business Object collections from that. public class BusinessObjectCollection : CollectionBase Now with the generic list class does anyone just use that instead? I've found that I use a compromise of the two techniques: public class BusinessObjectCollection : List<BusinessObject> I do this because I like to have strongly typed names instead of just passing Lists around. What is your approach? It's recommended that in public API's not to use List<T> but to use Collection<T> If you are inheriting from it though you should be fine afaik.  Use the type List<BusinessObject> where you have to declare a list of them. However where you return a list of BusinessObject consider returning IEnumerable<T> IList<T> or ReadOnlyCollection<T> - i.e. return the weakest possible contract that satisfies the client. Where you want to ""add custom code"" to a list code extension methods on the list type. Again attach these methods to the weakest possible contract e.g. public static int SomeCount(this IEnumerable<BusinessObject> someList) Of course you can't and shouldn't add state with extension methods so if you need to add a new property and a field behind it use a subclass or better a wrapper class to store this.  6 of 1 half dozen of another Either way its the same thing. I only do it when I have reason to add custom code into the BusinessObjectCollection. With out it having load methods return a list allows me to write more code in a common generic class and have it just work. Such as a Load method.  I prefer just to use List<BusinessObject>. Typedefing it just adds unnecessary boilerplate to the code. List<BusinessObject> is a specific type it's not just any List object so it's still strongly typed. More importantly declaring something List<BusinessObject> makes it easier for everyone reading the code to tell what types they are dealing with they don't have to search through to figure out what a BusinessObjectCollection is and then remember that it's just a list. By typedefing you'll have to require a consistent (re)naming convention that everyone has to follow in order for it to make sense.  I tend to do it with my own collection if I want to shield the access to the actual list. When you are writing business objects chance is that you need a hook to know if your object is being added/removed in such sense I think BOCollection is better idea. Of coz if that is not required List is more lightweight. Also you might want to check using IList to provide additional abstraction interface if you need some kind of proxying (e.g. a fake collection triggers lazy load from database) But... why not consider Castle ActiveRecord or any other mature ORM framework? :)  If you choose to create your own collection class you should check out the types in System.Collections.ObjectModel Namespace. The namespace defines base classes thare are ment to make it easier for implementers to create a custom collections.  try out this: System.Collections.ObjectModel.Collection<BusinessObject> it makes unnecessary to implement basic method like CollectionBase do  You should probably avoid creating your own collection for that purpose. It's pretty common to want to change the type of data structure a few times during refactorings or when adding new features. With your approach you would wind up with a separate class for BusinessObjectList BusinessObjectDictionary BusinessObjectTree etc. I don't really see any value in creating this class just because the classname is more readable. Yeah the angle bracket syntax is kind of ugly but it's standard in C++ C# and Java so even if you don't write code that uses it you're going to run into it all the time.  I would do this: using BusinessObjectCollection = List<BusinessObject>; This just creates an alias rather than a completely new type. I prefer it to using List<BusinessObject> directly because it leaves me free to change the underlying structure of the collection at some point in the future without changing code that uses it (as long as I provide the same properties and methods).  I use generic lists for almost all scenarios. The only time that I would consider using a derived collection anymore is if I add collection specific members. However the advent of LINQ has lessened the need for even that.  At the most of the time I simply go with the List way as it gives me all the functionality I need at the 90% of the time and when something 'extra' is needed I inherit from it and code that extra bit.  I do the exact same thing as you Jonathan... just inherit from List<T>. You get the best of both worlds. But I generally only do it when there is some value to add like adding a LoadAll() method or whatever. You could do the LoadAll() as an extension method that hangs from List. That would give you LoadAll() on every List/Collection and it could read in from any IEnumerable... some people might say this is an abuse of extension methods. But I say it allows you to act like you have multiple inheritance. Good idea although my LoadAll() method isn't really generic. It loads from different tables depending on the underlying object type. There might be a way to do it generically but I haven't really looked into that so far.  this is the way: return arrays accept IEnumerable<T> =) accept IEnumerable returns IEnumerable or ReadOnlyCollection but never an array. Read this : http://blogs.msdn.com/ericlippert/archive/2008/09/22/arrays-considered-somewhat-harmful.aspx ! Nice thing about returning IEnumerable is you can easily add lazy eval to your entire app.  You can use both. For laziness - I mean productivity - List is a very useful class it's also ""comprehensive"" and frankly full of YANGNI members. Coupled with the sensible argument / recommendation put forward by the MSDN article already linked about exposing List as a public member I prefer the ""third"" way: Personally I use the decorator pattern to expose only what I need from List i.e: public OrderItemCollection : IEnumerable<OrderItem> { private readonly List<OrderItem> _orderItems = new List<OrderItem>(); void Add(OrderItem item) { _orderItems.Add(item) } //implement only the list members which are required from your domain. //ie. sum items calculate weight etc... private IEnumerator<string> Enumerator() { return _orderItems.GetEnumerator(); } public IEnumerator<string> GetEnumerator() { return Enumerator(); } } Further still I'd probably abstract OrderItemCollection into IOrderItemCollection so I can swap my implementation of IOrderItemCollection over in the future in (I may prefer to use a different inner enumerable object such as Collection or more likley for perf use a Key Value Pair collection or Set.  I've been going back and forth on 2 options: public class BusinessObjectCollection : List<BusinessObject> {} or methods that just do the following: public IEnumerable<BusinessObject> GetBusinessObjects(); The benefits of the first approach is that you can change the underlying data store without having to mess with method signatures. Unfortunately if you inherit from a collection type that removes a method from the previous implementation then you'll have to deal with those situations throughout your code.  I generally only derive my own collection classes if I need to ""add value"". Like if the collection itself needed to have some ""metadata"" properties tagging along with it.  I am generally in the camp of just using a List directly unless for some reason I need to encapsulate the data structure and provide a limited subset of its functionality. This is mainly because if I don't have a specific need for encapsulation then doing it is just a waste of time. However with the aggregate initializes feature in C# 3.0 there are some new situations where I would advocate using customized collection classes. Basically C# 3.0 allows any class that implements IEnumerable and has an Add method to use the new aggregate initializer syntax. For example because Dictionary defines a method Add(K key V value) it is possible to initialize a dictionary using this syntax: var d = new Dictionary<string int> { {""hello"" 0} {""the answer to life the universe and everything is:"" 42} }; The great thing about the feature is that it works for add methods with any number of arguments. For example given this collection: class c1 : IEnumerable { void Add(int x1 int x2 int x3) { //... } //... } it would be possible to initialize it like so: var x = new c1 { {123} {456} } This can be really useful if you need to create static tables of complex objects. For example if you were just using List<Customer> and you wanted to create a static list of customer objects you would have to create it like so: var x = new List<Customer> { new Customer(""Scott Wisniewski"" ""555-555-5555"" ""Seattle"" ""WA"") new Customer(""John Doe"" ""555-555-1234"" ""Los Angeles"" ""CA"") new Customer(""Michael Scott"" ""555-555-8769"" ""Scranton PA"") new Customer(""Ali G"" """" ""Staines"" ""UK"") } However if you use a customized collection like this one: class CustomerList : List<Customer> { public void Add(string name string phoneNumber string city string stateOrCountry) { Add(new Customer(name phoneNumber city stateOrCounter)); } } You could then initialize the collection using this syntax: var customers = new CustomerList { {""Scott Wisniewski"" ""555-555-5555"" ""Seattle"" ""WA""} {""John Doe"" ""555-555-1234"" ""Los Angeles"" ""CA""} {""Michael Scott"" ""555-555-8769"" ""Scranton PA""} {""Ali G"" """" ""Staines"" ""UK""} } This has the advantage of being both easier to type and easier to read because their is no need to retype the element type name for each element. The advantage can be particularly strong if the element type is long or complex. That being said this is only useful if you need static collections of data defined in your app. Some types of apps like compilers use them all the time. Others like typical database apps don't because they load all their data from a database. My advice would be that if you either need to define a static collection of objects or need to encapsulate away the collection interface then create a custom collection class. Otherwise I would just use List<T> directly.  As someone else pointed out it is recommended not to expose List publicly and FxCop will whinge if you do so. This includes inheriting from List as in: public MyTypeCollection : List<MyType> In most cases public APIs will expose IList (or ICollection or IEnumerable) as appropriate. In cases where you want your own custom collection you can keep FxCop quiet by inheriting from Collection instead of List.",c# .net generics collections class-design
16556,A,"VS.NET Application Diagrams Have you used VS.NET Architect Edition's Application and System diagrams to start designing a solution? If so did you find it useful? Did the ""automatic implementation"" feature worked ok? I used to use it a lot. This designer worked good for stubbing out prototype projects but ultimately I found myself wasting a lot of time moving the mouse around when I could be typing. It seemed like an awesome idea to be able to print out the class diagrams to show APIs to other developers while I was prototyping but it proved quite limiting and it looks awful on a non-color printer. Now I just use the text editor and some AutoHotkey macros to get everything done.  Yes and no it's not very useful in my opinion. It's not very stable it's easy to get out of sync and the ""look how fast I generate this"" advantage is virtually nil when compared to more mundane things such as code snippets. Then again I am a total ""Architect"" luddite so take this with a grain of salt.  I agree with Stu and I don't consider myself an Architect luddite :-). Kind of like a lot of MS frameworks over the years you are tied to their particular way of thinking which doesn't always gel with the ideas that come out of the rest of the architecture community at large. Generating stubs in my opinion doesn't really add that much value and the round trip half of the equation has messed up some of my project files and made me have to re-write the things manually.",c# .net visual-studio architecture diagram
22322,A,"How to late bind 32bit/64 bit libs at runtime I've got a problem similar tobut subtly different from that described here (Loading assemblies and their dependencies). I have a C++ DLL for 3D rendering that is what we sell to customers. For .NET users we will have a CLR wrapper around it. The C++ DLL can be built in both 32 and 64bit versions but I think this means we need to have two CLR wrappers since the CLR binds to a specific DLL? Say now our customer has a .NET app that can be either 32 or 64bit and that it being a pure .NET app it leaves the CLR to work it out from a single set of assemblies. The question is how can the app code dynamically choose between our 32 and 64bit CLR/DLL combinations at run-time? Even more specifically is the suggested answer to the aforementioned question applicable here too (i.e. create a ResolveEvent handler)? Thanks in advance. I encountered a similar scenario a while back. A toolkit I was using did not behave well in a 64-bit environment and I wasn't able to find a way to dynamically force the assemblies to bind as 32 bit. It is possible to force your assemblies to work in 32 bit mode but this requires patching the CLR header (there is a tool that does that in the Framework) and if your assemblies are strongly-named this does not work out. I'm afraid you'll need to build and publish two sets of binaries for 32 and 64 bit platforms.  I was able to do this about a year ago but I no longer remember all of the details. Basically you can use IntPtr.Size to determine which DLL to load then perform the actual LoadLibrary through p/Invoke. At that point you've got the module in memory and you ought to be able to just p/Invoke functions from inside of it -- the same module name shouldn't get reloaded again. I think though that in my application I actually had the C++ DLL register itself as a COM server and then accessed its functionality through a generated .NET wrapper -- so I don't know if I ever tested p/Invoking directly.  I finally have an answer for this that appears to work. Compile both 32 & 64 bit versions - both managed & unmanaged - into separate folders. Then have the .NET app choose at run time which directory to load the assemblies from. The problem with using the ResolveEvent is that it only gets called if assemblies aren't found so it is all to easy to accidentally end up with 32 bit versions. Instead use a second AppDomain object where we can change the ApplicationBase property to point at the right folder. So you end up with code like: static void Main(String[] argv) { // Create a new AppDomain but with the base directory set to either the 32-bit or 64-bit // sub-directories. AppDomainSetup objADS = new AppDomainSetup(); System.String assemblyDir = System.IO.Path.GetDirectoryName(Application.ExecutablePath); switch (System.IntPtr.Size) { case (4): assemblyDir += ""\\win32\\""; break; case (8): assemblyDir += ""\\x64\\""; break; } objADS.ApplicationBase = assemblyDir; // We set the PrivateBinPath to the application directory so that we can still // load the platform neutral assemblies from the app directory. objADS.PrivateBinPath = System.IO.Path.GetDirectoryName(Application.ExecutablePath); AppDomain objAD = AppDomain.CreateDomain("""" null objADS); if (argv.Length > 0) objAD.ExecuteAssembly(argv[0]); else objAD.ExecuteAssembly(""MyApplication.exe""); AppDomain.Unload(objAD); } You end up with 2 exes - your normal app and a second switching app that chooses which bits to load. Note - I can't take credit for the details of this myself. One of my colleagues sussed that out given my initial pointer. If and when he signs up to StackOverflow I'll assign the answer to him",c# .net 64bit clr x86-64
3927,A,"What Are Some Good .NET Profilers? What profilers have you used when working with .net programs and which would you particularly recommend? Don't forget nProf - a prefectly good freeware profiler. Looks kind of abandoned... only an alpha release from 2006 :-( Worked great for me. It's now a Google Code project. Had a release in July 2009. The nProf page now states: NProf is not actively developed anymore. If you are looking for an open source .NET profiler take a look at SlimTune (http://code.google.com/p/slimtune/)  I would like to add yourkit java and .net profiler I love it for Java haven't tried .NET version though.  I recently discovered EQATEC Profiler http://www.eqatec.com/tools/profiler. It works with most .NET versions and on a bunch of platforms. It is easy to use and parts of it is free even for commercial use. Fails on tail calls too :( Reported bug. Only profiles methods unfortunately. This one is only free for non-commercial use. -1 Trialware!=Freeware It was completely free back in Aug '08 when TrolleFar wrote his answer. Now as Jon says it is only free for non-commercial use. Turns out that they changed the license terms again. Parts of it is free for commercial use again. As of FEB2011 normal .NET edition for self/commercial is free. This tool is nice because it works on client/server model and can profile/by-pass repeated boundaries (e.g. Native->COM->NET->COM->NET can be profiled). The UI is rather awful though :-)  I've worked with RedGate's profiler in the past. Did the job for me.  Unfortunate most of the profilers I tried failed when used with tail calls most notably ANTS. I just end up writing my own. There is a simple implementation on CodeProject that you can use as a base.  If Licensing is an issue you could try WINDBG for memory profiling  I've been working with JetBrains dotTrace for WinForms and Console Apps (not tested on ASP.net yet) and it works quite well: They recently also added a ""Personal License"" that is significantly cheaper than the corporate one. Still if anyone else knows some cheaper or even free ones I'd like to hear as well :-)  I have found dotTrace Profiler by JetBrains to be an excellent profiling tool for .NET and their ASP.NET mode is quality.  AutomatedQA AQTime for timing and SciTech MemProfiler for memory. MemProfiler has save our team when we had a memory leak. I tried other tools but no other tool gave the same detail.  [Full Disclosure] While not yet as full-featured as some of the other .NET memory profilers listed here there is a new entry on the market called JustTrace. It's made by Telerik and it's primary goal is to make tracing/profiling easier and faster to do for all types of apps (web/Silverlight/desktop). If you've ever found profiling and optimization intimidating or slow with other tools then JustTrace might be worth a look. Thanks for trying Kyralessa. We know that process can be improved. We're working on that right now. We hope to remove those hurdles soon. For now just uncheck the boxes and in 2 min you can have an account and free JustTrace download. Sorry for the short-term trouble. -T When I go to download it and try it out Telerik wants me to ""register"" and ""create an account."" And all those newsletter subscription buttons are checkmarked by default. I'd be happy to give JustTrace a try but not if Telerik makes it this difficult. post back and let me know when I can download without creating an account and I'll give it a try. Update: Today I was able to download using the link in the answer without having to create an account.  Don't forget the awesome scitech .net memory profiler It's great for tracking down why your .net app is running out of memory. Very nice tool. Easy to use and allows you to navigate through your object graph. I espacially like the 'realtime' memory tracking. It shows you how your object counts develop during the runtime of the application.  Intel® VTune™ Performance Analyzer for quick sampling @utility73 - really great line-by-line CPU cost breakdown in vtune -- which is exactly what I was hunting for today. Thanks for suggesting this.  Haven't tried it myself but maybe dotTrace? Their ReSharper application is certainly a good one. Maybe dotTrace is too :) I've used dotTrace and can recommend it.  I doubt that the profiler which comes with Visual Studio Team System is the best profiler but I have found it to be good enough on many occasions. What specifically do you need beyond what VS offers? EDIT: Unfortunately it is only available in VS Team System but if you have access to that it is worth checking out. It's a fine profiler but it's not quite up to the standard of the new version of ANTS. You mean vs2010? In vs2008 I haven't seen a profiler. Visual studio has a profiler? I was talking about the one in VS2008 but it may not be available in all version (I'm using VSTS). From the PDC2008 videos it seems like the profiler will improve a lot in VS2010. That profiler is only available with the Team Systems versions of Visual Studio. Visual Studio Team System (Developer Edition) has a profiler. See . Thanks yeah even at work we use the regular VS. Visual Studio has a profiler since VS 2005. It is only available with Team System. That is in fact the reason I use team system (at work I have professional). It is a very good profiler in my opinion. In vs2010 pro it's also available right?  If you're looking for something quick easy and free http://code.google.com/p/slimtune/ seems to do the job fine.  The current release of SharpDevelop (3.1.1) has a nice integrated profiler. It's quite fast and integrates very well into the SharpDevelop IDE and its NUnit runner. Results are displayed in a flexible Tree/List style (use LINQ to create your own selection). Doubleclicking the displayed method jumps directly into the source code.  AQTime is reasonable but has a bit of a learning curve and isn't as easy to use as the built in one in Team Suite  In the past I’ve used the profiler that ships with Visual Studio Team System.  Others have covered performance profiling but with regards to memory profiling I'm currently evaluating both the Scitech .NET Memory Profiler 3.1 and ANTS Memory Profiler 5.1 (current versions as of September 2009). I tried the JetBrains one a year or two ago and it wasn't as good as ANTS (for memory profiling) so I haven't bothered this time. From reading the web sites it looks like it doesn't have the same memory profiling features as the other two. Both ANTS and the Scitech memory profiler have features that the other doesn't so which is best will depend upon your preferences. Generally speaking the Scitech one provides more detailed information while the ANTS one is really incredible at identifying the leaking object. Overall I prefer the ANTS one because it is so quick at identifying possible leaks. Here are the main the pros and cons of each from my experience: Common Features of ANTS and Scitech .NET Memory Profiler Real-time analysis feature Excellent how-to videos on their web sites Easy to use Reasonably performant (obviously slower than without the profiler attached but not so much you become frustrated) Show instances of leaking objects Basically they both do the job pretty well ANTS One-click filters to find common leaks including: objects kept alive only by event handlers objects that are disposed but still live and objects that are only being kept alive by a reference from a disposed object. This is probably the killer feature of ANTS - finding leaks is incredibly fast because of this. In my experience the majority of leaks are caused by event handlers not being unhooked and ANTS just takes you straight to these objects. Awesome. Object retention graph. While the same info is available in Scitech it's much easier to interpret in ANTS. Shows size with children in addition to size of the object itself (but only when an instance is selected unfortunately not in the overall class list). Better integration to Visual Studio (right-click on graph to jump to file) Scitech .NET Memory Profiler Shows stack trace when object was allocated. This is really useful for objects that are allocated in lots of different places. With ANTS it is difficult to determine exactly where the leaked object was created. Shows count of disposable objects that were not disposed. While not indicative of a leak it does identify opportunities to fix this problem and improve your application performance as a result of faster garbage collection. More detailed filtering options (several columns can be filtered independently). Presents info on total objects created (including those garbage collected). ANTS only shows 'live' object stats. This makes it easier to analyze and tune overall application performance (eg. identify where lots of objects being created unnecessarily that aren't necessarily leaking). By way of summary I think ANTS helps you find what's leaking faster while Scitech provides a bit more detail about your overall application memory performance and individual objects once you know what to look at (eg. stack trace on creation). If the stack trace and tracking of undisposed disposable objects was added to ANTS I wouldn't see the need to use anything else. +1. Great summary. +1 Would like to upvote several times! Thanks for this summary! The 4.0 version of .NET Memory Profiler (now in preview) now has a graph view. This was the one feature I liked in the ANTS profiler that Scitech one didn't have (in 3.1/3.5).  If you're on ASP.NET MVC you can try MVCMiniProfiler (http://benjii.me/2011/07/using-the-mvc-mini-profiler-with-entity-framework/)  I've been testing Telerik's JustTrace recently and although it is well away from a finished product the guys are going in the right direction.  We selected YourKit Profiler for .NET in my company as it was the best value (price vs. feature). For a small company that wants to have flexible licensing (floating licenses) it was a perfect choice - ANTS was developer seat locket at the time. Also it provided us with the ability to attach to the running process which was not possible with dotTrace. Beware though that attaching is not the best option as everything .NET will slow down but this was the only way to profile .NET applications started by other processes. Feature wise ANTS and dotTrace were better - but in the end YourKit was good enough. Starting from January 2012 YourKit have raised the pricing for the YourKit profiler. Therefore the price advantage may no longer be valid.  The latest version of ANTS memory profiler (I think it's 5) simply rocks!!! I was haunting a leak using WinDbg and SOS since it proved to be the best way before then I tried ANTS and I got it in minutes. Really a wonderful piece of software.  The NuMega True Time profiler lives on in DevPartner Studio by Micro Focus. It provides line and method level detail for .NET apps requiring only PDBs no source needed (but it helps.) It can discriminate between algorithmically heavy routines versus those with long I/O waits using our proprietary per thread kernel mode timing driver. Version 10.5 ships with new 64-process support on February 4 2011. Shameless plug: I work on the DevPartner product line. Follow up at http://www.DevPartner.com for news of the 10.5 launch. Disclaimer: I am the Product Manager for DevPartner at Micro Focus. welcome to SO. You will need to disclose any relationship to DevPartner or you will be considered a spammer and dealt with as such. I see you've answered a number of profiling questions...  ANTS Profiler. I haven't used many but I don't really have any complaints about ANTS. The visualization is really helpful.  For me SpeedTrace is the best tool on the market because it does not only help you to find bottlenecks inside your applications. It also helps you in troubleshooting scenarios to find out why your application was crashing your setup did not install your application hung up your application performance is sometimes poor depending on the data input e.g. to identify slow db transactions.  I have used JetBrains dotTrace and Redgate ANTS extensively. They are fairly similar in features and price. They both offer useful performance profiling and quite basic memory profiling. dotTrace integrates with Resharper which is really convenient as you can profile the performance of a unit test with one click from the IDE. However dotTrace often seems to give spurious results (e.g. saying that a method took several years to run) I prefer the way that ANTS presents the profiling results. It shows you the source code and to the left of each line tells you how long it took to run. dotTrace just has a tree view. EQATEC profiler is quite basic and requires you to compile special instrumented versions of your assemblies which can then be run in the EQATEC profiler. It is however free. Overall I prefer ANTS for performance profiling although if you use Resharper then the integration of dotTrace is a killer feature and means it beats ANTS in usability. The free Microsoft CLR Profiler (.Net framework 2.0 / .Net Framework 4.0) is all you need for .NET memory profiling. 2011 Update: The Scitech memory profiler has quite a basic UI but lots of useful information including some information on unmanaged memory which dotTrace and ANTS lack - you might find it useful if you are doing COM interop but I have yet to find any profiler that makes COM memory issues easy to diagnose - you usually have to break out windbg.exe. The ANTS profiler has come on in leaps and bounds in the last few years and its memory profiler has some truly useful features which now pushed it ahead of dotTrace as a package in my estimation. I'm lucky enough to have licenses for both but if you are going to buy one .Net profiler for both performance and memory make it ANTS. The profiler in Visual Studio is also really easy to use Visual Studio 2010 is in Beta and hence is free also. There have been multiple enhancements in 2010 for viewing contention and concurrency. try it... @Rick Unfortunately the profiler of Visual Studio is not present in Professional Edition... I strongly disagree about the CLR profiler being all you need for .NET memory profiling although it's possibly true if you place no value on your time. See my answer below for a summary of the best couple of memory profilers - they *will* help you find memory leaks and potential issues much faster. Current releases of the EQUATEC profiler are not free anymore. Seems like EQATEC Profiler has become free for .NET (full framework) again EQATEC Profiler is free for **all platforms** now with some DLL-limit restrictions: desktop CF Silverlight and WP7. It's still the only profiler to support all .NET 2.0+ platforms. +1 for improving your answer 2+ years after the fact. Bravo! Be careful to read the license terms. DotTrace is extremely restrictive regarding transfer of license keys among developers. The CLR Profiler linked is the old version- the new one is [here](http://www.microsoft.com/download/en/details.aspx?displaylang=en&id=13382) I've had excellent results with the latest version of the CLR Profiler. It's free it comes with source and most importantly it gave me all I needed. It might not have the polish of commercial projects but it had more than enough detail for me. I use dotTrace with dotMemory (a separate app from JetBrains) and have found them to always deliver what I need. No experience with the others so I can't speak to how good it is in comparison.  I've found plenty of problems in a big C# app using this. Usually the problem occurs during startup or shutdown as plugins are being loaded and big data structures are being created destroyed serialized or deserialized. Often they are created and initialized more than once and change handlers get added multiple times further compounding the problem. In cases like this the program can be so sluggish that only 2 samples are sufficient to pinpoint the guilty method / function / property call sites.  I would add that dotTrace's ability to diff memory and performance trace sessions is absolutely invaluable (ANTS may also have a memory diff feature but I didn't see a performance diff). Being able to run a profiling session before and after a bug fix or enhancement then compare the results is incredibly valuable especially with a mammoth legacy .NET application (as in my case) where performance was never a priority and where finding bottlenecks could be VERY tedious. Doing a before-and-after diff allows you to see the change in call count for each method and the change in duration for each method. This is helpful not only during code changes but also if you have an application that uses a different database say for each client/customer. If one customer complains of slowness you can run a profiling session using their database and compare the results with a ""fast"" database to determine which operations are contributing to the slowness. Of course there are many database-side performance tools but sometimes I really helps to see the performance metrics from the application side (since that's closer to what the user's actually seeing). Bottom line: dotTrace works great and the diff is invaluable.  I must bring an amazing tool to your notice which i have used sometime back. AVICode Interceptor Studio. In my previous company we used this wonderful tool to profile the webapplication (This is supposed to be the single largest web application in the world and the largest civilian IT project ever done). The performance team did wonders with the help of this magnificent tool. It is a pain to configure it but that is a one time activity and i would say it is worth the time. Checkout this page for details. Thanks James",c# .net profiling profiler
6406,A,"How to access .Net element on Master page from a Content page? Is it possible to access an element on a Master page from the page loaded within the ContentPlaceHolder for the master? I have a ListView that lists people's names in a navigation area on the Master page. I would like to update the ListView after a person has been added to the table that the ListView is data bound to. The ListView currently does not update it's values until the cache is reloaded. We have found that just re-running the ListView.DataBind() will update a listview's contents. We have not been able to run the ListView.DataBind() on a page that uses the Master page. Below is a sample of what I wanted to do but a compiler error says ""PeopleListView does not exist in the current context"". GIS.master - Where ListView resides ...<asp:ListView ID=""PeopleListView""... GISInput_People.aspx - Uses GIS.master as it's master page GISInput_People.aspx.cs AddNewPerson() {  // Add person to table  ....  // Update Person List  PeopleListView.DataBind();  ... } What would be the best way to resolve an issue like this in C# .Net? I believe you could do this by using this.Master.FindControl or something similar but you probably shouldn't - it requires the content page to know too much about the structure of the master page. I would suggest another method such as firing an event in the content area that the master could listen for and re-bind when fired.  Option 1 :you can create public property of your master page control  public TextBox PropMasterTextBox1 { get { return txtMasterBox1; } set { txtMasterBox1 = value; } } access it on content page like  Master.PropMasterTextBox1.Text=""SomeString""; Option 2: on Master page:  public string SetMasterTextBox1Text { get { return txtMasterBox1.Text; } set { txtMasterBox1.Text = value; } } on Content Page:  Master.SetMasterTextBox1Text=""someText""; option 3 : you can create some public method that works for you these approach is not so useful but it helps if you just want to use some limited and predefined control Thank you this works. However You need to cast it: ((myMasterPage)Master).SetMasterTextBox1Text=""someText""; it depends on your implementation... for single master page it doesn't require to do so. and your actual implementation would be far complex then such basic example (like Print ""Hello World!"") This is the method I used without Serguei's additional change. Works very well doing exactly what I needed. Probably should have been marked as the answer too. +1  Assuming the control is called ""PeopleListView"" on the master page ListView peopleListView = (ListView)this.Master.FindControl(""PeopleListView""); peopleListView.DataSource = [whatever]; peopleListView.DataBind(); But @palmsey is more correct especially if your page could have the possibility of more than one master page. Decouple them and use an event.  One think to remember is the following ASP.NET directive. <%@ MasterType attribute=""value"" [attribute=""value""...] %> MSDN Reference It will help you when referencing this.Master by creating a strongly typed reference to the master page. You can then reference your ListView without needing to CAST.  you can access with the code this.Master.FindControl(ControlID) which control you wish. It returns the reference of the control so that the changes are effective. about firing an event could not be possible each situation.  Assuming your master page was named MyMaster: (Master as MyMaster).PeopleListView.DataBind(); Edit: since PeopleListView will be declared protected by default you will either need to change this to public or create a public property wrapper so that you can access it from your page.",c# .net
7586,A,"How do I generate WPF controls through code I was trying to get my head around XAML and thought that I would try writing some code. Trying to add a grid with 6 by 6 column definitions then add a textblock into one of the grid cells. I don't seem to be able to reference the cell that I want. There is no method on the grid that I can add the textblock to. There is only grid.children.add(object) no Cell definition. XAML: <Page x:Class=""WPF_Tester.Page1"" xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation"" xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml"" Title=""Page1"" Loaded=""Page_Loaded""> </Page> C#: private void Page_Loaded(object sender RoutedEventArgs e) { //create the structure Grid g = new Grid(); g.ShowGridLines = true; g.Visibility = Visibility.Visible; //add columns for (int i = 0; i < 6; ++i) { ColumnDefinition cd = new ColumnDefinition(); cd.Name = ""Column"" + i.ToString(); g.ColumnDefinitions.Add(cd); } //add rows for (int i = 0; i < 6; ++i) { RowDefinition rd = new RowDefinition(); rd.Name = ""Row"" + i.ToString(); g.RowDefinitions.Add(rd); } TextBlock tb = new TextBlock(); tb.Text = ""Hello World""; g.Children.Add(tb); } Update Here is the spooky bit: Using VS2008 Pro on XP WPFbrowser Project Template (3.5 verified) I don;t get the methods in autocomplete. The cell location is an attached property - the value belongs to the TextBlock rather than Grid. However since the property itself belongs to Grid you need to use either the property definition field or the provided static functions. TextBlock tb = new TextBlock(); // // Locate tb in the second row third column. // Row and column indices are zero-indexed so this // equates to row 1 column 2. // Grid.SetRow(tb 1); Grid.SetColumn(tb 2);  WPF makes use of a funky thing called attached properties. So in your XAML you might write this: <TextBlock Grid.Row=""0"" Grid.Column=""0"" /> And this will effectively move the TextBlock into cell (00) of your grid. In code this looks a little strange. I believe it'd be something like: g.Children.Add(tb); Grid.SetRow(tb 0); Grid.SetColumn(tb 0); Have a look at that link above - attached properties make things really easy to do in XAML perhaps at the expense of intuitive-looking code.  Here is some sample Grid grid = new Grid(); // Set the column and row definitions grid.ColumnDefinitions.Add(new ColumnDefinition() { Width = new GridLength(1 GridUnitType.Auto) }); grid.ColumnDefinitions.Add(new ColumnDefinition() { Width = new GridLength(1 GridUnitType.Star) }); grid.RowDefinitions.Add(new RowDefinition() { Height = new GridLength(1 GridUnitType.Auto) }); grid.RowDefinitions.Add(new RowDefinition() { Height = new GridLength(1 GridUnitType.Auto) }); // Row 0 TextBlock tbFirstNameLabel = new TextBlock() { Text = ""First Name: ""}; TextBlock tbFirstName = new TextBlock() { Text = ""John""}; grid.Children.Add(tbFirstNameLabel ); // Add to the grid Grid.SetRow(tbFirstNameLabel  0); // Specify row for previous grid addition Grid.SetColumn(tbFirstNameLabel  0); // Specity column for previous grid addition grid.Children.Add(tbFirstName ); // Add to the grid Grid.SetRow(tbFirstName  0); // Specify row for previous grid addition Grid.SetColumn(tbFirstName  1); // Specity column for previous grid addition // Row 1 TextBlock tbLastNameLabel = new TextBlock() { Text = ""Last Name: ""}; TextBlock tbLastName = new TextBlock() { Text = ""Smith""}; grid.Children.Add(tbLastNameLabel ); // Add to the grid Grid.SetRow(tbLastNameLabel  1); // Specify row for previous grid addition Grid.SetColumn(tbLastNameLabel  0); // Specity column for previous grid addition grid.Children.Add(tbLastName ); // Add to the grid Grid.SetRow(tbLastName  1); // Specify row for previous grid addition Grid.SetColumn(tbLastName  1); // Specity column for previous grid addition  Use attached properties of the Grid class. in C#: Grid.SetRow( cell rownumber ) In XAML: <TextBlock Grid.Row=""1"" /> Also I would advice if you do not use dynamic grids use the XAML markup language. I know it has a learning curve but once you mastered it it is so much easier especially if you are going to use ControlTemplates and DataTemplates! ;)",c# .net wpf xaml
20465,A,".NET - Excel ListObject autosizing on databind I'm developing an Excel 2007 add-in using Visual Studio Tools for Office (2008). I have one sheet with several ListObjects on it which are being bound to datatables on startup. When they are bound they autosize correctly. The problem comes when they are re-bound. I have a custom button on the ribbon bar which goes back out to the database and retrieves different information based on some criteria that the user inputs. This new data comes back and is re-bound to the ListObjects - however this time they are not resized and I get an exception: ListObject cannot be bound because it cannot be resized to fit the data. The ListObject failed to add new rows. This can be caused because of inability to move objects below of the list object. Inner exception: ""Insert method of Range class failed"" Reason: Microsoft.Office.Tools.Excel.FailureReason.CouldNotResizeListObject I was not able to find anything very meaningful on this error on Google or MSDN. I have been trying to figure this out for a while but to no avail. Basic code structure: //at startup DataTable tbl = //get from database listObj1.SetDataBinding(tbl); DataTable tbl2 = //get from database listObj2.SetDataBinding(tbl2); //in buttonClick event handler DataTable tbl = //get different info from database //have tried with and without unbinding old source listObj1.SetDataBinding(tbl); <-- exception here DataTable tbl2 = //get different info from database listObj2.SetDataBinding(tbl2); Note that this exception occurs even when the ListObject is shrinking and not only when it grows. I've got a similar issue with refreshign multiple listobjects. We are setting each listObject.DataSource = null then rebinding starting at the bottom listobject and working our way up instead of the top down.  If anyone else is having this problem I have found the cause of this exception. ListObjects will automatically re-size on binding as long as they do not affect any other objects on the sheet. Keep in mind that ListObjects can only affect the Ranges which they wrap around. In my case the list object which was above the other one had fewer columns than the one below it. Let's say the top ListObject had 2 columns and the bottom ListObject had 3 columns. When the top ListObject changed its number of rows it had no ability to make any changes to the third column since it wasn't in it's underlying Range. This means that it couldn't shift any cells in the third column and so the second ListObject couldn't be properly moved resulting in my exception above. Changing the positions of the ListObjects to place the wider one above the smaller one works fine. Following the logic above this now means that the wider ListObject can shift all of the columns of the second ListObject and since there is nothing below the smaller one it can also shift any cells necessary. The reason I wasn't having any trouble on the initial binding is that both ListObjects were a single cell. Since this is not optimal in my case I will probably use empty columns or try to play around with invisible columns if that's possible but at least the cause is now clear.  Just an idea of something to try to see if it gives you more info: Try resizes the list object before the exception line and see if that also throws an exception. If not try and resize the range object to the new size of the DataTable. You say that this happens when the ListObject shrinks and grows. Does it also happen if the ListObject remains the same size?",c# .net excel data-binding vsto
12135,A,"FileNotFoundException for mscorlib.XmlSerializers.DLL which doesn't exist I'm using an XmlSerializer to deserialize a particular type in mscorelib.dll XmlSerializer ser = new XmlSerializer( typeof( [.Net type in System] ) ); return ([.Net type in System]) ser.Deserialize( new StringReader( xmlValue ) ); This throws a caught FileNotFoundException when the assembly is loaded: ""Could not load file or assembly 'mscorlib.XmlSerializers Version=2.0.0.0 Culture=neutral PublicKeyToken=b77a5c561934e089' or one of its dependencies. The system cannot find the file specified."" FusionLog: === Pre-bind state information === LOG: User = ### LOG: DisplayName = mscorlib.XmlSerializers Version=2.0.0.0 Culture=neutral PublicKeyToken=b77a5c561934e089 processorArchitecture=x86 (Fully-specified) LOG: Appbase = file:///C:/localdir LOG: Initial PrivatePath = NULL Calling assembly : System.Xml Version=2.0.0.0 Culture=neutral PublicKeyToken=b77a5c561934e089. === LOG: This bind starts in default load context. LOG: Using application configuration file: C:\localdir\bin\Debug\appname.vshost.exe.Config LOG: Using machine configuration file from c:\WINDOWS\Microsoft.NET\Framework\v2.0.50727\config\machine.config. LOG: Post-policy reference: mscorlib.XmlSerializers Version=2.0.0.0 Culture=neutral PublicKeyToken=b77a5c561934e089 processorArchitecture=x86 LOG: Attempting download of new URL file:///C:/localdir/bin/Debug/mscorlib.XmlSerializers.DLL. LOG: Attempting download of new URL file:///C:/localdir/bin/Debug/mscorlib.XmlSerializers/mscorlib.XmlSerializers.DLL. LOG: Attempting download of new URL file:///C:/localdir/bin/Debug/mscorlib.XmlSerializers.EXE. LOG: Attempting download of new URL file:///C:/localdir/bin/Debug/mscorlib.XmlSerializers/mscorlib.XmlSerializers.EXE. As far as I know there is no mscorlib.XmlSerializers.DLL I think the DLL name has bee auto generated by .Net looking for the serializer. You have the option of creating a myApplication.XmlSerializers.DLL when compiling to optimise serializations so I assume this is part of the framework's checking for it. The problem is that this appears to be causing a delay in loading the application - it seems to hang for a few seconds at this point. Any ideas how to avoid this or speed it up? The type I'm dealing with is `RSAParameters` which is being used as part if some system cryptography stuff. I've worked around this now by storing the encrypted key by another means and creating a new RSAParameters myself. It seems like a relatively common thing to want to serialise (i.e. encryption/decryption keys). I'm guessing now. but: The system might be generating a serializer for the whole of mscorlib which could be very slow. You could probably avoid this by wrapping the system type in your own type and serialising that instead - then you'd get a serializer for your own assembly. You might be able to build the serializer for mscorlib with sgen.exe which was the old way of building serializer dlls before it got integrated into VS. Thanks again. I think it is (1) but I can't do (2) as it's a struct. I'll try (3) > but I can't do (2) as it's a struct. I know I'm being dim here but what's the problem with it being a struct - obviously there may be some extra copying going on but relative to the costs of xml serialisation it seems unlikely that's very significant. What is the system.xx type anyway?  Okay so I ran into this problem and have found a solution for it specific to my area. This occurred because I was trying to serialize a list into an XML document (file) without an XML root attribute. Once I added the following files the error goes away. XmlRootAttribute rootAttribute = new XmlRootAttribute(); rootAttribute.ElementName = ""SomeRootName""; rootAttribute.IsNullable = true; Dunno if it'll fix your problem but it fixed mine.  The delay is because having been unable to find the custom serializer dll the system is building the equivalent code (which is very time-consuming) on the fly. The way to avoid the delay is to have the system build the DLL and make sure it's available to the .EXE - have you tried this? Thanks @Will Dean that's kinda what I figured but it seems too slow even for that. If it were my own assembly creating the serialisation assembly shouldn't be an issue but how would I do that for mscorlib?",c# .net serialization assemblies
10456,A,"HowTo Disable WebBrowser 'Click Sound' in your app only The 'click sound' in question is actually a system wide preference so I only want it to be disabled when my application has focus and then re-enable when the application closes/loses focus. Originally I wanted to ask this question here on stackoverflow but I was not yet in the beta. So after googling for the answer and finding only a little bit of information on it I came up with the following and decided to post it here now that I'm in the beta. using System; using Microsoft.Win32; namespace HowTo { class WebClickSound { /// <summary> /// Enables or disables the web browser navigating click sound. /// </summary> public static bool Enabled { get { RegistryKey key = Registry.CurrentUser.OpenSubKey(@""AppEvents\Schemes\Apps\Explorer\Navigating\.Current""); string keyValue = (string)key.GetValue(null); return String.IsNullOrEmpty(keyValue) == false && keyValue != ""\""\""""; } set { string keyValue; if (value) { keyValue = ""%SystemRoot%\\Media\\""; if (Environment.OSVersion.Version.Major == 5 && Environment.OSVersion.Version.Minor > 0) { // XP keyValue += ""Windows XP Start.wav""; } else if (Environment.OSVersion.Version.Major == 6) { // Vista keyValue += ""Windows Navigation Start.wav""; } else { // Don't know the file name so I won't be able to re-enable it return; } } else { keyValue = ""\""\""""; } // Open and set the key that points to the file RegistryKey key = Registry.CurrentUser.OpenSubKey(@""AppEvents\Schemes\Apps\Explorer\Navigating\.Current"" true); key.SetValue(null keyValue RegistryValueKind.ExpandString); isEnabled = value; } } } } Then in the main form we use the above code in these 3 events: Activated Deactivated FormClosing private void Form1_Activated(object sender EventArgs e) { // Disable the sound when the program has focus WebClickSound.Enabled = false; } private void Form1_Deactivate(object sender EventArgs e) { // Enable the sound when the program is out of focus WebClickSound.Enabled = true; } private void Form1_FormClosing(object sender FormClosingEventArgs e) { // Enable the sound on app exit WebClickSound.Enabled = true; } The one problem I see currently is if the program crashes they won't have the click sound until they re-launch my application but they wouldn't know to do that. What do you guys think? Is this a good solution? What improvements can be made? I had a problem with this line: isEnabled = value; I've just commented it but i want to know what it was intended to be You disable it by changing Internet Explorer registry value of navigating sound to ""NULL"": Registry.SetValue(""HKEY_CURRENT_USER\\AppEvents\\Schemes\\Apps\\Explorer\\Navigating\\.Current""""""""NULL""); And enable it by changing Internet Explorer registry value of navigating sound to ""C:\Windows\Media\Cityscape\Windows Navigation Start.wav"": Registry.SetValue(""HKEY_CURRENT_USER\\AppEvents\\Schemes\\Apps\\Explorer\\Navigating\\.Current""""""""C:\Windows\Media\Cityscape\Windows Navigation Start.wav""); This does not even apply to the question....  Definitely feels like a hack but having done some research on this a long time ago and not finding any other solutions probably your best bet. Better yet would be designing your application so it doesn't require many annoying page reloads.. for example if you're refreshing an iframe to check for updates on the server use XMLHttpRequest instead. (Can you tell that I was dealing with this problem back in the days before the term ""AJAX"" was coined?)  I've noticed that if you use WebBrowser.Document.Write rather than WebBrowser.DocumentText then the click sound doesn't happen. So instead of this: webBrowser1.DocumentText = ""<h1>Hello world!</h1>""; try this: webBrowser1.Document.OpenNew(true); webBrowser1.Document.Write(""<h1>Hello world!</h1>""); your suggested solution prevents the control from making that click noise but on the other side this approach causes the control to have serious focus issues. In my case the webbrowser control steals back the focus at the end of the event loop. As far as I can tell there's no workaround for that. In my case I needed to get back to the DocumentText solution - but still I'm looking for disabling that annoying sound. Any other ideas? Just found out that James on this thread: http://stackoverflow.com/questions/393166/how-to-disable-click-sound-in-webbrowser-control has a great solution - at least for IE7 and IE8. I can use the DocumentText property have no focus issues and best of all I have no click sound.  If you want to use replacing Windows Registry use this: // backup value RegistryKey key = Registry.CurrentUser.OpenSubKey(@""AppEvents\Schemes\Apps\Explorer\Navigating\.Current""); string BACKUP_keyValue = (string)key.GetValue(null); // write nothing key = Registry.CurrentUser.OpenSubKey(@""AppEvents\Schemes\Apps\Explorer\Navigating\.Current"" true); key.SetValue(null """" RegistryValueKind.ExpandString); // do navigation ... // write backup key RegistryKey key = Registry.CurrentUser.OpenSubKey(@""AppEvents\Schemes\Apps\Explorer\Navigating\.Current"" true); key.SetValue(null BACKUP_keyValue RegistryValueKind.ExpandString);   const int FEATURE_DISABLE_NAVIGATION_SOUNDS = 21; const int SET_FEATURE_ON_PROCESS = 0x00000002; [DllImport(""urlmon.dll"")] [PreserveSig] [return: MarshalAs(UnmanagedType.Error)] static extern int CoInternetSetFeatureEnabled( int FeatureEntry [MarshalAs(UnmanagedType.U4)] int dwFlags bool fEnable); static void DisableClickSounds() { CoInternetSetFeatureEnabled( FEATURE_DISABLE_NAVIGATION_SOUNDS SET_FEATURE_ON_PROCESS true); } +1 for InterOp way this actually works! Thank you I needed this. Awesome works like a charm and only disables it for just your app and doesn't rely on form focus. Nice solution works perfectly. Great solution! Thank you very much!",c# .net winforms
4227,A,"Accessing a Dictionary.Keys Key through a numeric index I'm using a Dictionary<string int> where the int is a count of the key. Now I need to access the last-inserted Key inside the Dictionary but i do not know the name of it. The obvious attempt: int LastCount = mydict[mydict.keys[mydict.keys.Count]]; does not work because Dictionary.Keys does not implement a []-indexer. I just wonder if there is any similar class? I thought about using a Stack but that only stores a string. I could now create my own struct and then use a Stack<MyStruct> but I wonder if there is another alternative essentially a Dictionary that implements an []-indexer on the Keys? What happens if you box that variable? In case you decide to use dangerous code that is subject to breakage this extension function will fetch a key from a Dictionary according to its internal indexing (which for Mono and .NET currently appears to be in the same order as you get by enumerating the Keys property). It is much preferable to use Linq: dict.Keys.ElementAt(i) but I don't know if that function is smart enough to not iterate O(N). The following is O(1) but with a reflection performance penalty. using System; using System.Collections.Generic; using System.Reflection; public static class Extensions { public static TKey KeyByIndex<TKeyTValue>(this Dictionary<TKey TValue> dict int idx) { Type type = typeof(Dictionary<TKey TValue>); FieldInfo info = type.GetField(""entries"" BindingFlags.NonPublic | BindingFlags.Instance); if (info != null) { // .NET Object element = ((Array)info.GetValue(dict)).GetValue(idx); return (TKey)element.GetType().GetField(""key"" BindingFlags.Public | BindingFlags.Instance).GetValue(element); } // Mono: info = type.GetField(""keySlots"" BindingFlags.NonPublic | BindingFlags.Instance); return (TKey)((Array)info.GetValue(dict)).GetValue(idx); } };  You could always do this: string[] temp = new string[mydict.count]; mydict.Keys.CopyTo(temp 0) int LastCount = mydict[temp[mydict.count - 1]] But I wouldn't recommend it. There's no guarantee that the last inserted key will be at the end of the array. The ordering for Keys on MSDN is unspecified and subject to change. In my very brief test it does seem to be in order of insertion but you'd be better off building in proper bookkeeping like a stack--as you suggest (though I don't see the need of a struct based on your other statements)--or single variable cache if you just need to know the latest key.  Why don't you just extend the dictionary class to add in a last key inserted property. Something like the following maybe? public class ExtendedDictionary : Dictionary<string int> { private int lastKeyInserted = -1; public int LastKeyInserted { get { return lastKeyInserted; } set { lastKeyInserted = value; } } public void AddNew(string s int i) { lastKeyInserted = i; base.Add(s i); } } Eh? No I'm not(?) You are setting lastKeyInserted to the last value inserted. Either you meant to set it to the last key inserted or you need better names for the variable and property.  I don't know if this would work because I'm pretty sure that the keys aren't stored in the order they are added but you could cast the KeysCollection to a List and then get the last key in the list... but it would be worth having a look. The only other thing I can think of is to store the keys in a lookup list and add the keys to the list before you add them to the dictionary... it's not pretty tho. I didnt test the code but the method is documented on [MSDN][1] maybe its another version the framework? [1]: http://msdn.microsoft.com/en-us/library/bb908406.aspx @Juan: there is no .Last() method on the KeyCollection 2 years late but it might help someone... see my reply to Juan's post below. Last() is an extension method.  The way you worded the question leads me to believe that the int in the Dictionary contains the item's ""position"" on the Dictionary. Judging from the assertion that the keys aren't stored in the order that they're added if this is correct that would mean that keys.Count (or .Count - 1 if you're using zero-based) should still always be the number of the last-entered key? If that's correct is there any reason you can't instead use Dictionary<int string> so that you can use mydict[ mydict.Keys.Count ]?  I think you can do something like this the syntax might be wrong havent used C# in a while To get the last item Dictionary<string int>.KeyCollection keys = mydict.keys; string lastKey = keys.Last(); or use Max instead of Last to get the max value I dont know which one fits your code better. I would add that since ""Last()"" is an extension method you would need the .NET Framework 3.5 and to add ""using System.Linq"" at the top of your .cs file. Try this for last (when using a Dist obviously :-) KeyValuePair last = oAuthPairs.Last(); if (kvp.Key != last.Key) { _oauth_ParamString = _oauth_ParamString + ""&""; }  One alternative would be a KeyedCollection if the key is embedded in the value. Just create a basic implementation in a sealed class to use. So to replace Dictionary<string int> (which isn't a very good example as there isn't a clear key for a int). private sealed class IntDictionary : KeyedCollection<string int> { protected override string GetKeyForItem(int item) { // The example works better when the value contains the key. It falls down a bit for a dictionary of ints. return item.ToString(); } } KeyedCollection<string int> intCollection = new ClassThatContainsSealedImplementation.IntDictionary(); intCollection.Add(7); int valueByIndex = intCollection[0]; Regarding your comments on the key see my follow up answer to this one.  To expand on Daniels post and his comments regarding the key since the key is embedded within the value anyway you could resort to using a KeyValuePair<TKey TValue> as the value. The main reasoning for this is that in general the Key isn't necessarily directly derivable from the value. Then it'd look like this: public sealed class CustomDictionary<TKey TValue> : KeyedCollection<TKey KeyValuePair<TKey TValue>> { protected override TKey GetKeyForItem(KeyValuePair<TKey TValue> item) { return item.Key; } } To use this as in the previous example you'd do: CustomDictionary<string int> custDict = new CustomDictionary<string int>(); custDict.Add(new KeyValuePair<string int>(""key"" 7)); int valueByIndex = custDict[0].Value; int valueByKey = custDict[""key""].Value; string keyByIndex = custDict[0].Key;  Its very simple. But you need use linq. int LastCount = mydict.Keys.ElementAt(mydict.Count -1);  A Dictionary is a Hash Table so you have no idea the order of insertion! If you want to know the last inserted key I would suggest extending the Dictionary to include a LastKeyInserted value. E.g.: public MyDictionary<K T> : IDictionary<K T> { private IDictionary<K T> _InnerDictionary; public K LastInsertedKey { get; set; } public MyDictionary() { _InnerDictionary = new Dictionary<K T>(); } #region Implementation of IDictionary public void Add(KeyValuePair<K T> item) { _InnerDictionary.Add(item); LastInsertedKey = item.Key; } public void Add(K key T value) { _InnerDictionary.Add(key value); LastInsertedKey = key; } .... rest of IDictionary methods #endregion } You will run into problems however when you use .Remove() so to overcome this you will have to keep an ordered list of the keys inserted.  You can use an OrderedDictionary. Represents a collection of key/value pairs that are accessible by the key or index. Erhm after 19 upvotes no one mentioned that OrderedDictionary still does not allow to get the key by index? You can access a value with an integer index with an **OrderedDictionary** but not with a **System.Collections.Generic.SortedDictionary** where the index need to be a TKey  I agree with the second part of Patrick's answer. Even if in some tests it seems to keep insertion order the documentation (and normal behavior for dictionaries and hashes) explicitly states the ordering is unspecified. You're just asking for trouble depending on the ordering of the keys. Add your own bookkeeping (as Patrick said just a single variable for the last added key) to be sure. Also don't be tempted by all the methods such as Last and Max on the dictionary as those are probably in relation to the key comparator (I'm not sure about that).",c# .net
29664,A,"How to catch SQLServer timeout exceptions I need to specifically catch SQL server timeout exceptions so that they can be handled differently. I know I could catch the SqlException and then check if the message string Contains ""Timeout"" but was wondering if there is a better way to do it? try { //some code } catch (SqlException ex) { if (ex.Message.Contains(""Timeout"")) { //handle timeout } else { throw; } } Are you looking for a ConnectionTimeout or a CommandTimeout ie are you expecting the connection to fail or the executed command to fail? I'm looking for a CommandTimeout which is set to a default of 30 secs i think Whats the value for the SqlException.ErrorCode property? Can you work with that? Seems like this guy is having timeouts may be worth checking the code for -2146232060. I would set this up as a static const in your data code. Looking at the docs for ErrorCode it seems to me that it's reporting Interop-Level errors. So it may be more on the level of COM errors or that a provider encountered an exception (generally) instead of a specific error relating to what you're doing. @Eric is correct - that is an HRESULT code for the SqlException type not for the source of the exception.  here: http://www.tech-archive.net/Archive/DotNet/microsoft.public.dotnet.framework.adonet/2006-10/msg00064.html You can read also that Thomas Weingartner wrote: Timeout: SqlException.Number == -2 (This is an ADO.NET error code) General Network Error: SqlException.Number == 11 ... We handle the ""General Network Error"" as a timeout exception too. It only occurs under rare circumstances e.g. when your update/insert/delete query will raise a long running trigger.  To check for a timeout I believe you check the value of ex.Number. If it is -2 then you have a timeout situation. -2 is the error code for timeout returned from DBNETLIB the MDAC driver for SQL Server. This can be seen by downloading Reflector and looking under System.Data.SqlClient.TdsEnums for TIMEOUT_EXPIRED. Your code would read: if (ex.Number == -2) { //handle timeout } Code to demonstrate failure: try { SqlConnection sql = new SqlConnection(@""Network Library=DBMSSOCN;Data Source=YourServer1433;Initial Catalog=YourDB;Integrated Security=SSPI;""); sql.Open(); SqlCommand cmd = sql.CreateCommand(); cmd.CommandText = ""DECLARE @i int WHILE EXISTS (SELECT 1 from sysobjects) BEGIN SELECT @i = 1 END""; cmd.ExecuteNonQuery(); // This line will timeout. cmd.Dispose(); sql.Close(); } catch (SqlException ex) { if (ex.Number == -2) { Console.WriteLine (""Timeout occurred""); } Yes that's pretty much what I'm doing at the moment but it's not very elegant checking for -2 Download Red Gate's Reflector and search for TIMEOUT_EXPIRED. It lives in System.Data.SqlClient.TdsEnums and its value is -2. :o) For those who do not have access to Reflector: [link](http://www.dotnetframework.org/default.aspx/4@0/4@0/untmp/DEVDIV_TFS/Dev10/Releases/RTMRel/ndp/fx/src/Data/System/Data/SqlClient/TdsEnums@cs/1305376/TdsEnums@cs)",c# .net sql-server error-handling
21078,A,"What's the best string concatenation method using C#? What's the most efficient way to concatenate strings? It's also important to point it out that you should use the + operator if you are concatenating string literals. When you concatenate string literals or string constants by using the + operator the compiler creates a single string. No run time concatenation occurs. How to: Concatenate Multiple Strings (C# Programming Guide)  There are 5 types of string concatenations: using plus (+) symbol. using string.Concat(). using string.Format(). using string.Append(). using stringBuilder. In an experiment it has been proved that string.Concat() is the best way to approach if the strings are less than 1000(approximately) and if the strings are more than 1000 then stringBuilder should be used. For more information check this site. i am new to .net while referring this question i also got this link through google search. so i just forwarded here thinking it may help others. Could be a 1000 strings or a string 1000 characters long... 1000? 1000 strings chars carrots? @MatthewCanty carrots.. carrots because I am no longer working on this field (.NET). you can edit my post or add a post which explains more clearly than mine or downvote my post or better one is to comment here so that I can improve it. :) btw I made the statement as strings in my post -- _if the strings are less than 1000_.  For just two strings you definitely do not want to use StringBuilder. There is some threshold above which the StringBuilder overhead is less than the overhead of allocating multiple strings. So for more that 2-3 strings use DannySmurf's code. Otherwise just use the + operator.  If you're operating in a loop StringBuilder is probably the way to go; it saves you the overhead of creating new strings regularly. In code that'll only run once though String.Concat is probably fine. However Rico Mariani (.NET optimization guru) made up a quiz in which he stated at the end that in most cases he recommends String.Format. I've been recommending the use of string.format over string + string for years to people I've worked with. I think the readability advantages are an additional advantage beyond the performance benefit. This is the actual correct answer. The currently accepted answer for StringBuilder is incorrect as it does not mention single line appends for which string.concat or + is faster. Little known fact is that the compiler actually translates +'s into string.concat's. Also for loops or for multiple line concats I use a custom built string builder that only appends when .ToString is called - overcoming the indeterminate buffer problem that StringBuilder has  It really depends on your usage pattern. A detailed benchmark between string.Join stringConcat and string.Format can be found here: String.Format Isn't Suitable for Intensive Logging (This is actually the same answer I gave to this question)  The most efficient is to use StringBuilder like so: StringBuilder sb = new StringBuilder(); sb.Append(""string1""); sb.Append(""string2""); ...etc... String strResult = sb.ToString(); @jonezy: String.Concat is fine if you have a couple of small things. But if you're concatenating megabytes of data your program will likely tank.  The StringBuilder.Append() method is much better than using the + operator. But I've found that when the concatenations are less than 1000 String.Join() is even more efficient than StringBuilder. StringBuilder sb = new StringBuilder(); sb.Append(someString); The only problem with String.Join is that you have to concatenate the strings with a common delimiter. string key = String.Join(""_"" new String[] { ""Customers_Contacts"" customerID database SessionID }); funny but good point :) Isn't the 'ToString' call on 'someString' unnecessary? Unless 'someString' is really an int and it's a big lying liar. ;) It would be good to note that though String.Join adds a delimiter you can make that delimiter String.Empty. `StringBuilder` has a huge comparable start-up cost it's only efficient when used with very large strings or very many concatenations. It isn't trivial to find out for any given situation. If performance is of issue profiling is your friend (check ANTS). This is not true for single line concatenation. Say you do myString = ""foo"" + var1 + ""bar"" + var2 + ""hello"" + var3 + ""world"" the compiler automatically turns that into a string.concat call which is as efficient as it gets. This answer is incorrect there are plenty of better answers to choose from @csuave - true and noted below in Lee's answer. I suppose the original question is not specific enough to choose a single answer. For trivial string concatentation use what ever is most readable. string a = b + c + d; will almost always be faster than doing it with StringBuilder but the difference is typically irrelevant. Use StringBuilder (or other option of your choice) when repeatedly adding to the same string (eg. building up a report) or when dealing with large strings. Why haven't you mentioned `string.Concat`? 1000 what? Chars?  Rico Mariani the .NET Performance guru had an article on this very subject. It's not as simple as one might suspect. The basic advice is this: If your pattern looks like: x = f1(...) + f2(...) + f3(...) + f4(...) that's one concat and it's zippy StringBuilder probably won't help. If your pattern looks like: if (...) x += f1(...) if (...) x += f2(...) if (...) x += f3(...) if (...) x += f4(...) then you probably want StringBuilder. This answer is the correct one not the answer by ""TheImirOfGroofunkistan"" as that does not take into account single-line concats. +1 I didn't know that :) Neither of my books mentions that. Thanks I'm really used to single line +'s syntax  From Chinh Do - StringBuilder is not always faster: Rules of Thumb When concatenating three dynamic string values or less use traditional string concatenation. When concatenating more than three dynamic string values use StringBuilder. When building a big string from several string literals use either the @ string literal or the inline + operator. Most of the time StringBuilder is your best bet but there are cases as shown in that post that you should at least think about each situation. afaik @ only turns off escape sequences processing. http://msdn.microsoft.com/en-us/library/362314fe.aspx agree  It would depend on the code. StringBuilder is more efficient generally but if you're only concatenating a few strings and doing it all in one line code optimizations will likely take care of it for you. It's important to think about how the code looks too: for larger sets StringBuilder will make it easier to read for small ones StringBuilder will just add needless clutter.  From this MSDN article: There is some overhead associated with creating a StringBuilder object both in time and memory. On a machine with fast memory a StringBuilder becomes worthwhile if you're doing about five operations. As a rule of thumb I would say 10 or more string operations is a justification for the overhead on any machine even a slower one. So if you trust MSDN go with StringBuilder if you have to do more than 10 strings operations/concatenations - otherwise simple string concat with '+' is fine. Simple and sound if - I repeat - you decide to trust MSDN.  System.String is immutable. When we modify the value of a string variable then a new memory is allocated to the new value and the previous memory allocation released. System.StringBuilder was designed to have concept of a mutable string where a variety of operations can be performed without allocation separate memory location for the modified string.",c# .net string optimization
10274,A,"When should I not use the ThreadPool in .Net? When should I not use the ThreadPool in .Net? It looks like the best option is to use a ThreadPool in which case why is it not the only option? What are your experiences around this? MSDN has a list some reasons here: http://msdn.microsoft.com/en-us/library/0ka9477y.aspx There are several scenarios in which it is appropriate to create and manage your own threads instead of using thread pool threads: You require a foreground thread. You require a thread to have a particular priority. You have tasks that cause the thread to block for long periods of time. The thread pool has a maximum number of threads so a large number of blocked thread pool threads might prevent tasks from starting. You need to place threads into a single-threaded apartment. All ThreadPool threads are in the multithreaded apartment. You need to have a stable identity associated with the thread or to dedicate a thread to a task.  To quarrelsome's answer I would add that it's best not to use a ThreadPool thread if you need to guarantee that your thread will begin work immediately. The maximum number of running thread-pooled threads is limited per appdomain so your piece of work may have to wait if they're all busy. It's called ""queue user work item"" after all. Two caveats of course: You can change the maximum number of thread-pooled threads in code at runtime so there's nothing to stop you checking the current vs maximum number and upping the maximum if required. Spinning up a new thread comes with its own time penalty - whether it's worthwhile for you to take the hit depends on your circumstances.  I'm not speaking as someone with only theoretical knowledge here. I write and maintain high volume applications that make heavy use of multithreading and I generally don't find the thread pool to be the correct answer. Ah argument from authority - but always be on the look out for people who might be on the Windows kernel team. Neither of us were arguing with the fact that if you have some specific requirements then the .NET ThreadPool might not be the right thing. What we're objecting to is the trivialisation of the costs to the machine of creating a thread. The significant expense of creating a thread at the raison d'etre for the ThreadPool in the first place. I don't want my machines to be filled with code written by people who have been misinformed about the expense of creating a thread and don't for example know that it causes a method to be called in every single DLL which is attached to the process (some of which will be created by 3rd parties) and which may well hot-up a load of code which need not be in RAM at all and almost certainly didn't need to be in L1. The shape of the memory hierarchy in a modern machine means that 'distracting' a CPU is about the worst thing you can possibly do and everybody who cares about their craft should work hard to avoid it.  Threadpool threads are appropriate for tasks that meet both of the following criteria: The task will not have to spend any significant time waiting for something to happen Anything that's waiting for the task to finish will likely be waiting for many tasks to finish so its scheduling priority isn't apt to affect things much. Using a threadpool thread instead of creating a new one will save a significant but bounded amount of time. If that time is significant compared with the time it will take to perform a task a threadpool task is likely appropriate. The longer the time required to perform a task however the smaller the benefit of using the threadpool and the greater the likelihood of the task impeding threadpool efficiency.  @Eric @Derek I don't exactly agree with the scenario you use as an example. If you don't know exactly what's running on your machine and exactly how many total threads handles CPU time RAM etc that your app will use under a certain amount of load you are in trouble. Are you the only target customer for the programs you write? If not you can't be certain about most of that. You generally have no idea when you write a program whether it will execute effectively solo or if it will run on a webserver being hammered by a DDOS attack. You can't know how much CPU time you are going to have. Assuming your program's behavior changes based on input it's rare to even know exactly how much memory or CPU time your program will consume. Sure you should have a pretty good idea about how your program is going to behave but most programs are never analyzed to determine exactly how much memory how many handles etc. will be used because a full analysis is expensive. If you aren't writing real-time software the payoff isn't worth the effort. In general claiming to know exactly how your program will behave is far-fetched and claiming to know everything about the machine approaches ludicrous. And to be honest if you don't know exactly what method you should use: manual threads thread pool delegates and how to implement it to do just what your application needs you are in trouble. I don't fully disagree but I don't really see how that's relevant. This site is here specifically because programmers don't always have all the answers. If your application is complex enough to require throttling the number of threads that you use aren't you almost always going to want more control than what the framework gives you? No. If I need a thread pool I will use the one that's provided unless and until I find that it is not sufficient. I will not simply assume that the provided thread pool is insufficient for my needs without confirming that to be the case. I'm not speaking as someone with only theoretical knowledge here. I write and maintain high volume applications that make heavy use of multithreading and I generally don't find the thread pool to be the correct answer. Most of my professional experience has been with multithreading and multiprocessing programs. I have often needed to roll my own solution as well. That doesn't mean that the thread pool isn't useful or appropriate in many cases. The thread pool is built to handle worker threads. In cases where multiple worker threads are appropriate the provided thread pool should should generally be the first approach.  The only reason why I wouldn't use the ThreadPool for cheap multithreading is if I need to… interract with the method running (e.g. to kill it) run code on a STA thread (this happened to me) keep the thread alive after my application has died (ThreadPool threads are background threads) in case I need to change the priority of the Thread. We can not change priority of threads in ThreadPool which is by default Normal. P.S.: The MSDN article ""The Managed Thread Pool"" contains a section titled ""When Not to Use Thread Pool Threads"" with a very similar but slightly more complete list of possible reasons for not using the thread pool. There are lots of reasons why you would need to skip the ThreadPool but if you don't know them then the ThreadPool should be good enough for you. Alternatively look at the new Parallel Extensions Framework which has some neat stuff in there that may suit your needs without having to use the ThreadPool. u said :- keep the thread alive after my application has died (ThreadPool threads are background threads) but how far i know background thread always end with main thread. so what do u say?? @Mou: I say that I have no idea what you're trying to say unfortunately.  Thread pools make sense whenever you have the concept of worker threads. Any time you can easily partition processing into smaller jobs each of which can be processed independently worker threads (and therefore a thread pool) make sense. Thread pools do not make sense when you need thread which perform entirely dissimilar and unrelated actions which cannot be considered ""jobs""; e.g. One thread for GUI event handling another for backend processing. Thread pools also don't make sense when processing forms a pipeline. Basically if you have threads which start process a job and quit a thread pool is probably the way to go. Otherwise the thread pool isn't really going to help. Can you explain the remark ""thread pools don't make sense when processing forms a pipeline""? Suppose I have work items that need to be compressed then encrypted and compression uses 10x the compute as encryption. Why not use a threadpool with a 10:1 ratio of compressor to encryptor threads? Thread pools are generally for when a program has independent discrete pieces of work to do. If there's communication between the worker threads (such as in a pipeline) then you don't really have a thread pool scenario.  When you're going to perform an operation that is going to take a long time or perhaps a continuous background thread. I guess you could always push the amount of threads available in the pool up but there would be little point in incurring the management costs of a thread that is never going to be given back to the pool.  @Eric I'm going to have to agree with Dean. Threads are expensive. You can't assume that your program is the only one running. When everyone is greedy with resources the problem multiplies. I prefer to create my threads manually and control them myself. It keeps the code very easy to understand. That's fine when it's appropriate. If you need a bunch of worker threads though all you've done is make your code more complicated. Now you have to write code to manage them. If you just used a thread pool you'd get all the thread management for free. And the thread pool provided by the language is very likely to be more robust more efficient and less buggy than whatever you roll for yourself. Thread t = new Thread(new ThreadStart(DoSomething)); t.Start(); t.Join(); I hope that you would normally have some additional code in between Start() and Join(). Otherwise the extra thread is useless and you're wasting resources for no reason. People are way too afraid of the resources used by threads. I've never seen creating and starting a thread to take more than a millisecond. There is no hard limit on the number of threads you can create. RAM usage is minimal. Once you have a few hundred threads CPU becomes an issue because of context switches so at that point you might want to get fancy with your design. A millisecond is a long time on modern hardware. That's 3 million cycles on a 3GHz machine. And again you aren't the only one creating threads. Your threads compete for the CPU along with every other program's threads. If you use not-quite-too-many threads and so does another program then together you've used too many threads. Seriously don't make life more complex than it needs to be. Don't use the thread pool unless you need something very specific that it offers. Indeed. Don't make life more complex. If your program needs multiple worker threads don't reinvent the wheel. Use the thread pool. That's why it's there. Would you roll your own string class? Some people rolls their own wrapper over an array of char's and use it like a string.. so it's possible... and it's sad too. I down voted this. This is isn't an answer; it's a reply to someone else's. Tis well enough an answer. But 22 upvotes at this moment? Its not *that* good. There isn't a huge votering being run out of Redmond is there? @Will it's a 4-year old comment. It's averaging less than half an upvote per month. Hardly an unbelievable level of votes. @hwiechers it's half answer half reply. SO didn't have comments when this was posted and I'm not willing to waste the time to go through all my old answers and convert them to comments. @DerekPark: And you shouldn't. I showed up here because of an NAA flag. Then out of a burning jealousy left the comment. Just jokes. @Will no worries. I knew you were joking about the votering (we could manage better than 22 votes in 4 years) but wasn't sure how serious you were about the ""It's not *that* good"" comment. :)",c# .net multithreading design design-decisions
1995,A,"Most Efficient Way to Test Object Type I have values stored as strings in a DataTable where each value could really represent an int double or string (they were all converted to strings during an import process from an external data source). I need to test and see what type each value really is. What is more efficient for the application (or is there no practical difference)? Try to convert to int (and then double). If conversion works the return true. If an exception is thrown return false. Regular expressions designed to match the pattern of an int or double Some other method? I would say don't worry so much about such micro performance. It is much better to just get something to work and then make it as clear and concise and easy to read as possible. The worst thing you can do is sacrifice readability for an insignificant amount of performance. In the end the best way to deal with performance issues is to save them for when you have data that indicates there is an actual performance problem... otherwise you will spend a lot of time micro-optimizing and actually cause higher maintenance costs for later on. If you find this parsing situation is really the bottleneck in your application THEN is the time to try and figure out what the fastest way to solve the problem is. I think Jeff (and many others) have blogged about this sort of thing a lot.  I'd personally use int.tryparse then double.tryparse. Performance on those methods is quite fast. They both return a Boolean. If both fail then you have a string per how you defined your data.  Would use double.TryParse it has performance benefits.  You'll get different results for the different methods depending on whether you compile with optimisations on. You basically have a few options: object o; //checking with is o is int //check type o.GetType() != typeof( int ) //cast and catch exception try{ int j = (int) o; } catch {} //use the tryparse int.TryParse( Convert.ToString( o ) out j ) You can easily set up a console app that tries each of these 10000 times and returns durations for each (test when o is an int and when it's something else). The try-catch method is the quickest if the object does hold an int and by far the slowest if it doesn't (even slower than GetType). int.TryParse is pretty quick if you have a string but if you have an unknown object it's slower. Interestingly with .Net 3.5 and optimisations turned on the o is int check takes the same time as try-catch when o actually is an int. o is int is only slightly slower if o actually is something else. Annoyingly FxCop will throw up warnings if you do something like: if( o is int ) int j = (int) o; But I think that's a bug in FxCop - it doesn't know int is a value type and recommends you to use o as int instead. If your input is always a string int.TryParse is best otherwise the is operator is quickest. As you have a string I'd look at whether you need to know that it's an int rather than a double. If int.TryParse passes then so will double.TryParse so you could half the number of checks - return either double or string and floor the doubles when you expect an int.  The trouble you have is that there could be situations where the answer could be all three types. 3 could be an int a double or a string! It depends upon what you are trying to do and how important it is that they are a particular type. It might be best just to leave them as they are as long as you can or alternatively some up with a method to mark each one (if you have control of the source of the original string). The ultimate goal was to try to determine the most exclusive data type for the object. 3 would be an int. 3.5 would be a double. ""Three"" would be a string. I eventually put together a function that tried a bunch of object.TryParse calls until it could determine what was the ""best fit"" data type.",c# .net double int
26903,A,"How can you require a constructor with no parameters for types implementing an interface? Is there a way? I need all types that implement a specific interface to have a parameterless constructor can it be done? I am developing the base code for other developers in my company to use in a specific project. There's a proccess which will create instances of types (in different threads) that perform certain tasks and I need those types to follow a specific contract (ergo the interface). The interface will be internal to the assembly If you have a suggestion for this scenario without interfaces I'll gladly take it into consideration... So you need a thing that can create instances of an unknown type that implements an interface. You've got basically three options: a factory object a Type object or a delegate. Here's the givens: public interface IInterface { void DoSomething(); } public class Foo : IInterface { public void DoSomething() { /* whatever */ } } Using Type is pretty ugly but makes sense in some scenarios: public IInterface CreateUsingType(Type thingThatCreates) { ConstructorInfo constructor = thingThatCreates.GetConstructor(Type.EmptyTypes); return (IInterface)constructor.Invoke(new object[0]); } public void Test() { IInterface thing = CreateUsingType(typeof(Foo)); } The biggest problem with it is that at compile time you have no guarantee that Foo actually has a default constructor. Also reflection is a bit slow if this happens to be performance critical code. The most common solution is to use a factory: public interface IFactory { IInterface Create(); } public class Factory<T> where T : IInterface new() { public IInterface Create() { return new T(); } } public IInterface CreateUsingFactory(IFactory factory) { return factory.Create(); } public void Test() { IInterface thing = CreateUsingFactory(new Factory<Foo>()); } In the above IFactory is what really matters. Factory is just a convenience class for classes that do provide a default constructor. This is the simplest and often best solution. The third currently-uncommon-but-likely-to-become-more-common solution is using a delegate: public IInterface CreateUsingDelegate(Func<IInterface> createCallback) { return createCallback(); } public void Test() { IInterface thing = CreateUsingDelegate(() => new Foo()); } The advantage here is that the code is short and simple can work with any method of construction and (with closures) lets you easily pass along additional data needed to construct the objects.  Not to be too blunt but you've misunderstood the purpose of interfaces. An interface means that several people can implement it in their own classes and then pass instances of those classes to other classes to be used. Creation creates an unnecessary strong coupling. It sounds like you really need some kind of registration system either to have people register instances of usable classes that implement the interface or of factories that can create said items upon request.  I would like to remind everyone that: Writing attributes in .NET is easy Writing static analysis tools in .NET that ensure conformance with company standards is easy Writing a tool to grab all concrete classes that implement a certain interface/have an attribute and verifying that it has a parameterless constructor takes about 5 mins of coding effort. You add it to your post-build step and now you have a framework for whatever other static analyses you need to perform. The language the compiler the IDE your brain - they're all tools. Use them!  You do not need a parameterless constructor for the Activator to instantiate your class. You can have a parameterized constructor and pass all the parameters from the Activator. Check out MSDN on this.  Juan Unfortunately there is no way to get around this in a strongly typed language. You won't be able to ensure at compile time that the classes will be able to be instantiated by your Activator-based code. (ed: removed an erroneous alternative solution) The reason is that unfortunately it's not possible to use interfaces abstract classes or virtual methods in combination with either constructors or static methods. The short reason is that the former contain no explicit type information and the latter require explicit type information. Constructors and static methods must have explicit (right there in the code) type information available at the time of the call. This is required because there is no instance of the class involved which can be queried by the runtime to obtain the underlying type which the runtime needs to determine which actual concrete method to call. The entire point of an interface abstract class or virtual method is to be able to make a function call without explicit type information and this is enabled by the fact that there is an instance being referenced which has ""hidden"" type information not directly available to the calling code. So these two mechanisms are quite simply mutually exclusive. They can't be used together because when you mix them you end up with no concrete type information at all anywhere which means the runtime has no idea where to find the function you're asking it to call.  You can use type parameter constraint interface ITest<T> where T: new() { //... } class Test: ITest<Test> { //... }  No you can't do that. Maybe for your situation a factory interface would be helpful? Something like: interface FooFactory { Foo createInstance(); } For every implementation of Foo you create an instance of FooFactory that knows how to create it.  Call a RegisterType method with the type and constrain it using generics. Then instead of walking assemblies to find ITest implementors just store them and create from there. void RegisterType<T>() where T:ITest new() { }  Juan Manuel said: that's one of the reasons I don't understand why it cannot be a part of the contract in the interface It's an indirect mechanism. The generic allows you to ""cheat"" and send type information along with the interface. The critical thing to remember here is that the constraint isn't on the interface that you are working with directly. It's not a constraint on the interface itself but on some other type that will ""ride along"" on the interface. This is the best explanation I can offer I'm afraid. By way of illustration of this fact I'll point out a hole that I have noticed in aku's code. It's possible to write a class that would compile fine but fail at runtime when you try to instantiate it: public class Something : ITest<String> { private Something() { } } Something derives from ITest<T> but implements no parameterless constructor. It will compile fine because String does implement a parameterless constructor. Again the constraint is on T and therefore String rather than ITest or Something. Since the constraint on T is satisfied this will compile. But it will fail at runtime. To prevent some instances of this problem you need to add another constraint to T as below: public interface ITest<T> where T : ITest<T> new() { } Note the new constraint: T : ITest<T>. This constraint specifies that what you pass into the argument parameter of ITest<T> must also derive from ITest<T>. Even so this will not prevent all cases of the hole. The code below will compile fine because A has a parameterless constructor. But since B's parameterless constructor is private instantiating B with your process will fail at runtime. public class A : ITest<A> { } public class B : ITest<A> { private B() { } }  I don't think so. You also can't use an abstract class for this.",c# .net constructor interface oop
18533,A,"C#: What Else Do You Use Besides DataSet I've found myself increasingly unsatisfied with the DataSet/DataTable/DataRow paradigm in .Net mostly because it's often a couple of steps more complicated than what I really want to do. In cases where I'm binding to controls DataSets are fine. But in other cases there seems to be a fair amount of mental overhead. I've played a bit with SqlDataReader and that seems to be good for simple jaunts through a select but I feel like there may be some other models lurking in .Net that are useful to learn more about. I feel like all of the help I find on this just uses DataSet by default. Maybe that and DataReader really are the best options. I'm not looking for a best/worst breakdown just curious what my options are and what experiences you've had with them. Thanks! -Eric Sipple I have used typed and untyped DataSets DataViewManagers DataViews DataTables DataRows DataRowViews and just about anything you can do with the stack since it firsts came out in multiple enterprise projects. It took me awhile to get used to how allow of it worked. I have written custom components that leverage the stack as ADO.NETdid not quite give me what I really needed. One such component compares DataSets and then updates backend stores. I really know how all of these items work well and those that have seen what I have done are very impressed that I managed to get beyond there feel that it was only useful for demo use. I use ADO.NET binding in Winforms and I also use the code in console apps. I most recently have teamed with another developer to create a custom ORM that we used against a crazy datamodel that we were given from contractors that looked nothing like our normal data stores. I searched today for replacement to ADO.NET and I do not see anything that I should seriously try to learn to replace what I currently use.  DataSets are great for demos. I wouldn't know what to do with one if you made me use it. I use ObservableCollection Then again i'm in the client app space WPF and Silverlight. So passing a dataset or datatable through a service is ... gross. DataReaders are fast since they are a forward only stream of the result set.  I've been using the Data Transfer Objects pattern (originally from the Java world I believe) with a SqDataReader to populate collections of DTOs from the data layer for use in other layers of the application. The DTOs themselves are very lightweight and simple classes composed of properties with gets/sets. They can be easily serialized/deserialized and used for databinding making them pretty well suited to most of my development needs.  We've moved away from datasets and built our own ORM objects loosely based on CSLA. You can get the same job done with either a DataSet or LINQ or ORM but re-using it is (we've found) a lot easier. 'Less code make more happy'.  I NEVER use datasets. They are big heavyweight objects only usable (as someone pointed out here) for ""demoware"". There are lot's of great alternatives shown here. Yes there is a significant meaning. Serialize a dataset with even just a few rows to an XML file and take a look how big it is. Then make a simple Data Transfer Object (Jesse's response). Just define a simple class with members for each column - and then a List class. Serialize that to an XML file - and take a look at the difference. ""Heavyweight objects""? Does that term really have any meaning? If you're really serializing DataSets and then passing them over the wire or something and there's a genuine performance problem that's one thing. But I've seen ""DataSet bloat"" used as justification for making hideous string-literal-laden code that uses DataReaders everywhere in far too many shops I've worked in. Certainly replacing one bad implementation with another is a lousy solution - but I've yet to see a solution using dataset's that can't be implemented better as more effectively without one. Datasets are usefull for ""DEMOware"" and a holdover from pre-.NET ADO Now see that makes me think you haven't worked with ADO.NET DataSets much and perhaps just don't know much about them at all. ADO.NET DataSets are disconnected; they're containers for data. They enforce things like database relations and nullability which is why they have so many methods and properties that people refer to as ""bloat"". I can understand why people wouldn't prefer them as a matter of style but they're a solid alternative for those who don't mind a more database-oriented (rather than object-model-oriented) style.  I just build my business objects from scratch and almost never use the DataTable and especially not the DataSet anymore except to initially populate the business objects. The advantages to building your own are testability type safety and intellisense extensibility (try adding to a DataSet) and readability (unless you enjoy reading things like Convert.ToDecimal(dt.Rows[i][""blah""].ToString())). If I were smarter I'd also use an ORM and 3rd party DI framework but just haven't yet felt the need for those. I'm doing lots of smaller size projects or additions to larger projects.  I was fed up with DataSets in .Net 1.1 at least they optimised it so that it doesn't slow as exponentially for large sets any more. It was always a rather bloated model - I haven't seen many apps that use most of its features. SqlDataReader was good but I used to wrap it in an IEnumerable<T> where the T was some typed representation of my data row. Linq is a far better replacement in my opinion.  I've used typed DataSets for several projects. They model the database well enforce constraints on the client side and in general are a solid data access technology especially with the changes in .NET 2.0 with TableAdapters. Typed DataSets get a bad rap from people who like to use emotive words like ""bloated"" to describe them. I'll grant that I like using a good O/R mapper more than using DataSets; it just ""feels"" better to use objects and collections instead of typed DataTables DataRows etc. But what I've found is that if for whatever reason you can't or don't want to use an O/R mapper typed DataSets are a good solid choice that are easy enough to use and will get you 90% of the benefits of an O/R mapper. EDIT: Some here suggest that DataReaders are the ""fast"" alternative. But if you use Reflector to look at the internals of a DataAdapter (which DataTables are filled by) you'll see that it uses...a DataReader. Typed DataSets may have a larger memory footprint than other options but I've yet to see the application where this makes a tangible difference. Use the best tool for the job. Don't make your decision on the basis of emotive words like ""gross"" or ""bloated"" which have no factual basis. I'm not sure your comment is valid - a DataSet is populated via a DataAdaptor that uses a DataReader but when is the data available? If you have to wait until the read of all rows is completed of course it has to be slower. It depends on what you're doing with the data though. Maybe you're processing a large set of data row-by-row; maybe you're operating on the full set and can't do anything till you have it all anyway. Maybe you're getting the equivalent of one row and it doesn't matter which you use. *Always* eschewing DataSets is premature optimization. And if you need to edit and persist data DataSets are much easier to work with than DataReaders and temporary objects. To avoid them is to obfuscate your code for no reason.  I use them extensively but I don't make use of any of the ""advanced"" features that Microsoft was really pushing when the framework first came out. I'm basically just using them as Lists of Hashtables which I find perfectly useful. I have not seen good results when people have tried to make complex typed DataSets or tried to actually set up the foreign key relationships between tables with DataSets. Of course I am one of the weird ones that actually prefers a DataRow to an entity object instance.  Selecting a modern stable and actively supported ORM tool has to be probably the single biggest boost to productivity just about any project of moderate size and complexity can get. If you're concluding that you absolutely absolutely absolutely have to write your own DAL and ORM you're probably doing it wrong (or you're using the world's most obscure database). If you're doing raw datasets and rows and what not spend the day to try an ORM and you'll be amazed at how much more productive you can be w/o all the drudgery of mapping columns to fields or all the time filling Sql command objects and all the other hoop jumping we all once went through. I love me some Subsonic though for smaller scale projects along with demos/prototypes I find Linq to Sql pretty damn useful too. I hate EF with a passion though. :P  Since .NET 3.5 came out I've exclusively used LINQ. It's really that good; I don't see any reason to use any of those old crutches any more. As great as LINQ is though I think any ORM system would allow you to do away with that dreck. Do you mean LINQ To SQL (aka L2S)? Obviously since we're talking about database access. Though LINQ to Everything Else is just as good.  Pre linq I used DataReader to fill List of my own custom domain objects but post linq I have been using L2S to fill L2S entities or L2S to fill domain objects. Once I get a bit more time to investigate I suspect that Entity Framework objects will be my new favourite solution!  I'm a huge fan of SubSonic. A well-written batch/CMD file can generate an entire object model for your database in minutes; you can compile it into its own DLL and use it as needed. Wonderful model wonderful tool. The site makes it sound like an ASP.NET deal but generally speaking it works wonderfully just about anywhere if you're not trying to use its UI framework (which I'm moderately disappointed in) or its application-level auto-generation tools. For the record here is a version of the command I use to work with it (so that you don't have to fight it too hard initially): sonic.exe generate /server [servername] /db [dbname] /out [outputPathForCSfiles] /generatedNamespace [myNamespace] /useSPs true /removeUnderscores true That does it every time ... Then build the DLL off that directory -- this is part of an NAnt project fired off by CruiseControl.NET -- and away we go. I'm using that in WinForms ASP.NET even some command-line utils. This generates the fewest dependencies and the greatest ""portability"" (between related projects EG). Note The above is now well over a year old. While I still hold great fondness in my heart for SubSonic I have moved on to LINQ-to-SQL when I have the luxury of working in .NET 3.5. In .NET 2.0 I still use SubSonic. So my new official advice is platform version-dependent. In case of .NET 3+ go with the accepted answer. In case of .NET 2.0 go with SubSonic.",c# .net sql dataset
14934,A,"Parameter Binding: What happens under the hood? .NET Java and other high level database API's in various language often provide techniques known as prepared statements and parameter binding as opposed to sending plain text commands to the Database server. What I would like to know is what happens when you execute a statement like this: SqlCommand cmd = new SqlCommand(""GetMemberByID""); cmd.CommandType = CommandType.StoredProcedure; SqlParameter param = new SqlParameter(""@ID"" memberID); para.DbType = DbType.Integer; cmd.Parameters.Add(param); I know this is a best practice. SQL injection attacks are minimized this way. But what exactly happens under the hood when you execute these statements? Is the end result still a SQL safe string? If not what is the end result? And is this enough to prevent SQL injection attacks? in layman terms: if a prepared statement is sent then the DB will use a plan if it is available it doesn't not have to recreate a plan every time this query is sent over but only the values of the params have changed. this is very similar to how procs work the additional benefit with procs is that you can give permission through procs only and not to the underlying tables at all  The MySQL manual page on prepared statements provides lots of information (which should apply to any other RDBMS): http://dev.mysql.com/doc/refman/5.0/en/c-api-prepared-statements.html Basically your statement is parsed and processed ahead of time and the parameters are sent separately instead of being handled along with the SQL code. This eliminates SQL-injection attacks because the SQL is parsed before the parameters are even set.  If you're using MS SQL load up the profiler and you'll see what SQL statements are generated when you use parameterised queries. Here's an example (I'm using Enterprise Libary 3.1 but the results are the same using SqlParameters directly) against SQL Server 2005: string sql = ""SELECT * FROM tblDomains WHERE DomainName = @DomName AND DomainID = @Did""; Database db = DatabaseFactory.CreateDatabase(); using(DbCommand cmd = db.GetSqlStringCommand(sql)) { db.AddInParameter(cmd ""DomName"" DbType.String ""xxxxx.net""); db.AddInParameter(cmd ""Did"" DbType.Int32 500204); DataSet ds = db.ExecuteDataSet(cmd); } This generates: exec sp[underscore]executesql N'SELECT * FROM tblDomains WHERE DomainName = @DomName AND DomainID = @Did' N'@DomName nvarchar(9) @Did int' @DomName=N'xxxxx.net' @Did=500204 You can also see here if quotation characters were passed as parameters they are escaped accordingly: db.AddInParameter(cmd ""DomName"" DbType.String ""'xxxxx.net""); exec sp[underscore]executesql N'SELECT * FROM tblDomains WHERE DomainName = @DomName AND DomainID = @Did' N'@DomName nvarchar(10) @Did int' @DomName=N'''xxxxx.net' @Did=500204",c# .net sql database api
26522,A,".NET Multi Dimensional Array Printing Let's say I have a .NET Array of n number of dimensions. I would like to foreach through the elements and print out something like: [0 0 0] = 2 [0 0 1] = 32 And so on. I could write a loop using some the Rank and dimension functions to come up with the indices. Is there a built in function instead? Thanks for the answer here is what I wrote while I waited: public static string Format(Array array) { var builder = new StringBuilder(); builder.AppendLine(""Count: "" + array.Length); var counter = 0; var dimensions = new List<int>(); for (int i = 0; i < array.Rank; i++) { dimensions.Add(array.GetUpperBound(i) + 1); } foreach (var current in array) { var index = """"; var remainder = counter; foreach (var bound in dimensions) { index = remainder % bound + "" "" + index; remainder = remainder / bound; } index = index.Substring(0 index.Length - 2); builder.AppendLine("" ["" + index + ""] "" + current); counter++; } return builder.ToString(); }  Take a look at this: might helpful for you.",c# .net arrays
22623,A,"Throwing Exceptions best practices What are the best practices to consider when catching exceptions and re-throwing them? I want to make sure that the Exception object's InnerException and stack trace are preserved. Is there a difference between the following code blocks in how they handle this? try { //some code } catch (Exception ex) { throw ex; } //...... try { //some code } catch { throw; } I would definitely use: try { //some code } catch { throw; } That will preserve your stack. -1: this code is equivalent to not having a try/catch block at all.  The way to preserve the stack trace is through the use of the throw; This is valid as well try { // something that boms here } catch (Exception ex) { throw; } throw ex; is basically like throwing an exception from that point so the stack trace would only go to where you are issuing the throw ex; statement Mike is also correct assuming the exception allows you to pass an exception (which is recommended). Karl Seguin has a great write up on exception handling in his foundations of programming e-book as well which is a great read. That exception handling writeup is wonderful. Thank you for sharing. I'm not so sure if that write-up is wonderful it suggests try { // ... } catch(Exception ex) { throw new Exception(ex.Message + ""other stuff""); } is good. The problem is that you're completely unable to handle that exception any further up the stack unless you catch all exceptions a big no-no (you sure you want to handle that OutOfMemoryException?)  You may also use: try { // Dangerous code } finally { // clean up or do nothing } And any exceptions thrown will bubble up to the next level that handles them.  When you throw ex you're essentially throwing a new exception and will miss out on the original stack trace information. throw is the preferred method.  A few people actually missed a very important point - 'throw' and 'throw ex' may do the same thing but they don't give you a crucial piece of imformation which is the line where the exception happened. Consider the following code: static void Main(string[] args) { try { TestMe(); } catch (Exception ex) { string ss = ex.ToString(); } } static void TestMe() { try { //here's some code that will generate an exception - line #17 } catch (Exception ex) { //throw new ApplicationException(ex.ToString()); throw ex; // line# 22 } } When you do either a 'throw' or 'throw ex' you get the stack trace but the line# is going to be #22 so you can't figure out which line exactly was throwing the exception (unless you have only 1 or few lines of code in the try block). To get the expected line #17 in your exception you'll have to throw a new exception with the original exception stack trace. +1 beat me to it.  You should always use ""throw;"" to rethrow the exceptions in .NET Refer this http://weblogs.asp.net/bhouse/archive/2004/11/30/272297.aspx Basically MSIL (CIL) has two instructions - ""throw"" and ""rethrow"": C#'s ""throw ex;"" gets compiled into MSIL's ""throw"" C#'s ""throw;"" - into MSIL ""rethrow""! Basically I can see the reason why ""throw ex"" overrides the stack trace.  Acctually there are some situations which the throw statment will not preserve the StackTrace information. For example in the code below: try { int i = 0; int j = 12 / i; // Line 47 int k = j + 1; } catch { // do something // ... throw; // Line 54 } The StackTrace will indicate that line 54 raised the exception although it was raised at line 47. Unhandled Exception: System.DivideByZeroException: Attempted to divide by zero. at Program.WithThrowIncomplete() in Program.cs:line 54 at Program.Main(String[] args) in Program.cs:line 106 In situations like the one described above there are two options to preseve the original StackTrace: Calling the Exception.InternalPreserveStackTrace As it is a private method it has to be invoked by using reflection: private static void PreserveStackTrace(Exception exception) { MethodInfo preserveStackTrace = typeof(Exception).GetMethod(""InternalPreserveStackTrace"" BindingFlags.Instance | BindingFlags.NonPublic); preserveStackTrace.Invoke(exception null); } I has a disadvantage of relying on a private method to preserve the StackTrace information. It can be changed in future versions of .NET Framework. The code example above and proposed solution below was extracted from Fabrice MARGUERIE weblog. Calling Exception.SetObjectData The technique below was suggested by Anton Tykhyy as answer to In C# how can I rethrow InnerException without losing stack trace question. static void PreserveStackTrace (Exception e) { var ctx = new StreamingContext (StreamingContextStates.CrossAppDomain) ; var mgr = new ObjectManager (null ctx) ; var si = new SerializationInfo (e.GetType () new FormatterConverter ()) ; e.GetObjectData (si ctx) ; mgr.RegisterObject (e 1 si) ; // prepare for SetObjectData mgr.DoFixups () ; // ObjectManager calls SetObjectData // voila e is unmodified save for _remoteStackTraceString } Although it has the advantage of relying in public methods only it also depends on the following exception constructor (which some exceptions developed by 3rd parties do not implement): protected Exception( SerializationInfo info StreamingContext context ) In my situation I had to choose the first approach because the exceptions raised by a 3rd-party library I was using didn't implement this constructor. You can catch the exception and publish this exception anywhere you want to. Then throw a new one explaining what happened to the user. This way you can see what happened at the current time the exception was caught the user can careless what the actual exception was.  FYI I just tested this and the stack trace reported by 'throw;' is not an entirely correct stack trace. Example:  private void foo() { try { bar(3); bar(2); bar(1); bar(0); } catch(DivideByZeroException) { //log message and rethrow... throw; } } private void bar(int b) { int a = 1; int c = a/b; // Generate divide by zero exception. } The stack trace points to the origin of the exception correctly (reported line number) but the line number reported for foo() is the line of the throw; statement hence you cannot tell which of the calls to bar() caused the exception. Which is why it's best not to try to catch exceptions unless you plan to do something with them  The rule of thumb is to avoid Catching and Throwing the basic Exception object. This forces you to be a little smarter about exceptions; in other words you should have an explicit catch for a SqlException so that your handling code doesn't do something wrong with a NullReferenceException. In the real world though catching and logging the base exception is also a good practice but don't forget to walk the whole thing to get any InnerExceptions it might have. I think it's best to deal with unhandled exceptions for logging purposes by using the AppDomain.CurrentDomain.UnhandledException and Application.ThreadException exceptions. Using big try { ... } catch(Exception ex) { ... } blocks everywhere means a lot of duplication. Depends whether you want to log handled exceptions in which case (at least minimal) duplication might be inevitable. Plus using those events means you *do* log all unhandled exceptions whereas if you use big ol' try { ... } catch(Exception ex) { ... } blocks you might miss some.  If you throw a new exception with the initial exception you will preserve the initial stack trace too.. try{ } catch(Exception ex){ throw new MoreDescriptiveException(""here is what was happening"" ex); }",c# .net exception-handling
13353,A,Override tab behavior in WinForms I have a UserControl that consists of three TextBoxes. On a form I can have one or more or my UserControl. I want to implement my own tab behavior so if the user presses Tab in the second TextBox I should only move to the third TextBox if the the second TextBox has anything entered. If nothing is entered in the second TextBox the next control of the form should get focus as per the normal tab behavior. If the user hasn't entered anything in the first or second TextBox and the presses tab there is this special case where a control on the form should be skipped. By using the ProcessDialogKey I have managed to get it work kind of ok but I still have one problem. My question is if there is a way to detect how a WinForms control got focus since I would also like to know if the my UserControl got focus from a Tab or Shift-Tab and then do my weird stuff but if the user clicks the control I don't want to do anything special. I agree with DannySmurf. Messing with the tab order might give you hell later on if the requirements for the application change. Another thing that you could do is to implement some kind of wizard for the user to go through.  As a general rule I would say overriding the standard behavior of the TAB key would be a bad idea. Maybe you can do something like disabling the 3rd text box until a valid entry is made in the 2nd text box. Now having said this I've also broken this rule at the request of the customer. We made the enter key function like the tab key where the enter key would save the value in a text field and advance the cursor to the next field.  I don't think there's a built-in way that you could do it. All of the WinForms focus events (GotFocusLostFocusEnterLeave) are called with empty EventArgs parameters which will not give you any additional information. Personally I would disable the third textbox as Rob Thomas said. If you're determined to do this though it wouldn't be difficult to set up a manual (read: hackish) solution. Once the tab key is pressed (if the focus is on the second textbox) set a variable inside your form. If the next object focused is then the third textbox then you know exactly how it happened.  The reason for this odd tab behavior is all about speed in the input process. It was really good to get some input I hadn't thought about disabling a textbox but that could actually work. But using the Enter key to accept the input hadn't even crossed my mind. That will work so much better. The user can enter the numbers and then press enter to accept the input and the next possible textbox will be the active one. It's like having the cake and eating it too The speed factor is there since when using the enter key no unnecessary tabing must be done to get to the correct field and using the enter key next to the numeric keyboard makes it really smooth. Thanks for the input!  Better than disabling controls try monkeying around with TabStop - if this is false the control will be simply skipped when tabbing. I'd also suggest that the Changed event of the TextBox is the place to be updating TabStop on the other controls. I've done something similar to this with a login control where users could enter either a username or an email address (in separate fields) plus their password and tabStop is what I used to get the job done.,c# .net winforms
20156,A,"Is there an easy way to create ordinals in C#? Is there an easy way in C# to create Ordinals for a number? For example: 1 returns 1st 2 returns 2nd 3 returns 3rd ...etc Can this be done through String.Format() or are there any functions available to do this? Another alternative that I used based on all the other suggestions but requires no special casing:  public static string DateSuffix(int day) { Math.DivRem(day 10 out day); switch (day) { case 1: return ""st""; case 2: return ""nd""; case 3: return ""rd""; default: return ""th""; } } Fails for `11`.  My version of Jesse's version of Stu's and samjudson's versions :) Included unit test to show that the accepted answer is incorrect when number < 1  /// <summary> /// Get the ordinal value of positive integers. /// </summary> /// <remarks> /// Only works for english-based cultures. /// Code from: http://stackoverflow.com/questions/20156/is-there-a-quick-way-to-create-ordinals-in-c/31066#31066 /// With help: http://www.wisegeek.com/what-is-an-ordinal-number.htm /// </remarks> /// <param name=""number"">The number.</param> /// <returns>Ordinal value of positive integers or <see cref=""int.ToString""/> if less than 1.</returns> public static string Ordinal(this int number) { const string TH = ""th""; string s = number.ToString(); // Negative and zero have no ordinal representation if (number < 1) { return s; } number %= 100; if ((number >= 11) && (number <= 13)) { return s + TH; } switch (number % 10) { case 1: return s + ""st""; case 2: return s + ""nd""; case 3: return s + ""rd""; default: return s + TH; } } [Test] public void Ordinal_ReturnsExpectedResults() { Assert.AreEqual(""-1"" (1-2).Ordinal()); Assert.AreEqual(""0"" 0.Ordinal()); Assert.AreEqual(""1st"" 1.Ordinal()); Assert.AreEqual(""2nd"" 2.Ordinal()); Assert.AreEqual(""3rd"" 3.Ordinal()); Assert.AreEqual(""4th"" 4.Ordinal()); Assert.AreEqual(""5th"" 5.Ordinal()); Assert.AreEqual(""6th"" 6.Ordinal()); Assert.AreEqual(""7th"" 7.Ordinal()); Assert.AreEqual(""8th"" 8.Ordinal()); Assert.AreEqual(""9th"" 9.Ordinal()); Assert.AreEqual(""10th"" 10.Ordinal()); Assert.AreEqual(""11th"" 11.Ordinal()); Assert.AreEqual(""12th"" 12.Ordinal()); Assert.AreEqual(""13th"" 13.Ordinal()); Assert.AreEqual(""14th"" 14.Ordinal()); Assert.AreEqual(""20th"" 20.Ordinal()); Assert.AreEqual(""21st"" 21.Ordinal()); Assert.AreEqual(""22nd"" 22.Ordinal()); Assert.AreEqual(""23rd"" 23.Ordinal()); Assert.AreEqual(""24th"" 24.Ordinal()); Assert.AreEqual(""100th"" 100.Ordinal()); Assert.AreEqual(""101st"" 101.Ordinal()); Assert.AreEqual(""102nd"" 102.Ordinal()); Assert.AreEqual(""103rd"" 103.Ordinal()); Assert.AreEqual(""104th"" 104.Ordinal()); Assert.AreEqual(""110th"" 110.Ordinal()); Assert.AreEqual(""111th"" 111.Ordinal()); Assert.AreEqual(""112th"" 112.Ordinal()); Assert.AreEqual(""113th"" 113.Ordinal()); Assert.AreEqual(""114th"" 114.Ordinal()); Assert.AreEqual(""120th"" 120.Ordinal()); Assert.AreEqual(""121st"" 121.Ordinal()); Assert.AreEqual(""122nd"" 122.Ordinal()); Assert.AreEqual(""123rd"" 123.Ordinal()); Assert.AreEqual(""124th"" 124.Ordinal()); }  This page gives you a complete listing of all custom numerical formatting rules: http://msdn.microsoft.com/en-us/library/0c899ak8.aspx As you can see there is nothing in there about ordinals so it can't be done using String.Format. However its not really that hard to write a function to do it. public static string AddOrdinal(int num) { if( num <= 0 ) return num.ToString(); switch(num % 100) { case 11: case 12: case 13: return num + ""th""; } switch(num % 10) { case 1: return num + ""st""; case 2: return num + ""nd""; case 3: return num + ""rd""; default: return num + ""th""; } } Update: Technically Ordinals don't exist for <= 0 so I've updated the code above. Also removed the redundant ToString() methods. Also note this is not internationalised. I've no idea what ordinals look like in other languages. Assert.AreEqual(""0"" AddOrdinal(0)); See http://www.wisegeek.com/what-is-an-ordinal-number.htm Using an extention method (or whatever it's called -- see @Stu's answer) would work great here. @Si Adding that condition would be very easy if it is required. If I made it an extension method I would call it ""ToOrdinalString"". Forgot about '11th 12th 13th'... should be an interview question. :-) Nice answer. As a note the .ToString() calls are redundant removing these improves readability (slightly)  I rather liked elements from both Stu's and samjudson's solutions and worked them together into what I think is a usable combo:  public static string Ordinal(this int number) { const string TH = ""th""; var s = number.ToString(); number %= 100; if ((number >= 11) && (number <= 13)) { return s + TH; } switch (number % 10) { case 1: return s + ""st""; case 2: return s + ""nd""; case 3: return s + ""rd""; default: return s + TH; } } what's the rationale behind using a constant for ""th""? because it's used twice in the code. Just utilizing the age-old wisdom that you shouldn't repeat yourself :) In this case the .NET runtime should only create one copy of the string while with two ""th""s in the code there'd be two strings created and referenced in memory. and also if the value of TH ever changes you'll be set. @Jesse - You get my +1 but I don't believe .NET handles strings this way see http://www.yoda.arachsys.com/csharp/strings.html#interning my reading of that is each reference to the ""th"" literal would reference the same bit of memory. But I agree about DRY :) @Si - Rereading my last response I'm reversing what I said and agree with your assessment. .NET is pretty darn smart when it comes to string handling and you have to go out of your way to make it work badly. Removing duplication like this just hinders readability I think hence the confusion ""Why the TH?"". I don't think DRY should be interpreted as 'remove all duplication whatever the cost'.  You'll have to roll your own. From the top of my head: public static string Ordinal(this int number) { var work = number.ToString(); if ((number % 100) == 11 || (number % 100) == 12 || (number % 100) == 13) return work + ""th""; switch (number % 10) { case 1: work += ""st""; break; case 2: work += ""nd""; break; case 3: work += ""rd""; break; default: work += ""th""; break; } return work; } You can then do Console.WriteLine(432.Ordinal()); Edited for 11/12/13 exceptions. I DID say from the top of my head :-) Edited for 1011 -- others have fixed this already just want to make sure others don't grab this incorrect version. This function doesn't work: Ordinal(1011) -> 1011st  Remember internationalisation! The solutions here only work for English. Things get a lot more complex if you need to support other languages. For example in Spanish ""1st"" would be written as ""1.o"" ""1.a"" ""1.os"" or ""1.as"" depending on whether the thing you're counting is masculine feminine or plural! So if your software needs to support different languages try to avoid ordinals. Excellent point and very easy to forget. How can 1st be plural? @ Andomar: ""The first 2 readers"" => in Italian (and Spanish too I suppose) ""first"" is plural here. So you have singular masculine singulare feminine plural masculine plural feminine; maybe some language has also a neutral case (distinguing things from men/animals) That said you don't have to avoid ordinals: include them in localization once you know all the case you could face or (make your customer) accept some limitations. This explains why the .NET team steered clear of adding it to the DateTime formatters I still wish they had done it.  public static string OrdinalSuffix(int ordinal) { //Because negatives won't work with modular division as expected: var abs = Math.Abs(ordinal); var lastdigit = abs % 10; return //Catch 60% of cases (to infinity) in the first conditional: lastdigit > 3 || lastdigit == 0 || (abs % 100) - lastdigit == 10 ? ""th"" : lastdigit == 1 ? ""st"" : lastdigit == 2 ? ""nd"" : ""rd""; }  While I haven't benchmarked this yet you should be able to get better performance by avoiding all the conditional case statements. This is java but a port to C# is trivial: public class NumberUtil { final static String[] ORDINAL_SUFFIXES = { ""th"" ""st"" ""nd"" ""rd"" ""th"" ""th"" ""th"" ""th"" ""th"" ""th"" }; public static String ordinalSuffix(int value) { int n = Math.abs(value); int lastTwoDigits = n % 100; int lastDigit = n % 10; int index = (lastTwoDigits >= 11 && lastTwoDigits <= 13) ? 0 : lastDigit; return ORDINAL_SUFFIXES[index]; } public static String toOrdinal(int n) { return new StringBuffer().append(n).append(ordinalSuffix(n)).toString(); } } Note the reduction of conditionals and the use of the array lookup should speed up performance if generating a lot of ordinals in a tight loop. However I also concede that this isn't as readable as the case statement solution.  Similar to Ryan's solution but even more basic I just use a plain array and use the day to look up the correct ordinal: private string[] ordinals = new string[] {""""""st""""nd""""rd""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""st""""nd""""rd""""th""""th""""th""""th""""th""""th""""th""""st"" }; DateTime D = DateTime.Now; String date = ""Today's day is: ""+ D.Day.ToString() + ordinals[D.Day]; I have not had the need but I would assume you could use a multidimensional array if you wanted to have multiple language support. From what I can remember from my Uni days this method requires minimal effort from the server.",c# .net ordinals
9,A,"How do I calculate someone's age in C#? Given a DateTime representing a person's birthday how do I calculate their age? Do we need to account in our code for cases where the person in question have travelled large distances near the speed of light? what all of the answers so far have missed is that it depends where the person was born and where they are right now. @Yaur: Just convert the time of now + birth into GMT/UTC age is only a relative value hence timezones are irrelevant. For determining the user's current timezone you can use GeoLocating. Why not consider [Julian Date][1]? [1]: http://stackoverflow.com/questions/7103064/java-calculate-the-number-of-days-between-two-dates/14278129#14278129 Pretty crazy how a post that doesn't even follow site guidelines gets 776 votes.. I want to add Hebrew calendar calculations (or other System.Globalization calendar can be used in the same way) using rewrited functions from this thread:  Public Shared Function CalculateAge(BirthDate As DateTime) As Integer Dim HebCal As New System.Globalization.HebrewCalendar () Dim now = DateTime.Now() Dim iAge = HebCal.GetYear(now) - HebCal.GetYear(BirthDate) Dim iNowMonth = HebCal.GetMonth(now) iBirthMonth = HebCal.GetMonth(BirthDate) If iNowMonth < iBirthMonth Or (iNowMonth = iBirthMonth AndAlso HebCal.GetDayOfMonth(now) < HebCal.GetDayOfMonth(BirthDate)) Then iAge -= 1 Return iAge End Function  Do we need to consider people who is smaller than 1 year? as Chinese culture we describe small babies' age as 2 months or 4 weeks. Below is my implementation it is not as simple as what I imagined especially to deal with date like 2/28.  public static string HowOld(DateTime birthday DateTime now) { if (now < birthday) throw new ArgumentOutOfRangeException(""birthday must be less than now.""); TimeSpan diff = now - birthday; int diffDays = (int)diff.TotalDays; if (diffDays > 7)//year month and week { int age = now.Year - birthday.Year; if (birthday > now.AddYears(-age)) age--; if (age > 0) { return age + (age > 1 ? "" years"" : "" year""); } else {// month and week DateTime d = birthday; int diffMonth = 1; while (d.AddMonths(diffMonth) <= now) { diffMonth++; } age = diffMonth-1; if (age == 1 && d.Day > now.Day) age--; if (age > 0) { return age + (age > 1 ? "" months"" : "" month""); } else { age = diffDays / 7; return age + (age > 1 ? "" weeks"" : "" week""); } } } else if (diffDays > 0) { int age = diffDays; return age + (age > 1 ? "" days"" : "" day""); } else { int age = diffDays; return ""just born""; } } This implementation has passed below test cases.  [TestMethod] public void TestAge() { string age = HowOld( new DateTime(2011 1 1) new DateTime(2012 11 30)); Assert.AreEqual(""1 year"" age); age = HowOld( new DateTime(2011 11 30) new DateTime(2012 11 30)); Assert.AreEqual(""1 year"" age); age = HowOld( new DateTime(2001 1 1) new DateTime(2012 11 30)); Assert.AreEqual(""11 years"" age); age = HowOld( new DateTime(2012 1 1) new DateTime(2012 11 30)); Assert.AreEqual(""10 months"" age); age = HowOld( new DateTime(2011 12 1) new DateTime(2012 11 30)); Assert.AreEqual(""11 months"" age); age = HowOld( new DateTime(2012 10 1) new DateTime(2012 11 30)); Assert.AreEqual(""1 month"" age); age = HowOld( new DateTime(2008 2 28) new DateTime(2009 2 28)); Assert.AreEqual(""1 year"" age); age = HowOld( new DateTime(2008 3 28) new DateTime(2009 2 28)); Assert.AreEqual(""11 months"" age); age = HowOld( new DateTime(2008 3 28) new DateTime(2009 3 28)); Assert.AreEqual(""1 year"" age); age = HowOld( new DateTime(2009 1 28) new DateTime(2009 2 28)); Assert.AreEqual(""1 month"" age); age = HowOld( new DateTime(2009 2 1) new DateTime(2009 3 1)); Assert.AreEqual(""1 month"" age); // NOTE. // new DateTime(2008 1 31).AddMonths(1) == new DateTime(2009 2 28); // new DateTime(2008 1 28).AddMonths(1) == new DateTime(2009 2 28); age = HowOld( new DateTime(2009 1 31) new DateTime(2009 2 28)); Assert.AreEqual(""4 weeks"" age); age = HowOld( new DateTime(2009 2 1) new DateTime(2009 2 28)); Assert.AreEqual(""3 weeks"" age); age = HowOld( new DateTime(2009 2 1) new DateTime(2009 3 1)); Assert.AreEqual(""1 month"" age); age = HowOld( new DateTime(2012 11 5) new DateTime(2012 11 30)); Assert.AreEqual(""3 weeks"" age); age = HowOld( new DateTime(2012 11 1) new DateTime(2012 11 30)); Assert.AreEqual(""4 weeks"" age); age = HowOld( new DateTime(2012 11 20) new DateTime(2012 11 30)); Assert.AreEqual(""1 week"" age); age = HowOld( new DateTime(2012 11 25) new DateTime(2012 11 30)); Assert.AreEqual(""5 days"" age); age = HowOld( new DateTime(2012 11 29) new DateTime(2012 11 30)); Assert.AreEqual(""1 day"" age); age = HowOld( new DateTime(2012 11 30) new DateTime(2012 11 30)); Assert.AreEqual(""just born"" age); age = HowOld( new DateTime(2000 2 29) new DateTime(2009 2 28)); Assert.AreEqual(""8 years"" age); age = HowOld( new DateTime(2000 2 29) new DateTime(2009 3 1)); Assert.AreEqual(""9 years"" age); Exception e = null; try { age = HowOld( new DateTime(2012 12 1) new DateTime(2012 11 30)); } catch (ArgumentOutOfRangeException ex) { e = ex; } Assert.IsTrue(e != null); } Hope it's helpful.  A one Linear Answer  DateTime dateOfBirth = Convert.ToDateTime(""01/16/1990""); var age = ((DateTime.Now - dateOfBirth).Days) / 365;  I use this: public static class DateTimeExtensions { public static int Age(this DateTime birthDate) { return Age(birthDate DateTime.Now); } public static int Age(this DateTime birthDate DateTime offsetDate) { int result=0; result = offsetDate.Year - birthDate.Year; if (offsetDate.DayOfYear < birthDate.DayOfYear) result--; return result; } }  2 Main problems to solve are: 1. Calculate Exact age - in years months days etc. 2. Calculate Generally perceived age - people usually do not care how old they exactly are they just care when their birthday in the current year is. Solution for 1 is obvious: DateTime birth = DateTime.Parse(""1.1.2000""); DateTime today = DateTime.Today; //we usually don't care about birth time TimeSpan age = today - birth; //.NET FCL should guarantee this as precise double ageInDays = age.TotalDays; //total number of days ... also precise double daysInYear = 365.2425; //statistical value for 400 years double ageInYears = ageInDays / daysInYear; //can be shifted ... not so precise Solution for 2 is the one which is not so precise in determing total age but is perceived as precise by people. People also usually use it when they calculate their age ""manually"": DateTime birth = DateTime.Parse(""1.1.2000""); DateTime today = DateTime.Today; int age = today.Year - birth.Year; //people perceive their age in years if ( today.Month < birth.Month || ((today.Month == birth.Month) && (today.Day < birth.Day)) ) { age--; //birthday in current year not yet reached we are 1 year younger ;) //+ no birthday for 29.2. guys ... sorry just wrong date for birth } Notes to 2.: This is my preferred solution We cannot use DateTime.DayOfYear or TimeSpans as they shift number of days in leap years I have put there little more lines for readability Just one more note ... I would create 2 static overloaded methods for it one for universal usage second for usage-friendliness: public static int GetAge(DateTime bithDay DateTime today) { //chosen solution method body } public static int GetAge(DateTime birthDay) { return GetAge(birthDay DateTime.Now); }  Keeping it simple (and possibly stupid:)). DateTime birth = new DateTime(1975 09 27 01 00 00 00); TimeSpan ts = DateTime.Now - birth; Console.WriteLine(""You are approximately "" + ts.TotalSeconds.ToString() + "" seconds old.""); TimeSpan was my first choice but found that it doesn't offer a TotalYears property. You could try (ts.TotalDays / 365) - but it doesn't account for leap years etc.  How come the MSDN help did not tell you that? It looks so obvious: System.DateTime birthTime = AskTheUser(myUser); // :-) System.DateTime now = System.DateTime.Now; System.TimeSpan age = now - birthTime; //as simple as that double ageInDays = age.TotalDays; // will you convert to whatever you want yourself?  How about this solution? static string CalcAge(DateTime birthDay) { DateTime currentDate = DateTime.Now; int approximateAge = currentDate.Year - birthDay.Year; int daysToNextBirthDay = (birthDay.Month * 30 + birthDay.Day) - (currentDate.Month * 30 + currentDate.Day) ; if (approximateAge == 0 || approximateAge == 1) { int month = Math.Abs(daysToNextBirthDay / 30); int days = Math.Abs(daysToNextBirthDay % 30); if (month == 0) return ""Your age is: "" + daysToNextBirthDay + "" days""; return ""Your age is: "" + month + "" months and "" + days + "" days""; ; } if (daysToNextBirthDay > 0) return ""Your age is: "" + --approximateAge + "" Years""; return ""Your age is: "" + approximateAge + "" Years""; ; }  private int GetAge(int _year int _month int _day { DateTime yourBirthDate= new DateTime(_year _month _day); DateTime todaysDateTime = DateTime.Today; int noOfYears = todaysDateTime.Year - yourBirthDate.Year; if (DateTime.Now.Month < yourBirthDate.Month || (DateTime.Now.Month == yourBirthDate.Month && DateTime.Now.Day < yourBirthDate.Day)) { noOfYears--; } return noOfYears; }  I think the TimeSpan has all that we need in it without having to resort to 365.25 (or any other approximation). Expanding on Aug's example: DateTime myBD = new DateTime(1980 10 10); TimeSpan difference = DateTime.Now.Subtract(myBD); textBox1.Text = difference.Years + "" years "" + difference.Months + "" Months "" + difference.Days + "" days""; Nope. TimeSpan as Days but no Months or Years  Here's yet another answer: public static int AgeInYears(DateTime birthday DateTime today) { return ((today.Year - birthday.Year) * 372 + (today.Month - birthday.Month) * 31 + (today.Day - birthday.Day)) / 372; } This has been extensively unit-tested. It does look a bit ""magic"". The number 372 is the number of days there would be in a year if every month had 31 days. The explanation of why it works (lifted from here) is: Let's set Yn = DateTime.Now.Year Yb = birthday.Year Mn = DateTime.Now.Month Mb = birthday.Month Dn = DateTime.Now.Day Db = birthday.Day age = Yn - Yb + (31*(Mn - Mb) + (Dn - Db)) / 372 We know that what we need is either Yn-Yb if the date has already been reached Yn-Yb-1 if it has not. a) If Mn<Mb we have -341 <= 31*(Mn-Mb) <= -31 and -30 <= Dn-Db <= 30 -371 <= 31*(Mn - Mb) + (Dn - Db) <= -1 With integer division (31*(Mn - Mb) + (Dn - Db)) / 372 = -1 b) If Mn=Mb and Dn<Db we have 31*(Mn - Mb) = 0 and -30 <= Dn-Db <= -1 With integer division again (31*(Mn - Mb) + (Dn - Db)) / 372 = -1 c) If Mn>Mb we have 31 <= 31*(Mn-Mb) <= 341 and -30 <= Dn-Db <= 30 1 <= 31*(Mn - Mb) + (Dn - Db) <= 371 With integer division (31*(Mn - Mb) + (Dn - Db)) / 372 = 0 d) If Mn=Mb and Dn>Db we have 31*(Mn - Mb) = 0 and 1 <= Dn-Db <= 30 With integer division again (31*(Mn - Mb) + (Dn - Db)) / 372 = 0 e) If Mn=Mb and Dn=Db we have 31*(Mn - Mb) + Dn-Db = 0 and therefore (31*(Mn - Mb) + (Dn - Db)) / 372 = 0  This gives ""more detail"" to this question. Maybe this is what you're looking for DateTime birth = new DateTime(1974 8 29); DateTime today = DateTime.Now; TimeSpan span = today - birth; DateTime age = DateTime.MinValue + span; // Make adjustment due to MinValue equalling 1/1/1 int years = age.Year - 1; int months = age.Month - 1; int days = age.Day - 1; // Print out not only how many years old they are but give months and days as well Console.Write(""{0} years {1} months {2} days"" years months days); This does not work all the time. Adding a Span to the DateTime.MinValue could work boes this does not account for leap years etc. If you add the Years months and days to Age using the AddYears() AddMonths and AddDays() function it will not always return the Datetime.Now date. Consider the following TWO senarios. 1st DateTime.Now is 1/1/2001 and a child is born on 1/1/2000. 2000 is a leap year and the result will be 1years 0 months and 1 days. In the second senarion DateTime.Now is 1/1/2002 and the child is born on 1/1/2001. In this case the result will be 1 years 0 months and 0 days. That will happen because you are adding the timespan on a non-leap year. If DateTime.MinValue was a leap year then the results would be 1 year at the first and 0 years 11 months and 30 days. (Try it in your code). timespan itself automatically takes into account leap years between 2 dates so I'm not sure what your getting on about. I have asked on microsoft forums and microsoft has confirmed it takes into account leap years between 2 dates.  The simple answer to this is to apply AddYears as shown below because this is the only native method to add years to the 29th of Feb. of leap years and obtain the correct result of the 28th of Feb. for common years. Some feel that 1th of Mar. is the birthday of leaplings but neither .Net nor any official rule supports this nor does common logic explain why some born in February should have 75% of their birthdays in another month. Further an Age method lends itself to be added as an extension to DateTime. By this you can obtain the age in the simplest possible way: List item int age = birthDate.Age(); public static class DateTimeExtensions { /// <summary> /// Calculates the age in years of the current System.DateTime object today. /// </summary> /// <param name=""birthDate"">The date of birth</param> /// <returns>Age in years today. 0 is returned for a future date of birth.</returns> public static int Age(this DateTime birthDate) { return Age(birthDate DateTime.Today); } /// <summary> /// Calculates the age in years of the current System.DateTime object on a later date. /// </summary> /// <param name=""birthDate"">The date of birth</param> /// <param name=""laterDate"">The date on which to calculate the age.</param> /// <returns>Age in years on a later day. 0 is returned as minimum.</returns> public static int Age(this DateTime birthDate DateTime laterDate) { int age; age = laterDate.Year - birthDate.Year; if (age > 0) { age -= Convert.ToInt32(laterDate.Date < birthDate.Date.AddYears(age)); } else { age = 0; } return age; } } } Now run this test: class Program { static void Main(string[] args) { RunTest(); } private static void RunTest() { DateTime birthDate = new DateTime(2000 2 28); DateTime laterDate = new DateTime(2011 2 27); string iso = ""yyyy-MM-dd""; for (int i = 0; i < 3; i++) { for (int j = 0; j < 3; j++) { Console.WriteLine(""Birth date: "" + birthDate.AddDays(i).ToString(iso) + "" Later date: "" + laterDate.AddDays(j).ToString(iso) + "" Age: "" + birthDate.AddDays(i).Age(laterDate.AddDays(j)).ToString()); } } Console.ReadKey(); } } The critical date example is this: Birth date: 2000-02-29 Later date: 2011-02-28 Age: 11 Output: { Birth date: 2000-02-28 Later date: 2011-02-27 Age: 10 Birth date: 2000-02-28 Later date: 2011-02-28 Age: 11 Birth date: 2000-02-28 Later date: 2011-03-01 Age: 11 Birth date: 2000-02-29 Later date: 2011-02-27 Age: 10 Birth date: 2000-02-29 Later date: 2011-02-28 Age: 11 Birth date: 2000-02-29 Later date: 2011-03-01 Age: 11 Birth date: 2000-03-01 Later date: 2011-02-27 Age: 10 Birth date: 2000-03-01 Later date: 2011-02-28 Age: 10 Birth date: 2000-03-01 Later date: 2011-03-01 Age: 11 } And for the later date 2012-02-28: { Birth date: 2000-02-28 Later date: 2012-02-28 Age: 12 Birth date: 2000-02-28 Later date: 2012-02-29 Age: 12 Birth date: 2000-02-28 Later date: 2012-03-01 Age: 12 Birth date: 2000-02-29 Later date: 2012-02-28 Age: 11 Birth date: 2000-02-29 Later date: 2012-02-29 Age: 12 Birth date: 2000-02-29 Later date: 2012-03-01 Age: 12 Birth date: 2000-03-01 Later date: 2012-02-28 Age: 11 Birth date: 2000-03-01 Later date: 2012-02-29 Age: 11 Birth date: 2000-03-01 Later date: 2012-03-01 Age: 12 } +1 this is the closest I've come to a perfect answer to this question. I was about to downvote this question because this solution handles February 29 birth dates by increasing their age by one on February 28 in non-leap years. However asking around I discovered that people born on February 29 will celebrate their birthday February 28 if needed (this is probably culture specific though). I'm curious how for instance air plane companies that sell differently priced tickets based on age handles this. Will you have to pay the full price already on February 28 or will you still get the child discount?  Another function not my me but found on the web and a bit refined: public static int GetAge(DateTime birthDate) { DateTime n = DateTime.Now; // To avoid a race condition around midnight int age = n.Year - birthDate.Year; if (n.Month < birthDate.Month || (n.Month == birthDate.Month && n.Day < birthDate.Day)) age--; return age; } Just two things that come into my mind: What about people from countries that do not use the gregorian calendar? DateTime.Now is in the server-specific culture i think. I have absolutely 0 knowledge about actually working with Asian calendars and I do not know if there is an easy way to convert dates between calendars but just in case you're wondering about those chinese guys from the year 4660 :-) @SimonHewitt Indeed somehow that typo got unseen for 4 years oO Thanks! Corrected. You are still calling DateTime.Now twice??  I have a customized Function to calculate Age + a message if selected date in not matching //This function will validate the date private bool ValidateDate(string dob) { DateTime dobdate = DateTime.Parse(dob); DateTime nowdate = DateTime.Now; TimeSpan ts = nowdate - dobdate; int Years = ts.Days / 365; if (Years < 18) { message = ""Date of Birth must not be less then 18""; return false; } else if (Years > 65) { message = ""Date of Birth must not be greater then 65""; return false; } dobvalue = dob; return true; } //Below here you call that function and pass out datetime value (MM/DD/YYYY) you can format by any way you like //Function Call if (ValidateDate(""03/10/1982"") == false) { lbldatemessaeg.Visible = true; lbldatemessaeg.Text = message; //you can replace anything a messageboxor any container to display return; }  My suggestion int age = (int) ((DateTime.Now - bday).TotalDays/365.242199); That seems to have the year changing on the right date. (I spot tested up to age 107) 365 for the days in a year. +0.25 for leap years. +0.005 for other corrections Where does 365.255 come from? I don't think this will work in general. I don't think Harry Patch would have appreciated your spot-testing methodology: http://www.latimes.com/news/obituaries/la-me-harry-patch26-2009jul2607608030.story I like this answer because it is *exactly* what I was going to add as my own answer! Google says `days in a year = 365.242199` The average length of a year in the Gregorian Calendar is 365.2425 days. Google is not always right. I would say this is one of the simplest solutions and it's *good enough*. Who cares if I am half a day before my Xth birthday and the program says I am X years old. The program is more or less right although not mathematically. I really like this solution. ^^ Because sometimes it's important. In my testing this fails on the persons birthday it reports them younger than they are.  I don't think any of the answers so far provide for cultures that calculate age differently. See for example East Asian Age Reckoning versus that in the West. Any real answer has to include localization. The Strategy Pattern would probably be in order in this example. From the wikipedia article that you provided: ""In China and Japan it is used for traditional fortune-telling or religion and it is disappearing in daily life between peoples in the city."" @some -- Koreans still use this system primarily. Actually this concept can be pretty important - people don't like being told their personal information incorrectly. As an example half of my family lives in Malaysia and half in the UK. Right now my age is considered two years higher when I'm with one side of my family than with the other. Not only us this system used primarily in Korea but as a tourist discussing ages with locals locals will politely refer to yourself an each other by their birth year. I'm not 25 I'm 87. I like this approach better. more of an 'international birthdatetime format'  With less conversions and UtcNow this code can take care of someone born on the Feb 29 on a leap year: public int GetAge(DateTime DateOfBirth) { var Now = DateTime.UtcNow; return Now.Year - DateOfBirth.Year - ( ( Now.Month > DateOfBirth.Month || (Now.Month == DateOfBirth.Month && Now.Day >= DateOfBirth.Day) ) ? 0 : 1 ); }  I've created an Age struct which looks like this: public struct Age : IEquatable<Age> IComparable<Age> { private readonly int _years; private readonly int _months; private readonly int _days; public int Years { get { return _years; } } public int Months { get { return _months; } } public int Days { get { return _days; } } public Age( int years int months int days ) : this() { _years = years; _months = months; _days = days; } public static Age CalculateAge( DateTime dateOfBirth DateTime date ) { // Here is some logic that ressembles Mike's solution although it // also takes into account months & days. // Ommitted for brevity. return new Age (years months days); } // Ommited Equality Comparable GetHashCode functionality for brevity. }  This is the version we use here. It works and it's fairly simple. It's the same idea as Jeff's but I think it's a little clearer because it separates out the logic for subtracting one so it's a little easier to understand. public static int GetAge(this DateTime dateOfBirth DateTime dateAsAt) { return dateAsAt.Year - dateOfBirth.Year - (dateOfBirth.DayOfYear < dateAsAt.DayOfYear ? 0 : 1); } You could expand the ternary operator to make it even clearer if you think that sort of thing is unclear. Obviously this is done as an extension method on DateTime but clearly you can grab that one line of code that does the work and put it anywhere. Here we have another overload of the Extension method that passes in DateTime.Now just for completeness. I think this can be off by one day when exactly one of dateOfBirth or dateAsAt falls in a leap year. Consider the age of a person born on March 1 2003 on February 29 2004. To rectify this you need to do a lexicographic comparison of (Month DayOfMonth) pairs and use that for the conditional. it's also not going to show the right age as of your birthday.  This classic question is deserving of a Noda Time solution. static int GetAge(LocalDate dateOfBirth) { Instant now = SystemClock.Instance.Now; // The target time zone is important. // It should align with the *current physical location* of the person // you are talking about. When the whereabouts of that person are unknown // then you use the time zone of the person who is *asking* for the age. // The time zone of birth is irrelevant! DateTimeZone zone = DateTimeZoneProviders.Tzdb[""America/New_York""]; LocalDate today = now.InZone(zone).Date; Period period = Period.Between(dateOfBirth today PeriodUnits.Years); return (int) period.Years; } Usage: LocalDate dateOfBirth = new LocalDate(1976 8 27); int age = GetAge(dateOfBirth); You might also be interested in the following improvements: Passing in the clock as an IClock instead of using SystemClock.Instance would improve testability. The target time zone will likely change so you'd want a DateTimeZone parameter as well. See also my blog post on this subject: Handling Birthdays and Other Anniversaries  This is a strange way to do it but if you format the date to yyyymmdd and subtract the date of birth from the current date then drop the last 4 digits you've got the age :) I don't know C# but I believe this will work in any language. 20080814 - 19800703 = 280111 Drop the last 4 digits = 28. C# Code: var now = float.Parse(DateTime.Now.ToString(""yyyy.MMdd"")); var dob = float.Parse(dateOfBirth.ToString(""yyyy.MMdd"")); var age = (int)(now - dob); Or alternatively without all the type conversion in the form of an extension method. Error checking omitted: public static Int32 GetAge(this DateTime dateOfBirth) { var today = DateTime.Today; var a = (today.Year * 100 + today.Month) * 100 + today.Day; var b = (dateOfBirth.Year * 100 + dateOfBirth.Month) * 100 + dateOfBirth.Day; return (a - b) / 10000; } there is a subtract method in the datetime class .... It's the most elegant way IMO +1  I used ScArcher2's solution for an accurate Year calculation of a persons age but I needed to take it further and calculate their Months and Days along with the Years.  public static Dictionary<stringint> CurrentAgeInYearsMonthsDays(DateTime? ndtBirthDate DateTime? ndtReferralDate) { //---------------------------------------------------------------------- // Can't determine age if we don't have a dates. //---------------------------------------------------------------------- if (ndtBirthDate == null) return null; if (ndtReferralDate == null) return null; DateTime dtBirthDate = Convert.ToDateTime(ndtBirthDate); DateTime dtReferralDate = Convert.ToDateTime(ndtReferralDate); //---------------------------------------------------------------------- // Create our Variables //---------------------------------------------------------------------- Dictionary<string int> dYMD = new Dictionary<stringint>(); int iNowDate iBirthDate iYears iMonths iDays; string sDif = """"; //---------------------------------------------------------------------- // Store off current date/time and DOB into local variables //---------------------------------------------------------------------- iNowDate = int.Parse(dtReferralDate.ToString(""yyyyMMdd"")); iBirthDate = int.Parse(dtBirthDate.ToString(""yyyyMMdd"")); //---------------------------------------------------------------------- // Calculate Years //---------------------------------------------------------------------- sDif = (iNowDate - iBirthDate).ToString(); iYears = int.Parse(sDif.Substring(0 sDif.Length - 4)); //---------------------------------------------------------------------- // Store Years in Return Value //---------------------------------------------------------------------- dYMD.Add(""Years"" iYears); //---------------------------------------------------------------------- // Calculate Months //---------------------------------------------------------------------- if (dtBirthDate.Month > dtReferralDate.Month) iMonths = 12 - dtBirthDate.Month + dtReferralDate.Month - 1; else iMonths = dtBirthDate.Month - dtReferralDate.Month; //---------------------------------------------------------------------- // Store Months in Return Value //---------------------------------------------------------------------- dYMD.Add(""Months"" iMonths); //---------------------------------------------------------------------- // Calculate Remaining Days //---------------------------------------------------------------------- if (dtBirthDate.Day > dtReferralDate.Day) //Logic: Figure out the days in month previous to the current month or the admitted month. // Subtract the birthday from the total days which will give us how many days the person has lived since their birthdate day the previous month. // then take the referral date and simply add the number of days the person has lived this month. //If referral date is january we need to go back to the following year's December to get the days in that month. if (dtReferralDate.Month == 1) iDays = DateTime.DaysInMonth(dtReferralDate.Year - 1 12) - dtBirthDate.Day + dtReferralDate.Day; else iDays = DateTime.DaysInMonth(dtReferralDate.Year dtReferralDate.Month - 1) - dtBirthDate.Day + dtReferralDate.Day; else iDays = dtReferralDate.Day - dtBirthDate.Day; //---------------------------------------------------------------------- // Store Days in Return Value //---------------------------------------------------------------------- dYMD.Add(""Days"" iDays); return dYMD; }  Here is a very simple and easy to follow example. private int CalculateAge() { //get birthdate DateTime dtBirth = Convert.ToDateTime(BirthDatePicker.Value); int byear = dtBirth.Year; int bmonth = dtBirth.Month; int bday = dtBirth.Day; DateTime dtToday = DateTime.Now; int tYear = dtToday.Year; int tmonth = dtToday.Month; int tday = dtToday.Day; int age = tYear - byear; if (bmonth < tmonth) age--; else if (bmonth == tmonth && bday>tday) { age--; } return age; }  The best way that I know of because of leap years and everything is: DateTime birthDate = new DateTime(200031); int age = (int)Math.Floor((DateTime.Now - birthDate).TotalDays / 365.25D); Hope this helps. That's not a correct answer because like you say there are leap years and therefore not each year has 365 days. By just counting the number of days and dividing by 365 you'll get slippage every 4 years or so.  Try this solution it's working. int age = (Int32.Parse(DateTime.Today.ToString(""yyyyMMdd"")) - Int32.Parse(birthday.ToString(""yyyyMMdd rawrrr""))) / 10000;  Seems most of codes are very large  So I have here a small code and that will give you the result that you are expecting int _output = new DateTime ( DateTime.Now.Subtract(person_sBirthDate).Ticks ).Year -1;  Many years ago to provide an age calculator gimmick on my website I wrote a function to calculate age to a fraction. This is a quick port of that function to C# (from the PHP version). I'm afraid I haven't been able to test the C# version but hope you enjoy all the same! (Admittedly this is a bit gimmicky for the purposes of showing user profiles on Stack Overflow but maybe readers will find some use for it. :-)) double AgeDiff(DateTime date1 DateTime date2) {  double years = date2.Year - date1.Year;  /*  * If date2 and date1 + round(date2 - date1) are on different sides  * of 29 February then our partial year is considered to have 366  * days total otherwise it's 365. Note that 59 is the day number  * of 29 Feb.  */  double fraction = 365  + (DateTime.IsLeapYear(date2.Year) && date2.DayOfYear >= 59  && (date1.DayOfYear < 59 || date1.DayOfYear > date2.DayOfYear)  ? 1 : 0);  /*  * The only really nontrivial case is if date1 is in a leap year  * and date2 is not. So let's handle the others first.  */  if (DateTime.IsLeapYear(date2.Year) == DateTime.IsLeapYear(date1.Year))  return years + (date2.DayOfYear - date1.DayOfYear) / fraction;  /*  * If date2 is in a leap year but date1 is not and is March or  * beyond shift up by a day.  */  if (DateTime.IsLeapYear(date2.Year)) {  return years + (date2.DayOfYear - date1.DayOfYear  - (date1.DayOfYear >= 59 ? 1 : 0)) / fraction;  }  /*  * If date1 is not on 29 February shift down date1 by a day if  * March or later. Proceed normally.  */  if (date1.DayOfYear != 59) {  return years + (date2.DayOfYear - date1.DayOfYear  + (date1.DayOfYear > 59 ? 1 : 0)) / fraction;  }  /*  * Okay here date1 is on 29 February and date2 is not on a leap  * year. What to do now? On 28 Feb in date2's year the ``age''  * should be just shy of a whole number and on 1 Mar should be  * just over. Perhaps the easiest way is to a point halfway  * between those two: 58.5.  */  return years + (date2.DayOfYear - 58.5) / fraction; }  Would this work? public override bool IsValid(DateTime value) { _dateOfBirth = value; var yearsOld = (double) (DateTime.Now.Subtract(_dateOfBirth).TotalDays/365); if (yearsOld > 18) return true; return false; } Negative rater please explain the reason!!! Wow. Why is value an object rather than a DateTime? The method signature should be `public override bool Is18OrOlder(DateTime birthday)` What about people who were born on February 29? Who said that we were trying to check whether or not the user was at least 18 years old? The question was ""how do I calculate someone's age?"" How did that happen? I don't even remember putting IsValid as object. It should be DateTime!  I've made one small change to Mark Soen's answer: I've rewriten the third line so that the expression can be parsed a bit more easily.  public int AgeInYears(DateTime bday) { DateTime now = DateTime.Today; int age = now.Year - bday.Year; if (bday.AddYears(age) > now) age--; return age; } I've also made it into a function for the sake of clarity.  int age = DateTime.Now.Year - birthday.Year; if (DateTime.Now.Month < birthday.Month || DateTime.Now.Month == birthday.Month && DateTime.Now.Day < birthday.Day) age--; @AndrewBarber: I changed my answer I hope its fine now No it's not at all as simple as that. Not in the least. You also don't seem to have understood the question very well. Actually it's not right. Your conditional is clumsy and does not actually work right. It should be: `if (DateTime.Now.Month <= birthday.Month && DateTime.Now.Day < birthday.Day)` I removed your middle condition; combined the `<` and `==`. The way you had it it would not check the date; the `||` being true would cause the `&&` not even to be evaluated.  This is simple and appears to be accurate for my needs. I am making an assumption for the purposes of leap years that regardless of when the person chooses to celebrate the birthday they are not technically a year older until a full 365 days has passed since there last birthday (i.e 28th February does not make them a year older) DateTime now = DateTime.Today; DateTime birthday = new DateTime(1991 02 03);//3rd feb int age = now.Year - birthday.Year; if (now.Month < birthday.Month || (now.Month == birthday.Month && now.Day < birthday.Day))//not had bday this year yet age--; return age; Let us know if you spot any problems ;)  To calculate the age with nearest age: var ts = DateTime.Now - new DateTime(1988 3 19); var age = Math.Round(ts.Days / 365.0); not necessarily true. I guess the correct would be to divide by 365.25 to account for leap years somehow  TimeSpan diff = DateTime.Now - birthdayDateTime; string age = String.Format(""{0:%y} years {0:%M} months {0:%d} days old"" diff); I'm not sure how exactly you'd like it returned to you so I just made a readable string.  Here is a solution.  DateTime dateOfBirth = new DateTime(2000 4 18); DateTime currentDate = DateTime.Now; int ageInYears = 0; int ageInMonths = 0; int ageInDays = 0; ageInDays = currentDate.Day - dateOfBirth.Day; ageInMonths = currentDate.Month - dateOfBirth.Month; ageInYears = currentDate.Year - dateOfBirth.Year; if (ageInDays < 0) { ageInDays += DateTime.DaysInMonth(currentDate.Year currentDate.Month); ageInMonths = ageInMonths--; if (ageInMonths < 0) { ageInMonths += 12; ageInYears--; } } if (ageInMonths < 0) { ageInMonths += 12; ageInYears--; } Console.WriteLine(""{0} {1} {2}"" ageInYears ageInMonths ageInDays);  I am late to the party but here's a one-liner: int age = new DateTime(DateTime.Now.Subtract(birthday).Ticks).Year-1; Gotta love one-liners This is broken. Made testable: public static int CalculateAge(DateTime dateOfBirth DateTime dateToCalculateAge) { return new DateTime(dateToCalculateAge.Subtract(dateOfBirth).Ticks).Year - 1; } ...Gives age 14 when I input 1990-06-01 and calculate the age on the day BEFORE his 14th birthday (1990-05-31). As Kjensen says it's broken folks - take away your upvotes... -1 for incorrect answer. Yes it's wrong because you need to compare the month and day!  var now = DateTime.Now; var age = (int)Math.Floor(now.Substract(birdth).TotalYears); `TotalYears` property does not exist.  Here's a little code sample for C# I knocked up be careful around the edge cases specifically leap years not all the above solutions take them into account. Pushing the answer out as a DateTime can cause problems as you could end up trying to put too many days into a specific month e.g. 30 days in Feb. public string LoopAge(DateTime myDOB DateTime FutureDate) { int years = 0; int months = 0; int days = 0; DateTime tmpMyDOB = new DateTime(myDOB.Year myDOB.Month 1); DateTime tmpFutureDate = new DateTime(FutureDate.Year FutureDate.Month 1); while (tmpMyDOB.AddYears(years).AddMonths(months) < tmpFutureDate) { months++; if (months > 12) { years++; months = months - 12; } } if (FutureDate.Day >= myDOB.Day) { days = days + FutureDate.Day - myDOB.Day; } else { months--; if (months < 0) { years--; months = months + 12; } days = days + (DateTime.DaysInMonth(FutureDate.AddMonths(-1).Year FutureDate.AddMonths(-1).Month) + FutureDate.Day) - myDOB.Day; } //add an extra day if the dob is a leap day if (DateTime.IsLeapYear(myDOB.Year) && myDOB.Month == 2 && myDOB.Day == 29) { //but only if the future date is less than 1st March if(FutureDate >= new DateTime(FutureDate.Year 31)) days++; } return ""Years: "" + years + "" Months: "" + months + "" Days: "" + days; } I like this solution the best however when calculating the months it needs to be if(months >= 12). Try 6-8-2012 - 6-4-1993 to test.  This is not a direct answer but more of a philosophical reasoning about the problem at hand from a quasi-scientific point of view. I would argue that the question does not specify the unit nor culture in which to measure age most answers seem to assume an integer annual representation. The SI-unit for time is second ergo the correct generic answer should be (of course assuming normalized DateTime and taking no regard whatsoever to relativistic effects): var lifeInSeconds = (DateTime.Now.Ticks - then.Ticks)/TickFactor; In the Christian way of calculating age in years: var then = ... // Then in this case the birthday var now = DateTime.UtcNow; int age = now.Year - then.Year; if (now.AddYears(-age) < then) age--; In finance there is a similar problem when calculating something often referred to as the Day Count Fraction which roughly is the amount of years for a given period. And the age issue is really a time measuring issue. Example for the actual/actual (counting all days ""correctly"") convention: DateTime start end = .... // Whatever assume start is before end double startYearContribution = 1 - (double) start.DayOfYear / (double) (DateTime.IsLeapYear(start.Year) ? 366 : 365); double endYearContribution = (double)end.DayOfYear / (double)(DateTime.IsLeapYear(end.Year) ? 366 : 365); double middleContribution = (double) (end.Year - start.Year - 1); double DCF = startYearContribution + endYearContribution + middleContribution; Another quite common way to measure time generally is by ""serializing"" (the dude who named this date convention must seriously have been trippin'): DateTime start end = .... // Whatever assume start is before end int days = (end - start).Days; I wonder how long we have to go before a relativistic age in seconds becomes more useful than the rough approximation of earth-around-sun-cycles during ones lifetime so far :) Or in other words when a period must be given a location or a function representing motion for itself to be valid :)  For some reason Jeff's code didn't seem simple enough. To me this seems simpler and easier to understand: DateTime today = DateTime.Today; int age = today.Year - bday.Year; if (bday > today.AddYears(-age)) age--; Just wanted to comment on DateTime.Now performance. If you don't need an accurate time zone value use DateTime.UtcNow it's much faster. Given we're talking birthdays you can just use DateTime.Today given the time part has no relevance. This answer does not work with all locales and all ages. Several countries have skipped dates after the birth of current living people including Russia (1918) Greece (1924) and Turkey (1926). So we have a different age according to different countries and calendar ? What a scoop... @JAG: DateTime.Today should be even faster. Good catch Danvil! Changed last line to: if (bday > now.AddYears(-age)) age--; I think that fixes it. It passed my measly 3 tests :-) This is wrong! Try it with a person born 2000/02/29. If now is 2009/02/28 your code will state that the person is 9 years old. Actually it's still not entirely correct. This code presumes that 'bday' is the date-portion of a DateTime. It's an edge-case (I guess most people will just be passing dates and not date-times) but if you pass in a birthday as a date-and-time where the time is greater than 00:00:00 then you'll run into the bug Danvil pointed out. Setting bday = bday.Date fixes this. The last line made me think too much. Instead how about: if (bday.AddYears(age) > now) age--; This seems to be a more intuitive expression. Good idea cdiggins but it doesn't work as bday.AddYears(age) when age is 2/29 returns 2/28 on years that are not leap years...keep trying Or just do if (BirthDate.DayOfYear > Today.DayOfYear); no need to forther modify the date variables @NKCSS: That does not handle the leap year correctly. My testing shows that only `if (bday > now.AddYears(-age))` works. Since `DayOfYear` returns `61` in 2012 and `60` in 2011 for March 1. @Guvante Thanks...I lost my test last year when I lost my hard drive...I should have tested more @Danvil is it really wrong? Take a simpler example. Birthday = 2000/02/29 Today = 2001/02/28. Days elapsed: 365. Isn't that one year and therefore isn't the person one year old on the 28th? Or is the definition of a year 365-1/4 days? I'm just sayin' it's complicated. Wouldn't it be easier to just do `DateTime dateDifference = subject.Birthday - DateTime.Now; int age = dateDifference.Year;`? Also I don't think age depends on leap years. After all a year is defined as 365 DateTime.Today.AddYears(-age)) ? age-- : age;`  I have created a SQL Server User Defined Function to calculate someone's age given their birthdate. This is useful when you need it as part of a query: using System; using System.Data; using System.Data.Sql; using System.Data.SqlClient; using System.Data.SqlTypes; using Microsoft.SqlServer.Server; public partial class UserDefinedFunctions { [SqlFunction(DataAccess = DataAccessKind.Read)] public static SqlInt32 CalculateAge(string strBirthDate) { DateTime dtBirthDate = new DateTime(); dtBirthDate = Convert.ToDateTime(strBirthDate); DateTime dtToday = DateTime.Now; // get the difference in years int years = dtToday.Year - dtBirthDate.Year; // subtract another year if we're before the // birth day in the current year if (dtToday.Month < dtBirthDate.Month || (dtToday.Month == dtBirthDate.Month && dtToday.Day < dtBirthDate.Day)) years=years-1; int intCustomerAge = years; return intCustomerAge; } }; This method work perfectly.  The following approach (extract from Time Period Library for .NET class DateDiff) considers the calendar of the culture info: // ---------------------------------------------------------------------- private static int YearDiff( DateTime date1 DateTime date2 ) { return YearDiff( date1 date2 DateTimeFormatInfo.CurrentInfo.Calendar ); } // YearDiff // ---------------------------------------------------------------------- private static int YearDiff( DateTime date1 DateTime date2 Calendar calendar ) { if ( date1.Equals( date2 ) ) { return 0; } int year1 = calendar.GetYear( date1 ); int month1 = calendar.GetMonth( date1 ); int year2 = calendar.GetYear( date2 ); int month2 = calendar.GetMonth( date2 ); // find the the day to compare int compareDay = date2.Day; int compareDaysPerMonth = calendar.GetDaysInMonth( year1 month1 ); if ( compareDay > compareDaysPerMonth ) { compareDay = compareDaysPerMonth; } // build the compare date DateTime compareDate = new DateTime( year1 month2 compareDay date2.Hour date2.Minute date2.Second date2.Millisecond ); if ( date2 > date1 ) { if ( compareDate < date1 ) { compareDate = compareDate.AddYears( 1 ); } } else { if ( compareDate > date1 ) { compareDate = compareDate.AddYears( -1 ); } } return year2 - calendar.GetYear( compareDate ); } // YearDiff Usage: // ---------------------------------------------------------------------- public void CalculateAgeSamples() { PrintAge( new DateTime( 2000 02 29 ) new DateTime( 2009 02 28 ) ); // > Birthdate=29.02.2000 Age at 28.02.2009 is 8 years PrintAge( new DateTime( 2000 02 29 ) new DateTime( 2012 02 28 ) ); // > Birthdate=29.02.2000 Age at 28.02.2012 is 11 years } // CalculateAgeSamples // ---------------------------------------------------------------------- public void PrintAge( DateTime birthDate DateTime moment ) { Console.WriteLine( ""Birthdate={0:d} Age at {1:d} is {2} years"" birthDate moment YearDiff( birthDate moment ) ); } // PrintAge Interesting article. Thanks for the post.  Here's a DateTime extender that adds the age calculation to the DateTime object.  public static class AgeExtender { public static int GetAge(this DateTime dt) { int d = int.Parse(dt.ToString(""yyyyMMdd"")); int t = int.Parse(DateTime.Today.ToString(""yyyyMMdd"")); return (t-d)/10000; } } ugh don't do this. ToString and int.Parse are both relatively expensive and while i'm anti micro-optimization hiding expensive functions in extension methods that should be trivial operations is not a good idea. Also this is a duplicate of ScArcher2's answer: http://stackoverflow.com/questions/9/how-do-i-calculate-someones-age-in-c/11942#11942 Yaur I really like Elmer's solution that relies on DayOfYear probably more efficient than mine. Note that my goal wasn't to change ScArcher2's algorithm I felt that would be rude. It was simply to show how to implement an extension method.  The simplest way I've ever found is this. It works correctly for the US and western europe locales. Can't speak to other locales especially places like China. 4 extra compares at most following the initial computation of age. public int AgeInYears( DateTime birthDate  DateTime referenceDate ) { Debug.Assert( referenceDate >= birthDate  ""birth date must be on or prior to the reference date"" ) ; DateTime birth = birthDate.Date ; DateTime reference = referenceDate.Date ; int years = ( reference.Year - birth.Year ) ; // // an offset of -1 is applied if the birth date has // not yet occurred in the current year. // if ( reference.Month > birth.Month ) ; else if ( reference.Month < birth.Month ) --years ; else // in birth month { if ( reference.Day < birth.Day ) --years ; } return years ; } I was looking over the answers to this and noticed that nobody has made reference to regulatory/legal implications of leap day births. For instance per Wikipedia if you're born on February 29th in various jurisdictions you're non-leap year birthday varies: In the United Kingdom and Hong Kong: it's the ordinal day of the year so the next day March 1st is your birthday. In New Zealand: it's the previous day February 28th for the purposes of driver licencing and March 1st for other purposes. Taiwan: it's February 28th. And as near as I can tell in the US the statutes are silent on the matter leaving it up to the common law and to how various regulatory bodies define things in their regulations. To that end an improvement: public enum LeapDayRule { OrdinalDay = 1  LastDayOfMonth = 2  } static int ComputeAgeInYears( DateTime birth  DateTime reference  LeapYearBirthdayRule ruleInEffect ) { bool isLeapYearBirthday = CultureInfo.CurrentCulture.Calendar.IsLeapDay( birth.Year  birth.Month  birth.Day ) ; DateTime cutoff ; if ( isLeapYearBirthday && !DateTime.IsLeapYear(reference.Year) ) { switch ( ruleInEffect ) { case LeapDayRule.OrdinalDay : cutoff = new DateTime( reference.Year  1  1 ) .AddDays( birth.DayOfYear-1 ) ; break ; case LeapDayRule.LastDayOfMonth : cutoff = new DateTime( reference.Year  birth.Month  1 ) .AddMonths(1) .AddDays(-1) ; break ; default : throw new InvalidOperationException() ; } } else { cutoff = new DateTime(reference.Yearbirth.Monthbirth.Day) ; } int age = ( reference.Year - birth.Year ) + ( reference >= cutoff ? 0 : -1 ) ; return age < 0 ? 0 : age ; } It should be noted that this code assumes: A western (European) reckoning of age and A calendar like the Gregorian calendar that inserts a single leap day at the end of a month.  I don't know how the wrong solution can be accepted. The correct C# snippet was written by Michael Stum Here is a test snippet: DateTime bDay = new DateTime(2000 2 29); DateTime now = new DateTime(2009 2 28); MessageBox.Show(string.Format(""Test {0} {1} {2}"" CalculateAgeWrong1(bDay now) // outputs 9 CalculateAgeWrong2(bDay now) // outputs 9 CalculateAgeCorrect(bDay now))); // outputs 8 Here you have the methods: public int CalculateAgeWrong1(DateTime birthDate DateTime now) { return new DateTime(now.Subtract(birthDate).Ticks).Year - 1; } public int CalculateAgeWrong2(DateTime birthDate DateTime now) { int age = now.Year - birthDate.Year; if (now < birthDate.AddYears(age)) age--; return age; } public int CalculateAgeCorrect(DateTime birthDate DateTime now) { int age = now.Year - birthDate.Year; if (now.Month < birthDate.Month || (now.Month == birthDate.Month && now.Day < birthDate.Day)) age--; return age; } And the outputs?? this is the correct answer it needs to be voted up! +1 for your TDD approach to the answer! Output was -Test 9 9 8 While this code works it asserts that a person born on a leap day attains the next year of age on March 1st on non-leap years rather than on February 28th. In reality *either option may be correct*. [Wikipedia has something to say about this](http://en.wikipedia.org/wiki/Leap_day#Births). So while your code is not ""wrong"" neither is the accepted solution.  I've spent some time working on this and came up with this to calculate someone's age in years months and days. I've tested against the Feb 29th problem and leap years and it seems to work I'd appreciate any feedback: public void LoopAge(DateTime myDOB DateTime FutureDate) { int years = 0; int months = 0; int days = 0; DateTime tmpMyDOB = new DateTime(myDOB.Year myDOB.Month 1); DateTime tmpFutureDate = new DateTime(FutureDate.Year FutureDate.Month 1); while (tmpMyDOB.AddYears(years).AddMonths(months) < tmpFutureDate) { months++; if (months > 12) { years++; months = months - 12; } } if (FutureDate.Day >= myDOB.Day) { days = days + FutureDate.Day - myDOB.Day; } else { months--; if (months < 0) { years--; months = months + 12; } days += DateTime.DaysInMonth( FutureDate.AddMonths(-1).Year FutureDate.AddMonths(-1).Month ) + FutureDate.Day - myDOB.Day; } //add an extra day if the dob is a leap day if (DateTime.IsLeapYear(myDOB.Year) && myDOB.Month == 2 && myDOB.Day == 29) { //but only if the future date is less than 1st March if (FutureDate >= new DateTime(FutureDate.Year 3 1)) days++; } }",c# .net datetime
28637,A,"Is DateTime.Now the best way to measure a function's performance? I need to find a bottleneck and need to accurately as possible measure time. Is the following code snippet the best way to measure the performance? DateTime startTime = DateTime.Now; // Some execution process DateTime endTime = DateTime.Now; TimeSpan totalTimeTaken = endTime.Subtract(startTime); @dbasnett Can you go into more detail in an answer? In the above example change start and endtime to long and assign Stopwatch.GetTimestamp to them instead of DateTime.Now. The time taken is (end-start)/Stopwatch.Frequency. If you need greater precision use Stopwatch.GetTimestamp otherwise the answer is good. By the way if you are not looking for something quick and dirty performance counters can be used. See also: [The Case Against DateTime.Now](http://codeofmatt.com/2013/04/25/the-case-against-datetime-now/) This is the correct way: using System; using System.Diagnostics; class Program { public static void Main() { Stopwatch stopWatch = Stopwatch.StartNew(); // some other code stopWatch.Stop(); // this not correct to get full timer resolution Console.WriteLine(""{0} ms"" stopWatch.ElapsedMilliseconds); // Correct way to get accurate high precision timing Console.WriteLine(""{0} ms"" stopWatch.Elapsed.TotalMilliseconds); } } For more information go through Use Stopwatch instead of DataTime for getting accurate performance counter.  These are all great ways to measure time but that is only a very indirect way to find bottleneck(s). The most direct way to find a bottneck in a thread is to get it running and while it is doing whatever makes you wait halt it with a pause or break key. Do this several times. If your bottleneck takes X% of time X% is the probability that you will catch it in the act on each snapshot. Here's a more complete explanation of how and why it works  @Sean Chambers FYI the .NET Timer class is not for diagnostics it generates events at a preset interval like this (from MSDN): System.Timers.Timer aTimer; public static void Main() { // Create a timer with a ten second interval. aTimer = new System.Timers.Timer(10000); // Hook up the Elapsed event for the timer. aTimer.Elapsed += new ElapsedEventHandler(OnTimedEvent); // Set the Interval to 2 seconds (2000 milliseconds). aTimer.Interval = 2000; aTimer.Enabled = true; Console.WriteLine(""Press the Enter key to exit the program.""); Console.ReadLine(); } // Specify what you want to happen when the Elapsed event is // raised. private static void OnTimedEvent(object source ElapsedEventArgs e) { Console.WriteLine(""The Elapsed event was raised at {0}"" e.SignalTime); } So this really doesn't help you know how long something took just that a certain amount of time has passed. The timer is also exposed as a control in System.Windows.Forms... you can find it in your designer tool box in VS05/VS08  The way I use within my programs is using the StopWatch class as shown here. Stopwatch sw = new Stopwatch(); sw.Start(); int a = 5; // Critical lines of code long elapsedMs = se.Elapsed.TotalMilliseconds;  No it's not. Use the Stopwatch (in System.Diagnostics) Stopwatch sw = Stopwatch.StartNew(); PerformWork(); sw.Stop(); Console.WriteLine(""Time taken: {0}ms"" sw.Elapsed.TotalMilliseconds); Stopwatch automatically checks for the existence of high-precision timers. It is worth mentioning that DateTime.Now often is quite a bit slower than DateTime.UtcNow due to the work that has to be done with timezones DST and such. DateTime.UtcNow typically has a resolution of 15 ms. See John Chapman's blog post about DateTime.Now precision for a great summary. Interesting trivia: The stopwatch falls back on DateTime.UtcNow if your hardware doesn't support a high frequency counter. You can check to see if Stopwatch uses hardware to achieve high precision by looking at the static field Stopwatch.IsHighResolution. I'd place one PerformWork(); before Stopwatch for ""heating up"". Must also add recommendation that if your `PerformWork()` is very short that you may be able to call it repeatedly and compute the average of the batch of calls. Also time an entire batch of calls rather than starting/stopping your `Stopwatch` to avoid a strobe-effect that will muddy your timing measurements. Stopwatch is not threadsafe on multicore. See http://stackoverflow.com/questions/6664538/is-stopwatch-elapsedticks-threadsafe and http://stackoverflow.com/questions/1149485/best-practise-for-stopwatch-in-multi-processors-machine sw.ElapsedMilliseconds; can also  This article says that first of all you need to compare three alternatives Stopwatch DateTime.Now AND DateTime.UtcNow. It also shows that in some cases (when performance counter doesn't exist) Stopwatch is using DateTime.UtcNow + some extra processing. Because of that it's obvious that in that case DateTime.UtcNow is the best option (because other use it + some processing) However as it turns out the counter almost always exists - see Explanation about high-resolution performance counter and its existence related to .NET Stopwatch?. Here is a performance graph. Notice how low performance cost UtcNow has compared to alternatives: The X axis is sample data size and the Y axis is the relative time of the example. One thing Stopwatch is better at is that it provides higher resolution time measurements. Another is its more OO nature. However creating an OO wrapper around UtcNow can't be hard. The first link appears to be broken. became broken yep.. time machine can show it I would guess. Btw why you edit ""the three""  the isn't needed here I believe.  I've done very little of this sort of performance checking (I tend to just think ""this is slow make it faster"") so I have pretty much always gone with this. A google does reveal a lot of resources/articles for performance checking. Many mention using pinvoke to get performance information. A lot of the materials I study only really mention using perfmon.. Edit: Seen the talks of StopWatch.. Nice! I have learned something :) This looks like a good article  I just found a post in Vance Morrison's blog about a CodeTimer class he wrote that makes using StopWatch easier and does some neat stuff on the side.  Use the System.Diagnostics.Stopwatch class. Stopwatch sw = new Stopwatch(); sw.Start(); // Do some code. sw.Stop(); // sw.ElapsedMilliseconds = the time your ""do some code"" took.  Ditto Stopwatch it is way better. Regarding performance measuring you should also check whether your ""// Some Execution Process"" is a very short process. Also bear in mind that the first run of your ""// Some Execution Process"" might be way slower than subsequent runs. I typically test a method by running it 1000 times or 1000000 times in a loop and I get much more accurate data than running it once.  If you want something quick and dirty I would suggest using Stopwatch instead for a greater degree of precision. Stopwatch sw = new Stopwatch(); sw.Start(); // Do Work sw.Stop(); Console.WriteLine(""Elapsed time: {0}"" sw.Elapsed.TotalMilliseconds); Alternatively if you need something a little more sophisticated you should probably consider using a 3rd party profiler such as ANTS. Does ANTS work with F# yet?  The stopwatch functionality would be better (higher precision). I'd also recommend just downloading one of the popular profilers though (DotTrace and ANTS are the ones I've used the most... the free trial for DotTrace is fully functional and doesn't nag like some of the others).  It's useful to push your benchmarking code into a utility class/method. The StopWatch class does not need to be Disposed or Stopped on error. So the simplest code to time some action is public partial class With { public static long Benchmark(Action action) { var stopwatch = Stopwatch.StartNew(); action(); stopwatch.Stop(); return stopwatch.ElapsedMilliseconds; } } Sample calling code public void Execute(Action action) { var time = With.Benchmark(action); log.DebugFormat(“Did action in {0} ms.” time); } Here is the extension method version public static class Extensions { public static long Benchmark(this Action action) { return With.Benchmark(action); } } And sample calling code public void Execute(Action action) { var time = action.Benchmark() log.DebugFormat(“Did action in {0} ms.” time); } What about better granularity? Many things happen in less than one ms. Return the Elapsed property then it's a TimeSpan. I'm just showing you the pattern. Have fun implementing it. Return `Elapsed.TotalMilliseconds` for higher precision. See this question too http://stackoverflow.com/questions/8894425/difference-between-elapsedticks-elapsedmilliseconds-elapsed-milliseconds-and-e  Visual Studio Team System has some features that may help with this problem. Essentially you can write unit tests and mix them in different scenarios to run against your software as part of a stress or load test. This may help to identify areas of code that impact your applications performance the most. Microsoft' Patterns and Practices group has some guidance in Visual Studio Team System Performance Testing Guidance.",c# .net performance datetime timer
20346,A,".NET: What are attributes? What are they what are they good for and how do I create my own attributes? Many people have answered but no one has mentioned this so far... Attributes are used heavily with reflection. Reflection is already pretty slow. It is very worthwhile marking your custom attributes as being sealed classes to improve their runtime performance. It is also a good idea to consider where it would be appropriate to use place such an attribute and to attribute your attribute (!) to indicate this via AttributeUsage. The list of available attribute usages might surprise you: Assembly Module Class Struct Enum Constructor Method Property Field Event Interface Parameter Delegate ReturnValue GenericParameter All It's also cool that the AttributeUsage attribute is part of the AttributeUsage attribute's signature. Whoa for circular dependencies! [AttributeUsageAttribute(AttributeTargets.Class Inherited = true)] public sealed class AttributeUsageAttribute : Attribute  An attribute is a class that contains some bit of functionality that you can apply to objects in your code. To create one create a class that inherits from System.Attribute. As for what they're good for... there are almost limitless uses for them. http://www.codeproject.com/KB/cs/dotnetattributes.aspx  In the project I'm currently working on there is a set of UI objects of various flavours and an editor to assembly these objects to create pages for use in the main application a bit like the form designer in DevStudio. These objects exist in their own assembly and each object is a class derived from UserControl and has a custom attribute. This attribute is defined like this: [AttributeUsage (AttributeTargets::Class)] public ref class ControlDescriptionAttribute : Attribute { public: ControlDescriptionAttribute (String ^name String ^description) : _name (name) _description (description) { } property String ^Name { String ^get () { return _name; } } property String ^Description { String ^get () { return _description; } } private: String ^ _name ^ _description; }; and I apply it to a class like this: [ControlDescription (""Pie Chart"" ""Displays a pie chart"")] public ref class PieControl sealed : UserControl { // stuff }; which is what the previous posters have said. To use the attribute the editor has a Generic::List <Type> containing the control types. There is a list box which the user can drag from and drop onto the page to create an instance of the control. To populate the list box I get the ControlDescriptionAttribute for the control and fill out an entry in the list: // done for each control type array <Object ^> // get all the custom attributes ^attributes = controltype->GetCustomAttributes (true); Type // this is the one we're interested in ^attributetype = ECMMainPageDisplay::ControlDescriptionAttribute::typeid; // iterate over the custom attributes for each (Object ^attribute in attributes) { if (attributetype->IsInstanceOfType (attribute)) { ECMMainPageDisplay::ControlDescriptionAttribute ^description = safe_cast <ECMMainPageDisplay::ControlDescriptionAttribute ^> (attribute); // get the name and description and create an entry in the list ListViewItem ^item = gcnew ListViewItem (description->Name); item->Tag = controltype->Name; item->SubItems->Add (description->Description); mcontrols->Items->Add (item); break; } } Note: the above is C++/CLI but it's not difficult to convert to C# (yeah I know C++/CLI is an abomination but it's what I have to work with :-( ) You can put attributes on most things and there are whole range of predefined attributes. The editor mentioned above also looks for custom attributes on properties that describe the property and how to edit it. Once you get the whole idea you'll wonder how you ever lived without them.  Attributes are essentially bits of data you want to attach to your types (classes methods events enums etc.) The idea is that at run time some other type/framework/tool will query your type for the information in the attribute and act upon it. So for example Visual Studio can query the attributes on a 3rd party control to figure out which properties of the control should appear in the Properties pane at design time. Attributes can also be used in Aspect Oriented Programming to inject/manipulate objects at run time based on the attributes that decorate them and add validation logging etc. to the objects without affecting the business logic of the object.  You could check out Martin Flower's article How .NET’s Custom Attributes Affect Design.  Attributes are a kind of meta data for tagging classes. This is often used in WinForms for example to hide controls from the toolbar but can be implemented in your own application to enable instances of different classes to behave in specific ways. Start by creating an attribute: [AttributeUsage(AttributeTargets.Class AllowMultiple=false Inherited=true)] public class SortOrderAttribute : Attribute { public int SortOrder { get; set; } public SortOrderAttribute(int sortOrder) { this.SortOrder = sortOrder; } } All attribute classes must have the suffix ""Attribute"" to be valid. After this is done create a class that uses the attribute. [SortOrder(23)] public class MyClass { public MyClass() { } } Now you can check a specific class' SortOrderAttribute (if it have one) by doing the following: public class MyInvestigatorClass { public void InvestigateTheAttribute() { // Get the type object for the class that is using // the attribute. Type type = typeof(MyClass); // Get all custom attributes for the type. object[] attributes = type.GetCustomAttributes( typeof(SortOrderAttribute) true); // Now let's make sure that we got at least one attribute. if (attributes != null && attributes.Length > 0) { // Get the first attribute in the list of custom attributes // that is of the type ""SortOrderAttribute"". This should only // be one since we said ""AllowMultiple=false"". SortOrderAttribute attribute = attributes[0] as SortOrderAttribute; // Now we can get the sort order for the class ""MyClass"". int sortOrder = attribute.SortOrder; } } } If you want to read more about this you can always check out MSDN which have a pretty good description. I hope this helped you out!  Introduction to Attributes Programming C#: Attributes and Reflection (a great article excerpted from a book)  Attributes are also commonly used for Aspect Oriented Programming. For an example of this check out the PostSharp project.  To get started creating an attribute open a C# source file type attribute and hit [TAB]. It will expand to a template for a new attribute.  Attributes are like metadata applied to classes methods or assemblies. They are good for any number of things (debugger visualization marking things as obsolete marking things as serializable the list is endless). Creating your own custom ones is easy as pie. Start here: http://msdn.microsoft.com/en-us/library/sw480ze8(VS.71).aspx  You can use custom attributes as a simple way to define tag values in sub classes without having to write the same code over and over again for each subclass. I came across a nice concise example by John Waters of how to define and use custom attributes in your own code. There is a tutorial at http://msdn.microsoft.com/en-us/library/aa288454(VS.71).aspx  Metadata. Data about your objects/methods/properties. For example I might declare an Attribute called: DisplayOrder so I can easily control in what order properties should appear in the UI. I could then append it to a class and write some GUI components that extract the attributes and order the UI elements appropriately. public class DisplayWrapper { private UnderlyingClass underlyingObject; public DisplayWrapper(UnderlyingClass u) { underlyingObject = u; } [DisplayOrder(1)] public int SomeInt { get { return underlyingObject .SomeInt; } } [DisplayOrder(2)] public DateTime SomeDate { get { return underlyingObject .SomeDate; } } } Thereby ensuring that SomeInt is always displayed before SomeDate when working with my custom GUI components. However you'll see them most commonly used outside of the direct coding environment. For example the Windows Designer uses them extensively so it knows how to deal with custom made objects. Using the BrowsableAttribute like so: [Browsable(false)] public SomeCustomType DontShowThisInTheDesigner { get{/*do something*/} } Tells the designer not to list this in the available properties in the Properties window at design time for example. You could also use them for code-generation pre-compile operations (such as Post-Sharp) or run-time operations such as Reflection.Emit. For example you could write a bit of code for profiling that transparently wrapped every single call your code makes and times it. You could ""opt-out"" of the timing via an attribute that you place on particular methods. public void SomeProfilingMethod(MethodInfo targetMethod object target params object[] args) { bool time = true; foreach (Attribute a in target.GetCustomAttributes()) { if (a.GetType() is NoTimingAttribute) { time = false; break; } } if (time) { StopWatch stopWatch = new StopWatch(); stopWatch.Start(); targetMethod.Invoke(target args); stopWatch.Stop(); HandleTimingOutput(targetMethod stopWatch.Duration); } else { targetMethod.Invoke(target args); } } Declaring them is easy just make a class that inherits from Attribute. public class DisplayOrderAttribute : Attribute { private int order; public DisplayOrderAttribute(int order) { this.order = order; } public int Order { get { return order; } } } And remember that when you use the attribute you can omit the suffix ""attribute"" the compiler will add that for you. For what it's worth this is a list of all (built in) .NET attributes: http://msdn.microsoft.com/en-us/library/aa311259(VS.71).aspx  As said Attributes are relatively easy to create. The other part of the work is creating code that uses it. In most cases you will use reflection at runtime to alter behavior based on the presence of an attribute or its properties. There are also scenarios where you will inspect attributes on compiled code to do some sort of static analysis. For example parameters might be marked as non-null and the analysis tool can use this as a hint. Using the attributes and knowing the appropriate scenarios for their use is the bulk of the work.",c# .net attributes glossary
4335,A,High availability Is there anyway to configure a WCF service with a failover endpoint if the primary endpoint dies? Kind of like being able to specify a failover server in a SQL cluster... Specifically I am using the TCP/IP binding for speed but on the rare occurrence that the machine is not available I would like to redirect traffic to the failover server. Not too bothered about losing messages... I'd just prefer not to write the code to handle re-routing! You need to use a layer 4 load balancer in front of the two endpoints. Prob best to stick with a dedicated piece of hardware.  We've had good luck with BigIP as a solution though it's not cheap or easy to set up. One nice feature is it allows you to set up your SSL certificate (and backdoor to the CA) at the load balancer's common endpoint. Then you can use protocols to transfer the requests back to the WCF servers so the entire transmission is encrypted.  Without trying to sound too vague but I think Windows Network Load Balancing (NLB) should handle this for you.  Haven't done it yet with WCF but plan to have a local DNS entry pointing to our Network Load Balancing (NLB) virtual iP address which will direct all traffic to one of our servers hosting services within IIS. I have used NLB for this exact scenario in the past for web sites and see no reason why it will not work well with WCF. The beauty of it is that you can take servers in and out of the virtual cluster at will and NLB takes care of all the ugly re-directing to an available node. It also comes with a great price tag: $FREE with your Windows Server license.,c# .net wcf soa
16795,A,"PHPs htmlspecialcharacters equivalent in .NET? PHP has a great function called htmlspecialcharacters() where you pass it a string and it replaces all of HTML's special characters with their safe equivalents it's almost a one stop shop for sanitizing input. Very nice right? Well is there an equivalent in any of the .NET libraries? If not can anyone link to any code samples or libraries that do this well? System.Web.HttpUtility.HtmlEncode(string)  Try this. var encodedHtml = HttpContext.Current.Server.HtmlEncode(...);  Don't know if there's an exact replacement but there is a method HtmlUtility.HtmlEncode that replaces special characters with their HTML equivalents. A close cousin is HtmlUtility.UrlEncode for rendering URL's. You could also use validator controls like RegularExpressionValidator RangeValidator and System.Text.RegularExpression.Regex to make sure you're getting what you want.  Actually you might want to try this method: HttpUtility.HtmlAttributeEncode() Why? Citing the HtmlAttributeEncode page at MSDN docs: The HtmlAttributeEncode method converts only quotation marks ("") ampersands (&) and left angle brackets (<) to equivalent character entities. It is considerably faster than the HtmlEncode method.",c# .net php asp.net
17772,A,"Anyone know a quick way to get to custom attributes on an enum value? This is probably best shown with an example. I have an enum with attributes: public enum MyEnum { [CustomInfo(""This is a custom attrib"")] None = 0 [CustomInfo(""This is another attrib"")] ValueA [CustomInfo(""This has an extra flag"" AllowSomething = true)] ValueB } I want to get to those attributes from an instance: public CustomInfoAttribute GetInfo( MyEnum enumInput ) { Type typeOfEnum = enumInput.GetType(); //this will be typeof( MyEnum ) //here is the problem GetField takes a string // the .ToString() on enums is very slow FieldInfo fi = typeOfEnum.GetField( enumInput.ToString() ); //get the attribute from the field return fi.GetCustomAttributes( typeof( CustomInfoAttribute ) false ). FirstOrDefault() //Linq method to get first or null as CustomInfoAttribute; //use as operator to convert } As this is using reflection I expect some slowness but it seems messy to convert the enum value to a string (which reflects the name) when I already have an instance of it. Does anyone have a better way? Have you compared with `Enum.GetName()`? I generally find reflection to be quite speedy as long as you don't dynamically invoke methods. Since you are just reading the Attributes of an enum your approach should work just fine without any real performance hit. And remember that you generally should try to keep things simple to understand. Over engineering this just to gain a few ms might not be worth it.  This is probably the easiest way. A quicker way would be to Statically Emit the IL code using Dynamic Method and ILGenerator. Although I've only used this to GetPropertyInfo but can't see why you couldn't emit CustomAttributeInfo as well. For example code to emit a getter from a property public delegate object FastPropertyGetHandler(object target); private static void EmitBoxIfNeeded(ILGenerator ilGenerator System.Type type) { if (type.IsValueType) { ilGenerator.Emit(OpCodes.Box type); } } public static FastPropertyGetHandler GetPropertyGetter(PropertyInfo propInfo) { // generates a dynamic method to generate a FastPropertyGetHandler delegate DynamicMethod dynamicMethod = new DynamicMethod( string.Empty typeof (object) new Type[] { typeof (object) } propInfo.DeclaringType.Module); ILGenerator ilGenerator = dynamicMethod.GetILGenerator(); // loads the object into the stack ilGenerator.Emit(OpCodes.Ldarg_0); // calls the getter ilGenerator.EmitCall(OpCodes.Callvirt propInfo.GetGetMethod() null); // creates code for handling the return value EmitBoxIfNeeded(ilGenerator propInfo.PropertyType); // returns the value to the caller ilGenerator.Emit(OpCodes.Ret); // converts the DynamicMethod to a FastPropertyGetHandler delegate // to get the property FastPropertyGetHandler getter = (FastPropertyGetHandler) dynamicMethod.CreateDelegate(typeof(FastPropertyGetHandler)); return getter; }",c# .net reflection enums attributes
7719,A,"Capture MouseDown event for .NET TextBox Is there any way to capture the MouseDown even from the .NET 2.0 TextBox control? I know the inherited Control class has the event but it's not exposed in TextBox. Is there a way to override the event handler? I also tried the OpenNETCF TextBox2 control which does have the MouseDown event exposed but no matter what I do it doesn't fire the handler. Any suggestions? What kind of crazy mobile device do you have that has a mouse? :) Yes windows mobile does not have an actual mouse but you are mistaken that Windows Mobile .NET does not support the Mouse events. A click or move on the screen is still considered a ""Mouse"" event. It was done this way so that code could port over from full Windows easily. And this is not a Windows Mobile specific issue. The TextBox control on Windows does not have native mouse events either. I just happened to be using Windows Mobile in this case. Edit: And on a side note...as Windows Mobile is built of the WindowsCE core which is often used for embedded desktop systems and Slim Terminal Services clients or ""WinTerms"" it has support for a hardware mouse and has for a long time. Most devices just don't have the ports to plug one in. According to the .Net Framework the MouseDown Event Handler on a TextBox is supported. What happens when you try to run the code? Actually that's only there because it inherits it from ""Control"" as does every other Form control. It is however overridden (and changed to private I believe) in the TextBox class. So it will not show up in IntelliSense in Visual Studio. However you actually can write the code: textBox1.MouseDown += new System.Windows.Forms.MouseEventHandler(this.textBox1_MouseDown); and it will compile and run just fine the only problem is that textBox1_MouseDown() will not be fired when you tap the TextBox control. I assume this is because of the Event being overridden internally. I don't even want to change what's happening on the event internally I just want to add my own event handler to that event so I can fire some custom code as you could with any other event. What kind of crazy mobile device do you have that has a mouse? :) Seriously the reason there is no MouseDown event is because Windows Mobile doesn't have a mouse. What are you trying to do in the MouseDown event handler? Maybe there is another way. I know this answer is way late but hopefully it ends up being useful for someone who finds this. Also I didn't entirely come up with it myself. I believe I originally found most of the info on the OpenNETCF boards but what is typed below is extracted from one of my applications. You can get a mousedown event by implementing the OpenNETCF.Windows.Forms.IMessageFilter interface and attaching it to your application's message filter.  static class Program { public static MouseUpDownFilter mudFilter = new MouseUpDownfilter(); public static void Main() { Application2.AddMessageFilter(mudFilter); Application2.Run(new MainForm()); } } This is how you could implement the MouseUpDownFilter:  public class MouseUpDownFilter : IMessageFilter { List ControlList = new List(); public void WatchControl(Control buttonToWatch) { ControlList.Add(buttonToWatch); } public event MouseEventHandler MouseUp; public event MouseEventHandler MouseDown; public bool PreFilterMessage(ref Microsoft.WindowsCE.Forms.Message m) { const int WM_LBUTTONDOWN = 0x0201; const int WM_LBUTTONUP = 0x0202; // If the message code isn't one of the ones we're interested in // then we can stop here if (m.Msg != WM_LBUTTONDOWN && m.Msg != WM_LBUTTONDOWN) { return false; } // see if the control is a watched button foreach (Control c in ControlList) { if (m.HWnd == c.Handle) { int i = (int)m.LParam; int x = i & 0xFFFF; int y = (i >> 16) & 0xFFFF; MouseEventArgs args = new MouseEventArgs(MouseButtons.Left 1 x y 0); if (m.Msg == WM_LBUTTONDOWN) MouseDown(c args); else MouseUp(c args); // returning true means we've processed this message return true; } } return false; } } Now this MouseUpDownFilter will fire an MouseUp/MouseDown event when they occur on a watched control for example your textbox. To use this filter you add some watched controls and assign to the events it might fire in your form's load event:  private void MainForm_Load(object sender EventArgs e) { Program.mudFilter.WatchControl(this.textBox1); Program.mudFilter.MouseDown += new MouseEventHandler(mudFilter_MouseDown); Program.mudFilter.MouseUp += new MouseEventHandler(mudFilter_MouseUp); } void mudFilter_MouseDown(object sender MouseEventArgs e) { if (sender == textBox1) { // do what you want to do in the textBox1 mouse down event :) } }  is there an 'OnEnter' event that you could capture instead? it'd presumably also capture when you tab into the textbox as well as enter the text box by tapping/clicking on it but if that isn't a problem then this may be a more straightforward work-around  According to the .Net Framework the MouseDown Event Handler on a TextBox is supported. What happens when you try to run the code?  Looks like you're right. Bummer. No MouseOver event. One of the fallbacks that always works with .NET though is P/Invoke. Someone already took the time to do this for the .NET CF TextBox. I found this on CodeProject: http://www.codeproject.com/KB/cs/TextBox_subclassing.aspx Hope this helps  Fair enough. You probably know more than I do about Windows Mobile. :) I just started programming for it. But in regular WinForms you can override the OnXxx event handler methods all you want. A quick look in Reflector with the CF shows that Control TextBoxBase and TextBox don't prevent you from overriding the OnMouseDown event handler. Have you tried this?: public class MyTextBox : TextBox { public MyTextBox() { } protected override void OnMouseDown(MouseEventArgs e) { //do something specific here base.OnMouseDown(e); } }",c# .net events windows-mobile
7367,A,"Visual Studio - new ""default"" property values for inherited controls I'm looking for help setting a new default property value for an inherited control in Visual Studio: class NewCombo : System.Windows.Forms.ComboBox { public NewCombo() { DropDownItems = 50; } } The problem is that the base class property DropDownItems has a 'default' attribute set on it that is a different value (not 50). As a result when I drag the control onto a form the designer file gets an explicit mycontrol.DropDownItems = 50; line. At first this doesn't matter. But if later I change my inherited class to DropDownItems = 45; in the constructor this does not affect any of the controls on any form since all those designer files still have the value 50 hard-coded in them. And the whole point was to have the value set in one place so I can deal with the customer changing his mind. Obviously if I were creating my own custom property in the subclass I could give it its own designer default attribute of whatever I wanted. But here I'm wanting to change the default values of properties in the base. Is there any way to apply Visual Studio attributes to a base class member? Or is there some other workaround to get the result I want? In your derived class you need to either override (or shadow using new) the property in question and then re-apply the default value attribute.",c# .net vb.net visual-studio
8223,A,Connection Pooling in .NET/SQL Server? Is it necessary or advantageous to write custom connection pooling code when developing applications in .NET with an SQL Server database? I know that ADO.NET gives you the option to enable/disable connection pooling -- does that mean that it's built into the framework and I don't need to worry about it? Why do people talk about writing their own connection pooling software and how is this different than what's built into ADO.NET? I'm no real expert on this matter but I know ADO.NET has its own connection pooling system and as long as I've been using it it's been faultless. My reaction would be that there's no point in reinventing the wheel... Just make sure you close your connections when you're finished with them and everything will be fine! I hope someone else can give you some more firm anwers!  Well it is going to go away as the answer to all these questions will be LINQ. Incidentally we have never needed custom connection pooling for any of our applications so I am not sure what all the noise is about.  The connection pooling built-in to ADO.Net is robust and mature. I would recommend against attempting to write your own version.  With the advent of ADO.Net and the newer version of SQL connection pooling is handled on two layers first through ADO.Net itself and secondly by SQL Server 2005/2008 directly eliminating the need for custom connection pooling. I have been informed that similar support are being planned or have been implemented in Oracle and MySQL out of interest.  My understanding is that the connection pooling is automatically handled for you when using the SqlConnection object. This is purposefully designed to work with MSSQL and will ensure connections are pooled efficiently. You just need to be sure you close them when you are finished with them (and ensure they are disposed of). I have never heard of people needing to roll their own myself. But I admit my experience is kind of limited there.,c# .net sql-server connection-pooling
4816,A,"How do you resolve a domain name to an IP address with .NET/C#? How do you resolve a domain name to an IP address with .NET/C#? Try using the System.Net.Dns class  using System.Net; foreach (IPAddress address in Dns.GetHostAddresses(""www.google.com"")) { Console.WriteLine(address.ToString()); }",c# .net dns reverse-dns
2209,A,"How can I change the background of a masterpage from the code behind of a content page? I specifically want to add the style of background-color to the <body> tag of a master page from the code behind (C#) of a content page that uses that master page. I have different content pages that need to make the master page has different colors depending on which content page is loaded so that the master page matches the content page's theme. I have a solution below: I'm looking for something more like: Master.Attributes.Add(""style"" ""background-color: 2e6095""); Inside of the page load function of the content page. But I can't get the above line to work. I only need to change the background-color for the <body> tag of the page. I believe you are talking about a content management system. The way I have delt with this situation in the past is to either: Allow a page/content to define an extra custom stylesheet or Allow a page/content to define inline style tags  This is what I came up with: In the page load function: HtmlGenericControl body = (HtmlGenericControl)Master.FindControl(""default_body""); body.Style.Add(HtmlTextWriterStyle.BackgroundColor ""#2E6095""); Where default_body = the id of the body tag.  What I would do for the particular case is: i. Define the body as a server side control <body runat=""server"" id=""masterpageBody""> ii. In your content aspx page register the MasterPage with the register: <% MasterPageFile=""..."" %> iii. In the Content Page you can now simply use Master.FindControl(""masterpageBody"") and have access to the control. Now you can change whatever properties/style that you like!",c# asp.net .net master-pages
11804,A,"Returning Large Results Via a Webservice I'm working on a web service at the moment and there is the potential that the returned results could be quite large ( > 5mb). It's perfectly valid for this set of data to be this large and the web service can be called either sync or async but I'm wondering what people's thoughts are on the following: If the connection is lost the entire resultset will have to be regenerated and sent again. Is there any way I can do any sort of ""resume"" if the connection is lost or reset? Is sending a result set this large even appropriate? Would it be better to implement some sort of ""paging"" where the resultset is generated and stored on the server and the client can then download chunks of the resultset in smaller amounts and re-assemble the set at their end? I have seen all three approaches paged store and retrieve and massive push. I think the solution to your problem depends to some extent on why your result set is so large and how it is generated. Do your results grow over time are they calculated all at once and then pushed do you want to stream them back as soon as you have them? Paging Approach In my experience using a paging approach is appropriate when the client needs quick access to reasonably sized chunks of the result set similar to pages in search results. Considerations here are overall chattiness of your protocol caching of the entire result set between client page requests and/or the processing time it takes to generate a page of results. Store and retrieve Store and retrieve is useful when the results are not random access and the result set grows in size as the query is processed. Issues to consider here are complexity for clients and if you can provide the user with partial results or if you need to calculate all results before returning anything to the client (think sorting of results from distributed search engines). Massive Push The massive push approach is almost certainly flawed. Even if the client needs all of the information and it needs to be pushed in a monolithic result set I would recommend taking the approach of WS-ReliableMessaging (either directly or through your own simplified version) and chunking your results. By doing this you ensure that the pieces reach the client can discard the chunk as soon as you get a receipt from the client can reduce the possible issues with memory consumption from having to retain 5MB of XML DOM or whatever in memory (assuming that you aren't processing the results in a streaming manner) on the server and client sides. Like others have said though don't do anything until you know your result set size how it is generated and overall performance to be actual issues.  So it sounds like you'd be interested in a solution that adds 'starting record number' and 'final record number' parameter to your web method. (or 'page number' and 'results per page') This shouldn't be too hard if the backing store is sql server (or even mysql) as they have built in support for row numbering. Despite this you should be able to avoid doing any session management on the server avoid any explicit caching of the result set and just rely on the backing store's caching to keep your life simple.  I somewhat disagree with secretGeek's comment: That's already happening for you -- it's called tcp/ip ;-) Re-implementing that could be overkill. There are times when you may want to do just this but really only from a UI perspective. If you implement some way to either stream the data to the client (via something like a pushlets mechanism) or chunk it into pages as you suggest you can then load some really small subset on the client and then slowly build up the UI with the full amount of data. This makes for a slicker speedier UI (from the user's perspective) but you have to evaluate if the extra effort will be worthwhile... because I don't think it will be an insignificant amount of work.  There's no hard law against 5 Mb as a result set size. Over 400 Mb can be hard to send. You'll automatically get async handlers (since you're using .net) implement some sort of ""paging"" where the resultset is generated and stored on the server and the client can then download chunks of the resultset in smaller amounts and re-assemble the set at their end That's already happening for you -- it's called tcp/ip ;-) Re-implementing that could be overkill. Similarly -- entire resultset will have to be regenerated and sent again If it's MS-SQL for example that is generating most of the resultset -- then re-generating it will take advantage of some implicit cacheing in SQL Server and the subsequent generations will be quicker. To some extent you can get away with not worrying about these problems until they surface as 'real' problems -- because the platform(s) you're using take care of a lot of the performance bottlenecks for you.  The first question that you need to ask yourself is how fast is the network you client and server exist in. If both are inside the same network and it is your standard corporate LAN then you are likely looking at 100 Mbit/s. Most people aren't even going to notice the network delay in these cases so I would say that it is nothing to worry about. .NET should throw an exception if something goes wrong once again network speeds come in to play here as you might be able to just re-download the data without the user noticing. You might want to examine the data to make sure you are only getting the data that you need but if you need all of the data to do the task at hand I don't see why there would be an issue with the size. You might also want to look into compression to see if there are any ways to make it a bit smaller if size and speed are a major issue.",c# .net web-services
20168,A,"C# application detected as a virus Regarding the same program as my question a few minutes ago... I added a setup project and built an MSI for the program (just to see if I could figure it out) and it works great except for one thing. When I tried to install it on my parent's laptop their antivirus (the free Avast Home Edition) set off an alarm and accused my setup.exe of being a Trojan. Does anyone have any idea why this would be happening and how I can fix it? The very first thing to do would be to scan your build PC for viruses.  Rebuild the setup file check the exact file size. Check the exact file size of the ""suspected"" setup file. If the source code hasn't changed and the two file sizes are different there's a pretty good chance it got contaminated in transit. I'd do that as a bit of a sanity check first.  I don’t know “Avast” but in Kaspersky if the configuration is set to high almost every installer fires an alarm (iTunes Windows Update everything) especially if the installer modify some registry key or open a port. If avast checks for behavior and your program open a port probably that’s be the cause.  I would do what jsight suggested and make sure that your machine did not have a virus. I would also submit the .msi file to Avast's online scanner and see what they identified as being in your package. If that reports your file as containing a trojan contact Avast and ask them to verify that your .msi package does contain a trojan. If it doesn't contain a trojan find out from Avast what triggered their scanner. There may be something in your code that matches a pattern that Avast looks for They may be able to adjust their pattern to ignore your file or you could tweak your code so that it doesn't trigger their scanner.  Indeed boot from a clean CD (use a known good machine to build BartPE or something similar) and scan your machine thoroughly. Another good thing to check though would be exactly which virus Avast! thinks your program is. Once you know that you should be able to look it up in one of the virus databases and insure that your software can't contain it. The odds are that Avast! is just getting a false positive for some reason and I don't know that there's much you can do about that other than contacting Avast! and hoping for a reply. @Justin Bennett: so which of the two alternatives did you choose? Did you contact Avast?",c# .net antivirus
944,A,"Unhandled Exception Handler in .NET 1.1 I'm maintaining a .NET 1.1 application and one of the things I've been tasked with is making sure the user doesn't see any unfriendly error notifications. I've added handlers to Application.ThreadException and AppDomain.CurrentDomain.UnhandledException which do get called. My problem is that the standard CLR error dialog is still displayed (before the exception handler is called). Jeff talks about this problem on his blog here and here. But there's no solution. So what is the standard way in .NET 1.1 to handle uncaught exceptions and display a friendly dialog box? Edit: Jeff's response was marked as the correct answer because the link he provided has the most complete information on how to do what's required. AppDomain.UnhandledException is an event not a global exception handler. This means by the time it is raised your application is already on its way down the drain and there is nothing you can do about it except for doing cleanup and error logging. What happened behind the scenes is this: The framework detected the exception walked up the call stack to the very top found no handlers that would recover from the error so was unable to determine if it was safe to continue execution. So it started the shutdown sequence and fired up this event as a courtesy to you so you can pay your respects to your already-doomed process. This happens when an exception is left unhandled in the main thread. There is no single-point solution to this kind of error. You need to put a real exception handler (a catch block) upstream of all places where this error occurs and forward it to (for example) a global handler method/class that will determine if it is safe to simply report and continue based on exception type and/or content. Edit: It is possible to disable (=hack) the error-reporting mechanism built into Windows so the mandatory ""crash and burn"" dialog does not get displayed when your app goes down. However this becomes effective for all the applications in the system not just your own.  Unhandled exception behavior in a .NET 1.x WinForms app depends on: The type of thread that threw the exception Whether it occurred during window message processing Whether a debugger was attached to the process The DbgJitDebugLaunchSetting registry setting The jitDebugging flag in App.Config Whether you overrode the WinForms exception handler Whether you handled the CLR’s exception event The phase of the moon The default behaviour of unhandled exceptions is: If the exception occurs on the main thread when pumping window messages it's intercepted by the Windows Forms exception handler. If the exception occurs on the main thread when pumping window messages it will terminate the app process unless it's intercepted by the Windows Forms exception handler. If the exception occurs on a manual threadpool or finalizer thread it's swallowed by the CLR. The points of contact for an unhandled exception are: Windows Forms exception handler. The JIT-debug registry switch DbgJitDebugLaunchSetting. The CLR unhandled exception event. The Windows Form built-in exception handling does the following by default: Catches an unhandled exception when: exception is on main thread and no debugger attached. exception occurs during window message processing. jitDebugging = false in App.Config. Shows dialog to user and prevents app termination. You can disable the latter behaviour by setting jitDebugging = true in App.Config. But remember that this may be your last chance to stop app termination. So the next step to catch an unhandled exception is registering for event Application.ThreadException e.g. : Application.ThreadException += new Threading.ThreadExceptionHandler(CatchFormsExceptions); Note the registry setting DbgJitDebugLaunchSetting under HKEY_LOCAL_MACHINE\Software.NetFramework. This has one of three values of which I'm aware: 0: shows user dialog asking ""debug or terminate"". 1: lets exception through for CLR to deal with. 2: launches debugger specified in DbgManagedDebugger registry key. In Visual Studio go to Tools>Options>Debugging>JIT to set this key to 0 or 2. But a value of 1 is usually best on an end-user's machine. Note that this registry key is acted on before the CLR unhandled exception event. This last event is your last chance to log an unhandled exception. It's triggered before your Finally blocks have executed. You can intercept this event as follows: AppDomain.CurrentDomain.UnhandledException += new System.UnhandledExceptionEventHandler(CatchClrExceptions);  Oh in WinForms you definitely should be able to get it to work. The only thing you have to watch out for is things happening on different threads. I have an old CodeProject article here which should help: http://www.codeproject.com/KB/exception/ExceptionHandling.aspx  It's a WinForms app. The exceptions that are caught by Application.ThreadException work fine and I don't get the ugly .NET exception box (OK to terminate cancel to debug? who came up with that??). I was getting some exceptions that weren't being caught by that and ended up going to the AppDomain.UnhandledException event that were causing problems. I think I've caught most of those exceptions and I am displaying them in our nice error box now. So I'll just have to hope there are not some other circumstances that would cause exceptions to not be caught by the Application.ThreadException handler.  is this a console app or a winforms app? If it's a .NET 1.1 console app this is sadly by design -- it's confirmed by a MSFT dev in the second blog post you referenced: BTW on my 1.1 machine the example from MSDN does have the expected output; it's just that the second line doesn't show up until after you've attached a debugger (or not). In v2 we've flipped things around so that the UnhandledException event fires before the debugger attaches which seems to be what most people expect. Sounds like .NET 2.0 does this better (thank goodness) but honestly I never had time to go back and check.",c# .net exception exception-handling
260,A,"Adding scripting functionality to .NET applications I have a little game written in C#. It uses a database as back-end. It's a trading card game and I wanted to implement the function of the cards as a script. What I mean is that I essentially have an interface ICard which a card class implements (public class Card056 : ICard) and which contains function that are called by the game. Now to make the thing maintainable/moddable I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card I'll just add it to the database and tell my application to refresh without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies). Is that possible? Register a class from a source file and then instantiate it etc. ICard Cards[current] = new MyGame.CardLibrary.Card056(); Cards[current].OnEnterPlay(ref currentGameState); The language is C# but extra bonus if it's possible to write the script in any .NET language. @mattytommo No don't have anything left it was in the really early stages and essentially was just working like I outlined above. Nowadays I would look into Roslyn to do C# compilation: http://blogs.msdn.com/b/csharpfaq/archive/2011/10/19/introducing-the-microsoft-roslyn-ctp.aspx - Alternatively JavaScript using Jint - http://jint.codeplex.com/ That's funny me and a friend were thinking of writing a trading card game in C# a while back don't suppose you still have the source for this? Interested on how you'd approached this. ah thanks but I was looking more for the implementation of the trading card game itself and the structure you'd used as opposed to the scripting engine. Thanks anyway :) If you don't want to use the DLR you can use Boo (which has an interpreter) or you could consider the Script.NET (S#) project on CodePlex. With the Boo solution you can choose between compiled scripts or using the interpreter and Boo makes a nice scripting language has a flexible syntax and an extensible language via its open compiler architecture. Script.NET looks nice too though and you could easily extend that language as well as its an open source project and uses a very friendly Compiler Generator (Irony.net).  The main application that my division sells does something very similar to provide client customisations (which means that I can't post any source). We have a C# application that loads dynamic VB.NET scripts (although any .NET language could be easily supported - VB was chosen because the customisation team came from an ASP background). Using .NET's CodeDom we compile the scripts from the database using the VB CodeDomProvider (annoyingly it defaults to .NET 2 if you want to support 3.5 features you need to pass a dictionary with ""CompilerVersion"" = ""v3.5"" to its constructor). Use the CodeDomProvider.CompileAssemblyFromSource method to compile it (you can pass settings to force it to compile in memory only. This would result in hundreds of assemblies in memory but you could put all the dynamic classes' code together into a single assembly and recompile the whole lot when any change. This has the advantage that you could add a flag to compile on disk with a PDB for when you're testing allowing you to debug through the dynamic code.  You might be able to use IronRuby for that. Otherwise I'd suggest you have a directory where you place precompiled assemblies. Then you could have a reference in the DB to the assembly and class and use reflection to load the proper assemblies at runtime. If you really want to compile at run-time you could use the CodeDOM then you could use reflection to load the dynamic assembly. MSDN article which might help.  I'd suggest using LuaInterface as it has fully implemented Lua where it appears that Nua is not complete and likely does not implement some very useful functionality (coroutines etc). If you want to use some of the outside prepacked Lua modules I'd suggest using something along the lines of 1.5.x as opposed to the 2.x series that builds fully managed code and cannot expose the necessary C API.  The next version of .NET (5.0?) has had a lot of talk about opening the ""compiler as a service"" which would make things like direct script evaluation possible. Yes. Although Roslyn is still on the horizon [Mono.CSharp (available on NuGet)](http://blog.davidebbo.com/2012/02/quick-fun-with-monos-csharp-compiler-as.html) packs all the same functionality. I believe this refers to Roslyn? http://en.wikipedia.org/wiki/Microsoft_Roslyn  Oleg Shilo's C# Script solution (at The Code Project) really is a great introduction to providing script abilities in your application. A different approach would be to consider a language that is specifically built for scripting such as IronRuby IronPython or Lua. IronPython and IronRuby are both available today. For a guide to embedding IronPython read How to embed IronPython script support in your existing app in 10 easy steps. Lua is a scripting language commonly used in games. There is a Lua compiler for .NET available from CodePlex -- http://www.codeplex.com/Nua That codebase is a great read if you want to learn about building a compiler in .NET. A different angle altogether is to try PowerShell. There are numerous examples of embedding PowerShell into an application -- here's a thorough project on the topic: Powershell Tunnel By the way I've chosen this as the accepted answer because I wanted to loo at Python and IronPython anyway so the IronPython approach works best for *me*. LuaInterface is a lua interpreter that works fantastic as well. I implemented C# Script in a workflow system in Nov 09. It has performed really well for us.  I didn't try it but I did see an article on Code Project that implements C# scripting in a .NET application. http://www.codeproject.com/KB/cs/cs-script_for_cp.aspx While this link may answer the question it is better to include the essential parts of the answer here and provide the link for reference. Link-only answers can become invalid if the linked page changes.  You could use any of the DLR languages which provide a way to really easily host your own scripting platform. However you don't have to use a scripting language for this. You could use C# and compile it with the C# code provider. As long as you load it in its own AppDomain you can load and unload it to your heart's content.  I'm using LuaInterface1.3 + Lua 5.0 for NET1.1 application. The issue with Boo is that everytime you parse/compile/eval your code on the fly it creates a set of boo classes so you will get memory leaks. Lua in the other hand does not do that so it's very very stable and works wonderful (I can pass objects from C# to Lua and backwards). So far I havent put it in PROD yet but seems very promising. UPDATE: I did have memory leaks issues in PROD using LuaInterface + Lua 5.0 therefore I used Lua 5.2 and linked directly into C# with DllImport. The memory leaks were inside the LuaInterface library. Lua 5.2: from http://luabinaries.sourceforge.net and http://sourceforge.net/projects/luabinaries/files/5.2/Windows%20Libraries/Dynamic/lua-5.2_Win32_dll7_lib.zip/download Once I did this all my memory leaks were gone and the app was very stable.  Yes I thought about that but I soon figured out that another Domain-Specific-Language (DSL) would be a bit too much. Essentially they need to interact with my gamestate in possibly unpredictable ways. For example a card could have a rule ""When this cards enter play all your undead minions gain +3 attack against flying enemies except when the enemy is blessed"". As trading card games are turn based the GameState Manager will fire OnStageX events and let the cards modify other cards or the GameState in whatever way the card needs. If I try to create a DSL I have to implement a rather large feature set and possibly constantly update it which shifts the maintenance work to another part without actually removing it. That's why I wanted to stay with a ""real"" .NET language to essentially be able to just fire the event and let the card manipulate the gamestate in whatever way (within the limits of the code access security). (No need to flag this; while this should be a comment/answer update but is grandfathered in from before those were options)",c# .net scripting compiler
21288,A,"Which .NET Dependency Injection frameworks are worth looking into? Which C#/.NET Dependency Injection frameworks are worth looking into? And what can you say about their complexity and speed. [IoC Container Benchmark - Performance comparison](http://www.palmmedia.de/blog/2011/8/30/ioc-container-benchmark-performance-comparison) has performance and features comparison tables for 20+ products and keep them up-to-date. It recommends [Simple Injector](http://simpleinjector.codeplex.com/) I appreciate Ninject & Maestro. I'm happy that the top rated answer reffer Ninject as ""an absolute pleasure"" Autofac. http://code.google.com/p/autofac/ It is really fast and pretty good. Here is a link with comparisons (made after Ninject fixed a memory leak issue). http://www.codinginstinct.com/2008/05/ioc-container-benchmark-rerevisted.html Autofac is the first DI container I've really tried out and thus far it's been brilliant. Simple quick and powerful +1 for Autofac. I love it. Is it faster than the others? Or was that a general comment?  I think a good place to start is with Ninject it is new and has taken into account alot of fine tuning and is really fast. Nate the developer really has a great site and great support.  We use Unity from the Microsoft Enterprise Library  I suppose I might be being a bit picky here but it's important to note DI (Dependency Injection) is a programming pattern and is facilitated by (but does not require) an IoC (Inversion of Control) Framework. IoC Frameworks just make DI much easier but it's not only DI that they do they provide a host of other benefits over and above DI. That being said I'm sure that's what you were asking: about IoC Frameworks: I used to use Spring.Net and CastleWindsor a lot but the real pain in the beehiind was all that pesky XML config you had to write! They're pretty much all moving this way now but I started using StructureMap for the last year or so and since it has moved to a fluent config using strongly typed generics and a registry my pain barrier in using IoC has dropped below zero! I get an absolute kick out of knowing now that my IoC config is checked at compile-time (for the most part) and I have had nothing but joy with StructureMap and its speed. I won't say that the others were slow (runtime) but they were more difficult for me to setup and frustration often won the day. I believe they're all moving towards a more strongly typed config now - or at least providing the option but some people love putting all the config in XML - personally I can't bare it so I have stuck to StructureMap now. I can't comment much on Ninject except that I listened to Nate on one of the Herding Code podcasts and he's one switched-on guy and the screencasts I've watched have really tempted me to try it out - maybe on the next project - who knows. Update: In a follow up to my comments here I've been using Ninject (as promised) on my latest project and it has been an absolute pleasure to use. Words fail me a bit here but (as we say in the UK) this framework is the Dogs'. I highly recommend it for any green fields projects where you want to be up and running quickly. I got all I needed from a fantastic set of Ninject screencasts by Justin Etheredge. I also can't see that retro-fitting Ninject into existing (above average) code being a problem at all - but then the same could be said of StructureMap in my experience. It'll be a tough choice going forward between those two but I'd rather have competition than stagnation and there's a decent amount of healthy competition out there. Other IoC screencasts can also be found here on Dimecasts. Hope that helps Rob G It's great to see a quality well thought out answer rise about the one liners. You convinced me to check out StructureMap. Excellent answer with good references I like it! The dog's what? ;) Nice but to be fair - Windsor has a very nice fully-fledged fluent interface now as well. Could you explain what are the ""host of other benefits"" IoC frameworks provide besides easy implementation of DI? If performance is a factor this post provides a regularly updated benchmark for most of them: http://www.palmmedia.de/blog/2011/8/30/ioc-container-benchmark-performance-comparison @fearofawhackplanet one of the only things an IoC container can do that can't be done with *poor man's DI* is **Interception**. Good summary here: http://www.kenneth-truyers.net/2013/05/16/why-choose-di-interception-over-aspect-oriented-programming/  It depends on what you are looking for as they each have their pros and cons. Spring.NET is the most mature as it comes out of Spring from the java world. Spring has a very rich set of framework libraries that extend it to support Web Windows etc. Castle Windsor is one of the most widely used in the .NET platform and has the largest ecosystem is highly configurable / extensible has custom lifetime management AOP support has inherent NHibernate support and is an all around awesome container. Windsor is part of an entire stack which includes Monorail Active Record etc. NHibernate itself builds on top of Windsor. Structure Map has very rich and fine grained configuration through an internal DSL. Autofac is an IoC container of the new age with all of it's inherent functional programming support. It also takes a different approach on managing lifetime than the others. Autofac is still very new but it pushes the bar on what is possible with IoC. Ninject I have heard is more bare bones with a less is more approach (heard not experienced). The biggest discriminator of Unity is it's from and supported by Microsoft (p&p). Unity has very good performance and great documentation. It is also highly configurable. It doesn't have all the bells and whistles of say Castle / Structure Map. So in summary it really depends on what is important to you. I would agree with others on going and evaluating and seeing which one fits. The nice thing is you have a nice selection of donuts rather than just having to have a jelly one. :-) Good description. I would stay away from Unity though as it's simply a PITA to use. Autofac is actually not so new it is older than Unity :) Did I say it was newer than Unity? I said it is of the new age...ie I meant it's functional nature. OK what I said it's still very new what I meant though was it's nature not that IT was new. :-) @Krzysztof - I find Unity dead easy (at least when configured fluently in code). What did you find painful? That's funny considering Unity does not have fluent API :D @Krzysztof - [Using the UnityContainer Fluent Interface](http://msdn.microsoft.com/en-us/library/ff660904%28v=PandP.20%29.aspx) Here's an interesting performance benchmark: http://www.palmmedia.de/Blog/2011/8/30/ioc-container-benchmark-performance-comparison  Spring.Net is quite solid but the documentation took some time to wade through. Autofac is good and while .Net 2.0 is supported you need VS 2008 to compile it or else use the command line to build your app.  I've used Spring.NET in the past and had great success with it. I never noticed any substantial overhead with it though the project we used it on was fairly heavy on its own. It only took a little time reading through the documentation to get it set up.  I haven't used any other DI frameworks besides Unity from the Microsoft Patterns & Practices group but I was pretty surprised at how lightweight it seems. There's a great screencast that outlines the common usages and had me up to speed in under 30 minutes.  I use the Simple Service Locator. The Simple Service Locator is an easy-to-use Dependency Injection library that is a complete implementation of the Common Service Locator interface. It solely supports code-based configuration and is an ideal starting point for developers unfamiliar with larger DI libraries. Simple Injector project. Beware some consider the service locator an anti-pattern including someone who used it for some time and even wrote a library for it: http://blog.ploeh.dk/2010/02/03/ServiceLocatorisanAnti-Pattern/  Ninject is great. It seems really fast but I haven't done any comparisons. I know Nate the author did some comparisons between Ninject and other DI frameworks and is looking for more ways to improve the speed of Ninject. I've heard lots of people I respect say good things about StructureMap and CastleWindsor. Those in my mind are the big three to look at right now.  I'm a huge fan of Castle. I love the facilities it also provides beyond the IoC Container story. It really simplfies using NHibernate logging AOP etc. I also use Binsor for configuration with Boo and have really fallen in love with Boo as a language because of it.  I spent the better part of a day struggling without success to get the simplest Spring.NET example working. Could never figure out how to get it to find my assembly from the XML file. In about 2 hours on the other hand I was able to get Ninject working including testing integration with both NUnit and MSTest.  I can recommend Ninject. It's incredibly fast and easy to use but only if you don't need XML configuration else you should use Windsor.  The great thing about C# is that it is following a path beaten by years of Java developers before it. So my advice generally speaking when looking for tools of this nature is to look for the solid Java answer and see if there exists a .NET adaptation yet. So when it comes to DI (and there are so many options out there this really is a matter of taste) is Spring.NET. Additionally it's always wise to research the people behind projects. I have no issue suggesting SourceGear products for source control (outside of using them) because I have respect for Eric Sink. I have seen Mark Pollack speak and what can I say the guy just gets it. In the end there are a lot of DI frameworks and your best bet is to do some sample projects with a few of them and make an educated choice. Good luck!",c# .net dependency-injection inversion-of-control
23391,A,"Increases Skills what should I learn? My path to a 'fulltime'- developer stated as a analyst using VBA with Excel Access and then onto C#. I went to college part time once I discovered I had a passion for coding not business. I do about most of my coding in C# but being an ASP.NET developer I also write in HTML JavaScript SQL etc. . . the usual suspects. I like to keep moving forward find the edge that will get me to the next level the next job and of course more money. Most importantly I just want to learning something new and challenge me. I have spent time recently learning LINQ but was wondering what should I learn next? Something on the .NET Framework or a new language technology? As you continue to gain more experience in ASP.Net C# etc - it's always good to go check out the competition and see if it sparks ideas on how you can do things better in what you're doing. Taking a look at something like Rails or Django might change how you look at designing or building your apps.  @ Michael DSL=Domain Specific Language As for what you should learn that depends on what you're interested in. Are you looking to challenge yourself while staying in the same medium (web-centric applications)? I would suggest learning about Apache and the LAMP (Linux Apache MySQL PHP) architecture and challenge yourself to build a web application that you could readily build with ASP .NET using it. Want to learn something completely different? Try Prolog or LISP and see what you can do with those. Maybe you'd like to get into embedded software? Learn C to start. You have a wide variety of ways to improve your skills and each one has career paths attached to them. (Well maybe not Prolog but it's fun!)  The more languages you know the more marketable you are. Look and see what the more popular (market for not fan base) languages are then add on some cutting edge tech that is not in much use yet rounded out by general programming skill. With your skill set I would recommend (as far as languages): Java as a starting point For .Net add in the .Net MVC (you have LINQ or that would be here also) Language agnostic skills: Design Patterns (includes the MVC) Domain Driven Design Test Driven Design  Yeah the more I get into software I start to see myself focusing less on the language and more on the design.. Yeah there are framework bits we need to get our head around but most of the time ( most not all ) you can look those up as-and-when you need them.. But a good design head? That takes years of experience to start getting it working right.. And that is what the companies really pay for.. ""Build it and they will come"" and all that...  Here would be my suggestions: 1) Design Patterns - These are really neat as well as being very useful in some situations. 2) AJAX - Assuming you haven't already done some of this it is an interesting part of Web Development from my view. 3) Determine which parts of the chain do you enjoy the most: Front-end work(HTML CSS Javascript) middleware(C# for business logic parts) or back-end(MS-SQL with stored procedures indexes triggers and all that stuff). If it is all of it then try to stay where the team doing web development is small as otherwise you may be asked to choose. 4) Algorithm design and analysis - Do you know various sorting algorithms? Do you know various techniques to create an algorithm e.g. greedy recursion divide and conquer dynamic programming using custom data types like heap in heapsort etc. This can be new and cool. 5) Determine if there is a part of the development process you favor: Analyst designer programmer tester debugger? All can have varying degrees of being near the code IMO.  If you want to be one of the best you need to specialise. If you become very good in many skills then you may never become truly excellent in one. I know because I have taken this route myself and have found it difficult to get employment at times. After all who wants someone who is capable at many languages when there is someone who excels at the specific thing they need. If a company develops in C# then who would want someone who is OK at C# but also is good at C Visual Basic Perl and Cobol when all they really want is the best possible C# developer for the money they can afford. After all you will only ever be employed for one maybe two of your skills. There are very few jobs for people who are good in 10 or 15 skills. If you are looking to a new skill then maybe check out the job boards and find which skills are particularly in need but be aware that what is the flavour of the month this year may not even be on the scene next year which will make all of that effort to learn the skill futile and wasted. What I would say is: do one thing and do it well. This may include supporting skills (C# ASP.Net SQL LINQ etc). If you want to choose something else then choose something complementary. Possibly most importantly choose something you will enjoy. Maybe Ruby on Rails is the current flavour of the month but if you don't enjoy doing it then don't do it. Really it's not worth it. You will never wish on your death bed that you had worked more in something you didn't enjoy. Another direction you could look at is maybe not for a particular development skill but look for something else maybe soft skills like people management better business understanding or even look to something like literary skills to help improve your communications skills. All of these will help to allow you to do what you want to do more and cut down on the stuff you really don't enjoy thus helping to make your job more enjoyable. Apologies for the waffling here. Hope you are still awake :) Although I agree that you should focus on a particular language I still think that if you are versed in lower level languages such as C and C++ it will make you a better programmer in higher level languages such as C# or Java...so I still think that you should at least try to learn other languages. Other than that not every language is suitable for every particular job so the more the know the more you can apply for specific tasks...which in turn will make you more productive and ofcourse employers like that. I agree that specialization is important but I don't entirely agree with you. I worked in the data capture group at an analytics company and our group had SDK's for all the mobile platforms (there's 3 languages and 4 runtime environments alone) as well as projects in C# C++ Java and JavaScript. Any developer with truly good fundamentals should be able to become proficient in any language/runtime fairly quickly. I still think you should specialize but a deep understanding of software is more valuable than know .NET well for example. I would still encourage people to learn many languages.  Why don't you swap stacks and look at the LAMP stack? Or how about a functional language like haskell? Or write a DSL? Or an app for your phone? What is the point of swapping the stack? Whichever that is?  Maybe learn more about Usability (best practices testing etc.) if you haven't already done so. Steve Krug's ""Don't Make Me Think"" is a good book to start with. Jakob Nielsen always has interesting stuff as well.  If you're now proficient with the languages and technologies you use then start spending more time focusing on the design solution architecture and systems integration. The ""bigger picture"" that will set you apart from your contemporaries. Check out some Martin Fowler books like ""Patterns of Enterprise Application Architecture"" or Eric Evans' ""Domain-Driven Design"".  Check out OOAD & UML maybe... Ooo! And DDD - definitely. (Yes I just had to throw in the obligatory Wikipedia links! It is my first time doing so and now I feel dirty!)",c# .net
22012,A,"Loading assemblies and its dependencies My application dynamically loads assemblies at runtime from specific subfolders. These assemblies are compiled with dependencies to other assemblies. The runtime trys to load these from the application directory. But I want to put them into the modules directory. Is there a way to tell the runtime that the dlls are in a seperate subfolder? One nice approach I've used lately is to add an event handler for the AppDomain's AssemblyResolve event. AppDomain currentDomain = AppDomain.CurrentDomain; currentDomain.AssemblyResolve += new ResolveEventHandler(MyResolveEventHandler); Then in the event handler method you can load the assembly that was attempted to be resolved using one of the Assembly.Load Assembly.LoadFrom overrides and return it from the method. EDIT: Based on your additional information I think using the technique above specifically resolving the references to an assembly yourself is the only real approach that is going to work without restructuring your app. What it gives you is that the location of each and every assembly that the CLR fails to resolve can be determined and loaded by your code at runtime... I've used this in similar situations for both pluggable architectures and for an assembly reference integrity scanning tool. A good example of this technique is the application LINQPad. It ships as a single exe so all the libraries are included as embedded resources. See http://www.albahari.com/nutshell/ch16.aspx for code and http://www.linqpad.net/HowLINQPadWorks.aspx for insight.  You can use the <probing> element in a manifest file to tell the Runtime to look in different directories for its assembly files. http://msdn.microsoft.com/en-us/library/823z9h8w.aspx e.g.: <configuration> <runtime> <assemblyBinding xmlns=""urn:schemas-microsoft-com:asm.v1""> <probing privatePath=""bin;bin2\subbin;bin3""/> </assemblyBinding> </runtime> </configuration>  You can use the <codeBase> element found in the application configuration file. More information on ""Locating the Assembly through Codebases or Probing"". Well the loaded assembly doesn't have an application configuration file. Well if you know the specific folders at runtime you can use Assembly.LoadFrom.",c# .net
20467,A,"Path Display in Label Are there any automatic methods for trimming a path string in .NET? For example: C:\Documents and Settings\nick\My Documents\Tests\demo data\demo data.emx becomes C:\Documents...\demo data.emx It would be particularly cool if this were built into the Label class and I seem to recall it is--can't find it though! Not hard to write yourself though:  public static string TrimPath(string path) { int someArbitaryNumber = 10; string directory = Path.GetDirectoryName(path); string fileName = Path.GetFileName(path); if (directory.Length > someArbitaryNumber) { return String.Format(@""{0}...\{1}"" directory.Substring(0 someArbitaryNumber) fileName); } else { return path; } } I guess you could even add it as an extension method.  What you are thinking on the label is that it will put ... if it is longer than the width (not set to auto size) but that would be c:\Documents and Settings\nick\My Doc... If there is support it would probably be on the Path class in System.IO  You could use the System.IO.Path.GetFileName method and append that string to a shortened System.IO.Path.GetDirectoryName string.  Use TextRenderer.DrawText with TextFormatFlags.PathEllipsis flag void label_Paint(object sender PaintEventArgs e) { Label label = (Label)sender; TextRenderer.DrawText(e.Graphics label.Text label.Font label.ClientRectangle label.ForeColor TextFormatFlags.PathEllipsis); } Your code is 95% there. The only problem is that the trimmed text is drawn on top of the text which is already on the label. Yes thanks I was aware of that. My intention was only to demonstrate use of DrawText method. I didn't know whether you want to manually create event for each label or just override OnPaint() method in inherited label. Thanks for sharing your final solution though.  @ lubos hasko Your code is 95% there. The only problem is that the trimmed text is drawn on top of the text which is already on the label. This is easily solved:  Label label = (Label)sender; using (SolidBrush b = new SolidBrush(label.BackColor)) e.Graphics.FillRectangle(b label.ClientRectangle); TextRenderer.DrawText( e.Graphics label.Text label.Font label.ClientRectangle label.ForeColor TextFormatFlags.PathEllipsis);",c# .net winforms path
752,A,"Get a new object instance from a Type One may not always know the Type of an object at compile-time but may need to create an instance of the Type. How do you get a new object instance from a Type? The Activator class within the root System namespace is pretty powerful. There are a lot of overloads for passing parameters to the constructor and such. Check out the documentation at: http://msdn.microsoft.com/en-us/library/system.activator.createinstance.aspx Here are some simple examples: ObjectType instance = (ObjectType)Activator.CreateInstance(objectType); ObjectType instance = (ObjectType)Activator.CreateInstance(""MyNamespace.ObjectType MyAssembly""); Exactly! Thanks Karl! Glad to have finally found this but second call is not exactly right missing a quote and parms reversed should be: ObjectType instance = (ObjectType)Activator.CreateInstance(""MyAssembly""""MyNamespace.ObjectType""); You need to call 'Unwrap()' to get the actual type of object you want: ConcreteType instance = (ConcreteType)Activator.CreateInstance(objectType).Unwrap();  ObjectType instance = (ObjectType)Activator.CreateInstance(objectType); The Activator class has a generic variant that makes this a bit easier:  ObjectType instance = Activator.CreateInstance<ObjectType>(); I was drawn to this question because I recently needed to create boxed value types of an unknown `Type t` in order to use reflection's `FieldInfo.SetValue(object)` to populate field members of a struct or class that hold value types (int char enum etc.) To do this I used `Type t = FieldInfo.FieldType` to determine the field type then created the proper boxed `object` using `Convert.ChangeType(value t)` where `value` is a `ulong`. For enums (where `t.IsEnum`) I use `Enum.ToObject(t value)`. I suppose this is really just a cast-and-box not a `new()`. :-) @Kevin Of course. Such an operation *can’t* work in a statically typed language because it doesn’t make sense. You cannot invoke methods on an object of unknown type. In the meantime (= since writing this answer) C# has got the `dynamic` construct which *does* allow such constructs but for most purposes this answer still covers it. Except this doesn't work for runtime `Type t`.  If you want to use the default constructor then the solution using System.Activator presented earlier is probably the most convenient. However if the type lacks a default constructor or you have to use a non-default one then an option is to use reflection or System.ComponentModel.TypeDescriptor. In case of reflection it is enough to know just the type name (with its namespace). Example using reflection: ObjectType instance = (ObjectType)System.Reflection.Assembly.GetExecutingAssembly().CreateInstance( typeName: objectType.FulName // string including namespace of the type ignoreCase: false bindingAttr: BindingFlags.Default binder: null // use default binder args: new object[] { args to constructor } culture: null // use CultureInfo from current thread activationAttributes: null ); Example using TypeDescriptor: ObjectType instance = (ObjectType)System.ComponentModel.TypeDescriptor.CreateInstance( provider: null // use standard type description provider which uses reflection objectType: objectType argTypes: new Type[] { types of args } args: new object[] { args to constructor } );  Wouldnt the generic ""new T();"" work? Actually it would in a generic class/method but not for a given ""Type"".  If this is for something that will be called a lot in an application instance it's a lot faster to compile and cache dynamic code instead of using the activator or ConstructorInfo.Invoke(). Two easy options for dynamic compilation are compiled Linq Expressions or some simple IL opcodes and DynamicMethod. Either way the difference is huge when you start getting into tight loops or multiple calls.   public AbstractType New { get { return (AbstractType) Activator.CreateInstance(GetType()); } }  tags2k: If the issue is that the class is throwing an exception on instantiation this will also be thrown when default(T) is called This is not true. default() does not call constructors it initializes to null for reference types (classes) 0 for value types (eg. ints) and initializes each member of a struct to one of null or 0 based on the same rules. You're right but I don't think commenting was available in 2008 when this answer was written :P This is more a comment than an answer. Ah ok then. I tried to remove my downvote but it won't take it. Sorry.  One implementation of this problem is to attempt to call the parameter-less constructor of the Type:  public static object GetNewObject(Type t)  {  try  {  return t.GetConstructor(new Type[] { }).Invoke(new object[] { });  }  catch  {  return null;  }  } Here is the same approach contained in a generic method:  public static T GetNewObject<T>()  {  try  {  return (T)typeof(T).GetConstructor(new Type[] { }).Invoke(new object[] { });  }  catch  {  return default(T);  }  } Exception driven programming? This seems like a very poor implementation when you can simply reflect over the type to determine constructors.",c# .net reflection
9508,A,C# 2.0 code consuming assemblies compiled with C# 3.0 This should be fine seeing as the CLR hasn't actually changed? The boxes running the C# 2.0 code have had .NET 3.5 rolled out. The background is that we have a windows service (.NET 2.0 exe built with VS2005 deployed to ~150 servers) that dynamically loads assemblies (almost like plug-ins) to complete various work items asked of it. Whenever we roll out a new version of the bus logic we just drop the assemblies on an FTP server and the windows service knows how to check for grab and store the latest versions. New assemblies are now built using VS2008 and targetting .NET 2.0 we know that works ok. However we'd like to start taking advantage of C# 3.0 language features such as LINQ and targetting the assemblies against .NET 3.5 without having to build and deploy a new version of the windows service. C#3 and .Net 3.5 adds new assemblies but the IL is unchanged. This means that with .Net 2 assemblies you can compile and use C#3 as long as you don't use Linq or anything else that references System.Linq or System.Core yield var lambda syntax anon types and initialisers are all compiler cleverness. The IL they produce is cross-compatible. If you can reference the new assemblies for 3.5 it should all just work. There is no new version of ASP.Net - it should still be 2.0.50727 - but you should still compile for 3.5  yield var lambda syntax anon types and initialisers are all compiler cleverness. The IL they produce is cross-compatible. Minor nit-picking point but yield was a 2.0 feature anyway.  This is interesting stuff. I was looking at LinqBridge yesterday after someone on this forum suggested it to me and they are doing a similar thing. I find it strange that Microsoft named the frameworks 2.0 3.0 and 3.5 when they all compile down to produce the same IL required by the 2.0 CLR. I would have thought adding versions onto 2.0 would have made more sense altho I suppose it also is hard to get people to get their head around the fact that there are different versions of runtimes compilers and languages.,c# .net .net-3.5
9304,A,"C# 3.0 auto-properties - useful or not? Note: This was posted when I was starting out C#. With 2014 knowledge I can truly say that auto-properties are among the best things that ever happened to the C# language. I am used to create my properties in C# using a private and a public field: private string title; public string Title { get { return title; } set { title = value; } } Now with .NET 3.0 we got auto-properties: public string Title { get; set; } I know this is more a philosophical/subjective questions but is there any reason to use these auto-properties except from saving five lines of code for each field? My personal gripe is that those properties are hiding stuff from me and I am not a big fan of black magic. In fact the hidden private field does not even show up in the debugger which is OK given the fact that the get/set functions do nothing. But when I want to actually implement some getter/setter logic I have to use the private/public pair anyway. I see the benefit that I save a lot of code (one vs six lines) without losing the ability to change the getter/setter logic later but then again I can already do that by simply declaring a public field ""Public string Title"" without the need of the { get; set; } block thus even saving more code. So what am I missing here? Why would anyone actually want to use auto-properties? ""My personal gripe is that those properties are hiding stuff from me and I am not a big fan of black magic."" Huh? You ARE aware that the compiler hides a ton from you all the time right? Unless you are writing assembly (or more accurately the actual 1's and 0's for your code) EVERYTHING you write is hiding stuff from you. Well with code snippets an auto-property of the same name would be seven keystrokes in total ;)  @Domenic : I don't get it.. can't you do this with auto-properties?: public string Title { get; } or public string Title { get; private set; } Is this what you are referring to? Word of caution only structs are immutable when flagged readonly classes are just unassignable. You can (the latter; the former will not compile) but then the field is not immutable inside your object.  I think any construct that is intuitive AND reduces the lines of code is a big plus. Those kinds of features are what makes languages like Ruby so powerful (that and dynamic features which also help reduce excess code). Ruby has had this all along as: attr_accessor :my_property attr_reader :my_getter attr_writer :my_setter  One thing to note here is that to my understanding this is just syntactic sugar on the C# 3.0 end meaning that the IL generated by the compiler is the same. I agree about avoiding black magic but all the same fewer lines for the same thing is usually a good thing.  I use auto-properties all the time. Before C#3 I couldn't be bothered with all the typing and just used public variables instead. The only thing I miss is being able to do this: public string Name = ""DefaultName""; You have to shift the defaults into your constructors with properties. tedious :-( ~ I know this is like a dollar late and a day short but try http://msdn.microsoft.com/en-us/library/system.componentmodel.defaultvalueattribute.aspx @Matthew Whited ~ Good call must not have noticed the glaring yellow box because I use the scriptfree it blended in but c'est la vie ... @drachenstern check out the big yellow box on that page. DefaultValueAttribute only gives you something that can be used by reflection to tell what the default value should be. It doesn't set the value for you.  From Bjarne Stroustrup creator of C++: I particularly dislike classes with a lot of get and set functions. That is often an indication that it shouldn't have been a class in the first place. It's just a data structure. And if it really is a data structure make it a data structure. An you know what? He's right. How often are you simply wrapping private fields in a get and set without actually doing anything within the get/set simply because it's the ""object oriented"" thing to do. This is Microsoft's solution to the problem; they're basically public fields that you can bind to.  We use them all the time in Stack Overflow. You may also be interested in a discussion of Properties vs. Public Variables. IMHO that's really what this is a reaction to and for that purpose it's great.  Yes it does just save code. It's miles easier to read when you have loads of them. They're quicker to write and easier to maintain. Saving code is always a good goal. You can set different scopes: public string PropertyName { get; private set; } So you don't lose any functionality. In the original posters example how do you find when myObj.Title is changing from one value to another? we may need to take this outside Keith. :) But ok assume you have many setter calls to myObj.Title...you want to see where the value changes from ""text"" to null ie a conditional breakpoint. how do u acheive that? you cant even set a breakpoint on the setter @wal - You can put a breakpoint on them just like you can access of a member variable you just can't step into them. But why would you want to? What the auto-properties actually do is both trivial and auto-generated if you've got bugs that's one place they're extremely unlikely to be. ""So you don't lose any functionality."" how do you debug them? @wal - what's there to debug? From that point of view you're basically dealing with member variables. Just wondering about the readonly ""private set"" its cool thanks.  I always create properties instead of public fields because you can use properties in an interface definition you can't use public fields in an interface definition.  Auto-properties are as much a black magic as anything else in C#. Once you think about it in terms of compiling down to IL rather than it being expanded to a normal C# property first it's a lot less black magic than a lot of other language constructs.  I use CodeRush it's faster than auto-properties. To do this:  private string title; public string Title { get { return title; } set { title = value; } } Requires eight keystrokes total. If I hold down CTRL and V I can paste lots and lots of stuff /really quickly/ but that doesn't make it 'better'. How does this answer the original question?  I personally love auto-properties. What's wrong with saving the lines of code? If you want to do stuff in getters or setters there's no problem to convert them to normal properties later on. As you said you could use fields and if you wanted to add logic to them latter you'd convert them to properties. But this might present problems with any use of reflection (and possibly elsewhere?). Also the properties allow you to set different access levels for the getter and setter which you can't do with a field. I guess it's the same as the var keyword. A matter of personal preference.  One thing nobody seems to have mentioned is how auto-properties are unfortunately not useful for immutable objects (usually immutable structs). Because for that you really should do: private readonly string title; public string Title { get { return this.title; } } (where the field is initialized in the constructor via a passed parameter and then is read only.) So this has advantages over a simple get/private set autoproperty. @Keith: Your first sentence seems factually incorrect. If you have a struct changing any property on it results in a new struct. This would only be an issue if you wanted an internally immutable reference type - I can't see a reason why you ever would need one. @Domenic: I think he's confining his definition of structs to immutable ones. Wouldn't `public string Title { get; private set; }` kind of result in exactly the same thing? You would be able to change it from inside the class then of course but if you do that you have other problems... :p The idea is defensive coding. @Domenic: No problems like working on a team where the developers do stuff they shouldn't do. Like ""hey I know this is supposed to be an immutable object but let's just mutate this one variable to get this to work""-kind of thing... I just mean that from an outside API kind of view it wouldn't make much difference. And so auto-properties could be used if wanted. Best thing would of course be if you could do something like `public string Title { get; private readonly set; }` @zooone9243 Yeah and like i said if we can't stop ourselves from setting a value inside a class that should be immutable then we have different problems. @Svish: problems like working on a team consisting of programmers of different skill levels? @Svish it is not exactly the same thing because a readonly field can only be set on construction or declaration where as a private setter can be set on non-constructor methods in the same class as well. @Svish - by that argument the readonly keyword in C# should never be used because its use would mean that we were hiding these ""different problems"" I sometimes split .NET types into 2 groups:The types that can be written in .NET (`HttpRequest` `Button`) and those that can only be written below .NET and have a .NET ""interface"" so we can use them (`object` `Thread`).One might think that `BinaryFormatter` is of the later type. Well it isn't.Anyone could rewrite it in C#.It becomes clear that readonly fields MUST be updatable at any given time because deserializing a graph would otherwise require magic since in the general case there's no certain relation between ctor params and readonly fields: `FormatterServices.PopulateObjectMembers`  In my opinion you should always use auto-properties instead of public fields. That said here's a compromise: Start off with an internal field using the naming convention you'd use for a property. When you first either need access to the field from outside its assembly or need to attach logic to a getter/setter Do this: rename the field make it private add a public property Your client code won't need to change. Someday though your system will grow and you'll decompose it into separate assemblies and multiple solutions. When that happens any exposed fields will come back to haunt you because as Jeff mentioned changing a public field to a public property is a breaking API change.  It's simple it's short and if you want to create a real implementation inside the property's body somewhere down the line it won't break your type's external interface. As simple as that.  My biggest gripe with auto-properties is that they are designed to save time but I often find I have to expand them into full blown properties later. What VS2008 is missing is an Explode Auto-Property refactor. The fact we have an encapsulate field refactor makes the way I work quicker to just use public fields.  The three big downsides to using fields instead of properties are: You can't databind to a field whereas you can to a property If you start off using a field you can't later (easily) change them to a property There are some attributes that you can add to a property that you can't add to a field ""If you start off using a field you can't later (easily) change them to a property"" sorry but why ? @Homam Mainly any consumer code that uses reflection on your fields would break since they would have to switch from using FieldInfo to PropertyInfo. @Homam Also changing a field to a property breaks binary compatability requiring all consumers of the field to recompile. recompilation & reflection issues aside it's very easy to encapsulate fields using Visual Studio: Ctrl-R+E will allow you to turn a field into a property with appropriate getters/setters. (or right-click the field re-factor encapsulate field).  The only problem I have with them is that they don't go far enough. The same release of the compiler that added automatic properties added partial methods. Why they didnt put the two together is beyond me. A simple ""partial On<PropertyName>Changed"" would have made these things really really useful. You can put multiple partial methods inside of another method. Creating an auto-pattern of some sort for them would be confusing.",c# .net automatic-properties
6325,A,"Why are unsigned int's not CLS compliant? Why are unsigned integers not CLS compliant? I am starting to think the type specification is just for performance and not for correctness. Part of the issue I suspect revolves around the fact that unsigned integer types in C are required to behave as members of an abstract algebraic ring rather than as numbers [meaning for example that if an unsigned 16-bit integer variable equals zero decrementing it is required to yield 65535 and if it's equal to 65535 then incrementing it is required to yield zero.] There are times when such behavior is extremely useful but numeric types exhibit such behavior may have gone against the spirit of some languages. I would conjecture that the decision to omit unsigned types probably predates the decision to support both checked and unchecked numeric contexts. Personally I wish there had been separate integer types for unsigned numbers and algebraic rings; applying a unary minus operator to unsigned 32-bit number should yield a 64-bit signed result [negating anything other than zero would yield a negative number] but applying a unary minus to a ring type should yield the additive inverse within that ring. In any case the reason unsigned integers are not CLS compliant is that Microsoft decided that languages didn't have to support unsigned integers in order to be considered ""CLS compatible"".  Unsigned integers are not CLS compliant because they're not interoperable between certain languages.  Not all languages have the concept of unsigned ints. For example VB 6 had no concept of unsigned ints which I suspect drove the decision of the designers of VB7/7.1 not to implement as well (it's implemented now in VB8). To quote: http://msdn.microsoft.com/en-us/library/12a7a7h3.aspx The CLS was designed to be large enough to include the language constructs that are commonly needed by developers yet small enough that most languages are able to support it. In addition any language construct that makes it impossible to rapidly verify the type safety of code was excluded from the CLS so that all CLS-compliant languages can produce verifiable code if they choose to do so. Update: I did wonder about this some years back and whilst I can't see why a UInt wouldn't be type safety verifiable I guess the CLS guys had to have a cut off point somewhere as to what would be the baseline minimum number of value types supported. Also when you think about the longer term where more and more languages are being ported to the CLR why force them to implement unsigned ints to gain CLS compliance if there is absolutely no concept ever? @Kevin: I just wondered about the topic. You answer seems logic. I just like to think about the topic. I think it's a shame Pascal-like types didn't make it into the CLR. But your argument about other languages: that didn't stop IronPython using strongly dynamic typing (DLR) in an stongly static typed CLR? @doekman: Whilst yes IronPython and IronRuby demonstrates that the CLR can provide a platform onto which you can build dynamically typed languages the goal of the CLS was to provide a set of standards that transcend language functionality and allow them to interoperate sucessfully and safely. I don't think what a language can do in terms of say adding DL features is directly related to the what should go into the CLS/CTS.  Unsigned int's don't gain you that much in real life however having more than 1 type of int gives you pain so a lot of languages only have singed ints. CLS compliant is aimed at allowing a class to be made use of from lots of languages… @nicodemus13 when is the last time that you saw a business admin system that had bit-wise arithmetic in its problem domain? (E.g. the sort of software that VB.NET programmers write) Anything with a checksum will use bit-wise arithmetic that's fairly common and it seems odd to me to drag every other language down because VB didn't support unsigned integers. .NET is meant to be generic as well not just for VB-writers of LOB apps. When you say '1 type of int' you don't think having byte short int long is also a pain? I don't quite see why signing is any more awkward. They're pretty-much essential if you're doing any bit-wise arithmetic.",c# .net unsigned-integer cls-compliant
14731,A,"UrlEncode through a console application? Normally I would just use: HttpContext.Current.Server.UrlEncode(""url""); But since this is a console application HttpContext.Current is always going to be null. Is there another method that does the same thing that I could use? I ran into this problem myself and rather than add the System.Web assembly to my project I wrote a class for encoding/decoding URLs (its pretty simple and I've done some testing but not a lot). I've included the source code below. Please: leave the comment at the top if you reuse this don't blame me if it breaks learn from the code. ''' <summary> ''' URL encoding class. Note: use at your own risk. ''' Written by: Ian Hopkins (http://www.lucidhelix.com) ''' Date: 2008-Dec-23 ''' </summary> Public Class UrlHelper Public Shared Function Encode(ByVal str As String) As String Dim charClass = String.Format(""0-9a-zA-Z{0}"" Regex.Escape(""-_.!~*'()"")) Dim pattern = String.Format(""[^{0}]"" charClass) Dim evaluator As New MatchEvaluator(AddressOf EncodeEvaluator) ' replace the encoded characters Return Regex.Replace(str pattern evaluator) End Function Private Shared Function EncodeEvaluator(ByVal match As Match) As String ' Replace the "" ""s with ""+""s If (match.Value = "" "") Then Return ""+"" End If Return String.Format(""%{0:X2}"" Convert.ToInt32(match.Value.Chars(0))) End Function Public Shared Function Decode(ByVal str As String) As String Dim evaluator As New MatchEvaluator(AddressOf DecodeEvaluator) ' Replace the ""+""s with "" ""s str = str.Replace(""+""c "" ""c) ' Replace the encoded characters Return Regex.Replace(str ""%[0-9a-zA-Z][0-9a-zA-Z]"" evaluator) End Function Private Shared Function DecodeEvaluator(ByVal match As Match) As String Return """" + Convert.ToChar(Integer.Parse(match.Value.Substring(1) System.Globalization.NumberStyles.HexNumber)) End Function End Class Seems to work. Thanks. downvoted... writing your own code so you can avoid a reference to a standard lib that doesn't write is ""A Bad Thing"" typically. I have to agree with Justin here  Try using the UrlEncode method in the HttpUtility class. http://msdn.microsoft.com/en-us/library/system.web.httputility.urlencode.aspx  HttpUtility.UrlEncode(""url"") in System.Web.  You'll want to use System.Web.HttpUtility.urlencode(""url"") Make sure you have system.web as one of the references in your project. I don't think it's included as a reference by default in console applications.  use the static HttpUtility.UrlEncode method.  I'm not a .NET guy but can't you use: HttpUtility.UrlEncode Method (String) Which is described here: HttpUtility.UrlEncode Method (String) on MSDN I don't want to rain on everyone's parade but the mentioned HttpUtility.UrlEncode doesn't seem to be visible even when I include ""using System.Web"". Does this actually work for someone and if so can you include the actual code? You need (must) add System.Web as a reference. Simply putting using System.Web is not enough I knew about System.Web.HttpContext but it wasn't resolving. Thanks Anjisan for pointing out that I needed to add System.Web as a reference. +1 from me! Problem is you will get something like this: The referenced assembly "".."" could not be resolved because it has a dependency on ""System.Web ..."". Two options - either change the target framework to not use the client profile or use the C# example given by t3rse elsewhere on this page. why does this have so many votes for a NOT answer?  Try this! Uri.EscapeUriString(url); No need to reference System.Web. Not sure why this was down-voted; maybe the edit fixed something? Anyhow it's a good answer. For more info see [this answer](http://stackoverflow.com/a/8451941/530545) from another similar question. Works great and you don't need to add any refference. thank you for providing an answer not a NOT answer. This is a far better answer because you don't have to import new references to the console app since the `Uri` class is in `System`.  The code from Ian Hopkins does the trick for me without having to add a reference to System.Web. Here is a port to C# for those who are not using VB.NET: /// <summary> /// URL encoding class. Note: use at your own risk. /// Written by: Ian Hopkins (http://www.lucidhelix.com) /// Date: 2008-Dec-23 /// (Ported to C# by t3rse (http://www.t3rse.com)) /// </summary> public class UrlHelper { public static string Encode(string str) { var charClass = String.Format(""0-9a-zA-Z{0}"" Regex.Escape(""-_.!~*'()"")); return Regex.Replace(str String.Format(""[^{0}]"" charClass) new MatchEvaluator(EncodeEvaluator)); } public static string EncodeEvaluator(Match match) { return (match.Value == "" "")?""+"" : String.Format(""%{0:X2}"" Convert.ToInt32(match.Value[0])); } public static string DecodeEvaluator(Match match) { return Convert.ToChar(int.Parse(match.Value.Substring(1) System.Globalization.NumberStyles.HexNumber)).ToString(); } public static string Decode(string str) { return Regex.Replace(str.Replace('+' ' ') ""%[0-9a-zA-Z][0-9a-zA-Z]"" new MatchEvaluator(DecodeEvaluator)); } } Great work both t3rse and Ian Hopkins. I ran into this issue building a wpf application. wpf uses the slimmed down 'client profile' of .net while my class library was using the full version. Only the full version of .net has access to System.Web which contains HttpUtility.UrlEncode.  Kibbee offers the real answer. Yes HttpUtility.UrlEncode is the right method to use but it will not be available by default for a console application. You must add a reference to System.Web. To do that In your solution explorer right click on references Choose ""add reference"" In the ""Add Reference"" dialog box use the .NET tab Scroll down to System.Web select that and hit ok NOW you can use the UrlEncode method. You'll still want to add using System.Web at the top of your console app or use the full namespace when calling the method System.Web.HttpUtility.UrlEncode(someString)",c# .net console
26147,A,"Is it possible to Embed Gecko or Webkit in a Windows Form just like a WebView? I'd love to know if there is such a thing as a Gecko.NET ;) I mean just like we can embed a WebView and that is an ""instance"" of IE7 inside any Windows Forms application (and tell it to navigateto(fancy_url);). I'd love to use Firefox or WebKit. Anybody tried this? UPDATE: Please bear in mind that although it is possible to embed Gecko using the mentioned controls it is still impossible to print while using Gecko. UPDATE March 2010: It’s still not possible to print natively using GeckoFX however a couple of methods exist that may be enough depending upon what you’re trying to do. See: http://geckofx.org/viewtopic.php?id=796 for more information. UPDATE October 2013: I am no longer doing Windows development so I have no interest in this but seems like the development of Gecko can be found here: https://bitbucket.org/geckofx and it seems to be recently updated. Leaving this here for future Windows devs ;) http://code.google.com/p/geckofx/ This is a nice .NET-wrapped version of Gecko Active developed project is available at: https://bitbucket.org/geckofx  I'd just like to point out to all looking to embed Gecko into their applications that the GeckoFX project appears to have been abandoned by its creators (Skybound Software). MozNET while previously based on GeckoFX sorta' picked up the ball and ran with it. It has the full ability to print do print previews and allows you to set it all up via the native Windows print dialog even - and a whole lot more.  It certainly is possible. All you need to do is register the Mozilla ActiveX control (mozctlx.dll I believe) and you can drag it onto your form as any ActiveX control. The programming interface is similar (though not identical) to the IE one and you can even use the Microsoft.MSHTML.dll managed library for control in some cases. I believe this is packaged with Firefox. If not you can get just the embeddable bits from Mozilla as well. Just do a Google search for Mozilla ActiveX control or Mozilla Embedding C# and that should take you down the right path. The answer below should be the answer. GeckoFX is an updated .NET wrapper the ActiveX control has not been updated since 2005.  As of October 30 2011 there is new information to add since the time of the previous posts. Specifically while Skybound stopped maintaining their version there is at least one actively maintained free open-source fork available. I'm using Hindle's fork at BitBucket which by virtue of his tool which parses XpCom idls and creates c# wrappers is rapidly updated with support for each new version of Firefox/Gecko. See this post for an overview of other choices.  GeckoFX is no longer being updated. The alternative is the MozNet XulRunner wrapper by Se7en Soft. MozNet has a ton of features that GeckoFX doesn't and is being actively updated and maintained. MozNet's EULA contradicts LGPL making it illegal. Don't use it. worse than that there is now no longer a free demo. It's unlikely one is going to purchase an alternative to an IE plugin component they can verify that it's capable of performing whatever task you weren't able to accomplish with the IE component Active developed project of GeckoFX is available at: https://bitbucket.org/geckofx  OpenWebKitSharp is a wrapper arount the WebKit engine (nightly) and is very advanced. Take a look at here (OpenWebKitSharp section): http://code.google.com/p/open-webkit-sharp/ By far the best WebBrowser Control for non-IE needs for .Net OpenWebkitSharp was disabandoned and is therefore useless. Existing errors are not fixed anymore and one can not live with them.  @Martin: Yes the Adam Locke version is outdated. But that's because a separate distribution is not necessary. It's built with the rest of the Mozilla codebase now. If you download Prism (ie XulRunner) that will give you a base that you can customize to your needs and this includes the most recent version of the control (in the \Prism\xulrunner directory you'll find mozctlx.dll). @Greg: Actually it is an ActiveX control. Incidentally all ActiveX controls are COM controls. ActiveX is built on COM. I want to transfer winform data to Firefox browser. It can be possible through OpenWebKitSharp class Library also can it works for FF 26.0 version  I Belive ""Gecko FX""[1] is the thing you need. To Quote from the web site """""" GeckoFX is a Windows Forms control written in clean commented C# that embeds the Mozilla Gecko browser control in any Windows Forms Application. It also contains a simple class model providing access to the HTML and CSS DOM. """""" 1) I can't post a link as ""new users aren't allowed to add hyperlinks"" Search for ""geckofx"" on google code. The link is at http://code.google.com/p/geckofx/ Active developed vesrion of GeckoFX is available at: https://bitbucket.org/geckofx  Additionally if you find yourself using Gtk instead of Windows.Forms there is a tarball of webkit-sharp available that allows for easy embedding of WebViews into Gtk# applications.",c# .net winforms webkit gecko
709,A,".NET Testing Framework Advice I'm looking to introduce a unit testing framework into the mix at my job. We're using Visual Studio 2005 (though we may be moving to 2008 within the next 6 months) and work primarily in C#. If the framework has some kind of IDE integration that would be best but I'm open to frameworks that don't have integration but are still relatively simple to get set up. I'm going to get resistance to it one way or another so if I can make sure what I'm pushing isn't a pain in the neck that would help my case. The obvious choice from the research I've done so far points to nUnit but I'd like to get the impressions of someone who's actually used it before recommending it to my team. Has anyone out there used nUnit? If so are there any pitfalls or limitations of which I should be aware? Are there other good options out there? If so if you've used both nUnit at that I'd greatly appreciate an idea of the strengths and weaknesses of them. 2008. Facepalm. You should be using 2010 if your upgrading Try also PEX tool It Microsoft's own probably soon to be integrated into VSTS and does support NUnit  MbUnit and xUnit.net I use also small Console Application for testing one class or small library. You could copy paste the code from here  We've been using xUnit.net. It seems to combine all the best of nUnit mbUnit and MSTest. I majorly regret the wasted time not having tried it before I switched.  The built in unit testing in VS 2008 is alright but its difficult to integrate with CruiseControl.net certainly a lot harder than normal NUnit. So go with NUnit if you plan to have nice automated tests.  mbUnit is worth alook it has a set of features comparable to NUnit it has its own GUI or can be integrated into VS if you have Resharper. I would also recommend Rhino Mocks if you are doing any sort of TDD.  Scott Hanselman had a good Podcast about this entitled: ""The Past Present and Future of .NET Unit Testing Frameworks"" : Hanselminutes #112 That is was a money podcast. It highlights all the major unit test frameworks. I personally started using xUnit because of what I heard on this pod cast.  I think NUnit is your best bet. With TestDriven.NET you get great integration within VS.NET. (Resharper also has a unit test runner if you're using it). NUnit it simple to use and follows an established paradigm. You'll also find plenty of projects/tutorials/guides using it which always helps. Your other main choice is probably MBUnit which is more and more position itself as the BDD framework of choice (in conjunction with Gallio http://www.gallio.org).  Visual Studio 2008 has a built in test project type that works in a similar way to NUnit but obviously has much tighter integration with Visual Studio (can run on every build and shows the results in a similar way to the conversion results page when upgrading solution files) but it is obviously not as mature as NUnit as it's pretty new and I'm not sure about how it handles mocking. But it would be worth looking into when your team moves to VS2008  I would say mbUnit also I like being able to run a single test many times just by specifying inputs and result right above the test function. Horrible description of what I mean so here is a link that shows you what I mean.  VSTT 2010 should be a good bet if you are looking for functional test automation. Web Services Testing UI testing Biztalk testing and Data Driven Testing Support. Please look at VSTT  When I started unit testing I started with NUnit as it is simple to set up and use currently I am using the built in test runner that comes with Resharper that way I can easily flip between code and test results. Incidently NUnit detects when you have compiled your code so you do not need to do any refresh in NUnit. Resharper automatically does a build when you choose to run a specific test.",c# .net visual-studio unit-testing
25349,A,"What would be the fastest way to remove Newlines from a String in C#? I have a string that has some Environment.Newline in it. I'd like to strip those from the string and instead replace the Newline with something like a comma. What would be in your opinion the best way to do this using C#.NET 2.0? Thanks in advance. Why not: string s = ""foobar\ngork""; string v = s.Replace(Environment.NewLine""""); System.Console.WriteLine(v);  Like this: string s = ""hello\nworld""; s = s.Replace(Environment.NewLine """");  Don't reinvent the wheel - just use myString.Replace(Environment.NewLine """")  The best way is the builtin way: Use string.Replace. Why do you need alternatives?  string sample = ""abc"" + Environment.NewLine + ""def""; string replaced = sample.Replace(Environment.NewLine """");",c# .net string replace
19147,A,"What is the correct way to create a single instance application? Using C# and WPF under .net (rather than WindowsForms or console) what is the correct way to create an application that can only be run as a single instance? I know it has something to do with some mythical thing called a mutex rarely can I find someone that bothers to stop and explain what one of these are. The code needs to also inform the already running instance that the user tried to start a second one and maybe also pass any command line arguments if any existed. @San Saffron - Do you have an answer that does? Doesn't the CLR automatically release any unreleased mutexes when the application terminates anyway? @Cocowalla: the finalizer should dispose the unmanaged mutexes unless it can't know if the mutex was created by the managed app or attached to an existing one. Having only one instance of your app is reasonable. But passing arguments to an already existing app appears to me a bit silly. I can't see any reason to do so. If you associate an app with file extension you should open as many app as user want to open documents. That's the standard behavior which every users would expect. Just want to make correction about my previous state. Passing arguments to an existing app means that you want to do an MDI (multi document interface). I thought that MDI was a way that Microsoft was pushing out (Word and Excel are now SDI). But I realize that Chrome and IE are both MDI. Perharps we are in years where MDI is back ??? (But I still prefer SDI over MDI) @Cocowalla The CLR does not manage native resources. However if a process terminates all handles are freed by the system (the OS not the CLR). I prefer the answer by @huseyint. It uses Microsoft's own 'SingleInstance.cs' class so you don't have to worry about Mutexes and IntPtrs. Also no dependency on VisualBasic (yuk). See http://codereview.stackexchange.com/questions/20871/wpf-single-instance-best-practices/25667#25667 for more... You should never use a named mutex to implement a single instance application (or at least not for production code). Malicious code can easily DOS(Denial of Service) your ass... ""You should never use a named mutex"" - never say never. If malicious code is running on my machine I'm probably already hosed. Actually it doesn't even have to be malicious code. It could just be a accidental name collision. Then what should you do? The better question is what possible reason would you want that behavior. Don't design your app as a single instance application=). I know that's a lame answer but from a design standpoint it is almost always the correct answer. Without knowing more about the app its hard to say much more. At least under Windows Mutexes have access control so one one can toy with your object. As to name collisions themselves that's why UUID/GUID's where invented.  Well I have a disposable Class for this that works easily for most use cases: Use it like this: static void Main() { using (SingleInstanceMutex sim = new SingleInstanceMutex()) { if (sim.IsOtherInstanceRunning) { Application.Exit(); } // Initialize program here. } } Here it is: /// <summary> /// Represents a <see cref=""SingleInstanceMutex""/> class. /// </summary> public partial class SingleInstanceMutex { #region Fields /// <summary> /// Indicator whether another instance of this application is running or not. /// </summary> private bool isNoOtherInstanceRunning; /// <summary> /// The <see cref=""Mutex""/> used to ask for other instances of this application. /// </summary> private Mutex singleInstanceMutex = null; /// <summary> /// An indicator whether this object is beeing actively disposed or not. /// </summary> private bool disposed; #endregion #region Constructor /// <summary> /// Initializes a new instance of the <see cref=""SingleInstanceMutex""/> class. /// </summary> public SingleInstanceMutex() { this.singleInstanceMutex = new Mutex(true Assembly.GetCallingAssembly().FullName out this.isNoOtherInstanceRunning); } #endregion #region Properties /// <summary> /// Gets an indicator whether another instance of the application is running or not. /// </summary> public bool IsOtherInstanceRunning { get { return !this.isNoOtherInstanceRunning; } } #endregion #region Methods /// <summary> /// Closes the <see cref=""SingleInstanceMutex""/>. /// </summary> public void Close() { this.ThrowIfDisposed(); this.singleInstanceMutex.Close(); } public void Dispose() { this.Dispose(true); GC.SuppressFinalize(this); } private void Dispose(bool disposing) { if (!this.disposed) { /* Release unmanaged ressources */ if (disposing) { /* Release managed ressources */ this.Close(); } this.disposed = true; } } /// <summary> /// Throws an exception if something is tried to be done with an already disposed object. /// </summary> /// <remarks> /// All public methods of the class must first call this. /// </remarks> public void ThrowIfDisposed() { if (this.disposed) { throw new ObjectDisposedException(this.GetType().Name); } } #endregion } this one was pretty easy to get working. It would not close the second application until I changed Application.Exit(); to a simple return; but other than that its great. Although i admit I am going to look at the previous solution closer since it uses an interface. http://blogs.microsoft.co.il/blogs/arik/archive/2010/05/28/wpf-single-instance-application.aspx  From here. A common use for a cross-process Mutex is to ensure that only instance of a program can run at a time. Here's how it's done: class OneAtATimePlease { // Use a name unique to the application (eg include your company URL) static Mutex mutex = new Mutex (false ""oreilly.com OneAtATimeDemo""); static void Main() { // Wait 5 seconds if contended – in case another instance // of the program is in the process of shutting down. if (!mutex.WaitOne(TimeSpan.FromSeconds (5) false)) { Console.WriteLine(""Another instance of the app is running. Bye!""); return; } try { Console.WriteLine(""Running - press Enter to exit""); Console.ReadLine(); } finally { mutex.ReleaseMutex(); } } } A good feature of Mutex is that if the application terminates without ReleaseMutex first being called the CLR will release the Mutex automatically. I've got to say I like this answer a lot more than the accepted one simply due to the fact that it isn't dependent on WinForms. Personally most of my development has been moving to WPF and I don't want to have to pull in WinForm libraries for something like this. Of course to be a full answer you have to also describe passing the arguments to the other instance :) @EricOuellet: The problems with MDI were probably far more about having windows within windows than tabs being confusing and there's a strong push to all tabs being pulled out into their own top-level window mitigating it. These are all UI concerns though which shouldn't have any connection to how you split up your processes (multiple processes can be contained in the same window and vice-versa). @Simon you are right. I just question myself about a very old thing... MDI vs SDI (Multi documentinterface vs Single document interface). When you talk about tabs you refer to MDI. In 1998 a Microsoft book suggests to eliminate every MDI app. Microsoft switched Word Excel... to SDI which I think it is simplier and better. I understand that Chrome and others (now IE) want back to MDI. I personnaly (based on nothing / personal feelings) that it is still better to open a new app when file assoc is selected. But I understand better the question asked now. Thanks ! @Jason good thanks! But I prefer not passing any timeout. It is so much subjective and depends on so many variables. If you ever want to enable another app to start just release your mutex quicker.. for example as soon as the user confirm close @EricOuellet: Just about every program that has tabs does this - Photoshop Sublime Text Chrome .... If you have a good reason to have a ""master"" process (say you have a in-proc DB for settings) you might want to have it show UI as if it were a new process too.  A good solution by WPF disciple Daniel Vaughan using memory mapped files for IPC is here: http://danielvaughan.org/post/Enforcing-Single-Instance-WPF-Applications.aspx  So many answers to such a seemingly simple question. Just to shake things up a little bit here is my solution to this problem. Creating a Mutex can be troublesome because the JIT-er only sees you using it for a small portion of your code and wants to mark it as ready for garbage collection. It pretty much wants to out-smart you thinking you are not going to be using that Mutex for that long. In reality you want to hang onto this Mutex for as long as your application is running. The best way to tell the garbage collector to leave you Mutex alone is to tell it to keep it alive though out the different generations of garage collection. Example: var m = new Mutex(...); ... GC.KeepAlive(m); I lifted the idea from this page: http://www.ai.uga.edu/~mc/SingleInstance.html Wouldn't it be easier to store a shared copy of it in the application class?  Here's a lightweight solution I use which allows the application to bring an already existing window to the foreground without resorting to custom windows messages or blindly searching process names. [DllImport(""user32.dll"")] static extern bool SetForegroundWindow(IntPtr hWnd); static readonly string guid = ""<Application Guid>""; static void Main() { Mutex mutex = null; if (!CreateMutex(out mutex)) return; // Application startup code. Environment.SetEnvironmentVariable(guid null EnvironmentVariableTarget.User); } static bool CreateMutex(out Mutex mutex) { bool createdNew = false; mutex = new Mutex(false guid out createdNew); if (createdNew) { Process process = Process.GetCurrentProcess(); string value = process.Id.ToString(); Environment.SetEnvironmentVariable(guid value EnvironmentVariableTarget.User); } else { string value = Environment.GetEnvironmentVariable(guid EnvironmentVariableTarget.User); Process process = null; int processId = -1; if (int.TryParse(value out processId)) process = Process.GetProcessById(processId); if (process == null || !SetForegroundWindow(process.MainWindowHandle)) MessageBox.Show(""Unable to start application. An instance of this application is already running.""); } return createdNew; } Edit: You can also store and initialize mutex and createdNew statically but you'll need to explicitly dispose/release the mutex once you're done with it. Personally I prefer keeping the mutex local as it will be automatically disposed of even if the application closes without ever reaching the end of Main.  Here is a very good article regarding the Mutex solution. The approach described by the article is advantageous for two reasons. First it does not require a dependency on the Microsoft.VisualBasic assembly. If my project already had a dependency on that assembly I would probably advocate using the approach shown in the accepted answer. But as it is I do not use the Microsoft.VisualBasic assembly and I'd rather not add an unnecessary dependency to my project. Second the article shows how to bring the existing instance of the application to the foreground when the user tries to start another instance. That's a very nice touch that the other Mutex solutions described here do not address. UPDATE As of 8/1/2014 the article I linked to above is still active but the blog hasn't been updated in a while. That makes me worry that eventually it might disappear and with it the advocated solution. I'm reproducing the content of the article here for posterity. The words belong solely to the blog owner at Sanity Free Coding. Today I wanted to refactor some code that prohibited my application from running multiple instances of itself. Previously I had use System.Diagnostics.Process to search for an instance of my myapp.exe in the process list. While this works it brings on a lot of overhead and I wanted something cleaner. Knowing that I could use a mutex for this (but never having done it before) I set out to cut down my code and simplify my life. In the class of my application main I created a static named Mutex: static class Program { static Mutex mutex = new Mutex(true ""{8F6F0AC4-B9A1-45fd-A8CF-72F04E6BDE8F}""); [STAThread] ... } Having a named mutex allows us to stack synchronization across multiple threads and processes which is just the magic I'm looking for. Mutex.WaitOne has an overload that specifies an amount of time for us to wait. Since we're not actually wanting to synchronizing our code (more just check if it is currently in use) we use the overload with two parameters: Mutex.WaitOne(Timespan timeout bool exitContext). Wait one returns true if it is able to enter and false if it wasn't. In this case we don't want to wait at all; If our mutex is being used skip it and move on so we pass in TimeSpan.Zero (wait 0 milliseconds) and set the exitContext to true so we can exit the synchronization context before we try to aquire a lock on it. Using this we wrap our Application.Run code inside something like this: static class Program { static Mutex mutex = new Mutex(true ""{8F6F0AC4-B9A1-45fd-A8CF-72F04E6BDE8F}""); [STAThread] static void Main() { if(mutex.WaitOne(TimeSpan.Zero true)) { Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); Application.Run(new Form1()); mutex.ReleaseMutex(); } else { MessageBox.Show(""only one instance at a time""); } } } So if our app is running WaitOne will return false and we'll get a message box. Instead of showing a message box I opted to utilize a little Win32 to notify my running instance that someone forgot that it was already running (by bringing itself to the top of all the other windows). To achieve this I used PostMessage to broadcast a custom message to every window (the custom message was registered with RegisterWindowMessage by my running application which means only my application knows what it is) then my second instance exits. The running application instance would receive that notification and process it. In order to do that I overrode WndProc in my main form and listened for my custom notification. When I received that notification I set the form's TopMost property to true to bring it up on top. Here is what I ended up with: Program.cs static class Program { static Mutex mutex = new Mutex(true ""{8F6F0AC4-B9A1-45fd-A8CF-72F04E6BDE8F}""); [STAThread] static void Main() { if(mutex.WaitOne(TimeSpan.Zero true)) { Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); Application.Run(new Form1()); mutex.ReleaseMutex(); } else { // send our Win32 message to make the currently running instance // jump on top of all the other windows NativeMethods.PostMessage( (IntPtr)NativeMethods.HWND_BROADCAST NativeMethods.WM_SHOWME IntPtr.Zero IntPtr.Zero); } } } NativeMethods.cs // this class just wraps some Win32 stuff that we're going to use internal class NativeMethods { public const int HWND_BROADCAST = 0xffff; public static readonly int WM_SHOWME = RegisterWindowMessage(""WM_SHOWME""); [DllImport(""user32"")] public static extern bool PostMessage(IntPtr hwnd int msg IntPtr wparam IntPtr lparam); [DllImport(""user32"")] public static extern int RegisterWindowMessage(string message); } Form1.cs (front side partial) public partial class Form1 : Form { public Form1() { InitializeComponent(); } protected override void WndProc(ref Message m) { if(m.Msg == NativeMethods.WM_SHOWME) { ShowMe(); } base.WndProc(ref m); } private void ShowMe() { if(WindowState == FormWindowState.Minimized) { WindowState = FormWindowState.Normal; } // get our current ""TopMost"" value (ours will always be false though) bool top = TopMost; // make our form jump to the top of everything TopMost = true; // set it back to whatever it was TopMost = top; } } On the basis that this answer uses less code and less libraries and provides the raise to top functionality I'm going to make this the new accepted answer. If anyone knows a more correct way to bring the form to the top using API's feel free to add that. That's a nice little example - works beautifully in my application. Add it's simple to implement. Not sure I understand - why use Native Messages? That's what events are for... (if it's for the decoupling you should really be using cab or [EventBroker](http://www.codeproject.com/KB/dotnet/EventBroker.aspx)...) @BlueRaja you start up the first app instance. When you start up the second app instance it detects that another instance is already running and prepares to shutdown. Before doing so it sends a ""SHOWME"" native message to the first instance which brings the first instance to the top. Events in .NET don't allow cross-process communication which is why the native message is used. @Matt: Ah I understand. Thank you. Is there a way to pass the command lines from the other instance maybe? @matt david - don't worry about 'shipping' Microsoft.VisualBasic - it is already in the GAC. http://stackoverflow.com/questions/226517/is-the-microsoft-visualbasic-namespace-true-net-code @Simon_Weaver the issue is not whether it is in the GAC or not but the fact that it is delivered with the .NET Framework. I was not aware of that. Thanks for the link. @matt - i just wish they'd named the damn thing something else! i've just started using that component myself and it works quite well (my users will never know i stooped so low as to include a VB namespace - heh). its very convenient to be able to pass parameters and/or have the dormant application bring itself to the front without having to mess with any communication code yourself @Matt: How can we choose the name for the Mutex? In the sample it is `{8F6F0AC4-B9A1-45fd-A8CF-72F04E6BDE8F}` Where is it from :) ? @Nam the `Mutex` constructor simply requires a string so you could supply any string name you want e.g. ""This Is My Mutex"". Because a 'Mutex' is a system object that is available to other processes you typically want the name to be unique so it doesn't clash with other 'Mutex' names on the same system. In the article the cryptic-looking string is a 'Guid'. You can generate this programmatically by calling `System.Guid.NewGuid()`. In the case of the article the user probably generated it via Visual Studio as shown here: http://msdn.microsoft.com/en-us/library/ms241442(VS.80).aspx @Matt Davis you CANNOT use System.Guid.NewGuid() because each time you get different GUID and in effect each instance of your program will claim it is single instance. You have to use some token common to ALL instances defined at compile time. VS generated GUID is the way. @macias I never said that you would call `System.Guid.NewGuid()` and then pass the result to the Mutex. That would obviously be wrong as you have deftly pointed out. The question was where the string came from. I was simply saying that a GUID could be generated programmatically or using Visual Studio. Following the article worked like a charm for my WinForms application as well. Thanks! Does the mutex approach assume that the same user is attempting to start the application again? Certainly bringing ""the existing instance of the application to the foreground"" does not make sense after a 'switch user' article link broken. @Joshua no it's still there; just tried it. If you're attempting to access it at work it's very possible that your company's firewall is preventing access. @MattDavis Hmm it does show up now. My bad. The question asked for an approach for WPF not WinForms as the answer proposes. I used [this answer](http://stackoverflow.com/a/5484315/433718) for a WPF application. It's also posted as answer here: http://stackoverflow.com/a/2932076/433718 @OneWorld this solution is agnostic to the UI framework. The example shows how to do it using WinForms but it'd be just as easy to use in WPF. The solution you posted uses .NET Remoting a legacy technology that Microsoft retains for backward compatibility only. That's hardly a solution I would endorse. http://msdn.microsoft.com/en-us/library/kwdt6w2k(v=vs.100).aspx @MattDavis Didn't know about that. Good that we clarified that. The autor Arik Poznanski seemed to express high confidence that his approach has done it right. And several people said this is a ""novice"" approach since it was from 2010. I did not use your solution because I could not find a method `protected override void WndProc(ref Message m)` @OneWorld see the answers here. http://stackoverflow.com/questions/624367/how-to-handle-wndproc-messages-in-wpf  Here is an example that allows you to have a single instance of an application. When any new instances load they pass their arguments to the main instance that is running. public partial class App : Application { private static Mutex SingleMutex; public static uint MessageId; private void Application_Startup(object sender StartupEventArgs e) { IntPtr Result; IntPtr SendOk; Win32.COPYDATASTRUCT CopyData; string[] Args; IntPtr CopyDataMem; bool AllowMultipleInstances = false; Args = Environment.GetCommandLineArgs(); // TODO: Replace {00000000-0000-0000-0000-000000000000} with your application's GUID MessageId = Win32.RegisterWindowMessage(""{00000000-0000-0000-0000-000000000000}""); SingleMutex = new Mutex(false ""AppName""); if ((AllowMultipleInstances) || (!AllowMultipleInstances &amp;&amp; SingleMutex.WaitOne(1 true))) { new Main(); } else if (Args.Length > 1) { foreach (Process Proc in Process.GetProcesses()) { SendOk = Win32.SendMessageTimeout(Proc.MainWindowHandle MessageId IntPtr.Zero IntPtr.Zero Win32.SendMessageTimeoutFlags.SMTO_BLOCK | Win32.SendMessageTimeoutFlags.SMTO_ABORTIFHUNG 2000 out Result); if (SendOk == IntPtr.Zero) continue; if ((uint)Result != MessageId) continue; CopyDataMem = Marshal.AllocHGlobal(Marshal.SizeOf(typeof(Win32.COPYDATASTRUCT))); CopyData.dwData = IntPtr.Zero; CopyData.cbData = Args[1].Length*2; CopyData.lpData = Marshal.StringToHGlobalUni(Args[1]); Marshal.StructureToPtr(CopyData CopyDataMem false); Win32.SendMessageTimeout(Proc.MainWindowHandle Win32.WM_COPYDATA IntPtr.Zero CopyDataMem Win32.SendMessageTimeoutFlags.SMTO_BLOCK | Win32.SendMessageTimeoutFlags.SMTO_ABORTIFHUNG 5000 out Result); Marshal.FreeHGlobal(CopyData.lpData); Marshal.FreeHGlobal(CopyDataMem); } Shutdown(0); } } } public partial class Main : Window { private void Window_Loaded(object sender RoutedEventArgs e) { HwndSource Source; Source = HwndSource.FromHwnd(new WindowInteropHelper(this).Handle); Source.AddHook(new HwndSourceHook(Window_Proc)); } private IntPtr Window_Proc(IntPtr hWnd int Msg IntPtr wParam IntPtr lParam ref bool Handled) { Win32.COPYDATASTRUCT CopyData; string Path; if (Msg == Win32.WM_COPYDATA) { CopyData = (Win32.COPYDATASTRUCT)Marshal.PtrToStructure(lParam typeof(Win32.COPYDATASTRUCT)); Path = Marshal.PtrToStringUni(CopyData.lpData CopyData.cbData / 2); if (WindowState == WindowState.Minimized) { // Restore window from tray } // Do whatever we want with information Activate(); Focus(); } if (Msg == App.MessageId) { Handled = true; return new IntPtr(App.MessageId); } return IntPtr.Zero; } } public class Win32 { public const uint WM_COPYDATA = 0x004A; public struct COPYDATASTRUCT { public IntPtr dwData; public int cbData; public IntPtr lpData; } [Flags] public enum SendMessageTimeoutFlags : uint { SMTO_NORMAL = 0x0000 SMTO_BLOCK = 0x0001 SMTO_ABORTIFHUNG = 0x0002 SMTO_NOTIMEOUTIFNOTHUNG = 0x0008 } [DllImport(""user32.dll"" SetLastError=true CharSet=CharSet.Auto)] public static extern uint RegisterWindowMessage(string lpString); [DllImport(""user32.dll"")] public static extern IntPtr SendMessageTimeout(IntPtr hWnd uint Msg IntPtr wParam IntPtr lParam SendMessageTimeoutFlags fuFlags uint uTimeout out IntPtr lpdwResult); } Please don't crucify me if this is too much code. This is a really nice example of what I what to do. Nathan are all the args sent using this method? I have 7 or so in my app and i *think* that this code will work. In my example only the first argument is sent but it can be changed so that all of them are sent.  Use mutex solution: using System; using System.Windows.Forms; using System.Threading; namespace OneAndOnlyOne { static class Program { static String _mutexID = "" // generate guid"" /// <summary> /// The main entry point for the application. /// </summary> [STAThread] static void Main() { Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); Boolean _isNotRunning; using (Mutex _mutex = new Mutex(true _mutexID out _isNotRunning)) { if (_isNotRunning) { Application.Run(new Form1()); } else { MessageBox.Show(""An instance is already running.""); return; } } } } }  Just some thoughts: There are cases when requiring that only one instance of an application is not ""lame"" as some would have you believe. Database apps etc. are an order of magnitude more difficult if one allows multiple instances of the app for a single user to access a database (you know all that updating all the records that are open in multiple instances of the app on the users machine etc.). First for the ""name collision thing don't use a human readable name - use a GUID instead or even better a GUID + the human readable name. Chances of name collision just dropped off the radar and the Mutex doesn't care. As someone pointed out a DOS attack would suck but if the malicious person has gone to the trouble of getting the mutex name and incorporating it into their app you are pretty much a target anyway and will have to do MUCH more to protect yourself than just fiddle a mutex name. Also if one uses the variant of: new Mutex(true ""some GUID plus Name"" out AIsFirstInstance) you already have your indicator as to whether or not the Mutex is the first instance.  See my solution for this problem... Very interesting solution. Sadly the comments seems to be a bit neglected? i agree - interesting solution  Here is what I use. It combined process enumeration to perform switching and mutex to safeguard from ""active clickers"": public partial class App { [DllImport(""user32"")] private static extern int OpenIcon(IntPtr hWnd); [DllImport(""user32.dll"")] private static extern bool SetForegroundWindow(IntPtr hWnd); protected override void OnStartup(StartupEventArgs e) { base.OnStartup(e); var p = Process .GetProcessesByName(Process.GetCurrentProcess().ProcessName); foreach (var t in p.Where(t => t.MainWindowHandle != IntPtr.Zero)) { OpenIcon(t.MainWindowHandle); SetForegroundWindow(t.MainWindowHandle); Current.Shutdown(); return; } // there is a chance the user tries to click on the icon repeatedly // and the process cannot be discovered yet bool createdNew; var mutex = new Mutex(true ""MyAwesomeApp"" out createdNew); // must be a variable though it is unused - // we just need a bit of time until the process shows up if (!createdNew) { Current.Shutdown(); return; } new Bootstrapper().Run(); } }  Here is a new one that uses Mutex and IPC stuff and also passes any command line args to the running instance: http://blogs.microsoft.co.il/blogs/arik/archive/2010/05/28/wpf-single-instance-application.aspx +1 Comparing all the different solutions I'm going to give this a try. Sounds promising. I use this with great success. If you incorporate NamedPipes with this you can also pass command-line arguments to the original application. The class 'SingleInstance.cs' was written by Microsoft. I have added another link to a more readable version of Arik Poznanski's blog on CodeProject.  The code C# .NET Single Instance Application that is the reference for the marked answer is a great start. However I found it doesn't handle very well the cases when the instance that already exist has a modal dialog open whether that dialog is a managed one (like another Form such as an about box) or an unmanaged one (like the OpenFileDialog even when using the standard .NET class). With the original code the main form is activated but the modal one stays unactive which looks strange plus the user must click on it to keep using the app. So I have create a SingleInstance utility class to handle all this quite automatically for Winforms and WPF applications. Winforms: 1) modify the Program class like this: static class Program { public static readonly SingleInstance Singleton = new SingleInstance(typeof(Program).FullName); [STAThread] static void Main(string[] args) { // NOTE: if this always return false close & restart Visual Studio // this is probably due to the vshost.exe thing Singleton.RunFirstInstance(() => { SingleInstanceMain(args); }); } public static void SingleInstanceMain(string[] args) { // standard code that was in Main now goes here Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); Application.Run(new Form1()); } } 2) modify the main window class like this: public partial class Form1 : Form { public Form1() { InitializeComponent(); } protected override void WndProc(ref Message m) { // if needed the singleton will restore this window Program.Singleton.OnWndProc(this m true); // TODO: handle specific messages here if needed base.WndProc(ref m); } } WPF: 1) modify the App page like this (and make sure you set its build action to page to be able to redefine the Main method): public partial class App : Application { public static readonly SingleInstance Singleton = new SingleInstance(typeof(App).FullName); [STAThread] public static void Main(string[] args) { // NOTE: if this always return false close & restart Visual Studio // this is probably due to the vshost.exe thing Singleton.RunFirstInstance(() => { SingleInstanceMain(args); }); } public static void SingleInstanceMain(string[] args) { // standard code that was in Main now goes here App app = new App(); app.InitializeComponent(); app.Run(); } } 2) modify the main window class like this: public partial class MainWindow : Window { private HwndSource _source; public MainWindow() { InitializeComponent(); } protected override void OnSourceInitialized(EventArgs e) { base.OnSourceInitialized(e); _source = (HwndSource)PresentationSource.FromVisual(this); _source.AddHook(HwndSourceHook); } protected virtual IntPtr HwndSourceHook(IntPtr hwnd int msg IntPtr wParam IntPtr lParam ref bool handled) { // if needed the singleton will restore this window App.Singleton.OnWndProc(hwnd msg wParam lParam true true); // TODO: handle other specific message return IntPtr.Zero; } And here is the utility class: using System; using System.ComponentModel; using System.Runtime.InteropServices; using System.Threading; namespace SingleInstanceUtilities { public sealed class SingleInstance { private const int HWND_BROADCAST = 0xFFFF; [DllImport(""user32.dll"")] private static extern bool PostMessage(IntPtr hwnd int msg IntPtr wparam IntPtr lparam); [DllImport(""user32.dll"" CharSet = CharSet.Unicode)] private static extern int RegisterWindowMessage(string message); [DllImport(""user32.dll"")] private static extern bool SetForegroundWindow(IntPtr hWnd); public SingleInstance(string uniqueName) { if (uniqueName == null) throw new ArgumentNullException(""uniqueName""); Mutex = new Mutex(true uniqueName); Message = RegisterWindowMessage(""WM_"" + uniqueName); } public Mutex Mutex { get; private set; } public int Message { get; private set; } public void RunFirstInstance(Action action) { RunFirstInstance(action IntPtr.Zero IntPtr.Zero); } // NOTE: if this always return false close & restart Visual Studio // this is probably due to the vshost.exe thing public void RunFirstInstance(Action action IntPtr wParam IntPtr lParam) { if (action == null) throw new ArgumentNullException(""action""); if (WaitForMutext(wParam lParam)) { action(); ReleaseMutex(); } } public static void ActivateWindow(IntPtr hwnd) { if (hwnd == IntPtr.Zero) return; FormUtilities.ActivateWindow(FormUtilities.GetModalWindow(hwnd)); } public void OnWndProc(IntPtr hwnd int m IntPtr wParam IntPtr lParam bool restorePlacement bool activate) { if (m == Message) { if (restorePlacement) { WindowPlacement placement = WindowPlacement.GetPlacement(hwnd false); if (placement.IsValid && placement.IsMinimized) { const int SW_SHOWNORMAL = 1; placement.ShowCmd = SW_SHOWNORMAL; placement.SetPlacement(hwnd); } } if (activate) { SetForegroundWindow(hwnd); FormUtilities.ActivateWindow(FormUtilities.GetModalWindow(hwnd)); } } } #if WINFORMS // define this for Winforms apps public void OnWndProc(System.Windows.Forms.Form form int m IntPtr wParam IntPtr lParam bool activate) { if (form == null) throw new ArgumentNullException(""form""); if (m == Message) { if (activate) { if (form.WindowState == System.Windows.Forms.FormWindowState.Minimized) { form.WindowState = System.Windows.Forms.FormWindowState.Normal; } form.Activate(); FormUtilities.ActivateWindow(FormUtilities.GetModalWindow(form.Handle)); } } } public void OnWndProc(System.Windows.Forms.Form form System.Windows.Forms.Message m bool activate) { if (form == null) throw new ArgumentNullException(""form""); OnWndProc(form m.Msg m.WParam m.LParam activate); } #endif public void ReleaseMutex() { Mutex.ReleaseMutex(); } public bool WaitForMutext(bool force IntPtr wParam IntPtr lParam) { bool b = PrivateWaitForMutext(force); if (!b) { PostMessage((IntPtr)HWND_BROADCAST Message wParam lParam); } return b; } public bool WaitForMutext(IntPtr wParam IntPtr lParam) { return WaitForMutext(false wParam lParam); } private bool PrivateWaitForMutext(bool force) { if (force) return true; try { return Mutex.WaitOne(TimeSpan.Zero true); } catch (AbandonedMutexException) { return true; } } } // NOTE: don't add any field or public get/set property as this must exactly map to Windows' WINDOWPLACEMENT structure [StructLayout(LayoutKind.Sequential)] public struct WindowPlacement { public int Length { get; set; } public int Flags { get; set; } public int ShowCmd { get; set; } public int MinPositionX { get; set; } public int MinPositionY { get; set; } public int MaxPositionX { get; set; } public int MaxPositionY { get; set; } public int NormalPositionLeft { get; set; } public int NormalPositionTop { get; set; } public int NormalPositionRight { get; set; } public int NormalPositionBottom { get; set; } [DllImport(""user32.dll"" SetLastError = true)] private static extern bool SetWindowPlacement(IntPtr hWnd ref WindowPlacement lpwndpl); [DllImport(""user32.dll"" SetLastError = true)] private static extern bool GetWindowPlacement(IntPtr hWnd ref WindowPlacement lpwndpl); private const int SW_SHOWMINIMIZED = 2; public bool IsMinimized { get { return ShowCmd == SW_SHOWMINIMIZED; } } public bool IsValid { get { return Length == Marshal.SizeOf(typeof(WindowPlacement)); } } public void SetPlacement(IntPtr windowHandle) { SetWindowPlacement(windowHandle ref this); } public static WindowPlacement GetPlacement(IntPtr windowHandle bool throwOnError) { WindowPlacement placement = new WindowPlacement(); if (windowHandle == IntPtr.Zero) return placement; placement.Length = Marshal.SizeOf(typeof(WindowPlacement)); if (!GetWindowPlacement(windowHandle ref placement)) { if (throwOnError) throw new Win32Exception(Marshal.GetLastWin32Error()); return new WindowPlacement(); } return placement; } } public static class FormUtilities { [DllImport(""user32.dll"")] private static extern IntPtr GetWindow(IntPtr hWnd int uCmd); [DllImport(""user32.dll"" SetLastError = true)] private static extern IntPtr SetActiveWindow(IntPtr hWnd); [DllImport(""user32.dll"")] private static extern bool IsWindowVisible(IntPtr hWnd); [DllImport(""kernel32.dll"")] public static extern int GetCurrentThreadId(); private delegate bool EnumChildrenCallback(IntPtr hwnd IntPtr lParam); [DllImport(""user32.dll"")] private static extern bool EnumThreadWindows(int dwThreadId EnumChildrenCallback lpEnumFunc IntPtr lParam); private class ModalWindowUtil { private const int GW_OWNER = 4; private int _maxOwnershipLevel; private IntPtr _maxOwnershipHandle; private bool EnumChildren(IntPtr hwnd IntPtr lParam) { int level = 1; if (IsWindowVisible(hwnd) && IsOwned(lParam hwnd ref level)) { if (level > _maxOwnershipLevel) { _maxOwnershipHandle = hwnd; _maxOwnershipLevel = level; } } return true; } private static bool IsOwned(IntPtr owner IntPtr hwnd ref int level) { IntPtr o = GetWindow(hwnd GW_OWNER); if (o == IntPtr.Zero) return false; if (o == owner) return true; level++; return IsOwned(owner o ref level); } public static void ActivateWindow(IntPtr hwnd) { if (hwnd != IntPtr.Zero) { SetActiveWindow(hwnd); } } public static IntPtr GetModalWindow(IntPtr owner) { ModalWindowUtil util = new ModalWindowUtil(); EnumThreadWindows(GetCurrentThreadId() util.EnumChildren owner); return util._maxOwnershipHandle; // may be IntPtr.Zero } } public static void ActivateWindow(IntPtr hwnd) { ModalWindowUtil.ActivateWindow(hwnd); } public static IntPtr GetModalWindow(IntPtr owner) { return ModalWindowUtil.GetModalWindow(owner); } } }  Just as reference this is how I did without passing arguments (which I can't find any reason to do so... I mean a single app with arguments that as to be passed out from one instance to another one). If file association is required then an app should (per users standard expectation) be instanciated for each doc. If you have to pass args to existing app I think I would used vb dll. Not passing args (just single instance app) I prefer not registering a new Window message and not override the message loop as defined in Matt Davis Solution. Although it's not a big deal to add a VisualBasic dll but I prefer not add a new reference just to do single instance app. Also I do prefer instanciate a new class with Main instead of calling Shutdown from App.Startup override to ensure to exit as soon as possible. In hope that anybody will like it... or will inspire a little bit :-) Project startup class should be set as 'SingleInstanceApp'. public class SingleInstanceApp { [STAThread] public static void Main(string[] args) { Mutex _mutexSingleInstance = new Mutex(true ""MonitorMeSingleInstance""); if (_mutexSingleInstance.WaitOne(TimeSpan.Zero true)) { try { var app = new App(); app.InitializeComponent(); app.Run(); } finally { _mutexSingleInstance.ReleaseMutex(); _mutexSingleInstance.Close(); } } else { MessageBox.Show(""One instance is already running.""); var processes = Process.GetProcessesByName(Assembly.GetEntryAssembly().GetName().Name); { if (processes.Length > 1) { foreach (var process in processes) { if (process.Id != Process.GetCurrentProcess().Id) { WindowHelper.SetForegroundWindow(process.MainWindowHandle); } } } } } } } WindowHelper: using System; using System.Runtime.InteropServices; using System.Windows; using System.Windows.Interop; using System.Windows.Threading; namespace HQ.Util.Unmanaged { public class WindowHelper { [DllImport(""user32.dll"")] [return: MarshalAs(UnmanagedType.Bool)] public static extern bool SetForegroundWindow(IntPtr hWnd);  You could use the Mutex class but you will soon find out that you will need to implement the code to pass the arguments and such yourself. Well I learned a trick when programming in WinForms when I read Chris Sell's book. This trick uses logic that is already available to us in the framework. I don't know about you but when I learn about stuff I can reuse in the framework that is usually the route I take instead of reinventing the wheel. Unless of course it doesn't do everything I want. When I got into WPF I came up with a way to use that same code but in a WPF application. This solution should meet your needs based off your question. First we need to create our application class. In this class we are going override the OnStartup event and create a method called Activate which will be used later. public class SingleInstanceApplication : System.Windows.Application { protected override void OnStartup(System.Windows.StartupEventArgs e) { // Call the OnStartup event on our base class base.OnStartup(e); // Create our MainWindow and show it MainWindow window = new MainWindow(); window.Show(); } public void Activate() { // Reactivate the main window MainWindow.Activate(); } } Second we will need to create a class that can manage our instances. Before we go through that we are actually going to reuse some code that is in the Microsoft.VisualBasic assembly. Since I am using C# in this example I had to make a reference to the assembly. If you are using VB.NET you don't have to do anything. The class we are going to use is WindowsFormsApplicationBase and inherit our instance manager off of it and then leverage properties and events to handle the single instancing. public class SingleInstanceManager : Microsoft.VisualBasic.ApplicationServices.WindowsFormsApplicationBase { private SingleInstanceApplication _application; private System.Collections.ObjectModel.ReadOnlyCollection<string> _commandLine; public SingleInstanceManager() { IsSingleInstance = true; } protected override bool OnStartup(Microsoft.VisualBasic.ApplicationServices.StartupEventArgs eventArgs) { // First time _application is launched _commandLine = eventArgs.CommandLine; _application = new SingleInstanceApplication(); _application.Run(); return false; } protected override void OnStartupNextInstance(StartupNextInstanceEventArgs eventArgs) { // Subsequent launches base.OnStartupNextInstance(eventArgs); _commandLine = eventArgs.CommandLine; _application.Activate(); } } Basically we are using the VB bits to detect single instance's and process accordingly. OnStartup will be fired when the first instance loads. OnStartupNextInstance is fired when the application is re-run again. As you can see I can get to what was passed on the command line through the event arguments. I set the value to an instance field. You could parse the command line here or you could pass it to your application through the constructor and the call to the Activate method. Third it's time to create our EntryPoint. Instead of newing up the application like you would normally do we are going to take advantage of our SingleInstanceManager. public class EntryPoint { [STAThread] public static void Main(string[] args) { SingleInstanceManager manager = new SingleInstanceManager(); manager.Run(args); } } Well I hope you are able to follow everything and be able use this implementation and make it your own. This is the way we do it and I've never been too happy about it because of the dependency on WinForms. I'd stick with the mutex solution because it has nothing to do with forms. I've used this because I had issues with other approaches but I'm fairly sure it uses remoting under the hood. My app has had two related issues - some customers say it tries to phone home even though they've told it not to. When they look more carefully the connection is to localhost. Still they don't initially know that. Also I can't use remoting for a different purpose (I think?) because it's already being used for this. When I tried the mutex approach I could then use remoting again. Forgive me but unless I a missing something you avoided writing 3 lines of code and instead you re-used framework just to write pretty heavy code to do it. So where are the savings? it's possible do it in winforms? If you don't call InitializeComponent() on the application instance you won't be able to resolve resources... _application = new SingleInstanceApplication(); _application.InitializeComponent(); _application.Run();  MSDN actually has a sample application for both C# and VB to do exactly this: http://msdn.microsoft.com/en-us/library/ms771662(v=VS.90).aspx The most common and reliable technique for developing single-instance detection is to use the Microsoft .NET Framework remoting infrastructure (System.Remoting). The Microsoft .NET Framework (version 2.0) includes a type WindowsFormsApplicationBase which encapsulates the required remoting functionality. To incorporate this type into a WPF application a type needs to derive from it and be used as a shim between the application static entry point method Main and the WPF application's Application type. The shim detects when an application is first launched and when subsequent launches are attempted and yields control the WPF Application type to determine how to process the launches. For C# people just take a deep breath and forget about the whole 'I don't wanna include VisualBasic DLL'. Because of this and what Scott Hanselman says and the fact that this pretty much is the cleanest solution to the problem and is designed by people who know a lot more about the framework than you do. From a usability standpoint the fact is if your user is loading an application and it is already open and you're giving them an error message like 'Another instance of the app is running. Bye' then they're not gonna be a very happy user. You simply MUST (in a GUI application) switch to that application and pass in the arguments provided - or if command line parameters have no meaning then you must pop up the application which may have been minimized. The framework already has support for this - its just that some idiot named the DLL Microsoft.VisualBasic and it didn't get put into Microsoft.ApplicationUtils or something like that. Get over it - or open up Reflector. Tip: If you use this approach exactly as is and you already have an App.xaml with resources etc. you'll want to take a look at this too. I prefer your answer to be the selected one :) Thank you for including the 'take a look at this too' link. That's exactly what I needed. By the way solution #3 in your link is the best one. Excellent answer. This should be the selected answer.  Normally this is the code I use for single instance winform applications: [STAThread] public static void Main() { String assemblyName = Assembly.GetExecutingAssembly().GetName().Name; using (Mutex mutex = new Mutex(false assemblyName)) { if (!mutex.WaitOne(0 false)) { Boolean shownProcess = false; Process currentProcess = Process.GetCurrentProcess(); foreach (Process process in Process.GetProcessesByName(currentProcess.ProcessName)) { if (!process.Id.Equals(currentProcess.Id) && process.MainModule.FileName.Equals(currentProcess.MainModule.FileName) && !process.MainWindowHandle.Equals(IntPtr.Zero)) { IntPtr windowHandle = process.MainWindowHandle; if (NativeMethods.IsIconic(windowHandle)) NativeMethods.ShowWindow(windowHandle ShowWindowCommand.Restore); NativeMethods.SetForegroundWindow(windowHandle); shownProcess = true; } } if (!shownProcess) MessageBox.Show(String.Format(CultureInfo.CurrentCulture ""An instance of {0} is already running!"" assemblyName) assemblyName MessageBoxButtons.OK MessageBoxIcon.Asterisk MessageBoxDefaultButton.Button1 (MessageBoxOptions)0); } else { Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); Application.Run(new Form()); } } } Where native components are: [DllImport(""User32.dll"" CharSet = CharSet.Unicode ExactSpelling = true SetLastError = true)] [return: MarshalAs(UnmanagedType.Bool)] internal static extern Boolean IsIconic([In] IntPtr windowHandle); [DllImport(""User32.dll"" CharSet = CharSet.Unicode ExactSpelling = true SetLastError = true)] [return: MarshalAs(UnmanagedType.Bool)] internal static extern Boolean SetForegroundWindow([In] IntPtr windowHandle); [DllImport(""User32.dll"" CharSet = CharSet.Unicode ExactSpelling = true SetLastError = true)] [return: MarshalAs(UnmanagedType.Bool)] internal static extern Boolean ShowWindow([In] IntPtr windowHandle [In] ShowWindowCommand command); public enum ShowWindowCommand : int { Hide = 0x0 ShowNormal = 0x1 ShowMinimized = 0x2 ShowMaximized = 0x3 ShowNormalNotActive = 0x4 Minimize = 0x6 ShowMinimizedNotActive = 0x7 ShowCurrentNotActive = 0x8 Restore = 0x9 ShowDefault = 0xA ForceMinimize = 0xB } The problem by this implementation is that you can't provide any command-line arguments from the second instance back to the first one. For a better explanation [look here](http://www.hanselman.com/blog/TheWeeklySourceCode31SingleInstanceWinFormsAndMicrosoftVisualBasicdll.aspx).  It looks like there is a really good way to handle this. http://blogs.microsoft.co.il/blogs/arik/archive/2010/05/28/wpf-single-instance-application.aspx This provides a class you can add that manages all the mutex and messaging cruff to simplify the your implementation to the point where it's simply trivial. This didn't seem to bring the existing window to the foreground when I tried it.  The following code is my WCF named pipes solution to register a single instance application. It's nice because it also raises an event when another instance attempts to start and receives the command line of the other instance. It's geared toward WPF because it uses the System.Windows.StartupEventHandler class but this could be easily modified. This code requires a reference to PresentationFramework and System.ServiceModel. Usage: class Program { static void Main() { var applicationId = new Guid(""b54f7b0d-87f9-4df9-9686-4d8fd76066dc""); if (SingleInstanceManager.VerifySingleInstance(applicationId)) { SingleInstanceManager.OtherInstanceStarted += OnOtherInstanceStarted; // start the application } } static void OnOtherInstanceStarted(object sender StartupEventArgs e) { // Do something in response to another instance starting up. } } Source Code: /// <summary> /// A class to use for single-instance applications. /// </summary> public static class SingleInstanceManager { /// <summary> /// Raised when another instance attempts to start up. /// </summary> public static event StartupEventHandler OtherInstanceStarted; /// <summary> /// Checks to see if this instance is the first instance running on this machine. If it is not this method will /// send the main instance this instance's startup information. /// </summary> /// <param name=""guid"">The application's unique identifier.</param> /// <returns>True if this instance is the main instance.</returns> public static bool VerifySingleInstace(Guid guid) { if (!AttemptPublishService(guid)) { NotifyMainInstance(guid); return false; } return true; } /// <summary> /// Attempts to publish the service. /// </summary> /// <param name=""guid"">The application's unique identifier.</param> /// <returns>True if the service was published successfully.</returns> private static bool AttemptPublishService(Guid guid) { try { ServiceHost serviceHost = new ServiceHost(typeof(SingleInstance)); NetNamedPipeBinding binding = new NetNamedPipeBinding(NetNamedPipeSecurityMode.None); serviceHost.AddServiceEndpoint(typeof(ISingleInstance) binding CreateAddress(guid)); serviceHost.Open(); return true; } catch { return false; } } /// <summary> /// Notifies the main instance that this instance is attempting to start up. /// </summary> /// <param name=""guid"">The application's unique identifier.</param> private static void NotifyMainInstance(Guid guid) { NetNamedPipeBinding binding = new NetNamedPipeBinding(NetNamedPipeSecurityMode.None); EndpointAddress remoteAddress = new EndpointAddress(CreateAddress(guid)); using (ChannelFactory<ISingleInstance> factory = new ChannelFactory<ISingleInstance>(binding remoteAddress)) { ISingleInstance singleInstance = factory.CreateChannel(); singleInstance.NotifyMainInstance(Environment.GetCommandLineArgs()); } } /// <summary> /// Creates an address to publish/contact the service at based on a globally unique identifier. /// </summary> /// <param name=""guid"">The identifier for the application.</param> /// <returns>The address to publish/contact the service.</returns> private static string CreateAddress(Guid guid) { return string.Format(CultureInfo.CurrentCulture ""net.pipe://localhost/{0}"" guid); } /// <summary> /// The interface that describes the single instance service. /// </summary> [ServiceContract] private interface ISingleInstance { /// <summary> /// Notifies the main instance that another instance of the application attempted to start. /// </summary> /// <param name=""args"">The other instance's command-line arguments.</param> [OperationContract] void NotifyMainInstance(string[] args); } /// <summary> /// The implementation of the single instance service interface. /// </summary> private class SingleInstance : ISingleInstance { /// <summary> /// Notifies the main instance that another instance of the application attempted to start. /// </summary> /// <param name=""args"">The other instance's command-line arguments.</param> public void NotifyMainInstance(string[] args) { if (OtherInstanceStarted != null) { Type type = typeof(StartupEventArgs); ConstructorInfo constructor = type.GetConstructor(BindingFlags.Instance | BindingFlags.NonPublic null Type.EmptyTypes null); StartupEventArgs e = (StartupEventArgs)constructor.Invoke(null); FieldInfo argsField = type.GetField(""_args"" BindingFlags.Instance | BindingFlags.NonPublic); Debug.Assert(argsField != null); argsField.SetValue(e args); OtherInstanceStarted(null e); } } } }  I found the simpler solution similar to Dale Ragan's but slightly modified. It does practically everything you need and based on the standard Microsoft WindowsFormsApplicationBase class. Firstly you create SingleInstanceController class which you can use in all other single-instance applications which use Windows Forms: using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Windows.Forms; using Microsoft.VisualBasic.ApplicationServices; namespace SingleInstanceController_NET { public class SingleInstanceController : WindowsFormsApplicationBase { public delegate Form CreateMainForm(); public delegate void StartNextInstanceDelegate(Form mainWindow); CreateMainForm formCreation; StartNextInstanceDelegate onStartNextInstance; public SingleInstanceController(CreateMainForm formCreation StartNextInstanceDelegate onStartNextInstance) { // Set whether the application is single instance this.formCreation = formCreation; this.onStartNextInstance = onStartNextInstance; this.IsSingleInstance = true; this.StartupNextInstance += new StartupNextInstanceEventHandler(this_StartupNextInstance); } void this_StartupNextInstance(object sender StartupNextInstanceEventArgs e) { if (onStartNextInstance != null) { onStartNextInstance(this.MainForm); // This code will be executed when the user tries to start the running program again // for example by clicking on the exe file. } // This code can determine how to re-activate the existing main window of the running application. } protected override void OnCreateMainForm() { // Instantiate your main application form this.MainForm = formCreation(); } public void Run() { string[] commandLine = new string[0]; base.Run(commandLine); } } } Then you can use it in your program as follows: using System; using System.Collections.Generic; using System.Linq; using System.Windows.Forms; using SingleInstanceController_NET; namespace SingleInstance { static class Program { /// <summary> /// The main entry point for the application. /// </summary> static Form CreateForm() { return new Form1(); // Form1 is used for the main window. } static void OnStartNextInstance(Form mainWindow) // When the user tries to restart the application again // the main window is activated again. { mainWindow.WindowState = FormWindowState.Maximized; } [STAThread] static void Main() { Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); SingleInstanceController controller = new SingleInstanceController(CreateForm OnStartNextInstance); controller.Run(); } } } Both the program and the SingleInstanceController_NET solution should reference Microsoft.VisualBasic . If you just want to reactivate the running application as a normal window when the user tries to restart the running program the second parameter in the SingleInstanceController can be null. In the given example the window is maximized.  look at this code.great and simple solution about prevent multiple instance of wpf app  private void Application_Startup(object sender StartupEventArgs e) { Process thisProc = Process.GetCurrentProcess(); if (Process.GetProcessesByName(thisProc.ProcessName).Length > 1) { MessageBox.Show(""Application running""); Application.Current.Shutdown(); return; } var wLogin = new LoginWindow(); if (wLogin.ShowDialog() == true) { var wMain = new Main(); wMain.WindowState = WindowState.Maximized; wMain.Show(); } else { Application.Current.Shutdown(); } }  This code should go to the main method. Look at here for more information about the main method in WPF. [DllImport(""user32.dll"")] private static extern Boolean ShowWindow(IntPtr hWnd Int32 nCmdShow); private const int SW_SHOWMAXIMIZED = 3; static void Main() { Process currentProcess = Process.GetCurrentProcess(); var runningProcess = (from process in Process.GetProcesses() where process.Id != currentProcess.Id && process.ProcessName.Equals( currentProcess.ProcessName StringComparison.Ordinal) select process).FirstOrDefault(); if (runningProcess != null) { ShowWindow(runningProcess.MainWindowHandle SW_SHOWMAXIMIZED); return; } } Method 2 static void Main() { string procName = Process.GetCurrentProcess().ProcessName; // get the list of all processes by that name Process[] processes=Process.GetProcessesByName(procName); if (processes.Length > 1) { MessageBox.Show(procName + "" already running""); return; } else { // Application.Run(...); } } I find your Method 2 very clean and simple. Thanks! Method 1 has a nice touch -- it puts focus onto the running app. Method 2 will not work if run as administrator",c# .net wpf mutex
2871,A,Reading a C/C++ data structure in C# from a byte array What would be the best way to fill a C# struct from a byte[] array where the data was from a C/C++ struct? The C struct would look something like this (my C is very rusty): typedef OldStuff { CHAR Name[8]; UInt32 User; CHAR Location[8]; UInt32 TimeStamp; UInt32 Sequence; CHAR Tracking[16]; CHAR Filler[12]; } And would fill something like this: [StructLayout(LayoutKind.Explicit Size = 56 Pack = 1)] public struct NewStuff { [MarshalAs(UnmanagedType.ByValTStr SizeConst = 8)] [FieldOffset(0)] public string Name; [MarshalAs(UnmanagedType.U4)] [FieldOffset(8)] public uint User; [MarshalAs(UnmanagedType.ByValTStr SizeConst = 8)] [FieldOffset(12)] public string Location; [MarshalAs(UnmanagedType.U4)] [FieldOffset(20)] public uint TimeStamp; [MarshalAs(UnmanagedType.U4)] [FieldOffset(24)] public uint Sequence; [MarshalAs(UnmanagedType.ByValTStr SizeConst = 16)] [FieldOffset(28)] public string Tracking; } What is best way to copy OldStuff to NewStuff if OldStuff was passed as byte[] array? I'm currently doing something like the following but it feels kind of clunky. GCHandle handle; NewStuff MyStuff; int BufferSize = Marshal.SizeOf(typeof(NewStuff)); byte[] buff = new byte[BufferSize]; Array.Copy(SomeByteArray 0 buff 0 BufferSize); handle = GCHandle.Alloc(buff GCHandleType.Pinned); MyStuff = (NewStuff)Marshal.PtrToStructure(handle.AddrOfPinnedObject() typeof(NewStuff)); handle.Free(); Is there better way to accomplish this? Would using the BinaryReader class offer any performance gains over pinning the memory and using Marshal.PtrStructure? FYI If your program runs on various machines you might need to handle little vs big endian. How can you handle that on the level of the struct i.e. without having to individually reverse the bytes for each value in the struct? From what I can see in that context you don't need to copy SomeByteArray into a buffer. You simply need to get the handle from SomeByteArray pin it copy the IntPtr data using PtrToStructure and then release. No need for a copy. That would be: NewStuff ByteArrayToNewStuff(byte[] bytes) { GCHandle handle = GCHandle.Alloc(bytes GCHandleType.Pinned); NewStuff stuff = (NewStuff)Marshal.PtrToStructure( handle.AddrOfPinnedObject() typeof(NewStuff)); handle.Free(); return stuff; } Generic version: T ByteArrayToStructure<T>(byte[] bytes) where T: struct { GCHandle handle = GCHandle.Alloc(bytes GCHandleType.Pinned); T stuff = (T)Marshal.PtrToStructure(handle.AddrOfPinnedObject() typeof(T)); handle.Free(); return stuff; } ...  object ByteArrayToStructure(byte[] bytearray object structureObj int position) { int length = Marshal.SizeOf(structureObj); IntPtr ptr = Marshal.AllocHGlobal(length); Marshal.Copy(bytearray 0 ptr length); structureObj = Marshal.PtrToStructure(Marshal.UnsafeAddrOfPinnedArrayElement(bytearray position) structureObj.GetType()); Marshal.FreeHGlobal(ptr); return structureObj; } Have this  Watch out for packing issues. In the example you gave all fields are at the obvious offsets because everything is on 4 byte boundaries but this will not always be the case. Visual C++ packs on 8 byte boundaries by default.  If you have a byte[] you should be able to use the BinaryReader class and set values on NewStuff using the available ReadX methods.,c# .net data-structures marshalling
26570,A,"sizeof() equivalent for reference types? I'm looking for a way to get the size of an instance of a reference type. sizeof is only for value types. Is this possible? It's not a problem just a curiosity exercise. I have a bunch of items going into HttpContext.Items throughout a request and I was just curious how much memory they were taking up (if it even matters). I'm going through a ""measure everything"" phase. There are other ways to determine this (without code modification). Just use a memory profiler. Any decent profiler will show you number of bytes allocated per particular instance and also all memory that is held by the instance including memory taken by referenced instances. You need Marshal.SizeOf Edit: This is for unsafe code but then so is sizeof(). Marshal.SizeOf might return a different number of bytes than the number used. From MS : Returns the unmanaged size in bytes of a class.  Please refer my answer in the below link. It is possible via .sos.dll debugger extension Find out the size of a .net object  If you don't mind it being a little less accurate than perfect and for comparative purposes you could serialize the object/s and measure that (in bytes for example) EDIT (I kept thinking after posting): Because it's a little more complicated than sizeof for valuetypes for example: reference types can have references to other objects and so on... there's not an exact and easy way to do it that I know of...  If you can - Serialize it! Dim myObjectSize As Long Dim ms As New IO.MemoryStream Dim bf As New Runtime.Serialization.Formatters.Binary.BinaryFormatter() bf.Serialize(ms myObject) myObjectSize = ms.Position  I had a similar question recently and wanted to know the size of Object and LinkedListNode in C#. To solve the problem I developed a program that would: Measure the program's ""Working Set"" Allocate a lot of objects. Measure the ""Working Set"" again. Divide the difference by the number of allocated objects. On my computer (64-bit) I got the following data: Measuring Object: iter working set size estimate -1 11190272 1000000 85995520 74.805248 2000000 159186944 73.998336 3000000 231473152 73.4276266666667 4000000 306401280 73.802752 5000000 379092992 73.580544 6000000 451387392 73.3661866666667 7000000 524378112 73.3125485714286 8000000 600096768 73.613312 9000000 676405248 73.9127751111111 Average size: 73.7577032239859 Measuring LinkedListNode<Object>: iter working set size estimate -1 34168832 1000000 147959808 113.790976 2000000 268963840 117.397504 3000000 387796992 117.876053333333 4000000 507973632 118.4512 5000000 628379648 118.8421632 6000000 748834816 119.110997333333 7000000 869265408 119.299510857143 8000000 993509376 119.917568 9000000 1114038272 119.985493333333 Average size: 118.296829561905 Estimated Object size: 29.218576886067 Estimated LinkedListNode<reference type> size: 44.5391263379189 Based on the data the average size of allocating millions of Objects is approximately 29.2 bytes. A LinkedListNode object is approximately 44.5 bytes. This data illustrates two things: It's very unlikely that the system is allocating a partial byte. The fractional measure of bytes indicates the overhead the CLR requires to allocate and track millions of reference types. If we simply round-down the number of bytes we're still unlikely to have the proper byte count for reference types. This is clear from the measure of Objects. If we round down we assume the size is 29 bytes which while theoretically possible is unlikely because of padding. In order to improve performance object allocations are usually padded for alignment purposes. I would guess that CLR objects will be 4 byte aligned. Assuming CLR overhead and 4-byte alignment I'd estimate an Object in C# is 28 bytes and a LinkedListNode is 44 bytes. BTW Jon Skeet had the idea for the method above before I did and stated it in this answer to a similar question.  Beware that Marshal.SizeOf is for unsafe code... I don't think it's possible for managed code though maybe you can explain your problem there may be another way to solve it",c# .net
39,A,Reliable timer in a console application I am aware that in .NET there are three timer types (see Comparing the Timer Classes in the .NET Framework Class Library). I have chosen a threaded timer as the other types can drift if the main thread is busy and I need this to be reliable. The way this timer works in the control of the timer is put on another thread so it can always tick along with the work begin completed on the parent thread when it is not busy. The issue with this timer in a console application is that while the timer is ticking along on another thread the main thread is not doing anything so the application closes. I tried adding a while true loop but then the main thread is too busy when the timer does go off. You can use something like Console.ReadLine() to block the main thread so other background threads (like timer threads) will still work. You may also use an AutoResetEvent to block the execution then (when you need to) you can call Set() method on that AutoResetEvent object to release the main thread. Also ensure that your reference to Timer object doesn't go out of scope and garbage collected. yeah thanks fixed :) congradulations on being the [most relevant answer on Stack Overflow!](http://stackoverflow.com/search?tab=relevance&q=is%3aanswer) (as of Mar26 2012)  Consider using a ManualResetEvent to block the main thread at the end of its processing and call Reset() on it once the timer's processing has finished. If this is something that needs to run constantly consider moving this into a service process instead of a console app.,c# .net vb.net timer
9314,A,"""Could not find type"" error loading a form in the Designer I have a .NET 2.0 windows forms app which makes heavy use of the ListView control. I've subclassed the ListView class into a templated SortableListView<T> class so it can be a bit smarter about how it displays things and sort itself. Unfortunately this seems to break the Visual Studio Forms Designer in both VS2005 and 2008. The program compiles and runs fine but when I try view the owning form in the designer I get these Errors: Could not find type 'MyApp.Controls.SortableListView'. Please make sure that the assembly that contains this type is referenced. If this type is a part of your development project make sure that the project has been successfully built. There is no stack trace or error line information available for this error The variable 'listViewImages' is either undeclared or was never assigned. At MyApp.Main.Designer.cs Line:XYZ Column:1 Call stack: at System.ComponentModel.Design.Serialization.CodeDomSerializerBase.Error(IDesignerSerializationManager manager String exceptionText String helpLink) at System.ComponentModel.Design.Serialization.CodeDomSerializerBase.DeserializeExpression(IDesignerSerializationManager manager String name CodeExpression expression) at System.ComponentModel.Design.Serialization.CodeDomSerializerBase.DeserializeExpression(IDesignerSerializationManager manager String name CodeExpression expression) at System.ComponentModel.Design.Serialization.CodeDomSerializerBase.DeserializeStatement(IDesignerSerializationManager manager CodeStatement statement) The line of code in question is where it is actually added to the form and is this.imagesTab.Controls.Add( this.listViewImages ); listViewImages is declared as private MyApp.Controls.SortableListView<Image> listViewImages; and is instantiated in the InitializeComponent method as follows: this.listViewImages = new MyApp.Controls.SortableListView<Image>(); As mentioned earlier the program compiles and runs perfectly and I've tried shifting the SortableListView class out to a seperate assembly so it can be compiled seperately but this makes no difference. I have no idea where to go from here. Any help would be appreciated! I've had a problem like this (tho not the same) in the past where my control was in a different namespace to my form even tho it was in the same project. To fix it I had to add a using My.Other.Namespace; to the top of the designer generated code file. The annoying thing was it kept getting blown away when the designer regenerated the page.  when you added the listview did you add it to the toolbox and then add it to the form?  I had this problem too related to merging massive SVN changes (with conflicts) in the *.Designer.cs file. The solution was to just open up the design view graphically edit a control (move it to the left then right) and resave the design. The *.Designer.cs file magically changed and the warning went away on the next compilation. This is simply not true. If you get any of these warnings then the graphical view is broken. Nothing will show and so you cannot ""move something around to magically fix it"". There is just a list of errors and no gui as the op is complaining about. I disagree strongly; this worked for me like a charm (using Framework 4.0). When initially displaying the designer warnings shoed up for a few seconds then the form was drawn properly. I added a button deleted the button and rebuilt the solution; the warnings all disappeared. Dirk - you can think it is not true but this is what happened to me. I spent hours to trying to fix it. I wish I still had the before and after versions of the Designer.cs file but I don't. There's clearly a bug in Visual Studio that doesn't properly refresh some internal meta data and the only way I found to fix it is to force a refresh by resaving the graphical view.  I had something similar - a user control was referring to a remote serice (which I couldn't guarantee being available at design time). This post on MSDN suggested that I add if (this.DesignMode) return; to the Load function of the control or in my case to the point before the WCF client was initialised. That did the trick. So private readonly Client _client = new Client(); becomes private Client _client; public new void Load() { if(DesignMode) return; _client = new Client(); }  In my case the problem was the folder's name of my project! Why i think this: I use SVN and in the 'trunk\SGIMovel' works perfectly. But in a branch folder named as 'OS#125\SGIMovel' I can't open the designer for a form that uses a custom control and works in the trunk folder. Just get off the # and works nice. Thanks for nothing.  I had the same issue. In my case this issue was due to resource initialization. I moved the following code from InitializeComponent method to ctor(After calling InitializeComponent). After that this issue was resolved: this->resources = (gcnew System::ComponentModel::ComponentResourceManager(XXX::typeid));  The assembly that contains MyApp.Controls.SortableListView isn't installed in the GAC by any chance is it?  when you added the listview did you add it to the toolbox and then add it to the form? No I just edited Main.Designer.cs and changed it from System.Windows.Forms.ListView to MyApp.Controls.SortableListView<Image> Suspecting it might have been due to the generics led me to actually finding a solution. For each class that I need to make a SortableListView for I defined a 'stub class' like this class ImagesListView : SortableListView<Image> { } Then made the Main.Designer.cs file refer to these stub classes instead of the SortableListView. It now works hooray! Thankfully I am able to do this because all my types are known up front and I'm only using the SortableListView as a method of reducing duplicate code.  Perhaps you forgot to add that:  /// <summary> /// Required designer variable. /// </summary> private System.ComponentModel.IContainer components = null; /// <summary> /// Release all resources used. /// </summary> /// <param name=""disposing"">true if managed resources should be removed otherwise; false.</param> protected override void Dispose(bool disposing) { if (disposing && (components != null)) { components.Dispose(); } base.Dispose(disposing); } private void InitializeComponent() { // ... this.components = new System.ComponentModel.Container(); // Not necessarily if You do not use // ... }",c# .net winforms visual-studio-2008 visual-studio-2005
15204,A,"What is the best way to iterate through a strongly-typed generic List? What is the best way to iterate through a strongly-typed generic List in C#.NET and VB.NET? For C#: foreach(ObjectType objectItem in objectTypeList) { // ...do some stuff } Answer for VB.NET from Purple Ant: For Each objectItem as ObjectType in objectTypeList 'Do some stuff ' Next Since it's strongly typed you could also use: `foreach(var item in itemlist)`.  For VB.NET: For Each tmpObject as ObjectType in ObjectTypeList 'Do some stuff ' Next  Without knowing the internal implementation of a list I think generally the best way to iterate over it would be a foreach loop. Because foreach uses an IEnumerator to walk over the list it's up to the list itself to determine how to move from object to object. If the internal implementation was say a linked list then a simple for loop would be quite a bit slower than a foreach. Does that make sense? Yes because a linked list would need to search linearly for each new item whereas an iterator over it would just take one pass.  C# myList<string>().ForEach( delegate(string name) { Console.WriteLine(name); }); Anonymous delegates are not currently implemented in VB.Net but both C# and VB.Net should be able to do lambdas: C# myList<string>().ForEach(name => Console.WriteLine(name)); VB.Net myList(Of String)().ForEach(Function(name) Console.WriteLine(name)) As Grauenwolf pointed out the above VB won't compile since the lambda doesn't return a value. A normal ForEach loop as others have suggested is probably the easiest for now but as usual it takes a block of code to do what C# can do in one line. Here's a trite example of why this might be useful: this gives you the ability to pass in the loop logic from another scope than where the IEnumerable exists so you don't even have to expose it if you don't want to. Say you have a list of relative url paths that you want to make absolute: public IEnumerable<String> Paths(Func<String> formatter) { List<String> paths = new List<String>() { ""/about"" ""/contact"" ""/services"" }; return paths.ForEach(formatter); } So then you could call the function this way: var hostname = ""myhost.com""; var formatter = f => String.Format(""http://{0}{1}"" hostname f); IEnumerable<String> absolutePaths = Paths(formatter); Giving you ""http://myhost.com/about"" ""http://myhost.com/contact"" etc. Obviously there are better ways to accomplish this in this specfic example I'm just trying to demonstrate the basic principle. Your VB code won't work. VB only supports anonymous functions in this version you have to wait until VB10 to have anonymous subroutines. You are correct I didn't test it before posting. No wonder documentation for lambda expressions in VB are so scarce; they aren't nearly as useful. Obvious question: Why bother with callbacks when you can just do a `foreach`? You're assuming that the IEnumerable and delegate are from the same scope but despite my simple example they don't have to be. Being able to pass a closure into a function from another scope can be a very powerful design pattern. Maybe an example might help. And please start your posts to me with ""@Steve"" so that I get notified. @Steve Okay I've added an example to show you what I'm talking about. Been coding Ruby for the past year so forgive me if my C# is a bit rusty. Thanks Adam. With the example I can understand what you're saying. I realize the sample code is necessarily a bit trite but the technique does have value in the general case particularly for the flexibility it offers if the method taking the delegate is more complex. My only concern here is that I'm not sure that it answer's the OP's question as it's more complicated (and likely a little bit slower) than a basic foreach. I'd say it's not the best way in general but it's certainly one of the more flexible ways and therefore worth knowing about on that basis.  It depends on your application: for loop if efficiency is a priority foreach loop or ForEach method whichever communicates your intent more clearly Why would foreach be slower? foreach translates into GetEnumerator() MoveNext() and Current() calls which is obviously slower than incrementing a indexer and selecting from an array. We're talking nanoseconds though and is usually not of any concerns. ""for (index = objectListType.Count - 1; count >= 0; --count) { /* ... */ }"" is the best way in my opinion for one reason. It allows you to remove items while iterating. And if you decide to remove an item from objectListType ""objectListType.RemoveAt(index)"" while looping you won't get any strangeness or Modification-While-Enumeration exceptions. It's nice that it is performant.  I may be missing something but iterating through a generic list should be fairly simple if you use my examples below. The List<> class implements the IList and IEnumerable interfaces so that you can easily iterate through them basically any way you want. The most efficient way would be to use a for loop: for(int i = 0; i < genericList.Count; ++i) { // Loop body } You may also choose to use a foreach loop: foreach(<insertTypeHere> o in genericList) { // Loop body } No need to ``. The compiler with do it for you with `var`.  With any generic implementation of IEnumerable the best way is: //C# foreach( var item in listVariable) { //do stuff } There is an important exception however. IEnumerable involves an overhead of Current() and MoveNext() that is what the foreach loop is actually compiled into. When you have a simple array of structs: //C# int[] valueTypeArray; for(int i=0; i < valueTypeArray.Length; ++i) { int item = valueTypeArray[i]; //do stuff } Is quicker. Update Following a discussion with @Steven Sudit (see comments) I think my original advice may be out of date or mistaken so I ran some tests: // create a list to test with var theList = Enumerable.Range(0 100000000).ToList(); // time foreach var sw = Stopwatch.StartNew(); foreach (var item in theList) { int inLoop = item; } Console.WriteLine(""list foreach: "" + sw.Elapsed.ToString()); sw.Reset(); sw.Start(); // time for int cnt = theList.Count; for (int i = 0; i < cnt; i++) { int inLoop = theList[i]; } Console.WriteLine(""list for : "" + sw.Elapsed.ToString()); // now run the same tests but with an array var theArray = theList.ToArray(); sw.Reset(); sw.Start(); foreach (var item in theArray) { int inLoop = item; } Console.WriteLine(""array foreach: "" + sw.Elapsed.ToString()); sw.Reset(); sw.Start(); // time for cnt = theArray.Length; for (int i = 0; i < cnt; i++) { int inLoop = theArray[i]; } Console.WriteLine(""array for : "" + sw.Elapsed.ToString()); Console.ReadKey(); So I ran this in release with all optimisations: list foreach: 00:00:00.5137506 list for : 00:00:00.2417709 array foreach: 00:00:00.1085653 array for : 00:00:00.0954890 And then debug without optimisations: list foreach: 00:00:01.1289015 list for : 00:00:00.9945345 array foreach: 00:00:00.6405422 array for : 00:00:00.4913245 So it appears fairly consistent for is quicker than foreach and arrays are quicker than generic lists. However this is across 100000000 iterations and the difference is about .4 of a second between the fastest and slowest methods. Unless you're doing massive performance critical loops it just isn't worth worrying about. The question was about `List` not arrays. Regardless I don't believe that `foreach` on an native array actually uses `IEnumerable` at least not in optimized code so there's no real speed-up to be had. In fact my test shows `foreach` taking only three quarters the time of `for`. @Steven Sudit - `foreach` loops actually suffer versus `for` loops once compiler optimisation has been applied. However I did some digging around - in the case of an array `foreach` is optimised to exactly the same IL as a `for`. For a `List` the compiler can't use this optimisation and the resulting IL is slightly slower. Looks like we're both wrong (._. ) I wasn't just speaking from theory. I wrote a short test and ran it. If you'd like I would be glad to dig it up and post it so that you can see how it works for you. @Steven Sudit - yeah me too. I've updated the answer with the results. Let me thank you for putting in the hard work but I should mention that my tests had one key difference: I made sure the loops passed each element to an external method. Without this the compiler is likely to optimize away the assignment entirely. I don't know if this accounts for the tiny speed boost but it easily could.",c# .net vb.net generics collections
14943,A,"How to Disable Alt + F4 closing form? What is the best way to disable Alt + F4 in a c# win form to prevent the user from closing the form? I am using a form as a popup dialog to display a progress bar and I do not want the user to be able to close it. This does the job: private void Form1_FormClosing(object sender FormClosingEventArgs e) { e.Cancel = true; } Edit: In response to pix0rs concern - yes you are correct that you will not be able to programatically close the app. However you can simply remove the event handler for the form_closing event before closing the form: this.FormClosing -= new System.Windows.Forms.FormClosingEventHandler(this.Form1_FormClosing); this.Close(); Thanks Martin. This worked great! I suspect most people are implementing this method on the form in question (Form1). In this case it is recommended you do not attach a delegate but instead override the OnFormClosing method. ""The OnFormClosing method also allows derived classes to handle the event without attaching a delegate. This is the preferred technique for handling the event in a derived class."" http://tinyurl.com/3dzzljq I would have made the event handler as such: `e.Cancel = (e.Reason == CloseReason.UserClosing);`. This way you guarantee that you won't close only when the USER tries to close the form. all my life I've been doing it ... and then yet again I forgot! Thanks for reminding :) This approach has one big problem: if you want to shutdown/restart your PC it will cancel that request too (at least on Windows XP) That's BRILLIANT! I especially love removing the event when you want to close the form. It's so SIMPLE!!!  Would FormClosing be called even when you're programatically closing the window? If so you'd probably want to add some code to allow the form to be closed when you're finished with it (instead of always canceling the operation)  @TK If you look at the value of FormClosingEventArgs e.CloseReason it will tell you why the form is being closed. You can then decide what to do the possible values are: Member name - Description None - The cause of the closure was not defined or could not be determined. WindowsShutDown - The operating system is closing all applications before shutting down. MdiFormClosing - The parent form of this multiple document interface (MDI) form is closing. UserClosing - The user is closing the form through the user interface (UI) for example by clicking the Close button on the form window selecting Close from the window's control menu or pressing ALT+F4. TaskManagerClosing - The Microsoft Windows Task Manager is closing the application. FormOwnerClosing - The owner form is closing. ApplicationExitCall - The Exit method of the Application class was invoked. If only they broke out UserClosing to be more granular so you could target Alt+F4 specifically...  http://www.kassl.de/winlock/download.shtml This program allows you to block ALT F4 temporarily  You could handle the FormClosing event and set FormClosingEventArgs.Cancel to true.  Subscribe FormClosing event private void Form1_FormClosing(object sender FormClosingEventArgs e) { e.Cancel = e.CloseReason == CloseReason.UserClosing; } Only one line in the method body.  I believe this is the right way to do it: protected override void OnFormClosing(FormClosingEventArgs e) { switch (e.CloseReason) { case CloseReason.UserClosing: e.Cancel = true; break; } base.OnFormClosing(e); } better replace the break with return I am not sure about the reason but if I call the base class my application crashes after another subsequent Alt+F4 hit. At first I thought it was because plain F4 has some other meaning in my application but a long debugging session showed otherwise. Anyway it may still be a specific case on my side. Thanks for this great answer. Actually I believe the correct pattern is to set the cancel flag to true and then call the base class. When overriding On[Event] methods it is important to call the base class so that any event subscribers are also notified of the event. Yes in this case it's easy to think that since you've cancelled the event then no one else needs to know about it but I don't believe it correct to make that assumption. Calling the base class also causes my app to crash on subsequent Alt+F4s. I suspect the base class doesn't check e.Cancel and tries to destroy the form anyway. You need to look into why your application is crashing - it is likely you are doing something wrong elsewhere. The docs say ""The FormClosing event occurs as the form is being closed. When a form is closed it is disposed releasing all resources associated with the form. If you cancel this event the form remains opened. To cancel the closure of a form set the Cancel property of the FormClosingEventArgs passed to your event handler to true."" http://tinyurl.com/3tb7y9q  I am using a form as a popup dialog to display a progress bar and I do not want the user to be able to close it. If the user is determined to close your app (and knowledgeable) enough to press alt+f4 they'll most likely also be knowledgeable enough to run task manager and kill your application instead. At least with alt+f4 your app can do a graceful shutdown rather than just making people kill it. From experience people killing your app means corrupt config files broken databases half-finished tasks that you can't resume and many other painful things. At least prompt them with 'are you sure' rather than flat out preventing it.  Within the FormClosing event handler could you not interrogate the keyboard buffer (do you even have access to this?) to se if [Alt] + [F4] was pressed cancel if true continue if not?  Note that it is considered bad form for an application to completely prevent itself from closing. You should check the event arguments for the Closing event to determine how and why your application was asked to close. If it is because of a Windows shutdown you should not prevent the close from happening.",c# .net winforms
27674,A,"Dynamic top down list of controls in WindowsForms and C#? In our project SharpWired we're trying to create a download component similar to the download windows in Firefox or Safari. That is one single top down list of downloads which are custom controls containing progress bars buttons and what not. The requirements are that there should be one single list with one element on each row. Each element must be a custom control. The whole list should be dynamically re-sizable so that when you make it longer / shorter the list adds a scroll bar when needed and when you make it thinner / wider the custom controls should resize to the width of the list. We've tried using a FlowLayoutPanel but haven't gotten resizing to work the way we want to. Preferably we should only have to set anchoring of the custom controls to Left & Right. We've also thought about using a TableLayoutPanel but found adding rows dynamically to be a too big overhead so far. This must be quite a common use case and it seems a bit weird to me that the FlowLayoutPanel has no intuitive way of doing this. Has anyone done something similar or have tips or tricks to get us under way? Cheers! /Adam If you don't want to use databinding (via the DataRepeater control as mentioned above) you could use a regular Panel control and set its AutoScroll property to true (to enable scrollbars). Then you could manually add your custom controls and set the Dock property of each one to Top. That is what we've been doing. The data binding solution is way too much overhead for us.  .NET 3.5 SP1 introduced a DataRepeater Windows Forms control which sounds like it'd do what you want. Bind it to the list of ""downloads"" (or whatever your list represents) and customize each item panel to include the controls you need. That control is in VisualBasic Power Pack. How would I use it in C#? @Adam no it's just in the VisualBasic namespace. You can use it from any and all .NET languages and it's part of the framework as of .NET 3.5 SP1. As far as I know you may simply reference the assembly in your solution and use the methods within it as normal. The compiled .Net assemblies can interoperate with each other seamlessly. Of course I have no specific experince of this assembly and I can't guarantee anything I've just said in this instance. :)",c# .net winforms gui user-controls
8987,A,"Calling Table-Valued SQL Functions From .NET Scalar-valued functions can be called from .NET as follows: SqlCommand cmd = new SqlCommand(""testFunction"" sqlConn); //testFunction is scalar cmd.CommandType = CommandType.StoredProcedure; cmd.Parameters.Add(""retVal"" SqlDbType.Int); cmd.Parameters[""retVal""].Direction = ParameterDirection.ReturnValue; cmd.ExecuteScalar(); int aFunctionResult = (int)cmd.Parameters[""retVal""].Value; I also know that table-valued functions can be called in a similar fashion for example: String query = ""select * from testFunction(param1...)""; //testFunction is table-valued SqlCommand cmd = new SqlCommand(query sqlConn); SqlDataAdapter adapter = new SqlDataAdapter(cmd); adapter.Fill(tbl); My question is can table-valued functions be called as stored procedures like scalar-valued functions can? (e.g. replicate my first code snippet with a table-valued function being called and getting the returned table through a ReturnValue parameter). @ChuckConway Why dropping C# from the title? It was valid considering the C# tag... but that tag does not help it to show up in google. No because you need to select them. However you can create a stored proc wrapper which may defeat the point of having a table function.  You might think of a different approach which has nothing to do with SQL. We use a net library named finaquant protos in our calculation engine for ecological population forecasts. This library has high-level table functions for table algebra aggregation filtering sampling allocation distribution function routing and so on. Data tables are represented with a class named MatrixTable and all the operations apply on MatrixTable objects as inputs and outputs.",c# .net sql
26719,A,"Internalize Class and Methods in .NET Assembly I have a set of multiple assemblies (one assembly is to be used as an API and it depends on other assemblies). I would like to merge all assemblies into one single assembly but prevent all assemblies except the API one to be visible from the outside. I will then obfuscate this assembly with Xenocode. From what I have seen it is impossible to internalize assembly with Xenocode. I have seen ILMerge from Microsoft but was unable to figure if it can do what I want. http://research.microsoft.com/~mbarnett/ILMerge.aspx There are some issues with ILMerge but I think if you add optimisations + merge + obfuscation you're likely to create a highly complex situation for little benefit. Why not have just one assembly and make only your API public? If you're always distributing them as a single assembly there's no reason not to just compile them as that. You'll get more benefit from compiler optimisations and it will be quicker to compile too.  I have used ILMerge from microsoft to internalize DLL's into a single assembled library. There is a useful GUI for using ILMerge called NuGenUnify. You can find it here.  I know Xenocode can merge assemblies into one but I am not sure if it will internalize other non-primary assemblies. I have found the /internalize switch in ILMerge that ""internalize"" all assemblies except the primary one. Pretty useful!  I suggest you look at the InternalsVisibleTo attribute on MSDN. You can mark everything in all the assemblies (except the API assembly) as internal instead of public then reshow them to just your API assembly. Having done that using ILMerge should give you a single assembly with just the API classes visible.",c# .net vb.net assemblies
14505,A,"Alpha blending colors in .NET Compact Framework 2.0 In the Full .NET framework you can use the Color.FromArgb() method to create a new color with alpha blending like this: Color blended = Color.FromArgb(alpha color); or Color blended = Color.FromArgb(alpha red green  blue); However in the Compact Framework (2.0 specifically) neither of those methods are available you only get: Color.FromArgb(int red int green int blue); and Color.FromArgb(int val); The first one obviously doesn't even let you enter an alpha value but the documentation for the latter shows that ""val"" is a 32bit ARGB value (as 0xAARRGGBB as opposed to the standard 24bit 0xRRGGBB) so it would make sense that you could just build the ARGB value and pass it to the function. I tried this with the following: private Color FromARGB(byte alpha byte red byte green byte blue) { int val = (alpha << 24) | (red << 16) | (green << 8) | blue; return Color.FromArgb(val); } But no matter what I do the alpha blending never works the resulting color always as full opacity even when setting the alpha value to 0. Has anyone gotten this to work on the Compact Framework? There is a codeplex site out there that seems to do the heavy lifting of com interop for you:  i take this code and i add this device.RenderState.AlphaBlendEnable = true; device.RenderState.AlphaFunction = Compare.Greater; device.RenderState.AlphaTestEnable = true; device.RenderState.DestinationBlend = Blend.InvSourceAlpha; device.RenderState.SourceBlend = Blend.SourceAlpha; device.RenderState.DiffuseMaterialSource = ColorSource.Material; in the initialized routine and it work very well thank you  CE 6.0 does not support alpha blending. WM 5.0 and above do but not through the .NET CF you will need to P/Invoke GDI stuff to do so. There are ready-made solutions out there however if you are interested i can dig the links out tomorrow at the office. I have to work with CE 6.0 currently so i don't have them on my mind. If you are using CE 6.0 you can use pseudo-transparency by reserving a transparency background color (e.g. ff00ff or something similiarly ugly) and using that in your images for transparent areas. Then your parent controls must implement a simple interface that allows re-drawing the relevant portion on your daughter controls' graphics buffer. Note that this will not give you a true ""alpha channel"" but rather just a hard on-off binary kind of transparency. It's not as bad as it sounds. Take a look at the OpenNETCF ImageButton for starters. If you are going to use this method i have a somewhat extended version of some simple controls with this technique lying around if you are interested. One additional drawback is that this technique relies on the parent control implementing a special interface and the daugther controls using it in drawing. So with closed-source components (i.e. also the stock winforms components) you are out of luck. CE 6.0 *does* support alpha blending. It may be that your specific OS build doesn't but support is in the OS and can be included in an OS image.  Apparently it's not quite that simple but still possible if you have Windows Mobile 5.0 or newer. Wow...definitely not worth it if I have to put all that code in (and do native interop!) Good to know though thanks for the link.  Apparently it's not quite that simple but still possible if you have Windows Mobile 5.0 or newer.",c# .net graphics compact-framework
17532,A,"ASP.NET Custom Controls - Composites Summary Hi All OK further into my adventures with custom controls... In summary here is that I have learned of three main ""classes"" of custom controls. Please feel free to correct me if any of this is wrong! UserControls - Which inherit from UserControl and are contained within an ASCX file. These are pretty limited in what they can do but are a quick and light way to get some UI commonality with designer support. Custom Composite Controls - These are controls that inherit from WebControl where you add pre-existing controls to the control within the CreateChildControls method. This provides great flexibility but lack of designer support without additional coding. They are highly portable though since they can be compiled into a DLL. Custom Rendered Controls - Similar to Custom Composite Controls these are added to a Web Control Library project. The rendering of the control is completely controlled by the programmer by overriding the Render method. My Thoughts.. OK so while playing with custom composites I found the following: You have little/no control over the HTML output making it difficult to ""debug"". The CreateChildControls (and subsequent methods) can get real busy with Controls.Add(myControl) everywhere. I found rendering tables (be it for layout or content) to be considerably awkward. The Question(s).. So I admit I am new to this so I could be way off-base with some of my points noted above.. Do you use Composites? Do you have any neat tricks to control the HTML output? Do you just say ""to hell with it"" and go ahead and create a custom rendered control? Its something I am keen to get really firm in my mind since I know how much good control development can cut overall development time. I look forward to your answers ^_^ Here's another extension method that I use for custom rendering:  public static void WriteControls (this HtmlTextWriter o string format params object[] args) { const string delimiter = ""<2E01A260-BD39-47d0-8C5E-0DF814FDF9DC>""; var controls = new Dictionary<stringControl>(); for(int i =0; i < args.Length; ++i) { var c = args[i] as Control; if (c==null) continue; var guid = Guid.NewGuid().ToString(); controls[guid] = c; args[i] = delimiter+guid+delimiter; } var _strings = string.Format(format args).Split( new string[]{delimiter} StringSplitOptions.None); foreach(var s in _strings) { if (controls.ContainsKey(s)) controls[s].RenderControl(o); else o.Write(s); } } Then to render a custom composite in the RenderContents() method I write this: protected override void RenderContents(HtmlTextWriter o) { o.WriteControls (@""<table> <tr> <td>{0}</td> <td><{1}></td> </tr> </table>"" Text control1 ); }  I often use composite controls. Instead of overriding Render or RenderContents just assign each Control a CssClass and use stylesheets. For multiple Controls.Add I use an extension method: //Controls.Add(c1 c2 c3) static void Add(this ControlCollection coll params Control[] controls) { foreach(Control control in controls) coll.Add(control); } For quick and dirty rendering I use something like this: writer.Render(@""<table> <tr><td>{0}</td></tr> <tr> <td>"" Text); control1.RenderControl(writer); writer.Render(""</td></tr></table>""); For initializing control properties I use property initializer syntax: childControl = new Control { ID=""Foo""  CssClass=""class1""  CausesValidation=true; };  I say go ahead with the custom rendered control. I find that in most cases the composite can be easier done and used in a UserControl but anything beyond that and you'd need to have a finer degree of control (pun unintended) to merit your own rendering strategy. There maybe controls that are simple enough to merit a composite (e.g. a textbox combined with a javascript/dhtml based datepicker for example) but beyond that one example it looks like custom rendered controls are the way to go.  Using custom composite controls has a point in a situation where you have a large web application and want to reuse large chunks in many places. Then you would only add child controls of the ones you are developing instead of repeating yourself. On a large project I've worked recently what we did is the following: Every composite control has a container. Used as a wrapped for everything inside the control. Every composite control has a template. An ascx file (without the <%Control%> directive) which only contains the markup for the template. The container (being a control in itself) is initialized from the template. The container exposes properties for all other controls in the template. You only use this.Controls.Add([the_container]) in your composite control. In fact you need a base class that would take care of initializing a container with the specified template and also throw exceptions when a control is not found in the template. Of course this is likely to be an overkill in a small application. If you don't have reused code and markup and only want to write simple controls you're better off using User Controls.  You might be able to make use of this technique to make design-time easier: http://aspadvice.com/blogs/ssmith/archive/2007/10/19/Render-User-Control-as-String-Template.aspx Basically you create an instance of a user control at runtime using the LoadControl method then hand it a statebag of some kind then attach it to the control tree. So your composite control would actually function like more of a controller and the .ascx file would be like a view. This would save you the trouble of having to instantiate the entire control tree and style the control in C#!  Rob you are right. The approach I mentioned is kind of a hybrid. The advantage of having ascx files around is that on every project I've seen designers would feel most comfortable with editing actual markup and with the ascx you and a designer can work separately. If you don't plan on actual CSS/markup/design changes on the controls themselves later you can go with a custom rendered control. As I said my approach is only relevant for more complicated scenarios (and these are probably where you need a designer :))",c# .net asp.net user-controls controls
11767,A,"Browse for a directory in C# How can I present a control to the user that allows him/her to select a directory? There doesn't seem to be any native .net controls which do this? string folderPath = """"; FolderBrowserDialog folderBrowserDialog1 = new FolderBrowserDialog(); if (folderBrowserDialog1.ShowDialog() == DialogResult.OK) { folderPath = folderBrowserDialog1.SelectedPath ; } Thanks works great! Thanks this is the quick reference that works. I love this type of answers.  For much more functionality than the FolderBrowserdialog like filtering check-boxes etc take a look at 3rd party controls like Shell MegaPack. Since they are controls so they can be put in your own forms instead of appearing as a modal dialog. good idea if selection etc is required.  Please don't try and roll your own with a TreeView/DirectoryInfo class. For one thing there are many nice features you get for free (icons/right-click/networks) by using SHBrowseForFolder. For another there are a edge cases/catches you will likely not be aware of.  You could use a TreeView in combination with the DirectoryInfo class.  You could just use the FolderBrowserDialog class from System.Windows.Forms -1 Dup http://stackoverflow.com/a/11775/11635  FolderBrowserDialog class? http://msdn.microsoft.com/en-us/library/system.windows.forms.folderbrowserdialog.aspx in System.Windows.Forms Dll",c# .net
10412,A,"How can a Word document be created in C#? I have a project where I would like to generate a report export in MS Word format. The report will include images/graphs tables and text. What is the best way to do this? Third party tools? What are your experiences? I've written a blog post series on Open XML WordprocessingML document generation. My approach is that you create a template document that contains content controls and in each content control you write an XPath expression that defines how to retrieve the content from an XML document that contains the data that drives the document generation process. The code is free and is licensed under the the Microsoft Reciprocal License (Ms-RL). In that same blog post series I also explore an approach where you write C# code in content controls. The document generation process then processes the template document and generates a C# program that generates the desired documents. One advantage of this approach is that you can use any data source as the source of data for the document generation process. That code is also licenced under the Microsoft Reciprocal License.  Schmidty if you want to generate Word documents on a web server you will need a licence for each client (not just the web server). See this section in the first link Rob posted: ""Besides the technical problems you must also consider licensing issues. Current licensing guidelines prevent Office applications from being used on a server to service client requests unless those clients themselves have licensed copies of Office. Using server-side Automation to provide Office functionality to unlicensed workstations is not covered by the End User License Agreement (EULA)."" If you meet the licensing requirements I think you will need to use COM Interop - to be specific the Office XP Primary Interop Assemblies.  I have found Aspose Words to be the best as not everybody can open Office Open XML/*.docx format files and the Word interop and Word automation can be buggy. Aspose Words supports most document file types from Word 97 upwards. It is a pay-for component but has great support. The other alternative as already suggested is RTF. I've found Aspose Words to be a bit lacking when working with OpenXml documents. Specifically its handling of content controls is next to useless and it cannot handle AltChunk nodes at all.  @Dale Ragan: That will work for the Office 2003 XML format but that's not portable (as say .doc or .docx files would be). To read/write those you'll need to use the Word Object Library ActiveX control: http://www.codeproject.com/KB/aspnet/wordapplication.aspx  I have had good success using the Syncfusion Backoffice DocIO which supports doc and docx formats. In prior releases it did not support everything in word but accoriding to your list we tested it with tables and text as a mail merge approach and it worked fine. Not sure about the import of images though. On their blurb page http://www.syncfusion.com/products/DocIO/Backoffice/features/default.aspx it says Blockquote Essential DocIO has support for inserting both Scalar and Vector images into the document in almost all formats. Bitmap gif png and tiff are some of the common image types supported. So its worth considering. As others have mentioned you can build up a RTF document there are some good RTF libraries around for .net like http://www.codeproject.com/KB/string/nrtftree.aspx  You could also use Word document generator. It can be used for client-side or server-side deployment. From the project description: WordDocumentGenerator is an utility to generate Word documents from templates using Visual Studio 2010 and Open XML 2.0 SDK. WordDocumentGenerator helps generate Word documents both non-refresh-able as well as refresh-able based on predefined templates using minimum code changes. Content controls are used as placeholders for document generation. It supports Word 2007 and Word 2010. Grab it: http://worddocgenerator.codeplex.com/ Download SDK: http://www.microsoft.com/en-us/download/details.aspx?id=5124  Another alternative is Windward Docgen (disclaimer - I'm the founder). With Windward you design the template in Word including images tables graphs gauges and anything else you want. You can set tags where data from an XML or SQL datasource is inserted (including functionality like forEach loops import etc). And then generate the report to DOCX PDF HTML etc.  @Danny Smurf: Actually this article describes what will become the Office Open XML format which Rob answered with. I will pay more attention to the links I post for now on to make sure there not obsolete. I actually did a search on WordML which is what it was called at the time. I believe that the Office Open XML format is the best way to go.  I faced this problem and created a small library for this. It was used in several projects and then I decided to publish it. It is free and very very simple but I'm sure it will help with you with the task. Invoke the Office Open XML Library http://invoke.co.nz/products/docx.aspx.  The answer is going to depend slightly upon if the application is running on a server or if it is running on the client machine. If you are running on a server then you are going to want to use one of the XML based office generation formats as there are know issues when using Office Automation on a server. However if you are working on the client machine then you have a choice of either using Office Automation or using the Office Open XML format (see links below) which is supported by Microsoft Office 2000 and up either natively or through service packs. One draw back to this though is that you might not be able to embed some kinds of graphs or images that you wish to show. The best way to go about things will all depend sightly upon how much time you have to invest in development. If you go the route of Office Automation there are quite a few good tutorials out there that can be found via Google and is fairly simple to learn. However the Open Office XML format is fairly new so you might find the learning curve to be a bit higher. Office Open XML Iinformation Office Open XML - http://en.wikipedia.org/wiki/Office%5FOpen%5FXML OpenXML Developer - http://openxmldeveloper.org/default.aspx Introducing the Office (2007) Open XML File Formats - http://msdn.microsoft.com/en-us/library/aa338205.aspx Update as of 9/2011...I do both Interop and OpenXml and faced with this task in either case I would absolutely use OpenXml. It's the only solution which absolutely guarantees you'll have absolute control over the output.  Have you considered using .RTF as an alternative? It supports embedding images and tables as well as text opens by default using Microsoft Word and whilst it's featureset is more limited (count out any advanced formatting) for something that looks and feels and opens like a Word document it's not far off. Your end users probably won't notice. Please don't use RTF - the spec is a mess even Microsoft does not follow it fully and it has lots of ambiguity in it.  To generate Word documents with Office Automation within .NET specifically in C# or VB.NET: Add the Microsoft.Office.Interop.Word assembly reference to your project. The path is \Visual Studio Tools for Office\PIA\Office11\Microsoft.Office.Interop.Word.dll. Follow the Microsoft code example you can find here: http://support.microsoft.com/kb/316384/en-us.  I have spent the last week or so getting up to speed on Office Open XML. We have a database application that stores survey data that we want to report in Microsoft Word. You can actually create Word 2007 (docx) files from scratch in C#. The Open XML SDK version 2 includes a cool application called the Document Reflector that will actually provide the C# code to fully recreate a Word document. You can use parts or all of the code and substitute the bits you want to change on the fly. The help file included with the SDK has some good code samples as well. There is no need for the Office Interop or any other Office software on the server - the new formats are 100% XML.  I currently do this exact thing. If the document isn't very big doesn't contain images and such then I store it as an RTF with #MergeFields# in it and simply replace them with content sending the result down to the user as an RTF. For larger documents including images and dynamically inserted images I save the initial Word document as a Single Webpage *.mht file containing the #MergeFields# again. I then do the same as above. Using this I can easily render a DataTable with some basic Html table tags and replace one of the #MergeFields# with a whole table. Images can be stored on your server and the url embedded into the document too. Interestingly the new Office 2007 file formats are actually zip files - if you rename the extension to .zip you can open them up and see their contents. This means you should be able to switch content such as images in and out using a simple C# zip library.  The quickest way I have done it in the past is to use XML. Here is a good article that should get you started: http://msdn.microsoft.com/en-us/magazine/cc164064.aspx Wow that is a good article. Saving this using office 2010 is not possible. http://support.microsoft.com/kb/2445060 MSFT has lost some case for saving custom xml. http://www.zdnet.com/blog/microsoft/microsoft-loses-its-appeal-in-200-million-plus-custom-xml-patent-infringement-case/4835  DocX free library for creating DocX documents actively developed and very easy and intuitive to use.  Check out VSTO (Visual Studio Tools for Office). It is fairly simple to create a Word template inject an xml data island into it then send it to the client. When the user opens the doc in Word Word reads the xml and transforms it into WordML and renders it. You will want to look at the ServerDocument class of the VSTO library. No extra licensing is required from my experience.  LibreOffice also supports headless interaction via API. Unfortunately there's currently not much information about this feature yet.. :(",c# .net ms-word openxml
9734,A,"C#.Net case-insensitive string Why does C#.Net allow the declaration of the string object to be case-insensitive? String sHello = ""Hello""; string sHello = ""Hello""; Both the lower-case and upper-case S of the word String are acceptable and this seems to be the only object that allows this. Can anyone explain why? Firstly it is not case-insensitive. You can’t write `STRING` or `strinG` or anything else. Secondly it is not the only type that has an alias: `object` is an alias for `Object`; `bool` is an alias for `Boolean`; `double` is an alias for `Double` etc. Incidentally `void` is also an alias for `Void` but C# doesn’t let you use `Void`... See [this question](http://stackoverflow.com/questions/7074/in-c-what-is-the-difference-between-string-and-string#7077) for more information. I use String and not string Int32 instead of int so that my syntax highlighting picks up on a string as a Type and not a keyword. I want keywords to jump out at me.  string is an alias for System.String. They are the same thing. By convention though objects of type (System.String) are generally refered to as the alias - e.g. string myString = ""Hello""; whereas operations on the class use the uppercase version e.g. String.IsNullOrEmpty(myStringVariable); I don't think the convention is particularly to use the upper case version for operations. I certainly haven't seen that written down. The important thing is to use the BCL version for public names e.g. ReadSingle instead of ReadFloat. says who? never heard of this convention!  ""string"" is a C# keyword. it's just an alias for ""System.String"" - one of the .NET BCL classes.  string is a language keyword while System.String is the type it aliases. Both compile to exactly the same thing similarly: int is System.Int32 long is System.Int64 float is System.Single double is System.Double char is System.Char byte is System.Byte short is System.Int16 ushort is System.UInt16 uint is System.UInt32 ulong is System.UInt64 I think in most cases this is about code legibility - all the basic system value types have aliases I think the lower case string might just be for consistency.  ""String"" is the name of the class. ""string"" is keyword that maps this class. it's the same like Int32 => int Decimal => decimal Int64 => long ... and so on...  Further to the other answers it's good practice to use keywords if they exist. E.g. you should use string rather than System.String.  ""string"" is just an C# alias for the class ""String"" in the System-namespace.",c# .net
14359,A,".Net Dynamic Plugin Loading with Authority What recommendations can you give for a system which must do the following: Load Plugins (and eventually execute them) but have 2 methods of loading these plugins: Load only authorized plugins (developed by the owner of the software) Load all plugins And we need to be reasonably secure that the authorized plugins are the real deal (unmodified). However all plugins must be in seperate assemblies. I've been looking at using strong named assemblies for the plugins with the public key stored in the loader application but to me this seems too easy to modify the public key within the loader application (if the user was so inclined) regardless of any obfuscation of the loader application. Any more secure ideas? you can broaden your question : ""how can I protect my .net assemblies from reverse engineering ?"" the answer is - you can not. for those who havent seen it yet just look up ""reflector"" and run it on some naive exe. (by the way this is always the answer for code that is out of your hands as long as you do not have en/decryption hardware sent with it) obfuscating tries to make the reverse engineering to be harder (cost more money) than development and for some types of algorithems it succeeds.  Basically if you're putting your code on someone else's machine there's no absolute guarantee of security. You can look at all kinds of security tricks but in the end the code is on their machine so it's out of your control. How much do you stand to lose if the end user loads an unauthorised plugin?  Sign the assemblies. Strong-name signing or strong-naming gives a software component a globally unique identity that cannot be spoofed by someone else. Strong names are used to guarantee that component dependencies and configuration statements map to exactly the right component and component version. http://msdn.microsoft.com/en-us/library/h4fa028b(VS.80).aspx  How much do you stand to lose if the end user loads an unauthorised plugin? Admittedly this won't happen often but when/if it does happen we lose a lot and I although I understand we will produce nothing 100% secure I want to make it enough of a hindrance to put people off doing it. The annoying thing about going with a simple dynamic loading with full strong name is that all it takes is a simple string literal change within the loader app to load any other assembly even though the plugins are signed.",c# .net plugins assemblies dynamics-crm
12702,A,".Net - Returning DataTables in WCF I have a WCF service from which I want to return a DataTable. I know that this is often a highly debated topic as far as whether or not returning DataTables is a good practice. Let's put that aside for a moment. When I create a DataTable from scratch as below there are no problems whatsoever. The table is created populated and returned to the client and all is well: [DataContract] public DataTable GetTbl() { DataTable tbl = new DataTable(""testTbl""); for(int i=0;i<100;i++) { tbl.Columns.Add(i); tbl.Rows.Add(new string[]{""testValue""}); } return tbl; } However as soon as I go out and hit the database to create the table as below I get a CommunicationException ""The underlying connection was closed: The connection was closed unexpectedly."" [DataContract] public DataTable GetTbl() { DataTable tbl = new DataTable(""testTbl""); //populate table with sql query return tbl; } The table is being populated correctly on the server side. It is significantly smaller than the test table that I looped through and returned and the query is small and fast - there is no issue here with timeouts or large data transfer. The same exact functions and DataContracts/ServiceContracts/BehaviorContracts are being used. Why would the way that the table is being populated have any bearing on the table returning successfully?? I added the Datable to a data set and returned the table like so... DataTable result = new DataTable(""result""); //linq to populate the table Dataset ds = new DataSet(); ds.Tables.Add(result); return ds.Tables[0]; Hope it helps :)  Other than sessting max values for all binding attribute. Make sure each table you are passing/returning from webservice must have table name means table.tablename property should not be blank  You probably blew your quota - the datatable is larger than the allowed maximum packet size for your connection. You probably need to set MaxReceivedMessageSize and MaxBufferSize to higher values on your connection.  The best way to diagnose these kinds of WCF errors (the ones that really don't tell you much) is to enable tracing. In your web.config file add the following:  <system.diagnostics> <sources> <source name=""System.ServiceModel"" switchValue=""Information"" propagateActivity=""true""> <listeners> <add name=""ServiceModelTraceListener"" type=""System.Diagnostics.XmlWriterTraceListener System Version=2.0.0.0 Culture=neutral PublicKeyToken=b77a5c561934e089"" initializeData=""wcf-traces.svclog""/> </listeners> </source> </sources> </system.diagnostics> You can then open the resulting file in the SvcTraceViewer.exe utility which comes in the .NET Framework SDK (or with Visual Studio). On my machine it can be found at %PROGRAMFILES%\Microsoft SDKs\Windows\v6.0A\Bin\SvcTraceViewer.exe. Just look for an error message (in bold red) and that will tell you specifically what your problem is.  For anyone having similar problems I have solved my issue. It was several-fold. As Darren suggested and Paul backed up the Max..Size properties in the configuration needed to be enlarged. The SvcTraceViewer utility helped in determining this but it still does not always give the most helpful error messages. It also appears that when the Service Reference is updated on the client side the configuration will sometimes not update properly (e.g. Changing config values on the server will not always properly update on the client. I had to go in and change the Max..Size properties multiple times on both the client and server sides in the course of my debugging) My final problem seemed to be that the DataTable was not initialized with a name. I'm still trying to figure out why this matters but this: return new DataTable(); will fail where this: return new DataTable(""someName""); will not. Any input on this would be great. Hopefully that will help someone. Very strange with the name thingy. I had same problem. Setting a name on the DataTable solved it... Weird. +1 because setting a table name also fixed it for me. +1 fixed for me after I named the columns +1 Setting table name worked for me +1 Setting table name worked for me too. +1 for table name. I looked at the HTTP return in Fiddler and VS uses that table name to generate a custom datatype. If the name is null I guess it tries to use a blank name for that custom datatype and just errors out. +1 added the name to the DataTable and it worked. Great question and great answer. I remember having this problem with something else before I can't remember I think it was just classic web services. I don't want to open a can of worms but I don't feel guilty using DataTables across the pipe because if I am only using it for display information I don't think it matters at all. When you start passing DataTables and DataRows as parameters that is when it becomes a major @#$#(*@%_ up. Objects are always safer but if your data changes often because of a skitzo decision maker - then I don't see the harm just for display purposes.  The attribute you want is OperationContract (on interface) / Operation Behavior (on method) [ServiceContract] public interface ITableProvider { [OperationContract] DataTable GetTbl(); } [OperationBehavior] public DataTable GetTbl(){ DataTable tbl = new DataTable(""testTbl""); //populate table with sql query return tbl; } Also in the... i think service configuration... you want to specify that errors can be sent you might be hitting an error that is something like the message size is to big etc. You can fix that by fudging w/ the reader quotas and such. By default wsHttpBinding has a receive size quota of like 65k so if the serialized data table's xml is more than that it would throw an error (and i'm 95% sure the data table is more than 65k with data in it) You can change the settings for the reader quotas and such in the web.config / app.config or you can set it on a binding instance in code. But yeah that's probably what your problem is if you haven't changed it by default. WSHttpBindingBase Members - Look at ReaderQuotas property as well as the MaxReceivedMessageSize property  I think Darren is most likely correct - the default values provided for WCF are laughably small and if you bump into them you end up with errors that can be difficult to track down. They seem to appear as soon as you attempt to do anything beyond a simple test case. I wasted more time than I'd like to admit debugging problems that turned out to be related to the various configuration (size) settings on both the client and server. I think I ended up modifying almost all of them ex. MaxBufferPoolSize MaxBufferSize MaxConnections MaxReceivedMessageSize etc. Having said that the SvcTraceViewer utility also mentioned is great. I did run into a few cases where it wasn't as helpful as I would have liked but overall it's a nice tool for analyzing the communications flow and errors.",c# .net wcf web-services datatable
3284,A,"Why can't I have abstract static methods in C#? I've been working with providers a fair bit lately and I came across an interesting situation where I wanted to have an abstract class that had an abstract static method. I read a few posts on the topic and it sort of made sense but is there a nice clear explanation? Please leave these open to allow to future improvements. Here is a situation where there is definitely a need for inheritance for static fields and methods: abstract class Animal { protected static string[] legs; static Animal() { legs=new string[0]; } public static void printLegs() { foreach (string leg in legs) { print(leg); } } } class Human: Animal { static Human() { legs=new string[] {""left leg"" ""right leg""}; } } class Dog: Animal { static Dog() { legs=new string[] {""left foreleg"" ""right foreleg"" ""left hindleg"" ""right hindleg""}; } } public static void main() { Dog.printLegs(); Human.printLegs(); } //what is the output? //does each subclass get its own copy of the array ""legs""? No there's only one instance of the array 'legs'. Output is nondeterministic as you don't know what order the static constructors will be called (there's actually no guarantee the base class static constructor would be called at all). 'Need' is a fairly absolute term where 'desire' is probably more accurate.  Another respondent (McDowell) said that polymorphism only works for object instances. That should be qualified; there are languages that do treat classes as instances of a ""Class"" or ""Metaclass"" type. These languages do support polymorphism for both instance and class (static) methods. C# like Java and C++ before it is not such a language; the static keyword is used explicitly to denote that the method is statically-bound rather than dynamic/virtual.  Because C# design was copied from Java. And Java doesn't allow abstract static methods. -1 Because ""company""/""product""/""dev team"" is never an answer to a question like this. The original question is asking ""Why is this not supported"" And saying this is a copy is missing the point. They are asking ""Why does the original concept not include this feature"".  To add to the previous explanations static method calls are bound to a specific method at compile-time which rather rules out polymorphic behavior. C# is statically typed; calls to polymorphic methods are also bound at compile time as I understand it - that is to say the CLR is not left to resolve which method to call during runtime. So how exactly do you think polymorphism works on the CLR? Your explanation just ruled out virtual method dispatch. That's not really as useful a comment as it could be. I invited (with 'as I understand it') useful discourse think maybe you could provide a little more content - seeing as people come here looking for answers and not insults. Although it seems I may be guilty of the same thing - I really meant the above comment as a question: Doesn't C# evaluate these things at compile time? Apologies I didn't mean an insult (although I do admit to responding a bit snappily ;-). The point of my question was if you've got these classes: class Base { public virtual void Method(); } class Derived : Base { public override void Method(); } and write thusly: Base instance = new Derived(); instance.Method(); the compile-time type information on the call site is that we've got an instance of Base when the actual instance is a Derived. So the compiler can't resolve the exact method to call. Instead it emits a ""callvirt"" IL instruction that tells the runtime to dispatch.. ... whereas for static methods there's no instance to do virtual dispatch on so it always necessarily emits a ""call"" instruction. And now that I expanded on my answer I realize what a crappy answer it was. ;-) Thanks man thats informative! Guess I have been putting off the dive into IL long enough wish me luck.  Static methods are not instantiated as such they're just available without an object reference. A call to a static method is done through the class name not through an object reference and the IL code to call it will call the abstract method through the name of the class that defined it not necessarily the name of the class you used. Let me show an example. With the following code: public class A {  public static void Test()  {  } } public class B : A { } If you call B.Test like this: class Program {  static void Main(string[] args)  {  B.Test();  } } Then the actual code inside the Main method is as follows: .entrypoint .maxstack 8 L0000: nop L0001: call void ConsoleApplication1.A::Test() L0006: nop L0007: ret As you can see the call is made to A.Test because it was the A class that defined it and not to B.Test even though you can write the code that way. If you had class types like in Delphi where you can make a variable referring to a type and not an object you would have more use for virtual and thus abstract static methods (and also constructors) but they aren't available and thus static calls are non-virtual in .NET. I realize that the IL designers could allow the code to be compiled to call B.Test and resolve the call at runtime but it still wouldn't be virtual as you would still have to write some kind of class name there. Virtual methods and thus abstract ones are only useful when you're using a variable which at runtime can contain many different types of objects and you thus want to call the right method for the current object you have in the variable. With static methods you need to go through a class name anyway so the exact method to call is known at compile time because it can't and won't change. Thus virtual/abstract static methods are not available in .NET. Combined with the way operator-overloading is done in C# this unfortunately eliminates the possibility of requiring subclasses to provide an implementation for a given operator overload. I don't find this answer terribly useful as the definition of `Test()` is in `A` rather than being abstract and potentially defined in `B`.\ Generic type parameters effectively behave as non-persistable ""type"" variables and virtual static methods could be useful in such context. For example if one had a `Car` type with a virtual static `CreateFromDescription` factory method then code which accepted a `Car`-constrained generic type `T` could call `T.CreateFromDescription` to produce a car of type `T`. Such a construct could be supported pretty well within the CLR if each type which defined such a method held a static singleton instance of a nested class generic which held the virtual ""static"" methods.  We actually override static methods (in delphi) it's a bit ugly but it works just fine for our needs. We use it so the classes can have a list of their available objects without the class instance for example we have a method that looks like this: class function AvailableObjects: string; override; begin Result := 'Object1 Object2'; end; It's ugly but necessary this way we can instantiate just what is needed instead of having all the classes instantianted just to search for the available objects. This was a simple example but the application itself is a client-server application which has all the classes available in just one server and multiple different clients which might not need everything the server has and will never need an object instance. So this is much easier to maintain than having one different server application for each client. Hope the example was clear.  Static methods cannot be inherited or overridden and that is why they can't be abstract. Since static methods are defined on the type not the instance of a class they must be called explicitly on that type. So when you want to call a method on a child class you need to use its name to call it. This makes inheritance irrelevant. Assume you could for a moment inherit static methods. Imagine this scenario: public static class Base {  public static virtual int GetNumber() { return 5; } } public static class Child1 : Base {  public static override int GetNumber() { return 1; } } public static class Child2 : Base {  public static override int GetNumber() { return 2; } } If you call Base.GetNumber() which method would be called? Which value returned? Its pretty easy to see that without creating instances of objects inheritance is rather hard. Abstract methods without inheritance are just methods that don't have a body so can't be called. Given your scenario i would say Base.GetNumber() would return 5; Child1.GetNumber() returns 1; Child2.GetNumber() returns 2; Can you prove me wrong to help me understand your reasoning? Thank you The face that you think Base.GetNumber() returns 5 means that you already understand what is going on. By returning the base value there is no inheritance going on. Why in the world would Base.GetNumber() return anything else but 5? It's a method in the base class - there's only 1 option there. @ArtemRussakovskii: Suppose one had `int DoSomething() where T:Base {return T.GetNumber();}`. It would seem useful if `DoSomething()` could return five while `DoSomething()` would return two. Such ability would be not only useful for toy examples but also for something like `class Car {public static virtual Car Build(PurchaseOrder PO);}` where every class deriving from `Car` would have to define a method which could build an instance given a purchase order. There is exactly same ""problem"" with non-static inheritance.  The abstract methods are implicitly virtual. Abstract methods require an instance but static methods do not have an instance. So you can have a static method in an abstract class it just cannot be static abstract (or abstract static). -1 virtual methods do not need an instance except by design. And you do not actually address the question so much as deflect it.",c# .net language-design
19517,A,"Is anybody using the Specter BDD Framework? I was reading the example chapter from the book by Ayende and on the website of the Boo language I saw a reference to the Specter BDD Framework. I am wondering if anybody is using it in their project how that works out and if there are more examples and/or suggested readings. Just in case you are wondering I'm a C# developer and so I plan to use it in a C#/.NET environment. A few year later visiting this question. I think we can safely assume Specflow and some others like NSpec became the tools we are using. I'm not using it but I've seen demos of it. It's very nice. Boo has a lot of interesting extensibility points in parsing and interpreting the language itself that make it ideal for writing frameworks like Specter. The end result is much nicer looking than you'd be able to get with languages like C#. Unfortunately the fact that Boo isn't ""in the box"" and can't simply be something you check into your source tree and use really holds it back here. It's a much heavier adoption cost than just picking a framework like NSpec.  I have used it a little I'm starting a new project right now and I plan on using specter. I'm really enjoying it.",c# .net bdd boo
10855,A,"LINQ query on a DataTable I'm trying to perform a LINQ query on a DataTable object and bizarrely I am finding that performing such queries on DataTables is not straightforward. For example: var results = from myRow in myDataTable where results.Field(""RowNo"") == 1 select results; This is not allowed. How do I get something like this working? I'm amazed that LINQ queries are not allowed on DataTables! You can find more LINQ/Lambda example from http://webmingle.blogspot.com/2010_09_01_archive.html You want what's known as [LINQ to DataSet](http://blogs.msdn.com/adonet/archive/2007/01/26/querying-datasets-introduction-to-linq-to-dataset.aspx). That link will take you to the first in a series of posts introducing it on the ADO.NET team blog. LinqTutorial.net domain has expired as of time of checking. It's not that they were deliberately not allowed on DataTables it's just that DataTables pre-date the IQueryable and generic IEnumerable constructs on which Linq queries can be performed. Both interfaces require some sort type-safety validation. DataTables are not strongly typed. This is the same reason why people can't query against an ArrayList for example. For Linq to work you need to map your results against type-safe objects and query against that instead. +1 ""understanding"" is better than ""knowing""  For VB.NET The code will look like this: Dim results = From myRow In myDataTable Where myRow.Field(Of Int32)(""RowNo"") = 1 Select myRow  Try this var row = (from result in dt.AsEnumerable().OrderBy( result => Guid.NewGuid()) select result).Take(3) ;  Most likely the classes for the DataSet DataTable and DataRow are already defined in the solution. If that's the case you won't need the DataSetExtensions reference. Ex. DataSet class name-> CustomSet DataRow class name-> CustomTableRow (with defined columns: RowNo ...) var result = from myRow in myDataTable.Rows.OfType<CustomSet.CustomTableRow>() where myRow.RowNo == 1 select myRow; Or (as I prefer) var result = myDataTable.Rows.OfType<CustomSet.CustomTableRow>().Where(myRow => myRow.RowNo); Happy coding!  Try this...  SqlCommand cmd = new SqlCommand( ""Select * from Employee""con); SqlDataReader dr = cmd.ExecuteReader( ); DataTable dt = new DataTable( ""Employee"" ); dt.Load( dr ); var Data = dt.AsEnumerable( ); var names = from emp in Data select emp.Field<String>( dt.Columns[1] ); foreach( var name in names ) { Console.WriteLine( name ); }  var query = from p in dt.AsEnumerable() where p.Field<string>(""code"") == this.txtCat.Text select new { name = p.Field<string>(""name"") age= p.Field<int>(""age"") };  You can't query against the DataTable's Rows collection since DataRowCollection doesn't implement IEnumerable<T>. You need to use the AsEnumerable() extension for DataTable. Like so: var results = from myRow in myDataTable.AsEnumerable() where myRow.Field<int>(""RowNo"") == 1 select myRow; And as Keith says you'll need to add a reference to System.Data.DataSetExtensions AsEnumerable() returns IEnumerable<DataRow>. If you need to convert IEnumerable<DataRow> to a DataTable use the CopyToDataTable() extension. VB Version: Dim results = From myRow In myDataTable.AsEnumerable _ Where myRow.Field(""RowNo"") = 1 _ Select myRow I already had a reference to the dll mentioned but was missing `using System.Data;` How do I get DataTable back from var results ? VB Version needs to insert (Of String) between myRow.Field and (""RowNo""). That part should read: myRow.Field(Of String)(""RowNo"") = 1 - Reference @Cros comment. this solution is needlessly complicated. Use `myDataTable.Rows` instead as @JoelFan suggested. @Markus Just to clarify the reason that @JoelFan's solution works with `myDataTable.Rows` is because the `myRow` variable is explicitly cast to `DataRow`. When it is compiled that query is rewritten to `myDataTable.Rows.Cast().Where(myRow => (int)myRow[""RowNo""] == 1)`. Personally I don't find the call to `AsEnumerable()` any more complicated than the call to `Cast()`. As far as I know the performance is the same so it's just a matter of preference. `...If you need to convert IEnumerable to aDataTable use the CopyToDataTable() extension.` this I have ben searching for ;)  Using LINQ to manipulate data in DataSet/DataTable var results = from myRow in tblCurrentStock.AsEnumerable() where myRow.Field<string>(""item_name"").ToUpper().StartsWith(tbSearchItem.Text.ToUpper()) select myRow; DataView view = results.AsDataView(); The AsDataView doesn't appear in Intellisense for me. I included using System.Data.Linq and using System.Linq but still it's not working. Do you know what am I missing? Thanks in advance. @Naomi It comes from `System.Data.DataSetExtensions`.  You can get it work elegant via linq like this: from prod in TenMostExpensiveProducts().Tables[0].AsEnumerable() where prod.Field<decimal>(""UnitPrice"") > 62.500M select prod Or like dynamic linq this (AsDynamic is called directly on DataSet): TenMostExpensiveProducts().AsDynamic().Where (x => x.UnitPrice > 62.500M) I prefer the last approach while is is the most flexible. P.S.: Don't forget to connect System.Data.DataSetExtensions.dll reference  As @ch00k said: using System.Data; //needed for the extension methods to work ... var results = from myRow in myDataTable.Rows where myRow.Field<int>(""RowNo"") == 1 select myRow; //select the thing you want not the collection You also need to add a project reference to System.Data.DataSetExtensions  var results = from DataRow myRow in myDataTable.Rows where (int)myRow[""RowNo""] == 1 select myRow this should be the accepted solution. it's so simple!  You can use LINQ to objects on the Rows collection like so: var results = from myRow in myDataTable.Rows where myRow.Field(""RowNo"") == 1 select myRow;  var results = from myRow in myDataTable where results.Field<Int32>(""RowNo"") == 1 select results;  //Create DataTable DataTable dt= New DataTable(); dt.Columns.AddRange(New DataColumn[] { new DataColumn(""ID""typeOf(System.Int32)) new DataColumn(""Name""typeOf(System.String)) }); //Fill with data dt.Rows.Add(New Object[]{1""Test1""}); dt.Rows.Add(New Object[]{2""Test2""}); //Now Query DataTable with linq //To work with linq it should required our source implement IEnumerable interface. //But DataTable not Implement IEnumerable interface //So we call DataTable Extension method i.e AsEnumerable() this will return EnumerableRowCollection<DataRow> // Now Query DataTable to find Row whoes ID=1 DataRow drow = dt.AsEnumerable().Where(p=>P.Field<Int32>(0)==1).FirstOrDefault(); // Next time please explain your code a bit more. Thanks.",c# .net linq datatable .net-3.5
1189,A,"ViewState invalid only in Safari One of the sites I maintain relies heavily on use of ViewState (it isn't my code). However on certain pages where the ViewState is extra-bloated Safari throws a ""Validation of viewstate MAC failed"" error. This appears to only happen in Safari. Firefox IE and Opera all load successfully in the same scenario. I've been doing a little research into this and whilst I'm not entirely sure its the cause I believe it is because Safari is not returning the full result set (hence cropping it). I have been in dicussion with another developer and found the following post on Channel 9 as well which recommends making use of the SQL State service to store the viewstate avoiding the postback issue and also page size. http://channel9.msdn.com/forums/TechOff/250549-ASPNET-ViewState-flawed-architecture/?CommentID=270477#263702 Does this seem like the best solution?  My first port of call would be to go through the elements on the page and see which controls: Will still work when I switch ViewState off Can be moved out of the page and into an AJAX call to be loaded when required Failing that and here's the disclaimer - I've never used this solution on a web-facing site - but in the past where I've wanted to eliminate massive ViewStates in limited-audience applications I have stored the ViewState in the Session. It has worked for me because the hit to memory isn't significant for the number of users but if you're running a fairly popular site I wouldn't recommend this approach. However if the Session solution works for Safari you could always detect the user agent and fudge appropriately.  While I second the Channel 9 solution also be aware that in some hosted environments Safari is not considered an up-level browser. You may need to add it to your application's browscap in order to make use of some ASP.Net features. That was the root cause of some headaches we had for a client's site that used the ASP Menu control.",c# .net safari viewstate
5863,A,"WCF Service - Backward compatibility issue I'm just getting into creating some WCF services but I have a requirement to make them backward compatible for legacy (.NET 1.1 and 2.0) client applications. I've managed to get the services to run correctly for 3.0 and greater clients but when I publish the services using a basicHttpBinding endpoint (which I believe is required for the compatibility I need) the service refactors my method signatures. e.g. public bool MethodToReturnTrue(string seedValue); appears to the client apps as public void MethodToReturnTrue(string seedValue out bool result out bool MethodToReturnTrueResultSpecified); I've tried every configuration parameter I can think of in the app.config for my self-hosting console app but I can't seem to make this function as expected. I suppose this might lead to the fact that my expectations are flawed but I'd be surprised that a WCF service is incapable of handling a bool return type to a down-level client. My current app.config looks like this. <?xml version=""1.0"" encoding=""utf-8"" ?> <configuration> <system.serviceModel> <services> <service behaviorConfiguration=""MyServiceTypeBehaviors"" Name=""MyCompany.Services.CentreService.CentreService""> <clear /> <endpoint address=""http://localhost:8080/CSMEX"" binding=""basicHttpBinding"" bindingConfiguration="""" contract=""IMetadataExchange"" /> <endpoint address=""http://localhost:8080/CentreService"" binding=""basicHttpBinding"" bindingName=""Compatible"" name=""basicEndpoint"" contract=""MyCompany.Services.CentreService.ICentreService"" /> </service> </services> <behaviors> <serviceBehaviors> <behavior name=""MyServiceTypeBehaviors"" > <serviceMetadata httpGetEnabled=""true"" /> </behavior> </serviceBehaviors> </behaviors> </system.serviceModel> </configuration> Can anyone advise please? You do have to use the XmlSerializer. For example: [ServiceContract(Namespace=""CentreServiceNamespace"")] [XmlSerializerFormat(Style=OperationFormatStyle.Document SupportFaults=true Use=OperationFormatUse.Literal)] public interface ICentreService { [OperationContract(Action=""CentreServiceNamespace/MethodToReturnTrue"")] bool MethodToReturnTrue(string seedValue); } You have to manually set the operation action name because the auto-generated WCF name is constructed differently from the ASMX action name (WCF includes the interface name as well ASMX does not). Any data contracts you use should be decorated with [XmlType] rather than [DataContract]. Your config file should not need to change.  Ah this is killing me! I did this at work about 3 months ago and now I can't remember all the details. I do remember however that you need basicHttpBinding and you can't use the new serializer (which is the default); you have to use the ""old"" XmlSerializer. Unfortunately I don't work at the place where I did this anymore so I can't go look at the code. I'll call my boss and see what I can dig up.  OK we needed to resolve this issue in the short term and so we came up with the idea of a ""interop"" or compatibility layer. Baiscally all we did was added a traditional ASMX web service to the project and called the WCF service from that using native WCF calls. We were then able to return the appropriate types back to the client applications without a significant amount of re-factoring work. I know it was a hacky solution but it was the best option we had with such a large legacy code-base. And the added bonus is that it actually works surprisingly well. :)",c# .net wcf web-services backwards-compatibility
4610,A,"C#.Net Prototype Methods How is it possible to make prototype methods in C#.Net? In JavaScript I can do the following to create a trim method for the string object: String.prototype.trim = function() { return this.replace(/^\s+|\s+$/g""""); } How can I go about doing this in C#.Net? Using the 3.5 compiler you can use an Extension Method: public static void Trim(this string s) {  // implementation } You can use this on a CLR 2.0 targeted project (3.5 compiler) by including this hack: namespace System.Runtime.CompilerServices {  [AttributeUsage(AttributeTargets.Method | AttributeTargets.Class | AttributeTargets.Assembly)]  public sealed class ExtensionAttribute : Attribute  {  } }  You can't dynamically add methods to existing objects or classes in .NET except by changing the source for that class. You can however in C# 3.0 use extension methods which look like new methods but are compile-time magic. To do this for your code: public static class StringExtensions {  public static String trim(this String s)  {  return s.Trim();  } } To use it: String s = "" Test ""; s = s.trim(); This looks like a new method but will compile the exact same way as this code: String s = "" Test ""; s = StringExtensions.trim(s); What exactly are you trying to accomplish? Perhaps there are better ways of doing what you want? Thanks Lassevk great answer :) In response to ""What exactly are you trying to accomplish?"". Every now and again I have the need to manipulate a string or other object. Instead of having to call a function todo this I would have thought it better to call it as a method. I'm currently writting web applications in Asp.net and I don't think there Asp.net 3.x yet so I'll have to wait for now. But thanks for your answer.  You need to create an extension method which requires .NET 3.5. The method needs to be static in a static class. The first parameter of the method needs to be prefixed with ""this"" in the signature. public static string MyMethod(this string input) {  // do things } You can then call it like ""asdfas"".MyMethod();  It sounds like you're talking about C#'s Extension Methods. You add functionality to existing classes by inserting the ""this"" keyword before the first parameter. The method has to be a static method in a static class. Strings in .NET already have a ""Trim"" method so I'll use another example. public static class MyStringEtensions { public static bool ContainsMabster(this string s) { return s.Contains(""Mabster""); } } So now every string has a tremendously useful ContainsMabster method which I can use like this: if (""Why hello there Mabster!"".ContainsMabster()) { /* ... */ } Note that you can also add extension methods to interfaces (eg IList) which means that any class implementing that interface will also pick up that new method. Any extra parameters you declare in the extension method (after the first ""this"" parameter) are treated as normal parameters.",c# .net
17170,A,"When to use IList and when to use List I know that IList is the interface and List is the concrete type but I still don't know when to use each one. What I'm doing now is if I don't need the Sort or FindAll methods I use the interface. Am I right? Is there a better way to decide when to use the interface or the concrete type? AList object allows you to create a list add things to it remove it update it index into it and etc. List is used whenever you just want a generic List where you specify object type in it and that's it. IList on the other hand is an Interface. Basically if you want to create your own type of List say a list class called BookList then you can use the Interface to give you basic methods and structure to your new class. IList is for when you want to create your own special sub-class that implements List. Another difference is: IList is an Interface and cannot be instantiated. List is a class and can be instantiated. It means: IList<string> MyList = new IList<string>(); List<string> MyList = new List<string>  Microsoft guidelines as checked by FxCop discourage use of List<T> in public APIs - prefer IList<T>. Incidentally I now almost always declare one-dimensional arrays as IList<T> which means I can consistently use the IList<T>.Count property rather than Array.Length. For example: public interface IMyApi { IList<int> GetReadOnlyValues(); } public class MyApiImplementation : IMyApi { public IList<int> GetReadOnlyValues() { List<int> myList = new List<int>(); ... populate list return myList.AsReadOnly(); } } public class MyMockApiImplementationForUnitTests : IMyApi { public IList<int> GetReadOnlyValues() { IList<int> testValues = new int[] { 1 2 3 }; return testValues; } } I like this explanation / example the most!  There are two rules I follow: Accept the most basic type that will work Return the richest type your user will need So when writing a function or method that takes a collection write it not to take a List but an IList<T> an ICollection<T> or IEnumerable<T>. The generic interfaces will still work even for heterogenous lists because System.Object can be a T too. Doing this will save you headache if you decide to use a Stack or some other data structure further down the road. If all you need to do in the function is foreach through it IEnumerable<T> is really all you should be asking for. On the other hand when returning an object out of a function you want to give the user the richest possible set of operations without them having to cast around. So in that case if it's a List<T> internally return a copy as a List<T>. You shouldn't treat input/output types any differently. Input and output types should *both* be the most basic type (preferably interface) that will support clients needs. Encapsulation relies on telling clients as little about the implementation of your class as possible. If you return a concrete List you can't then change to some other better type without forcing all of your clients to re-compile/update. I disagree with the 2 rules... I would use most primitive type and specialy when returning in this case IList (better IEnumarable) and you should work with List in your function inside. Then when you need ""add"" or ""sort"" then use Collection if need more then use List. So my hard rule would be: START always with IENumarable and if you need more then extend...  In situations I usually come across I rarely use IList directly. Usually I just use it as an argument to a method void ProcessArrayData(IList almostAnyTypeOfArray) { // Do some stuff with the IList array } This will allow me to do generic processing on almost any array in the .NET framework unless it uses IEnumerable and not IList which happens sometimes. It really comes down to the kind of functionality you need. I'd suggest using the List class in most cases. IList is best for when you need to make a custom array that could have some very specific rules that you'd like to encapsulate within a collection so you don't repeat yourself but still want .NET to recognize it as a list.  I would agree with Lee's advice for taking parameters but not returning. If you specify your methods to return an interface that means you are free to change the exact implementation later on without the consuming method ever knowing. I thought I'd never need to change from a List<T> but had to later change to use a custom list library for the extra functionality it provided. Because I'd only returned an IList<T> none of the people that used the library had to change their code. Of course that only need apply to methods that are externally visible (i.e. public methods). I personally use interfaces even in internal code but as you are able to change all the code yourself if you make breaking changes it's not strictly necessary.  I don't think there are hard and fast rules for this type of thing but I usually go by the guideline of using the lightest possible way until absolutely necessary. For example let's say you have a Person class and a Group class. A Group instance has many people so a List here would make sense. When I declare the list object in Group I will use an IList<Person> and instantiate it as a List. public class Group { private IList<Person> people; public Group() { this.people = new List<Person>(); } } And if you don't even need everything in IList you can always use IEnumerable too. With modern compilers and processors I don't think there is really any speed difference so this is more just a matter of style. why not make it a just a List in the first place? I still don't understand why bonus you get from making it a IList then in the constructor you make it into a List<>  If you're working within a single method (or even in a single class or assembly in some cases) and no one outside is going to see what you're doing use the fullness of a List. But if you're interacting with outside code like when you're returning a list from a method then you only want to declare the interface without necessarily tying yourself to a specific implementation especially if you have no control over who compiles against your code afterward. If you started with a concrete type and you decided to change to another one even if it uses the same interface you're going to break someone else's code unless you started off with an interface or abstract base type.  There's an important thing that people always seem to overlook: You can pass a plain array to something which accepts an IList<T> parameter and then you can call IList.Add() and will receive a runtime exception: Unhandled Exception: System.NotSupportedException: Collection was of a fixed size. For example consider the following code: private void test(IList<int> list) { list.Add(1); } If you call that as follows you will get a runtime exception: int[] array = new int[0]; test(array); This happens because using plain arrays with IList<T> violates the Liskov substitution principle. For this reason if you are calling IList<T>.Add() you may want to consider requiring a List<T> instead of an IList<T>.  It's always best to use the lowest base type possible. This gives the implementer of your interface or consumer of your method the opportunity to use whatever they like behind the scenes. For collections you should aim to use IEnumerable where possible. This gives the most flexibility but is not always suited.  You should use the interface only if you need it e.g. if your list is casted to an IList implementation other than List. This is true when for example you use NHibernate which casts ILists into an NHibernate bag object when retrieving data. If List is the only implementation that you will ever use for a certain collection feel free to declare it as a concrete List implementation.  IEnumerable you should try and use the least specific type that suits your purpose. IEnumerable is less specific than IList You use IEnumerable when you want to loop through the items in a collection IList IList implements IEnumerable You should use IList when you need access by index to your collection add and delete elements etc.. List List implements IList Excellent clear answer which I marked as helpful. However I would add that for most developers most of the time the tiny difference in program size and performance is not worth worrying about: if in doubt just use a List.  You are most often better of using the most general usable type in this case the IList or even better the IEnumerable interface so that you can switch the implementation conveniently at a later time. However in .NET 2.0 there is an annoying thing - IList does not have a Sort() method. You can use a supplied adapter instead: ArrayList.Adapter(list).Sort()",c# .net
2214,A,"What's the best way to implement BDD/TDD in .NET 2.0? I'm looking to add a testing suite to my application however I can't move to the newer testing frameworks for .NET 3.5. Does anyone have a suggestion about good testing frameworks to use? I am going to have to put a shout out for Moq. It is clean light mocking framework that helps guide you into the pit of success. The testing tools built into TFS are okay they will get the job done but can often be a little cumbersome to work with. The generated reports code coverage and a few other portions are particularly bad they make you go bald at 22 rather than 50. If you are really loving the testing consider trying some Continuous Integration. You will feel the pain from regression quickly and potentially help you get to the end goal faster. Regardless of what you do try out a few and see which one is the most natural if you have time. Good luck and happy coding. The problem with Moq is that it require .NET 3.5 because it uses lambda expressions and expressions trees. Not necessarily a horrible thing but you are right this would hold back a v2.0 shop.  NUnit is always a favorite of mine. However if you are using TFS as your source control I suggest you stick with the Microsoft Stack. There are no compelling reasons to use MS Test over NUnit or MbUnit. It is flat out an inferior tool. Seconded. My recommendation is MbUnit. That wasn't really my point with MS Test there is a lot of nice surger that TFS gives you when combined with MS Test.  For my project I used NUnit and TestDriven.NET with great success. You can either create a separate library just to host your test code or you can put it in your executable or library. It all depend if you want your production code to be intertwine with your test code. For Dependency Injection I use NInject in my current project and its work great. If you use Constructor injection you don't need to clutter your code with the [Inject] attribute. I haven't used a mock library for my .NET 2.0 project but for another .NET 3.5 project I will use Moq Note that all this works with .NET 2.0 and higher. (except Moq)  For a Mock Object library I've found the BSD-licensed Rhino.Mocks to be rather pleasing.  I've had great success using NUnit as well. I've also used NMock when the need arose for mock objects. As an added bonus the factory for creating your mock objects is called the Mockery. To facilitate the running of unit tests I've used TestDriven.NET to run unit tests as I coded. Also I've used Cruise Control .NET to watch SVN and check that every new commit builds and passes all unit tests. NMock's over use of magic strings makes it a poor choice for a mocking framework. RhinoMocks or Moq are better choices because they rely on strong typing.  I recommend the following: TestDriven.NET - Unit Testing add on for VS that is fully integrated with all major unit testing frameworks including NUnit MbUnit etc... Typemock Isolator- A mocking framework for .Net Unit Testing NUnit - An open source unit testing framework that is in C#.  We use MbUnit and Rihno Mocks and they prove to work very well together. When doing TDD you will almost certainly need to do some form of dependency injection while this can be done manually its worth looking at an IoC container such as Castle Windor. It well worth looking at John Paul Bodhood's screen casts to get you started. JPB's Blog  NUnit is available at http://www.nunit.org I would suggest this even when working on the MS stack - the support for non-MS frameworks is happening in the MVC previews which shows a definate movement in the right direction to allow us all to customise our stacks to fit.  Using nUnit with TFS isn't too difficult. There's even a project on codeplex to implement this: NUnit for Team Build which even ""publishes"" the results to the warehouse. I haven't tried it - but I would advise clients who have a large investment (or who have a strong preference for it over the MSTest tool) in nUnit who are interested in implementing TFS to continue with nUnit as opposed to trying convert all their existing tests.  This is probably a summary of what has already been said but for TDD I personally use Rhino Mocks and MBUnit. Rhino Mocks is a mocking framework that is free and open source. The advantage of Rhino Mocks is we do not need to use magic strings in setting your expectations as you do in NMock. I like MBUnit because MbUnit has the concept of RowTests which allow you to vary your inputs to your test method. MBUnit is also freely available. You also want to make sure that whatever you choose for your unit testing framework is supported by your CI (Continuous Integration Server). Nunit is supported by default in Cruise Control.NET and you have to do a little extra work to get MBUnit to work in ccnet. From an IDE standpoint you must have TestDriven.NET. TestDriven.NET allows you to right click and run tests in the IDE and it supports MBUnit and Nunit and others. NBehave is the BDD library I have used. I have not used any others so I could not compare and contrast them with you but NBehave is supported by Gallio from the MBUnit team which means you can run your BDD tests just as you would your unit tests with TestDriven.NET. I would also highly recommend Resharper. You will find your productivity increase significantly with this refactoring and guidance tool. It will assist you with changing your code as you are developing your tests. Hope this helps  NUnit and Rhino suit well and the auto-mocking container might be of interest. If you're looking at BDD too then NBehave is probably a good choice. If however you just mean the style of BDD that relates to unit testing (xSpec) though you can get away with adding a framework (though things like specunit do add some synctactic sugar) but you might want to look at MSpec is also interesting.  Check out Rob Conery's screencast on BDD using MSpec. Very impressive http://blog.wekeroad.com/mvc-storefront/kona-3/",c# .net testing tdd bdd
24644,A,"Hooking my program with windows explorer's rename event Is there any way in any language to hook my program when a user renames a file? For example: A user renames a file and presses enter (or clicks away) to confirm the rename action. BEFORE the file is actually renamed my program ""listens"" to this event and pops up a message saying ""Are you sure you want to rename C:\test\file.txt to C:\test\test.txt?"". I'm thinking/hoping this is possible with C++ C# or .NET.. But I don't have any clue where to look for. Thank you. You can probably solve this by using the FileSystemWatcher class in .NET framework. From the class remarks: You can watch for renaming deletion or creation of files or directories. For example to watch for renaming of text files set the Filter property to ""*.txt"" and call the WaitForChanged method with a Renamed specified for its parameter.  IFileOperationProgressSink.PreRenameItem is the closest supported thing I know of. Unfortunately it's not a hook into Explorer - so you can only use it for your own IFileOperation actions. Depending on your needs you can write a shell extension to do your own ConfirmRename (or something) and branch from there. Otherwise you're looking at hooking SHFileOperation I think. This would have to be done in unmanaged code as you'll be loaded into Explorer.exe. For Vista this has been changed to IFileOperation - which probably means you'll have to hook the creation of it and pass out your mock. Personally I think since you're talking a rename wilhelmtell's idea of confirming after the change and undoing it if necessary is the best idea.  My guess is that this is not possible I did find this which is for monitoring operations (including rename) on a folder but there does not appear to be a similar method for files. @Richard FileSystemWatcher is good if you only need to monitor changes but he needs to interrupt them which it cannot do.",c# .net file io
14029,A,Disabling a ListView in C# but still showing the current selection I have a ListView control and I'm trying to figure out the easiest/best way to disallow changing the selected row(s) without hiding the selected row(s). I know there's a HideSelection property but that only works when the ListView is still enabled (but not focused). I need the selection to be viewable even when the ListView is disabled. How can I implement this? You could also make the ListView ownerdraw. You then have complete control over how the items look whether they are selected or not or whether the ListView itself is enabled or not. The DrawListViewItemEventArgs provides a way to ask the ListView to draw individual parts of the item so you only have to draw the bits you're interested in. For example you can draw the background of the item but leave it up to the ListView to draw the text.  There are two options change the selected rows disabled colors. Or change all the other rows to simulate they are disabled except for the selected one. The first option is obviously the easiest and the second option obviously is going to need some extra protections. I have actually done the first option before and it works quite well. You just have to remember to change the colors back to the defaults in case another row is selected later on in the process.  Implement SelectedIndexChanged and do this  private void listViewABC_SelectedIndexChanged(object sender EventArgs e) { listViewABC.SelectedItems.Clear(); },c# .net winforms listview
26369,A,"What is the best way to store user settings for a .NET application? I have a .NET 2.0 Windows Forms application. Where is the best place the store user settings (considering Windows guidelines)? Some people pointed to Application.LocalUserAppDataPath. However that creates a folder structure like: C:\Documents and Settings\user_name\Local Settings\Application Data\company_name\product_name\product_version\ If I release version 1 of my application and store an XML file there then release version 2 that would change to a different folder right? I'd prefer to have a single folder per user to store settings regardless of the application version. I think [this article](http://blog.kowalczyk.info/kb/getting-user-specific-application-data-directory-for-.net-winforms-apps.html) covers the solution. Or write your settings in a xml file and save it using Isolated Storage. Depending on the store you use it saves it in the Application Data folder. You can also choose a roaming enabled store which means when the user logs on a different computer the settings move with them.  Isolated storage is primarily used for applications distributed using ClickOnce and are run in a secure sandbox. The base path is decided for you and you won't be able infer it in your code. The path will be something like ""\LocalSettings\ApplicationData\IsolatedStorage\ejwnwe.302\kfiwemqi.owx\url.asdaiojwejoieajae...."" not all that friendly. Your storage space is also limited. Ryan Farley has it right.  I love using the built-in Application Settings. Then you have built in support for using the settings designer if you want at design-time or at runtime to use: // read setting string setting1 = (string)Settings.Default[""MySetting1""]; // save setting Settings.Default[""MySetting2""] = ""My Setting Value""; It does store the settings in a similar folder structure as you describe (with the version in the path). However with a simple call to: Properties.Settings.Default.Upgrade(); The app will pull all previous versions settings in to save in. Thanks for the Upgrade() tip. the only annoying thing about `Settings.Default` is that you need to create them manually beforehand unlike `NSUserDefaults` in Cocoa that returns nil if a setting does not exist. Which namespace is this in? I don't seem to have access to a Settings object in my .NET 4 winforms app. Properties.Settings.Default Ryan Farley. How to use the above settings in multi user environment @Anjali the settings are stored in a user specific folder so each user in a multiuser environment will have their own settings file based on their own user environment. Unless you're asking how to have them share settings can't do that. @RyanFarley you know how to use application settings in multi user environment  I'd go down the folder list you posted except for the product version. You don't want the settings reset after an update is released. I'm actually moving away from the registry for user settings because of the debug/footprint factor. I'm currently only storing a few basic settings (window size position version of a data file) in the registry and I've run into more problems if an update goes bad or a user loses a second monitor and that is where the application was opening to. A few of them are savvy enough to understand regedit but for the rest they have to do a reinstall which is quick but I think they grumble a bit. With the file based version all I'd have to do is have them open up an XML file in Notepad and make a quick tweak. In addition I'm looking to make my application runnable off a USB flash drive and having the settings tied into the file seems much friendlier to that process. I'm sure I can do some code to check/clean the registry but I think most of us are already tired of the registry clutter that seems to eat up our machines nowadays. I know there are some security tradeoffs to this but none of the data I'm sorting is that critical to that cause and I'm not suffering any performance hits due to the size of the application.  One approach that has worked for me in the past has been to create a settings class and use XML serialization to write it to the file system. You could extend this concept by creating a collection of settings objects and serializing it. You would have all of your settings for all users in one place without having to worry about managing the file system. Before anyone gives me any flak for partially re-inventing the wheel let me say a few things. For one it is only a few lines of code to serialize and write the file. Secondly if you have an object that contains your settings you don't have to make multiple calls to the appSettings object when you load your app. And lastly it is very easy to add items that represent your applications state thereby allowing you to resume a long-running task when the application loads next. If you're willing to build custom XML serialization why not serialize it into a single application setting? That way you get to use the app settings infrastructure. Create a serializable class or type converter and then import the class using the app settings dialog.  .NET applications have a built-in settings mechanism that is easy to use. The problem with it in my opinion is that it stores those settings off into a rather obscure directory and end users will not be able to find it. Moreover just switching from debug to release build changes the location of this directory meaning that any settings saved in one configuration are lost in the other. For these and other reasons I came up with my own settings code for Windows Forms. It's not quite as slick as the one that comes with .NET but it's more flexible and I use it all the time.  Settings are standard key-value pairs (string-string). I could wrap them in an XML file if that helps. I'd rather use the file system instead of the registry. It seems to be easier to maintain. In support scenarios if the user needs to manually open/change the settings that would be easier if it's in the file system.",c# .net
25158,A,"Building C# .NET windows application with multiple views I'm rewriting an old application and use this as a good opportunity to try out C# and .NET development (I usually do a lot of plug-in stuff in C). The application is basically a timer collecting data. It has a start view with a button to start the measurement. During the measurement the app has five different views depending on what information the user wants to see. What is the best practice to switch between the views? From start to running? Between the running views? Ideas: Use one form and hide and show controls Use one start form and then a form with a TabControl Use six separate forms Creating a bunch of overlaid panels is a design-time nightmare. I would suggest using a tab control with each ""view"" on a separate tab and then picking the correct tab at runtime. You can avoid showing the tab headers by putting something like this in your form's Load event: tabControl1.Top = tabControl1.Top - tabControl1.ItemSize.Height; tabControl1.Height = tabControl1.Height + tabControl1.ItemSize.Height; tabControl1.Region = new Region(new RectangleF(tabPage1.Left tabPage1.Top tabPage1.Width tabPage1.Height + tabControl1.ItemSize.Height)); If the tabControl is 'fill' docked inside another container and if you resize that container the tab control no longer fill docks to the parent container if you use the above code. Just fyi. Thanks  Tabbed forms are usually good... but only if you want the user to be able to see any view at any time... and it sounds like you might not. Separate forms definitely works but you need to make sure that the switch is seemless...if you make sure the new form appears the same exact size and location of the old form it will look like it thew same for with changing controls. The method I often use is actually to pre-setup all my controls on individual ""Panel"" controls and then show and hide these panels as I need them. The ""Panel"" control is basically a control container... you can move the panel and all controls on it move relative. And if you show or hide the panel the controls on it do the same. They are great for situations like this.  What I do is to have a Panel where your different views will sit on the main form. then create user controls for your different views. Then when I want to switch between a'view' you dock it to Panel on the main form.. code looks a little like this. i preffer this because you can then reuse your views like if you want to open up a view in a tab you can dock your user controls inside tab pages.. or even inherit from tabpage instead of usercontrol to make things a bit more generic public partial class MainForm : Form { public enum FormViews { A B } private MyViewA viewA; //user control with view a on it private MyViewB viewB; //user control with view b on it private FormViews _formView; public FormViews FormView { get { return _formView; } set { _formView = value; OnFormViewChanged(_formView); } } protected virtual void OnFormViewChanged(FormViews view) { //contentPanel is just a System.Windows.Forms.Panel docked to fill the form switch (view) { case FormViews.A: if (viewA != null) viewA = new MyViewA(); //extension method you could use a static function. this.contentPanel.DockControl(viewA); break; case FormViews.B: if (viewB != null) viewB = new MyViewB(); this.contentPanel.DockControl(viewB); break; } } public MainForm() { InitializeComponent(); FormView = FormViews.A; //simply change views like this } } public static class PanelExtensions { public static void DockControl(this Panel thisControl Control controlToDock) { thisControl.Controls.Clear(); thisControl.Controls.Add(controlToDock); controlToDock.Dock = DockStyle.Fill; } }  I would also check out Composite Application Guidance for WPF or Smart Client Software Factory  The method I often use is actually to pre-setup all my controls on individual ""Panel"" controls and then show and hide these panels as I need them. Instead of making each view a panel within a single form you could make each view a UserControl. Then create a single form and write code to create and display the correct UserControl in the Form and to switch from one to the next. This would be easier to maintain because you will have a separate class for each view instead of a single Form class with 6 panels each with their own controls -- that seems difficult and error prone to maintain.",c# .net windows
25982,A,"What's the simplest way to connect to a .NET remote server object Given that my client code knows everything it needs to about the remoting object what's the simplest way to connect to it? This is what I'm doing at the moment: ChannelServices.RegisterChannel(new HttpChannel() false); RemotingConfiguration.RegisterWellKnownServiceType( typeof(IRemoteServer) ""RemoteServer.rem"" WellKnownObjectMode.Singleton); MyServerObject = (IRemoteServer)Activator.GetObject( typeof(IRemoteServer) String.Format(""tcp://{0}:{1}/RemoteServer.rem"" server port)); WCF. I have used IPC before there was a WCF and believe me IPC is a bear. And it isn't documented fully/correctly. What’s the simplest way to connect to a .NET remote server object? WCF.  The first two lines are in the server-side code for marshaling out the server object yes? In that case yes the third line is the simplest you can get at client-side. In addition you can serve out additional server-side objects from the MyServerObject instance if you include public accessors for them in IRemoteServer interface so accessing those objects become the simple matter of method calls or property accesses on your main server object so you don't have to use activator for every single thing: //obtain another marshalbyref object of the type ISessionManager: ISessionManager = MyServerObject.GetSessionManager();",c# .net remoting
2785,A,"Setting Objects to Null/Nothing after use in .NET Should you set all the objects to null (Nothing in VB.NET) once you have finished with them? I understand that in .NET it is essential to dispose of any instances of objects that implement the IDisposable interface to release some resources although the object can still be something after it is disposed (hence the isDisposed property in forms) so I assume it can still reside in memory or at least in part? I also know that when an object goes out of scope it is then marked for collection ready for the next pass of the garbage collector (although this may take time). So with this in mind will setting it to null speed up the system releasing the memory as it does not have to work out that it is no longer in scope and are they any bad side effects? MSDN articles never do this in examples and currently I do this as I cannot see the harm. However I have come across a mixture of opinions so any comments are useful. +1 great question. Does anyone know a circumstance under which the compiler will optimize away the assignment altogether? i.e. has anyone looked at MSIL under different circumstances and noted IL for setting an object to null (or the lack thereof). Karl is absolutely correct there is no need to set objects to null after use. If an object implements IDisposable just make sure you call IDisposable.Dispose() when you're done with that object (wrapped in a try..finally or a using() block). But even if you don't remember to call Dispose() the finaliser method on the object should be calling Dispose() for you. I thought this was a good treatment: Digging into IDisposable and this Understanding IDisposable There isn't any point in trying to second guess the GC and its management strategies because it's self tuning and opaque. There was a good discussion about the inner workings with Jeffrey Richter on Dot Net Rocks here: Jeffrey Richter on the Windows Memory Model and Richters book CLR via C# chapter 20 has a great treatment: The rule about not setting to null isn't ""hard and fast""...if the object gets put on the large object heap (size is >85K) it will help the GC if you set the object to null when you are done using it. I agree to a limited extent but unless you're starting to experience memory pressure then I see no need to 'prematurely optimise' by setting objects to null after use. This whole business of ""don't prematurely optimize"" sounds more like ""Prefer slow and don't worry because CPUs are getting faster and CRUD apps don't need speed anyway."" It may just be me though. :) What it really means is ""The Garbage Collector is better at managing memory than you are."" That might be just me though. :) How about if you disposed the object from a reference in a place different than the original (eg. another form) and later you want to check from the original reference if the object was disposed?  Take a look at this article as well: http://www.codeproject.com/KB/cs/idisposable.aspx For the most part setting an object to null has no effect. The only time you should be sure to do so is if you are working with a ""large object"" which is one larger than 84K in size (such as bitmaps).  Some object suppose the .dispose() method which forces the resource to be removed from memory. No it doesn't; Dispose() does *not* collect the object - it is used to perform deterministic clean up typically releasing unmanaged resources. Bearing in mind that the determinism applies only to the managed resources not the unmanaged ones (i.e. memory)  this kind of ""there is no need to set objects to null after use"" is not entirely accurate. There are times you need to NULL the variable after disposing it. Yes you should ALWAYS call .Dispose() or .Close() on anything that has it when you are done. Be it file handles database connections or disposable objects. Separate from that is the very practical pattern of LazyLoad. Say I have and instantiated ObjA of class A. Class A has a public property called PropB of class B. Internally PropB uses the private variable of _B and defaults to null. When PropB.Get() is used it checks to see if _PropB is null and if it is opens the resources needed to instantiate a B into _PropB. It then returns _PropB. To my experience this is a really useful trick. Where the need to null comes in is if you reset or change A in some way that the contents of _PropB were the child of the previous values of A you will need to Dispose AND null out _PropB so LazyLoad can reset to fetch the right value IF the code requires it. If you only do _PropB.Dispose() and shortly after expect the null check for LazyLoad to succeed it won't be null and you'll be looking at stale data. In effect you must null it after Dispose() just to be sure. I sure wish it were otherwise but I've got code right now exhibiting this behavior after a Dispose() on a _PropB and outside of the calling function that did the Dispose (and thus almost out of scope) the private prop still isn't null and the stale data is still there. Eventually the disposed property will null out but that's been non-deterministic from my perspective. The core reason as dbkk alludes is that the parent container (ObjA with PropB) is keeping the instance of _PropB in scope despite the Dispose().  Chances are that your code is not structured tightly enough if you feel the need to null variables. There are a number of ways to limit the scope of a variable: As mentioned by Steve Tranby using(SomeObject object = new SomeObject()) {  // do stuff with the object } // the object will be disposed of Similarly you can simply use curly brackets: {  // Declare the variable and use it  SomeObject object = new SomeObject() } // The variable is no longer available I find that using curly brackets without any ""heading"" to really clean out the code and help make it more understandable.  There are some cases where it makes sense to null references. For instance when you're writing a collection--like a priority queue--and by your contract you shouldn't be keeping those objects alive for the client after the client has removed them from the queue. But this sort of thing only matters in long lived collections. If the queue's not going to survive the end of the function it was created in then it matters a whole lot less. On a whole you really shouldn't bother. Let the compiler and GC do their jobs so you can do yours.  The only time you should set a variable to null is when the variable does not go out of scope and you no longer need the data associated with it. Otherwise there is no need. That's true but it also means you should probably refactor your code. I don't think I've ever needed to declare a variable outside of it's intended scope.  In general there's no need to null objects after use but in some cases I find it's a good practice. If an object implements IDisposable and is stored in a field I think it's good to null it just to avoid using the disposed object. The bugs of the following sort can be painful: this.myField.Dispose(); // ... at some later time this.myField.DoSomething(); It's good to null the field after disposing it and get a NullPtrEx right at the line where the field is used again. Otherwise you might run into some cryptic bug down the line (depending on exactly what DoSomething does). Well a disposed object should throw ObjectDisposedException if it has already been disposed. This does as far as I know require boilerplate code all over the place but then again Disposed is a badly thought-out paradigm anyway.  No don't null objects. You can check out http://codebetter.com/blogs/karlseguin/archive/2008/04/27/foundations-of-programming-pt-7-back-to-basics-memory.aspx for more information but setting things to null won't do anything except dirty your code. Nice and detail explanation about memory in the shared link  In general no need to set to null. But suppose you have a Reset functionality in your class. Then you might do because you do not want to call dispose twice since some of the Dispose may not be implemented correctly and throw System.ObjectDisposed exception. private void Reset() { if(_dataset != null) { _dataset.Dispose(); _dataset = null; } //..More such member variables like oracle connection etc. _oraConnection }  Also: using(SomeObject object = new SomeObject()) { // do stuff with the object } // the object will be disposed of  Another reason to avoid setting objects to null when you are done with them is that it can actually keep them alive for longer. e.g. void foo() { var someType = new SomeType(); someType.DoSomething(); // someType is now eligible for garbage collection // ... rest of method not using 'someType' ... } will allow the object referred by someType to be GC'd after the call to ""DoSomething"" but void foo() { var someType = new SomeType(); someType.DoSomething(); // someType is NOT eligible for garbage collection yet // because that variable is used at the end of the method // ... rest of method not using 'someType' ... someType = null; } may sometimes keep the object alive until the end of the method. The JIT will usually optimized away the assignment to null so both bits of code end up being the same. That's an interesting point. I always thought that objects don't go out of scope until after the method in which they are scoped is complete. Unless of course the object is scoped within a Using block or is explicitly set to Nothing or null. The preferred way to ensure that they stay alive is to use `GC.KeepAlive(someType);` See http://ericlippert.com/2013/06/10/construction-destruction/",c# .net vb.net memory memory-management
7244,A,"Anyone know a good workaround for the lack of an enum generic constraint? What I want to do is something like this: I have enums with combined flagged values. public static class EnumExtension { public static bool IsSet<T>( this T input T matchTo ) where T:enum //the constraint I want that doesn't exist in C#3 { return (input & matchTo) != 0; } } So then I could do: MyEnum tester = MyEnum.FlagA | MyEnum.FlagB if( tester.IsSet( MyEnum.FlagA ) ) //act on flag a Unfortunately C#'s generic where constraints have no enum restriction only class and struct. C# doesn't see enums as structs (even though they are value types) so I can't add extension types like this. Anyone know a workaround? Keith: download version 0.0.0.2 of UnconstrainedMelody - I've implemented HasAll and HasAny. Enjoy. Offtopic but a couple of days ago I would not have had a clue what you were asking. (Thanks Jon Skeet and your book!) What do you mean by “C# doesn't see enums as structs”? You can use enum types as type parameters that are constrained to `struct` just fine. check this article here: http://www.codeproject.com/KB/cs/ExtendEnum.aspx 'IsValidEnumValue' or 'IsFlagsEnumDefined' methods are probably the answer to your question. @dmihailescu - see @Jon Skeet's far more complete and detailed solution in the accepted answer. @dmihailescu: No that code project is addressing a different more complicated problem: determining whether a given value is a **valid** value for a given Enum. E.g. if you are handed a value ""9"" is that valid for your Enum? (No if you only have 3 flag bits). OP is trying to generalize simple bit operations on a Flags enum. These operations are one-liners if you have a SPECIFIC Enum type. E.g. clearing a Flag bit is something like `value = value & (~MyEnum.FlagA)`. But its a pain having to write that each time so it would be nice to write generic methods once and be done with it. Vote for this [uservoice idea](http://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/2557231-enums-constraint-for-generics) if you would like to see it built-in in .net one day. Actually it is possible with an ugly trick. However it cannot be used for extension methods. public abstract class Enums<Temp> where Temp : class { public static TEnum Parse<TEnum>(string name) where TEnum : struct Temp { return (TEnum)Enum.Parse(typeof(TEnum) name); } } public abstract class Enums : Enums<Enum> { } Enums.IsSet<DateTimeKind>(""Local"") If you want to you can give Enums<Temp> a private constructor and a public nested abstract inherited class with Temp as Enum to prevent inherited versions for non-enums.  Using your original code inside the method you can also use reflection to test that T is an enum: public static class EnumExtension { public static bool IsSet<T>( this T input T matchTo ) { if (!typeof(T).IsEnum) { throw new ArgumentException(""Must be an enum"" ""input""); } return (input & matchTo) != 0; } } Thanks but that turns a compile time issue (the where constraint) into a runtime one (your exception). Also you'd still need to convert the inputs to ints before you could do anything with them.  You can achieve this using IL Weaving and ExtraConstraints Allows you to write this code public class Sample { public void MethodWithDelegateConstraint<[DelegateConstraint] T> () { } public void MethodWithEnumConstraint<[EnumConstraint] T>() { } } What gets compiled public class Sample { public void MethodWithDelegateConstraint<T>() where T: Delegate { } public void MethodWithEnumConstraint<T>() where T: struct Enum { } }  Here's some code that I just did up that seems to work like you want without having to do anything too crazy. It's not restricted to only enums set as Flags but there could always be a check put in if need be. public static class EnumExtensions { public static bool ContainsFlag(this Enum source Enum flag) { var sourceValue = ToUInt64(source); var flagValue = ToUInt64(flag); return (sourceValue & flagValue) == flagValue; } public static bool ContainsAnyFlag(this Enum source params Enum[] flags) { var sourceValue = ToUInt64(source); foreach (var flag in flags) { var flagValue = ToUInt64(flag); if ((sourceValue & flagValue) == flagValue) { return true; } } return false; } // found in the Enum class as an internal method private static ulong ToUInt64(object value) { switch (Convert.GetTypeCode(value)) { case TypeCode.SByte: case TypeCode.Int16: case TypeCode.Int32: case TypeCode.Int64: return (ulong)Convert.ToInt64(value CultureInfo.InvariantCulture); case TypeCode.Byte: case TypeCode.UInt16: case TypeCode.UInt32: case TypeCode.UInt64: return Convert.ToUInt64(value CultureInfo.InvariantCulture); } throw new InvalidOperationException(""Unknown enum type.""); } }  The way I do it is put a struct constraint then check that T is an enum at runtime. This doesn't eliminate the problem completely but it does reduce it somewhat where T : struct IComparable IFormattable IConvertible -- this is the closest you can get to enum :)  This doesn't answer the original question but there is now a method in .NET 4 called Enum.HasFlag which does what you are trying to do in your example If you know it doesn't answer the question why not leave it as a comment? This does not provide an answer to the question. To critique or request clarification from an author leave a comment below their post.  Darren that would work if the types were specific enumerations - for general enumerations to work you have to cast them to ints (or more likely uint) to do the boolean math: public static bool IsSet( this Enum input Enum matchTo ) { return ( Convert.ToUInt32( input ) & Convert.ToUInt32( matchTo ) ) != 0; } And if you have a ridiculous number of flags you can call GetTypeCode() on the arguments and Convert.ToUint64() Awesome the combination of 'Enum` and `Convert.ToUInt32` I didn't find anywhere else. AFAIK Its the only decent Pre-Net-4 solution that also works in VB. BTW if `matchTo` might have multiple flag bits then replace `!= 0` with `== Convert.ToUInt32(matchTo)`.  EDIT: This is now live in version 0.0.0.2 of UnconstrainedMelody. (As requested on my blog post about enum constraints. I've included the basic facts below for the sake of a standalone answer.) The best solution is to wait for me to include it in UnconstrainedMelody1. This is a library which takes C# code with ""fake"" constraints such as where T : struct IEnumConstraint and turns it into where T : struct System.Enum via a postbuild step. It shouldn't be too hard to write IsSet... although catering for both Int64-based and UInt64-based flags could be the tricky part. (I smell some helper methods coming on basically allowing me to treat any flags enum as if it had a base type of UInt64.) What would you want the behaviour to be if you called tester.IsSet(MyFlags.A | MyFlags.C) ? Should it check that all the specified flags are set? That would be my expectation. I'll try to do this on the way home tonight... I'm hoping to have a quick blitz on useful enum methods to get the library up to a usable standard quickly then relax a bit. EDIT: I'm not sure about IsSet as a name by the way. Options: Includes Contains HasFlag (or HasFlags) IsSet (it's certainly an option) Thoughts welcome. I'm sure it'll be a while before anything's set in stone anyway... 1 or submit it as a patch of course... HasAny and HasAll seem awesome. I suppose if multiple flags are passed in it should check for all of them. My actual fix for this (back in 2008 when I asked it) was to have a template extension method for each flags enum - messy but works. Never bothered with the check for multiple flags because all the checks we have are for a single flag - not such a problem in internal only code but something that would need to be accounted for in an shared library. You had to go and mention PostSharp LOL :o http://www.postsharp.org/blog/generic-constraints-for-enums-and-delegates I would use the Flags-terminology simply because it already exists in .NET (see `FlagsAttribute`.) I see two explicit names here: `HasAnyFlag` and `HasAllFlags`. They can be shortened to `HasFlag` and `HasFlags`. I can't say which is best it's a matter of taste I guess. Oh and Keith have a look at http://stackoverflow.com/questions/1404077/is-there-a-workaround-for-generic-type-constraint-of-special-class-enum-in-c-3 `=)` Or actually simpler HasAny() and HasAll() Yes I agree that's even better. `colors.HasAny(Colors.Red | Colors.Blue)` looks like very readable code. `=)` Yup I like HasAny and HasAll too. Will go with that.",c# .net enums flags
29284,A,"Windows Vista: Unable to load DLL 'x.dll': Invalid access to memory location. (DllNotFoundException) I was testing on a customer's box this afternoon which has Windows Vista (He had home but I am testing on a Business Edition with same results). We make use of a .DLL that gets the Hardware ID of the computer. It's usage is very simple and the sample program I have created works. The Dll is This from AzSdk. In fact this works perfectly under Windows XP. However for some strange reason inside our project (way bigger) we get this exception: Exception Type: System.DllNotFoundException Exception Message: Unable to load DLL 'HardwareID.dll': Invalid access to memory location. (Exception from HRESULT: 0x800703E6) Exception Target Site: GetHardwareID I don't know what can be causing the problem since I have full control over the folder. The project is a c#.net Windows Forms application and everything works fine except the call for the external library. I am declaring it like this: (note: it's not a COM library and it doesn't need to be registered). [DllImport(""HardwareID.dll"")] public static extern String GetHardwareID(bool HDD bool NIC bool CPU bool BIOS string sRegistrationCode); And then the calling code is quite simple: private void button1_Click(object sender EventArgs e) { textBox1.Text = GetHardwareID(cb_HDD.Checked cb_NIC.Checked cb_CPU.Checked cb_BIOS.Checked ""*Registration Code*""); } When you create a sample application it works but inside my projectit doesn't. Under XP works fine. Any ideas about what should I do in Vista to make this work? As I've said the folder and its sub-folders have Full Control for ""Everybody"". Thanks in advance UPDATE: I do not have Vista SP 1 installed. UPDATE 2: I have installed Vista SP1 and now with UAC disabled not even the simple sample works!!! :( Damn Vista. Have you made a support request to the vendor? Perhaps there's something about the MacBook Pro hardware that prevents the product from working.  In addition to allowing full control to ""Everyone"" does the location also allow processes with a medium integrity level to write? How do I check that ? I am new to Vista I don't like it too much it's too slow inside a VM for daily work and for VStudio usage inside a Virtual Machine it doesn't bring anything new. From a command prompt to you can execute: icacls C:\Folder If you see a line such as ""Mandatory Label\High Mandatory Level"" then the folder is only accessible to a high integrity process. If there is no such line then medium integrity processes can access it provided there are no other ACLs denying access (based on user for example). EDIT: Forgot to mention you can use the /setintegritylevel switch to actually change the required integrity level for accessing the object.  Is the machine you have the code deployed on a 64-bit machine? You could also be running into a DEP issue. Edit This is a 1st gen Macbook Pro with a 1st gen Core Duo 2 Intel processor. Far from 64 bits. I mentioned 64 bit because at low levels structs from 32 bit to 64 bit do not get properly handled. Since the machines aren't 64bit then more than likely disabling DEP would be a good logical next step. Vista did get more secure than XP SP2. Well I've just turned DEP globally off to no avail. Same error. Well I also read that people were getting this error after updating a machine to Vista SP1. Do these Vista installs have SP1 on them? Turns out to be something completely different. Just for the sake of testing I've disabled de UAC (note: I was not getting any prompt). Great I was actually going to suggest that but I figured you probably tried it already.  @Martín The reason you were not getting the UAC prompt is because UAC can only change how a process is started once the process is running it must stay at the same elevation level. The UAC will prompt will happen if: Vista thinks it's an installer (lots of rules here the simplest one is if it's called ""setup.exe"") If it's flagged as ""Run as Administrator"" (you can edit this by changing the properties of the shortcut or the exe) or If the exe contains a manifest requesting admin privileges. The first two options are workarounds for 'legacy' applications that were around before UAC the correct way to do it for new applications is to embed a manifest resource asking for the privileges that you need. Some program such as Process Explorer appear to elevate a running process (when you choose ""Show details for all process"" in the file menu in this case) but what they really do is start a new instance and it's that new instance that gets elevated - not the one that was originally running. This is the recommend way of doing it if only some parts of your application need elevation (e.g. a special 'admin options' dialog).  Given that the exception is a DllNotFoundException you might want to try checking the HardwareID.dll with Dependency Walker BEFORE installing any dev tools on the Vista install to see if there is in fact a dependency missing.  Unable to load DLL 'HardwareID.dll': Invalid access to memory location. (Exception from HRESULT: 0x800703E6) The name of DllNotFoundException is confusing you - this isn't a problem with finding or loading the DLL file the problem is that when the DLL is loaded it does an illegal memory access which causes the loading process to fail. Like another poster here I think this is a DEP problem and that your UAC etc changes have finally allowed you to disable DEP for this application. +1 for explaining the problem in such a way that I can understand what the real problem is and know what to start looking for",c# .net windows-vista dllnotfoundexception
29654,A,"WinForms databinding and foreign key relationships I'm developing a WinForms application (.Net 3.5 no WPF) where I want to be able to display foreign key lookups in a databound DataGridView. An example of the sort of relationship is that I have a table of OrderLines. Orderlines have a foreign key relationship to Products and Products in turn have a foreign key relationship to ProductTypes. I'd like to have a databound DataGridView where each row represents an orderline displaying the line's product and producttype. Users can add or edit orderlines direct to the grid and choose the product for the order line from a comboBoxColumn - this should then update the producttype column showing the producttype for the selected product in the same row. The closest to a good fit that I've found so far is to introduce a domain object representing an orderline then bind the DataGridView to a collection of these orderlines. I then add properties to the orderline object that expose the product and the producttype and raise relevant notifypropertychanged events to keep everything up to date. In my orderline repository I can then wire up the mappings between this orderline object and the three tables in my database. This works for the databinding side of things but having to hand code all that OR-mapping in the repository seems bad. I thought nHibernate would be able to help with this wiring up but am struggling with the mappings through all the foreign keys - they seem to work ok (the foreignkey lookup for an orderline's product creates the correct product object based on the foreign key) until I try to do the databinding I can't get the databound id columns to update my product or producttype objects. Is my general approach even in the right ballpark? If it is what is a good solution to the mapping problem? Or is there a better solution to databinding rows including foreign key lookups that I haven't even considered? Here's a good ""How Do I"" video that demonstrates data binding: http://windowsclient.net/learn/video.aspx?v=52579  This article may help ""A Look Under the Hood of Windows Forms Data Binding"".  My original question obviously wasn't clear sorry about that. The problem wasn't with databinding to a DataGridView in general or with the implementation of a DataGridViewComboBoxColumn - as the people who have answered already rightly say that is well documented on the web. The problem I've been trying to solve is with the refresh of properties that are drilling down through relationships. In my orders example when I change the value of the ""Product"" column the ""Product Type"" column is not being updated - even though in the code I am setting the property and firing the NotifyPropertyChanged event. (In debug I go to all the right places) After a lot of poking around I realised that this was not even working when I directly set the ""Product Type"" property of datasource rather that setting it in the ""Product"" setter. The other thing that I believe has me back on the right track is that when I provide a mocked dataccess layer created in the main form everything works fine. Also when I copy the IList made by nHibernate to a IBindingList - everything again appears fine. So the problem is I think with threading and the NotifyPropertyChanged events being lost when using certain datasources in certain ways (wish I could be more definitive than that!) I'm going to keep researching better ways of resolving this than copying the IList to the IBindingList - maybe I need to learn about thread marshalling. Edit I've now developed a solution that solves the issue and think I understand what was confusing me - basically it appears that anything but basic property databinding doesn't play nicely for lists that aren't derived from BindingList - as soon as I was trying to databind to properties that fired chained NotifyPropertyChanged events things went haywire and I my events got lost. The data access solution I have now is using a variation of the Rob Conery IRepository pattern returning my collections to be bound as a custom class I made a SortableBindingLazyList that derives from BindingList implements the Sort Core methods and also stores its internal list as a query delaying the list materialisation.  I think the problem you're having is that when you are binding to a grid it is not enough to support INotifyPropertyChanged but you have to fire the ListChanged events in your IBindingList implementation and make sure that you override and return true for the SupportsChangeNotification property. If you don't return true for this the grid won't look for it to know if the data has changed. In .NET 2.0+ you can create a generic collection using the BindingList class this will take care of most of the nastiness (just don't forget to override and return true for the SupportsChangeNotification property). If the class you use for data binding has a property that is a collection (such as IBindingList or BindingList) then you can bind the foreign key grid to that property directly. When you configure the bindings in the Forms designer just select the collection property as the data source for the grid. It should ""just work"". The only sneaky part is making sure that you handle empty or null collections the right way. Thanks Garo - that pretty nicely covers what I've found myself. The only differenc is I have a foreign key column not a grid. I'm going to update my won response too making it clear just what was causing me problems - I think the reasons why I originally misdiagnosed the issue may be useful  welcome to StackOverflow :) Normally what you would do is base the information in the drop down on two values ValueMember and DisplayMember. The ValueMember is the source of the actual controls value (this will be the key value in the order line) the display member is the value that is displayed to the user instead of the value (this will be the FK value). Is there no particular reason you cannot just return all the data required and set these properties?  Well I don't know whether it's supported by the DataGridView but when you're doing regular WinForms databinding (say to a regular TextBox) you can use property paths to navigate through object relationships. Something like this: myTextBox.DataBindings.Add(""Text"" anOrderLine ""OrderedPart.PartNumber""); Would be worth seeing if this works in your situation too.",c# .net winforms
18088,A,"Are there any studies comparing Java EE vs. .NET? I've been tasked with the awesome responsibility of trying to document the advantages of using Java EE for a web app over .NET. Of course via Google I am mostly getting back blog posts on how an Int is an object in Java or a list of code comparisons. No real hard evidence or numbers. Is anybody aware of any legitimate studies trying to prove that one of the platforms is better than the other? For example I'd guess that there are probably a lot more free APIs out there for Java than there are for .NET. Many people share that opinion with me. But has that ever been documented anywhere did anybody ever attempt to quantify it? Is there a study on the quality of developer (education level of experience even salary) that does a Java app vs. the quality of a developer that is doing .NET? etc. I'm looking for LINKS to known studies here not people's opinions. I already have my own opinion. If you want links then Google is the best place to look :-p You might find Jeff Atwoods findings interesting - http://www.codinghorror.com/blog/2013/03/why-ruby.html (open source thrives better with Java than .NET) J2EE development will not cost a dime in terms of buying the OS IDE framework etc. whereas .Net development is not free you need to buy windows OS Visual Studio etc. Apart from this you should look at what technology resources are available to you already. From the market you can easily get resources for both the technology at same salary. Rest all is same in case of .Net and Java.  Although not helpful for your cause this article has some interesting stats regarding the market share of technologies including .NET and Java: http://news.cnet.com/8301-13505_3-9884500-16.html  I can't say much about .NET as I'm not really a Microsoft fan. As such I do can understand why Microsoft would use Websphere in their comparisons: it is by far the worst slowest most hated appServer around. Now take JBOSS for example... Having said that .NET also lacks stuff Java has. E.g. the ease of EJBs frameworks that can compete with e.g. Spring etc. I am a Java EE developer for over 10 years and lately I must say I'm really beginning to dislike Java. Frameworks like JSF make my hair fall out. A bunch of open-source stuff like M2eclipse does not work well. A LOT of bugs in eclipse. Many eclipse packages that are not compatible with each other resulting in NullPointerExceptions in your error console build problems etc etc.. Shoot me but I have lost my faith in open source. It does not work at a level you could call 'professional'. I feel such is merele logical: in a company you have some pressure from people who will call the helpdesk law-suits because stuff is bad etc and so some manager(s) will do the best they can to make sure all works together. Of course software will always have bugs. However when I compare my years as a C++ developer using Microsof Visual Studio against my years using Eclipse or Netbeans I must dat Dev Studio gave me never headache. It always worked and I cannot remember it having crashed once... Eclipse? I could write a book!! So I agree with what i read somewhere: while open-source may be free and costless the loss in productivity is huge compared to what I had years ago... But people who never knew anything else then reply: yeah but you need to know your tools... If only they had known a little more experience in older tools... I'm currently thinking about migrating to .NET despite my love for Apple and hatred towards Microsoft... Hot deploy never works it is just a bunch of crap. Haven't tried JEE6 with Spring MVC will soon I really hope there has been progress in the hot deploy area! And you are right Eclipse is a bunch of crap its plugins is mostly crap m2eclipse is crap and opensource is mostly crap unless it is backed by a company. Opensource is overrated. No developer should ever release code for free it just ruins it for all of us that want to get payed. Websphere is also a pain in the ass. I like the Java language though and its static nature but c# is more rich with some negative side effects.  First off I'm a .NET guy so I am biased. Second if by Java EE you mean J2EE and you are planning web based development then I have some questions. If you are planning on desktop development ask yourself if the extra 5% market share you get by using Java is worth it. Its definitely a .NET world when developing desktop applications. However I'm thinking you are looking at this for Web Development. My first question is what Java application server are you considering? Apache/TomCat is small and free while on the flipside IBM WebSphere is huge and expensive ($2000 per cpu). Microsoft did a great performance/cost comparison between Windows 2k3/IIS and RedHat/WebSphere here. According to TheServerSide .NET is both cheaper and faster in this situation. http://www.theserverside.net/tt/articles/showarticle.tss?id=NET2BMNovember Its a good starting point for research. All that said You will have to look high and low to find a java developer who does not admit that C# is a better language to enjoy writing in. C# has real generics (Java Generics still are boxed/unboxed its just syntax sugar) LINQ lambda functions delegates and a host of other goodies that the java is missing. Actually J2EE is now known as JEE it has been for five years now. But maybe you've discovered that in the year and a half since you left this answer. :P WebSphere is definetly one of the worst app server in Java world. @bpapa and now it is called Java EE...  People have successfully built applications with both technology stacks. People have also experienced colossal failures with both. In the end compatibility with existing platforms and skill sets is probably what matters most when selecting one over the other. If you intend to deploy on non-Windows servers for instance then Java is obviously a better fit. EDIT: The best way to get access to those kinds of studies is to get them from someone interested in selling you the technology. Otherwise companies like the Gartner Group charge large sums of money for papers like that.  I agree totally with Slavo but I also think that there are no silly questions. Hopefully this site doesn't become a flamewar site.  From the official Stackoverflow FAQ: What kind of questions should I not ask here? Tabs versus Spaces. Emacs versus Vi. C++ versus Java. This is not yet another place for programmers to argue about The One True Way. Why do we have to talk about this? Guess you missed the part where I said ""I'm looking for LINKS to known studies here not people's opinions""  checkout this blog... http://it.toolbox.com/blogs/web2-place/net-vs-j2ee-java-ee-architectural-philosophy-11290 .NET vs. J2EE (Java EE) - Architectural Philosophy  ""Is anybody aware of any legitimate studies trying to prove that one of the platforms is better than the other?"" That sentence seems like a contradiction in terms to me. I would not consider any study made with the goal of reaching a certain conclusion to be legitimate. That's why ""biased"" has negative connotations. My point is that you should be very critical with studies in an area like this. Most people who have an interest in doing this kind of study also have an interest in doing it wrong.",c# java .net java-ee
20267,A,"Best way to replace tokens in a large text template I have a large text template which needs tokenized sections replaced by other text. The tokens look something like this: ##USERNAME##. My first instinct is just to use String.Replace() but is there a better more efficient way or is Replace() already optimized for this? Had to do something similar recently. What I did was: make a method that takes a dictionary (key = token name value = the text you need to insert) Get all matches to your token format (##.+?## in your case I guess not that good at regular expressions :P) using Regex.Matches(input regular expression) foreach over the results using the dictionary to find the insert value for your token. return result. Done ;-) If you want to test your regexes I can suggest the regulator.  System.Text.RegularExpressions.Regex.Replace() is what you seek - IF your tokens are odd enough that you need a regex to find them. Some kind soul did some performance testing and between Regex.Replace() String.Replace() and StringBuilder.Replace() String.Replace() actually came out on top. I believe they did their test in PowerShell which does not apply to C#. C3 have a different memory management from PowerShell and does not convert StringBuilder to String for replacing characters in it. On the other hand RegEx and StringBuilder work better on large data sizes which added to them in chunks  string.Replace is fine. I'd prefer using a Regex but I'm * for regular expressions. The thing to keep in mind is how big these templates are. If its real big and memory is an issue you might want to create a custom tokenizer that acts on a stream. That way you only hold a small part of the file in memory while you manipulate it. But for the naiive implementation string.Replace should be fine.  This is an ideal use of Regular Expressions. Check out this helpful website the .Net Regular Expressions class and this very helpful book Mastering Regular Expressions.  Regular expressions would be the quickest solution to code up but if you have many different tokens then it will get slower. If performance is not an issue then use this option. A better approach would be to define token like your ""##"" that you can scan for in the text. Then select what to replace from a hash table with the text that follows the token as the key. If this is part of a build script then nAnt has a great feature for doing this called Filter Chains. The code for that is open source so you could look at how its done for a fast implementation.  Well depending on how many variables you have in your template how many templates you have etc. this might be a work for a full template processor. The only one I've ever used for .NET is NVelocity but I'm sure there must be scores of others out there most of them linked to some web framework or another.  FastReplacer implements token replacement in O(n*log(n) + m) time and uses 3x the memory of the original string. FastReplacer is good for executing many Replace operations on a large string when performance is important. The main idea is to avoid modifying existing text or allocating new memory every time a string is replaced. We have designed FastReplacer to help us on a project where we had to generate a large text with a large number of append and replace operations. The first version of the application took 20 seconds to generate the text using StringBuilder. The second improved version that used the String class took 10 seconds. Then we implemented FastReplacer and the duration dropped to 0.1 seconds.  If you are doing multiple replaces on large strings then it might be better to use StringBuilder.Replace() as the usual performance issues with strings will appear.  If your template is large and you have lots of tokens you probably don't want walk it and replace the token in the template one by one as that would result in an O(N * M) operation where N is the size of the template and M is the number of tokens to replace. The following method accepts a template and a dictionary of the keys value pairs you wish to replace. By initializing the StringBuilder to slightly larger than the size of the template it should result in an O(N) operation (i.e. it shouldn't have to grow itself log N times). Finally you can move the building of the tokens into a Singleton as it only needs to be generated once. static string SimpleTemplate(string template Dictionary<string string> replacements) { // parse the message into an array of tokens Regex regex = new Regex(""(##[^#]+##)""); string[] tokens = regex.Split(template); // the new message from the tokens var sb = new StringBuilder((int)((double)template.Length * 1.1)); foreach (string token in tokens) sb.Append(replacements.ContainsKey(token) ? replacements[token] : token); return sb.ToString(); }  The only situation in which I've had to do this is sending a templated e-mail. In .NET this is provided out of the box by the MailDefinition class. So this is how you create a templated message: MailDefinition md = new MailDefinition(); md.BodyFileName = pathToTemplate; md.From = ""test@somedomain.com""; ListDictionary replacements = new ListDictionary(); replacements.Add(""<%To%>"" someValue); // continue adding replacements MailMessage msg = md.CreateMailMessage(""test@someotherdomain.com"" replacements this); After this msg.Body would be created by substituting the values in the template. I guess you can take a look at MailDefinition.CreateMailMessage() with Reflector :). Sorry for being a little off-topic but if this is your scenario I think it's the easiest way.",c# .net
10905,A,Can you use generic forms in C#? You should be able to create a generic form: public partial class MyGenericForm<T> : Form where T : class { /* form code */ public List<T> TypedList { get; set; } } Is valid C# and compiles. However the designer won't work and the form will throw a runtime exception if you have any images stating that it cannot find the resource. I think this is because the windows forms designer assumes that the resources will be stored under the simple type's name. tx just what i was drowning on!! Yes you can! Here's a blog post I made a while ago with the trick: Designing Generic Forms Edit: Looks like you're already doing it this way. This method works fine so I wouldn't consider it too hacky. What about if you have 3 forms? I want Form3 : Form2. This includes the generic type parameter + controls in Form2. Any idea?  I have a hack to workaround this which works but isn't ideal: Add a new class to the project that inherits the form with its simple name. internal class MyGenericForm: MyGenericForm<object> { } This means that although the designer is still wrong the expected simple type (i.e without <>) is still found.,c# .net winforms
2872,A,"Possible to ""spin off"" several GUI threads? (Not halting the system at Application.Run) My Goal I would like to have a main processing thread (non GUI) and be able to spin off GUIs in their own background threads as needed and having my main non GUI thread keep working. Put another way I want my main non GUI-thread to be the owner of the GUI-thread and not vice versa. I'm not sure this is even possible with Windows Forms(?) (Sorry for the big post here. I've had complaints about previous shorter versions of this question just isn't comprehensible. I'm a lousy writer) Background I have a component based system in which a controller dynamically load assemblies and instantiates and run classes implementing a common IComponent interface with a single method DoStuff() . Which components that gets loaded is configured via a xml configuration file and by adding new assemblies containing different implementations of IComponent . The components provides utility functions to the main application. While the main program is doing it's thing e.g. controlling a nuclear plant the components might be performing utility tasks (in their own threads) e.g. cleaning the database sending emails printing funny jokes on the printer what have you. What I would like is to have one of these components be able to display a GUI e.g. with status information for the said email sending component. The lifetime of the complete system looks like this Application starts. Check configuration file for components to load. Load them. For each component run DoStuff() to initialize it and make it live its own life in their own threads. Continue to do main application-thingy king of work forever. I have not yet been able to successfully perform point 3 if the component fires up a GUI in DoStuff() . It simply just halts until the GUI is closed. And not until the GUI is closed does the program progress to point 4. It would be great if these components were allowed to start up their own Windows Forms GUIs. Problem When a component tries to fire up a GUI in DoStuff() (the exact line of code is when the component runs Application.Run(theForm))  the component and hence our system ""hangs"" at the Application.Run() line until the GUI is closed. Well the just fired up GUI works fine as expected. Example of components. One hasn't nothing to do with GUI whilst the second fires up a cute windows with pink fluffy bunnies in them. public class MyComponent1: IComponent {  public string DoStuff(...) { // write something to the database } } public class MyComponent2: IComponent  public void DoStuff()  {  Application.EnableVisualStyles();  Application.SetCompatibleTextRenderingDefault(false);  Application.Run(new Form());  // I want the thread to immediately return after the GUI  // is fired up so that my main thread can continue to work.  } } I have tried this with no luck. Even when I try to fire up the GUI in it's own thread the execution halts until the GUI as closed.  public void DoStuff()  {  new Thread(ThreadedInitialize).Start()  }  private void ThreadedInitialize()  {  Application.EnableVisualStyles();  Application.SetCompatibleTextRenderingDefault(false);  Application.Run(new Form());  } Is it possible to spin off a GUI and return after Application.Run()? I'm not sure if this is right however I remember running window forms from a console application by just newing the form and calling newForm.Show() on it if your components use that instead of Application.Run() then the new form shouldn't block. Of course the component will be responsible for maintaining a reference to the forms it creates  I'm sure this is possible if you hack at it hard enough but I'd suggest it is not a good idea. 'Windows' (that you see on the screen) are highly coupled to processes. That is each process which displays any GUI is expected to have a Message Loop which processes all of the messages which are involved with creating and managing windows (things like 'clicked the button' 'closed the app' 'redraw the screen' and so on. Because of this it is more or less assumed that if you have any message loop it must be available for the lifetime of your process. For example windows might send you a 'quit' message and you need to have a message loop available to handle that even if you've got nothing on the screen. Your best bet is do it like this: Make a fake form which is never shown which is your 'main app' Start up Call Application.Run and pass in this fake form. Do your work in another thread and fire events at the main thread when you need to do Gui stuff. Actually windows are coupled to threads not processes. You can have multiple message loops per process and it will let you have several completely independent windows.  Application.Run method displays one (or more) forms and initiates the standard message loop which runs until all the forms are closed. You cannot force a return from that method except by closing all your forms or forcing an application shutdown. You can however pass an ApplicationContext (instad of a new Form()) to Application.Run method and ApplicationContext can be used to launch several forms at once. Your application will only end when all of those are closed. See here: http://msdn.microsoft.com/en-us/library/system.windows.forms.application.run.aspx Also any forms that you Show non-modally will continue to run alongside your main form which will enable you to have more than one windows that do not block each other. I believe this is actually what you are trying to accomplish.",c# .net winforms
4913,A,"How to make a button appear as if it is pressed? Using VS2008 C# .Net 2 and Winforms how can I make a regular Button look ""pressed""? Imagine this button is an on/off switch. ToolStripButton has the Checked property but the regular Button does not. I think you may need a ToggleButton. You can take a look at third party vendors of WinForms components such as Telerik DevExpress ComponentFactory ViBlend which provide such control. They all provide toggle buttons.  One method you can used to obtain this option is by placing a ""CheckBox"" object and changing its ""Appearance"" from ""Normal"" to ""Button"" this will give you the same functionality that I believe you are looking for.  You could probably also use the ControlPaint class for this.",c# .net winforms gui button
25343,A,Is there any way to automate windows forms testing? I am familiar with nunit for unit testing of the business layer however I am looking now to automate the test of the win forms gui layer. I have seen watin and the watin recorder for automating tests on web application by accessing the controls and automating them. However I am struggling to find a watin equivalent for windows forms (written in c# or vb.net) preferably that is open source. Does one exist or are all products based on recording mouse and keyboard presses? Update: I have looked at this blog post on white and it seems the sort of thing I am looking for. The blog post raises some issues but as white is only in version 0.6 these may be resolved. Be interested if others have used white or any others for comparison. Here are some links from MSDN Magazine on automatic testing code: Using UIAutomation Bugslayer March 2007 Using PowerShell Test Run December 2007 Tester a utility for recording mouse clicks and keystrokes then playing them back & program checking behaviour. Excellent for unmanaged code. Uses windows handles so may not work well for managed code. Bugslayer March 2002.  AutomatedQA's TestComplete is a good testing application to automate GUI testing. It supports more than just Windows Forms also so you can reuse it for other applications. It is not open source and this is the best that I have found. I haven't seen an open source equivalent to WatiN. It does have a free trial for you decide if you like it or not. The main reason I went with it is that it really is cost effective compared to other testing applications.  Check out http://www.codeplex.com/white and http://nunitforms.sourceforge.net/. We've used the White project with success. Same Answer to a previous question  You could check out the Microsoft UI Automation framework. This has been included in .NET since version 3.0. This is actually what the White framework uses anyway.  As far as I know White is an abstraction layer over the top of Microsoft's UI Automation framework. I have written a similar layer that we use internally on our projects and it works great. So White would definattley be worth a look Microsoft have released the source to UI Automation so if necessary you should be able to debug right down the whole stack if necessary. The really cool thing is that with licence cost you can scale up and run as many machines as you like for execution. We run inside VSTS and link our results to requirements but you can use c# express and nUnit and get first class tools and languages for little to no cost.,c# .net vb.net winforms automated-tests
