313916,A,"Custom Cursor in a Swing JDialog I have a Java Swing application developed on Mac OS X 10.5 using Java 1.5. I'm trying to make a custom cursor appear when the user moves the mouse over some text in a dialog. The cursor never changes though. When I don't use a JFrame instead of a JDialog the cursor does change. But then I'll have to write all the dialog code myself. How can I get the cursor to appear? Here's the simplest code I could create to demonstrate the problem: import javax.swing.*; import java.awt.*; public class CursorTest { public static void main(String[] args) { JLabel label = new JLabel(""Move mouse here for hand cursor""); label.setCursor(Cursor.getPredefinedCursor(Cursor.HAND_CURSOR)); JOptionPane pane = new JOptionPane(label); pane.setOptions(new Object[]{""OK""}); JDialog dialog = pane.createDialog(null ""Test Dialog""); dialog.setVisible(true); } } Looks like it is a bug in Java 1.5: I first tried with Java 1.6.0_07 and it worked as expected (on Windows XP). Then I recompiled with Java 1.5.0_06 and indeed the cursor remains in default state. Knowing the difficulties of Java 1.6 on MacOS I see it will be hard to fix that... Bug ID: 5079694 JDialog doesn't respect setCursor They give a workaround... [EDIT] Tested workaround: public class CursorTest extends JFrame { private CursorTest() { } private void ShowDialog() { JLabel label = new JLabel(""Move mouse here for hand cursor""); label.setCursor(Cursor.getPredefinedCursor(Cursor.HAND_CURSOR)); JOptionPane pane = new JOptionPane(label); pane.setOptions(new Object[] { ""OK"" } ); JDialog dialog = pane.createDialog(this ""Test Dialog""); dialog.setVisible(true); } public static void main(String[] args) { SwingUtilities.invokeLater(new Runnable() { public void run() { CursorTest testFrame = new CursorTest(); testFrame.setTitle(""Test GUI""); testFrame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); testFrame.setSize(500 300); testFrame.setVisible(true); testFrame.ShowDialog(); } }); } } Works fine with my JDK & system.  Thanks PhiLho that Sun bug report gave me the solution. The owner (parent frame) must be non-null and showing. For the record here's a modified version of my example code that does show a hand cursor. import javax.swing.*; import java.awt.*; public class CursorTest { public static void main(String[] args) { JLabel label = new JLabel(""Move mouse here for hand cursor""); label.setCursor(Cursor.getPredefinedCursor(Cursor.HAND_CURSOR)); JOptionPane pane = new JOptionPane(label); pane.setOptions(new Object[]{""OK""}); JFrame parent = new JFrame(); parent.setVisible(true); JDialog dialog = pane.createDialog(parent ""Test Dialog""); dialog.setModal(false); dialog.setVisible(true); } } non null? What variable that you gave a null anyway? ~ sorry I'm trying to understand ur thread... :(",java swing jdialog joptionpane custom-cursor71842,A,"How can I detect from a Swing app that the PC is being shut-down? Well behaved windows programs need to allow users to save their work when they are shutting the PC down. How can I make my app detect the shutdown event? Any solution should allow the user to abort the shutdown if user selects say ""Cancel"". The normal Swing window closing hook doesn't work nor does adding a shutdown hook. On testing the methods of WindowListener (windowClosingwindowClosed etc) do not get called. The answer I have accepted requires the use of platform specific code (JNI to register for WM_QUERYENDSESSION ). Isn't this a bug on Swing? See http://forums.sun.com/thread.jspa?threadID=481807&messageID=2246870 Are you using the shutdown hook from java.lang.runtime ? Write some JNI code to WM_QUERYENDSESSION message. You can get details for this from the MSDN documentation or by googling it. If you don't want to write too much C++ code to do this I can recommend the JNA library click here. Which gives you some nice Java abstractions for C code.  Look for signal handling in java. when Windows closes it will send a signal to the application asking it to terminate most likely a sigterm see here for more about this (I am not the owner of the website)  The above seems to be the better answer. I can't find any good information on detecting window shutdown events. I guess the best possible method would be to detect weather your application is trying to close using a window closing event or the like then ask the question. http://www.javalobby.org/java/forums/t17933  how-do-i-get-my-java-application-to-shutdown-nicely-in-windows That might be of help",java swing operating-system149153,A,"Loading animated gif from JAR file into ImageIcon I'm trying to create a ImageIcon from a animated gif stored in a jar file. ImageIcon imageIcon = new ImageIcon(ImageIO.read(MyClass.class.getClassLoader().getResourceAsStream(""animated.gif""))); The image loads but only the first frame of the animated gif. The animation does not play. If I load the animated gif from a file on the filesystem everything works as expected. The animation plays through all the of frames. So this works: ImageIcon imageIcon = new ImageIcon(""/path/on/filesystem/animated.gif""); How can I load an animated gif into an ImageIcon from a jar file? EDIT: Here is a complete test case why doesn't this display the animation? import javax.imageio.ImageIO; import javax.swing.*; public class AnimationTest extends JFrame { public static void main(String[] args) { SwingUtilities.invokeLater(new Runnable() { public void run() { AnimationTest test = new AnimationTest(); test.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); test.setVisible(true); } }); } public AnimationTest() { super(); try { JLabel label = new JLabel(); ImageIcon imageIcon = new ImageIcon(ImageIO.read(AnimationTest.class.getClassLoader().getResourceAsStream(""animated.gif""))); label.setIcon(imageIcon); imageIcon.setImageObserver(label); add(label); pack(); } catch (Exception e) { e.printStackTrace(); } } } You have to use getClass().getResource(imgName); to get a URL to the image file. Check out this tutorial from Real's HowTo. EDIT: Once the image is loaded you have to set the ImageObserver property to get the animation to run. I load png images just fine from the jar file using the first section of code. And the gif loads - it's just not animated. I see your problem now. See my edit for more details. setting the ImageObserver did not help in my case. It seems that ImageIO isn't reading the animated gif properly. If I use a different constructor for the ImageIcon it works. I updated the question with a complete code example. You'll need an animated.gif in your classpath.  Since this thread was just linked from a more current thread that had little to do with animated GIFs but got dragged OT I thought I'd add this trivial source that 'works for me'. import javax.swing.*; import java.net.URL; class AnimatedGifInLabel { public static void main(String[] args) throws Exception { final URL url = new URL(""http://i.stack.imgur.com/OtTIY.gif""); Runnable r = new Runnable() { public void run() { ImageIcon ii = new ImageIcon(url); JLabel label = new JLabel(ii); JOptionPane.showMessageDialog(null label); } }; SwingUtilities.invokeLater(r); } } if anyone wondered how to just load image from file here is how: url = new URL(""file"" ""localhost"" ""resources/image.gif"");  Hopefully it's not too late for this. I managed to get the animated gif inside my JPanel this way: private JPanel loadingPanel() { JPanel panel = new JPanel(); BoxLayout layoutMgr = new BoxLayout(panel BoxLayout.PAGE_AXIS); panel.setLayout(layoutMgr); ClassLoader cldr = this.getClass().getClassLoader(); java.net.URL imageURL = cldr.getResource(""img/spinner.gif""); ImageIcon imageIcon = new ImageIcon(imageURL); JLabel iconLabel = new JLabel(); iconLabel.setIcon(imageIcon); imageIcon.setImageObserver(iconLabel); JLabel label = new JLabel(""Loading...""); panel.add(iconLabel); panel.add(label); return panel; } Some points of this approach: 1. The image file is within the jar; 2. ImageIO.read() returns a BufferedImage which doesn't update the ImageObserver; 3. Another alternative to find images that are bundled in the jar file is to ask the Java class loader the code that loaded your program to get the files. It knows where things are. So by doing this I was able to get my animated gif inside my JPanel and it worked like a charm.  This reads gif animation from inputStream InputStream in = ...; Image image = Toolkit.getDefaultToolkit().createImage(org.apache.commons.io.IOUtils.toByteArray(in)); This is the definite answer. Thank you after researching this issue several hours. This also solves the problem with loading resources from Eclipse and from Maven in JARs. Thanks alot!",java swing animated-gif javax.imageio401598,A,"How can I get the length of a JTextField's contents as the user types? JTextField has a keyTyped event but it seems that at the time it fires the contents of the cell have not yet changed. Because of that .length() is always wrong if read here. There must be a simple way of getting the length as it appears to the user after a key stroke? Use this code: public void jTextField6KeyReleased(java.awt.event.KeyEvent evt) { System.out.println(jTextField6.getText().length()); } Consider expanding your answer to explain to the asker why this achieves the desired result possibly linking to documentation. As is this is only marginally useful.  KeyEvents are low-level events that are not appropriate here [that sounds familiar]. How does the JTextField system know that a character has been typed? Through a key typed event (IIRC done through the PL&F). Does the event get dispatched to the system listener before your listener? It might or might not do. In this case you probably want to go to the Document and add a higher-level listener. With Swing it's a good idea to go for the model early - the 'J' class interfaces are incoherent. If you are intercepting input data then you probably want a custom model (or in the case of Document a DocumentFilter).  This may be related to this ""bug"" (or rather ""feature"") The listeners are notified of the key events prior to processing them to allow the listeners to ""steal"" the events by consuming them. This gives compatibility with the older awt notion of consuming events. The ""typed"" event does not mean text was entered into the component. This is NOT a bug it is intended behavior. A possible solution is to listen to an associated Document // Listen for changes in the text myTextField.getDocument().addDocumentListener(new DocumentListener() { public void changedUpdate(DocumentEvent e) { // text was changed } public void removeUpdate(DocumentEvent e) { // text was deleted } public void insertUpdate(DocumentEvent e) { // text was inserted } }); Note this works no matter how the text gets changed; via a clipboard cut/paste progamatic ""setText()"" on the TextField or the user typing into the field on the UI.  This is probably not the optimal way (and it's been a while) but in the past I have added a DocumentListener to the JTextField and on any of the events (insert update remove) I: evt.getDocument().getLength() Which returns the total length of text field's contents.",java swing events283967,A,How do I control the display of a JComponent's Tooltip? I have a JComponent that's painting various shapes on itself. I'm detecting whenever the mouse enters one of these shapes and changing the tooltip accordingly. The problems I'm having are: The tooltip doesn't follow the mouse as the user tracks the mouse across the shape. It stays where it was first set and then only jumps whenever another shape changes the tooltip. It takes about a second for the tooltip to appear but I'd like it to appear immediately. Can someone suggest a way of getting these behaviours without writing a custom tooltip mechanism? Take a look at the ToolTipManager. You can register your component with that manager and then adjust a number of settings. Its pretty straight forward to use. That at least can solve your initialdelay problem. For your first problem you can overide the createTooltip command from your component to get a hold of the JTooltip instance. and then its easy make the position change whenever you move your mouse(aka follow your mouse) as its a subclass of the JComponent class.  To solve your first issue of where the tooltip doesn't follow the mouse if you override the getToolTipLocation(MouseEvent e) in JComponent you can return the point for where you want to the display the tooltip. The MouseEvent will allow you to retrieve the x and y.,java swing176150,A,"Swing: Is there a way to differentiate between a user-caused ItemEvent and an application-caused one? I'm working with a combobox in a Swing-based application and I'm having a hard time figuring out what to do to differentiate between an ItemEvent that is generated from a user event vs one caused by the application. For instance Lets say I have a combobox 'combo' and I'm listening for itemStateChanged events with my ItemListener 'listener'. When either a user changes the selection to item 2 or I execute the line (pseudocode): combo.setSelection(2) .. it seems like I'm not able to tell these events apart. That said I'm no Swing expert by any means so I thought I would ask. Thanks! @awied: you also need to worry about the situation in which a user accessibility application is driving your program. I'm not following this. Why would you generate events programmatically and then want them to be different from normal events? I'm not generating events exactly. I have listeners that ""do things"" which are attached to the combobox. When the user performs the action the application works properly. However when I need to update the combo it still causes the events but I need it handled differently. You can set a flag in your code before you set the selection and then check for this flag in the listener (and unset the flag if it is set)... There may be a better way since Java 6 but this is the way I always used to do it... [Edit]: As David points out you will need to set the flag (and update the combo) in the EDT using SwingUtilities.invokeLater or similar (you should do this anyway as you are changing a UI control)  So I'm guessing you want the user selection to perform some action rather than just a plain old direct state change. This is an issue caused by limited flexibility (flexibility is always going to be limited particularly if you have flexibility in other directions). My suggestion: Firstly always go straight to using model in Swing. The widgets are way to complicated and you want different concerns to be split up. Fortunately Swing is already there with its models. A common pattern is to have delegation between models. So in this case you have the ""real"" default model that holds your data. Insert between the JComboBox and real ComboBoxModel and delegating ComboBoxModel that performs actions on state change instructions. Your application code should ignore the JComboBox and go straight for the real ComboBoxModel bypassing the delegating model. So in a diagram:  User -- JComboBox -- ActionComboBoxModel -- DefaultComboBoxModel -- Application code  Whether the user selects Item 2 or the API calls setSelection(2) the event will appear the same. The solution to your problem might be in re-thinking what you want the itemStateChanged code to do when the selection changes. Why would your app work differently under each condition? Maybe there are similarities that you can use to your advantage. Be careful when using flags. The itemStateChanged event will occur on the Event Dispatch Thread which is a different thread than the one on which you'd set the state of the flag. This would mean that using a flag may not be 100% reliable.  If you need to tell the events apart then there is probably something about your design that needs a rethink. The whole point of MVC is to decouple changes to the model from the actual mouse clicks of the user. Perhaps you should restate the question in terms of why you would ever want to differentiate between these two situations. We could then provide some guidance on a different way of achieving the goal.  The Action and Reaction law is quite clear :). If you try to react on change there is no need to distinguish between user and application. I can imagine only one use case where you need to ""distinguish"". The case where application is displaying some data. In this case you have probably data model for your application. And also there are some change listener in this model and application GUI will react by setting values to components. And also. If user selects anything into GUI component. The data model will react by changing value. In this case it is easy to set up some sort of read-only state on data model which will notify model to ignore ANY event coming from observed objects. This notification set should run in EDT and there is no problem with flagging. Small example: class ApplicationDataModel { private Flag current = Flag.RW; public void setData(ApplicationData data) { current = Flag.RO; setDataImpl(data); notifyObservers(); current = Flag.RW; } public void reaction(Event e) { if (flag = Flag.RO) return; ... } } Be careful with flagging and don't forget about threading. If you are calling setData from another thread then EDT you are going into trouble. Of course. The extraction of ApplicationData object has to be run in different thread ;). In general rethink design of your application.",java swing events combobox listeners482041,A,"How to select first item in JPopupMenu? In the past when one made a JPopupMenu visible it's first item would get selected by default: http://weblogs.java.net/blog/alexfromsun/archive/2008/02/jtrayicon_updat.html Nowadays the default behavior is to pop up the menu without any item selected. I would like create a JPopupMenu with a single item that will pop up selected and centered under the mouse pointer. I have managed to get the item to pop up centered under the mouse but I the JMenuItem refuses to render as if it is selected. If I move the mouse out of the item and back in it selects properly. Any ideas? Here is my testcase: import java.awt.Component; import java.awt.Point; import java.awt.event.ActionEvent; import java.awt.event.ActionListener; import java.awt.event.MouseAdapter; import java.awt.event.MouseEvent; import javax.swing.JFrame; import javax.swing.JMenuItem; import javax.swing.JPopupMenu; public class Test extends JFrame { public static void main(String[] args) { JFrame frame = new JFrame(); frame.setSize(800 600); frame.getContentPane().addMouseListener(new MouseAdapter() { @Override public void mousePressed(MouseEvent e) { if (e.isPopupTrigger()) popupTriggered(e); } @Override public void mouseReleased(MouseEvent e) { if (e.isPopupTrigger()) popupTriggered(e); } private void popupTriggered(MouseEvent e) { JPopupMenu menu = new JPopupMenu(); final JMenuItem item = new JMenuItem(""This is a JMenuItem""); menu.add(item); Point point = e.getPoint(); int x = point.x - (item.getPreferredSize().width / 2); int y = point.y - (item.getPreferredSize().height / 2); menu.show((Component) e.getSource() x y); } }); frame.setDefaultCloseOperation(JFrame.DISPOSE_ON_CLOSE); frame.setVisible(true); } } I found some inconsistent behavior too (see my updated answer). Can you confirm this? I reported this as a bug to Sun. I'll let you know what they write back. Here is the associated bug report: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6799989 Secret turns out to be MenuSelectionManager.defaultManager().setSelectedPath(new MenuElement[]{menu ...}); import java.awt.event.MouseAdapter; import java.awt.event.MouseEvent; import javax.swing.JFrame; import javax.swing.JMenuItem; import javax.swing.JPopupMenu; import javax.swing.MenuElement; import javax.swing.MenuSelectionManager; import javax.swing.SwingUtilities; /** * Demonstrates programmatic {@link JMenuItem} selection; * specifically how to make the first item selected by default */ public class TestPopup extends JFrame { public static void main(String[] args) { final JFrame frame = new JFrame(""TestPopup""); frame.setSize(640 480); frame.getContentPane().addMouseListener(new MouseAdapter() { @Override public void mousePressed(MouseEvent e) { if (e.isPopupTrigger()) { popupTriggered(e); } } private void popupTriggered(MouseEvent e) { final JPopupMenu menu = new JPopupMenu(); final JMenuItem item0 = new JMenuItem(""JMenuItem 0""); final JMenuItem item1 = new JMenuItem(""JMenuItem 1""); menu.add(item0); menu.add(item1); menu.pack(); // use invokeLater or just do this after the menu has been shown SwingUtilities.invokeLater(new Runnable() { public void run() { MenuSelectionManager.defaultManager().setSelectedPath(new MenuElement[]{menu item0}); } }); int x = (int) ((int) (frame.getSize().width - (menu.getPreferredSize().width / 2.)) / 2.); int y = (int) ((int) (frame.getSize().height - (menu.getPreferredSize().height / 2.)) / 2.); menu.show(frame x y); // doesn't work: //item0.setSelected(true); // doesn't work: //menu.getSelectionModel().setSelectedIndex(0); // bingo; see also MenuKeyListener / MenuKeyEvent // MenuSelectionManager.defaultManager().setSelectedPath(new MenuElement[]{menu item0}); } }); frame.setDefaultCloseOperation(JFrame.DISPOSE_ON_CLOSE); frame.setLocationRelativeTo(null); frame.setVisible(true); } }  This is weird. I tried it with Windows and with Java 1.5.0_08 and even 1.6.0_07 the first Element is selected automatically as you expected it to be. So I tried it with 1.6.0_11 and it does not work any more the first element is not selected initially. Selecting the element in the selectionModel does not seem to help. One workaround (that I'm not at all proud of) is to move the mouse automatically after displaying the popup menu using the coordinates of the MouseEvent. Maybe someone's got a better idea? import java.awt.AWTException; import java.awt.Robot; import java.awt.event.MouseAdapter; import java.awt.event.MouseEvent; import javax.swing.JFrame; import javax.swing.JMenuItem; import javax.swing.JPopupMenu; public class SelectedPopupMenu extends JFrame { public SelectedPopupMenu() { addMouseListener(new MouseAdapter() { public void mouseClicked(final MouseEvent e) { JPopupMenu popupMenu = new JPopupMenu(); popupMenu.add(new JMenuItem(""Test-Item"")); popupMenu.add(new JMenuItem(""Test-Item-2"")); // do not care to really hit the center of the popup popupMenu.show(SelectedPopupMenu.this e.getX() - 30 e.getY() - 10); try { // shake mouse so that first element is selected even in Java 1.6.0_11 Robot robot = new Robot(); robot.mouseMove(e.getX() + 1 e.getY()); robot.mouseMove(e.getX() e.getY()); } catch (AWTException ex) { ex.printStackTrace(); } } }); } public static void main(String[] args) { JFrame frame = new SelectedPopupMenu(); frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); frame.setSize(800 600); frame.setVisible(true); } }  Nowadays the default behavior is to pop up the menu without any item selected. Actually I would argue that this is the correct behavior at least in Windows. Other non-Java applications do this too. I don't think it's worth breaking this convention even if there is only one item in the menu. If you feel otherwise you can set the selection index as in sean.bright's answer. So I finally got the chance to try it out on Java 1.6.0_11 and found some inconsistent behavior: If the popup menu juts out of the parent frame the item is automatically selected; if the popup menu appears entirely within the parent frame nothing is selected. Sounds like a Swing bug which at least warrants an RFE for consistent behavior. +1: The right behavior is whatever the particular platform does for other (non-Java) programs. Zach I agree with your general assessment but unfortunately this doesn't answer my question. I *want* to break away from the conventional behavior but I'm finding it impossible to do so. I'm trying to find out if this is a Swing bug or user error. I filed a bug report with Sun: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6799989  MenuSelectionManager.defaultManager() is indeed a good solution but it won't work when you'll try to pre-select your JPopupMenu's sub menus (it will hide the parent menu). Also it messes up other keyboard navigation behaviors (you can't press left to hide the sub-menu etc.) Unfortunatelly there's no good solution for this question in Swing... My solution is ugly but sadly does the job perfect: public static void setMenuSelectedIndex(final JPopupMenu popupMenu final int index) { SwingUtilities.invokeLater(new Runnable(){public void run() { for (int i=0; i < index+1; i++) { popupMenu.dispatchEvent(new KeyEvent(popupMenu KeyEvent.KEY_PRESSED 0 0 KeyEvent.VK_DOWN '\0')); } }}); } As you can see I'm basically simulating 'Down' Keyboard Key-Presses on the popupmenu... A better solution might be not to Hardcodedly simulate VK_DOWN but to read the Popup's input map and determine which KeyCode means ""select next menu item"" - but I think most of us will get along with this hack... You might also want to look at this method which selects a menu's item once it gets selected It utilizes the previous method public static void setSelectedIndexWhenVisible(final JMenu menu final int index) { menu.getPopupMenu().addPopupMenuListener(new PopupMenuListener() { @Override public void popupMenuWillBecomeVisible(PopupMenuEvent e) { PopupUtils.setMenuSelectedIndex(menu.getPopupMenu() index); menu.getPopupMenu().removePopupMenuListener(this); } @Override public void popupMenuWillBecomeInvisible(PopupMenuEvent e) { } @Override public void popupMenuCanceled(PopupMenuEvent e) { } }); } aside from that the solution of simulating the down arrow keypress does work. er what's PopupUtils? Doesn't seem to be part of my JDK.",java swing jmenupopup282539,A,"Java actionListener for a nameless JButton? I was wondering if there is a way to implement an action listener for a Jbutton without a name. For example I have the following for loop that creates a button for each letter of the alphabet. for (int i = 65; i < 91; i++){ alphabetPanel.add(new JButton(""<html><center>"" + (char)i)); } Is there a way that I can add an action listener for each of those buttons without getting rid of my for loop and hard coding each JButton and then creating an action listener for each? Thanks in advance Tomek Your question is a little vague. it would be trivial to modify the loop to add a listener inside the loop: ActionListener listener = something; for (int i = 65; i < 91; i++){ JButton button = new JButton(""<html><center>"" + (char)i); button.addActionListener( listener ); alphabetPanel.add(button); } if you can't modify the loop you could iterate over all of the panel's children and add listeners to any of the children that are jbuttons. also why are you using html to center the text? isn't that overkill? doesn't jbutton already center text? you could use setHorizontalAlignement(SwingConstants.CENTER) to do it too. for some reason I thought that te way action listener works is that after it is created it somehow stops there in the code until an action is performed but I guess that defeats the entire purpose of it. I changed it and it worked exactly as I wanted it to. Thanks! P.S. html was overkill  It is possible to add ActionListener to anonymous components like below: new JButton().addActionListener(new ActionListener(){ @Override public void actionPerformed(ActionEvent arg0) { // TODO your action } }); However in your case where you try to add the anonymous JButton to your panel this approach will not work because the return type of addActionListener method (which is void) will be taken instead of JButton's constructor as shown below: for (int i = 65; i < 91; i++){ alphabetPanel.add(new JButton(""<html><center>"" + (char)i).addActionListener(new ActionListener(){ @Override public void actionPerformed(ActionEvent arg0) { // TODO your action } })); } The above code complains about invalid argument for panel.add() method. So in your case you will have to create a named instance of the JButton. Hope this clarifies. Best Regards Suresh  What is the problem of doing this? for (int i = 65; i < 91; i++){ JButton button = new JButton(""<html><center>"" + (char)i)); button.addActionListener( new ButtonListener()); alphabetPanel.add(button); } ... class ButtonListener implements ActionListener { ButtonListener() { } public void actionPerformed(ActionEvent e) { //TODO: } } Also if the button's text doesn't identify the button you could set the button's name with the letter of the alphabet. button.setName((char)i)); // or button.setName(i);  By named you seem to mean storing the button instance in a local variable of your immediate method. Attempting to avoid that is likely to make your code more difficult to read. But to answer your question: The most obvious way is to use the old but newly-popular double-brace idiom. alphabetPanel.add(new JButton(""<html><center>"" + (char)i) {{ addActionListener(new ActionListener() { public void actionPerformed(ActionEvent event) { ... } }); }}); Note in this case as i is not final it will not be usable from the anonymous inner class. Either assign it to another (final) variable or reformulate the loop. Another route would be to go via an Action. (Usually I'd suggest avoiding Actions as they are jsut a poor man's Hashtable. ButtonModel is ""good"" though.) alphabetPanel.add(new JButton(new AbstractAction(""<html><center>"" + (char)i) { public void actionPerformed(ActionEvent event) { ... } })); Then of course there is the application specific library way: Form alphabetForm = new Form(alphabetPanel); for (char c='A'; c <= 'Z'; ++c) { alphabetForm.button(""<html><center>"" + c new ActionListener() { public void actionPerformed(ActionEvent event) { ... } }); }",java swing jbutton actionlistener334397,A,"Detect whether FocusEvent of component is lost or gained I implementing a EventQueue and get notified when AWTEvents are send. I wait till instances of FocusEvent are send to the dispatchEvent methode. The FocusEvent by itself does not have a methode to ask if the focus of the component is gained or lost. The methode paramString returns a String in which the information is placed but i dont want to hack or pars the String. A contains call can give me the answer but the returnes String is no constant so it could change in the future. The paramString methode of FocusEvent is like:  switch(id) { case FOCUS_GAINED: typeStr = ""FOCUS_GAINED""; break; case FOCUS_LOST: typeStr = ""FOCUS_LOST""; break; default: typeStr = ""unknown type""; } return typeStr + (temporary ? ""temporary"" : ""permanent"") + ""opposite="" + getOppositeComponent(); Do you know another solution for this issue. What's wrong with ""evt.getID()""? It returns FOCUS_LOST or FOCUS_GAINED? when you want to implement something during the last minutes in the office you sometimes get crazy. Thanks a lot. @Markus - I know that feeling well. Glad to help.",java swing events awt309675,A,"How can I make a swing JButton repeat its action when it is held down? I am creating an touch screen application using Swing and have a request to change one of buttons so that it will behave like a keyboard when the button is held down. (First of all I am not sure that the touch screen will allow the user to ""hold down"" the button but pretend that they can for now) I was going to go down the path of starting a loop when mousePressed was called and then ending the loop when mouseReleased was called. This will involve starting a thread and having to deal with synchronization as well as invokeLater() to get events back on the EventQueue. Is there a very simple way to do what I want? I hope I am just not seeing the API to do it. There is no simple way. I think what you outlined with a thread doing timed sleeps and polling the button is the only way. I went with the java.swing.Timer since it will automatically post back to the Swing EventQueue and that is what I am looking for. Thanks for the help.  I would do it like this: Listen to mousePressed and schedule a java.util.Timer to be launched at a later time. The Timer does the action and set itself to schedule again. Listen to mouseReleased to cancel the Timer.  javax.swing.Timer is your friend. And here's an article with some more info. @Christopher updated thanks That article link is stale.",java swing407506,A,Is Google Web Toolkit similar to AWT and Swing I've looked breifly into GWT and like the idea that I can develop in Java and have the application compile down to HTML and JavaScript. Is the concept behind GWT and AWT and Swing the same or different? AWT and Swing are for programming stand-alone applications (and to a lesser extent applets). GWT is supposed to make programming web applications similar to stand-alone apps. I wouldn't program a non-web app using GWT.  It is programmed very similarly(patterned after Swing) and the code is 100% java (compiles with a standard Java compiler without errors) but the way it works is very different. Instead of compiling into a Java app it compiles into Javascript that is sent to your browser. This ability to program good active Javascript without actually coding Javascript and HTML is pretty nice. Also since it programs much like swing you can do stuff like adding listeners that effect other controls pretty easily. Actually GTW supports only a strict subset of Java's standard libraries. There are some libraries that aren't supported simply because they can't be represented in JavaScript. For example GWT's Random is a util class with static methods while Java 1.5 uses it as an object etc...  disclamer: While I do work at IT Mill this is just for information to the original poster. This isn't marketing spam. If you like the idea of being able to write Java and get a webpage out of that you might be interested in IT Mill Toolkit. It's a toolkit for making RIA software on top of a J2EE stack and it uses GWT heavily. One of the basic ideas are that the code generated by GWT is just as prone to client-side forging attacks as any other JS/Ajax-traffic. IT Mill Toolkit makes sure that the data is validated server-side too. The toolkit is also designed in such a way that if you are familiar to Swing you should have no problems picking it up.  GWT is very much similar to Swing in its usage of Widgets Panels and the EventListeners it provides. A different way to look at GWT is to think of Javascript and HTML as Assembly language and GWT as a sort of High level language which generates Javascript and HTML. With GWT its easy to develop desktop-like apps for the web using the same tools you would use for building a desktop app  GWT is conceptually similar to Swing but is more a replacement for JSPs than anything else. I agree. Though you still use Java on the server side.  GWT is a javascript toolkit that allows you to write the javascript in Java. The only real similarities to Swing and AWT are that they are toolkits for creating user interfaces and they use Java. The end product is different and the real purpose for using them is different. GWT gives you the ability to generate a ajax user interface for a web browser while the other 2 give you a console (or applet) java app. In my mind the real reason for using GWT is to get a quick ajax interface up for prototyping purposes. But I dont think its really production ready- ie I dont thing Google uses it in their own webapps. A better choice for more robust ajax webapps is http://developer.yahoo.com/yui/ or http://script.aculo.us/.  Define concept. AWT/Swing are used for desktop Java apps or applets. They both require JVM to run. GWT is used to translate Java code to Javascript. This only runs on Javascript engines i.e. browser. The API design as stated above is similar to Swing. You get the same Panels Buttons and other Component classes as in Swing.,java swing gwt awt100123,A,"Application wide keyboard shortcut - Java Swing I would like to create an application wide keyboard shortcut for a Java Swing application. Looping over all components and adding the shortcut on each has focus related side effects and seems like a brute force solution. Anyone has a cleaner solution? For each window use JComponent.registerKeyboardAction with a condition of WHEN_IN_FOCUSED_WINDOW. Alternatively use: JComponent.getInputMap(WHEN_IN_FOCUSED_WINDOW).put(keyStroke command); JComponent.getActionMap().put(commandaction); as described in the registerKeyboardAction API docs. +1 The best easiest answer I have found. I will upvote this x1000 x1001 would be better that way he'd at least get an upvote. @Epaga Or 999 times  For people wondering (like me) how to use KeyEventDispatcher here is an example that I put together. It uses a HashMap for storing all global actions because I don't like large if (key == ..) then .. else if (key == ..) then .. else if (key ==..) .. constructs. /** map containing all global actions */ private HashMap<KeyStroke Action> actionMap = new HashMap<KeyStroke Action>(); /** call this somewhere in your GUI construction */ private void setup() { KeyStroke key1 = KeyStroke.getKeyStroke(KeyEvent.VK_A KeyEvent.CTRL_DOWN_MASK); actionMap.put(key1 new AbstractAction(""action1"") { @Override public void actionPerformed(ActionEvent e) { System.out.println(""Ctrl-A pressed: "" + e); } }); // add more actions.. KeyboardFocusManager kfm = KeyboardFocusManager.getCurrentKeyboardFocusManager(); kfm.addKeyEventDispatcher( new KeyEventDispatcher() { @Override public boolean dispatchKeyEvent(KeyEvent e) { KeyStroke keyStroke = KeyStroke.getKeyStrokeForEvent(e); if ( actionMap.containsKey(keyStroke) ) { final Action a = actionMap.get(keyStroke); final ActionEvent ae = new ActionEvent(e.getSource() e.getID() null ); SwingUtilities.invokeLater( new Runnable() { @Override public void run() { a.actionPerformed(ae); } } ); return true; } return false; } }); } The use of SwingUtils.invokeLater() is maybe not necessary but it is probably a good idea not to block the global event loop. Not the simplest solution but definitely the most elegant and reliable one.  Install a custom KeyEventDispatcher. The KeyboardFocusManager class is also a good place for this functionality. KeyEventDispatcher  Use the following piece of code ActionListener a=new ActionListener(){ public void actionPerformed(ActionEvent ae) { // your code } }; getRootPane().registerKeyboardAction(aKeyStroke.getKeyStroke(""ctrl D"")JComponent.WHEN_IN_FOCUSED_WINDOW); Replace ""ctrl D"" with the shortcut you want. @kleopatra Hmm. Thanks for the comment. I want to know the reason. I didn't find it! don't quite understand - reason for what? Why is registerKeyboardAction() obselete that's a question for the swing team 10+ years ago :-) There used to be an article (old swingconnection?) introducing keyBindings that also argued the why .. don't have a reference though sorry. no that's outdated api (superceded by actionMap/inputMap since jdk 1.2 or 1.3 - way back in stone age) Please see the javadoc (JComponent.registerKeyboardAction(java.awt.event.ActionListener java.lang.String javax.swing.KeyStroke int)): This method is now obsolete please use a combination of getActionMap() and getInputMap() for similiar behavior.  When you have a menu you can add global keyboard shortcuts to menu items:  JMenuItem item = new JMenuItem(action); KeyStroke key = KeyStroke.getKeyStroke( KeyEvent.VK_R KeyEvent.CTRL_DOWN_MASK); item.setAccelerator(key); menu.add(item);",java swing shortcut keystroke272124,A,"Best way to implement tooltips for JTree? since JTree & TreeModel don't provide tooltips straight out-of-the-box what do you think what would be the best way to have item-specific tooltips for JTree? Edit: (Answering my own question afterwards.) @Zarkonnen: Thanks for the getTooltipText idea. I found out another (maybe still a bit nicer) way with overriding DefaultTreeCellRenderer and thought to share it: public class JTreeWithToolTips { private static class OwnRenderer extends DefaultTreeCellRenderer { @Override public Component getTreeCellRendererComponent(JTree tree Object value boolean sel boolean expanded boolean leaf int row boolean hasFocus) { setToolTipText(""foobar"" + row); return super.getTreeCellRendererComponent(tree value sel expanded leaf row hasFocus); } } public static void main(String[] args) { JTree tree = new JTree(new Object[] { ""foo"" ""bar"" ""foobar"" }); tree.setCellRenderer(new OwnRenderer()); ToolTipManager.sharedInstance().registerComponent(tree); JFrame frame = new JFrame(); frame.getContentPane().add(tree); frame.pack(); frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); frame.setVisible(true); } } Your answer should be in an answer so people can vote on it. DefaultTreeCellRenderer#getTreeCellRendererComponent is called a lot and making this too heavyweight can make stuff not work as expected. Like tooltips that should show up but don't. Overriding JTree#getToolTipText(MouseEvent e) is only called when needed and as such is a much better solution! See getTooltipText on JTree. This should allow you to show tooltips depending on what in the tree is being hovered over. (Do read the docs though you need to register the JTree with the ToolTipManager.)  Yeah you can use onMouseMoved and then use a method (I don't remember the name) that tells you in which node you are over. If you get null obviously then you are not over a node. Since it's not mentioned elsewhere: the methods linking mouse position to tree node are `getPathForLocation(int int)` and `getRowForLocation(int int)`. As suggested by other answers implementing custom renderer or overriding `getToolTipText(MouseEvent)` is cleaner than adding a `MouseListener`.",java swing tooltip jtree201287,A,"How do I get which JRadioButton is selected from a ButtonGroup I have a swing application that includes radio buttons on a form. I have the ButtonGroup however looking at the available methods I can't seem to get the name of the selected JRadioButton. Here's what I can tell so far: From ButtonGroup I can perform a getSelection() to return the ButtonModel. From there I can perform a getActionCommand but that doesn't seem to always work. I tried different tests and got unpredictable results. Also from ButtonGroup I can get an Enumeration from getElements(). However then I would have to loop through each button just to check and see if it is the one selected. Is there an easier way to find out which button has been selected? I'm programing this in Java 1.3.1 and swing. Java 1.3.1? As in only supported on vintage Solaris 8 and no bugs from April? Yeah I know. The desktop machines that I'm developing this for have older applications that still run on this version and I don't want to mess with that. I suggest going straight for the model approach in Swing. After you've put the component in the panel and layout manager don't even bother keeping a specific reference to it. If you really want the widget then you can test each with isSelected or maintain a Map<ButtonModelJRadioButton>.  I got similar problem and solved with this: import java.util.Enumeration; import javax.swing.AbstractButton; import javax.swing.ButtonGroup; public class GroupButtonUtils { public String getSelectedButtonText(ButtonGroup buttonGroup) { for (Enumeration<AbstractButton> buttons = buttonGroup.getElements(); buttons.hasMoreElements();) { AbstractButton button = buttons.nextElement(); if (button.isSelected()) { return button.getText(); } } return null; } } It returns the text of the selected button. I love making custom methods for tasks. Nicely done. This method is EXACTLY what I needed. I thank you very much! I wish I could give you 999 ups. This should probably be in Java in the first place...  I would just loop through your JRadioButtons and call isSelected(). If you really want to go from the ButtonGroup you can only get to the models. You could match the models to the buttons but then if you have access to the buttons why not use them directly? It does look like this is the only way thanks. please consider this reading : http://www.javaworld.com/article/2077509/core-java/java-tip-142--pushing-jbuttongroup.html what could possibly be the point of button group then? @Thufir : ButtonGroup tells Java that only on of the JRadioButtons of the group should be selected. without that all of them could be selected simultaneously.  Use the isSelected() method. It will tell you the state of your radioButton. Using it in combination with a loop(say for loop) you can find which one has been selected. Isn't this the same as the accepted answer?  The following code displays which JRadiobutton is selected from Buttongroup on click of a button. It is done by looping through all JRadioButtons in a particular buttonGroup.  JRadioButton firstRadioButton=new JRadioButton(""Female""true); JRadioButton secondRadioButton=new JRadioButton(""Male""); //Create a radio button group using ButtonGroup ButtonGroup btngroup=new ButtonGroup(); btngroup.add(firstRadioButton); btngroup.add(secondRadioButton); //Create a button with text ( What i select ) JButton button=new JButton(""What i select""); //Add action listener to created button button.addActionListener(this); //Get selected JRadioButton from ButtonGroup public void actionPerformed(ActionEvent event) { if(event.getSource()==button) { Enumeration<AbstractButton> allRadioButton=btngroup.getElements(); while(allRadioButton.hasMoreElements()) { JRadioButton temp=(JRadioButton)allRadioButton.nextElement(); if(temp.isSelected()) { JOptionPane.showMessageDialog(null""You select : ""+temp.getText()); } } } } hmm ... this differs from earlier answers in that .. ?  You could use getSelectedObjects() of ItemSelectable (superinterface of ButtonModel) which returns the list of selected items. In case of a radio button group it can only be one or none at all. I tried this but I was getting a NPE. I did a little research and found this: http://java.sun.com/javase/6/docs/api/javax/swing/DefaultButtonModel.html#getSelectedObjects() Since JRadioButton's button model is JToggleButton.ToggleButtonModel it will always return null.  import javax.swing.Action; import javax.swing.ButtonGroup; import javax.swing.Icon; import javax.swing.JRadioButton; import javax.swing.JToggleButton; public class RadioButton extends JRadioButton { public class RadioButtonModel extends JToggleButton.ToggleButtonModel { public Object[] getSelectedObjects() { if ( isSelected() ) { return new Object[] { RadioButton.this }; } else { return new Object[0]; } } public RadioButton getButton() { return RadioButton.this; } } public RadioButton() { super(); setModel(new RadioButtonModel()); } public RadioButton(Action action) { super(action); setModel(new RadioButtonModel()); } public RadioButton(Icon icon) { super(icon); setModel(new RadioButtonModel()); } public RadioButton(String text) { super(text); setModel(new RadioButtonModel()); } public RadioButton(Icon icon boolean selected) { super(icon selected); setModel(new RadioButtonModel()); } public RadioButton(String text boolean selected) { super(text selected); setModel(new RadioButtonModel()); } public RadioButton(String text Icon icon) { super(text icon); setModel(new RadioButtonModel()); } public RadioButton(String text Icon icon boolean selected) { super(text icon selected); setModel(new RadioButtonModel()); } public static void main(String[] args) { RadioButton b1 = new RadioButton(""A""); RadioButton b2 = new RadioButton(""B""); ButtonGroup group = new ButtonGroup(); group.add(b1); group.add(b2); b2.setSelected(true); RadioButtonModel model = (RadioButtonModel)group.getSelection(); System.out.println(model.getButton().getText()); } }  Add the radiobuttons to a button group then: buttonGroup.getSelection().getActionCommand not answering the question (which was to get the selected _JRadioButton_ vs. its actionCommand)  you must add setActionCommand to the JRadioButton then just do String entree = entreeGroup.getSelection().getActionCommand(); ex  java = new JRadioButton(""Java""); java.setActionCommand(""Java""); c = new JRadioButton(""C/C++""); c.setActionCommand(""c""); System.out.println(""Selected Radio Button: "" + buttonGroup.getSelection().getActionCommand());  jRadioOne = new javax.swing.JRadioButton(); jRadioTwo = new javax.swing.JRadioButton(); jRadioThree = new javax.swing.JRadioButton(); ... then for every button: buttonGroup1.add(jRadioOne); jRadioOne.setText(""One""); jRadioOne.setActionCommand(ONE); jRadioOne.addActionListener(radioButtonActionListener); ...listener ActionListener radioButtonActionListener = new java.awt.event.ActionListener() { public void actionPerformed(java.awt.event.ActionEvent evt) { radioButtonActionPerformed(evt); } }; ...do whatever you need as response to event protected void radioButtonActionPerformed(ActionEvent evt) { System.out.println(evt.getActionCommand()); } That confuses input events and state changes. Other code may change the state. It also takes responsibility away from the button group model.",java swing378161,A,"In Java Swing how can you manage a list of panels allowing multiple panels to be selected? IŠ—Èm working on an in-house app that tracks a bunch of tasks. I wanted to have a simple task monitor that would list the task name and the taskŠ—Ès status. I need this to look just a little nice IŠ—Èm no designer so whatever I do is going to suck but a basic text display wonŠ—Èt work for the project requirements. What I am essentially attempting to do is show something similar to the Firefox download window the I-Tunes download window and well I could name more but they all look basically the same. In each of these apps each of the Š—…progress panelsŠ—È is selectable. So to implement this I thought it would be simple to just use a list of JPanels each with a JProgressBar and a JLabel each of which can just accept focus to determine if it and others are selected. I thought this was going to be an easy task but if I use a JList it just displays text. I then just figured I would show all the task panels in a larger panel but I cannot get the inner panels to recognize focus. Is there a pattern for this? Is there a rolled standard solution that I just have not found? Or is there a better method for doing this? I donŠ—Èt want to re-invent the wheel but I thought this was just going to be simple. The standard way of doing this kind of things is to use JTable (or JList) as a container. You don't have to use default renderes fot table cells but you can specify your own renderer for specific cells. Take a look at CellRenderer  It sounds like what you may be looking for is an JList. You can add your items to the JList's by first adding your ""task"" to the JList object's ListModel (see the Create a Model section from The Java Tutorials) and then you'll want to assigned a custom ListCellRenderer which will accept your ""task"" and render on the JList as a JPanel in the list itself. The key here is to make your custom ListCellRenderer be able to display your ""task"" in the JList the way you want to have it show on the JList. Take a look into the Writing a Custom Cell Renderer section from the How to Use Lists page of The Java Tutorials. It will describe how to make your custom ListCellRenderer so you can represent your ""task"" as anything you want. To keep it short you will implement the ListCellRenderer interface by implementing the getListCellRendererComponent which will return a Component which is the representation of your task in the JList. You'll probably want to either construct or instantiate your JPanel in this method and return it as the Component. Here's some simple code showing how to render JPanels in a JList as alluded to in the answer: http://www.rgagnon.com/javadetails/java-0203.html  How about a JTable (which you can set to allow multiple rows to be selected) with an internal JPanel occupying the single cell in each row which contains a JProgressBar and a JLabel. Or you could use a JList with the same structure as I just described.",java swing88434,A,"How can I detect if caps lock is toggled in Swing? I'm trying to build a better username/password field for my workplace and would like to be able to complain when they have their caps lock on. Is this possible? And if so I'd like to have it detected before the client types their first letter. Is there a non-platform specific way to do this? In addition to Nick's answer to react to this condition before the user presses a key you can listen to the focus event of your text entry component and test the caps-lock as the component receives focus.  here is some info on the class http://java.sun.com/j2se/1.5.0/docs/api/java/awt/Toolkit.html#getLockingKeyState(int)  Try this from java.awt.Toolkit returns a boolean: Toolkit.getDefaultToolkit().getLockingKeyState(KeyEvent.VK_CAPS_LOCK) Short and to the point perfect! Except that it doesn't work on all platforms. For instance it throws a UnsupportedException under OpenJDK-6 in Linux. :( JDK 1.7 i have compile time error with this keycode as others have pointed out this throws an error on Linux. Interestingly there must be an internal way to do it in Linux as Gnome displays the message ""You have the caps lock key on."" when it is on and the screen is locked. Perhaps OS has APIs but java has not implemented them? using jdk 1.6 and fedora 14",java swing147802,A,Why does Swing in my Java Applet flicker on fast mouse over? I made a Java Applet with some Standard GUI Components on it. I used the MigLayout Manager. If I move the mouse slowly over the various GUI Components everything appears to be fine but if I move the mouse fast it flickers. What could make that nasty ugly redraw? (Core 2 Duo 6300 2GB Ram Windows XP) One thought would be to check your code (and/or the MigLayout code) for unnecessary repaint() operations. Custom UIs and layouts can cause weird problems sometimes... You're right. Thanks. I found out that I used a custom component which registered a MouseListener.  I found the bugger: I used a custom ClosableTabbedPaint Class.  you could use double buffering in java applet to improve screen refreshing speed. ask more if details needed.. According to http://java.sun.com/products/jfc/tsc/articles/painting/ double buffering is ENABLED BY DEFAULT for all Swing components.,java swing applet207557,A,"What's the best way to add a self-update feature to a Java Swing application? I'm trying to figure out a way to add a self-update feature to a Java/Swing application I'm working on. Basically I've got a bunch of jar files with extra functionality to be re-deployed to the installed users when they change. Nothing complicated just check if a new version has been released download them over HTTP and then optionally offer to restart the app to the user. I had a look at webstart and it could work. But this particular app does some funky stuff with classloading and GC memory settings that don't look like they are supported via webstart or will at least complicate matters. (It's a tweaked build of JMeter) I also went down the road of adding in this plugin handler http://swing-fx.blogspot.com/2008/06/add-auto-update-and-plugins-to-your.html but it is very alpha and tries to do too much with the usual bugs you get with alpha stuff. Updates plugins separation of concern etc. are exactly what OSGi is about - you might want to take a look at this. It won't come free (read: with a steep initial learning curve especially when you are currently using classloading tricks) at least there are good open source implementations (felix - see felix.apache.org equinox - see www.eclipse.org and others) For these implementations autoupdaters are available - if you write your modules correctly it's possible to update at runtime without restarting.  I would definitely first try out Webstart. We've had lots of success launching even the early Eclipse RCP apps using Webstart and you can probably not get more funky classloading issues than with the OSGI framework (Eclipse Equinox). Could you perhaps give some more detail in your question about you classloading approach? Regarding the GC and other VM settings: these are easy to specify in your JNLP (Java Network Launching Protocol) files used by Webstart for launching apps. Could you give a link to an RCP app? Do you mean a RCP app that can be webstarted? The one's I worked on are all for intranet type enterprise applications so not available on the web.  The Java Web Start is good choice. The GC stuff is not important. Classloading could be problem. But when you got trusted by user you can grant AllPermisions and you will be able to do custom classloading. Maybe it will be good to reconsider funky stuff with classloading. It is really necessary? Or look at NetBeans. There should be found inspiration for auto-update.  I did the exact same thing. But that was long back so there are probably better tools today. What I found out I needed was a loader. The loader main program did not have the app jars in classpath. It first downloaded an update if required and then created a custom classloader with the app jars in class path and invoked the main method of the application main class. It is not very complicated. IIRC I needed to do this because the jars could not be overwritten in windows if they were already in classpath. Hope this helps. That seemed to be the easiest way all round. I kept an XML file on the server and a replica of it locally listing all the files to be updated and a version number. Quick and simple but does the trick.  we had a swing app 6 years ago that had self-update. like you suggested 1)it downloaded the latest jars over http 2) copied them to a folder. 3) since the swing app is launched using a .BAT file after user said YES we would shut down the swing app and look for any files in the update folder. if yes launch another .BAT file to copy the NEW JARs to the required directory. 4) then re launch the swing app.  I believe you should look again at Java WebStart or at least detail the ""funky classloading"" which you think is going to cause problems (as it might also cause problems with any solution proposed here). IIRC you can set command line parameters using Java WebStart ( http://java.sun.com/j2se/1.5.0/docs/guide/javaws/developersguide/syntax.html#resources ).",java swing491323,A,"Is it safe to construct Swing/AWT widgets NOT on the Event Dispatch Thread? I've been integrating the Substance look and feel into my application and ran into several problems regarding it's internal EDT (Event Dispatch Thread) checking routines. Substance absolutely refuses to construct UI classes outside of the EDT. I've done plenty of Swing/AWT and I know most of the rules regarding the EDT. I use SwingWorker SwingUtilties.invokeLater to modify components. I always though that components could be CONSTRUCTED outside of the EDT but must be realized and manipulated on the EDT. In other words you can construct and setup defaults in the background but the call to pack/setVisible must be EDT as well as any subsequent calls to manipulate the component. The reason I ask is that I have a particularly ""beefy"" window to construct involving many widgets state and resources (lots of icons). Previously I constructed the window on the background method of a SwingWorker and made the window visible in the done method. Never had a single problem. Upon switching to Substance the internal EDT checking bites me. I've been able to refactor code to get around this. I can construct on the EDT which isn't a good solution since the entire application will block. I can also refactor even more and try my best to load all of the extra resources outside of the EDT. Wrapping it up ... Is it safe to construct Swing/AWT widgets NOT on the Event Dispatch Thread? No. Simple reason is that even the EDT likes to deadlock in some rare cases and in general it's easy to deadlock the UI when using Swing (or so I've been told). I suggest you read these three articles from Kirill's (the Substance dev) blog: New article on Swing EDT violations Unwritten rule of working with SwingŠ—Ès EDT Stricter checks on EDT violations in Substance  Sun has changed the rules in 2004 -- before you were allowed to create the components outside the EDT and only had to move into the EDT once the component had been realized. The new rule now reads: To avoid the possibility of deadlock you must take extreme care that Swing components and models are created modified and queried only from the event-dispatching thread. this blog post of mine gives more details including links to other related articles. note that all official Sun examples have been rewritten and are very strict about this. historically it probably was the increasing availability of multi-core computers as desktop machines that motivated the re-formulation of the rule -- threading issues became more and more apparent on the client stack and by being very strict on EDT guidelines a lot of them can be prevented from the start. sneaky sneaky ... thanks for the concrete evidence I was craving. Time to refactor! It's more race conditions than deadlocks that cause the problem. @tom: sorry i missed that the quote explicitly mentions the deadlocks -- but as said before i agree with you that it's more the race conditions... @tom: i agree about the race conditions -- never claimed it were the deadlocks have i (just referred to 'threading issues')?",java multithreading gui swing awt422956,A,"Java Swing or Java Qt? Can someone with extensive experience with both Qt and Java Swing please discuss whether you would use Swing or Qt under Java and why? Secondly what is the business impact of using Qt? Is it reasonably popular or will I have a hard time finding experienced Qt developers? Are there any other business impacts I should be aware of? UPDATE: I am more interested in the technical and business impacts of Swing vs Qt than the license type/fee since in my case the cost is not a concern. I agree with Jason. This issue is quite subjective. I accepted an answer favoring Qt but I personally still favor Swing. @HaveAGuess: because at the time the question was posed Qt was a rising star. There are plenty of questions discussing other frameworks. This question focuses solely on the differences between Swing and Qt. Can I ask why we are disregarding Netbeans/Eclipse RCP and even Gtk? Qt Jambi has been picked by community though: http://qt-jambi.org It is licenced under LGPL and approaching 4.7 release. And now Qt will become LGPL as of Qt 4.5 Qt Jambi too ;-) http://www.qtsoftware.com/about/news/lgpl-license-option-added-to-qt As far as Qt vs Java PDF Deepak has presented it clearly was written many years ago. Since then Java's virtual machine has improved tremendously so memory and performance issues are not an issue anymore. The article discusses even the validity of using garbage collector which I find hilarious! ItŠ—Ès also old when it comes to Qt: The Qt toolkit follows a similar approach; like Swing it only relies on the native libraries only for very basic things and handles the drawing of GUI components itself. This is not true anymore Qt now uses native widgets. It no longer emulates them.  As far as Qt vs Java PDF Deepak has presented it clearly was written many years ago. Since then Java's virtual machine has improved tremendously so memory and performance issues are not an issue anymore. The article discusses even the validity of using garbage collector which I find hilarious! Next discussing programming models signal-slot model has been presented as superiour to MVC with only measurement being number of the lines of the code required to achieve same effect! What was overlooked in that document is that Java's code is clearly self-documenting unlike Qt's. I'm not saying that Qt is worse than Swing. I'm just saying that that document should NOT be used as an argument. First two answers give the best description of both frameworks discussing it's strenghts and weakness alone without comparing programming models and pulling conlusions out of a thin air.  Qt is far better than AWT/Swing. I have been using Qt for past three years and have found absolutely no issues in application development. Compared to Qt(C++) Swing(Java) loses out in run time efficiency and memory efficiency. You may get a lot of Java/Swing resources easily they are hundred a penny but if you can hire a good Qt/C++ application developer thats the best choice I say. No offence to Java developers but you have to accept the facts. Qt is available with LGPL licensing. I did not see anybody mention about its cross platform support and the way it is implemented. There is tremendous advantage for Qt there. Great documentation Qt's own intuitive IDE(QtCreator) lotsa examples and a great and fast growing community out there for support! Regarding shipping extra files - there are packaging solutions available. Read more here link text Questionable. How is Qt more cross-platform than Swing? How is LGPL better than ""GPL with classpath exception"" which Swing ships with? All the Qt applications I have seen look horrible especially on OSX whereas Java on OSX is quite reasonable  I don't know much about swing but I'd like to react to Adeel's answer regarding Qt. I don't think finding experienced developer in Qt should be a showstopper : it is very easy and fast to learn Qt. The documentation is very good (that's maybe the best part of Qt : its documentation). IMHO the Qt community is great and I always found the help needed when I had problems. There is many forums (QtCenter.org QtForum.org and others) and Trolltech is running a very active mailing list. I didn't say that it is a showstopper. I just made a point to consider. As the original question mentioned it clearly. Would you down-vote the question too. Kidding. I didn't made any point regarding documentation. Its great I must admit. But I forgot to include it and now I did. By not so strong community I meant number of developers strength. Just go to any Java forum Suns JavaRanch Stackoverflow you would find much help. Of course your list is specific to Qt where else you will find help then if not there.  To correct Adeel's comments; You can ship your software commercially - you just have to include the source. There are thousands of developers with Qt experience (KDE). Qt is standard (used by KDE Nasa ESA Adobe Skype etc) There's a large Qt community and many books and the Qt Jambi product is quite new so it's not surprising it's not that well known yet. And thats what we are talking about Qt Jambi not Qt. I admit Qt is quite common even I am using KDE and quite a no. of applications built on top of Qt. By Commercially I meant closed source. I said it wrong sorry for that. Now correction is made.  Pete's comment is right on. For those who need a more powerful swing based toolkit check out Jide http://www.jidesoft.com/.  Be aware that Qt Jambi will be discontinued shortly. http://www.qtsoftware.com/about/news/preview-of-final-qt-jambi-release-available. My interpretation of this is that following the March 4.5 release Jambi will be in the same boat as Qt bindings for other languages - up to the community to maintain. Regarding your questions I have a few years of Swing experience and I've been working with Qt Jambi for the past month and I'm pretty mixed. On one hand I'm particularly disappointed with Qt's model/view paradigm. Creating an editable tree in Swing by contrast using a completely non-Swing model is a breeze. A couple of hours work. After a week of struggling I've come to the conclusion that it's just not possible to do such a thing in Jambi 4.4. (Dunno about 4.5) The only solution I can find in Qt is to tie data to the Qt model classes by subclassing QStandardItemModel and QStandardItem. (While QAbstractItemModel is very capable in C++ Qt it's literally unusable in Qt Jambi.) On the other hand Qt Jambi gives me access to the amazing QGraphicsView drawing tools and I don't know of a Java library that can compare. To me that's the power of Qt Jambi - it gives you access in Java to excellent 2D and GL drawing tools that really aren't available in Java otherwise. My advice is that if you need to build an application that uses only standard UI widgets like tables trees menus etc. then just use Swing. Layout in Swing is not that hard really especially with tools like NetBeans. However if you need GL or a canvas to paint on Qt Jambi might be worth looking into.  I think the most important factor you should consider is that Jambi QT is going to be discontinued from active development. Swing isn't that of a recent product as well. You should also definitely consider SWT since in my opinion it generally looks better than Swing. There are not production quality designers for SWT Eclipse comes built in with Windows Builder Pro now (or actually at the time of writing an available download that was suppose to be included into the Indigo release).  From my experience (one year Qt several years of Swing). Swing: Pro: Available on any Java installation. No need to ship any additional code You can write your own custom widgets in Java Contra: Swing is old. There haven't been any updates on the core for years and there won't ever be. If you plan to use Swing get a good wrapper which will make using Swing much more simple. Swing is hard to understand and use especially if you're used to UI programming on Windows. (One word: Layouts). Not many powerful widgets in the core set. You'll especially miss a good data grid. For a good look&feel you need an extra library Qt: Pro: Comprehensive set of powerful widgets Easy to use and learn Good documentation Good support Active development Uses native widgets and wraps them in a common API across all platforms Contra: You need to ship extra files Qt is written in C++ so you're accessing it via a wrapper library. If you need to implement a complex custom component things can get hairy. If you can hire a seasoned Swing developer give it a try. If you can't and if you have to start from scratch I suggest against Swing. With Qt you'll have results within hours and with only little hair pulling. Swing is powerful but it makes no attempt to hide this fact. So you'll find yourself struggling a lot with the API and the defaults which have made sense in 1996 but not anymore today. Qt has a much steeper learning curve and the API is much more consistent not to mention that Qt has been improved the last seven years while Swing hasn't (see below). KDE is based on Qt so there are lot of people out there using it and most of them have only little time (say a few hours here and there) and most can handle Qt after a short time. Which you simply can't say for Swing. There is a lot of Swing documentation but most only covers the common cases which you can figure out yourself from the Javadoc. If you need something more complex and if you're looking for a bird's eye view something which gives you a feeling how to combine things to achieve the desired result I haven't seen anything free and I also can't recommend a book for Swing book because I have stopped looking at them five years ago. If you look at Java 7 then you'll find that Sun is thinking about working on the Swing API. But: Java 7 is due in two years there is no commitment for this work items and last but not least: Can you switch to Java 7 when it will be available? Update: It seems that there won't be any Swing updates for Java 7 after all. Which is a pity. It will leave us with a built-in UI framework from the late 90's which just isn't on top of the times anymore. Being an old Amiga lover I know how it feels to be abandoned. Thanks Swing it's been a nice time. yeah because playing with AWT to generate a custom swing component is not a pain. Do you think in Swing we don't have good documentation good support. Come on I can come up with 10 or more times more article tutorials and books. Your pro and con stuff is just plain wrong. Swing has a lot more documentation tutorials and other resources available than there will ever be for QT. Swing is a very flexible framework which allows you to do whatever you want granted that makes it sometimes a bit complicated. At least it is free. I strictly disagree with your pros and cons. Completely disagree with all of your Swing cons. If you want to list pros and cons you must draw a line somewhere. Yeah there is a lot of Swing docs. They explain the basic stuff pretty well and then the air gets thin quick. So the Qt docs are better. Swing is flexible but it is also old. That's why I said it's more simple to write custom widgets in Swing *in Java* but Qt is easier to use and understand. From my experience Swing was good seven years ago and it stayed that way while everything else improved. It's sad :( Adeel: Ok I call. give me the URL of a good documentation of JTextPane which explains how to build your own custom editor with syntax hl spell checking everything you expect from an editor today. Dan: Since you give no reasons I can only ignore your comment :) Completely disagree with the entire answer quite frankly. Details in my answer below. It should also be pointed out that Swing widgets are non-native and ass ugly while Qt widgets are native and beautiful. Qt for Java i.e. Jambi will be officially abandoned as announced by Nokia. @Xolve: Last I heard is that Jambi > 4.5 will become OSS (just like Qt). Please either post a link if you have new information or stop spreading FUD. @Monkey: Please read the question again. This is not an argument against Swing it's whether he'll likely find developers. Qt is easier to learn than Swing. Plus Swing has been abandoned by Sun so no updates for Java 7 :( Gili: URL? As I heard it the Swing JSR will be part of the OpenJDK; that doesn't mean it will be in Java 7 :( FYI: Sun just announced that Swing Application Framework will be part of Java 7. To be completely clear Aaron's update about Swing updates not being issued past Java 7 is purely simply wrong. The Swing Application Framework (JSR 296) was (IMO) a relatively unambitious compromise effort to provide a unified foundation for building GUI apps but it only addressed the least interesting plumbing and infrastructure bits (e.g. resource mgmt bootstrapping session state etc). These are all capabilities that every Java app framework (including NetBeans and Eclipse) have done well for *years* so it's absolutely no loss (again IMO) that JSR 296 has been shelved. @Chas Emerick: I'm sure most readers will understand that my complaint is that Sun didn't put any effort into Swing for years not even something as JSR 296. I didn't say anything about JSR 296 itself. Qt widgets are _not_ native. It draws them itself just as Swing with native L&F does. It's just that Qt native L&F is somewhat better than Swing. Qt has themes that use native widget drawing mechanisms even if it does everything else itself so you can get a native ""look"" even if the ""feel"" is implemented in Qt. Aaron care to comment on this now one year later and with the changes in QT? Please include a @yar in your answer as I THINK that SO will inform me that way. Thanks! @yar: Well ... in one sentence: Swing still sucks a lot C++ Qt sucks a bit less than last year Java Qt sucks much more. I haven't used Qt Jambi for anything serious last year so I can't comment on its state but at least there is an open repository with the code and TrollTech tries to build a community to support it which is more than Sun does for Swing. Interesting. I got burned answering a few questions SO recently because I said that Swing does NOT give you native look and feel. People said ""get with it! That's no longer true! Swing is now near perfect."" I don't know myself... QT does NOT look like it's got much of a community behind it judging from random googling. So uh if Swing goes away what else can we use that's ""native""? Java would be left with no UI? Would we be stuck with either doing command line or web pages? @Brian: My experience is that Qt is much more simple to learn and use then Swing. This doesn't mean you *must not use Swing*. That would be silly. If you have a choice by all means use Qt. If you *don't* have a choice (because Qt just isn't available) well there is no point in arguing which is better is there? @Aaron Qt is fine except that it's not native. You have to go out of your way to use it. It adds complexity to the project and I don't even know if it's readily available in a stable version on all the platforms that Swing is. That's my concern right there. Qt is the basis for the Unix GUI environment KDE. Millions of lines of example code. And in my time maybe 10 years ago very well and extensively documented in the standard documentation. And the Qt philosophy matches QUI development very well which makes it easy to learn. ""If you plan to use Swing get a good wrapper which will make using Swing much more simple."" Which wrappers would you suggest? I've removed the part about Qt not being free for commercial apps. Qt is LGPL'd now. @Alexey: Try Swingx http://swingx.java.net/ +1 for the Amiga lover. I have FIVE. ;-)  I completely disagree with Aaron Digulla's entire answer as it pertains to Swing. I have found Swing to be while not the best design and a little convoluted reasonably simple and workable and ultimately quite well thought out. Further it most definitely is capable of what is required for almost all GUI app's. Using the native LAF the application will look and function enough like a native application to receive a passing grade (IMO). As to the bit about layouts... it's true that the Swing layout's are a little hard to use and need nesting (sometimes a fair amount thereof) to get the desired results but the concept of Layouts are one of the best things about doing GUI's in Java. Take the time to understand what they do for you and get yourself a good table-based layout (e.g. MatrixLayout TableLayout JGoodies FormLayout or MigLayout) which will eliminate 99% of the nesting. A table-based layout will also make your GUI simpler and will make the code better reflect the end visual result. So my advice is that if QT does things in a way in which you would prefer or provides functionality that Swing doesn't then by all means look into it - provided that you are happy with distributing it's Java and native components with your app and that it targets the platforms on which you want to run (or may want to run in the future). Otherwise it's hard to beat Swing's flexibility the fact that it's baked into every Java install and it's ability for you to easily tailor look and behavior. Oh and to be fair I have not looked at QT before - But I have about 6 10 years of active Swing and AWT development comprising 1 commercially deployed AWT application and 3 such (non-trivial) Swing applications plus a number of personal Swing apps. Perhaps more important is that I have implemented a fully-functional lightweight GUI toolkit on top of AWT very much analogous to Swing but with a completely different component and event architecture which has been successfully deployed commercially. Give a try to Qt ;) @Massimo: Last time I check QT for Java was abandoned or discontinued. You should give a try to C++ Qt Dude half year of Qt and 2 years of Swing and AWT here and if you say such things about Swing than you should definitely try Qt...",java qt gui swing476721,A,"Merging cells in JTable Is it possible to merge some cells of a JTable object? If it's not possible through JTable what is the best approach. Thanks. You could implement a JTable using a TableModel merging two columns of the original TableModel. class Model2 extends AbstractTableModel { private TableModel delegate; public Model2(TableModel delegate) { this.delegate= delegate; } public int getRowCount() { return this.delegate.getRowCount();} public int getColumnCount() { return this.delegate.getColumnCount()-1;} public Object getValueAt(int row int col) { if(col==0) return """"+delegate.getValueAt(rowcol)+delegate.getValueAt(rowcol+1); return delegate.getValueAt(col+1); } (...) } I said merging 'cells' not columns.  Not out-of-the-box. Here is an example that supports merging arbitrarty cells. This page has several examples of tables with spanning cells. Of course it's old and you get what you pay for. If paid software is an option JIDE Grids has some really nice Swing table support including custom cell spans. 3 out of 4 of those URLs are 404. :(",java swing jtable cell html276254,A,"How to disable (or hide) the close (x) button on a JFrame? I have a window (derived from JFrame) and I want to disable the close button during certain operations which are not interruptible. I know I can make the button not do anything (or call a handler in a WindowListener) by calling setDefaultCloseOperation(JFrame.DO_NOTHING_ON_CLOSE); but I would like to make it clear visually that it is pointless to click it. I agree with Josh. At the very least map close to a popup that says ""Operation in Progress..."" with a ""Cancel"" (hides popup) and ""Close Anyway"" (forces quit) button. When the background operation completes the app closes if that popup is still visible (i.e. they haven't clicked Cancel) Just a suggestion you might want to consider avoiding such GUI behavior due to poor usability. For those coming to this later than 2008 there has been a change making it possible to do this. See this link Second response from the bottom shows how to do it by name. Like many other things in Swing this too is a complete PITA.  If I understand it correctly this bug report indicates that this is currently not possible.  This is probably the best you are going to get: setUndecorated(true); getRootPane().setWindowDecorationStyle(JRootPane.NONE); This will remove the entire titlebar java doesn't really specify a way to remove individual components of the titlebar edit: There may be a way check out these threads: link 1 link 2",java windows swing74171,A,"Java Compilation - Is there a way to tell the compiler to ignore parts of my code? I maintain a Java Swing application. For backwards compatibility with java 5 (for Apple machines) we maintain two codebases 1 using features from Java 6 another without those features. The code is largely the same except for 3-4 classes that uses Java 6 features. I wish to just maintain 1 codebase. Is there a way during compilation to get the Java 5 compiler to 'ignore' some parts of my code? I do not wish to simply comment/uncomment parts of my code depending on the version of my java compiler. Not really but there are workarounds. See http://forums.sun.com/thread.jspa?threadID=154106&messageID=447625 That said you should stick with at least having one file version for Java 5 and one for Java 6 and include them via a build or make as appropriate. Sticking it all in one big file and trying to get the compiler for 5 to ignore stuff it doesn't understand isn't a good solution. HTH -- nikki --  Keep one ""master"" source root that builds under JDK 5. Add a second parallel source root that has to build under JDK 6 or higher. (There should be no overlap i.e. no classes present in both.) Use an interface to define the entry point between the two and a tiny bit of reflection. For example: ---%<--- main/RandomClass.java // ... if (...is JDK 6+...) { try { JDK6Interface i = (JDK6Interface) Class.forName(""JDK6Impl"").newInstance(); i.browseDesktop(...); } catch (Exception x) { // fall back... } } ---%<--- main/JDK6Interface.java public interface JDK6Interface { void browseDesktop(URI uri); } ---%<--- jdk6/JDK6Impl.java public class JDK6Impl implements JDK6Interface { public void browseDesktop(URI uri) { java.awt.Desktop.getDesktop().browse(uri); } } ---%<--- You could configure these as separate projects in an IDE using different JDKs etc. The point is that the main root can be compiled independently and it is very clear what you can use in which root whereas if you try to compile different parts of a single root separately it is too easy to accidentally ""leak"" usage of JDK 6 into the wrong files. Rather than using Class.forName like this you can also use some kind of service registration system - java.util.ServiceLoader (if main could use JDK 6 and you wanted optional support for JDK 7!) NetBeans Lookup Spring etc. etc. The same technique can be used to create support for an optional library rather than a newer JDK.  You can do all of your compiling exclusively on Java6 and then use System.getProperty(""java.version"") to conditionally run either the Java5 or the Java6 code path. You can have Java6-only code in a class and the class will run fine on Java5 as long as the Java6-only code path is not executed. This is a trick that is used to write applets that will run on the ancient MSJVM all the way up to brand-new Java Plug-in JVMs.  This will make all the Java purists cringe (which is fun heh heh) but i would use the C preprocessor put #ifdefs in my source. A makefile rakefile or whatever controls your build would have to run cpp to make a temporary files to feed the compiler. I have no idea if ant could be made to do this. While stackoverflow looks like it'll be the place for all answers you could wehn no one's looking mosey on over to http://www.javaranch.com for Java wisdom. I imagine this question has been dealt with there prolly a long time ago.  I think the best approach here is probably to use build scripts. You can have all your code in one location and by choosing which files to include and which not to include you can choose what version of your code to compile. Note that this may not help if you need finer-grained control than per file.  A simple solution could be: Place the divergent classes outside of your normal classpath. Write a simple custom classloader and install it in main as your default. For all classes apart from the 5/6 ones the cassloader can defer to its parent (the normal system classloader) For the 5/6 ones (which should be the only ones that cannot be found by the parent) it can decide which to use via the 'os.name' property or one of your own.  Assuming that the classes have similar functionality with 1.5 vs. 6.0 differences in implementation you could merge them into one class. Then without editing the source to comment/uncomment you can rely on the optimization that the compiler always do. If an if expression is always false the code in the if statement will not be included in the compilation. You can make a static variable in one of your classes to determine which version you want to run: public static final boolean COMPILED_IN_JAVA_6 = false; And then have the affected classes check that static variable and put the different sections of code in a simple if statement if (VersionUtil.COMPILED_IN_JAVA_6) { // Java 6 stuff goes here } else { // Java 1.5 stuff goes here } Then when you want to compile the other version you just have to change that one variable and recompile. It might make the java file larger but it will consolidate your code and eliminate any code duplication that you have. Your editor may complain about unreachable code or whatever but the compiler should blissfully ignore it. Is that a documented behaviour of Java compilers? This answer seems incorrect. I did a quick Java app that used java.io.Console and the above approach. The compiler failed in 1.5 with an error like the following: Test.java:8: cannot find symbol: method console() location: class java.lang.System I could see how you could compile in 1.6 and exclude certain runtime features when running in a 1.5 JVM. Of course you would also need to re-compile into 1.5 JVM bytecode format to avoid the ""invalid minor version 49.0"" error. For that approach this solution could work. This answer *is* incorrect. The Java 5 compiler will fail to compile the ""Java 6 stuff goes here"" block so you haven't fixed the problem. A better solution would be to have two implementations of an interface one for Java 5 and one for Java 6. Your build tool can then include the right implementation at compile time. Ant could do this easily by using a build property.  You can probably refactor your code so that conditional compile really isn't needed just conditional classloading. Something like this: public interface Opener{ public void open(File f); public static class Util{ public Opener getOpener(){ if(System.getProperty(""java.version"").beginsWith(""1.5"")){ return new Java5Opener(); } try{ return new Java6Opener(); }catch(Throwable t){ return new Java5Opener(); } } } } This could be a lot of effort depending on how many version-specific pieces of code you have.  It depends on what Java 6 features you want to use. For a simple thing like adding row sorters to JTables you can actually test at runtime: private static final double javaVersion = Double.parseDouble(System.getProperty(""java.version"").substring(0 3)); private static final boolean supportsRowSorter = (javaVersion >= 1.6); //... if (supportsRowSorter) { myTable.setAutoCreateRowSorter(true); } else { // not supported } This code must be compiled with Java 6 but can be run with any version (no new classes are referenced). EDIT: to be more correct it will work with any version since 1.3 (according to this page).  You can use reflection API. put all your 1.5 code in one class and 1.6 api in another. In your ant script create two targets one for 1.5 that won't compile the 1.6 class and one for 1.6 that won't compile the class for 1.5. in your code check your java version and load the appropriate class using reflection that way javac won't complain about missing functions. This is how i can compile my MRJ(Mac Runtime for Java) applications on windows.  The suggestions about using custom class loaders and dynamically commented code are a bit incredulous when it comes to maintenance and the preservation of the sanity of whichever poor soul picks up the project after you shuffle to pastures new. The solution is easy. Pull the affected classes out into two separate independent projects - make sure the package names are the same and just compile into jars that you can then consume in your main project. If you keep the package names the same and the method signatures the same no problems - just drop whichever version of the jar you need into your deployment script. I would assume you run separate build scripts or have separate targets in the same script - ant and maven can both easily handle conditionally grabbing files and copying them. Independent projects are overkill separate source folders and a custom build script will do just fine. Use source folders for src/main with the common codebase and say src/java5 and src/java6 for features dependent on each version.  The public static final solution mentioned above has one additional benefit the author didn't mention--as I understand it the compiler will recognize it at compile time and compile out any code that is within an if statement that refers to that final variable. So I think that's the exact solution you were looking for.  You can get conditional compile but not very nicely - javac will ignore unreachable code. Thus if you structured your code properly you can get the compiler to ignore parts of your code. To use this properly you would also need to pass the correct arguments to javac so it doesn't report unreachable code as errors and refuse to compile :-)  There is no pre-compiler in Java. Thus no way to do a #ifdef like in C. Build scripts would be the best way. He's suggesting to use s C compiler to run the actual C pre-processor which would output modified source files then run the Java compiler on those. Most if not all C compilers have a switch to run the pre-processor only.",java swing compilation397500,A,How to design interface for a game in Java We're a team of a designer and a programmer. Me the programmer is hopeless on design of all sorts so the user interface of the game must be created by the designer. We were thinking of a main screen where the character walks around a small minimap in the top an inventory section etc. All these things would have to be designed in a way that looks pretty i.e nice graphics/buttons/colors etc. I'm assuming that the designer will create an outline of this interface in photoshop/illustrator then send me the file in .png or .jpeg format and I'll implement it into the program making sure the buttons all work etc. My question is is this the correct method for doing this? Should he send me the interface's layout in a .png/.jpeg format or send me only the buttons and I have to code the rest of the interface manually in java putting the buttons/icons where they need to be etc. If so how can I do this? Any classes/frameworks that do this? Any guidelines at all will be helpful. Thanks! You've described one of the primary use cases stated for JavaFX. There's at least one visual design tool already out for it as well. I've also seen articles on this blog that address the idea of taking visual assets from a graphic designer and working with them in an app. And of course you can drop into Java for the heavy lifting at any point.  It really depends on a few things..Is it for J2ME or are you considering this for desktop (OpenGL/JOGL)? For J2ME you have to really know a bit about making games for devices with constrained memory. J2ME comes with its own GameCanvas and Sprite related classes that you can utilise. I Would recommend you read up on J2ME game development either through google or buy a book. While there are 3D libraries for the J2ME environment I have never been impressed by it. For a desktop based game I would recommend using some form of accelerated hardware based libraries for 2D or 3D based games. Bit of a steep learning curve but better in the long run. Plenty of libraries out there to help you get started(Jogl and JAva3D for example) You should look into using some called a scene graph which will help you provide a good foundation to start from. Once again steep learning curve but much easier to maintain and develop with. In regards to your design/implementation question it seems you dont have much experience in this area.Generally graphic designers/UI interaction designer will have a better understanding of how to provide an interface for the game. They will generally develop a mock of some sortyou will implement it a test will be done with user's and feedback will determine where you go from there. If you dont have some form of interaction designer you or your designers will need to read up on it. Interaction through an interfaceespecially for games is not an easy thing and can make or break your game. But it seems that you should definitely do some reading up on game architectures before proceeding to implementation phase if you do not have experience in this area. It will help you understand some theory and get a foundation before going ahead and building something which inevitably turns out to be completely wrong.  Think up some weird XML format that completely describes the interface and make him create it. :)  take a look at this: http://www.cs.qub.ac.uk/~P.Hanna/CSC207/lectures/lectures.htm the link is not working anymore. :( anyone knows about resources related to this class?  I suggest you look at java games which do this already for examples of how this is done. e.g. http://sourceforge.net/projects/freecol/#item3rd-2 http://sourceforge.net/projects/megamek/#item3rd-2 http://sourceforge.net/project/screenshots.php?group_id=1111 +1 attaching similar reference: http://www.brackeen.com/javagamebook/  The designer will also have to learn something about game development how to produce textures that will work fine at different resolutions if it's a platformer to create sprites that lend themselves properly to animation and so on and so forth. Answering your question he'll probably need to do both (send you buttons sprites etc. and a global view to see how it all fits together). I suggest you both check http://www.gamedev.net/reference/ and http://www.gamasutra.com,java swing 2d356671,A,"JFileChooser.showSaveDialog(...) - how to set suggested file name The bloated JFileChooser seems to be missing one feature: a way to suggest the file name when saving a file (the thing that usually gets selected so that it would get replaced when user starts typing). Is there a way around this? Great! Works perfectly in Windows too with Java 1.6.35. Only a little change in my case: FileChooserUI fcUi = jFileChooser.getUI(); Class<? extends FileChooserUI> fcClass = fcUi.getClass(); Method setFileName = fcClass.getMethod(""setFileName"" String.class); setFileName.invoke(fcUi defaultDirectoryName);  setSelectedFile doesn't work with directories as mentioned above a solution is  try { FileChooserUI fcUi = fileChooser.getUI(); fcUi.setSelectedFile(defaultDir); Class<? extends FileChooserUI> fcClass = fcUi.getClass(); Method setFileName = fcClass.getMethod(""setFileName"" String.class); setFileName.invoke(fcUi defaultDir.getName()); } catch (Exception e) { e.printStackTrace(); } Unfortunately the setFileName is not included in the UI interface thus the need to call it dynamically. Only tested on mac. Work for me in a Mac 10.3.4 / Java 1.4.2  If I understand you correctly you need to use the setSelectedFile method. JFileChooser jFileChooser = new JFileChooser(); jFileChooser.setSelectedFile(new File(""fileToSave.txt"")); jFileChooser.showSaveDialog(parent); The file doesn't need to exist. EDIT: If you pass a File with an absolute path JFileChooser will try to position itself in that directory (if it exists).  If that doesn't work here is a workaround: dialog.getUI().setFileName( name ) But you should check whether the selection mode is FILES_ONLY or FILES_AND_DIRECTORIES. If it's DIRECTORIES_ONLY then setSelectedFile() will strip the file name. I would copy the method. How would you access the dialog though? It's private created on the spot in `showSaveDialog()` and disposed immediately after it was shown still inside that function.",java swing jfilechooser407343,A,"Where are Swing applications used? Are Swing applications really used nowadays? I don't find a place where they are used. Is it okay to skip the AWT and Swing package (I learned a bit of the basics though)? Related: http://stackoverflow.com/questions/2994304/is-java-swing-still-in-use/2994324#2994324 You may checkout Swing Sightings. This website is hosted by SUN and it is dedicated to sw projects that use Swing. There are a lot of projects using Swing ... http://java.sun.com/products/jfc/tsc/sightings/ While I don't doubt Swing has it's place even today (and at the same time being an ugly and complex beast to get started with) the last sightings issue is from 2005 - so it cannot really prove that Swing is used _today_ ;) LandlordMax (http://www.LandlordMax.com) is a current desktop application that's based on Swing. I can assure you the Swing community is very alive! FYI: It was feature on Swing Sightings years ago.  Are you skipping it for an exam/interview? Besides really good apps like IntelliJ IDEA and NetBeans there are lots of Swing like frameworks [SWT (Eclipse) GWT etc.] which you can learn faster with Swing knowledge...  Hmmmm... how about NetBeans? You know the IDE? It uses Swing. oh thanks for the info ya i know and also eclipse While Eclipse is great IDE it doesn't use Swing but SWT.  Whenever you want to write a desktop GUI app for non-Windows OS you use Swing as the only sane and guaranteed cross-platform GUI framework. Besides Swing has a very good design. I recommend to learn it anyways to make yourself a better programmer.  You should probably be looking at JavaFX for future work. As the FAQ states Sun is not replacing Swing with JavaFX Script. Instead JavaFX Script makes Swing easier to use. Using/learning it will give you a very good understanding of the important Swing concepts and how they fit in with ""the future"". I haven't used JavaFX yet but heard very good things about it.  Skip AWT and Swing? To jump where? SWT? Web-based development? In the broader sense I have a number of Java applications although I am not too sure if they use Swing or SWT. Lot of database tools like SQuirreL SQL Client are written in Java. I think SQuirrel uses stuff from Netbean which is of course Swing based. yEd is written in Java probably Swing. A number of P2P softwares are written in Java including Frostwire (I see no trace of SWT there but I can just miss it). And this list is far from exhaustive! Lol! I forgot to mention the software suite made by the company I work for! It is quite specialized used by mobile phone companies to monitor health of their network nodes (superficially looks like a spreadsheet). Totally Swing based. Open Office is *not* written in Java (it's slow for other reasons ;)). Ah? Somebody already told me but before posting I checked and found lot of jar files (in program/classes). It has lot of DLL and exe files too indeed. Confusing at least. OpenOffice is written in C++ and supports Java plug-ins somehow.  If you are writing for the web exclusively you can probably skip Swing but otherwise you're absolutely going to run into it. I've never worked on a non-trivial Java app without a Swing GUI. Also Swing is one of the better APIs to use. If you use most others you are going to find them more difficult to use and/or platform incompatible. (If anyone reading this is aware of exceptions to this please leave comments I haven't looked for a while and am kind of curious if anything better has become available) Other JVM languages like JRuby and Jython are often used because of their access to Swing.  AWT I never actually learnt in full as swing is just a more sophisticated version knowing swing is very important if you have any intention of ever making a Java GUI application. will it be ever used for enterprise application development ?  There is no universal question to whether it is ok to skip something or not. It's a matter of priorities. While Swing has a lot to teach you (and it is too heavily infused with AWT) if you're never going to be writing GUIs you may be better off investing in something else. Swing while ugly as hell is still used in many places. A quick search on ""java swing"" in Indeed or dice would reveal many jobs and industries that require it. i find that the file choosers are very slow in swing - i hate them Swing while not great in many ways is far from ""ugly as hell"". It has many nice concepts and is quite good to use after a bit of experience is gained. And with recent font improvements makes it quite possible to write a GUI which is indistinguishable from a native app. Indistinguishable except that it resizes properly that is. You can write something pretty in every language but in my experience the vast majority of applications written with similar effort in Swing compared to other APIs tend to be clunkier less aesthetic and less robust. I always put the following right at the top of my `main` method to reduce the ugly-ness: `UIManager.setLookAndFeel(UIManager.getSystemLookAndFeelClassName());` (with the necessary try/catch). It's still not as beautiful as you might want it to be but it helps a lot.  You should certainly write Swing for desktop Java only using AWT to the degree that Swing demands it. I'm sure people can come up with examples of very good Swing apps besides SQL Squirrel and IntelliJ. I think that RIA technologies like Flex Silverlight etc. are ascendant because the web and services are taking mindshare from desktops. It's not just Swing that's losing out. ""certainly"" perhaps not there is at least the SWT alternative (which I didn't learn). I wouldn't consider SWT as a viable alternative but that's my personal choice.  IIRC jEdit is also a Swing app. Quite a popular text editor.  Check out Filthy Rich Clients. It explains some of the history of AWT and Swing. Swing being a lightweight alternative (successor) to most of the AWT classes.  While Swing has some cross-platform look-and-feel deficiencies and it would be nice if it was updated to support generics it is still well designed and quite usable. I have always been a fan of the sheer amount of customization offered. SWT is nice and is more native but you give up some power and control with that as well. In addition it seems simpler to use which can be a plus since Swing can be overly complex due to its flexibility.  Geertjan Wielenga often blogs about applications based on the NetBeans platform and therefore Swing. The applications range across the board from rather small esoteric applications to very large mission-critical systems (Boeing Aircraft comes to mind). Many of the enterprise-level applications that Geertjan misses are mentioned on Planet NetBeans. It seems like every few weeks there is an announcement or description of such a program. As noted above lots of tools use Swing including the IntelliJ IDEA IDE a favorite. I'm surprised no one else mentioned it. Sun also used to maintain a Swing Sightings web site but it hasn't been updated in a few years. Where I work Swing is used in the presentation layer for a very large document management system. In my own development experience I've used Swing for desktop applications in the areas of image processing device control (video motors etc.) math statistics and medical devices. BTW I agree about the slowness of file choosers. But there are lots of alternatives that will use the native file chooser. It can just be a bit jarring if the L&F's don't match up very well. EDIT: Oh and as others have mentioned it's very easy to use Swing from other languages on the JVM. With Clojure for example it is even easier to use than in Java in my opinion.  Swing is heavily used in business specific (vertical)/internal application development.  Swing applications are used in most cases where a Java app runs on the desktop. Sometimes you don't even know - for example LimeWire is a Java Swing application. When learning Swing you'll find that you will come to know those parts of AWT that are still important such as Event LayoutManager Graphics Font Color etc. Yes Azureus is an Eclipse RCP i.e. it uses SWT. azureus was developed in swing ? wow .. thanks for the info pal :) I believe that Azureus uses SWT toolkit (from of Eclipse) not Swing. OK edited my answer to fix that. Sorry for the mistake. I tend to agree. You won't even realize you're running Swing apps when they're done right. Unless you really look there's no way to tell our app (http://www.landlordmax.com) is a Swing app. No Azureus/Vuze is NOT Eclipse RCP based but on SWT.",java swing31127,A,"Java Swing: Displaying images from within a Jar When running a Java app from eclipse my ImageIcon shows up just fine. But after creating a jar the path to the image obviously gets screwed up. Is there a way to extract an image from the jar at runtime so I can then open it up? Or is there a better way to do this? I'd like to distribute a single jar file if possible. The ""Tom Hawtin - tackline"" answer is much better it just showed up a little late. Please consider changing your selected answer. You can try something like: InputStream stream = this.getClass().getClassLoader().getResourceAsStream(""/images/image.jpg""); In your JAR file you might have a directory structure of: MyJAR.jar - com (class files in here) - images ----image.jpg  This is working for me to load and set the content pane background image: jar (or build path) contains:  - com - img ---- bg.png java contains: JFrame f = new JFrame(""Testing load resource from jar""); try { BufferedImage bg = ImageIO.read(getClass().getResource(""/img/bg.png"")); f.setContentPane(new ImagePanel(bg)); } catch (IOException e) { e.printStackTrace(); } Tested and working in both jar and unjarred (is that the technical term) execution. BTW getClass().getClassLoader().getResourceAsStream(""/img/bg.png"") - which I tried first - returned me a null InputStream.  To create an ImageIcon from an image file within the same jars your code is loaded: new javax.swing.ImageIcon(getClass().getResource(""myimage.jpeg"")) Class.getResource returns a URL of a resource (or null!). ImageIcon has a constructors that load from a URL. To construct a URL for a resource in a jar not on your ""classpath"" see the documentation for java.net.JarURLConnection.",java swing image344969,A,Making a JDialog button respond to the Enter key I have a JQueryDialog with a text field an OK button and a cancel button. I want to be able to hit the enter key after filling in the text fields and have it do the same action as when I click the OK button. What happened to the code? Are JQueryDialog(in question) and JDialog(in title) surely the same things? In your dialog call getRootPane().setDefaultButton(okButton).  The code is almost correct. I would change the if comparison and use the correct method as noted below. if (KeyEvent.VK_ENTER == event.getKeyCode()) { yourButton.doClick(); } Where do you see the code? It looks like the original code that I responded to is missing.,java gui swing145972,A,"How can I setup LookAndFeel Files in Java? I need to setup LookAndFeel Files in JDK 1.6. I have two files: napkinlaf-swingset2.jar napkinlaf.jar How can I set this up and use it? I would like a GTK look and feel OR Qt look and feel Are they available? Can you please be more clear? These 2 files do you have the source or are they just binaries you have? This page explains how the work with Look&Feels: http://java.sun.com/docs/books/tutorial/uiswing/lookandfeel/plaf.html You can do it commandline: java -Dswing.defaultlaf=com.sun.java.swing.plaf.gtk.GTKLookAndFeel MyApp Or in code: UIManager.setLookAndFeel(""javax.swing.plaf.metal.MetalLookAndFeel""); You need to make sure the jars containing the look&feel are on the application classpath. How this works depends on the application. A typical way would be to put it in a lib folder. Look&Feels that are available by default in the JDK are: com.sun.java.swing.plaf.gtk.GTKLookAndFeel com.sun.java.swing.plaf.motif.MotifLookAndFeel com.sun.java.swing.plaf.windows.WindowsLookAndFeel Quioting the link above: The GTK+ L&F will only run on UNIX or Linux systems with GTK+ 2.2 or later installed while the Windows L&F runs only on Windows systems. Like the Java (Metal) L&F the Motif L&F will run on any platform. i know how to use LAF  but i want install LAF files . and the GTK LAF not installed by default . @Waseem -- Then I suggest you elaborate in your question.  The Qt look and feel is available from Trolltech as the product Jambi which IS Qt for Java. this is no look and feel. it is the whole toolkit.  The class name for Naplin is net.sourceforge.napkinlaf.NapkinLookAndFeel. So to set it as default on the command line use: java -Dswing.defaultlaf=net.sourceforge.napkinlaf.NapkinLookAndFeel To install it add napkinlaf.jar to the lib/ext direction and the lines: swing.installedlafs=napkin swing.installedlaf.napkin.name=Napkin swing.installedlaf.napkin.class=net.sourceforge.napkinlaf.NapkinLookAndFeel to lib/swing.properties within your Java installation (you'll probably have to create the file). See the Napkin wiki page it's work now  thank you nice LookAndFeel",java swing qt gtk look-and-feel461112,A,"Panel with line wrapping and line breaking in Java Swing How to implement a panel that would support line wrapping and line breaking? I would only add textual labels and line breaks to this panel. The labels should flow from left to right wrapping to the next ""line"" if needed. The line breaks would cause a jump to the next line. I would also like to make the panel vertically scrollable. The solution should work in Java 5. SwingX can be used. Clarification: The textual labels are actually JXHyperlinks (from SwingX) i.e. the panel contains clickable labels. This is the reason I cannot just use JTextArea. Although it may not be a solution you're in search of but from the requirements you have it seems like a custom LayoutManager may be able to achieve what you are after. By designing and assigning a custom Layout Manager which allows line breaks to a Container (such as Panel) it should be possible to have a Panel which allows line breaks. The Laying Out Components Within a Container article from The Java Tutorials will provide general information on how Layout Managers work in Java and in particular the Creating a Custom Layout Manager will provide information on how to make a custom Layout Manager to apply to an Container. The behavior of the FlowLayout (the default Layout Manager for Panel) seems fairly close to the behavior you may be after. Adding functionality to line break seems like the missing piece. Suggestion: Perhaps the custom Layout Manager can have the ability to add a line break by having a Component that represents a line break which can be added to a Container by using the add() method. For example have a class constant Component in the custom Layout Manager such as (a hypothetical) LineBreakLayout.LINE_BREAK and adding that to the Container can tell the custom layout manager to move to the next line. Perhaps an implementation can be like: Panel p = new Panel(new LineBreakLayout()); p.add(new Label(""First Line"")); p.add(LineBreakLayout.LINE_BREAK); p.add(new Label(""Second Line"")); The above hypothetical LineBreakLayout will then render the first Label in one line and the second Label in the second line.  I found JTextPane which I had overlooked before for some reason. This class does what I need. Thanks for your help though. :)  UPDATE: I missed the request for hyperlink support. Don't know how to do that w/o using the EditorPane. JTextArea does exactly what you've described. JTextArea textArea = new JTextArea(); JScrollPanel sPane = new JScrollPane(textArea); I want to make the labels clickable so that they could behave like hyperlinks. Could I do it with TextArea? (I don't want to use the JEditorPane with HTML.) Any reason against the JEditorPane (I'm just curious)? Seemed to be slow and an overkill. Also I couldn't figure out how to store a Java object with each hyperlink on the page so that clicking on the link would do some action based on the object. The Hyperlink event listener calls back with the Element and URL from anchor tag which caused the hyperlink. You could probably create some sort of mapping from URL->Object to take actions Right I currently have something like that. I'm just wondering if there is a better solution without such a mapping table. ahhh good deal. Now you've got me interested in the solution ;) Do you really don't know how to store an object for the hiperlink? In java there is a data structure named: ""Map"" with various subclasses. You can have map.put( aLink anObject ); and get the object when some link is used. It seems to me very straight forward.  This sample is not from a panel that is a container but from a JLabel that is intended to show content. You could use HTML in your content and use a <br> on each break. You should programmatically calculate the breaks according with your rules on component resize. Here's the code: import javax.swing.*; import java.awt.*; public class Wrap { public static void main( String [] args ) { JFrame frame = new JFrame(""Wrap test""); String text = ""<html>This<br>is<br>a<br>multiline<br>label</html>""; frame.add( new JLabel( text ) ); frame.pack(); frame.setVisible( true ); } } Yes I don't feel like implementing a map that would map strings to objects. I can use JXHyperlink (from SwingX) to store an object ""into the link"" and have an action performed on the object when the link is clicked. The problem is only how to layout the links so that they wrap in a scrollable pane. As per the hyperlinks you can have the by using a mouse listener. You can get where the object has been clicked and use a map to execute the action. But as reading your comments on basszero answer I think you just don't feel like program it.",java gui swing440745,A,"JSeparator with Title Do somebody knows a (free) horizontal JSeparator with a title label? Something like that: --- Title XYZ -------------------- Thank you in advance! Best Regards Thomas HmmŠ—_ without any testing and completely from the top of my head: JPanel panel = new JPanel(); panel.setBorder(new TitledBorder(""Title"")); menu.add(panel); Most Swing containers eat anything so that might even work. Another approach would be to create a custom component (maybe with a horizontal BoxLayout) and add a JSeparator a JLabel and another JSeparator to it then add it to the menu.  I found a solution: SwingX JXTitledSeparator. We already use SwingX in our project. I didn't know that SwingX provides a titled separator. @Bombe Thank you for your help.",java gui swing339821,A,"Find composite location on screen I am implementing a on screen keyboard in Java for SWT and AWT. One important thing is to move the keyboard to a position where the selected text field can show and is not lying behind the on screen keyboard. For AWT i can detect the position of the current selected component with Component owner = KeyboardFocusManager.getCurrentKeyboardFocusManager().getFocusOwner(); if (owner == null) { return; } Point ownerLocation = owner.getLocationOnScreen(); Dimension ownerSize = owner.getSize(); How can i implement the same logic in SWT? I get the current selected widget by adding a focuslistener to the SWT event queue. But when i call Point location = new Point(mTextWidget.getLocation().x mTextWidget.getLocation().y); Dimension dimension = new Dimension(mTextWidget.getSize().x mTextWidget.getSize().y); I will get the position relativ to the parent composite. How can i get the location of a special widget relativ to the complete screen? I believe the method Control.toDisplay() should be able to translate your coordinates into ones relative to the screen. This snippet may illustrate what you are after: package org.eclipse.jface.snippets; import org.eclipse.swt.SWT; import org.eclipse.swt.events.SelectionAdapter; import org.eclipse.swt.events.SelectionEvent; import org.eclipse.swt.graphics.Rectangle; import org.eclipse.swt.widgets.Button; import org.eclipse.swt.widgets.Display; import org.eclipse.swt.widgets.Shell; import org.eclipse.swt.widgets.Text; public class Bla { public static void main(String[] args) { Display display = new Display(); Shell shell = new Shell(display); final Text t = new Text(shellSWT.BORDER); t.setBounds(new Rectangle(101020030)); System.err.println(t.toDisplay(1 1)); Button b = new Button(shellSWT.PUSH); b.setText(""Show size""); b.setBounds(new Rectangle(2201010020)); b.addSelectionListener(new SelectionAdapter() { public void widgetSelected(SelectionEvent e) { System.err.println(t.toDisplay(1 1)); } }); shell.open(); while (!shell.isDisposed()) { if (!display.readAndDispatch()) display.sleep(); } display.dispose(); } } Perfect this is what im looking for. thanks @Mario: You are welcome. Glad I could help. Thank you buddy! Your answer brought an end to a morning of pain. @VonC: omg didn't realise that;) well sadly SWT/RCP still lives on through RAP. I'm longing for JavaFX as a desktop/web client crossover framework though... works perfectly thanks for bringing up toDisplay()! It will also accept a Point which is handy when translating component locations. I used it to translate event coordinates during a Drag&Drop session: composite.toDisplay(composite.getLocation()) @Gregor Nice to know this answer is still helpful... more than 5 years later.",java swing plugins swt awt145863,A,Best Java/Swing browser component? What's the best cross platform Java Swing browser component at least able to play nicely in a swing interface (lightweight component ?) and able to run on MacOSX and Windows ? Things like : FlyingSaucer JDIC maybe others ? Highweight browser based http://code.google.com/p/jbrowser/. It use Canvas component. based on Mozilla 2.x  The Lobo Browser could be what you're looking for: http://lobobrowser.org/index.jsp It's GPL and renders JavaFX as well as HTML Edit JavaFX 2.0 comes with a Browser component: http://docs.oracle.com/javafx/2/webview/jfxpub-webview.htm Lobo is almost useless in that too many websites don't render right.  i belive this could help: http://djproject.sourceforge.net/ns/index.html I tried them all DJ is the best Well their webstart doesn't demo doesn't launch! Boo. isnt this windows only? It runs on Mac OS as well even on new Lion. I could not find a method to integrate it into netbeans so it seems useless.  you can go for Mozswing which have all the features that mozilla firefox 3.0 supports .. but the same is heavy. Mozswing has been dead for quite a while and only supports 32 bit.  We (@ WebRenderer) believe we have the best Java browser SDK - http://www.webrenderer.com/ WebRenderer is Swing based using Firefox as the underlying engine and supports HTML5 SVG etc on both 32 and 64bit systems. Welcome to Stack Overflow! Thanks for posting your answer! Please be sure to read the [FAQ on Self-Promotion](http://stackoverflow.com/faq#promotion) carefully. Thank you Andrew for your contribution. I checked the FAQ before posting my response and hence made sure to identify my association with WebRenderer. Whilst we are on this topic you may however wish to look at Vladimirs (of JXBrowser) posts (user #459345 and user#241010) above. Secondary I decided to post WebRenderer as it is not only relevant to the discussion but also for completeness. WebRenderer was previously posted on this Question as an answer back in 2009 by Lukasz (last name withheld) Š—– http://goo.gl/8263M Lukasz Drukarz posted a link-only answer on July 1 09 and it was deleted because it was only a link. (as a 10k user I can see deleted posts). I saw Vladimir's post and would have left a comment for him as well but he has not been on the site for quite some time (over 2 years). This type of question and the answers that it generates are not generally preferred around here and this question has been protected and flagged for closure. This question is in fact quite problematic most'best to do this' question are since they (naturally) just attract links. The accepted answer to this question is in fact a link. Deleting self promotional answers on a question basically _asking_ for them is not going to help so I have closed this instead.,java swing browser437413,A,How can jFrames be used inside of JavaFX? I just saw a article on Swing being used in JavaFX. How can an application that uses a jFrame to display graphics be ported into JavaFX? Also will the jButtons and jSliders work in the normal manner? I know this is a generic question but I know little of JavaFX and am curious about porting some desktop applications to the web via the JavaFX package. javafx file: import javax.swing.JComponent; import javafx.ext.swing.SwingComponent; class NewFxComponent extends SwingComponent { var comp: JComponent; public override function createJComponent():JComponent { return new OldJComponent(); } },java swing web-applications javafx99626,A,"What's the definitive Java Swing starter guide and reference? Obviously the Java API reference but what else is there that you all use? I've been doing web development my entire career. Lately I've been messing around a lot with Groovy and I've decided to do a small application in Griffon just to experiment more with Groovy and also break some ground in desktop development. The only thing is I'm totally green when it comes to desktop apps. So world where's a good place to start? The Swing Tutorial is very good. Apart from that the Swing API is obviously the reference however it's also a treasure trove of fairly good source code! Add the API source to your IDE and you can jump directly to the implementation to all the Swing classes. This is a great way to explore the functionality see how various Swing components work and learn a good Swing ""style"". Furthermore it's great to be able to step through the API classes if things don't seem to work and you have no idea why! Adding the API source to the IDE has the additional benefit that you get all the JavaDocs along with it although all modern IDEs can also pull them from the net -- you do not want to program desktop Java without the documentation available from within the IDE! NetBeans and other IDEs do make the creation of IDEs very easy but be aware that there is a lot more to Swing than just containers and layout managers. In fact containers and layout managers are among the easier things and I'd recommend learning to use them by hand too. There is nothing at all wrong with using a GUI builder but in some cases it's overkill and then it's nicer to just quickly whip up a GUI from source. In other cases you need to be able to create a GUI dynamically and then GUI builders are no use at all! For creating very complex layouts from source I recommend FormLayout which has its own set of quirks but which does scale (in terms of programming effort) to very big frames and layouts. If you've only done Groovy so far you'll be surprised how well documented Swing and the rest of the Java API is and how well everything is integrated. It might also take some getting used to a different style of programming using the debugger more often and println-debugging less etc. There might also be some ""boiler-plate"" code that will be very annoying. ;) Enjoy. I've actually been doing a lot of Java development but all with a web front end (mostly Struts) so I'm very familiar with debugging and the usefulness of IDEs. I guess I'm looking for more of a refcard type resource that I can use to help until I become more familiar with the components and widets  When it comes to developing java desktop applications I would highly recommend using the IDE environment Netbeans. Especially when it comes to the development of Swing based applications.  The Sun Java tutorials are pretty good. I cannot vouch specifically for the Swing one as it has been ages since I've done any Swing development and I have not read it myself. Creating a GUI with JFC/Swing  I recommend you to play around with netbeans. It will allow you to build complete GUIs using only your mouse. Once you get familiar with Swing components start using the Java API. Thats how I started.  The O'Reilly Swing Book is a pretty good reference it has a good overview of general Swing concepts and covers each of the major classes. I used it recently when I had to refresh my memory on Swing.",java swing groovy griffon286674,A,Remoting from a Swing app to GWT server To put it simple I've written a JSE Swing app that needs to talk to a GWT server I've written earlier. I absolutely love the way GWT does remoting between it's javascript and server sides and wish I could utilize this mechanism. Has anyone managed to use GWT-RPC this way? Should I just go Restlet instead? If you are doing Java-to-Java communication RMI would be simpler and more expedient. Serializing data to/from some XML or URL-based format doesn't add a lot of value. With EJB3 it is dead simple to deploy remote objects and to call them. You can then turn those EJBs into web services if you need to later but for Java-to-Java I can't think of a good reason to not use some sort of RMI-based communication. RMI does not work at the moment on AppEngine. I'm not sure if Google will fix that,java swing gwt remoting restlet7269,A,"How can I identify in which Java Applet context I'm running without passing an ID? I'm part of a team that develops a pretty big Swing Java Applet. Most of our code is legacy and there are tons of singleton references. We've bunched all of them to a single ""application context"" singleton. What we now need is to create some way to separate the shared context (shared across all applets currently showing) and non-shared context (specific to each applet currently showing). However we don't have an ID at each of the locations that call to the singleton nor do we want to propagate the ID to all locations. What's the easiest way to identify in which applet context we're running? (I've tried messing with classloaders thread groups thread ids... so far I could find nothing that will enabled me to ID the origin of the call). Singletons are evil what do you expect? ;) Perhaps the most comprehensive approach would be to load the bulk of the applet in a different class loader (use java.net.URLClassLoader.newInstance). Then use a WeakHashMap to associate class loader with an applet. If you could split most of the code into a common class loader (as a parent of each per-applet class loader) and into the normal applet codebase that would be faster but more work. Other hacks: If you have access to any component you can use Component.getParent repeatedly or SwingUtilities.getRoot. If you are in a per-applet instance thread then you can set up a ThreadLocal. From the EDT you can read the current event from the queue (java.awt.EventQueue.getCurrentEvent()) and possibly find a component from that. Alternatively push an EventQueue with a overridden dispatchEvent method. This is (by far) the best collection of ideas I saw on the subject. I especially like the ""push a customized eventqueue"" - and I'm going to try it.  If I understand you correctly the idea is to get a different ""singleton"" object for each caller object or ""context"". One thing you can do is to create a thread-local global variable where you write the ID of the current context. (This can be done with AOP.) Then in the singleton getter the context ID is fetched from the thread-local to use as a key to the correct ""singleton"" instance for the calling context. Regarding AOP there should be no problem using it in applets since depending on your point-cuts the advices are woven at compile time and a JAR is added to the runtime dependencies. Hence no special evidence of AOP should remain at run time.  @Hugo regarding threadlocal: I thought about that solution. However from experiments I found two problems with that approach: Shared thread (server connections etc) are problematic. This can be solved though by paying special attention to these thread (they're all under my control and are pretty much isolated from the legacy code). The EDT thread is shared across all applets. I failed to find a way to force the creation of a new EDT thread for each applet. This means that the threadlocal for the EDT would be shared across the applets. This one I have no idea how to solve. Suggestions? You should be able to get a new EDT thread by using a different value for the archive tag. I think you can just add a random jar name to the end even if it does exist.",java swing applet294813,A,Embedding web browser window in Java Does anyone know a way to open up an instance of the platform's (Windows/Linux/Mac) browser within a Swing window that is integrated into a Java application. No other actions would be preformed other than opening a given URL. Currently we open a new browser window because the Java embedded browsers have been insufficient. However from a user interaction standpoint this is less than desirable. I'm curious if a solution for this was part of the 1.6 Java release. So far my google-foo has not turned up anything of note. Are there any closed-source libraries that do this? Anything? WebRenderer is a commercial product that does this and does it well. However the last time I checked it was also pretty expensive (they wanted a $2 per-client fee for a large number of client and a several $1000 support contract).  JDIC Your link is broken. Although I am using Chrome so if it isn't it's only my problem. Downloaded from here: http://www.java2s.com/Code/Jar/j/Downloadjdic092jar.htm Documentation was here: 1) http://www.aswinanand.com/2006/03/two-minute-web-browser-in-java/  MozSwing it is free or JxBrowser or JExplorer ($500)  use JEditorPane A text component to edit various kinds of content. By default the following types of content are known: text/plain text/html and text/rtf or Lobo Lobo is an open source web browser that is written completely in Java. The OP asked about opening the platform browser.  We use JDIC as well and it works for us in Windows; however configuring it to work in *nix/OS X can be a pain as it simply utilizes a platform-native browser (supports IE and Mozilla) while on Linux/Mac you may have neither - that's the problem.,java swing browser embed473540,A,"Correct way to use Actions to create menus toolbars and other components in Java The naive way of writing building a menu in a Java Swing app is to do something like: JMenu fileMenu = new JMenu(""File""); JMenuItem openItem = new JMenuItem(""Open...""); openItem.addActionListener(new ActionListener() { /* action listener stuff */ } ) fileMenu.addMenuItem(openItem); A more experienced developer will recognize that actions can be accessed through a variety of mechanisms - menus toolbar buttons maybe even other workflows in the system. That person is more likely to write: Action openAction = new AbstractAction(); openAction.setName(""Open...""); openAction.addActionListener(new ActionListener() { /* action listener stuff */ } ) ... JMenuItem openItem = new JMenuItem(openAction); My question is what is the best way to manage these Action objects so they can be used across menus toolbars etc? Create a factory class that returns specific actions? Declare all of the actions as private static final Action in some utility class? Take advantage of a Java application framework? Something else? Duplicate of http://stackoverflow.com/questions/448179/organizing-actions-in-a-swing-application#448195  as pointed out by Dave Ray. Action is a bad abstraction - an ActionListener welded to a poor man's Map. Certainly do not assign them to a static as they are mutable and also need some context to operate usefully. My general advice for GUI programming is to note that it is actually much the same as any other area of programming. Follow the usual good practices. Notably layering separation of concerns use (implementation) inheritance rarely and don't write a big ball of mud.  You can group all your abstractAction using the dedicated Map javax.swing.actionmap . See http://java.sun.com/javase/6/docs/api/javax/swing/ActionMap.html Moreover each JComponent has an internal actionMap (getActionMap()). class MyComponent extends JPanel { public static final String ACTION_NAME1=""my.action.1""; public MyComponent() { AbstractAction action= new AbstractAction() { ... } getActionMap().put(ACTION_NAME1action); ... menu.add(getActionMap().get(ACTION_NAME1)); } } Hope it helps  Create a base action for your application; this will help you IMMENSELY later on Do create actions as you have in your code instead favor subclasses of your base action To organize them it will depend on what you are doing with them and you may have some actions organized one way and others created a different way. It will all depend. What you want is to have a consistent way to locate/create an action in your code. Depending on your UI you may need to differentiate between ""static"" actions (i.e. stuff that's always available in your app such as the menu system) and dynamic actions that are created only on certain screens or in certain locations. In any case using concrete subclasses of your specialized base action will help you keep these things organized. What you don't want is to be specifying things like labels mnemonics and icons all over the place in your code.  Applications that I have developed that need to use that same actions across menus toolbars and other buttons have been done using Swing Application Framework. Swing Application Framework This framework will allow you to have a resource file where you can define all menu text tooltips and ICONS. I think the icons are the key you do not have to load them yourself. Also if you have any actions that you need to enable/disable you can override the method to control its state. The website is worth the read.  Also see this question which is pretty much the same as what you're asking.  Edit: I got the feeling people didn't believe this was possible or easy so I did it--took about an hour from scratch--would have taken 40 mins if I'd just used a single method as a target instead of reflecting it out to separate methods for each menu item. Here's the Tested source code. It works but is one big method and ugly--refactor it if you use it. I may fix it up a little over the next few days I've always wanted to have a copy of this to keep around to reuse. --- original post First of all remember to separate your code from data. That means you should NEVER type: new Menu(""File...""); The string ""File..."" is data. If you start thinking this way you will find that your question answers itself. First you need to build up some data. You need to get ""File..."" and ""Save"" into menus. I generally start off with a string array (which you can easily move to a file) new String[]{""File...""""+Save""""Load""...} This is one of the simpler patterns I've started out with. Then you can parse out the + sign and use it to mean ""Drop down a level in the menu when you add this one"" This is just a silly convention invent your own if you don't like it. The next step is binding that to code to run. You could have them all call the same method but what a pain in the ass (Giant switch statement). One possibility is to use reflection to bind a method name while you are reading in the data. Here's one solution (again it might not fit your tastes) new String[]{""File...[fileMenu]""""+Save[saveMenu]""""Load[loadMenu]""...} Then you parse out the thing in square braces reflectively hook it up to a method in your current class and you are set. There is a temptation I ALWAYS have at this point and I've learned to fight it because it NEVER works out. The temptation is to use the first set of data (""File..."") and manipulate it to fit some pattern and auomatically bind to your code (in this case remove all non-alpha chars make the first letter lower case and append ""Menu"" to get the correct method name). Feel free to try this it's very attractive and seems slick but be ready to abandon it when it doesn't meet some need (such as two menu items with the exact same name in different sub-menus). Another way would be if your language supports closures then you could actually create the file name and closure in the same place.. Anyway once you start coding like this you'll find that ALL your menu construction is in a single 10 line method and you can alter it to suit your needs. I had a case where I had to change a set of menus to a button hierarchy and I did it in 2 minutes. In the end you can use this pattern to set up the action objects easily and change how they are used easily (in a single location single line of code) so you experiment with them. There are many ways to use them but if you don't do what I'm recommending here you will end up having to re-implement across every menu item for every change which is really annoying--after a single change you will have wasted more time than if you had just implemented a data-driven solution in the first place. This really isn't hard code should take like an hour or two then you never have to write new Menu(""... again. Trust me this kind of tooling is just about always worth it. edit: I just about always code data-driven these days. Usually I'll prototype a few things the normal way recognize the pattern and refactor--and if you are refactoring correctly the data just about always factors out and what you're left with is beautiful tight and maintainable. I could do what I suggested above in less than 1/2 an hour (maybe an hour to do the reflective version). This is almost always just as long as it would do to use the unfactored version and from then on your savings multiply for every change. This is very similar to what people like about ruby except with ruby they seem to insert even more data into their code (which makes it awfully hard to extract your data from the code completely which is always a nice goal for internationalization). Hmm did I mention that if you're good at extracting your data like this i18n is virtually free? I suggest you just give it a try sometime and see what you think. Embedding the control in the strings is unnecessary if it makes you uncomfortable. I tend to use string/object arrays just because they are really easy to enter are still in the file while you are coding and are trivial to externalize later but if you like YML or XML or properties files use whatever you're comfortable with--just abstract your data from your code! You really code your GUI's like this? :| How can your GUI be fully factored without being data driven? There is so much repetitiveness. By the way String.split (used to be StringTokenizer) can help a lot with parsing these items. A string like ""File...|*|fileMethod"" can be parsed in a second (the * means ""top level"" in this case--you can make up your ""language"" on the fly--very like a Ruby DSL but easier)",java gui swing160315,A,"How to check for key being held down on startup in Java I'm trying to write a resolution selection dialog that pops up when a program first starts up. To prevent boring the user I want to implement the fairly standard feature that you can turn off that dialog with a checkbox but get it back by holding down the alt key at startup. Unfortunately there is no obvious way to ask java whether a given key is currently being pressed. You can only register to be informed of new key presses via a KeyListener but that doesn't help if the keypress starts before the app launches. I don't know much about Java (mostly code in C#) but what about having a small loader program written in C or something that then launches your Java app with some parameters (like whether or not a certain key is down)? A difficult solution in that the program wants to run on Mac/Windows/Linux and that I don't know enough C. @Zarkonnen Does it have JVM bundled with the installer? If the answer is yes then the `KeyboadUtils.isPressed` would work on Windows Mac and Linux  public class LockingKeyDemo { static Toolkit kit = Toolkit.getDefaultToolkit(); public static void main(String[] args) { System.out.println(""caps lock2 = "" + kit.getLockingKeyState(KeyEvent.VK_CAPS_LOCK)); } } where should I import the Toolkit class from? has this solution overcome the problems described in this blog post? It kind of describes this method as unreliable but it's old.... http://weblogs.java.net/blog/2007/11/02/log-me-log-me-out  The original question seems to be not answered. The proposed method determines the locking key state like CapsLock ScrollLock etc. So it would not work for Alt pressed state. Consider the following code: com.sun.jna.platform.KeyboardUtils.isPressed(java.awt.event.KeyEvent.VK_ALT); The only problem is that this class is an internal Sun's JDK class and not likely to be available in any other JVM. Depend on your project it may or may not be acceptable. Internally it calls into User32.DLL on Windows: User32.INSTANCE.GetAsyncKeyState(...)  Well there are two types of key press detection: event based and polling. If you poll the keyboard for KEY_PRESSED on startup (through a loop with a sleep.thread(timeInMs) constantly checking if your key is down) then you can detect if it's already pressed on startup.  import java.awt.*; import java.awt.event.*; import javax.swing.JFrame; public class LockingKeyDemo { static Toolkit kit = Toolkit.getDefaultToolkit(); public static void main(String[] args) { JFrame frame = new JFrame(); frame.addWindowListener(new WindowAdapter() { public void windowActivated(WindowEvent e) { System.out.println(""caps lock1 = "" + kit.getLockingKeyState(KeyEvent.VK_CAPS_LOCK)); try { Robot robot = new Robot(); robot.keyPress(KeyEvent.VK_CONTROL); robot.keyRelease(KeyEvent.VK_CONTROL); } catch (Exception e2) { System.out.println(e2); } System.out.println(""caps lock2 = "" + kit.getLockingKeyState(KeyEvent.VK_CAPS_LOCK)); } }); frame.addKeyListener(new KeyAdapter() { public void keyReleased(KeyEvent e) { System.out.println(""caps lock3 = "" + kit.getLockingKeyState(KeyEvent.VK_CAPS_LOCK)); } }); frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); frame.setSize(200 200); frame.setLocationRelativeTo(null); frame.setVisible(true); } }  So it appears that you can do this but only for caps lock et al. Hence I've switched to using caps lock for this purpose. Not perfect but OK.",java swing keyboard key awt210214,A,"Learning Java Swing? I am a veteran C/C++ programmer who has used Win32 MFC and WTL to write Windows apps for many years. I have some very basic Java experience but haven't done anything with a UI. I want to start learning how to write desktop apps in Java and from what I can gather Swing is the way to go. My question is: where do I start? Can anyone recommend any decent books? (I do like a good programming book). I've played with Netbeans a little in the past (and was impressed with what I saw) so I'd like to use that as my Java IDE of choice if that makes any difference. You should definitely see the SwingSet2 demo which comes with jdk. You can see the sources there and it is a great reference as an ""how-to"" about Swing objects. If I start to use a new Swing object in my application I just check those sources to see my options.  Once you get your feet wet I highly recommend the book ""Swing Hacks"" to harness the full power of swing.  I also like the O'Reilly Java Swing book; it's been useful to me. Good descriptions of concepts good references clear concise and to the point. That would be my recommendation. It's the first book I get when searching amazon for ""java swing"". Also amusingly that search will get you a porch swing made from wood from the island of Java...  That's exactly how I came to Java/Swing from C++/MFC etc. I have to agree that Swing is the only way to go there's a lot to learn in terms of concepts but if you know MFC inside out it will help (because the fundamentals aren't that different they're both event driven windowing systems except one of them is a bag of spanners held together with string)... I started with a copy of an IDE (Jbuilder in my case) and worked through the Sun Java Swing Tutorials Also this beginner's guide is pretty useful for the big picture.  This question and this question is very similar to yours. There are a ton of good answers here too.  The Swing Tutorial is very nice. That's how I taught myself swing.  Netbeans is a decent environment. Check out the O'Reilly Java Swing (Marmoset on cover) for a pretty good look at the ins and outs. However My edition is 2001 and I don't know if the more current ones are any good or not. The big gotcha in Swing is: Don't do any significant work in the listeners. And don't access swing components from any thread other than the EDT (SwingUtilities.invoke* and SwingWorker are your friends) +1 jsight. Even seemingly ""safe"" calls such as ""setVisible()"" on a top-level frame are not necessarily safe from outside the EDT.  If your intention is to use NetBeans and its powerful GUI building capabilities I'd recommend trying to do a lot of hand coding to start with. When I conduct interview we get a lot of people who might be able to use a GUI builder but that is not quite the same thing as 'knowing' Swing.  If you really want a good book and not an eBook or a pdf Java : The complete reference by Herbert Schildt is the best. It is like an encyclopedia and explains a lot of concepts including swing clearly.  You can start to learn it by doing simple apps using Netbeans GUI editor which gives you a quick view on your app. Meanwhile Swing is very flexible and powerful. Since you can do almost anything in Swing this advantage leads to somehow deeper learning curve. To learn more you need some good book (like java swing or sun's swing tutorial on their web) and good understanding of MVC design pattern Java bean style event handling customerized rendered etc. Anyway Swing is of much better OOP and MVC than the old age mixed MFC library. You should be able to learn a bit on how to design a clean a extensible app through the learning of Swing.  I wrote a site as part of a project whilst at University that taught students how to learn Swing through example and exercises (with a bunch of screenshots). Although I don't have personal access to it any longer Heriot Watt University still host it. You can find the link here.. The Guidebook - Lessons in Swing Might get you started at least :)  Once you have mastered the basics the de-facto standard book for top notch swing GUIs is Filthy Rich Clients. I think your link is not what you think. Corrected thanks for the heads up.  I'm sorry but what I'd recommend is to stay clear of Swing altogether X-) From my point of view it's veeery verbose (even for Java) but more than anything it has a confusing and unintuitive API (repaint()/refresh() comes to mind) that will haunt you with subtle bugs every day. I'd try SWT instead.. Clearer better looking and has better performance too. What are your credentials? How big applications have you build in Swing and SWT? Are you talking about the core APIs or about certain RCP layers on top of them? Hi :) I've been a Java dev for 3yrs my team was to build a rich client designed to manage small-to-mid retail stores at every level. Eventually we dropped it and went for a web UI instead (management decision). I knew my answer would be downvoted I just had to share the pain Swing did to us :D  Just another book recommendation: Java Swing by Matthew Robinson und Pavel Vorobiev It's the only book i read on Swing so far so i can't compare it to the other ones. On the other hand it's the only book i needed so far so it can't be bad.",java swing115103,A,"How do you implement position-sensitive zooming inside a JScrollPane? I am trying to implement position-sensitive zooming inside a JScrollPane. The JScrollPane contains a component with a customized 'paint' that will draw itself inside whatever space it is allocated - so zooming is as easy as using a MouseWheelListener that resizes the inner component as required. But I also want zooming into (or out of) a point to keep that point as central as possible within the resulting zoomed-in (or -out) view (this is what I refer to as 'position-sensitive' zooming) similar to how zooming works in google maps. I am sure this has been done many times before - does anybody know the ""right"" way to do it under Java Swing?. Would it be better to play with Graphic2D's transformations instead of using JScrollPanes? Sample code follows: package test; import java.awt.*; import java.awt.event.*; import java.awt.geom.*; import javax.swing.*; public class FPanel extends javax.swing.JPanel { private Dimension preferredSize = new Dimension(400 400); private Rectangle2D[] rects = new Rectangle2D[50]; public static void main(String[] args) { JFrame jf = new JFrame(""test""); jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); jf.setSize(400 400); jf.add(new JScrollPane(new FPanel())); jf.setVisible(true); } public FPanel() { // generate rectangles with pseudo-random coords for (int i=0; i<rects.length; i++) { rects[i] = new Rectangle2D.Double( Math.random()*.8 Math.random()*.8 Math.random()*.2 Math.random()*.2); } // mouse listener to detect scrollwheel events addMouseWheelListener(new MouseWheelListener() { public void mouseWheelMoved(MouseWheelEvent e) { updatePreferredSize(e.getWheelRotation() e.getPoint()); } }); } private void updatePreferredSize(int n Point p) { double d = (double) n * 1.08; d = (n > 0) ? 1 / d : -d; int w = (int) (getWidth() * d); int h = (int) (getHeight() * d); preferredSize.setSize(w h); getParent().doLayout(); // Question: how do I keep 'p' centered in the resulting view? } public Dimension getPreferredSize() { return preferredSize; } private Rectangle2D r = new Rectangle2D.Float(); public void paint(Graphics g) { super.paint(g); g.setColor(Color.red); int w = getWidth(); int h = getHeight(); for (Rectangle2D rect : rects) { r.setRect(rect.getX() * w rect.getY() * h rect.getWidth() * w rect.getHeight() * h); ((Graphics2D)g).draw(r); } } } Added bounty to see if I can get a full answer (ideally: the code snippet that when added above answers the question). Tested this seems to work... private void updatePreferredSize(int n Point p) { double d = (double) n * 1.08; d = (n > 0) ? 1 / d : -d; int w = (int) (getWidth() * d); int h = (int) (getHeight() * d); preferredSize.setSize(w h); int offX = (int)(p.x * d) - p.x; int offY = (int)(p.y * d) - p.y; setLocation(getLocation().x-offXgetLocation().y-offY); getParent().doLayout(); } Update Here is an explanation: the point p is the location of the mouse relative to the FPanel. Since you are scaling the size of the panel the location of p (relative to the size of the panel) will scale by the same factor. By subtracting the current location from the scaled location you get how much the point 'shifts' when the panel is resized. Then it is simply a matter of shifting the panel location in the scroll pane by the same amount in the opposite direction to put p back under the mouse cursor. Exactly what I was looking for. Thanks!  Your MouseWheelListener also has to locate the cursor move it to the center of the JScrollPane and adjust the xmin/ymin and xmax/ymax of the content to be viewed. Yes that is true - it is also what I was trying to do in the first place (the cursor is located at 'p' and adjusting those bounds correctly is what I do not know how to do).  I think smt like this should be working...  private void updatePreferredSize(int n Point p) { double d = (double) n * 1.08; d = (n > 0) ? 1 / d : -d; int w = (int) (getWidth() * d); int h = (int) (getHeight() * d); preferredSize.setSize(w h); // Question: how do I keep 'p' centered in the resulting view? int parentWdt = this.getParent( ).getWidth( ) ; int parentHgt = this.getParent( ).getHeight( ) ; int newLeft = p.getLocation( ).x - ( p.x - ( parentWdt / 2 ) ) ; int newTop = p.getLocation( ).y - ( p.y - ( parentHgt / 2 ) ) ; this.setLocation( newLeft newTop ) ; getParent().doLayout(); } EDIT: Changed a couple things. Your code does not keep the point 'p' centered in the resulting view (for an example try zooming near the bottom-right corner) even after changing `int newTop = p.y - w / 2;` to `int newTop = p.y - h / 2;`. Please test code before proposing it as an answer. The updated code seems to zoom into the top-left corner (java 6 on XP) not into wherever the mouse pointer is pointing. I am using the same test program listed in the question.  Here's a minor refactoring of @Kevin K's solution: private void updatePreferredSize(int wheelRotation Point stablePoint) { double scaleFactor = findScaleFactor(wheelRotation); scaleBy(scaleFactor); Point offset = findOffset(stablePoint scaleFactor); offsetBy(offset); getParent().doLayout(); } private double findScaleFactor(int wheelRotation) { double d = wheelRotation * 1.08; return (d > 0) ? 1 / d : -d; } private void scaleBy(double scaleFactor) { int w = (int) (getWidth() * scaleFactor); int h = (int) (getHeight() * scaleFactor); preferredSize.setSize(w h); } private Point findOffset(Point stablePoint double scaleFactor) { int x = (int) (stablePoint.x * scaleFactor) - stablePoint.x; int y = (int) (stablePoint.y * scaleFactor) - stablePoint.y; return new Point(x y); } private void offsetBy(Point offset) { Point location = getLocation(); setLocation(location.x - offset.x location.y - offset.y); }",java swing user-interface zoom178667,A,"Does JEditorPane have Charset problems when showing HTML? I have the following code: import javax.swing.JEditorPane; import javax.swing.JFrame; import javax.swing.JScrollPane; import javax.swing.ScrollPaneConstants; public class ScratchPad { public static void main(String args[]) throws Exception { String html =""<html>""+ ""<head>""+ ""<meta http-equiv=\""Content-Type\"" content=\""text/html; charset=ISO-8859-1\""/>""+ // this is the problem right here ""<title>Error 400 BAD_REQUEST</title>""+ ""</head>""+ ""<body>""+ ""<h2>HTTP ERROR: 400</h2><pre>BAD_REQUEST</pre>""+ ""<p>RequestURI=null</p>""+ ""<p><i><small><a href=\""http://jetty.mortbay.org\"">Powered by jetty://</a></small></i></p>""+ ""</body>""+ ""</html>""; JFrame f = new JFrame(); JEditorPane editor = new JEditorPane(); editor.setEditable( false ); editor.getDocument().putProperty( ""Ignore-Charset"" ""true"" ); // this line makes no difference either way editor.setContentType( ""text/html"" ); editor.setText( html ); f.add( new JScrollPane(editor ScrollPaneConstants.VERTICAL_SCROLLBAR_AS_NEEDED ScrollPaneConstants.HORIZONTAL_SCROLLBAR_NEVER) ); f.pack(); f.setVisible( true ); } } If you run it you'll notice the frame is blank. However if I remove the ""; charset=ISO-8859-1"" from the meta tag the HTML shows up. Any ideas why and what I can do to prevent this (other than manually hacking the HTML string over which I have no control...). Edit #1 - putProperty( ""Ignore-Charset"" ""true"" ) makes no difference unfortunately. Use the follow line before setText and after setContentType. editor.getDocument().putProperty(""IgnoreCharsetDirective"" Boolean.TRUE); This is one of the mystic undocumented features. setContentType create a new Document that it has no effect if you set it before.  When I run the code I can only see the HTML text when I delete the meta line. Maybe it has something to do with character settings of the system it runs on.",java html swing jeditorpane113464,A,"Java User Interface Specification Java supplies standard User Interface guidelines for applications built using Java Swing. The basic guidelines are good but I really feel the look and feel is really boring and outdated. Is anyone aware of a publicly available Java User Interface Guide that has better look & feel guidelines than the Sun provided guidelines? the apple developer guide has a human computer interface guide - http://developer.apple.com/documentation/UserExperience/Conceptual/AppleHIGuidelines/XHIGIntro/chapter_1_section_1.html#//apple_ref/doc/uid/TP30000894-TP6 . Even though its targeted at the mac platform you could learn something from it - its the reason why so many mac apps are pleasant to use as well as aesthetically pleasing!  Along the line of Chii's answer I would recommend taking a look at the Windows Vista User Experience Guidelines for general tips on making user interfaces. Although the name (""Windows Vista User Experience Guidelines"") and source (Microsoft) may suggest that it only contains Windows-centric tips and advice it does offer good general tips and directions that can be used when designing interfaces for non-Windows applications as well. The Design Principles sections address some points to keep in mind when designing an effective user interface. For example bullet three of How to Design a Great User Experience says: Don't be all things to all people Your program is going to be more successful by delighting its target users than attempting to satisfy everyone. These are the kinds of tips that apply to designing user interfaces on any platform. Of course there are also Windows-specific guidelines as well. I believe one of the biggest reasons why look and feel of Swing applications seems ""boring"" and ""outdated"" is due to the platform-independent nature of Java. In order for the graphical user interfaces to work on several different platforms Java needs to have facilities to adapt the user interface to the different host operating systems. For example various platforms have various sizes for windows buttons and other visual components so absolute positioning does not work too well. To combat that problem Swing uses Layout Managers which (generally) use relative positioning to place the visual components on the screen. Despite these ""limitations"" of building graphical user interfaces for Java I think that using tips from guidelines that are provided by non-Sun sources and non-Java-specific sources can still be a good source of information in designing and implementing an user interface that is effective. After all designing an user interface is less about programming languages and more about human-machine interaction.  I don't think there are any other complete guidelines. But if you are not talking about the spacing/positioning of components (I don't think that part of Look And Feel Design Guidelines is outdated) but only about the look and feel good starting points are singlabx / swingx: http://swinglabs.org http://swinglabs.org/docs/presentations/2007/DesktopMatters/FilthyRichClients.pdf http://parleys.com/display/PARLEYS/Home#slide=1;talk=7643;title=Filthy%20Rich%20Clients and JGoodies: http://www.jgoodies.com/articles/index.html http://www.jgoodies.com/articles/efficient%20swing%20design.pdf  You have many LNF (Look And Feel) displayed here but they have not exactly a 'Java User Guide' Provided. However MigLayout does follow closely the main User Interface standards that exist out there (including some obcure points of button order): For instance the OK and Cancel buttons have different order on Windows and Mac OS X. While other layout managers use factories and button builders for this it is inherently supported by MigLayout by just tagging the buttons. One just tags the OK button with ""ok"" and the Cancel button with ""cancel"" and they will end up in the correct order for the platform the application is running on if they are put in the same grid cell. Example on Mac:",java swing user-interface128016,A,Java Swing: how do I set the maximum width of a JTextField? I'm writing a custom file selection component. In my UI first the user clicks a button which pops a JFileChooser; when it is closed the absolute path of the selected file is written to a JTextField. The problem is absolute paths are usually long which causes the text field to enlarge making its container too wide. I've tried this but it didn't do anything the text field is still too wide: fileNameTextField.setMaximumSize(new java.awt.Dimension(450 2147483647)); Currently when it is empty it is already 400px long because of GridBagConstraints attached to it. I'd like it to be like text fields in HTML pages which have a fixed size and do not enlarge when the input is too long. So how do I set the max size for a JTextField ? It may depend on the layout manager your text field is in. Some layout managers expand and some do not. Some expand only in some cases others always. I'm assuming you're doing filedNameTextField = new JTextField(80); // 80 == columns If so for most reasonable layouts the field should not change size (at least it shouldn't grow). Often layout managers behave badly when put into JScrollPanes. In my experience trying to control the sizes via setMaximumSize and setPreferredWidth and so on are precarious at best. Swing decided on its own with the layout manager and there's little you can do about it. All that being said I have no had the problem you are experiencing which leads me to believe that some judicious use of a layout manager will solve the problem.  I solved this by setting the maximum width on the container of the text field using setMaximumSize. According to davetron's answer this is a fragile solution because the layout manager might disregard that property. In my case the container is the top-most and in a first test it worked. Yeah that is unfortunately how it goes with Swing. It's a nice toolkit in many ways but the unpredictability of the components in different layout managers is really annoying.  Don't set any of the sizes on the text field. Instead set the column size to a non-zero value via setColumns or using the constructor with the column argument. What is happening is that the preferred size reported by the JTextComponent when columns is zero is the entire amount of space needed to render the text. When columns is set to a non-zero value the preferred size is the needed size to show that many standard column widths. (for a variable pitch font it is usually close to the size of the lower case 'm'). With columns set to zero the text field is requesting as much space as it can get and stretching out the whole container. Since you already have it in a GridBagLayout with a fill you could probably just set the columns to 1 and let the fill stretch it out based on the other components or some other suitably low number. I recommend this approach when using `FlowLayout`.,java swing271888,A,"Best practice for handling null strings from database (in Java) In my database application I sometimes have to deal with null strings in the database. In most cases this is fine but when it comes do displaying data in a form the Swing components - using JTextField for example - cannot handle null strings. (.setText(null) fails) (EDIT: I just noticed that JTextField actually accepts a null string but the question remains for all other cases where unexpected null values can lead to problems.) The null values have no special meaning they can (must) be treated as empty strings. What is the best practice to deal with this problem? Unfortunatly I cannot change the database. Checking every value if it is null before calling setText()? Adding a try-catch handler to every setText() call? Introducing a static method which filters all null strings? Replace all null values to empty strings immediatly after reading from the database? ... [your suggestions] You could extend or wrap JTextField and overwrite the setText() method to replace NULL with an empty String. Yes but actually ""NULL"" can be legal value in DB ;> Indeed that is why you would wrap setText() & getText() so you can interchange null with """" for setText and vice versa for getText.  Use Beans Binding API to bind values from your entity objects to your SWING Widgets. Beanins Binding will transparently handle null values and will not replace the null with an empty string.  As Ruben said I would extend the JTextField to overwrite the setText() method and replace NULL with the empty string. However I would also overwrite the getText() method to overwrite empty string with NULL so that when you are saving back into the database you do not overwrite a null value in there with the empty string.  From a SQL angle try: select ISNULL(column_name'') from ... Someone just marked this answer down :(. While I accept that the question asks about Java. This solution can be used to handle ALL unexpected null values from a database. and as the question states ""unfortunately I can't change the database"" it implies that non java answers are also acceptable.  I think all your answers are reasonable but since you tagged this ""best practices"" I'd like to remind you of the null object design pattern. Wherever it seems worth the effort for whatever class need the protection write special instantiation code for a ""null"" object of that class. The idea is this ""null"" object is real and can behave appropriately no matter what you ask it to do. Your null ""String"" object could provide whatever you want as it's value. This pattern also means you can get rid of lots of null checks and the code is more robust. It does use up a bit of CPU sending messages to nulls and having them do nothing so it is less desirable when a large percentage of objects are expected to be null.  If you are using any ORM tool or somehow you map your DB fields to Java bean you can allways have:  public void setFoo(String str) { this.foo = str != null ? str : """"; } On Oracle i don't believe this is an issue. It may depend on settings but our 10g implementation interprets empty strings as nulls. Other DBMS's and perhaps other configurations may vary. You do have to be careful when writing back the data to the DB since you will be inserting an empty String instead of the NULL value! I think that's the best solution but I will change the getter. (I guess that's what you meant all along) I think Marko ment the setter since that is used by most ORM tools e.g. hibernate to put the values from the database into the instances. When using the getter you still need to be carefull for side effects in the database when using an ORM tool. FWIW I'd flip the inequality to an equality test. Just another best practice (or opinion depending on how you look at it). public void setFoo(String str) { this.foo = str == null ? """" : str; } Then how would you check whether the value is empty in the DB or NULL from your Entity object?  If you can add a default value - empty string - for a field in DB . Yes that would be best but unfortunatly I cannot do that :(",java database swing299495,A,"How to add an image to a JPanel? I have a JPanel to which I'd like to add JPEG and PNG images that I generate on the fly. All the examples I've seen so far in the Swing Tutorials specially in the Swing examples use ImageIcons. I'm generating these images as byte arrays and they are usually larger than the common icon they use in the examples at 640x480. Is there any (performance or other) problem in using the ImageIcon class to display an image that size in a JPanel? What's the usual way of doing it? How to add an image to a JPanel without using the ImageIcon class? Edit: A more careful examination of the tutorials and the API shows that you cannot add an ImageIcon directly to a JPanel. Instead they achieve the same effect by setting the image as an icon of a JLabel. This just doesn't feel right... I'm doing something very similar in a private project I'm working on. Thus far I've generated images up to 1024x1024 without any problems (except memory) and can display them very quickly and without any performance problems. Overriding the paint method of JPanel subclass is overkill and requires more work than you need to do. The way I do it is: Class MapIcon implements Icon {...} OR Class MapIcon extends ImageIcon {...} The code you use to generate the image will be in this class. I use a BufferedImage to draw onto then when the paintIcon() is called use g.drawImvge(bufferedImage); This reduces the amount of flashing done while you generate your images and you can thread it. Next I extend JLabel: Class MapLabel extends Scrollable MouseMotionListener {...} This is because I want to put my image on a scroll pane I.e. display part of the image and have the user scroll around as needed. So then I use a JScrollPane to hold the MapLabel which contains only the MapIcon. MapIcon map = new MapIcon (); MapLabel mapLabel = new MapLabel (map); JScrollPane scrollPane = new JScrollPane(); scrollPane.getViewport ().add (mapLabel); But for your scenario (just show the whole image every time). You need to add the MapLabel to the top JPanel and make sure to size them all to the full size of the image (by overriding the GetPreferredSize()).  JLabel imgLabel = new JLabel(new ImageIcon(""path_to_image.png""));  You can avoid rolling your own Component subclass completely by using the JXImagePanel class from the free SwingX libraries. Download  I think there is no need to subclass of anything. Just use a Jlabel. You can set an image into a Jlabel. So resize the Jlabel then fill it with an image. Its OK. This is the way I do. Simpler by a long shot.  If you are using JPanels then are probably working with Swing. Try this: BufferedImage myPicture = ImageIO.read(new File(""path-to-file"")); JLabel picLabel = new JLabel(new ImageIcon(myPicture)); add(picLabel); The image is now a swing component. It becomes subject to layout conditions like any other component. +1 Excellent code. +1 that. clean. Nice just used that code myself. +1. Nice one.. Just used this code.. +1 how to scale the image according to the size of the JLabel? Nice code! I'm not much experienced with Swing but I can't get it work. Does anybody tried it in jdk 1.6.0_16? @ATorras I know you asked this a while back but if any other newbies had my issues remember to picLabel.setBounds();  JPanel is almost always the wrong class to subclass. Why wouldn't you subclass JComponent? There is a slight problem with ImageIcon in that the constructor blocks reading the image. Not really a problem when loading from the application jar but maybe if you're potentially reading over a network connection. There's plenty of AWT-era examples of using MediaTracker ImageObserver and friends even in the JDK demos.  There shouldn't be any problem (other than any general problems you might have with very large images). If you're talking about adding multiple images to a single panel I would use ImageIcons. For a single image I would think about making a custom subclass of JPanel and overriding its paintComponent method to draw the image. (see 2)  Fred Haslam's way works fine. I had trouble with the filepath though since I want to reference an image within my jar. To do this I used: BufferedImage wPic = ImageIO.read(this.getClass().getResource(""snow.png"")); JLabel wIcon = new JLabel(new ImageIcon(wPic)); Since I only have a finite number (about 10) images that I need to load using this method it works quite well. It gets file without having to have the correct relative filepath.  Here's how I do it (with a little more info on how to load an image): import java.awt.Graphics; import java.awt.image.BufferedImage; import java.io.File; import java.io.IOException; import java.util.logging.Level; import java.util.logging.Logger; import javax.imageio.ImageIO; import javax.swing.JPanel; public class ImagePanel extends JPanel{ private BufferedImage image; public ImagePanel() { try { image = ImageIO.read(new File(""image name and path"")); } catch (IOException ex) { // handle exception... } } @Override protected void paintComponent(Graphics g) { super.paintComponent(g); g.drawImage(image 0 0 null); // see javadoc for more info on the parameters } } Opps... put the example together a little to quick... @Dutow - Good call I edited the answer. Thanks. I tried using this with some custom buttons on top and found that there were strange redrawing issues. Fred Haslam's answer below did not suffer from this problem. -1 for invalid implementation of paintComponent (@Dogmatixed most probably that's why you are having those redrawing issues) - it _must_ garantee to cover its complete area if it reports being opaque (which is the default) easiest achieved by calling super.paintComponent @kleopatra Thanks I didn't realize that... according to the javadoc: ""Further if you do not invoker super's implementation you must honor the opaque property that is if this component is opaque you must completely fill in the background in a non-opaque color. If you do not honor the opaque property you will likely see visual artifacts."" I'll update the answer now. thanks for the edit reverted my vote :-) Please always respect the `Principle of Encapsulation` while overriding methods of the Super Class the Access Specifier of the `paintComponent(...)` method is `protected` and not `public` :-) How do you handle errors in this implementation? I mean if an error is thrown in the constructor not only will you have to deal not just with that but you'll also have to deal with `NullPointerException`s that paintComponent() will throw (and will throw as many times as it is called). Wait nevermind. `drawImage()` doesn't throw a NPE when `img` is null.  You can subclass JPanel - here is an extract from my ImagePanel which puts an image in any one of 5 locations top/left top/right middle/middle bottom/left or bottom/right: protected void paintComponent(Graphics gc) { super.paintComponent(gc); Dimension cs=getSize(); // component size gc=gc.create(); gc.clipRect(insets.leftinsets.top(cs.width-insets.left-insets.right)(cs.height-insets.top-insets.bottom)); if(mmImage!=null) { gc.drawImage(mmImage(((cs.width-mmSize.width)/2) +mmHrzShift)(((cs.height-mmSize.height)/2) +mmVrtShift)null); } if(tlImage!=null) { gc.drawImage(tlImage(insets.left +tlHrzShift)(insets.top +tlVrtShift)null); } if(trImage!=null) { gc.drawImage(trImage(cs.width-insets.right-trSize.width+trHrzShift)(insets.top +trVrtShift)null); } if(blImage!=null) { gc.drawImage(blImage(insets.left +blHrzShift)(cs.height-insets.bottom-blSize.height+blVrtShift)null); } if(brImage!=null) { gc.drawImage(brImage(cs.width-insets.right-brSize.width+brHrzShift)(cs.height-insets.bottom-brSize.height+brVrtShift)null); } }",java image swing jpanel103179,A,"How do I set an Application's Icon Globally in Swing? I know I can specify one for each form or for the root form and then it'll cascade through to all of the children forms but I'd like to have a way of overriding the default Java Coffee Cup for all forms even those I might forget. Any suggestions? Extend the JDialog class (for example name it MyDialog) and set the icon in constructor. Then all dialogs should extend your implementation (MyDialog).  There is another way but its more of a ""hack"" then a real fix.... If you are distributing the JRE with your Application you could replace the coffee cup icon resource in the java exe/dll/rt.jar wherever that is with your own icon. It might not be very legit but it is a possibility... Agreed. It'd work but I'm not feeling that desperate. :) If it's the only way it doesn't matter if you're desperate or not :) My company does it through InstallAnywhere's `executableIcon` property. I think it does it by replacing `JavaCup.png` in `jre/lib/resources.jar`.  Also if you have one ""main"" window and set its icon properly as long as you use that main window as the ""parent"" for any Dialog classes they will inherit the icon. Any new Frames need to have the icon set on them though. as Paul/Andreas said subclassing JFrame is going to be your best bet.  You can make the root form (by which I assume you mean JFrame) be your own subclass of JFrame and put standard functionality in its constructor such as:  this.setIconImage(STANDARD_ICON); You can bundle other standard stuff in here too such as memorizing the frame's window metrics as a user preference managing splash panes etc. Any new frames spawned by this one would also be instances of this JFrame subclass. The only thing you have to remember is to instantiate your subclass instead of JFrame. I don't think there's any substitute for remembering to do this but at least now it's a matter of remembering a subclass instead of a setIconImage call (among possibly other features). Not ideal but it works. There should be a way of doing this for all forms in an app. Some forms might be spawned by third party tools etc. Yes there *should* be a way but sun hasn't provided one. Its probably a sev3 enhancement in bugparade somewhere...  There may be a way of doing it using the Look and Feel overriding the UIDefaults. I'm just not sure which index would do.",java swing354866,A,Swing JButton: Icon above Text How can I create a JButton in Swing with the icon above the text? just do this:   button.setVerticalTextPosition(SwingConstants.BOTTOM); button.setHorizontalTextPosition(SwingConstants.CENTER);,java swing jbutton188944,A,Java/Swing: How to draw a simple bar graph in a custom renderer for a JLabel I would like to dynamically create a minimal transparent bar graph to display over a canvas. I was thinking of using a custom renderer for a JButton or a JLabel; but how do I draw my bar graph in this renderer? The standard way would be to create a subclass (possibly an anonymous one if you prefer) of JLabel or JPanel and overload the paintComponent(Graphics g) method. You can then use the passed Graphics object to draw whatever rectangles (and so forth) that you need. For more information on that part of it refer to the Java 2D Graphics Trail. EDIT: Does that answer the question? I just re-read it and now I'm not sure. Your answer is OK... I was thinking of a custom renderer as for table cells but this may not exist for JLabel &/or JButtons. thanks julien Okay. And no there isn't a custom renderer for JLabel or JButton (at least not in standard Swing; there might be third-party libraries which offer something similar). To add any JComponent to a JTable you can extend the DefaultTableCellRenderer and over ride the getTableCellRendererComponent. Just return an instance of your BarGraph object. You have to set the cellRenderder on the JTable also to your subclassed DefaultTableCellRenderer.,java swing custom-renderer386792,A,"In Java Swing how do you get a Win32 window handle (hwnd) reference to a window? In Java 1.4 you could use ((SunToolkit) Toolkit.getDefaultToolkit()).getNativeWindowHandleFromComponent() but that was removed. It looks like you have to use JNI to do this now. Do you have the JNI code and sample Java code to do this? I need this to call the Win32 GetWindowLong and SetWindowLong API calls which can be done via the Jawin library. I would like something very precise so I can pass a reference to the JDialog or JFrame and get the window handle. Swing transparency using JNI may be related. You don't have write any C/JNI code. From Java: import sun.awt.windows.WComponentPeer; public static long getHWnd(Frame f) { return f.getPeer() != null ? ((WComponentPeer) f.getPeer()).getHWnd() : 0; } Caveats: This uses a sun.* package. Obviously this is not public API. But it is unlikely to change (and I think less likely to break than the solutions above). This will compile and run on Windows only. You would need to turn this into reflection code for this to be portable. mike rodent asked "" Thanks this looks really good... but with WComponentPeer I'm getting: ""Access restriction on required library rt.jar"" - rt.jar is part of my OpenOffice API imports. Given that sun.awt.windows classes aren't public how do you use them like this?"" @mike: reflection might help: http://comments.gmane.org/gmane.comp.video.mplayer.user/58067 @Jared you might be able to compile it in windows just then never run that particular code in other OS's and it might work.  Both of the above methods work just fine but both return a HWND as a java int (32bits). this is fine for a 32 bit platform but it will be unlikely that your application will be functional on a 64bit platform. I would change the return types to longs (64bits) as this will behave correctly on both 64 and 32bit systems (you'll only need to recompile the DLL) Thank you very much.  The following code lets you pass a Component to get the window handle (HWND) for it. To make sure that a Component has a corresponding window handle call isLightWeight() on the Component and verify that it equals false. If it doesn't try it's parent by calling Component.getParent(). Java code: package win32; public class Win32 { public static native int getWindowHandle(Component c); } Header file main.h: /* DO NOT EDIT THIS FILE - it is machine generated */ #include <jni.h> /* Header for class win32_Win32 */ #ifndef _Included_win32_Win32 #define _Included_win32_Win32 #ifdef __cplusplus extern ""C"" { #endif /* * Class: win32_Win32 * Method: getWindowHandle * Signature: (Ljava/awt/Component;Ljava/lang/String;)I */ JNIEXPORT jint JNICALL Java_win32_Win32_getWindowHandle (JNIEnv * jclass jobject); #ifdef __cplusplus } #endif #endif The C source main.c: #include<windows.h> #include <jni.h> #include <jawt.h> #include <jawt_md.h> HMODULE _hAWT = 0; JNIEXPORT jint JNICALL Java_win32_Win32_getWindowHandle (JNIEnv * env jclass cls jobject comp) { HWND hWnd = 0; typedef jboolean (JNICALL *PJAWT_GETAWT)(JNIEnv* JAWT*); JAWT awt; JAWT_DrawingSurface* ds; JAWT_DrawingSurfaceInfo* dsi; JAWT_Win32DrawingSurfaceInfo* dsi_win; jboolean result; jint lock; //Load AWT Library if(!_hAWT) //for Java 1.4 _hAWT = LoadLibrary(""jawt.dll""); if(!_hAWT) //for Java 1.3 _hAWT = LoadLibrary(""awt.dll""); if(_hAWT) { PJAWT_GETAWT JAWT_GetAWT = (PJAWT_GETAWT)GetProcAddress(_hAWT ""_JAWT_GetAWT@8""); if(JAWT_GetAWT) { awt.version = JAWT_VERSION_1_4; // Init here with JAWT_VERSION_1_3 or JAWT_VERSION_1_4 //Get AWT API Interface result = JAWT_GetAWT(env &awt); if(result != JNI_FALSE) { ds = awt.GetDrawingSurface(env comp); if(ds != NULL) { lock = ds->Lock(ds); if((lock & JAWT_LOCK_ERROR) == 0) { dsi = ds->GetDrawingSurfaceInfo(ds); if(dsi) { dsi_win = (JAWT_Win32DrawingSurfaceInfo*)dsi->platformInfo; if(dsi_win) { hWnd = dsi_win->hwnd; } else { hWnd = (HWND) -1; } ds->FreeDrawingSurfaceInfo(dsi); } else { hWnd = (HWND) -2; } ds->Unlock(ds); } else { hWnd = (HWND) -3; } awt.FreeDrawingSurface(ds); } else { hWnd = (HWND) -4; } } else { hWnd = (HWND) -5; } } else { hWnd = (HWND) -6; } } else { hWnd = (HWND) -7; } return (jint)hWnd; } Sorry to bump a very old topic here but I keep getting an `EXCEPTION_ACCESS_VIOLATION` in `jvm.dll` whenever I try to get the drawing surface (`GetDrawingSurface`) of a component (in my case a `java.awt.Cavas`). I made sure it is _not_ lightweight and it is already visible on the screen. Has anything changed in Java 1.6 or is there anything else you need to do before you can get the drawing surface? No idea. Try asking a new question to get more eyes on the issue. pdinklag were you able to deal with that issue calling GetDrawingSurface? I experience the same problem now and jvm crashes in DSGetDrawingSurface. Tried with several jvms (1.6 and 1.7) - still crashes.  In JNA library we see that using Native AWT in Java 5 and 6 UnsatisfiedLinkError when run headless so use dynamic linking. See the method Java_com_sun_jna_Native_getWindowHandle0 in https://github.com/twall/jna/blob/master/native/dispatch.c.  This little JNI method accepts a window title and returns the corresponding window handle. JNIEXPORT jint JNICALL Java_JavaHowTo_getHwnd (JNIEnv *env jclass obj jstring title){ HWND hwnd = NULL; const char *str = NULL; str = (*env)->GetStringUTFChars(env title 0); hwnd = FindWindow(NULLstr); (*env)->ReleaseStringUTFChars(env title str); return (jint) hwnd; } UPDATE: With JNA it's a little bit easier. I made a small example which find the handle and use it to bring the program to front. This is not precise enough. I'd rather not hope that the window title is not in use by another window. just be sure to set the window title to something really really unique before the call (so you don't accidentally pick up the hwnd for another window with the same title - the FindWindow call is not process specific) You can replace the ""NULL"" with a class name to make the search more precise. You determine the window class name with a special tool like SPY++ or WinID. Small example is awesome  I found this: http://jna.java.net/javadoc/com/sun/jna/Native.html#getWindowID(java.awt.Window) JNA lets you call native libraries without having to write jni native code. Turns out the library itself has a method that takes a Window and produces an int presumably a handle (or pointer?) that hopefully works on all platforms. Actually getWindowPointer() is for Windows. According to their docs the method getWindowID() is for X11.  This is the same as Jared MacD's answer but it uses reflection so that the code can compile and load on a non-Windows computer. Of course it will fail if you try to call it. import java.awt.Frame; import java.lang.reflect.InvocationTargetException; import java.lang.reflect.Method; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class WindowHandleGetter { private static final Logger log = LoggerFactory.getLogger(WindowHandleGetter.class); private final Frame rootFrame; protected WindowHandleGetter(Frame rootFrame) { this.rootFrame = rootFrame; } protected long getWindowId() { try { Frame frame = rootFrame; // The reflection code below does the same as this // long handle = frame.getPeer() != null ? ((WComponentPeer) frame.getPeer()).getHWnd() : 0; Object wComponentPeer = invokeMethod(frame ""getPeer""); Long hwnd = (Long) invokeMethod(wComponentPeer ""getHWnd""); return hwnd; } catch (Exception ex) { log.error(""Error getting window handle""); } return 0; } protected Object invokeMethod(Object o String methodName) throws IllegalAccessException IllegalArgumentException InvocationTargetException { Class c = o.getClass(); for (Method m : c.getMethods()) { if (m.getName().equals(methodName)) { Object ret = m.invoke(o); return ret; } } throw new RuntimeException(""Could not find method named '""+methodName+""' on class "" + c); } }",java winapi swing jni hwnd496233,A,"What are your best Swing design patterns and tips? I'm writing a GUI for an application using Swing and in the interests of code maintenance and readability I want to follow a consistent pattern throughout the whole system. Most of the articles and books (or at least book sections) that I've read appear to provide plenty of examples on how to create and arrange various components but ignore the bigger picture of writing a full GUI. What are your best tips for application GUI design and what patterns do you follow when designing or refactoring a GUI application? here are my four babys : http://blue-walrus.com/swing-design-patterns/ Make heavy use of the MVC pattern. Here's a simple example of what I mean: class Person { String firstName; String lastName; // and getters and setters... } class PersonSwingModel { private Person person; private javax.swing.text.PlainDocument firstName; private javax.swing.text.PlainDocument lastName; // and getters and setters... // Create some method like init() that initializes PlainDocument values // to attributes in model. } class SavePersonAction extends AbstractAction { private PersonSwingModel model; // and getters and setters... } class PersonSwingView extends JFrame { private PersonSwingModel model; private javax.swing.JTextField firstName; private javax.swing.JTextField lastName; private SavePersonAction savePersonAction; // hook up to JButton/JMenuItem // and getters and setters... // Create some method like init() which binds PlainDocument to JTextField // and Actions to JButtons or JMenuItems } I see some people disagree with extending JFrame or JPanel. I don't. Works for me. Also use LayoutManagers. GridBagLayout is very powerful. If you use it define some GridBagConstraints constants (like LABEL_GBC and FIELD_GBC) and keep reusing them.  I think a good working knowledge of concurrency is often understated. You really need to be familiar with Swing's threading policy and general synchronization techniques to build a responsive GUI and an efficient backend.  Definitely put the GUI in one class and the logic in another class or multiple classes -- to the greatest extent possible. If you use the MVC (Model-View-Controller) pattern this will happen automatically. If you don't do this the GUI will quickly become unmaintainably complicated.  Avoid inherit when composition would be easier. For instance I have seen a lot like this: public class CustomerSupportApp extends JFrame { JList<Customer> customers; OtherBusinessComponent importantComponent; etc. etc } This is mixing business logic with presentation. It only makes changes from difficult to impossible. Better is: public class CustomerSupportApp { JList<Customer> customers; OtherBusinessComponent importantComponent; // The app HAS-A frame but not IS-A frame JFrame frame; etc. etc } In your case it is obvious because application != frame but there are other examples e.g. `FooFrame extends BarFrame` where inheritance also is not appropriate e.g. because they have too less in common.  Karsten Lentzsch's JGoodies has been very helpful to me for architectural design especially with regard to the Presentation Model pattern bindings and validation. Check out his articles and libraries. Use an MVC-like pattern. I say ""like"" because the goal is really to separate the view from the model not to conform to a specific flavor of MVC. I prefer using Presentation Model myself. MiGLayout - I use it for everything unless a basic layout manager will do. Modularize and reuse as much as you can. WindowBuilder Pro for Eclipse - The best visual designer because it works with existing/edited code and doesn't lock you in. And it's free now! I have no issue with using designers because the view should be separate from the rest of the code. Netbeans Platform (RCP) - The only real Swing framework. I hope to learn and use this when I have time because part of a framework's job is to address concerns like yours. JavaBuilders - Cool project that allows declarative UIs but I'm not sure it's mature enough to risk it especially with an existing project. However it's interesting to read their PDF book if only to understand the problems they're trying to solve.  Avoid using GUI layout designers (builders). Later on it will make your code much cleaner and easier to maintain. It's true that if you start your GUI with a builder you are pretty much committed to using that builder throughout the whole life of the GUI. This is sometimes acceptable sometimes not. Yes it's true. Different builders store metadata in different formats which are not mutually compatibel. The only exception is Instantiations Swing Designer which works with the code directly. All of them create code which is not meant to be edited by hand (unreadable) which will bite you later. I disagree. If you know Swing well any code generated by a GUI builder will be readable enough. Problem is that by using a GUI builder you will not get to know Swing well. Good separation is of course necessary. WindowBuilder Pro does a good job with generated code. Check it out: https://developers.google.com/java-dev-tools/wbpro/?hl=fr  Get into the habit of having your callbacks spawn off threads to do the actual work and then you won't be having frozen GUIs when one of your callbacks turns into a time consuming monster. Better yet use SwingWorker. Yes SwingWorker is one of many ways to spawn off a thread. Dont forget SwingUtilities invoker later if that thread needs to update the GUI afterwards :) Take a look at FoxTrot: http://foxtrot.sourceforge.net/  I think that the main problem you are going to be faced with is testability of your gui application. So regarding maintainability and ease of unit testing I am leaning towards the ""Presenter first"" idiom instead of Model View Controller (MVC) and other derivatives that instruct you to have the view knowing of the actual application logic (Model). The best resource is the web site of the group that introduced it as a thought. Since using an approach like that is going to take a lot of boilerplate code to initialize the various elements of your application I would also suggest in using a dependency injection framework. I have settled with Guice.  Avoid spawning too many threads when user clicks action button multiple times. Disable button on first click spawn your action in background thread and when done enable button again. This may not be problem for short running tasks.  Try not to code the text into your app. Swing guis can be pretty easily written to be data driven consider defining your GUI in an xml file (including the component names and positions/layout attributes). I worked on systems that had a LOT of property sheets (which are just piles of controls page after page of them)--without making it data driven it's virtually impossible to maintain or internationalize. If you decide to use a GUI builder never modify the code it outputs if you can possibly avoid it--it's better to bind to the GUI from an external class. Think about what will happen if you have to do it without the builder--will it be difficult to port? Impossible? Understand the gotchas in swing--only modifying GUI components from the AWT thread returning the AWT thread as quickly as possible (spawn a new thread if you have to do anything that takes over 100ms) Try your best to keep your code DRY--It can be a real programming challenge with Swing GUIs--Again data driven code is the only way I've found to not constantly repeat code like new JButton(""...""); If your data is property-sheet based seriously consider creating a binding mechanism to tie your controls to your data. A good goal for DRY code would be 0 (ZERO) control-specific lines of code per control to get a piece of data from your database to your GUI have the user edit it and get it back to your DB. This means that you should be able to add a new control by doing nothing but modifying your data.  Have a look at the application framework API ( https://appframework.dev.java.net/ and http://java.sun.com/developer/technicalArticles/javase/swingappfr/. It's a great API to build your swing application. e.g. : all the styles (color fonticons...) are defined in a simple config file.  mvc is your friend.  This is a more abstract high-level answer about what your GUI represents not the mechanics of it.. Depending on your task it may be kind of difficult to make it so your user can conceptually grasp what the GUI is doing. I've done some pretty tricky work involving GUIs and my most successful approaches have been those that took a complex set of controls and put them into a layout that the user expected. For instance I wrote a system to manage 2 devices one at either end of a T1 line (kinda like modems). The controls were really hard to comprehend--fields like ""create loopback test far end signal test near end bit patterns sending various bit patterns ..."" (this is a huge oversimplification it was a lot worse than this) I had to really understand the problem so I went to a Tech Support rep who helped customers with this problem all the time. He showed me a diagram in the manual and stepped me through what the different controls did on that diagram. I took the diagram re-created it using graphics (just a simple line-drawing for the most part but it showed both ends and the connections between them) then used regions of the graphics to represent controls AND feedback (color changes). You could visually see that a signal was going out. When you turned on a loopback at the far end you could see that the line looped the signal back to it's outgoing line then you could see the color change as your near-end started getting the pattern that it was sending out it's other line. The ""Controls"" were significantly more convoluted than this but the GUI reduced it to EXACTLY what the customer needed to understand the problem. After this we had customers coming back to us telling us that they had never been able to figure this stuff out before but now they totally get it! This presentation was infinitely more important than the wiring of the GUI implementation.  Never derive from JDialog JFrame or JInternalFrame for defining your forms dialogs... Rather derive from JPanel. This will bring you the follwing advantages: possibility to later change from a JFrame to a JDialog for instance (because user changed his mind) you can reuse one panel instance from one JDialog to another (JDialog are generally not reusable because they are constructed with a reference to their ""parent"" a frame or another dialog) you can later on change replace JDialog with a more functional subclass from a 3rd-party framework. Along with this I would define a 'view' interface. What should your 'view' interface do?  Use layout managers. You might think it's simpler just to position everything with hard coded positions now (especially if you use a graphical layout tool) but when it comes time to update the gui or internationalize it your successors will hate you. (Trust me on this I was the guy saying to use the layout managers from the start and the successor to the guy who ignored me.)  You're not supposed to extend JFrame JDialog JPanel JButton Janything classes (although certain extensions to table behaviour are only available if you extend it). You can extend JComponent if you feel like doing custom component. If are supposed to implement models (e.g. by extending abstract models) listeners (e.g. by extending adapters) but that's it. You don't need/have to extend swing components usually and you better not do it as it makes your code tied to implementation of superclass.",java gui design-patterns swing138793,A,"How do I add a separator to a JComboBox in Java? I have a JComboBox and would like to have a separator in the list of elements. How do I do this in Java? A sample scenario where this would come in handy is when making a combobox for font-family-selection; similar to the font-family-selection-control in Word and Excel. In this case I would like to show the most-used-fonts at the top then a separator and finally all font-families below the separator in alphabetical order. Can anyone help me with how to do this or is this not possible in Java? By the time I wrote and tested the code below you probably got lot of better answers... I don't mind as I enjoyed the experiment/learning (still a bit green on the Swing front). [EDIT] Three years later I am a bit less green and I took in account the valid remarks of bobndrew. I have no problem with the key navigation that just works (perhaps it was a JVM version issue?). I improved the renderer to show highlight though. And I use a better demo code. The accepted answer is probably better (more standard) mine is probably more flexible if you want a custom separator... The base idea is to use a renderer for the items of the combo box. For most items it is a simple JLabel with the text of the item. For the last recent/most used item I decorate the JLabel with a custom border drawing a line on its bottom. import java.awt.*; import javax.swing.*; @SuppressWarnings(""serial"") public class TwoPartsComboBox extends JComboBox { private int m_lastFirstPartIndex; public TwoPartsComboBox(String[] itemsFirstPart String[] itemsSecondPart) { super(itemsFirstPart); m_lastFirstPartIndex = itemsFirstPart.length - 1; for (int i = 0; i < itemsSecondPart.length; i++) { insertItemAt(itemsSecondPart[i] i); } setRenderer(new JLRenderer()); } protected class JLRenderer extends JLabel implements ListCellRenderer { private JLabel m_lastFirstPart; public JLRenderer() { m_lastFirstPart = new JLabel(); m_lastFirstPart.setBorder(new BottomLineBorder()); // m_lastFirstPart.setBorder(new BottomLineBorder(10 Color.BLUE)); } @Override public Component getListCellRendererComponent( JList list Object value int index boolean isSelected boolean cellHasFocus) { if (value == null) { value = ""Select an option""; } JLabel label = this; if (index == m_lastFirstPartIndex) { label = m_lastFirstPart; } label.setText(value.toString()); label.setBackground(isSelected ? list.getSelectionBackground() : list.getBackground()); label.setForeground(isSelected ? list.getSelectionForeground() : list.getForeground()); label.setOpaque(true); return label; } } } Separator class can be thick with custom color etc. import java.awt.*; import javax.swing.border.AbstractBorder; /** * Draws a line at the bottom only. * Useful for making a separator in combo box for example. */ @SuppressWarnings(""serial"") class BottomLineBorder extends AbstractBorder { private int m_thickness; private Color m_color; BottomLineBorder() { this(1 Color.BLACK); } BottomLineBorder(Color color) { this(1 color); } BottomLineBorder(int thickness Color color) { m_thickness = thickness; m_color = color; } @Override public void paintBorder(Component c Graphics g int x int y int width int height) { Graphics copy = g.create(); if (copy != null) { try { copy.translate(x y); copy.setColor(m_color); copy.fillRect(0 height - m_thickness width - 1 height - 1); } finally { copy.dispose(); } } } @Override public boolean isBorderOpaque() { return true; } @Override public Insets getBorderInsets(Component c) { return new Insets(0 0 m_thickness 0); } @Override public Insets getBorderInsets(Component c Insets i) { i.left = i.top = i.right = 0; i.bottom = m_thickness; return i; } } Test class: import java.awt.*; import java.awt.event.*; import javax.swing.*; @SuppressWarnings(""serial"") public class TwoPartsComboBoxDemo extends JFrame { private TwoPartsComboBox m_combo; public TwoPartsComboBoxDemo() { Container cont = getContentPane(); cont.setLayout(new FlowLayout()); cont.add(new JLabel(""Data: "")) ; String[] itemsRecent = new String[] { ""ichi"" ""ni"" ""san"" }; String[] itemsOther = new String[] { ""one"" ""two"" ""three"" }; m_combo = new TwoPartsComboBox(itemsRecent itemsOther); m_combo.setSelectedIndex(-1); cont.add(m_combo); m_combo.addActionListener(new ActionListener() { public void actionPerformed(ActionEvent ae) { String si = (String) m_combo.getSelectedItem(); System.out.println(si == null ? ""No item selected"" : si.toString()); } }); // Reference to check we have similar behavior to standard combo JComboBox combo = new JComboBox(itemsRecent); cont.add(combo); } /** * Start the demo. * * @param args the command line arguments */ public static void main(String[] args) { // turn bold fonts off in metal UIManager.put(""swing.boldMetal"" Boolean.FALSE); SwingUtilities.invokeLater(new Runnable() { public void run() { JFrame demoFrame = new TwoPartsComboBoxDemo(); demoFrame.setTitle(""Test GUI""); demoFrame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); demoFrame.setSize(400 100); demoFrame.setVisible(true); } }); } } C++ braces traitor! ;) :-D Not really C++ specific actually. I first used K&R style when I read their C book years ago then I chose to align braces for better readability (for me question of taste) and never came back (except on projects requiring them of course). @bobndrew: hey! As I wrote I was a newbie at the time (3 years already!). Among sins you don't point out I probably used some Swing test template I found and even worse I didn't use SwingUtilities.invokeLater! The code I have currently uses it at least (but it is still a JFrame subclass...). And m_lastRecentIndex is more local... But most of your criticism is about a quickly made test class which isn't really production code. Today I pay more attention to such code as newbies can take inspiration from it... :-) Also you are right about highlighting hovered elements and selection. TODO Your variable-naming is not the worst thing here: You're breaking the whole combobox-item-selection: the selection is not painted anymore and the first-letter-key-jumps are broken. And you should define `m_combo` and `m_renderer` in the smallest possible scope (in `public TestGui()`). And should not use a glooooobal `m_lastRecentIndex` for the Renderer **and** the 'TestGui' class (which should be a lonely Main class not a 'JFrame' subclass). But I like the braces-style! Note: I edited the code above for a more modern / correct version. One advantage of my approach is that it is more flexible (in look at least) than JSeparator and it doesn't take a slot.  You can use a custom ListCellRenderer which would draw the separator items differently. See docs and a small tutorial.  There is a pretty short tutorial with an example that shows how to use a custom ListCellRenderer on java2s http://www.java2s.com/Code/Java/Swing-Components/BlockComboBoxExample.htm Basically it involves inserting a known placeholder in your list model and when you detect the placeholder in the ListCellRenderer you return an instance of 'new JSeparator(JSeparator.HORIZONTAL)' The `BlockComboBoxExample` example breaks the cursor-key and the first-letter-key navigation. Santhosh Kumar's [example](http://www.jroller.com/santhosh/entry/jcombobox%5Fitems%5Fwith%5Fseparators) seems to work better.",java swing446056,A,"Can I use two different look and feels in the same Swing application? I'm using the Flamingo ribbon and the Substance Office 2007 look and feel. Of course now every control has this look and feel even those on dialog boxes. What I want is something like in Office 2007 where the ribbons have their Office 2007 look but other controls keep their native Vista/XP look. Is it possible to assign certain controls a different look and feel? Perhaps using some kind of chaining or a proxy look and feel? Here is a library which will automaticaly change the look and feel. I am not sure it this will done for every component in a different way but you should take a look at it. pbjar.org This book should be useful if you want to go deep into look and feel /java-look-and-feel-design-guidelines-second-edition I would be glad to see some code example if someone can write it feel free to get starting. EDIT: In this forum thread Thread i found the following description Swing uses a Look & Feel (a PLAF). PLAFs aren't attached on a per-JFrame level. They are attached on a per-VM level. It is almost impossible to mix PLAFs within one application. I have seen a few attempts all failed. It's actually per-AppContext. You should be able to have applets on different sites having different PL&Fs installed.  Swing unfortunately does lots of ""psuedo-global"" things behind the scenes. AFAIK the only way to do it consistently is to use the private AppContext API. Each AppContext has its own event dispatch thread and other ""psuedo-globals"".  I just discovered: Since Substance 5.0 the SKIN_PROPERTY is available. It allows assigning different skins to different JRootPanes (i.e. JDialog JFrame JInternalFrame) A little trick: I override JInternalFrame to remove the extra border and the title pane so that it looks just like a borderless panel. That way it is possible to create the impression that different parts of a form/dialog have different looks.",java swing look-and-feel substance218155,A,"How do I change JPanel inside a JFrame on the fly? To put it simple there's a simple java swing app that consists of JFrame with some components in it. One of the components is a JPanel that is meant to be replaced by another JPanel on user action. So what's the correct way of doing such a thing? I've tried panel = new CustomJPanelWithComponentsOnIt(); parentFrameJPanelBelongsTo.pack(); but this won't work. What would you suggest? I suggest you to add both panel at frame creation then change the visible panel by calling setVisible(true/false) on both. When calling setVisible the parent will be notified and asked to repaint itself.  frame.setContentPane(newContents()); frame.revalidate(); // frame.pack() if you want to resize. Remember Java use 'copy reference by value' argument passing. So changing a variable wont change copies of the reference passed to other methods. Also note JFrame is very confusing in the name of usability. Adding a component or setting a layout (usually) performs the operation on the content pane. Oddly enough getting the layout really does give you the frame's layout manager. Tom thanks for your reply. I'm not aiming to replace the contentpane just a jpanel placed on it (like frame.add(jpanel1) frame.add(jpanel2) frame.add(jpanel3)). Could you plz suggest a sane solution in code? Hey John Your use case seems perfect for CardLayout. http://java.sun.com/docs/books/tutorial/uiswing/layout/card.html In card layout you can add multiple panels in the same place but then show or hide one panel at a time. @swapnonil: Make that an answer so I can vote it up. :) You may run into problems when using the setContentPane() method. I had cases where all (custom) cursors not showing up anymore after calling it.  1) Setting the first Panel: JFrame frame=new JFrame(); frame.getContentPane().add(new JPanel()); 2)Replacing the panel: frame.getContentPane().removeAll(); frame.getContentPane().add(new JPanel()); Also notice that you must do this in the Event's Thread to ensure this use the SwingUtilities.invokeLater or the SwingWorker  class Frame1 extends javax.swing.JFrame { remove(previouspanel); //or getContentPane().removeAll(); add(newpanel); //or setContentPane(newpanel); invalidate(); validate(); // or ((JComponent) getContentPane()).revalidate(); repaint(); //DO NOT FORGET REPAINT } Sometimes you can do the work without using the revalidation and sometimes without using the repaint.My advise use both.  The other individuals answered the question. I want to suggest you use a JTabbedPane instead of replacing content. As a general rule it is bad to have visual elements of your application disappear or be replaced by other content. Certainly there are exceptions to every rule and only you and your user community can decide the best approach.  I was having exactly the same problem!! Increadible!! The solution I found was: Adding all the components (JPanels) to the container; Using the setVisible(false) method to all of them; On user action setting setVisible(true) to the panel I wanted to show. // Hiding all components (JPanels) added to a container (ex: another JPanel) for (Component component : this.container.getComponents()) { component.setVisible(false); } // Showing only the selected JPanel the one user wants to see panel.setVisible(true); No revalidate() no validate() no CardLayout needed.  On the user action: // you have to do something along the lines of myJFrame.getContentPane().removeAll() myJFrame.getContentPane().invalidate() myJFrame.getContentPane().add(newContentPanel) myJFrame.getContentPane().revalidate() Then you can resize your wndow as needed.  Your use case seems perfect for CardLayout. In card layout you can add multiple panels in the same place but then show or hide one panel at a time. When using CardLayout keep in mind that the preferred size for the panel that uses it will be the size of the LARGEST panel in the layout. If you want the space to be reclaimed you will want to use setVisible(false) and setPreferredSize( new Dimension( 00 ) ) to hide a component. I hadn't heard of CardLayout before. Thanks - was perfect for something I needed to do.  Hope this piece of code give you an idea of changing jPanels inside a JFrame. public class PanelTest extends JFrame { Container contentPane; public PanelTest() { super(""Changing JPanel inside a JFrame""); contentPane=getContentPane(); } public void createChangePanel() { contentPane.removeAll(); JPanel newPanel=new JPanel(); contentPane.add(newPanel); System.out.println(""new panel created"");//for debugging purposes validate(); setVisible(true); } }  Problem: My component does not appear after I have added it to the container. You need to invoke revalidate and repaint after adding a component before it will show up in your container. Source: http://docs.oracle.com/javase/tutorial/uiswing/layout/problems.html  Just call the method pack() after setting the ContentPane (java 1.7 maybe older) like this: JFrame frame = new JFrame(); JPanel panel1 = new JPanel(); JPanel panel2 = new JPanel(); .... frame.setContentPane(panel1); frame.pack(); ... frame.setContentPane(panel2); frame.pack(); ...  It all depends on how its going to be used. If you will want to switch back and forth between these two panels then use a CardLayout. If you are only switching from the first to the second once and (and not going back) then I would use telcontars suggestion and just replace it. Though if the JPanel isn't the only thing in your frame I would use remove(java.awt.Component) instead of removeAll. If you are somewhere in between these two cases its basically a time-space tradeoff. The CardLayout will save you time but take up more memory by having to keep this whole other panel in memory at all times. But if you just replace the panel when needed and construct it on demand you don't have to keep that meory around but it takes more time to switch. Also you can try a JTabbedPane to use tabs instead (its even easier than CardLayout because it handles the showing/hiding automitically)",java swing jpanel layout-manager cardlayout416947,A,"Swing components are light-weight? Whenever I read about Swing they say they are light weight components. So I just googled Swing and found that it means Swing does not depend on native peers. Is that why they are called ""light weight""? I mean by light weight I thought maybe the Swing components occupy less memory than the AWT components. Isn't that so? Lightweight vs heavyweight is a question of how the UI components are implemented. Heavyweight components wrap operating system objects lightweight components don't. They are implemented strictly in the JDK. what can you say about the memory the components occupy pal ? do the swing components occupy less memory ? It's hard to say. Lightweight components may occupy more simply because the operating system handles some of the stuff with heavyweight components. Or the overhead of OS objects might be huge. Or simply interfacing those objects might have a huge overhead. In addition to this it highly depends on the LAF (Look & Feel) you use. This is one other advantage of Swing: you can change LAF in just a few lines of code.  Swing is considered lightweight because it is fully implemented in Java without calling the native operating system for drawing the graphical user interface components. On the other hand AWT (Abstract Window Toolkit) is heavyweight toolkit as it merely makes calls to the operating system in order to produce its GUI components. The Evolution of the Swing Paint System section from the Painting in AWT and Swing article explains the difference between lightweight and heavyweight: When the original AWT API was developed for JDK 1.0 only heavyweight components existed (""heavyweight"" means that the component has it's own opaque native window). This allowed the AWT to rely heavily on the paint subsystem in each native platform. [...] With the introduction of lightweight components in JDK 1.1 (a ""lightweight"" component is one that reuses the native window of its closest heavyweight ancestor) the AWT needed to implement the paint processing for lightweight components in the shared Java code. As Swing is implemented in Java it does have some performance disadvantage however I hear that performance has improved in recent releases of Java. The advantage of Swing is that it has many more components available such as JTable and JList which are more graphical and extensible than the components provided in AWT allowing for more graphics-rich applications to be developed. i agree that there are too many cool things with swing - especially the tooltips and icons . In Java 6 the Windows look-and-feel delegates to the OS to draw the lightweight components (see http://weblogs.java.net/blog/chet/archive/2006/02/these_are_some.html).",java swing awt297938,A,"""Always on Top"" Windows with Java In Java is there a way to have a window that is ""Always on top"" regardless if the user switches focus to another application? I've searched the web and all of the solutions lean to some sort of JNI interface with native bindings. Truly this can't be the only way to do it?.. or is it? Try this method of the Window class: Window.setAlwaysOnTop(boolean) It works the same way as the default in the Windows TaskManager: switch to another app but it shows always on top. This was added in Java 1.5 Sample code: import javax.swing.JFrame; import javax.swing.JLabel; public class Annoying { public static void main(String[] args) { JFrame frame = new JFrame(""Hello!!""); // Set's the window to be ""always on top"" frame.setAlwaysOnTop( true ); frame.setLocationByPlatform( true ); frame.add( new JLabel("" Isn't this annoying?"") ); frame.pack(); frame.setVisible( true ); } } Window remains on top even when is not active you would think a simple search for ""java application always on top"" on would have this answer but it couldn't find it. Thanks. Guess what. Now it does!! :) It brings you here! http://www.google.com/search?&q=java+application+always+on+top This is simple and awesome. I was also looking for something like this but didn't know they implemented this in Java 1.5. Thanks for posting. Unfortunately this does not work for me when running a full screen application such as a video game. Anyone know of a way to force it to the top in that situation? @Dream lane I'd probably ask that as a new question This works for a login dialog box but my main application window then goes to the background. I'm open to suggestions. +1 for nothing more than the ""Isn't this annoying"" quip. @MMJZ haha true. Actually I'm surprised I didn't do it for the `args` declaration. I **always** use space after parenthesis. This is a very very old habit that I develop back in the days I used notepad to program. Double clicking on a word would select the parenthesis if there is no space between which was very annoying because I had to delete them afterwards if what I intended to do was re-use the variable somewhere else. This is like the first code I've seen anywhere ever that pads out boolean parameters with spaces.  From my observation I found that AlwaysOnTop privilege is given to the latest process which requested to be always on top. So if you have an application which setAlwaysOnTop(true) and later another application uses this option the privilege is given to the second application. In order to work around this I have set the setAlwaysOnTop(false) and again setAlwaysOnTop(true) whenever any window comes on top of the current window. I've checked it with wordweb in windows. WordWeb is one of the applications which uses AlwaysOnTop option from the OS I'm not sure about if it works properly with your game scenario. Warning: I'm not aware of the side effects. Here is the code example: import java.awt.event.*; import javax.swing.*; public class MainWindow extends JFrame implements WindowFocusListener { public MainWindow() { addWindowFocusListener(this); setAlwaysOnTop(true); this.setFocusable(true); // this.setFocusableWindowState(true); panel = new JPanel(); //setSize(WIDTHHEIGHT); setUndecorated(true); setLocation(XY); setExtendedState(MAXIMIZED_BOTH); setVisible(true); } public void windowGainedFocus(WindowEvent e){} public void windowLostFocus(WindowEvent e) { if(e.getNewState()!=e.WINDOW_CLOSED){ //toFront(); //requestFocus(); setAlwaysOnTop(false); setAlwaysOnTop(true); //requestFocusInWindow(); System.out.println(""focus lost""); } } private JPanel panel; private static final int WIDTH = 200; private static final int HEIGHT = 200; private static final int X = 100; private static final int Y = 100; public static void main(String args[]){ new MainWindow();} }",java gui swing awt295649,A,Adding rows to a JTable We have a simple project where we read data from a socket and we want to populate a table with the coming data but we can't find a way to add rows to a yet created JTable object we can only find how to add rows at creation time of the table. Is it possible to add rows dynamically to a JTable or there is a better alternative object to deal with this way of showing data? EDIT: Thanks a lot for your answers. All three of them look very promising but I have to choose only one and I think the best is Guillaume's. You should create a custom TableModel. A JTable doesn't actually store the rows it always delegates that to a TableModel. To help you implementing it you should make use of AbstractTableModel. Don't forget to call fireTableRowsInserted() every time you add rows. For better performances if you add a lot of rows try to batch the updates and add many rows at a time.  If you use the default table model for a JTable then you can add rows with following code  if ( dest+1 < table.getRowCount()-1 ) ( (DefaultTableModel) table.getModel() ).insertRow(dest+1 getValuesForNewRow()); else ( (DefaultTableModel) table.getModel() ).addRow(getValuesForNewRow()); It's best to just keep hold of the DefaultTableModel before passing it to the JTable constructor. Then you don't need to touch the JTable or do any casting.  Once you start dynamically adding and removing elements from a JTable you really need to start using a TableModel. See the Java Tutorial for more details.,java swing225108,A,Resize a JPanel in line with a JDialog I've got a JDialog which contains a series of JPanels in a CardLayout. Some of these panels contain JTables which I would like to be resized in line with any resizing of the JDialog. I am not sure how to achieve this and any help would be greatly appreciated. At present the tables simply remain their current size and do not scale. I'm sure its something simple but I'm having trouble locating the exact approach needed. Many thanks in advance. I will provide any more information if required. edit: The JDialog is used as a wizard so only one of the panels is being displayed at any one time hence the use of CardLayout. I would ideally like to keep this is layout manager although if it is the source of the problems then obviously I would rethink! You can keep the CardLayout but you need to do the following: 1. set the layout of your JDialog to BorderLayout and add a new JPanel (contentPanel) to the JDialog 2. now set this contentPanel layout to be CardLayout 3. add your other panels to the cardlayout as required. 4. Also make sure off the layouts you use on each of the panels you're adding to the CardLayout. By default JPanel uses FlowLayout I think and this is not ideal for a JTable. So you might need to play around with the layout of the panel containing the table as well; try out BoxLayout or BorderLayout for that as well.,java swing resize jdialog354745,A,"JAVA Swing GUI Components howto RTL view? How can i make my Java Swing GUI Components [Right To Left] for Arabic language from NetBeans Desktop Application? Do yo mean how to display text in a JLabel for instance? you could use it if you have components inside panels inside contentPane  Component[] component = contentPane.getComponents(); for(int i=0; i<component.length; i++){ component[i].applyComponentOrientation(ComponentOrientation.RIGHT_TO_LEFT); Component[] cp = ((Container) component[i]).getComponents(); for(int j=0; j<cp.length; j++){ try{ ((Component) ((JComboBox) cp[j]).getRenderer()).applyComponentOrientation(ComponentOrientation.RIGHT_TO_LEFT); }catch(Exception e){ continue; } } }  Don't you just have to use: Component.setComponentOrientation( ComponentOrientation.RIGHT_TO_LEFT ) I believe that the swing components all already have support for RTL don't they? Not sure how/where you'd do that in regards to netbeans though. There's also Component.applyComponentOrientation(..) to change a whole component tree.  You could use alignment but that would not handle the complexities if you have English letters or numbers embedded within your text. It might be preferable to use some sort of styled text widget or even an embedded HTML/rich text viewer. I don't think that standard JLabels can handle the complexities otherwise. JLabel display unicode letters. I think they relay on the system fonts and if the system fonts can display the letter then everything it's ok. For instance in my comp I can write ""Extra’±o""  The call of  Component.setComponentOrientation( ComponentOrientation.RIGHT_TO_LEFT ) should do the trick. But be sure to use the SwingConstants LEADING and TRAILING instead of LEFT and RIGHT in your layouts. The same goes for GridBagConstraints.LINE_START or LINE_END instead of WEST or EAST and probably some similar cases which I forgot to mention. That's a great answer the information about using the more meaningful alignment constants may not be a given to others having trouble with this.",java swing right-to-left477663,A,Is it possible to set a TitledBorder opaque on Swing? Is it somehow possible on Swing to set a TitledBorder transparent so that a background image shines through? Thanks for the hint got confused within my own thoughts :) Strange - TitledBorder.isBorderOpaque() supposedly returns false so it should already work. Maybe the problem is just that the component you're putting the border on just doesn't paint the background image over the border insets?  Found the answer. Use the method setOpaque(false) on the underlying panel.,java swing opacity titled-border242896,A,Problem with Swing GUI on Macintosh I am new to Swing. Are there any specific issues related to customizing the paint operation on the Mac? I have developed a sample application using NetBeans + Swing on Windows. It is working fine. But if I run the same application on a Mac panels' buttons' labels don't appear on the screen. Only when the mouse over operation is performed on particular component does it get displayed on the screen. Kindly can anyone help me out in solving this issue? Thanks in advance. sakkiharry Since Swing paints all UI itself it is not really influenced by Mac OS. There are exceptions though. If you allow Java to use a native menu the menu will behave like any other Swing menu but it is in fact translated to native menu functions (so it will be displayed on top of screen and behave like a native Mac OS X menu... nothing you as programmer need to care about but great for Mac users who hate menus to appear elsewhere). I guess your issue is probably something else but it's hard to guess if I have no code to work with. Can you break down the issue into an ultra minimal test case? E.g. can you just draw a JFrame add a singe one of your custom buttons there that shows the problematic behavior and just use as much code as is necessary to paint this minimal UI and expose the problem? If you'd post this code here I'd take a closer look into it and will try to find out what causes the issue and how to resolve it (I'm a graduated Java programmer but I also have years of Mac OS X development experience; so these are two fields of knowledge I should know really well but I usually don't combine them as I don't develop in Java for Mac OS X).,java osx swing netbeans33708,A,"My (Java/Swing) MouseListener isn't listening help me figure out why So I've got a JPanel implementing MouseListener and MouseMotionListener: import javax.swing.*; import java.awt.*; import java.awt.event.*; public class DisplayArea extends JPanel implements MouseListener MouseMotionListener { public DisplayArea(Rectangle bounds Display display) { setLayout(null); setBounds(bounds); setOpaque(false); setPreferredSize(new Dimension(bounds.width bounds.height)); this.display = display; } public void paintComponent(Graphics g) { Graphics2D g2 = (Graphics2D)g; if (display.getControlPanel().Antialiasing()) { g2.addRenderingHints(new RenderingHints(RenderingHints.KEY_ANTIALIASING RenderingHints.VALUE_ANTIALIAS_ON)); } g2.setColor(Color.white); g2.fillRect(0 0 getWidth() getHeight()); } public void mousePressed(MouseEvent event) { System.out.println(""mousePressed()""); mx1 = event.getX(); my1 = event.getY(); } public void mouseReleased(MouseEvent event) { System.out.println(""mouseReleased()""); mx2 = event.getX(); my2 = event.getY(); int mode = display.getControlPanel().Mode(); switch (mode) { case ControlPanel.LINE: System.out.println(""Line from "" + mx1 + "" "" + my1 + "" to "" + mx2 + "" "" + my2 + "".""); } } public void mouseEntered(MouseEvent event) { System.out.println(""mouseEntered()""); } public void mouseExited(MouseEvent event) { System.out.println(""mouseExited()""); } public void mouseClicked(MouseEvent event) { System.out.println(""mouseClicked()""); } public void mouseMoved(MouseEvent event) { System.out.println(""mouseMoved()""); } public void mouseDragged(MouseEvent event) { System.out.println(""mouseDragged()""); } private Display display = null; private int mx1 = -1; private int my1 = -1; private int mx2 = -1; private int my2 = -1; } The trouble is none of these mouse functions are ever called. DisplayArea is created like this: da = new DisplayArea(new Rectangle(CONTROL_WIDTH 0 DISPLAY_WIDTH DISPLAY_HEIGHT) this); I am not really a Java programmer (this is part of an assignment) but I can't see anything glaringly obvious. Can someone smarter than I see anything? I don't see anywhere in the code where you call addMouseListener(this) or addMouseMotionListener(this) for the DisplayArea in order for it to subscribe to those events.  The implements mouselistener mousemotionlistener just allows the displayArea class to listen to some to be defined Swing component's mouse events. You have to explicitly define what it should be listening at. So I suppose you could add something like this to the constructor: this.addMouseListener(this); this.addMouseMotionListener(this);  I don't see any code here to register to the mouse listeners. You have to call addMouseListener(this) and addMouseMotionListener(this) on the DisplayArea.",java swing309023,A,"How to bring a window to the front? We have a Java-application that needs to be brought to the foreground when a telecontrol mechanism activates something in the application. In order to get this we have realised in the called method of the Class which represents the Frame of our application (extension of a JFrame) following implementation: setVisible(true); toFront(); Under Windows XP this works the first time it is called on the second time only the tab in the taskbar flashes the frame doesn't come to the front anymore. Same goes for Win2k. On Vista it seems to work fine. Anyone ideas? do you have a sample for this behavior? The proper answer is to call `toFront()` on the EDT using `invokeLater`. There is a simple answer included below but it is not the accepted answer. It does work though. Perfectly. I know this is old but this also happens on OSX I'm experiencing this problem but none of the answers below seems to solve it. I'm sure it's caused by windows not allowing me to 'Steal' Focus for my first window in the application. Here's a method that REALLY works (tested on Windows Vista) :D  frame.setExtendedState(JFrame.ICONIFIED); frame.setExtendedState(fullscreen ? JFrame.MAXIMIZED_BOTH : JFrame.NORMAL); The fullscreen variable indicates if you want the app to run full screen or windowed. This does not flash the task bar but bring the window to front reliably. Thanks for the setExtendedState tip. I used it along with the toFront() and repaint() solution to bring the window to the foreground even if it was minimized. Confirmed: this solution works in WindowsXP using toFront results in flashing message in task bar. Thanks!  Simplest way I've found that doesn't have inconsistency across platforms: setVisible(false); setVisible(true); causes some blinking though doesn't it? nice and simple though :) did not work for my background process. Also window comes up white for the first refresh if called from foreground process. Can't use for screen grabs.  Windows has the facility to prevent windows from stealing focus; instead it flashes the taskbar icon. In XP it's on by default (the only place I've seen to change it is using TweakUI but there is a registry setting somewhere). In Vista they may have changed the default and/or exposed it as a user accessible setting with the out-of-the-box UI. Preventing windows from forcing themselves to the front and taking focus is a feature since Windows 2K (and I for one am thankful for it). That said I have a little Java app I use to remind me to record my activities while working and it makes itself the active window every 30 minutes (configurable of course). It always works consistently under Windows XP and never flashes the title bar window. It uses the following code called in the UI thread as a result of a timer event firing: if(getState()!=Frame.NORMAL) { setState(Frame.NORMAL); } toFront(); repaint(); (the first line restores if minimized... actually it would restore it if maximized too but I never have it so). While I usually have this app minimized quite often it's simply behind my text editor. And like I said it always works. I do have an idea on what your problem could be - perhaps you have a race condition with the setVisible() call. toFront() may not be valid unless the window is actually displayed when it is called; I have had this problem with requestFocus() before. You may need to put the toFront() call in a UI listener on a window activated event. 2014-09-07: At some point in time the above code stopped working perhaps at Java 6 or 7. After some investigation and experimentation I had to update the code to override the window's toFront method do this (in conjunction with modified code from what is above): setVisible(true); toFront(); requestFocus(); repaint(); ... public @Override void toFront() { int sta=super.getExtendedState()&~JFrame.ICONIFIED&JFrame.NORMAL; super.setExtendedState(sta); super.setAlwaysOnTop(true); super.toFront(); super.requestFocus(); super.setAlwaysOnTop(false); } As of Java 8_20 this code seems to be working fine. +1 for supporting not allowing windows to steal the focus. I hate when that happens when I'm typing in a document. I completely agree with you against stealing focus but in this precise case the user expects the application to come to the front. But it would uncool to change the registry settings and change the complete windows behavior.  This simple method worked for me perfectly in Windows 7:  private void BringToFront() { java.awt.EventQueue.invokeLater(new Runnable() { @Override public void run() { if(jFrame != null) { jFrame.toFront(); jFrame.repaint(); } } }); }  Hj all methods of yours are not working for me in Fedora KDE 14. I have a dirty way to do bring a window to front while we're waiting for Oracle to fix this issue. import java.awt.MouseInfo; import java.awt.Point; import java.awt.Robot; import java.awt.event.InputEvent; public class FrameMain extends javax.swing.JFrame { //... private final javax.swing.JFrame mainFrame = this; private void toggleVisible() { setVisible(!isVisible()); if (isVisible()) { toFront(); requestFocus(); setAlwaysOnTop(true); try { //remember the last location of mouse final Point oldMouseLocation = MouseInfo.getPointerInfo().getLocation(); //simulate a mouse click on title bar of window Robot robot = new Robot(); robot.mouseMove(mainFrame.getX() + 100 mainFrame.getY() + 5); robot.mousePress(InputEvent.BUTTON1_DOWN_MASK); robot.mouseRelease(InputEvent.BUTTON1_DOWN_MASK); //move mouse to old location robot.mouseMove((int) oldMouseLocation.getX() (int) oldMouseLocation.getY()); } catch (Exception ex) { //just ignore exception or you can handle it as you want } finally { setAlwaysOnTop(false); } } } //... } And this works perfectly in my Fedora KDE 14 :-) I love it. Thanks for this one. A little hacky works for us but only for the first call :-). (Kubuntu 12.04) - other solution did fail  The rules governing what happens when you .toFront() a JFrame are the same in windows and in linux : -> if a window of the existing application is currently the focused window then focus swaps to the requested window -> if not the window merely flashes in the taskbar BUT : -> new windows automatically get focus So let's exploit this ! You want to bring a window to the front how to do it ? Well : Create an empty non-purpose window Show it Wait for it to show up on screen (setVisible does that) When shown request focus for the window you actually want to bring the focus to hide the empty window destroy it Or in java code : // unminimize if necessary this.setExtendedState(this.getExtendedState() & ~JFrame.ICONIFIED); // don't blame me blame my upbringing // or better yet blame java ! final JFrame newFrame = new JFrame(); newFrame.add(new JLabel(""boembabies is this in front ?"")); newFrame.pack(); newFrame.setVisible(true); newFrame.toFront(); this.toFront(); this.requestFocus(); // I'm not 100% positive invokeLater is necessary but it seems to be on // WinXP. I'd be lying if I said I understand why SwingUtilities.invokeLater(new Runnable() { @Override public void run() { newFrame.setVisible(false); } }); Didn't work on Win7 both windows flash (if I don't hide the 2nd). Creative. Didn't work for my background process on Win7 when covered. New frame does not come up on top. Older JDK 6u21.  A possible solution is: java.awt.EventQueue.invokeLater(new Runnable() { @Override public void run() { myFrame.toFront(); myFrame.repaint(); } }); +1 WORKS! Simple to the point. Perhaps one should start ALL the UI code inside invokeLater in first place? ;) Did not work for me in Java 7 on KDE 4.9.5 the window would still hide below other programs. What helped me was changing the order of bringing windows to the front. Instead of hiding one window and show the second window show the second window and then hide the first window (JFrame).  I tested your answers and only Stefan Reich's one worked for me. Although I couldn't manage to restore the window to its previous state (maximized/normal). I found this mutation better: view.setState(java.awt.Frame.ICONIFIED); view.setState(java.awt.Frame.NORMAL); That is setState instead of setExtendedState.  There are numerous caveats in the javadoc for the toFront() method which may be causing your problem. But I'll take a guess anyway when ""only the tab in the taskbar flashes"" has the application been minimized? If so the following line from the javadoc may apply: ""If this Window is visible brings this Window to the front and may make it the focused Window.""  I had the same problem with brining a frame to the front under Ubuntu (Java 1.6.0_10). And the only way I could resolve it is by providing a window listener. Specifically I had to set frame to always stay on top whenever toFront is invoked and provide windowDeactivated event handler to setAlwaysOnTop(false). So here is the code that could be placed into a base frame which is used to derive all application frames. @Override public void setVisible(final boolean visible) { // make sure that frame is marked as not disposed if it is asked to be visible if (visible) { setDisposed(false); } // let's handle visibility... if (!visible || !isVisible()) { // have to check this condition simply because super.setVisible(true) invokes toFront if frame was already visible super.setVisible(visible); } // ...and bring frame to the front.. in a strange and weird way if (visible) { int state = super.getExtendedState(); state &= ~JFrame.ICONIFIED; super.setExtendedState(state); super.setAlwaysOnTop(true); super.toFront(); super.requestFocus(); super.setAlwaysOnTop(false); } } @Override public void toFront() { super.setVisible(true); int state = super.getExtendedState(); state &= ~JFrame.ICONIFIED; super.setExtendedState(state); super.setAlwaysOnTop(true); super.toFront(); super.requestFocus(); super.setAlwaysOnTop(false); } Whenever frame should be displayed or brought to front call frame.setVisible(true). Since I moved to Ubuntu 9.04 there seems to be no need in having a window listener for invoking super.setAlwaysOnTop(false) -- as can be observed this code was moved to methods toFront and setVisible. Pls note that method setVisible should always be invoked on EDT. Worked under all circumstances so I accepted this one. Thanks! Also related is this question: http://stackoverflow.com/questions/2315560/how-do-you-force-a-java-swt-program-to-move-itself-to-the-foreground +1 Was very helpful Thanks! @ka3ak This is a protected setter that could be introduced in the suggested JFrame-base class in order to track the situation with frame being disposed. Method dispose() would need to be overridden with a call to setDisposed(true). This is not strictly speaking needed for everyone. It doesn't compile by me because of setDisposed() method. Can't be found. The `.setAlwaysOnTop(true);` was the only one that worked for me when using a JWindow. This may be the greatest the most important the most happy-making answer I've ever encountered on stack Overflow. Thanks for your service to mankind. This has been driving me NUTS.",java windows swing awt304874,A,What are good docking frameworks for Java/Swing? I'm looking for a good lightweight Java docking framework. I know that Netbeans and Eclipse can be used as RCP but I'm looking for something a little bit more lightweight. See a comprehensive list (with links) of over 10 docking frameworks here. Raven Docking Apache 2; 0.2 MB MyDoggy LGPL; only JARs: 0.7 MB; Dec 2010 VLDocking LGPL; 0.4 MB NetBeans CDDL/GPL; 4.6 MB (platform.zip) Eclipse CPL or EPL ? only swt (?) InfoNode GPL or Commercial Sanaware GPL or Commercial full zip 0.3MB Docking Frames LGPL; 3 MB Jide commercial; <3MB FlexDock MIT; 0.4 MB; Nov 2011 Inactive projects SwingDocking seems to me fully functional and fast; Apache license 2; Oct 2007 XUI will be further developed here?; MPL; 1.6 MB (XUI-jdk15.zip); Feb 2008 JDocking CDDL; 1.3 MB (v0.8.zip) the docking part of netbeans JRichClient GPL; derivation of flexdock; Nov 2007 [Infonode](http://www.infonode.net/index.html?idw); GPL or Commercial Flexdock 1.1 is actually 433 KB 1.6 MB is for the demo package (see the [download page](http://java.net/projects/flexdock/downloads)) Docking Frames is actually 3 MB these days only the oldest versions are anywhere near 0.7 MB.  See the infonode docking windows. They have a gpl version and a commercial version but the licenses are not that expensive. Robust and good looking if you select the right skin (we use the ShapedGradientDockingTheme which looks a little like eclipse). Do you know if it is actively developed? The last release is from over a year now... Well the company is still there so I think they are. I haven't seen increases in version numbers for a while though. Not expensive? A commercial Infonode docking license costs $6000! $6000 is for a site license single user is $300.  I've just released another docking framework. It's really lightweight and available under the Apache 2.0 license. Raven Docking: http://raven.java.net/ravenDocking/index.html  We use VLDocking from vlsolutions (http://vldocking.com) quite successfully in 3 of our products. They have some open-source license compatible with GPL.  JIDE has quite a few components including a docking framework. The core of JIDE is open source but they also have several commercial libraries. The docking framework is commercial. http://www.jidesoft.com/products/component.htm  I have successfully used FlexDock in the past but it seems not well supported and it is quite hard to start with (this is a quite complex framework for docking). FlexDock is open source. Besides more recently I have enjoyed using MyDoggy which is well supported and quite easy to use (very well documented with enough examples and tutorials). Its main drawback (for me) is the difficulty to adapt its look when using 3rd-party LAFs (like Substance for instance). But in general I really like it. If I remember correctly it is quite a lightweight library. I would recommend it for any use (it is open source and free to use) for its good API.  I once evaluated several docking frameworks (including the already mentioned flexdock and mydoggy and jdocking. Finaly I came to Docking Frames which I can really recommend. It is easy to use but still feature rich + good documentation and quick support from developer via forum. +1 docking frames is quite nice and its still supported updated just a few weeks ago After reviewing the list above and testing a few of the frameworks I decided to give Docking Frames a shot mainly because it seems like the most active project.,java swing frameworks docking260574,A,"Matisse in Eclipse I have just installed Eclipse 3.4 and found out that there is not a plugin to create Swing applications yet. I also have found that there is a Matisse implementation in MyEclipse IDE but I'd like to now whether there is such a Matisse plugin for free. I did a quick Google search and found that you could use Netbeans Matisse and Eclipse in parallel: NetBeans Wiki: UsingNetbeansMatisseAndEclipseInParallel It seems to basically involve building the Swing GUI in Netbeans and doing the other coding tasks from within Eclipse. Yeah I have being doing this. But this is not much practical unfortunately. I'll read the article you recommended.  there isnt one for free. myeclipse is the only way to run matisse inside eclipse.  Instatiations Swing Designer is the best in my opinion. We settled on it after trying may different Eclipse plugins. I didn't know it. Thank you very much for the recomendation. I'll try it. Instatiations Swing Designer is now [Google WindowBuilder Pro](https://developers.google.com/java-dev-tools/download-wbpro) ""Instatiations""? i just broke my tongue trying to pronounce that word  Although this is not a true answer to your question you may as well look at alternative solutions in terms of layout management: Matisse and GroupLayout are neither the only way nor the best one to define your GUI forms. I would suggest you take a look at: MigLayout (very powerful and quite simple) and DesignGridLayout (quite powerful and very simple) Both are open source and have a friendly license (not GPL). A quick search on Google will give you the links immediately. Disclaimer: I am one of DesignGridLayout both project owners but I point you to it because I'm convinced it provides a better way to define Swing layouts. No problem I'll check it. I mentioned Matisse because it's the best design I've knew so far but I'm open to alternatives as long as I can still work in eclipse. :-)",java eclipse swing eclipse-3.4 matisse396156,A,"Automatically size JPanel inside JFrame I have a JPanel subclass on which I add buutons labels tables etc. To show on screen it I use JFrame: MainPanel mainPanel = new MainPanel(); //JPanel subclass JFrame mainFrame = new JFrame(); mainFrame.setTitle(""main window title""); mainFrame.getContentPane().add(mainPanel); mainFrame.setLocation(100 100); mainFrame.pack(); mainFrame.setVisible(true); mainFrame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); But when I size the window size of panel don't change. How to make size of panel to be the same as the size of window even if it was resized? If the BorderLayout option provided by our friends doesnot work try adding ComponentListerner to the JFrame and implement the componentResized(event) method. When the JFrame object will be resized this method will be called. So if you write the the code to set the size of the JPanel in this method you will achieve the intended result. Ya I know this 'solution' is not good but use it as a safety net. ;)  You can set a layout manager like BorderLayout and then define more specifically where your panel should go: MainPanel mainPanel = new MainPanel(); JFrame mainFrame = new JFrame(); mainFrame.setLayout(new BorderLayout()); mainFrame.add(mainPanel BorderLayout.CENTER); mainFrame.pack(); mainFrame.setVisible(true); This puts the panel into the center area of the frame and lets it grow automatically when resizing the frame.  From my experience I used GridLayout.  thePanel.setLayout(new GridLayout(abcd)); a = row number b = column number c = horizontal gap d = vertical gap. For example if I want to create panel with: unlimited row (set a = 0) 1 column (set b = 1) vertical gap= 3 (set d = 3) The code is below:  thePanel.setLayout(new GridLayout(0103)); This method is useful when you want to add JScrollPane to your JPanel. Size of the JPanel inside JScrollPane will automatically changes when you add some components on it so the JScrollPane will automatically reset the scroll bar.  As other posters have said you need to change the LayoutManager being used. I always preferred using a GridLayout so your code would become: MainPanel mainPanel = new MainPanel(); JFrame mainFrame = new JFrame(); mainFrame.setLayout(new GridLayout()); mainFrame.pack(); mainFrame.setVisible(true); GridLayout seems more conceptually correct to me when you want your panel to take up the entire screen. What about BorderLayout.CENTER?.I think it can used mainly for these kind of cases.  You need to set a layout manager for the JFrame to use - This deals with how components are positioned. A useful one is the BorderLayout manager. Simply adding the following line of code should fix your problems: mainFrame.setLayout(new BorderLayout()); (Do this before adding components to the JFrame) Further reading . The important thing in this case is that a JFrame's default layout manager is FlowLayout.",java swing size jframe jpanel357562,A,"Java based Swing Browser should support JavaScript In my company I am implementing a java based html browser. I found a lot of tools to generate complete browsers only in Swing which are looking like Mozilla. But I was not able to find a browser which supports JavaScript. The browser I will implement should execute JavaScript inside the HTML sides. Do you know of a tool that supports this? Or do you know of a parser which pairs the javascript to something I can use inside the html browser? I know that the eclipse plugins can handle javascript but I can not use AWT in my project. Thanks for your help. I'd look at Lobo. It sounds like just want you want. It has a HTML Renderer and parser and some support for Javascript. If it's missing a feature of Javascript that you need it seems like it would easier to contribute to Lobo instead of reinventing the wheel. That sounds like a good solution. I will test this. Thanks Will you please tell me that how to implement this?  It will be available. I hope pretty soon. Its name is JWebPane and it is based on WebKit afaik. The interesting question is ""When"" Here's the link: http://weblogs.java.net/blog/ixmal/archive/2008/05/introducing_jwe.html News today: http://weblogs.java.net/blog/alex2d/archive/2008/12/jwebpane_projec.html  In my company I am implementing a java based html browser. Good God why? That said this page at java.net discusses some options; you could search it more extensively.  You don't want to build this yourself. Fortunately there are a number of open source javascript engines you might be able to adapt. add the moment the html sides are shown by using C++ and a firefox plugin but i should use the existing html sides which including javascript. I have no choice i have to show html with javascript. I'm not saying don't do it: I'm saying find someone else that's already done it and use that.",java javascript swing swt115277,A,"Fast search in java swing applications? I'm wandering myself what component is the best for displaying fast search results in swing. I want to create something like this make a text field where user can enter some text during his entering I'll improve in back end fast search on database and I want to show data bellow the text box and he will be able to browse the results and on pres enter result will be displayed in table. So my question is is there any component which already have this logic for displaying? Or is it's not what is the best way to implement that. This search will be something what ajax gives me on web same logic same look and feel if it's possible on desktop application. You will have to first attach a listener to the JTextFields Document to be notified whenever the user types in the field (or changes it). From there you can fire off any server-side code you need. The results of that can be used to update a listbox. A few things to keep in mind: The code to do the search against the backend must be in another thread The code that updates the list box should update the list box's model You will need to manage all your backend search results so that you only update the listbox with the most recent result (e.g. user types 'A' backenf searches for that. Meanwhile user has typed 'C' kicking off a backend search for 'AC'. You need to ensure the results from the 'A' search dont' make it to the listbox if the 'AC' search results are available).  It is possible of course. It is simple too. For drop down list of terms just use popup menu. This is simple. The background processing of entered text is simple too. Enjoy!  Use Hibernate Search. The SwingHack (http://oreilly.com/catalog/9780596009076/) book has an example of this.  In the interest of killing two birds with one stone: have a separate indexing thread. This will: Improve the speed of searches whenever they are executed. Improve the responsiveness of the UI since indexing is happening in a separate thread. Of course exactly how you perform the indexing will vary widely depending on your particular application. Here is a good place to start researching: Search Indexing. And please ignore the reference to Web 3.0 [sic].  Are you looking for something like an AutoComplete component for Java Swing? SwingX has such a component. See here for the JavaDoc. It has a lot of utility methods to do various things i.e. auto-completing a text box from the contents of a JList. Thanks for the tip. I downloaded the swingx classes and I tried: ArrayList nums = new ArrayList(); numsadd(new StringBuffer(""4000"")); nums.add(new StringBuffer(""5000"")); autoCompleteAdaptor = new TextComponentAdaptor(numsInputnums); where numsInput is a JTextField. I don't know what do I need to setup next. Do you happen to know where I can find a sample to get started ?  I strongly strongly recommend that you take a look at Glazed Lists - this is one of the finer open source Java libraries out there and it makes the bulk of what you are asking about super easy.",java swing search491726,A,can I build swing applications on eclipse? I used to work on netbeans to build Java applications but now: i am using eclipse. I was was wondering if there a a free good plug-in to help me with swing windows.?? I'm assuming you want a GUI designer. The best plug-in for this is the excellent Swing Designer. Definitely worth a look. Nope sorry. But it is worth the license. it is not free ??  Jigloo - CloudGarden(free non-commercial) Visual Editor Project AND JForm (pay) I think your third link is wrong. It looks like a domain parking site... cheers looks like they forgot to pay there bill...  JForm designer is a good swing designer but it is not free.  Jigloo is free for non-commercial use. There are others on the UI category at Eclipse Plugin Central.,java eclipse swing408820,A,"What is the difference between swing and awt? Can someone please explain me what's the difference between swing and awt? Are there any cases where awt is more useful/advised to use than swing or vice-versa? Related: http://stackoverflow.com/questions/2994304/is-java-swing-still-in-use/2994324#2994324 Swing: Swing is part of the java foundation classes. Swing components are platform-independent. Swing components are lightweight components because swing sits on the top of awt. AWT: AWT is called the abstract window tool. AWT components are platform-dependent. AWT components are heavyweight components.  As far as when AWT may be more useful than Swing - you may be targeting an older JVM or platform that doesn't support Swing. This used to really come into play if you were building Applets - you wanted to target the lowest common denominator so people wouldn't have to install a newer Java plugin. I'm not sure what the current most widely installed version of the Java plugin is - this may be different today. some people prefer the native look of AWT over Swing's 'not quite there' platform skins. (There are better 3rd party native looking skins than Swing's implementations BTW) Lots of people preferred using AWT's FileDialog over Swing's FileChooser because it gave the platform file dialog most people were used to rather than the 'weird' custom Swing one. But for the last one we can also create a FileChooser that pretty much looks like windows file dialog (but with no autocomplete) http://stackoverflow.com/q/17630055/2534090  swing component provide much flexible user interface because it follow model view controller(mvc). awt is not mvc based. swing works faster. awt does not work faster. swing componets are light weight. awt componentsare heavy weight. swing occupies less memory space. awt occupies more memory space. swing component is platform independent. awt is platform dependent. swing require javax.swing package. awt require javax.awt package. I don't think swing works faster than AWT because AWT uses native code (the gui code) that was already there in the OS but swing builds every component from the scratch. So AWT might be faster. Could you say me what is your point of view in saying **swing works faster**? Thanks.  Several consequences result from this difference between AWT and Swing. AWT is a thin layer of code on top of the OS whereas Swing is much larger. Swing also has very much richer functionality. Using AWT you have to implement a lot of things yourself while Swing has them built in. For GUI-intensive work AWT feels very primitive to work with compared to Swing. Because Swing implements GUI functionality itself rather than relying on the host OS it can offer a richer environment on all platforms Java runs on. AWT is more limited in supplying the same functionality on all platforms because not all platforms implement the same-looking controls in the same ways. Swing components are called ""lightweight"" because they do not require a native OS object to implement their functionality. JDialog and JFrame are heavyweight because they do have a peer. So components like JButton JTextArea etc. are lightweight because they do not have an OS peer. A peer is a widget provided by the operating system such as a button object or an entry field object. Great answer. Especially the **peer** no one discussed this. Thank you :)  AWT is a Java interface to native system GUI code present in your OS. It will not work the same on every system although it tries. Swing is a more-or-less pure-Java GUI. It uses AWT to create an operating system window and then paints pictures of buttons labels text checkboxes etc. into that window and responds to all of your mouse-clicks key entries etc. deciding for itself what to do instead of letting the operating system handle it. Thus Swing is 100% portable and is the same across platforms (although it is skinnable and has a ""pluggable look and feel"" that can make it look more or less like how the native windows and widgets would look). These are vastly different approaches to GUI toolkits and have a lot of consequences. A full answer to your question would try to explore all of those. :) Here are a couple: AWT is a cross-platform interface so even though it uses the underlying OS or native GUI toolkit for its functionality it doesn't provide access to everything that those toolkits can do. Advanced or newer AWT widgets that might exist on one platform might not be supported on another. Features of widgets that aren't the same on every platform might not be supported or worse they might work differently on each platform. People used to invest lots of effort to get their AWT applications to work consistently across platforms - for instance they may try to make calls into native code from Java. Because AWT uses native GUI widgets your OS knows about them and handles putting them in front of each other etc. whereas Swing widgets are meaningless pixels within a window from your OS's point of view. Swing itself handles your widgets' layout and stacking. Mixing AWT and Swing is highly unsupported and can lead to ridiculous results such as native buttons that obscure everything else in the dialog box in which they reside because everything else was created with Swing. Because Swing tries to do everything possible in Java other than the very raw graphics routines provided by a native GUI window it used to incur quite a performance penalty compared to AWT. This made Swing unfortunately slow to catch on. However this has shrunk dramatically over the last several years due to more optimized JVMs faster machines and (I presume) optimization of the Swing internals. Today a Swing application can run fast enough to be serviceable or even zippy and almost indistinguishable from an application using native widgets. Some will say it took far too long to get to this point but most will say that it is well worth it. Finally you might also want to check out SWT (the GUI toolkit used for Eclipse and an alternative to both AWT and Swing) which is somewhat of a return to the AWT idea of accessing native Widgets through Java. :) .. please check my edited question Um... having done some pretty extensive Swing across multiple platforms I can tell you that it very much is not the same across platforms. Similar? Sure. Same? No way. thanks a lot skiphoppy... The heavyweight/leightweight problems will disappear with Java 6 update 12 (see http://java.dzone.com/news/a-farewell-heavyweightlightwei). Wow. I can't believe they can fix it and I still can't believe mixing lightweight and heavyweight components would ever be desirable. But it's incredible that they can fix it. Just forget about both. Have a look at WPF. :)  AWT 1 . AWT occupies more memory space 2 . AWT is platform dependent 3 . AWT require javax.awt package swings 1 . Swing occupies less memory space 2 . Swing component is platform independent 3 . Swing requires javax.swing package Could you say me how does AWT occupies more memory space? Because it uses native code? awt requires java.awt.*  Swing vs AWT. Basically AWT came first and is a set of heavyweight UI components (meaning they are wrappers for operating system objects) whereas Swing built on top of AWT with a richer set of lightweight components. Any serious Java UI work is done in Swing not AWT which was primarily used for applets. are there any cases where awt is more useful/ advised to use then swing? Samiksha make that another question instead of trying to have a discussion thread in these comments. :) It used to be relevant... 10 years ago. @Pacerier he was talking about AWT not SWT  The base difference that which already everyone mentioned is that One is heavy weight and other is light weight. Let me explain bacially what the term heavy weight means is that when you are using the awt components the native code used for getting the view component is generated by the Operating System thats why it the look and feel changes from OS to OS. Where as in swing components its the responsibility of JVM to generate the view for the components. Another statement which i saw is that swing is MVC based and awt is not. actually Swing uses a Model-Delegate approach which is derived from the MVC approach where in the View and Controller are combined for a Delegate structure +1 for more simpler explanation",java swing awt378754,A,"Java swing UI crash debugging I am trying to debug a problem where a user clicks on the button and the UI just dies. I know good luck. The logs just end after the user clicks the button so i'm thinking there may be some exception/error that we are not logging. Maybe an OutOfMemoryError. Any suggestions on how to proceed? to get more information. Java command setting etc. Thanks for any help rich i was able to find the jvm error file. Looks like something happened while in the ""AWT-Windows"" native thread. =>0x02acf000 JavaThread ""AWT-Windows"" daemon [_thread_in_native id=3616 stack(0x02eb00000x02f00000)] siginfo: ExceptionCode=0xc0000005 writing address 0xe2789280 Registers: EAX=0x234f099c EBX=0x00001400 ECX=0x00000100 EDX=0xe2789280 ESP=0x02eff4a4 EBP=0x00000400 ESI=0x234f099c EDI=0xe2789280 EIP=0x6d02bcbd EFLAGS=0x00010206 Top of Stack: (sp=0x02eff4a4) 0x02eff4a4: 02eff500 00000100 02eff584 00000100 0x02eff4b4: 6d0a5697 00000400 00000400 00000100 0x02eff4c4: 00000100 02eff700 02eff500 00000000 0x02eff4d4: 00000000 00000100 041ac3a0 00000100 0x02eff4e4: 00182620 00000400 e2789280 00000000 0x02eff4f4: 00000000 00000100 00000100 00000000 0x02eff504: 00000000 00000100 00000100 00000000 0x02eff514: 00000000 00000004 00000400 00000000 Instructions: (pc=0x6d02bcbd) 0x6d02bcad: 00 00 00 8b 4c 24 14 8b e9 c1 e9 02 8b f0 8b fa 0x6d02bcbd: f3 a5 8b cd 83 e1 03 f3 a4 8b 74 24 18 8b 4c 24 Stack: [0x02eb00000x02f00000] sp=0x02eff4a4 free space=317k Native frames: (J=compiled Java code j=interpreted Vv=VM code C=native code) C [awt.dll+0x2bcbd] [error occurred during error reporting (printing native stack) id 0xc0000005] Java frames: (J=compiled Java code j=interpreted Vv=VM code) j sun.awt.windows.WToolkit.eventLoop()V+0 j sun.awt.windows.WToolkit.run()V+69 j java.lang.Thread.run()V+11 v ~StubRoutines::call_stub  Try redirecting standard output - you'll probably see the exception stack trace there.  I don't know what you mean by ""just dies"". Does the UI still redraw itself if you drag it outside your screen edge and then back in? Does the entire process eventually terminate unexpectedly? Does the entire process immediately terminate unexpectedly? Assuming the UI is still there when you click a button and nothing seems to be happening another easy way to diagnose what might be going wrong is to monitor that process' CPU and memory usage. Task Manager (or better Process Explorer) if you're in Windows; ps if you're some flavor of Unix (and probably Mac as well). Check how much CPU that process is using first. If it's 0% then you probably have something benign like the button having no listener (and hence clicking it has no effect whatsoever). If it's 100% then you probably have some business logic running like mad possibly in an infinite loop. Two things to look at: one check memory usage and see whether it's going up; a bug could be causing large numbers of objects to be created and you'll eventually run out of memory. It's impossible to say for sure without knowing what the code does. The second thing is mentioned above: drag the UI offscreen and then back. Java's EDT (Event Dispatch Thread) is responsible for handling all UI events including redrawing the UI when it is made visible; if it doesn't do that then you know something is running in the EDT that shouldn't be keeping it from getting around to doing things like redraws. For all I know the business logic is working just fine but merely takes a while and is hogging the EDT. (If it's just under 50% 33% 25% etc. then you're on a multiple-CPU machine; see 100% above...) From your description however (namely ""the logs just end"") it sounds like your UI or business logic is waiting on something that'll never come so you'll have 0% CPU on that process. Worth checking anyway since it's quick and can head off a needless bug hunt in the wrong place.  You must have an event listener waiting for the mouse clicked event. Did you trace through that code to a specific line? The code must at least reach the first line I can't see the event listener not working. You'll need to break it down a bit. And if it's only got one line then you need to drill into that code until you have more than one line or until you can isolate it some more...  the application is running on java 1.6. and the entire process immediately terminate unexpectedly. One other piece of information is that the swing app is started using webstart. i'm are looking through code based on the last line in the log to see if i can figure out what's happening. unfortunately this has happened before and each time at a different point so i haven't been able to reproduce. we'll probably end up eventually using the Thread.setDefaultUncaughtExceptionHandler() suggestion and see if we can get more info. any more thought are welcome. thanks so much for the help  Which version of java and what machine? In any case here's the scoop: the event queue thread runs somewhat separately from the main thread. In Java < 5 there was a bug that made it difficult to capture events from that thread so some exceptions just went away. In Java 5 there's a new method Thread.setDefaultUncaughtExceptionHandler() that will let you set up an exception handler for anything that might otherwise have gone uncaught. Add a handler there and catch all Throwables and log them. This is also a good hack for dealing with things you might otherwise call System.exit() for as well; have a normalExit Throwable; throw that anywhere you'd call exit in the GUI and make sure all gets cleaned up. Charlie: I think of myself as pretty Java savant and this is one new feature of the language I definitely didn't know about. Thanks for sharing it! Well it happened in part because I complained about the difficulty when I was a Java Architect at Sun. System.exit() basically just shoots the process in the head; I wanted an orderly shutdown.",java swing211051,A,"Find ""real"" height/width of Swing/AWT object Because Canvas3D doesn't have the ability to resize dynamically with the parent frame I would like to be able to track when a user resizes a window and then resize it manually myself. (If this ends up crashing Canvas3D as some docs suggest I will simply destroy and recreate it when the user resizes their window). Part of this procedure involves being able to accurately tell how big the container panel is to begin with. The two methods I've tried: panel.getHeight(); panel.getPreferredSize().height; Don't seem to accurately report things: getHeight() is invariably zero and getPreferredSize() returns numbers that don't actually have anything to do with the actual size of the panel. Any ideas? Edit: So I took a debugger to the panel object and manually inspected the non-object properties and I didn't see anything that resembled width/height. Granted there are sub-objects that I didn't look at. Also maybe the window has to be visible (it isn't at the point I'm interfacing the object) when I query for height/object? Edit 2: So Swing classes are subclasses of AWT classes so I imagine if you're able to find the height/width of those the approach would generalize. I've amended the title accordingly. I found out that if you extend by JFrame this code can be used also to save time effort and space. int windowWidth = getWidth(); int windowHeight = getHeight(); I know you already got an answer but if you ever need an alternative here it is.  To determine the size of a component you have to either: have set it manually at some point run the layout manager responsible for layouting the component Generally you get the exact size of a component via the getSize() method which returns a Dimension object containing width and height but getWidth/Height() should work too. But this can only work if one of the two preconditions are met. If a window has never been made visible has no layout manager or the component (you want to know the size of) has been added after the window/container has been made visible the size usually is zero. So to get the correct size you have to make the container/frame visible (after you have added the component) or call validate() or doLayout() on the container to recalculate the layout if you added the component after the last layout was done. Another thing to keep in mind is setting and probably configuring a layout manager on the container. If no layout manager ist set (null) even making a container visible oder calling validate() does not set a size on its children. The minimumSize/preferredSize/maximumSize properties are hints to the layout manager how the component should be sized but it does not have to obey them (most layout managers don't). Edit 2: After I read your other question about the same subject I think you should read Using Layout Managers from The Java Tutorials Edit: I don't know if you already figured that out but to react to the resizing of the window you can do something like this: public class WindowResizeTest extends JFrame { public static void main(String[] args) { new WindowResizeTest(); } public WindowResizeTest() { this.setSize(640 480); JPanel panel = new JPanel(); panel.setBackground(Color.RED); this.add(panel); this.addComponentListener(new ComponentListener() { public void componentResized(ComponentEvent e) { System.out.println(e.getComponent().getSize()); } public void componentHidden(ComponentEvent e) {} public void componentMoved(ComponentEvent e) {} public void componentShown(ComponentEvent e) {} }); this.setVisible(true); } } Thank you so much for the well thought out answer. I will try it out promptly! Thanks for the response. Saved my life! Thanks nice work!",java swing156472,A,Is there a good drop-in replacement for Java's JEditorPane? I'm not happy with the rendering of HTML by Swing's JEditorPane. In particular bullets for unordered lists are hideous. Customising the rendering seems extremely difficult. Therefore I'm looking for a replacement with better HTML rendering. Does this exist? (I asked Google and found nothing except a promising dead link). Something that I looked at extensively a while back - and there are many options - however I nearly ended up using http://lobobrowser.org/cobra.jsp but then the project was cancelled so I can't tell you how it all turned out... Cobra works well for my needs. I wish the jar was a little smaller though.  Cobra did the trick. Almost a drop-in replacement for JEditorPane with very nice HTML rendering. One complaint: it's a big jar to add to my little application. Thanks for the responses.  http://today.java.net/pub/a/today/2004/05/24/html-pt1.html  Take a look at SwingBox. SwingBox is a Java Swing component that allows displaying the (X)HTML documents including the CSS support. It is designed as a JEditorPane replacement with considerably better rendering results. SwingBox is pure Java and it is using the CSSBox rendering engine for rendering the documents.,java swing jeditorpane213378,A,"Open-source improvements or replacements for Swing components I develop a number of desktop Java applications using Swing and while Swing is quite powerful (once you get the hang of it) there are still a lot of cases where I wish some advanced component was available right out of the box. For example I'd really like to see easy-to-use components (without writing them myself which I could do given enough time) like: Multi-line label Windows File Explorer-like Icons or Thumbnails view Drop-down button (like Firefox's old Back button) 5-star rating widget Combo box with automatic history (like the text field on Google) An Outlook-style accordion-style bar and so on I know of a couple of sources of free Swing components like SwingLabs home of JXTable JXDatePicker and a few others. Where do you go for Swing components beyond those included with Java itself? Multi-line labels are built into Swing because you can use HTML in JLabels: http://stackoverflow.com/questions/685521/multiline-text-in-jlabel The following are worth a look: swingX Glazed lists Substance look'n'feel Flamingo components Ken Orr's Mac Widgets Jide's open source components Your first link has too many http's in it.  Hey There I know you can get an awesome wrapping labe and an accordion from javaswingcomponents however they are not open source implementations. Otherwise Jide and SwingX are great choices.  As for: ""Windows File Explorer-like Icons or Thumbnails view"" They are built in in swing. File explorer icons are accessed through FileSystemView class ( it is used by JFileChooser ) when the L&F is Windows of course. FileSystemView.getFileSystemView(); Icon driveIcon = fsv.getSystemIcon( new File(""C:\\"")); And the Thumbnails icon can be retrieved with the sun.com class that are discouraged by Sun sun.awt.shell.ShellFolder getIcon( boolean largeIcon ) But this one may not perform very well some times ( due to native resources handling I think ). I realize that... I was thinking about lists that look like Explorer views but aren't used for the file system. For example a thumbnail list of photos or some other type of icon.",java swing components281478,A,"Jlabel HTML formatting I have a JLabel which has an e-mail address in it. I used HTML formatting on the JLabel so it appears as a link. However you are not able to click the link. In fact you cannot select any of the text in the label. Is there a property that I can set on the JLabel to allow the user to at least select the text of the e-mail and preferably to click on the e-mail address the way they would on a webpage? My code for my JLabel is essentially: JLabel l = new JLabel(""<html><a href=\""mailto:bob@bob.com\"">bob@bob.com</a>""); The default JLabel doesn't allow you to do this. If you really want to use a JLabel you could add a mouse listener to it to capture clicks and react to them. Another way would be to use a non-editable JEditorPane and call addHyperlinkListener on it to add your HyperlinkListener.",java swing438508,A,"How to securely trigger a Swing-Action in a restricted applet? I simply want to call a swing action from my own popup menu. But since there is a security manager I need a solution to invoke this action without calling it directly. For instance the paste action of a text component will fail because sun.swing.SwingUtilities2 cannot be loaded if there is any of my classes in the call stack. Is there any way to enqueue an event to the event thread? JComponent.dispatchEvent doesn't do the job because it processes the event itself. Short answer: you can't without signing the applet. Long answer: If you could without permissions you could queue all kind of interesting messages. Your example paste or in long form: have access to something the client has copied before is an action the client needs to know about and authorize. Think about a rouge applet monitoring the clipboard ""pasting"" everything and sending it over the wire to a remote server. Your PIN for example. The solution is to sign your applet thereby telling the client ""It is in (your name here) responsibility that this applet is not evil."" and asking the user if he/she believes you. If yes the security manager will no longer block you. If not - well the user distrusts you why should the JVM do otherwise? See http://java.sun.com/developer/onlineTraining/Programming/JDCBook/signed.html",java security swing applet action421381,A,"Swing buttons don't react immediately! How can I change that? I've built a form with Netbeans's visual editor. When I press one of the buttons it should do the following : set it to disabled perform a task that takes some time when the task finishes the button will be enabled again However the following happens: the button remains in a pressed state until the task finishes when the task finishes the enabling/disabling of buttons will be very fast (they will happen but you won't notice them) This behaviour is not something I want. I tried using repaint on the JButton on the JFrame and even on the JPanel containing the button but I can't seem to get it to do what I want. Some hints? You need to do the task that takes some time in a different thread. The reason the button is blocking is because the work is being done in the same thread that draws the button. Once the work is done the button can do the rest of what you tell it to. If you use a different thread the thread will go do the task while the drawing code can continue drawing the form.  When you do work in a button callback you are stalling the GUI painting thread until it completes. What you need to do is spawn a thread to do the long running task and then have that thread use SwingUtilities.invokeLater() to update the UI when it completes. Not using invokeLater is not thread safe and is generally bad mojo. A basic example is: button.setEnabled(false); new Thread(new Runnable() { public void run() { // Do heavy lifting here SwingUtilies.invokeLater(new Runnable() { public void run() { button.setEnabled(true); } }); } }).start(); The part with ""button.setEnabled(true)"" is taking place in the thread that does the work ? Should I pass the button to the thread ( in case I don't want to use anonymous classes ) ? It's taking place in the GUI Thread. See http://java.sun.com/j2se/1.4.2/docs/api/javax/swing/SwingUtilities.html#invokeLater(java.lang.Runnable) As for how much you dislike anonymous classes that's up to you. You might want to put a try-finally in there too. Also it's more robust to calculate the new button state (in the EDT) rather than firing delayed messages with old state about the place. I forgot the run methods. Thanks Tom. Goes to show you how dependent I am of my IDE :) Sothe answer's yes? :) This answer is lacking in explanation - feel free to copy some of the explanation from my answer. Done. Thanks Paul. Made it community while I was at it. You might as well consider using SwingWorker (part of Java6 but exists as Open Source library for Java5) which will make the source code ligher (threading and EDT issues are handled by SwingWorker itself).  The Concurrency in Swing tutorial from Sun is well worth a read. Excellent explanation and background reading including the event dispatching thread using worker threads etc  When you do things in a button callback you are essentially stalling the gui painting thread - not just for the button but for ANY gui painting. (Try covering the interface with another window and then exposing it again - it won't repaint until the task is finished!) What you need to do is spawn a thread to do the long running task and then have that thread use SwingUtilities.invokeLater() to do the enabling of the button. invokeLater forces the button enable to happen in the gui painting thread. You may want to set a busy cursor or otherwise lock the interface while the long-running thread is operating. Too bad we can't merge answers. @Allain the important thing is making sure the accepted answer is as good as we can make it.",java swing481379,A,Java: Handle logoff or shutdown on Windows and Linux Is there a way for a Java GUI application to respond to system shutdown or logoff events other than to use JNI? (On Windows the JNI would use WM_QUERYENDSESSION on Linux?) The method should allow the program to prompt users to save etc. and then continue the logoff process. You can schedule a Thread to be run on JVM shutdown - see http://java.sun.com/j2se/1.4.2/docs/api/java/lang/Runtime.html#addShutdownHook(java.lang.Thread)  This doesn't answer the question but addresses part of it. In a Unix GUI session I consider the right way to handle the logoff event is to save the document to a temporary file and save the information in the session state. During the session recovery the program can reload the temporary file and take up where it left off. No need to ask the user about saving or not. I just wish more software did transparent session save and recovery. Too many programs reopen with empty document windows because the GUI framework used does that much but none of the rest of the work has been done to actually handle any meaningful program state.  I think that Runtime.getRuntime().addShutdownHook should provide the functionality you need.  As far as I know there's no way in Java to catch the system shutdown or logoff events. You can however catch when the JVM is terminating by adding a shutdown hook. AWT's WindowAdapter also has a windowClosing event that you can override and hook to a window that you want to monitor. Swing inherits this; I believe SWT does as well. Be aware that you MUST manually dispose of the window if you override this event! I believe that MS Windows will fire these events as it is closing. I believe a SIGTERM on Linux/UNIX does the same although Linux will SIGKILL an app shortly afterwords if this is during shutdown. Beware AWT's WindowAdapter will only hook to events on the window. If the environment is terminated using shutdown the windowClosing or windowClosed events will not fire!,java windows linux swing95767,A,"How can I catch AWT thread exceptions in Java? We'd like a trace in our application logs of these exceptions - by default Java just outputs them to the console. There is a distinction between uncaught exceptions in the EDT and outside the EDT. Another question has a solution for both but if you want just the EDT portion chewed up... class AWTExceptionHandler { public void handle(Throwable t) { try { // insert your exception handling code here // or do nothing to make it go away } catch (Throwable t) { // don't let the exception get thrown out will cause infinite looping! } } public static void registerExceptionHandler() { System.setProperty('sun.awt.exception.handler' AWTExceptionHandler.class.getName()) } } Three years old but still a very useful answer. Thanks! No need to catch throwable. There will be no infinite looping. java.awt.EventDispatchThread.handleException is catching any exceptions for you. There saids `classs AWTExceptionHandler`  There are two ways: /* Install a Thread.UncaughtExceptionHandler on the EDT */ Set a system property: System.setProperty(""sun.awt.exception.handler""MyExceptionHandler.class.getName()); I don't know if the latter works on non-SUN jvms. -- Indeed the first is not correct it's only a mechanism for detecting a crashed thread. Using Thread.UncaufhtExceptionHandler won't catch EDT exceptions. The EDT class catches all throwables and prints them out rather than letting them unwind the whole thread. You are also missing details about what is needed in the second option the MyExceptionHandler class must have a handle(Throwable) instance method accessable and a no-args constructor accessable.  A little addition to shemnons anwer: The first time an uncaught RuntimeException (or Error) occurs in the EDT it is looking for the property ""sun.awt.exception.handler"" and tries to load the class associated with the property. EDT needs the Handler class to have a default constructor otherwise the EDT will not use it. If you need to bring a bit more dynamics into the handling story you are forced to do this with static operations because the class is instantiated by the EDT and therefore has no chance to access other resources other than static. Here is the exception handler code from our Swing framework we are using. It was written for Java 1.4 and it worked quite fine there: public class AwtExceptionHandler { private static final Logger LOGGER = LoggerFactory.getLogger(AwtExceptionHandler.class); private static List exceptionHandlerList = new LinkedList(); /** * WARNING: Don't change the signature of this method! */ public void handle(Throwable throwable) { if (exceptionHandlerList.isEmpty()) { LOGGER.error(""Uncatched Throwable detected"" throwable); } else { delegate(new ExceptionEvent(throwable)); } } private void delegate(ExceptionEvent event) { for (Iterator handlerIterator = exceptionHandlerList.iterator(); handlerIterator.hasNext();) { IExceptionHandler handler = (IExceptionHandler) handlerIterator.next(); try { handler.handleException(event); if (event.isConsumed()) { break; } } catch (Throwable e) { LOGGER.error(""Error while running exception handler: "" + handler e); } } } public static void addErrorHandler(IExceptionHandler exceptionHandler) { exceptionHandlerList.add(exceptionHandler); } public static void removeErrorHandler(IExceptionHandler exceptionHandler) { exceptionHandlerList.remove(exceptionHandler); } } Hope it helps.",java swing exception-handling awt304663,A,"How can I validate parameters without creating a separate dialog? I'm going to make an application (in Swing) that uses a tree to visualize a data structure (JTree). A tree will be on the left side of a window. The user will be able to browse a tree. The parameters of every tree node will be displayed on the right side of the window. The example windows will be looking like this =========================== | tree panel | data panel | | | | | | | | | | --------------------------- The problem arises when a user wants to change that data. when should I validate them ? The easy approach is to open a new modal dialog (JDialog) and let the user to change this data in it. Validation of data would take place in an ""ok"" button listener method but this is a little clunky. I would like to allow the user to edit those data right in the data panel. In that case when should I validate them? Is there a pattern of such solution in Swing? Or any online tutorial how to do it? Thanks in advance. what about ""save"" button in data panel? ;) I'm not totally sure what you're after but.. You could maybe add this ""ok"" button (or ""commit changes"" or whatever) to data panel and when the button would be pressed you would validate the data and save the changes if the changes are valid? (So you'd have editable components at the data panel) Edit: if this wasn't good could you clarify me a bit: Is the data panel showing data for one item of the tree at time? What kind of data is there to change (and to validate) Anyway if you want to validate straight the changes made to an edit component (for example JTextField) you can use for example Formatted text fields see How to Use Formatted Text Fields For more general validating see InputVerifier More ideas see Validating Numerical Input in a JTextField (concentrates of numerical input but usable for other purposes also)  Dialogs are bad. Immediately discard any complete nonsense input immediately. For instance typing a letter in the numerical field (use Document filters). Don't beep. Don't require any particular commit step. You may have retain partially entered data.",java validation swing227526,A,"Bus or listeners/delegates in client-side Swing application? Building a client-side swing application what should be notified on a bus (application-wide message system similar in concept to JMS but much simpler) and what should be notified using direct listeners? When using a bus I always have an unescapable feeling of ""I have no idea who uses that and where"". Also no set order hard to veto events hard to know exactly what's going on at a set time. On the other hand using listeners means either directly referencing the source object (coupling) or passing the reference through myriad conversions (A--b_listener-->B B--c_listener-->C only because a needs to know something only C can to tell but B has no interest in). So are there any rule of the thumb regarding this? Any suggestion how to balance? In my experience trying to make Swing do something it wasn't designed for or doesn't want you to do is extremely painful. I would go with the simplest thing that would work; keep your code clean do it the ""Swing Way"" until you start seeing problems.  Well I can imagine the approach where models are updated using BUS like system and events from models are delegated using listeners. Simple scenario: I got server side which represents producer of data. Then on client side a got consumer interface which consumes all incoming messages and transform them into my internal messages/DTOs and push them into bus which distributes them into application model(s). These model process incoming messages and decide to notify interested components using listeners.  Event buses are very very useful tools for providing decoupling in certain architectures. Listeners are easy to implement but they have significant limitations when your object and dependency graph gets large. Listeners tend to run into problems with cyclic dependencies (events can 'bounce' in odd ways and you wind up having to play games to ensure that you don't get stuck. Most binding frameworks do this for you but there's something distasteful about knowing that listener events are shooting off into a million places). I make this kind of decision based on project size and scalability. If it's a big app or there are aspects of the app that can by dynamic (like plugin modules etc...) then a bus is a good way to keep the architecture clean (OSGI-like module containers are another approach but heavier weight). If you are considering a bus architecture I recommend that you take a look at the Event Bus project - it works very well with Swing and provides a robust out of the box solution for what you are asking about. Link [Event Bus](https://eventbus.dev.java.net/) is dead. Are you referring to [EventBus](http://www.eventbus.org/) or [simpleeventbus](http://code.google.com/p/simpleeventbus/) or something else? Whew - the code at EventBus looks the same as what I pointed at back in 2008 but I haven't followed the project that closely...  The convention in Java Swing is to use listeners heavily. Sticking with the convention improves maintainability but stifles innovation. I've not encountered the bus approach in Swing but I find it interesting.",java swing events architecture320682,A,Do I need to free Swing components before letting them get garbage collected? Wnen I use external resources such as files or DB connection I need to close them before I let them go. Do I need to do the same thing with Swing components ? If yes then how ? Objects are automatically garbage collected if there are no references to them. You do not have to treat Swing components the same way that you do external resources. However if you have a component that you are not going to need later you can set any references to that component to null. JPanel p = new JPanel(); p = null; Setting p to null does not delete the object but it removes any references to the object so the next time the garbage collector passes it gets picked up. You will have to be careful though that other reference to the component do not exist. p = null is rarely needed. See http://stackoverflow.com/questions/271530/cross-references-and-garbage-collection But swing components use external resources (eg window handles I gues) what about them ?  Normally you don't need to dispose of objects when you are done with them (although setting the references to them to null may allow them to be GCed sooner). However AWT and Swing objects allocate some amount of native resources that need to be freed. Furthermore the AWT thread treats the windows as top-level objects preventing them from being garbage collected and the JVM from terminating. Thus when you are done with your window you need to dispose of it which frees the native resources that it has allocated. One way to do this is to call Window.dispose() on it. However a better option would be to call JFrame.setDefaultCloseOperation() when you initialize each of your root windows. If you pass it DISPOSE_ON_CLOSE it will take care of disposing itself when the user closes the window. When the last such window closes the AWT thread will stop blocking and allow the JVM to close (assuming you don't have any other aberrant threads running). Alternatively you can pass it EXIT_ON_CLOSE which will cause your window to call System.exit() which tells the JVM that your application is done and to gracefully terminate. An what if I only get rid of a JPanel lith some controls in order to put there someting else ? Withount closing the entire window. What then ?  Windows (including dialogs and frames) should be disposed. If you create (AWT) Graphics objects then they should be disposed of too (but usually locally within say a paintComponent method). If you have a listener to update a short lived target from a long lived source then you should remove it before discarding the target. There's a neat hack where the listener uses a WeakReference to the target so that it can deregister when the reference goes away (and an event is fired).  At one point it was taught that you had to disconnect all the listeners because otherwise they'd act as references to the Swing component. But I'm told that this is no longer a problem.,java swing97586,A,Has anyone got an example of aerith style swing mixed with GUI maintainability of SWT editing? My boss loves VB (we work in a Java shop) because he thinks it's easy to learn and maintain. We want to replace some of the VB with java equivalents using the Eclipse SWT editor because we think it is almost as easy to maintain. To sell this we'd like to use an aerith style L&F. Can anyone provide an example of an SWT application still being able to edit the GUI in eclipse but having the Aerith L&F? SWT doesn't support look & feels. You can get different L&F's by altering your OS native L&F. The only exception is to using the eclipse forms toolkit. It still has the OS native feel but strives for a web-browser-like look. It does this mostly by setting everything to SWT.FLAT and using white backgrounds on everything. Occassionally they have to manually draw outlines around controls that don't natively support it. If you're looking for custom L&F's that will appear across platforms you really want Swing.  Like Heath Borders said SWT doesn't support L&Fs so you have to use Swing for that. Aerith however does not base on a look and feel but on custom painting on the components with a lot of gradients. If you are looking for a Swing GUI Editor that is (nearly) as easy to use as VB try the Matisse GUI Builder in NetBeans. There is also a version for Eclipse but it is shipped with the commercial MyEclipse. If you want to learn more about writing apps with cool a cool GUI have a look at the Filthy Rich Clients book by Chet Haase and Romain Guy. If this does not convince your boss try to resize the VB GUI and then resize the Swing GUI. ;-) And I would say a VB is really not very good to maintain in the long run...,java eclipse swing swt lf32529,A,"How do I restrict JFileChooser to a directory? I want to limit my users to a directory and its sub directories but the ""Parent Directory"" button allows them to browse to an arbitraty directory. How should I go about doing that? The solution of Allain is almost complete. Three problems are open to solve: Clicking the ""Home""-Button kicks the user out of restrictions DirectoryRestrictedFileSystemView is not accessible outside the package Starting point is not Root Append @Override to DirectoryRestrictedFileSystemView public TFile getHomeDirectory() { return rootDirectories[0]; } set class and constructor public Change JFileChooser fileChooser = new JFileChooser(fsv); into JFileChooser fileChooser = new JFileChooser(fsv.getHomeDirectory()fsv); I use it for restricting users to stay in a zip-file via TrueZips TFileChooser and with slight modifications to the above code this works perfectly. Thanks a lot.  No need to be that complicated. You can easily set selection mode of a JFileChooser like this JFileChooser fc = new JFileChooser(); fc.setFileSelectionMode(JFileChooser.DIRECTORIES_ONLY); fc.setMultiSelectionEnabled(false); You can read more reference here How to Use File Choosers This limits them to directories in general but not to a specific directory which is the OP's question.  You can probably do this by setting your own FileSystemView. how do you get the default filesystemview (e.g. to delegate to it)? @Jason S - probably via static method `getFileSystemView()` Just if someone could need it here is an exact example of what OP wanted: http://tips4java.wordpress.com/2009/01/28/single-root-file-chooser/  Incase anyone else needs this in the future: class DirectoryRestrictedFileSystemView extends FileSystemView { private final File[] rootDirectories; DirectoryRestrictedFileSystemView(File rootDirectory) { this.rootDirectories = new File[] {rootDirectory}; } DirectoryRestrictedFileSystemView(File[] rootDirectories) { this.rootDirectories = rootDirectories; } @Override public File createNewFolder(File containingDir) throws IOException { throw new UnsupportedOperationException(""Unable to create directory""); } @Override public File[] getRoots() { return rootDirectories; } @Override public boolean isRoot(File file) { for (File root : rootDirectories) { if (root.equals(file)) { return true; } } return false; } } You'll obviously need to make a better ""createNewFolder"" method but this does restrict the user to one of more directories. And use it like this: FileSystemView fsv = new DirectoryRestrictedFileSystemView(new File(""X:\\"")); JFileChooser fileChooser = new JFileChooser(fsv); or like this: FileSystemView fsv = new DirectoryRestrictedFileSystemView( new File[] { new File(""X:\\"") new File(""Y:\\"") }); JFileChooser fileChooser = new JFileChooser(fsv); Doesn't work @Allain",java swing jfilechooser292279,A,"Populate JTable from a Hashtable in Java I have a function which gets a key from the user and generates a Hashtable (on a pattern specified by the key). After creating a Hashtable I would like to populate a JTable so that each each column represents a key and every rows represents the values associated with the key. I tried everything but couldn't get this work. I'm not creating the table from within the constructor as I need to get input from the user. See How to Use Tables: Creating a Table Model. The JTable constructor used by SimpleTableDemo creates its table model with code like this: new AbstractTableModel() { public String getColumnName(int col) { return columnNames[col].toString(); } public int getRowCount() { return rowData.length; } public int getColumnCount() { return columnNames.length; } public Object getValueAt(int row int col) { return rowData[row][col]; } public boolean isCellEditable(int row int col) { return true; } public void setValueAt(Object value int row int col) { rowData[row][col] = value; fireTableCellUpdated(row col); } } You basically have to wrap your hashtable in the above manner. Here's an example. package eed3si9n.hashtabletable; import java.awt.BorderLayout; import java.util.Enumeration; import java.util.Hashtable; import javax.swing.JFrame; import javax.swing.JPanel; import javax.swing.JScrollPane; import javax.swing.JTable; import javax.swing.table.AbstractTableModel; import javax.swing.JButton; import java.awt.Dimension; public class MainForm extends JFrame { private static final long serialVersionUID = 1L; private JPanel jContentPane = null; // @jve:decl-index=0:visual-constraint=""2338"" private JScrollPane m_scrollPane = null; private JTable m_table = null; private Hashtable<String String> m_hash = null; private JButton m_btnAdd = null; /** * This is the default constructor */ public MainForm() { super(); initialize(); m_hash = new Hashtable<String String>(); m_hash.put(""Dog"" ""Bow""); } private void onButtonPressed() { m_hash.put(""Cow"" ""Moo""); m_table.revalidate(); } /** * This method initializes this * * @return void */ private void initialize() { this.setSize(409 290); this.setTitle(""JFrame""); this.setContentPane(getJContentPane()); } /** * This method initializes jContentPane * * @return javax.swing.JPanel */ private JPanel getJContentPane() { if (jContentPane == null) { jContentPane = new JPanel(); jContentPane.setLayout(new BorderLayout()); jContentPane.setSize(new Dimension(500 500)); jContentPane.setPreferredSize(new Dimension(500 500)); jContentPane.add(getM_scrollPane() BorderLayout.NORTH); jContentPane.add(getM_btnAdd() BorderLayout.SOUTH); } return jContentPane; } /** * This method initializes m_scrollPane * * @return javax.swing.JScrollPane */ private JScrollPane getM_scrollPane() { if (m_scrollPane == null) { m_scrollPane = new JScrollPane(); m_scrollPane.setViewportView(getM_table()); } return m_scrollPane; } /** * This method initializes m_table * * @return javax.swing.JTable */ private JTable getM_table() { if (m_table == null) { m_table = new JTable(); m_table.setModel(new AbstractTableModel(){ private static final long serialVersionUID = 1L; public int getColumnCount() { return 2; } public int getRowCount() { return m_hash.size(); } public String getColumnName(int column) { if (column == 0) { return ""Animal""; } else { return ""Sound""; } } public Object getValueAt(int rowIndex int columnIndex) { if (columnIndex == 0) { return getKey(rowIndex); } else { return m_hash.get(getKey(rowIndex)); } // if-else } private String getKey(int a_index) { String retval = """"; Enumeration<String> e = m_hash.keys(); for (int i = 0; i < a_index + 1; i++) { retval = e.nextElement(); } // for return retval; } }); } return m_table; } /** * This method initializes m_btnAdd * * @return javax.swing.JButton */ private JButton getM_btnAdd() { if (m_btnAdd == null) { m_btnAdd = new JButton(); m_btnAdd.setPreferredSize(new Dimension(34 30)); m_btnAdd.addActionListener(new java.awt.event.ActionListener() { public void actionPerformed(java.awt.event.ActionEvent e) { onButtonPressed(); } }); } return m_btnAdd; } public static void main(String[] args) { //Schedule a job for the event-dispatching thread: //creating and showing this application's GUI. javax.swing.SwingUtilities.invokeLater(new Runnable() { public void run() { MainForm frame = new MainForm(); frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); frame.setSize(500 500); frame.setVisible(true); } }); } } // @jve:decl-index=0:visual-constraint=""1010""  Firstly avoid Hashtable go straight for Map. In this case there two potential standard implementations you mights want: LinkedHashMap can retain the order that the entries were added; TreeMap a SortedMap/NavigableMap will sort the results (order of which can be determined by a Comparator. Alternatively you might want a form of Map that fire events or also provides a TableModel. If you want a one time conversion from the Map to table then it's pretty straightforward. public static TableModel toTableModel(Map<??> map) { DefaultTableModel model = new DefaultTableModel( new Object[] { ""Key"" ""Value"" } 0 ); for (Map.Entry<??> entry : map) { model.addRow(new Object[] { entry.getKey() entry.getValue() }); } return model; } Then just create the JTable with this pre-populated model. (Disclaimer: I've not tested or so much as compiled this code.) To keep the Map and TableModel synchronized is more code. Generally it's best to avoid duplicating state whereever possible. Write a class that exposes itself as both a Map and a TableModel. You could go more disjoint by having a Map that fires events and a TableModel that adapts the Map (although note that Map does not have random access based on index so you'll need to be iether clever or slow for large maps). Going the other way a simpler approach would be to add the data straight to a DefaultTableModel and not using a Map at all.",java swing hashtable jtable329506,A,"Is there a multiple input JOptionPane in Java? I was wondering if there is a JOptionPane where you can get multiple inputs from a user instead of just one? If not how could i accomplish this using some type of prompt. I am creating Battleship and wanted to prompt the user to specify locations to place each ship. Thanks Tomek The object that you pass in as the message to the JOptionPane can be graphical components so something like this should work: JPanel panel = new JPanel(); // Populate your panel components here. int ret = JOptionPane.showConfirmDialog(parent panel ""Title"" JOptionPane.YES_NO_OPTION); if ( ret == JOptionPane.YES_OPTION ) { // Read component values. }",java swing input jdialog joptionpane210998,A,Canvas3D not appearing in Swing window I am attempting to insert a Canvas3D object inside a Swing JPanel but the code doesn't seem to be working (i.e. nothing happens):  Canvas3D canvas = new Canvas3D(SimpleUniverse.getPreferredConfiguration()); SimpleUniverse universe = new SimpleUniverse(canvas); BranchGroup root = new BranchGroup(); root.addChild(new ColorCube()); universe.addBranchGraph(root); universe.getViewingPlatform().setNominalViewingTransform(); canvasPanel.add(canvas); What am I missing? The JPanel was created using NetBean's Visual Editor. Probably you have to set a layout manager on the panel which automatically expands the child components to the full area. A JPanel has a FlowLayout by default which does not expand the child components. You could try a BorderLayout instead by calling: canvasPanel.setLayout(new BorderLayout()); Ah that worked perfectly. Thank you!  Canvas3D needs a size passed to it; setting the preferred configuration from SimpleUniverse is not enough. In my case that meant this code:  // 3D canvas initialization Canvas3D canvas = new Canvas3D(SimpleUniverse.getPreferredConfiguration()); SimpleUniverse universe = new SimpleUniverse(canvas); BranchGroup root = new BranchGroup(); root.addChild(new ColorCube()); universe.addBranchGraph(root); universe.getViewingPlatform().setNominalViewingTransform(); canvas.setSize(100 100); canvasPanel.add(canvas);,java swing java-3d241342,A,Is it possible to display Swing components in a JSP? I was wondering if I could pop up JOptionPanes or other Swing components from within a browser using JSP. You may also want to consider GWT which enables you to develop a web interface in Java code (the Java code is converted to HTML & JavaScript by the GWT compiler). Although you don't program to the Swing API directly when writing GWT applications the GWT API is very similar in style to Swing programming.  If you embed an applet. But I don't think that's what you want. Swing is for desktop apps. JSP web pages. If you want components try looking into JSF or some of the many AJAX Javascript frameworks like prototype.  Assuming you're familiar with Swing you may want to introduce yourself to Apache Wicket which is very similar to the way you build web pages as Swing is to building GUI:s. That is in Wicket you add new instancef of Label Button DataTable etc. etc. to page and link those to bean property data which is then ultimately transformed to fully functioning web page. As for the actual question you really can't do it as-is. If choosing a new/different/another web framework to help you isn't possible the only proper way I can think of is doing what sblundy suggested.,java swing jsp143341,A,Are there any frameworks for handling database requests in swing applications? I believe any programmer who has been dealing with database requests in a gui application has run into some or all of the following problems: Your GUI freezes because you call database layer from within the event dispatch thread When you have multiple windows/panels/jframes where user can start a db request your performance degrades because you don't have any control about the threads your user creates User may be able to lock down the application and even the database because he calls any action many times before the first action has been finished What I'd like to know about: are there any frameworks that handle the requirements of handling an ordered set of long running actions (including but not limited to database calls i.e. calculations) outside the event dispatch thread? Note: I know of SwingWorker ;-) Such a thing should be found in Netbeans for example. See RequestProcessor. But in simpler cases this is not required. Last time I need something like thread scheduling and control I simply used new concurrency packages included in J5 (I used J6). With its ExecutorFactory-ies you can simply achieve basic control over tasks. You can also use some queues. This PDF can help. The PDF is written in Slovak language but the Single/Multiple task workers are there written in Java ;)  Naked Objects facilitate a clean domain model and they also have a GUI 2 DB mapping layer -- http://www.nakedobjects.org/home/index.shtml  I doubt you will find something specific for database requests. You can try to reuse existing generic task scheduling libraries. An example is the Eclipse jobs API. This does not depend on the IDE. See http://www.eclipse.org/articles/Article-Concurrency/jobs-api.html That has been my impression at the time too. We've developed a kind of queue where you could add SwingWorker instances that would execute in scheduled order.,java database multithreading swing248353,A,"Java GUI LayoutManagers I'm busy with an asignment where i have to make a graphical interface for a simple program. But i'm strugling with the layout. This is the idea: What is the easiest way to accomplish such a layout? And what method do you use to make layouts in java. Just code it or use an IDE like netbeans? I build everything by hand. Like Christian I've had bad experiences with GUI builders; they always either refused to configure a couple of components quite right or they generated huge amounts of unnecessary code which made later maintenance impractical or both. I used to do build a lot of UIs using GridBagLayout but for years I've never seen an office-environment UI that couldn't be built with nested BorderLayouts GridLayouts and the occasional BoxLayout or FlowLayout. About 98% of the stuff I've seen is doable with nested BorderLayouts. In your case the layout organization will be as bmeck says. Speaking from memory using CENTER for the JTable (remember to put it in a JScrollPane!) and NORTH for everything else ensures that if you resize your JFrame the JTable will get all of the extra space and that should be exactly what you want. For the top labels and fields the nested GridLayouts should ensure that each ""column"" of labels and fields will take up equal horizontal space. (They'll get only enough vertical space to be completely visible and no more since the JTable is taking up everything else.) Everything else is just a matter of adding borders and setting the GridLayout padding reasonably.  I've used GUI layout generating tools for super rapid development (maybe get the first 2 or 3 iterations of an interface out of the way). I've ultimately found that using a simple fixed layout (no layout manager) with these tools is the best approach. Once we are starting to hone in on a design we switch to manual layout. Whenever I've tried to use GUI generators to create code for layout managers I've almost always been bitten eventually where the layout would just stop working and I spent more time debugging the impossible to read auto-generated code than if I'd done the layout by hand anyway. For what it's worth when we are doing the early phase of layouts we use the Jigloo plugin for Eclipse. It's very inexpensive and does a good job. I'm a big fan of MiGLayout. I've found that it is incredibly easy to use for simple layouts and is capable of doing extremely complicated layouts. All without the need to resort to nested panels etc... JGoodies Forms is also good but harder to use.  And what method do you use to make layouts in java. Just code it or use an IDE like netbeans? NetBeans for GUI developers is like a calculator for grade schoolers: you really shouldn't use it until you know how to do things without it but then it will save you a lot of time. (I'd love to answer your primary question but the firewall I'm behind is blocking the picture.)  Well considering how simple the layout is I would suggest you use a BorderLayout with NORTH set to the top section in a container and the JTable in the CENTER of the BorderLayout. For the Top it appears to be a simple BorderLayout again with NORTH as the Instruction: south as the black box (possibly in a container with a FlowLayout). The center of the top pane appears to be 2 Containers of GridLayouts with 2 rows and 2 columns so put thos in another container with a GirdLayout. So in pseudo: Container(BorderLayout) { @NORTH Container(BorderLayout) { @NORTH Label(Instruction); @CENTER Container(GridLayout(21)) { Container(GirdLayout(22)) { Label() TextField() Label() TextField() } Container(GirdLayout(22)) { Label() TextField() Label() TextField() } } @SOUTH Container(FlowLayout()) { JButton() //shaded thing? } } @CENTER { JTable } }  Use GroupLayout :) All the alignments are pretty easy to do  For myself gui-builders for swing or swt never worked that well that's why i code layouts myself using layout managers. Your question doesn't mention which gui-system you are using but i assume you want to use swing. If that's the case I would recommend to use GridBagLayout for your layout. It is not that easy to use in the beginning but as soon as you know how it works you can do most layouts in the way you want it to be and i think it is also the layoutmanager of choice for the layout you want to do.  I used to love Motif's XmForm for this sort of thing. In Java I usually put Boxes inside of boxes. So I have a vertical box. First row of the box contains a JLabel for the Instruction. Second row contains something for the label/result stuff possibly some sort of grid. Third row contains whatever that blacked out thing Fourth row contains the JTable. Then I'd spend some time to try to figure out how to do the lable/result stuff. Then I'd probably end up saying ""dammit"" and doing it as a GridBagLayout.  I wrote an article a while back on layout managers: http://developer.java.sun.com/developer/onlineTraining/GUI/AWTLayoutMgr It describes how nesting (as bmeck above demonstrates) can be used very effectively for many UI designs.  Try table layout. Works great. https://tablelayout.dev.java.net/",java swing gui370259,A,"Java GUI Swing Model Explanation I've been working with Java GUI for a while now but the whole model/structure of JFrames paint() super etc is all murky in my mind. I need a clear explanation or link that will explain how the whole GUI system is organized. Thanks everyone some more answers would be better but this is great! I've found that simply browsing around in the source code (ctrl-click on a name if you're using NetBeans) has been really helpful. If I see a method appear in the completion dialog that I'm not familiar with I'll just click ""Go to source"" and look around until I'm comfortable with it.  If after reading the Swing tutorial you find your interest lies in more advanced topics you may also wish to look at Swing Second Edition by Robinson and Vorobiev.  The same happened to me. Actually to this day I don't quite get 100% how all it works. Swing is a very flexible framework--perhaps too flexible. With flexibility comes a lot of abstraction and with abstraction comes confusion. :) I've found the following articles worth reading. They helped me to better understand the big picture of Swing. http://web.archive.org/web/20110413222135/http://java.sun.com/products/jfc/tsc/articles/architecture/ http://www.oracle.com/technetwork/java/architecture-142923.html (original links now broken) http://java.sun.com/products/jfc/tsc/articles/architecture/ http://java.sun.com/products/jfc/tsc/articles/architecture/ui_install/index.html They explain quite well how the model and the delegate work. It always drives me mad when I see those JLabel LabelUI ui.update etc. I hope this helps. Very useful link - had not seen that before; bookmarked for a closer look later. Yeahh ... I don't remember how I came to that link. I didn't found it until after several years. I don't know the ""google search"" to produce it either so I have it in my bookmarks too. @OscarRyz links are dead. do you have the copy? i need those for my students. thanks. @OscarRyz Cool thanks! @ihsan Unfortunately the site in Oracle has broken images:http://www.oracle.com/technetwork/java/architecture-142923.html Fortunately we have the wayback machine: http://web.archive.org/web/20110413222135/http://java.sun.com/products/jfc/tsc/articles/architecture/  Since this question is tagged with JFrame I'll suggest a few links for understanding how JFrames and other top-level Swing containers work. I also found that Swing was (and still is) quite involved and taking a look at the documentation provided by Sun is required every once in a while -- Every time I check I seem to learn something new. First the basics: JFrame class from the Java API Specifications. The Java API Specifications often provide good detailed information about the classes. In this instance you'll notice that there are several links such as How to Make Frames section from The Java Tutorials. Aside from that I'll also recommend looking at the Lesson: Using Swing Components from The Java Tutorials. The lesson provides instructions on how to use the components provided in Swing along with some useful examples. For more specifics parts that I've found confusing when I started with Swing was all the different types of panes such as the ContentPane RootPane GlassPane. The Using Top-Level Containers section provides information and helpful diagrams on the container hierarchy of the top-level containers. The How to Use Root Panes section gets into the details about the Glass Layered and Content Panes with plenty of examples.  Filthy Rich Clients by Chet Haase and Romain Guy is a great book about Java UI. It covers some more advanced stuff too but introduction and few first chapters explain fundamental things well.  I found Swing Explorer to be a precious tool to understand the hierarchy of components (particularly in complex GUIs) and look at properties (alas read-only: we get used to Firebug convenience!). It has an Eclipse plugin.  Have you looked at the Java Swing Tutorial (click here)? It does a pretty good job of covering the basics of developing Swing applications.",java swing gui jframe258099,A,"How to close a Java Swing application from the code What is the proper way to terminate a Swing application from the code and what are the pitfalls? I'd tried to close my application automatically after a timer fires. But just calling dispose() on the JFrame didn't do the trick - the window vanished but the application did not terminate. However when closing the window with the close button the application does terminate. What should I do? Please post up a code snippet of your timer. May be the safe way is something like:  private JButton btnExit; ... btnExit = new JButton(""Quit""); btnExit.addActionListener(new ActionListener() { public void actionPerformed(ActionEvent e){ Container frame = btnExit.getParent(); do frame = frame.getParent(); while (!(frame instanceof JFrame)); ((JFrame) frame).dispose(); } }); Pretty bad style to name a variable `Frame` with a capital letter exactly like the name of a classŠ—_  Try: System.exit(0); Crude but effective. System.exit(0) isn't just crude it's evil. Check all frames call dispose. If that fails run a debugger and see what non-daemon threads are still alive. Unfortunately this is too crude for me. I want the window closing events to be processed for some cleanup actions. OK I could do a System.exit with a SwingUtils.invokeLater but I'd rather do the proper thing. There's been plenty of bugs even within the JDK that leave the process about. So +1 to exit() but you might want to disable it in debug builds.  In response to other comments DISPOSE_ON_CLOSE does not seem to properly exit the application - it only destroys the window but the application will continue running. If you want to terminate the application use EXIT_ON_CLOSE. Can't remember how I tested this now. This response suggests the exact opposite of James Schek's answer. Which one is correct? (when I test with a simple application both seem to work ...)  I guess a EXIT_ON_CLOSE frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); before System.exit(0) is better since you can write a Window Listener to make some cleaning operations before actually leaving the app. That window listener allows you to defined: public void windowClosing(WindowEvent e) { displayMessage(""WindowListener method called: windowClosing.""); //A pause so user can see the message before //the window actually closes. ActionListener task = new ActionListener() { boolean alreadyDisposed = false; public void actionPerformed(ActionEvent e) { if (frame.isDisplayable()) { alreadyDisposed = true; frame.dispose(); } } }; Timer timer = new Timer(500 task); //fire every half second timer.setInitialDelay(2000); //first delay 2 seconds timer.setRepeats(false); timer.start(); } public void windowClosed(WindowEvent e) { //This will only be seen on standard output. displayMessage(""WindowListener method called: windowClosed.""); }  Take a look at the Oracle Documentation. Starting from JDK 1.4 an Application terminates if: There are no displayable AWT or Swing components. There are no native events in the native event queue. There are no AWT events in java EventQueues. Cornercases: The document states that some packages create displayable components without releasing them.A program which calls Toolkit.getDefaultToolkit() won't terminate. is among others given as an example. Also other Processes can keep AWT alive when they for what ever reason are sending events into the native event queue. Also I noticed that on some Systems it takes a coupple of seconds before the Application actually terminates.  Your JFrame default close action can be set to ""DISPOSE_ON_CLOSE"" instead of EXIT_ON_CLOSE (why people keep using EXIT_ON_CLOSE is beyond me). If you have any undisposed windows or non-daemon threads your application will not terminate. This should be considered a error (and solving it with System.exit is a very bad idea). The most common culprits are java.util.Timer and a custom Thread you've created. Both should be set to daemon or must be explicitly killed. If you want to check for all active frames you can use Frame.getFrames(). If all Windows/Frames are disposed of then use a debugger to check for any non-daemon threads that are still running. In my case I discovered with the debugger that I had a Swingworker still active. I called its cancel(true) method in the WindowClose Eventlistener and the program terminates now. Thanks! Note that you may have to call dispose on each frame and typically that is ""enough"" (though setting the default close action to EXIT_ON_CLOSE is probably not a bad idea either). First window should add itself to as a listener to the second window and take appropriate action. What if you have one window opening another but not disposing itself so that you can use it for a `back` window? If the second window is then closed and you use `DISPOSE_ON_CLOSE` the programme doesn't terminate because the first window is still ""undisposed""... is there a way to solve that _without_ using `DISPOSE_ON_CLOSE`? This response suggests the exact opposite of Bizorke's answer. Which one is correct? (when I test with a simple application both seem to work ...) Using EXIT_ON_CLOSE will forcibly terminate the application. If you need to take action before the program exits (such as saving working data) then you have to tap into the JVM event handlers instead of just using the normal swing event handlers. Both will ""work"" but the EXIT_ON_CLOSE will cause problems for more complex apps. An example in support of graceful shutdown: I needed to ensure my finally block was executed so network connections were closed gracefully. This would not happen with a System.exit call (EXIT_ON_CLOSE).  I think the idea is here the WindowListener - you can add any code there that you'd like to run before the thing shuts down  If I understand you correctly you want to close the application even if the user did not click on the close button. You will need to register WindowEvents maybe with addWindowListener() or enableEvents() whichever suits your needs better. You can then invoke the event with a call to processWindowEvent(). Here is a sample code that will create a JFrame wait 5 seconds and close the JFrame without user interaction. import javax.swing.*; import java.awt.*; import java.awt.event.*; public class ClosingFrame extends JFrame implements WindowListener{ public ClosingFrame(){ super(""A Frame""); setSize(400 400); //in case the user closes the window setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); setVisible(true); //enables Window Events on this Component this.addWindowListener(this); //start a timer Thread t = new Timer(); t.start(); } public void windowOpened(WindowEvent e){} public void windowClosing(WindowEvent e){} //the event that we are interested in public void windowClosed(WindowEvent e){ System.exit(0); } public void windowIconified(WindowEvent e){} public void windowDeiconified(WindowEvent e){} public void windowActivated(WindowEvent e){} public void windowDeactivated(WindowEvent e){} //a simple timer class Timer extends Thread{ int time = 10; public void run(){ while(time-- > 0){ System.out.println(""Still Waiting:"" + time); try{ sleep(500); }catch(InterruptedException e){} } System.out.println(""About to close""); //close the frame ClosingFrame.this.processWindowEvent( new WindowEvent( ClosingFrame.this WindowEvent.WINDOW_CLOSED)); } } //instantiate the Frame public static void main(String args[]){ new ClosingFrame(); } } As you can see the processWindowEvent() method causes the WindowClosed event to be fired where you have an oportunity to do some clean up code if you require before closing the application. windowClosed should call dispose() not System.exit(0).  The following program includes code that will terminate a program lacking extraneous threads without explicitly calling System.exit(). In order to apply this example to applications using threads/listeners/timers/etc one need only insert cleanup code requesting (and if applicable awaiting) their termination before the WindowEvent is manually initiated within actionPerformed(). For those who wish to copy/paste code capable of running exactly as shown a slightly-ugly but otherwise irrelevant main method is included at the end. public class CloseExample extends JFrame implements ActionListener { private JButton turnOffButton; private void addStuff() { setDefaultCloseOperation(DISPOSE_ON_CLOSE); turnOffButton = new JButton(""Exit""); turnOffButton.addActionListener(this); this.add(turnOffButton); } public void actionPerformed(ActionEvent quitEvent) { /* Iterate through and close all timers threads etc here */ this.processWindowEvent( new WindowEvent( this WindowEvent.WINDOW_CLOSING)); } public CloseExample() { super(""Close Me!""); addStuff(); } public static void main(String[] args) { java.awt.EventQueue.invokeLater(new Runnable() { public void run() { CloseExample cTW = new CloseExample(); cTW.setSize(200 100); cTW.setLocation(300300); cTW.setVisible(true); } }); } }",java swing476678,A,"Tabs with equal (constant) width in JTabbedPane I'm trying to get a JTabbedPane where all tabs (the actual tabs not the components) have the same width (either the minimum width needed for the widest label or a constant width). I've tried to override BasicTabbedPaneUI.getTabBounds(int tabIndex Rectangle dest) but apparently this method isn't used by the painting methods of BasicTabbedPaneUI instead it uses a rects array to determine the tabs size. My next approach would be to override JTabbedPane.insertTab(String title Icon icon Component component String tip int index) and setting the preferred size of the label component but this doesn't seem very elegant and I'm not even sure it would work at all. Is there a way to achieve this? The answer is simple. When we put the name for the tab just format the name using html. say tp - JTabbedPane object tp.addTab(""<html><body><table width='150'>Name</table></body></html>""Componentobject) This sounds very good. I've seen other situations where html was the only way to achieve something in swing (e.g. line wrap on tooltips). I'll definitely give it a try.  I think it's not as complicated as you've done. Just use setTabComponentAt() with a JLabel on which you've set preferred size. That works thanks. Unfortunately I have to set all other parameters of the label component (color font size etc.) myself. I thought of retrieving the label via getTabComponentAt() but it returns null all the time. Yep that's because the getter only gets a label that was previously set (I think the doco specifically mentions that).  I've tried the following: tabPane.setUI(new javax.swing.plaf.metal.MetalTabbedPaneUI() { @Override protected int calculateTabHeight(int tabPlacement int tabIndex int fontHeight) { return super.calculateTabHeight(tabPlacement tabIndex fontHeight) + 12; } }); This seems to work fine for me. But if your using a different L&F you'll end up rendering it with the 'metal' regardless. I guess you could get the default UI and do an 'instanceof' on it to determine which is being used and instantiate it accordingly. For example: TabbedPaneUI ui = tabPane.getUI(); if (ui instanceof WindowsTabbedPaneUI) { // Create the windows rendition } else if (ui instanceof MetalTabbedPaneUI) { // Create the metal rendition } else if (ui instanceof MotifTabbedPaneUI) { // Create the motif rendition } else if (ui instanceof SynthTabbedPaneUI) { // Etc... } Thanks but this is only affecting the tab height not the width right? @Ole: That's right I don't know how I came to read width and end up giving a height example. Ah well now there for others who may need it I guess.  this is worked for me.  JLabel lab = new JLabel(); lab.setPreferredSize(new Dimension(200 30)); jTabbedPane1.setTabComponentAt(0 lab); // tab index jLabel or try this change to all tab component in same sizes (called in main method) UIManager.getLookAndFeelDefaults().put(""TabbedPane:TabbedPaneTab.contentMargins"" new Insets(10 100 0 0));",java swing jtabbedpane457463,A,"Putting JComboBox into JTable I want to put individual JComboBoxes into each cells of a JTable. ie. The JComboBox content is not identical for each cell. I basically would like to be able to just call the following code to add a row of JComboBox into the JTable. Anyone has any idea? Thanks JComboBox cb1 = new JComboBox(...); JComboBox cb2 = new JComboBox(...); model.addRow(new Object[] {""Row name"" cb1 cb2} ); JComboBox cb3 = new JComboBox(...); JComboBox cb4 = new JComboBox(...); model.addRow(new Object[] {""Row name 2"" cb3 cb4} ); This is the resultant view if I do the above. http://www.freeimagehosting.net/uploads/a6292e08ee.png The closest example code I can find is as follows. But it is for where JComboBox content is identical for the individual column. Not the solution I need. TableColumn col = table.getColumnModel().getColumn(vColIndex); col.setCellEditor(new MyComboBoxEditor(values)); where public class MyComboBoxEditor extends DefaultCellEditor { public MyComboBoxEditor(String[] items) { super(new JComboBox(items)); } } You need to create a subclass of JTable to override the method TableCellEditor getCellEditor(int row int column). This enables you to set arbitrary cell editors for any row and column combination. The default way is to set the cell editor for an entire column. (You can also set individual cell renderers by overriding getCellRenderer.)  I am sure this will solve your problem. Mention in which column you need to set the combo box in .getColumn(int column) private void addComboToTable(JComboBox combo) { TableColumn gradeColumn = YourTable.getColumnModel().getColumn(0); JComboBox comboBox = combo; comboBox.removeAllItems(); try { comboBox.addItem(""Item 1""); comboBox.addItem(""Item 2""); comboBox.addItem(""Item 3""); } catch (NullPointerException e) { } catch (Exception e) { e.printStackTrace(); } gradeColumn.setCellEditor(new DefaultCellEditor(comboBox)); }  There is a tutorial on a pattern of embedding components into JTables here: http://ivolo.mit.edu/post/A-Simple-Pattern-for-Embedding-Components-into-a-Swing-JTable.aspx  @Override public TableCellEditor getCellEditor(int row int column) { Object value = super.getValueAt(row column); if(value != null) { if(value instanceof JComboBox) { return new DefaultCellEditor((JComboBox)value); } return getDefaultEditor(value.getClass()); } return super.getCellEditor(row column); } And then override the toString method from JComboBox. This actually repeats [another answer](http://stackoverflow.com/a/946949/572834) yet it adds one point: use a customized `JComboBox` so that its `toString()` method returns the selected value. In this case you could use the default `TableCellRenderer` implementation.  The easiest way is to implement your own TableModel public class MyModel extends AbstractTableModel { List rows; public int getRowCount() { return rows.size(); } public int getColumnCount() { return 4; } public Object getValueAt(int row int column) { return rows.get(row).getCol(col); //assuming your row ""Object"" has a getCol() } public Class<?> getColumnClass(int col) { return Boolean.class; } public void setValueAt(Object aValue int rowIndex int columnIndex) { rows.get(rowIndex).getCol(columnIndex).setValue(aValue); } } Load this into you JTable. If you haven't replaced the default cell renderer for Boolean's all you cells will be rendered as check boxes thanks to you implementation of getColumnClass(). All user input to these check boxes is collected with our setValueAt(). Err he asked about a JComboBox not JCheckBox. How did this answer even get accepted? @SarelBotha Because OP was last seen at Jan 31 '09 and the correct answer is from Jun 3 '09. Apparently no one thinks this is a problem. See [meta](http://meta.stackexchange.com/questions/161946/rethinking-sort-order-of-answers).  The JComboBox content is render identical for each row selection because the JTable does not offer the capability to have more than one editor per column. You have to extend the JTable class to support an additional selection for rows. This article explains it very well: http://www.javaworld.com/javaworld/javatips/jw-javatip102.html  In addition to cellEditor it is necessary to do the cellRenderer to paint the combobox in the cell look at this:  public void example(){ TableColumn tmpColum =table.getColumnModel().getColumn(1); String[] DATA = { ""Data 1"" ""Data 2"" ""Data 3"" ""Data 4"" }; JComboBox comboBox = new JComboBox(DATA); DefaultCellEditor defaultCellEditor=new DefaultCellEditor(comboBox); tmpColum.setCellEditor(defaultCellEditor); tmpColum.setCellRenderer(new CheckBoxCellRenderer(comboBox)); table.repaint(); } /** Custom class for adding elements in the JComboBox. */ class CheckBoxCellRenderer implements TableCellRenderer { JComboBox combo; public CheckBoxCellRenderer(JComboBox comboBox) { this.combo = new JComboBox(); for (int i=0; i<comboBox.getItemCount(); i++){ combo.addItem(comboBox.getItemAt(i)); } } public Component getTableCellRendererComponent(JTable jtable Object value boolean isSelected boolean hasFocus int row int column) { combo.setSelectedItem(value); return combo; } }  You need to override: Component getTableCellRendererComponent(JTable table Object value boolean isSelected boolean hasFocus int row int column) ...in TableCellEditor. The value passed in to this method is what you can put in your JComboBox. That means that the 'value' for that particular cell needs to be something that can be translated into a collection. It could potentially just be a List of objects or it could be a POJO with fields that could be made into a JComboBox. So just edit MyComboBoxEditor to override that method and change your model to allow for an Object that actually represents several other objects.  This page might help you although it seems you are restricted to having the same combobox in all the cells in a column.  Extend JTable with this code: @Override public TableCellEditor getCellEditor(int row int column) { Object value = super.getValueAt(row column); if(value != null) { if(value instanceof JComboBox) { return new DefaultCellEditor((JComboBox)value); } return getDefaultEditor(value.getClass()); } return super.getCellEditor(row column); } This will create a unique JComboBox cell editor for each combo box you get the a value for. +1 -- one should also should set a custom `TableCellRenderer` on the `TableColumnModel` of the corresponding column in order to ensure that the selected value is drawn instead of a string `javax.swing.JCombobox[...]` while the cell is not being edited. This `TableCellRenderer` should implement `getTableCellRendererComponent(..)` and could return a `JLabel` with the value of `JComboBox.getSelectedItem().toString()` (after checking for null pointers).",java swing jtable jcombobox110016,A,"JTable Sort I know that Jtable can sort by a single column. But is it possible to allow for multiple column sort or do i need to write the code myself? Thanks in advance You should be able to set the TableRowSorter and the Comparator associated with it. Example: TableModel myModel = createMyTableModel(); JTable table = new JTable(myModel); TableRowSorter t = new TableRowSorter(myModel); t.setComparator(column that the comparator works against Comparator<?> comparator); table.setRowSorter(new TableRowSorter(myModel)); unrelated to multi-column sorts  You can sort by multiple columns by specifying more than one sort key when calling setSortKeys in the RowSorter you're using. a pity this isn't available in java5  ""I know that Jtable can sort by a single column. But is it possible to allow for multiple column sort or do i need to write the code myself? "" Table sorting and filtering is managed by a sorter object. The easiest way to provide a sorter object is to set autoCreateRowSorter bound property to true; JTable table = new JTable(); table.setAutoCreateRowSorter(true); This action defines a row sorter that is an instance of javax.swing.table.TableRowSorter. _no_ is wrong - a JTable definitely supports multi-column sorts (see setSortKeys as mentioned in another answer) only the visual clue is showing on the primary sort column only  ETable from the netbeans collection. It is part of org-netbeans-swing-outline.jar A google search aught to turn it up. The ETable is primarily a foundation for Outline (a TreeTable) but it has multi-column ordering built in as well as many other nice features  Look into JXTable. JXTable is an extension of JTable that supports multi-column sorting as well as other functions that JTable doesn't provide. It's freely available from JDNC / SwingLabs. Are you sure there? Actually the JXTable API states: ""Sorting support is single column only."" Ok but it works with filters. you just have to put shuttlesorters into a filterpipeline",java swing286727,A,"Java KeyListener for JFrame is being unresponsive? I'm trying to implement a KeyListener into my JFrame. On the constructor I'm using this code: System.out.println(""test""); addKeyListener(new KeyListener() { public void keyPressed(KeyEvent e) { System.out.println( ""tester""); } public void keyReleased(KeyEvent e) { System.out.println(""2test2""); } public void keyTyped(KeyEvent e) { System.out.println(""3test3""); } }); When I run it the test message comes up in my console. However when I press a key I don't get any of the other messages as if the KeyListener was not even there. I was thinking that it could be because the focus is not on the JFrame and so they KeyListener doesn't recieve any events but I'm pretty sure it is. Is there something that I am missing? I got the same problem until i read that the real problem is about FOCUS the your JFrame has already added Listeners but tour frame is never on Focus because you got a lot of components inside your JFrame that also are focusable so try: JFrame.setFocusable(true); Good Luck Great!This is the right answer! I found that this works only until I use something that is on my JFrame then the KeyListener no longer responds  You must add your keyListener to every component that you need. Only the component with the focus will send these events. For instance if you have only one TextBox in your JFrame that TextBox has the focus. So you must add a KeyListener to this component as well. The process is the same: myComponent.addKeyListener(new KeyListener ...); Note: Some components aren't focusable like JLabel. For setting them to focusable you need to: myComponent.setFocusable(true); yea you were right when the program starts you can slightly see that the focus is on the button A. adding a keylistener to each button fixed this. thats a little weird i would think that adding a keylistener to the JFrame would work but i guess not. Thanks!  This should help  yourJFrame.setFocusable(true); yourJFrame.addKeyListener(new java.awt.event.KeyAdapter() { @Override public void keyTyped(KeyEvent e) { System.out.println(""you typed a key""); } @Override public void keyPressed(KeyEvent e) { System.out.println(""you pressed a key""); } @Override public void keyReleased(KeyEvent e) { System.out.println(""you released a key""); } });  InputMaps and ActionMaps were designed to capture the key events for the component it and all of its sub-components or the entire window. This is controlled through the parameter in JComponent.getInputMap(). See How to Use Key Bindings for documentation. The beauty of this design is that one can pick and choose which key strokes are important to monitor and have different actions fired based on those key strokes. This code will call dispose() on a JFrame when the escape key is hit anywhere in the window. JFrame doesn't derive from JComponent so you have to use another component in the JFrame to create the key binding. The content pane might be such a component. InputMap inputMap; ActionMap actionMap; AbstractAction action; JComponent component; inputMap = component.getInputMap(JComponent.WHEN_IN_FOCUSED_WINDOW); actionMap = component.getActionMap(); action = new AbstractAction() { @Override public void actionPerformed(ActionEvent e) { dispose(); } }; inputMap.put(KeyStroke.getKeyStroke(KeyEvent.VK_ESCAPE 0) ""dispose""); actionMap.put(""dispose"" action);  You could have custom JComponents set their parent JFrame focusable. Just add a constructor and pass in the JFrame. Then make a call to setFocusable() in paintComponent. This way the JFrame will always receive KeyEvents regardless of whether other components are pressed. -1 definitely not - that's complete in more than one respect: a) indecent subclassing b) indecent reference passing c) inappropriate state change while painting d) ..  lol .... all you have to do is make sure that addKeyListener(this); is placed correctly in your code. You should really explain the ""correct place"" to make this a helpful answer.  If you don't want to register a listener on every component you could add your own KeyEventDispatcher to the KeyboardFocusManager: public class MyFrame extends JFrame { private class MyDispatcher implements KeyEventDispatcher { @Override public boolean dispatchKeyEvent(KeyEvent e) { if (e.getID() == KeyEvent.KEY_PRESSED) { System.out.println(""tester""); } else if (e.getID() == KeyEvent.KEY_RELEASED) { System.out.println(""2test2""); } else if (e.getID() == KeyEvent.KEY_TYPED) { System.out.println(""3test3""); } return false; } } public MyFrame() { add(new JTextField()); System.out.println(""test""); KeyboardFocusManager manager = KeyboardFocusManager.getCurrentKeyboardFocusManager(); manager.addKeyEventDispatcher(new MyDispatcher()); } public static void main(String[] args) { MyFrame f = new MyFrame(); f.pack(); f.setVisible(true); } } KeyboardFocusManager is application wide if you have multi frames you will get trouble? So this should work something like: foreach(""focusable components in the frame"" as _){ _.addkeylistener(frameKeylistener);}  in order to capture key events of ALL text fields in a JFrame one can employ a key event post processor. Here is a working example after you add the obvious includes. public class KeyListenerF1Demo extends JFrame implements KeyEventPostProcessor { public static final long serialVersionUID = 1L; public KeyListenerF1Demo() { setTitle(getClass().getName()); // Define two labels and two text fields all in a row. setLayout(new FlowLayout()); JLabel label1 = new JLabel(""Text1""); label1.setName(""Label1""); add(label1); JTextField text1 = new JTextField(10); text1.setName(""Text1""); add(text1); JLabel label2 = new JLabel(""Text2""); label2.setName(""Label2""); add(label2); JTextField text2 = new JTextField(10); text2.setName(""Text2""); add(text2); // Register a key event post processor. KeyboardFocusManager.getCurrentKeyboardFocusManager() .addKeyEventPostProcessor(this); } public static void main(String[] args) { JFrame f = new KeyListenerF1Demo(); f.setName(""MyFrame""); f.pack(); f.setVisible(true); } @Override public boolean postProcessKeyEvent(KeyEvent ke) { // Check for function key F1 pressed. if (ke.getID() == KeyEvent.KEY_PRESSED && ke.getKeyCode() == KeyEvent.VK_F1) { // Get top level ancestor of focused element. Component c = ke.getComponent(); while (null != c.getParent()) c = c.getParent(); // Output some help. System.out.println(""Help for "" + c.getName() + ""."" + ke.getComponent().getName()); // Tell keyboard focus manager that event has been fully handled. return true; } // Let keyboard focus manager handle the event further. return false; } } For a working example you might consider adding the imports. I usually add 'package imports' to keep them short. Otherwise +1. Interesting technique.  Deion (and anyone else asking a similar question) you could use Peter's code above but instead of printing to standard output you test for the key code PRESSED RELEASED or TYPED. @Override public boolean dispatchKeyEvent(KeyEvent e) { if (e.getID() == KeyEvent.KEY_PRESSED) { if (e.getKeyCode() == KeyEvent.VK_F4) { dispose(); } } else if (e.getID() == KeyEvent.KEY_RELEASED) { if (e.getKeyCode() == KeyEvent.VK_F4) { dispose(); } } else if (e.getID() == KeyEvent.KEY_TYPED) { if (e.getKeyCode() == KeyEvent.VK_F4) { dispose(); } } return false; }  Hmm.. what class is your constructor for? Probably some class extending JFrame? The window focus should be at the window of course but I don't think that's the problem. I expanded your code tried to run it and it worked - the key presses resulted as print output. (run with Ubuntu through Eclipse): public class MyFrame extends JFrame { public MyFrame() { System.out.println(""test""); addKeyListener(new KeyListener() { public void keyPressed(KeyEvent e) { System.out.println(""tester""); } public void keyReleased(KeyEvent e) { System.out.println(""2test2""); } public void keyTyped(KeyEvent e) { System.out.println(""3test3""); } }); } public static void main(String[] args) { MyFrame f = new MyFrame(); f.pack(); f.setVisible(true); } } I get all of the messages output also. Run in Windows command line. You get all the messages because in this example the JFrame has the focus. try adding a TextBox component to the JFrame and see what happens.  I have been having the same problem. I followed Bruno's advice to you and found that adding a KeyListener just to the ""first"" button in the JFrame (ie on the top left) did the trick. But I agree with you it is kind of an unsettling solution. So I fiddled around and discovered a neater way to fix it. Just add the line myChildOfJFrame.requestFocusInWindow(); to your main method after you've created your instance of your subclass of JFrame and set it visible.  KeyListener is low level and applies only to a single component. Despite attempts to make it more usable JFrame creates a number of component components the most obvious being the content pane. JComboBox UI is also often implemented in a similar manner. It's worth noting the mouse events work in a strange way slightly different to key events. For details on what you should do see my answer on Application wide keyboard shortcut - Java Swing.",java swing jframe keylistener316454,A,"Can you set a permanent size for a JPanel inside of a JFrame? My current problem is that I have a JFrame with a 2x2 GridLayout. And inside one of the squares I have a JPanel that is to display a grid. I am having a field day with the java swing library... take a look Image Java is automatically expanding each JLabel to fit the screen. I want it to just be those blue squares (water) and the black border and not that gray space. Is there a way I can just set the size of that JPanel permanently so that I don't have to go through changing the size of the JFrame a million times before I get the exact dimension so that the gray space disappears? I also would like to set the size of those buttons so they are not so huge (BorderLayout is being used for the buttons and TextField) GridBagLayout is what you really want to use. The GridLayout will force the same size for each component in the layout no matter what size constraints you put on them. GridBagLayout is a lot more powerful and a lot more complicated. Study up on the API page for it. Using GridBagLayout the components won't fill the whole grid space if you don't want them to and can even stay the size that you ask it to be. To keep a component's size from changing I would set all three available size constraints: water.setPreferredSize(new Dimension(20 20)); water.setMinimumSize(new Dimension(20 20)); water.setMaximumSize(new Dimension(20 20)); For your buttons I would definitely use an inner panel as Bryan mentions. You could use either a GridLayout like he suggests or a FlowLayout if you don't want all the buttons to be the same size. Add all your buttons to that inner panel instead of the main one.  If you can setResizeable( false ) on the top level frame you can then set your layout manager to null and hard code each location and size via setBounds. This is how I would do it (contingent on resizing of course).  I have had success solving problems like these using TableLayout which is a third party layout manager. You will need to download it and read the tutorial but the key would be to set the justification to CENTER when adding the JButtons to their positions in the layout.  If you want the two checkerboards to stay the same size then you'll need to have them each contained in their own JPanel. Set each of those parent JPanel's to have a layout type of GridBagLayout. Set the preferedSize for each checkerboard component and then add them to their respective containers. GridBagLayout should by default lay each board out in the center of the parent JPanel. So as the window is resized the JPanel parent area will get larger or smaller but the checkerboard components inside will remain the same size. Alternatively you could have your blue squares scale to the right size as the window is resized by having each checkboard square be a JPanel with a BorderLayout layout manager and adding the JLabel (with a blue background color) to its BorderLayout.CENTER location. As for your buttons try something like this: JPanel theButtonPanel = new JPanel(new BorderLayout()); JButton button1 = new JButton(""Fire""); JButton button2 = new JButton(""Pass""); JButton button3 = new JButton(""Forfiet""); JPanel innerButtonContainer = new JPanel(new Grid(1 3 8 8)); innerButtonContainer.add(button1); innerButtonContainer.add(button2); innerButtonContainer.add(button3); theButtonPanel.add(innterButtonContainer); Lastly consider using a design tool for your Swing user interface. Netbeans has an excellent UI designer built into it. Download Netbeans here.",java swing size jlabel grid-layout112603,A,"What is 'JNI Global reference' I am using jProfiler to find memory leaks in a Java swing application. I have identified instances of a JFrame which keeps growing in count. This frame is opened and then closed. Using jProfiler and viewing the Paths to GC Root there is only one reference 'JNI Global reference'. What does this mean? Why is it hanging on to each instance of the frame? A JNI global reference is a reference from ""native"" code to a Java object managed by the Java garbage collector. Its purpose is to prevent collection of an object that is still in use by native code but doesn't appear to have any live references in the Java code. A JFrame is a java.awt.Window and is associated with a ""native"" Window object. When you are completely finished with a particular JFrame instance you should invoke its dispose() method to clean up. I am not sure if any native code is creating a global reference to the JFrame but it seems likely. If it does this will prevent the JFrame from being garbage collected. If you are creating many Windows (or subclasses) and seeing that they are never collected make sure that they are disposed. If the code is only Java this is the most likely explanation. I've had problems with global pointers but I've been working with JNI.  Wikipedia has a good overview of Java Native Interface essentially it allows communication between Java and native operating system libraries writen in other languages. JNI global references are prone to memory leaks as they are not automatically garbage collected and the programmer must explicitly free them. If you are not writing any JNI code yourself it is possible that the library you are using has a memory leak. edit here is a bit more info on local vs. global references and why global references are used (and how they should be freed) Wikipedia is a secondary source. The primary source and official document is the [JNI Specification](http://docs.oracle.com/javase/6/docs/technotes/guides/jni/spec/jniTOC.html).",java swing jprofiler458817,A,"Java Swing: Libraries Tools Layout Managers What libraries/tools do you have in your Java Swing Tool set? XUL Layout Managers Packagers/Installers Books etc..... Two useful Swing related libraries: The Swing Application Framework is a light framework that simplifies the creation and maintaining of small- to medium-sized Java desktop applications. The framework consists of a Java class library that supports constructs for things such as the following: Remembering state between sessions. Easier managing of actions including running as background tasks and specifying blocking behavior. Enhanced resource management including resource injection for bean properties. Here's an article about it. It's been integrated with Netbeans 6.0 and later. EventBus is a Swing-oriented publisher-subscriber framework that I've found very useful for updating GUIs.  Not really a tool but I've been working on annotating important things in the JavaDocs for Swing (and several other APIs). Too many methods contain surprises like ""don't call this if you want a refresh call X instead"". I use a tool that I built for my PhD to access that kind of info (it highlights calls in the source code to methods that have those sort of things). IMHO the JavaDocs for swing are difficult to use because they combine information that is meant for people using an object and people subclassing existing classes. Sounds interesting. Anything that you are going to make available to the rest of us? Right now it only supports Eclipse. I've still got to do some cleanups and update the annotations database before I am presenting it at Eclipsecon at the end of March but if you want to try it out visit http://emoose.cs.cmu.edu or contact me and I'll gladly help you with the install.  Here is what I use: ""Framework"": Swing Application Framework does not do much but does it quite well (if you use it you may want to take a look at one presentation I did last year) JTables: handling tables is often a pain (lots of boilerplate code...); I generally use GlazedLists which simplifies the work a lot (and brings many improvements) EventBus: this was mentioned in another answer LayoutManager: DesignGridLayout (shameless plug this is one of my open source projects) Look & Feel: Substance is very good in some situations where you don't want to use the system look and feel Docking library: if your application needs docking you will find MyDoggy useful (and it has a well-written API). One problem it has is a bad integration with some third-party look and feels (like Substance) All these libraries above are open source. In addition to that I have my own set of utility classes that among other things help integrating the GUI with a Dependency Injection library: I have a set of utilities for HiveMind container (for the few developers that know it and still use it) and another -in preparation soon open sourced- for Guice. I have read no specific book about Swing development but I have used Swing for about 10 years now (not continuously however). Hence I have no recommendation in terms of books (unfortunately because I admit that this is one weak point of Swing). ""Filthy Rich Clients"" book is useful only if: you know Swing well you want to build ""fancy"" GUIs  For books take a look at the answers to Swing Programming Books.  Netbeans with the GUI WYSIWYG editor. It makes creating Java 6 Swing forms very easy. I subclass the forms to add functionality to ensure continued tool support. I've also used SwingX for widgets like date pickers and collapsible panels. Plus there's always SwingWorker in the JRE for running background jobs that update the UI.  I pretty much only use GridBagLayout for production code unless the GUI is so simple that I can get away with a BorderLayout. I sometimes look into other LayoutManagers but never really found the need to change since GridBagLayout can do pretty much anything I need. The installer I use for my own stuff is izPack and works for me so far. It has been a long time since I really read any Swing books now. Obviously the Java Swing one from O'Reilly is the de facto bible :) When it comes to books on design I do have a lot of recommendations but that might be off topic? Totally Gridbag - http://madbean.com/anim/totallygridbag/ @Ran Biron that is the best comment I have seen on SO thus far. That is so reminiscent of my GridBagLayout experiences. At one point I even wrote a GridBagLayout wrapper for most of the stuff I do but it's hard to really grok. +1 for this answer so more people see this comment :)  Spring Rich Client and JGoodies are the base of my team's GUI applications; Spring remoting for connecting to server and Java Web Start for deployement.",java swing devtools2594090,A,"mysql error in php i'm trying to run this php code which should display a quote from mysql but can't figure out where is it going wrong. the result variable is null or empty. can someone help me out. thanks! <?php include 'config.php'; // 'text' is the name of your table that contains // the information you want to pull from $rowcount = mysql_query(""select count(*) as rows from quotes""); // Gets the total number of items pulled from database. while ($row = mysql_fetch_assoc($rowcount)) { $max = $row[""rows""]; //print_r ($max); } // Selects an item's index at random $rand = rand(1$max)-1; print_r ($rand); $result = mysql_query(""select * from quotes limit $rand 1"") or die ('Error: '.mysql_error()); if (!$result or mysql_num_rows($result)) { echo ""Empty""; } else{ while ($row = mysql_fetch_array($result)) { $randomOutput = $row['cQuotes']; echo '<p>' . $randomOutput . '</p>'; } } Seems like you have an unnecessary query in there. Try this instead and cut out some code: `SELECT * FROM quotes ORDER BY rand() LIMIT 1` The performance drawbacks of `ORDER BY Rand() LIMIT 1` have been discussed numerous times here on SO and all over the internet... http://stackoverflow.com/search?q=mysql+rand @VolkerK - Indeed there are performance drawbacks but that doesn't preclude it from being a viable option in difference scenarios. if ($result && mysql_num_rows($result) > 0) { while ($row = mysql_fetch_array($result)) { $randomOutput = $row['cQuotes']; echo '<p>' . $randomOutput . '</p>'; } } else { echo ""Empty""; } thanks! that worked!  $result = mysql_query(""SELECT * FROM quotes ORDER BY rand() LIMIT 1"") or die ('Error: '.mysql_error()); if (!$result || mysql_num_rows($result) == 0) echo ""Empty""; else { while ($row = mysql_fetch_array($result)) { $randomOutput = $row['cQuotes']; echo '<p>' . $randomOutput . '</p>'; } }  // your script probably can't go on without this file? require 'config.php'; // I prefer to always pass the connection resource to mysql_query/mysql_real_escape_string // assume $mysql = mysql_connect.... $result = mysql_query(""SELECT Count(*) AS rows FROM quotes"" $mysql) or die(mysql_error()); // there's only one row with only one column so mysql_result() is fine $rowcount = mysql_result($result 0 0); $rand = rand(0$rowcount-1); $result = mysql_query(""SELECT cQuotes FROM quotes LIMIT $rand 1"" $mysql) or die ('Error: '.mysql_error()); // there's either one or zero records. Again no need for a while loop $row = mysql_fetch_array($result MYSQL_ASSOC); if ( !$row ) { echo ""Empty""; } else{ // do you have to treat $row['cQuotes'] with htmlspecialchars()? echo '<p>' $row['cQuotes'] '</p>'; } thank you! this was helpful.",php sql database mysql2202888,A,"MySQL database setup help I am making a classifieds website... I have these 6 tables: Every category has sub-categories (or options) which you can see below. Lets say the user wants to post a classified and has entered all info into the forms necessary and I am at the stage where I have to create the PHP code to actually INSERT the data into the database. I am thinking something like this: mysql_query(""INSERT INTO classifieds (classified_id ad_id poster_id cat_id area_id headline description) VALUES ($classified_id '$ad_id' $poster_id $cat_id $area_id '$headline' '$description')""); But I don't know where to take it from here... I think the posters table should not be like this because how should I determine what the poster_id should be? Or should I set it to auto-increment? Remember this posters may not log in or anything so there is no problem with one person having multiple poster_table records if you know what I mean. classified_id is a random unique value generated by PHP so that is always unique. Please guide me! I don't know how to link the tables together correctly. If you have any Q let me know and I will update this Q! category table: cat_id (PK) cat_name category_options table: option_id (PK) cat_id (FK) option_name option_values table: value_id (PK) option_id (FK) value classifieds table: classified_id (PK) ad_id (VARCHAR) something like ""Bmw330ci_28238239832"" which will appear in URL poster_id (FK) cat_id (FK) area_id (FK) headline description price etc.... posters table: poster_id (PK) name email tel password area table: area_id (PK) area community You've got the right idea already. When someone creates a post and enters their personal info FIRST insert the ""poster"" record into the posters table. The ""poster_id"" primary key for that table should be an auto_increment field. Next get the ID of the new poster you just created using PHP's ""mysql_insert_id"". That integer value will be the number you put in the ""poster_id"" foreign key field in the ""classifieds"" table. Structurally your database schema is looking pretty good.  You should usually set the primary key to an auto-increment field. When you have linked tables and you need to join on the id you can first insert into the main table and then use the function mysql_insert_id to retrieve the id of the element you just inserted. You can then insert into the other table using this value as the foreign key. This is a very standard way to do things so it should be fine for you. But I have a primary key in every table do they all have to be AI? They don't have to be but it's almost always a good idea to have the primary key as an auto-increment. One obvious exception is when you have an intermediate table then you only need the two foreign keys and no extra column for the primary key. I don't think you have such a table in your schema though so it doesn't matter. so in my case what would you set to primary? I mean the cat_id couldn't be PK right? because there are 15 categories I have which are constant (ie set by me non-changeable)... If you've defined some fixed ID's in your code then you can use those as a primary key but if there's any chance ever that you might have to change those ids then it wouldn't hurt to add an extra column with an auto-increment id as the PK and use that in all joins. Changing a PK once your system is live is a painful experience. You should avoid using a PK that might one day need to change.",php sql mysql database2226997,A,"query_cache_min_res_unit; What is it and what does it do? I am setting up cache in MySQL. Could someone please explain query_cache_min_res_unit? What does it do etc? I have read the manual and it doesn't explain so good. Details are appreciated... Or examples... Thanks query_cache_min_res_unit is a variable which may be used for optimization queries depending on large of result sets you may be working with. By definition the value is the minimum amount of memory MySQL will allocate to store a query. You would want the this value to be roughly the average query size. Each database has different values for the minimum depending on how large of sets you are working with. Here is mine: mysql> show variables like ""query%""; +------------------------------+---------+ | Variable_name | Value | +------------------------------+---------+ | query_alloc_block_size | 8192 | | query_cache_limit | 1048576 | | query_cache_min_res_unit | 4096 | | query_cache_size | 0 | | query_cache_type | ON | | query_cache_wlock_invalidate | OFF | | query_prealloc_size | 8192 | +------------------------------+---------+ 7 rows in set (0.25 sec) As you can see my minimum value is 4096 bytes. As a follow-up you can read more at Optimizing the MySQL Query Cache Thanks I think I understand. That article was good! Btw I think that the numbers in the variables are bytes not KB... I'm not sure though... Thanks :) You might be correct I'll edit it anyways because now I am doubtful myself. the query cache allocates blocks with a minimum size given by the query_cache_min_res_unit system variable. When a query is executed the last result block is trimmed to the actual data size so that unused memory is freed. If you do click through to the linked article; note the comments at the bottom!",php sql mysql database caching2213433,A,"Can't get all values from mysql table I have this table: option_values table: option_id (FK) value_id (PK) classified_id (FK) value example:  option_id (FK) value_id (PK) classified_id (FK) value 1 1 22 'Petrol' 2 2 22 'Manual' 3 3 22 'Black' How can I retrieve and echo every value found with the classified_id=22 ? I have tried this:  $res=mysql_query(""SELECT * FROM option_values WHERE classified_id=22""); $row = mysql_fetch_row($res); echo $row[3]; // This displays 'Petrol' But how can I also display the 'Manual' 'Black' etc? Thanks  $res=mysql_query(""SELECT * FROM option_values WHERE classified_id=22""); while($row = mysql_fetch_array($res)) { echo $row[1]; echo $row[2]; echo $row[3]; }  $res=mysql_query(""SELECT * FROM option_values WHERE classified_id=22""); while(FALSE != ($row = mysql_fetch_row($res)) { echo $row[3]; } Why are you calling mysql_fetch_rows twice? bad copy paste i'll edit  Do yourself a favor and implement a helper function like so: function fetch_multi_rows($query) { $rows = array(); while ( $row = mysql_fetch_array($result) ) $rows[] = $row; return $rows; } // Use it like this $my_rows = fetch_multi_rows(...your query...); foreach ( $my_rows as $row ) echo $row[3]; Cheers!  Use this you need to get an array of rows...they way you are doing it is giving you a single row's value in an array. while ($row = mysql_fetch_array($result MYSQL_NUM)) { printf(""ID: %s Value: %s"" $row[0] $row[3]); } Source: here  You can write a ""more object oriented"" code like :)  // Execute the query $res = mysql_query(""SELECT * FROM option_values WHERE classified_id=22""); // Check for empty result if (mysql_num_rows($result) == 0) { echo ""No results.""; exit; } // Fetch results as objects while ($row = mysql_fetch_object($result)) { echo ""Option Id: "".$row->option_id; echo ""Value: "".$row->value; } // Free results memory mysql_free_result($result); Cheers Mate!",php sql mysql database2966418,A,Check mysql_query results if DELETE query worked? I have a DELETE query which deletes a record from a mysql db. is there any way to make sure if the delete was performed or not? I mean for a query to FIND stuff you do  $res=mysql_query($var); $nr=mysql_num_rows($res); and you get nr of rows returned. Is there any similiar method for deletion of records? Thanks Use mysql_affected_rows(). It does not require the response as a parameter. mysql_query('DELETE FROM whatever'); $num = mysql_affected_rows(); Also I like PDO better than the classic mysql_ functions. Just saying.,php sql mysql database1176014,A,"How to model a many to many relationship? With only a bit of previous experience with databases and no formal education with them I'm a bit stuck as to how to model this (and retrieve the data I require from it in PHP). This is what I'm trying to model: For each item on my site it is allowed to have multiple tags such as file upload php recursive etc. However the tags are reusable I can have two different items and they each could have the php tag. I've been trying to read up on how to do this and whether it is lack of experience with it or something else I don't know but I can't seem to grasp the concept. Apparently you need a middle table which links the two together? Also once I have this relationship and the tables defined how would I do things such as: - Retrieve all items with a certain tag? - Retrieve all tags that one item has? Thanks for your help also if anyone could list any further reading on this to strengthen my understanding of the concept that would be great. The db part is easy. This is just a sample so you can see how db can look like not any particular SQL engine queries. CREATE TABLE posts ( id INT PRIMARY KEY subject VARCHAR(100) body TEXT ) CREATE TABLE tags ( id INT PRIMARY KEY name VARCHAR(50) ) CREATE TABLE post_tags ( post_id INT tag_id INT FOREIGN KEY (post_id) REFERENCES posts (id) FOREIGN KEY (tag_id) REFERENCES posts (id) ) To get items with yourTag tag you will just run query like this SELECT P.* FROM posts P LEFT JOIN post_tags PT ON (PT.post_id = P.id) LEFT JOIN tags T ON (T.id = PT.tag_id) WHERE T.name = 'yourTag'; To get tags associated with post with id of 123 you run this query: SELECT T.* FROM tags T LEFT JOIN post_tags PT ON (T.id = PT.tag_id) LEFT JOIN posts P ON (PT.post_id = P.id) WHERE P.id = 123; For the PHP part you could use a framework. Many (if not all) frameworks can easily model such relationships. For example in CakePHP this done like that: class Post extends AppModel { $useTable = 'posts'; $hasAndBelongsToMany = array( 'Tag' => array( 'className' => 'Tag' 'joinTable' => 'post_tags' 'foreignKey' => 'post_id' 'associationForeignKey' => 'tag_id' ) ); } class Tag extends AppModel { $useTable = 'tags'; $hasAndBelongsToMany = array( 'Post' => array( 'className' => 'Post' 'joinTable' => 'post_tags' 'foreignKey' => 'tag_id' 'associationForeignKey' => 'post_id' ) ); } ITYM Tag->$hasAndBelongsToMany = array( 'Post' ... etc. Thanks for the database part thats fantastic. I use CodeIgniter and it doesn't actually model relationships like that you have to do it yourself. Plus I'd prefer to actually understand the SQL queries involved as opposed to relying on automagic. @Stobor - thanks for finding that this was a copying error @James - I put a sample query for you as well. Understanding queries is important but once you start working with ORM you won't probably come back to typing SQLs Nicely shown. Marginally better solution than serializing arrays and then putting them into table cells like I've too-often seen.  You should use an intermediate table to relate the two entities:  -------- 1:n ------------ --------- | ITEM |-Î_---------<| ITEM_TAG | n:1 | TAG | | Id | | ItemId |>-------Î_-| Id | | Name | | TagId | | Name | ÎÀÎÀÎÀÎÀÎÀÎÀÎÀÎÀ ÎÀÎÀÎÀÎÀÎÀÎÀÎÀÎÀÎÀÎÀÎÀÎÀ ÎÀÎÀÎÀÎÀÎÀÎÀÎÀÎÀÎÀ Then for querying the data you should join your tables in a select statement: All the items in the tag ""FooTag"" SELECT item.* FROM item JOIN item_tag on item.id = item_tag.itemId JOIN tag on item_tag.tagId = tag.id WHERE tag.Name = 'FooTag' All the tags for the item with name ""FooItem"" SELECT tag.* FROM tag JOIN item_tag on tag.id = item_tag.tagId JOIN item on item_tag.itemId = item.id WHERE item.Name = 'FooItem' nice diagram :) +1  Yeah many-to-many relationship needs additional third table called association table. Database part is not that hard it's harder to use it in code with all those left joins and it can get pretty messy :) My advice is to use ORM framework like Doctrine or Propel (though I prefer Doctrine) which handle even some complex queries for you.  You're right many-to-many relationships are implemented using additional table for instance: Blog_entry(entry_id entry_body) Tag(tag_id tag_name) Entry_tag(entry_id tag_id) Any operations are being done using multiple joins. For instance if you want to select all entries with tag 'foo' using tables from my example you have to execute: select * from blog_entry tag entry_tag where tag.tag_name = 'foo' and entry_tag.tag_id = tag.tag_id and entry_tag.entry_id = blog_entry.entry_id (update) To retrieve all tags that certain entry (here with ID 123) has: select tag_name from blog_entry tag entry_tag where Blog_entry.entry_id = 123 entry_tag.tag_id = tag.tag_id and entry_tag.entry_id = blog_entry.entry_id",php sql database many-to-many2287881,A,"Search database using LIKE and wildcards I have four search fields that are used to search a database for book id:s and then echos out the result. Depending on wich field you choose to search from the sql query builds up as you can see in the code below. The title and isbn field are working fine but when I try to use the author or category field nothing gets returned. The relevent database tables can also be seen below. Maybe thereÎ‚s something wrong with the way I use the sql function LIKE??? Database: CREATE TABLE IF NOT EXISTS `bok` ( `bokId` int(11) NOT NULL AUTO_INCREMENT `bokTitel` varchar(100) DEFAULT NULL `upplaga` varchar(100) DEFAULT NULL `ISBN` varchar(30) DEFAULT NULL PRIMARY KEY (`bokId`) ) CREATE TABLE IF NOT EXISTS `skrivenav` ( `bokId` int(11) DEFAULT NULL `fId` smallint(6) DEFAULT NULL ) CREATE TABLE IF NOT EXISTS `forfattare` ( `fId` smallint(6) NOT NULL `fNamn` varchar(80) DEFAULT NULL PRIMARY KEY (`fId`) ) CREATE TABLE IF NOT EXISTS `bokkat` ( `bokId` int(11) DEFAULT NULL `katId` smallint(6) DEFAULT NULL ) CREATE TABLE IF NOT EXISTS `kategori` ( `katId` smallint(6) NOT NULL `katNamn` varchar(80) DEFAULT NULL PRIMARY KEY (`katId`) ) PHP code: <?php $q = ""SELECT DISTINCT bokId FROM ""; if($_GET['search_title']!=""""||$_GET['search_ISBN']!=""""){ $q = $q.""(SELECT * FROM bok WHERE ""; if($_GET['search_title']!="""") $q = $q.""bokTitel LIKE '%$_GET[search_title]%' ""; if($_GET['search_title']!="""" && $_GET['search_ISBN']!="""") $q = $q.""AND ""; if($_GET['search_ISBN']!="""") $q = $q.""ISBN LIKE '%$_GET[search_ISBN]%' ""; $q = $q."") AS F""; } else $q = $q.""bok""; if($_GET['search_author']!=""""){ $author = explode("""" $_GET['search_author']); $auth = """"; foreach ($author as $value){ $auth = $auth . ""%"" . $value . ""%' '""; } $auth = trim($auth "" '""); $q = $q."" NATURAL JOIN (SELECT * FROM skrivenav NATURAL JOIN forfattare WHERE fNamn LIKE ('$auth')) AS S ""; } if($_GET['search_category']!="""") { $category = explode("""" $_GET['search_category']); $cat = ""'""; foreach ($category as $value){ $cat = $cat . ""%"" . $value . ""%' '""; } $cat = trim($cat "" '""); $q = $q."" NATURAL JOIN (SELECT * FROM bokkat NATURAL JOIN kategori WHERE katNamn LIKE ('$cat')) AS K ""; } $rs = mysql_query($q); confirm_query($rs); while($row = mysql_fetch_row($rs)){ echo $row[0].""<br />""; } ?> Generated query when searching with author field: SELECT DISTINCT bokId FROM bok NATURAL JOIN (SELECT * FROM skrivenav NATURAL JOIN forfattare WHERE fNamn LIKE ('%Jonas%' '%Alex%')) AS S Quick solution from anthares answer and it worked so thank you!! if($_GET['search_author']!=""""){ $author = explode("""" $_GET['search_author']); $auth = """"; $q = $q. "" NATURAL JOIN (SELECT * FROM skrivenav NATURAL JOIN forfattare WHERE fNamn LIKE ""; foreach ($author as $value){ $auth = $auth . ""%"" . $value . ""%'""; $q = $q. ""'$auth OR ""; $auth = """"; } $q = trim($q "" OR""); $q = $q. "") AS A""; } Please post the generated query that causes wrong results. This will make it a lot easier to help. I think this piece of code: foreach ($author as $value){ $auth = $auth . ""%"" . $value . ""%' '""; } $auth = trim($auth "" '""); $q = $q."" NATURAL JOIN (SELECT * FROM skrivenav NATURAL JOIN forfattare WHERE fNamn LIKE ('$auth')) AS S ""; will return a result only if you pass as value subset of the real authors in exact order which is written. So this query doesn't check for scrambled authors' names. The same thing with categories. You should add an ""or"" in your where clause for every category or author in your filter and make a separate expression for each of them.",php sql database1592391,A,CakePHP mathematic-calculation field? (Database structure like http://stackoverflow.com/questions/1545764/cakephp-select-default-value-in-select-input) So I have two tables in CakePHP: Trees and Leafs. Every Leaf has a tree_id for its corresponding tree. Every leaf also has a numeric value. The default view that I baked for trees just lists all the trees in a table. Is there a way to add a dynamic column to that view's table that SUMS all the leafs of that tree and displays the sum in the table as well as another field showing the number of leafs a tree has? example: Leafs Id | Tree Id | Leaf value -----+-----------+--------------- 24 | 1 | 19 70 | 1 | 33 121 | 1 | 30 Trees Id | Tree | Number of leafs | Sum of leafs | Actions -----+--------+-------------------+----------------+------------------- 1 | foo | 120 | 7270 | View Edit Delete 2 | bar | 72 | 4028 | View Edit Delete I don't think you can use group within containable calls. 1.3 should have support for this: http://teknoid.wordpress.com/2009/10/06/top-10-things-to-look-forward-to-in-cakephp-1-3/  Two ideas: Fetch the summed field dynamically each time you need it using the Containable behavior like (off the top of my head): $this->Tree->find('all' array( ... 'contain' => array( 'Leaf' => array( 'fields' => array('SUM(Leaf.value)') 'group' => array('Leaf.tree_id') ) ) ); Or create a new column in the Tree model like leaf_values and update it every time you change something in the Leaf model: // Leaf model function afterSave() { $sum = /* calculate sum */; $this->Tree->updateAll( array('Tree.leaf_values' => $sum) array('Tree.id' => $this->data['Leaf']['tree_id']) ); } function afterDelete() { // same for afterDelete },php sql mysql database cakephp3931002,A,"Should I use sessions for ""LOGINS"" on my site? I have a classifieds website where anyone (no need for login currently) can post a classified. It is PHP based. The procedure for posting is currently like this: click on ""New Classified"" ---> fill in a form of all information and hit ""View classified before publishing it"" ---> the form submits to a ""verify classifieds"" page where users verify their inputs ---> If everything is okay in the ""verify"" page then the user hits OK and the classified is published. The above procedure isn't exactly optimized. The first page (new_classified) where the form is is pretty good but the second page (verify) uses x number of hidden inputs in another form used to contain the previous pages form inputs. Now you know how it works on my site. The issue today is that alot of companies want to publish their classifieds and alot of classifieds at the same time. This means they have to fill out the form again and again currently. I am thinking about creating a login for companies only so that their information is automatically inputted into the form so all they would have to do is fill out the specific classified details like ""headline"" and ""description"" etc. How should I do this in my case? Sessions? This means I will have to create a new MySql table (I use MySql mainly) and store company-profiles there. So do you think converting to sessions is alot of work? Worth it? More reliable? I have never used sessions so I wouldn't know. As a last note you should know that I use a picture upload tool on the first page of ""new_classified"". When a user choses a file to upload the page is automatically *refreshed* and then the image is displayed on the same page under section ""images uploaded"". I hope the session wont interfere with this approach. Thanks Please use formatting wisely. it's hard to read such a pitted text I think it is worth your while to do logins and even on a very basic level it will help you to identify who is using your site etc. This is probably a big debate around developers what is the best way to do a good login system whether it's basic or not doesn't matter I think the concepts still stay the same. In your case I would suggest session cookies along with a login table consisting of user details. This would help you to verify the user on more than one occasion during his/her visit to the site. A login is checked against a user entry in a table and then a session cookie is created. This session you can choose to never expire also. You can then on every step check that the user is the user that is supposed to be logged in and get the companies details by checking the username. This would make for a better query in my opinion. Sessions aren't a lot of work and it's relatively easy to learn. http://www.php.net/manual/en/book.session.php http://www.9lessons.info/2010/02/php-login-script-with-encryption.html is a good example of what you can do with this. Have a look around still. There are a bunch of these great tutorials on the web.",php sql mysql database session3057351,A,Large strings: Text files or SQL DB? I am coding a forum system using PHP. I am currently storing a threads ID title author views and other attributes in an SQL database and then storing the thread body (the HTML and BBcode) in text files inside a folder named after the thread ID. In practise it's really simple to grab the database values then just grab the thread body from the text file but I was wondering if this is the 'proper way'? I have personally no problems doing this but if it turns out it is massively inefficient and I should instead store both the thread body HTML and BBcode in the database instead then I will change. However to me it seems wrong to store such a (very possibly) huge string of multi-line text along with lots of different characters in a database - I was taught that databases are more for short field 'values' rather than website content. I would just like a definitive answer to this because it's been bugging me for ages as to wherever IŠ—Ève been doing it properly. Does anyone know how popular forum systems store threads? Added Thanks for the answers so it's best to store thread content in the database what field type should i use? Also what about replies? Another table which has the thread ID and comment ID then the comment body? I'm new to this database stuff so thanks for your help. Joomla - all the content is in the database. Drupal probably too. Countless systems store content in a database. (Beware this is only a statistic!) Best to ask a separate followup question for database design. There's no limit to how many questions you can ask and changing the criteria means those who originally provided answers could be downvoted -- we're not alerted when you update your question. Ok yeah i understand thanks! This is an aside as the question has already been accepted however you should check out phpbb3 (http://www.phpbb.com/). Very robust php forum. May save you some development time :D Thanks but the main purpose for me coding this forum is as a learning exercise for myself otherwise i would def use phpbb :)  Confluence (a commercial wiki) stores the entire page content within a single column. The reason to store large text in the database is: There's (hopefully) no disconnect between the value and the record(s) the text is associated with There are technologies like Full Text Search (FTS) to make finding specific strings in large amounts of text Simplified backup & restore process +1. I forgot about Confulence and we use it...  I know that DotNetNuke and the AspDotNetStorefront use a database to store such data. These aren't forums but a content management system and a shopping cart with content management capabilities. I've also experimented with several forums (Such as YAF) and all of those use databases as well. Personally I'd stick with a DB for the HTML and any image/content files should be stored on the disk with a reference to their location in HTML. Perhaps the strongest argument for storing in the DB: It's a heck of a lot easier to search the text fields with a LIKE clause than to search for a strong in a text file. Also with free forum software cout there can I ask why you're writing a new one from scratch? I realize there are probably good reasons but just in case it's something you hadn't thought of yet... Added Most of my references were .NET code. Here's an open source forum written in PHP: http://www.phorum.org/ And that LIKE clause can end up being very slow... You may want to use full text indexing for that. @Nelson - Good point! Thanks. Also i'm coding it myself mainly as a learning exercise it isn't a serious website so i thought i'd give it a go coding the system myself. That's good.. It's a good learning experience. Still it might not be too bad an idea to get the source code for phorum at some point and compare to see how you did compared to how they did... Looking at established code and comparing it with your own is a very good way to learn. Have fun!  It would be best practice to store the thread in the database since that will allow you to scale and search easier. If you want to continue using files to store the content I would recommend using something along the lines of GridFS. Basically just chunks up files and stores them in NOSQL.  I agree with the other answers storing all the data in your database simplify scaling backup/restore allows you to query the data and so on. If you're concerned with performance you could implement a cache for the page content. I know PHPBB does this by having a serialized array in a text file with a expiration timestamp. Could also be done using memcached or otherwise. Storing the data in a database give you the most flexibility and convenience most problems related to serving the data to the end-user can be handled by caching the data.,php sql database1304732,A,"How can I get this mysqli database class working? I'll cut right to the chase. All I can achieve at this point with this class is a database connection. I am unable to make a query. Can you show me exactly how to get this working and/or show me how to recode it in a better way. <?php class database{ public $dbHost = ''; public $dbUser = ''; public $dbPass = ''; public $dbName = ''; public $db; public function __construct(){} public function dbConnect(){ $mysqli = new mysqli($this->dbHost $this->dbUser $this->dbPass $this->dbName); /* check connection */ if (mysqli_connect_errno()){ printf(""Connect failed: %s\n"" mysqli_connect_error()); exit(); }else{ echo 'connection made'; } /* close connection */ $mysqli->close(); } public function query($sql){ $query = $sql; self::preparedStatement($query); } public function preparedStatement(){ if ($stmt = $mysqli->prepare($query)){ /* execute statement */ $stmt->execute(); /* bind result variables */ $stmt->bind_result($name $code); /* fetch values */ while ($stmt->fetch()) { printf (""%s (%s)\n"" $name $code); } /* close statement */ $stmt->close(); } } public function __destruct(){} } ?> You have omitted a parameter: public function preparedStatement($query) (and this method actually should be static) Next time try to debug your code before asking. Even simple echo statements would have done here. EDIT: and even that wouldn't work. I think you've misunderstood the concept of variable scope. $mysqli should be an instance variable of that class because it wouldn't persist to preparedStatement() if you just set it in __construct() as a local variable. Yes I understand there are some serious issues here. I think 3 hours counts as ""trying to debug your code before asking"".  This worked for me. I've commented my changes. <?php class database{ public $dbHost = ''; public $dbUser = ''; public $dbPass = ''; public $dbName = ''; public $db; public function __construct(){} public function dbConnect(){ ### not $mysqli $this->db = new mysqli($this->dbHost $this->dbUser $this->dbPass $this->dbName); /* check connection */ if (mysqli_connect_errno()){ printf(""Connect failed: %s\n"" mysqli_connect_error()); exit(); }else{ echo 'connection made'; } /* close connection */ ### $this->db->close(); // DO NOT close the connection here! } public function query($sql){ $query = $sql; self::preparedStatement($query); } public function preparedStatement($query){ ### parameter $query added if ($stmt = $this->db->prepare($query)){ ### not $mysqli->prepare() /* execute statement */ $stmt->execute(); /* bind result variables */ $stmt->bind_result($name $code); /* fetch values */ while ($stmt->fetch()) { printf (""%s (%s)\n"" $name $code); } /* close statement */ $stmt->close(); } } public function __destruct(){} } ### Test code /* $db = new Database(); $db->dbHost = '127.0.0.1'; $db->dbUser = 'root'; $db->dbPass = 'root'; $db->dbName = 'test'; $db->dbConnect(); $db->query('SELECT * FROM test'); */ ?> Your awesome! Thank you so much. I made almost all of those changes during my debugging too bad I didn't put them all together at once. Thanks.",php sql database mysql mysqli3294432,A,"SQL query to get data from a large list of strings I have a large list of strings (1500 email addresses to be more specific) and I need to look up a piece of data in a very large DB table for each of the strings (e.g. the primary key mydataitem). How can I do it efficiently? For example this is way too slow (amongst other problems): $stringArray = ('foo''bar''baz'... 'for 1000s of items'); foreach($stringArray as $mystring) { $res = mysql_query(""select mydataitemblah FROM users WHERE blah = '$mystring'""); $info=mysql_fetch_assoc($res); ... } Things I want to avoid: I don't want to loop over the list and do a SELECT for each item. i.e. 1500 queries (as in example above) I don't want to read the whole table into an array in one query and do the lookup in code because it would take too much memory. The DB table has 100k+ rows. I don't want to build a massive query with 1499 ORs because the query would be too big. (for example ""select mydataitem FROM users WHERE blah = 'aaa' OR blah = 'bbb' OR ..."") Note: I'm using MySql v5.0.45 Update: Thanks everyone - for some reason I thought IN was just for Integer ID lists - now I know better. mysql_query(""select mydataitemblah FROM users WHERE blah IN ('"" .implode(""''""array_map('mysql_real_escape_string'$stringArray).""')'; Better yet use mysqli or PDO which can use prepared statements: $stmt = $PDO->prepare('select mydataitemblah FROM users WHERE blah IN (' .implode(''array_fill(0count($stringArray)'?')).')'; $stmt->execute($stringArray); Your query doesn't link mydataitem to a particular email address. Pfff. SELECT mydataitemblah then as `blah` apparantly IS the email address.  Unless this needs to but lightning fast I would just use a MySQL in clause turn the array into a string: $emails = array(""abc@def.com"" ""123@456.net"" ""me@google.com""); $list = ""(\"""". implode(""\"" \"""" $balls) . ""\"")""; then just use it in your sql $sql = ""select mydataitem FROM users WHERE blah in {$list}""; Your query doesn't link mydataitem to a particular email address.  If you use a prepared statement you can prepare it outside of your loop and then use it within your loop. That should run more quickly than a new mysql_query call each time. I don't know what you mean by a query being ""too big"". Try it and see how slow it is. Add a key on the email field if you don't already have one. This doesn't sound like the kind of code that would be running often so I would guess it's okay if it takes a second. If not maybe you can explain the goal of this code and we can help you figure out a better way of accomplishing that goal.  I think what you want is SELECT mydataitem FROM users WHERE blah IN ('foo' 'bar' 'baz' ...) Your query doesn't link mydataitem to a particular email address.  WHERE blah IN ('aaa''bbb'...) But it's still not efficient. If you explain why you need to retrieve so many records we might perhaps be able to come up with a more efficient logic. EDIT Create a temporary table holding these values and use a join to that temp table in your select query The temporary table idea is brilliant. Thanks - I'll probably use it!",php sql mysql database performance2221742,A,"Is there any way to know what cache size is needed? I am using mysql as a db. Is there any formula for determining the cache size needed to cache the results? Thanks Caching where? PHP has no cache - if you don't enough memory allocated the instance will through a fatal error and stop. There are lots of caches within MySQL by default it allocates large values for these. IME these can safely be left alone - note that any memory allocated for MySQL means less memory available for the system's I/O caching. Why do you think you need to fix something? C.  This is usually a function of how much spare RAM you have the size of your database and how much of the dataset is ""popular"". (Below is assuming that you are talking about an application-level cache and not I/O caches buffer caches or other lower-level caching.) If you're sizing your cache for performance (i.e. maximize throughput and minimize latency) then one simple formula would be to use as much as your spare RAM as possible that is less than your total database size. Another simple formula would be to start somewhere between 1% and 10% of your database size and grow based on usage. If you want to carefully calculate how much cache you need then the most reliable way to do it is by experimentation i.e. run load-tests against growing cache-sizes and graph the hit-rate (This is especially true if your database load/usage characteristics are complicated.) For example you can have a graph where the X-axis is the cache-size and the Y-axis has both hit-rate and query-latency. Your goal would be to find the minimum X (cache-size) where hit-rate is maximized and query-latency is minimized (these could be different points). In order to do this correctly you need a real-world load test i.e. if you keep logs of your queries you can replay them. You may want to limit your replay of only non-mutating queries only (for simplicity). Note that instead of loadtests you can simplify this process by adding a cache (start somewhere between 1% and 10%) to a live database then watching the hit-rate and query-latency over time. This is a bit easier to do if you don't have a load-test framework setup but may be more intrusive on a production system. If the hit-rate is too low (or query-latency too high) then grow the cache. If not then see if shrinking it makes a noticeable difference. (Of course there are edge cases here which I'm glossing over but this is the general idea. E.g. sometimes different types of queries can have different costs and you may need to allocate different caches for different query types.) Once you do have a cache you should monitor it's statistics along with other query stats such as latency. You may need to grow it over time. Or you may find that you need to warm the cache up before you can get any reliable performance. For example if you rely on your cache to be able to serve out a specific query-load and your caching component crashes starting up cold then your database will get overloaded for some period of time while the cache warms up. Anyhow the short answer is that there is no simple solution and sizing your cache best done by experimentation.",php sql mysql database1998692,A,"Is there an conceptual difference between a so called ""record set"" and an so called ""statement""? I wonder why the result of an SQL query in PHP PDO is called ""statement"". I'd expect ""record set"". My english is pretty bad as I'm not a native speaker. So: I craeate a ""query"" to ""ask the database to do/retrieve something"". Sometimes I use ""prepared statements"" to ask that (blue confusion alert!). Then PDO returns me an object of class called PDOStatement (red confusion alert!). Then this PDOStatement object has a fetch() method which seems to return me a ""record set"". All right...so is there any logical difference between that PDOStatement thing and the record set I get from fetch()? What's the difference? Or does the PDOStatement object actually perform the DB query and then return a record set? Or is PDOStatement the record set? It's because statements can be executed and when they are the resulting rows are stored inside of a buffer. In essence the object contains not only the records it returned but information on how to execute it again. That's why it's called a statement.  The PDOStatement represents both statements and result sets ; quoting the manual : Represents a prepared statement and after the statement is executed an associated result set. And the PDO::query method : Executes an SQL statement returning a result set as a PDOStatement object",php sql database526118,A,"What is the best way to access data in a normalized database schema? I've got a problem that keeps coming up with normalized databases and was looking for the best solution. Suppose I've got an album information database. I want to setup the schema in a normalized fashion so I setup two tables - albums which has one listing for each album and songs which lists all songs contained by albums. albums ------ aid name songs ----- aid sid length This setup is good for storing the data in a normalized fashion as an album can contain any number of songs. However accessing the data in an intuitive manner has now become a lot more difficult. A query which only grabs the information on a single album is simple but how do you grab multiple albums at once in a single query? Thus far the best answer I have come up with is grouping by aid and converting the songs information as arrays. For example the result would look something like this: aid sids lengths 1 [1 2] [1:04 5:45] 2 [3 4 5] [3:30 4:30 5:30] When I want to work with the data I have to then parse the sids and lengths which seems a pointless exercise: I'm making the db concatenate a bunch of values just to separate them later. My question: What is the best way to access a database with this sort of schema? Am I stuck with multiple arrays? Should I store the entirety of a song's information in an object and then those songs into a single array instead of having multiple arrays? Or is there a way of adding an arbitrary number of columns to the resultset (sort of an infinite-join) to accommodate N number of songs? I'm open to any ideas on how to best access the data. I'm also concerned about efficiency as these queries will be run often. If it makes any difference I'm using a PostgreSQL db along with a PHP front-end. I wouldn't break your normalisation for that. Leave the tables normailsed and then use the following to query - http://stackoverflow.com/questions/43870/how-to-concatenate-strings-of-a-string-field-in-a-postgresql-group-by-query  I see your point but I have issues with the first query because you end up with a lot of repeated data - the album name is repeated many times. I'm trying to have my cake and eat it too - I want the data to be as compact as possible but that's not realistic without aggregates. Ah I understand your question now. You're asking how best to micro-optimize something that's actually not very expensive for most cases. And the solution you're toying with is actually going to be significantly less efficient than the ""problem"" it's trying to solve. My advice would be to join the tables and return the columns you need. For anything less than 10000 records returned you won't notice any significant wire time penalty for handing back that AlbumName with each Song record. If you notice it performing slowly in the field then optimize it. But keep in mind that a lot of smart people have spent about 50 years of research making the ""join the tables & return what you need"" solution fast. I doubt you'll beat it with your home-rolled string concatenation/de-concatenation strategy. This is an example. The actual Albums table will have approximately 10 columns that I'll want and that's a lot of repeated data. I'm going with two queries instead. Also no need to be condescending. I know that string concat/de-concate would be slow which is why I posted the question. :P You should also know that returning two recordsets will be slow. Certainly not worth it to avoid repeating 10 columns a few hundred times. Sorry if I sounded condescending. This seems to be new ground for you and it's DB 101.  I have difficulty seeing your point. What exactly do you mean by ""how do you grab multiple albums at once in a single query""? What exactly do you have difficulties with? Intuitively I would say: SELECT a.aid album_id a.name album_name s.sid song_id s.name song_name s.length song_length FROM albums a INNER JOIN songs s ON a.aid = s.aid WHERE a.aid IN (1 2 3) and SELECT a.aid album_id a.name album_name COUNT(s.sid) count_songs SUM(s.length) sum_length /* assuming you store an integer seconds value */ FROM /* here not a string containing '3:18' or such */ albums a INNER JOIN songs s ON a.aid = s.aid WHERE a.aid IN (1 2 3) GROUP BY a.aid Depending on what you want to know/display. Either you query the database for aggregate information or you calculate it yourself out of the query result #1 in your app. Depending on how much data is cached in your app and how long queries take the one strategy can be faster than the other. I would recommend querying the DB though. DBs are made for this kind of stuff. I see your point but I have issues with the first query because you end up with a lot of repeated data - the album name is repeated many times. I'm trying to have my cake and eat it too - I want the data to be as compact as possible but that's not realistic without aggregates. Leave off the album name from the first query. You have it in the second one (which probably comes first anyway) and your app can store some context as well. Other than that I see your point as well. But I guess the repeated album name won't clog your performance too badly. ;-) (Funnily enough I rephrased my second paragraph before posting to avoid the ""you can't have your cake and eat it too"" platitude :-D)  I agree with Jason Kester insofar as I think this is unlikely to really be a performance bottleneck in practice even if you have 10 columns with repeated data. However if you're bent on cutting out that repeated data then I'll suggest using 2 queries: Query #1: SELECT sid length -- And whatever other per-song fields you want FROM songs ORDER BY aid Query #2: SELECT aid a.name COUNT(*) FROM albums a JOIN songs s USING (aid) GROUP BY aid a.name ORDER BY aid a.name The second query enables you to break up the output of the first query into segments appropriately. Note that this will only work reliably if you can assume that no changes will be made to the table between these two queries -- otherwise you'll need a transaction with SET TRANSACTION ISOLATION LEVEL SERIALIZABLE. Again the mere fact that you're using two separate queries is likely to make this slower overall as in most cases the doubled network latency + query parsing + query planning is likely to swamp the effective increase in network throughput. But at least you won't have that nasty horrible feeling of sending repeated data... :)  SELECT aidGROUP_CONCAT(sid) FROM songs GROUP BY aid; +----+-------------------------+ |aid | GROUP_CONCAT(sid) | +----+-------------------------+ | 3 | 567 | +----+-------------------------+ Yes that's true. I didn't notice the PostgreSQL part of the question. My googling suggests that GROUP_CONCAT() is not supplied by PostgreSQL. However you can build it yourself using CREATE AGGREGATE.  The join queries will ask the database to put the tables together matching the ids and return a single table. That way the data can be dynamically configured to the current task something that non normalized databases cannot do.",php sql database postgresql2967006,A,"I can't delete records from MySql I have two tables. table a references table b I believe. When I try to delete the package alltogether like this: $query=""DELETE a b FROM classified as a $sql_table as b WHERE a.ad_id = '$id' AND a.classified_id = b.classified_id AND a.poster_password='$pass'""; b MUST be deleted first I guess. Even in PhpMyAdmin I cant delete a if b is still there so I delete b first. But what decides the order in which comes first? The tables are alla InnoDB. What should I do? Thanks The reason the reference key is the way it is is because I use JOIN when I display my records... Just so you know. The MySQL manual says about multi-table DELETE and foreign keys: If you use a multiple-table DELETE statement involving InnoDB tables for which there are foreign key constraints the MySQL optimizer might process tables in an order that differs from that of their parent/child relationship. In this case the statement fails and rolls back. Instead you should delete from a single table and rely on the ON DELETE capabilities that InnoDB provides to cause the other tables to be modified accordingly. So that when a record in your main table is deleted so are its foreign references e.g: ALTER TABLE products ADD CONSTRAINT fk_supplier FOREIGN KEY (supplier_id supplier_name) REFERENCES supplier(supplier_id supplier_name) ON DELETE CASCADE;  Your Delete syntax is invalid. You need to do this in two statements (unless as nuqqsa mentioned you have CASCADE DELETE enabled on the relationship between table a and table b): Delete From b Where Exists ( Select 1 From a Where a.poster_password = '$pass' And a.ad_id = '$id' And a.classified_id = b.classified_id ) Delete From a Where a.poster_password = '$pass' And a.ad_id = '$id' What decides which comes first is the foreign keys relationships. Whichever table is the parent table must be deleted from last. You are a SQL server user I'm guessing? @simplemotives - Me? I am however the equivalent of the above syntax should work in any database product. @Thomas - Your SQL style is all I was commenting on. @simplemotives - Np. Although I've worked against Oracle and I use the same style. Thomas: Check this Q out I am having trouble getting your code above to work: http://stackoverflow.com/questions/2972796/sql-syntax-error-little-help-please @Camran - MySql apparently requires that you use the `From` keyword in your Delete statements and I've updated my post to reflect that. IIRC the official SQL specification does not provide for the use of a `From` clause in a Delete statement.",php sql mysql html database2229851,A,Selecting distinct months and years and then breakdown of values for I'm using Open Flash Chart to create statistics and one of the things i need to be able to do is generate a Stacked Bar Chart. Logically i need to be able to Group all the distinct Month/Year combinations Dec 2009 Jan 2010 Feb 2010 etc. and then from that group all the various rows i.e. the different types of enquiry a visitor made (via website via email via phonecall) at the moment the table attributes look like this: id (int auto increment) date_time(date time format) type (enum visit website phone email) Any suggestions? I've tried a few things and haven't had much luck. SELECT EXTRACT(YEAR_MONTH FROM date_time) AS ym type COUNT(*) FROM mytable GROUP BY ym type Cool didn't know about `extract(year_month ...)` !  Something like this should work: select count(*) type YEAR(date_time) MONTH(date_time) from `table` group by type YEAR(date_time) MONTH(date_time)  To group by year and month the sql can look like this: SELECT DATE_FORMAT(date_time '%Y-%m') AS yearmonth COUNT(*) AS count_month FROM table_name GROUP BY yearmonth  You could create a table with a month field and populate it for the months you're interested in for example: StartOfMonth 2010-01-01 2010-02-01 2010-03-01 ... Then you can use left join to group on all months: select year(mt.StartOfMonth)  month(mt.StartOfMonth)  e.type  count(*) from MonthTable mt left join Enquiries e on mt.StartOfMonth <= e.EnquiryDate and e.EnquiryDate < mt.StartOfMonth + interval 1 month where mt.StartOfMonth <= NOW() group by year(mt.StartOfMonth) month(mt.StartOfMonth) e.type,php sql mysql database datatable1737865,A,"Is there a limit to MySQL queries? I am trying to insert 10000+ fields into my database? Is there a limit? $sql = 'INSERT INTO `_'.$test.'` (`user` `pass`) VALUES ' . preg_replace($test $replace $final_check) . ';'; mysql_query($sql) or die(mysql_error()); Every time I try to insert the data it fails. ""it fails""? Is that all the error message you get? ""Failed""? Or did you get something more specific? If you did please post the entire error message otherwise all we can say is ""tough luck it fails"". I believe it's your query. Make sure you are importing the right data and it shouldn't fail. Echo the $sql to test it. echo $sql  There is a packet size limit in the MySQL protocol. If your SQL statement exceeds that it can't send it to the server. The limit was for a very long time 16Mb but fairly recent versions have raised it higher. Also check that you are enclosing each row's worth of data in it's own parentheses.",php sql database mysql2794667,A,"MySql paging; ""Showing result-set"" of ""total found"" help I need a formula for showing results on my classifieds website. I am now done with the paging of records but this formula for showing results remains. I want it like this:  Showing 1-50 of 123 found. Now what is the formula for this? I have these variables which should be enough I think:  $results_per_page = 50; //results per page $page = 1; //current page Also a variable called $num_total contains the total nr of hits in this case 123. Thanks Is this what you want? <?php $page = 1; $results_per_page = 50; $num_total = 123; echo 'Showing ' . ((($page - 1) * $results_per_page) + 1) . '-' . min($num_total ($page * $results_per_page)) . ' of ' . $num_total . ' found.'; ?> @Camran: Do you want me to write the `if ($num_total > 0)`?",php sql mysql html database2101102,A,MySQL linking tables; some final issues Firstly I want to thank all of you who have helped me understand Normalization and how I should build up my database. Now I have some final issues left... How does LINKING of tables actually work? Say you have three tables: CATEGORY TABLE: cat_id (PK) -> 1 cat_name -> cars CATEGORY_OPTIONS TABLE: cat_opt_id (FK) -> 1 cat_id (FK) -> 1 option_name -> year CATEGORY_OPTIONS_VALUES TABLE: cat_opt_val_id (PK) -> 1 cat_opt_id (FK) -> 1 value -> 1999 Basically the values should look like this: CATEGORY (1 cars) (2 MC) CATEGORY_OPTIONS (1 1 year) (2 1 fuel) (3 2 type) CATEGORY_OPTIONS_VALUES (1 1 2010) (2 1 Petrol) (3 2 Cross) Is this correct as I have it setup above? How would I search these how is the logic made up? I think I need examples of queries from PHP (SELECT etc) Say you want to search for a CAR -> year=2010 fuel=PETROL how is the query then? AND SAY you want to search for a CAR -> fuel=PETROL year=anything LASTLY should I use AutoIncrement on any of these fields? And when is AI used? Thanks PS: For more info check out this Q: http://stackoverflow.com/questions/2100008/can-this-mysql-db-be-improved-or-is-it-good-as-it-is You want SQL joins. Table linking is a completely unrelated technique that has nothing to do with what you are trying to achieve (for details see MySQL documentation on the MERGE engine). Generally: SELECT f.name b.value FROM foo f LEFT JOIN bar b ON b.foo_id = f.id WHERE f.age > 10 HAVING b.value IS NOT NULL In order to understand how joins are performed you must understand how the database engine processes a query - especially the significance of conditions in ON WHERE and HAVING clauses which all apply at different stages.,php sql mysql database search711473,A,"Why can't I connect to my sql database? I get the error message: ""Can't connect to local MySQL server through socket"" I just moved my site to a new web host and after changing the database-login file it still can't connect. I get the following error: Warning: mysql_query() [function.mysql-query]: Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2) in /usr/www/users/simpleof/index.php on line 91 I changed the password and tried again but it still doesn't work. All the information in the db-login is correct so why can't I connect to the database? Wow. I feel pretty dumb but I put an extra space into the server name when I logged in. So my advice to anyone else having this problem is REALLY check to make sure your log-in info is correct.  There was a recent update to Debian/Ubuntu which caused this error for me. I had to tweak some of the Ubuntu config to mysql work. You may want to check with your hosting company and see if this is the problem.  Is the MySQL server on the same host as the web application? If not you can't use a socket connection and will need to connect via TCP. If the MySQL server is on the same host then maybe the socket is in a different location than '/tmp/mysql.sock'? Without more information about what application/platform you're using that's about all the help I can give.  Check in mysql user privilages if your user's host is correct.",php sql mysql database connect2173201,A,"How should I query MySQL and how to cache the results from MySQL? I have managed finally to get Solr working with the help of all you guys so THANK YOU! And I have to say I now understand why you recommended it it's really powerful. Now to the issue... I have indexed all ""Searchable"" information into Solr and my plan is to query Solr and then get the ID:s of the query-results (of all records that is each has an ID field value) which I then use to query MySQL and fetch the rest of the information. So first query Solr next solr sends back id:s for all ads which match the query then I use the ID:s to query MySQL for the rest of the info. My Q is When doing the part with MySql should I save all the received ID:s into an array and then query mysql to find all records with those ID:s? Should I do something like this? (might contain some code errors):  for ($i=0; $i<$id_from_solr.length; $i++){ mysql_query(""SELECT * FROM table_name WHERE ad_id=$id_from_solr[$i]""); } The above seems not like a good solution because it does a ""new query"" everytime it loops again! How would you do it? Follow-up Question: Would adding a sort function into the MySQL query slow things down compared to WITHOUT using the sort function? for example:  ORDER BY insert_date ASC And last Q: Is there anyway to cache MySQL results so when sorting I don't have to make a new query? Thanks alot! If you need more input let me know and I will update this Q! If the query is slow with the _ORDER BY_ try addind an INDEX on that coulomb. I think you meant ""cache"" rather than ""catch"" - I've made this edit for clarity. For the first part here's how I would write a single query statement: $instr=implode("" ""$id_from_solr); $stmt = ""SELECT * FROM table_name WHERE ad_id IN ("".$instr."")"";  Question 1 (retrieving IDs and then querying the database): why not return some of your fields from the Solr query so that you don't always have to hit the database as well? Q2 (Performance and sorting): well sorting represents an extra task to perform on your data so it is bound to add a bit of work for the database: this can of course be minimized if you have an index on your ORDER BY column(s). Q3 (catching MySql queries): you can either turn on the MySql cache (which will return a cached copy of your results if the request matched a previous one assuming the data has not been changed in the interim) or use a caching layer outside of the database such as EhCache: http://ehcache.org/",php sql mysql database2311680,A,"What kind of JOIN should I use here? I'm new to JOINS in MySql. I have six tables: t1 t2 t3 t4 t5 t6. And I also have one main table: main_table. TOTAL 7 TABLES! The first column of ALL tables is called classified_id. If the user searches for ""cars"" then the main table will match everything in table t1 (which is the cars table) where classified_id is the same in both tables. So:  SELECT * FROM main_table t1 WHERE main_table.classified_id=t1.classified_id This works fine although I am not sure this is the way to join here. Performance is an issue in my case! However here is my problem. Whenever ALL CLASSIFIEDS are searched then I need to match the main_table.classified_id to the other tables classified_id column and get every classified there is. How should this query be made up?  SELECT * FROM main_table t1 t2 t3 t4 t5 t6 // I have this so far which is not much! If you need more input just ask and I will update this Q. Thanks EDIT: Table setup:  main_table: t1: ID(PK) ID (PK) classified_id -> 25 classified_id -> 25 category -> CARS year -> 1997 What do you expect to happen when in one of the tables there are no record with classified_id. Because this is the main criteria which join type to use. It sounds like t1-t6 are classified entries each with 2 columns id and value where 'value' is something like '2008 Camry. Runs good.' Is that right? then return 0! No matches found! Check my update! If the row would exist in all tables (i.e. every table has a row for a specific classified_id) then you would use an inner join: SELECT m.classified_id m.category t1.year ........ FROM main_table m INNER JOIN t1 ON m.classified_id = t1.classified_id INNER JOIN t2 ON m.classified_id = t2.classified_id INNER JOIN t3 ON m.classified_id = t3.classified_id INNER JOIN t4 ON m.classified_id = t4.classified_id INNER JOIN t5 ON m.classified_id = t5.classified_id INNER JOIN t6 ON m.classified_id = t6.classified_id If the row does not exist in every table then you'd use LEFT JOINS so that rows are not dropped That will return an error because of using `SELECT *` - there are column name collisions with `classified_id`. I've edited the answer based on this/camran's edit  Use:  SELECT mt.* t1.* t2.* t3.* t4.* t5.* t6.* FROM MAIN_TABLE mt LEFT JOIN TABLE_1 t1 ON t1.classified_id = mt.classified_id LEFT JOIN TABLE_2 t2 ON t2.classified_id = mt.classified_id LEFT JOIN TABLE_3 t3 ON t3.classified_id = mt.classified_id LEFT JOIN TABLE_4 t4 ON t4.classified_id = mt.classified_id LEFT JOIN TABLE_5 t5 ON t5.classified_id = mt.classified_id LEFT JOIN TABLE_6 t6 ON t6.classified_id = mt.classified_id I used LEFT JOINs because if JOIN was used - records would be omitted that did not have a supporting record in at least one of the t1/2/3/4/5/6 tables. You might find this link helpful for understanding JOINs.",php sql mysql html database1139360,A,"PHP Cookie Security Question I have the following code that is presenting a 'word-of-the-day' As I am relatively new to php coding I wanted to make sure that there weren't any security issues for how I am selecting from my database from the cookie value. Thanks. if ($word_of_the_day) { $wotd = $wpdb->get_results(""SELECT termdefinition FROM glossary WHERE term = '{$word_of_the_day}'""); foreach ($wotd as $term) { } } elseif ($_COOKIE['WOTD']) { $word_of_the_day = htmlspecialchars(addslashes($_COOKIE['WOTD'])); $wotd = $wpdb->get_results(""SELECT termdefinition FROM glossary WHERE term = '{$word_of_the_day}'""); foreach ($wotd as $term) { } } else { $wotd = $wpdb->get_results(""SELECT termdefinition FROM glossary ORDER BY RAND() LIMIT 1""); foreach ($wotd as $term) { setcookie(""WOTD"" $term->term time()+86400); } } Where does $word_of_the_day come from? If it comes from user input you are open to SQL injection.  One of the safest ways is to use the PDO MySQL functions which implements parameters: $db = new PDO('mysql:host=hostname;dbname=defaultDbName' 'username' 'password'); $stmt = $db->prepare('SELECT termdefinition FROM glossary WHERE term = :wotd'); if ($stmt) { if ($stmt->execute(array(':wotd' => $word_of_the_day))) { //This is safe for any input method $info = $stmt->fetchAll(); foreach($info as $row) { //Whatever } } } The PDO drivers does the correct escaping / quoting according to the data type in the table.  You should check out mysql_real_escape_string: ""Escapes special characters in a string for use in a SQL statement"". You don't have to do the stuff that you're doing with htmlspecialchars and addslashes manually. Are you familiar with SQL injection security risks? If the variable that you're including in the SELECT statement $word_of_the_day comes from the user then you have a potential SQL injection problem.  Well if $word_for_the_day comes from user input there's your first problem. Do this before you use it: $word_for_the_day = mysql_real_escape_string($word_for_the_day); Your cookie actually looks OK. The htmlspecialchars() and addslashes() calls in the context you're using them don't appear vulnerable to SQL injection or XSS attacks.  Another option you could consider would be to store the id of the word instead of the word itself in the cookie. That way it can only ever be an integer. Of course using the word is fine too as long as you mysql_real_escape_string it first I just wanted to offer another option.  addslashes is extremely weak. First thing run everything you query from the db through mysql_escape_string to prevent sql injection. That's just the basics. if($word_of_the_day){ $word_of_the_day = mysql_escape_string($word_of_the_day); $wotd = $wpdb->get_results (""SELECT termdefinition FROM glossary WHERE term = '{$word_of_the_day}'""); Also cookies in general aren't very secure no matter how secure code you write. For a much more secure solution I recommend you use PHP sessions ($_SESSION). You can store variables in this superglobal variable and it will stay there between page loads. http://www.php.net/manual/en/session.examples.basic.php After that you may want to protect against session hijacking or poisoning if you're really going for it",php sql database security cookies1940254,A,"I have to write two SQL statements in order to update a record is there a better way to do it? I want to update a table: $result=mysql_query(""select balance from tablename where userid='$userid"")or die(mysql_error()); $row=mysql_fetch_assoc($result); $accountbalance=$row['balance']; if($accountbalance>$cost) { $result=mysql_query(""update tablename set balance-'$cost' where userid='$userid"")or die(mysql_error()); } else { ... } You see I have to write two mysql statements is there a better way to do it? mysql_query(""update users set balance=balance+'$pwbalance'-'$totalprice' where memberid='$memberid' and (balance+'$pwbalance'-'$totalprice')>=0"")or die(mysql_error()); $count=mysql_affected_rows(); Why is $count is 0 even I think it should be 1? Waiting a solution. Do you know that `$count` is 1 in your original two query approach? UPDATE tablename SET balance=balance-$cost WHERE userid=$userid AND balance > $cost If you check that balance > cost I'd make damn sure that at least 1 row got updated. ""Not enough balance 0 rows updated' :-) so I use mysql_affected_rows to get the result? Right - I would just like to point out that in the answer it should probably read ""$cost"" instead of just ""cost"" (in both cases without the double quotes) Roland you're right I must have misread this as for some reason I had the idea that `cost` was another column. Fixed. mysql_query(""update users set balance=balance+'$pwbalance'-'$totalprice' where memberid='$memberid' and (balance+'$pwbalance'-'$totalprice')>=0"")or die(mysql_error()); $count=mysql_affected_rows(); Why is $count is 0 even I think it should be 1?",php mysql sql database sql-update85,A,"Flat File Databases What are your best practices around creating flat file database structures in PHP? A lot of the more mature PHP flat file frameworks I see out there attempt to implement SQL-like query syntax which is over the top for my purposes in most cases (I would just use a database at that point). Are there any elegant tricks out there to get good performance and features with the small code overhead one would want by taking on this problem in the first place? You might consider SQLite. It's almost as simple as flat files but you do get a SQL engine for querying. It works well with PHP too. SQLite was build into 5.0+ by default but discountinued (!) from PHP 5.4+ on !!! As I write this in July 2012 SQLite will not work on up-to-date systems anymore by default. Official statement [here](http://www.php.net/manual/en/sqlite.requirements.php) Installing the SQLite PDO driver is pretty trivial if you have server access. On Ubuntu/Debian running Apache2 just do apt-get install php5-sqlite service apache2 restart  This one is inspiring as a practical solution: https://github.com/mhgolkar/FlatFire It uses multiple strategies to handling data... [Copied from Readme File] Free or Structured or Mixed - STRUCTURED Regular (table row column) format. [DATABASE] / \ TX TableY \_____________________________ |ROW_0 Colum_0 Colum_1 Colum_2| |ROW_1 Colum_0 Colum_1 Colum_2| |_____________________________| - FREE More creative data storing. You can store data in any structure you want for each (free) element its similar to storing an array with a unique ""Id"". [DATABASE] / \ EX ElementY (ID) \________________ |Field_0 Value_0 | |Field_1 Value_1 | |Field_2 Value_2 | |________________| recall [ID]: get_free(""ElementY"") --> array([Field_0]=>Value_0[Field_1]=>Value_1... - MIXD (Mixed) Mixed databases can store both free elements and tables.If you add a table to a free db or a free element to a structured db flat fire will automatically convert FREE or SRCT to MIXD database. [DATABASE] / \ EX TY  One way to store flat-file content would be to save literal arrays to php files. For example: $data = array(); if( $_POST ) { $data = $_POST; $content = ""<?php\n""; $content .= '$data=' . var_export($data true) . ""\n""; $content .= ""?>""; save_to_file($filename $content); } // echo form `""Well what is the nature of the flat databases. Are they large or small. Is it simple arrays with arrays in them? if its something simple say userprofiles built as such: $user = array(""name"" => ""dubayou"" ""age"" => 20 ""websites"" => array(""dubayou.com""""willwharton.com""""codecream.com"") ""and_one"" => ""more""); and to save or update the db record for that user. $dir = ""../userdata/""; //make sure to put it bellow what the server can reach. file_put_contents($dir.$user['name']serialize($user)); and to load the record for the user function &get_user($name){ return unserialize(file_get_contents(""../userdata/"".$name)); } but again this implementation will vary on the application and nature of the database you need.  IMHO you have two options if you want to avoid homebrewing something: 1) SQLite If you're familiar with PDO you can install a PDO driver that supports SQLite. Never used it but I have used PDO a ton with MySQL. I'm going to give this a shot on a current project. 2) XML Done this many times for relatively small amounts of data. XMLReader is a lightweight read-forward cursor-style class. SimpleXML makes it simple to read an XML document into an object that you can access just like any other class instance.  If you're going to use a flat file to persist data use XML to structure the data. PHP has a built-in XML parser.  A low level object API flatfile database is Mimesis (an open source PHP flat file database low-level API).  If you want a human-readable result you can also use this type of file : ofaurax|27|male|something| another|24|unknown|| ... This way you have only one file you can debug it (and manually fix) easily you can add fields later (at the end of each line) and the PHP code is simple (for each line split according to |). However the drawbacks is that you should parse the entire file to search something (if you have millions of entry it's not fine) and you should handle the separator in data (for example if the nick is WaR|ordz).  That's true. serialize() can be pretty useful for that as well. You could serialize but this saves a step since you don't have to unserialize. Not sure if its actually better performance-wise. I think the trick to coming up with a viable system is finding some way to index the data nodes without killing yourself with complexity. Maybe have one central file that keeps track of all indexes? Like tags.txt which has a list of all post id's associated with each tags. May have to keep redundant data around to save time.  In my opinion using a ""Flat File Database"" in the sense you're meaning (and the answer you've accepted) isn't neccesarily the best way to go about things. First of all using serialize() and unserialize() can cause MAJOR headaches if someone gets in and edits the file (they can in fact put arbritrary code in your ""database"" to be run each time.) Personally I'd say - why not look to the future? There have been so many times that I've had issues because I've been creating my own ""proprietary"" files and the project has exploded to a point where it needs a database and I'm thinking ""you know I wish I'd written this for a database to start with"" - because the refactoring of the code takes way too much time and effort. From this I've learnt that future proofing my application so that when it gets bigger I don't have to go and spend days refactoring is the way to go forward. How do I do this? SQLite. It works as a database uses SQL and is pretty easy to change over to mySQL (espescially if you're using abstracted classes for database manipulation like I do!) In fact espescially with the ""accepted answer""'s method it can drastically cut the memory usage of your app (you don't have to load all the ""RECORDS"" into PHP)  I have written two simple functions designed to store data in a file. You can judge for yourself if it's useful in this case. The point is to save a php variable (if it's either an array a string or an object) to a file. <?php function varname(&$var) { $oldvalue=$var; $var='AAAAB3NzaC1yc2EAAAABIwAAAQEAqytmUAQKMOj24lAjqKJC2Gyqhbhb+DmB9eDDb8+QcFI+QOySUpYDn884rgKB6EAtoFyOZVMA6HlNj0VxMKAGE+sLTJ40rLTcieGRCeHJ/TI37e66OrjxgB+7tngKdvoG5EF9hnoGc4eTMpVUDdpAK3ykqR1FIclgk0whV7cEn/6K4697zgwwb5R2yva/zuTX+xKRqcZvyaF3Ur0Q8T+gvrAX8ktmpE18MjnA5JuGuZFZGFzQbvzCVdN52nu8i003GEFmzp0Ny57pWClKkAy3Q5P5AR2BCUwk8V0iEX3iu7J+b9pv4LRZBQkDujaAtSiAaeG2cjfzL9xIgWPf+J05IQ=='; foreach($GLOBALS as $var_name => $value) { if ($value === 'AAAAB3NzaC1yc2EAAAABIwAAAQEAqytmUAQKMOj24lAjqKJC2Gyqhbhb+DmB9eDDb8+QcFI+QOySUpYDn884rgKB6EAtoFyOZVMA6HlNj0VxMKAGE+sLTJ40rLTcieGRCeHJ/TI37e66OrjxgB+7tngKdvoG5EF9hnoGc4eTMpVUDdpAK3ykqR1FIclgk0whV7cEn/6K4697zgwwb5R2yva/zuTX+xKRqcZvyaF3Ur0Q8T+gvrAX8ktmpE18MjnA5JuGuZFZGFzQbvzCVdN52nu8i003GEFmzp0Ny57pWClKkAy3Q5P5AR2BCUwk8V0iEX3iu7J+b9pv4LRZBQkDujaAtSiAaeG2cjfzL9xIgWPf+J05IQ==') { $var=$oldvalue; return $var_name; } } $var=$oldvalue; return false; } function putphp(&$var $file=false) { $varname=varname($var); if(!$file) { $file=$varname.'.php'; } $pathinfo=pathinfo($file); if(file_exists($file)) { if(is_dir($file)) { $file=$pathinfo['dirname'].'/'.$pathinfo['basename'].'/'.$varname.'.php'; } } file_put_contents($file'<?php'.""\n\$"".$varname.'='.var_export($var true)."";\n""); return true; } This is a four-year-old question with an accepted answer and many additional answers. Consider focusing on newer questions unless the accepted answer here is clearly wrong or inadequate.  Here's the code we use for Lilina. It stores each entry as a separate file which we found is efficient enough for use (no unneeded data is loaded and it's faster to save).  Just pointing out a potential problem with a flat file database with this type of system: data|some text|more data row 2 data|bla hbalh|more data ...etc The problem is that the cell data contains a ""|"" or a ""\n"" then the data will be lost. Sometimes it would be easier to split by combinations of letters that most people wouldn't use. For example: Column splitter: #$% (Shift+345) Row splitter: ^&* (Shift+678) Text file: test data#$%blah blah#$%^&*new row#$%new row data 2 Then use: explode(""#$%"" $data); use foreach the explode again to separate columns Or anything along these lines. Also I might add that flat file databases are good for systems with small amounts of data (ie. less than 20 rows) but become huge memory hogs for larger databases.  That's true. serialize() can be pretty useful for that as well. I think the trick to coming up with a viable system is finding some way to index the data nodes without killing yourself with complexity. This is post #100! post 100 :D upvote  One framework I'm considering would be for a blogging platform. Since just about any possible view of data you would want would be sorted by date I was thinking about this structure: One directory per content node: ./content/YYYYMMDDHHMMSS/ Subdirectories of each node including /tags /authors /comments as well as simple text files in the node directory for pre- and post-rendered content and the like. This would allow a simple PHP glob() call (and probably a reversal of the result array) to query on just about anything within the content structure:glob(""content/*/tags/funny""); would return paths including all articles tagged ""funny"".",php sql database flat-file2208152,A,Filtering duplicities by another table I have two (example) tables here A) data_table: +----------+-------+ | location | value | +----------+-------+ | 43 | 38 | | 44 | 31 | | 3 | 31 | | 11 | 38 | | 47 | 35 | | 49 | 31 | | 50 | 31 | | 55 | 16 | | 56 | 16 | | 59 | 35 | | 42 | 35 | +----------+-------+ and B) neighbour_table: +-----------+-----------+ | location1 | location2 | +-----------+-----------+ | 43 | 3 | | 43 | 11 | | 43 | 55 | | 3 | 50 | | 3 | 16 | | 49 | 56 | | 49 | 42 | +-----------+-----------+ I would like to select the locations with same value as at least one of their neighbour has. What is the best way to do this (according to performance)? So far I tried this: 1) Select all locations with value which is present more than once in the table: SELECT locationvalue FROM data_table WHERE value IN (SELECT value FROM data_table GROUP BY value HAVING COUNT(value) > 1); 2) Now I would like to filter the result using the neighbour_table but how? Using JOIN? Or another derived table (subquery)? I think about using PHP to do the job but how about the performance? Anyway I would like to see the SQL solution if there is one. Thanks in advance You could use a join to look up the value for both neighbours. Then you can select neighbours with the same value using a where clause: select n.* from neighbour_table n join data_table d1 on d1.location = n.location1 join data_table d2 on d2.location = n.location2 where d1.value = d2.value That's it? That's pretty simple! Shame I didn't realize that :-) Thank you very much.,php sql mysql database performance3263189,A,"back up a database I need to back up a big database everydays. Should I code it myself in PHP or is there a good script out there ? How big is ""big""? What sort of database is it? MySQL? Do you own the server it is on or is this a hosted database? We need more details to answer helpfully. around 20mo it's SQL and I do not own the server 20mb isn't big but it might be big enough to cause a PHP timeout. Do you mean `Microsoft SQL Server` when you say `SQL`? Yes here is an award-winning script at phpclasses.org.  If you run your server under linux use a cronjob to do it (for example nightly)! Cron could trigger mysqldump (in case you are using MYSQL) backing up your database(s). Also worth considering if it's MySQL on Linux is http://sourceforge.net/projects/automysqlbackup/ -- this again can be triggered by cron and uses mysqldump but it stores daily weekly and monthly backup cycles in a nice structure and is quite configurable.  You can cronjob the tool provided with your DBMS  If you're using cPanel or Plesk or something then they generally have back-up scripts available to you (but as Chris Aitchison says) how useful any of these answers are depends on the details.",php sql database backup2677322,A,"Which MySql line is faster: I have a classified_id variable which matches one document in a MySql table. I am currently fetching the information about that one record like this:  SELECT * FROM table WHERE table.classified_id = $classified_id I wonder if there is a faster approach for example like this:  SELECT 1 FROM table WHERE table.classified_id = $classified_id Wont the last one only select 1 record which is exactly what I need so that it doesn't have to scan the entire table but instead stops searching for records after 1 is found? Or am I dreaming this? Thanks Is there a unique or primary key constraint on `classified_id`? You should add an index to the classified_id column to avoid a table scan. CREATE INDEX classified_idx ON table (classified_id); +1 Always good advice Not always though. With many inserts it can do some bad things Agree with `Col. Shrapnel` might be a bad idea when the field is the primary key. OP mentioned that the field value identified the row uniquely.  You want to use LIMIT: SELECT * FROM table WHERE table.classified_id = $classified_id LIMIT 1 will this improve performance? @Camran - Hard to say your current version will literally select ""1"" a one column one row result this will actually select the first record which seems to be what you want...but it is a different result. You won't get performance *better* (or simpler) than this so I'd go with it. @John I would say that this is not the answer the question states that there is only one record satisfying the query so LIMIT will make no difference  Why don't you try it? SELECT 1 FROM table; returns +---+ | 1 | +---+ | 1 | | 1 | | 1 | | 1 | | 1 | | 1 | +---+ 6 rows in set (0.00 sec) which is a computed column a constant value of one in this case (for all 6 rows in my test case). For your question SELECT * FROM table WHERE table.classified_id = $classified_id this is the fastest way to retrieve data (assuming that you need all the columns from the table) There are following things that you can do: check if there is an index on classified_id if there is and if using the index is faster the database will use the index and not scan the whole table so you'll get what you want (using index can be slower if there are just a few records or if a high percentage of records satisfy a criteria but having index will not bring any penalty to reading data database will chose the best way to retrieve it) if you don't need all the columns from the table then specify exactly which ones you need if there is more then one record that satisfy the criteria you can use LIMIT keyword to get only one or only a few records other then this for such a simple query the only next step would be to partition the table to several hard drives (which might not be an option on your system).  Yes you're dreaming this. There are 2 major faults in your reasoning: The question itself. Most newbies fail to that hole though. They ask ""what if I do something - will it be faster?"". But the proper question is ""My application Runs slow. How to find a bottleneck?"" and ""I have certain bottleneck. How to eliminate it?"" You suppose fieldlist part influencing database search. That's wrong. The field list is responsible only for the returned fields of the found rows. In both cases the number of rows would be the same.",php mysql sql database3196022,A,"mySQL images upload I need a simple code to upload images to mySQL using PHP... short! snippet... and is it possible to upload an html css file to mySQL?... its reason is complicated but all answers are appreciated!... EDIT:: say I have 1000 users.. and they each have their own layout for their page.. So inside their MYSQL record will be a html file css file(possibly) and image(s)... I am a big fan of using a filesystem for storing physical files i've yet to see any solid reason why they are better off in a database. To automate this process you could have a shell script called through exec exec(""/home/some/path/my_filesystem_creator.sh "".escapeshellarg($args)); or PHP's native mkdir or anything really. If you went for a structure like: /common/ /userdirs/1/ /userdirs/2/ essentially all i would imagine you would need to do is create a user dir and copy into it the default versions of their site assets - images/css/html etc. This should be easy enough to manage I am too.. i would rather use a filesystem... how would you suggest I automate a directory/file creation? i would have a basic template that can be copied I guess... but how would you suggest doing it? have any links? simple option above perfect... thanks!  You might want to take a look at http://mysqldump.azundris.com/archives/36-Serving-Images-From-A-Database.html and http://hashmysql.org/index.php?title=Storing_files_in_the_database before doing that. Storing files in mysql is generally considered a bad idea.  Just use different CSS rules for each user. Create the CSS dynamically though PHP based on user-specific variables. For example if they have a div with an avatar or some other personal image just create a class that uses variables for images and then you really only need one or two files at most to do the whole thing. I would use a heredoc but you could just use quotation marks to integrate the PHP. php creates your css - .useravatar{ 'background: url($baseurl.$urseridpic)'} In the html the div just needs the class of 'useravatar' never needing to be changed.  Your page would be faster if you generate a directory on your filespace for each user and store their css/js/image files there. The reason for this is that when you like to output your images to the browser you will need to establish an own db connection for each file (since each is an own HTTP request to a PHP file selecting the image). I see.. ya.. well the only problem with that is that whenever I get another user I would have to create another file set.. have any automated ideas? You could automate the file creation... There are functions in PHP like mkdir() and fopen() uhhu.. thanks.. I guess i will go with a filesystem... now just how to do it with the least amount of effort...  Are you asking how to store a file in the database? http://www.php-mysql-tutorial.com/wikis/mysql-tutorials/uploading-files-to-mysql-database.aspx Or do you need to know how to upload a file to your web server in order to display it in a PHP/MySQL website? I know how to upload files ect... I need SOME of them INSIDE the MYSQL database.. for instance.. I have 1000 users.. and they each will have their own layout for their page.. So inside their record will be a html file css file(possibly) and image(s)... get the idea? Thanks for the link.. helps alot!",php sql mysql database3284275,A,"concat tables with different content I am currently building a small web application for publishing stories using PHP and MySQL. Each story may either be a article (with lots of fields and data) just a hyperlink/url just an image or a downloadable file with certain attributes (once again with lots of fields). My problem is related to finding the optimal database layout for the system. I have thought about 3 different solutions that may or may not work (fields are just examples don't get caught of with whether the data should be stored in the database or not): 1) Making one table for each type and just UNION them. E.g: articles id | date | title | author | preview | last_edited | category | content hyperlinks id | date | title | author | url pictures id | date | title | author | thumbnail | fullimg files id | date | title | author | filetype | filename | filecontent Is it possible to make a SQL statement that will concat these in such a way that every field is added to the rows from the individual tables and the individual row is ""tagged"" with its type depending on which table its from? Or do I have to settle for just the common fields (3-4 field WILL be identical for each table) and to individual lookups for each row? 2) Making some sort of index table that references the correct table and row depending on the type? index id | type | title | date | referenceid -> either articles hyperlinks pictures or files depending on the ""type"" field. Is this possible in some way when using foreign keys? I suspect no but not really sure what you can and can not do in MySQL. 3) Have ALL fields for ALL types in one and the same table and just make the specific field nullable (I dont really like this solution since it appears messy). Any ideas? I suspect I can not be the first person to have encountered the issue of references to different entity types/fields depending on some sort of type. Ideas are highly appreciated. If you name fields you can union then quite easily and throw in whatever constants you like. I do this all the time: Select id 'articles' as tablename title author preview last_edited category '' as url from articles UNION Select id 'hyperlinks' as tablename title author '' as preview '' as last_edited '' as category url From hyperlinks ... UNION is inherently slow. For SQL Server UNION ALL is a lot faster - not sure about mySQL. But like everything else with databases performance is dependent on too many factors to isolate. Unless you are dealing with gobs of data I wouldn't expect this query to be the choke point. What would be the performance penalty of solving it in this way? I am quite interested in finding out the different advantages and disadvantages of possible solutions.  I'd add a 'type' column to each table that specifies what table it came from and then do an equijoin followed by a group: SELECT * FROM articles a INNER JOIN hyperlinks h ON a.id =h.id AND a.date=h.date AND a.title=h.title AND a.author=h.author JOIN pictures p ON h.id=p.id AND h.date=p.date AND h.title=p.title AND h.author=p.author JOIN files f ON p.id=f.id AND p.date=f.date AND p.title=f.title AND p.author=f.author ORDER BY type; It's an ugly-looking query but it should do what you want... What would be the performance penalty of solving it in this way?  You have so few fields just put them all in one table and add a type field. No sense overcomplicating things.  I'd suggest adding a stories table to be the central table. This allows for a great deal of flexibility in the system design and centralizes the data that is core to a story. Something along these lines: stories id date title author article_id hyperlink_id picture_id file_id articles id preview last_edited category content hyperlinks id url pictures id thumb full files id filetype filename filecontent Won't this have some issues with foreign keys and stuff like that if for instance article_id isn't relevant for that particular entry? FKs can be null",php sql mysql database database-design2701262,A,"How to use multiple database adapter to query involving tables from different databases? I've 2 databases which are set up as mentioned here. How can I write a SQL query which involves database_1.table_1 and database_2.table_1 ? E.g. consider this query $sql = ""SELECT distinct database_1.users.id database_1.users.name FROM database_1.users database_2.sales WHERE database_2.sales.user_id = database_1.users.id""; How this query could be written using multiple db adapter? Edit: I thought of using 2 database adapters because this way I can change actual database names in application.ini. Is there any other way I can change database names without changing sql queries? Solution I'm using: I used another config variable to read second database name. First database name comes from adapter settings. You can't unless you use something like Federated databases but even then you'd use one database adapter for the query and let the database handle the fetching from the federated other databases. Zend_Application_Resource_Multidb is just setting up multiple database adapters at once. Nothing more. You will use each adapter separately from the other. Use Adapter1 to query database1 and use adapter to query database2. Two queries. Merge the results inside your application. @Gordon: That's what I suspected. @Gordon: could you please comment on my 'Edit in the question' above? @understack are these databases on the same server in the same database system? yes. BTW I ended up using the approach I mentioned in edit. I made another config variable to read second database name and it is working properly. @understack ah well you solved it yourself :) cheers",php sql database zend-framework2798572,A,Will MySql caching cause performance problems? I am about to upload my website onto a VPS. It is a classifieds website where all data is stored in MySql and Solr. I wonder if when using MySql:s cache the server will slow down? Ie if somebody makes a search for the first time and MySql is to cache the query will the caching make the server slower than if it would not cache anything? After the caching is done I know things will improve in terms of performance... But I would like to know if I should even use the cache or not what do you think? Thanks Best is not to make any assumptions but to do some benchmarking. There are several programs available to benchmark a website. I've never run into a situation where Mysql caching was detrimental to performance. The first time a query is run there is no performance hit when the query is written to Mysql's memory cache. The only significant resource used when query caching is memory. The more memory you configure Mysql to use the more it will cache. But to get the real answer you need to test it. Gathering metrics is the only way to get a real answer for your particular situation. There are a variety of caching techniques some of which might be more useful than query caching to your particular situation.,php sql mysql database caching2228356,A,"Get MySql result-set size from query using PHP Is it possible to get the size of the result-set when doing a query? I need to set a proper MySql cache_limit (MB) and therefore I am trying out some queries but I need to know the sizes of the result-sets to fine-tune my cache configurations. What exactly does query_cache_limit do when measuring the size of a query (or result)... Any help appreciated! Thanks So you want to size in bytes of a mysql query result? And what mysql_fetch function are you using? fetch_assoc...... There are several ways to measure the size of data sent from your mysql server to your php process: Pure SQL Do your query and execute SHOW SESSION STATUS directly after it. You will get several statistics including the sent and received bytes: Bytes_received 191 Bytes_sent 120 Subtract the bytes from a SHOW SESSION STATUS query alone and you have the exact values. mysqlnd PHP 5.3 offers the ""MySQL Native Driver"" which gives you some nice options to debug your connection. Do your query and then call mysqli_get_connection_stats. It returns the network statistics too: Array ( [bytes_sent] => 43 [bytes_received] => 80 ... You need to use mysqli and mysqlnd here but you get more accurate numbers as with the pure SQL solution.  As a rouph estimate you coud try <?php // This is only an example the numbers below will // differ depending on your system echo memory_get_usage() . ""\n""; // 36640 $a = mysql_fetch_assoc($result); echo memory_get_usage() . ""\n""; // 57960 unset($a); echo memory_get_usage() . ""\n""; // 36744 ?> or echo strlen(serialize(mysql_fetch_assoc($result))); strlen won't always be indicative of the byte length as there may be things like multibyte strings in the response (which take up one character but several bytes) Very true like I said this would only be an estimate. Considering the problem it is likly Camran would know if there would be an issue with multibyte strings. Also consider that serialized string might not represent an accurate size compared to a array  I believe Petah's method of using memory_get_usage before and after is probably the easiest way. To get a more accurate result you could use mb_strlen but you'd need to loop through each row in the result and each field of each row summing up the total as you go. You'd also need to use the correct encoding. http://us3.php.net/manual/en/function.mb-strlen.php",php sql mysql database caching2208934,A,"Character set in MySQL; Can't insert special characters why? I can't insert special characters. Whenever I try to all characters BEFORE the special character gets inserted but after the special character nothing is inserted into the field. $conn = mysql_connect($dbhost $dbuser $dbpass) or die('Error connecting to mysql'); mysql_select_db($dbname$conn); mysql_set_charset('utf-8' $conn); mysql_query(""SET NAMES 'utf8'"") or die(mysql_error()); mysql_query(""SET CHARACTER SET 'utf8'"") or die(mysql_error()); I have set the table to utf-8 collation and all fields as well... Any thoughts? Thanks You'll have to provide examples of the code you use to do the insert and the results you get. Have you set the necessary UTF-8 parameters in your PHP config? I used to begin my PHP files with that:  ini_set(""mbstring.internal_encoding""""UTF-8""); ini_set(""mbstring.func_overload""7); ..that fixed it..",php sql mysql database3746632,A,"PHP: SELECT ing 2 tables? I have a activities page and a statusmessages page for each user. In activities it contains what the users have done such as being friends with someone commented on pictures and so. users_activities id | uID | msg | date In users_statusmessages I got the statusmessages the user creates. users_statuses id | uID | message | date uID is the userÎ‚s id. Now i would like to select both of them and while{} them in one. Where they get sorted by date desc ( as the date in both tables is UNIX timestamp). So something like WHERE uID = '$userID' ORDER BY date DESC So example of how i wish it to look: User: Today is a good day (message) (date: 1284915827) (users_statuses) User have added as Jack as friend (msg) (date: 1284915811) (users_activities) User: I have a hard day today (message) (date: 1284915801) (users_statuses) User have commented on Jacks picture (msg) (date: 1284915776) (users_activities) How should i do this the right way? Something like this would do SELECT act.*status.* FROM users_activities act users_statuses status WHERE act.id = status.id AND status.id = '$UID' ORDER BY status.dateact.date DESC LIMIT 30 Spaced out for visual purposes: SELECT act.*status.* FROM users_activities act users_statuses status WHERE act.id = status.id AND status.id = '$UID' ORDER BY status.dateact.date DESC LIMIT 30 You may have misread the question. There is no relationship between activities and statuses as far as I can tell.  You need to use the UNION operator:  SELECT ua.msg ua.date 'activity' AS is_table FROM USERS_ACTIVITIES ua WHERE ua.uid = '{$userID}' UNION ALL SELECT us.message us.date 'status' FROM USERS_STATUSES us WHERE us.uid = '{$userID}' ORDER BY `date` UNION UNION removes duplicates. UNION ALL does not remove duplicates and is faster for it. But the data types at each position in the SELECT must match. In the query provided you can see that the date column is referenced in the second position. You'd get an error if the column order were reversed between the first and second query. The ORDER BY is applied to the result of the UNION'd query in standard SQL. In MySQL that includes the LIMIT clause. But MySQL also supports putting brackets around the UNION'd queries so you can use ORDER BY & LIMIT before the queries are UNION'd. When im using this in a while($show = mysql_fetch_array($query)) im receiving: mysql_fetch_array() expects parameter 1 to be resource boolean given in. This is because ORDER BY ua.date  how can i solve this? @Karem: Typo on my part see the update. And while waiting for answer on the ORDER part i tried echo $show[""msg""] and it works well gets all the userÎ‚s status but when I do $show[""message""] show anything. just noticed when i do $show[""msg""] it shows BOTH msg and messages like I wanted @Karem: Yes the column reference is based on the first of the UNION'd queries. Sorry mentioned everything but that. Ok last thing i think im trying to sort out WHERE `uID` = '$USER' but then i dont get any results. How is this wrong? @Karem: Sorry I missed that requirement. See the updated one. @OMG Ponies; ty OK almost there just one last thing how can i know if its from the status or activity? Example i want to make $show[""status""] bold if its a status else if its a activity just display without having it bold. How can i check for that? Last question before accepting thank you @Karem: Add a column with statically defined values. See the update I labelled the column ""is_table"". You can check the value in PHP and handle presentation accordingly. So let me get this clear: I make a column called ""activity"" in users_activities and a column in users_statuses called ""status"" ? And then make a standardvalue ""1"" for it? And then after that i check by doing if(isset($show[""is_table""] == 1)) ? Sorry if im asking too much @Karem: Using what I provided `$show['is_table'] == 'activity'` for knowing when to handle activities; `$show['is_table'] == 'status'` for statuses. You can change the value to be numeric if you like. Yes ok so standardvalue should be status/activity ? OH my bad! I thought you want me to add an column in the table.. But now i understand what you did thank you accepted and +1! @Karem: I should have said ""derived column"" sorry.  You're going to want to use a union http://dev.mysql.com/doc/refman/5.0/en/union.html This is untested... (SELECT uID msg as message date from users_activities) UNION (SELECT uId message date from users_statuses) order by date desc limit 20 There are a lot more examples on that page",php sql mysql database3613485,A,"Unable to Select Record from Database I am learning PHP and SQL and I'm trying to figure out how to select a record from a database. I created a function called selectById() Right now in the browser displayed is ""Error:"" but no specific error was displayed.  // function selectById -------------------------------------------------------------------- function selectById($pUInput) { $sql = mysql_query(""SELECT * FROM tblStudents WHERE id='$pUInput[0]'""); if (!mysql_query($sql)) { die('Error: ' . mysql_error()); } echo ""Record Selected""; } PHP Code: //Call function mainline mainline(); // Declare the function mainline function mainline() { $uInput = getUserInput(); $connectDb = openConnect(); // Open Database Connection selectDb($connectDb); // Select Database doAction($uInput); //display(); //closeConnect(); } //Declare function getUserInput -------------------------------------------------------- function getUserInput() { echo ""In the function getUserInput()"" . ""<br/>""; // Variables of User Input $idnum = $_POST[""idnum""]; // id (NOTE: auto increments in database) $fname = $_POST[""fname""]; // first name $lname = $_POST[""lname""]; // last name $major = $_POST[""major""]; // major $year = $_POST[""year""]; // year $action = $_POST[""action""]; // action (select insert update delete) $userInput = array($idnum $fname $lname $major $year $action); return $userInput; } function doAction($pUserInput) { echo ""In function doAction()"" . ""<br/>""; if ($pUserInput[5] == ""sel"") { selectById($pUserInput); } elseif ($pUserInput[5] == ""ins"") { insert($pUserInput); } } // Create a database connection -------------------------------------------------------- function openConnect() { $connection = mysql_connect(""localhost"" ""root_user"" ""password""); echo ""Opened Connection!"" . ""<br/>""; if(!$connection) { die(""Database connection failed: "" . mysql_error()); } return $connection; } // Select a database to ---------------------------------------------------------------- function selectDb($pConnectDb) { $dbSelect = mysql_select_db(""School"" $pConnectDb); if(!$dbSelect) { die(""Database selection failed: "" . mysql_error()); } else { echo ""You are in the School database! <br/>""; } } // function select --------------------------------------------------------------------- function selectById($pUInput) { $sql = mysql_query(""SELECT * FROM tblStudents WHERE id='$pUInput[0]'""); if (!mysql_query($sql)) { die('Error: ' . mysql_error()); } echo ""Record Selected""; } // function insert ----------------------------------------------------------------------------- function insert($pUInput) { $sql=""INSERT INTO tblStudents (first_name last_name major year) VALUES ('$pUInput[1]''$pUInput[2]''$pUInput[3]' '$pUInput[4]')""; if (!mysql_query($sql)) { die('Error: ' . mysql_error()); } echo ""1 record added""; } ?> SQL Syntax: CREATE TABLE `tblStudents` ( `id` int(11) NOT NULL AUTO_INCREMENT `first_name` varchar(30) NOT NULL `last_name` varchar(50) NOT NULL `major` varchar(40) NOT NULL `year` date NOT NULL PRIMARY KEY (`id`) ) You are running a query on a query result. This will not work. You will need to use something along the lines of $sql = mysql_query(""SELECT * FROM tblStudents WHERE id='"" . $pUInput[0] . ""'""); if (!$row = mysql_fetch_assoc($sql)) Which would assign $row an array value if the query did not fail. You may also want to filter the pUinput as well with mysql_real_escape_string as you do not necessarily know what it contains (or statically cast it to an integer). EDIT Added a bit extra information. thank you for the response. (i'm new to PHP and SQL i'm trying to fully understand your answer.) So the statement in the selectById() function will not actually select the record by that one statement alone--it needs the function mysql_fetch_assoc(). i'm just summarizing what i think i understand... Keep http://cwe.mitre.org/data/definitions/89.html in mind and take a look at http://docs.php.net/mysql_real_escape_string . Or even better use parametrized queries see e.g. http://docs.php.net/pdo.prepared-statements",php sql database forms1381131,A,How to write SQL query for these 5 tables? I am writing an application that helps book exchange between users. I am using PHP and MySQL and I am pretty new to them both. I have 5 tables 3 data tables and 2 service tables: user: with user attributes (user_id name birth... etc). book: with book attributes (book_id name author publisher... etc). copy: represents actual copies of a books (copy_id condition comments... etc). user_copy: describes which user holds which copy composed out of userID and copyID. copy_book: represents the connection of copy and book composed out of copyID and bookID My question is: what is the easiest and most efficient statement for getting the book attributes and copy attributes for each copy that a user holds? Why do you have a separate `copy_book` table? To my mind it would make more sense to have a `bookID` column on the `copy` table. Usually you only need a table like `copy_book` if there is a many-to-many relationship between books and copies which I don't believe is the case You need to inner join all the tables that you are interested in: book copy user_copy and copy_book. The SELECT statement that returns attributes on all copies held by a user may look like this: SELECT B.bookID  B.name  B.author  B.publisher  C.condition  C.comments -- you may get other fields that you are interested in here.. FROM book B INNER JOIN copy_book CB ON B.bookID = CB.bookID INNER JOIN user_copy UC ON UC.copyID = CB.copyID INNER JOIN copy C ON C.copyID = UC.copyID WHERE UC.userID = <the user Id that you want> I hope it's pretty clear what the statement does but if you have any questions please ask.,php sql database mysql1732657,A,"what is wrong with this mysql code $db_user=""root""; $db_host=""localhost""; $db_password=""root""; $db_name = ""fayer""; $conn = mysqli_connect($db_host$db_user$db_password$db_name) or die (""couldn't connect to server""); // perform query $query = 'SELECT * FROM posts'; $result = mysqli_query($conn $query) or die (""Couldn't execute query.""); // use returned data while($row = mysqli_fetch_assoc($result)) { echo $row['title']; } I get in the browser: ""mysql problem"". Help! UPDATE I have echoed the query. It shows SELECT * FROM posts and when I query manually it gets the rows. I think it has something to do with mysqli. I think i should use mysql. Do u think I have incompatibility problems with mysqli? i have echoed it. it shows SELECT * FROM posts. and when i query manually it gets the rows. i think it has something to do with mysqli. i think i should use mysql. do u think i have incompatibility problems with mysqli? are you going to change the question so that answers become invalid? Change $result = mysqli_query($conn $query) or die (""Couldn't execute query.""); to $result = mysqli_query($conn $query) or die (""Couldn't execute query because: "" . mysqli_error()); and you will know why the query is failing. Rule of thumb: Whenever you have a failed query print it out and run it through phpmyadmin or some other raw-query executor and you will discover very quickly what the problem is. i forgot to delete it. here is my new code and i still have problem! it shows nothing . just ""mysql error"" it says ""mysql problem"" not mysql error=) echo $query and execute it manually like I suggested.  You have empty WHERE clause. Remove it or add a search condition.",php sql mysql database2103472,A,"Can you do queries against two databases if mysql_select_db was already used? I have code that in the connection setup selects the database using mysql_select_db(). $link = mysql_connect('localhost' 'user' 'pass'); mysql_select_db(""database1""); Can I later run a query against two databases such as: SELECT database1.row database2.row FROM database1.table database2.table WHERE database1.row = database2.otherrow even though ""database1"" was already selected at first? Or is there a method for unselecting the database? You can. Also check this out: How do I construct a cross database query in PHP?",php sql mysql database database-connection2184235,A,"Small Php and MySql problem I have an array of ID:s and the ID:s are in this format:  Bmw_330ci_89492822 So it's a string! Now I have this code to find whatever is in that array in MySQL: ($solr_id_arr is the array I mentioned above it contains string ID:s) ex: $solr_id_arr[0] outputs Bmw_330ci_89492822 $solr_id_arr_imploded = implode("" "" $solr_id_arr); $query = ""SELECT * FROM my_table WHERE ad_id IN ('$solr_id_arr_imploded')""; $qry_result = mysql_query($query) or die(mysql_error()); Problem is this wont work because (I think) that there should be quotes around each of the imploded elements in order for MySQL to find the match. The field in MySQL I am matching is of type Varchar. Here is the $query echoed:  SELECT * FROM my_table WHERE ad_id IN ('Bmw_m3_cool_565440282 Bmw_m5_839493889') Do you have any other solutions for this all I need is to find matches in MySQL which are inside this array! Thanks Don't surround the entire thing in quotes. It is looking for where ad_id is 'Bmw_m3_cool_565440282 test' Use SELECT * FROM my_table WHERE ad_id IN ('Bmw_m3_cool_565440282' 'test') A quick fix would be to change: //this $solr_id_arr_imploded = implode("" "" $solr_id_arr); //to this $solr_id_arr_imploded = implode(""' '"" $solr_id_arr);  Simple switch to ' ' in implode(): implode(""' '"" $solr_id_arr); This together with the hardcoded quotes in the SQL string will format them as separate items.  This one seems complicated but it's more safer and fastest one function escaped($str) { return mysql_escape_string($str); } $arrayOfIds = array_map(""escaped"" $solr_id_arr); $solr_id_arr_imploded = implode("" "" $arrayOfIds); $query = ""SELECT * FROM my_table WHERE ad_id IN ('$solr_id_arr_imploded')""; $qry_result = mysql_query($query) or die(mysql_error());  Previous answers will work fine. Just make sure the strings themselves do not contain quotes. If they do escape each string before you do the implode().  If it were my code I'd write it like this: $solr_id_arr_imploded = ""'"" . implode(""' '"" $solr_id_arr) . ""'""; $query = ""SELECT * FROM my_table WHERE ad_id IN ($solr_id_arr_imploded)""; $qry_result = mysql_query($query) or die(mysql_error()); ...just because it keeps all the quoting work in one place. You might also want to make sure that the array isn't empty before entering this block of code. Otherwise the SELECT will match all empty ad_id's which probably isn't what you wanted. We're also assuming that the elements of the array don't include any quote characters (or user-provided strings that haven't been sanity-checked).",php sql mysql html database1943769,A,"Update doesn't work as should be in MySQL  echo $totalprice; echo ""<br/>""; echo $shortfall; echo ""<br/>""; echo $unitprice; echo ""<br/>""; I got 24 80 0.3 Then the following command was executed. // update query However only total_price was changed(became 0.00) while other values like unit_price stay unchanged. But other values like unit_price should be changed. Total_price is unsigned when total_price-pricebalance is done it becomes 0.00. So does it refuse to subtract $totalprice? Any idea? Can you post the actual mysql query that was executed? Why are you using ANDs in your UPDATE query? mysql_query(""update piecework set total_price=total_price-pricebalance+$totalprice quota=quota-shortfall+$shortfall shortfall=$shortfall unit_price=$unitprice pricebalance=$totalprice where piecework_id='$pieceworkid' and publisher=$memberid and (pricebalance-$totalprice)>=0"")or die(mysql_error()); Or with better readability: UPDATE piecework SET total_price = total_price - pricebalance + $totalprice quota = quota - shortfall + $shortfall shortfall = $shortfall unit_price = $unitprice pricebalance = $totalprice ... Many thanks oh my brain!!!!",php sql mysql database2209338,A,"Another mysql JOIN question I have these tables: classified: classified_id (PK) price headline cat_id // THIS IS ANYTHING FROM 1 TO 30 DEPENDING ON CATEGORY. IT IS SO THAT I CAN LINK WHICH CATEGORY TO USE IN THE CATEGORY TABLE BELOW text etc... category: cat_id (PK) cat_name category_options: option_id (PK) cat_id (FK) // FOREIGN KEY FROM CATEGORY TABLE... option_name option_values: value_id (PK) option_id (FK) classified_id (FK) value How should I use join here could anybody give me a quick example? Here is an example of my setup:  category cat_id cat_name 1 cars category_options option_id cat_id option_name 1 1 color 2 1 gearbox option_values value_id option_id classified_id value 1 1 22 red 2 2 22 manual classified classified_id price headline cat_id 22 5000 'test' 1 //for cars I want to be able to retrieve all options and their values from one category (in this ex cars) by only 'knowing' classified_id (which is 22 in this case). Basically I need help with the join statement... and please don't use aliases in the code to simplify it for me :) Thanks Can there be multiple values per option? Do you want to select them based on `cat_id` `classified_id` or both? No multiple options per category but only one value per option name... I want to select them based on classified_id and cat_id so let's say cat_id = 1 and classified_id = 22 Then there is imo no real reason to have a `value_id` as both `option_id` and `classified_id` would make a primary key for the option values.. Something like SELECT category_option.option_name option_values.value FROM classified category_option option_values WHERE classified.classified_id=?id AND classified.cat_id=category_options.cat_id AND option_values.option_id=category_options.option_id If you passed in 22 for the ?id parameter you'd get 2 rows: Color Red Gearbox Manual  I know this doesn't answer your main question but I'd like to offer a suggestion that I believe will make your life easier... Column names for PK columns -- just call all of them ""id"". Reduces the number of things you have to remember. Eliminates a major source of confusion and potential bugs. Make table names consistent. I mean make them all the same form. You could make them all a singular noun or all a plural noun but just make them all the same. Queries become easier to write and easier to understand. classifieds categories category_options option_values Column names for FK cols -- like this: parent_table_id. For example: classified.category_id. Eliminate any verbiage that doesn't contain new information. For example category.name instead of category.cat_name. re (1): I disagree. Especially when dealing with joins it is a *lot* easier to have unique names for the *id* columns so you can easily see which ids should be interpreted the same. I agree with (4) as those won't make an index but for indexed columns it is better to have unique names that spread over all tables where the same id is meant.  You actually don't even need to explicitely specify the join here. It's just as simple that you want to get values from two tables (options and their values) where the option_ids are identical and select only thos results where your cat & classified id matches. SELECT cat_id classified_id option_id option_name value FROM option_values category_options WHERE category_options.option_id = option_values.option_id AND classified_id = <?> AND cat_id = <?> Hi... This works fine thanks... But what If I would like to insert an ad. I know how to insert into the classifieds table but I don't know how to insert the values of the option_values because there are more than one row that needs to be inserted. The classifieds table is easy because it's just one row but the option_values table has multiple rows per classified_id. Could you make a Insert statement for me as well? Thanks For inserting just execute the same insert statement multiple times (which changed values of course). Or you can use the syntax to add multiple values at once (`INSERT INTO tbl ( col1 col2 col3 ) VALUES ( row1-1 row1-2 row1-3 ) ( row2-1 row2-2 row2-3) ...`) but most times that is not really the easiest way when working with dynamic content (it's easy to use that syntax when you know how many rows will be inserted but for a dynamic number just insert one row per statement).",php sql mysql database1870997,A,Is it a good practice to write subqueries in MySQL? I am writing the following sub query for some project specific purpose: SELECT count(*) from table1 WHERE userB='$p' AND userA IN (SELECT userB FROM table1 WHERE userA='$row[username]') I was curious if this was the best practice when doing it in PHP or should I resort to the conventional way of first getting the subquery result and then counting the records? In general most databases perform better with left joins (which your query could be converted to) than subqueries. Joins in general but there are caveats  Worth noting that subqueries are only available in MySql 4.1 and higher. While ideally everyone should be on MySql 5 some users are stuck with what their host offers (I have been stung by this a few times).  I agree with Ted left join will be faster. and its easier to read too. also dont use count(*) use count(id)  As long as the subquery doesn't cause a performance hit I think it's better to stick to one query. It will minimize the code you have to write and maintain which is almost always a good thing.  I was curious if this was the best practice when doing it in PHP or should I resort to the conventional way of first getting the subquery result and then counting the records? Leaving the SQL query in PHP or stored procedure holy war aside less trips to the database is the best practice. There's time to the database & back that can never be recouped and separating the queries runs the risk of data changing in between the queries. Can the query itself be optimized? In this example potentially yes: SELECT COUNT(*) FROM TABLE t JOIN TABLE t2 ON t2.userB = t.userA AND t2.userA = '$row[username]' WHERE t.userB = '$p' If you really want to be sure about query performance you'll have to get familiar with generating an explain plan & interpreting the output to tune the query. What's an Explain Plan? The MySQL explain plan shows how the MySQL query optimizer has decided to run a SELECT statement in order to best access the data that's been requested. How Do I Generate an Explain Plan? In MySQL you just have to add the keyword explain to the SELECT query before the SELECT keyword. IE: EXPLAIN SELECT COUNT(*) FROM TABLE t JOIN TABLE t2 ON t2.userB = t.userA AND t2.userA = '$row[username]' WHERE t.userB = '$p' Probably should have mentioned this earlier but you don't want to run this from within PHP because it won't return what you queried for. Use whatever SQL IDE like PHPMyAdmin/etc. I've Gots My Explain Plan But What Does it Mean?! The MySQL EXPLAIN documentation is a good place to read up on each column that is returned & what the column represents. EXPLAIN SELECT * FROM OMG Ponies; +1,php sql mysql database query-optimization1749520,A,"How can I make my mysql database records visible to search engines? I am creating a classifieds website called 'mySite' and I want whoever searches for honda +mySite in google to find all ads with the description 'honda' or headline 'honda' from my database. How is this done? (a htm page for every ad? which then loads the 'ad data' when user clicks to open the htm page?) I have an example for you to look at: www.blocket.se is a swedish site where you can buy almost anything. I am guessing they dont actually have 500thousand html pages just so that google can find them right? Try searching this in google: blocket +bmw 330ci and you will see results from blocket.se database. Question is: How have they done it? and how should I do it so that I have the same functionality? Thanks If you need more input tell me and I will update! This looks very familiar-> http://stackoverflow.com/questions/1748688/how-to-have-search-engines-index-database-driven-content Anyway read the responses here tell us if helps (or not). You're talking about something like when typing `tree german` it comes up with a link to a dictionary...? could someone please show me an example code? Sample code would look like the code for your search. The code that generates the search results ON YOUR SITE would be a good place to start. You want to iterate all the records of your database and generate links to all items in it. If you don't know how to do this you need to do some studying of your code and/or ask some different SPECIFIC questions on SO. I will do some studying and then post another Q if I get stuck! You don't need an actual html page for every advertisement. Most of the time there is one page that looks at the url and displays content accordingly. mysite.com/honda mysite.com/acura mysite.com/bmw All of these urls would be handled by one page. The page would use the url to find what content to display and serve just that content. Basically you're just creating a website and google does the rest @camran you may be used to doing the same thing by passing a parameter to some 'index.php' such as '?type=honda'. Galen's method isn't so different if you imagine a web server responding to any requests for mysite.com with 'website.php?url=mysite.com/honda'.  I create a sitemap that links to every category and every dynamic page that way spiders can easily navigate through every url on your site. If you do this dynamically then you can easily group by popular keywords and have a special ""grouped by keyword"" sitemap. At any rate its best to have the sitemap generated dynamically so you don't miss a single dynamic page. how about meta keywords and meta descriptions are they also generated the same way? or how would you solve that? meta's are certainly able to be generated dynamically just like any other html element. i just dont know where to start! An example would simplify things for me break things up and do it one at a time first step is to create a sitemap so 100% of your pages are linked to and are able to be spidered! Then you can move on to meta tags  You need to create links to your database pages. Right now the only way to get to your pages is to use the search on your site. Google doesn't fill out form fields. So create some links to your pages. Your pages should to be search engine friendly so  http://site.com?q=honda+civic is bad http://site.com/cars/honda/civic is good. You can rewrite urls using your framework (you are using a web application framework right?). You need to link to these pages preferably from other sites. You won't ever get every page in google because they are too similar and google will probably throw a lot of them out. But you need links to them to start. Ok. I get your explanation... but could you please post an example? You are talking about auto-adding url to a 'sitemap' but what would that url lead to? There are 2 separate issues here. 1) You don't have a sitemap so google doesn't know you have any pages. 2) Even if you did google doesn't like pages with ?q= in it So there are 2 things to fix. Sample code is way out of the scope of this question. we have no idea what framework you are using if you are using one at all. Do you know how to iterate the database and generate pages? yes i know that! I just dont get the idea of how to create links which are renamed to something else and then somehow add a meta-element to it? I will have to study some more I guess. But thanks Google URL rewriting. Check stack overflow as well. You can make URLs like /cars/honda/civic automatically go to ?q=honda+civic. Good luck! You can modify the meta tags by editing the code the displays the page. The data for the meta tag should come from the data you are displaying. OK I think I get it you are saying crawler goes in thorugh the backdoor even though the actual page to display the record 'honda civic' hasent yet been created but google will find it anyway right? just as long as there is a link there to a php page which fetches data from a mysql database? right or wrong? Url rewriting will take one (nonexistant) url and serve the data from another url (that exists). To the user/crawler it will look like the nonexistant url has the data. so even thought here is no /cars/hond/civic on your site the web server will make the end user think there is.  You need to have links to the (dynamically created) pages. Google doesn't know (or care) if the page is dynamically generated. But it's not going to find it if you don't have a link to it. The google bot doesn't just spam your search box looking for keywords (for obvious reasons). For example your homepage should link to a ""latest"" page with a list of all your latest items. You should also create an archive page for every day with links to the items that were posted that day. These index pages can be dynamically generated as long as there is a link to them from your home page. Also remember to cache your daily archives and give a long value for the EXPIRES meta-tag so you don't have to hit your database every time somebody has a look. If you want to know more google has a guide for web-masters: http://www.google.com/support/webmasters/bin/answer.py?hl=en&answer=35769 In particular look at sitemaps: http://www.google.com/support/webmasters/bin/answer.py?hl=en&answer=156184 I'm suggesting that he creates a page for every day which links to all the items posted that day. Those pages aren't going to change so they can be cached. I should have written ""cache your indexes of items posted that day"". Good answer btw what do you mean by ""remember to cache your daily archives""",php sql mysql html database1655725,A,"How to show multiple results from MySQL Array Here is my current code:  $sql = ""SELECT * FROM user_posts""; $result = mysql_query($sql); $row = mysql_fetch_array($result); while ($row = mysql_fetch_array($result)) { print $row['message']; } My goal is to show all of the data in that SQL database through an array. But currently it only shows the latest one and nothing else. How am I able to do this? Thanks! You should remove this line $row = mysql_fetch_array($result); Apart from that it should display every message Works great! So that means I should not specify the variable before to make it work? What you're doing there is effectively removing the first row from the results. Each call to mysql_fetch_array moves on to the next row  You're only getting the one row because you overwrite the $row variable with the values from your results array. $sql = ""SELECT * FROM user_posts""; $result = mysql_query($sql); while ($info = mysql_fetch_array($result)){ print $info['message']; } Change it to something like that. It worked great! Thanks!",php sql database arrays2207575,A,"Fine-tuning my MySQL relations database and how to use JOIN on it? I am very new to mysql and databases so I need help here... How should I use JOIN to fetch a record from the tables below when the only given variable is the ad_id? category and category options are filled in manually i.e. the users may not alter them. So they are only reference tables but I am not sure this is how I should do it... I have 6 tables: category: cat_id (PK) cat_name category_options: option_id (PK) cat_id (FK) option_name option_value: value_id (PK) (AI) // I think this should have Auto Increment option_id (FK) classified_id (FK) value classified: (THIS IS THE MAIN TABLE YOU COULD SAY) classified_id (PK) (AI) ad_id cat_id headline description area: // I am thinking about moving these fields over to the posters table right? area_id (PK) classified_id (FK) area description Here is how I insert a classified into the tables: mysql_query(""INSERT INTO classified (ad_id cat_id headline description) VALUES ('$ad_id' $cat_id '$headline' '$description')""); $last_classified_id=mysql_insert_id(); mysql_query(""INSERT INTO poster (classified_id name email tel) VALUES ($last_classified_id '$name' '$email' '$tel')""); mysql_query(""INSERT INTO area (classified_id area community) VALUES ($last_classified_id '$area' '$community')""); I am new to JOIN! Every category has sub options (CARS -> color) and every option has a value. I want to only by having the ad_id select all this information. How can I do so? And should I merge the area and posters table? Also please take a careful look at my db and tell me if there is anything I might have missed... This is really out of my knowledge-base so detailed explanations are appreciated! Thanks This is an example of joining some of your tables to get data from more than one of them: SELECT c.cat_name co.option_name cl.headline FROM category c INNER JOIN category_options co ON co.cat_id = c.cat_id INNER JOIN classified cl ON cl.cat_id = c.cat_id WHERE cl.ad_id = {Your ad_id} You can join to any other tables needed in the same way (poster area). Edit (response to comment): The 'c' 'cl' and 'co' are aliases for the 'category' 'classified' and 'category_option' tables. They don't have anything to do with the join. Here's a source. When I say FROM category c that allows me to use 'c' as the a shortcut for the category table. Using aliases allows you to make the select/joins/where clause how I did instead of like this: SELECT category.cat_name category_options.option_name classified.headline FROM category INNER JOIN category_options ON category_options.cat_id = category.cat_id INNER JOIN classified ON classified.cat_id = category.cat_id WHERE classified.ad_id = {Your ad_id} Basically it's a shortcut that can save you some typing. what is the c for in c.cat_name? or the ""co"" or ""cl""... know any tutorial on this type of JOIN?  It looks like you have two fields that could be the primary key in classified: classified_id and ad_id. Then you have two other tables poster and area that have a one-to-one correlation with classified. If this is the case you could put all the fields in classified. A query to join the tables in your insert statements would like like this: select classified.ad_id classified.classified_id classified.headline classified.description AS classified_description poster.name poster.email poster.tel area.area area.description AS area_description from classified inner join poster on classified.ad_id = poster.classified_id inner join area on classified.classified_id where classified.ad_id = 123 Sounds good now that you mention it... Could you also take a look and let me know how to fetch a complete record from only having the ad_id... BTW I have the ad_id only because it is a varchar (BMW_330_8392829 for example) which I then have in the URL and some other reasons as well. Hmm.. that didn't handle my indentation too well.",php sql mysql database3488413,A,"How to find all records which are NOT in this array? (MySql) I have an array which contains a bunch of ID:s... I can't figure out how to write a query for finding all records which are NOT inside this array in mysql.  SELECT * FROM main_table WHERE .......... Any ideas? Thanks Like this: $str = implode('' $your_array); The above statements converts an array into comma-delimited string. ""SELECT * FROM main_table WHERE id NOT IN ('$str')"" More Info: http://dev.mysql.com/doc/refman/5.0/en/any-in-some-subqueries.html +1 for PHP integration Little tweak: `$str = count($your_array) != 0 ? implode('' $your_array); : ""null"";`. `IN` doesn't react well to empty braces.  SELECT * FROM main_table WHERE id NOT IN(1 2 3)",php sql mysql html database2754770,A,Kohana v3 automatically escape illegal characters? Quick question does Kohana (version 3) automatically escape data that is passed into ORM::factory..... (and everywhere else that has to do with the database)? For example: $thread = ORM::factory('thread' $this->request->param('id')); Would the data passed in the second argument be auto-escaped before it goes in the SQL query or do I have to manually do it? Probably a stupid question and it's better to be safe than sorry but yeah... I usually do manually escape the data but I want to know if Kohana does this for me? Thanks It's auto-escaped. The only scenario where you have to worry about escaping is if you're writing your own SQL and inserting your data directly (by way of concatenation for example) which you shouldn't be doing. The normal ways of querying a database in Kohana are parametrized queries (if you need to provide the SQL yourself) the query builder and ORM all of which handle escaping for you. Can you show me where it says it escapes it? or did you look at the code? I wasn't able to find anything on the site when i looked. @Galen: Sorry for the late response Š—– see the docs for the query builder (which is what ORM uses internally): http://docs.kohanaphp.com/libraries/database/builder#limitations,php sql database security kohana-32194685,A,"Should I use AI on these fields in MySQL? I have this db below. I wonder how I should use the ID to identify each record. Everything is connected from the classified_table! Two Questions: Should I use AI on every PK in this case? Could somebody give me the FULL code for selecting an entire classified from only an ad_id (""bmw_330ci_8939483"" for example)? I am new to normalized db and making a good database work so detailed instructions is very much appreciated... Also if you notice any 'wrongs' in this db please let me know. category table: cat_id (PK) cat_name category_options table: option_id (PK) cat_id (FK) option_name option_values table: value_id (PK) option_id (FK) value classifieds table: classified_id (PK) ad_id (VARCHAR) something like ""Bmw330ci_28238239832"" which will appear in URL poster_id (FK) cat_id (FK) area_id (FK) headline description price etc.... posters table: poster_id (PK) name email tel password area table: area_id (PK) area community Thanks What do you mean by AI in this context? Allen Iversion or Artificial Intelligence? I'm guessing auto increment in this context. auto increment....... I was thinking of Haley Joel Osment: http://www.imdb.com/title/tt0212720/ Ahh and PK is primary key now I get it. @OP please R from using A like that not E gets them ;) Using auto-increment for your PKs sounds sensible because it sounds like you already want to use a surrogate key and auto-increment makes the inserts very straightforward. Worth taking a look at this discussion about how to pragmatically choose what primary key to use.  I would auto-increment (AI) on fields that I would do majority of searching by. AI makes it easier to return results but there are performance issues where it can slow down the database. In regards to the query I am not exactly sure what you would want to return but this query returns the classified_id by the given ad_id SELECT classified_id FROM classifieds_table WHERE ad_id = ""bmw_330ci_8939483"" To perform a single insert into your classifieds table and column ad id the value audi a4 would be: INSERT INTO classifieds_table ad_id VALUES ""audi_a4"" Or multiple inserts using the same table multiple fields and multiple values would be: INSERT INTO classifieds_table (ad_id poster_id) VALUES (""audi_a4"" 10) Notice I left out classified_id because if you choose to auto-increment it will automatically assign a value without you explicitly assigning one. Check out MySQL :: Building a Database-Driven Website using PHP and MySQL for more tutorials. okay thanks! Could you also answer this: How should I insert an ad into these tables? Multiple """"insert into statement? What do you mean by ad? If you gave me more detail I could help sorry I mean a classified (my website is a classifieds website). For example user fills in a form to insert a classified. Then I have problem with actually inserting it into the tables. I don't know where to start really... Do you understand? Thanks I tried to demonstrate the basics of inserting above hope this helps. okay I understand but does this mean I have to make a new insert for every table right? and then do one mysql_query() for every insert statement right? Thanks again! You cannot perform inserts onto multiple tables in one query. I would suggest starting off to perform one insert per one query just to get a feel for inserting and then when you feel ready enough you can expand your skills. If you need to do a set of inserts in one go into separate tables a stored procedure would be a convenient way of doing it.",php sql mysql database indexing1882407,A,"major php issues I am trying to create a simple login system. When I run the login form (with the correct username and password) it doesn't seem to run the php. Any suggestions? <?php $host=""linuxserver""; // Host name $username=""jparry2""; // Mysql username $password=""""; // Mysql password $db_name=""jparry2""; // Database name $tbl_name=""customer""; // Table name // Connect to server and select databse. mysqli_connect(""$host"" ""$username"" ""$password"")or die(""cannot connect""); mysqli_select_db(""$db_name"")or die(""cannot select DB""); // username and password sent from form $myusername=$_POST['myusername']; $mypassword=$_POST['mypassword']; // To protect MySQL injection $myusername = stripslashes($myusername); $mypassword = stripslashes($mypassword); $myusername = mysql_real_escape_string($myusername); $mypassword = mysql_real_escape_string($mypassword); $sql=""SELECT * FROM $tbl_name WHERE username='$myusername' and password='$mypassword'""; $result=mysqli_query($sql); // Mysql_num_row is counting table row $count=mysqli_num_rows($result); // If result matched $myusername and $mypassword table row must be 1 row if($count==1){ // Register $myusername $mypassword and redirect to file Š—“login_success.phpŠ— session_register(""myusername""); session_register(""mypassword""); header(""location:login_success.php""); } else { echo ""Wrong Username or Password""; } ?> <html> <body> </body> </html> edit added login form code <html> <head><title>Login</title></head> <body> <form action='checklogin.php' method='POST' style='margin: .5in'> <p><label for='user_name' style='font-weight: bold; padding-bottom: 1em'>USER ID: </label> <input type='text' name='myusername' id='myusername' value='' /></p> <p><label for='password' style= 'font-weight: bold'>Password: </label> <input type='password' name='mypassword' id='mypassword' value='' /></p> <p><input type='submit' value='Login'> </p> <input type='hidden' name='sent' value='yes'/> <a href= ""/home/jparry2/public_html/register.php"">Register</a> </form> </body> </html> We really need all the errors messages you get if you want us to help you... What does the browser's source code say? What do you see there? I think you should specify way more information then this. For example what OS are you using. What is problem? No output shown. Does a simple work? Can you please add code for your login form? a more specific title would be nice I've changed a few things and now the browser brings up a dialogue box asking me to download the php. I'm using linux and opera. You will have to check if you have php installed and configured correctly. Also telling us that you *Changed a few things* to solve your *major php problem* isnÎ‚t helping us much. If your browser asks you to download the php file it means the php interpreter is not being invoked. i.e. you don't have it installed or configured correctly.  Are you getting any error message? Seems ok to me. Have you tried echoing something in the if-block for example? That might help you understand what's wrong. Some things you could check or try: Have you got error reporting on? Put `var_dump($_POST); die(); on the top of the page to see if the $_POST variables are submitted correctly. Make sure you are not outputting anything to the browser before the header() function. If you have error_reporting off and you outputted something to the browser using header() will result in a fatal error which could cause a blank white page. A few other notes from your code: You don't need to put variables inside double quotes they work on their own: mysqli_select_db(""$db_name"") becomes mysqli_select_db($db_name) You don't need to stripslashes() if you're doing mysql_real_escape_string. The latter will handle the job on its own.  You don't do any ""session_start()"" so your session can't be used. Maybe you need it to started in your ""login_success.php"" script.  In some browsers the Location header is case-sensitive and thus your header(""location:login_success.php""); call might not be working (a comment on the header documentation page suggests that this occurs in IE7). Try capitalizing the l in Location. IIRC In most of browsers headers follow the standard: Uppercase Names and space after "":"".  I agree with Daniel by revising header(""Location: login_success.php""); Also as a side note since at the time of writing this it wasn't clearly explained what didn't work but you when adding session variables you need to have session_start(). Also try to use $_SESSION['variable'] since session_register() is deprecated as of PHP 5.30 taken from PHP: session_register try something like this if($count==1){ session_start(); // Register $myusername $mypassword and redirect to file Š—“login_success.phpŠ— $_SESSION['username'] = $myusername; $_SESSION['mypassword'] = $mypassword; session_write_close(); // makes sure nothing was lost during redirect header('Location: nextpage.php'); }",php sql database login1940671,A,"Why does mysql_affected_rows return 0 even if one record should be updated mysql_query(""update users set balance=balance+'$pwbalance'-'$totalprice' where memberid='$memberid' and (balance+'$pwbalance'-'$totalprice')>=0"")or die(mysql_error()); $count=mysql_affected_rows(); When I echo $pwbalance it is 40.00; when I echo $totalprice it is 40; So there should be one record to be updated. However when I echo $count I get 0. What's wrong? Roland is right obviously you want to know if the query was successful the fact that the balance stays the same is unimportant for you. You might want to add a new field like purchase_count that you increment in this update or last_purchase_date something to trigger an actual update.  MySQL only actually updates a row if there would be a noticeable difference before and after the updat. Your calculation is basically: SET balance = balance + 40 - 40 So nothing changes and MySQL will not count this as an affectd row. Side note: don't single quote numeric values in the sql. single quotes act as string delimiters. For mysql  in this case they are automatically converted to numbers but it is bad practice at any rate. I agree with Roland Bouman; if `$pwbalance` contains a value that is used as integer in the query then don't use the quotes.",php sql mysql database2186091,A,mySQL Table Structure for a User-based website I am developing a website that has user profiles accounts account settings inboxes etc. just like Facebook or LinkedIn and I'm wondering how to set up the mySQL tables for it. Should I create a table for every user for each function (profile inbox etc.)? In short yes each function should be in one table if there is aneed to. On edit: And not a table for every user. One record in each corresponding table The concept this deals with is normalization. Consider profile and inbox. A user has only one profile but would have numerous messages in the inbox. It makes sense to have the inbox as another table with each message being identified by a message-id and its owner then its content.  You really need to think about everything you put into a database in terms of relationships (as mentioned by other posters). In the example you gave a user is going to have a one to many relationship with things like mail they will have a one to one relationship with their user profile and they will have a many to one relationship with something like 'locations' where many users live in one city. As you are designing your database always ask yourself which relationship type you need to build and make an attempt to never duplicate data in multiple tables when you don't need to. When you set up something like a users table make sure that every row is equal to a user (as opposed to every user being a table) and that every row has a unique auto-increment id. This user id (that is generated by MySQL) is going to be the reference that you use in other tables to link your data together. So when you setup your mail table you might have 15 rows containing email data but each of those rows will contain a field named something like user_id that will contain the unique id of that user from the users table. Start getting familiar with things like LEFT JOIN--this is how you will run a single query and get for example your user's data AND all of his email at once.  You wouldn't create a table for every user. You would create a record and a unique id for each user and then relate that user to other tables using the ID as a foreign key in other tables.,php sql mysql database table3002347,A,"Search SQL Question Between Related Two Tables I am writing some kind of search engine for my web application and i have a problem. I have 2 tables first of is projects table: PROJECTS TABLE id int(11) NO PRI NULL auto_increment employer_id int(11) NO MUL NULL project_title varchar(100) NO MUL NULL project_description text NO NULL project_budget int(11) NO NULL project_allowedtime int(11) NO NULL project_deadline datetime NO NULL total_bids int(11) NO NULL average_bid int(11) NO NULL created datetime NO MUL NULL active tinyint(1) NO MUL NULL PROJECTS_SKILLS TABLE project_id int(11) NO MUL NULL skill_id int(11) NO MUL NULL For example: I want ask this query to database: 1-) Skills are 5 and 7. 2-) Order results by created 3-) project title contains ""php"" word. 4-) Returned rows should contain projects.* columuns. 5-) Projects should be distinct(i don't want same projects in return of query). Please write sql query that ensure these conditions. Thank You. One query for all conditions or just each query for each condition? When you say skills are 5 and 7 - does that mean the results can have either or must have both? @vodkhang For all conditions. @OMG Ponies 5 Or 7 But you didn't try anything yet and want us to do something complex for you? It is not really complex but is it your homework or what sql did you try? @vodkhang trying doesn't matter in this query because performance proper query is very important for this web based application. And this is why i can't complate like homework ! SELECT projects.* FROM projects WHERE EXISTS ( SELECT * FROM projects_skills WHERE skill_id = 5 AND project_id = projects.project_id ) AND EXISTS ( SELECT * FROM projects_skills WHERE skill_id = 7 AND project_id = projects.project_id ) AND project_title LIKE '%php%' ORDER BY created or SELECT projects.* FROM projects WHERE EXISTS ( SELECT * FROM projects_skills WHERE skill_id IN (5 7) AND project_id = projects.project_id ) AND project_title LIKE '%php%' ORDER BY created Depending on what your intended result is.  It sounds like you're looking for an EXISTS query which verifies that matching rows exist in a table but without performing a JOIN. SELECT * FROM projects WHERE EXISTS (SELECT 1 FROM projects_skills AS ps WHERE ps.project_id = projects.project_id AND ps.skill_id IN (5 7)) AND project_title LIKE '%php%' ORDER BY created;",php sql mysql database2974009,A,"MySql syntax error; Deleting from two tables in one query possible? Is it not possible to perform two deletes in one query by separating them with a semicolon? Here is my query: $query=""DELETE FROM $sql_table WHERE EXISTS ( SELECT 1 FROM classified WHERE classified.poster_password = '$pass' AND classified.ad_id = '$id' AND classified.classified_id = $sql_table.classified_id ); DELETE FROM classified WHERE classified.poster_password = '$pass' AND classified.ad_id = '$id'""; This gives this error: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'DELETE FROM classified WHERE classified.poster_password = 'xxxxxxx' at line 10 Please help me solve this one it is starting to give me a headache. I need it in one query... Thanks `mysql_query()` can take only 1 query if it is what you're using. ""I need it in one query..."" - please elaborate. Can you use something like mysqli_multi_query() ? Why do you need it in one query? It makes absolutely no sense as it is not stored in a transaction and therefore the first query will be executed even if the second will fail. You didn't mention which PHP function you use to submit this to MySQL. MySQLi's multi_query can handle this.  you can build tmth like this DELETE t1t2 FROM t1t2t3 WHERE t1.id=t2.id AND t2.id=t3.id to clarify a bit more build the SELECT that will show the record you want to DELETE then switch the ""SELECT fields"" with ""DELETE table"" keeping FROM and everything after. Only records in the tables immediately following DELETE with be deleted. i was just giving a path to think) with such requests you can do all much easier & better;  Take a look at transactions Using MySQL Transactions BEGIN COMMIT",php sql mysql html database2972796,A,"Sql syntax error Here is my query: $query=""Delete b Where Exists ( Select 1 From a Where a.poster_password = '$pass' And a.ad_id = '$id' And a.classified_id = b.classified_id ) Delete a Where a.poster_password = '$pass' And a.ad_id = '$id'""; I get this error: ""You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'Where Exists ( Select 1 From a Where a.poster_p' at line 2"" If you need more input let me know... Whats wrong here? Thanks UDPATE: Just a Q: Do I need to specify also that a = ""this table"" and b = ""another table"" or does MySql get that by this code? As for the new code posted where to use FROM and a terminator semicolon wont work and give this error: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'Delete FROM a Where a.poster_password = 'xxxxxxxxxxxxxxxxxxxxx' at line 10 UPDATE2:  $query=""Delete FROM $sql_table Where Exists ( Select 1 From classified Where classified.poster_password = '$pass' And classified.ad_id = '$id' And classified.classified_id = $sql_table.classified_id ); Delete FROM classified Where classified.poster_password = '$pass' And classified.ad_id = '$id'""; And when I echo $query: (fordon is in this case $sql_table variable.) Delete FROM fordon Where Exists ( Select 1 From classified Where classified.poster_password = 'xxxxx' And classified.ad_id = 'motorbat_166250627' And classified.classified_id = fordon.classified_id ); Delete FROM classified Where classified.poster_password = 'xxxxx' And classified.ad_id = 'motorbat_166250627' Thanks again Did you try to remove the second query (`Delete a`) and only execute the first one? I think it was mysql version 5.1 btw... Peter: No I haven't You're not specifying the tables to delete from. Try: $query=""Delete FROM b Where Exists ( Select 1 From a Where a.poster_password = '$pass' And a.ad_id = '$id' And a.classified_id = b.classified_id ); Delete FROM a Where a.poster_password = '$pass' And a.ad_id = '$id'""; I've also added in a semicolon after the end of the first DELETE query. If you want to run both at the same time you'll need a separator to terminate the first query before you run the second version. Re. your question edit about MySQL ""getting"" the tables - if a and b are aliases here then no MySQL doesn't know what a and b are. You'll need to alias the tables or replace a and b with the actual table names. Check my update please this wont work either for some reason Okay changed the aliases but still get the same error in the update of my Q... hmm Can you post your exact query string now? yes check update again pls...  The two deletes need to be separate statements ( and executed separately ). MySQL supposts multi-table deletes: http://dev.mysql.com/doc/refman/5.0/en/delete.html. However the OP's syntax appears incorrect. There should be a `FROM` in there.",php sql mysql database126161,A,Where do the responsibilities of a Db Abstraction in PHP start and end? In PHP what is the best practice for laying out the responsibilities of a Db Abstraction Layer? Is OOP a good idea in terms of performance? How much should be generic object code and how much should be very specific functions? In most applications I have written there are generally two different types of data access. One is for transactional operations: retrieving specific objects from the datastore modifying them and saving them back. I've found a solid ORM to be the best solution here. Don't try writing your own (as interesting as it might be.) The other common type of data access is for reporting. ORMs aren't the best solution here which is why I usually go with a scheme that uses custom SQL queries. Plain ol' PDO works well here. You can create a special value object just for that report and have the PDO query fetch the values into the object. Reports need to be fast and building them using an ORM layer is usually just too slow and cumbersome.  There are already some great solutions for this. A DAL is not a simple thing especially since so many security concerns are involved. I would suggest checking out PDO and MySQLi. Even if you write a wrapper class for one of them the heavy lifting will be done for you in a robust and secure way.,php sql mysql database2094247,A,"user activity database structure I am working on a community website. I want to show the user's activity in 2 places in the website. The User ""A"" Profile. The Friends page of the user ""A"" friends. ""What are your friends doing?"" The tables for instance are: members members_gallery members_videos members_friends my problem is in the Sql structure. I've read this question ""User recent activities - PHP MySql"" The ""union"" idea is good but I have an alternative one. I am going to make a new table called members_activity The fields: id | user_id | photo | video | friend | p_id | v_id | f_id | datetime let's say that the user has just uploaded an image. id | user_id | photo | video | friend | p_id | v_id | f_id | datetime 1 | 15 | 1 | 0 | 0 | 1203 | 0 | 0 | NOW() advantages: When i make a SELECT QUERY i can easily know if it's a photo video or a friendship activity. The user can delete the 'photo activity' but keep the photo. Can notify friends of the user easily. disadvantages: Huge number of table rows? Any ideas or suggestions how the big websites deal with it? digg facebook etc. If you have a huge number of rows it is really not going to be a practical disadvantage as long as you index the table properly. At the very least I would index user_id and datetime assuming you will be selecting activity for a particular user and ordering by date. Use MySQL's EXPLAIN (<query>) to ensure your indexes are optimised for the queries you are running often. I have no idea about the INDEX functionality. Thanks i am going to search about that.  I don't see why you need the friends id. For the friends page you would first do a select for all his friends then select from activity table where user_id in (2689 etc) I would make photo and video fields a single field called type where photo and video would be values this way you can later on add more activity types I would make p_id and v_id a single column called item_id .. no need for 2 columns I would add an extra column called info where I would store other information in a json format. This is for the extra data that not all events have. For example you could have an event for adding a link to the profile ... and you could place the link there since other events don't have urls and adding a column just for this event type would be not a good solution the `f_id` is to say ""X has become friends with Y"". thanks for the other notes. well that info i see it in the extra column since there is only one event that needs this  I think you're correct that a single-table approach is best here. One disadvantage however is that it doesn't scale well--what if you want to add link or comment activity types? With this model you'd have to add another column for each of those. An approach that I've seen in Rails-land is to use a polymorphic model which would look like this: id | user_id | activity_type_id | p_id | v_id | f_id | datetime You can see that I've replaced video photo etc. with activity_type_id. Then there would be a second table called activity_types:  id | name ----+------- 1 | photo 2 | video 3 | ... Then when you create a members_activity record you can assign the appropriate activity_type_id and if you want to create new activity types later on it's relatively painless and you could SELECT a particular kind of activity with a simple JOIN e.g.: SELECT * FROM members_activity JOIN activity_types ON members_activity.activity_type_id = activity_types.id WHERE activity_types.name = 'photo'; that was good. but rather than making a new MySQL table called `activity_types` i'd just make an array. it's makes it easier and faster. Voted + Chosen as best answers. thanks. An array? You mean in PHP? Better to use MySQL's ENUM type in that case I think. http://dev.mysql.com/doc/refman/5.0/en/enum.html",php sql mysql database data-structures2789021,A,"Does this query fetch unnecessary information? Should I change the query? I have this classifieds website and I have about 7 tables in MySql where all data is stored. I have one main table called ""classifieds"". In the classifieds table there is a column called classified_id. This is not the PK or a key whatsoever. It is just a number which is used for me to JOIN table records together. Ex:  classifieds table: fordon table: id => 33 id => 12 classified_id => 10 classified_id => 10 ad_id => 'bmw_m3_92923' This above is linked together by the classified_id column. Now to the Q I use this method to fetch all records WHERE the column ad_id matches any of the values inside an array called in this case $ad_arr: SELECT mt.* fordon.* boende.* elektronik.* business.* hem_inredning.* hobby.* FROM classified mt LEFT JOIN fordon ON fordon.classified_id = mt.classified_id LEFT JOIN boende ON boende.classified_id = mt.classified_id LEFT JOIN elektronik ON elektronik.classified_id = mt.classified_id LEFT JOIN business ON business.classified_id = mt.classified_id LEFT JOIN hem_inredning ON hem_inredning.classified_id = mt.classified_id LEFT JOIN hobby ON hobby.classified_id = mt.classified_id WHERE mt.ad_id IN ('$ad_arr')""; Is this good or would this actually fetch unnecessary information? Check out this Q I posted couple of days ago. In the comments HLGEM is commenting that it is wrong etc etc. What do you think? http://stackoverflow.com/questions/2782275/another-rookie-question-how-to-implement-count-here Thanks you should have accepted HLGEM answer he was right both yesterday and today. Ad Hoc Queries These are queries that you write to run one time or on rare occasions. How large of a result data set must you return that it would take longer to do a SELECT * than type out the column names? How likely are you to forget a column add it and have to run it again? Your time is more expensive than CPU time. If you're running it once let the database do the work. SELECT * is fine for ad hoc queries if it will save you time. There are exceptions such as Blob fields on large data sets but you get the point. Production Queries These are queries that are stored in your application or database. These queries are run often. How many times do you have to run a query to make up for the time it would take to name your columns? It adds up fast. Name your columns in production queries to allow your application to scale better and perform at maximum efficiency. There are other minor advantages but they're not as exciting. Summary Add Hoc Queries : SELECT * generally okay. Production Queries: SELECT * always bad. It's okay to be a little lazy but be smart about it.  Strongly disagree with marr75. First becasue if you do this poor techinie in most of your queries you are adding unnecessary load to virtually every query. Database queries need to be written as well optimized s possible as it is is exceedingly painful to later go bnack and rewrite every query in your datbase becasue you used a known poor techinique. Refactoring in datbases is hard and performance must be considered in design it is not premature optimaization to use techiniqes that are known to improve performance from the start it is good design. Next you have the maintenance issue. If you are depending onthese columns being in a particular order and someone changes the structure of the databe you are out of liuck. Alos if someone adds a column that you don't want to show the user (Which is is common) you are out of luck. THis is a very bad techinique and select * should almost never be used ina production system. If someone adds a column it will be returned inthe query but you need to know what was added and why in order to make the interface do what it needs to do anyway so you have no maintenance savings by using this poor technique. +1 waste a fraction of a second oh well. waste a fraction of a second a million times every day oh *%$@! don't be lazy only return the columns you need!  You are surely returning unnecessary results to answer your question. It is a bad habit to get into. So how should it be written then? SELECT table_name.column_name? What if there are alot of columns it would be a loooong query then right? @Camran you pick: one long SELECT statement or an even longer result set multiplied by the number of rows. You can use abbreviated table names for aliases which would shorten the query a bit. Naturally the query will be longer by naming the columns but as programmers we shan't be lazy. And I don't know about mySQl but in SQL Server I can drag and drop the columns into my query so listing them doesn't take much time at all.  This is a matter of opinion. Are you having performance or scaling issues? If not then being specific about which columns to return is probably a matter of premature optimization. Duplication of integer join columns isn't going to break the bandwidth bank any time soon. Okay... No I don't have performance issues. The website is not uploaded yet... Thanks for the answer -1 Not remotely a matter of opinion or taste. By only selecting the columns you need you maximise the chance that a query can be satisfied from an index alone and reduce the overall query processing workload. I hope the site's a success Camran. Once you you start having problems serving up requests then you should look at typing out every column name. A web framework (Cake Django Rails etc) could make this easier too. Django for example let's you pick just the columns you need with ""defer"" and ""only"" methods then generates the sql for you. I think we'll have to agree to disagree on that Martin optimized performance becomes a problem to look at once your app hits a bottleneck and is actively being used. Also the first optimization of performance I would do if I found this query to be a bottleneck would be to cache the results or the resulting pages outperforming any index or column optimization pretty easily. So fire fighting when performance suddenly becomes a problem is better than a fairly easy way of doing it right in the first place? Depending on the requirements and constraints. My take on this particular problem was that a solo developer is about to deploy a web app in a domain that already has a lot of alternatives it's important to understand that he could have written this query to perform better but there's a big chance it won't get used much anyway and there's an even bigger chance that this query will not be any kind of performance bottleneck that can't be better solved by caching. If he has a choice between launching today and launching tomorrow based on optimizing these queries I'm an advocate for today. when you get good at developing and go the the next level with your SQL you will discover the covering index where you include data (additional columns) in the index that is not part of the index. The database can then use these columns and return the results without going back to the table from the index find. If you always select * you can not use a covering index because you are asking for all the columns. When you are tuning your slow queries (which are fast now because the app is not live and has no data) you will not be able to use this technique. I don't think it's fair to make any assumptions about whether I'm ""good"" at developing or not based on my answer. My answer says yes this query can be optimized but I feel he should profile first with a real load before optimizing anything. Profiling with a real load will be made more difficult as he is not returning the columns he needs. The Database Tuning Advisor and missing index DMVs won't have anything to work with. @marr75 - I understand your point but this is generally considered SQL 101 not advanced optimization. this question about `select tableA.* tableB.* ...` is right up there with questions about `why can't I just make all my columns varchar(5000)` some people will call it an opinion on how to do it other will call it ridiculous. Try to get either of those past a code review. I'd laugh at anyone trying to put that code in production.",php sql mysql html database2202845,A,SQL help query not returning all data I am building a website that remembers the users choices from a navigation menu and then shows content the next time they visit the webiste there last view content is available to this I am running this query SELECT * FROM (`categoryTable`) LEFT JOIN `userMenuTable` ON `userMenuTable`.`categoryId` = `categoryTable`.`categoryId` This returns in PHPmyAdmin all the relative results however when running in it through my website it returns the relative but it does not return the categoryId if the categoryyId does not exists in the UserMenutable. What I need is a way to what the user has saved and pull those results out and then find out what he hasnt saved and then do something else Is this possible? just a guess but if you are accessing the yourResultSetHere['categoryId'] you are getting the null from the it from userMenuTable and not the value from categoryTable. You should try changing SELECT * into: SELECT col1 col2 categoryTable.categoryId AS c_categoryId userMenuTable.categoryId AS u_categoryId  col3 ... and see if you get the value in c_categoryId,php sql mysql database2209502,A,MySQL headache should I or should I not? I have a classifieds website. I am using SOLR for indexing and storing data. Then I also have a MySQL db with some more information about the classified which I dont store or index. Now I have a pretty normalized db with 4 tables. Whenever ads are searched on the website SOLR does the searching and returns an array of ID_numbers which will then be used to query mysql. So solr returns id:s which are then used to get all ads from the mysql db with THOSE id:s. Now all the JOIN and relations between my tables gives me a headache. What except for maintanance-ease do I get for having a normalized db? I could you know store all info into one table with some 50 columns. So instead of this for finding one ad and displaying it: SELECT category_option.option_name option_values.value FROM classified category_option option_values WHERE classified.classified_id=?id AND classified.cat_id=category_options.cat_id AND option_values.option_id=category_options.option_id I could use this: SELECT * FROM table_name WHERE classified_id = $classified_id Isn't the last one actually faster? Or does a normalized db permform faster? Thanks The query using a JOIN is trivial as far as MySQL joins are concerned. I see no need to denormalize this. I would however suggest rewriting it to not be such a PITA to read: SELECT category_option.option_name option_values.value FROM classified JOIN category_option USING (cat_id) JOIN option_values USING (option_id) WHERE classified.classified_id = ?  Whenever you do denormalization you usually gain reading speed and lose write speed because you have to write the same value many times. Additionally extra care should be taken to maintain data integrity. How many times the query will be executed? Is this a high traffic application? Can you add a cache? What I meant suggesting to add a cache is to consider other alternatives of performance improvement. I have to add a cache yes but what does that have to do with normalization? Because the results are cached not the database am I right? It is pretty heavy traffic also and what do you mean how many times will the query be executed? Only once every time users click 'search' i guess... sorry But you have to explain a little more detailed  I would advise against denormalizing in your situation. You'll get better with joins as you use them more and they start to become clearer in your head and maintenance ease is a good benefit for the future. Here's a pretty good link about normalization (and denormalization). Here's a question about denormalization. One answer suggests creating a view using joins to get the data you need and using that like your SELECT * FROM table_name WHERE classified_id = $classified_id query. A normalized DB will likely be slower but it's unlikely you'll want to denormalize for that reason. I hope this provides some help.,php sql mysql database normalization2908884,A,Thoughts/Input about Database Design for a CMS I'm just about to expand the functionality of our own CMS but was thinking of restructuring the database to make it simpler to add/edit data types and values. Currently the CMS is quite flat - the CMS requires a field in the database for every type of stored value (manually created). The first option that comes to mind is simply a table which keeps the data types (ie: Address 1 Suburb Email Address etc) and another table which holds values for each of these data types. Just like how Wordpress keeps values in the 'options' table PHP serialize would be used to store an array of values. The second option is how Drupal works the CMS creates tables for every data type. Unlike Wordpress this can be a bit of an overkill but really useful for SQL queries when ordering and grouping by a particular value. What's everyone's thoughts? I'm talking about CMS through the whole question. The main question I'm asking is what's the best method of how the database should be structured? Wordpress Vs Drupal Method of structuring the database. Are you talking about a CMS (content management system) or a CRM (customer relationship management) product? It sounds like you are confusing the two. I think My Lively wants to know what you mean by CMS. See here http://en.wikipedia.org/wiki/CMS for the possibilities. In my opinion you should avoid serialization where possible. Your relational database should be relational and thus be structured as such. This would include the 'Drupal Method' e.g. one table per data type. This also keeps your database healthy in a sense that it can be indexed en easily queried upon. Very good point I have already adopted the process of creating tables on the fly for the different data types. This has produced a much better system.  Unless you plan to have lots of different data types that will be added in the future which are unknown now this is not really going to help you and would be overkill. If you have very wide tables and lots of holes in your data (i.e. lots of columns that seem to be NULL at random) then that is a pattern that is screaming to maybe have a seperate table for data that may only belong to certain entries. Keep it simple and logical. Don't abstract for the sake of abstraction. Indeed storing integers is cheaper with regards to storage space but unless that is a problem then don't do it in this case. Hi Lloyd after careful consideration with all of our clients the best approach was to create a new table for each data type (blog photo testimonial). We have a master table which keeps record of the structure and we create/amend tables on the fly based on this structure. We tested each scenario with 10 million rows in the database and speed is our biggest consideration. Selecting inserting updating and deleting table rows was much faster and efficient compared to a segmented database with a table full of keys and another table full of values. A good solution: clean separation simple and logical. Well done Dallas good work.,php sql mysql database content-management-system3286644,A,"Select from where field not equal to Mysql Php I'm just wondering what kind of mysql command i could execute in php that would select all items from a certain table where columna is not equal to x and columnb is not equal to x Something like: select something from table where columna does not equal x and columnb does not equal x Any ideas? The key is the sql query which you will set up as a string: $sqlquery = ""SELECT field1 field2 FROM table WHERE NOT columnA = 'x' AND NOT columbB = 'y'""; Note that there are a lot of ways to specify NOT. Another one that works just as well is: $sqlquery = ""SELECT field1 field2 FROM table WHERE columnA != 'x' AND columbB != 'y'""; Here is a full example of how to use it: $link = mysql_connect($dbHost$dbUser$dbPass) or die(""Unable to connect to database""); mysql_select_db(""$dbName"") or die(""Unable to select database $dbName""); $sqlquery = ""SELECT field1 field2 FROM table WHERE NOT columnA = 'x' AND NOT columbB = 'y'""; $result=mysql_query($sqlquery); while ($row = mysql_fetch_assoc($result) { //do stuff } You can do whatever you would like within the above while loop. Access each field of the table as an element of the $row array which means that $row['field1'] will give you the value for field1 on the current row and $row['field2'] will give you the value for field2. Note that if the column(s) could have NULL values those will not be found using either of the above syntaxes. You will need to add clauses to include NULL values: $sqlquery = ""SELECT field1 field2 FROM table WHERE (NOT columnA = 'x' OR columnA IS NULL) AND (NOT columbB = 'y' OR columnB IS NULL)""; Thanks great detail :) Glad to help. I started off with the block of code as an example...then I edited like 10 times as I kept saving only to think ""wait I could add one more thing to make it that much clearer"" neither of these seem to work if column's default value is `NULL` @SpYk3HH Good point. I'll address that.",php mysql sql database select1071060,A,"Single Autonumber Instead of Multiple Key Is there a reason to use a single incrementing field for a primary key instead of multiple fields that actually represent the unique record? I'm working on an existing php application and the tables all seem to have a single 'id' key instead of using the 2 or more fields that are actually unique to the record (like user auction bid). I'm not a database expert but that just seems lazy (or inexperienced) to me. Is there any benefit (performance or otherwise)? Updated: I'm not referring to psudo-unique data (ssn e-mail address etc) where you may want to ensure the data is really unique. I'm talking about tables with obvious foreign key references but instead of using those references along with the unique field(s) in the table itself every table just has an incrementing ID. Not trying to start up a subjective debate it just didn't make sense to me. Here are a few points to use autonumber Autonumbers are a single unique key that make foreign key relationships much easier to maintain and use Autonumbers are numbers so it is pretty easy to use them and not mess them up. What I mean is if your primary key is a string and your developer forgets to put that in single quotes it will destroy your performance It is normal standard practice to use an autonumber You can still make other fields ""unique"" resetting a sequence is much easier with an autonumber if you need to jump ahead in the sequence it is much easier with a number than a combo of attributes or strings Just a few things...  Almost every ""natural"" key combination I've ever tried to use in a database ended up being non-unique over time. Data models need to evolve quickly as abstractions become leaky. That includes names phone numbers SSNs legal document references page numbers email addresses usernames project numbers and a few other things I've tried to use over my career. Aside from that the other answers regarding performance for writing new records comparing foreign keys etc. are enough reason alone. You can preserve your current business logic of uniqueness without baking it into the primary key--just set up a unique index on your natural-key columns. You'll pay a price on inserts and updates as with any index but if it happens to also be a useful index (helps to cover some queries) all the better. So if the 'natural' key is replaced by a surrogate key say a username becomes a userid (unique generated number) why not use the userid (along with other immutable ids) as the keys for related tables? A PK by definition is unique. For argumentative purposes you have just created a PK every time that a Unique Constraint is built. Why not just break off the table and replace it with a view?  Yes this will spur debate. In general primary key data should be immutable which is frequently not the case when using a natural key derived from the table data. As noted earlier things like SSNs can often be changed thus throwing off immutability. Monotonically increasing surrogate keys like ""autonumber"" or ""identity"" columns are a simple substitute for a natural key. However they can be prone to index inefficiencies since they may not balance well across B-tree style index algorithms. This can be remedied by using a randomly generated surrogate key like a uniqueidentifier i.e. GUID in MS SQL Server but I've read that this also has performance ramifications. Generally I use a surrogate key produced from a sequential feature like autonumber or identity for ease of table joins.  Well the id's give a sequential ordering to your database from 1-infinity. User names and such are transient and aren't always ordered. So presumably it would make searching faster. Plus it seems like you're suggesting having multiple keys signify an item. That is generally going to slow things down because now two things have to be checked to make sure something is the right item instead of one.  It all comes down to how ""normal"" your data structure is. A highly normalized databaseby definition can only have single field for the primary key. In this case there is little to any reason to use a serial or auto generated number as a PK. The data structure should be designed with with unique entries as PK(tracking people is a problem there are only so many names). Of course with normalization comes the performance penalty so the database is de-normalized to make is usable(very common for web apps). With a heavily de-normalized DB many times it is impossible to get a PK without using every field in the table. Remember that the reason that the structure is de-normalized is to increase the performance. All of the databases that I am familiar with builds an index for every PK. The larger the index the larger the overhead to maintain the index. Building gigantic indexes will kill the insert and update time performance making the de-normalization useless(unless its a read-only DB). It also takes longer to search gigantic indices and uses more memory than smaller ones as well. In summery It is often advantageous for performance reasons to to auto-generate the PK for any table that requires multiple fields to get a unique PK.  Using synthetic primary keys has several advantages: You can change values in key fields without having to take an index update hit The indexes are smaller It makes foreign key relationships simpler Since you're not dealing with strings there are never encoding issues Databases often have specific optimizations around building indexes with monotonically incrementing keys. That being said there is nothing wrong with a little denormalization now and then. If the use-case is clear and the tables are relatively small do what's convenient. -1 ""there is nothing wrong with a little denormalization now and then""  Oh dear it looks like we're opening up the great natural vs. surrogate keys debate again. The simplest reason is to prevent data redundancy. Natural keys tend to require multiple keys that may change over the lifetime of the database. For example if a person gets married and changes their last name then that last name has to be updated everywhere it's referenced. This isn't a problem if you have your foreign keys set to on update cascade as the DB will do it for you. As your table nest further and further you may find your keys need more and more columns. I've actually seen a table that had a seven-column primary key. For a table that only had four other columns. On redundancy now the code is responsibly to check for duplicate data instead of the database stopping duplicate data. For example in the code that prompted this question before an auction offer can be submitted the code has to check the database for any offers of the same value from the same user for the same auction. Sure it should do that anyway but if the code fails the database won't stop it. In that case there's duplicate data. R. Bemrose wrote : This isn't a problem if you have your foreign keys set to on update cascade as the DB will do it for you. But all references to this record outsite your database are lost. If you have interfaces with other systems your in trouble. @Tim Lytle: There's nothing stopping you from having unique constraints.  You generally want a clustered index on your primary key. The issue with having a compound clustered primary key is that as you insert new rows SQL has to stick the new record in between other records which means shuffling. In addition the larger your primary key the more space is required to store it. Here is an article on using a GUID as a primary key but the same holds true for a compound key. Also see this great answer.  in most cases it's really not clear-cut when those fields really uniquely identify the entity represented by the record. again and again I've seen cases where old database concepts entrenched in the business mentality hamper any further evolution.  It depends on the definition of ""Unique"". Yes names email addresses and SSN values are supposed to be ""unique"". However stranger things have happened. Having a separate ID value in a lot of cases can make life a lot easier... Update Based on the edit to the question I don't really see much of a need. It sounds like the situation you have is something like. a ""join table"" something where you are simply creating an association of a UniqueId from one table to the UniqueId of another table. A simple example of what I'm thinking you are talking about would be a User -> Role association. You must associate a User to a Role. A UserId and a RoleId. You have in your database a structure similar to MappingId (Your Auto Number) (This is the PK) UserId (From the user table) RoleId (From the Role table) This structure does NOT make sense to me I would have just the User and RoleId make up the Primary Key since there is no need to duplicate entries here. If you have something different that might change things... Agreed. I typically opt for a sythetic primary key but then add an index with a uniqueness constraint to identify the natural key. That way I can change / delete the index if my initial assumptions during design no longer hold. SSNs will be reused over time. After all the number of people alive in the US is estimated to be 306808431 according to the US Census population clock... nearly 1/3 of the available space for SSNs. Updated the question to make it clearer not talking about questionably unique data. I mean a table with a userid auctionid etc but sill have a single auto incrementing primary key. Posted updated comments I wanted it to be more abstract guess that might have been less than helpful. Example: A 'bid' table has the auctionid the userid and the bid amount (along with other data about the bid). Why then do they use a bidid as the primary key? It's not just joining tables but it seems to me that you would want to use the other keys to *avoid* duplicate data. So a user can't bid the same amount more than once (sure the code should check that but shouldn't the database ensure that as well?",php sql database database-design695289,A,"Cannot simply use PostgreSQL table name (""relation does not exist"") I'm trying to run the following PHP script to do a simple database query: $db_host = ""localhost""; $db_name = ""showfinder""; $username = ""user""; $password = ""password""; $dbconn = pg_connect(""host=$db_host dbname=$db_name user=$username password=$password"") or die('Could not connect: ' . pg_last_error()); $query = 'SELECT * FROM sf_bands LIMIT 10'; $result = pg_query($query) or die('Query failed: ' . pg_last_error()); This produces the following error: Query failed: ERROR: relation ""sf_bands"" does not exist In all the examples I can find where someone gets an error stating the relation does not exist it's because they use uppercase letters in their table name. My table name does not have uppercase letters. Is there a way to query my table without including the database name i.e. showfinder.sf_bands? Are you sure that the sf_bands table exists? Does showfinder.sf_bands work? showfinder.sf_bands works perfectly Perhaps I should note that my database was migrated from MySQL Can you try pg_query($dbconn $query)? The implicit connection can cause hard-to-debug issues may as well eliminate it as a possible problem. Can you also try pg_dbname($dbconn) to make sure it's indeed connected to showfinder? Postgres process query different from other RDMS. Put schema name in double quote before your table name like this ""SCHEMA_NAME"".""SF_Bands"" What does your answer adds to the previously accepted answer upvoted 22 times and with lot of details?  From what I've read this error means that you're not referencing the table name correctly. One common reason is that the table is defined with a mixed-case spelling and you're trying to query it with all lower-case. In other words the following fails: CREATE TABLE ""SF_Bands"" ( ... ); SELECT * FROM sf_bands; -- ERROR! Use double-quotes to delimit identifiers so you can use the specific mixed-case spelling as the table is defined. SELECT * FROM ""SF_Bands""; Re your comment you can add a schema to the ""search_path"" so that when you reference a table name without qualifying its schema the query will match that table name by checked each schema in order. Just like PATH in the shell or include_path in PHP etc. You can check your current schema search path: SHOW search_path ""$user""public You can change your schema search path: SET search_path TO showfinderpublic; See also http://www.postgresql.org/docs/8.3/static/ddl-schemas.html Oops forgive me. I meant to say that my table name has no uppercase letters not my database name. That did it many thanks! Right on the money! +1 @romkyns: Yes this is actually pretty common across RDBMS brands that undelimited identifiers are advertised as ""case-insensitive."" But they're not truly case insensitive because the way they've implemented that is to force lowercase. This matches the name of the table only if you had allowed the table name to be lowercased when you defined the table. If you use double-quote delimiters when you CREATE TABLE you must use delimiters when you reference it in queries. It appears that even if you type `SELECT * FROM SF_Bands` this will still fail because Postgres decides to lowercase that table name for you. Weird...  If everything posted above fails try to put dbname parameter in your connection string. It works for me while everything else failed.  pg_query($dbconn $query); make sure the database connection is successful... this is a nonsense if the connection fail the code he posted would stop at `or die('Could not connect: ' . pg_last_error());`  I had problems with this and this is the story (sad but true) : If your table name is all lower case like : accounts you can use: select * from AcCounTs and it will work fine If your table name is all lower case like : accounts The following will fail: select * from ""AcCounTs"" If your table name is mixed case like : Accounts The following will fail: select * from accounts If your table name is mixed case like : Accounts The following will work OK: select * from ""Accounts"" I dont like remembering useless stuff like this but you have to ;) Same for column names in where-clauses 5. Mixed case like `Accounts` will fail with `select * from Accounts;` I find the weirdest part: same-case is NOT identical.",php sql database postgresql2576405,A,"Storing info in a PostgreSQl database issue Ok I am making a registry for my website. First page asks for some personal info  if($error==false) { $query = pg_query(""INSERT INTO chatterlogins(firstName lastName gender password ageMonth ageDay ageYear email createDate) VALUES('$firstNameSignup' '$lastNameSignup' '$genderSignup' md5('$passwordSignup') $monthSignup $daySignup $yearSignup '$emailSignup' now());""); $query = pg_query(""INSERT INTO chatterprofileinfo(email lastLogin) VALUES('$emailSignup' now());""); $userNameSet = $emailSignup; $_SESSION['$userNameSet'] = $userNameSet; header('Location: signup_step2.php'.$rdruri); } The first query works. The second query works but doesn't save the email... the session doesn't work but the header works and sends me to the next page I get no errors even if I comment out header next page  @session_start(); $conn = pg_connect(""host=localhost dbname=brittains_db user=brittains password=XXXX"" ); $signinCheck = false; $checkForm = """"; if(isset($_SESSION['$userName'])) { $userName = $_SESSION['$userName']; $signinCheck = true; $query = pg_query(""UPDATE chatterprofileinfo SET lastLogin='now()' WHERE email='$userName'""); } if(isset($_SESSION['$userNameSet'])) { $userName = $_SESSION['$userNameSet']; $signinCheck = true; $query = pg_query(""UPDATE chatterprofileinfo SET lastLogin='now()' WHERE email='$userName'""); } This is the top starting the session depending on if your logged in or not. then if I enter in the info here and put it through this if($error==false) { $query = pg_query(""UPDATE chatterprofileinfo SET aboutSelf='$aboutSelf' hobbies='$hobbies' music='$music' tv='$tv' sports='$sports' lastLogin='now()' WHERE email='$userName'"") or exit(pg_last_error()); //header('Location: signup_step3.php'.$rdruri); } nothing shows up for on my database from this. I have no idea where I went wrong the website is http://opentech.durhamcollege.ca/~intn2201/brittains/chatter/ For starters don't put things that aren't strings in single-quotes like that. 'now()' means a literal string ""now()"" Also if you're doing updates to your database you're better of using prepared statements to help prevent against sql injection. In your case see http://www.php.net/manual/en/function.pg-prepare.php kk thanks I should have known that duh moment >< Or go for pg_query_params() the easiest solution for safe input in a query. http://nl2.php.net/pg_query_params pg_prepare is good when you have repeating queries.",php sql database postgresql2219748,A,Why isn't this easy join working? (mysql) I have two tables classified and fordon. classified table: classified_id (PK) etc... fordon table: id (PK) classified_id (FK) I try to use this code: SELECT * FROM classified fordon WHERE classified.ad_id IN ('$solr_id_arr_imploded') AND classified.classified_id=fordon.classified_id BTW the array is a set of ad_id:s returned from solr never mind that that is not the problem here... Then I use mysql_fetch_array in a while-loop to display all the results: while($row = mysql_fetch_array($qry_result)){ but when I try to echo something which is inside the table fordon then the index can't be found error appears. But whatever is inside the table classified works to echo! Any ideas? Thanks UPDATE  while($row = mysql_fetch_array($qry_result)){ echo $row['type']; // This doesn't work because the 'type' column is inside the 'fordon' table echo $row['headline']; // This does work because it's inside 'classified' table. no I don't think it's the implode! What does your code look like when you `echo` the results? I meant the actual while loop. :) could I have the FK setup wrongly here? The FK is in the fordon table maybe it should be other way around? (does it matter) Try to change the query from `SELECT * FROM ...` to `SELECT fordon.type classified.headline FROM ...` just to see if your query is set up correctly. Let me know if that returns the results but I cannot tell if it has anything to do with where the foreign key resides. it give a 'unknown column 'year' in field list'... but the headline works! hmmmm I have to get to work now but I will have to try some more later... If you think of something please let me know... Thanks :) Might be the values that were *imploded* (which is what I am guessing those are) you don't think they are the problem? Does this help? SELECT * FROM classified c INNER JOIN fordon f ON c.classified_id=f.classified_id WHERE classified.ad_id IN ('$solr_id_arr_imploded'); Also its generally not a good idea to use: SELECT *. Its better to either select only the elements you want or use the * in context of the table you are getting all from e.g. SELECT classified.* FROM classified c INNER JOIN fordon f ON c.classified_id=f..classified_id WHERE classified.ad_id IN ('$solr_id_arr_imploded'); When you do joins with a blanket * you get every field in all tables. I believe that is what he wants to achieve. understood but what if you have classified.field_name and fordon.field_name. You now have an error because you are using SELECT *. Its generally good practice to just query specifically what you want esp when you start joining tables. But do how you like I am just suggesting ;),php sql mysql database2782275,A,"Another rookie question; How to implement Count() here? I have this query: SELECT mt.* fordon.* boende.* elektronik.* business.* hem_inredning.* hobby.* FROM classified mt LEFT JOIN fordon ON fordon.classified_id = mt.classified_id LEFT JOIN boende ON boende.classified_id = mt.classified_id LEFT JOIN elektronik ON elektronik.classified_id = mt.classified_id LEFT JOIN business ON business.classified_id = mt.classified_id LEFT JOIN hem_inredning ON hem_inredning.classified_id = mt.classified_id LEFT JOIN hobby ON hobby.classified_id = mt.classified_id ORDER BY modify_date DESC I need to implement a count here to just count all rows in combination with the JOINS you see. How should I do this? SELECT COUNT(mt.* fordon.* etc) FROM ? // This method wont work Thanks Shame on you for using select * in any query with a join. When you do this you are returning data you don't need (the joins fields are duplicated) and causing the server to do unnecessary work and sending more information over your network than is needed. If you do this on most queries you are causing performance problems for literally no reason other than laziness. Very poor practice. HLGEM for simplification it's common to use `SELECT *` in examples here. While the user should not use them in production code and it's great to remind the OP ""shame on you"" is jumping the gun. SELECT COUNT(*) FROM (SELECT mt.* fordon.* boende.* elektronik.* business.* hem_inredning.* hobby.* FROM classified mt LEFT JOIN fordon ON fordon.classified_id = mt.classified_id LEFT JOIN boende ON boende.classified_id = mt.classified_id LEFT JOIN elektronik ON elektronik.classified_id = mt.classified_id LEFT JOIN business ON business.classified_id = mt.classified_id LEFT JOIN hem_inredning ON hem_inredning.classified_id = mt.classified_id LEFT JOIN hobby ON hobby.classified_id = mt.classified_id) As A That is a bad idea! It would result in a huge temporary table from which you do not need any data.  I removed the ORDER BY as it is not required for the COUNT: SELECT count(*) FROM classified mt LEFT JOIN fordon ON fordon.classified_id = mt.classified_id LEFT JOIN boende ON boende.classified_id = mt.classified_id LEFT JOIN elektronik ON elektronik.classified_id = mt.classified_id LEFT JOIN business ON business.classified_id = mt.classified_id LEFT JOIN hem_inredning ON hem_inredning.classified_id = mt.classified_id LEFT JOIN hobby ON hobby.classified_id = mt.classified_id And lastly how do I retrieve the nr of rows? $res=mysql_query($query); Then what do I do? @Camran: it will return a table with a single row and a single column. please guys the title says ""rookie"". Give me the code... you can add an alias to the count results and access just like any other field in a query: SELECT Count(*) As NumberOfRecs FROM ....  How about SELECT COUNT(*) FROM ... ? I'm not sure what you're trying to count. I am trying to count nr of rows found... Need it for paging... Why are the answers so different? @Camran are you trying to count everything in those tables? Or just a certain table? If trying to count all SELECT COUNT(*) works No not all only rows which are JOINED check my Query Well `COUNT(*)` counts the combination of results between the joined tables. If you need it for paging you probably just need `SELECT COUNT(*) FROM mt` to get the count separately from the main JOIN query. I agree @Camran does not need to make JOINs for counting since all of them are left joins (assuming that there is not more than a single corresponding row in each joined table)  How about simply: SELECT COUNT(*) FROM ...",php sql mysql database3470988,A,"In MySQL need to join two tables with one table having multiple references to the second I have two tables one is signups and contained in it are two fields firstchoice and secondchoice. Another is a schedule table and it has things like a begin and end date and a semesterid. firstchoice and secondchoice from the signups table both reference the semesterid from the schedule table. I am trying to create a page which displays all of the registered people and the schedules they have registered for (the begin and end dates) and my current query: $query = ""SELECT * FROM signups INNER JOIN (schedule) ON signups.firstchoice=schedule.semesterid AND signups.secondchoice=schedule.semesterid""; is not returning any results from the schedule table. Is it possible to join two tables like this with two columns on one table referencing a single column on another? Just for kicks try this: SELECT * FROM signups a INNER JOIN (schedule) b ON a.firstchoice=b.semesterid OR a.secondchoice=b.semesterid I think you are looking for this: SELECT * FROM signups s INNER JOIN schedule sc1 ON s.firstchoice=sc1.semesterid INNER JOIN schedule sc2 ON s.secondchoice=sc2.semesterid If they don't always have a second choice you may want to do this: SELECT * FROM signups s INNER JOIN schedule sc1 ON s.firstchoice=sc1.semesterid LEFT OUTER JOIN schedule sc2 ON s.secondchoice=sc2.semesterid This did the trick",php sql mysql database join2410994,A,"MySql displaying results in same order no matter ""array-order"" I am using ""solr"" search engine to query an index for classifieds that match a given criteria. The results are the ID:numbers of the classifieds which I then use to find all matches in a MySql database with those ID:s. The ID:s returned are put into an array. As you can see below the array is imploded. Then I use the ""IN"" to find all matches. $solr_id_arr_imploded = implode(""' '"" $solr_id_arr); $query = ""SELECT mt.* $sql_tbl.* FROM classified mt LEFT JOIN $sql_tbl ON $sql_tbl.classified_id = mt.classified_id WHERE mt.ad_id IN ('$solr_id_arr_imploded')""; $sql_tbl is the category chosen by the user in this case lets say it is ""cars"". My problem is this: I have the ID:numbers in an order (inside the array) but MySql doens't ""care"" about this order. MySql displays the oldest item first no matter what order the array is in. So here is one same query displayed with two different ""array-directions"": SELECT mt.* fordon.* FROM classified mt LEFT JOIN fordon ON fordon.classified_id = mt.classified_id WHERE mt.ad_id IN ('Bmw_520i_Svensksald_784332731' 'Bmw_M3_Svensksald_755599519' 'Bmw_M3_E46_Full-utrustad_338210082') SELECT mt.* fordon.* FROM classified mt LEFT JOIN fordon ON fordon.classified_id = mt.classified_id WHERE mt.ad_id IN ('Bmw_M3_E46_Full-utrustad_338210082' 'Bmw_M3_Svensksald_755599519' 'Bmw_520i_Svensksald_784332731') As you can see the ID:s are reversed in the second query above... But they are still displayed in the same order anyways. Why? Should I use some other method of finding all MySql matches with ID:s from an array? Ideas? Thanks MySQL will return the data in the order it ""wants"" (I suppose it'll be the order of the clustered index or something like that) if you do not specify an order by clause. If you want to change the order in which MySQL returns the results you'll have to add an order by clause. If that's not possible in your case you'll have to re-order the elements from the PHP code -- for instance instead of displaying the results from what MySQL returns you should iterate over the list of ids returned by Solr and display the results starting from there. Basically you'll first execute the MySQL query to fetch the results : SELECT mt.* fordon.* FROM classified mt LEFT JOIN fordon ON fordon.classified_id = mt.classified_id WHERE mt.ad_id IN ( 'Bmw_520i_Svensksald_784332731' 'Bmw_M3_Svensksald_755599519' 'Bmw_M3_E46_Full-utrustad_338210082' ) Then you can loop over those results in PHP storing them in an associative array (pseudo-code) : $hash = array(); foreach ($db_results as $elem) { $hash[$elem->ad_id] = $elem; } $hash will contain the data indexed by id. And then you'll display the data using what Solr returned as a starting point for the loop (pseudo-code) : foreach ($solr_results as $id_solr) { echo $hash[$id_solr]->some_field . '<br />'; } With this you will : display the results in the order returned by Solr not do an additionnal (and possibily costly) sort on the database-side.  This should do it: SELECT mt.* $sql_tbl.* FROM classified mt LEFT JOIN $sql_tbl ON $sql_tbl.classified_id = mt.classified_id WHERE mt.ad_id IN ('$solr_id_arr_imploded') ORDER BY FIELD(mt.ad_id'$solr_id_arr_imploded') See Order By Field in Sorting Rows.",php sql mysql database arrays3764894,A,"Any way of ""multiplying"" MySql records to test a large db on server? I have several mysql tables in a database. Currently I am doing finishing test on my website and one is to test a heavy db to see how much this affects performance (searching). The website is a classifieds website. It would take a very long time for me to insert one classified at a time to reach a significant nr. So I wonder is there any way of multiplying records in MySql preferrably with phpMyAdmin? Lets say I already have 20 finished records and just multiply them several times and I get a large db in no time. Possible? You should know that my tables have foreign keys and other relations... If you need more input let me know... Thanks INSERT INTO mytable SELECT * FROM mytable There's no need to list the fields individually as you know the structure is going to be the same. The only potential problem would be any auto-incrementing identity field.  insert into mytable ( col1 col2 col3... ) select col1 col2 col3 from mytable",php sql mysql database search3006164,A,"Should I sanitize EVERY form variable passed along? I have a form with many fields... The action is set to a php page which queries mysql... Should I sanitize with mysql_real_escape_string every single variable? Or can I ignore sanitizing drop-lists and radios for instance? Also besides mysql_real_escape_string what else should I do to prevent attacks? Thanks Here is a derived table approach that can avoid SQL Injection http://beyondrelational.com/blogs/madhivanan/archive/2010/05/14/derived-table-new-approach-to-avoid-sql-injection.aspx incredible stupid approach So do you think the method is open to SQL Injection? Yes it is still open. I've not evaluated Method 1 but in Method 2 1=1 would pass and return unfiltered values from the SQL. If those were medical appointments joined to patient records and you were EXPECTING to pass in Patient_ID = nnnnn... but I called it with 1=1 that would be injection and Method 2 would fail - I'd get a complete list of every patient and their appointments. You set up a single case SQL Injection and built a function that stops that one case. Yes. That would anywany avoid updating the table Try with any DML or DDL statements  Another bunch of ignorant answers. Camran you're attracting it like magnet. You have to understand that mysql_real_escape_string has nothing to do with forms and radios with checking and sanitizing. And it does not prevent attacks. It is merely a string escaping function. It escapes a data that going to be inserted into SQL query string as a string data. SQL query is a little program. With it's own syntax. You must follow that syntax not because of ""attacks"" but because of it's just a syntax. And of course these rules do not depend on the source of data! Radio button html form or browser - all doesn't matter! And it works only with strings. Not with numbers nor identifiers. Here is my answer on how to handle an SQL query: http://stackoverflow.com/questions/2993027/in-php-when-submitting-strings-to-the-db-should-i-take-care-of-illegal-characters/2995163#2995163  You only have to sanitize the fields that you don't want an attacker to hijack. The data can be form any source not just your page. mysql_real_escape_string is good for any value that will concatenated into a query but I ""sanitize"" everything. To me ""sanitize"" means more than handling injection attacks it includes any field validation as well (sting length numeric valid date empty etc).  In general it is trivial to form a POST request outside of the browser and so bypass any restrictions the drop down list (for example) may have imposed on possible values. Because of this you should always treat user data as hostile and error-prone and put as much validation and protection on the server-side as possible.  You only need to use mysql_real_escape_string to escape strings prior to using them in SQL statements to prevent SQL Injection attacks. In addition when taking data out of your database and writing it out as HTML you should consider using htmlspecialchars or strip_tags to prevent cross-site scripting attacks. Better to use htmlspecialchars() I think. strip_tags is not always working as intended. neither htmlspecialchars nor mysql_real_escape_string work as a magic pill under all conditions please see http://stackoverflow.com/questions/110575/do-htmlspecialchars-and-mysql-real-escape-string-keep-my-php-code-safe-from-injec  Any variable sent from the client can't be consider as safe and valid. If you are using them in query you should always sanitize them. what about variables that weren't sent from the client?  You must check selects and radio buttons too. Anyone can create their own HTML form and post it to your script. The Firefox extension Web Developer Toolbar even has an option to convert selects to text inputs. You can also check that the posted data only contains correct values. For example if you have a radio button make sure that the posted form only contain one of the valid values. You should of course only run mysql_real_escape_string on variables that you are going to put into MySQL. If saving to file using on the commandline or anything other there are more apropriate functions and solutions. remember mysql_real_escape_string is only safe to use when the escaped value is delimited by single quotes in the resultant sql statement. Even better: forget about string escaping and just use bound sql parameters.",php sql mysql database security3024265,A,Expand my knowledge in DB programming my name is Tal Im working on a PHP Application the should have lots and lots of records what DB should I use and are there guides on the web that explains how to build efficient dbs and tables? Tnx! Don't select every row (*) just select what you need in a query. Always close connections. Use either prepared statements or escape inputted user information when inserting or updating. `(*)` refers to columns not rows. Closing (non persistent) connections is useless. sorry kemp you carn't always be right like I guess you are all the time.  This is a big topic merely selecting technology A or B is not enough. You have to consider the whole chain from the end user all the way up to the web server. Most DB's are close performance wise. How well you utilise each DB will have a direct and bigger impact than simply using one platform over another. A badly designed DB schema and poorly optimised query will perform badly in ANY db platform.  Get familiar with database normalization. It's a brilliant theory that will help you build stable and scalable databases. There is a good article on the subject at http://en.wikipedia.org/wiki/Database_normalization As to what database management system you should use I'd recommend that you start with MySQL. It's the world's most popular database software (it's what they use in WordPress phpBB and Drupal). It's fast reliable open source and there are plenty of learning materials about it. I got a kick out of the edit history for this answer. +1 I know :) Sometimes I lose control.  MySql is easy to use but probably not the most efficient b/c it is free. SQLite works well too if you need an embedded database in your app.  PHP is widely used with MySql. You can also use PHP with sqlite. sqlite is faster and embeddable but is not ideal for large dbs. As far as db efficiency is concerned check this out.,php sql database3333089,A,"I need some advice on storing data in mysql where one needs to store more than one let say userids for a single post? In cases when some one needs to store more than one value in a in a cell what approach is more desirable and advisable storing it with delimiters or glue and exploding it into an array later for processing in the server side language of choice for example. $returnedFromDB = ""159|160|161|162|163|164|165""; $myIdArray = explode(""|""$returnedFromDB); or as a JSON or PHP serialized array like this. :6:{i:0;i:1;i:1;i:2;i:2;i:3;i:3;i:4;i:4;i:5;i:5;i:6;} then later unserialize it into an array and work with it OR have a new row for every new entry like this postid 12 | showto 2 postid 12 | showto 3 postid 12 | showto 5 postid 12 | showto 6 postid 12 | showto 8 instead of postid 12 | showto ""2|3|4|6|8|5|"". OR postid 12 | showto "":6:{i:0;i:2;i:1;i:3;i:2;i:3;i:3;i:4;i:4;i:5;i:5;i:6;}"". Thanks looking forward to your opinions :D You should only serialize data in the DB if the data is never needed to be processed by the DB. For example you could serialize user ID in the user_id field if you never need to do a query with the user_id field; e.g. never selecting anything based on user. If these are posts (blog/news/etc. posts?) then I'm pretty confident you'll need to be able to query them by user. Normalizing the user into another table would serve you: CREATE TABLE posts (post_id ....); CREATE TABLE post_users (post_id user_id ...); You can then get the users in a different query or use group_concat: SELECT post_id GROUP_CONCAT(user_id) FROM posts JOIN post_users USING (post_id) GROUP BY post_id. When you need to show user name just join to the users table to get their name in the group concat.  From RDBMS point of view i would 'have a new row for every new entry' Thats called m:n relationship table. You can then query the data however you like. If you need postid 12 | showto "":6:{i:0;i:2;i:1;i:3;i:2;i:3;i:3;i:4;i:4;i:5;i:5;i:6;}"". you can do SELECT postid CONCAT(':'count(showto)':{i:'GROUP_CONCAT(showto SEPARATOR ';i:')';}') AS showto FROM tablename GROUP BY postid However if you only need the data in 1 form and not do any other kind of queries on that data then you may aswell store the string. Wow never thought of this syntax :D ""CONCAT(':'count(showto)':{i:'GROUP_CONCAT(showto SEPARATOR ';i:')';}')"" might help me alot :D Thanks. +1 for givin me a cool idea :P  Most of the time the recommendation is that many-to-many relationships (such as posts to users) should have a mapping table with 1 row for each post-user combination (in other words your ""new row for every new entry"" version). It's more optimal for things like join queries and lets you retrieve only the data you need.  In cases when some one needs to store more than one value in a in a cell what approach is more desirable and advisable storing it with delimiters or glue and exploding it into an array later for processing in the server side language of choice for example. Neither. Oh goodness neither! Edgar F. Codd is rolling in his grave right now. Storing delimited data in a text field is no better than storing it in a flat file. The data becomes unqueryable. Storing PHP serialized data in a text field is even worse because then only PHP can parse the data. You want a nice happy normalized database. The thing you're trying to describe is a many-to-many relationship. Each user can maintain one or more posts. Likewise each post can be maintained by one or more user. Right? Then something like this will work. CREATE TABLE users ( user_id INTEGER PRIMARY KEY ... ); CREATE TABLE posts ( post_id INTEGER PRIMARY KEY ... ); CREATE TABLE user_posts ( user_id INTEGER REFERENCES users(user_id) post_id INTEGER REFERENCES posts(post_id) UNIQUE KEY(user_id post_id) ); -- All posts made by user 22. SELECT posts.* FROM posts user_posts WHERE user_posts.user_id = 22 AND posts.post_id = user_posts.post_id -- All users that worked on post 47 SELECT users.* FROM users user_posts WHERE user_posts.post_id = 47 AND users.user_id = user_posts.user_id CREATE TABLE user_posts ( user_id INTEGER REFERENCES users(user_id) post_id INTEGER REFERENCES posts(post_id) UNIQUE KEY(user_id post_id) ); This part can you clearify this a bit more for me please the INTEGER REFERENCES and UNIQUE KEY is this like a forign key constraint or something?. or its some sort of table that relates the post id with the userid And well i guess im convinced that I should not be storing data as delimited stings and serializations @Akay The `REFERENCES` clauses create foreign keys yes. This makes sure that you can't insert nonsensical identifiers in the link table. `UNIQUE KEY(col1 col2)` establishes something called a ""compound key"" -- two columns kind of glued together. In this case the combination of the two columns is unique. You couldn't insert `VALUES(1 2) (1 2)` for example. The restriction is in place because it makes sense for the data model I described above. It might not make sense if you need to store additional data in the link table about the nature of the relationship. You should not be using LEFT OUTER JOINs here. If user dont have a post it does not caontain in n:m table anyway and INNER JOIN allows much better optimisation. @Imre sorry bad habit from using a broken database engine that didn't understand the word ""INNER"". I'm editing to use worse/better syntax. @Charles Thanks alot im sure this will help me quite a bit to normalize my database :D its sad tho MySQL documentation is a bit tough to get around things need so much clarification :( . @Akay thankfully that's what SO is for. If you can't figure it out yourself ask for more help in new questions. Good luck!",php sql database arrays1921270,A,"Updating SQL database using PHP I am trying to make a password retrieval system on my site and I am having problems updating the password reset field in my database. I have tried everything but nothing seems to work. This is my code so far: $passwordreset = md5(mt_rand()) . md5(mt_rand()) . md5(mt_rand()); $con = mysql_connect(""localhost""""XXX""""XXX""); if (!$con) { die('Could not connect: ' . mysql_error()); } mysql_select_db(""database"" $con); mysql_query(""UPDATE members SET passwordreset = $passwordreset WHERE id = $id""); When I try to insert the data I get the error: Error: Query was empty Any help would be appreciated Thanks. Are you sure the message comes from this particular query? How do you get the error? Are the two line breaks after $passwordreset intentional? Can you try removing them? They shouldn't be a problem. I have lots of long MySQL statements here with line breaks and php / MySQL have no problems with them.  I am not sure if you get an empty query error for this but you need ticks around the values: mysql_query(""UPDATE members SET passwordreset = '$passwordreset' WHERE id = '$id'"");  I guess the backticks around the names of the columns are missing try: mysql_query(""UPDATE members SET `passwordreset` = '$passwordreset' WHERE `id` = '$id'"");  Not sure it's the only problem but I'm guessing your passwordreset field is a string in the database -- to store a concatenation of several md5 which are strings it has to. So there should be quotes arround the value you put in this field in the SQL query : mysql_query(""UPDATE members SET passwordreset = '$passwordreset' WHERE id = $id""); And in a general case you should escape your string values with mysql_real_escape_string : mysql_query(""UPDATE members SET passwordreset = '"" . mysql_real_escape_string($passwordreset) . ""' WHERE id = $id""); It won't change anything here as there is no quote in a md5... But it's a good practice to always do it to never find yourself in a situation where it was necessary and you didn't do it. Thanks for your reply still doesn't work getting the same error",php sql database sql-update2270475,A,help with sql query with parentheses i have following code: SELECT * FROM table WHERE thread = $thread AND (user != $user1 OR user != $user2) i want the code to pick all rows that contains $thread BUT the user isn't $user1 or $user2. is my code correct? or should it be like: SELECT * FROM table WHERE thread = $thread (AND user != $user1 OR user != $user2) thanks in advance You could also use SELECT * FROM table WHERE thread = '$thread' AND user NOT IN ($user1 $user2) Don't know which executes faster but this is my preferred way because I like it's readability better.  Use this: SELECT * FROM table WHERE thread = $thread (AND user != $user1 AND user != $user2) Because you don't want if the user is either of user1 or user2 for this reason using 'AND' will be proper option here. Also if the $thread is not an integer field you need enclose it in quotes eg: WHERE thread = '$thread'  Use: SELECT t.* FROM TABLE t WHERE t.thread = mysql_real_escape_string($thread) AND t.user NOT IN (mysql_real_escape_string($user1) mysql_real_escape_string($user2)) Please use mysql_real_escape_string or risk SQL injection attacks. Mind that you don't need single quotes because of using `mysql_real_escape_string` i have already escaped them=) `mysql_escape_string` is deprecated but an alternative for PHP prior to 5.3: http://php.net/manual/en/function.mysql-escape-string.php @noname: Sorry just making sure.  SELECT * FROM table WHERE thread = $thread AND user != $user1 AND user != $user2 what if thread is a string? Just following the OP's lead. Avoiding SQL injection is important obviously.  I think you should also be using <> instead of != So: SELECT * FROM table WHERE thread = $thread AND user <> $user1 AND user <> $user2 <> and != both are same and understood by mysql `!=` is ANSI-92 and supported by MySQL at least 4.1+,php sql mysql database2523631,A,"SQL Select * from multiple tables Using PHP/PDO/MySQL is it possible to use a wildcard for the columns when a select is done on multiple tables and the returned array keys are fully qualified to avoid column name clash? example: SELECT * from table1 table2; gives: Array keys are 'table1.id' 'table2.id' 'table1.name' etc. I tried ""SELECT table1.*table2.* ..."" but the returned array keys were not fully qualified so columns with the same name clashed and were overwritten. So basically you are lazy? Too lazy to do your job correctly? beware of identically named coluns in different tables - you'll only get one instance. Yes. I did notice that if I knew the number of columns in each table I could retrieve values by the numeric index but thats not the case. Is there a specific reason you need to do this? It's usually a bad idea to use SELECT * from multiple tables anyway so I'm just trying to figure out the thought process behind you doing this before I give you an answer. Agreed. Unless you don't know the column names (and I bet you do) SELECT * is never a good idea: you're running two queries instead of one (one for the column names then your query) and you're most likely bringing back more data than you need. Might not notice a problem now but if some of those fields are BLOBs or have a lot of text you will. @Stephen I have several 'content' tables with unrelated columns and one 'metadata' table that holds similar data for the other tables. I query one content table with the metadata table (lets say one to one relationship) for all the content table columns. I wish could explain better but my database lingo is limited. @Tom Of course I know the column names. Just don't want to type them out! Yes you can. The easiest way is with pdo although there's at least a few other extensions which are capable of it. pdo Set the attribute on the PDO object not the PDOStatment. $PDO->setAttribute(PDO::ATTR_FETCH_TABLE_NAMES true); That's it. Then you get associative array keys like myTable.myColumn. It works if you fetch an object too so beware because you need to access the properties like $obj->{'myTable.myColumn'}; *The manual says that attribute is only supported by certain drivers. If the above doesn't work this might work instead. $pdoStatement->setFetchMode(PDO::FETCH_NUM); $pdoStatement->execute(); //build our associative array keys $qualifiedColumnNames = array(); for ($i = 0; $i < $pdoStatement->columnCount(); $i++) { $columnMeta = $pdoStatement->getColumnMeta($i); $qualifiedColumnNames[] = ""$columnMeta[table].$columnMeta[name]""; } //fetch results and combine with keys while ($row = $pdoStatement->fetch()) { $qualifiedRow = array_combine($qualifiedColumnNames $row); print_r($qualifiedRow); } Same basic pattern is used for other database extensions mysql $res = mysql_query($sql); //build our associative array keys $qualifiedColumnNames = array(); for ($i = 0; $i < mysql_num_fields($res); $i++) { $columnMeta = mysql_fetch_field($res $i); $qualifiedColumnNames[] = ""$columnMeta[table].$columnMeta[name]""; } //fetch results and combine with keys while ($row = mysql_fetch_row($res)) { $qualifiedRow = array_combine($qualifiedColumnNames $row); print_r($qualifiedRow); } mysqli $res = $mysqli->query($sql); //build our associative array keys $qualifiedColumnNames = array(); foreach ($res->fetch_fields() as $columnMeta) { $qualifiedColumnNames[] = ""{$columnMeta->table}.{$columnMeta->name}""; } //fetch results and combine with keys while ($row = $res->fetch_row()) { $qualifiedRow = array_combine($qualifiedColumnNames $row); print_r($qualifiedRow); } Dude that worked. Thanks. This is an awesome work around you saved my bacon.  Unfortunately no; there is no SQL syntax for ensuring that column names are unique. If you truly don't know the names of the columns and must use SELECT * your only real option would be to revert to some very ugly looking dynamic SQL that could inspect the structure of the tables and generate a query that would select them all explicitly with a table-name prefix. I don't know which RDBMS you're using but something like this should work on SQL Server: declare @columns table (idx int identity(11) tablename varchar(100) columnname varchar(100)) insert into @columns (tablename columnname) select tablename columnname from INFORMATION_SCHEMA.COLUMNS where tablename in ('table_1' 'table_2') declare @sql nvarchar(4000) declare @i int declare @cnt in declare @col varchar(100) declare @table varchar(100) select @i = 0 @cnt = max(idx) @sql = '' from @columns while @i < @cnt begin select @i = @i + 1 select @col = columnname @table = tablename from @columns where idx = @i if len(@sql) > 0 select @sql = @sql + ' ' select @sql = @sql + '[' + @table + '].[' + @col + '] as [' + @table + '_' + @col + ']' end select @sql = 'select ' + @sql + ' from table_1 table_2' exec sp_executesql @sql By the time I write that I could have written the sql queries by hand. Hang on... I could have done that instead of being here. Joking. I don't know which language/db/library but I do remember having to work with fully qualified column names and hating to type the full column name. Now I have the reverse problem. @zaf: I've essentially written it for you... Nice try but using MySQL. @zaf: Then adapt it. What you're looking for isn't strictly possible. I've provided you with something that will at least *accomplish* what you're looking for even if it's less than ideal.  Unfortunately PHP (particularly the MySQL PgSQL MSSQL extensions) will always have your columns overwrite in the case of overlap. I would recommend creating a View in your database and Alias your columns so that they are ""fully-qualified"". For example: (MySQL) CREATE VIEW viewTable1Table2 AS SELECT t1.field1 AS Table1Field1 t2.field1 AS Table2Field1 FROM Table1 t1 INNER JOIN Table2 t2 ON t1.id = t2.id; The syntax may not be perfect but you can get a general idea of what I am talking about. Didn't know about that but still the same problem.  you can do this: SELECT Table1.*Table2.xyz Table2.abc... From... where you get all columns from one table using ""*"" and then just the columns from the other table you need so there is no clash. You could also use column aliases where you ""rename"" a column: SELECT Table1.A AS T1_ATable2.A AS T2_A... From... your result set would be of columns T1_A and T2_A Firstly you are specifying the column names - we don't know the columns and what if xyz or abc are also in Table1?. Secondly as I said I've tried the wildcard. If we don't know the columns in the tables then its just a tad more difficult to rename them. how can you not know the columns? is this generated with dynamic SQL? if so dynamically build the select list. The tables involved are dynamic. I'm trying to avoid writing code that handles each 'type' of table. @zaf if you don't know the column names how do you know which ones you need/ which ones are being overwritten? @Tom And thats the puzzle. If the column name included the table name we would be ok.",php sql mysql database pdo2352170,A,"MySQL delete from 3 tables I have the following tables with these keys in my database: bookings session_id sessions session_id course_id courses course_id I want to create a query to delete all date relating to a single course (course_id). For example if I wanted delete course_id=10 I would want any sessions with course_id=10 to be deleted in addition any bookings associated with any of these sessions need to be deleted too. Is this possible? what is the best way to approach it? (I'm writing this in PHP.) Any help much appreciated! does the sessions table reference itself with the session_id key? I think the best way would be to configure the tables adding proper foreign keys (you'll have to use InnoDB for this to actually work in mysql) and setting the behavior of the FKs to 'ON DELETE CASCADE'. This way when you delete something from the courses table the related bookings and sessions will be deleted automatically. Some linksies: MySQL DELETE with possible gotchas about this. Foreign Keys examples  MySQL supports multi-table deletes: DELETE FROM BOOKINGS USING BOOKINGS JOIN SESSIONS JOIN COURSES WHERE BOOKINGS.session_id = SESSIONS.session_id AND SESSIONS.course_id = COURSES.course_id AND COURSES.course_id = ? Another alternative would be to use stored procedure and process the deletions in proper order: BOOKINGS DELETE FROM BOOKINGS WHERE EXISTS(SELECT NULL FROM SESSIONS s WHERE s.session_id = session_id AND s.course_id = ?) SESSIONS DELETE FROM SESSIONS WHERE EXISTS(SELECT NULL FROM COURSES c WHERE c.course_id = course_id AND c.course_id = ?) COURSES DELETE FROM COURSES WHERE course_id = ? Hi Guys Thanks ever so much for all your help - think I've got it working how I wanted now!.. does my proposed solution have any drawbacks apart from depending on using the InnoDB engine? Also it's _id for the keys. @Adriano Varoli Piazza: `DELETE ON CASCADE` isn't a recommended practice because someone else wouldn't necessarily know it is in place & end up wiping out data they shouldn't have. While it seems like more work being explicit about what is being done is the best approach. Hi There Thanks for the response I am attempting to use the first multi delete method: DELETE FROM bookings sessions courses USING bookings JOIN sessions JOIN courses WHERE bookings.session_id=sessions.session_id AND sessions.course_id=courses.course_id AND courses.course_id=""13"" This doesn't seem to be working - is my syntax correct? -Thanks! If you don't use transactions *don't use a sequence of related actions*. @bart: Yes which is why I mentioned ""stored procedure"". @Fred: What error are you getting? Dealing with this via comments isn't the most ideal way. I'm getting the following: #1064 - You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'FROM bookings sessions courses USING bookings JOIN sessions JOIN courses WHERE' at line 1 Sorry I agree not sure where else to post this other than comments? @Fred: Remove the `FROM` I'll update my answer. Hi Thanks again for the help... I'm now using: 'DELETE bookings sessions courses USING bookings JOIN sessions JOIN courses WHERE bookings.session_id=sessions.session_id AND sessions.course_id=courses.course_id AND courses.course_id=""10""' But still getting the following: '#1064 - You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'USING bookings JOIN sessions JOIN courses WHERE bookings.session_id=sessions.ses' at line 1' ? @OMG Ponies I don't get exactly who would not necessarily know about the behavior: if it's the end user he's as likely to be unable to read the code. If it's the programmer he could study the db schema before twiddling random bits shouldn't he? Also backups are delicious. @Adriano Varoli Piazza: People don't all share the same skill sets and centralization of configuration is a principle every app strives for. Just because you haven't heard of a best practice doesn't mean others don't share it. You could ask the question on SO. @Adriano Varoli Piazza: Any shop where there's more than one person able to make changes to the database. It's the same rationale why triggers aren't liked - there's now multiple places to check for configuration to know why something happened because something was done ""auto-magically"". I agree co-workers should be diligent but they aren't all as familiar with the technology as you are. @Fred perhaps you have to use the alternative syntax? DELETE bookings sessions courses FROM bookings INNER JOIN sessions ON bookings.session_id = session.session_id INNER JOIN courses ON sessions.course_id = courses.course_id WHERE courses.course_id = '10' @Fred: Missed your comment update answer. @OMG Ponies that argument sounds very shallow to me: ""We might hire crappy coders so we can't do things the proper (to me at least) way. Let's enforce the way through code"". This is not 'hiding' or 'automagic'. This is stated clearly in the DB schema which one should learn before coding their way into a paperbag. To sum up: I hadn't ever heard that CASCADEs were not recommended practice before. Could you cite?",php sql mysql database3263371,A,"SQL FOREIGN KEY USAGE ? what does it really do ? and when it was needed? ok im makeing a simple database for my example there is users data and the user company's data . CREATE TABLE `users` ( `UID` INT(25) NOT NULL AUTO_INCREMENT  `username` VARCHAR(60) NOT NULL  `password` VARCHAR(100) NOT NULL  `ownername` VARCHAR(150) NOT NULL  `userstatus` TINYINT(1) NOT NULL  `userregistertime` DATETIME NOT NULL  `userlastonline` DATETIME NOT NULL  PRIMARY KEY (`UID`)  INDEX `username` (`username` ASC) ) ENGINE = InnoDB DEFAULT CHARACTER SET = utf8; CREATE TABLE `company` ( `CID` INT(25) NOT NULL AUTO_INCREMENT  `UID` INT(25) NOT NULL  `companyname` VARCHAR(60) NOT NULL  `companyaddress` VARCHAR(255) NOT NULL  `companyemail` VARCHAR(255) NULL DEFAULT NULL  `companyphone` VARCHAR(20) NOT NULL  `companyimage` VARCHAR(255) NULL DEFAULT NULL  `companyyahoo` VARCHAR(255) NULL DEFAULT NULL  `companytwitter` VARCHAR(255) NULL DEFAULT NULL  `companykaskus` VARCHAR(255) NULL DEFAULT NULL  `companyfacebook` VARCHAR(255) NULL DEFAULT NULL  `companytype` TINYINT(1) NOT NULL DEFAULT '0'  `companystatus` TEXT NULL DEFAULT NULL  `companytemplate` TEXT NULL DEFAULT NULL  `companyintroduction` TEXT NULL DEFAULT NULL  `partnership` TINYINT(1) NOT NULL DEFAULT '0'  PRIMARY KEY (`CID`)  INDEX `ownername` (`UID` ASC)  INDEX `companyname` (`companyname` ASC)  CONSTRAINT `ownernamecompany` FOREIGN KEY (`UID` ) REFERENCES `users` (`UID` ) ON DELETE CASCADE ON UPDATE CASCADE) ENGINE = InnoDB DEFAULT CHARACTER SET = utf8; 1.why after i insert data to the users table ( uid is auto increment ) it doesnt update my company UID table ? if you have php knowledge please see how im inserting it. $RegisterInsert1 = $dbConnect->prepare(""INSERT INTO users ( `username` `password` `ownername` `userregistertime` `userlastonline`) VALUES ( :username :password :ownername :userregistertime :userlastonline)""); $RegisterInsert1->execute($RegisterData1); as you see i get UID = 1 ( auto ) then usernamepaswordownernameetc inserted on user table. but somehow my company UID is not updated. it should be UID = 1 then the rest CID ( auto ) companyname null etc null. 2.am i right defining a foreign key usage for? 3.please give me the best example of inserting users data + company data with the right usage from the right usage of foreign. how im doing it right now // INSERT USERS DB $RegisterInsert1 = $dbConnect->prepare(""INSERT INTO users ( `username` `password` `ownername` `userregistertime` `userlastonline`) VALUES ( :username :password :ownername :userregistertime :userlastonline)""); $RegisterInsert1->execute($RegisterData1); // GET USERS GIVEN AUTO GENERATED UID // QUESTION ? THIS one should be automated by foreign useage ? $GetUid = $dbConnect->prepare(""SELECT UID FROM users WHERE username = :username""); $GetUid->execute($RegisterData3); $UserID = $GetUid->fetch(); $RegisterData2['UID'] = $UserID; // INSERT COMPANY INFO + UID $RegisterInsert2 = $dbConnect->prepare(""INSERT INTO company ( `UID``companyphone``partnership`) VALUES ( :UID :companyphone :partnership)""); $RegisterInsert2->execute($RegisterData2); U will get more appreciate ans .. if u write only that code which is related to question drct... what im trying to do is updateing the UID.company from UID.users when im inserting data olny to users table. UID.users are auto incr and it should be copyied to UID.company when its incr. so i dont have to use // GET USERS GIVEN AUTO GENERATED UID . hope you understand. thanks mate. why after i insert data to the users table ( uid is auto increment ) it doesnt update my company UID table ? SQL does not support multiple assignment you need to do this procedurally. You need to use (at least) one INSERT statement per table. INSERT INTO users which auto-generates the UID value(s); Capture auto-generated value(s) for UID; INSERT INTO users supplying the captured UID value(s). FWIW SQL Server 2008 makes this easy with an OUTPUT keyword i.e. the auto-generated values can be captured (to a staging temp table) within the INSERT statement. In MS Access you could create a VIEW with a JOIN between the two tables then INSERT INTO the VIEW and the auto-generate value would appear automatically in both tables (only worked for a two-table VIEW). I don't know if mySQL has similar features. yup no INSERT CASCADE. just UPDATE CASCADE :| . ive just notice it .  The foreign key in your schema definition is the UID column in the Company table. This refers to a single row in the Users table. You can ensure that an invalid UID is never inserted into the Company table by adding a foreign key constraint... ALTER TABLE COMPANY ADD FOREIGN KEY COMPANY_USER_FK (UID) REFERENCES USER(UID); and this will cause attempts to add a UID into the Company name that don't exist in the User table to fail. You can add extra features so that deleting a User from the User table deletes all the matching rows in the Company table as follows... ALTER TABLE COMPANY ...etc... REFERENCES USER(UID) ON DELETE CASCADE; or you can prevent users from being deleted if rows for them exist in the company table by... ALTER TABLE COMPANY ...etc... REFERENCES USER(UID) ON DELETE RESTRICT; Although it doesn't apply to your schema you could also cascade changes to the UID in the Users table by... ALTER TABLE COMPANY ...etc... REFERENCES USER(UID) ON UPDATE CASCADE; Note that all of this only works on MySQL if the storage engine is INNODB; ALTER TABLE COMPANY ...etc... REFERENCES USER(UID) ON UPDATE CASCADE; this one. why it doent update? my company table is still empty when im inserting the users data. ooooooooooooooooooooooooo i see there is no INSERT CASCADE. akakakak . stupid me .",php sql mysql database database-design964200,A,Problem writing this query in mysql (marking read messages in a forum) Hey. i am writing a forum and i have this table that marks messages a specific user read: `read_messages`(`message_id``user_id`) a simplified version of the messages table: `messages`(`id``forum_id``author_id`) now i want to be able when retrieving the message data from the database for a given forum to add a variable that will tell me if the current user has read that message or not. i know how to do this with 2 queries (1st i retrieve all messages then i check for each of them if the user has read them) but no clue as to how to join them together. any ideas? It sounds like you're after an Outer Join check out the Outer Joins Section for the syntax which allows you to select all values from one table and NULLS where the values don't exist.  SELECT messages.* read_messages.id as read_id FROM messages LEFT OUTER JOIN read_messages ON ( messages.id = read_messages.message_id AND read_messages.user_id = [ USER ID ] ) If read_id is returned as a number > 0 rather than NULL then the message has been read because there is a corresponding record in read_messages for that user.,php sql mysql database2334656,A,"LEFT JOIN or REGULAR JOIN and how to compare MySql table to an array? Need performance! I have six tables: t1 t2 t3 t4 t5 t6. And I also have one main table: main_table. TOTAL 7 TABLES! Now I am using SOLR for the searching of classifieds and the results from solr are put into an array. The array results are ID:nrs which I use to match agains the same ID:s in MySql. The first column of ALL tables in MySql is called classified_id. If the user searches for ""cars"" then Solr will find all cars classifieds put the id:s into an array and finally compare the MySql main table to match everything in table t1 (which is the cars table) where classified_id is the same in both tables. The SOLR results array is first imploded then: SELECT * FROM classified t1 WHERE classified.ad_id IN ('$solr_id_arr_imploded') AND classified.classified_id=t1.classified_id My Q is is this how I should do this? Is this how I should JOIN here or use a LEFT JOIN? Is there any faster way of comparing to the array? the table t1 may be empty if there are no car-classifieds... Remember the query could become very very long for example if SOLR returns 10000 matches then an array of 10000 id numbers which look like this would be returned: bmw_m3_low_miles_8948939 Thanks Will the results of the search be paged? That is if the SOLR search returns those 10000 matches do you need to fetch them all at once or just (e.g.) 50 at a time? Hi. The results are paged with MySql LIMIT. Not Solr. However if you know of how to do this in Solr maybe this is how to go then? An alternative to IN is to create a temporary table fill it with the IDs and perform an inner join on that. Make sure the other tables have an index on classified_id. To compare the options use EXPLAIN.",php sql mysql html database1801997,A,"PHP: display entries from Database in groups of five? Is it possible and if so how can I do it to select all entries in a table in my database and then display five results at the time in one group. Meaning: A example is that I've 15 records total in my database then I want to present my data like this: <div class=""1-5"">Record[1] Record[2] Record[3] Record[4] Record[5]</div> <div class=""6-10"">Record[6] Record[7] Record[8] Record[9] Record[10]</div> <div class=""11-15"">Record[11] Record[12] Record[13] Record[14] Record[15]</div> I'm not completely sure if I can do it with an SQL statement or I've to write some sort of ""do...while"" or loop to retrieve each set of data. I've also thought about something with arrays but haven't got up with a result. Thanks Mestika I find array_chunk() to be pretty useful for this kind of thing. // pull all the records into an array $query = mysql_query('SELECT * FROM mytable'); $rows = array(); while ($row = mysql_fetch_array($query)) { $rows[] = $row; } // this turns an array into an array of arrays where each sub-array is // 5 entries from the original $groups = array_chunk($rows 5); // process each group one after the other $start = 1; foreach ($groups as $group) { $end = $start + 4; // $group is a group of 5 rows. process as required $content = implode(' ' $group); echo <<<END <div class=""$start-$end"">$content</div> END; $start += 5; } You can of course do this without reading them all in first but if you're going to read them all anyway it doesn't make much difference and the above version will probably be far more readable than implementing the appropriate break condition(s) as you read the rows from the DB.  Dunno if i understand the question right but if u want to group all the result in groups of 5:  $i =1; while ($row = mysql_fetch_array($query)) { echo $row['name'].""\n""; if ($i % 5 == 0) { echo 'hr'; // Or any other separator you want } $i++; } This answer pretty nice and shortcut solution... thanks buddy",php sql database loops while-loop890529,A,Returning multiple rows per row (in Zend Framework) I have a MySQL database containing these tables: sessions -------- sessionid (INT) [courseid (INT)] [locationid (INT)] [comment (TEXT)] dates ----- dateid (INT) sessionid (INT) date (DATE) courses ------- ... locations --------- ... Each session has a unique sessionid and each date has a unique dateid. But dates don't necessarily have a unique sessionid as a session can span over a variable number of dates (not necessarily consecutive). Selecting each full row is simply a matter of joining the tables on the sessionid. However I'm looking for a way to return a rowset for a particular courseid where each row in that rowset represents a location and contains another rowset each containing single session which in turn contains another rowset which contains all of the dates for that session: course location sesssion date date session date date date location ... This is because I'm using querying this database from PHP using Zend Framework which has a great interface for manipulating rows and rowsets in an object-oriented manner. Ultimately I'm trying to output a 'schedule' to the view organized first by course then location then date. Ideally I'd be able iterate over each row as a location and then for each location iterate over each session and then for each session iterate over each date. I'm thinking of doing this by querying for all the locations sessions and dates separately. Then I'd convert each rowset into an array and add each sessions array as a member of a locations array and add each dates array as a member of a sessions array. This however feels very kludgy and doesn't provide me with the ability to handle the rows in an object-oriented manner. I was wondering if there was either: a) a better table schema for representing this data; b) an sql query which i'm not aware of; c) a method in Zend_Db that allows me to assign a rowset to a rowset Please let me know if I haven't been clear anywhere and thanks in advance. (Crossing my fingers that this doesn't end up on the daily wtf...) You could handle this scenario using the relationship features of Zend_ Db_ Table. You'd need to create table wrapper classes for sessions dates courses etc. if you're using Zend_ Db_ Aadpter for your queries currently. http://framework.zend.com/manual/en/zend.db.table.relationships.html It's not too different from the approach you described of querying for each dataset separately but it gives you a straight forward OO interface for retrieving the appropriate related data for a given record. You'll want to do some benchmarking if you go this route as it could potentially execute a lot of queries.  I've run into lots of issues with using Zend Frameworks database abstraction classes when I have to deal with data from multiple tables. The number of queries that run and the overhead of all of the objects generated has brought my hosting server to it's knees. I've since reverted back to writing queries to gather all of my data and then walking the data to build my display. It's not a pretty or OO as using the abstraction layers but it's also not making my PHP scripts page to disk just to display a table full of data. As Steve mentions benchmark whatever solution you end up with I'd also profile your memory usage. +1 I agree and I contributed quite a bit to the Zend Framework DB classes. The issues apply to any ORM; it's not just Zend Framework. Very true this is an ORM problem and not specific to Zend Framework.,php sql mysql database zend-framework1105886,A,"MySQL joins how to output relation ""the proper way"" First of all excuse my poor topic title. I simply have no idea how to formulate this question or what to Google after so don't shoot me if this is something easy answerable. Assume I have the following tables: [AUTHORS] id name [NEWS] id item author_id If I wanted to display a news item and output the corresponding author (stored in author_id) I'd do the following query: SELECT * FROM `news` JOIN `authors` ON news.author_id = authors.id And then outputting it by doing something like this $Q = ""SELECT * FROM news JOIN authors ON news.author_id=news.id""; $query = $this->lite->query($Q) or die($this->lite->error); $result=null; while($obj = $query->fetch_object()){ $result.= '<li>'.$obj->item. 'by ' . $obj->name . '</li>'; } Here $obj->name would contain the name of the author and would successfully output. So what happens if the ""name"" field were called ""item"" instead? There would obviously be some conflicts. With my previous experience in Propel & symfony I would do something like this: getAuthorId()->getName() - but for this project I'm required to write SQL from scratch. Can you give more details about your class? Does it's fetching all params in object? You would need to use a qualified name like news.item or authors.item.  Never use * syntax in production code. Rewrite your query as this: SELECT news.item AS news_item author.name AS author_name FROM `news` JOIN `authors` ON news.author_id = authors.id  aliasing your fields as necessary to avoid naming conflicts. Many thanks! This did the trick. This is not production code of course :-)  You name them explicitly SELECT n.id n.item n.author_ida.namea.id FROM `news` as n JOIN `authors` as a ON n.author_id = n.id ; Or perhaps more like SELECT n.id as newsid n.item as newsitem n.author_id as autohor_authorid a.name as authornamea.id as authorid FROM `news` as n JOIN `authors` as a ON n.author_id = n.id; You should only pull out the columns you actually need. It's considered bad style to do select *  always name the columns you're interested in or it's easy to break code if e.g. another column is added to the table.",php sql database join database-relations2755967,A,"Adjusting sql statement in a function based upon input Hey there This is a bit urgent! I'm trying to make a simple filter search where-by you can choose from a series of 3 drop downs and then based upon this the results are then displayed How would I go about adjusting the sql query for each and if you were to only choose to search from aone of the 3 rather than all 3 etc... example there could be the url with input such as: url.com?location=gb&color=3&hair=4 and still form the correct sql query for something like this: url.com?location=gb&hair=1 and not encounter problems with WHERE and AND etc etc and empty variables in the statement Would this not need to be a massive function to check using if to see how the data is set for all possibilities? Thanks Stefan I answered a question the other day that I think is pretty similar to yours: PHP: prepared statement IF statement help needed The idea is that you use conditional logic in your code to collect terms as needed corresponding to your application inputs. Then you join them together in such a way that produces the right SQL expression. It does need some application function to build the SQL expression dynamically and there are techniques to make it as concise as possible. If you really have many possible search terms you might end up with a lengthy function. But guess what? If you have complex inputs it should be no surprise that you need complex code to deal with them. Re your comment: url.com?location=gb&color=3&hair=4 Okay you have up to three inputs and you have to dynamically build up an SQL query from these. Let's start from the end and work backwards. Ultimately you want an SQL expression like this: WHERE (location = 'gb') AND (color = 3) AND (hair = 4) If you have an array of three terms you can join them together in PHP using the implode() function. But you may also have fewer than three. You can handle any number of terms by putting however many terms you have into an array and imploding them with AND between each term: $where_array = array( ""(location = 'gb')"" ""(color = 3)"" ""(hair = 4)"" ); $where_expr = ""WHERE "" . implode("" AND "" $where_array); So how do you create the array with these terms? By writing code to append to the array conditionally for each input that is present in your app's current request: $where_array = array(); if (array_key_exists(""location"" $_GET)) { $location = mysql_real_escape_string($_GET[""location""]); $where_array[] = ""(location = '$location')""; } if (array_key_exists(""color"" $_GET)) { $color = mysql_real_escape_string($_GET[""color""]); $where_array[] = ""(color = '$color')""; } if (array_key_exists(""hair"" $_GET)) { $hair = mysql_real_escape_string($_GET[""hair""]); $where_array[] = ""(hair = '$hair')""; } After all that's done your array has between zero and three elements. If it has one or more you want to generate a WHERE clause as shown previously otherwise skip it. $where_expr = ''; if ($where_array) { $where_expr = ""WHERE "" . implode("" AND "" $where_array); } Then append the $where_expr to your baseline SQL query. $sql .= $where_expr The stuff about $params is for query parameters which is an alternative method of including dynamic values into an SQL expression instead of mysql_real_escape_string(). It's not mandatory (and in fact PHP's old mysql extension doesn't support query parameters) but I recommend switching to PDO so you can use this feature. See example here: PDO::prepare(). I must be tired... Hmmm i dont understand the param sections I'm still relatively new. and where() implode etc...my db class doesnt handle much more than connecting and making basic calls such as return row and query. Could you elaborate a little more please? Don't try to learn new coding techniques when you're too tired to concentrate. You're better off sleeping and coming back to it when you're fresh. It all makes sense after having a nights sleep! thank you for your more thorough explanation! :)  Here is my go at it: // discard empty values and unwanted keys $get = array_intersect_key(array_filter($_GET 'strlen') array_flip(array('location' 'color' 'hair'))); foreach ($get as $key => $value) { $get[$key] = $key . ' = ' . mysql_real_escape_string($value); } $sql .= ((count($get) == 0) ? null : ' WHERE ') . implode(' AND ' $get); I haven't tested it but it should work well. This also looks like a good method even less code but I accepted the answer above due to its in depth explanation Yes +1 but I used the more verbose code to show each step more clearly. Also it makes it easy to use a different subexpression for each input.",php sql database search2797360,A,"DB Cursor fetching in Web Applications I never understood this: in web development whe[n|re] does it make sense to fetch results one by one? I mean why should I use PDOStatement->fetch*() when I can use PDOStatement->fetchAll()? http://stackoverflow.com/questions/2770630/pdofetchall-vs-pdofetch-in-a-loop fetchAll() will fetch all the results into one big array. With very large result sets it could exceed the PHP script's memory limit. A pure fetch() will fetch each record one by one neutralizing that danger. That's the only reason not to use fetchAll() I can think of. Sure but we usually don't emit SQL statements like `SELECT * FROM oneMillionRowsTable` without a limit clause at least I've never seen a query like that in web applications. @Alix neither have I but it is not entirely unthinkable to happen. I prefer the `fetch` variant out of a general sense of ""My PHP script's memory is more limited than that of the mySQL server"". It could be though that `fetchAll` is faster because it talks to the server only once - I don't know I've never measured it. Thanks Pekka. =)",php sql mysql pdo database2362063,A,MySql 'Select' help I have some tables. These tables all have one column in common called 'classified_id':  main_table: cars_table: id (PK) => 4222 id (PK) => 1021 classified_id => 25 classified_id => 25 Now I want whenever a search is performed to compare if any of the main_table.classified_id matches any of the cars_table.classified_id (in this case). the cars_table may return no matches! the classified_id in every table is the only relation. I would never need to compare the cars_table.classified_id to main_table.classified_id but the other way around is what I need (main_table.classified_id=cars_table.classified_id). I don't know what type of Join to use... Any help? Left Join? Thanks Please state more clearly what you are trying to do. Do you want to get only rows from main_table that are also in cars_table? Or do you want to get all rows from main_table and get some additional info that the row is also in cars_table? no only rows that match in both tables on classified_id SELECT * FROM main_table LEFT JOIN cars_table ON main_table.classified_id = cars_table.classified_id Will return 1-?? copies of main_table rows depending on how many in cars_table that matches. If there is no match all values from cars_table will be NULL  I'm not quite sure what you're asking but assuming you're looking for all the records in main_table that match some condition and you'd like to bring along any records in the cars_table that have the same classified_id as any of the matching records in the main table even if there are no such records in the cars_table you should be using left join like so:  SELECT * FROM main_table AS M LEFT JOIN cars_table as C ON C.classified_id = M.classified_id WHERE f(M.foo) When there is an M record such that f(M.foo) evaluates to TRUE but no corresponding C record the M record will still appear in the result set but all the C fields will be NULL. A more thorough explanation of left outer joins (same thing as a left join) can be found here: http://en.wikipedia.org/wiki/Left_outer_join#Sample_tables You'll need to look at the sample data to make sense of the example they give for left outer join: http://en.wikipedia.org/wiki/Left_outer_join#Sample_tables  Yes it is a left join Something like SELECT * FROM main_table mt LEFT JOIN cars_table ct ON mt.classified_id = ct.classified_id Okay a short follow-up Q What would happen if I was to switch places of the variables around the 'equal' mark in your code so it would be 'ON ct.classified_id=mt.classified_id'? Would it matter? No that would not matter it is the LEFT JOIN and the tables that matter. pesar it won't mater because equality is a symmetric relation: http://en.wikipedia.org/wiki/Symmetric_relation,php sql mysql database2467146,A,"Left Join 3 Tables and Show True or False on Empty Cells Ok this may be confusing so I hope I explain it correctly. I have 4 tables: business photos video category I want to display ""featured"" businesses on the home page (or elsewhere) and I want to show a Yes or No in the table row based upon whether or not there are photos or videos for that business. Example: Joes Crab Shack has no videos or photos but is featured. So when his row is echoed out it will show the Business Name and Business Owner but there will be no data in the photo or video cells thus in the video and photos column it will say No. Otherwise if the opposite was true it would say Yes. Here's my pastebin I'm thinking perhaps it might be better to have separate functions since on the individual business pages I will be listing photos and videos anyway. Maybe I'm making this harder then it needs to be? Since I will need to have functions that query for videos photos and specials anyway would it be possible to while the initial table is being displayed to check the db for the presence of these items? In other words when the row for Joes is being echoed a function runs to check for photos etc? But how would it know to check for Joes and not Bobs? SELECT b.busname  b.busowner  b.webaddress  IF (EXISTS (SELECT 1 FROM photos p WHERE p.busid = b.id) 'Yes' 'No') has_photo  IF (EXISTS (SELECT 1 FROM video v WHERE v.busid = b.id) 'Yes' 'No') has_video FROM business b WHERE b.featured = 1  Ok here is what I was able to do to solve the problem based upon suggestions from you guys: Model: function frontPageList() { $this->db->select('b.busname b.busowner b.webaddress p.photoname v.title'); $this->db->from ('business AS b'); $this->db->where('featured' '1'); $this->db->join('photos AS p' 'p.busid = b.id' 'left'); $this->db->join('video AS v' 'v.busid = b.id' 'left'); return $this->db->get(); } Control: function index() { $this->load->model('Business_model'); $data['featured'] = $this->Business_model->frontPageList(); $data['user_id'] = $this->tank_auth->get_user_id(); $data['username'] = $this->tank_auth->get_username(); $data['page_title'] = 'Welcome To Jerome - Largest Ghost Town in America'; $data['page'] = 'welcome_message'; // pass the actual view to use as a parameter $this->load->view('container'$data); } View: <table id=""businessTable""> <thead><tr><th>Business Name</th><th>Business Owner</th><th>Web</th><th>Photos</th><th>Videos</th></tr></thead> <?php foreach ($featured->result() as $row): ?> <tr> <td><?=$row->busname?></td> <td><?=$row->busowner?></td> <td><a href=""<?=$row->webaddress?>"">Visit Site</a></td> <td> <?php if(isset($row->photoname)):?> no <?php else:?> yes <?php endif?> </td> <td> <?php if(isset($row->title)):?> no <?php else:?> yes <?php endif?> </td> </tr> <?php endforeach; ?> </table>  You can cheat a little with something like this: SELECT b.[other stuff] (SELECT COUNT(1) FROM photos WHERE busid = b.id) AS photo_count (SELECT COUNT(1) FROM videos WHERE busid = b.id) AS video_count FROM business AS b [etc] photo_count & video_count will return 0 or greater than 0 - easy enough to get no/yes from in PHP. That would also stop the duplicate results you'd get from having more than 1 photo/video per business. Caveat!: converting that to the ORM you're using... I'm not sure an ORM would be okay with it. But if it's not barking over the ""AS"" aliasing in from() & join() maybe you can sneak the subqueries in select() without any problems. Would it make more sense to have a separate function that checks for photos or videos based upon the b.id? You mean in a PHP function? That might be cleaner but I doubt it would have a positive effect - one query is speedier than the same split into 3 if only because it's calling out to the DB once. ok just wondered. i'm having an issue with doing the select counts using activerecord. i wondered if maybe i was trying to do too much.  I'm going to take a stab at this. What I would do is when generating the table for display of ""featured"" businesses I would make a call to your database the one generally made when generating the photos and videos categories and check the output. If there is something there then have it say yes if the return from the database is null it's a safe assumption there aren't any photos or videos and thus you can print out a No. Your suggestion worked I posted an answer to the problem below but since it was your suggestion I'll give you the credit. @ Jason Shultz - Thanks.  I'm going to assume here that your photos and videos tables contain more than 1 record per business a ""one to many"" relationship. In this case you're going to need to rethink your approach or at least do some formatting of your database results. Currently if Joes crab shack has more than 1 videos and/or photos you're going to have multiple results for Joes crab shack. If you need photos/videos results you could format the results as you are receiving them now to create a multi dimensional array/object where $featured['videos'] or $featured['photos] would contain the results of your join if your formatted array doesn't contain the 'videos' key then you have no video results. If all you need to know is if it's returning more than 0 rows then create two new methods in your model to count videos and photos that belong to a specific business. Now it's just a matter of echo'ing 'Yes' if the methods return more than 0 rows or 'No' otherwise. Edit: Model function should look something like this function frontPageList() { $this->db->select('b.busname b.busowner b.webaddress'); $this->db->select('(SELECT COUNT(1) FROM photos WHERE busid = b.id) AS photo_count' FALSE); $this->db->select('(SELECT COUNT(1) FROM videos WHERE busid = b.id) AS video_count' FALSE); $this->db->from ('business AS b'); $this->db->where('featured' '1'); return $this->db->get(); } The query you have now is fine for displaying the business info you just need to format the results into a multi dimensional array before outputting it to your view. You're likely going to need a count function in your model at some point in your project you can create those now and use them or use the suggested nested query from tadamson. I'll edit my answer with an example of how to use the nested query with CI's Active Record Eventually what I want to do is have an individual business page where all the photos and videos will be listed. but on the list of buisnesses page I just want to show if they have things like photos or videos or specials/coupons. Would I be better off having separate functions one for showing the business info and then separate functions checking for photos and videos and specials and either showing yes or no in the list and showing the actual results on the business page?  Im assuming that the tables are set up sort of like this: Business Info Photos Videos ? You would create a unique ID for each business (autoincrement works nicely) and whenever a photo or video is uploaded for the business that record would be inserted into the respective tables with that ID attached to it (the ID column or whatever). Each table would allow multiple entries for the business (""one to many"" as Dyllon noted). So whenever you are displaying the featured business you would run a query against both the video and photo tables using the unique ID and look for returned rows. Rows = yes !rows = no. One question: Are you going to store the images in the db or file names and have them uploaded to a directory? The only other input that I would add to the above recommendations is to structure your tables so that there are never any null values in the tables themselves which may be the case seeing as you have four tables for this project already. I second the multi dimensional array/object method of storing and sorting through the returned data. A nice touch would be to use the PHP image functions to resize the first image returned as a thumbnail for the photos - you could also catch a frame for each video as well - so instead of yes or no we would seem thumbnails for both or a 'no images/video' slug. Not much but my $.02.",php sql database codeigniter1081851,A,"MYSQL: Query to get previous and next video ID? I am developing a video website (PHP - MYSQL) just like youtube in which I want to provide the functionality of Next video and Previous video. Let's say I am currently on videoId: 234 so Next and Previous video links will point to videoId: 233 and 235 respecively. My table structure is as follows: videoId videoName videoURL IsActive ----------------------------------------------------- 1 Love world love-world 1 2 Hello world hellow-world 1 3 World news world-news 0 4 The web the-web 1 5 Google web google-web 1 6 Internet internet 1 IsActive a bool (01) type column is basically tells that video is viewable on website or not. If its 0 - notviewable and 1 - viewable Now there are two type of situations which I though are: When I am browsing through videoId: 4 then I want to run a query to get the the next and previous video id means 2 and 5 respectively 3 is not because it is disabled. Other condition would be When I am browsing through videoId: 1 then query should return only one record which is 2 because there is no previous record same in the case of last record. Please tell me how to make query for this? Thanks MAking a bunch of assumptions here but Consider what will happen if: A user views the ""Hello World"" video An admin(or who ever) marks ""The Web"" as inactive. that user clicks next. best query string : SELECT (SELECT MAX(`id`) FROM `table` WHERE `id` < `t`.`id`) as `_prev_id` (SELECT MIN(`id`) FROM `table` WHERE `id` > `t`.`id`) as `_next_id` FROM `table` `t` WHERE `t`.`id` = '1' LIMIT 1  I'd use  SELECT * FROM videos WHERE videoId > :id AND IsActive = 1 LIMIT 1 UNION SELECT * FROM videos WHERE videoId < :id AND IsActive = 1 LIMIT 1  Try this. Completely untested but this will give you a normal row with two additional columns 'nextID' and 'prevID'. If one of them is null then there isn't one. SELECT v.* n.id AS nextID p.id AS prevID FROM vedios v LEFT JOIN (SELECT vn.id FROM vedios vn WHERE vn.id > v.id AND isActive = 1 ORDER BY id ASC LIMIT 1) n LEFT JOIN (SELECT vp.id FROM vedios vp WHERE vp.id < v.id AND isActive = 1 ORDER BY id DESC LIMIT 1) p If you have any issues / errors with it let me know and I'll test it properly.  This will get the next one $stmt = $PDO->prepare(""SELECT * FROM vedios WHERE vedio > :id AND IsActive = 1"") $stmt->execute(array(""id"" => $id)); $all = $stmt->fetchAll(PDO::FETCH_ASSOC); And change > to < for previous. If count($all) return 0 then you don't have a next/previous video. Ok but is it possible to fetch both next and previous in two rows using a single query?  I think you could use something like: SELECT * FROM videos AS c WHERE (VideoId = (SELECT MAX(VideoId) FROM videos WHERE VideoId < c.VideoId AND IsActive = 1) OR VideoId = (SELECT MIN(VideoId) FROM videos WHERE VideoId > c.VideoId AND IsActive = 1))",php sql database mysql3221721,A,Database migration through php I have a mysql database that I am trying to migrate into another database. THey have different schema's and I have written a php script for each table of the old database in order to populate its data in to the new one. The script works just fine but the problem is that it does not move all the data. for example if I have a table and all its info are being selected and then inserted into the new table but only half of them are done. The way I am doing it I am opening a database selecting * and puting it in an associative array. then I close the db connection and connect to the other one go through each element of the array and insert them in the new one. Is there a limit to how big an array could be? what is wrong here? How much data are there in these tables? 10 rows with 20 bytes per row; or more like 10M rows with 1KB per row? 1000000 rows with 0.5 KB per row * 20 tables You may be running into PHP's execution time or memory limits. Make sure the appropriate settings in php.ini are high enough to allow the script to finish executing. can you tell me what are the things I need to look for in there? @Shahin Kian: max_execution_time and max_memory are the two prime suspects. tnx I will do that with what 81403 suggested and i think it should work.  Why not do this via sql scripts? If you prefer to do it via php then you could open connections to both databases and insert to target as you read from source. That way you can avoid using too much memory. I had problem connecting to 2 databases at a time! plus how would I go about reading everything but 1 at a time? (selecting * from table 1 at a time?) you add parameter `LIMIT xy` to your query X being the first row to read and Y the number of row to read. Instead of a static X you use a PHP variable that increments itself in a `while` or `for` loop  Using php to do the transform/convert logic is a possibility. I would do it if you are doing complex transformations and if your php skills are much better thant your mysql skillset. If you need more memory in your php script use: memory_limit = 2048M max_execution_time = 3600 This will give you 2gigs of possible space for the array and about an hour for processing. But if your database is really this big it would much (really a lot) much faster to use: 1. mysqldump to make a dump of your source-server Check it here: http://dev.mysql.com/doc/refman/5.1/en/mysqldump.html 2. Upload the dumpfile and iport it. There are a bunch of example on the mysql documentation page. (Look also in the comments). After this you can transform your database through CREATE/SELECT-statements. CREATE TABLE one SELECT * FROM two; As an alternative you can use UPDATE-statements. What is best depends heavily on the kind of job that you are doing. Good luck!  First of all I don't see the point in writing a script to do this. Why don't you just get a SQL dump from phpMyAdmin and edit it so that it fits the other database? Or are they that different? But to reply on your question: my first thought would be like other people already said that the problem would be the time limit. Before you try to do something about this you should check the value of max_execution_time in php.ini (this is about 30 seconds most of the time) and how long it takes for the script to execute. If it terminates after roughly 30 seconds (or the value of max_execution_time if it's different) then it's likely that that's the problem although php should throw an error (or at least a warning). I don't think there's a limit on the size of an array in php. However there is a directive in php.ini namely memory_limit that defines the amount of memory a script can use. If you are have acces to your php.ini file I suggest setting both max_execution_time and memory_limit to a higher value. If you don't have acces to php.ini you won't be able to change the memory_limit directive. You will have to work your way around this for example by using LIMIT in your SQL. Be sure to unset your used variables or you could run in to the same problem.  It would be preferable to do a mysql dump at the command line: mysqldump -a -u USER_NAME -p SOURCE_DATABASE_NAME > DATA.mysql You can also gzip the file to make it smaller for transfer to another server: gzip DATA.mysql After transfer unzip the file: gunzip -f DATA.mysql.gz And import it: mysql -u USER_NAME -p TARGET_DATABASE_NAME < DATA.sql  You should read the rows from the first database in chunks (of 1000 rows for example) write those rows to the second database clean the array (with unset() or an empty array) and repeat the process until you read all the rows. This overcomes the memory limitations. Another problem might be that the script is running for too long (if the table is too large) so try using the function set_time_limit(). This function resets the timeout for a script after which it should be terminated. I suggest calling it after processing each chunk. thank you I will let you know how it works thanks alot it helped out alot!  You may have constraints in the target database that are rejecting some of your attempted inserts. +1 because this is what really happens without any dramatic error messages. Check your FKs. And remember there are no FKs on a MyIsam table....  Your server (as all server do) will have a memory limit for PHP - if you use more than the assigned limit then the script will fail. Is it possible to just Dump the current MySQL Database into text files perform find-and-replaces or RegExp-based replacements to change the schemas within the text files and then reload the amended test files into MySQL to complete the change? If this is a one-off migration then it may be a better way to do it. that seems like a hassle but thanks for the info,php sql mysql database relational-database3931575,A,Sync large local DB with server DB (MySQL) I need to weekly sync a large (3GB+ / 40+ tables) local MySQL database to a server database. The two databases are exactly the same. The local DB is constantly updated and every week or so the server DB need to be updated with the local data. You can call it 'mirrored DB' or 'master/master' but I'm not sure if this is correct. Right now the DB only exist locally. So: 1) First I need to copy the DB from local to server. With PHPMyAdmin export/import is impossible because of the DB size and PHPMyAdmin limits. Exporting the DB to a gzipped file and uploading it through FTP probably will break in the middle of the transfer because of connection to the server problems or because of the server file size limit. Exporting each table separately will be a pain and the size of each table will also be very big. So what is the better solution for this? 2) After the local DB us fully uploaded to the server I need to weekly update the server DB. What the better way to doing it? I never worked with this kind of scenario I don't know the different ways for achieving this and I'm not precisely strong with SQL so please explain yourself as good as possible. Thank you very much. This article should get you started. Basically get Maatkit and use the sync tools in there to perform a master-master-synchronization:  mk-table-sync --synctomaster h=serverNameD=databaseNamet=tableName  You can use a DataComparer for mysql. Customize the template synchronization which specify the data which tables to synchronize. Schedule a weekly update on the template. I have 2 servers daily synchronized with dbForge Data Comparer via command line.,php sql mysql database1746007,A,How does Doctrine handle changes to the database schema? In brief what happens when you add a column to a table? What happens when you remove one? In more details suppose you have the following: class User extends Doctrine_Record { public function setTableDefinition() { $this->hasColumn('username' 'string' 255); $this->hasColumn('password' 'string' 255); } } What happens when you add the following line to the setTableDefinition function? $this->hasColumn('firstname' 'string' 255); What happens when you delete the following line from the setTableDefinition function? $this->hasColumn('password' 'string' 255); You'd want to have a look at Doctrine migrations that allows you to The Doctrine migration package allows you to easily update your production databases through a nice programmatic interface. The changes are done in a way so that your database is versioned and you can walk backwards and forwards through the database versions. That will allow you to perform changes to your database without screwing up your data. Just what I was looking for. Thank you.,php sql database schema doctrine3539529,A,"Tips on writing SQL for multiple databases Different databases have differences in SQL support & implementation. Sometimes there is a difference in SQL syntax sometimes support for some SQL commands is missing sometimes the database has a feature that other databases do not have. What are considered to be good practices in writing SQL queries that are good for different databases (MySQL PostgreSQL Oracle MSSQL SQLite) taking in account that the developer uses a framework (like CakePHP Codeigniter Zend etc.) that provides a database abstraction layer? What SQL syntax should the developer try to avoid? Sometimes ORMs do not handle the query correctly. F.ex. `FULL JOIN` in MySQL `RIGHT JOIN` in SQLite. I mean the syntax of the query is good but the database does not support that. That's what ORMs are there for. As quantumSoup alluded to just don't. If you take a look at each of the frameworks you listed you'll notice that they all use ORM or some kind of database abstraction layer for inserting/extracting data. This allows you to write db-neutral code that works irrespective to the desired data source. The ORM then uses the correct data source ""drivers"" to convert your intentions into commands understood by each data source. So the trick is 1.) defining a universal interface for your ORM or database abstraction layer; and then 2.) writing the appropriate drivers for the ORM. Then each time you want to use a new type of data source (including flat files or CSV) it's a simple matter of adding a new driver. Sometimes I can create queries with syntax that is not supported by currently used database. F.ex. `FULL JOIN` in MySQL. I was able to create the query that passed through DB abstraction layer and that was looking okay. But the current database did not support that syntax.  ""Cautiously use ANSI SQL"" is the most direct answer to your question. However keep in mind these words from Jeremy Zawodny especially: Good engineers try to select the best tools for the job and then do everything they can to take advantage of their tool's unique and most powerful features. In the database world that means specific hints indexing data types and even table structure decisions. If you truly limit yourself to the subset of features that is common across all major RDBMSes you're doing yourself and your clients a huge disservice. What people are really looking for with ORM is a non-relational data store that can be easily transformed into programming language data structures (e.g. Ruby objects). If you need this you might want to examine one of the many ""NoSQL"" options out there (MongoDB CouchDB are two of the more mature ones). In practice you are probably better off to pick a particular DBMS and then freely use any proprietary features that strike your fancy. Of course this isn't always possible like if you're trying to write a package to be sold to people whose DBMS choices you can't control (or you don't want to limit your market).  You can use an ORM for example which will essentially abstract away the details from each database. Although you have to make sure your ORM supports all the databases needed. Doctrine and Propel are good friends of php. Check either out. If you cannot find an ORM that supports all your DB's then perhaps find one that covers most and extend php to handle the last. Although I doubt this will be the case.  Then you dig into using ORM you'll find that for complex queries - it doesn't perform. It's hard enough for people to write SQL that performs well - I don't expect a DB abstraction layer fair any better. Most ORMs support native stored procedures... which defeats the purpose of using ORM. ANSI SQL is striving to make SQL more portable amongst databases but adoption varies from vendor to vendor. And ANSI syntax doesn't necessarily mean it performs as well as native syntax (IE: COALESCE vs native ISNULL/IFNULL/NVL/etc). The reality is for getting the best performing database interaction you need to write custom code for each vendor involved. Some would use this as a point to why the database should be nothing more than basic persistence because it's easier to maintain a central application. But this pales when you deal with high usage applications who suffer because of multiple trips between the application and the database poor data typing and table design. Frankly it's a waste of a database... I completely agree. An abstraction layer will only ensure that your application runs equally slow on all DBMS  You are looking for Object-relational mapping (ORM). Object-relational mapping (ORM O/RM and O/R mapping) in computer software is a programming technique for converting data between incompatible type systems in object-oriented programming languages. This creates in effect a ""virtual object database"" that can be used from within the programming language. You can go for famous Doctrine out there. Also have a look at: Getting Started with ORM in PHP I thought ORM is implemented in those frameworks.",php sql database frameworks3595976,A,"Backup MySql database with PHP I have a pretty large db in MySql and I need to take backups of it every day or so. I need to be able to take backups from any computer so therefore I thought about making a php script to do this and put this php script online (offcourse with password protection and authorization etc so that only I can access it). I wonder however how is this done properly? What commands should I use and is it possible to change settings of the backup (for instance Add AUTO_INCREMENT value = true)? I would appreciate examples... Also if this is a bad method (unsafe or maybe gives bad backups with bad sql files) what other method would be preferred? I have shell-access and I have a VPS (ubuntu server). My Mysql version is 5.1 Thanks There's no need to involve PHP in the database backup. You just need a script that uses mysqldump to backup the database and setup a CRON job to periodically execute the script: mysqldump db_name > backup-file.sql ...will backup your database to a file by redirecting the output from the mysqldump to the specified file name. Peter brought up a good point that the command would only give you one day of archiving--any archive over two days old would be overwritten. This would allow you have a rolling log going back seven days: CURRENT_DAY_OF_WEEK=`date '+%u'` FILENAME=""mysqlbackup_""$CURRENT_DAY_OF_WEEK"".sql"" mysqldump db_name > $FILENAME Also be aware that file permissions will apply - can't write a file if the user executing the script doesn't have permissions to the folder. Of course you probably shouldn't over write the same file every day. Maybe tack on the current date to the file name or some such.... @Peter Ajtai: Goood point updated. Don't send a PHP to do a cron mans job  I agree with OMG Ponies mysqldump + script is the way to go. The only other option that I use is to set up a slave server. This provides an almost instant backup against hardware failure and can be located in a different building to your main server. Unless you have a large number of writes to the database you don't necessarily need a very powerful server as it is not processing queries only database updates.",php sql mysql database backup3611726,A,"Insert User Data to Database with INSERT statement From a user form: I am trying to insert the following data: 1) First Name 2) Last Name 3) Major 4) Graduation Year I am able to connect to the database and select the database I need--but I am unable to insert the data from the form. I am able to create records but the data is not being saved to the database. Basically right now I'm creating blank forms. The variable $uInput holds the user data. I tried passing $uInput into the function doAction() but I believe that is where the problem is. I'm trying to figure out how to pass the user data into the function doAction().  <?php //Call function mainline mainline(); // Declare the function mainline function mainline() { $uInput = getUserInput(); $connectDb = openConnect(); // Open Database Connection selectDb($connectDb); // Select Database doAction($uInput); //closeConnect(); //display(); } //Declare function getUserInput ------------------------------------------------------------------------------------ function getUserInput() { echo ""In the function getUserInput()"" . ""<br/>""; // Variables of User Input $idnum = $_POST[""idnum""]; // id (NOTE: auto increments in database) $fname = $_POST[""fname""]; // first name $lname = $_POST[""lname""]; // last name $major = $_POST[""major""]; // major $year = $_POST[""year""]; // year $action = $_POST[""action""]; // action (select insert update delete) $userInput = array($idnum $fname $lname $major $year $action); //echo ""info from getUserInput: "" . $action; return $userInput; } function doAction($pUserInput) { // if user selects INSERT from dropdown menu then call function insert //and pass $uInput if ($pUserInput[5] == ""ins"") { insert($uInput); } } // Create a database connection -------------------------------------------------------- function openConnect() { $connection = mysql_connect(""localhost"" ""root_user"" ""password""); echo ""Opened Connection!"" . ""<br/>""; if(!$connection) { die(""Database connection failed: "" . mysql_error()); } return $connection; } // Select a database to ---------------------------------------------------------------- function selectDb($pConnectDb) { $dbSelect = mysql_select_db(""School"" $pConnectDb); if(!$dbSelect) { die(""Database selection failed: "" . mysql_error()); } else { echo ""You are in the School database! <br/>""; } } // function insert --------------------------------------------------------------------- function insert($pUInput) { $sql=""INSERT INTO tblStudents (first_name last_name major year) VALUES ('$pUInput[1]''$pUInput[2]''$pUInput[3]' '$pUInput[4]')""; if (!mysql_query($sql)) { die('Error: ' . mysql_error()); } echo ""1 record added""; } ?> everything looks cool when you print_r($pUInput)? Change insert($uInput); function to insert($pUserInput);  Your doAction() function is buggy. You are taking the parameter into the function as $pUserInput but sending to the insert() function as $uInput. You should do it like this: function doAction($pUserInput) { // if user selects INSERT from dropdown menu then call function insert //and pass $uInput if ($pUserInput[5] == ""ins"") { insert($pUserInput); // <-- FIXED: Not using correct parameter. } } Ah! just noticed that! thanks I knew it had something to do how the variable was being passed. 1 record added: not blank! / hmm but the year in the database is 0000-00-00. looks like i'm dealing with a different issue. the user chooses a year from a dropdown menu (ie. 2010 2011 2012 etc...etc...) @crewof1 please post a separate question for that. no prob just trying to see if i can figure it out first :)",php sql database forms3750707,A,"""disable"" some MySql records so they are not returned when searching? I have a mysql database which I support using phpMyAdmin. The website this is for is a classifieds website. The issue here is that whenever a new classified is posted (and inserted into mysql database) I need to first review it manually. My question is is there anyway to tell mysql that ""this record is inactive so don't return it""? I know of one way offcourse to add a column named ""state"" and change it to ""active"" for all classifieds which I want active. But is there any other method built into mysql which does the same? In other words I dont want the record returned when users search the website if the record isn't ""reviewed"" first by me. EDIT: I know of the WHERE clause that is not my Q here. Is there any other method built into phpMyAdmin? Thanks No there is no built-in method. Beside of methods mentioned above you could try using views to filter inactive records. Instead of: SELECT * FROM table WHERE status = 'active'; use a view: CREATE VIEW only_active AS SELECT * FROM table WHERE status = 'active'; and then just SELECT * FROM only_active That makes you sure that you will never get inactive records incidentally.  Have a reviewed column in the table of type BOOLEAN. Initialize it to false and update to true once a listing has been reviewed. Whenever you get the list of classifieds for the site include reviewed=true in the WHERE clause. There is no way built into phpMyAdmin.  There really isn't a way to achieve this without having some sort of DB field that tells you which records you've reviewed and which you haven't. So the only sensible answer you're going to get is ""add a state field"". The question really is why you don't want to do it that way? (especially if you already know how to do it). If you can answer that you may get some useful help help with solving the problems you perceive the obvious answer may cause you.  On a row level there are no properties other then ones you specify yourself. So the answer is definitively no. Using views as Piotr described might be useful to you; especially if you reverse the situation and rename the original table create a view in it's name that will return only 'reviewed' records This way the solution might be transparent to your application. Few notes: The database does not care if myphpadmin or any other client/application is looking at the data all clients are essentially equal; so the implication is that what you ask can not be possible (otherwise how would this hiding mechanism determine if it should display the rows or hide them?). There is a semi exception though - RDBMS that support row-level security could do this (but effectively such system store additional attribute per row) EDIT: Forgot to link http://www.sqlmaestro.com/resources/all/row_level_security_mysql/ This gives some examples and details.  I know of the WHERE clause that is not my Q here. Is there any other method built into phpMyAdmin? no it's not. your should realy use a ""state"" column to get what you want. Using a new column 'state' or 'reviewed' will also give you more flexibility in the future. You'll be able to alter the column state to inactive at a later date (eg programmatically when the classified expires after a certain date) or maybe if the ad causes problems in any form you can quickly disable it.  If you are using the ORM Doctrine you can use the SoftDelete behavior which does exactly the thing you want. You can build query's and the ""SoftDeleted"" records do not return. You should be using Doctrine for it though. If you can not go with Doctrine I would use Piotr Pankowski's solution. The only thing is that I would use a DateTime field and not an Boolean field. Set the field to the current DateTime when it's added and NULL when it's not disabled.",php sql mysql html database3151941,A,Tricky SQL for a smart search I am using a form through a PHP CMS system that defines custom fields and such. One of the custom fields allows for an input field which does a smart search. What this means is that when you start typing it shows the records that match quite similar to google suggest. The smartsearch input field relies on a stored mysql search and this is what I am having trouble with because it just looks too complex. I am going to paste the SQl from an existing search and then explain what I am trying to do. There are different sql queries in a few columns as follows: fromclause ((`clients` INNER JOIN `addresstorecord` ON `clients`.`uuid` = `addresstorecord`.`recordid` AND `addresstorecord`.`tabledefid`='tbld:6d290174-8b73-e199-fe6c-bcf3d4b61083' AND addresstorecord.primary='1') INNER JOIN `addresses` ON `addresstorecord`.`addressid` = `addresses`.`uuid`) displayfield: IF(clients.company != '' CONCAT(clients.company IF(clients.lastname != '' OR clients.firstname != '' CONCAT(' (' IF(clients.lastname != '' clients.lastname '{blank}') ' ' IF(clients.firstname != '' clients.firstname '{blank}') ')') '') ) IF(clients.lastname != '' OR clients.firstname != '' CONCAT(IF(clients.lastname != '' clients.lastname '{blank}') ' ' IF(clients.firstname != '' clients.firstname '{blank}')) '')) ) secondaryfield: IF(addresses.city != '' OR addresses.state !='' OR addresses.postalcode != '' CONCAT(IF(addresses.city != '' addresses.city '') ' ' IF(addresses.state != '' addresses.state '') ' ' IF(addresses.postalcode != '' addresses.postalcode '')) 'unspecified location') classfield clients.type searchfields clients.company clients.firstname clients.lastname filterclause clients.inactive=0 I am having trouble understanding how these queries actually work. displayfield and secondaryfield in particular seem very redundant. i donÎ‚t think my needs are so different from how the current example smartsearch field works...just instead of clients i want guests and instead of address i just want it to match firstname lastname or passport number. I wonder if I even need secondaryfield in that case? In particular the inner join in the fromclause confuses me as I donÎ‚t think I need to do that as all the guest information is in one table... Any assistance here is much appreciated thankyou. how would I do that? I donÎ‚t think I can...I think the smartsearch field does different queries depending on what is typed.... could you provide the entire query as a block so we can see what's actually being queried from the DB? I reformatted your code samples with some indenting so it's easier to read. They were very long and scrolling horizontally it's hard to tell what's going on. Something like this appears to do nothing: IF(addresses.state != '' addresses.state '') I would guess it was written by someone who didn't understand how NULL works in SQL or someone who is accustomed to Oracle where NULL and '' are equivalent. Displayfield and secondaryfield have different content. Displayfield shows the person's company and name whereas secondaryfield shows the person's address state and postal code. These are not redundant. The complexity comes from trying to handle blank or unspecified content. Thankyou for the reformatting. The code definitely does work and was designed to work with MySQL. I think it has something to do with that since it is a smartsearch what I have posted is not the entire query rather the query would be made from part of what I have poested and part of what I type in the field as I type it. Unfortunately I am having trouble finding any documentation and figuring this out and am working somewhat blind. Would you have any suggestions on how I can figure out what queries are actually being made to the database? Can mysql be configured to log all queries? I agree some unecesary complexity could be avoided using `IFNULL(addresses.city ''` instead of `IF(addresses.city != '' addresses.city '')` for example. @Jacob: I think you're right probably the smartsearch system uses and modify these parts of queries to build one based on the answers/choices on the form. this is why there are so many options that seems unecessary. They may be used depending on the choices for the search. To log mysql queries you can insert in `/etc/my.cnf`: `[mysqld]` section: `log=/tmp/mysql.log` mysql needs rights to create and write to the file. Make it only readable to mysql as it will log ALL queries including passwords and to use it only during developing debugging as it will become very big quickly +1 to @laurent-rpnet. You can read more about MySQL logging here: http://dev.mysql.com/doc/refman/5.1/en/server-logs.html,php sql mysql database2226932,A,"MySql cache problems... some questions First of all I am using PhpMyAdmin is this okay or not? Because when I have cache disabled and do two queries after eachother the second query always is faster so I am thinking maybe there is an internal cache on PhpMyAdmin? Secondly is there any way to get the time of how long a query takes into php and echo it onto the browser? (so I can use php instead of phpMyAdmin) Thirdly SHOW STATUS LIKE '%qcache%' gives me this: Qcache_free_blocks 1 Qcache_free_memory 25154096 Qcache_hits 0 Qcache_inserts 2 Qcache_lowmem_prunes 0 Qcache_not_cached 62 Qcache_queries_in_cache 2 Qcache_total_blocks 6 How come Qcache_not_cached grows by a number of 5 or 10 for every query I make? Shouldn't there only be 1 increase per query? Also when I enabled the cache and did a query the Qcache_queries_in_cache got increased by 2... I thought it would be increased by 1 per every query explain someone? THEN when I did another query the same as the one I cached there was no performance gain at all the query took as long as without the cache enabled... Any help here please except for referring to the manual (I have read it already). Thanks UPDATE Here is a typical query I make:  SELECT * FROM `langlinks` WHERE ll_title='Africa' PhpMyAdmin do query and update status from the mysql server so you won't see it increment by one in phpmyadmin  First of all I am using PhpMyAdmin is this okay or not? I suppose it's better than nothing -- and more user-friendly than a command-line client ; but a thing I don't like with phpMyAdmin is that it sends queries you didn't write. I've already seen phpMyAdmin send some queries that were ""hurting"" a server while the one that had been written by the user was OK for instance (I don't have the exact example in mind). Generally speaking though I'd say it's ""ok"" as long as you accept that more requests will be sent : phpMyAdmin displays lots of informations (like the list of databases tables and so on) and has to get those informations from somewehre ! Shouldn't there only be 1 increase per query? If you really want to see the impact of your query and no other you'd probably better use the command-line mysql client instead of phpMyAdmin : that graphical tool has to send queries to get the informations it displays. The question actually is : do you prefer a user-friendly tool ? Or do you want to monitor only what your query actually does ? In most cases the answer is ""user-friendly tool"" -- and that's why phpMyAdmin has so much success ;-)",php sql mysql database caching3463844,A,"Optimize a rankings page using PHP and MySQL I could really use some help optimizing a table on my website that is used to display rankings. I have been reading a lot on how to optimize queries and how to properly use indexes but even after implementing changes I thought would work little improvement can be seen. My quick fix has been simply to use only the top 100000 rankings (updated daily and stored in a different table) to improve the speed for now but I really don't like that option. So I have a table that stores the information for users that looks something like: table 'cache': id (Primary key) name region country score There are other variables being stored about the user but I don't think they are relevant here as they are not used in the rankings. There are 3 basic ranking pages that a user can view: A world view: SELECT cache nameregioncountryscore FROM cache ORDER BY score DESC LIMIT 026 A region view: SELECT nameregioncountryscore FROM cache WHERE region='Europe' ORDER BY score DESC LIMIT 026 and a country view: SELECT nameregioncountryscore FROM cache WHERE region='Europe' AND country='Germany' ORDER BY score DESC LIMIT 026 I have tried almost every combination of indexes I can think of to help alleviate work for the database and while some seem to help a little bit I can't find one that will only return 26 rows for both the region and country queries(with simply an index on 'score' the world rankings are blazing fast). I feel like I might be missing something basic any help would be much appreciated! Little extra info: the cache table is currently around 920 megabytes with a little more than 800000 rows total. If you could use any more info just let me know. Nice try Ponies. We know you mean well. :-) I knew something looked off. Fixed. Your world rankings benefit from the score index because score is the only criteria in the query. The logical sequence it sorts on is built into the query. So that's good. The other queries will benefit from an index on region. However similar to what @Matt indicates a composite index on region country and score may be the best bet. Note the three columns for the key should be in region country score sequence. From what you provided it seems that that index would be best. Are there times when the query has a country filter but no region filter? If yes then an index on region will probably provide the best solution for that type of query. I don't agree with the statement ""Too many indices will slow you down."" You want to create the ""right"" indexe(s) and that may mean more than one. Thanks for the response but I've actually already tried using this index. It definately is 10x faster then doing a full table scan but doesn't show the speed I need when searching for countries in particular. If this is the best index to use maybe this problem has just come down to not having a powerful enough server to host this database?  How many records are we talking about? I am no SQL guru but in this case if just changes to indexes did not do the trick. I would consider playing around with the table structure to see what perf gains I could get. Cache id (pk) LocationId (index) name score Location LocationId (pk) CountryId (index) maybe RegionId (index) maybe Country CountryId name Region RegionId name Location LocationId (Primary key) CountryId RegionId Country CountryId name Region RegionId name Temp tables in Procs would allow you to select on Location Id in every case. It would reduce the over all complexity of the issue you are having: you would be troubleshooting 1 query plan not 3. The effort would be high and the payoff would be until you were done so I would suggest looking at the index approach first. Good luck We're talking about 850000+ records and growing by about 2500/day. I will keep this response in mind for a time when I have time to restructure the tables.  put ONE index on country score region. Too many indices will slow you down.",php sql mysql database ranking2104063,A,"My final mysql db could someone check if the tables are correctly made? I have these tables: category table: cat_id (PK) cat_name category_options table: option_id (PK) cat_id (FK) option_name option_values table: value_id (PK) option_id (FK) value classifieds table: ad_id (PK) (VARCHAR) something like ""Bmw330ci_28238239832"" poster_id (FK) cat_id (FK) headline description price etc.... posters table: poster_id (PK) name email tel password etc.... Three main questions: 1- Is the above good enough? It covers all my needs atleast... 2- Sometimes when I try out different queries I get strange results... Could you write a PHP query string which will fetch one complete ad from an ad_id only? (imagine the only variable you have is ad_id) 3- In the query string must I specify all different tables which are connected in order to display an ad? Can't I just use something like ""SELECT * FROM classifieds WHERE ad_id=$ad_id"" and it would handle the links automatically ie fetch all related information also? Thanks and if you need more input let me know! I'd change ad_id to an int/bigint value if at all possible and store your VARCHAR in a new column. ok I will do that... get rid of the varchar PK in classifieds like @davek suggests and make posters use a int id PK (poster_id) similar to what you did in the other tables and make name a data column so you join on the int but display the name. nice if you need to change a name like what happens after a wedding/divorce oh I missed that actually I DO have a poster_id field! Thanks! I think you should learn how to use SQL so that you know how to make proper queries: http://www.w3schools.com/SQL/sql_intro.asp and http://dev.mysql.com/doc/refman/5.0/en/select.html to get a complete ad (can return multiple rows): SELECT * FROM classifieds c INNER JOIN posters p ON c.poster_id=p.poster_id INNER JOIN category a ON c.cat_id=a.cat_id INNER JOIN category_options o ON a.cat_id=o.cat_id INNER JOIN option_values v ON o.option_id=v.option_id WHERE ad_id=x You have serious design problems. Never ever ever use name as a PK; it is not unique and it is subject to change! Women change thier names when they get married for instance. In fact don't use any varchars as PKS at all. Use surrogate keys instead. Surrogate keys don't change text keys values often do and they are slower too. And never store name as just one field this is a poor practice. At a minumum you need first name last name middle name and suffix. You wil also need a autoincrementing id field so that John Smith at one address in Chicago can exist in the table with a different John Smith who lives elsewhere in Chicago. No you can't get all the data from related tables without adding them to the query through the use of a join. This is database 101 and if you don't know that then you don't understand relational databases enough to design one. Do some research into joins and querying. You can get all the information for an ad from just having the ad id though as your current relations appear to work. Do not use implied joins when you add the other tables to your queries. They are outdated by 18 years. Learn correctly by using explicit joins. re. ""women change their names when they get married""...make sure your validator allows hyphens.  1) If it meets your needs then wouldn't that make it ""good enough""? But seriously I would agree with davek that you should make the ad_id field an int/bigint and I'd also suggest the same for the posters table. Make the name a regular value field and create an autonum int/bigint PK field for it. If for any reason that user wants to change their name (for privacy concerns perhaps) then you would have to update any foreign keys in the database as well. With an autonum key you wouldn't have this problem. 2) Yes from what I see you should be able to gather all the data on an ad by knowing only the ad_id. 3) No you need to do more than that either equi-join in a SELECT query or use the JOIN keyword to pull your data in. MySQL doesn't have a ""meta"" relationship model (like MS Access) so it won't automatically understand your primary/foreign key relationships.",php sql mysql database1888870,A,numpy : How to convert an array type quickly I find the astype() method of numpy arrays not very efficient. I have an array containing 3 million of Uint8 point. Multiplying it by a 3x3 matrix takes 2 second but converting the result from uint16 to uint8 takes another second. More precisely :  print time.clock() imgarray = np.dot(imgarray M)/255 print time.clock() imgarray = imgarray.clip(0 255) print time.clock() imgarray = imgarray.astype('B') print time.clock() dot product and scaling takes 2 sec clipping takes 200 msec type conversion takes 1 sec Given the time taken by the other operations I would expect astype to be faster. Is there a faster way to do type conversion or am I wrong when guesstimating that type conversion should not be that hard ? Edit : the goal is to save the final 8 bit array to a file Why do you need to go to uint16 and back again? Is it possible to have `M` as a uint8 matrix then you don't need the conversion. the result of the dot product will exceed the uint8 range. I originally was using a float M matrix and thought going to integer would give me some improvement but this is not true. What takes all that time probably is accessing all the memory locations. Sounds hard to fix. But clipping is also accessing all memory locations yet it is fast. Hopefully clipping does not need to modify a lot of locations. Similar operation done in C don't have this memory bandwith problem so I don't buy the memory acessing problem Interesting here it takes 0.2s 0.02s and 0.01s respectively for those three operations. Sure my machine seems to be faster than yours but the astype() operation certainly doesn't take anywhere near as long as the multiplication. When you use imgarray = imgarray.astype('B') you get a copy of the array cast to the specified type. This requires extra memory allocation even though you immediately flip imgarray to point to the newly allocated array. If you use imgarray.view('uint8') then you get a view of the array. This uses the same data except that it is interpreted as uint8 instead of imgarray.dtype. (np.dot returns a uint32 array so after the np.dot imgarray is of type uint32.) The problem with using view however is that a 32-bit integer becomes viewed as 4 8-bit integers and we only care about the value in the last 8-bits. So we need to skip to every 4th 8-bit integer. We can do that with slicing: imgarray.view('uint8')[:::4] IPython's %timeit command shows there is a significant speed up doing things this way: In [37]: %timeit imgarray2 = imgarray.astype('B') 10000 loops best of 3: 107 us per loop In [39]: %timeit imgarray3 = imgarray.view('B')[:::4] 100000 loops best of 3: 3.64 us per loop Can I save this view to a file @shodanex: Yes you could use np.save(). See http://docs.scipy.org/doc/numpy-1.3.x/reference/generated/numpy.save.html @shodanex: For other format options see also http://docs.scipy.org/doc/numpy-1.3.x/reference/routines.io.html it is then implicitly architecture-dependent since which slice to use depends on endianness. @kaizer.se: Yes that's true. Do you know a nice way to make the code non-architecture-dependent?,python numpy1791791,A,"Stacking numpy recarrays without losing their recarrayness Suppose I make two recarrays with the same dtype and stack them: >>> import numpy as np >>> dt = [('foo' int) ('bar' float)] >>> a = np.empty(2 dtype=dt).view(np.recarray) >>> b = np.empty(3 dtype=dt).view(np.recarray) >>> c = np.hstack((ab)) Although a and b are recarrays c is not: >>> c.foo Traceback (most recent call last): File ""<stdin>"" line 1 in <module> AttributeError: 'numpy.ndarray' object has no attribute 'foo' >>> d = c.view(np.recarray) >>> d.foo array([ 0 111050731618561 0 7718048 8246760947200437872]) I can obviously turn it into a recarray again as shown with d above but that is inconvenient. Is there a reason why stacking two recarrays does not produce another recarray? Incidentally you can also use: c = np.concatenate((ab)) or c = np.r_[a b] ( Source: this mailing list message ) They don't preserve the recarrayness either.  Alternatively there are some helper utilities in numpy.lib.recfunctions which I stumbled across here. This module has functions for both merging and stacking recarrays: from numpy.lib.recfunctions import stack_arrays c = stack_arrays((a b) asrecarray=True usemask=False) c.foo >>> array([ 140239282560000 4376479720 -4611686018427387904 4358733828 4365061216]) If one wants to add extra columns to a recarray this can be done using merge_arrays: import numpy as np from numpy.lib.recfunctions import merge_arrays dt1 = [('foo' int) ('bar' float)] dt2 = [('foobar' int) ('barfoo' float)] aa = np.empty(6 dtype=dt1).view(np.recarray) bb = np.empty(6 dtype=dt2).view(np.recarray) cc = merge_arrays((aa bb) asrecarray=True flatten=True) type(cc) >>> numpy.core.records.recarray (Although not an answer to the question I'm posting the latter example as a reference)  I don't know. Most likely it's a bug/feature that's never been implemented. numpy.hstack is basically a wrapper around a function in numpy.core.fromnumeric. Numeric is one of the two predecessors of numpy. Most functions in numpy have a convention to output the same type as the input by calling the method __array_wrap__ of the input on the output and the resulting output is should have the same data but ""wrapped"" in the new class. Perhaps the concept of ""wrapping"" was not in numeric andnever got added to this function. You can use this technique to make a smarter stacking function def hstack2(arrays) : return arrays[0].__array_wrap__(numpy.hstack(arrays)) This works for both recarrays and regular arrays >>> f = hstack2((ab)) >>> type(f) <class 'numpy.core.records.recarray'> >>> f.foo array([ 140633760262784 111050731618561 140633760262800 7536928 8391166428122670177]) >>> x = numpy.random.rand(3) >>> y = numpy.random.rand(2) >>> z = hstack2((xy)) >>> type(z) <type 'numpy.ndarray'> I'm not sure what you're planning but you might want to ask on the numpy mailing list is there's a better way than using the documented but double-underscored method and what their reasoning is for not doing the wrapping themselves.",python numpy recarray1236695,A,"Is 'for x in array' always result in sorted x? [Python/NumPy] For arrays and lists in Python and Numpy are the following lines equivalent: itemlist = [] for j in range(len(myarray)): item = myarray[j] itemlist.append(item) and: itemlist = [] for item in myarray: itemlist.append(item) I'm interested in the order of itemlist. In a few examples that I have tried they are identical but is it guaranteed? For example I know that the foreach statement in C# doesn't guarantee order and that I should be careful with it. Oops yes I did mean to throw in a range() Did you mean: for j in range(len(myarray)): ? Yes it's entirely guaranteed. for item in myarray (where myarray is a sequence which includes numpy's arrays builtin lists Python's array.arrays etc etc) is in fact equivalent in Python to: _aux = 0 while _aux < len(myarray): item = myarray[_aux] ...etc... for some phantom variable _aux;-). Btw both of your constructs are also equivalent to itemlist = list(myarray) Thanks! Yeah I wasnt really trying to convert an array to a list just exploring the order.  It is guaranteed for lists. I think the more relevant Python parallel to your C# example would be to iterate over the keys in a dictionary which is NOT guaranteed to be in any order. # Always prints 0-9 in order a_list = [0123456789] for x in a_list: print x # May or may not print 0-9 in order. Implementation dependent. a_dict = {'0':0'1':1'2':2'3':3'4':4'5':5'6':6'7':7'8':8'9':9} for x in a_dict: print x The for <element> in <iterable> structure only worries that the iterable supplies a next() function which returns something. There is no general guarantee that these elements get returned in any order over the domain of the for..in statement; lists are a special case. Thanks for highlighting that arrays have a notion of order that it is implemented via the next() function. The for ... in ... structure takes advantage of next() and so data with an intrinsic order (arrays) implements next() differently than data without an intrinsic order (such as dictionaries.)  Yes the Python Language Reference guarantees this (emphasis is mine):  for_stmt ::= ""for"" target_list ""in"" expression_list "":"" suite [""else"" "":"" suite] ""The suite is then executed once for each item provided by the iterator in the order of ascending indices.""",python arrays list numpy1800187,A,replace values in an array as a replacement value for another within an operation with arrays or how to search within an array and replace a value by another for example: array ([[NaN 1. 1. 1. 1. 1. 1.] [1. NaN 1. 1. 1. 1. 1.] [1. 1. NaN 1. 1. 1. 1.] [1. 1. 1. NaN 1. 1. 1.] [1. 1. 1. 1. NaN 1. 1.] [1. 1. 1. 1. 1. NaN 1.] [1. 1. 1. 1. 1. 1. NaN]]) where it can replace NaN by 0. thanks for any response these days there is the special function: a = numpy.nan_to_num(a) Just saved my bacon while doing in Inverse Filter. [image-processing] But this will involve a temporary variable with same type and shape as ```a``` it will matter on large matrices.  You could do this: import numpy as np x=np.array([[np.NaN 1. 1. 1. 1. 1. 1.][1. np.NaN 1. 1. 1. 1. 1.][1. 1. np.NaN 1. 1. 1. 1.] [1. 1. 1. np.NaN 1. 1. 1.] [1. 1. 1. 1. np.NaN 1. 1.][1. 1. 1. 1. 1. np.NaN 1.] [1. 1. 1. 1. 1. 1. np.NaN]]) x[np.isnan(x)]=0 np.isnan(x) returns a boolean array which is True wherever x is NaN. x[ boolean_array ] = 0 employs fancy indexing to assign the value 0 wherever the boolean array is True. For a great introduction to fancy indexing and much more see also the numpybook. NameError: name 'x' is not defined not work @ricardo: Let x be your numpy array. hi excellent response thanks,python numpy1727669,A,"Contruct 3d array in numpy from exist 2d array during preparing data for numpy calculate i curious about way to contruct myarray.shape => (21818) from d1.shape => (1818) d2.shape => (1818) i try to use numpy command hstack([[d1][d2]]) but it looks not work!! hstack and vstack do no change the number of dimensions of the arrays: they merely put them ""side by side"". Thus combining 2-dimensional arrays creates a new 2-dimensional array (not a 3D one!). You can do what Daniel suggested. You can alternatively convert your arrays to 3D arrays before stacking them by adding a new dimension to each array: d3 = vstack([ d1[newaxis...] d2[newaxis...] ]) # shape = (2 18 18) In fact d1[newaxis...].shape == (1 18 18) and you can stack both 3D arrays directly and get the new 3D array (d3) that you wanted. :) thank EOL  now i 'll know more about vstackhstack  Just doing d3 = array([d1d2]) seems to work for me: >>> from numpy import array >>> # ... create d1 and d2 ... >>> d1.shape (1818) >>> d2.shape (1818) >>> d3 = array([d1 d2]) >>> d3.shape (2 18 18) oh its work thank Daniel :)",python numpy442218,A,How do I use a 2-d boolean array to select from a 1-d array on a per-row basis in numpy? Let me illustrate this question with an example: import numpy matrix = numpy.identity(5 dtype=bool) #Using identity as a convenient way to create an array with the invariant that there will only be one True value per row the solution should apply to any array with this invariant base = numpy.arange(5305) #This could be any 1-d array provided its length is the same as the length of axis=1 of matrix from above result = numpy.array([ base[line] for line in matrix ]) result now holds the desired result but I'm sure there is a numpy-specific method for doing this that avoids the explicit iteration. What is it? Here is another ugly way of doing it: n.apply_along_axis(base.__getitem__ 0 matrix).reshape((51))  If I understand your question correctly you can simply use matrix multiplication: result = numpy.dot(matrix base) If the result must have the same shape as in your example just add a reshape: result = numpy.dot(matrix base).reshape((51)) If the matrix is not symmetric be careful about the order in dot.  My try: numpy.sum(matrix * base axis=1),python numpy877479,A,"What's the simplest way to extend a numpy array in 2 dimensions? I have a 2d array that looks like this: XX xx What's the most efficient way to add an extra row and column: xxy xxy yyy For bonus points I'd like to also be able to knock out single rows and columns so for example in the matrix below I'd like to be able to knock out all of the a's leaving only the x's - specifically I'm trying to delete the nth row and the nth column at the same time - and I want to be able to do this as quickly as possible: xxaxx xxaxx aaaaa xxaxx xxaxx The shortest in terms of lines of code i can think of is for the first question. >>> import numpy as np >>> p = np.array([[12][34]]) >>> p = np.append(p [[56]] 0) >>> p = np.append(p [[7][8][9]]1) >>> p array([[1 2 7] [3 4 8] [5 6 9]]) And the for the second question  p = np.array(range(20)) >>> p.shape = (45) >>> p array([[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14] [15 16 17 18 19]]) >>> n = 2 >>> p = np.append(p[:n]p[n+1:]0) >>> p = np.append(p[...:n]p[...n+1:]1) >>> p array([[ 0 1 3 4] [ 5 6 8 9] [15 16 18 19]])  Answer to the first question: Use numpy.append. http://docs.scipy.org/doc/numpy/reference/generated/numpy.append.html#numpy.append Answer to the second question: Use numpy.delete http://docs.scipy.org/doc/numpy/reference/generated/numpy.delete.html  maybe you need this. >>> x = np.array([1122]) >>> y = np.array([1876]) >>> z = np.array([135]) >>> np.concatenate((xyz)) array([11 22 18 7 6 1 3 5])  Another elegant solution to the first question may be the insert command: p = np.array([[12][34]]) p = np.insert(p 2 values=0 axis=1) # insert values before column 2 Leads to: array([[1 2 0] [3 4 0]]) insert may be slower than append but allows you to fill the whole row/column with one value easily. As for the second question delete has been suggested before: p = np.delete(p 2 axis=1) Which restores the original array again: array([[1 2] [3 4]])  A useful alternative answer to the first question using the examples from tomeedeeŠ—Ès answer would be to use numpyŠ—Ès vstack and column_stack methods: Given a matrix p >>> import numpy as np >>> p = np.array([ [12]  [34] ]) an augmented matrix can be generated by: >>> p = np.vstack( [ p  [5  6] ] ) >>> p = np.column_stack( [ p  [ 7  8  9 ] ] ) >>> p array([[1 2 7] [3 4 8] [5 6 9]]) These methods may be convenient in practice than np.append() as they allow 1D arrays to be appended to a matrix without any modification in contrast to the following scenario: >>> p = np.array([ [ 1  2 ]  [ 3  4 ]  [ 5  6 ] ] ) >>> p = np.append( p  [ 7  8  9 ]  1 ) Traceback (most recent call last): File ""<stdin>"" line 1 in <module> File ""/usr/lib/python2.6/dist-packages/numpy/lib/function_base.py"" line 3234 in append return concatenate((arr values) axis=axis) ValueError: arrays must have same number of dimensions In answer to the second question a nice way to remove rows and columns is to use logical array indexing as follows: Given a matrix p >>> p = np.arange( 20 ).reshape( ( 4  5 ) ) suppose we want to remove row 1 and column 2: >>> r  c = 1  2 >>> p = p [ np.arange( p.shape[0] ) != r  : ] >>> p = p [ :  np.arange( p.shape[1] ) != c ] >>> p array([[ 0 1 3 4] [10 11 13 14] [15 16 18 19]]) Note - for reformed Matlab users - if you wanted to do these in a one-liner you need to index twice: >>> p = np.arange( 20 ).reshape( ( 4  5 ) ) >>> p = p [ np.arange( p.shape[0] ) != r  : ] [ :  np.arange( p.shape[1] ) != c ] This technique can also be extended to remove sets of rows and columns so if we wanted to remove rows 0 & 2 and columns 1 2 & 3 we could use numpy's setdiff1d function to generate the desired logical index: >>> p = np.arange( 20 ).reshape( ( 4  5 ) ) >>> r = [ 0  2 ] >>> c = [ 1  2  3 ] >>> p = p [ np.setdiff1d( np.arange( p.shape[0] ) r )  : ] >>> p = p [ :  np.setdiff1d( np.arange( p.shape[1] )  c ) ] >>> p array([[ 5 9] [15 19]])  I find it much easier to ""extend"" via assigning in a bigger matrix. E.g. import numpy as np p = np.array([[12] [34]]) g = np.array(range(20)) g.shape = (45) g[0:2 0:2] = p Here are the arrays: p  array([[1 2] [3 4]]) g: array([[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14] [15 16 17 18 19]]) and the resulting g after assignment:  array([[ 1 2 2 3 4] [ 3 4 7 8 9] [10 11 12 13 14] [15 16 17 18 19]])",python arrays math numpy1518779,A,"How to install numpy and scipy on Windows XP I have a problem installing Numpy and Scipy from http://www.scipy.org/Installing%5FSciPy/Windows I went to download page and downloaded .exe files for Python26. I have Python26 on my machine. After installation I tried >>> import nympy scipy Traceback (most recent call last): File ""<stdin>"" line 1 in <module> ImportError: No module named nympy >>> How to proceed? try with numpy instead of nympy My bad Thanks!!",python numpy scipy1724504,A,Just curious about result from NumPy function! I have used NumPy for my Master thesis. I've converted parts of the code from MATLAB code but I have doubts in NumPy/Python when I reference: m = numpy.ones((102)) m[:0] which returns: array([ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]) and when I ref to: m[:0:1] it returns: array([[ 1.] [ 1.] [ 1.] [ 1.] [ 1.] [ 1.] [ 1.] [ 1.] [ 1.] [ 1.]]) that I think it should be cause same result with MATLAB!!! It would be very helpful if you'd proofread your question and format it properly. oops  sorry about that :) this should help a bit though I still don't understand the question exactly! thank you very much for formatting Amro :) I'm still learning Python myself but I think the way that slicing works is that indices point to in-between locations therefore 0:1 only gets you the first column. Is this what you were asking about? This is what the documentation has to say: One way to remember how slices work is to think of the indices as pointing between characters with the left edge of the first character numbered 0. Then the right edge of the last character of a string of n characters has index n for example:  +---+---+---+---+---+ | H | e | l | p | A | +---+---+---+---+---+ 0 1 2 3 4 5 -5 -4 -3 -2 -1 No m[:0:1] is the equivalent of the matlab statement as shown in the question - this extracts column 0 equivalent to column 1 in Matlab. 0:2 is a slice covering 01 which is both columns (so the whole array in this case) I think this what the OP was trying to do since (aside from the starting index) in MATLAB: `m(:1:2)` gets you two columns while in Python/NumPy: `m[:0:1]` returns one column. I guess this is something to be clarified.. Agree its not clear - I read the question as asking about extracting a column - in matlab m(:1) gives a 2d column vector - the same as m[:0:1] in numpy but m[:0] in numpy gives a 1d array - I think the question was why this is different to matlab but the slices translate as you say... Yea it's not definitely clear in the question. I meant the same as Amro: MATLAB m(:1:2) NumPy m[:0:2]  I forget what numpy does but Matlab indexes vectors from 1 not 0. So array(:0) is an error in Matlab.  This is because numpy has the concept of 1d arrays which Matlab doesn't have. Coupled with numpys broadcasting this provides a powerful simplification (less worrying about inserting transposes everywhere) but does mean you have to think a little bit about translating from Matlab. In this case extracting a single column with a scalar Numpy simplifies the result to a 1d array - but with a slice it preserves the original dimensions. If you want to stay closer to Matlab semantics you could try using the Matrix class. See NumPy for matlab users page for details. In this case you could do either of the following: m[:0][:newaxis] # gives same as matlab np.matrix(m)[:0] # gives same as matlab But remember if you use matrix class * becomes matrix multiplication and you need to use multiply() for elementwise. (This is all covered in NumPy for Matlab Users page). Generally I would recommend trying to get used to using 1d arrays where you would have column or row vector in matlab and generally things just work. You only need to worry about column vs row when reassembling them into a 2d array. You may be interested in automated matlab to python converters such as OMPC (paper) (I think there are others as well). ohh great i got it :D thank very much  thrope!!! no problem... If you feel this answers the question you could click on the tick by the answer to accept it... :),python matlab numpy1949225,A,"""painting"" one array onto another using python / numpy I'm writing a library to process gaze tracking in Python and I'm rather new to the whole numpy / scipy world. Essentially I'm looking to take an array of (xy) values in time and ""paint"" some shape onto a canvas at those coordinates. For example the shape might be a blurred circle. The operation I have in mind is more or less identical to using the paintbrush tool in Photoshop. I've got an interative algorithm that trims my ""paintbrush"" to be within the bounds of my image and adds each point to an accumulator image but it's slow(!) and it seems like there's probably a fundamentally easier way to do this. Any pointers as to where to start looking? Sounds like you want some form of quick blit. However I lack knowledge of python to suggest a good answer. OpenCV uses numpy arrays and has basic drawing functions: circles elipses polylines... To draw a line you can call cv.line(arrayprevious_pointnew_pointcolourthickness=x) each time you get a mouse event.  Have you looked into Tkinter? Python Image Library may be some help too. Tkinter alarms me a bit -- I'm really leery of using a GUI tooklit to do array math. And I'm familiar with PIL but don't really see how this solves anything that numpy doesn't. I'd still need to do some odd jiggery-pokery to add the arrays together...?  In your question you describe a Gaussian filter for which scipy has support via a package. For example: from scipy import * # rand from pylab import * # figure imshow from scipy.ndimage import gaussian_filter # random ""image"" I = rand(100 100) figure(1) imshow(I) # gaussian filter J = gaussian_filter(I sigma=10) figure(2) imshow(J) Of course you can apply this on the whole image or just on a patch using slicing: J = array(I) # copy image J[30:70 30:70] = gaussian_filter(I[30:70 30:70] sigma=1) # apply filter to subregion figure(2) imshow(2) For basic image manipulation the Python Image library (PIL) is probably what you want. NOTE: for ""painting"" with a ""brush"" I think you could just create a boolean mask array with your brush. For instance: # 7x7 boolean mask with the ""brush"" (example: a _crude_ circle) mask = array([[0 0 1 1 1 0 0] [0 1 1 1 1 1 0] [1 1 1 1 1 1 1] [1 1 1 1 1 1 1] [1 1 1 1 1 1 1] [0 1 1 1 1 1 0] [0 0 1 1 1 0 0]] dtype=bool) # random image I = rand(100 100) # apply filter only on mask # compute the gauss. filter only on the 7x7 subregion not the whole image I[40:47 40:47][mask] = gaussian_filter(I[40:47 40:47][mask] sigma=1) Hm this may put me on the right track -- I think some slicing magic will help me do what I need. I added an example with a boolean mask maybe that's what you need. this is nice +1 :)  Doing a little of math in Fourier space may help: a translation (convolution by a dirac) is equal to a simple multiplication by a phase in Fourier... this makes your paintbrush move to the exact place (a similar solution than catchmeifyoutry & dwf but this allows a translation finer than the pixel like 2.5 alas with some ringing). Then a sum of such strokes is the sum of these operations. In code: import numpy import pylab from scipy import mgrid def FTfilter(image FTfilter): from scipy.fftpack import fftn fftshift ifftn ifftshift from scipy import real FTimage = fftshift(fftn(image)) * FTfilter return real(ifftn(ifftshift(FTimage))) def translate(image vec): """""" Translate image by vec (in pixels) """""" u = ((vec[0]+image.shape[0]/2) % image.shape[0]) - image.shape[0]/2 v = ((vec[1]+image.shape[1]/2) % image.shape[1]) - image.shape[1]/2 f_x f_y = mgrid[-1:1:1j*image.shape[0] -1:1:1j*image.shape[1]] trans = numpy.exp(-1j*numpy.pi*(u*f_x + v*f_y)) return FTfilter(image trans) def occlude(image mask): # combine in oclusive mode return numpy.max(numpy.dstack((image mask)) axis=2) if __name__ == '__main__': Image = numpy.random.rand(100 100) X Y = mgrid[-1:1:1j*Image.shape[0] -1:1:1j*Image.shape[1]] brush = X**2 + Y**2 < .05 # relative size of the brush # shows the brush pylab.imshow(brush) # move it to some other position / use a threshold to avoid ringing brushed = translate(brush [20 -10.51]) > .6 pylab.imshow(brushed) pylab.imshow(occlude(Image brushed)) more_strokes = [[40 -15.1] [-40 -15.1] [-25 15.1] [20 10] [0 -10] [25 -10.51]] for stroke in more_strokes: brushed = brushed + translate(brush stroke) > .6 pylab.imshow(occlude(Image brushed))  You should really look into Andrew Straw's motmot and libcamiface. He uses it for fly behaviour experiments but it's a flexible library for doing just the kind of image acquisition and processing you're doing I think. There's a video of his presentation at SciPy2009. As for the paintbrush scenario you mention I'd make a copy of the image with the .copy() method keep the paintbrush image in an array and simply add it with arr[first_br_row:last_br_row first_br_col:last_br_col] += brush[first_row:last_row first_col:last_col] where you set first_br_row last_br_row first_br_col last_br_col to address the subimage where you want to add the brush and first_row last_row first_col last_col to clip the brush (normally set them to 0 and # rows/cols - 1 but adjust when you're near enough to the image boundary to only want to paint part of the brush). Hope all that helps. Thanks! Turns out that yes slicing and indexing tricks will help a bunch. However! The Right Answer is probably to draw individual points and apply the brush and blur both as kernels. Thanks for the bump on the libraries; however this is really a post-processing task: the data have already been collected.",python image-processing numpy scipy1782114,A,Why don't these two math functions return the same result? I'm trying to use fancy indexing instead of looping to speed up a function in Numpy. To the best of my knowledge I've implemented the fancy indexing version correctly. The problem is that the two functions (loop and fancy-indexed) do not return the same result. I'm not sure why. It's worth pointing out that the functions do return the same result if a smaller array is used (e.g. 20 x 20 x 20). Below I've included everything necessary to reproduce the error. If the functions do return the same result then the line find_maxdiff(data) - find_maxdiff_fancy(data) should return an array full of zeroes. from numpy import * def rms(data axis=0): return sqrt(mean(data ** 2 axis)) def find_maxdiff(data): samples channels epochs = shape(data) window_size = 50 maxdiff = zeros(epochs) for epoch in xrange(epochs): signal = rms(data[: : epoch] axis=1) for t in xrange(window_size alen(signal) - window_size): amp_a = mean(signal[t-window_size:t] axis=0) amp_b = mean(signal[t:t+window_size] axis=0) the_diff = abs(amp_b - amp_a) if the_diff > maxdiff[epoch]: maxdiff[epoch] = the_diff return maxdiff def find_maxdiff_fancy(data): samples channels epochs = shape(data) window_size = 50 maxdiff = zeros(epochs) signal = rms(data axis=1) for t in xrange(window_size alen(signal) - window_size): amp_a = mean(signal[t-window_size:t] axis=0) amp_b = mean(signal[t:t+window_size] axis=0) the_diff = abs(amp_b - amp_a) maxdiff[the_diff > maxdiff] = the_diff return maxdiff data = random.random((600 20 100)) find_maxdiff(data) - find_maxdiff_fancy(data) data = random.random((20 20 20)) find_maxdiff(data) - find_maxdiff_fancy(data) What magnitude of difference is there between the two? This isn't the typical floating point accuracy issue that catches so many people out is it? At what value between 20x20x20 and 600x20x100 do things start to go wrong? Do things go wrong gradually and more and more or all at once? The magnitude of the differences is rather large to just be floating point errors. First in fancy your signal is now 2D if I understand correctly - so I think it would be clearer to index it explicitly (eg amp_a = mean(signal[t-window_size:t:] axis=0). Similarly with alen(signal) - this should just be samples in both cases so I think it would be clearer to use that. It is wrong whenever you are actually doing something in the t loop - when samples < window_lenght as in the 20x20x20 example that loop never gets executed. As soon as that loop is executed more than once (ie samples > 2 *window_length+1) then the errors come. Not sure why though - they do look equivalent to me.  The problem is this line: maxdiff[the_diff > maxdiff] = the_diff The left side selects only some elements of maxdiff but the right side contains all elements of the_diff. This should work instead: replaceElements = the_diff > maxdiff maxdiff[replaceElements] = the_diff[replaceElements] or simply: maxdiff = maximum(maxdiff the_diff) As for why 20x20x20 size seems to work: This is because your window size is too large so nothing gets executed. Thanks for helping me better understand how fancy assignment works. Also I should have caught the silly reason why the smaller array was working :) Thanks again.,python numpy scipy1975704,A,"Python - pickling fails for numpy.void objects  >>> idmapfile = open(""idmap"" mode=""w"") >>> pickle.dump(idMap idmapfile) >>> idmapfile.close() >>> idmapfile = open(""idmap"") >>> unpickled = pickle.load(idmapfile) >>> unpickled == idMap False idMap[1] {1537: (552 1 1537 17.793827056884766 3) 1540: (4220 1 1540 19.31205940246582 3) 1544: (592 1 1544 18.129131317138672 3) 1675: (529 1 1675 18.347782135009766 3) 1550: (4048 1 1550 19.31205940246582 3) 1424: (1528 1 1424 19.744396209716797 3) 1681: (1265 1 1681 19.596025466918945 3) 1560: (3457 1 1560 20.530569076538086 3) 1690: (477 1 1690 17.395542144775391 3) 1691: (554 1 1691 13.446117401123047 3) 1436: (3010 1 1436 19.596025466918945 3) 1434: (3183 1 1434 19.744396209716797 3) 1441: (3570 1 1441 20.589576721191406 3) 1435: (476 1 1435 19.640911102294922 3) 1444: (527 1 1444 17.98480224609375 3) 1478: (1897 1 1478 19.596025466918945 3) 1575: (614 1 1575 19.371648788452148 3) 1586: (2189 1 1586 19.31205940246582 3) 1716: (3470 1 1716 19.158674240112305 3) 1590: (2278 1 1590 19.596025466918945 3) 1463: (991 1 1463 19.31205940246582 3) 1594: (1890 1 1594 19.596025466918945 3) 1467: (1087 1 1467 19.31205940246582 3) 1596: (3759 1 1596 19.744396209716797 3) 1602: (3011 1 1602 20.530569076538086 3) 1547: (490 1 1547 17.994071960449219 3) 1605: (658 1 1605 19.31205940246582 3) 1606: (1794 1 1606 16.964881896972656 3) 1719: (1826 1 1719 19.596025466918945 3) 1617: (583 1 1617 11.894925117492676 3) 1492: (3441 1 1492 20.500667572021484 3) 1622: (3215 1 1622 19.31205940246582 3) 1628: (2761 1 1628 19.744396209716797 3) 1502: (1563 1 1502 19.596025466918945 3) 1632: (1108 1 1632 15.457141876220703 3) 1468: (3779 1 1468 19.596025466918945 3) 1642: (3970 1 1642 19.744396209716797 3) 1518: (612 1 1518 18.570245742797852 3) 1647: (854 1 1647 16.964881896972656 3) 1650: (2099 1 1650 20.439058303833008 3) 1651: (540 1 1651 18.552841186523438 3) 1653: (613 1 1653 19.237197875976563 3) 1532: (537 1 1532 18.885730743408203 3)} >>> unpickled[1] {1537: (64880 1638 56700 -1.0808743559293829e+18 152) 1540: (64904 1638 0 0.0 0) 1544: (54472 1490 0 0.0 0) 1675: (6464 1509 0 0.0 0) 1550: (43592 1510 0 0.0 0) 1424: (43616 1510 0 0.0 0) 1681: (0 0 0 0.0 0) 1560: (400 152 400 2.1299736657737219e-43 0) 1690: (408 152 408 2.7201111331839077e+26 34) 1435: (424 152 61512 1.0122952080313192e-39 0) 1436: (400 152 400 20.250289916992188 3) 1434: (424 152 62080 1.0122952080313192e-39 0) 1441: (400 152 400 12.250144958496094 3) 1691: (424 152 42608 15.813941955566406 3) 1444: (400 152 400 19.625289916992187 3) 1606: (424 152 42432 5.2947192852601414e-22 41) 1575: (400 152 400 6.2537390010262572e-36 0) 1586: (424 152 42488 1.0122601755697111e-39 0) 1716: (400 152 400 6.2537390010262572e-36 0) 1590: (424 152 64144 1.0126357235581501e-39 0) 1463: (400 152 400 6.2537390010262572e-36 0) 1594: (424 152 32672 17.002994537353516 3) 1467: (400 152 400 19.750289916992187 3) 1596: (424 152 7176 1.0124003054161436e-39 0) 1602: (400 152 400 18.500289916992188 3) 1547: (424 152 7000 1.0124003054161436e-39 0) 1605: (400 152 400 20.500289916992188 3) 1478: (424 152 42256 -6.0222748507426518e+30 222) 1719: (400 152 400 6.2537390010262572e-36 0) 1617: (424 152 16472 1.0124283313854301e-39 0) 1492: (400 152 400 6.2537390010262572e-36 0) 1622: (424 152 35304 1.0123190301052127e-39 0) 1628: (400 152 400 6.2537390010262572e-36 0) 1502: (424 152 63152 19.627988815307617 3) 1632: (400 152 400 19.375289916992188 3) 1468: (424 152 38088 1.0124213248931084e-39 0) 1642: (400 152 400 6.2537390010262572e-36 0) 1518: (424 152 63896 1.0127436235399031e-39 0) 1647: (400 152 400 6.2537390010262572e-36 0) 1650: (424 152 53424 16.752857208251953 3) 1651: (400 152 400 19.250289916992188 3) 1653: (424 152 50624 1.0126497365427934e-39 0) 1532: (400 152 400 6.2537390010262572e-36 0)} The keys come out fine the values are screwed up. I tried same thing loading file in binary mode; didn't fix the problem. Any idea what I'm doing wrong? Edit: Here's the code with binary. Note that the values are different in the unpickled object. >>> idmapfile = open(""idmap"" mode=""wb"") >>> pickle.dump(idMap idmapfile) >>> idmapfile.close() >>> idmapfile = open(""idmap"" mode=""rb"") >>> unpickled = pickle.load(idmapfile) >>> unpickled==idMap False >>> unpickled[1] {1537: (12176 2281 56700 -1.0808743559293829e+18 152) 1540: (0 0 15934 2.7457842047810522e+26 108) 1544: (400 152 400 4.9518498821046956e+27 53) 1675: (408 152 408 2.7201111331839077e+26 34) 1550: (456 152 456 -1.1349175514578289e+18 152) 1424: (432 152 432 4.5939047815653343e-40 11) 1681: (408 152 408 2.1299736657737219e-43 0) 1560: (376 152 376 2.1299736657737219e-43 0) 1690: (376 152 376 2.1299736657737219e-43 0) 1435: (376 152 376 2.1299736657737219e-43 0) 1436: (376 152 376 2.1299736657737219e-43 0) 1434: (376 152 376 2.1299736657737219e-43 0) 1441: (376 152 376 2.1299736657737219e-43 0) 1691: (376 152 376 2.1299736657737219e-43 0) 1444: (376 152 376 2.1299736657737219e-43 0) 1606: (25784 2281 376 -3.2883343074537754e+26 34) 1575: (24240 2281 376 2.1299736657737219e-43 0) 1586: (24240 2281 376 2.1299736657737219e-43 0) 1716: (24240 2281 376 -3.0093091599657311e-35 26) 1590: (24240 2281 376 2.1299736657737219e-43 0) 1463: (24240 2281 376 2.1299736657737219e-43 0) 1594: (24240 2281 376 -4123208450048.0 196) 1467: (25784 2281 376 2.1299736657737219e-43 0) 1596: (25784 2281 376 2.1299736657737219e-43 0) 1602: (25784 2281 376 -5.9963281433905448e+26 76) 1547: (25784 2281 376 -218106240.0 139) 1605: (25784 2281 376 -3.7138649803377281e+27 56) 1478: (376 152 376 2.1299736657737219e-43 0) 1719: (25784 2281 376 2.1299736657737219e-43 0) 1617: (25784 2281 376 -1.4411779941597184e+17 237) 1492: (25784 2281 376 2.8596493694487798e-30 80) 1622: (25784 2281 376 184686084096.0 93) 1628: (1336 152 1336 3.1691839245470052e+29 179) 1502: (1272 152 1272 -5.2042207205116645e-17 99) 1632: (1208 152 1208 2.1299736657737219e-43 0) 1468: (1144 152 1144 2.1299736657737219e-43 0) 1642: (1080 152 1080 2.1299736657737219e-43 0) 1518: (1016 152 1016 4.0240902787680023e+35 145) 1647: (952 152 952 -985172619034624.0 237) 1650: (888 152 888 12094787289088.0 66) 1651: (824 152 824 2.1299736657737219e-43 0) 1653: (760 152 760 0.00018310768064111471 238) 1532: (696 152 696 8.8978061885676389e+26 125)} OK I've isolated the problem but don't know why it's so. First apparently what I'm pickling are not tuples (though they look like it) but instead numpy.void types. Here is a series to illustrate the problem. first = run0.detections[0] >>> first (1 19 1578 82.637763977050781 1) >>> type(first) <type 'numpy.void'> >>> firstTuple = tuple(first) >>> theFile = open(""pickleTest"" ""w"") >>> pickle.dump(first theFile) >>> theTupleFile = open(""pickleTupleTest"" ""w"") >>> pickle.dump(firstTuple theTupleFile) >>> theFile.close() >>> theTupleFile.close() >>> first (1 19 1578 82.637763977050781 1) >>> firstTuple (1 19 1578 82.637764 1) >>> theFile = open(""pickleTest"" ""r"") >>> theTupleFile = open(""pickleTupleTest"" ""r"") >>> unpickledTuple = pickle.load(theTupleFile) >>> unpickledVoid = pickle.load(theFile) >>> type(unpickledVoid) <type 'numpy.void'> >>> type(unpickledTuple) <type 'tuple'> >>> unpickledTuple (1 19 1578 82.637764 1) >>> unpickledTuple == firstTuple True >>> unpickledVoid == first False >>> unpickledVoid (7936 1705 56700 -1.0808743559293829e+18 152) >>> first (1 19 1578 82.637763977050781 1) show us the same code with binary-mode writing and reading. There is nothing wrong with this code. I tried it out and it worked just fine. I wasn't sure exactly what you were pickling however I used an array of dicts because that looked similar. Works for me in Python 2.4.5 2.5.2 and with the obvious changes in Python 3.0. Please post actual test data for which it fails. Also what version of pickle are you using? pickle or cPickle? idMap is a list of dictionaries where dictionary is int-> tuple object. idMap[1] is available at http://pastebin.com/f44a58355 I'm using pickle not cPickle. I'm using Python 2.6.4 on WindowsXP (r264:75708 Oct 26 2009 08:23:19) [MSC v.1500 32 bit (Intel)] In my response below I used your data with pickle (not cPickle) on both python2.51 (Cygwin) and python3.1 (Windows) using all protocols and it works so pickling will only work with top level module functions and classes and will not pickle class data so if some numpy class code/data are required to produce a representation of the numpy void type pickling isn't going to work as expected. It may be that the numpy package has implemented an internal __repr__ to print the void type as a tuple if this is the case then what you pickled certainly is not going to be what you printed. jottos - if you submit that comment as an answer I'll accept it and close the question. That must be what's happening internally. I'm just wrapping it in a tuple call and the pickling works as expected. Something with your system (filesystem?) ; I would try pickling in binary mode; use dump(idMap idmapfile protocol=2) Did not fix the problem - same result.  So using python31 I made just a small change to your example and it worked fine. Note that I added the ""b"" for binary in the file open's I tried this with all protocols and it worked for each idmapfile = open(""idmap"" mode=""wb"") pickle.dump(idMap idmapfile) idmapfile.close() idmapfile = open(""idmap"" ""rb"") unpickled = pickle.load(idmapfile) print ('they are equal' unpickled == idMap) src> ./pick.py they are equal True  I agree. I think there is a problem with serializing numpy.void example that doesn't work (Python 2.7.3 numpy 1.6.1): import pickle numpy as np my_array = np.array([('hello' 45.5 'world')] dtype=[('a' str 10) ('b' float) ('c' str10)]) my_void = my_array[0] print my_void print pickle.loads(pickle.dumps(my_void)) which will print: ('hello' 45.5 'world') ('\xc0\x00llo' 45.5 'world') The first looks like a tuple but it is actually a numpy.void So to avoid this you can't have numpy.void you should instead wrap your void with numpy.array() or call .tolist() on your numpy.void. Edit: There is a bug in numpy https://github.com/numpy/numpy/pull/3188  so pickling will only work with top level module functions and classes and will not pickle class data so if some numpy class code/data are required to produce a representation of the numpy void type pickling isn't going to work as expected. It may be that the numpy package has implemented an internal repr to print the void type as a tuple if this is the case then what you pickled certainly is not going to be what you printed. Š—– jottos Dec 29 '09 at 18:42",python serialization numpy marshalling pickle111983,A,"python.array versus numpy.array If you are creating a 1d array in Python is there any benefit to using the NumPy package? It all depends on what you plan to do with the array. If all you're doing is creating arrays of simple data types and doing I/O the array module will do just fine. If on the other hand you want to do any kind of numerical calculations the array module doesn't provide any help with that. NumPy (and SciPy) give you a wide variety of operations between arrays and special functions that are useful not only for scientific work but for things like advanced image manipulation or in general anything where you need to perform efficient calculations with large amounts of data. Numpy is also much more flexible e.g. it supports arrays of any type of Python objects and is also able to interact ""natively"" with your own objects if they conform to the array interface.",python numpy601477,A,"Best way to create a NumPy array from a dictionary? I'm just starting with NumPy so I may be missing some core concepts... What's the best way to create a NumPy array from a dictionary whose values are lists? Something like this: d = { 1: [102030]  2: [5060] 3: [100200300400500] } Should turn into something like: data = [ [102030??] [5060???] [100200300400500] ] I'm going to do some basic statistics on each row eg: deviations = numpy.std(data axis=1) Questions: What's the best / most efficient way to create the numpy.array from the dictionary? The dictionary is large; a couple of million keys each with ~20 items. The number of values for each 'row' are different. If I understand correctly numpy wants uniform size so what do I fill in for the missing items to make std() happy? Update: One thing I forgot to mention - while the python techniques are reasonable (eg. looping over a few million items is fast) it's constrained to a single CPU. Numpy operations scale nicely to the hardware and hit all the CPUs so they're attractive. numpy dictionary You can use a structured array to preserve the ability to address a numpy object by a key like a dictionary. import numpy as np dd = {'a':1'b':2'c':3} dtype = eval('[' + ''.join([""('%s' float)"" % key for key in dd.keys()]) + ']') values = [tuple(dd.values())] numpy_dict = np.array(values dtype=dtype) numpy_dict['c'] will now output array([ 3.]) However the resulting array has a nested tuple so it might be slower for some operations.  You don't need to create numpy arrays to call numpy.std(). You can call numpy.std() in a loop over all the values of your dictionary. The list will be converted to a numpy array on the fly to compute the standard variation. The downside of this method is that the main loop will be in python and not in C. But I guess this should be fast enough: you will still compute std at C speed and you will save a lot of memory as you won't have to store 0 values where you have variable size arrays. If you want to further optimize this you can store your values into a list of numpy arrays so that you do the python list -> numpy array conversion only once. if you find that this is still too slow try to use psycho to optimize the python loop. if this is still too slow try using Cython together with the numpy module. This Tutorial claims impressive speed improvements for image processing. Or simply program the whole std function in Cython (see this for benchmarks and examples with sum function ) An alternative to Cython would be to use SWIG with numpy.i. if you want to use only numpy and have everything computed at C level try grouping all the records of same size together in different arrays and call numpy.std() on each of them. It should look like the following example. example with O(N) complexity: import numpy list_size_1 = [] list_size_2 = [] for row in data.itervalues(): if len(row) == 1: list_size_1.append(row) elif len(row) == 2: list_size_2.append(row) list_size_1 = numpy.array(list_size_1) list_size_2 = numpy.array(list_size_2) std_1 = numpy.std(list_size_1 axis = 1) std_2 = numpy.std(list_size_2 axis = 1) I'm doing the numpy.std in a loop now and you're right the memory savings are important. I would like to at least do a speed comparison with the numpy version though. The problem is that numpy.std() was made to accept only fix size array. So the only way I see to do this test is to group all the records of same size together and call numpy.std() on each of them. Shouldn't CPython really be Cython? Have I got it wrong? Yes correct. Fixed. Grouping same sized records simple but effective. I like it.  While there are already some pretty reasonable ideas present here I believe following is worth mentioning. Filling missing data with any default value would spoil the statistical characteristics (std etc). Evidently that's why Mapad proposed the nice trick with grouping same sized records. The problem with it (assuming there isn't any a priori data on records lengths is at hand) is that it involves even more computations than the straightforward solution: at least O(N*logN) 'len' calls and comparisons for sorting with an effective algorithm O(N) checks on the second way through the list to obtain groups(their beginning and end indexes on the 'vertical' axis) Using Psyco is a good idea (it's strikingly easy to use so be sure to give it a try). It seems that the optimal way is to take the strategy described by Mapad in bullet #1 but with a modification - not to generate the whole list but iterate through the dictionary converting each row into numpy.array and performing required computations. Like this: for row in data.itervalues(): np_row = numpy.array(row) this_row_std = numpy.std(np_row) # compute any other statistic descriptors needed and then save to some list In any case a few million loops in python won't take as long as one might expect. Besides this doesn't look like a routine computation so who cares if it takes extra second/minute if it is run once in a while or even just once. A generalized variant of what was suggested by Mapad: from numpy import array mean std def get_statistical_descriptors(a): if ax = len(shape(a))-1 functions = [mean std] return f(a axis = ax) for f in functions def process_long_list_stats(data): import numpy groups = {} for key row in data.iteritems(): size = len(row) try: groups[size].append(key) except KeyError: groups[size] = ([key]) results = [] for gr_keys in groups.itervalues(): gr_rows = numpy.array([data[k] for k in gr_keys]) stats = get_statistical_descriptors(gr_rows) results.extend( zip(gr_keys zip(*stats)) ) return dict(results) Thanks Maleev this is essentially what I ended up doing. One thing I forgot to mention - while looping in Python is fast I believe I'm only using a single CPU with this method. Matrix operations hit all CPUs so they're attractive. Why would you need to sort the rows before grouping vectors by length? Only grouping is needed. Moreover I would be careful with the big O notation: here N ~ 1000000 but the speed between a Python and C program can be ~100 times slower. So N -> 1000 is not really tending to the infinity 2 Parand: You're right taking multi-threading into account does really make sense. 2 Mapad: If I'm not terribly mistaken grouping is essentially equivalent to sorting. How then do you suggest to group them? Python code whether it is just loop over the rows or grouping is executed in any of the cases. So talking exclusively of python code's asymptotic complexity we've got difference in p*O(NlogN) - p*O(N) = p*O(NlogN). Besides C code looping through rows inside groups adds up c*O(N) to it. You say c << p. Sure. But that still leaves that p*O(NlogN) difference. Unless you prove you can really do grouping in O(N) in average and worst case. I agree with your simplifications I just want to recall they assume N >> p (p being computation time introduced by Python loop compared to C loop to process a record). Since all process here take O(N) (see my example) I would not throw away the p with the big O notation to check complexity",python numpy1350174,A,"What does matrix**2 mean in python/numpy? I have a python ndarray temp in some code I'm reading that suffers this: x = temp**2 Is this the dot square (ie equivalent to m.*m) or the matrix square (ie m must be a square matrix)? In particular I'd like to know whether I can get rid of the transpose in this code: temp = num.transpose(whatever) num.sum(temp**2axis=1)) and turn it into this: num.sum(whatever**2axis=0) That will save me at least 0.1ms and is clearly worth my time. Thanks! The ** operator is ungooglable and I know nothing! a ** is the raise-to-power operator in Python so x**2 means ""x squared"" in Python -- including numpy. Such operations in numpy always apply element by element so x**2 squares each element of array x (whatever number of dimensions) just like say x*2 would double each element or x+2 would increment each element by two (in each case x proper is unaffected -- the result is a new temporary array of the same shape as x!). Edit: as @kaizer.ze points out while what I wrote holds for numpy.array objects it doesn't apply to numpy.matrix objects where multiplication means matrix multiplication rather than element by element operation like for array (and similarly for raising to power) -- indeed that's the key difference between the two types. As the Scipy tutorial puts it for example: When we use numpy.array or numpy.matrix there is a difference. A*x will be in the latter case matrix product not elementwise product as with array. i.e. as the numpy reference puts it: A matrix is a specialized 2-d array that retains its 2-d nature through operations. It has certain special operators such as * (matrix multiplication) and ** (matrix power). Well it is sadly not so simple as I answered; the differing behaviors of `array` and `matrix` can confuse this and operators such as `*` and `**` change meaning! (If A * B is matrix multiplication whith A B matrix A**2 has to be matrix exponentiation of course.) Yes there's a difference between matrix and array -- though `**` is of course still the raise-to-power operation operations on a matrix apply to ""the matrix"" on an array to ""the elements"". Good point let me edit to clarify.  You should read NumPy for Matlab Users. The elementwise power operation is mentioned there and you can also see that in numpy some operators apply differently to array and matrix. >>> from numpy import * >>> a = arange(4).reshape((22)) >>> print a**2 [[0 1] [4 9]] >>> print matrix(a)**2 [[ 2 3] [ 6 11]]  It's just the square of each element. from numpy import * a = arange(4).reshape((22)) print a**2 prints [[0 1] [4 9]] Woot thanks. Fifteeeeenherewecome. You're welcome. (I signed back into point out the probably obvious note that if you're ndarray are >2 dimensions I don't think the transposing axis swapping thing will work.) I can see where this might be confusing. Without knowing Python and understanding that for real (and complex) numbers squaring means ""multiply a number by itself"" it would have been reasonable to assume that it meant ""multiply a matrix by itself"" for matricies. This means that the matrix has equal numbers of rows and columns of course.",python numpy1579218,A,"numpy.extract and numpy.any functions is it possible to make it simpler way? If there is any possibility to make this code simpler I'd really appreciate it! I am trying to get rid of rows with zeros. The first column is date. If all other columns are zero they have to be deleted. Number of columns varies. import numpy as np condition = [ np.any( list(x)[1:] ) for x in r] r = np.extract( condition r ) numpy.extract docs seems simple enough to me. what are you not happy about? just felt that for ndarray had to be a better way conversion to list and then list comprehension looked weird You can avoid the list comprehension and instead use fancy indexing: #!/usr/bin/env python import numpy as np import datetime r=np.array([(datetime.date(200011)01) (datetime.date(200011)11) (datetime.date(200011)10) (datetime.date(200011)00) ]) r=r[r[:1:].any(axis=1)] print(r) # [[2000-01-01 0 1] # [2000-01-01 1 1] # [2000-01-01 1 0] if r is an ndarray then r[:1:] is a view with the first column removed. r[:1:].any(axis=1) is a boolean array which you can then use as a ""fancy index"" Beautiful! I like it. Ugh I can't read this. Please format as ""Code Sample"". Edit your text select the code and click on the button that looks like ""101/010"". This is a promising answer but I don't think it is quite correct yet. He wants rows compressed if they are *all* zeroes not if any single value is zero. Okay I've modified my code per steveha's comment absolutely what I needed thanks a lot should have known ndarray indexing better!",python numpy1208118,A,"Using numpy to build an array of all combinations of two arrays I'm trying to run over the parameters space of a 6 parameter function to study it's numerical behavior before trying to do anything complex with it so I'm searching for a efficient way to do this. My function takes float values given a 6-dim numpy array as input. What I tried to do initially was this: 1) First I created a function that takes 2 arrays and generate an array with all combinations of values from the two arrays from numpy import * def comb(ab): c = [] for i in a: for j in b: c.append(r_[ij]) return c The I used reduce to apply that to m copies of the same array: def combs(am): return reduce(comb[a]*m) And then I evaluate my function like this: values = combs(np.arange(010.1)6) for val in values: print F(val) This works but it's waaaay too slow. I know the space of parameters is huge but this shouldn't be so slow. I have only sampled (10)^6 = a million points in this example and it took more then 15 seconds just to create the array 'values'. Do you know any more efficient way of doing this with numpy? I can modify the way the function F take it's arguments if it's necessary. itertools.combinations is in general the fastest way to get combinations from a Python container (if you do in fact want combinations i.e. arrangements WITHOUT repetitions and independent of order; that's not what your code appears to be doing but I can't tell whether that's because your code is buggy or because you're using the wrong terminology). If you want something different than combinations perhaps other iterators in itertools product or permutations might serve you better. For example it looks like your code is roughly the same as: for val in itertools.product(np.arange(0 1 0.1) repeat=6): print F(val) All of these iterators yield tuples not lists or numpy arrays so if your F is picky about getting specifically a numpy array you'll have to accept the extra overhead of constructing or clearing and re-filling one at each step. Thanks. This is exactly what I needed. I'm still not used to some python concepts like iterators. @Rafael glad to know I've been of help!  It looks like you want a grid to evaluate your function in which case you can use numpy.ogrid (open) or numpy.mgrid (fleshed out): import numpy my_grid = numpy.mgrid[[slice(010.1)]*6]  You can do something like this import numpy as np def cartesian_coord(*arrays): grid = np.meshgrid(*arrays) coord_list = [entry.ravel() for entry in grid] points = np.vstack(coord_list).T return points a = np.arange(4) # fake data print(cartesian_coord(*6*[a]) which gives array([[0 0 0 0 0 0] [0 0 0 0 0 1] [0 0 0 0 0 2] ... [3 3 3 3 3 1] [3 3 3 3 3 2] [3 3 3 3 3 3]])  The following numpy implementation should be approx. 2x the speed of the given answer: def cartesian2(arrays): arrays = [np.asarray(a) for a in arrays] shape = (len(x) for x in arrays) ix = np.indices(shape dtype=int) ix = ix.reshape(len(arrays) -1).T for n arr in enumerate(arrays): ix[: n] = arrays[n][ix[: n]] return ix  Here's a pure-numpy implementation. It's ca. 5’ã faster than using itertools.  import numpy as np def cartesian(arrays out=None): """""" Generate a cartesian product of input arrays. Parameters ---------- arrays : list of array-like 1-D arrays to form the cartesian product of. out : ndarray Array to place the cartesian product in. Returns ------- out : ndarray 2-D array of shape (M len(arrays)) containing cartesian products formed of input arrays. Examples -------- >>> cartesian(([1 2 3] [4 5] [6 7])) array([[1 4 6] [1 4 7] [1 5 6] [1 5 7] [2 4 6] [2 4 7] [2 5 6] [2 5 7] [3 4 6] [3 4 7] [3 5 6] [3 5 7]]) """""" arrays = [np.asarray(x) for x in arrays] dtype = arrays[0].dtype n = np.prod([x.size for x in arrays]) if out is None: out = np.zeros([n len(arrays)] dtype=dtype) m = n / arrays[0].size out[:0] = np.repeat(arrays[0] m) if arrays[1:]: cartesian(arrays[1:] out=out[0:m1:]) for j in xrange(1 arrays[0].size): out[j*m:(j+1)*m1:] = out[0:m1:] return out Nice Pauli this solves my 2D interpolation problem. Defining the data point coords for griddata was giving some trouble. Does this function make into the master numpy code? why not creat `out` with `np.ndarray` that saves time. ever consider submitting this to be included in numpy? this is not the first time I've gone looking for this functionality and found your post. This rocks! Saved me some real time! Thanks There is bug in this implementation. For arrays of strings for example: arrays[0].dtype = ""|S3"" and arrays[1].dtype = ""|S5"". So there is a need in finding the longest string in input and use its type in out = np.zeros([n len(arrays)] dtype=dtype) Can I just say thank you so much. Thats like 2 hours of my time I could have saved had I gotten here first. FYI: seems to have made it into the scikit-learn package at `from sklearn.utils.extmath import cartesian`",python arrays multidimensional-array numpy1382846,A,How can I create a numpy array holding values of a multi-variable function? I want to create an array holding a function f(xyz). If it were a function of one variable I'd do for instance: sinx = numpy.sin(numpy.linspace(-55100)) to get sin(x) for x in [-55] How can I do the same to get for instance sin(x+y+z)? What would be the values for xyz and/or how do you plan to generate them? xyz would be the cartesian product of `numpy.linspace(-55100)` over all three dimensions. I don't know the best way to generate them. I guess that's a pre-requisite for the question. xyz = numpy.mgrid[-5:5-5:5-5:5] sinxyz = numpy.sin(xyz[0]+xyz[1]+xyz[2])  I seem to have found a way: # define the range of xyz x_range = numpy.linspace(x_minx_maxx_num) y_range = numpy.linspace(y_miny_maxy_num) z_range = numpy.linspace(z_minz_maxz_num) # create arrays xyz in the correct dimensions # so that they create the grid xyz = numpy.ix_(x_rangey_rangez_range) # calculate the function of x y and z sinxyz = numpy.sin(x+y+z)  The numpy.mgrid function would work equally well: xyz = numpy.mgrid[x_min:x_max:x_num y_min:y_max:y_num z_min:z_max:z_num] sinxyz = numpy.sin(x+y+z) edit: to get it to work x_num y_num and z_num have to be explicit numbers followed by j e.g. xy = numpy.mgrid[-1:1:10j -1:1:10j],python function multidimensional-array numpy1055131,A,"How to modify a NumPy.recarray using its two views I am new to Python and Numpy and I am facing a problem that I can not modify a numpy.recarray when applying to masked views. I read recarray from a file then create two masked views then try to modify the values in for loop. Here is an example code. import numpy as np import matplotlib.mlab as mlab dat = mlab.csv2rec(args[0] delimiter=' ') m_Obsr = dat.is_observed == 1 m_ZeroScale = dat[m_Obsr].scale_mean < 0.01 for d in dat[m_Obsr][m_ZeroScale]: d.scale_mean = 1.0 But when I print the result newFile = args[0] + "".no-zero-scale"" mlab.rec2csv(dat[m_Obsr][m_ZeroScale] newFile delimiter=' ') All the scale_means in the files are still zero. I must be doing something wrong. Is there a proper way of modifying values of the view? Is it because I am applying two views one by one? Thank you. I think you have a misconception in this term ""masked views"" and should (re-)read The Book (now freely downloadable) to clarify your understanding. I quote from section 3.4.2: Advanced selection is triggered when the selection object obj is a non-tuple sequence object an ndarray (of data type integer or bool) or a tuple with at least one sequence object or ndarray (of data type integer or bool). There are two types of advanced indexing: integer and Boolean. Advanced selection always returns a copy of the data (contrast with basic slicing that returns a view). What you're doing here is advanced selection (of the Boolean kind) so you're getting a copy and never binding it anywhere -- you make your changes on the copy and then just let it go away then write a new fresh copy from the original. Once you understand the issue the solution should be simple: make your copy once make your changes on that copy and write that same copy. I.e.: dat = mlab.csv2rec(args[0] delimiter=' ') m_Obsr = dat.is_observed == 1 m_ZeroScale = dat[m_Obsr].scale_mean < 0.01 the_copy = dat[m_Obsr][m_ZeroScale] for d in the_copy: d.scale_mean = 1.0 newFile = args[0] + "".no-zero-scale"" mlab.rec2csv(the_copy newFile delimiter=' ') Yes you were right I did not realise I am doing an advanced selection and that the later returns a temporary copy. And my understanding of ""masked views"" is indeed very hazy. Thank you for the quote. I was reading the same section 3 earlier but did not get to this Î_. Your fix will work. Though my question whether it is possible to modify the original data in dat without taking a copy of the part of the array. I need the order of the original to be preserved while modify only subset. Will simple iterative approach work? Or is there anything nicer? To modify dat itself I know nothing nicer than the ""simple iterative approach"" (generally on the .flat view as that IS indeed a view!-). BTW SO etiquette is that you upvote good answers and accept one that does answer your question or fix your problem -- since you comment ""your fix will work"" by that etiquette you should upvote and accept (and probably open another question specifically about selective modification in the main array itself -- somebody might give you a better approach than iteration if they saw that question but may not notice the question if you just ask it in a comment!) I did accept the solution because it is indeed the solution to the described problem. I can't up-vote as I don't have enough rating yet :). Thank you for your interest in the problem.",python numpy matplotlib1687566,A,"Why does an assignment for double-sliced numpy arrays not work? why do the following lines not work as I expect? import numpy as np a = np.array([01211]) a[a==1][1:] = 3 print a >>> [0 1 2 1 1] # I would expect [0 1 2 3 3] Is this a 'bug' or is there another recommended way to this? On the other hand the following works: a[a==1] = 3 print a >>> [0 3 2 3 3] Cheers Philipp It appears you simply can't do an assignment through a double-slice like that. This works though: a[numpy.where(a==1)[0][1:]] = 3  This does what you want a[2:][a[2:]==1]=3 But that requires knowing in advance that the first occurrence of 1 is at position 1.  Because the a[a==1] part isn't actually a slice. It creates a new array. It makes sense when you think about it-- you're only taking the elements that satisfy the boolean condition (like a filter operation). @tom10 - It's not a ""hack"". It's part of the implementation of the array class. Behavior is documented for instance here: http://www.scipy.org/Tentative_NumPy_Tutorial#head-864862d3f2bb4c32f04260fac61eb4ef34788c4c. ""Slicing an array returns a view of it"" i.e. not a copy. normal list works that way too -- you can assign to slices (only with iterables) `l = range(10); l[5:] = range(5)` @Dave - Certainly a slice in numpy is a view but a[a==1] is not a slice and not a view. I added a second example that works like I expect. I don't really see the difference. Shouldn't the assignment being ""piped through""? I don't think this is quite right. If you do `a[a==1] = 3` that actually changes the contents of a. @Dave - I think this is perimosocodiae is correct and that your counter-example is due to something more like a hack in the numpy internals to create the appearance of an in-place operation.  It's related to how fancy indexing works. There is a thorough explanation here. It is done this way to allow inplace modification with fancy indexing (ie a[x>3] *= 2). A consequence of this is that you can't assign to a double index as you have found. Fancy indexing always returns a copy rather than a view. Actually your solution modifies the first occurrence of 1 which is not what he wants. Right - took it off before your comment. Ps hi Philip it's Robin! Hey Robin - what chance is that to meet here... Cheers from munich!",python numpy variable-assignment slicing1698036,A,"Convert little endian string to integer I have read samples out of a wave file using the wave module but it gives the samples as a string it's out of wave so it's little endian (for example '`\x00'). What is the easiest way to convert this into a python integer or a numpy.int16 type? (It will eventually become a numpy.int16 so going directly there is fine). Code needs to work on little endian and big endian processors. The general case is: http://stackoverflow.com/questions/444591/convert-a-string-of-bytes-into-an-int-python struct is fine if you have to convert one or a small number of 2-byte strings to integers but array and numpy itself are better options. Specifically numpy.fromstring (called with the appropriate dtype argument) can directly convert the bytes from your string to an array of (whatever that dtype is). (If numpy.little_endian is false you'll then have to swap the bytes -- see here for more discussion but basically you'll want to call the byteswap method on the array object you just built with fromstring). This is really good to know as well I'm going to go with the struct solution though so that I don't need to worry about correcting endianess manually. If you're in no hurry or have very few data points that's fine. Otherwise you _can_ codify endianness as a string as part of the `dtype` (I don't know the details offhand though).  The struct module converts packed data to Python values and vice-versa. >>> import struct >>> struct.unpack(""<h"" ""\x00\x05"") (1280) >>> struct.unpack(""<h"" ""\x00\x06"") (1536) >>> struct.unpack(""<h"" ""\x01\x06"") (1537) ""h"" means a short int or 16-bit int. ""<"" means use little-endian.",python numpy wav1735025,A,"How to normalize a NumPy array to within a certain range? After doing some processing on an audio or image array it needs to be normalized within a range before it can be written back to a file. This can be done like so: # Normalize audio channels to between -1.0 and +1.0 audio[:0] = audio[:0]/abs(audio[:0]).max() audio[:1] = audio[:1]/abs(audio[:1]).max() # Normalize image to between 0 and 255 image = image/(image.max()/255.0) Is there a less verbose convenience function way to do this? matplotlib.colors.Normalize() doesn't seem to be related. You can also rescale using sklearn. The advantages are that you can adjust normalize the standard deviation in addition to mean-centering the data and that you can do this on either axis by features or by records. from sklearn.preprocessing import scale X = scale( X axis=0 with_mean=True with_std=True copy=True ) The keyword arguments axis with_mean with_std are self explanatory and are shown in their default state. The argument copy performs the operation in-place if it is set to False. Documentation here.  You can use the ""i"" (as in idiv imul..) version and it doesn't look half bad: image /= (image.max()/255.0) For the other case you can write a function to normalize an n-dimensional array by colums: def normalize_columns(arr): rows cols = arr.shape for col in xrange(cols): arr[:col] /= abs(arr[:col]).max() Can you clarify this? The parentheses make it behave differently than without? @endolith: I think I was first but that doesn't matter. Accept the answer you like the most. parantheses don't change anything. the point was to use `/=` instead of `= .. / .. ` Oh you just both answered with the same thing at the same time?  audio /= np.max(np.abs(audio)axis=0) image *= (255.0/image.max()) Using /= and *= allows you to eliminate an intermediate temporary array thus saving some memory. Multiplication is less expensive than division so image *= 255.0/image.max() # Uses 1 division and image.size multiplications is marginally faster than image /= image.max()/255.0 # Uses 1+image.size divisions Since we are using basic numpy methods here I think this is about as efficient a solution in numpy as can be. Why is multiplication less expensive than division? I don't know exactly why. However I am confident of the claim having checked it with timeit. With multiplication you can work with one digit at a time. With division especially with large divisors you have to work with many digits and ""guess"" how many times the divisor goes into the dividend. You end up doing many multiplication problems to solve one division problem. The computer algorithm for doing division may not be the same as human long division but nevertheless I believe it's more complicated than multiplication. Probably worth mentioning a divide by zero for blank images.",python arrays numpy scipy convenience-methods1799527,A,Numpy - show decimal values in array results how do I calculate that an array of python numpy or me of all the calculate decimals and not skip like. >> A = numpy.array ([[123] [456] [789]]). >> C = numpy.array ([[789] [123] [456]]). >> A / C array ([[0 0 0] [4 2 2] [1 1 1]]) but in the first vector would not have to be given to absolute zero [0.143 0.250 0.333] This is an English speaking forum. Your title needs editing to be in English. Hola Ricardo el t’_tulo en ingl’©s por favor. :-) I have no idea what the question is about I hope I translated correctly :) hello excuse was a mistake not happen again Try converting one of the arrays A or C into an array of floats. For instance: A = A * 1.0 Then the division will be floating point division.  Numpy arrays may have different types. You may also create a float array it will always divide correctly: >>> A = numpy.array ([[123] [456] [789]] dtype=float) >>> A/2 array([[ 0.5 1.  1.5] [ 2.  2.5 3. ] [ 3.5 4.  4.5]]) Notice the dtype= argument to numpy.array  To avoid integer division use numpy.true_divide(AC). You can also put from __future__ import division at the top of the file to default to this behavior. thanks for response,python numpy1550130,A,"""Cloning"" row or column vectors Sometimes it is useful to ""clone"" a row or column vector to a matrix. By cloning I mean converting a row vector such as [123] Into a matrix [[123] [123] [123] ] or a column vector such as [1 2 3 ] into [[111] [222] [333] ] In matlab or octave this is done pretty easily:  x = [123] a = ones(31) * x a = 1 2 3 1 2 3 1 2 3 b = (x') * ones(13) b = 1 1 1 2 2 2 3 3 3 I want to repeat this in numpy but unsuccessfully In [14]: x = array([123]) In [14]: ones((31)) * x Out[14]: array([[ 1. 2. 3.] [ 1. 2. 3.] [ 1. 2. 3.]]) # so far so good In [16]: x.transpose() * ones((13)) Out[16]: array([[ 1. 2. 3.]]) # DAMN # I end up with In [17]: (ones((31)) * x).transpose() Out[17]: array([[ 1. 1. 1.] [ 2. 2. 2.] [ 3. 3. 3.]]) Why wasn't the first method (In[16]) working? Is there a way to achieve this task in python in a more elegant way? In Matlab note that it is much faster to use `repmat`: `repmat([1 2 3]31)` or `repmat([1 2 3].'13)` Octave also has `repmat`. First note that with numpy's broadcasting operations it's usually not necessary to duplicate rows and columns. See this and this for descriptions. But to do this repeat and newaxis are probably the best way In [12]: x = array([123]) In [13]: repeat(x[:newaxis] 3 1) Out[13]: array([[1 1 1] [2 2 2] [3 3 3]]) In [14]: repeat(x[newaxis:] 3 0) Out[14]: array([[1 2 3] [1 2 3] [1 2 3]]) This example is for a row vector but applying this to a column vector is hopefully obvious. repeat seems to spell this well but you can also do it via multiplication as in your example In [15]: x = array([[1 2 3]]) # note the double brackets In [16]: (ones((31))*x).transpose() Out[16]: array([[ 1. 1. 1.] [ 2. 2. 2.] [ 3. 3. 3.]]) @AFoglia - Good point. I updated my answer to point this out. newaxis has the additional benefit that it doesn't actually copy the data until it needs to. So if you are doing this to multiply or add to another 3x3 array the repeat is unnecessary. Read up on numpy broadcasting to get the idea.  Here's an elegant Pythonic way to do it: >>> array([[123]]*3) array([[1 2 3] [1 2 3] [1 2 3]]) >>> array([[123]]*3).transpose() array([[1 1 1] [2 2 2] [3 3 3]]) the problem with [16] seems to be that the transpose has no effect for an array. you're probably wanting a matrix instead: >>> x = array([123]) >>> x array([1 2 3]) >>> x.transpose() array([1 2 3]) >>> matrix([123]) matrix([[1 2 3]]) >>> matrix([123]).transpose() matrix([[1] [2] [3]]) (transpose works for 2D arrays e.g. for the square one in the example or when turning into a `(N1)`-shape array using `.reshape(-1 1)`)  I think using the broadcast in numpy is the best and faster I did a compare as following import numpy as np b = np.random.randn(1000) In [105]: %timeit c = np.tile(b[: newaxis] (1100)) 1000 loops best of 3: 354 Îµs per loop In [106]: %timeit c = np.repeat(b[: newaxis] 100 axis=1) 1000 loops best of 3: 347 Îµs per loop In [107]: %timeit c = np.array([b]*100).transpose() 100 loops best of 3: 5.56 ms per loop about 15 times faster using broadcast  Use numpy.tile: >>> tile(array([123]) (3 1)) array([[1 2 3] [1 2 3] [1 2 3]]) or for repeating columns: >>> tile(array([[123]]).transpose() (1 3)) array([[1 1 1] [2 2 2] [3 3 3]]) Upvote! On my system for a vector with 10000 elements repeated 1000 times the `tile` method is 19.5 times faster than the method in the currently accepted answer (using the multiplication-operator-method).",python matlab numpy octave linear-algebra1642730,A,"How to delete columns in numpy.array I would like to delete selected columns in a numpy.array . This is what I do: n [397]: a = array([[ NaN 2. 3. NaN] .....: [ 1. 2. 3. 9]]) In [398]: print a [[ NaN 2. 3. NaN] [ 1. 2. 3. 9.]] In [399]: z = any(isnan(a) axis=0) In [400]: print z [ True False False True] In [401]: delete(a z axis = 1) Out[401]: array([[ 3. NaN] [ 3. 9.]]) In this example my goal is to delete all the columns that contain NaN's. I expect the last command to result in: array([[2. 3.] [2. 3.]]) How can I do that? From Numpy Documentation np.delete(arr obj axis=None) Return a new array with sub-arrays along an axis deleted. >>> arr array([[ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]]) >>> np.delete(arr 1 0) array([[ 1 2 3 4] [ 9 10 11 12]]) >>> np.delete(arr np.s_[::2] 1) array([[ 2 4] [ 6 8] [10 12]]) >>> np.delete(arr [135] None) array([ 1 3 5 7 8 9 10 11 12])  Another way is to use masked arrays: import numpy as np a = np.array([[ np.nan 2. 3. np.nan] [ 1. 2. 3. 9]]) print(a) # [[ NaN 2. 3. NaN] # [ 1. 2. 3. 9.]] The np.ma.masked_invalid method returns a masked array with nans and infs masked out: print(np.ma.masked_invalid(a)) [[-- 2.0 3.0 --] [1.0 2.0 3.0 9.0]] The np.ma.compress_cols method returns a 2-D array with any column containing a masked value suppressed: a=np.ma.compress_cols(np.ma.masked_invalid(a)) print(a) # [[ 2. 3.] # [ 2. 3.]] See manipulating-a-maskedarray  This creates another array without those columns:  b = a.compress(logical_not(z) axis=1) cool. I wish matlab's syntax worked here: ""a(:z) = []"" is much simpler similar: b = a[:[12]] @bpowah: indeed. the more general way would be b = a[:z]. You might want to update your answer accordingly  Given its name I think the standard way should be delete: A = scipy.delete(A 1 0) # delete second row of A B = scipy.delete(B 2 0) # delete third row of B C = scipy.delete(C 1 1) # delete second column of C  In your situation you can extract the desired data with: a[: -z] ""-z"" is the logical negation of the boolean array ""z"". This is the same as: a[: logical_not(z)]  From HERE a=array([[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11] [12 13 14 15]]) delete(a s_[1:3] axis=0) # remove rows 1 and 2 output: array([[ 0 1 2 3] [12 13 14 15]]) delete(a s_[1:3] axis=1) # remove columns 1 and 2 output: array([[ 0 3] [ 4 7] [ 8 11] [12 15]]) Hope that helps",python numpy scipy1929045,A,Implementing tridiagonal matrix algorithm (TDMA) with NumPy I'm implementing TDMA in Python using NumPy. The tridiagonal matrix is stored in three arrays: a = array([...]) b = array([...]) c = array([...]) I'd like to calculate alpha-coefficients efficiently. The algorithm is as follows: # n = size of the given matrix - 1 alpha = zeros(n) alpha[0] = b[0] / c[0] for i in range(n-1): alpha[i+1] = b[i] / (c[i] - a[i] * alpha[i]) However this is not efficient because of Python's for loop. Want I want is something like this approach: # n = size of the given matrix - 1 alpha = zeros(n) alpha[0] = b[0] / c[0] alpha[1:] = b[1:] / (c[1:] - a[1:] * alpha[:-1]) In this latter case the result is incorrect because NumPy stores the right part of the last expression in a temprorary array and then assigns references to its elements to alpha[1:]. Therefore a[1:] * alpha[:-1] is just an array of zeros. Is there a way to tell NumPy to use values of alpha calculated on previous steps within its internal loop? Thanks. this isn't possible. see http://stackoverflow.com/questions/1587367/python-numpy-tricky-slicing-problem for a similar issue. if you really need the speed increase try cython. If its tridiagonal systems you want to solve there is solve_banded() in numpy.linalg. Not sure if that's what you're looking for. i don't think there is any provision for banded matrix solving  in numpy or even in scipy  there is no sp.sparse as far as i know. I think it's my bad  scipy.sparse exists(it doesn't exist on my system  it existsin docs so it must actually exist)  but not solve_banded() in numpy.linalg  may have been when present in 2009  not now.  Apparently there is no way to do this in Python without using C or its pythonic variations.,python numpy numerical-methods318390,A,Running numpy from cygwin I am running a windows machine have installed Python 2.5. I also used the windows installer to install NumPy. This all works great when I run the Python (command line) tool that comes with Python. However if I run cygwin and then run Python from within it cannot find the numpy package. What environment variable do I need to set? What value should it be set to? Cygwin comes with its own version of Python so it's likely that you have two Python installs on your system; one that installed under Windows and one which came with Cygwin. To test this try opening a bash prompt in Cygwin and typing which python to see where the Python executable is located. If it says /cygdrive/c/Python25/python.exe or something similar then you'll know you're running the Windows executable. If you see /usr/local/bin/python or something like that then you'll know that you're running the Cygwin version. I recommend opening a DOS prompt and running Python from there when you need interactive usage. This will keep your two Python installs nicely separate (it can be very useful to have both; I do this on my own machine). Also you may have some problems running a program designed for Windows interactive console use from within a Cygwin shell. You were right! This was helpful. Thanks Note: numpy can be installed directly from the Cygwin setup.exe.  numpy built for windows is not compatible with cygwin python. You have to build it by yourself on cygwin.  You're running a separate copy of python provided by cygwin. You can run /cygdrive/c/python25/python (or wherever you installed it) to get your win32 one or just install another copy of numpy.  Ensure that PYTHONPATH has NumPy. Refer The Module Search Path (section 6.1.2) and Modifying Python's Search Path (section 4.1).,python numpy560283,A,"How do you construct an array suitable for numpy sorting? I need to sort two arrays simultaneously or rather I need to sort one of the arrays and bring the corresponding element of its associated array with it as I sort. That is if the array is [(5 33) (4 44) (3 55)] and I sort by the first axis (labeled below dtype='alpha') then I want: [(3.0 55.0) (4.0 44.0) (5.0 33.0)]. These are really big data sets and I need to sort first ( for nlog(n) speed ) before I do some other operations. I don't know how to merge my two separate arrays though in the proper manner to get the sort algorithm working. I think my problem is rather simple. I tried three different methods: import numpy x=numpy.asarray([543]) y=numpy.asarray([334455]) dtype=[('alpha'float) ('beta'float)] values=numpy.array([(x)(y)]) values=numpy.rollaxis(values1) #values = numpy.array(values dtype=dtype) #a=numpy.array(valuesdtype=dtype) #q=numpy.sort(aorder='alpha') print ""Try 1:\n"" values values=numpy.empty((len(x)2)) for n in range (len(x)): values[n][0]=y[n] values[n][1]=x[n] print ""Try 2:\n"" values #values = numpy.array(values dtype=dtype) #a=numpy.array(valuesdtype=dtype) #q=numpy.sort(aorder='alpha') ### values = [(x[0] y[0]) (x[1]y[1])  (x[2]y[2])] print ""Try 3:\n"" values values = numpy.array(values dtype=dtype) a=numpy.array(valuesdtype=dtype) q=numpy.sort(aorder='alpha') print ""Result:\n""q I commented out the first and second trys because they create errors I knew the third one would work because that was mirroring what I saw when I was RTFM. Given the arrays x and y (which are very large just examples shown) how do I construct the array (called values) that can be called by numpy.sort properly? *** Zip works great thanks. Bonus question: How can I later unzip the sorted data into two arrays again? I think you just need to specify the axis that you are sorting on when you have made your final ndarray. Alternatively argsort one of the original arrays and you'll have an index array that you can use to look up in both x and y which might mean you don't need values at all. (scipy.org seems to be unreachable right now or I would post you a link to some docs) Given that your description doesn't quite match your code snippet it's hard to say with certainty but I think you have over-complicated the creation of your numpy array.  I couldn't get a working solution using Numpy's sort function but here's something else that works: import numpy x = [543] y = [334455] r = numpy.asarray([(x[i]y[i]) for i in numpy.lexsort([x])]) lexsort returns the permutation of the array indices which puts the rows in sorted order. If you wanted your results sorted on multiple keys e.g. by x and then by y use numpy.lexsort([xy]) instead.  Simon suggested argsort as an alternative approach; I'd recommend it as the way to go. No messy merging zipping or unzipping: just access by index. idx = numpy.argsort(x) ans = [ (x[idx[i]]y[idx[i]]) for i in idx]  for your bonus question -- zip actually unzips too: In [1]: a = range(10) In [2]: b = range(10 20) In [3]: c = zip(a b) In [4]: c Out[4]: [(0 10) (1 11) (2 12) (3 13) (4 14) (5 15) (6 16) (7 17) (8 18) (9 19)] In [5]: d e = zip(*c) In [6]: d e Out[6]: ((0 1 2 3 4 5 6 7 8 9) (10 11 12 13 14 15 16 17 18 19))  zip() might be inefficient for large arrays. numpy.dstack() could be used instead of zip: ndx = numpy.argsort(x) values = numpy.dstack((x[ndx] y[ndx])) it actually turns out np.take(xndx) is faster than fancy indexing. [http://wesmckinney.com/blog/?p=215](http://wesmckinney.com/blog/?p=215) @user545424: looks interesting. thanks for the link thankyou as far as I can tell this is the fastest answer given (I haven't done any speed tests but I really doubt that building a zip and then unzipping it is the fastest)  I think what you want is the zip function. If you have x = [123] y = [456] then zip(xy) == [(14)(25)(36)] So your array could be constructed using a = numpy.array(zip(xy) dtype=dtype) +1: zip works well with generators so you don't have to create giant in-memory lists you can use generator functions instead. How can I later unzip the sorted data into two arrays again? once you have `a` above you can do `c d = zip(*a)` to unzip.",python algorithm arrays numpy362489,A,How do I add a guard ring to a matrix in NumPy? Using NumPy a matrix A has n rows and m columns and I want add a guard ring to matrix A. That guard ring is all zero. What should I do? Use Reshape? But the element is not enough to make a n+1 m+1 matrix. Or etc.? Thanks in advance I mean an extra ring of cells that always contain 0 surround matrix A.Basically there is a Matrix B has n+2rows m+2columns where the first row and columns and the last row and columns are all zeroand the rest of it are same as matrix A. This is a less general but easier to understand version of Alex's answer: >>> a = numpy.array(range(9)).reshape((33)) >>> a array([[0 1 2] [3 4 5] [6 7 8]]) >>> b = numpy.zeros(a.shape + numpy.array(2) a.dtype) >>> b array([[0 0 0 0 0] [0 0 0 0 0] [0 0 0 0 0] [0 0 0 0 0] [0 0 0 0 0]]) >>> b[1:-11:-1] = a >>> b array([[0 0 0 0 0] [0 0 1 2 0] [0 3 4 5 0] [0 6 7 8 0] [0 0 0 0 0]])  Following up on your comment: >>> import numpy >>> a = numpy.array(range(9)).reshape((33)) >>> b = numpy.zeros(tuple(s+2 for s in a.shape) a.dtype) >>> b[tuple(slice(1-1) for s in a.shape)] = a >>> b array([[0 0 0 0 0] [0 0 1 2 0] [0 3 4 5 0] [0 6 7 8 0] [0 0 0 0 0]]) Wanted to mention that at least with the version of NumPy (1.2.0 release) and Python (2.5.2) I have the conversion to tuple is unnecessary and omitting it appeared to save time in my own limited testing. I forgot you could use slices like this!! Python is like the Feng Shui of programming. And by 'omitting' I mean using [] instead of tuple(). Oops :),python numpy1201817,A,"Adding a field to a structured numpy array What is the cleanest way to add a field to a structured numpy array? Can it be done destructively or is it necessary to create a new array and copy over the existing fields? Are the contents of each field stored contiguously in memory so that such copying can be done efficiently? def add_field(a descr): """"""Return a new array that is like ""a"" but has additional fields. Arguments: a -- a structured numpy array descr -- a numpy type description of the new fields The contents of ""a"" are copied over to the appropriate fields in the new array whereas the new fields are uninitialized. The arguments are not modified. >>> sa = numpy.array([(1 'Foo') (2 'Bar')] \ dtype=[('id' int) ('name' 'S3')]) >>> sa.dtype.descr == numpy.dtype([('id' int) ('name' 'S3')]) True >>> sb = add_field(sa [('score' float)]) >>> sb.dtype.descr == numpy.dtype([('id' int) ('name' 'S3') \ ('score' float)]) True >>> numpy.all(sa['id'] == sb['id']) True >>> numpy.all(sa['name'] == sb['name']) True """""" if a.dtype.fields is None: raise ValueError ""`A' must be a structured numpy array"" b = numpy.empty(a.shape dtype=a.dtype.descr + descr) for name in a.dtype.names: b[name] = a[name] return b  If you're using numpy 1.3 there's also numpy.lib.recfunctions.append_fields(). For many installations you'll need to import numpy.lib.recfunctions to access this. import numpy will not allow one to see the numpy.lib.recfunctions",python numpy773030,A,"Why are 0d arrays in Numpy not considered scalar? Surely a 0d array is scalar but Numpy does not seem to think so... am I missing something or am I just misunderstanding the concept? >>> foo = numpy.array(1.11111111111 numpy.float64) >>> numpy.ndim(foo) 0 >>> numpy.isscalar(foo) False >>> foo.item() 1.11111111111 One should not think too hard about it. It's ultimately better for the mental health and longevity of the individual. The curious situation with Numpy scalar-types was bore out of the fact that there is no graceful and consistent way to degrade the 1x1 matrix to scalar types. Even though mathematically they are the same thing they are handled by very different code. If you've been doing any amount of scientific code ultimately you'd want things like max(a) to work on matrices of all sizes even scalars. Mathematically this is a perfectly sensible thing to expect. However for programmers this means that whatever presents scalars in Numpy should have the .shape and .ndim attirbute so at least the ufuncs don't have to do explicit type checking on its input for the 21 possible scalar types in Numpy. On the other hand they should also work with existing Python libraries that does do explicit type-checks on scalar type. This is a dilemma since a Numpy ndarray have to individually change its type when they've been reduced to a scalar and there is no way of knowing whether that has occurred without it having do checks on all access. Actually going that route would probably make bit ridiculously slow to work with by scalar type standards. The Numpy developer's solution is to inherit from both ndarray and Python scalars for its own scalary type so that all scalars also have .shape .ndim .T etc etc. The 1x1 matrix will still be there but its use will be discouraged if you know you'll be dealing with a scalar. While this should work fine in theory occasionally you could still see some places where they missed with the paint roller and the ugly innards are exposed for all to see: >>> from numpy import * >>> a = array(1) >>> b = int_(1) >>> a.ndim 0 >>> b.ndim 0 >>> a[...] array(1) >>> a[()] 1 >>> b[...] array(1) >>> b[()] array(1) There's really no reason why a[...] and a[()] should return different things but it does. There are proposals in place to change this but looks like they forgot to finish the job for 1x1 arrays. A potentially bigger and possibly non-resolvable issue is the fact that Numpy scalars are immutable. Therefore ""spraying"" a scalar into a ndarray mathematically the adjoint operation of collapsing an array into a scalar is a PITA to implement. You can't actually grow a Numpy scalar it cannot by definition be cast into an ndarray even though newaxis mysteriously works on it: >>> b[0123] = 1 Traceback (most recent call last): File ""<stdin>"" line 1 in <module> TypeError: 'numpy.int32' object does not support item assignment >>> b[newaxis] array([1]) In Matlab growing the size of a scalar is a perfectly acceptable and brainless operation. In Numpy you have to stick jarring a = array(a) everywhere you think you'd have the possibility of starting with a scalar and ending up with an array. I understand why Numpy has to be this way to play nice with Python but that doesn't change the fact that many new switchers are deeply confused about this. Some have explicit memory of struggling with this behaviour and eventually persevering while others who are too far gone are generally left with some deep shapeless mental scar that frequently haunts their most innocent dreams. It's an ugly situation for all. +1 for the philosophical introduction :-) Have you considered a writing side career?  You have to create the scalar array a little bit differently: >>> x = numpy.float64(1.111) >>> x 1.111 >>> numpy.isscalar(x) True >>> numpy.ndim(x) 0 It looks like scalars in numpy may be a bit different concept from what you may be used to from a purely mathematical standpoint. I'm guessing you're thinking in terms of scalar matricies?",python numpy1761419,A,Matlab-like structure 'Cell Array' in Numpy? i try to use create Cell Array in Numpy Anyone have an Information ? Matlab cell arrays are most similar to Python lists since they can hold any object - but scipy.io.loadmat imports them as numpy object arrays - which is an array with dtype=object. To be honest though you are just as well off using Python lists - if you are holding general objects you will loose almost all of the advantages of numpy arrays (which are designed to hold a sequence of values which each take the same amount of memory). Thank thrope!:) The one thing that I am missing by using python lists is the possibility of indexing the array with an array of indexes. Thanks for making me discover numpy object arrays :),python matlab numpy1704823,A,"Initializing numpy matrix to something other than zero or one I have the following code: r = numpy.zeros(shape = (width height 9)) It creates a width x height x 9 matrix filled with zeros. Instead I'd like to know if there's a function or way to initialize them instead to NaN. Is there any? Without having to resort to manually doing loops and such? Thanks One caveat is that NumPy doesn't have an integer NA value (unlike R). See [pandas list of gotchas](http://pandas.pydata.org/pandas-docs/stable/gotchas.html). Hence `np.nan` goes wrong when converted to int. Are you familiar with numpy.nan? You can create your own method such as: def nans(shape dtype=float): a = numpy.empty(shape dtype) a.fill(numpy.nan) return a Then nans([34]) would output array([[ NaN NaN NaN NaN] [ NaN NaN NaN NaN] [ NaN NaN NaN NaN]]) I found this code in a mailing list thread.  You rarely need loops for vector operations in numpy. You can create an uninitialized array and assign to all entries at once: >>> a = numpy.empty((33)) >>> a[:] = numpy.NAN >>> a array([[ NaN NaN NaN] [ NaN NaN NaN] [ NaN NaN NaN]]) I have timed the alternatives a[:] = numpy.nan here and a.fill(numpy.nan) as posted by Blaenk: $ python -mtimeit ""import numpy as np; a = np.empty((100100));"" ""a.fill(np.nan)"" 10000 loops best of 3: 54.3 usec per loop $ python -mtimeit ""import numpy as np; a = np.empty((100100));"" ""a[:] = np.nan"" 10000 loops best of 3: 88.8 usec per loop The timings show a preference for ndarray.fill(..) as the faster alternative. OTOH I like numpy's convenience implementation where you can assign values to whole slices at the time the code's intention is very clear. I agree that your code's intention is clearer. But thanks for the unbiased timings (or rather the fact that you still posted them) I appreciate it :) I like this one: `a = numpy.empty((3 3)) * numpy.nan`. It timed faster than `fill` but slower than the assignment method but it is a oneliner!! Please look at this answer: http://stackoverflow.com/questions/10871220/making-a-matrix-square-and-padding-it-with-desired-value-in-numpy I prefer the `.fill()` method but the difference in speeds reduces to practically nothing as the arrays get larger.",python numpy1408311,A,NumPy array slice using None This had me scratching my head for a while. I was unintentionally slicing an array with None and getting something other than an error (I expected an error). Instead it returns an array with an extra dimension. >>> import numpy >>> a = numpy.arange(4).reshape(22) >>> a array([[0 1] [2 3]]) >>> a[None] array([[[0 1] [2 3]]]) Is this behavior intentional or a side-effect? If intentional is there some rationale for it? Using None is equivalent to using numpy.newaxis so yes it's intentional. In fact they're the same thing but of course newaxis spells it out better. The docs A related SO question.,python arrays numpy1871536,A,"Euclidean distance between points in two different Numpy arrays not within I have two arrays of x-y coordinates and I would like to find the minimum Euclidean distance between each point in one array with all the points in the other array. The arrays are not necessarily the same size. For example: xy1=numpy.array( [[ 243 3173] [ 525 2997]]) xy2=numpy.array( [[ 682 2644] [ 277 2651] [ 396 2640]]) My current method loops through each coordinate xy in xy1 and calculates the distances between that coordinate and the other coordinates. mindist=numpy.zeros(len(xy1)) minid=numpy.zeros(len(xy1)) for ixy in enumerate(xy1): dists=numpy.sqrt(numpy.sum((xy-xy2)**2axis=1)) mindist[i]minid[i]=dists.min()dists.argmin() Is there a way to eliminate the for loop and somehow do element-by-element calculations between the two arrays? I envision generating a distance matrix for which I could find the minimum element in each row or column. Another way to look at the problem. Say I concatenate xy1 (length m) and xy2 (length p) into xy (length n) and I store the lengths of the original arrays. Theoretically I should then be able to generate a n x n distance matrix from those coordinates from which I can grab an m x p submatrix. Is there a way to efficiently generate this submatrix? If you need to speed up your code you should remove the unnecessary numpy.sqrt (and only take the square root of the minimum squared distance when you have found it). For what you're trying to do: dists = numpy.sqrt((xy1[: 0 numpy.newaxis] - xy2[: 0])**2 + (xy1[: 1 numpy.newaxis - xy2[: 1])**2) mindist = numpy.min(dists axis=1) minid = numpy.argmin(dists axis=1) Edit: Instead of calling sqrt doing squares etc. you can use numpy.hypot: dists = numpy.hypot(xy1[: 0 numpy.newaxis]-xy2[: 0] xy1[: 1 numpy.newaxis]-xy2[: 1]) Oh my that's amazing. I did not realize that element-by-element could work that way too. So `xy1[:0numpy.newaxis]` effectively replaces my for loop by being a column vector from which all the *x*-values of `xy2` are subtracted. Very cool thank you. Yes. For a more general and elegant method see Alex's answer. @fideli: help(numpy.subtract.outer) tells you that the numpy.newaxis trick of Alok is what is also at work in Alex's answer.  (Months later) scipy.spatial.distance.cdist( X Y ) gives all pairs of distances for X and Y 2 dim 3 dim ... It also does 22 different norms detailed here . # cdist example: (nxdim) (nydim) -> (nxny) from __future__ import division import sys import numpy as np from scipy.spatial.distance import cdist #............................................................................... dim = 10 nx = 1000 ny = 100 metric = ""euclidean"" seed = 1 # change these params in sh or ipython: run this.py dim=3 ... for arg in sys.argv[1:]: exec( arg ) np.random.seed(seed) np.set_printoptions( 2 threshold=100 edgeitems=10 suppress=True ) title = ""%s dim %d nx %d ny %d metric %s"" % ( __file__ dim nx ny metric ) print ""\n"" title #............................................................................... X = np.random.uniform( 0 1 size=(nxdim) ) Y = np.random.uniform( 0 1 size=(nydim) ) dist = cdist( X Y metric=metric ) # -> (nx ny) distances #............................................................................... print ""scipy.spatial.distance.cdist: X %s Y %s -> %s"" % ( X.shape Y.shape dist.shape ) print ""dist average %.3g +- %.2g"" % (dist.mean() dist.std()) print ""check: dist[03] %.3g == cdist( [X[0]] [Y[3]] ) %.3g"" % ( dist[03] cdist( [X[0]] [Y[3]] )) # (trivia: how do pairwise distances between uniform-random points in the unit cube # depend on the metric ? With the right scaling not much at all: # L1 / dim ~ .33 +- .2/sqrt dim # L2 / sqrt dim ~ .4 +- .2/sqrt dim # Lmax / 2 ~ .4 +- .2/sqrt dim Hello I actually just came across this last week. Much faster too! @LWZ just what you have -- `np.array([ dist( x y ) for x y in zip( X Y )])` @denis cdist calculate distances between ALL pairs. How can I distance only between corresponding elements for example `[ dist(X[0]Y[0]) dist(X[1]Y[1]) ... dist(X[N]Y[N]) ]` assuming `X` and `Y` are of same length `N`? This works! And pretty fast. Just a note that the elements to calculate must be of length 2 otherwise python will raise an error. For a list of points in a contour detected by opencv2 I needed to use reshape function of numpy to reshape it first... @denis: well e.g. the result of cv2.findContours is something like this: [ [[x1 y1]] [[x2 y2]].....[[xn yn]] ]. I don't know why they put the coordinates in 2 square bracket but if you apply cdist directly to the list each element will only have length 1 (a list containing 1 list inside) I have to reshape it so the contour become the list of length-2 element (which means flat out the double bracket) @Jim Raynor right -- cdist expects arrays with ndim == 2 should check can you post an example of how to use it? there are none in the docs  To compute the m by p matrix of distances this should work: >>> def distances(xy1 xy2): ... d0 = numpy.subtract.outer(xy1[:0] xy2[:0]) ... d1 = numpy.subtract.outer(xy1[:1] xy2[:1]) ... return numpy.hypot(d0 d1) the .outer calls make two such matrices (of scalar differences along the two axes) the .hypot calls turns those into a same-shape matrix (of scalar euclidean distances). +1: just learned about the properties of Numpy's ufuncs! This method is faster I would go for cdist in this case but +1'd and I've learnt from this solution cool stuff Faster it's numpy!",python numpy euclidean-distance643699,A,"How can I use numpy.correlate to do autocorrelation? I need to do auto-correlation of a set of numbers which as I understand it is just the correlation of the set with itself. I've tried it using numpy's correlate function but I don't believe the result as it almost always gives a vector where the first number is not the largest as it ought to be. So this question is really two questions: What exactly is numpy.correlate doing? How can I use it (or something else) to do auto-correlation? See also: http://stackoverflow.com/questions/12269834/is-there-any-numpy-autocorrellation-function-with-standardized-output for information about normalized autocorrelation. Auto-correlation comes in two versions: statistical and convolution. They both do the same except for a little detail: The former is normalized to be on the interval [-11]. Here is an example of how you do the statistical one: def acf(x length=20): return numpy.array([1]+[numpy.corrcoef(x[:-i] x[i:]) \ for i in range(1 length)]) You want ``numpy.corrcoef[x:-i] x[i:])[01]`` in the second line as the return value of ``corrcoef`` is a 2x2 matrix  1) Here is the documentation for numpy.correlate. The code inside the file looks like this: mode = _mode_from_name(mode) return multiarray.correlate(avmode) multiarray.correlate points to a .pyd file (i.e. a DLL file) so to get the inner workings you should probably ask the numpy developers. 2) If you don't believe the numpy results you might try SciPy's correlate function. The scipy and numpy correlate functions are both in C. numpy multiarray source code is somewhere in here: http://svn.scipy.org/svn/numpy/trunk/numpy/core/src/multiarray/ and scipy correlate source code is here: http://svn.scipy.org/svn/scipy/trunk/scipy/signal/correlate_nd.c.src  To answer your first question Numpy.correlate(a v mode) is performing the convolution of a with the reverse of v and giving the results clipped by the specified mode. Because of the definition of convolution the correlation C(t) = Sum for -inf < i < inf of (a[i] * v[t + i]) where -inf < t < inf. Even though this definition of the correlation would allow for results from -infinity to infinity you obviously can't store an infinitely long array. So it has to be clipped and that is where the mode comes in. There are 3 different modes: full same & valid. 'full' mode returns results for every t where both a and v have some overlap. 'same' mode returns a result with the same length as the shortest vector (a or v). 'valid' mode returns results only when a and v completely overlap each other. The documentation for Numpy.convolve gives more detail on the modes. For your second question I think Numpy.correlate is giving you the autocorrelation it is just giving you a little more as well. The autocorrelation is used to find how similar a signal or function is to itself at a certain time difference. At a time difference of 0 the auto-correlation should be the highest because the signal is identical to itself so you expected that the first element in the auto-correlation result array would be the greatest. However the correlation is not starting at a time difference of 0. It starts at a negative time difference closes to 0 and then goes positive. That is you were expecting: Autocorrelation(a) = Sum for -inf < i < inf (a[i] * v[t + i]) where 0 <= t < inf But what you got was: Autocorrelation(a) = Sum for -inf < i < inf (a[i] * v[t + i]) where -inf < t < inf What you need to do is take the last half of your correlation result and that should be the auto-correlation you are looking for. A simple python function to do that would be: def autocorr(x): result = numpy.correlate(x x mode='full') return result[result.size/2:] You will of course need error checking to make sure that x is actually a 1-d array. Also this explanation probably isn't the most mathematically rigorous. I've been throwing around infinities because the definition of convolution uses them but that doesn't necessarily apply for auto-correlation. So the theoretical portion of this explanation may be slightly wonky but hopefully the practical results are helpful. These pages on auto-correlation are pretty helpful and can give you a much better theoretical background if you don't mind wading through the notation and heavy concepts. In current builds of numpy the mode 'same' can be specified to achieve exactly what the A. Levy proposed. The body of the function could then read `return numpy.correlate(x x mode='same')` @DavidZwicker but the resultings are different! `np.correlate(xxmode='full')[len(x)//2:] != np.correlate(xxmode='same')`. For example `x = [12312]; np.correlate(xxmode='full');` {`>>> array([ 2 5 11 13 19 13 11 5 2])`} `np.correlate(xxmode='same');` {`>>> array([11 13 19 13 11])`}. The correct one is: `np.correlate(xxmode='full')[len(x)-1:];` {`>>> array([19 13 11 5 2])`} see **the first item** is **the largest one**. Note that this answer gives the unnormalized autocorrelation.  As I just ran into the same problem I would like to share a few lines of code with you. In fact there are several rather similar posts about autocorrelation in stackoverflow by now. If you define the autocorrelation as a(x L) = sum(k=0N-L-1)((xk-xbar)*(x(k+L)-xbar))/sum(k=0N-1)((xk-xbar)**2) [this is the definition given in IDL's a_correlate function and it agrees with what I see in answer 2 of question #12269834] then the following seems to give the correct results: import numpy as np import matplotlib.pyplot as plt # generate some data x = np.arange(0.6.120.01) y = np.sin(x) # y = np.random.uniform(size=300) yunbiased = y-np.mean(y) ynorm = np.sum(yunbiased**2) acor = np.correlate(yunbiased yunbiased ""same"")/ynorm # use only second half acor = acor[len(acor)/2:] plt.plot(acor) plt.show() As you see I have tested this with a sin curve and a uniform random distribution and both results look like I would expect them. Note that I used mode=""same"" instead of mode=""full"" as the others did.  Using the numpy.corrcoef function instead of numpy.correlate to calculate the statistical correlation for a lag of t: def autocorr(x t=1): numpy.corrcoef(numpy.array([x[0:len(x)-t] x[t:len(x)]]))",python math numpy numerical-methods1903462,A,"How can I ""zip sort"" parallel numpy arrays? If I have two parallel lists and want to sort them by the order of the elements in the first it's very easy: >>> a = [2 3 1] >>> b = [4 6 2] >>> a b = zip(*sorted(zip(ab))) >>> print a (1 2 3) >>> print b (2 4 6) How can I do the same using numpy arrays without unpacking them into conventional Python lists? @YGA will your input array ""a"" ever have non-unique values? If so how would you like the sort to behave in that case? Arbitrary order? Stable sort? Secondary sort using corresponding values in array ""b""? Your question is the answer to my question -- I was searching for that kind of sort. b[a.argsort()] should do the trick. Here's how it works. First you need to find a permutation that sorts a. argsort is a method that computes this: >>> a = numpy.array([2 3 1]) >>> p = a.argsort() >>> p [2 0 1] You can easily check that this is right: >>> a[p] array([1 2 3]) Now apply the same permutation to b. >>> b = numpy.array([4 6 2]) >>> b[p] array([2 4 6]) This doesn't use `b` for ""auxiliary sorting"" for example when `a` has elements that repeat. Please see my answer for details. otoh auxiliary sorting is not always desired.  Here's an approach that creates no intermediate Python lists though it does require a NumPy ""record array"" to use for the sorting. If your two input arrays are actually related (like columns in a spreadsheet) then this might open up an advantageous way of dealing with your data in general rather than keeping two distinct arrays around all the time in which case you'd already have a record array and your original problem would be answered merely by calling sort() on your array. This does an in-place sort after packing both arrays into a record array: >>> from numpy import array rec >>> a = array([2 3 1]) >>> b = array([4 6 2]) >>> c = rec.fromarrays([a b]) >>> c.sort() >>> c.f1 # fromarrays adds field names beginning with f0 automatically array([2 4 6]) Edited to use rec.fromarrays() for simplicity skip redundant dtype use default sort key use default field names instead of specifying (based on this example). Thanks! I really wish I could accept two answers. This one is less simple but more general. I've upvoted it though as the least I could do :-)  This might the simplest and most general way to do what you want. (I used three arrays here but this will work on arrays of any shape whether two columns or two hundred). import numpy as NP fnx = lambda : NP.random.randint(0 10 6) a b c = fnx() fnx() fnx() abc = NP.column_stack((a b c)) keys = (abc[:0] abc[:1]) # sort on 2nd column resolve ties using 1st col indices = NP.lexsort(keys) # create index array ab_sorted = NP.take(abc indices axis=0) One quirk w/ lexsort is that you have to specify the keys in reverse order i.e. put your primary key second and your secondary key first. In my example i want to sort using the 2nd column as the primary key so i list it second; the 1st column resolves ties only but it is listed first). nice catch Brendan thanks.",python sorting numpy1613249,A,"NumPy: Comparing Elements in Two Arrays Anyone ever come up to this problem? Let's say you have two arrays like the following a = array([123456]) b = array([145]) Is there a way to compare what elements in a exist in b? For example c = a == b # Wishful example here print c array([145]) # Or even better array([True False False True True False]) I'm trying to avoid loops as it would take ages with millions of elements. Any ideas? Cheers what data do you have in the arrays? Index-like unique integers like the example? Numpy has a set function numpy.setmember1d() that works on sorted and uniqued arrays and returns exactly the boolean array that you want. If the input arrays don't match the criteria you'll need to convert to the set format and invert the transformation on the result. import numpy as np a = np.array([6123456]) b = np.array([145]) # convert to the uniqued form a_set a_inv = np.unique1d(a return_inverse=True) b_set = np.unique1d(b) # calculate matching elements matches = np.setmea_set b_set) # invert the transformation result = matches[a_inv] print(result) # [False True False False True True False] Edit: Unfortunately the setmember1d method in numpy is really inefficient. The search sorted and assign method you proposed works faster but if you can assign directly you might as well assign directly to the result and avoid lots of unnecessary copying. Also your method will fail if b contains anything not in a. The following corrects those errors: result = np.zeros(a.shape dtype=np.bool) idxs = a.searchsorted(b) idxs = idxs[np.where(idxs < a.shape[0])] # Filter out out of range values idxs = idxs[np.where(a[idxs] == b)] # Filter out where there isn't an actual match result[idxs] = True print(result) My benchmarks show this at 91us vs. 6.6ms for your approach and 109ms for numpy setmember1d on 1M element a and 100 element b. That's a nice solution. I'll try out your suggestion and what I just wrote to see what's more optimal in speed. Many thanks everyone for your help! The method I wrote is a bit faster. For a 10000 element array the time it took using timeit in iPython is roughly 3 Îµs. The setmember1d method took 3 ms. I think your method is more elegant but I need the speed. you forgot to close a parenthesis in the 3rd line. you should fix it before some computer science professor notices it... ebressert: seems that you're right setmember1d has an absolutely terrible implementation in numpy. But the method you're using seems to be using nan values for no good reason you might just as well use the result array directly. I'll edit with the corresponding example. Ants Aasma: Your edit is good. I implemented pieces of it to my code and increased the speed once more. Rather than doing nans I put in -1 and then filtered on match = b >= 0. I'm dealing with indexing in my case so there are no indexes of -1. That's why I used np.nan which would work for the more general case. Thanks for your input. My code is really flying now.  Your example implies set-like behavior caring more about existance in the array than having the right element at the right place. Numpy does this differently with its mathematical arrays and matrices it will tell you only about items at the exact right spot. Can you make that work for you? >>> import numpy >>> a = numpy.array([123]) >>> b = numpy.array([133]) >>> a == b array([ True False True] dtype=bool) sorry this example doesn't work if you try it; moreover you would have to sort the arrays first. @dalloligom: Uh I copied from my interactive session so at least it works exactly like that for some version of Python and Numpy. ok but it doesn't work if the two arrays have different length; in any case you have to sort them first (try array([123])==array([231]). he wants to know which elements of an array exists in another. and by the way even sorting the arrays won't work... you have to use a set structure. @dalloliogm: Did you read my answer? Does it seem like I didn't understand all that?  Thanks for your reply kaizer.se. It's not quite what I was looking for but with a suggestion from a friend and what you said I came up with the following. import numpy as np a = np.array([145]).astype(np.float32) b = np.arange(10).astype(np.float32) # Assigning matching values from a in b as np.nan b[b.searchsorted(a)] = np.nan # Now generating Boolean arrays match = np.isnan(b) nonmatch = match == False It's a bit of a cumbersome process but it beats writing loops or using weave with loops. Cheers  Use np.intersect1d. #!/usr/bin/env python import numpy as np a = np.array([123456]) b = np.array([145]) c=np.intersect1d(ab) print(c) # [1 4 5] Note that np.intersect1d gives the wrong answer if a or b have nonunique elements. In that case use np.intersect1d_nu. There is also np.setdiff1d setxor1d setmember1d and union1d. See Numpy Example List With Doc +1: Excellent. The right function for this task.  Actually there's an even simpler solution than any of these: import numpy as np a = array([123456]) b = array([145]) c = np.in1d(ab) The resulting c is then: array([ True False False True True False] dtype=bool) Is there an ""almost_equal"" version of this? Where you can specify the condition used to test for equality?  ebresset your answer won't work unless a is a subset of b (and a and b are sorted). Otherwise the searchsorted will return false indices. I had to do something similar and combining that with your code: # Assume a and b are sorted idxs = numpy.mod(b.searchsorted(a)len(b)) idxs = idxs[b[idxs]==a] b[idxs] = numpy.nan match = numpy.isnan(b)",python numpy1708775,A,Combining two record arrays I have two Numpy record arrays that have exactly the same fields. What is the easiest way to combine them into one (i.e. append one table on to the other)? #!/usr/bin/env python import numpy as np desc = {'names': ('gender''age''weight') 'formats': ('S1' 'f4' 'f4')} a = np.array([('M'64.075.0)('F'25.060.0)] dtype=desc) b = np.array([('M'64.075.0)('F'25.060.0)] dtype=desc) alen=a.shape[0] blen=b.shape[0] a.resize(alen+blen) a[alen:]=b[:] This works with structured arrays though not recarrays. Perhaps this is a good reason to stick with structured arrays. Is there a reason why this does not work with recarrays? I thought recarrays were just structured arrays with an extra __getattribute__/__setattr__ arguments? I don't know why. I only know that when I try the same thing with recarrays I get a ValueError: cannot resize this array: it does not own its own data. Having run into problems like this with recarrays in the past I tend to use structured arrays instead of recarrays. The syntactic sugar isn't worth the trouble.  for i in array1: array2.append(i) Or (if implemented) array1.extend(array2) Now array1 contains also all elements of array2  Use numpy.hstack(): >>> import numpy >>> desc = {'names': ('gender''age''weight') 'formats': ('S1' 'f4' 'f4')} >>> a = numpy.array([('M'64.075.0)('F'25.060.0)] dtype=desc) >>> numpy.hstack((aa)) array([('M' 64.0 75.0) ('F' 25.0 60.0) ('M' 64.0 75.0) ('F' 25.0 60.0)] dtype=[('gender' '|S1') ('age' '<f4') ('weight' '<f4')]),python numpy recarray1822417,A,Simple question about numpy matrix in python Let's suppose I have a numpy matrix variable called MATRIX with 3 coordinates: (x y z). Is acessing the matrix's value through the following code myVar = MATRIX[000] equal to myVar = MATRIX[00][0] or myVar = MATRIX[0][00] ? What about if I have the following code? myTuple = (00) myScalar = 0 myVar = MATRIX[myTuple myScalar] Is the last line equivalent to doing myVar = MATRIX[myTuple[0] myTuple[1] myScalar] I have done simple tests and it seems so but maybe that is not so in all the cases. How do square brackets work in python with numpy matrices? Since day one I felt confused as how they work. Thanks Are you sure? I get a `TypeError` when I try any of this. If you have a tuple `MYTUPLE=(123)` then the only possible indices are `MYTUPLE[0]` `MYTUPLE[1]` and `MYTUPLE[2]`. Sorry now that I see it it's numpy matrices that I was refering to. It's not possible to index a tuple with another tuple so none of that code is valid.  I assume you have a array instance rather than a matrix since the latter only can have two dimensions. m[0 0 0] gets the element at position (0 0 0). m[0 0] gets a whole subarray (a slice) which is itself a array. You can get the first element of this subarray like this: m[0 0][0] which is why both syntaxes work (even though m[i j k] is preferred because it doesn't have the unnecessary intermediate step). Take a look at this ipython session: rbonvall@andy:~$ ipython Python 2.5.4 (r254:67916 Sep 26 2009 08:19:36) [...] In [1]: import numpy.random In [2]: m = numpy.random.random(size=(3 3 3)) In [3]: m Out[3]: array([[[ 0.68853531 0.8815277  0.53613676] [ 0.9985735  0.56409085 0.03887982] [ 0.12083102 0.0301229  0.51331851]] [[ 0.73868543 0.24904349 0.24035031] [ 0.15458694 0.35570177 0.22097202] [ 0.81639051 0.55742805 0.5866573 ]] [[ 0.90302482 0.29878548 0.90705737] [ 0.68582033 0.1988247  0.9308886 ] [ 0.88956484 0.25112987 0.69732309]]]) In [4]: m[0 0] Out[4]: array([ 0.68853531 0.8815277  0.53613676]) In [5]: m[0 0][0] Out[5]: 0.6885353066709865 It only works like this for numpy arrays. Python built-in tuples and lists are not indexable by tuples just by integers. hmm and what would m[000] yield? The same as `m[0 0][0]` given that `len(m.shape) == 3`.,python numpy367565,A,How do I build a numpy array from a generator? How can I build a numpy array out of a generator object? Let me illustrate the problem: >>> import numpy >>> def gimme(): ... for x in xrange(10): ... yield x ... >>> gimme() <generator object at 0x28a1758> >>> list(gimme()) [0 1 2 3 4 5 6 7 8 9] >>> numpy.array(xrange(10)) array([0 1 2 3 4 5 6 7 8 9]) >>> numpy.array(gimme()) array(<generator object at 0x28a1758> dtype=object) >>> numpy.array(list(gimme())) array([0 1 2 3 4 5 6 7 8 9]) In this instance gimme() is the generator whose output I'd like to turn into an array. However the array constructor does not iterate over the generator it simply stores the generator itself. The behaviour I desire is that from numpy.array(list(gimme())) but I don't want to pay the memory overhead of having the intermediate list and the final array in memory at the same time. Is there a more space-efficient way? This is an interesting issue. I came accross this by `from numpy import *; print any(False for i in range(1))` - which shadows the built-in [`any()`](http://docs.python.org/library/functions.html#any) and produces the opposite result (as I know now). @moooeeeep that's terrible. if `numpy` can't (or doesn't want to) to treat generators as Python does at least it should raise an exception when it receives a generator as an argument. @max I stepped on exact same mine. Apparently this was raised [on the NumPy list](http://thread.gmane.org/gmane.comp.python.numeric.general/47681/focus=47702) (and [earlier](http://thread.gmane.org/gmane.comp.python.numeric.general/13197)) concluding that this will not be changed to raise exception and one should always use namespaces. Numpy arrays require their length to be set explicitly at creation time unlike python lists. This is necessary so that space for each item can be consecutively allocated in memory. Consecutive allocation is the key feature of numpy arrays: this combined with native code implementation let operations on them execute much quicker than regular lists. Keeping this in mind it is technically impossible to take a generator object and turn it into an array unless you either: (a) can predict how many elements it will yield when run: my_array = numpy.zeros(predict_length()) for i el in enumerate(gimme()): my_array[i] = el (b) are willing to store its elements in an intermediate list : my_array = numpy.array(list(gimme())) (c) can make two identical generators run through the first one to find the total length initialize the array and then run through the generator again to find each element: length = sum(1 for el in gimme()) my_array = numpy.zeros(length) for i el in enumerate(gimme()): my_array[i] = el (a) is probably what you're looking for. (b) is space inefficient and (c) is time inefficient (you have to go through the generator twice). Thanks that makes alot of sense. The builtin `array.array` is a contiguous non-linked list and you can simply `array.array('f' generator)`. To say say it's impossible is misleading. It's just dynamic allocation. Why numpy.array doesn't do the memory allocation the same way as the builtin array.array as Cuadue says. What is the tradeof? I ask because there is contiguous allocated memory in both examples. Or not? numpy assumes its array sizes to not change. It relies heavily on different views of the same chunk of memory so allowing arrays to be expanded and reallocated would require an additional layer of indirection to enable views for example.  One google behind this stackoverflow result I found that there is a numpy.fromiter(data dtype count). The default count=-1 takes all elements from the iterable. It requires a dtype to be set explicitly. In my case this worked: numpy.fromiter(something.generate(from_this_input) float) Interesting I shall try it the next time I need it. how would you apply this to the question? `numpy.fromiter(gimme() float count=-1)` does not work. What does `something` stand for? something.generate is just the name of the generator @Matthias009 `numpy.fromiter(gimme() float count=-1)` works for me. A thread explaining why `fromiter` only works on 1D arrays: http://mail.scipy.org/pipermail/numpy-discussion/2007-August/028898.html. fwiw `count=-1` does not need to be specified as it is the default.  Somewhat tangential but if your generator is a list comprehension you can use numpy.where to more effectively get your result (I discovered this in my own code after seeing this post),python numpy generator1587367,A,"Python/numpy tricky slicing problem I have a problem with some numpy stuff. I need a numpy array to behave in an unusual manner by returning a slice as a view of the data I have sliced not a copy. So heres an example of what I want to do: Say we have a simple array like this: a = array([1 0 0 0]) I would like to update consecutive entries in the array (moving left to right) with the previous entry from the array using syntax like this: a[1:] = a[0:3] This would get the following result: a = array([1 1 1 1]) Or something like this: a[1:] = 2*a[:3] # a = [1248] To illustrate further I want the following kind of behaviour: for i in range(len(a)): if i == 0 or i+1 == len(a): continue a[i+1] = a[i] Except I want the speed of numpy. The default behavior of numpy is to take a copy of the slice so what I actually get is this: a = array([1 1 0 0]) I already have this array as a subclass of the ndarray so I can make further changes to it if need be I just need the slice on the right hand side to be continually updated as it updates the slice on the left hand side. Am I dreaming or is this magic possible? Update: This is all because I am trying to use Gauss-Seidel iteration to solve a linear algebra problem more or less. It is a special case involving harmonic functions I was trying to avoid going into this because its really not necessary and likely to confuse things further but here goes. The algorithm is this: while not converged: for i in range(len(u[:0])): for j in range(len(u[0:])): # skip over boundary entries ij == 0 or len(u) u[ij] = 0.25*(u[i-1j] + u[i+1j] + u[i j-1] + u[ij+1]) Right? But you can do this two ways Jacobi involves updating each element with its neighbours without considering updates you have already made until the while loop cycles to do it in loops you would copy the array then update one array from the copied array. However Gauss-Seidel uses information you have already updated for each of the i-1 and j-1 entries thus no need for a copy the loop should essentially 'know' since the array has been re-evaluated after each single element update. That is to say every time we call up an entry like u[i-1j] or u[ij-1] the information calculated in the previous loop will be there. I want to replace this slow and ugly nested loop situation with one nice clean line of code using numpy slicing: u[1:-11:-1] = 0.25(u[:-21:-1] + u[2:1:-1] + u[1:-1:-2] + u[1:-12:]) But the result is Jacobi iteration because when you take a slice: u[:-21:-1] you copy the data thus the slice is not aware of any updates made. Now numpy still loops right? Its not parallel its just a faster way to loop that looks like a parallel operation in python. I want to exploit this behaviour by sort of hacking numpy to return a pointer instead of a copy when I take a slice. Right? Then every time numpy loops that slice will 'update' or really just replicate whatever happened in the update. To do this I need slices on both sides of the array to be pointers. Anyway if there is some really really clever person out there that awesome but I've pretty much resigned myself to believing the only answer is to loop in C. just to clarify again this is not what you want: a[1:] = 2*a[:3]; a[:3] = [100] so we now have a = [1200] but our a[:3] is now [120] so a becomes [1240] and once again a[:3] is [124] so we assign that to a[1:] and a becomes [1248] -- and now finally a[1:] ([248]) = 2*a[:3] (2*[124]) so our assignment is finished. what you're saying is that that's NOT what you want to happen? just to put an analogy on what you're trying to do since most people don't seem to understand it: it's somewhat like pointing a video camera at a television screen displaying its own output. so what you want is some sort of recursive assignment -- but i don't believe there is any guarantee that this will settle down into a constant value. sure it does in your case but not in general -- for example: `a[:] = 2*a[:]` would loop forever. so no what you want is not possible in numpy without explicitly looping and comparing until propagation of values is done. @daver I don't think you're getting how numpy works. When you say a[1:] = 2*a[:3] there are _two_ loops. The first one is 2*a[:3] which makes a temporary array. And then a second loop does the assignment. a[1:] is not getting assigned from itself but from a temporary. The problem is not that a[:3] isn't a view into a because it is but that 2*a[:3] is a completely different array. Numpy is giving you the speed of C but at the cost of more temporaries. Once you grasp this you'll see why you can't easily do what you want in NumPy without delving into lower-level stuff. @daver: unfortunately what i described before will not work in general in numpy since there is no convergence guarantee. as i said before a[:] = 2*a[:] would loop forever. for example if a = [1 1 1] then going through a[:] = 2*a[:] gives a = 2*[111] so a[:] is assigned [222]. so now we have a[:] ([222]) = 2*[222] which aren't equal so we go again: a[:] ([444]) = 2*[444]... etc it'll never converge. the only fixed point of a[:] = 2*a[:] is if a = [000] anything else will grow exponentially. What you described is *exactly* what I want to happen. Numpy appears to assign a bunch of stuff at once in reality it is just looping somewhere else. Default behaviour is like this first round: a = [1200]  second round: a = [1200] third round: a = [1200]. If the slice a[:3] were a pointer to a's data (view I think its called in numpy) then after the first round that slice would have updated so it would then be: a[:3] = [120] then a becomes: [1240] then the slice is pointing at a's data so a[:3] = [124] and infally we end up with a = [1248]. @daver: can you post a proper example using a loop? for now the loop is the same as a[1:]=a[1]. the for loop is the same of a[1:]=a[1]... Andrea don't try to think about how you could solve this trivial example in a simpler way think about the mechanics of what is going on yes the output is the same as a[1:] = a[0] but in the general case not even close. Why would that loop forever? And no it is not some sort of recursive assignment it is simple iteration. I just want like a pointer instead of a deep copy of my array when I take a slice of it its not really that hard to comprehend surely?? The problem with the ""kind of behavior... a[i+1]=a[i]"" is that it is such a trivial case that even though many of the posted solutions fulfil it you're not satisfied and neither is anyone else and no one can recognize a possible answer as an actual answer. That's why I asked you to give a simple but NON-TRIVIAL example of what you want using numbers other than 1 and 0. Do this and you may get a good answer. (But not from me I've read this problem too many times already.) Dude I'm sorry man but you asked me to update my question so that it is clearer I have done that and I have provided a case other than 1 and 0. You even replied to a comment I made where I gave you a cut down version of the 2-d thing I am using this on. Not one single response addresses the problem none of them so what you just said is simply not true. I'm sorry man. I even know the technical details of what I am after I'm specifically asking: can I get a slice to return a pointer to my data instead of a deep copy? And read my question it is in there. Did you look at the link in my answer to the SciPy page on Performance Python. The actual example of solving Laplace's equation using Gauss-Seidel iteration. They explicitly mention having to use a temporary to do what you want if you stick to pure NumPy and then give more advanced techniques to avoid that. Thanks for the link but it doesn't solve the problem I'm afraid. I've already implemented exactly what they have on that page but they even admit that it is not updating the entries in the manner I want to: ""... However since the NumPy expression uses temporaries internally only the old value of u[11] will be used."". It works but its called Jacobi iteration not Gauss-Seidel. Unfortunately I have to use Gauss-Seidel for an assignment. Thanks anyway. I am sorry but I don't understand very well your question... Anyway have you tried with a.copy()? What you're asking for is largely senseless. Why should you be able to say `a[0:3]` and have is mean `a[0]` only? That's incomprehensible. -1: I don't get your question either. Can you formalize what the behavior should be and break it down into well defined steps? First implement a simple for-loop version then we can maybe help you to optimize it. Did you ever get solved this? I just did exactly what is indicated here and usign Jacobi negates the speed of numpy because you need many more iterations. Late answer but this turned up on Google so I probably point to the doc the OP wanted. Your problem is clear: when using NumPy slices temporaries are created. Wrap your code in a quick call to weave.blitz to get rid of the temporaries and have the behaviour your want. Read the weave.blitz section of PerformancePython tutorial for full details.  It is not the correct logic. I'll try to use letters to explain it. Image array = abcd with abcd as elements. Now array[1:] means from the element in position 1 (starting from 0) on. In this case:bcd and array[0:3] means from the character in position 0 up to the third character (the one in position 3-1) in this case: 'abc'. Writing something like: array[1:] = array[0:3] means: replace bcd with abc To obtain the output you want now in python you should use something like: a[1:] = a[0] I've just read his comment above. The question is pretty unclear so. The fist part of my post explain why it does not work as the OP thinks. I'm waiting for a question improvement to try to solve his problem. It is not clear as he would want to update it. I did edit it it should be very clear now. Sorry this is my first post what I want to know is why this question got 3 downvotes? I commented on the question. I didn't downvoted this but I think it got downvoted because of the unclear exposition. Try to provide an alternative working way to solve the problem or at least to explain the algorithm you'd like to be used in the details. Andrea I have updated again with even more information I'm afraid I don't think it makes it any clearer but its there if you are interested. And yeah I got downvotes after I clarified things so I'm thinking theres a bit of people confusing not understanding the problem with my explanation of it going on. Yes the original question was vague and oversimplified. Found clarification in a comment. I wonder why people are afraid to edit original posts? The OP is trying to do something more sophisticated than that. The goal is to update elements of a slice based on element values that were updated in the current operation. It's hard to comprehend but it's much faster than traditional python loops.  You could have a look at np.lib.stride_tricks. There is some information in these excellent slides: http://mentat.za.net/numpy/numpy_advanced_slides/ with stride_tricks starting at slide 29. I'm not completely clear on the question though so can't suggest anything more concrete - although I would probably do it in cython or fortran with f2py or with weave. I'm liking fortran more at the moment because by the time you add all the required type annotations in cython I think it ends up looking less clear than the fortran. There is a comparison of these approaches here: www. scipy. org/ PerformancePython (can't post more links as I'm a new user) with an example that looks similar to your case.  Numpy must be checking if the target array is the same as the input array when doing the setkey call. Luckily there are ways around it. First I tried using numpy.put instead In [46]: a = numpy.array([1000]) In [47]: numpy.put(a[123]a[0:3]) In [48]: a Out[48]: array([1 1 1 1]) And then from the documentation of that I gave using flatiters a try (a.flat) In [49]: a = numpy.array([1000]) In [50]: a.flat[1:] = a[0:3] In [51]: a Out[51]: array([1 1 1 1]) But this doesn't solve the problem you had in mind In [55]: a = np.array([1000]) In [56]: a.flat[1:] = 2*a[0:3] In [57]: a Out[57]: array([1 2 0 0]) This fails because the multiplication is done before the assignment not in parallel as you would like. Numpy is designed for repeated application of the exact same operation in parallel across an array. To do something more complicated unless you can find decompose it in terms of functions like numpy.cumsum and numpy.cumprod you'll have to resort to something like scipy.weave or writing the function in C. (See the PerfomancePython page for more details.) (Also I've never used weave so I can't guarantee it will do what you want.)  It must have something to do with assigning a slice. Operators however as you may already know do follow your expected behavior: >>> a = numpy.array([1000]) >>> a[1:]+=a[:3] >>> a array([1 1 1 1]) If you already have zeros in your real-world problem where your example does then this solves it. Otherwise at added cost set them to zero either by multiplying by zero or assigning to zero (whichever is faster) edit: I had another thought. You may prefer this: numpy.put(a[123]a[:3])  In the end I came up with the same problem as you. I had to resort to use Jacobi iteration and weaver:  while (iter_n < max_time_steps): expr = ""field[1:-1 1:-1] = (field[2: 1:-1] ""\ ""+ field[:-2 1:-1]+""\ ""field[1:-1 2:] +""\ ""field[1:-1 :-2] )/4."" weave.blitz(expr check_size=0) #Toroidal conditions field[:0] = field[:self.flow.n_x - 2] field[:self.flow.n_x -1] = field[:1] iter_n = iter_n + 1 It works and is fast but is not Gauss-Seidel so convergence can be a bit tricky. The only option of doing Gauss-Seidel as a traditional loop with indexes.  accumulate is designed to do what you seem to want; that is to proprigate an operation along an array. Here's an example: from numpy import * a = array([1000]) a[1:] = add.accumulate(a[0:3]) # a = [1 1 1 1] b = array([1111]) b[1:] = multiply.accumulate(2*b[0:3]) # b = [1 2 4 8] Another way to do this is to explicitly specify the result array as the input array. Here's an example: c = array([2000]) multiply(c[:3] c[:3] c[1:]) # c = [ 2 4 16 256]  i would suggest cython instead of looping in c. there might be some fancy numpy way of getting your example to work using a lot of intermediate steps... but since you know how to write it in c already just write that quick little bit as a cython function and let cython's magic make the rest of the work easy for you.  Just use a loop. I can't immediately think of any way to make the slice operator behave the way you're saying you want it to except maybe by subclassing numpy's array and overriding the appropriate method with some sort of Python voodoo... but more importantly the idea that a[1:] = a[0:3] should copy the first value of a into the next three slots seems completely nonsensical to me. I imagine that it could easily confuse anyone else who looks at your code (at least the first few times). No no no its not copying the first value into the next three its updating each consecutive entry with data from the previous entry. However each time it updates I want it to be aware of the previous update. Yes I can loop but its extremely slow and clumsy for the purpose I have in mind. But heres what it would look like in a loop: for i in a: *Dammit sorry i hit tab and it updated my comment... the code: for i in a: a[i+1] = a[i] The point is this is for a 2 dimensional array and is a specific numeric algorithm that I need to implement. why not just a[1:4]=a[0]? unknown: You really don't want the array copy to work that way. How would you copy parts of the array if it worked that way? gnibbler: That completely misses the point of the algorithm this is a simple example what I am doing is Gauss-Seidel iteration which infers information about a location in a matrix by using data that has already been inferred in previous entries. Deep in the machinery of numpy as I understand it it performs this loop. However it loops over the copy of the original data in the slice. I want it to loop over the slice and update the slice as it goes. Maybe I could make it clearer like this: a[1:] = 2*a[0:3] with the expected result being: a = [1248]. Oh yeah and no I do not want my array copy to work like that I want my array slice to not be a copy I want my array slice to be a view of the data contained in the array. Please fix the question. Do no correct your question in the comments on an answer. Please update the question with this revised description of the problem. One of the main advantages to numpy is the ability to avoid expensive python iterations. (aka broadcasting). The question is perfectly valid and a reasonable thing to expect numpy to do.",python numpy slice1025379,A,"Decimal alignment formatting in Python This should be easy. Here's my array (rather a method of generating representative test arrays): >>> ri = numpy.random.randint >>> ri2 = lambda x: ''.join(ri(09x).astype('S')) >>> a = array([float(ri2(x)+ '.' + ri2(y)) for xy in ri(110(102))]) >>> a array([ 7.99914000e+01 2.08000000e+01 3.94000000e+02 4.66100000e+03 5.00000000e+00 1.72575100e+03 3.91500000e+02 1.90610000e+04 1.16247000e+04 3.53920000e+02]) I want a list of strings where '\n'.join(list_o_strings) would print:  79.9914 20.8 394.0 4661.0 5.0 1725.751 391.5 19061.0 11624.7 353.92 I want to space pad to the left and the right (but no more than necessary). I want a zero after the decimal if that is all that is after the decimal. I do not want scientific notation. ..and I do not want to lose any significant digits. (in 353.98000000000002 the 2 is not significant) Yeah it's nice to want.. Python 2.5's %g %fx.x etc. are either befuddling me or can't do it. I have not tried import decimal yet. I can't see that NumPy does it either (although the array.__str__ and array.__repr__ are decimal aligned (but sometimes return scientific). Oh and speed counts. I'm dealing with big arrays here. My current solution approaches are: to str(a) and parse off NumPy's brackets to str(e) each element in the array and split('.') then pad and reconstruct to a.astype('S'+str(i)) where i is the max(len(str(a))) then pad It seems like there should be some off-the-shelf solution out there... (but not required) Top suggestion fails with when dtype is float64: >>> a array([ 5.50056103e+02 6.77383566e+03 6.01001513e+05 3.55425142e+08 7.07254875e+05 8.83174744e+02 8.22320510e+01 4.25076609e+08 6.28662635e+07 1.56503068e+02]) >>> ut0 = re.compile(r'(\d)0+$') >>> thelist = [ut0.sub(r'\1' ""%12f"" % x) for x in a] >>> print '\n'.join(thelist) 550.056103 6773.835663 601001.513 355425141.8471 707254.875038 883.174744 82.232051 425076608.7676 62866263.55 156.503068 Please post the code that doesn't work. Sorry but after thorough investigation I can't find any way to perform the task you require without a minimum of post-processing (to strip off the trailing zeros you don't want to see); something like: import re ut0 = re.compile(r'(\d)0+$') thelist = [ut0.sub(r'\1' ""%12f"" % x) for x in a] print '\n'.join(thelist) is speedy and concise but breaks your constraint of being ""off-the-shelf"" -- it is instead a modular combination of general formatting (which almost does what you want but leaves trailing zero you want to hide) and a RE to remove undesired trailing zeros. Practically I think it does exactly what you require but your conditions as stated are I believe over-constrained. Edit: original question was edited to specify more significant digits require no extra leading space beyond what's required for the largest number and provide a new example (where my previous suggestion above doesn't match the desired output). The work of removing leading whitespace that's common to a bunch of strings is best performed with textwrap.dedent -- but that works on a single string (with newlines) while the required output is a list of strings. No problem we'll just put the lines together dedent them and split them up again: import re import textwrap a = [ 5.50056103e+02 6.77383566e+03 6.01001513e+05 3.55425142e+08 7.07254875e+05 8.83174744e+02 8.22320510e+01 4.25076609e+08 6.28662635e+07 1.56503068e+02] thelist = textwrap.dedent( '\n'.join(ut0.sub(r'\1' ""%20f"" % x) for x in a)).splitlines() print '\n'.join(thelist) emits:  550.056103 6773.83566 601001.513 355425142.0 707254.875 883.174744 82.232051 425076609.0 62866263.5 156.503068 I can't guarantee that %12f won't lose significant digits. (I made an edit and changed the way my test arrays are generated to reflect this.) If I increase to %20 or more to guarantee this then there is simply too much padding to the left. (want the largest value to have no leading spaces) I'll take back-of-the-cupboard solutions too!  Pythons string formatting can both print out only the necessary decimals (with %g) or use a fixed set of decimals (with %f). However you want to print out only the necessary decimals except if the number is a whole number then you want one decimal and that makes it complex. This means you would end up with something like: def printarr(arr): for x in array: if math.floor(x) == x: res = '%.1f' % x else: res = '%.10g' % x print ""%*s"" % (15-res.find('.')+len(res) res) This will first create a string either with 1 decimal if the value is a whole number or it will print with automatic decimals (but only up to 10 numbers) if it is not a fractional number. Lastly it will print it adjusted so that the decimal point will be aligned. Probably though numpy actually does what you want because you typically do want it to be in exponential mode if it's too long.",python formatting numpy code-golf573487,A,"Any way to create a NumPy matrix with C API? I read the documentation on NumPy C API I could find but still wasn't able to find out whether there is a possibility to construct a matrix object with C API Š—” not a two-dimensional array. The function is intended for work with math matrices and I don't want strange results if the user calls matrix multiplication forgetting to convert this value from an array to a matrix (multiplication and exponentiation being the only difference that matrix subclass has). What do you mean by ""matrix""? Is it `numpy.matrix` class? You can call any python callable with the PyObject_Call* functions. PyObject *numpy = PyImport_ImportModule(""numpy""); PyObject *numpy_matrix = PyObject_GetAttrString(numpy ""matrix""); PyObject *my_matrix = PyObject_CallFunction(numpy_matrix ""(s)"" ""0 0; 0 0""); This will create a matrix my_matrix of size 2x2. EDIT: Changed references to numpy.zeros/numpy.ndarray to numpy.matrix instead. I also found a good tutorial on the subject: http://starship.python.net/crew/hinsen/NumPyExtensions.html OP asks `numpy.matrix` but `zeros` returns `ndarray`.  numpy.matrix is an ordinary class defined in numpy/core/defmatrix.py. You can construct it using C API as any other instance of user-defined class in Python.",python numpy python-c-api1966207,A,"Converting NumPy array into Python List structure? How do I convert a NumPy array to a Python List (for example [[123][456]] ) and do it reasonably fast? Arrays are *already* array_like as are lists. Do you mean ""how do I convert an array to a list""? classic SO crankiness directly above! Use tolist(): import numpy as np >>> np.array([[123][456]]).tolist() [[1 2 3] [4 5 6]]  NumPy arrays have a tolist method: In [1]: arr=np.array([[123][456]]) In [2]: arr.tolist() Out[2]: [[1 2 3] [4 5 6]]",python numpy1624395,A,"Removing Array Elements in Python while keeping track of their position I'v got two numpy arrays. The first array contains some zeros (which are distributed randomly over the length of the array) which I would like to remove. My issue is that I would also like to remove the entries of the second array at the index positions where the first array elements are zero. I only came up with a very cumbersome for-loop. Does anyone have an ""elegant"" method for doing this? Thx! You can use boolean indexing. x!=0 gives you a boolean array with True where x!=0 false where x==0. If you index either x or y with this array (ie x_nozeros=x[x!=0]) then you will get only the elements where x!=0. eg: In [1]: import numpy as np In [2]: x = np.array([120304]) In [3]: y = np.arange(17) In [4]: indx = x!=0 In [5]: x_nozeros = x[indx] In [6]: y_nozeros = y[indx] In [7]: x_nozeros Out[7]: array([1 2 3 4]) In [8]: y_nozeros Out[8]: array([1 2 4 6])  Is it what you want? I am a NumPy newbie. In [1]: import numpy as np In [2]: a = np.array([120304]) In [3]: b = np.array([123456]) In [4]: b[np.where(a)] Out[4]: array([1 2 4 6]) In [5]: np.where(a) Out[5]: (array([0 1 3 5])) In [6]: a[np.where(a)] Out[6]: array([1 2 3 4]) That's exactly what I looked for thanks! @AFoglia thanks for the introduction of np.extract. it's really cool. @Dzz Glad it helped :) This is the way I usually do it but there is an even simpler method. `np.extract(ab)`. It does the same as `b[np.where(a)]`.",python arrays numpy1939228,A,"Constructing a python set from a numpy matrix I'm trying to execute the following >> from numpy import * >> x = array([[323][444]]) >> y = set(x) TypeError: unhashable type: 'numpy.ndarray' How can I easily and efficiently create a set from a numpy array? The immutable counterpart to an array is the tuple hence try convert the array of arrays into an array of tuples: >> from numpy import * >> x = array([[323][444]]) >> x_hashable = map(tuple x) >> y = set(x_hashable) set([(3 2 3) (4 4 4)]) and how to I easily/efficiently transform back to a list? `map(array y)`  If you want a set of the elements: >> y = set(e for r in x for e in r) set([2 3 4]) For a set of the rows: >> y = set(tuple(r) for r in x) set([(3 2 3) (4 4 4)])  The above answers work if you want to create a set out of the elements contained in an ndarray but if you want to create a set of ndarray objects Š—– or use ndarray objects as keys in a dictionary Š—– then you'll have to provide a hashable wrapper for them. See the code below for a simple example: from hashlib import sha1 from numpy import all array uint8 class hashable(object): r'''Hashable wrapper for ndarray objects. Instances of ndarray are not hashable meaning they cannot be added to sets nor used as keys in dictionaries. This is by design - ndarray objects are mutable and therefore cannot reliably implement the __hash__() method. The hashable class allows a way around this limitation. It implements the required methods for hashable objects in terms of an encapsulated ndarray object. This can be either a copied instance (which is safer) or the original object (which requires the user to be careful enough not to modify it). ''' def __init__(self wrapped tight=False): r'''Creates a new hashable object encapsulating an ndarray. wrapped The wrapped ndarray. tight Optional. If True a copy of the input ndaray is created. Defaults to False. ''' self.__tight = tight self.__wrapped = array(wrapped) if tight else wrapped self.__hash = int(sha1(wrapped.view(uint8)).hexdigest() 16) def __eq__(self other): return all(self.__wrapped == other.__wrapped) def __hash__(self): return self.__hash def unwrap(self): r'''Returns the encapsulated ndarray. If the wrapper is ""tight"" a copy of the encapsulated ndarray is returned. Otherwise the encapsulated ndarray itself is returned. ''' if self.__tight: return array(self.__wrapped) return self.__wrapped Using the wrapper class is simple enough: >>> from numpy import arange >>> a = arange(0 1024) >>> d = {} >>> d[a] = 'foo' Traceback (most recent call last): File ""<input>"" line 1 in <module> TypeError: unhashable type: 'numpy.ndarray' >>> b = hashable(a) >>> d[b] = 'bar' >>> d[b] 'bar'  If you want a set of the elements here is another probably faster way: y = set(x.flatten()) PS: after performing comparisons between x.flat x.flatten() and x.ravel() on a 10x100 array I found out that they all perform at about the same speed. For a 3x3 array the fastest version is the iterator version: y = set(x.flat) which I would recommend because it is the less memory expensive version (it scales up well with the size of the array). PS: There is also a NumPy function that does something similar: y = numpy.unique(x) This does produce a NumPy array with the same element as set(x.flat) but as a NumPy array. This is very fast (almost 10 times faster) but if you need a set then doing set(numpy.unique(x)) is a bit slower than the other procedures (building a set comes with a large overhead). @musicinmybrain: very good points! Thank you! Good suggestion! You could also use set(x.ravel()) which does the same thing but creates a copy only if needed. Or better use set(x.flat). x.flat is an iterator over the elements of the flattened array but does not waste time actually flattening the array @conradlee: This solution is indeed designed to give the set of all the numbers found in the array. WARNING: this answer *will not* give you a set of vectors but rather a set of numbers. If you want a set of vectors then see miku's answer below which converts the vectors to tuples",python arrays numpy set1836966,A,Passing numpy.arange() an argument I'm trying to pass the values that I want numpy.arange to use. The code is: for x in numpy.arange(argument) where argument is: argument = (.16.3.1) (tuple) TypeError: arange: scaler arguements expected instead of a tuple arguement = [.16.3.1] (list) TypeError: unsupported operand type(s) for -: 'str' and 'int' arguement = '.16.3.1' (string) TypeError: unsupported operand type(s) for -: 'str' and 'int' and I've tried putting the tuple and list in a string. None of these have worked. I've searched the literature and can find no reference to this. Any insights would be appreciated. arange is like python's range function. Perhaps you were looking for numpy.array? Or maybe you really did want the range to be from 0.1 to 6.3 in steps of 0.1. In that case use Python's argument unpacking syntax: arguments = (.1 6.3 .1) numpy.arange(*arguments) I had to change 'argument =...' to 'arguments =...' and then it worked. I'll have to read up on Python's argument unpacking sytax. Thanks,python numpy1909994,A,"How do I add rows and columns to a NUMPY array? Hello I have a 1000 data series with 1500 points in each. They form a (1000x1500) size Numpy array created using np.zeros((1500 1000)) and then filled with the data. Now what if I want the array to grow to say 1600 x 1100? Do I have to add arrays using hstack and vstack or is there a better way? I would want the data already in the 1000x1500 piece of the array not to be changed only blank data (zeros) added to the bottom and right basically. Thanks. If you want zeroes in the added elements my_array.resize((1600 1000)) should work. Note that this differs from numpy.resize(my_array (1600 1000)) in which previous lines are duplicated which is probably not what you want. Otherwise (for instance if you want to avoid initializing elements to zero which could be unnecessary) you can indeed use hstack and vstack to add an array containing the new elements; numpy.concatenate() (see pydoc numpy.concatenate) should work too (it is just more general as far as I understand). In either case I would guess that a new memory block has to be allocated in order to extend the array and that all these methods take about the same time. Just a note that this doesn't appear to keep the data in place in the case when you merely want to extend the data set: >>> a = numpy.array([[12][34]]) >>> a array([[1 2] [3 4]]) >>> a.resize((24)) Traceback (most recent call last): File """" line 1 in ValueError: cannot resize an array references or is referenced by another array in this way. Use the resize function >>> a = numpy.array(a) >>> a.resize((24)) >>> a array([[1 2 3 4] [0 0 0 0]])  No matter what you'll be stuck reallocating a chunk of memory so it doesn't really matter if you use arr.resize() np.concatenate hstack/vstack etc. Note that if you're accumulating a lot of data sequentially Python lists are usually more efficient.  This should do what you want (ie using 3x3 array and 4x4 array to represent the two arrays in the OP) >>> import numpy as NP >>> a = NP.random.randint(0 10 9).reshape(3 3) >>> a >>> array([[1 2 2] [7 0 7] [0 3 0]]) >>> b = NP.zeros((4 4)) mapping a on to b: >>> b[:3:3] = a >>> b array([[ 1. 2. 2. 0.] [ 7. 0. 7. 0.] [ 0. 3. 0. 0.] [ 0. 0. 0. 0.]]) @kÔàives yes a typo thank you--editing my post now. I got an error from that code. Shouldn't the last line be b[:3 :3] = a ? All the same plus one since when I did that it worked and that is what I was looking for.  You should use reshape() and/or resize() depending on your precise requirement. If you want chapter and verse from the authors you are probably better off posting on the numpy discussion board.",python arrays numpy reshape1401712,A,"How can the euclidean distance be calculated with numpy? I have two points in 3D: (xa ya za) (xb yb zb) And I want to calculate the distance: dist = sqrt((xa-xb)^2 + (ya-yb)^2 + (za-zb)^2) What's the best way to do this with Numpy or with Python in general? I have: a = numpy.array((xa ya za)) b = numpy.array((xb yb zb)) Another instance of this problem solving method. As soon as I submitted the question I got it: def dist(xy): return numpy.sqrt(numpy.sum((x-y)**2)) a = numpy.array((xayaza)) b = numpy.array((xbybzb)) dist_a_b = dist(ab) can you use numpy's sqrt and/or sum implementations? That should make it faster (?). Thanks! I'll update the answer I found this on the other side of the interwebs `norm = lambda x: N.sqrt(N.square(x).sum())` ; `norm(x-y)` scratch that. it had to be somewhere. here it is: `numpy.linalg.norm(x-y)`  Can be done like this don't know how fast it is but its no numpy. from math import sqrt a = (123) #data point 1 b = (456) #data point 2 print sqrt(sum( (a - b)**2 for a b in zip(a b)))  I find a 'dist' function in matplotlib.mlab but i don't think it's handy enough. I'm posting it here just for reference. import numpy as np import matplotlib as plt a = np.array([123]) b = np.array([234]) # distance between a and b dis = plt.mlab.dist(ab)  Use numpy.linalg.norm: dist = numpy.linalg.norm(a-b) I knew there was a reason for me not to accept my own answer :-). Just for the record I managed to see Mark Lavin's answer before he deleted it. I liked it better for the link to Python's docs and the explanation. Can you add some details? The linalg.norm docs can be found here: http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html My only real comment was sort of pointing out the connection between a norm (in this case the Frobenius norm/2-norm which is the default for norm function) and a metric (in this case Euclidean distance).  There's a function for that in SciPy it's called Euclidean example: from scipy.spatial import distance a = (123) b = (456) dst = distance.euclidean(ab)  dist = numpy.linalg.norm(a-b) Is a nice one line answer. However if speed is a concern I would recommend experimenting on your machine. I found that using the math library's sqrt with the ** operator for the square is much faster on my machine than the one line numpy solution. I ran my tests using this simple program: #!/usr/bin/python import math import numpy from random import uniform def fastest_calc_dist(p1p2): return math.sqrt((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2 + (p2[2] - p1[2]) ** 2) def math_calc_dist(p1p2): return math.sqrt(math.pow((p2[0] - p1[0]) 2) + math.pow((p2[1] - p1[1]) 2) + math.pow((p2[2] - p1[2]) 2)) def numpy_calc_dist(p1p2): return numpy.linalg.norm(numpy.array(p1)-numpy.array(p2)) TOTAL_LOCATIONS = 1000 p1 = dict() p2 = dict() for i in range(0 TOTAL_LOCATIONS): p1[i] = (uniform(01000)uniform(01000)uniform(01000)) p2[i] = (uniform(01000)uniform(01000)uniform(01000)) total_dist = 0 for i in range(0 TOTAL_LOCATIONS): for j in range(0 TOTAL_LOCATIONS): dist = fastest_calc_dist(p1[i] p2[j]) #change this line for testing total_dist += dist print total_dist On my machine math_calc_dist runs much faster than numpy_calc_dist: 1.5 seconds versus 23.5 seconds. To get a measurable difference between fastest_calc_dist and math_calc_dist I had to up TOTAL_LOCATIONS to 6000. Then fastest_calc_dist takes ~50 seconds while math_calc_dist takes ~60 seconds. You can also experiment with numpy.sqrt and numpy.square though both were slower than the math alternatives on my machine. My tests were run with Python 2.6.6. You're badly misunderstanding how to use numpy... _Don't_ use loops or list comprehensions. If you're iterating through and applying the function to _each_ item then yeah the numpy functions will be slower. The whole point is to vectorize things. If I move the numpy.array call into the loop where I am creating the points I do get better results with numpy_calc_dist but it is still 10x slower than fastest_calc_dist. If I have that many points and I need to find the distance between each pair I'm not sure what else I can do to advantage numpy. I realize this thread is old but I just want to reinforce what Joe said. You are not using numpy correctly. What you are calculating is the sum of the distance from every point in p1 to every point in p2. The solution with numpy/scipy is over 70 times quicker on my machine. Make p1 and p2 into an array (even using a loop if you have them defined as dicts). Then you can get the total sum in one step `scipy.spatial.distance.cdist(p1 p2).sum()`. That is it. Or use `numpy.linalg.norm(p1-p2).sum()` to get the sum between each point in p1 and the corresponding point in p2 (i.e. not every point in p1 to every point in p2). And if you do want every point in p1 to every point in p2 and don't want to use scipy as in my previous comment then you can use np.apply_along_axis along with numpy.linalg.norm to still do it much much quicker then your ""fastest"" solution. Previous versions of NumPy had very slow norm implementations. In current versions there's no need for all this.  You can just substract the vectors and then innerproduct. Following your example a = numpy.array((xayaza)) b = numpy.array((xbybzb)) tmp = a - b result = numpy.dot( tmp.T  tmp) Simple Code an easy to understand. this will give me the square of the distance. you're missing a sqrt here.",python numpy euclidean-distance934616,A,How do I find out if a numpy array contains integers? I know there is a simple solution to this but can't seem to find it at the moment. Given a numpy array I need to know if the array contains integers. Checking the dtype per-se is not enough as there are multiple int dtypes (int8 int16 int32 int64 ...). Please specify whether you want to check whether the **type** is an integer or whether the **value** is an integer (see [my solution](http://stackoverflow.com/a/7236784/866007)). Checking for an integer type does not work for floats that are integers e.g. 4. Better solution is np.equal(np.mod(x 1) 0) as in: >>> import numpy as np >>> def isinteger(x): ... return np.equal(np.mod(x 1) 0) ... >>> foo = np.array([0. 1.5 1.]) >>> bar = np.array([-5 1 2 3 -4 -2 0 1 0 0 -1 1]) >>> isinteger(foo) array([ True False True] dtype=bool) >>> isinteger(bar) array([ True True True True True True True True True True True True] dtype=bool) >>> isinteger(1.5) False >>> isinteger(1.) True >>> isinteger(1) True  Found it in the numpy book! Page 23: The other types in the hierarchy de´Œne particular categories of types. These categories can be useful for testing whether or not the object returned by self.dtype.type is of a particular class (using issubclass). issubclass(n.dtype('int8').type n.integer) >>> True issubclass(n.dtype('int16').type n.integer) >>> True  This also works:  n.dtype('int8').kind == 'i' For unsigned dtype kind = 'u'. A more general test should be: **some_dtype.kind in ('u''i')**,python numpy417664,A,"How can I use Numerical Python with Python 2.6 I'm forced to upgrade to Python 2.6 and am having issues using Numerical Python (NumPy) with Python 2.6 in Windows. I'm getting the following error... Traceback (most recent call last): File ""<pyshell#0>"" line 1 in <module> from numpy.core.numeric import arraydotall File ""C:\svn\svn_urbansim\UrbanSimDev\Builds\working\urbansim\Tools\Python26\lib\site-packages\numpy\__init__.py"" line 39 in <module> import core File ""C:\svn\svn_urbansim\UrbanSimDev\Builds\working\urbansim\Tools\Python26\lib\site-packages\numpy\core\__init__.py"" line 5 in <module> import multiarray ImportError: Module use of python25.dll conflicts with this version of Python. It appears that the existing module is trying to use the python25.dll file. Is there any way I can tell it to use the python26.dll file instead without modifying the source code? NumPy 1.3.0 is available for Python 2.6 now.  How did you install it? NumPy doesn't currently have a Python 2.6 binary. If you have LAPACK/ATLAS/BLAS etc. and a development environment you should be able to compile numpy from sources. Otherwise I think you're stuck with using Python 2.5 on Windows if you need NumPy. The next version of NumPy should have a 2.6 binary and it's likely to be out within the next month or so. [Edit]: It appears that a pygame developer created a NumPy 1.2.1 binary for Python 2.6 on Windows available here.",python windows numpy1988091,A,"Poor numpy.cross() performance I've been doing some performance testing in order to improve the performance of a pet project I'm writing. It's a very number-crunching intensive application so I've been playing with Numpy as a way of improving computational performance. However the result from the following performance tests were quite surprising.... Test Source Code (Updated with test cases for hoisting and batch submission) import timeit numpySetup = """""" import numpy left = numpy.array([1.00.00.0]) right = numpy.array([0.01.00.0]) """""" hoistSetup = numpySetup +'hoist = numpy.cross\n' pythonSetup = """""" left = [1.00.00.0] right = [0.01.00.0] """""" numpyBatchSetup = """""" import numpy l = numpy.array([1.00.00.0]) left = numpy.array([l]*10000) r = numpy.array([0.01.00.0]) right = numpy.array([r]*10000) """""" pythonCrossCode = """""" x = ((left[1] * right[2]) - (left[2] * right[1])) y = ((left[2] * right[0]) - (left[0] * right[2])) z = ((left[0] * right[1]) - (left[1] * right[0])) """""" pythonCross = timeit.Timer(pythonCrossCode pythonSetup) numpyCross = timeit.Timer ('numpy.cross(left right)'  numpySetup) hybridCross = timeit.Timer(pythonCrossCode numpySetup) hoistCross = timeit.Timer('hoist(left right)' hoistSetup) batchCross = timeit.Timer('numpy.cross(left right)' numpyBatchSetup) print 'Python Cross Product : %4.6f ' % pythonCross.timeit(1000000) print 'Numpy Cross Product : %4.6f ' % numpyCross.timeit(1000000) print 'Hybrid Cross Product : %4.6f ' % hybridCross.timeit(1000000) print 'Hoist Cross Product : %4.6f ' % hoistCross.timeit(1000000) # 100 batches of 10000 each is equivalent to 1000000 print 'Batch Cross Product : %4.6f ' % batchCross.timeit(100) Original Results Python Cross Product : 0.754945 Numpy Cross Product : 20.752983 Hybrid Cross Product : 4.467417 Final Results Python Cross Product : 0.894334 Numpy Cross Product : 21.099040 Hybrid Cross Product : 4.467194 Hoist Cross Product : 20.896225 Batch Cross Product : 0.262964 Needless to say this wasn't the result I expected. The pure Python version performs almost 30x faster than Numpy. Numpy performance in other tests has been better than the Python equivalent (which was the expected result). So I've got two related questions: Can anyone explain why NumPy is performing so poorly in this case? Is there something I can do to fix it? To reduce the numpy calling overhead you might try using cython as an intermediate to call into the numpy functions. See Fast numerical computations with Cython (SciPy 2009) for details.  Excellent post! I think that the comparison is not actually fair. Batch Cross Product gives an array containing the cross products of all vectors while Python Cross Product gives one vector at a time. If you need to compute all cross products at once of course Batch is better but if you need to compute every cross product separately you should include the overhead of accessing the array. Also if a cross product if a function of the previous cross product the Batch implementation should be modified.  You can see the source code yourself here: http://www.google.com/codesearch/p?hl=en#5mAq98l-MUw/trunk/dnumpy/numpy/core/numeric.py&q=cross%20package:numpy&sa=N&cd=1&ct=rc numpy.cross just handles lots of cases and does some extra copies. In general numpy is going to be plenty fast enough for slow things like matrix multiplication or inversion - but operations on small vectors like that have a lot of overhead.  Try this with larger arrays. I think that just the cost of calling the methods of numpy here overruns the simple several list accesses required by the Python version. If you deal with larger arrays I think you'll see large wins for numpy. In this particular case 3 component arrays (xyz co-ordinates) are by far the most common case. What's also a bit weird is that even reading from numpy arrays the python code is still faster. If it was call overhead I'd expect that to be slowed down even more than the pure NumPy solution. @Adam: but by reading from numpy's arrays you save the overhead of calling the `cross` function itself which is a dynamically loaded extension so it goes through at least a couple of pointers. For such short arrays it indeed makes sense as a micro-optimization to unroll the call to `cross` I just added a test case where I batched the arrays together and saw a considerable performance boost. So I'd say the overhead theory is correct. Looks like if I want to use Numpy for a performance boost I'll need to find a way of batching these operations together.",python performance numpy1066758,A,"find length of sequences of identical values in a numpy array In a pylab program (which could probably be a matlab program as well) I have a numpy array of numbers representing distances: d[t] is the distance at time t (and the timespan of my data is len(d) time units). The events I'm interested in are when the distance is below a certain threshold and I want to compute the duration of these events. It's easy to get an array of booleans with b = d<threshold and the problem comes down to computing the sequence of the lengths of the True-only words in b. But I do not know how to do that efficiently (i.e. using numpy primitives) and I resorted to walk the array and to do manual change detection (i.e. initialize counter when value goes from False to True increase counter as long as value is True and output the counter to the sequence when value goes back to False). But this is tremendously slow. How to efficienly detect that sort of sequences in numpy arrays ? Below is some python code that illustrates my problem : the fourth dot takes a very long time to appear (if not increase the size of the array) from pylab import * threshold = 7 print '.' d = 10*rand(10000000) print '.' b = d<threshold print '.' durations=[] for i in xrange(len(b)): if b[i] and (i==0 or not b[i-1]): counter=1 if i>0 and b[i-1] and b[i]: counter+=1 if (b[i-1] and not b[i]) or i==len(b)-1: durations.append(counter) print '.' durations = [] counter = 0 for bool in b: if bool: counter += 1 elif counter > 0: durations.append(counter) counter = 0 if counter > 0: durations.append(counter) sure this is more consise but just as inefficient ; what I want to do is move the loop down to the C layer by means of using some clever combination of numpy calls... check my edited answer I now offer one such ""clever combinations"" (always trying hard not to be TOO clever though;-) -- but do measure the speed of that one AND the itertools.groupby-based solution and let us know which one is faster (and by how much) in examples realistic-for-you!  Here is a solution using only arrays: it takes an array containing a sequence of bools and counts the length of the transitions. >>> from numpy import array arange >>> b = array([000111000111100] dtype=bool) >>> sw = (b[:-1] ^ b[1:]); print sw [False False True False False True False False True False False False True False] >>> isw = arange(len(sw))[sw]; print isw [ 2 5 8 12] >>> lens = isw[1::2] - isw[::2]; print lens [3 4] sw contains a true where there is a switch isw converts them in indexes. The items of isw are then subtracted pairwise in lens. Notice that if the sequence started with an 1 it would count the length of the 0s sequences: this can be fixed in the indexing to compute lens. Also I have not tested corner cases such sequences of length 1.  Just in case anyone is curious (and since you mentioned MATLAB in passing) here's one way to solve it in MATLAB: threshold = 7; d = 10*rand(1100000); % Sample data b = diff([false (d < threshold) false]); durations = find(b == -1)-find(b == 1); I'm not too familiar with Python but maybe this could help give you some ideas. =) thanks for this answer as well this is exactly the kind of stuff I was looking for diff() exists in numpy too so this is more or less what you want though replace find(foo) with where(foo)[0].  While not numpy primitives itertools functions are often very fast so do give this one a try (and measure times for various solutions including this one of course): def runs_of_ones(bits): for bit group in itertools.groupby(bits): if bit: yield sum(group) If you do need the values in a list just can use list(runs_of_ones(bits)) of course; but maybe a list comprehension might be marginally faster still: def runs_of_ones_list(bits): return [sum(g) for b g in itertools.groupby(bits) if b] Moving to ""numpy-native"" possibilities what about: def runs_of_ones_array(bits): # make sure all runs of ones are well-bounded bounded = numpy.hstack(([0] bits [0])) # get 1 at run starts and -1 at run ends difs = numpy.diff(bounded) run_starts = numpy.where(difs > 0) run_ends = numpy.where(difs < 0) return run_ends - run_starts Again: be sure to benchmark solutions against each others in realistic-for-you examples! Hmmmmm... that last one looks familiar. ;) Thanks a lot ! The diff/where solution is exactly what I had in mind (not to mention it is about 10 times faster than the other solutions). Call that ""not too clever"" if you like but I wish I was clever enough to come up with it :-) @gnovice I don't do matlab (funny enough my daughter now a PhD candidate in advanced radio engineering does;-) but now looking at your answer I do see the analogies -- get the end-of-runs minus the start-of-runs get those by locating <0 and >0 spot in the differences and pad the bits with zeros to make sure all runs-of-ones do end. Guess there aren't that many ways to skin this ""run lengths"" problem!-) @Gyom you're welcome -- as @gnovice hints the matlab solution is also similar or so I guess it would be if one knew matlab -- so it must be that neither is very clever;-)... it's more a question of having had to do run-length coding stuff before (most of the time in my edit was about translating from Numeric which is what I still tend instinctively to turn to to much-better numpy -- but where I actually first learned such things was with APL 30 years ago when I was still a hardware designer...!-).",python matlab numpy pylab1846836,A,"the best shortest path algorithm what is the difference between the ""Floyd-Warshall algorithm"" and ""Dijkstra's Algorithm"" and which is the best for finding the shortest path in a graph? I need to calculate the shortest path between all the pairs in a net and save the results to an array as follows: **A B C D E** A 0 10 15 5 20 B 10 0 5 5 10 C 15 5 0 10 15 D 5 5 10 0 15 E 20 10 15 15 0 thanks for your answers but the other one was closed mostly because of the user's bad english and one of the solutions named these exact two algorithms as alternatives. If we close this as dup how will the author find out more about the previous question? Will we really all be nice enough to go over there and vote to reopen? hi sorry but wanted to add an array example with respect to a picture but I did not do thanks SilentGhost for re-edit my question Shouldn't DE in that graph be 15? In the meanwhile better algorithms for the single source shortest path problem are known. A practically relevant one is a derivation of Dijkstra's algorithm by Torben Hagerup. The algorithm has the same worst case complexity as Djikstra's but in the average case the expected runtime is linear in the size of the graph which is much faster than the pure Dijkstra. The idea of the algorithm is based on the idea that there is no need to always poll the minimum edge from the queue. It is possible poll an edge from the queue whose weight is 1+k times as large as the minimum edge weight where k is some number larger 0. Even if such an edge is chosen the algorithm will still find the shortest path.  Dijkstra's algorithm finds the shortest path between a node and every other node in the graph. You'd run it once for every node. Weights must be non-negative so if necessary you have to normalise the values in the graph first. Floyd-Warshall calculates the shortest routes between all pairs of nodes in a single run! Cycle weights must be non-negative and the graph must be directed (your diagram is not). Johnson's algorithm is using Dijkstra's algorithm to find all pairs in a single pass and is faster for sparse trees (see the link for analysis). From the wikipedia link you cite for Dijkstra: ""the algorithm finds the path with lowest cost between that vertex and **every** other vertex"" (my emphasis). You thus don't need to run it for every pair of vertex but only for every vertex. thx Andreas fixed You can convert an undirected graph to a directed graph by replacing every edge uv with two edges (uv) and (vu) with the same weight. Then presumably Floyd-Warshall should work just fine? err .. floyd-warshall does not require it to have non-negative edges from wikipedia ""is a graph analysis algorithm for finding shortest paths in a weighted graph with positive or negative edge weights (but with no negative cycles)""  Floyd Warshall find the paths between all pairs of vertices but Dijkstra only finds the path from one vertex to all others. Floyd Warshall is O(|V|3) and Dikstra is O(|E| + |V| log |V|) but you'll have to run it V times to find all pairs which gives a complexity of O(|E * V| + |V2| log |V|) I guess. This means it's possibly faster to use Dijsktra repeatedly than the FW algorithm I would try both approaches and see which one is fastest in the actual case. Francis Haart's comment: ""@Andreas Brinck in a complete graph E=(V^2-V)/2 and dijkstra's would be no faster.""  Use the Floyd-Warshall algorithm if you want to find the shortest path between all pairs of vertexes as it has a (far) higher running time than Dijkstra's algorithm. The Floyd-Warshall algorithm has a worst case performance of O(|V|3) where as Dijkstra's has a worse case performance of O(|E| + |V|log |V|)  Dijkstra's is mainly for single pair shortest path finding i.e. from one node to all other nodes where as Floyd-Warshall is for all-pair shortest path i.e. shortest path between all pair of vertices. The Floyd-Warshall algorithm has a worst case performance of O(|V|3) where as Dijkstra's has a worse case performance of O(|E| + |V|log |V|) Also Dijkstra's cannot be used for negative weights ( we use Bellmann Ford for the same ). but for Floyd-Warshall we can use negative weights but no negative cycles  Dijkstra finds the shortest path from only one vertex Floyd-Warshall finds it between all of them.",python algorithm numpy shortest-path1564000,A,List of tuples to Numpy recarray Given a list of tuples where each tuple represents a row in a table e.g. tab = [('a'1)('b'2)] Is there an easy way to convert this to a record array? I tried np.recarray(tabdtype=[('name'str)('value'int)]) which doesn't seem to work. try np.rec.fromrecords(tab) rec.array([('a' 1) ('b' 2)] dtype=[('f0' '|S1') ('f1' '<i4')]),python numpy1783369,A,String preallocation in numpy.arrays >>> import numpy as np >>> a = np.array(['zero' 'one' 'two' 'three']) >>> a[1] = 'thirteen' >>> print a ['zero' 'thirt' 'two' 'three'] >>> As you can see the second element has been truncated to the maximum number of characters in the original array. Is it possible to workaround this problem? If you don't know the maximum length element then you can use dtype=object >>> import numpy as np >>> a = np.array(['zero' 'one' 'two' 'three'] dtype=object) >>> a[1] = 'thirteen' >>> print a ['zero' 'thirteen' 'two' 'three'] >>> But then you lose the performance advantages of having an allocated contigous block of memory so you may as well use a python list.  Use the dtype argument in numpy.array e.g.: >>> import numpy as np >>> a = np.array(['zero' 'one' 'two' 'three'] dtype='S8') >>> a[1] = 'thirteen' >>> print(a) ['zero' 'thirteen' 'two' 'three'],python numpy500328,A,"Identifying numeric and array types in numpy Is there an existing function in numpy that will tell me if a value is either a numeric type or a numpy array? I'm writing some data-processing code which needs to handle numbers in several different representations (by ""number"" I mean any representation of a numeric quantity which can be manipulated using the standard arithmetic operators + - * / **). Some examples of the behavior I'm looking for >>> is_numeric(5) True >>> is_numeric(123.345) True >>> is_numeric('123.345') False >>> is_numeric(decimal.Decimal('123.345')) True >>> is_numeric(True) False >>> is_numeric([1 2 3]) False >>> is_numeric([1 '2' 3]) False >>> a = numpy.array([1 2.3 4.5 6.7 8.9]) >>> is_numeric(a) True >>> is_numeric(a[0]) True >>> is_numeric(a[1]) True >>> is_numeric(numpy.array([numpy.array([1]) numpy.array([2])]) True >>> is_numeric(numpy.array(['1']) False If no such function exists I know it shouldn't be hard to write one something like isinstance(n (int float decimal.Decimal numpy.number numpy.ndarray)) but are there other numeric types I should include in the list? What should return `is_numeric([123])` and `is_numeric([1 '2' 3])`? False in both cases. I'll edit that into the question. What about `numpy.array([numpy.array([1]) numpy.array([2])])`? `numpy.array(['1'])`? ""Testing by trying to do math"" will not catch `bool` values or numpy arrays of them. In general the flexible fast and pythonic way to handle unknown types is to just perform some operation on them and catch an exception on invalid types. try: a = 5+'5' except TypeError: print ""Oops"" Seems to me that this approach is easier than special-casing out some function to determine absolute type certainty. It is not an answer to the question but I agree completely. The problem is that '5'*5 does work. @JF that's true but I still like this answer to this question. I think the str*int bug will be easier to catch than the is_numeric function will be to write. Also consider that IIRC no other mathematical operation is defined where the two operands are str and int. I like it too... if only I could accept more than one ;-) `TrueFalse` (and numpy arrays of them) ""look like numbers"" by this test.  isinstance(numpy.int32(4) numbers.Number) returns False so that doesn't quite work. operator.isNumberType() does work on all the variants of numpy numbers however including numpy.array([1]).  Your is_numeric is ill-defined. See my comments to your question. Other numerical types could be: long complex fractions.Fraction numpy.bool_ numpy.ubyte ... operator.isNumberType() returns True for Python numbers and numpy.array. Since Python 2.6 you can use isinstance(d numbers.Number) instead of deprecated operator.isNumberType(). Generally it is better to check the capabilities of the object (e.g. whether you can add an integer to it) and not its type. Yeah but if I had an exact definition in mind I could have written the function ;-) I edited in some more information.  As others have answered there could be other numeric types besides the ones you mention. One approach would be to check explicitly for the capabilities you want with something like def is_numeric(obj): attrs = ['__add__' '__sub__' '__mul__' '__div__' '__pow__'] return all(hasattr(obj attr) for attr in attrs) This works for all your examples except the last one numpy.array(['1']). That's because numpy.ndarray has the special methods for numeric operations but raises TypeError if you try to use them inappropriately with string or object arrays. You could add an explicit check for this like  ... and not (isinstance(obj ndarray) and obj.dtype.kind in 'OSU') This may be good enough. But... you can never be 100% sure that somebody won't define another type with the same behavior so a more foolproof way is to actually try to do a calculation and catch the exception something like def is_numeric_paranoid(obj): try: obj+obj obj-obj obj*obj obj**obj obj/obj except ZeroDivisionError: return True except Exception: return False else: return True but depending on how often you plan to call use it and with what arguments this may not be practical (it can be potentially slow e.g. with large arrays). `TrueFalse` and numpy arrays of them look like numbers by these tests so they'd need to be included in the `and not` clause; assuming that you don't want to do math on them.  Also numpy has numpy.isreal and other similar functions (numpy.is + Tab should list them). They all have their fun corner cases but one of those could be useful.",python numpy1599754,A,"Is there easy way in python to extrapolate data points to the future? I have a simple numpy array for every date there is a data point. Something like this: >>> import numpy as np >>> from datetime import date >>> from datetime import date >>> x = np.array( [(date(200835) 4800 ) (date(2008315) 4000 ) (date(20083 20) 3500 ) (date(200845) 3000 ) ] ) Is there easy way to extrapolate data points to the future: date(200851) date(2008 5 20) etc? I understand it can be done with mathematical algorithms. But here I am seeking for some low hanging fruit. Actually I like what numpy.linalg.solve does but it does not look applicable for the extrapolation. Maybe I am absolutely wrong. Actually to be more specific I am building a burn-down chart (xp term): 'x=date and y=volume of work to be done' so I have got the already done sprints and I want to visualise how the future sprints will go if the current situation persists. And finally I want to predict the release date. So the nature of 'volume of work to be done' is it always goes down on burn-down charts. Also I want to get the extrapolated release date: date when the volume becomes zero. This is all for showing to dev team how things go. The preciseness is not so important here :) The motivation of dev team is the main factor. That means I am absolutely fine with the very approximate extrapolation technique. When you googled for ""statistics python"" what did you find? Any questions on any of the statistical packages you found? It is hard to talk about any extrapolation without knowing the nature of the data in question. The above as far as one can see could be anything (not excluding random values) so to talk about any practical approach would be just speculating. Refine the question. you are absolutely right! refined. A simple way of doing extrapolations is to use interpolating polynomials or splines: there are many routines for this in scipy.interpolate and there are quite easy to use (just give the (x y) points and you get a function [a callable precisely]). Now as as been pointed in this thread you cannot expect the extrapolation to be always meaningful (especially when you are far from your data points) if you don't have a model for your data. However I encourage you to play with the polynomial or spline interpolations from scipy.interpolate to see whether the results you obtain suit you. like this definitely going to try thanks a lot!  The mathematical models are the way to go in this case. For instance if you have only three data points you can have absolutely no indication on how the trend will unfold (could be any of two parabola.) Get some statistics courses and try to implement the algorithms. Try Wikibooks. absolutely agree do understand it but want to clarify I am just checking if by some chance there is numpy.extrapolate function already in place with argument ""choose extrapolation method"" :) That's why I call it ""low hanging fruit""  It's all too easy for extrapolation to generate garbage; try this. Many different extrapolations are of course possible; some produce obvious garbage some non-obvious garbage many are ill-defined. """""" extrapolate ymd data with scipy UnivariateSpline """""" import numpy as np from scipy.interpolate import UnivariateSpline # pydoc scipy.interpolate.UnivariateSpline -- fitpack unclear from datetime import date from pylab import * # ipython -pylab __version__ = ""denis 23oct"" def daynumber( ymd ): """""" 200511 -> 0 200611 -> 365 ... """""" return date( ymd ).toordinal() - date( 200511 ).toordinal() days values = np.array([ (daynumber(200511) 1.2 ) (daynumber(200541) 1.8 ) (daynumber(200591) 5.3 ) (daynumber(2005101) 5.3 ) ]).T dayswanted = np.array([ daynumber( year month 1 ) for year in range( 2005 2006+1 ) for month in range( 1 12+1 )]) np.set_printoptions( 1 ) # .1f print ""days:"" days print ""values:"" values print ""dayswanted:"" dayswanted title( ""extrapolation with scipy.interpolate.UnivariateSpline"" ) plot( days values ""o"" ) for k in (123): # line parabola cubicspline extrapolator = UnivariateSpline( days values k=k ) y = extrapolator( dayswanted ) label = ""k=%d"" % k print label y plot( dayswanted y label=label ) # pylab legend( loc=""lower left"" ) grid(True) savefig( ""extrapolate-UnivariateSpline.png"" dpi=50 ) show() Added: a Scipy ticket says ""The behavior of the FITPACK classes in scipy.interpolate is much more complex than the docs would lead one to believe"" -- imho true of other software doc too. very good example! thank you!  You have to swpecify over which function you need extrapolation. Than you can use regression http://en.wikipedia.org/wiki/Regression%5Fanalysis to find paratmeters of function. And extrapolate this in future. For instance: translate dates into x values and use first day as x=0 for your problem the values shoul be aproximatly (01.2) (4001.8)(9005.3) Now you decide that his points lies on function of type a+b*x+c*x^2 Use the method of least squers to find ab and c http://en.wikipedia.org/wiki/Linear%5Fleast%5Fsquares (i will provide full source but later beacuase I do not have time for this)",python numpy interpolation spline burndowncharts1520234,A,"How to check which version of Numpy I'm using? How can I check which version of Numpy I'm using? I'm using Mac OS X 10.6.1 Snow Leopard. numpy.version.version +1 - That looks like a better way of doing it than mine. @Dominic Rodger: yeah but your is more general to any module that cares to set a `__version__`. This is not the public API numpy.__version__ is. Actually `import numpy ; numpy.version.version` . The lack of `import numpy` through me an obvious newbie. Since the use of `__version__` in recommended in PEP8 and most packages support `__version__` vs the non standard `version.version` I think that this answer should be treated more as a curiosity than an accepted method. Use `numpy.__version__` or `.__version__` as [Dominic Rodger's answer recommends](http://stackoverflow.com/a/1520264/298607) Parse the version (and create your own version strings) as recommended in PEP 386 / PEP 440.  You can also check if your version is using MKL with: import numpy numpy.show_config()  from the command line you can simply issue: python -c ""import numpy; print numpy.version.version"" or python -c ""import numpy; print numpy.__version__""  numpy.version.version type it. This answer doesn't improve on the identical answer given (and accepted) four years before this post.  >> import numpy >> print numpy.__version__ Thank you for your help! @keijo - You might want to consider changing your accepted answer to SilentGhost's. This is the API we numpy developers will support. numpy.version.version is an implementation detail that should not be relied upon. The same works for scipy ! ....",python numpy1727950,A,"Just Curious about Python+Numpy to Realtime Gesture Recognition i 'm just finish labs meeting with my advisor previous code is written in matlab and it run offline mode not realtime mode so i decide to convert to python+numpy (in offline version) but after labs meeting my advisor raise issue about speed of realtime recognition so i have doubt about speed of python+numpy to do this project. or better in c? my project is about using electronic glove (2x sensors) to get realtime data and do data processing recognition process ohh don't know about accepting answers thankfor that :) What size arrays (N) are you dealing with? I've found for some problems the speed advantage of numpy over pure python only become recognizable when N > 10000 or so. In fact pure python can be faster than numpy when dealing with small arrays since there is a performance hit associated with importing numpy and creating the arrays. NumPy is very fast if you follow some basic rules. You should avoid Python loops using the operators provided by NumPy instead whenever you can. This and this should be a good starting points. After reading through that why don't you write some simple code in both Matlab and NumPy and compare the performance? If it performs well in NumPy it should be enough to convince your advisor especially if the code is representative of the actual algorithms you are using in your project. Note: you should also see that your algorithm really is suited for realtime recognition.  You might look at OpenCV which has Python libs ctypes-opencv and opencv-cython; I haven't used these myself. Ideally you want to combine a fast-running C inner loop with a flexible Python/Numpy play-with-algorithms. Bytheway google ""opencv gesture recognition"" Šæê 6680 hits.  I think the answer depends on three things: how well you code in Matlab how well you code in Python/Numpy and your algorithm. Both Matlab and Python can be fast for number crunching if you're diligent about vectorizing everything and using library calls. If your Matlab code is already very good I would be surprised if you saw much performance benefit moving to Numpy unless there's some specific idiom you can use to your advantage. You might not even see a large benefit moving to C. I this case your effort would likely be better spent tuning your algorithm. If your Matlab code isn't so good you could 1) write better Matlab code 2) rewrite in good Numpy code or 3) rewrite in C.",python c numpy gesture-recognition310459,A,"Adding a dimension to every element of a numpy.array I'm trying to transform each element of a numpy array into an array itself (say to interpret a greyscale image as a color image). In other words: >>> my_ar = numpy.array((0510)) [0 5 10] >>> transformed = my_fun(my_ar) # In reality my_fun() would do something more useful array([ [ 0 0 0] [ 5 10 15] [10 20 30]]) >>> transformed.shape (3 3) I've tried: def my_fun_e(val): return numpy.array((val val*2 val*3)) my_fun = numpy.frompyfunc(my_fun_e 1 3) but get: my_fun(my_ar) (array([[0 0 0] [ 5 10 15] [10 20 30]] dtype=object) array([None None None] dtype=object) array([None None None] dtype=object)) and I've tried: my_fun = numpy.frompyfunc(my_fun_e 1 1) but get: >>> my_fun(my_ar) array([[0 0 0] [ 5 10 15] [10 20 30]] dtype=object) This is close but not quite right -- I get an array of objects not an array of ints. Update 3! OK. I've realized that my example was too simple beforehand -- I don't just want to replicate my data in a third dimension I'd like to transform it at the same time. Maybe this is clearer? Use map to apply your transformation function to each element in my_ar: import numpy my_ar = numpy.array((0510)) print my_ar transformed = numpy.array(map(lambda x:numpy.array((xx*2x*3)) my_ar)) print transformed print transformed.shape  I propose:  numpy.resize(my_ar (33)).transpose() You can of course adapt the shape (my_ar.shape[0])*2 or whatever  Does numpy.dstack do what you want? The first two indexes are the same as the original array and the new third index is ""depth"". >>> import numpy as N >>> a = N.array([[123][456][789]]) >>> a array([[1 2 3] [4 5 6] [7 8 9]]) >>> b = N.dstack((aaa)) >>> b array([[[1 1 1] [2 2 2] [3 3 3]] [[4 4 4] [5 5 5] [6 6 6]] [[7 7 7] [8 8 8] [9 9 9]]]) >>> b[11] array([5 5 5])  Does this do what you want: tile(my_ar (113))",python arrays numpy795570,A,"Correlate one set of vectors to another in numpy? Let's say I have a set of vectors (readings from sensor 1 readings from sensor 2 readings from sensor 3 -- indexed first by timestamp and then by sensor id) that I'd like to correlate to a separate set of vectors (temperature humidity etc -- also all indexed first by timestamp and secondly by type). What is the cleanest way in numpy to do this? It seems like it should be a rather simple function... In other words I'd like to see: > a.shape (36520) > b.shape (365 5) > correlations = magic_correlation_function(ab) > correlations.shape (20 5) Cheers /YGA P.S. I've been asked to add an example. Here's what I would like to see: $ In [27]: x $ Out[27]: array([[ 0 0 0] [-1 0 -1] [-2 0 -2] [-3 0 -3] [-4 0.1 -4]]) $ In [28]: y $ Out[28]: array([[0 0] [1 0] [2 0] [3 0] [4 0.1]]) $ In [28]: magical_correlation_function(x y) $ Out[28]: array([[-1.  0.70710678 1. ] [-0.70710678 1.  0.70710678]]) Ps2: whoops mis-transcribed my example. Sorry all. Fixed now. It's not obvious to me what you're trying to do could you maybe post example input and output (for some smaller size data)? What formula are you using to arrive at those numbers? I can't seem to reproduce them with any normal correlation/covariance formulas (but then I'm no expert in statistics). The simplest thing that I could find was using the scipy.stats package In [8]: x Out[8]: array([[ 0.  0.  0. ] [-1.  0.  -1. ] [-2.  0.  -2. ] [-3.  0.  -3. ] [-4.  0.1 -4. ]]) In [9]: y Out[9]: array([[0.  0. ] [1.  0. ] [2.  0. ] [3.  0. ] [4.  0.1]]) In [10]: import scipy.stats In [27]: (scipy.stats.cov(yx) /(numpy.sqrt(scipy.stats.var(yaxis=0)[:numpy.newaxis])) /(numpy.sqrt(scipy.stats.var(xaxis=0)))) Out[27]: array([[-1.  0.70710678 -1. ] [-0.70710678 1.  -0.70710678]]) These aren't the numbers you got but you've mixed up your rows. (Element [00] should be 1.) A more complicated but purely numpy solution is In [40]: numpy.corrcoef(x.Ty.T)[numpy.arange(x.shape[1])[numpy.newaxis:] numpy.arange(y.shape[1])[:numpy.newaxis]] Out[40]: array([[-1.  0.70710678 -1. ] [-0.70710678 1.  -0.70710678]]) This will be slower because it computes the correlation of each element in x with each other element in x which you don't want. Also the advanced indexing techniques used to get the subset of the array you desire can make your head hurt. If you're going to use numpy intensely get familiar with the rules on broadcasting and indexing. They will help you push as much down to the C-level as possible. I've updated the question with the ""right"" inputs -- prob. makes sense to update the response just so as not to confuse people :-) Done. I've also added links to some helpful documentation.  Will this do what you want? correlations = dot(transpose(a) b)  As David said you should define the correlation you're using. I don't know of any definitions of correlation that gives sensible numbers when correlating empty and non-empty signals.",python numpy1544948,A,"python numpy savetxt Can someone indicate what I am doing wrong here? import numpy as np a = np.array([12345]dtype=int) b = np.array(['a''b''c''d''e']dtype='|S1') np.savetxt('test.txt'zip(ab)fmt=""%i %s"") The output is: Traceback (most recent call last): File ""loadtxt.py"" line 6 in <module> np.savetxt('test.txt'zip(ab)fmt=""%i %s"") File ""/Users/tom/Library/Python/2.6/site-packages/numpy/lib/io.py"" line 785 in savetxt fh.write(format % tuple(row) + '\n') TypeError: %d format: a number is required not numpy.string_ I think the problem you are having is that you are passing tuples through the formating string and it can't interpret the tuple with %i. Try using fmt=""%s"" assuming this is what you are looking for as the output: 1 a 2 b 3 c 4 d 5 e that's just wrong. `fmt=""%s""` works for entirely different reasons `fmt=""%s %s""` works too btw. You're right as soon as I posted I realized it worked but not for the reason I thought. My bad. The post by SilentGhost is much better. Thanks.  You need to construct you array differently: z = np.array(zip([12345] ['a''b''c''d''e']) dtype=[('int' int) ('str' '|S1')]) np.savetxt('test.txt' z fmt='%i %s') when you're passing a sequence savetext performs asarray(sequence) call and resulting array is of type |S4 that is all elements are strings! that's why you see this error. one small comment - it should be savetxt() instead of savetext()  If you want to save a CSV file you can also use the function rec2csv (included in matplotlib.mlab) >>> from matplotlib.mlab import rec2csv >>> rec = array([(1.0 2) (3.0 4)] dtype=[('x' float) ('y' int)]) >>> rec = array(zip([12345] ['a''b''c''d''e']) dtype=[('x' int) ('y' str)]) >>> rec2csv(rec 'recordfile.txt' delimiter=' ') hopefully one day pylab's developers will implement a decent support to writing csv files.",python numpy1057666,A,"Using Python to replace MATLAB: how to import data? I want to use some Python libraries to replace MATLAB. How could I import Excel data in Python (for example using NumPy) to use them? I don't know if Python is a credible alternative to MATLAB but I want to try it. Is there a a tutorial? One way to interpret the original question is: how can I read a (proprietary) Excel (.xls .xlsx) file into Python. An answer to this could be useful but I don't have one. So the general flow here is to export in another format from Excel namely CSV. Depending on what kind of computations you are doing with MATLAB (and on which toolboxes you are using) Python could be a good alternative to MATLAB. Python + NumPy + SciPy + Matplotlib are the right combination to start. For the data you can for example save your data directly in text file (assuming that you are not directly concerned by floating-point precision issues) and read it in Python. If your data are Excel data where each value is separated by a "";"" you can for example read the file line by line and use the split() method (with "";"" as argument) to get each value. For MATLAB up to version 7.1 it is possible to directly load .mat files from Python with the scipy.io.matlab.mio module.  If you saved you data in MATLAB format use: from scipy.io import loadmat datafile = ""yourfile.mat"" data = loadmat(datafile matlab_compatible=True) var1 = data['nameOfYourVariable'].squeeze() var2 = data['nameOfYourOtherVariable'].squeeze()  Pandas is a Python data analysis library that can import/export from Excel pretty easily. Here's how to do it: http://pandas.pydata.org/pandas-docs/stable/10min.html#excel Crash course: import pandas as pd data = pd.read_excel('foo.xlsx' 'Sheet1' index_col=None na_values=['NA'])  I had a look at mlabwrap as a step to easing some MATLAB developers into using Python more. But I have been unable to cleanly build it and I don't run production installs here so I'm dead in the water.  If you come from the MATLAB world Pylab will ease your transition. Once you have converted your data to ASCII pylab.load() will do the rest: pylab.load(fname comments='#' delimiter=None converters=None skiprows=0 usecols=None unpack=False dtype=<type 'numpy.float64'>)  There are probably hundreds of ways you could import text data into Python. But since you want to replace MATLAB you're going be using NumPy and probably SciPy. Keep things simple: use NumPy's standard text-loading: import numpy imported_array = numpy.loadtxt('file.txt'delimiter='\t') # Assuming tab-delimiter print imported_array.shape  There's Matplotlib for plots and the csv module for reading Excel data (assuming you can dump to CSV). Here's a tutorial about replacing MATLAB with Python. SAGE (mentionend in the tutorial see http://sagemath.org/) is a pretty cool stack based on Python. Thanx a lot. I'm going to try SAGE.  ""I don't know if Python is a credible alternative to MATLAB"" For me (experimental physics) Python is not only a full replacement for MATLAB (when including SciPy and Matplotlib as mentioned above) but it is useful for many things other than data crunching and visualisation (such are general programming needs). ""I'm going to try SAGE."" It is worth noting that there are a couple of servers running Sage which offer the notebook environmet (check Try Sage online in http://www.sagemath.org/). This is pretty neat given the fact that all you need it is an Internet browser and access (no installation required). As for the question as interpreted by Kevin Buchs (in another answer) reading proprietary Excel to Python can be done in several methods some are platform (OS) dependent: A nice resource (platform independent) - http://www.python-excel.org/ An example using xlrd which I once found useful (this is what I used when I needed it): http://code.activestate.com/recipes/483742/ for an example based on xlrd (platform independent) pyexcelerator is another option. I hope this helps. If not I can try to arrange some example code myself (though the ones I have are over six years old...). I personally prefer as was proposed in the other answers to use the CSV or ASCII format.",python excel matlab numpy1730600,A,"Principal component analysis in Python I'd like to use principal component analysis (PCA) for dimensionality reduction. Does numpy or scipy already have it or do I have to roll my own using numpy.linalg.eigh? I don't just want to use singular value decomposition (SVD) because my input data are quite high-dimensional (~460 dimensions) so I think SVD will be slower than computing the eigenvectors of the covariance matrix. I was hoping to find a premade debugged implementation that already makes the right decisions for when to use which method and which maybe does other optimizations that I don't know about. Here is another implementation of a PCA module for python using numpy scipy and C-extensions. The module carries out PCA using either a SVD or the NIPALS (Nonlinear Iterative Partial Least Squares) algorithm which is implemented in C.  You do not need full Singular Value Decomposition (SVD) at it computes all eigenvalues and eigenvectors and can be prohibitive for large matrices. scipy and its sparse module provide generic linear algrebra functions working on both sparse and dense matrices among which there is the eig* family of functions : http://docs.scipy.org/doc/scipy/reference/sparse.linalg.html#matrix-factorizations Scikit-learn provides a Python PCA implementation which only support dense matrices for now. Timings : In [1]: A = np.random.randn(1000 1000) In [2]: %timeit scipy.sparse.linalg.eigsh(A) 1 loops best of 3: 802 ms per loop In [3]: %timeit np.linalg.svd(A) 1 loops best of 3: 5.91 s per loop Ah now I see that that the relative speed of the sparse vs nonsparse methods depends on the size of the matrix. If I use your example where A is a 1000*1000 matrix then `eigsh` and `svds` are faster than `eigh` and `svd` by a factor of ~3 but if A is smaller say 100*100 then `eigh` and `svd` are quicker by factors of ~4 and ~1.5 respectively. T would still use sparse SVD over sparse eigenvalue decomposition though. Indeed I think I am biased toward large matrices. To me large matrices are more like 10Š_ * 10Š_ than 1000 * 1000. In those case you often can't even store the covariance matrices ... You don't need to compute sparse matrices from dense matrices. The algorithms provided in the sparse.linalg module rely only on the matrice vector multiplication operation through the matvec method of the Operator object. For dense matrices this is just something like matvec=dot(A x). For the same reason you don't need to compute the covariance matrix but only to provide the operation dot(A.T dot(A x)) for A. Not really a fair comparison since you still need to compute the covariance matrix. Also it's probably only worth using the sparse linalg stuff for very large matrices since it seems to be quite slow to construct sparse matrices from dense matrices. for example `eigsh` is actually ~4x slower than `eigh` for nonsparse matrices. The same is true for `scipy.sparse.linalg.svds` versus `numpy.linalg.svd`. I would always go with SVD over eigenvalue decomposition for the reasons that @dwf mentioned and perhaps use sparse version of SVD if the matrices get really huge.  You can use sklearn: import sklearn.decomposition as deco import numpy as np x = (x - np.mean(x 0)) / np.std(x 0) # You need to normalize your data first pca = deco.PCA(n_components) # n_components is the components number after reduction x_r = pca.fit(x).transform(x) print ('explained variance (first %d components): %.2f'%(n_components sum(pca.explained_variance_ratio_))) Upvoted because this works nicely for me - I have more than 460 dimensions and even though sklearn uses SVD and the question requested non-SVD I think 460 dimensions is likely to be OK.  PCA using scipy.linalg.svd is super easy. Here's a simple demo: import numpy as np import matplotlib.pyplot as plt from scipy.linalg import svd from scipy.misc import lena # the underlying signal is a sinusoidally modulated image img = lena() t = np.arange(100) time = np.sin(0.1*t) real = time[:np.newaxisnp.newaxis] * img[np.newaxis...] # we add some noise noisy = real + np.random.randn(*real.shape)*255 # (observations features) matrix M = noisy.reshape(noisy.shape[0]-1) # singular value decomposition factorises your data matrix such that: # # M = U*S*V.T (where '*' is matrix multiplication) # # * U and V are the singular matrices containing orthogonal vectors of # unit length in their rows and columns respectively. # # * S is a diagonal matrix containing the singular values of M - these # values squared divided by the number of observations will give the # variance explained by each PC. # # * if M is considered to be an (observations features) matrix the PCs # themselves would correspond to the rows of S^(1/2)*V.T. if M is # (features observations) then the PCs would be the columns of # U*S^(1/2). # # * since U and V both contain orthonormal vectors U*V.T is equivalent # to a whitened version of M. U s Vt = svd(M full_matrices=False) V = Vt.T # sort the PCs by descending order of the singular values (i.e. by the # proportion of total variance they explain) ind = np.argsort(s)[::-1] U = U[: ind] s = s[ind] V = V[: ind] # if we use all of the PCs we can reconstruct the noisy signal perfectly S = np.diag(s) Mhat = np.dot(U np.dot(S V.T)) print ""Using all PCs MSE = %.6G"" %(np.mean((M - Mhat)**2)) # if we use only the first 20 PCs the reconstruction is less accurate Mhat2 = np.dot(U[: :20] np.dot(S[:20 :20] V[::20].T)) print ""Using first 20 PCs MSE = %.6G"" %(np.mean((M - Mhat2)**2)) fig [ax1 ax2 ax3] = plt.subplots(1 3) ax1.imshow(img) ax1.set_title('true image') ax2.imshow(noisy.mean(0)) ax2.set_title('mean of noisy images') ax3.imshow((s[0]**(1./2) * V[:0]).reshape(img.shape)) ax3.set_title('first spatial PC') plt.show()  SVD should work fine with 460 dimensions. It takes about 7 seconds on my Atom netbook. The eig() method takes more time (as it should it uses more floating point operations) and will almost always be less accurate. If you have less than 460 examples then what you want to do is diagonalize the scatter matrix (x - datamean)^T(x - mean) assuming your data points are columns and then left-multiplying by (x - datamean). That might be faster in the case where you have more dimensions than data. can you describe more in detail this trick when you have more dimensions than data? Basically you assume that the eigenvectors are linear combinations of the data vectors. See Sirovich (1987). ""Turbulence and the dynamics of coherent structures.""  You can quite easily ""roll"" your own using scipy.linalg (assuming a pre-centered dataset data): covmat = data.dot(data.T) evs evmat = scipy.linalg.eig(covmat) Then evs are your eigenvalues and evmat is your projection matrix. If you want to keep d dimensions use the first d eigenvalues and first d eigenvectors. Given that scipy.linalg has the decomposition and numpy the matrix multiplications what else do you need? cov matrix is np.dot(data.Tdataout=covmat) where data must be centered matrix.  Months later here's a small class PCA and a picture: #!/usr/bin/env python """""" a small class for Principal Component Analysis Usage: p = PCA( A fraction=0.90 ) In: A: an array of e.g. 1000 observations x 20 variables 1000 rows x 20 columns fraction: use principal components that account for e.g. 90 % of the total variance Out: p.U p.d p.Vt: from numpy.linalg.svd A = U . d . Vt p.dinv: 1/d or 0 see NR p.eigen: the eigenvalues of A*A in decreasing order (p.d**2). eigen[j] / eigen.sum() is variable j's fraction of the total variance; look at the first few eigen[] to see how many PCs get to 90 % 95 % ... p.npc: number of principal components e.g. 2 if the top 2 eigenvalues are >= `fraction` of the total. It's ok to change this; methods use the current value. Methods: The methods of class PCA transform vectors or arrays of e.g. 20 variables 2 principal components and 1000 observations using partial matrices U' d' Vt' parts of the full U d Vt: A ~ U' . d' . Vt' where e.g. U' is 1000 x 2 d' is diag([ d0 d1 ]) the 2 largest singular values Vt' is 2 x 20. Dropping the primes d . Vt 2 principal vars = p.vars_pc( 20 vars ) U 1000 obs = p.pc_obs( 2 principal vars ) U . d . Vt 1000 obs p.obs( 20 vars ) = pc_obs( vars_pc( vars )) fast approximate A . vars using the `npc` principal components Ut 2 pcs = p.obs_pc( 1000 obs ) V . dinv 20 vars = p.pc_vars( 2 principal vars ) V . dinv . Ut 20 vars p.vars( 1000 obs ) = pc_vars( obs_pc( obs )) fast approximate Ainverse . obs: vars that give ~ those obs. Notes: PCA does not center or scale A; you usually want to first A -= A.mean(A axis=0) A /= A.std(A axis=0) with the little class Center or the like below. See also: http://en.wikipedia.org/wiki/Principal_component_analysis http://en.wikipedia.org/wiki/Singular_value_decomposition Press et al. Numerical Recipes (2 or 3 ed) SVD PCA micro-tutorial iris-pca .py .png """""" from __future__ import division import numpy as np dot = np.dot # import bz.numpyutil as nu # dot = nu.pdot __version__ = ""2010-04-14 apr"" __author_email__ = ""denis-bz-py at t-online dot de"" #............................................................................... class PCA: def __init__( self A fraction=0.90 ): assert 0 <= fraction <= 1 # A = U . diag(d) . Vt O( m n^2 ) lapack_lite -- self.U self.d self.Vt = np.linalg.svd( A full_matrices=False ) assert np.all( self.d[:-1] >= self.d[1:] ) # sorted self.eigen = self.d**2 self.sumvariance = np.cumsum(self.eigen) self.sumvariance /= self.sumvariance[-1] self.npc = np.searchsorted( self.sumvariance fraction ) + 1 self.dinv = np.array([ 1/d if d > self.d[0] * 1e-6 else 0 for d in self.d ]) def pc( self ): """""" e.g. 1000 x 2 U[: :npc] * d[:npc] to plot etc. """""" n = self.npc return self.U[: :n] * self.d[:n] # These 1-line methods may not be worth the bother; # then use U d Vt directly -- def vars_pc( self x ): n = self.npc return self.d[:n] * dot( self.Vt[:n] x.T ).T # 20 vars -> 2 principal def pc_vars( self p ): n = self.npc return dot( self.Vt[:n].T (self.dinv[:n] * p).T ) .T # 2 PC -> 20 vars def pc_obs( self p ): n = self.npc return dot( self.U[: :n] p.T ) # 2 principal -> 1000 obs def obs_pc( self obs ): n = self.npc return dot( self.U[: :n].T obs ) .T # 1000 obs -> 2 principal def obs( self x ): return self.pc_obs( self.vars_pc(x) ) # 20 vars -> 2 principal -> 1000 obs def vars( self obs ): return self.pc_vars( self.obs_pc(obs) ) # 1000 obs -> 2 principal -> 20 vars class Center: """""" A -= A.mean() /= A.std() inplace -- use A.copy() if need be uncenter(x) == original A . x """""" # mttiw def __init__( self A axis=0 scale=True verbose=1 ): self.mean = A.mean(axis=axis) if verbose: print ""Center -= A.mean:"" self.mean A -= self.mean if scale: std = A.std(axis=axis) self.std = np.where( std std 1. ) if verbose: print ""Center /= A.std:"" self.std A /= self.std else: self.std = np.ones( A.shape[-1] ) self.A = A def uncenter( self x ): return np.dot( self.A x * self.std ) + np.dot( x self.mean ) #............................................................................... if __name__ == ""__main__"": import sys csv = ""iris4.csv"" # wikipedia Iris_flower_data_set # 5.13.51.40.2 # Iris-setosa ... N = 1000 K = 20 fraction = .90 seed = 1 exec ""\n"".join( sys.argv[1:] ) # N= ... np.random.seed(seed) np.set_printoptions( 1 threshold=100 suppress=True ) # .1f try: A = np.genfromtxt( csv delimiter="""" ) N K = A.shape except IOError: A = np.random.normal( size=(N K) ) # gen correlated ? print ""csv: %s N: %d K: %d fraction: %.2g"" % (csv N K fraction) Center(A) print ""A:"" A print ""PCA ...""  p = PCA( A fraction=fraction ) print ""npc:"" p.npc print ""% variance:"" p.sumvariance * 100 print ""Vt[0] weights that give PC 0:"" p.Vt[0] print ""A . Vt[0]:"" dot( A p.Vt[0] ) print ""pc:"" p.pc() print ""\nobs <-> pc <-> x: with fraction=1 diffs should be ~ 0"" x = np.ones(K) # x = np.ones(( 3 K )) print ""x:"" x pc = p.vars_pc(x) # d' Vt' x print ""vars_pc(x):"" pc print ""back to ~ x:"" p.pc_vars(pc) Ax = dot( A x.T ) pcx = p.obs(x) # U' d' Vt' x print ""Ax:"" Ax print ""A'x:"" pcx print ""max |Ax - A'x|: %.2g"" % np.linalg.norm( Ax - pcx np.inf ) b = Ax # ~ back to original x Ainv A x back = p.vars(b) print ""~ back again:"" back print ""max |back - x|: %.2g"" % np.linalg.norm( back - x np.inf ) # end pca.py Fyinfo there's an excellent talk on [Robust PCA](http://videolectures.net/nipsworkshops2010_caramanis_rcf/snippet/) by C. Caramanis January 2011. Thanks for posting this. Concur with Pete; thanks very much. is this code will output that image(Iris PCA)? If not can you post an alternative solution in which the out would be that image. IM having some difficulties in converting this code to c++ because I'm new in python :) oh thats fine.Still thank you so much for this code :)  You might have a look at MDP. I have not had the chance to test it myself but I've bookmarked it exactly for the PCA functionality. +1 great extension!  matplotlib.mlab has a PCA implementation. the link for [PCA of matplotlib](http://matplotlib.sourceforge.net/api/mlab_api.html#matplotlib.mlab.PCA) is updated. The matplotlib.mlab implementation of PCA uses SVD. Here's [a more detailed description](http://www.clear.rice.edu/comp130/12spring/pca/pca_docs.shtml) of the its functions and how to use.  I just finish reading the book Machine Learning: An Algorithmic Perspective. All code examples in the book was written by Python(and almost with Numpy). The code snippet of chatper10.2 Principal Components Analysis maybe worth a reading. It use numpy.linalg.eig. By the way I think SVD can handle 460 * 460 dimensions very well. I have calculate a 6500*6500 SVD with numpy/scipy.linalg.svd on a very old PC:Pentium III 733mHz. To be honest the script needs a lot of memory(about 1.xG) and a lot of time(about 30 minutes) to get the SVD result. But I think 460*460 on a modern PC will not be a big problem unless u need do SVD a huge number of times. You should never use eig() on a covariance matrix when you can simply use svd(). Depending on how many components you plan on using and the size of your data matrix the numerical error introduced by the former (it does more floating point operations) can become significant. For the same reason you should never explicitly invert a matrix with inv() if what you're really interested in is the inverse times a vector or matrix; you should use solve() instead. @dwf thanks for the info!",python numpy scipy pca568962,A,How do I create an empty array/matrix in NumPy? I'm sure I must be being very dumb but I can't figure out how to use an array or matrix in the way that I would normally use a list. I.e. I want to create an empty array (or matrix) and then add one column (or row) to it at a time. At the moment the only way I can find to do this is like: mat = None for col in columns: if mat is None: mat = col else: mat = hstack((mat col)) Whereas if it were a list I'd do something like this: list = [] for item in data: list.append(item) Is there a way to use that kind of notation for NumPy arrays or matrices? (Or a better way -- I'm still pretty new to python!) A NumPy array is a very different data structure from a list and is designed to be used in different ways. Your use of hstack is potentially very inefficient... every time you call it all the data in the existing array is copied into a new one. (The append function will have the same issue.) If you want to build up your matrix one column at a time you might be best off to keep it in a list until it is finished and only then convert it into an array. e.g.  mylist = [] for item in data: mylist.append(item) mat = numpy.array(mylist) item can be a list an array or any iterable as long as each item has the same number of elements. In this particular case (data is some iterable holding the matrix columns) you can simply use  mat = numpy.array(data) (Also note that using list as a variable name is probably not good practice since it masks the built-in type by that name which can lead to bugs.) EDIT: If for some reason you really do want to create an empty array you can just use numpy.array([]) but this is rarely useful! Are numpy arrays/matrices fundamentally different from Matlab ones? @levesque Look [HERE](http://www.scipy.org/NumPy_for_Matlab_Users)  ARRAY OBJECTS Array objects consist of one- or multidimensional homogeneous fixed-size structures i.e. they have a fixed number of elements all of the same datatype (which allows much faster methods than Python's list object). An array element is retrieved as A[ijk..] (list elements are retrieved as L[i][j][k]..). A matrix is a two-dimensional array. Arrays a have attributes a.attr which can be distinguished in properties and methods a.meth(). The former return values (such as the shape and type) that belong to the array; the latter specify actions that are to be performed on the array. Often there is a function that performs the same action as a method; function and method then have the same name. Howeverthe default settings of the parameters may differ for methods and their corresponding functions. Array construction Arrays can be created in various ways: with the function array(obj) where 'obj' is a (nested) sequence e.g. a list [ ] or a tuple ( ). When 'obj' is an array a copy of this array is returned. The function matrix does the same for matrices. with the function copy(obj) where 'obj' is another array or matrix or a (nested) sequence with the function asarray(obj) which is like 'copy' except that no copy is made if 'obj' is already an array. with the function empty(shape dtype) which produces an uninitialized array with specified shape and typecode or with the function empty_like(a) which produces an uninitialized array with the same shape and typecode as its argument a with the function ones(shape dtype) producing an array initialized with ones or ones_like(a). with the function zeros(shape dtype) producing an array initialized with zeros or zeros_like(a) with the function identity(ndtype) producing a 2-d n*n identity matrix with the function arange(..) which does the same as array(range(..)) with the function concatenate(..) which concatenates sequences to an array. When you copy-paste documentation in place of an answer you should cite a source.  You have the wrong mental model for using NumPy efficiently. NumPy arrays are stored in contiguous blocks of memory. If you want to add rows or columns to an existing array the entire array needs to be copied to a new block of memory creating gaps for the new elements to be stored. This is very inefficient if done repeatedly to build an array. In the case of adding rows your best bet is to create an array that is as big as your data set will eventually be and then add data to it row-by-row: >>> import numpy >>> a = numpy.zeros(shape=(52)) >>> a array([[ 0. 0.] [ 0. 0.] [ 0. 0.] [ 0. 0.] [ 0. 0.]]) >>> a[0] = [12] >>> a[1] = [23] >>> a array([[ 1. 2.] [ 2. 3.] [ 0. 0.] [ 0. 0.] [ 0. 0.]]) There is also numpy.empty() if you don't need to zero the array. What's the benefit of using empty() over zeros()? that if you're going to initialize it with your data straight away you save the cost of zeroing it.  To create an empty multidimensional array in NumPy (e.g. a 2D array m*n to store your matrix) in case you don't know m how many rows you will append and don't care about the computational cost Stephen Simmons mentioned (namely re-buildinging the array at each append) you can squeeze to 0 the dimension to which you want to append to: X = np.empty(shape=[0 n]). This way you can use for example (here m = 5 which we assume we didn't know when creating the empty matrix and n = 2): n = 2 X = np.empty(shape=[0 n]) for i in range(5): for j in range(2): X = np.append(X [[i j]] axis=0) print X which will give you: [[ 0. 0.] [ 0. 1.] [ 1. 0.] [ 1. 1.] [ 2. 0.] [ 2. 1.] [ 3. 0.] [ 3. 1.] [ 4. 0.] [ 4. 1.]]  If you absolutely don't know the final size of the array you can increment the size of the array like this: my_arr = numpy.zeros((05)) for i in range(3): my_arr=numpy.concatenate( ( my_arr numpy.ones((15)) ) ) print(my_arr) [[ 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1.]] Notice the 0 in the first line. numpy.append is another option. It calls numpy.concatenate.  You can use the append function. For rows: >>> from numpy import * >>> a = array([102030]) >>> append(a [[123]] axis=0) array([[10 20 30] [1 2 3]]) For columns: >>> append(a [[15][15]] axis=1) array([[10 20 30 15] [1 2 3 15]]) EDIT Of course as mentioned in other answers unless you're doing some processing (ex. inversion) on the matrix/array EVERY time you append something to it I would just create a list append to it then convert it to an array.  I looked into this a lot because I needed to use a numpy.array as a set in one of my school projects and I needed to be initialized empty... I didn't found any relevant answer here on Stack Overflow so I started doodling something. # Initialize your variable as a empty list first In [32]: x=[] # and now cast it as a numpy ndarray In [33]: x=np.array(x) The result will be: In [34]: x Out[34]: array([] dtype=float64) Therefore you can directly initialize an np array as follows: In [36]: x= np.array([] dtype=np.float64) I hope this helps.,python arrays numpy1520379,A,"How to update Numpy on Mac OS X Snow Leopard? How can I update Numpy into the newest one? Should I download .dmg file from here: http://sourceforge.net/projects/numpy/files/ Is this .dmg only for 10.5? I have installed numpy using these instructions: http://www.scipy.org/Installing_SciPy/Mac_OS_X My current Numpy is 1.2.1. I'm running on Mac OS X 10.6.1 Snow Leopard. Thanks! Use pip install -U numpy instead as easy_install is deprecated in favor of pip  For some reason easy_install -U numpy didn't work. print numpy.__version__ would always give 1.2.1 So I first removed numpy 1.2.1 by finding it and deleting the entire folder: import numpy print numpy.__file__ I downloaded the GNU Fortran Compiler from: http://r.research.att.com/gfortran-4.2.3.dmg I used easy_install to install numpy. In retrospect easy_install -U numpy might have worked if I had the Fortran compiler installed.  sudo easy_install -U numpy Installing via setuptools will get the new numpy on the sys.path for non-system utilties (I've been told that some Apple utilities rely on the system-numpy). In general setuptools will ""do the right"" thing on OS X. As noted by Austin you have to install http://r.research.att.com/gfortran-4.2.3.dmg first. Tested on a new 10.6.4 install I had similar problems trying sudo easy_install -U numpy So I did the following: sudo easy_install pip to install pip. Than installed numpy via `pip` pip install numpy which worked great.  as suggested elsewhere macports works fine on multiple architecture and versions of MacOsX + allows updates and more: $ port search numpy py-numpy @1.3.0 (python) The core utilities for the scientific library scipy for Python py25-numpy @1.3.0 (python) The core utilities for the scientific library scipy for Python py25-symeig @1.4 (python science) Symeig - Symmetrical eigenvalue routines for NumPy. py26-numpy @1.3.0 (python) The core utilities for the scientific library scipy for Python py26-scikits-audiolab @0.10.2 (python science audio) Audiolab is a python toolbox to read/write audio files from numpy arrays Found 5 ports. $ in your case simply issue : $ sudo port install py26-numpy alternatively if you want / need to compile yourself the instructions in HJBlog are very useful. I tested and could easily compile the 64-bit version of matplotlib.",python osx osx-snow-leopard numpy221386,A,"Removing a sequence of characters from a large binary file using python I would like to trim long sequences of the same value from a binary file in python. A simple way of doing it is simply reading in the file and using re.sub to replace the unwanted sequence. This will of course not work on large binary files. Can it be done in something like numpy? You need to make your question more precise. Do you know the values you want to trim ahead of time? Assuming you do I would probably search for the matching sections using subprocess to run ""fgrep -o -b <search string>"" and then change the relevant sections of the file using the python file object's seek read and write methods.  AJMayorga suggestion is fine unless the sizes of the replacement strings are different. Or the replacement string is at the end of the chunk. I fixed it like this: def ReplaceSequence(inFilename outFilename oldSeq newSeq): inputFile = open(inFilename ""rb"") outputFile = open(outFilename ""wb"") data = """" chunk = 1024 oldSeqLen = len(oldSeq) while 1: data = inputFile.read(chunk) dataSize = len(data) seekLen= dataSize - data.rfind(oldSeq) - oldSeqLen if seekLen > oldSeqLen: seekLen = oldSeqLen data = data.replace(oldSeq newSeq) outputFile.write(data) inputFile.seek(-seekLen 1) outputFile.seek(-seekLen 1) if dataSize < chunk: break inputFile.close() outputFile.close()  dbr's solution is a good idea but a bit overly complicated all you really have to do is rewind the file pointer the length of the sequence you are searching for before you read your next chunk. def ReplaceSequence(inFilename outFilename oldSeq newSeq): inputFile = open(inFilename ""rb"") outputFile = open(outFilename ""wb"") data = """" chunk = 1024 while 1: data = inputFile.read(chunk) data = data.replace(oldSeq newSeq) outputFile.write(data) inputFile.seek(-len(oldSequence) 1) outputFile.seek(-len(oldSequence) 1) if len(data) < chunk: break inputFile.close() outputFile.close()  If two copies fit in memory then you can easily make a copy. The second copy is the compressed version. Sure you can use numpy but you can also use the array package. Additionally you can treat your big binary object as a string of bytes and manipulate it directly. It sounds like your file may be REALLY large and you can't fit two copies into memory. (You didn't provide a lot of details so this is just a guess.) You'll have to do your compression in chunks. You'll read in a chunk do some processing on that chunk and write it out. Again numpy array or simple string of bytes will work fine.  This generator-based version will keep exactly one character of the file content in memory at a time. Note that I am taking your question title quite literally - you want to reduce runs of the same character to a single character. For replacing patterns in general this does not work: import StringIO def gen_chars(stream): while True: ch = stream.read(1) if ch: yield ch else: break def gen_unique_chars(stream): lastchar = '' for char in gen_chars(stream): if char != lastchar: yield char lastchar=char def remove_seq(infile outfile): for ch in gen_unique_chars(infile): outfile.write(ch) # Represents a file open for reading infile = StringIO.StringIO(""1122233333444555"") # Represents a file open for writing outfile = StringIO.StringIO() # Will print ""12345"" remove_seq(infile outfile) outfile.seek(0) print outfile.read()  If you don't have the memory to do open(""big.file"").read() then numpy wont really help.. It uses the same memory as python variables do (if you have 1GB of RAM you can only load 1GB of data into numpy) The solution is simple - read the file in chunks.. f = open(""big.file"" ""rb"") then do a series of f.read(500) remove the sequence and write it back out to another file object. Pretty much how you do file reading/writing in C.. The problem then is if you miss the pattern you are replacing.. For example: target_seq = ""567"" input_file = ""1234567890"" target_seq.read(5) # reads 12345 doesn't contain 567 target_seq.read(5) # reads 67890 doesn't contain 567 The obvious solution is to start at the first character in the file check len(target_seq) characters then go forward one character check forward again. For example (pseudo code!): while cur_data != """": seek_start = 0 chunk_size = len(target_seq) input_file.seek(offset = seek_start whence = 1) #whence=1 means seek from start of file (0 + offset) cur_data = input_file.read(chunk_size) # reads 123 if target_seq == cur_data: # Found it! out_file.write(""replacement_string"") else: # not it shove it in the new file out_file.write(cur_data) seek_start += 1 It's not exactly the most efficient way but it will work and not require keeping a copy of the file in memory (or two). Thanks that helps a lot. I was hoping numpy would have some auto memory management for large files - I'm not too familiar with it.",python numpy binaryfiles1767865,A,"Using Numpy to find average value across data sets with some missing data I have several (10 or so) CSV-formatted data sets. Each column of a data set represents one aspect of a running system (available RAM CPU usage open TCP connections and so forth). Each row contains the values for these columns at one moment in time. The data sets were captured during individual runs of the same test. The number of rows is not guaranteed to be the same in each data set (i.e.: some tests ran longer than others). I want to produce a new CSV file that represents the ""average"" value across all data sets for a given time offset and a given column. Ideally values missing in one data set would be ignored. If necessary though missing values could be assumed to be the same as the last known value or the average of known values for that row. A simplified example: +---------------+ +---------------+ +---------------+ | Set 1 | | Set 2 | | Average | +---+-----+-----+ +---+-----+-----+ +---+-----+-----+ | t | A | B | | t | A | B | | t | A | B | +---+-----+-----+ +---+-----+-----+ +---+-----+-----+ | 1 | 10 | 50 | | 1 | 12 | 48 | | 1 | 11 | 49 | | 2 | 13 | 58 | | 2 | 7 | 60 | | 2 | 10 | 59 | | 3 | 9 | 43 | | 3 | 17 | 51 | => | 3 | 13 | 47 | | 4 | 14 | 61 | | 4 | 12 | 57 | | 4 | 13 | 59 | | : | : | : | | : | : | : | | : | : | : | | 7 | 4 | 82 | | 7 | 10 | 88 | | 7 | 7 | 86 | +---+-----+-----+ | 8 | 15 | 92 | | 8 | 15 | 92 | | 9 | 6 | 63 | | 9 | 6 | 63 | +---+-----+-----+ +---+-----+-----+ I'm new to numpy having picked it up specifically for this project. What's the best way to do this? For data sets with the same number of rows (which I've been forcing by chopping longer data sets short) I just do: d_avg = sum(dsets) / float(len(dsets)) where ""dsets"" is a list of the ndarrays containing the data from each CSV file. This works well but I don't want to discard the data from the longer runs. I can also resize the shorter runs to the length of the longest but all the new fields are filled with ""NoneType"". Later operations then error when adding (for example) a float and a NoneType. Any suggestions? I think the average for row 7 is wrong I knew I was going to miss one of those rows! Updated. Edit: I've revised my method abandoning scipy.nanmean in favor of masked arrays. If it is unclear what the code is doing at any point first try putting print statements in. If it is still unclear feel free to ask; I'll try my best to explain. The trick part is getting the t-values merged. (That was done with numpy array's searchsorted method.) Playing with numpy has led me to believe that its speed advantages may not exist until the datasets get quite big (maybe you'll need at least 10000 rows per data set). Otherwise a pure python solution may be both easier to write and faster. Here are the toy datasets I used: % cat set1 1 10 50 2 13 58 3943 41461 7 4 82 % cat set2 1 12 48 2 7 60 31751 41257 71088 81592 9663 And here is the code: #!/usr/bin/env python import numpy as np filenames=('set1''set2') # change this to list all your csv files column_names=('t''a''b') # slurp the csv data files into a list of numpy arrays data=[np.loadtxt(filename delimiter='') for filename in filenames] # Find the complete list of t-values # For each elt in data elt[ab] is the value in the a_th row and b_th column t_values=np.array(list(reduce(set.union(set(elt[:0]) for elt in data)))) t_values.sort() # print(t_values) # [ 1. 2. 3. 4. 7. 8. 9.] num_rows=len(t_values) num_columns=len(column_names) num_datasets=len(filenames) # For each data set we compute the indices of the t_values that are used. idx=[(t_values.searchsorted(data[n][:0])) for n in range(num_datasets)] data2=np.ma.zeros((num_rowsnum_columnsnum_datasets)) for n in range(num_datasets): data2[idx[n]:n]=data[n][::] data2=np.ma.masked_equal(data2 0) averages=data2.mean(axis=-1) print(averages) # [[1.0 11.0 49.0] # [2.0 10.0 59.0] # [3.0 13.0 47.0] # [4.0 13.0 59.0] # [7.0 7.0 85.0] # [8.0 15.0 92.0] # [9.0 6.0 63.0]] Nice! I didn't know about 'loadtxt'. I was using the 'tabular' module which turned out to be overkill. Thanks.  Why not just us numpy's ma (masked array) module? maxLen = reduce(lambda ab : max(a b.shape[0]) dSets 0) all = N.ma.zeros((maxLen)+ dSets[0].shape[1:] + (len(dSets)) dtype=float) # set the dtype to whatever all.mask = True for i set in enumerate(dSets): all.mask[:len(set)...i] = False all[:len(set)...i] = set mean = all.mean(axis=-1) Of course this only works if you can guarantee that the time in each row is the same across all arrays i.e. set[i0] == set[j0] for all ij This works great. Thanks! One thing: the reduce/lambda construct can fail when an early value is the highest: 'int' has no method 'shape'. replaced with: maxLen = max([a.shape[0] for a in dSets]) Yes you're right I ballsed up the lambda. Edited to correct. Cheers! Even if the time isn't the same you can use masked arrays. You just need to be smarter in setting up the masked array so the data for each time is in the same row.  Well one way to do it would be to iterate over each row of each data set and append a given column value to an array that's stored in a dictionary where the time index is used for its key value. You then iterate over the dictionary and pull the average for each array stored there. This isn't particularly efficient -- the other option is to find the longest array iterate over it and query the other datasets to create an temporary array to average. This way you save the secondary iteration over the dictionary. I was really hoping that numpy with its array-oriented efficiency would provide a way to do exactly that. You're right though I'll have to fall back to the method you suggest if there's no existing operation for it. If you're really wanting to stay in numpy take a look at masked arrays here: http://docs.scipy.org/doc/numpy/reference/maskedarray.generic.html It's not so much numpy itself that I want. It's clean easy-to-understand code! Frankly I'd drop Python for (hypothetically) R if that meant an elegant solution. But I know even less about R than numpy. Thanks for the tip on masked arrays. I'll check it out.",python numpy911871,A,"Detect if a NumPy array contains at least one non-numeric value? I need to write a function which will detect if the input contains at least one value which is non-numeric. If a non-numeric value is found I will raise an error (because the calculation should only return a numeric value). The number of dimensions of the input array is not known in advance - the function should give the correct value regardless of ndim. As an extra complication the input could be a single float or numpy.float64 or even something oddball like a zero-dimensional array. The obvious way to solve this is to write a recursive function which iterates over every iterable object in the array until it finds a non-iterabe. It will apply the numpy.isnan() function over every non-iterable object. If at least one non-numeric value is found then the function will return False immediately. Otherwise if all the values in the iterable are numeric it will eventually return True. That works just fine but it's pretty slow and I expect that NumPy has a much better way to do it. What is an alternative that is faster and more numpyish? Here's my mockup: def contains_nan( myarray ): """""" @param myarray : An n-dimensional array or a single float @type myarray : numpy.ndarray numpy.array float @returns: bool Returns true if myarray is numeric or only contains numeric values. Returns false if at least one non-numeric value exists Not-A-Number is given by the numpy.isnan() function. """""" return True Your description for `contains_nan` looks suspicious: ""Returns false if at least one non-numeric value exists"". I would have expected `contains_nan` to return `True` if the array contains NaN. With numpy 1.3 or svn you can do this In [1]: a = arange(10000.).reshape(100100) In [3]: isnan(a.max()) Out[3]: False In [4]: a[5050] = nan In [5]: isnan(a.max()) Out[5]: True In [6]: timeit isnan(a.max()) 10000 loops best of 3: 66.3 Îµs per loop The treatment of nans in comparisons was not consistent in earlier versions.  This should be faster than iterating and will work regardless of shape. numpy.isnan(myarray).any() Edit: 30x faster: import timeit s = 'import numpy;a = numpy.arange(10000.).reshape((100100));a[1010]=numpy.nan' ms = [ 'numpy.isnan(a).any()' 'any(numpy.isnan(x) for x in a.flatten())'] for m in ms: print "" %.2f s"" % timeit.Timer(m s).timeit(1000) m Results:  0.11 s numpy.isnan(a).any() 3.75 s any(numpy.isnan(x) for x in a.flatten()) Bonus: it works fine for non-array NumPy types: >>> a = numpy.float64(42.) >>> numpy.isnan(a).any() False >>> a = numpy.float64(numpy.nan) >>> numpy.isnan(a).any() True with numpy 1.7 the flatten() version is only twice as fast as the first one",python numpy1632673,A,"Python File Slurp w/ endian conversion It was recently asked how to do a file slurp in python and the accepted answer suggested something like: with open('x.txt') as x: f = x.read() How would I go about doing this to read the file in and convert the endian representation of the data? For example I have a 1GB binary file that's just a bunch of single precision floats packed as a big endian and I want to convert it to little endian and dump into a numpy array. Below is the function I wrote to accomplish this and some real code that calls it. I use struct.unpack do the endian conversion and tried to speed everything up by using mmap. My question then is am I using the slurp correctly with mmap and struct.unpack? Is there a cleaner faster way to do this? Right now what I have works but I'd really like to learn how to do this better. Thanks in advance! #!/usr/bin/python from struct import unpack import mmap import numpy as np def mmapChannel(arrayName fileName channelNo line_count sample_count): """""" We need to read in the asf internal file and convert it into a numpy array. It is stored as a single row and is binary. Thenumber of lines (rows) samples (columns) and channels all come from the .meta text file Also internal format files are packed big endian but most systems use little endian so we need to make that conversion as well. Memory mapping seemed to improve the ingestion speed a bit """""" # memory-map the file size 0 means whole file # length = line_count * sample_count * arrayName.itemsize print ""\tMemory Mapping..."" with open(fileName ""rb"") as f: map = mmap.mmap(f.fileno() 0 access=mmap.ACCESS_READ) map.seek(channelNo*line_count*sample_count*arrayName.itemsize) for i in xrange(line_count*sample_count): arrayName[0 i] = unpack('>f' map.read(arrayName.itemsize) )[0] # Same method as above just more verbose for the maintenance programmer. # for i in xrange(line_count*sample_count): #row # be_float = map.read(arrayName.itemsize) # arrayName.itemsize should be 4 for float32 # le_float = unpack('>f' be_float)[0] # > for big endian < for little endian # arrayName[0 i]= le_float map.close() return arrayName print ""Initializing the Amp HH HV and Phase HH HV arrays..."" HHamp = np.ones((1 line_count*sample_count) dtype='float32') HHphase = np.ones((1 line_count*sample_count) dtype='float32') HVamp = np.ones((1 line_count*sample_count) dtype='float32') HVphase = np.ones((1 line_count*sample_count) dtype='float32') print ""Ingesting HH_Amp..."" HHamp = mmapChannel(HHamp 'ALPSRP042301700-P1.1__A.img' 0 line_count sample_count) print ""Ingesting HH_phase..."" HHphase = mmapChannel(HHphase 'ALPSRP042301700-P1.1__A.img' 1 line_count sample_count) print ""Ingesting HV_AMP..."" HVamp = mmapChannel(HVamp 'ALPSRP042301700-P1.1__A.img' 2 line_count sample_count) print ""Ingesting HV_phase..."" HVphase = mmapChannel(HVphase 'ALPSRP042301700-P1.1__A.img' 3 line_count sample_count) print ""Reshaping...."" HHamp_orig = HHamp.reshape(line_count -1) HHphase_orig = HHphase.reshape(line_count -1) HVamp_orig = HVamp.reshape(line_count -1) HVphase_orig = HVphase.reshape(line_count -1) I wanted to add to this for anyone else who finds this post useful. Running the original code I had takes about 80 seconds or so. Running the solution provided by Alex Martelli and J F Sebastian is less than a second. The program that calls this function does so many times. As such the running time has dropped considerably. Thank you both for the help and for teaching me something =) with open(fileName ""rb"") as f: arrayName = numpy.fromfile(f numpy.float32) arrayName.byteswap(True) Pretty hard to beat for speed AND conciseness;-). For byteswap see here (the True argument means ""do it in place""); for fromfile see here. This works as is on little-endian machines (since the data are big-endian the byteswap is needed). You can test if that is the case to do the byteswap conditionally change the last line from an unconditional call to byteswap into for example: if struct.pack('=f' 2.3) == struct.pack('<f' 2.3): arrayName.byteswap(True) i.e. a call to byteswap conditional on a test of little-endianness. that is remarkably straightforward. thank you what's weird is i had seen those when trying to figure out how to do this but it just didn't register for some reason. comes with experience i suppose =) numpy.float32 has native byte order that might not be always big-endian. http://stackoverflow.com/questions/1632673/python-file-slurp-w-endian-conversion/1633525#1633525 Indeed it will mostly be little-endian but if you're running e.g. on a Power PC machine it will be big endian (if that's an issue just conditionally omit the byteswap call -- let me edit the answer to add that bit). Testing sys.byteorder is a little more straightforward than using struct.pack.  Slightly modified @Alex Martelli's answer: arr = numpy.fromfile(filename numpy.dtype('>f4')) # no byteswap is needed regardless of endianess of the machine  I'd expect something like this to be faster arrayName[0] = unpack('>'+'f'*line_count*sample_count map.read(arrayName.itemsize*line_count*sample_count)) Please don't use map as a variable name  You could coble together an ASM based solution using CorePy. I wonder though if you might be able to gain enough performance from the some other part of your algorithm. I/O and manipulations on 1GB chunks of data are going to take a while which ever way you slice it. One other thing you might find helpful would be to switch to C once you have prototyped the algorithm in python. I did this for manipulations on a whole-world DEM (height) data set one time. The whole thing was much more tolerable once I got away from the interpreted script.",python struct numpy endianness mmap1711865,A,Accessing a matrix element by matrix[(a b) c] instead of matrix[a b c] I want to achieve the following: Have a AxBxC matrix (where ABC are integers). Access that matrix not as matrix[a b c] but as matrix[(a b) c] this is I have two variables var1 = (x y) and var2 = z and want access my matrix as matrix[var1 var2]. How can this be done? I am using numpy matrix if it makes any difference. I know I could use matrix[var1[0] var1[1] var2] but if possible I'd like to know if there is any other more elegant way. Thanks! matrix[ab][c] ? Add that as asnwer and I'll rate it. Thanks! If var1 = (xy) and var2 = z you can use matrix[var1][var2]  I think you can simply subclass the NumPy matrix type with a new class of your own; and overload the __getitem__() nethod to accept a tuple. Something like this: class SpecialMatrix(np.matrix): def __getitem__(self arg1 arg2 arg3=None): try: i j = arg1 k = arg2 assert(arg3 is None) x = super(SpecialMatrix self).__getitem__(i j k) except TypeError: assert(arg3 is not None) return super(SpecialMatrix self).__getitem__(arg1 arg2 arg3) And do something similar with __setitem__(). I'm not sure if __getitem__() takes multiple arguments like I'm showing here or if it takes a tuple or what. I don't have NumPy available as I write this answer sorry. EDIT: I re-wrote the example to use super() instead of directly calling the base class. It has been a while since I did anything with subclassing in Python. EDIT: I just looked at the accepted answer. That's totally the way to do it. I'll leave this up in case anyone finds it educational but the simple way is best.,python numpy1658714,A,Range of valid numpy values I'm interested in finding for a particular Numpy type (e.g. np.int64 np.uint32 np.float32 etc.) what the range of all possible valid values is (e.g. np.int32 can store numbers up to 2**31-1). Of course I guess one can theoretically figure this out for each type but is there a way to do this at run time to ensure more portable code? You can use numpy.iinfo(arg).max to find the max value for integer types of arg and numpy.finfo(arg).max to find the max value for float types of arg. >>> numpy.iinfo(numpy.uint64).min 0 >>> numpy.iinfo(numpy.uint64).max 18446744073709551615L >>> numpy.finfo(numpy.float64).max 1.7976931348623157e+308 >>> numpy.finfo(numpy.float64).min -1.7976931348623157e+308 iinfo only offers min and max but finfo also offers useful values such as eps (the smallest number > 0 representable) and resolution (the approximate decimal number resolution of the type of arg).  Quoting from a numpy dicussion list: That kind of information is available via numpy.finfo() and numpy.iinfo(): In [12]: finfo('d').max Out[12]: 1.7976931348623157e+308 In [13]: iinfo('i').max Out[13]: 2147483647 In [14]: iinfo(uint8).max Out[14]: 255 The link is here: link to numpy discussion group page,python numpy1803860,A,Performing operations on a NumPy arrray but masking values along the diagonal from these operations as I can perform operations on arrays so that does nothing on the diagonal is calculated such that all but the diagonal array ([[0. 1.37 1. 1.37 1. 1.37 1.] [1.37 0.  1.37 1.73 2.37 1.73 1.37] [1.  1.37 0.  1.37 2.  2.37 2. ] [1.37 1.73 1.37 0.  1.37 1.73 2.37] [1.  2.37 2.  1.37 0.  1.37 2. ] [1.37 1.73 2.37 1.73 1.37 0.  1.37] [1.  1.37 2.  2.37 2.  1.37 0. ]]) to avoid the NaN value but retained the value zero on the diagonal in all responses What are you trying to do? What is the operation involved? Are you trying to do matrix multiplication or inversion? Your question is very unclear. yes I need to do is Can you just do the calculation as normal then afterwards set the diagonal back to zero? yes I need to do is Then do this after each calculation: for i in range(len(array)):array[i][i]=0  I wonder if masked arrays might do what you want e.g. import numpy as NP A = NP.random.random_integers(0 9 16).reshape(4 4) dg = NP.r_[ [NP.nan] * 4 ] # proper syntax is 'nan' not 'NaN' dg = NP.diag(dg) A += dg # a 4x4 array w/ NaNs down the main diagonal NP.sum(A axis=1) # doesn't work gives: array([ NaN NaN NaN NaN]) from numpy import ma as MA Am = **MA.masked_invalid**(A) NP.sum(Am axis=1) # now it works (treats 'nan' as 0) The other way to do this of is of course to first convert the NaNs to 0s then mask the 0s: NP.nan_to_num(A) MA.masked_equal(A 0) Finally it's often efficient to mask and convert the NaNs in one step: MA.fix_invalid(A) Pretty straightforward just keep in mind that 'ma' might not yet be in your namespace and also that these functions deal with 'NaNs' and 'infs' which is usually what you want.  >>> arr = [ ... [0. 1.37 1. 1.37 1. 1.37 1.] ... [1.37 0.  1.37 1.73 2.37 1.73 1.37] ... [1.  1.37 0.  1.37 2.  2.37 2. ] ... [1.37 1.73 1.37 0.  1.37 1.73 2.37] ... [1.  2.37 2.  1.37 0.  1.37 2. ] ... [1.37 1.73 2.37 1.73 1.37 0.  1.37] ... [1.  1.37 2.  2.37 2.  1.37 0. ] ... ] >>> for i in range(6): ... for y in range(6): ... if (i <> y): ... print arr[i][y]*arr[y][i] ... 1.8769 1.0 1.8769 1.0 1.8769 1.8769 1.8769 2.9929 5.6169 2.9929 1.0 1.8769 1.8769 4.0 5.6169 1.8769 2.9929 1.8769 1.8769 2.9929 1.0 5.6169 4.0 1.8769 1.8769 1.8769 2.9929 5.6169 2.9929 1.8769 Depends on what you need to calculate  Do your calculation as normal and then myarray[arange(len(array)) arange(len(array))] = 0.,python arrays numpy scipy695794,A,"more efficient way to pickle a string The pickle module seems to use string escape characters when pickling; this becomes inefficient e.g. on numpy arrays. Consider the following z = numpy.zeros(1000 numpy.uint8) len(z.dumps()) len(cPickle.dumps(z.dumps())) The lengths are 1133 characters and 4249 characters respectively. z.dumps() reveals something like ""\x00\x00"" (actual zeros in string) but pickle seems to be using the string's repr() function yielding ""'\x00\x00'"" (zeros being ascii zeros). i.e. (""0"" in z.dumps() == False) and (""0"" in cPickle.dumps(z.dumps()) == True) You should add a specific question to your post here. What do you want to serialize a Python string or a numpy array of bytes? should be len(cPickle.dumps(z)) Try using a later version of the pickle protocol with the protocol parameter to pickle.dumps(). The default is 0 and is an ASCII text format. Ones greater than 1 (I suggest you use pickle.HIGHEST_PROTOCOL). Protocol formats 1 and 2 (and 3 but that's for py3k) are binary and should be more space conservative.  Solution: import zlib cPickle def zdumps(obj): return zlib.compress(cPickle.dumps(objcPickle.HIGHEST_PROTOCOL)9) def zloads(zstr): return cPickle.loads(zlib.decompress(zstr)) >>> len(zdumps(z)) 128 Here's something more on the subject: http://tinyurl.com/3ymhaj5 . Basically if you're serializing to disk you can just do gzip.open() instead of open. @slack3r that link is dead. 'ascii' codec can't encode character u'\xda' in position 1: ordinal not in range(128)  An improvement to vartec's answer that seems a bit more memory efficient (since it doesn't force everything into a string): def pickle(fname obj): import cPickle gzip cPickle.dump(obj=obj file=gzip.open(fname ""wb"" compresslevel=3) protocol=2) def unpickle(fname): import cPickle gzip return cPickle.load(gzip.open(fname ""rb"")) (1) Then py2 code won't read py3 objects. (2) the header says ""an improvement to vartec's answer"" which was using compression -- I think it used less mem but it could have been a false impression... (3) fixed -1 (1) Don't hard-code protocol numbers use `-1` or `HIGHEST_PROTOCOL`. (2) Subsequent compression is an ADD-ON and is irrelevant to his question. (3) Specifying `compresslevel` when decompressing is pointless; any such information that may be necessary to decompress the file would be stored in the header of the compressed file -- otherwise how would you be able to decompress a file if you didn't know what compression level was used?  z.dumps() is already pickled string i.e. it can be unpickled using pickle.loads(): >>> z = numpy.zeros(1000 numpy.uint8) >>> s = z.dumps() >>> a = pickle.loads(s) >>> all(a == z) True",python numpy pickle space-efficiency1796597,A,"import array in python how can I import an array to python (numpy) from a file and that way the file must be written. For example a matrix to and from that file type (extention). thanks for any response Checkout the entry on the numpy example list. Here is the entry on .loadtxt() >>> from numpy import * >>> >>> data = loadtxt(""myfile.txt"") # myfile.txt contains 4 columns of numbers >>> tz = data[:0] data[:3] # data is 2D numpy array >>> >>> txyz = loadtxt(""myfile.txt"" unpack=True) # to unpack all columns >>> tz = loadtxt(""myfile.txt"" usecols = (03) unpack=True) # to select just a few columns >>> data = loadtxt(""myfile.txt"" skiprows = 7) # to skip 7 rows from top of file >>> data = loadtxt(""myfile.txt"" comments = '!') # use '!' as comment char instead of '#' >>> data = loadtxt(""myfile.txt"" delimiter=';') # use ';' as column separator instead of whitespace >>> data = loadtxt(""myfile.txt"" dtype = int) # file contains integers instead of floats hello thanks for answering I can only doubt as he defines the path of where the file  Another option is numpy.genfromtxt e.g: import numpy as np data = np.genfromtxt(""myfile.dat""delimiter="""") This will make data a numpy array with as many rows and columns as are in your file  (I know the question is old but I think this might be good as a reference for people with similar questions) If you want to load data from an ASCII/text file (which has the benefit or being more or less human-readable and easy to parse in other software) numpy.loadtxt is probably what you want: http://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html If you just want to quickly save and load numpy arrays/matrices to and from a file take a look at numpy.save and numpy.load: http://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html http://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html  Have a look at SciPy cookbook. It should give you an idea of some basic methods to import /export data. If you save/load the files from your own Python programs you may also want to consider the Pickle module or cPickle. Pickling is inappropriate for arrays - while you can do it it will be slow as hell. Use np.save() to save in the .npy format or np.savez() to save a zipped archive of several arrays.",python numpy118370,A,"How do you use the ellipsis slicing syntax in Python? This came up in Hidden features of Python but I can't see good documentation or examples that explain how the feature works. You'd use it in your own class since no builtin class makes use of it. Numpy uses it as stated in the documentation. Some examples here. In your own class you'd use it like this: >>> class TestEllipsis(object): ... def __getitem__(self item): ... if item is Ellipsis: ... return ""Returning all items"" ... else: ... return ""return %r items"" % item ... >>> x = TestEllipsis() >>> print x[2] return 2 items >>> print x[...] Returning all items Of course there is the python documentation and language reference. But those aren't very helpful. looks quite broken since the ""propper"" way to say all items is >>> x[:] >>> x[: 1:2] @Ronny: The point was to demonstrate some custom usage of Ellipsis. so true that docs are utterly cryptic  The ellipsis is used to slice higher-dimensional data structures. It's designed to mean at this point insert as many full slices (:) to extend the multi-dimensional slice to all dimensions. Example: >>> from numpy import arange >>> a = arange(16).reshape(2222) Now you have a 4-dimensional matrix of order 2x2x2x2. To select all first elements in the 4th dimension you can use the ellipsis notation >>> a[... 0].flatten() array([ 0 2 4 6 8 10 12 14]) which is equivalent to >>> a[:::0].flatten() array([ 0 2 4 6 8 10 12 14]) In your own implementations you're free to ignore the contract mentioned above and use it for whatever you see fit. This was a great explanation and good examples. Thanks!  Python documentation aren't very clear about this but there is another use of ellipsis. It is used as a representation of infinite data structures in case of Python. This question discusses how and some actual applications. This doesn't actually use the Python ellipsis object; it just uses ... when representing infinite structures as strings.  This is another use for Ellipsis which has nothing to do with slices: I often use it in intra-thread communication with queues as a mark that signals ""Done""; it's there it's an object it's a singleton and its name means ""lack of"" and it's not the overused None (which could be put in a queue as part of normal data flow). YMMV. P.S: I don't mind downvotes when what I say in an answer is not useful in relation to the question; then I try to improve my answer. But I sure can't understand how one can downvote any of the answers in this questionŠ—” when the question is Š—“how do you use the Ellipsis in PythonŠ—Š—_ It seems that people think that downvoting means Š—“I disagreeŠ— or Š—“I don't like thisŠ—. Never thought of that nice idea! Mightn't it be clearer to just say: ""Done = object()"" somewhere and just use that? Not necessarily - it requires you to actually _say_ Done=object() somewhere. Sentinel values aren't necessarily a bad thing -- and using otherwise nearly-useless Python singletons as sentinels isn't so horrible IMO (Ellipsis and () are the ones I've used where None would be confusing). +1 to counter unexplained anonymous downvotes. Regarding Done = object() I think using Ellipsis is better especially if you're using it for communication with queues. If you go from intra-thread to intra-process communication id(Done) will not be the same in the other process and there is nothing to distinguish one object from another. The id of Ellipsis won't be the same either but at least the type will be the same - this is the point of a singleton.",python numpy subclass slicing ellipsis1511354,A,Using lambda for a constraint function import numpy from numpy import asarray Initial = numpy.asarray [2.0 4.0 5.0 3.0 5.0 6.0] # Initial values to start with bounds = [(1 5000) (1 6000) (2 100000) (1 50000) (1.0 5000) (2 1000000)] # actual passed bounds b1 = lambda x: numpy.asarray([1.4*x[0] - x[0]]) b2 = lambda x: numpy.asarray([1.4*x[1] - x[1]]) b3 = lambda x: numpy.asarray([x[2] - x[3]]) constraints = numpy.asarray([b1 b2 b3]) opt= optimize.fmin_slsqp(funcInitialieqcons=constraintsbounds=bounds full_output=Trueiter=200iprint=2 acc=0.01) Problem: I want to pass in inequality constraints. Consider that I have 6 parameters [ a b c d e f] in the Initial values and my constraints are: a<=e<=1.4*a ('e' varies from a to 1.4*a) b<=f<=1.4*b ('f' varies from b to 1.4*b) c>d ('c' must always be greater than d) But this is not working properly. I don't know what the mistake is. Is there any better way to pass my constraints as a function? Please help me. I don't know numpy but are a and b negative? otherwise I can't seee how any values of e and f can satisfy 1.4*a <= e <= a and 1.4*b <= f <= b. It would help if you state clearly what it is exactly that you are doing what is it you want to happen and what actually happens instead of just pasting a code fragment. @pear I've tried to answer your question but as hughdbrown says the constraints in your code above don't seem to work for positive numbers. Maybe the signs are backwards on the first two? Sorry all are positive values greater than 0. I have changed i hope its correct. Based on the comment from Robert Kern I have removed my previous answer. Here are the constraints as continuous functions: b1 = lambda x: x[4]-x[0] if x[4]<1.2*x[0] else 1.4*x[0]-x[4] b2 = lambda x: x[5]-x[1] if x[5]<1.2*x[1] else 1.4*x[1]-x[5] b3 = lambda x: x[2]-x[3] Note: Python 2.5 or greater is required for this syntax.1 To get the constraint a<=e<=1.4*a note that 1.2*a is the halfway point between a and 1.4*a. Below this point that is all e<1.2*a we use the continuous function e-a. Thus the overall constraint function is negative when e<a handling the lower out-of-bounds condition zero on the lower boundary e==a and then positive for e>a up to the halfway point. Above the halfway point that is all e>1.2*a we use instead the continuous function 1.4*a-e. This means the overall constraint function is is negative when e>1.4*a handling the upper out-of-bounds condition zero on the upper boundary e==1.4*a and then positive when e<1.4*a down to the halfway point. At the halfway point where e==1.2*a both functions have the same value. This means that the overall function is continuous. Reference: documentation for ieqcons. 1 - Here is pre-Python 2.5 syntax: b1 = lambda x: (1.4*x[0]-x[4] x[4]-x[0])[x[4]<1.2*x[0]] system Pause as Robert says function has to continuous. so i have made lambda x: ([1.4*x[0] - x[0]]) ie.lambda x:(max-min). But what am i made is correct or not i don't know. @system Pause Thank you it seems b1 and b2 are working good but b3 = lambda x: x[2]-x[3] not working as expected.For example some times func() passes [150 192 1.8487 2.07364 194 216] here b1 and b2 are well defined but b3 is violated. Like this it happens couple of times.what to do? any better way of defining 'b2'? No this will not work. The constraint functions should be continuous as much as possible >0 when they are satisfied <0 when they are not and ==0 when they are precisely on the boundary. @pear Sorry I don't know why `b3` is violated. Subtracting `c-d` (aka `x[2]-x[3]`) is a continuous function that is be positive when `c>d` and zero/negative when `c<=d`. But clearly 1.8487 < 2.07364 so I am stumped. @pear I don't think that can be correct as it does not use *e* (aka `x[4]`) at all in the expression. That expression is equivalent to `1.4*a - a` which is always going to have the value `0.4a`.,python lambda numpy scipy1721802,A,What is the equivalent of MATLAB's repmat in NumPy I would like to execute the equivalent of the following MATLAB code using NumPy: repmat([1; 1] [1 1 1]). How would I accomplish this? Note that some of the reasons you'd need to use MATLAB's repmat are taken care of by NumPy's broadcasting mechanism which allows you to do various types of math with arrays of similar shape. So if you had say a 1600x1400x3 array representing a 3-color image you could (elementwise) multiply it by [1.0 0.25 0.25] to reduce the amount of green and blue at each pixel. See the above link for more information. thank kwatford :)  Here is a much better (official) NumPy for Matlab Users link - I'm afraid the mathesaurus one is quite out of date. The numpy equivalent of repmat(a m n) is tile(a (m n)). This works with multiple dimensions and gives a similar result to matlab. (Numpy gives a 3d output array as you would expect - matlab for some reason gives 2d output - but the content is the same). Matlab: >> repmat([1;1][111]) ans = 1 1 Python: In [46]: a = np.array([[1][1]]) In [47]: np.tile(a [111]) Out[47]: array([[[1] [1]]]) when i try size(repmat([1;1][112])) it get ans = 2 1 2 [in matlab] but in python np.tile(a[112]).shape it get(1 2 2)  i want numpy give result as same as matlab np.tile(a[:np.newaxis][112]) - it gives the same. Problem is tile promotes `a` to the dimension of the tile argument by *prepending* new axes as necessary. Matlab seems to work the other way. Similarly with 4d tiling you will need newaxis twice... so `np.tile(a[:newaxisnewaxis][1234]) = size(repmat(a[1 2 3 4]))` as required...  See NumPy for Matlab users. Matlab: repmat(a 2 3) Numpy: numpy.kron(numpy.ones((23)) a) I don't think the mathesaurus link is very good. There is an Numpy For Matlab Users page as part of the official documentation which is more comprehensive and up to date: http://www.scipy.org/NumPy_for_Matlab_Users thank you rcs i will try it I've edited the answer to point to the official docs. This is probably slow but it works nicely  Know both tile and repeat. x = numpy.arange(5) print numpy.tile(x 2) print x.repeat(2),python matlab numpy1530598,A,"Definition of mathematical operations (sinŠ—_) on NumPy arrays containing objects I would like to provide ""all"" mathematical functions for the number-like objects created by a module (the uncertainties.py module which performs calculations with error propagation)Š—”these objects are numbers with uncertainties. What is the best way to do this? Currently I redefine most of the functions from math in the module uncertainties.py so that they work on numbers with uncertainties. One drawback is that users who want to do from math import * must do so after doing import uncertainties. The interaction with NumPy is however restricted to basic operations (an array of numbers with uncertainties can be added etc.); it does not (yet) include more complex functions (e.g. sin()) that would work on NumPy arrays that contain numbers with uncertainties. The approach I have taken so far consists in suggesting that the user define sin = numpy.vectorize(math.sin) so that the new math.sin function (which works on numbers with uncertainties) is broadcast to the elements of any Numpy array. One drawback is that this has to be done for each function of interest by the user which is cumbersome. So what is the best way to extend mathematical functions such as sin() so that they work conveniently with simple numbers and NumPy arrays? The approach chosen by NumPy is to define its own numpy.sin rather than modifying math.sin so that it works with Numpy arrays. Should I do the same for my uncertainties.py module and stop redefining math.sin? Furthermore what would be the most efficient and correct way of defining sin so that it works both for simple numbers numbers with uncertainties and Numpy arrays? My redefined math.sin already handles simple numbers and numbers with uncertainties. However vectorizing it with numpy.vectorize is likely to be much slower on ""regular"" NumPy arrays than numpy.sin. It looks like following what NumPy itself does keeps things clean: ""extended"" mathematical operations (sinŠ—_) that work on new objects can be put in a separate name space. Thus NumPy has numpy.sin etc. These operations are mostly compatible with those from math but also work on NumPy arrays. Therefore it seems to me that mathematical functions that should work on usual numbers and NumPy arrays and their counterparts with uncertainties are best defined in a separate name space. For instance the user could do: from uncertainties import sin or from uncertainties import * # sin cos etc. For optimization purposes an alternative might be to provide two distinct sets of mathematical functions: those that generalize functions to simple numbers with uncertainties and those that generalize them to arrays with uncertainties: from uncertainties.math_ops import * # Work on scalars and scalars with uncertainty or from uncertainties.numpy_ops import * # Work on everything (scalars arrays numbers with uncertainties arrays with uncertainties)",python arrays numpy operations1295994,A,"Numpy: Is there an array size limit? I'm learning to use Numpy and I wanted to see the speed difference in the summation of a list of numbers so I made this code: np_array = numpy.arange(1000000) start = time.time() sum_ = np_array.sum() print time.time() - start sum_ >>> 0.0 1783293664 python_list = range(1000000) start = time.time() sum_ = sum(python_list) print time.time() - start sum_ >>> 0.390000104904 499999500000 The python_list sum is correct. If I do the same code with the summation to 1000 both print the right answer. Is there an upper limit to the length of the Numpy array or is it with the Numpy sum function? Thanks for your help The standard list switched over to doing arithmetic with the long type when numbers got larger than a 32-bit int. The numpy array did not switch to long and suffered from integer overflow. The price for speed is smaller range of values allowed. >>> 499999500000 % 2**32 1783293664L  Numpy is creating an array of 32-bit unsigned ints. When it sums them it sums them into a 32-bit value. if 499999500000L % (2**32) == 1783293664L: print ""Overflowed a 32-bit integer"" You can explicitly choose the data type at array creation time: a = numpy.arange(1000000 dtype=numpy.uint64) a.sum() -> 499999500000  Notice that 499999500000 % 2**32 equals exactly 1783293664 ... i.e. numpy is doing operations modulo 2**32 because that's the type of the numpy.array you've told it to use. Make np_array = numpy.arange(1000000 dtype=numpy.uint64) for example and your sum will come out OK (although of course there are still limits with any finite-size number type). You can use dtype=numpy.object to tell numpy that the array holds generic Python objects; of course performance will decay as generality increases.",python numpy1588224,A,"Is there any possibilty to convert recarray to ndarray and change ndim? I am getting recarray from matplotlib.mlab.csv2rec function. My expectation was it would have 2 dimensions like 'x' but it has 1 dimension like 'y'. Is there any way to get x from y? >>> import numpy as np >>> from datetime import date >>> x=np.array([(date(200011)01) ... (date(200011)11) ... (date(200011)10) ... (date(200011)00) ... ]) >>> x array([[2000-01-01 0 1] [2000-01-01 1 1] [2000-01-01 1 0] [2000-01-01 0 0]] dtype=object) >>> y = np.rec.fromrecords( x ) >>> y rec.array([(datetime.date(2000 1 1) 0 1) (datetime.date(2000 1 1) 1 1) (datetime.date(2000 1 1) 1 0) (datetime.date(2000 1 1) 0 0)] dtype=[('f0' '|O4') ('f1' '<i4') ('f2' '<i4')]) >>> x.ndim 2 >>> y.ndim 1 >>> x.shape (4 3) >>> y.ndim 1 >>> y.shape (4) >>> If your csv file has two columns csv2rec should create an array with two dimensions. Can you provide an example of the file you are parsing and the call to csv2rec that you make? moreover notice that you can use the new numpy.genfromtxt instead of csv2rec: it works better but you must pass it dtype=None as a parameter. actually it has 7 columns first one is date in a format dd/mm/yyyy then 6 doubles can different types be the cause? Well there might be a more efficient way than this but here is one way: #!/usr/bin/env python import numpy as np from datetime import date x=np.array([(date(200011)01) (date(200011)11) (date(200011)10) (date(200011)00) ]) y=np.rec.fromrecords( x ) z=np.empty((len(y)len(y.dtype))dtype='object') for idxfield in enumerate(y.dtype.names): z[:idx]=y[field] assert (x==z).all() sure but I can't believe there is no elegant way for such conversion :(  Sounds weird but... I can save to csv by using matplotlib.mlab.rec2csv and then read to ndarray by using numpy.loadtxt. My case is simpler as I already have csv file. Here is an example how it works. >>> a = np.loadtxt( 'name.csv' skiprows=1 delimiter='' converters = {0: lambda x: 0} ) >>> a array([[ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.  0.  0.  0.  0. ] [ 0.  0.29 0.29 0.43 0.29 0. ] [ 0.  0.71 0.29 0.57 0.  0. ] [ 0.  1.  0.57 0.71 0.  0. ] [ 0.  0.43 0.29 0.14 0.14 0. ] [ 0.  1.  0.43 0.71 0.  0. ] [ 0.  0.57 0.57 0.29 0.14 0. ] [ 0.  1.43 0.43 0.86 0.43 0. ] [ 0.  1.  0.71 0.57 0.  0. ] [ 0.  1.14 0.57 0.29 0.  0. ] [ 0.  1.43 0.29 0.71 0.29 0.29] [ 0.  1.14 0.43 1.  0.29 0.29] [ 0.  0.43 1.14 0.86 0.43 0.14] [ 0.  1.14 0.86 0.86 0.29 0.29]]) >>> t = a.any( axis = 1 ) >>> t array([False False False False False False False False False False False False False False False False True True True True True True True True True True True True True] dtype=bool) >>> a.ndim 2 Also in my case I don't need a first column for making a decision.  You can do it via pandas: import pandas as pd pd.DataFrame(y).values array([[2000-01-01 0 1] [2000-01-01 1 1] [2000-01-01 1 0] [2000-01-01 0 0]] dtype=object) But I would consider doing my project in pandas if I were you. Support for named columns is built much more deeply into pandas than into regular numpy. >>> z = pd.DataFrame.from_records(y index=""f0"") >>> z f1 f2 f0 2000-01-01 0 1 2000-01-01 1 1 2000-01-01 1 0 2000-01-01 0 0 >>> z[""f1""] f0 2000-01-01 0 2000-01-01 1 2000-01-01 1 2000-01-01 0 Name: f1 +1 for pandas which ought to make all of this easier but I believe the proper way to access a DataFrame as a numpy array is ``.values`` not ``.__array__()``. Changed __array__() to values; thanks @DanAllan",python numpy1322380,A,"gotchas where Numpy differs from straight python? Folks is there a collection of gotchas where Numpy differs from python points that have puzzled and cost time ? ""The horror of that moment I shall never never forget !"" ""You will though"" the Queen said ""if you don't make a memorandum of it."" For example NaNs are always trouble anywhere. If you can explain this without running it give yourself a point -- from numpy import array NaN isnan pynan = float(""nan"") print pynan is pynan pynan is NaN NaN is NaN a = (0 pynan) print a a[1] is pynan any([aa is pynan for aa in a]) a = array(( 0 NaN )) print a a[1] is NaN isnan( a[1] ) (I'm not knocking numpy lots of good work there just think a FAQ or Wiki of gotchas would be useful.) Edit: I was hoping to collect half a dozen gotchas (surprises for people learning Numpy). Then if there are common gotchas or better common explanations we could talk about adding them to a community Wiki (where ?) It doesn't look like we have enough so far. should be community wiki No one mentioned primitive types. Does this mean a python float is equivalent to a np.float and so on? The biggest gotcha for me was that almost every standard operator is overloaded to distribute across the array. Define a list and an array >>> l = range(10) >>> l [0 1 2 3 4 5 6 7 8 9] >>> import numpy >>> a = numpy.array(l) >>> a array([0 1 2 3 4 5 6 7 8 9]) Multiplication duplicates the python list but distributes over the numpy array >>> l * 2 [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9] >>> a * 2 array([ 0 2 4 6 8 10 12 14 16 18]) Addition and division are not defined on python lists >>> l + 2 Traceback (most recent call last): File ""<stdin>"" line 1 in <module> TypeError: can only concatenate list (not ""int"") to list >>> a + 2 array([ 2 3 4 5 6 7 8 9 10 11]) >>> l / 2.0 Traceback (most recent call last): File ""<stdin>"" line 1 in <module> TypeError: unsupported operand type(s) for /: 'list' and 'float' >>> a / 2.0 array([ 0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5]) Numpy overloads to treat lists like arrays sometimes >>> a + a array([ 0 2 4 6 8 10 12 14 16 18]) >>> a + l array([ 0 2 4 6 8 10 12 14 16 18]) Yes that got me too. A simple table with columns: op python numpy would settle that. Actually ``a + a`` **is** defined for lists. It concatenates them.  A 0-d array of None looks like None but it is not the same: In [1]: print None None In [2]: import numpy In [3]: print numpy.array(None) None In [4]: numpy.array(None) is None Out[4]: False In [5]: numpy.array(None) == None Out[5]: False In [6]: print repr(numpy.array(None)) array(None dtype=object)  print pynan is pynan pynan is NaN NaN is NaN This tests identity that is if it is the same object. The result should therefore obviously be True False True because when you do float(whatever) you are creating a new float object. a = (0 pynan) print a a[1] is pynan any([aa is pynan for aa in a]) I don't know what it is that you find surprising with this. a = array(( 0 NaN )) print a a[1] is NaN isnan( a[1] ) This I did have to run. :-) When you stick NaN into an array it's converted into a numpy.float64 object which is why a[1] is NaN fails. This all seems fairly unsurprising to me. But then I don't really know anything much about NumPy. :-)  NaN is not a singleton like None so you can't really use the is check on it. What makes it a bit tricky is that NaN == NaN is False as IEEE-754 requires. That's why you need to use the numpy.isnan() function to check if a float is not a number. Or the standard library math.isnan() if you're using Python 2.6+. Well it's in the definition of NaN. def isnan(x): return (x != x)  Not such a big gotcha: With boolean slicing I sometimes wish I could do x[ 3<= y < 7 ] like the python double comparison. Instead I have to write x[ np.logical_and( 3<=y y<7) ] (Unless you know something better?) Also np.logical_and and np.logical_or only take two arguments each I would like them to take a variable number or a list so I could feed in more than just two logical clauses. (numpy 1.3 maybe this has all changed in later versions.) What about x[(3<=y) & (y<7)] ?  from Neil Martinsen-Burrell in numpy-discussion 7 Sept -- The ndarray type available in Numpy is not conceptually an extension of Python's iterables. If you'd like to help other Numpy users with this issue you can edit the documentation in the online documentation editor at numpy-docs  I found the fact that multiplying up lists of elements just creates view of elements caught me out. >>> a=[0]*5 >>>a [00000] >>>a[2] = 1 >>>a [00100] >>>b = [np.ones(3)]*5 >>>b [array([ 1. 1. 1.]) array([ 1. 1. 1.]) array([ 1. 1. 1.]) array([ 1. 1. 1.]) array([ 1. 1. 1.])] >>>b[2][1] = 2 >>>b [array([ 1. 2. 1.]) array([ 1. 2. 1.]) array([ 1. 2. 1.]) array([ 1. 2. 1.]) array([ 1. 2. 1.])] So if you create a list of elements like this and intend to do different operations on them you are scuppered ... A straightforward solution is to iteratively create each of the arrays (using a 'for loop' or list comprehension) or use a higher dimensional array (where e.g. each of these 1D arrays is a row in your 2D array which is generally faster).  Because __eq__ does not return a bool using numpy arrays in any kind of containers prevents equality testing without a container-specific work around. Example: >>> import numpy >>> a = numpy.array(range(3)) >>> b = numpy.array(range(3)) >>> a == b array([ True True True] dtype=bool) >>> x = (a 'banana') >>> y = (b 'banana') >>> x == y Traceback (most recent call last): File ""<stdin>"" line 1 in <module> ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all() This is a horrible problem. For example you cannot write unittests for containers which use TestCase.assertEqual() and must instead write custom comparison functions. Suppose we write a work-around function special_eq_for_numpy_and_tuples. Now we can do this in a unittest: x = (array1 'deserialized') y = (array2 'deserialized') self.failUnless( special_eq_for_numpy_and_tuples(x y) ) Now we must do this for every container type we might use to store numpy arrays. Furthermore __eq__ might return a bool rather than an array of bools: >>> a = numpy.array(range(3)) >>> b = numpy.array(range(5)) >>> a == b False Now each of our container-specific equality comparison functions must also handle that special case. Maybe we can patch over this wart with a subclass? >>> class SaneEqualityArray (numpy.ndarray): ... def __eq__(self other): ... return isinstance(other SaneEqualityArray) and self.shape == other.shape and (numpy.ndarray.__eq__(self other)).all() ... >>> a = SaneEqualityArray( (2 3) ) >>> a.fill(7) >>> b = SaneEqualityArray( (2 3) ) >>> b.fill(7) >>> a == b True >>> x = (a 'banana') >>> y = (b 'banana') >>> x == y True >>> c = SaneEqualityArray( (7 7) ) >>> c.fill(7) >>> a == c False That seems to do the right thing. The class should also explicitly export elementwise comparison since that is often useful.  In [1]: bool([]) Out[1]: False In [2]: bool(array([])) Out[2]: False In [3]: bool([0]) Out[3]: True In [4]: bool(array([0])) Out[4]: False So don't test for the emptiness of an array by checking its truth value. Use size(array).  No one seems to have mentioned this so far: >>> all(False for i in range(3)) False >>> from numpy import all >>> all(False for i in range(3)) True >>> any(False for i in range(3)) False >>> from numpy import any >>> any(False for i in range(3)) True numpy's any and all don't play nicely with generators and don't raise any error warning you that they don't.  Slicing creates views not copies. >>> l = [1 2 3 4] >>> s = l[2:3] >>> s[0] = 5 >>> l [1 2 3 4] >>> a = array([1 2 3 4]) >>> s = a[2:3] >>> s[0] = 5 >>> a array([1 2 5 4]) not always: ""There are two kinds of fancy indexing in numpy which behave similarly ..."" http://mail.scipy.org/pipermail/numpy-discussion/2008-January/031101.html  (Related but a NumPy vs. SciPy gotcha rather than NumPy vs Python) Slicing beyond an array's real size works differently: >>> import numpy scipy.sparse >>> m = numpy.random.rand(2 5) # create a 2x5 dense matrix >>> print m[:3 :] # works like list slicing in Python: clips to real size [[ 0.12245393 0.20642799 0.98128601 0.06102106 0.74091038] [ 0.0527411 0.9131837 0.6475907 0.27900378 0.22396443]] >>> s = scipy.sparse.lil_matrix(m) # same for csr_matrix and other sparse formats >>> print s[:3 :] # doesn't clip! IndexError: row index out of bounds So when slicing scipy.sparse arrays you must make manually sure your slice bounds are within range. This differs from how both NumPy and plain Python work.  The truth value of a Numpy array differs from that of a python sequence type where any non-empty sequence is true. >>> import numpy as np >>> l = [0123] >>> a = np.arange(4) >>> if l: print ""Im true"" ... Im true >>> if a: print ""Im true"" ... Traceback (most recent call last): File ""<stdin>"" line 1 in <module> ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all() >>> The numerical types are true when they are non-zero and as a collection of numbers the Nupy array inherits this definition. But with a collection of numbers truth could reasonably mean ""all elements are non-zero"" or ""at least one element is non-zero"". Numpy refuses to guess which definition is meant and raises the above exception. Using the .any() and .all() methods allows one to specify which meaning of true is meant. >>> if a.any(): print ""Im true"" ... Im true >>> if a.all(): print ""Im true"" ... >>>  I think this one is funny: >>> import numpy as n >>> a = n.array([[12][34]]) >>> a[1] a[0] = a[0] a[1] >>> a array([[1 2] [1 2]]) For Python lists on the other hand this works as intended: >>> b = [[12][34]] >>> b[1] b[0] = b[0] b[1] >>> b [[3 4] [1 2]] Funny side note: numpy itself had a bug in the shuffle function because it used that notation :-) (see here). The reason is that in the first case we are dealing with views of the array so the values are overwritten in-place. Could you explain how the numpy array ends up being so?",python numpy1764859,A,How to compute laplacian of a field? I'm trying to compute the laplacian of a 2d field A using scipy.ndimage.convolve. stencil = numpy.array([[0 1 0][1 -4 1] [0 1 0]]) scipy.ndimage.convolve(A stencil mode='wrap') This doesn't seem to give me the right answer though. Any ideas where I'm going wrong or are there better ways of computing the laplacian in numpy? how does it seem not right ? do you have an example image to compare to ? I'm testing this out on a gaussian in 2d. So I have an array where I've evaluated the laplacian of the gaussian analytically and then I try my numerical laplacian on the gaussian itself. When I take the difference between the two the results are not close to 0. i seem to remember that a convolution with a laplace kernel is only an approximation of a laplace transform... By laplacian I mean: d^2(phi)/dx^2 + d^2(phi)/dy^2. The stencil I used is supposed to be a finite difference approximation to the laplacian. did you try another laplace convolution kernel like [[111][1-81][111]] ? Just tried it and it also doesn't seem to work.  I got another idea: did you take into account that your stencil in order to approximate the Laplacian should be divided by step**2 where step is the step size of your grid? Only then can you compare the ndimage.convolve result with the analytical result. In fact with a Gaussian I obtain results that indicate that ndimage.convolve works quite well: from scipy import ndimage stencil = numpy.array([[0 1 0][1 -4 1] [0 1 0]]) x = linspace(-10 10 100) y = linspace(-10 10 100) xx yy = meshgrid(x y) image = exp(-xx**2-yy**2) # Standard deviation in x or y: 1/sqrt(2) laplaced = ndimage.convolve(image stencil)/(x[1]-x[0])**2 # stencil from original post expected_result = -4*image + 8*(xx**2+yy**2)*image # Very close to laplaced in most points! I did actually take that into account when I worked with the result matrix. I think the problem I was seeing was that the grid I was using was too small.  I tried your example and it does work with the latest SciPy on my machine. I would suggest that you plot image-ndimage.convolve(Š—_) in order to see how the convolution changes your image. Example: image = vstack(arange(-10 10)**2 for _ in range(20)) ndimage.convolve(image stencil mode='wrap') yields array([[-38 2 2 2 2 2 2 2 2 2 2 2 2...) which is quite correct (the second order derivative of x**2 being 2)Š—”except for the left border. I get the same result and in 1d this works for the gaussian but the 2d gaussian still doesn't work for me.,python numpy scipy1398822,A,"The Assignment Problem a numpy function? Since an assignment problem can be posed in the form of a single matrix I am wandering if numpy has a function to solve such a matrix. So far I have found none. Maybe one of you guys know if numpy/scipy has an assignment-problem-solve function? Edit: In the meanwhile I have found a python (not numpy/scipy) implementation at http://www.clapper.org/software/python/munkres/. Still I suppose a numpy/scipy implementation could be much faster right? What a shame it was not implemented with numpy. Not only might it be faster but the algorithm must be much easier to express with numpy as well. There is an implementation of the Munkres' algorithm as a python extension module which has numpy support. I've used it successfully on my old laptop. However it does not work on my new machine - I assume there is a problem with ""new"" numpy versions (or 64bit arch).  There is now a numpy implementation of the munkres algorithm in scikit-learn under sklearn/utils/linear_assignment_.py its only dependency is numpy. I tried it with some approximately 20x20 matrices and it seems to be about 4 times as fast as the one linked to in the question. cProfiler shows 2.517 seconds vs 9.821 seconds for 100 iterations.  No NumPy contains no such function. Combinatorial optimization is outside of NumPy's scope. It may be possible to do it with one of the optimizers in scipy.optimize but I have a feeling that the constraints may not be of the right form. NetworkX probably also includes algorithms for assignment problems.",python numpy scipy49926,A,Open source alternative to MATLAB's fmincon function? Is there an open-source alternative to MATLAB's fmincon function for constrained linear optimization? I'm rewriting a MATLAB program to use Python / NumPy / SciPy and this is the only function I haven't found an equivalent to. A NumPy-based solution would be ideal but any language will do. The open source Python packageSciPy has quite a large set of optimization routines including some for multivariable problems with constraints (which is what fmincon does I believe). Once you have SciPy installed type the following at the Python command prompt help(scipy.optimize) The resulting document is extensive and includes the following which I believe might be of use to you.  Constrained Optimizers (multivariate) fmin_l_bfgs_b -- Zhu Byrd and Nocedal's L-BFGS-B constrained optimizer (if you use this please quote their papers -- see help) fmin_tnc -- Truncated Newton Code originally written by Stephen Nash and adapted to C by Jean-Sebastien Roy. fmin_cobyla -- Constrained Optimization BY Linear Approximation  Python optimization software: OpenOpt http://openopt.org (this one is numpy-based as you wish with automatic differentiation by FuncDesigner) Pyomo https://software.sandia.gov/trac/coopr/wiki/Package/pyomo CVXOPT http://abel.ee.ucla.edu/cvxopt/ NLPy http://nlpy.sourceforge.net/  I don't know if it's in there but there's a python distribution called Enthought that might have what you're looking for. It was designed specifically for data analysis has over 60 additional libraries. Two other people added links that weren't sure whether or not their suggestions would have what the original poster wanted. Why the down votes. A comment would be nice here.  For numerical optimization in Python you may take a look at OpenOpt solvers: http://openopt.org/NLP http://openopt.org/Problems  GNU Octave is another MATLAB clone that might have what you need.  Is your problem convex? Linear? Non-linear? I agree that SciPy.optimize will probably do the job but fmincon is a sort of bazooka for solving optimization problems and you'll be better off if you can confine it to one of the categories below (in increasing level of difficulty to solve efficiently) Linear Program (LP) Quadratic Program (QP) Convex Quadratically-Constrained Quadratic Program (QCQP) Second Order Cone Program (SOCP) Semidefinite Program (SDP) Non-Linear Convex Problem Non-Convex Problem There are also combinatoric problems such as Mixed-Integer Linear Programs (MILP) but you didn't mention any sort of integrality constraints suffice to say that they fall into a different class of problems. The CVXOpt package will be of great use to you if your problem is convex. If your problem is not convex you need to choose between finding a local solution or the global solution. Many convex solvers 'sort of' work in a non-convex domain. Finding a good approximation to the global solution would require some form Simulated Annealing or Genetic Algorithm. Finding the global solution will require an enumeration of all local solutions or a combinatorial strategy such as Branch and Bound.  Have a look at http://www.aemdesign.com/downloadfsqp.htm. There you will find C code which provides the same functionality as fmincon. (However using a different algorithm. You can read the manual if you are interested in the details.) It's open source but not under GPL.  There is a program called SciLab that is a MATLAB clone. I haven't used it at all but it is open source and might have the function you are looking for.,python matlab numpy numerical scientific-computing893657,A,"How do I calculate r-squared using Python and Numpy? I'm using Python and Numpy to calculate a best fit polynomial of arbitrary degree. I pass a list of x values y values and the degree of the polynomial I want to fit (linear quadratic etc.). This much works but I also want to calculate r (coefficient of correlation) and r-squared(coefficient of determination). I am comparing my results with Excel's best-fit trendline capability and the r-squared value it calculates. Using this I know I am calculating r-squared correctly for linear best-fit (degree equals 1). However my function does not work for polynomials with degree greater than 1. Excel is able to do this. How do I calculate r-squared for higher-order polynomials using Numpy? Here's my function: import numpy # Polynomial Regression def polyfit(x y degree): results = {} coeffs = numpy.polyfit(x y degree) # Polynomial Coefficients results['polynomial'] = coeffs.tolist() correlation = numpy.corrcoef(x y)[01] # r results['correlation'] = correlation # r-squared results['determination'] = correlation**2 return results @leif -- The request boils down to ""do it like Excel does"". I'm getting the feeling from these answers that the users may be reading too much into the r-squared value when using a non-linear best-fit curve. Nonetheless I'm not a math wizard and this is the requested functionality. Note: you use the degree only in the calculation of coeffs. tydok is correct. You are calculating the correlation of x and y and r-squared for y=p_0 + p_1 * x. See my answer below for some code that should work. If you don't mind me asking what is your ultimate goal? Are you doing model selection (choosing what degree to use)? Or something else? I have been using this successfully where x and y are array-like. def rsquared(x y): """""" Return R^2 where x and y are array-like."""""" slope intercept r_value p_value std_err = scipy.stats.linregress(x y) return r_value**2  From the numpy.polyfit documentation it is fitting linear regression. Specifically numpy.polyfit with degree 'd' fits a linear regression with the mean function E(y|x) = p_d * x**d + p_{d-1} * x **(d-1) + ... + p_1 * x + p_0 So you just need to calculate the R-squared for that fit. The wikipedia page on linear regression gives full details. You are interested in R^2 which you can calculate in a couple of ways the easisest probably being SST = Sum(i=1..n) (y_i - y_bar)^2 SSReg = Sum(i=1..n) (y_ihat - y_bar)^2 Rsquared = SSReg/SST Where I use 'y_bar' for the mean of the y's and 'y_ihat' to be the fit value for each point. I'm not terribly familiar with numpy (I usually work in R) so there is probably a tidier way to calculate your R-squared but the following should be correct import numpy # Polynomial Regression def polyfit(x y degree): results = {} coeffs = numpy.polyfit(x y degree) # Polynomial Coefficients results['polynomial'] = coeffs.tolist() # r-squared p = numpy.poly1d(coeffs) # fit values and mean yhat = p(x) # or [p(z) for z in x] ybar = numpy.sum(y)/len(y) # or sum(y)/len(y) ssreg = numpy.sum((yhat-ybar)**2) # or sum([ (yihat - ybar)**2 for yihat in yhat]) sstot = numpy.sum((y - ybar)**2) # or sum([ (yi - ybar)**2 for yi in y]) results['determination'] = ssreg / sstot return results Thank you this explanation is very clear to me. I'm going to try this one out. No problem glad to help. Exactly what I was looking for. I just want to point out that using the numpy array functions instead of list comprehension will be much faster e.g. numpy.sum((yi - ybar)**2) and easier to read According to wiki page http://en.wikipedia.org/wiki/Coefficient_of_determination the most general definition of R^2 is `R^2 = 1 - SS_err/SS_tot` with `R^2 = SS_reg/SS_tot` being just a special case.  The wikipedia article on r-squareds suggests that it may be used for general model fitting rather than just linear regression.  R-squared is a statistic that only applies to linear regression. Essentially it measures how much variation in your data can be explained by the linear regression. So you calculate the ""Total Sum of Squares"" which is the total squared deviation of each of your outcome variables from their mean. . . \sum_{i}(y_{i} - y_bar)^2 where y_bar is the mean of the y's. Then you calculate the ""regression sum of squares"" which is how much your FITTED values differ from the mean \sum_{i}(yHat_{i} - y_bar)^2 and find the ratio of those two. Now all you would have to do for a polynomial fit is plug in the y_hat's from that model but it's not accurate to call that r-squared. Here is a link I found that speaks to it a little. This seems to be the root of my problem. How does Excel get a different r-squared value for a polynomial fit vs. a linear regression then? are you just giving excel the fits from a linear regression and the fits from a polynomial model? It's going to calculate the rsq from two arrays of data and just assume that you're giving it the fits from a linear model. What are you giving excel? What is the 'best fit trendline' command in excel? It's part of the graphing functions of Excel. You can plot some data right-click on it then choose from several different types of trend lines. There is the option to see the equation of the line as well as an r-squared value for each type. The r-squared value is also different for each type. @Travis Beale -- you are going to get a different r-squared for each different mean function you try (unless two models are nested and the extra coeffecients in the larger model all work to be 0). So of course Excel gives a different r-squared values. @Baltimark -- this is linear regression so it is r-squared.  A very late reply but just in case someone needs a ready function for this: scipy.stats.stats.linregress i.e. slope intercept r_value p_value std_err = scipy.stats.linregress(x y) as in @Adam Marples's answer. It's reasonable to analyze with *coefficient of correlation* and then to do the bigger job *regression*.",python math statistics numpy curve-fitting1987694,A,"Print the full numpy array When I print a numpy array I get a truncated representation but I want the full array. Is there any way to do this? Examples: >>> numpy.arange(10000) array([ 0 1 2 ... 9997 9998 9999]) >>> numpy.arange(10000).reshape(25040) array([[ 0 1 2 ... 37 38 39] [ 40 41 42 ... 77 78 79] [ 80 81 82 ... 117 118 119] ... [9880 9881 9882 ... 9917 9918 9919] [9920 9921 9922 ... 9957 9958 9959] [9960 9961 9962 ... 9997 9998 9999]]) Are you using `numpy` specifically? It looks like he is.. Is there a way to do it on a ""one off"" basis? That is to print out the full output once but not at other times in the script? @Matt O'Brien see ZSG's answer below This sounds like you're using numpy. If that's the case you can add: set_printoptions(threshold=nan) That will disable the corner printing. For more information see this NumPy Tutorial.  Here is a one-off way to do this if you don't want to change your default settings: def fullprint(*args **kwargs): from pprint import pprint import numpy opt = numpy.get_printoptions() numpy.set_printoptions(threshold='nan') pprint(*args **kwargs) numpy.set_printoptions(**opt)  To clarify on Reed's reply import numpy numpy.set_printoptions(threshold=numpy.nan) Note that the reply as given above works with an initial 'from numpy import *' which is not advisable. This also works for me numpy.set_printoptions(threshold='nan') For full documentation see http://docs.scipy.org/doc/numpy/reference/generated/numpy.set_printoptions.html.",python arrays numpy1962980,A,"Selecting rows from a NumPy ndarray I want to select only certain rows from a NumPy array based on the value in the second column. For example this test array has integers from 1 to 10 in the second column. >>> test = numpy.array([numpy.arange(100) numpy.random.randint(1 11 100)]).transpose() >>> test[:10 :] array([[ 0 6] [ 1 7] [ 2 10] [ 3 4] [ 4 1] [ 5 10] [ 6 6] [ 7 4] [ 8 6] [ 9 7]]) If I wanted only rows where the second value is 4 it is easy: >>> test[test[: 1] == 4] array([[ 3 4] [ 7 4] [16 4] ... [81 4] [83 4] [88 4]]) But how do I achieve the same result when there is more than one wanted value? The wanted list can be of arbitrary length. For example I may want all rows where the second column is either 2 4 or 6: >>> wanted = [2 4 6] The only way I have come up with is to use list comprehension and then convert this back into an array and seems too convoluted although it works: >>> test[numpy.array([test[x 1] in wanted for x in range(len(test))])] array([[ 0 6] [ 3 4] [ 6 6] ... [90 2] [91 6] [92 2]]) Is there a better way to do this in NumPy itself that I am missing? numpy.in1d is what you are looking for: print test[numpy.in1d(test[:1] wanted)] It should easily be the fastest solution if wanted is large; plus it is the most readable one id say.  test[numpy.logical_or.reduce([test[:1] == x for x in wanted])] The result should be faster than the original version since NumPy's doing the inner loops instead of Python. This solution goes through the array len(wanted) times. It is usually faster to go through the array in a single pass. Thanks Amnon. This is the solution that I decided to accept. I think it is clear to understand and is about 20 x faster than my original solution.  The following solution should be faster than Amnon's solution as wanted gets larger: wanted_set = set(wanted) # Much faster look up than with lists for larger lists @numpy.vectorize def selected(elmt): return elmt in wanted_set # Or: selected = wanted_set.__contains__ print test[selected(test[: 1])] In fact it has the advantage of searching through the test array only once (instead of len(wanted) times). It also uses Python's built-in fast element look up in sets which are much faster for this than lists. It is also fast because it uses Numpy's fast loops. You also get the optimization of the in operator: once a wanted element matches the remaining elements do not have to be tested (as opposed to the ""logical or"" approach of Amnon were all the elements in wanted are tested no matter what). Alternatively you could use the following one-liner which also goes through your array only once: test[numpy.apply_along_axis(lambda x: x[1] in wanted 1 test)] This is much much slower though as this extracts the element in the second column at each iteration (instead of doing it in one pass as in the first solution of this answer). @Amnon: Good point and interesting results. Thanks! These solutions call python for every element instead of using numpy's comparison. According to my tests your first solution is faster than mine for len(wanted)=50 but slower for len(wanted)=5. EOL many thanks for your time and effort. Your explanations were clear. I chose to use Amnon's solution because for my usual scenario (len(test) about 1000 and len(wanted) about 3-5) that was faster than your first solution. The speed difference is not huge but I also found it clearer. But it was good to be reminded of numpy's vectorize and I am sure I will find a use for it soon.  This is two times faster than Amnon's variant for len(test)=1000: wanted = (246) wanted2 = numpy.expand_dims(wanted 1) print test[numpy.any(test[: 1] == wanted2 0) :] @ahatchkins: Some typos in your version. What you are suggesting is this - # convert wanted list into a one column array wanted = numpy.array(wanted).reshape((len(wanted)1)) # print test[numpy.any(test[:1] == wanted 0)] In my tests this is about 2 times faster than Amnon's solution. Yes there was a typo: s/wanted2/wanted/ . Fixed Hmm yes. You are right. Two typos in fact. And only 2 times faster. )",python numpy1029207,A,"Interpolation in SciPy: Finding X that produces Y Is there a better way to find which X gives me the Y I am looking for in SciPy? I just began using SciPy and I am not too familiar with each function. import numpy as np import matplotlib.pyplot as plt from scipy import interpolate x = [70 80 90 100 110] y = [49.7 80.6 122.5 153.8 163.0] tck = interpolate.splrep(xys=0) xnew = np.arange(701111) ynew = interpolate.splev(xnewtckder=0) plt.plot(xy'x'xnewynew) plt.show() tck=tck yToFind = 140 print interpolate.sproot((tc-yToFindk)) #Lowers the spline at the abscissa Can you elaborate on what you want to be better? Performance accuracy conciseness? The UnivariateSpline class in scipy makes doing splines much more pythonic. x = [70 80 90 100 110] y = [49.7 80.6 122.5 153.8 163.0] f = interpolate.UnivariateSpline(x y s=0) xnew = np.arange(701111) plt.plot(xy'x'xnewf(xnew)) To find x at y then do: yToFind = 140 yreduced = np.array(y) - yToFind freduced = interpolate.UnivariateSpline(x yreduced s=0) freduced.roots() I thought interpolating x in terms of y might work but it takes a somewhat different route. It might be closer with more points. Wouldn't this require twice the amount of CPU calculations since are interpolating practically the same data set two times? @JcMaco the first use of UnivariateSpline is just to make a pretty plot. The second usage is what actually gives the values. Should that be `freduced.roots()` on the last line? Craig is right can you correct it on your example as it's otherwise great! Fixed the typo. Thanks Craig.  If all you need is linear interpolation you could use the interp function in numpy. Your question didn't specify what type of interpolation you needed -- if linear isn't good enough for your problem then I don't think interp will help. I'd prefer spline interpolation. How would the interp function help me solve my problem more easily?  I may have misunderstood your question if so I'm sorry. I don't think you need to use SciPy. NumPy has a least squares function. #!/usr/bin/env python from numpy.linalg.linalg import lstsq def find_coefficients(data exponents): X = tuple((tuple((pow(xp) for p in exponents)) for (xy) in data)) y = tuple(((y) for (xy) in data)) x resids rank s = lstsq(Xy) return x if __name__ == ""__main__"": data = tuple(( (1.47 52.21) (1.50 53.12) (1.52 54.48) (1.55 55.84) (1.57 57.20) (1.60 58.57) (1.63 59.93) (1.65 61.29) (1.68 63.11) (1.70 64.47) (1.73 66.28) (1.75 68.10) (1.78 69.92) (1.80 72.19) (1.83 74.46) )) print find_coefficients(data range(3)) This will return [ 128.81280358 -143.16202286 61.96032544]. >>> x=1.47 # the first of the input data >>> 128.81280358 + -143.16202286*x + 61.96032544*(x**2) 52.254697219095988 0.04 out not bad The problem is finding which number will give me 52.21. Of course there can be many solutions if the interpolation is quadratic (or higher power).",python numpy scipy interpolation scientific-computing790960,A,"How to synthesize sounds? I'd like to produce sounds that would resemble audio from real instruments. The problem is that I have very little clue how to get that. What I know this far from real instruments is that sounds they output are rarely clean. But how to produce such unclean sounds? This far I've gotten to do this it produces quite plain sound from which I'm not sure it's even using the alsa correctly. import numpy from numpy.fft import fft ifft from numpy.random import random_sample from alsaaudio import PCM PCM_NONBLOCK PCM_FORMAT_FLOAT_LE pcm = PCM()#mode=PCM_NONBLOCK) pcm.setrate(44100) pcm.setformat(PCM_FORMAT_FLOAT_LE) pcm.setchannels(1) pcm.setperiodsize(4096) def sine_wave(x freq=100): sample = numpy.arange(x*4096 (x+1)*4096 dtype=numpy.float32) sample *= numpy.pi * 2 / 44100 sample *= freq return numpy.sin(sample) for x in xrange(1000): sample = sine_wave(x 100) pcm.write(sample.tostring()) As other people said not a trivial topic at all. There are challenges both at the programming side of things (especially if you care about low-latency) and the synthesis part. A goldmine for sound synthesis is the page by Julius O. Smith. There is a lot of techniques for synthesis http://ccrma-www.stanford.edu/~jos/.  Sound synthesis is a complex topic which requires many years of study to master. It is also not an entirely solved problem although relatively recent developments (such as physical modelling synthesis) have made progress in imitating real-world instruments. There are a number of options open to you. If you are sure that you want to explore synthesis further then I suggest you start by learning about FM synthesis. It is relatively easy to learn and implement in software at least in basic forms and produces a wide range of interesting sounds. Also check out the book ""The Computer Music Tutorial"" by Curtis Roads. It's a bible for all things computer music and although it's a few years old it is the book of choice for learning the fundamentals. If you want a quicker way to produce life-like sound consider using sampling techniques: that is record the instruments you want to reproduce (or use a pre-existing sample bank) and just play back the samples. It's a much more straightforward (and often more effective) approach. I wouldn't like to use sample banks. I want something that resembles instruments not life-like at all.  Cheery if you want to generate (from scratch) something that really sounds ""organic"" i.e. like a physical object you're probably best off to learn a bit about how these sounds are generated. For a solid introduction you could have a look at a book such as Fletcher and Rossings The Physics of Musical Instruments. There's lots of stuff on the web too you might want to have a look at a the primer James Clark has here Having at least a skim over this sort of stuff will give you an idea of what you are up against. Modeling physical instruments accurately is very difficult! If what you want to do is have something that sounds physical rather something that sounds like instrument X your job is a bit easier. You can build up frequencies quite easily and stack them together add a little noise and you'll get something that at least doesn't sound anything like a pure tone. Reading a bit about Fourier analysis in general will help as will Frequency Modulation (FM) techniques. Have fun!  I agree that this is very non-trivial and there's no set ""right way"" but you should consider starting with a (or making your own) MIDI SoundFont.",python numpy alsa1601613,A,"python contour for binary 2D matrix I want to calculate a convex hull around a shape in a binary NxM matrix. The convex hull algorithm expects a list of coordinates so I take numpy.argwhere(im) to have all shape point coordinates. However most of those points are not contributing to the convex hull (they lie on the inside of the shape). Because convex hull computation time is at least proportional to the number of points that it gets as input I devised an idea to filter the plethora of useless points on beforehand and only pass those that span the outline. The idea is quite simple that for each row in the binary NxM matrix I take only the minimal and maximal indices. So for example: im = np.array([[1110] [1011] [1101] [0000] [0111]] dtype=np.bool) outline = somefunc(im) Then outline should read (in tuples or as a 5x2 numpy array I don't mind): [(00)(02)(10)(13)(20)(23)(41)(43)] Any convex hull tight around this shape (im) must a subset of these points (outline). In other words if ""somefunc()"" is efficient in filtering the inside points then it saves time for the convex hull computation. I have code that does the above trick but I am hoping someone has a more clever (read faster) approach since I need to run it many many times. The code I have is: # I have a 2D binary field. random for the purpose of demonstration. import numpy as np im = np.random.random((320360)) > 0.9 # This is my algorithm so far. Notice that coords is sorted. coords = np.argwhere(im) left = np.roll(coords[:0] 1 axis=0) != coords[:0] outline = np.vstack([coords[left] coords[left[1:]] coords[-1]]) Another idea I had was to use Python's reduce() so I'd need to run over the list of coords only once. But I have difficulty finding a good reducing function. Any help would greatly be appreciated! edit In the meanwhile I have found a faster way to go from im directly to outline. At least with large images this is significantly faster. In the apparent absence of an external solution I am positing it as the solution to this question. Still if somebody knows an even faster method please speak up :) @Paul: Probably a good approach to complain because parts of your question are unclear and unhelpful. If we can't get your question (including your tags) we're pretty much unable to help. `fast` is not very helpful tag *sigh* I'm looking for answers wise guy. In the absence of an acceptable answer I post my best working code as the solution. def outline(im): ''' Input binary 2D (NxM) image. Ouput array (2xK) of K (yx) coordinates where 0 <= K <= 2*M. ''' topbottom = np.empty((12*im.shape[1]) dtype=np.uint16) topbottom[00:im.shape[1]] = np.argmax(im axis=0) topbottom[0im.shape[1]:] = (im.shape[0]-1)-np.argmax(np.flipud(im) axis=0) mask = np.tile(np.any(im axis=0) (2)) xvalues = np.tile(np.arange(im.shape[1]) (12)) return np.vstack([topbottomxvalues])[:mask].T  For more general solution you could use somekind of edge detection method to find only the edge points. I believe (Google..) that NumPy has built-in sobel filter which will do that. The filter will give you the bitmap/matrix where you can find all the indices like you did in your code. Oh wait you got the example image with sobel and it has too many points? yes I know the sobel filter and it is marvelous. In fact that is how I got to these binary images. the filter does not give indices however. You're right. I want to fit a polygon around the (thresholded) sobel. And therefore first I'd like to reduce the number of points. This last part is where I am trying to find fast code for. In machine vision application I've been using there's contour output in blob tool but unfortunately I don't see such feature in OpenCV. That would've been elegant solution..  This assignment seems to accomplish the same thing as your last two steps: outline = np.array(dict(reversed(coords)).items() + dict(coords).items()) Don't know if it's any faster however. Too bad it's 10 times(!) slower. That is an interesting approach. Trying it now...",python algorithm numpy contour971678,A,Iterating through a multidimensional array in Python I have created a multidimensional array in Python like this: self.cells = np.empty((rc)dtype=np.object) Now I want to iterate through all elements of my twodimensional array and I do not care about the order. How do I achieve this? Just iterate over one dimension then the other. for row in self.cells: for cell in row: do_something(cell) Of course with only two dimensions you can compress this down to a single loop using a list comprehension or generator expression but that's not very scalable or readable: for cell in (cell for row in self.cells for cell in row): do_something(cell) If you need to scale this to multiple dimensions and really want a flat list you can write a flatten function. Wow this answer is ancient. You're right; will fix. Isn't the way he did it fine? It's just a generator expression instead of a list comprehension...am I missing something? O.o You got it wrong. It should be: for cell in [cell for row in self.cells for cell in row]: do_something(cell) The 'for's used to be backwards. I edited it since.  It's clear you're using numpy. With numpy you can just do: for cell in self.cells.flat: do_somethin(cell)  How about this: import itertools for cell in itertools.chain(*self.cells): cell.drawCell(surface posx posy) `itertools.chain.from_iterable(self.cells)`  If you need to change the values of the individual cells then ndenumerate (in numpy) is your friend. Even if you don't it probably still is! for indexvalue in ndenumerate( self.cells ): do_something( value ) self.cells[index] = new_value,python arrays multidimensional-array numpy iteration1589706,A,"Iterating over arbitrary dimension of numpy.array Is there function to get an iterator over an arbitrary dimension of a numpy array? Iterating over the first dimension is easy... In [63]: c = numpy.arange(24).reshape(234) In [64]: for r in c : ....: print r ....: [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] [[12 13 14 15] [16 17 18 19] [20 21 22 23]] But iterating over other dimensions is harder. For example the last dimension: In [73]: for r in c.swapaxes(20).swapaxes(12) : ....: print r ....: [[ 0 4 8] [12 16 20]] [[ 1 5 9] [13 17 21]] [[ 2 6 10] [14 18 22]] [[ 3 7 11] [15 19 23]] I'm making a generator to do this myself but I'm surprised there isn't a function named something like numpy.ndarray.iterdim(axis=0) to do this automatically. I'd use the following: c = numpy.arange(2 * 3 * 4) c.shape = (2 3 4) for r in numpy.rollaxis(c 2): print(r) The function rollaxis creates a new view on the array. In this case it's moving axis 2 to the front equivalent to the operation c.transpose(2 0 1). +1: Quite direct but unfortunately a tad slower than the simple `c[::i]` approach (not sure why).  There is special Ellipsis object in python which can be passed to __getitem__ or written as ... in slice operations: >>> c[... ... 0] array([[ 0 4 8] [12 16 20]]) @Denis: The ellipsis is less appropriate here than "":"": the ellipsis is intended to represent any number of "":"". Your `c[......0]` would thus be better written as `c[...0]`.  I guess there is no function. When I wrote my function I ended up taking the iteration EOL also suggested. For future readers here it is: def iterdim(a axis=0) : a = numpy.asarray(a); leading_indices = (slice(None))*axis for i in xrange(a.shape[axis]) : yield a[leading_indices+(i)]  What you propose is quite fast but the legibility can be improved with the clearer forms: for i in range(c.shape[-1]): print c[::i] or better (faster and more explicit): for i in range(c.shape[-1]): print c[...i] However the first approach above appears to be about twice as slow as the swapaxes() approach: python -m timeit -s 'import numpy; c = numpy.arange(24).reshape(234)' 'for r in c.swapaxes(20).swapaxes(12): u = r' 100000 loops best of 3: 3.69 usec per loop python -m timeit -s 'import numpy; c = numpy.arange(24).reshape(234)' 'for i in range(c.shape[2]): u = c[::i]' 100000 loops best of 3: 6.08 usec per loop python -m timeit -s 'import numpy; c = numpy.arange(24).reshape(234)' 'for r in numpy.rollaxis(c 2): u = r' 100000 loops best of 3: 6.46 usec per loop I would guess that this is because swapaxes() does not copy any data and because the handling of c[::i] might be done through general code (that handles the case where : is replaced by a more complicated slice). Note however that the more explicit second solution c[...i] is both quite legible and quite fast: python -m timeit -s 'import numpy; c = numpy.arange(24).reshape(234)' 'for i in range(c.shape[2]): u = c[...i]' 100000 loops best of 3: 4.74 usec per loop  So one can iterate over the first dimension easily as you've shown. Another way to do this for arbitrary dimension is to use numpy.rollaxis() to bring the given dimension to the first (the default behavior) and then use the returned array (which is a view so this is fast) as an iterator. In [1]: array = numpy.arange(24).reshape(234) In [2]: for array_slice in np.rollaxis(array 1): ....: print array_slice.shape ....: (2 4) (2 4) (2 4) EDIT: I'll comment that I submitted a PR to numpy to address this here: https://github.com/numpy/numpy/pull/3262. The concensus was that this wasn't enough to add to the numpy codebase. I think using np.rollaxis is the best way to do this and if you want an interator wrap it in iter().",python numpy iterate1735263,A,"Help with Python UnboundLocalError: local variable referenced before assignment I have post the similar question beforehoweverI think I may have misinterpreted my questionso may I just post my origin code hereand looking for someone can help meI am really stuck now..thanks alot. from numpy import * import math as M #initial condition All in SI unit G=6.673*10**-11 #Gravitational constant ms=1.9889*10**30 #mass of the sun me=5.9742*10**24 #mass of the earth dt=10 #time step #Creat arrays vs=array([[000]]) #1st element stand for x component of V of earth ve=array([[2977000]]) rs=array([[000]]) re=array([[01.4960*10**110]]) #First update velocity in order to start leapfrog approximation fs=-G*ms*me*((rs-re)/(M.sqrt((rs-re)[0][0]**2+(rs-re)[0][1]**2+(rs-re)[0][2]**2))**3) fe=-fs vs=vs+fs*dt/ms ve=ve+fe*dt/me n=input('please enter the number of timestep you want it evolve:') #update force def force(nmsmersreG): rsre=update_r(rsrendt) fs=-G*ms*me*((rs-re)/(M.sqrt((rs-re)[0][0]**2+(rs-re)[0][1]**2+(rs-re)[0][2]**2))**3) fe=-fs return fsfe #update velocities def update_v(nvsvemsmedtfsfe): fsfe=force(nmsmersreG) i=arange(n) vs=vs+fs[:]*i[:newaxis]*dt/ms ve=ve+fe[:]*i[:newaxis]*dt/me return vsve #update position def update_r(rsrendt): vsve=update_v(nvsvemsmedtfsfe) i=arange(n) rs=rs+vs[:]*i[:newaxis]*dt re=re+ve[:]*i[:newaxis]*dt return rsre #there is start positionvrf all have initial arrays(when n=0). #then it should calculate f(n=1) then use this to update v(n=0) #to v(n=1)then use v(n=1) update r(n=0) to r(n=1)then use r(n=1) #update f(n=1) to f(n=2)....and so on until finish n.but this code seems doesnt do thishow can I make it? Š—– when i call force python gives: please enter the number of timestep you want it evolve:4Traceback (most recent call last): File ""<pyshell#391>"" line 1 in <module> force(nmsmersreG) File ""/Users/Code.py"" line 24 in force rsre=update_r(rsrendt) File ""/Users/Code.py"" line 39 in update_r vsve=update_v(nvsvemsmedtfsfe) UnboundLocalError: local variable 'vs' referenced before assignment can anyone give me some tips?thanks...... The use of ""from numpy import *"" is a bad practice. It pollutes the global namespace. ""import numpy as np"" is better. If you have specific functions you use a lot and you are tired of writing np.sin() np.cos etc you should import those specifically (""from numpy import sin""). cheers. thanks for the tips:) Put an additional global statement containing all your globals after each def statement. Otherwise all globals are transformed into locals within your def without it. def update_v(nvsvemsmedtfsfe): global vs ve ...  where do you call force in this code? In any event the problem is in update_r. You reference vs in the first line of update_r even though vs is not defined in this function. Python is not looking at the vs defined above. Try adding global vs as the first line of update_r or adding vs to the parameter list for update_r  In the first line of update_r you have vsve=update_v(nvsvemsmedtfsfe). Look at the function that you are calling. You are calling update_v with a bunch of parameters. One of these parameters is vs. However that is the first time in that function that vs appears. The variable vs does not have a value associated with it yet. Try initializing it first and your error should disappear there is a global definition of vs. normally it would have been used. the only reason that it's not is the vs in the left hand side of the assignment. that defines an unintialized local variable with the same name. I did intend to convey that but perhaps I should have worded my answer better. Sorry for the miscommunicaton thanks for replayhoweverin my understanding(newb's)is that vs on the left hand side doesnt not really matter if it has the sam name with one of the global variables it is local.please help me with understanding this Okay so you're assigning a local variable called vs to the return value of some computation on the global variable vs. While you and I understand this distinction the Python interpreter does not. When you create the local vs (which is being assigned) then the next call to vs will be to the local vs. So what happens is that the Python interpreter is trying to perform the computation on the local vs (which has no value yet). I would fix it by doing this: temp_vsve=update_v(nvsvemsmedtfsfe) vs = temp_vs This should fix your problem. Also do what foosion says (before the vs init)  On line 39 you do vsve=update_v(nvsvemsmedtfsfe) while you are inside a function. Since you defined a global variable called vs you would expect this to work. It would have worked if you had: vs_newve_new = update_v(nvsvemsmedtfsfe) because then the interpreter knows vs in the function arguments is the global one. But since you had vs in the left hand side you created an uninitialized local variable. But dude you have a much bigger problem in your code: update_r calls update_v update_v calls force and force calls update_r - you will get a stack overflow :) thanks for replay..the thing is how can I solve this bigger problemthat is actually the reason I post thisit does really make me feel badplease help me..",python numpy1100100,A,"FFT-based 2D convolution and correlation in Python Is there a FFT-based 2D cross-correlation or convolution function built into scipy (or another popular library)? There are functions like these: scipy.signal.correlate2d - ""the direct method implemented by convolveND will be slow for large data"" scipy.ndimage.correlate - ""The array is correlated with the given kernel using exact calculation (i.e. not FFT)."" scipy.fftpack.convolve.convolve which I don't really understand but seems wrong Numarray had a correlate2d() function with a 'fft=True' switch (http://structure.usc.edu/numarray/node61.html) but I guess numarray was folded into numpy and I can't find if this function was included. note that using exact calculation (no FFT) is exactly the same as saying it is slow :) More exactly the FFT-based method will be much faster if you have a signal and a kernel of approximately the same size (if the kernel is much smaller than the input then FFT may actually be slower than the direct computation). Oh you're not talking about zero padding you're talking about matching a 5x5 image with a 2000x2000 image. Why can't the algorithm just guess whether the FFT would be more efficient and do it whichever way is faster? Ideally the FFT algorithm would automatically take care of zero-padding things to the right size for best speed. scipy has an fftconvolve function http://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.fftconvolve.html#scipy.signal.fftconvolve I wrote a cross-correlation/convolution wrapper that takes care of padding & nans and includes a simple smooth wrapper here. It's not a popular package but it also has no dependencies besides numpy (or fftw for faster ffts). I've also implemented an FFT speed testing code here in case anyone's interested. It shows - surprisingly - that numpy's fft is faster than scipy's at least on my machine. EDIT: moved code to N-dimensional version here  I've lost track of the status of this package in scipy but I know we include ndimage as part of the stsci_python release package as a convenience for our users: http://www.stsci.edu/resources/software_hardware/pyraf/stsci_python/current/download or you should be able pull it from the repository if you prefer: https://www.stsci.edu/svn/ssb/stsci_python/stsci_python/trunk/ndimage/ Turns out stsci is being removed from SciPy (which is why it doesn't work) and the stsci_python version is now the authoritative one so I'm moving this to be the accepted answer. According to SciPy docs it's not FFT-based though as I mentioned in the question. http://www.scipy.org/SciPyPackages/Ndimage Oh! I can just import that python file directly if I remove the reference to _correlate. The FFT correlation is all in Python. Now I've got it working. :) Thanks! The convolve package is also available from the stsci_python repository. It includes the correlate2d function that has the fft=True switch that you also mentioned. https://www.stsci.edu/svn/ssb/stsci_python/stsci_python/trunk/convolve/lib/Convolve.py Also the 1-D convolve/correlate is not FFT-accelerated. :(  I think you want the scipy.stsci package: http://docs.scipy.org/doc/scipy/reference/stsci.html In [30]: scipy.__version__ Out[30]: '0.7.0' In [31]: from scipy.stsci.convolve import convolve2d correlate2d I saw that too but it doesn't seem to be included in SciPy anymore? >>> import scipy.stsci.convolve Traceback (most recent call last): File """" line 1 in ImportError: No module named convolve Hi - I pasted the output from my prompt above. What's your version? Clearly something is wrong: http://pastebin.com/mdd2bc6d Good to know it exists though. Werid. From your ipython prompt I see you're using python 2.6. I have python 2.5.2. I have no idea why scipy would have a different release per version. Maybe it's easier to just re-install scipy and see if the problem persists? It works on my Windows machine with 2.6 but not on other Ubuntu machines so it must be a packaging issue with Ubuntu. https://bugs.launchpad.net/bugs/397217 you could use correlate2d from scipy.signal: it uses more or less the same implementation technique as the stsci.convolve one (no FFT). The 2.6 problem is weird - may be related to a distutils thing.  I found scipy.signal.fftconvolve as also pointed out by magnus but didn't realize at the time that it's n-dimensional. Since it's built-in and produces the right values it seems like the ideal solution. From Example of 2D Convolution: In [1]: a = asarray([[ 1 2 3] ...: [ 4 5 6] ...: [ 7 8 9]]) In [2]: b = asarray([[-1-2-1] ...: [ 0 0 0] ...: [ 1 2 1]]) In [3]: scipy.signal.fftconvolve(a b mode = 'same') Out[3]: array([[-13. -20. -17.] [-18. -24. -18.] [ 13. 20. 17.]]) Correct! The STSCI version on the other hand requires some extra work to make the boundaries correct? In [4]: stsci.convolve2d(a b fft = True) Out[4]: array([[-12. -12. -12.] [-24. -24. -24.] [-12. -12. -12.]]) (The STSCI method also requires compiling which I was unsuccessful with (I just commented out the non-python parts) has some bugs like this and modifying the inputs ([1 2] becomes [[1 2]]) etc. So I changed my accepted answer to the built-in fftconvolve() function.) Correlation of course is the same thing as convolution but with one input reversed: In [5]: a Out[5]: array([[3 0 0] [2 0 0] [1 0 0]]) In [6]: b Out[6]: array([[3 2 1] [0 0 0] [0 0 0]]) In [7]: scipy.signal.fftconvolve(a b[::-1 ::-1]) Out[7]: array([[ 0. -0. 0. 0. 0.] [ 0. -0. 0. 0. 0.] [ 3. 6. 9. 0. 0.] [ 2. 4. 6. 0. 0.] [ 1. 2. 3. 0. 0.]]) In [8]: scipy.signal.correlate2d(a b) Out[8]: array([[0 0 0 0 0] [0 0 0 0 0] [3 6 9 0 0] [2 4 6 0 0] [1 2 3 0 0]]) and the latest revision has been sped up by using power-of-two sizes internally (and then I sped it up more by using real FFT for real input and using 5-smooth lengths instead of powers of 2 :D ).  look at scipy.signal.fftconvolve signal.convolve and signal.correlate (there is a signal.correlate2d but it seems to return an shifted array not centered). I changed my accepted answer to this as explained below http://stackoverflow.com/questions/1100100/fft-based-2d-convolution-and-correlation-in-python/1768140#1768140",python image numpy signal-processing fft1734626,A,"Each looping return a result I am a beginner and got an issue really head around now. Here is the code: n=3 #time step #f v and r are arrayseg [345] #rvf all have initial array which is when n=0 def force(): r=position() f=r*2 return f def position(n): v=velocity(n) for i in range(n): #This part may wrong... r=v*i #How can I return results when i=01...5? return r def velocity(n): f=force for i in range(n): v=f*i #Same problem here..... return v Another problem is force. It is a function of position which is a function of velocity and velocity is a function of force. So it's kind of a logic loop. I can't even start. Physically it should initially start from force at time=0 then carrying on looping. But I just don't know how to do it in Python. Also how can I make the row of rv to be the results with the evolution of the time? You can use yield.  def velocity(n): f=force for i in range(n): v=f*i yield(v)  for vel in velocity(n): //do something One working example. It will print the output of function test as soon as it yields. So you do not need to wait for the next iteration of the loop.  import time def test(): for i in range(10): time.sleep(i) yield(i)  for k in test(): print k thanks for replayhowever i dont quite understand whats does yield do? +1 for using generators. A much under valued/used feature in my opinion. I have changed to yieldhowever it gives '''' when I call the function..it seems is a mistake..also how can I make these three functions run?they messed together how to start?thanks what exactly you are trying to achieve and what are you initial inputs? sorry about the confusing i made. The initial input is just n(timestep)and i want is the code gives two arraysone for r one for vwhich the rows of them are correspond to i=0123...n this code is trying to simulate gravity force between 2 stars.Thanks for helping AFAIK your code says: force depends on position position depends on velocity and velocity depends on force. So there is no start position you are stuck in a circle. Or may be try to clarify the problem statement. Or is this some sort of http://en.wikipedia.org/wiki/Recurrence_relation? there is start positionvrf all have initial arrays(when n=0).then it should calculate f(n=1) then use this to update v(n=0) to v(n=1)then use v(n=1) update r(n=0) to r(n=1)then use r(n=1) update f(n=1) to f(n=2)....and so on until finish n.  You need to use append to add to the list. def position(n): v=velocity(n) r = array() for i in range(n): #this part may wrong... r.append(v*i) #how can I return results when i=01...5? return r thanks for replay yesi am going to use appendbut it doesnt really solve the question seems..  You could use a list comprehension: def position(n): v=velocity(n) return [v*i for i in range(n)] Or since you are using numpy: v=np.array([123]) # array([1 2 3]) you can use numpy broadcasting to express the entire calculation in one blow: i=np.arange(5) # array([0 1 2 3 4]) v[:]*i[:np.newaxis] # array([[ 0 0 0] # [ 1 2 3] # [ 2 4 6] # [ 3 6 9] # [ 4 8 12]]) In the above calculation the scalar values in i (e.g. 01234) are each multiplied against the array v. The results are collected in a 2-d numpy array. Each row corresponds to a different value of i. See http://www.scipy.org/EricsBroadcastingDoc for an introduction to numpy broadcasting. @OP: To address your question regarding a ""logic loop"": Typically what you do is define a ""state"" of the system. Perhaps in your case a state would consist of a tuple (timepositionvelocity). You would then define a function which is given a state-tuple as an input and return a new state-tuple as output. Given a (timepositionvelocity) the force could be computed (mainly from the old position). From the force you then compute the new velocity. From the velocity you compute a new position. Don't write code first. In this case sit down with paper and pencil and grind out the calculation by hand with a concrete example. Do enough iterations until you see clearly the pattern of how the calculation is done. What is the order of the steps? What parts get repeated? Once you see how to do it by hand it will be much clearer how to write the python code. thanks for replaybut i do need use array unluckly.. thanks alotit helps! however still left a bit of question see my functions relationship..really messhow can i sort it out?thanks again I've added a bit of advice on how to resolve the ""logic loop"". thanks alotwhat you have said is exactly the same as my tutor said which is really important and i think i have already know clearly about the physicsjust dont know how to translate to python code to add a bit more: there is start positionvrf all have initial arrays(when n=0).then it should calculate f(n=1) then use this to update v(n=0) to v(n=1)then use v(n=1) update r(n=0) to r(n=1)then use r(n=1) update f(n=1) to f(n=2)....and so on until finish n.  It looks like you're trying to do an Euler algorithm and getting a bit mixed up in the looping. Here's how I think it should look (and I'll assume this is for a game and not homework... if it is for homework you should state that clearly so we don't give the full answer like I'm doing here.) This example is for a ball on a spring which I think you're aiming for. I'm the example my initial conditions are to thrown diagonally along the x-z axis and I've also included gravity (if you didn't intend to you vectors you can just replace all the vector quantities with scalars e.g. t x v = 0. 0. 2.; etc). from numpy import * # set the start conditions etc. n_timesteps = 100 dt m k = .1 1. 2. # timestep mass spring-const (I'll write the equations correctly so the units make sense) t x v = 0. array([0.0.0.]) array([2. 0. 2.]) # initial values gravity = array([0. 0. -9.8]) # to make the problem a little more interesting result = zeros((4 n_timesteps)) # run the simulation looping through the timesteps for n in range(n_timesteps): # do the calculation f = -k*x + gravity a = f/m v += a*dt x += v*dt # store the results t += dt # just for easy record keeping result[0n] = t result[1:4 n] = x Note that for loop is looping over the timesteps (and the all looping over the vectors is handles by numpy broadcasting e.g. f = -k*x+gravity what could be easier?). Also note that the force is set first and then we work our way down the chain of integrating the derivatives then go back to the top and start at the force again. (You're right that this is a bit asymmetric and really we should update them all at the same time or something like that and this is a deficiency of the Euler method but it works well enough for small timesteps.) Here's what the plots look like... the ball oscillates as expected Edit: To clarify your question: Basically your code's issue is not a question of ""starting the functions"" as you imply; instead your code is approaching the problem in the wrong way so you need to fix the approach. It looks like you're trying to iterate your timesteps within each function. This is incorrect! Instead you need to do an enveloping iteration through the timesteps and for each timestep update the current state of each variable used in the calculation at that timestep. You can write this update as a separate function or for example you can do it inline like I did. But it makes no sense to iterate the timesteps within each variable calculation function. Instead for your example to make sense force velocity and other functions should have as inputs things at the present timestep and return an update to the state of that variable to be used in the next timestep. See how my example does this: it just cycles through the timesteps and within each timestep cycle it sequentially updates all the variables basing each updated variable on the variables that were updated just before it in this current timestep. Thanks for replayhoweverthe real problem in my question is how can I start these functions(I got initial conditions)thanks",python arrays numpy752482,A,"Can I compile numpy & scipy as eggs for free on Windows32? I've been asked to provide Numpy & Scipy as python egg files. Unfortunately Numpy and Scipy do not make official releases of their product in .egg form for a Win32 platform - that means if I want eggs then I have to compile them myself. At the moment my employer provides Visual Studio.Net 2003 which will compile no version of Numpy later than 1.1.1 - every version released subsequently cannot be compiled with VS2003. What I'd really like is some other compiler I can use perhaps for free but at a push as a free time-limited trial... I can use that to compile the eggs. Is anybody aware of another compiler that I can get and use without paying anything and will definitely compile Numpy on Windows? Please only suggest something if you know for a fact that that it will compile Numpy - no speculation! Thanks Notes: I work for an organization which is very sensitive about legal matters so everything I do has to be totally legit. I've got to do everything according to licensed terms and will be audited. My environment: Windows 32 Standard C Python 2.4.4 Try compiling the whole Python stack with MinGW32. This is a GCC-Win32 development environment that can be used to build Python and a wide variety of software. You will probably have to compile the whole Python distribution with it. Here is a guide to compiling Python with MinGW. Note that you will probably have to provide a python distribution that is compiled with MinGW32 as well. If recompiling the Python distro is not a goer I believe that Python 2.4 is compiled using VS2003. You are probably stuck with back-porting Scipy and Numpy to VS2003 or paying a consultant to do it. I would dig out the relevant mailing lists or contact the maintainers and get some view of the effort that would be required to do it. Another alternative would be to upgrade the version of Python to a more recent one but you will probably have to regression test your application and upgrade the version of Visual Studio to 2005 or 2008. No good - we use a stock CPython from python.org. We cannot use a special python. :-( There is absolutely no need to build your own python to build numpy (or any package for that matter) with mingw.  If you just need the compiler it is part of the .NET framework. For instance you can find the 3.5 framework (Which is used be visual studio 2008) in: ""C:\Windows\Microsoft.NET\Framework\v3.5"" You cannot reliably compile numpy (or any python extension) for python 2.4 with VS 2008. You need to use the same compiler as the one python itself was built with which is VS 2003 in python 2.4 case  You could try GCC for Windows. GCC is the compiler most often used for compiling Numpy/Scipy (or anything else really) on Linux so it seems reasonable that it should work on Windows too. (Never tried it myself though) And of course it's distributed under the GPL so there shouldn't be any legal barriers. The GCC coming with mingw is support by numpy. It is actually the compiler I use to build the official windows installers.",python windows numpy scipy1972877,A,Matlab's griddata3 for numpy? I realize that there is a griddata for numpy via matplotlib but is there a griddata3 (same has griddata but for higher dimensions). In other words I have (xyzd(xyz)) where (xyz) form an irregular grid and d(xyz) is a scalar function of three variables. I need to generate d(xiyizi) for a new set of (xiyizi) points using some kind of interpolation that can handle the non-uniformity of the original (xyz) data. Ultimately the (xiyizid(xiyizi)) data will have to be rendered as a surface somehow but that's a problem for later. I also do not have an analytical form for the d(.) function; I just have data for it. Any help appreciated. Not sure how you intend to render a surface of a scalar function of 3 variables except perhaps using cutplanes or something similar. Mayavi (really VTK which powers Mayavi) has support for efficient Delaunay triangulation via enthought.mayavi.mlab.pipeline.delaunay3d which is the core of the algorithm used by griddata3. See the 2D example code they have posted just add one dimension (and use delaunay3d instead). I don't know of a way to explicitly get the interpolated values used to render the surface but there might be a way to sample it through Mayavi you could dig through the documentation or ask on one of the Enthought mailing lists. Alternatively one of the C functions in the NCAR natgrid library may be useful i.e. dsgrid3d. There is a partial wrapper implemented as a matplotlib toolkit. thanks! I will look into these.  I am not familiar with griddata3 but you might want to look into meshgrid and this related post.  Scipy 0.9 (at the moment a first beta is out) has a new griddata function that can handle N-dimensional data. yay! great work!,python numpy analysis interpolation scientific-computing603114,A,Fonts for Carbon OpenGL app on OS X I'm trying to add text rendering to a Carbon OpenGL app I'm developing for OS X. Since the aglUseFont is now deprecated I'm looking for another way to add text as well as be able to query the glyph properties (i.e. width height spacing etc) So far I've investigated CoreText and ATSUI but both without much luck. Please help me!! Thanks! You could take a look at the FreeType project: it's an open source portable font rendering engine that supports OpenType TrueType Postscript Type 1 and other formats. There are several open source integrations of FreeType with OpenGL; see for example OGLFT. Or you could just roll your own: it's not hard to make FreeType generate bitmaps in some suitable pixel format and then pass these bitmaps to glTexImage2D.  In the end I just went with good old glBitmap for my fonts. Found an apple dev sample that created rendered each character and got its pertinent info (width height offset etc.) However if I get the time to do some more work on it later I plan on using the FreeType project as was suggested above. Thanks!,c++ osx opengl fonts carbon340185,A,"using GDAL/OGR api to read vector data (shapefile)--How? I am working on an application that involves some gis stuff. There would be some .shp files to be read and plotted onto an opengl screen. The current opengl screen is using the orthographic projection as set from glOrtho() and is already displaying a map using coordinates from a simple text file.. Now the map to be plotted is to be read from a shapefile. I have the following doubts: How to use the WGS84 projection of the .shp file(as read from the .prj file of the shapefileWKT format) into my existing glOrtho projection..is there any conversion that needs to be done? and how is it different from what the glOrtho() sets up?basically how to use this information? My application needs to be setup in such a way that i can know the exact lat/long of a point on the map.for eg. if i am hovering on X cityits correct lat/long could be fetched.I know that this can be done by using opensource utils/apis like GDAL/OGR but i am messed up as the documentation of these apis are not getting into my head. I tried to find some sample c++ progs but couldnt find one. I have already written my own logic to read the coordinates from a shapefile containing either points/polyline/polygon(using C-shapelib) and plotted over my opengl screen.I found a OGR sample code in doc to read a POINTS shapefile but none for POLYGON shapefile.And the problem is that this application has to be so dynamic that upon loading the shapefileit should correctly setup the projection of the opengl screen depending upon the projection of the .shp file being read..eg WGS84LCCEVEREST MODIFIED...etc. how to achieve this from OGR api? Kindly give your inputs on this problem.. I am really keen to make this work but im not getting the right start.. 1.Shapefile rendering is quite straight forward in OpenGL.You may require ""shapelib""a free shapefile parsing library in C(google for it).Use GL_POINTS for point shapefile GL_LINES for line shapefile and GL_LINE_LOOP for polygon shapefile.Set your bounding box coods to the Ortho. 2.What u read from .prj file is projection info.WGS84 gives u lat/long coods(Spherical). But ur display system is 2D(Rectangular).Sou need to convert 3D Spherical coods to 2D Rectangular coods(This is the meaning of Projection).Projection types are numerousdepending on the area of interest on the globe(remeber projection distorts area/shape/size of features).Projection types range from PolyconicModified EverestNADUTM etc. 3.If u simly need WGS84 then read bounding box coods of ur sh file and assign them to glOrtho.If u have any projection(eg:-UTM) then u convert ur bounding box coods into Projection coods and then assign the newly projected coods to glOrtho.For converting lat/long into any Projectionu may require projection libraries like ""Projlib"" or ""GeotransEngine"" and etc. For further clarifications u may contact me on dgplinux@ y a h o o . c o m  Please read the OGR API Tutorial where you can learn how to read vector data from sources like Shapefile. Next check the OGR Projections Tutorial where you can learn about how to use information about projection and spatial reference system read from OGR sources.  GDAL/OGR has everything you need to load a vector file then convert any coordinates. I understand your frustration with GDAL as the documentation is not the greatest. If you want a good intro to using the API look at gdalinfo.c and ogrinfo.cpp in the GDAL subversion tree. Source can be seen at https://svn.osgeo.org/gdal/trunk/gdal. If that does not help I have two basic examples that I use to parse vector info and do coordinate conversion. They are really bad but they may help get the point. Vector Loading Coordinate Conversion Finally if you are not familiar with GIS formats I would consider reading the ArcGIS introduction here under Guide Books/Map Projections. I can compete with experts despite no cartography training due to these guides. Another good source is Wikipedia. When in doubt just pick a UTM grid you want to stick with and use UTM as your coordinate system. It uses X (Easting) Y(Northing) and Z(Altitude). The only key is picking a single UTM Grid and making sure all coordinates use that as a reference. UTM is easy to test code with as there are a lot of guides online. You also can find conversion code using OGR/GDAL or other resources. Other projected coordinate systems are worthwhile and may be better but I would look at that to start with. Finally if all else fails take a look at the NGA GeoTrans. That is a great testing tool.",c++ linux opengl gdal1009150,A,"C++/OpenGL - Rotating a rectangle For my project i needed to rotate a rectangle. I thought that would be easy but i'm getting an unpredictable behavior when running it.. Here is the code:  glPushMatrix(); glRotatef(30.0f 0.0f 0.0f 1.0f); glTranslatef(vec_vehicle_position_.x vec_vehicle_position_.y 0); glEnable(GL_TEXTURE_2D); glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); glBegin(GL_QUADS); glTexCoord2f(0.0f 0.0f); glVertex2f(0 0); glTexCoord2f(1.0f 0.0f); glVertex2f(width_sprite_ 0); glTexCoord2f(1.0f 1.0f); glVertex2f(width_sprite_ height_sprite_); glTexCoord2f(0.0f 1.0f); glVertex2f(0 height_sprite_); glEnd(); glDisable(GL_BLEND); glDisable(GL_TEXTURE_2D); glPopMatrix(); The problem with that is that my rectangle is making a translation somewhere in the window while rotating. In other words the rectangle doesn't keep the position : vec_vehicle_position_.x and vec_vehicle_position_.y. What's the problem ? Thanks To elaborate on the previous answers. Transformations in OpenGL are performed via matrix multiplication. In your example you have: M_r_ - the rotation transform M_t_ - the translation transform v - a vertex and you had applied them in the order: M_r_ * M_t_ * v Using parentheses to clarify: ( M_r_ * ( M_t_ * v ) ) We see that the vertex is transformed by the closer matrix first which is in this case the translation. It can be a bit counter intuitive because this requires you to specify the transformations in the order opposite of that which you want them applied in. But if you think of how the transforms are placed on the matrix stack it should hopefully make a bit more sense (the stack is pre-multiplied together). Hence why in order to get your desired result you needed to specify the transforms in the opposite order. Indeed :) Thanks for the update !  Make sure the rotation is applied before the translation.  Inertiatic provided a very good response. From a code perspective your transformations will happen in the reverse order they appear. In other words transforms closer to the actual drawing code will be applied first. For example: glRotate(); glTranslate(); glScale(); drawMyThing(); Will first scale your thing then translate it then rotate it. You effectively need to ""read your code backwards"" to figure out which transforms are being applied in which order. Also keep in mind what the state of these transforms is when you push and pop the model-view stack.  You need to flip the order of your transformations: glRotatef(30.0f 0.0f 0.0f 1.0f); glTranslatef(vec_vehicle_position_.x vec_vehicle_position_.y 0); becomes glTranslatef(vec_vehicle_position_.x vec_vehicle_position_.y 0); glRotatef(30.0f 0.0f 0.0f 1.0f); Thanks a lot it works !",c++ opengl rotation1272120,A,What are the error messages for breaking the GLSL shader instruction limits? We're a small dev team working with some GLSL that may be too large for older graphics cards to compile. We want to display a sensible error message to the user (rather than just dump the info log or output a generic 'this shader didn't work' type of message) when this happens based on the type of error. The question is ATI and nVidia have different conventions for these error messages and the only way I've found to decide what type of error the shader had is to parse the error string generated by glGetShaderInfoLog. Given that is there a listing somewhere or does anyone know what the error output for both ATI and nVidia cards looks like? Or is there a better way to detect when the instruction limit has been exceeded? Even if you know what the error messages look like now nVidia and ATI are under no obligation to keep them the same in the next version(s) of their drivers. They basically can't be relied on for anything except debugging purposes. I would look and see if the vendor extensions might be able to provide you with more specific diagnostic information. http://petewarden.com/notes/archives/2005/06/fragment_progra_3.html did the trick.,c++ opengl glsl1218876,A,"Problem with using OpenGL's VBO I just tried to render the first redbook example ( the white Quad ) by using VBOs. It works fine with immediate mode and vertex arrays. But when using VBOs the screen stays black. I think i must have missed something important. init: unsigned int bufIds[2]; glGenBuffers( 2 bufIds ); GLfloat vertices[] = { 0.25 0.25 0.0 0.75 0.25 0.0 0.75 0.75 0.0 0.25 0.75 0.0 }; glBindBuffer( GL_ARRAY_BUFFER bufIds[0] ); glBufferData( GL_ARRAY_BUFFER 12 vertices GL_STATIC_DRAW ); glBindBuffer( GL_ARRAY_BUFFER 0 ); glClearColor( 0 0 0 1 ); glColor3f( 1 1 1 ); glOrtho( 0.0 1.0 0.0 1.0 -1.0 1.0 ); renderloop for VBO (not working): glClear( GL_COLOR_BUFFER_BIT ); glEnableClientState( GL_VERTEX_ARRAY ); glBindBuffer( GL_ARRAY_BUFFER bufIds[0] ); glVertexPointer( 3 GL_FLOAT 0 0 ); glDrawArrays( GL_QUADS 0 12 ); glBindBuffer( GL_ARRAY_BUFFER 0 ); glDisableClientState( GL_VERTEX_ARRAY ); renderloop for vertex arrays (working): glClear( GL_COLOR_BUFFER_BIT ); glEnableClientState( GL_VERTEX_ARRAY ); glBindBuffer( GL_ARRAY_BUFFER 0 ); glVertexPointer( 3 GL_FLOAT 0 vertices ); glDrawArrays( GL_QUADS 0 12 ); glDisableClientState( GL_VERTEX_ARRAY ); argh i just figured it out by trying to read back the contents of the buffer: i need to allocate the buffer with 12 * sizeof( GLfloat ) instead of only 12 glBufferData( GL_ARRAY_BUFFER 12 * sizeof( GLfloat ) vertices GL_STATIC_DRAW ); my read back code GLfloat vertices2[12]; glBindBuffer( GL_ARRAY_BUFFER bufIds[0] ); glGetBufferSubData ( GL_ARRAY_BUFFER 0 12 * sizeof( GLfloat ) vertices2 ); glBindBuffer( GL_ARRAY_BUFFER 0 ); for ( int i = 0; i < 4; i ++ ) { LOG_DEBUG << ""point "" << i << "": "" << vertices2[ i * 3 + 0 ] << "" / "" << vertices2[ i * 3 + 1 ] << "" / "" << vertices2[ i * 3 + 2 ]; } +1 Awesome! I had exactly the same problem thank you so much!",c++ opengl vbo664698,A,"How to I draw pixels as a texture to a polygon in OpenGL? In C++ OpenGL I want to draw each pixel manually (as a texture I assume) on to a simple square primitive or indeed 2 polygons forming a square. I have no idea where to start or what phrases to look for. Am I looking for texture mapping or creating textures? Most examples are to load from a file but I dont want to do that. I've tried reading my OpenGL Programming Guide book but its just a maze as I'm quite new to OpenGL. Please help. In other words you want to draw a texture without perspective? After you see the right tutorials check my post over here -> http://stackoverflow.com/questions/503816/linux-fastest-way-to-draw/504440#504440 The geometry is to be rotated transformed etc. in a 3D sense. I'm not sure what you mean ""draw without perspective""... Thanks to Reed Copsey for pointing me towards glTexImage2D. Turns out this is very simple; just pass an array of GLubyte to the glTexImage2D function (as well as all the functions needed to bind the texture etc). Haven't tried this exact snippet of code but it should work fine. The array elements represent a serial version of the rows columns and channels. int pixelIndex = 0; GLubyte pixels[400]; for (int x = 0; x < 10; x++) { for (int y = 0; y < 10; x++) { for (int channel = 0; channel < 4; channel++) { // 0 = black 255 = white pixels[pixelIndex++] = 255; } } } glTexImage2D( GL_TEXTURE_2D 0 GL_RGBA SIZE SIZE 0 GL_RGBA GL_UNSIGNED_BYTE pixels); I've read in the OpenGL book you can use a 2D array for monochrome images so I assume you could use a 3D array also.  If the square you are drawing to is 2 dimensional and not rotated you may be looking for glDrawPixels. It allows you to draw a rectangular region of pixels directly to the buffer without using any polygons.  If you are new then I would recommend starting from tutorial one on from NeHe.  Take a close look at glTexImage2D. This is the call that loads the image in OpenGL for a 2D Texture. glTexImage2D actually takes a raw pointer to the pixel data in the image. You can allocate memory yourself and set the image data directly (however you want) then call this function to pass the image to OpenGL. Once you've created the texture you can bind it to the state so that your triangles use that texture. There is nothing in OpenGL that directly requires images used as textures to be loaded from files. A good resource for textures can be found in this GameDev article.  What you are looking for is generally called ""render to texture."" http://developer.nvidia.com/object/gdc_oglrtt.html That tutorial is pretty old. I'd guess that some of those extensions aren't actually extensions in newer versions of OGL. Sorry I can't be more help. I don't work directly with graphics API's much any more and if I did I'd use D3D if I could (to avoid the extension soup and for other reasons I won't bore you with here.)  Do note that while glTexImage2D() takes a pointer to the pixels to load it does not care about any changes to that data after the call. That is the data is really loaded from the memory area you specify and OpenGL creates a copy of its own. This means that if the data changes you will need to either re-do the glTexImage2D() call or use something like glTexSubImage2D() to do a partial update. I would recommend testing and profiling to see if sub-texture updating is quick not sure how actual drivers optimize for that case.",c++ opengl textures1122203,A,"How do I get all the shader constants (uniforms) from a ID3DXEffect? I'm creating an effect using hr = D3DXCreateEffectFromFile( g_D3D_Device shaderPath.c_str() macros NULL 0 NULL &pEffect &pBufferErrors ); I would like to get all the uniforms that this shader is using. In OpenGL I used glGetActiveUniform and glGetUniformLocation to get constant's size type name etc. Is there a D3DX9 equivalent function? Thanks! D3DXHANDLE handle = m_pEffect->GetParameterByName( NULL ""Uniform Name"" ); if ( handle != NULL ) { D3DXPARAMETER_DESC desc; if ( SUCCEEDED( m_pEffect->GetParameterDesc( handle &desc ) ) ) { // You now have pretty much all the details about the parameter there are in ""desc"". } } You can also iterate through each parameter by doing the following: UINT index = 0; while( 1 ) { D3DXHANDLE handle = m_pEffect->GetParameter( NULL index ); if ( handle == NULL ) break; // Get parameter desc as above. index++; }",c++ opengl graphics 3d directx1824656,A,Hiding the Cursor I have a windows program with directx/opengl renderers and a custom mouse rendered as a quad. The program currently runs windowed. The problem is the standard windows mouse is overlaid ontop of my custom cursor. How do I hide it when its inside my window? Try ShowCursor(FALSE); when you init your window.,c++ windows opengl directx mouse1919251,A,Display image in opengl I am fairly new to openGL. I have a 3d game that I have running and it seems to go fairly well. What I would like to do is display an image straight onto the screen and I am not sure the easiest way to do that. My only idea is to draw a rectangle right in front of the screen and use the image as the texture. It seems like there should be an easier way. This is for menu screens and things so if there is a better way to do that as well please let me know. I would recommend setting up OpenGL for 2D rendering via gluOrtho2d(); then load the image into a texture and as you said draw it to the screen by creating a polygon and binding the texture to it. A good example can be found here.  You've got the basic idea. The other obvious alternative is to use glDrawPixels() but I think you'll find the texture method has much better performance. If you're feeling frisky you might also take a look at Pixel Buffer Objects. Good luck!,c++ opengl181731,A,Texture Sampling in Open GL i need to get the color at a particular coordinate from a texture. There are 2 ways i can do this by getting and looking at the raw png data or by sampling my generated opengl texture. Is it possible to sample an opengl texture to get the color (RGBA) at a given UV or XY coord? If so how? Off the top of my head your options are Fetch the entire texture using glGetTexImage() and check the texel you're interested in. Draw the texel you're interested in (eg. by rendering a GL_POINTS primitive) then grab the pixel where you rendered it from the framebuffer by using glReadPixels. Keep a copy of the texture image handy and leave OpenGL out of it. Options 1 and 2 are horribly inefficient (although you could speed 2 up somewhat by using pixel-buffer-objects and doing the copy asynchronously). So my favourite by FAR is option 3. Edit: If you have the GL_APPLE_client_storage extension (ie. you're on a Mac or iPhone) then that's option 4 which is the winner by a long way. Outside of option 2 you need a method for sampling based on the texcoords though which is the hard part -- this is described in my answer. My understanding was that the poster was asking how to implement the 'getTexel' part of your example not how to replicate the filtering (which depends on what kind of filtering he wants to replicate anyway). I was sort of asking about the getTexel part but he's right that 1 and 2 are too slow esp considering i'm working on a mobile device. Thanks :) Mobile device? Would that be an iPhone by any chance? See updated answer. indeed it would Mike F thanks for the tip... altho in this case it does turn out that the data can be pre processed as raw image data before the creation of the openGL texture.  The most efficient way I've found to do it is to access the texture data (you should have our PNG decoded to make into a texture anyway) and interpolate between the texels yourself. Assuming your texcoords are [01] multiply texwidth*u and texheight*v and then use that to find the position on the texture. If they're whole numbers just use the pixel directly otherwise use the int parts to find the bordering pixels and interpolate between them based on the fractional parts. Here's some HLSL-like psuedocode for it. Should be fairly clear: float3 sample(float2 coord texture tex) { float x = tex.w * coord.x; // Get X coord in texture int ix = (int) x; // Get X coord as whole number float y = tex.h * coord.y; int iy = (int) y; float3 x1 = getTexel(ix iy); // Get top-left pixel float3 x2 = getTexel(ix+1 iy); // Get top-right pixel float3 y1 = getTexel(ix iy+1); // Get bottom-left pixel float3 y2 = getTexel(ix+1 iy+1); // Get bottom-right pixel float3 top = interpolate(x1 x2 frac(x)); // Interpolate between top two pixels based on the fractional part of the X coord float3 bottom = interpolate(y1 y2 frac(x)); // Interpolate between bottom two pixels return interpolate(top bottom frac(y)); // Interpolate between top and bottom based on fractional Y coord }  As others have suggested reading back a texture from VRAM is horribly inefficient and should be avoided like the plague if you're even remotely interested in performance. Two workable solutions as far as I know: Keep a copy of the pixeldata handy (wastes memory though) Do it using a shader,c++ opengl680125,A,Can I use a grayscale image with the OpenGL glTexImage2D function? I have a texture which has only 1 channel as it's a grayscale image. When I pass the pixels in to glTexImage2D it comes out red (obviously because channel 1 is red; RGB). glTexImage2D( GL_TEXTURE_2D 0 GL_RGBA dicomImage->GetColumns() dicomImage->GetRows() 0 GL_RGBA GL_UNSIGNED_BYTE pixelArrayPtr); Do I change GL_RGBA? If so what to? It appears that I should use GL_LUMINANCE instead of GL_RGBA for the 3rd argument. Edit (in reply to comments): When I set the 7th argument to GL_LUMINANCE (as well as the 3rd) the picture goes completely distorted. With the DICOM pixel format it appears that the 7th argument must be GL_RGBA for some reason. The strange behavior is because I'm using the DICOM standard. The particular DICOM reader I am using outputs integer pixel values (as pixel values may exceed the normal maximum of 255). For some strange reason the combination of telling OpenGL that I am using an RGBA format but passing in integer values rendered a perfect image. Because I was truncating the DICOM > 255 pixel values anyway it seemed logical to copy the values in to a GLbyte array. However after doing so a SIGSEGV (segmentation fault) occurred when calling glTexImage2D. Changing the 7th parameter to GL_LUMINANCE (as is normally required) returned the functionality to normal. Weird eh? So a note to all developers using the DICOM image format: You need to convert the integer array to a char array before passing it to glTexImage2D or just set the 7th argument to GL_RGBA (the later is probably not recommended). My case is unusual see my edit for explanation. It is argument #7 that counts here! Hmm when change #7 it goes red... but #3 has the desired effect. Can you explain this please? As ypnos says arguments 7 and 8 are what you're interested in. They tell OpenGL the format of the data which the pointer points to. The earlier arguments indicate the type of texture as I recall. Nick argument #3 is for internal storage #7 is for input format. GL will convert from #7 to #3. The effect you are getting can have several reasons I can't tell from here. In almost every case however you want both be the same anyway.  Change it to GL_LUMINANCE. See http://www.opengl.org/documentation/specs/man_pages/hardcopy/GL/html/gl/teximage2d.html It seems your link is broken. (It redirects to the home page). [glTextImage2D](http://www.opengl.org/sdk/docs/man/xhtml/glTexImage2D.xml) works but it doesn't mention GL_LUMINANCE anywhere. It seems they obsoleted it... Deprecated in OpenGL 4.0. But OpenGL 4.0 does not have a fixed function pipeline you need to bind your own shaders that's why there is no use in LUMINANCE ALPHA etc. any more. You need to use GL_RED and process the single channel accordingly.,c++ opengl textures1259461,A,"How to fix weird camera rotation while moving camera with sdl opengl in c++ I have a camera object that I have put together from reading on the net that handles moving forward and backward strafe left and right and even look around with the mouse. But when I move in any direction plus try to look around it jumps all over the place but when I don't move and look around its fine. I'm hoping someone can help me work out why I can move and look around at the same time? main.h #include ""SDL/SDL.h"" #include ""SDL/SDL_opengl.h"" #include <cmath> #define CAMERASPEED 0.03f // The Camera Speed struct tVector3 // Extended 3D Vector Struct { tVector3() {} // Struct Constructor tVector3 (float new_x float new_y float new_z) // Init Constructor { x = new_x; y = new_y; z = new_z; } // overload + operator tVector3 operator+(tVector3 vVector) {return tVector3(vVector.x+x vVector.y+y vVector.z+z);} // overload - operator tVector3 operator-(tVector3 vVector) {return tVector3(x-vVector.x y-vVector.y z-vVector.z);} // overload * operator tVector3 operator*(float number) {return tVector3(x*number y*number z*number);} // overload / operator tVector3 operator/(float number) {return tVector3(x/number y/number z/number);} float x y z; // 3D vector coordinates }; class CCamera { public: tVector3 mPos; tVector3 mView; tVector3 mUp; void Strafe_Camera(float speed); void Move_Camera(float speed); void Rotate_View(float speed); void Position_Camera(float pos_x float pos_yfloat pos_z float view_x float view_y float view_z float up_x float up_y float up_z); }; void Draw_Grid(); camera.cpp #include ""main.h"" void CCamera::Position_Camera(float pos_x float pos_y float pos_z float view_x float view_y float view_z float up_x float up_y float up_z) { mPos = tVector3(pos_x pos_y pos_z); mView = tVector3(view_x view_y view_z); mUp = tVector3(up_x up_y up_z); } void CCamera::Move_Camera(float speed) { tVector3 vVector = mView - mPos; mPos.x = mPos.x + vVector.x * speed; mPos.z = mPos.z + vVector.z * speed; mView.x = mView.x + vVector.x * speed; mView.z = mView.z + vVector.z * speed; } void CCamera::Strafe_Camera(float speed) { tVector3 vVector = mView - mPos; tVector3 vOrthoVector; vOrthoVector.x = -vVector.z; vOrthoVector.z = vVector.x; mPos.x = mPos.x + vOrthoVector.x * speed; mPos.z = mPos.z + vOrthoVector.z * speed; mView.x = mView.x + vOrthoVector.x * speed; mView.z = mView.z + vOrthoVector.z * speed; } void CCamera::Rotate_View(float speed) { tVector3 vVector = mView - mPos; tVector3 vOrthoVector; vOrthoVector.x = -vVector.z; vOrthoVector.z = vVector.x; mView.z = (float)(mPos.z + sin(speed)*vVector.x + cos(speed)*vVector.z); mView.x = (float)(mPos.x + cos(speed)*vVector.x - sin(speed)*vVector.z); } and the mousemotion code void processEvents() { int mid_x = screen_width >> 1; int mid_y = screen_height >> 1; int mpx = event.motion.x; int mpy = event.motion.y; float angle_y = 0.0f; float angle_z = 0.0f; while(SDL_PollEvent(&event)) { switch(event.type) { case SDL_MOUSEMOTION: if( (mpx == mid_x) && (mpy == mid_y) ) return; // Get the direction from the mouse cursor set a resonable maneuvering speed angle_y = (float)( (mid_x - mpx) ) / 1000; //1000 angle_z = (float)( (mid_y - mpy) ) / 1000; //1000 // The higher the value is the faster the camera looks around. objCamera.mView.y += angle_z * 2; // limit the rotation around the x-axis if((objCamera.mView.y - objCamera.mPos.y) > 8) objCamera.mView.y = objCamera.mPos.y + 8; if((objCamera.mView.y - objCamera.mPos.y) <-8) objCamera.mView.y = objCamera.mPos.y - 8; objCamera.Rotate_View(-angle_y); SDL_WarpMouse(mid_x mid_y); break; case SDL_KEYUP: objKeyb.handleKeyboardEvent(eventtrue); break; case SDL_KEYDOWN: objKeyb.handleKeyboardEvent(eventfalse); break; case SDL_QUIT: quit = true; break; case SDL_VIDEORESIZE: screen = SDL_SetVideoMode( event.resize.w event.resize.h screen_bpp SDL_OPENGL | SDL_HWSURFACE | SDL_RESIZABLE | SDL_GL_DOUBLEBUFFER | SDL_HWPALETTE ); screen_width = event.resize.w; screen_height = event.resize.h; init_opengl(); std::cout << ""Resized to width: "" << event.resize.w << "" height: "" << event.resize.h << std::endl; break; default: break; } } } does this happen only when you are looking and moving at the same time? yes individually they work together it goes weird. I agree with Goz. You need to use homegenous 4x4 matrices if you want to represent affine transformations such as rotate + translate Assuming row major representation then if there is no scaling or shearing your 4x4 matrix represents the following: Rows 0 to 2 : The three basis vectors of your local co-ordinate system ( i.e xyz ) Row 3 : the current translation from the origin So to move along your local x vector as Goz says because you can assume it's a unit vector if there is no scale/shear you just multiply it by the move step ( +ve or -ve ) then add the resultant vector onto Row 4 in the matrix So taking a simple example of starting at the origin with your local frame set to world frame then your matrix would look something like this 1 0 0 0 <--- x unit vector 0 1 0 0 <--- y unit vector 0 0 1 0 <--- z unit vector 0 0 0 1 <--- translation vector In terms of a way most game cameras work then the axes map like this: x axis <=> Camera Pan Left/Right y axis <=> Camera Pan Up/Down z axis <=> Camera Zoom In/Out So if I rotate my entire frame of reference to say look at a new point LookAt then as Goz puts in his BaseCamera overloaded constructor code you then construct a new local co-ordinate system and set this into your matrix ( all mCameraMat.Set( vLat vUp vDir vPos ) does typically is set those four rows of the matrix i.e VLat would be row 0 vUp row 1 vDir row 2 and vPos row 3 ) Then to zoom in/out would just become row 3 = row 2 * stepval Again as Goz rightly points out you then need to transform this back into world-space and this is done by multiplying by the inverse of the view matrix Do bear in mind that the above code is for a row major matrix. You will need to transpose the matrix for a column major matrix :) Yep absolutely true  I'm not entirely sure what you are doing above. Personally I would just allow a simple 4x4 matrix. Any implementation will do. To rotate you simply need to rotate using the change of mouse x and y as euler inputs for rotation around the y and x axes. There is lots of code available all over the internet that will do this for you. Some of those matrix libraries won't provide you with a ""MoveForward()"" function. If this is the case its ok moving forward is pretty easy. The third column (or row if you are using row major matrices) is your forward vector. Extract it. Normalise it (It really should be normalised anyway so this step may not be needed). Multiply it by how much you wish to move forward and then add it to the position (the 4th column/row). Now here is the odd part. A view matrix is a special type of matrix. The matrix above defines the view space. If you multiply your current model matrix by this matrix you will not get the answer you expect. Because you wish to transform it such that the camera is at the origin. As such you need to effectively undo the camera transformation to re-orient things to the view defined above. To do this you multiply your model matrix by the inverse of the view matrix. You now have an object defined in the correct view space. This is my very simple camera class. It does not handle the functionality you describe but hopefully will give you a few ideas on how to set up the class (Be warned I use row major ie DirectX style matrices). BaseCamera.h: #ifndef BASE_CAMERA_H_ #define BASE_CAMERA_H_ /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ #include ""Maths/Vector4.h"" #include ""Maths/Matrix4x4.h"" /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ class BaseCamera { protected: bool mDirty; MathsLib::Matrix4x4 mCameraMat; MathsLib::Matrix4x4 mViewMat; public: BaseCamera(); BaseCamera( const BaseCamera& camera ); BaseCamera( const MathsLib::Vector4& vPos const MathsLib::Vector4& vLookAt ); BaseCamera( const MathsLib::Matrix4x4& matCamera ); bool IsDirty() const; void SetDirty(); MathsLib::Matrix4x4& GetOrientationMatrix(); const MathsLib::Matrix4x4& GetOrientationMatrix() const; MathsLib::Matrix4x4& GetViewMatrix(); }; /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ inline MathsLib::Matrix4x4& BaseCamera::GetOrientationMatrix() { return mCameraMat; } /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ inline const MathsLib::Matrix4x4& BaseCamera::GetOrientationMatrix() const { return mCameraMat; } /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ inline bool BaseCamera::IsDirty() const { return mDirty; } /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ inline void BaseCamera::SetDirty() { mDirty = true; } /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ #endif BaseCamera.cpp: #include ""Render/stdafx.h"" #include ""BaseCamera.h"" /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ BaseCamera::BaseCamera() : mDirty( true ) { } /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ BaseCamera::BaseCamera( const BaseCamera& camera ) : mDirty( camera.mDirty ) mCameraMat( camera.mCameraMat ) mViewMat( camera.mViewMat ) { } /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ BaseCamera::BaseCamera( const MathsLib::Vector4& vPos const MathsLib::Vector4& vLookAt ) : mDirty( true ) { MathsLib::Vector4 vDir = (vLookAt - vPos).Normalise(); MathsLib::Vector4 vLat = MathsLib::CrossProduct( MathsLib::Vector4( 0.0f 1.0f 0.0f ) vDir ).Normalise(); MathsLib::Vector4 vUp = MathsLib::CrossProduct( vDir vLat );//.Normalise(); mCameraMat.Set( vLat vUp vDir vPos ); } /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ BaseCamera::BaseCamera( const MathsLib::Matrix4x4& matCamera ) : mDirty( true ) mCameraMat( matCamera ) { } /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/ MathsLib::Matrix4x4& BaseCamera::GetViewMatrix() { if ( IsDirty() ) { mViewMat = mCameraMat.Inverse(); mDirty = false; } return mViewMat; } /*+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+*/",c++ linux opengl sdl1533380,A,c++ opengl converting model coordinates to world coordinates for collision detection (This is all in ortho mode origin is in the top left corner x is positive to the right y is positive down the y axis) I have a rectangle in world space which can have a rotation m_rotation (in degrees). I can work with the rectangle fine it rotates scales everything you could want it to do. The part that I am getting really confused on is calculating the rectangles world coordinates from its local coordinates. I've been trying to use the formula: x' = x*cos(t) - y*sin(t) y' = x*sin(t) + y*cos(t) where (x y) are the original points (x' y') are the rotated coordinates and t is the angle measured in radians from the x-axis. The rotation is counter-clockwise as written. -credits duffymo I tried implementing the formula like this: //GLfloat Ax = getLocalVertices()[BOTTOM_LEFT].x * cosf(DEG_TO_RAD( m_orientation )) - getLocalVertices()[BOTTOM_LEFT].y * sinf(DEG_TO_RAD( m_orientation )); //GLfloat Ay = getLocalVertices()[BOTTOM_LEFT].x * sinf(DEG_TO_RAD( m_orientation )) + getLocalVertices()[BOTTOM_LEFT].y * cosf(DEG_TO_RAD( m_orientation )); //Vector3D BL = Vector3D(AxAy0); I create a vector to the translated point store it in the rectangles world_vertice member variable. That's fine. However in my main draw loop I draw a line from (000) to the vector BL and it seems as if the line is going in a circle from the point on the rectangle (the rectangles bottom left corner) around the origin of the world coordinates. Basically as m_orientation gets bigger it draws a huge circle around the (000) world coordinate system origin. edit: when m_orientation = 360 it gets set back to 0. I feel like I am doing this part wrong: and t is the angle measured in radians from the x-axis. Possibly I am not supposed to use m_orientation (the rectangles rotation angle) in this formula? Thanks! edit: the reason I am doing this is for collision detection. I need to know where the coordinates of the rectangles (soon to be rigid bodies) lie in the world coordinate place for collision detection. what you do is rotation [ special linear transformation] of a vector with angle Q on 2d.It keeps vector length and change its direction around the origin. [linear transformation : additive L(m + n) = L(m) + L(n) where {m n} ŠäŒ vector  homogeneous L(k.m) = k.L(m) where m ŠäŒ vector and k ŠäŒ scalar ] So: You divide your vector into two pieces. Like m[1 0] + n[0 1] = your vector. Then as you see in the image rotation is made on these two pieces after that your vector take the form: m[cosQ sinQ] + n[-sinQ cosQ] = [m*cosQ - n*sinQ m*sinQ + n*cosQ] you can also look at Wiki Rotation If you try to obtain eye coordinates corresponding to your object coordinates you should multiply your object coordinates by model-view matrix in opengl. For M => model view matrix and transpose of [x y z w] is your object coordinates you do: M[x y z w]T = Eye Coordinate of [x y z w]T Thank you. I will work on this later tonight! :) OpenGL handles graphics not linear algebra operations. If he needs the transformed coordinates for collision detection that's a bad advice in my opinion. But +1 for a good explanation. If you use OpenGL to transform the mesh during the actual rendering remember to rotate about the Z axis.  This seems to be overcomplicating things somewhat: typically you would store an object's world position and orientation separately from its set of own local coordinates. Rotating the object is done in model space and therefore the position is unchanged. The world position of each coordinate is the same whether you do a rotation or not - add the world position to the local position to translate the local coordinates to world space. Any rotation occurs around a specific origin and the typical sin/cos formula presumes (00) is your origin. If the coordinate system in use doesn't currently have (00) as the origin you must translate it to one that does perform the rotation then transform back. Usually model space is defined so that (00) is the origin for the model making this step trivial.,c++ opengl matrix rotation trigonometry1733488,A,"Terrain minimap in OpenGL? So I have what is essentially a game... There is terrain in this game. I'd like to be able to create a top-down view minimap so that the ""player"" can see where they are going. I'm doing some shading etc on the terrain so I'd like that to show up in the minimap as well. It seems like I just need to create a second camera and somehow get that camera's display to show up in a specific box. I'm also thinking something like a mirror would work. I'm looking for approaches that I could take that would essentially give me the same view I currently have just top down... Does this seem feasible? Feel free to ask questions... Thanks! Well I don't have an answer to your specific question but it's common in games to render the world to an image using an orthogonal perspective from above and use that for the minimap. It would at least be less performance intensive than rendering it on the fly.  One way to do this is to create an FBO (frame buffer object) with a render buffer attached render your minimap to it and then bind the FBO to a texture. You can then map the texture to anything you'd like generally a quad. You can do this for all sorts of HUD objects. This also means that you don't have to redraw the contents of your HUD/menu objects as often as your main view; update the the associated buffer only as often as you require. You will often want to downsample (in the polygon count sense) the objects/scene you are rendering to the FBO for this case. The functions in the API you'll want to check into are: glGenFramebuffersEXT glBindFramebufferEXT glGenRenderbuffersEXT glBindRenderbufferEXT glRenderbufferStorageEXT glFrambufferRenderbufferEXT glFrambufferTexture2DEXT glGenerateMipmapEXT There is a write-up on using FBOs on gamedev.net. Another potential optimization is that if the contents of the minimap are static and you are simply moving a camera over this static view (truly just a map). You can render a portion of the map that is much larger than what you actually want to display to the player and fake a camera by adjusting the texture coordinates of the object it's mapped onto. This only works if your minimap is in orthographic projection. Would using multiple viewports also work? Can I render polygons to the frame buffer? Obviously I'm pretty noob to graphics programming haha. Yes you can draw to an FBO in exactly the same way that you draw normally in your window's frame buffer (the same as rendering to the back buffer before swapping with the front buffer). You can use different gluPerspective/gluLookAt's in each FBO. The benefit is that you don't have to redraw in the FBO if you don't need to for the current frame the FBO can be of any dimensions and it's very fast when used for textures as you don't need to use a glCopyTexImage. You can create many FBOs and switch between them with glBindFramebufferEXT (0 binds the window's framebuffer that your used to).",c++ opengl graphics662440,A,"Palette Animation in OpenGL I am making an old-school 2d game and I want to animate a specific color in my texture. Only ways I know are: opengl shaders. animating one color channel only. white texture under the color-animated texture. But I don't want to use shaders I want to make this game as simple as possible not many extra openGL functions etc.. And the color channel animating doesnt fit this because I need all color channels in my textures. Currently I am doing it with 2 textures: white texture under the other texture translated the specific pixel color into transparent then I change white texture color with glColor3f() function to what ever I want and I see the ""palet animation"" on that specific color. But that style sounds pretty hacky so I am wondering if there is some better trick to this? If you want your game to work on modern hardware the fragment shaders are pretty much your only option since paletted textures are deprecated and may not be available on newer hardware. The solution you have right now sounds reasonable especially since it will probably work everywhere.  How about just using paletted textures? There are extensions to do just that. If using extensions is out of question you can just make palette handling by your own. Just do your palette tricks there are lot of them and just write RGB texture using palette. Ofcourse this limits number of colors but thats whole point of using palette. Paint programs that are good for palette handling are nowadays rare. That's why I will not remove Deluxe Paint from my drive. ahh Deluxe Paint!  You may also use the stencil buffer to do something equivalent. Write into the stencil buffer at the positions where your animation should occur (= the positions that should have the animated color). Then render the box with the normal texture only on non-set positions of the stencil buffer using the corresponding stencil op. After that render the animated color into the resp. positions using different stencil op. I don't know if this really would be an improvement - depends also on in which way you have the data on your hands - but is probably less ""hackish"".  For a 2D game I think it's better to use ARB_vertex_program extension than GLSL. There are still OpenGL drivers out there that do not support GLSL but support ARB_fragment_program. Support for paletted textures is nowadays non-existent but pre-shader-age video cards may support it. See the links for statistics. The old ARB language is a low-level assembly language but you can use NVidia's high level Cg language to compile shaders to this format. Despite it being a NVidia technology it works for all GPUs. That said if you are programming the game for your own amusement it may not be worth the trouble.  While I am unfamiliar with the palette texture extension I still recommend using a fragment shader for this sort of effect. It is almost trivial to do a color-key replacement with a shader versus the other methods you mentioned and will be way faster than writing the palette functionality yourself. Here's an example GLSL fragment shader that would replace the color white in a texture for whatever color is passed in. uniform vec4 fvReplaceColor; uniform sampler2D baseMap; varying vec2 Texcoord; void main( void ) { vec4 fvBaseColor = texture2D( baseMap Texcoord); if(fvBaseColor == vec4(1.0 1.0 1.0 1.0)) fvBaseColor = fvReplaceColor; gl_FragColor = fvBaseColor; } Yes it does take a little bit extra to set up shader but but what it sounds like you are trying to do I feel it's the best approach.",c++ c opengl784445,A,"How could simply calling Pitch() and Yaw() cause the camera to eventually Roll()? I'm coding a basic OpenGL game and I've got some code that handles the mouse in terms of moving the camera. I'm using the following method: int windowWidth = 640; int windowHeight = 480; int oldMouseX = -1; int oldMouseY = -1; void mousePassiveHandler(int x int y) { int snapThreshold = 50; if (oldMouseX != -1 && oldMouseY != -1) { cam.yaw((x - oldMouseX)/10.0); cam.pitch((y - oldMouseY)/10.0); oldMouseX = x; oldMouseY = y; if ((fabs(x - (windowWidth / 2)) > snapThreshold) || (fabs(y - (windowHeight / 2)) > snapThreshold)) { oldMouseX = windowWidth / 2; oldMouseY = windowHeight / 2; glutWarpPointer(windowWidth / 2 windowHeight / 2); } } else { oldMouseX = windowWidth / 2; oldMouseY = windowHeight / 2; glutWarpPointer(windowWidth / 2 windowHeight / 2); } glutPostRedisplay(); } However after looking around in circles you'll find the camera starts to ""roll"" (rotate). Since I'm only calling Pitch and Yaw I don't see how this is possible. Here is the code I'm using for my Camera class: http://pastebin.com/m20d2b01e As far as I know my camera ""rolling"" shouldn't happen. It should simply pitch up and down or yaw left and right. NOT roll. What could be causing this? Well if you start off looking forward horizontal to the horizon pitch up 90 degrees then yaw left 90 degrees then pitch down 90 degrees you'd be looking in the same direction as you started but the horizon would be vertical (as if you'd rolled 90 degrees left). Edit: I think the problem is that yaw/pitch/roll would be appropriate if the camera is being treated like an airplane. What you probably want to do is treat it like a point in a sphere keeping track of where on the sphere you are pointing the camera. Instead of yaw/pitch use spherical coordinates keeping track of theta (latitude) and phi (longitude). They may sound similar but consider the extreme case where the camera is pointing directly up. With yaw/pitch you can still freely adjust the yaw and pitch from that straight-up direction. With theta/phi you could only adjust theta downward and no matter how much you adjusted phi decreasing theta would still give you a camera that is parallel to the horizon. This is how FPS camera's work (you can't look so far down that you're looking behind you). Edit 2: Looking at the camera code you linked to you want to be using the rotLati(float angle) and rotLongi(float angle) functions. If I start moving my mouse in tight circles on the screen you'll see a distinct and slow roll. It completely rolls all 360 degrees. It isn't inverting the view. +1 Beat me to it. If you're moving your mouse in tight circles you'll get small amounts of roll. That's just how the combination of movements work. well if you replace the 90's in my answer with 20's the answer would still be the same. moving in circles would do basically what i am describing. Nestor Kip just explained how pitching and yawing can be combined to get the net effect of a roll. His numbers are exaggerated to make the effect easier to see -- hold your hand in front of you and make those motions with it. You're getting smaller motions from your mouse which is why you have to move it around a lot more before you go 360 degrees but it's still the same issue.  You will probably need to use quaternions for composing rotations if you are not doing so already. This avoids the problem of gimbal lock which you can get when orienting a camera by rotation around the 3 axes. Here is how to convert between them. Use quaternions is the answer.  I believe this circumstance is called Gimbal Lock - there's an example of it with illustrations on the wikipedia page.  Mathematically the reason for this is that rotations in 3D space do not commute. What that means is that pitch() followed by yaw() is not the same as yaw() followed by pitch() but a consequence of that fact is that the three kinds of rotations are inextricably linked and you can't perform any two of them without getting some of the third. In other words any sequence of pitch()es and yaw()s will produce a noticeable roll() effect over time unless the second half of the sequence is the exact reverse of the first half. (There's a lot of fairly intricate math involved in this but the details aren't particularly relevant)  Congratulations -- you have discovered Lie group theory! Yes it's possible. The outcome of a series of transformations depends on the order in which they're executed. Doing a pitch followed by a yaw is not the same as a doing a yaw followed by a pitch. In fact in the limit of infinitesimally small yaws and pitches the difference amounts to a pure roll; the general case is a little more complicated. (Physicists call this the ""commutation relationships of the rotational group"".) If you're familiar with rotation matrices you can work it out quite easily. heh looks like we were thinking exactly the same thing ;-)  Pitch/yaw/roll are all relative to your vehicle's orientation. When you pitch up/down you change your axis of yaw. Likewise when you yaw you change your pitch axis. So it's possible to change your orientation in a way similar to a roll maneuver just by a combination and pitch & yaw maneuvers.",c++ opengl camera glut237899,A,"How to draw a filled envelop like a cone on OpenGL (using GLUT)? I am using freeglut for opengl rendering... I need to draw an envelop looking like a cone (2D) that has to be filled with some color and some transparency applied. Is the freeglut toolkit equipped with such an inbuilt functionality to draw filled geometries(or some trick)? or is there some other api that has an inbuilt support for filled up geometries.. Edit1: just to clarify the 2D cone thing... the envelop is the graphical interpretation of the coverage area of an aircraft during interception(of an enemy aircraft)...that resembles a sector of a circle..i should have mentioned sector instead.. and glutSolidCone doesnot help me as i want to draw a filled sector of a circle...which i have already done...what remains to do is to fill it with some color... how to fill geometries with color in opengl? Edit2: All the answers posted to this questions can work for my problem in a way.. But i would definitely would want to know a way how to fill a geometry with some color. Say if i want to draw an envelop which is a parabola...in that case there would be no default glut function to actually draw a filled parabola(or is there any?).. So to generalise this question...how to draw a custom geometry in some solid color? Edit3: The answer that mstrobl posted works for GL_TRIANGLES but for such a code: glBegin(GL_LINE_STRIP); glColor3f(0.0 0.0 1.0); glVertex3f(0.0 0.0 0.0); glColor3f(0.0 0.0 1.0); glVertex3f(200.0 0.0 0.0); glColor3f(0.0 0.0 1.0); glVertex3f(200.0 200.0 0.0); glColor3f(0.0 0.0 1.0); glVertex3f(0.0 200.0 0.0); glColor3f(0.0 0.0 1.0); glVertex3f(0.0 0.0 0.0); glEnd(); which draws a square...only a wired square is drawn...i need to fill it with blue color. anyway to do it? if i put some drawing commands for a closed curve..like a pie..and i need to fill it with a color is there a way to make it possible... i dont know how its possible for GL_TRIANGLES... but how to do it for any closed curve? just to clarify the 2D cone thing... the envelop is the graphical interpretation of the coverage area of an aircraft during interception(of an enemy aircraft)...that resembles a sector of a circle..i should have mentioned sector instead.. Edit yoru comment into question because it's where it belongs. edited my original question..as i am newbie to stackoverflow i thought that followups to orig questions should go into comments.. is this how stackoverflow works? if the original poster feels to add to the conversation..how he should proceed?through comments/answering to own question or editing ques Since you reclarified your question to ask for a pie: there's an easy way to draw that too using opengl primitives: You'd draw a solid sphere using gluSolidSphere(). However since you only want to draw part of it you just clip the unwanted parts away: void glClipPlane(GLenum plane const GLdouble * equation); With plane being GL_CLIPPLANE0 to GL_CLIPPLANEn and equation being a plane equation in normal form (a*x + b*y + c*z + d = 0 would mean equation would hold the values { a b c d }. Please note that those are doubles and not floats.  On the edit on colors: OpenGL is actually a state machine. This means that the current material and/or color position is used when drawing. Since you probably won't be using materials ignore that for now. You want colors. glColor3f(float r float g float b) // draw with r/g/b color and alpha of 1 glColor4f(float r float g float b float alpha) This will affect the colors of any vertices you draw of any geometry you render - be it glu's or your own - after the glColorXX call has been executed. If you draw a face with vertices and change the color inbetween the glVertex3f/glVertex2f calls the colors are interpolated. Try this: glBegin(GL_TRIANGLES); glColor3f(0.0 0.0 1.0); glVertex3f(-3.0 0.0 0.0); glColor3f(0.0 1.0 0.0); glVertex3f(0.0 3.0 0.0); glColor3f(1.0 0.0 0.0); glVertex3f(3.0 0.0 0.0); glEnd(); But I pointed at glColor4f already so I assume you want to set the colors on a per-vertex basis. And you want to render using display lists. Just like you can display lists of vertices you can also make them have a list of colors: all you need to do is enable the color lists and tell opengl where the list resides. Of course they need to have the same outfit as the vertex list (same order). If you had glEnableClientState(GL_VERTEX_ARRAY); glVertexPointer(3 GL_FLOAT 0 vertices_); glDisableClientState(GL_VERTEX_ARRAY); you should add colors this way. They need not be float; in fact you tell it what format it should be. For a color list with 1 byte per channel and 4 channels (R G B and A) use this: glEnableClientState(GL_VERTEX_ARRAY); glEnableClientState(GL_COLOR_ARRAY); glVertexPointer(3 GL_FLOAT 0 vertices_); glColorPointer(4 GL_UNSIGNED_BYTE 0 colors_); glDisableClientState(GL_COLOR_ARRAY); glDisableClientState(GL_VERTEX_ARRAY); EDIT: Forgot to add that you then have to tell OpenGL which elements to draw by calling glDrawElements.  On Edit3: The way I understand your question is that you want to have OpenGL draw borders and anything between them should be filled with colors. The idea you had was right but a line strip is just that - a strip of lines and it does not have any area. You can however have the lines connect to each other to define a polygon. That will fill out the area of the polygon on a per-vertex basis. Adapting your code: glBegin(GL_POLYGON); glColor3f(0.0 0.0 1.0); glVertex3f(0.0 0.0 0.0); glColor3f(0.0 0.0 1.0); glVertex3f(200.0 0.0 0.0); glColor3f(0.0 0.0 1.0); glVertex3f(200.0 200.0 0.0); glColor3f(0.0 0.0 1.0); glVertex3f(0.0 200.0 0.0); glColor3f(0.0 0.0 1.0); glVertex3f(0.0 0.0 0.0); glEnd(); Please note however that drawing a polygon this way has two limitations: The polygon must be convex. This is a slow operation. But I assume you just want to get the job done and this will do it. For the future you might consider just triangulating your polygon. Note that you don't need the multiple glColor3f() statements. OpenGL is a state machine and the state is retained. So one glColor3f()-statement will suffice. ThankYou mstroblthis is really what i wanted...ur solution made my day!  I'm not sure what you mean by ""an envelop"" but a cone is a primitive that glut has: glutSolidCone(radius height number_of_slices number_of_stacks) The easiest way to fill it with color is to draw it with color. Since you want to make it somewhat transparent you need an alpha value too: glColor4f(float red float green float blue float alpha) // rgb and alpha run from 0.0f to 1.0f; in the example here alpha of 1.0 will // mean no transparency 0.0 total transparency. Call before drawing. To render translucently blending has to be enabled. And you must set the blending function to use. What you want to do will probably be achieved with the following. If you want to learn more drop me a comment and I will look for some good pointers. But here goes your setup: glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); Call that before doing any drawing operations possibly at program initialization. :) I never remember those blending parameters.  I remember there was a subroutine for that. But it's neither too hard to do by yourself. But I don't understand the 2D -thing. Cone in 2D? Isn't it just a triangle? Anyway here's an algorithm to drawing a cone in opengl First take a circle subdivision it evenly so that you get a nice amount of edges. Now pick the center of the circle make triangles from the edges to the center of the circle. Then select a point over the circle and make triangles from the edges to that point. The size shape and orientation depends about the values you use to generate the circle and two points. Every step is rather simple and shouldn't cause trouble for you. First just subdivision a scalar value. Start from [0-2] -range. Take the midpoint ((start+end)/2) and split the range with it. Store the values as pairs. For instance subdividing once should give you: [(01) (12)] Do this recursively couple of times then calculate what those points are on the circle. Simple trigonometry just remember to multiply the values with Ò— before proceeding. After this you have a certain amount of edges. 2^n where n is the amount of subdivisions. Then you can simply turn them into triangles by giving them one vertex point more. Amount of triangles ends up being therefore: 2^(n+1). (The amounts are useful to know if you are doing it with fixed size arrays. Edit: What you really want is a pie. (Sorry the pun) It's equally simple to render. You can again use just triangles. Just select scalar range [-0.25 - 0.25] subdivide project to circle and generate one set of triangles. The scalar - circle projection is simple as: x=cos(v*pi)r y=sin(vpi)*r where (xy) is the resulting vertex point r is a radius and trigonometric functions work on radiances not degrees. (if they work with degrees replace pi with 180) Use vertex buffers or lists to render it yourself. Edit: About the coloring question. glColor4f if you want some parts of the geometry to be different by its color you can assign a color for each vertex in vertex buffer itself. I don't right now know all the API calls to do it but API reference in opengl is quite understandable.",c++ opengl glut freeglut640095,A,"When using a GL_RGBA16F_ARB-texture it contains just crap but I get no error message I generate a texture like this: GLuint id; glGenTextures(1 &id); glBindTexture(GL_TEXTURE_2D id); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_WRAP_S GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_WRAP_T GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_NEAREST); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_NEAREST); glTexImage2D( GL_TEXTURE_2D 0 GL_RGBA16 //GL_RGBA16F_ARB //< Won't work 256 256 0 GL_RGBA GL_FLOAT NULL ); glBindTexture(GL_TEXTURE_2D 0); I attach it to a framebuffer object (FBO) for rendering to. All of this works like a charm when I set the internal format to GL_RGBA16. However I need a higher dynamic range and was thinking that GL_RGBA16F_ARB might do the trick. Unfortunately if I replace GL_RGBA16 with GL_RGBA16F_ARB in the code given above the texture seems to stop working. Nothing I try to render to the FBO/texture sticks and when I use the texture it contains random garbage. (A lot of purple as it turns out) This would not be so frustrating if I had gotten an error message hinting at what might be wrong but I can't seem to find one. In other words glGetError() returns 0 after the glTexImage2D-call and glCheckFramebufferStatusEXT(GL_FRAMEBUFFER_EXT) returns GL_FRAMEBUFFER_COMPLETE_EXT when I have attached the texture I haven't messed with glClampColorARB(...) ... yet :) Have I forgotten to check for errors in a place/way that I haven't thought of? Do GL_RGBA16F_ARB-textures require any special treatment that I haven't given? Is there anything else that might be wrong? I'm stumped since everything works smoothly with GL_RGBA16... :( EDIT: When using GL_RGBA16F_ARB the first frame I try to render to screen doesn't make it. Seems to me that I should be getting an error message somewhere..? EDIT: By inspecting ShadowIce's working code example I figured out that the problems disappeared if I changed the depth buffer on my FBO and give glRenderBufferStorageEXT(...) GL_DEPTH_COMPONENT24 as its second parameter rather than GL_DEPTH_COMPONENT16. I have no idea why this works but apparently it does work. Also ShadowIce's code breaks like mine if I do the opposite substitution there. How are you actually filling the texture? I am attaching it to an FBO and rendering to it. There shouldn't be anything special to do for setting up a framebuffer with float textures. Some things I would check: Is the FBO bound and the draw/read buffer set correctly before you call glCheckFramebufferStatusEXT? Also try testing it right before you draw to it. Does the texture look ok after a simple glClear with a specific clear color? If yes there might be something wrong with your shaders (if you use any) or the way you draw to the FBO. Are your drivers up to date? And does the problem still exist on a PC with different hardware? How about GL_RGBA32F_ARB? Edit: Check the id of your framebuffer and texture also check if the texture id matches the one attached to your fbo (with glGetFramebufferAttachmentParameteriv). Normally I would guess that everything is ok with that if it works with a RGBA texture but random data (especially purple) is a good sign that nothing was written to the texture or it wasn't cleared properly. I have written a small example application that should work maybe that helps. I have only tested it on windows so for linux you might need to change it a bit: link The example you made worked nicely. Now to isolate the differences... I ought to create sockpuppet-accounts so I could thank you properly ;) Hehe thanks. ;) 1. Yes. Verified by testing right before drawing 2. No it does not look OK 3. I get my drivers from the Ubuntu-repository. Should be reasonably up to date (nvidia). I get the same problem om a different machine 4. I get the same result sometimes but now it has apparently locked completely! (4. continued:) When breaking it in a debugger the stack I get to see is only one deep with ""libGL"" as the only element. The program is completely locked and uses 100% CPU :O Also: Thanks! If you have any more ideas I'm all ears :)  GL_HALF_FLOAT_ARB might work as the type instead of GL_FLOAT. Thanks. Unfortunately this gives the same result; It still works with GL_RGBA16 but fails with GL_RGBA*F_ARB :(",c++ c opengl fbo746034,A,glDrawPixels in grayscale? I have an image that I'm rendering like this: glDrawPixels(image->width image->height GL_BGR GL_UNSIGNED_BYTE image->imageData); Is there anyway I can draw it in grayscale instead (without loading it into a texture first)? I don't care if only say the blue component is used for the gray value rather than the L2 norm or something I just need a quick and dirty output. GL_LUMINANCE would be great except that it won't work on a 3-channel image. @timday: A perverse idea for you to try and I've no idea if it'll work: glPixelZoom(1.0f/3.0f1.0f); glDrawPixels(3*widthheightGL_LUMINANCEGL_UNSIGNED_BYTEdata); ie treat your 3-channel image as being a 1-channel (grayscale) image 3 times as wide and compensate for this by squishing the width using the x zoom factor. I believe GL always does nearest-neighbour sampling for zoomed glDrawPixels so it ought to consistently pick out the same component from each triple of samples as you require. Oh my God..... I can't believe that works! It sort of splits the image in half and one side grainier than the other but it works. Could be something to do with the precision with which 1.0/3.0 is maintained internally (especially if it works OK up to a certain size). I'd suggest adjusting the ratio very slightly or using a 4-bytes-per-pixel format and a zoom factor of 0.25.,c++ opengl1569829,A,Open Source C++ game engine math libraries? I'm looking for a free to use game engine math library. Specifically I'd like a good matrix and vector implementation. And everything needed to move objects in 3D space. Does anyone know any good ones? I'm targeting OpenGL. I'd like to write them myself but don't have the time. Besides Ogre 3D there's also Crystal Space. Here's an article that compares the two. That article appears to 404 on me. @darthcoder it looks like arcanoria.com did some reorganizing. I've updated the article's URL accordingly  I have good work with Open Dynamics Engine is Full and Stable Physics Engine the ode in a BSD License and have some functions for Matrix Manipulation Quaternion and rotations.  Take a look here https://sourceforge.net/projects/mg3d/ It is an opensource engine that has all former OpenGL transformation routines. The implementation here is very straightforward and clear. And it is very easy to include the module with the routines in your project.  If you want an entire 3D engine (which of course would contain the 3d maths you need) see Ogre 3D (LGPL) Actually MIT license now for current svn trunk and all coming releases.  I'd recommend OpenGL Mathematics (GLM) Though if you want physics with your math you could go with Bullet Physics Library Finally if you want an entire engine i'd go with OGRE I think GLM will work nicely... seems light weight enough and has what I need  You might want to consider Blitz++.,c++ opengl933020,A,Macro use depending on integer I have to use a macro multiple times inside a function and the macro that needs to be used depends on a number I pass into the function. e.g.  function(int number) { switch(number) { case 0: doStuff(MACRO0); break; case 1: doStuff(MACRO1); break; } } The problem is: I have a lot stuff to do per switch statement with the same macro. Is there are more elegant solution then having all that stuff in the switch statement? Like passing the macro itself to the function? I have read about eval() like methods in C++ but they just don't feel right to me. Another way could be do determine into what the macro expands but I haven't found any info on this. Oh it's openGL actually. This very much depends on what MACRO1 expands to. If it's a constant you can just call the function outside of the switch or do multiple fall-through cases. If it depends on the local context then you will have to evaluate it every time.  I would use a function object struct Method1 { void operator()() { ... } }; template<typename Method> void function(Method m) { ... m(); ... } int main() { function(Method1()); } Why not just use a function pointer? Because function objects using op() are faster and can be inlined. Given that he is doing OpenGL i think speed matters.  In addition to the above suggestions often I find using virtual inheritance can get rid of long conditionals especially switches-over-enums type code. I'm not sure what your particular situation so I'm not sure how applicable his will be but let's say the above was enum StyleID { STYLE0 = 0 STYLE1 STYLE2 /* ... */ }; void drawStyle(StyleID id) { switch(id) { case STYLE1: doDraw(MACROSTYLE1); break; /* ... */ }; } Long blocks of switches could be avoided via virtual inheritance: class StyleInterface { /* some methods */ virtual void doDraw() = 0; }; class Style1 : public StyleInterface { /* concrete impl */ virtual void doDraw() { doDraw(MACROSTYLE1); } }; void drawStyle(StyleInterface* id) { id->doDraw(); },c++ opengl macros366742,A,Creating an Environment Stack in OpenGL I'd like to create an abstraction in OpenGL of the environment settings(blending stenciling depth etc.) that works like the matrix stack. Push onto the stack make any changes you need draw your objects then pop the stack and go back to the prior settings. For example currently you might have drawing code like this: glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); glDisable(GL_DEPTH_TEST); //Draw operations glEnable(GL_DEPTH_TEST); glDisable(GL_BLEND); But with an environment stack it would look like this: glPushEnv(); glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); glDisable(GL_DEPTH_TEST); //Draw operations glPopEnv(); As I see it there are only 2 ways to do this: Create my own 'flavor' of each environment setting function and call that. It will in turn update the current EnvStack data structure and call the OpenGL environment function. Alter the OpenGL environment functions to point to my environment functions which will again update the current EnvStack data structure and call the original OpenGL environment functions. So option 1 is obviously much simpler. But I run into a problem if I'm using other peoples code in that I don't necessarily know what changes it's making to the environement and therefor my data structure would be out of sync. And since the whole point is to have a simple method of ensuring the environment settings are correct this is not cool. So my question is in this context how do I change the functions that the OpenGL environment functions point to? OpenGL already contains this functionality. You want glPushAttrib(GL_ALL_ATTRIB_BITS); and glPopAttrib();. See http://opengl.org/documentation/specs/man_pages/hardcopy/GL/html/gl/pushattrib.html for more. Wow. I have never come across that. It seemed like something so useful they'd have to have a way to do it. Thanks.,c++ c opengl abstraction371665,A,"openGL into png I'm trying to convert an openGL [edit: ""card that I drew""(?):) thx unwind]containing a lot of textures (nothing moving) into one PNG file that I can use in another part of the framework I'm working with. Is there a C++ library that does that? thanks! What does ""card that I drew"" mean? it's a static constant scene that looks like a card... What is an ""OpenGL file""? OpenGL is a graphics API it doesn't specify any file formats. Do you mean a DDS file or something?  There are better ways to make a compose texture than drawing them with the graphics card. This is really something you would want to do before hand on the cpu store and then use as and when you need it with opengl Can you give me a clue on how I would do that?  If you simply mean ""take a scene rendered by OpenGL and save it as an image"" then it is fairly straightforward. You need to read the scene with glReadPixels() and then convert that data to an image format such as PNG (http://www.opengl.org/resources/faq/technical/miscellaneous.htm). There are also more efficient ways of achieving this such as using FBOs. Instead of rendering the scene directly into the framebuffer you can render it to a texture via an FBO then render that texture as a full-screen quad. You can then take this texture and save it to a file (using glGetTexImage for example).",c++ opengl png ldf52431,A,How do I draw text using OpenGL SDL and C++? I heard about SDL_TFF which I read about here but I don't understand how am I supposed to connect the TrueType2 library. Maybe there is something better out there? Here's a good answer if you decide to use ttf: http://stackoverflow.com/questions/5289447/using-sdl-ttf-with-opengl You can try to use FreeGLUT. If you like you can pull the text drawing files from the project.  I came across this great guide on linking in SDL extensions for those new to SDL which you may find useful. That said when I had your problem I eventually went with FTGL as the way SDL-ttf produces an SDL-Surface with its font rendered on it overcomplicated matters in my situation. This may not be the case in your situation though  For OpenGL things I usually use QT. This library is well documented and easy to use.  This article is about SDL and text output. Hope that helps.,c++ opengl sdl1719325,A,"FLTK in Cygwin using Eclipse (Linking errors) I have this assignment due that requires the usage of FLTK. The code is given to us and it should compile straight off of the bat but I am having linking errors and do not know which other libraries I need to include. I currently have ""opengl32"" ""fltk_gl"" ""glu32"" and ""fltk"" included (-l) each of which seem to reduce the number of errors. I compiled FLTK using make with no specified options. Including all of the produced library files doesn't fix the problem and I'm convinced that it's just some Windows specific problem. Compile log: **** Build of configuration Debug for project CG5 **** make all Building target: CG5.exe Invoking: Cygwin C++ Linker g++ -o""CG5.exe"" ./src/draw_routines.o ./src/gl_window.o ./src/my_shapes.o ./src/shape.o ./src/shapes_ui.o ./src/tesselation.o -lopengl32 -lfltk_z -lfltk_gl -lglu32 -lfltk /usr/lib/gcc/i686-pc-cygwin/3.4.4/../../../libfltk_gl.a(Fl_Gl_Window.o):Fl_Gl_Window.cxx:(.text+0x197): undefined reference to `_SelectPalette@12' /usr/lib/gcc/i686-pc-cygwin/3.4.4/../../../libfltk_gl.a(Fl_Gl_Window.o):Fl_Gl_Window.cxx:(.text+0x1a7): undefined reference to `_RealizePalette@4' /usr/lib/gcc/i686-pc-cygwin/3.4.4/../../../libfltk_gl.a(Fl_Gl_Window.o):Fl_Gl_Window.cxx:(.text+0x1fe): undefined reference to `_glDrawBuffer@4' /usr/lib/gcc/i686-pc-cygwin/3.4.4/../../../libfltk_gl.a(Fl_Gl_Window.o):Fl_Gl_Window.cxx:(.text+0x20d): undefined reference to `_glReadBuffer@4' /usr/lib/gcc/i686-pc-cygwin/3.4.4/../../../libfltk_gl.a(Fl_Gl_Window.o):Fl_Gl_Window.cxx:(.text+0x23a): undefined reference to `_glGetIntegerv@8' /usr/lib/gcc/i686-pc-cygwin/3.4.4/../../../libfltk_gl.a(Fl_Gl_Window.o):Fl_Gl_Window.cxx:(.text+0x2c3): undefined reference to `_glOrtho@48' /usr/lib/gcc/i686-pc-cygwin/3.4.4/../../../libfltk_gl.a(Fl_Gl_Window.o):Fl_Gl_Window.cxx:(.text+0x2f3): undefined reference to `_SwapBuffers@4' ...and lots more Thanks a ton for the help. EDIT: These first few lines are obviously OpenGL related although I'm still not sure what additional libraries need to be included. its probably not it but try changing the order so that -lglu32 is before the fltk libs. Also are you certain its: -lGLU32 -lOpenGL32 rather than -lGLU -lGL ? Sorry for the lack of closure but I just booted into my Linux netbook and got it working. -lfltk -lfltk_gl -lGLU -lGL -lXext -lX11 -lm  Just a guess: your makefile was written for Linux and on Cygwin some libraries are either missing or in a different place. You're going to have to examine the makefile locate the missing libraries and either move the libs to where the makefile expects them or change the makefile to look in the right place. The libraries it needs are listed on the line starting g++ (prepend 'lib' to the names after the -l flags)",c++ windows opengl linker-error fltk1167120,A,OpenGL Alpha blending with wrong color I am trying to create a simple ray tracer. I have a perspective view which shows the rays visibly for debugging purposes. In my example screenshot below I have a single white sphere to be raytraced and a green sphere representing the eye. Rays are drawn as lines with glLineWidth(10.0f) If a ray misses the sphere it is given color glColor4ub(100100100100); in my initialization code I have the following:  glEnable(GL_ALPHA_TEST); glAlphaFunc(GL_GREATER 0.0f); glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHAGL_SRC_ALPHA); You can see in the screen shot that for some reason the rays passing between the perspective view point and the sphere are being color blended with the axis line behind the sphere rather than with the sphere itself. Here is a screenshot: Can anyone explain what I am doing wrong here? Thanks!! I edited to include your screenshot AlphaTest is only for discarding fragments - not for blending them. Check the spec By using it you are telling OpenGL that you want it to throw away the pixels instead of drawing them so you won't can any transparent blending. The most common blending function is glBlendFunc (GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); You can also check out the OpenGL Transparency FAQ.  You dont need the glAlphaFunc disable it. Light rays should be blended by adding to the buffer: glBlendFunc(GL_ONE GL_ONE) (for premultiplied alpha which you chose. Turn off depth buffer writing (not testing) when rendering the rays: glDepthMask(GL_FALSE) Render the rays last.  Is it a possibility you cast those rays before you draw the sphere? Then if Z-buffer is enabled the sphere's fragments simply won't be rendered as those parts of rays are closer. When you are drawing something semi-transparent (using blending) you should watch the order you draw things carefully. In fact I think you cannot use Z-buffer in any sensible way together with ray-tracing process. You'll have to track Z-order manually. While we are at it OpenGL might not be the best API to visualize ray-tracing process. (It will do so possibly much slower than pure software ray-tracer) @puddlesofjoy: any chance you could edit the question and add the result after this fix? It might be instructive for people to see what your intended result looked like. Not a biggie - just a suggestion. Glad this worked out! Well I'll be... just changing the order of my drawing code is all it took; I had no idea that could effect things so much!! Thank you sir! You are a gentleman and a scholar. Just to clear up my intent for the curious. The actual ray tracing is fully independent of the OpenGL drawing. I have just thrown in a 3d perspective view to help me debug while I get my ray tracer working. It just shows the rays and a copy of the raytraced image textured onto a quad in front of the raytracer eye point.,c++ qt opengl1191525,A,"I can't get the transparency in my images to work Stemming from this question of mine: http://stackoverflow.com/questions/1191093/im-seeing-artifacts-when-i-attempt-to-rotate-an-image In the source code there I am loading a TIF because I can't for the life of me get any other image format to load the transparency parts correctly. I've tried PNG GIF & TGA. I'd would like to be able to load PNGs. I hope the source code given in the question above will be enough if not then let me know. For a better description of what happens when I attempt to load some other format -- One of the images I was attempting was a 128*128 orange triangle. Depending on the format it would either make the entire 128*128 square orange or make the transparent parts of the image white. OK I'm new at OpenGL + SDL but here is what I have.. Loads all? formats SDL_image supports except I can't get .xcf to work and don't have a .lbm to test with. //called earlier.. glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); //load texture SDL_Surface* tex = IMG_Load(file.c_str()); if (tex == 0) { std::cout << ""Could not load "" << file << std::endl; return false; } glGenTextures(1 &texture); glBindTexture(GL_TEXTURE_2D texture); //nearest works but linear is best when scaled? glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_NEAREST); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_NEAREST); width = tex->w; height = tex->h; //IMG_is* doesn't seem to work right esp for TGA so use extension instead.. std::string ext = file.substr(file.length() - 4); bool isBMP = (ext.compare("".bmp"") == 0) || (ext.compare("".BMP"") == 0); bool isPNG = (ext.compare("".png"") == 0) || (ext.compare("".PNG"") == 0); bool isTGA = (ext.compare("".tga"") == 0) || (ext.compare("".TGA"") == 0); bool isTIF = ((ext.compare("".tif"") == 0) || (ext.compare("".TIF"") == 0) || (ext.compare(""tiff"") == 0) || (ext.compare(""TIFF"") == 0)); //default is RGBA but bmp and tga use BGR/A GLenum format = GL_RGBA; if(isBMP || isTGA) format = (tex->format->BytesPerPixel == 4 ? GL_BGRA : GL_BGR); //every image except png and bmp need to be converted if (!(isPNG || isBMP || isTGA || isTIF)) { SDL_Surface* fixedSurface = SDL_CreateRGBSurface(SDL_SWSURFACE width height 32 0x000000ff 0x0000ff00 0x00ff0000 0xff000000); SDL_BlitSurface(tex 0 fixedSurface 0); glTexImage2D(GL_TEXTURE_2D 0 GL_RGBA width height 0 format GL_UNSIGNED_BYTE fixedSurface->pixels); SDL_FreeSurface(fixedSurface); } else { glTexImage2D(GL_TEXTURE_2D 0 GL_RGBA width height 0 format GL_UNSIGNED_BYTE tex->pixels); } SDL_FreeSurface(tex); list = glGenLists(1); glNewList(list GL_COMPILE); GLint vertices[] = { 00 00 01 0height 11 widthheight 10 width0 }; glEnableClientState(GL_TEXTURE_COORD_ARRAY); glEnableClientState(GL_VERTEX_ARRAY); glBindTexture(GL_TEXTURE_2D texture); glTexCoordPointer(2 GL_INT 4*sizeof(GLint) &vertices[0]); glVertexPointer(2 GL_INT 4*sizeof(GLint) &vertices[2]); glDrawArrays(GL_POLYGON 0 4); glDisableClientState(GL_VERTEX_ARRAY); glDisableClientState(GL_TEXTURE_COORD_ARRAY); glEndList(); And then to draw I set the color to opaque white (doesn't affect transparency?) then just call the list.. glColor4f(1111); glCallList(list); And of course any help for my code would be much appreciated too! :) I used bits and pieces from your code and it finally worked. Turns out when I was loading the image ( I used my own function instead of IMG_Load() ) it was discarding the alpha layer as it was converting the BPPs. So thanks a lot for your code.  Make sure that you have alpha blending enabled with glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); otherwise primitives will draw solid colors where there should be transparency. You may need a different blendfunc. This is a common setup. I have that code in my previous question linked in the first post. Actually you have: glBlendFunc(GL_ONE GL_ONE_MINUS_SRC_ALPHA); // notice the GL_ONE instead of GL_SRC_ALPHA - this can make a difference depending on what you are seeing Sorry if you had the code already I wasn't able to scroll the code block on an iPhone. As Jim was saying the blendfunc that you have may not be correct. The blendfunc you're using is for blending a texture with pre-multiplied alpha. Ah well I tried your code then and now it just won't draw it at all :( Try to load in an image that has a known amount of transparency then look at the loaded buffer in the debugger to make sure that the alpha value contains the transparency you expect. If you don't see anything at all I suspect that the alpha could be 0.  I'm not familiar with SDL but since it's SDL that loading the image I would look closer at their docs. I use .png in my own work along with OpenGL and transparency works with no problem. (I use a .png parser called LightZPng.) Also I just noticed your linked post has: glBlendFunc(GL_ONE GL_ONE_MINUS_SRC_ALPHA); instead of: glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); This would have the affect of adding the pixels that should be transparent to whatever is in the background (assuming the alpha is 0 in those texels). Changing that makes the image not appear at all. Even with the TIF now Huh could it be that alpha is simply 0 for all your texels? I would look at your image data before passing it to glTexImage2D to confirm what the alpha values are for some texels. If they are simply RGB images (no alpha at all) then be sure to do a glColor4ub(255 255 255 255) before rendering to be sure your alpha is effectively set to fully opaque.",c++ gui opengl sdl1147249,A,Connecting Catmull-Rom splines together and calculating its length? I'm trying to create a class which takes in any number of points (position and control) and creates a catmull-rom spline based on the information given. What I'm doing - and I'm really unsure if this is the right way to do it - is storing each individual point in a class like so: class Point { public: Vector3 position; Vector3 control; } Where obviously position is the position of the point and control is the control point. My issue is connecting up the splines - obviously given the above class holding a point in the spline array indicates that any given position can only have one control point. So when having three or more points in a catmull rom spline the various individual catmull-rom splines which are being connected share one position and one control with another such spline. Now with position being the same is required - since I want to create splines which are continuous between themselves. However I really wonder should the control points also be the same between the two splines? With a bit of fiddling of the control points I can make it appear to be transitioning smoothly from one spline to another however I must emphasize that I'm not sure if the way they are transitioning is consistent with how catmull-rom splines form their shape. I'd much rather do it correctly than sit on my hands and rationalize that it's good enough. Obviously the second part of my question is self explanatory: Given two control and position points how do I calculate the length of a catmull-rom spline? With regards to measuring the lengths you can do this with calculus since its a polynomial spline. You need to do integrate the distance function across the line. Its described quite well on Wikipedia...  To define the spline between two control points the Catmull-Rom spline needs the control points and the tangent vector at each control point. However the tangent vector at internal (i.e. non-endpoint) control points is defined by the control points on either side of it: T(Pn) = (Pn+1 - Pn-1) / 2. For closed curves the spline is completely defined by the set of control points. For non-closed curves you need to also supply the tangent vector at the first and last control point. This is commonly done: T(P0) = P1 - P0 and T(Pn) = Pn - Pn-1. Thus for closed curves your data structure is just a list of control points. For general splines it's a list of points plus the first and last normal vector. If you want to have a cardinal spline then you can add a weighting factor to the tangent vector calculation as in the Wikipedia article. To calculate the length of such a spline one approach would be to approximate it by evaluating the spline at many points and then calculating the linear distance between each neighboring pair of points.,c++ opengl graphics directx spline23918,A,"OpenGL Rotation I'm trying to do a simple rotation in OpenGL but must be missing the point. I'm not looking for a specific fix so much as a quick explanation or link that explains OpenGL rotation more generally. At the moment I have code like this: glPushMatrix(); glRotatef(90.0 0.0 1.0 0.0); glBegin(GL_TRIANGLES); glVertex3f( 1.0 1.0 0.0 ); glVertex3f( 3.0 2.0 0.0 ); glVertex3f( 3.0 1.0 0.0 ); glEnd(); glPopMatrix(); But the result is not a triangle rotated 90 degrees. Edit Hmm thanks to Mike Haboustak - it appeared my code was calling a SetCamera function that use glOrtho. I'm too new to OpenGL to have any idea of what this meant but disabling this and rotating in the Z-axis produced the desired result. Thanks! The ""accepted answer"" is not fully correct - rotating around the Z will not help you see this triangle unless you've done some strange things prior to this code. Removing a glOrtho(...) call might have corrected the problem in this case but you still have a couple of other issues. Two major problems with the code as written: Have you positioned the camera previously? In OpenGL the camera is located at the origin looking down the Z axis with positive Y as up. In this case the triangle is being drawn in the same plane as your eye but up and to the right. Unless you have a very strange projection matrix you won't see it. gluLookat() is the easiest command to do this but any command that moves the current matrix (which should be MODELVIEW) can be made to work. You are drawing the triangle in a left handed or clockwise method whereas the default for OpenGL is a right handed or counterclockwise coordinate system. This means that if you are culling backfaces (which you are probably not but will likely move onto as you get more advanced) you would not see the triangle as expected. To see the problem put your right hand in front of your face and imagining it is in the X-Y plane move your fingers in the order you draw the vertices (11) to (32) to (31). When you do this your thumb is facing away from your face meaning you are looking at the back side of the triangle. You need to get into the habit of drawing faces in a right handed method since that is the common way it is done in OpenGL. The best thing I can recommend is to use the NeHe tutorials - http://nehe.gamedev.net/. They begin by showing you how to set up OpenGL in several systems move onto drawing triangles and continue slowly and surely to more advanced topics. They are very easy to follow.  Regarding Projection matrix you can find a good source to start with here: http://msdn.microsoft.com/en-us/library/bb147302(VS.85).aspx It explains a bit about how to construct one type of projection matrix. Orthographic projection is the very basic/primitive form of such a matrix and basically what is does is taking 2 of the 3 axes coordinates and project them to the screen (you can still flip axes and scale them but there is no warp or perspective effect). transformation of matrices is most likely one of the most important things when rendering in 3D and basically involves 3 matrix stages: Transform1 = Object coordinates system to World (for example - object rotation and scale) Transform2 = World coordinates system to Camera (placing the object in the right place) Transform3 = Camera coordinates system to Screen space (projecting to screen) Usually the 3 matrix multiplication result is referred to as the WorldViewProjection matrix (if you ever bump into this term) since it transforms the coordinates from Model space through World then to Camera and finally to the screen representation. Have fun  When I had a first look at OpenGL the NeHe tutorials (see the left menu) were invaluable.  Ensure that you're modifying the modelview matrix by putting the following before the glRotatef call: glMatrixMode(GL_MODELVIEW); Otherwise you may be modifying either the projection or a texture matrix instead.  Do you get a 1 unit straight line? It seems that 90deg rot. around Y is going to have you looking at the side of a triangle with no depth. You should try rotating around the Z axis instead and see if you get something that makes more sense. OpenGL has two matrices related to the display of geometry the ModelView and the Projection. Both are applied to coordinates before the data becomes visible on the screen. First the ModelView matrix is applied transforming the data from model space into view space. Then the Projection matrix is applied with transforms the data from view space for ""projection"" on your 2D monitor. ModelView is used to position multiple objects to their locations in the ""world"" Projection is used to position the objects onto the screen. Your code seems fine so I assume from reading the documentation you know what the nature of functions like glPushMatrix() is. If rotating around Z still doesn't make sense verify that you're editing the ModelView matrix by calling glMatrixMode. IMPORTANT! See also Perry's answer below.  I'd like to recommend a book: 3D Computer Graphics : A Mathematical Introduction with OpenGL by Samuel R. Buss It provides very clear explanations and the mathematics are widely applicable to non-graphics domains. You'll also find a thorough description of orthographic projections vs. perspective transformations.",c++ opengl glut721802,A,"What disadvantages could I have using OpenGL for GUI design in a desktop application? There are tons of GUI libraries for C/C++ but very few of them are based on the idea that opengl is a rather multiplatform graphics library. Is there any big disadvantage on using this OpenGL for building my own minimal GUI in a portable application? Blender is doing that and it seems that it works well for it. EDIT: The point of my question is not about using an external library or making my own. My main concern is about the use of libraries that use opengl as backend. Agar CEGUI or Blender's GUI for instance. Thanks. Here's an oddball one that bit a large physics experiment I worked on: because an OpenGL GUI bypasses some of the usual graphics abstraction layers it may defeat remote viewing applications. In the particular instance I'm thinking of we wanted to allow remote shift operations over VNC. Everything worked fine except for the one program (which we only needed about once per hour but we really needed) that used an OpenGL interface. We had to delay until a remote version of the OpenGL interface could be prepared. I was not involved in the solution but they arranged to display the OpenGL on the remote host. A little clunky but it meant I could sit shift in my PJs in my usual time-zone so I was happy. Yes this is the kind of answer I was looking for. Thanks dmckee! Good point. Generally anything that uses 3D acceleration will be invisible to apps like VNC. There are some ways to make it work but it causes a lot of performance issues and so isn't a great idea. I think to fix this you have to think an app as GUI-core-decoupled so you don't need VNC to control it. Actually there are several possibilities to use OpenGL enabled applications remotely such as for example xvnc/xf4vnc virtualgl or even just plain X11. The best solution depends on whether you want the OpenGL hardware acceleration to be done on the remote machine or locally on the viewer.  You're losing the native platforms capabilities for accessibility. For example on Windows most controls provide information to screen readers or other tools supporting accessibility impaired users. Basically unless you have a real reason to do this you shouldn't.  Re-inventing the Wheel: Yeah you'd be doing it. But I note OP used the word ""minimal"" in the problem statement so assuming it really doesn't need to scale up to all that it may be a small enough wheel as to not matter. The product I currently work on supports OpenGL on three platforms (Win Mac Linux) and we built all our own widgets (text boxes buttons dialogs). It's a lot of work but now that we've done it we own a huge chunk of our stack and don't have to debug into third party frameworks when things don't work as expected. It's nice having complete control of the experience. There's always something you want to do that a framework doesn't support. Like everything in our business it is a trade-off and you just have to weigh your needs against your need to finish on time. Portability: Yes you will still have to write platform specific code to boot-strap everything. This will be difficult if you've not done it before as it requires you to understand all the target platforms. Windows Drivers: We've found that graphics card manufacturers have much better support for DirectX on Windows than OpenGL since that's what is required to get MSFT certification. Often low- to mid-range cards have bugs missing functionality or outright crashes in their OpenGL support.  With Qt 4.5 you can select if you want to use OpenGL as window renderer. More info: http://blog.qt.digia.com/blog/2008/10/22/so-long-and-thanks-for-the-blit/ Read the comments to know about the problems about this. Your link is dead. Here's the new link: http://blog.qt.digia.com/blog/2008/10/22/so-long-and-thanks-for-the-blit/ link updated :)  The obvious one is that you're basically building the GUI elements yourself instead of having a nice designed like for wxWidgets or Qt.  You cant just use opengl you need a platform specific code to set up a window for opengl. From the freely available opengl red book: OpenGL is designed as a streamlined hardware-independent interface to be implemented on many different hardware platforms. To achieve these qualities no commands for performing windowing tasks or obtaining user input are included in OpenGL; instead you must work through whatever windowing system controls the particular hardware you're using. There are multiplatform solutions for this like glut qt wxWidgets ... And if you have to use them anyway why not use built in GUI elements. They also give you the opportunity to build your own and make use of the framework to handle mouse/keyboard events and stuff. It's very easy to make a multiplatform opengl program using preprococessor conditions and glut. It's far from using a huge library like qt for the whole GUI system. It very similar to make a multiplatform opengl program using qt: derive from QGLWidget; override initialiseGL paintGL resizeGL; assign your new class as mainwidget to a QApplication and thats it. The library is bigger yes. But i dont see the problem with that? Can you please tell me how they give you the opportunity to build your own GUI elements?  If you want a GUI as in windows/button etc. Don't do it yourself. There a lot of free solutions for this wxwidgetsqt or GTK. All have OpenGL support if you want a 3d window",c++ gui opengl1691538,A,"What 3D graphics framework should I use for a real world game engine? I'm a C++ programmer with very extensive server programming experience. I'm however fairly bored at the moment and I decided to tackle a new area: 3D game programming for learning purposes. Additionally I think this learning project may turn out to be good resume material in the future should I decide to work in this area. Instead of creating a 3D engine from scratch I decided to emulate as exactly as I'm able an existing one: World of Warcraft's. If you are curious as to why (feel free to skip this): It's a real world successful game All the map textures models and what not are already done (I'm not interested in learning how to actually draw a texture with photoshop or whatever) Their file formats have been more or less completely reverse engineered There is already an identical open source project (wowmapview) that I can look at if I'm in trouble. ok that was a long preface.. Now my main question is the following: Should I use DirectX OpenGL wrapper libraries such as sdl or what? What's the most used one in the real world? And something else that perplexes me: World of Warcraft appears to be using both! In fact normally it uses DirectX but you can use opengl by starting it with the ""-opengl"" switch via command line. Is this something common in games? Why did they do it? I imagine it's a lot of work and from my understanding nobody uses OpenGL anyway (very very few people know about the secret switch at all). If it's something usually done do programmers usually create their own 3d engine ""wrapper"" something like SDL made in house and based on switches / #defines / whatnot decide which API function to ultimately call (DirectX or OpenGL)? Or is this functionality already built in in sdl (you can switch between DirectX and OpenGL at will)? And finally do you have any books to suggest? Thanks! ""Why did they do it?"" Because Mac OsX doesn't have DirectX support? SDL is merely a platform abstraction layer it substitutes neither OpenGL nor DirectX. When SDL is used though it is more commonly used with OpenGL since both cross platform libraries. Also worth noting is that SDL doesn't provide a widget toolkit so if that's a requirement (not very common in fullscreen 3D games) something like Qt might be a better choice for a cross platform application. @gf: good point. Makes me wonder now why they don't support linux natively since they went through all the trouble to make OpenGL work for mac.. should only need relatively trivial changes. oh well guess I'll never find out. Blizzard do or at least did at some point have an internal unsupported build for Linux but it's never been released. I'm pretty sure they're using SDL too since Slouken WoW's lead interface programmer is also the author of SDL... take a look at this as well http://gamedev.stackexchange.com/questions/90/why-is-it-so-hard-to-develop-a-mmo this is my favorite post when I think I am boring and decide to do some game for fun especially WOW like . ^_^ You might want to look at some projects that encapsulate the low level 3d api in a higher level interface that is api independent such as Ogre3D. As you are doing this to learn I assume you probably will be more interesting in implementing the low level detail yourself but you could probably learn a lot from such a project. Or irrlicht or openscenegraph Indeed all good.  if you are really only interested in the rendering part i can suggest ogre3d. it is clean c++ tested and cross-platform. i used it in two projects and compared to other experiences (torque3d for example) i liked the good support (tutorials/wiki/forum) and the not so steep learning curve. i think someone can also learn a lot by looking at the sourcecode and the concepts they have used in the design. there is a accompanying book as well which is a bit outdated but it is good for the start the problem with this is you will be thinking inside this engine and soon you will need gameplay-like (timers events) elements for simulating and testing your effects or whatever you want to do. so you will end up working around ogre3ds shortcomings (it is not a game engine) and implement in on your own or use another middleware. so if you really want to touch 3d rendering first i would take some computer graphics books (gpu gems shaderx) and see some tutorials and demos on the web and start building my own basic framework. this is for the experience and i think you will learn the most from this approach. at least i did ...  If you just want it to work on Windows then DirectX is a good choice. Your first decision will be to look at what is available for both OpenGL and DirectX and decide which will give you more of what you want with less work. If you have an old version of DirectX and don't want to upgrade you may want to use OpenGL but the main reason for the switch is for support on non-windows machines. Since you are using C++ you can pick either option. If you use a library or wrapper it will simplify your life but then you will need to design within the limits of the libraries. You may want to use Lua for much of the top-level parts of your application as that is what WoW is using and then where you need you can go lower-level to limit how much low-level work you need to do. I'm already familiar with Lua and I've used it extensively in the non performance critical parts of my server projects I love it! However I wanted to focus on the actual 3d and rendering engine not the interface so I don't think I will be using it for this project. Then just first decide what requirements you have such as OS and peripheral support as support will differ between OpenGL and DirectX. I decided I'll go with DirectX (at least at first) thanks! Nice choice it comes with so much when you have just installed it. Try to avoid making shapes with individual triangles fans will be your friend. :)  I realize you already accepted an answer but I think this deserves some more comments. Sorry to quote you out of order I'm answering by what I think is important. Instead of creating a 3D engine from scratch I decided to emulate as exactly as I'm able an existing one: World of Warcraft's. However I wanted to focus on the actual 3d and rendering engine not the interface so I don't think I will be using it [lua] for this project. From these two snippets I can tell you that you are not trying to emulate the game engine. Just the 3D rendering backend. It's not the same thing and the rendering backend part is very small part compared to the full game engine. This by the way can help answer one of your questions: World of Warcraft appears to be using both! In fact normally it uses DirectX but you can use opengl by starting it with the ""-opengl"" switch via command line. Yep they implemented both. The amount of work to do that is non-negligeable but the rendering back-end in my experience is at most 10% of the total code usually less. So it's not that outraging to implement multiple ones. More to the point the programming part of a game engine today is not the biggest chunk. It's the asset production that is the bulk (and that includes most game programming. Most lua scripts are considered on that side of things e.g.) For WoW OSX support meant OpenGL. So they did it. They wanted to support older hardware too... So they support DX8-level hardware. That's already 3 backends. I'm not privy to how many they actually implement but it all boils down to what customer base they wanted to reach. Multiple back-ends in a game engine is something that is more or less required to scale to all graphics cards/OSs/platforms. I have not seen a single real game engine that did not support multiple backends (even first party titles tend to support an alternate back-end for debugging purposes). ok that was a long preface.. Now my main question is the following: Should I use DirectX OpenGL wrapper libraries such as sdl or what? Well this depends strongly on what you want to get out of it. I might add that your option list is not quite complete: DirectX9 DirectX10 DirectX11 OpenGL < 3.1 (before deprecated API is removed) OpenGL >= 3.1 OpenGL ES 1.1 (only if you need to. It's not programmable) OpenGL ES 2.0 Yep those APIs are different enough that you need to decide which ones you want to handle. If you want to learn the very basics of 3D rendering any of those can work. OpenGL < 3.1 tends to hide a lot of things that ultimately has to happen in user code for the other ones (e.g. Matrix manipulation see this plug). The DX SDKs do come with a lot of samples that help understand the basic concepts but they also tend to use the latest and greatest features of DX when it's not necessarily required when starting (e.g. using Geometry shader to render sprites...) On the other hand most GL tutorials tend to use features that are essentially non-performant on modern hardware (e.g. glBegin/glEnd selection/picking ... see the list of things that got removed from GL 3.1 or this other plug) and tend to seed the wrong concepts for a lot of things. What's the most used one in the real world? For games DirectX9 is the standard today in PC world. By a far margin. However I'm expecting DirectX11 to grab more market share as it allows for some more multithreaded work. It's unfortunately significantly more complicated than DX9. nobody uses OpenGL anyway (very very few people know about the secret switch at all). Ask the Mac owners what they think. Side question do you really think hardware vendors would spend any energy in OpenGL drivers if this was really the case (I realize I generalize your comment sorry)? there are real world usages of it. Not much in games though. And Apple makes OpenGL more relevant through the iphone (well OpenGL ES really). If it's something usually done do programmers usually create their own 3d engine ""wrapper"" It's usually a full part of the engine design. Mind you it's not abstracting the API at the same level it's usually more at a ""draw this with all its bells and whistles over there"". Which rendering algorithm to apply on that draw tends to be back-end specific. This however is very game engine dependent. If you want to understand better you could look at UE3 it just got released free (beer) for non-commercial use (I have not looked at it yet so I don't know if they exposed the backends but it's worth a look). To get back to my comment that game engine does not just mean 3D look at this. +1 for a very thorough and thoughtful answer! Great answer marked this one as accepted. Thanks ! wow I did not even know you could change the accepted answer after the fact.  I think the primary benefit of using OpenGL over DirectX is the portability. DirectX only runs on windows. However this is often not a problem (many games only run on Windows). DirectX also provides other libraries which are useful for games which are unrelated to graphics such as sound and input. I believe there are equivalents which are often used with OpenGL but I don't think they're actually part of OpenGL itself. If you're going to be locking into windows with DirectX and you are willing to/interested in learning C# and managed code I have found XNA to be and extremely easy platform to learn. It allows you to learn most of the concepts without dealing with a lot of the really tricky details of DirectX (or OpenGL). You can still use shader code and have the full power of DirectX but in a much friendlier environment. It would be my recomendation but again you'd have to switch to C# (mind you you can also put that on you're resume). DirectX no longer supports C#: http://social.msdn.microsoft.com/Forums/en-US/gametechnologiesdirectx101/thread/e9f458e0-65c6-4936-9af4-4276fc92f111. The last version I used with support was 9.0c Huge +1 for XNA given the askers background and future applicability of the technology True you cannot program DirectX directly with C# however XNA is a C# library which uses DirectX underneath. It is not the same as DirectX and is very much in use today version 3.0 just came out recently.  I'm doing some OpenGL work right now (on both Windows and Mac). Compared to my midnight game programming using the Unity3D engine usingOpenGL is a bit like having to chop down your own trees to make a house versus buying the materials. Unity3D runs on everything (Mac PC and iPhone Web player etc) and lets you concentrate on the what makes a game a game. To top it off it's faster than anything I could write. You code for it in C# Java or Boo. I just used Unity to mock up a demo for a client who wants something made in OpenGL so it has it's real world uses also. -Chris PS: The Unity Indie version recently became free. A little correction: You can program in Javascript not Java! :-)",c++ opengl directx sdl944665,A,"Designing a Qt + OpenGL application in Eclipse I'm starting a C++ project using OpenGL and Qt for the UI in eclipse. I would like to create a UI where a portion of the window contains a frame for OpenGL rendering and the rest would contain other Qt widgets such as buttons and so on. I haven't used Qt or the GUI editor in eclipse before and I'm wondering what the best approach would be? Should I create the UI by hand coding or would it be easier to use eclipse's GUI designer - I had a quick look at this and there doesn't seem to be an OpenGL widget built in. Thanks any particular aversion to QtCreator? This might be handy http://doc.trolltech.com/4.5/qtopengl.html If you are using Qt Designer (which I think is available via Eclipse Integration) you can place a base QWidget in the layout and then ""promote"" that widget to a QGLWidget. To do this: Add the QWidget to the desired place in the layout Right-click on the widget Select ""Promote To"" Enter QGLWidget as the class name and as the header Hit Add Select the QGLWidget from the list of promoted widgets at the top of the dialog Hit Promote This way you don't have to go through the placeholder route and create an additional layer. Thanks. That was just what I was after :-)  I had the same problem while using Qt Designer. I used a simple frame as a placeholder for the OpenGL widget then in main window constructor I created OpenGL widget manually and assigned it to the placeholder frame (as a child). The main advantage here is that you see where the OpenGL widget should be while designing your interface. The main disadvantage is that some coding is still required to set up the GUI.  Why won't you use Qt Eclipse Integration? It works flawlessly enables you to edit UIs directly from Eclipse. i am using that...",c++ eclipse gui qt opengl538810,A,How do I get the current mouse position in C++ / OpenGL? I know that I can use a Mouse callback function for when a user clicks the mouse but what if I want to know the current x/y position without the user clicking? Will I have to use a different callback that gets called on any mouse movement and keep track of the x/y myself or is there a function I can call within GLUT/OpenGL to get it? This is more related to glut than OpenGL. Things like mouse position are usually handled by the OS and have little to do with either OpenGL or C++. Register a glutPassiveMotionFunc callback function See info about callbacks @crashmstr Now? It is working now.  You need to use the glutMotionFunc/glutPassiveMotionFunc callback to track mouse movement independent of mouse clicks. 7.6 glutMotionFunc glutPassiveMotionFunc,c++ opengl mouse glut679210,A,How can I use a dynamically sized texture array with glTexImage2D? Currently I'm able to load in a static sized texture which I have created. In this case it's 512 x 512. This code is from the header: #define TEXTURE_WIDTH 512 #define TEXTURE_HEIGHT 512 GLubyte textureArray[TEXTURE_HEIGHT][TEXTURE_WIDTH][4]; Here's the usage of glTexImage2D: glTexImage2D( GL_TEXTURE_2D 0 GL_RGBA TEXTURE_WIDTH TEXTURE_HEIGHT 0 GL_RGBA GL_UNSIGNED_BYTE textureArray); And here's how I'm populating the array (rough example not exact copy from my code): for (int i = 0; i < getTexturePixelCount(); i++) { textureArray[column][row][0] = (GLubyte)pixelValue1; textureArray[column][row][1] = (GLubyte)pixelValue2; textureArray[column][row][2] = (GLubyte)pixelValue3; textureArray[column][row][3] = (GLubyte)pixelValue4; } How do I change that so that there's no need for TEXTURE_WIDTH and TEXTURE_HEIGHT? Perhaps I could use a pointer style array and dynamically allocate the memory... Edit: I think I see the problem in C++ it can't really be done. The work around as pointed out by Budric is to use a single dimensional array but use all 3 dimensions multiplied to represent what would be the indexes: GLbyte *array = new GLbyte[xMax * yMax * zMax]; And to access for example x/y/z of 1/2/3 you'd need to do: GLbyte byte = array[1 * 2 * 3]; However the problem is I don't think the glTexImage2D function supports this. Can anyone think of a workaround that would work with this OpenGL function? Edit 2: Attention OpenGL developers this can be overcome by using a single dimensional array of pixels... [0]: column 0 > [1]: row 0 > [2]: channel 0 ... n > [n]: row 1 ... n > [n]: column 1 .. n ... no need to use a 3 dimensional array. In this case I've had to use this work around as 3 dimensional arrays are apparently not strictly possible in C++. You don't simply multiply the indices. It's (rowIndex * numColumns * numColourComponents + columnIndex + colourComponent); Oops. Should be (rowIndex * numColumns * numColourComponents + columnIndex*numColourComponents + colourComponent); You could always wrap it up in a class. If you are loading the image from a file you get the height and width out with the rest of the data (how else could you use the file?) you could store them in a class that wraps the file loading instead of using preprocessor defines. Something like: class ImageLoader { ... ImageLoader(const char* filename ...); ... int GetHeight(); int GetWidth(); void* GetDataPointer(); ... }; Even better you could hide the function calls to glTexImage2d in there with it. class GLImageLoader { ... ImageLoader(const char* filename ...); ... GLuint LoadToTexture2D(); // returns texture id ... };  Ok since this took me ages to figure this out here it is: My task was to implement the example from the OpenGL Red Book (9-1 p373 5th Ed.) with a dynamic texture array. The example uses: static GLubyte checkImage[checkImageHeight][checkImageWidth][4]; Trying to allocate a 3-dimensional array as you would guess won't do the job. Someth. like this does NOT work: GLubyte***checkImage; checkImage = new GLubyte**[HEIGHT]; for (int i = 0; i < HEIGHT; ++i) { checkImage[i] = new GLubyte*[WIDTH]; for (int j = 0; j < WIDTH; ++j) checkImage[i][j] = new GLubyte[DEPTH]; } You have to use a one dimensional array: unsigned int depth = 4; GLubyte *checkImage = new GLubyte[height * width * depth]; You can access the elements using this loops: for(unsigned int ix = 0; ix < height; ++ix) { for(unsigned int iy = 0; iy < width; ++iy) { int c = (((ix&0x8) == 0) ^ ((iy&0x8)) == 0) * 255; checkImage[ix * width * depth + iy * depth + 0] = c; //red checkImage[ix * width * depth + iy * depth + 1] = c; //green checkImage[ix * width * depth + iy * depth + 2] = c; //blue checkImage[ix * width * depth + iy * depth + 3] = 255; //alpha } } Don't forget to delete it properly: delete [] checkImage; Hope this helps... +1 for putting so much effort in to a 3 year old question. Helped me out too ! SO take my vote...This is one of those little intricacies of OpenGL  You can use int width = 1024; int height = 1024; GLubyte * texture = new GLubyte[4*width*height]; ... glTexImage2D( GL_TEXTURE_2D 0 GL_RGBA width height 0 GL_RGBA GL_UNSIGNED_BYTE textureArray); delete [] texture; //remove the un-needed local copy of the texture; However you still need to specify the width and height to OpenGL in glTexImage2D call. This call copies texture data and that data is managed by OpenGL. You can delete resize change your original texture array all you want and it won't make a different to the texture you specified to OpenGL. Edit: C/C++ deals with only 1 dimensional arrays. The fact that you can do texture[a][b] is hidden and converted by the compiler at compile time. The compiler must know the number of columns and will do texture[a*cols + b]. Use a class to hide the allocation access to the texture. For academic purposes if you really want dynamic multi dimensional arrays the following should work: int rows = 16 cols = 16; char * storage = new char[rows * cols]; char ** accessor2D = new char *[rows]; for (int i = 0; i < rows; i++) { accessor2D[i] = storage + i*cols; } accessor2D[5][5] = 2; assert(storage[5*cols + 5] == accessor2D[5][5]); delete [] accessor2D; delete [] storage; Notice that in all the cases I'm using 1D arrays. They are just arrays of pointers and array of pointers to pointers. There's memory overhead to this. Also this is done for 2D array without colour components. For 3D dereferencing this gets really messy. Don't use this in your code. @Budric my array needs to have 3 dimensions not 2. I'm accessing it in the style of texture[column][row][channel] Hmm this would work only when assigning values to the array I get this error: invalid types Š—…unsigned char[int]Š—È for array subscript Are you using texture[i][j]? You can't use that with the code above. texture[row * width + column].,c++ opengl glteximage2d1569939,A,Rendering different triangle types and triangle fans using vertex buffer objects? (OpenGL) About half of my meshes are using triangles another half using triangle fans. I'd like to offload these into a vertex buffer object but I'm not quite sure how to do this. The triangle fans all have a different number of vertices... for example one might have 5 and another 7. VBO's are fairly straight forward using plain triangles however I'm not sure how to use them with triangle fans or with different triangle types. I'm fairly sure I need an index buffer but I'm not quite sure what I need to do this. I know how many vertices make up each fan during run time... I'm thinking I can use that to call something like glArrayElement Any help here would be much appreciated! VBOs and index buffers are an orthogonal things. If you're not using index buffers yet maybe it is wiser to move one step at a time. So... regarding your question. If you put all your triangle fans in a vbo the only thing you need to draw them is to setup your vbo and pass the index in it for your fan start  glBindBuffer(GL_VERTEX_BUFFER buffer); glVertexPointer(3 GL_FLOAT 0 NULL); // 3 floats per vertex for each i in fans glDrawArrays(GL_TRIANGLE_FAN indef_of_first_vertex_for_fan[i] fan_vertex_count[i]) Edit: I'd have to say that you're probably better off transforming your fans to a regular triangle set and use glDrawArrays(GL_TRIANGLES) for all your triangles. A call per primitive is rarely efficient. Well if you have 200K triangle fans then you have that many calls **per frame**. Think about the cost compared to some load-time (or better off-line process time) that's required to transform the fans to triangles. sun proposed an extension because this was too much of an overhead *10 years ago*. The overhead/intersting work ratio only increased since. http://www.opengl.org/registry/specs/SUN/triangle_list.txt To be complete I should add that [primitive restart](http://www.opengl.org/registry/specs/NV/primitive_restart.txt) is an extension that you could be using as well (but requires indexing of your primitives which you should look at anyways). [glMultiDrawArrays](http://www.opengl.org/sdk/docs/man/xhtml/glMultiDrawArrays.xml) is yet another attempt at reducing the overhead but is rarely actually optimized in the drivers. Bahbar Thanks for the tip! I had read about transforming the fans into triangles... However I might have 200000 triangle fan primitives. Granted I'd only need to do this once so in your opinion is it cheaper to transform them and then do glDrawArrays or should I just do the call for each prim? Thanks Good stuff thanks man. It is so hard to find good examples/documentation of this kind of stuff,c++ opengl graphics 3d vertex-buffer1977737,A,"OpenGL Rotations around World Origin when they should be around Local Origin I'm implementing a simple camera system in OpenGL. I set up gluPerspective under the projection matrix and then use gluLookAt on the ModelView matrix. After this I have my main render loop which checks for keyboard events and if any of the arrow keys are pressed modifies angular and forward speeds (I only rotate through the y axis and move through the z (forwards)). Then I move the view using the following code (deltaTime is the amount of time since the last frame was rendered in seconds in order to decouple movement from framerate): //place our camera newTime = RunTime(); //get the time since app start deltaTime = newTime - time; //get the time since the last frame was rendered time = newTime; glRotatef(view.angularSpeed*deltaTime010); //rotate glTranslatef(00view.forwardSpeed*deltaTime); //move forwards //draw our vertices draw(); //swap buffers Swap_Buffers(); Then the code loops around again. My draw algorithm begins with a glPushMatrix() and ends in a glPopMatrix(). Each call to glRotatef() and glTranslatef() pushes the view forwards by the forwards speed in the direction of view. However when I run the code my object is drawn in the correct place but when I move the movement is done with the orientation of the world origin (000 - facing along the Z axis) as opposed to the local orientation (where I'm pointing) and when I rotate the rotation is done about (000) and not the position of the camera. I end up with this strange effect of my camera orbiting (000) as opposed to rotating on the spot. I do not call glLoadIdentity() at all anywhere inside the loop and I am sure that the Matrix Mode is set to GL_MODELVIEW for the entire loop. Another odd effect is if I put a glLoadIdentity() call inside the draw() function (between the PushMatrix and PopMatrix calls the screen just goes black and no matter where I look I can't find the object I draw. Does anybody know what I've messed up in order to make this orbit (000) instead of rotate on the spot? Thanks in advance for all of your help Please put code into code tags! glRotate() rotates the ModelView Matrix around the World Origin so to rotate around some arbitrary point you need to translate your matrix to have that point at the origin rotate and then translate back to where you started. I think what you need is this float x y z;//point you want to rotate around glTranslatef(00view.forwardSpeed*deltaTime); //move forwards glTranslatef(xyz); //translate to origin glRotatef(view.angularSpeed*deltaTime010); //rotate glTranslatef(-x-y-z); //translate back //draw our vertices draw(); //swap buffers Swap_Buffers(); Note that the comments on the 2nd and 3rd glTranslatef() calls are incorrect. They should be ""translate to origin"" and ""translate from origin"" respectively. Good catch! Thanks  Swap your rotate and translate calls around :) Since they post-multiply the matrix stack the last the be called is the 'first' to be applied conceptually if you care about that sort of thing. I tried that but it just gives the same effect. Since the rotate and translate calls all have such minute values in them and since they stack on top of each other as the while loop iterates there is little difference in their application order. Oh all your transformations are relative! If you reset the camera position each time (glLoadIdentity()) and do an absolute translation and rotation each time then things should work :)  I think you first have to translate your camera to point (000) then rotate then translate it back.",c++ opengl matrix rotation transform1135901,A,"Windows message loop Theres some reason for this code not reach the first else? I got it exactly the same from vairous sources. Than I did my own encapsulation. Everything goes fine. Window is created messages are treated events are generated to keyborad input in the client area the gl canvas works fine (when I force it to draw). The only problem is that message loop never leaves the first if. :/ I'm really stuck. while (!done) { if (::PeekMessage (&msg NULL 0 0 PM_REMOVE)) { if (msg.message == WM_QUIT) { done = TRUE; } else { ::TranslateMessage (&msg); ::DispatchMessage (&msg); } } else { // Code is never reaching this! draw (); ::SwapBuffers(hDC); idle (); } } return msg.wParam; Obviously something it posting new messages into the queue while Translate/Dispatch is done. You should just list all messages retrieved and deduce what message it is and why it appears. Using spy i got a hard flow of WM_PAINT with hdc 0. No idea how this is being generated. In your case the message queue must never be empty - why? Well it depends on what the rest of your program is doing. Some possibilities: Your code is posting new messages to the queue in a manner such that the queue doesn't get empty. I'd suggest logging out the message ids as they are handled. You aren't handling paint messages - from msdn: ""The PeekMessage function normally does not remove WM_PAINT messages from the queue. WM_PAINT messages remain in the queue until they are processed. However if a WM_PAINT message has a NULL update region PeekMessage does remove it from the queue."" Hope this helps. [Edit] To handle WM_PAINT either call BeginPaint and EndPaint or forward to DefWindowProc looks like you can also do it by forwarding wm_paint to DefWindowProc but it probably does the same thing looks like thats the problem. But the my MainWndProc is returning 0 from WM_PAINT. What I know is that every message you treat you return 0. So in theory no message should be left. He's handling WM_PAINT because he's seeing things appearing. Added this code and it start to work as expected. But would like to have some explanation if possible please. case WM_PAINT: BeginPaint(hwnd &ps); EndPaint(hwnd &ps); return 0; WM_PAINT isn't a real message - it's just a flag on the window that says it has invalidated regions (WM_PAINT never handled.) As long as that flag is present WM_PAINT will be generated. there isnt another way to acomplish that? looks like this will just add more processing to my program instead if just discard the message.  PeekMessage will return 0 only if there are no messages in the message queue. Since there are messages to be dispatched in the message queue it is returning a non-zero value and your else condition is never executed. I guess he is asking about this - why doesn't it ever happen that there're no messages left.  Make sure you are processing the WM_PAINT correctly. By this I mean make sure you are calling BeginPaint and EndPaint from inside the WM_PAINT message otherwise you will be confusing Windows into thinking your application still needs to be painted.  May be there is always a message waiting ? If you have a new question please ask it by clicking the [Ask Question](http://stackoverflow.com/questions/ask) button. Include a link to this question if it helps provide context.",c++ winapi opengl363302,A,openGL textures that are not 2^x in dimention I'm trying to display a picture in an openGL environment. The picture's origninal dimensions are 3648x2432 and I want to display it with a 256x384 image. The problem is 384 is not a power of 2 and when I try to display it it looks stretched. How can I fix that? If GL_EXT_texture_rectangle is true then use GL_TEXTURE_RECTANGLE_EXT for the first param in glEnable() and GLBindTexture() calls.  You can resize your texture so it is a power of two (skew your texture so that when it is mapped onto the object it looks correct). I am under the impression that textures are always a power of two because the hardware would use the same amount of resources anyways. But I could be incorrect. Yes this is incorrect in modern hardware.  There's three ways of doing this that I know of - The one Albert suggested (resize it until it fits). Subdivide the texture into 2**n-sized rectangles and piece them together in some way. See if you can use GL_ARB_texture_non_power_of_two. It's probably best to avoid it though since it looks like it's an Xorg-specific extension. Option 2 is great - prevents loss of fidelity  ARB_texture_rectangle is probably what you're looking for. It lets you bind to GL_TEXTURE_RECTANGLE_ARB instead of GL_TEXTURE_2D and you can load an image with non power-of-2 dimensions. Be aware that your texture coordinates will range from [0..w]x[0..h] instead of [0..1]x[0..1].,c++ opengl ldf1095378,A,"How do I destruct data associated with an object after the object no longer exists? I'm creating a class (say C) that associates data (say D) with an object (say O). When O is destructed O will notify C that it soon will no longer exist :( ... Later when C feels it is the right time C will let go of what belonged to O namely D. If D can be any type of object what's the best way for C to be able to execute ""delete D;""? And what if D is an array of objects? My solution is to have D derive from a base class that C has knowledge of. When the time comes C calls delete on a pointer to the base class. I've also considered storing void pointers and calling delete but I found out that's undefined behavior and doesn't call D's destructor. I considered that templates could be a novel solution but I couldn't work that idea out. Here's what I have so far for C minus some details:  // This class is C in the above description. There may be many instances of C. class Context { public: // D will inherit from this class class Data { public: virtual ~Data() {} }; Context(); ~Context(); // Associates an owner (O) with its data (D) void add(const void* owner Data* data); // O calls this when he knows its the end (O's destructor). // All instances of C are now aware that O is gone and its time to get rid // of all associated instances of D. static void purge (const void* owner); // This is called periodically in the application. It checks whether // O has called purge and calls ""delete D;"" void refresh(); // Side note: sometimes O needs access to D Data *get (const void *owner); private: // Used for mapping owners (O) to data (D) std::map _data; }; // Here's an example of O class Mesh { public: ~Mesh() { Context::purge(this); } void init(Context& c) const { Data* data = new Data; // GL initialization here c.add(this new Data); } void render(Context& c) const { Data* data = c.get(this); } private: // And here's an example of D struct Data : public Context::Data { ~Data() { glDeleteBuffers(1 &vbo); glDeleteTextures(1 &texture); } GLint vbo; GLint texture; }; }; P.S. If you're familiar with computer graphics and VR I'm creating a class that separates an object's per-context data (e.g. OpenGL VBO IDs) from its per-application data (e.g. an array of vertices) and frees the per-context data at the appropriate time (when the matching rendering context is current). So if I understand correctly you want reference counting? Thanks all. In my program there is an update thread and a render thread. The render thread is responsible for rendering twice once for each eye to create a stereo image. Each 3D object O has eye-specific rendering data D for each context (i.e. for each O there are two copies of D). The problem: O can be created or destroyed in the update thread but O's eye-specific rendering data must be destroyed in the render thread and only when rendering the associated eye. C needs to know if O is destructed so that in the render thread it will know to destroy both instances of D. The question is rather vague on the requirements so it's hard to give a good concrete answer. I hope the following helps. If you want the data to disappear immediately when its owner dies have the owner delete it (and notify C if the C instances need to know). If you want C to do the deletion at its leisure your solution looks fine. Deriving from Data seems to me the right thing to do. (Of course it is crucial that ~Data() be virtual as you have done.) What if D is an array of objects? There are two interpretations of this question. If you mean that D is always an array let it be an array (or vector<>) of pointers to Data. Then in C::purge() walk the vector and delete the objects. If you mean that D could be an array of objects but could also be a single object there are two ways to go. Either decide that it is always an array (possibly of size 1) or that it is a single object (derived from Data) which can be a class wrapping the array of the actual objects (or pointers to them). In the latter case the wrapper class destructor should walk the array and do the deletions. Note that if you want the array (or vector<>) to contains the actual objects not pointers to them (in which case you won't have to walk the array and delete manually) then you'll have the following limitations. 1. All objects in the array will have to be of the same actual type. 2. You will have to declare the array to be of that type. This will lose you all the benfits of polymorphism.  To answer the question ""What if D is an array of objects ?"" I'd suggest a vector<> but you'd have to associate it with D:  struct D_vector :D { vector<whatever> vw; };  What you're looking for is Boost::shared_ptr or some similar smart-pointer system.",c++ opengl graphics723762,A,"Programs causing static noise in speakers? Does anyone know a reason why my programs could be causing my speakers to output some soft static? The programs themselves don't have a single element that outputs sound to anything yet when I run a few of my programs I can hear a static coming from my speakers. It even gets louder when I run certain programs. Moving the speakers around doesn't help so it must be coming from inside the computer. I'm not sure what other details to put down since this seems very odd. They are OpenGL programs written in C++ with MS Visual C++. Edit: It seems to be that swapping the framebuffers inside an infinite loop is making the noise as when I stop swapping I get silence... I get exactly the same thing with a number of programs - particularly with ObjectDock (a Mac Dock imitation for Windows) - but only when I move my mouse if the cursor is over the dock. Quite strange. I don't know if ObjectDock is supposed to do that - seems weird that it would. Since you say you don't touch sound in your programs I doubt it's your code doing this. Does it occur if you run any other graphics-intensive programs? Also what happens if you mute various channels in the mixer (sndvol32.exe on 32-bit windows)? Not knowing anything else I'd venture a guess that it could be related to the fan on your graphics card. If your programs cause the fan to turn on and it's either close to your sound card or the fan's power line crosses an audio cable it could cause some static. Try moving any audio cables as far as possible from the fan and power cables and see what happens. It could also be picking up static from a number of other sources and I wouldn't say it's necessarily unusual. If non-graphics-intensive programs cause this as well it could be hard-disk access or even certain frequencies of CPU/power usage being picked up on an audio line like an antenna. You can also try to reduce the number of loops in your audio wires and see if it helps but no guarantees. I opened Sim City muted game sounds and I heard the same static. I guess I never noticed because I always play with sound. =/ Turns out it was some power wires hanging over my sound card. I moved them and silence!  Most electronic devices give off some kind of electromagnetic interference. Your speakers or sound hardware may be picking up something as simple as the signaling on your video cable or the graphics card itself. Cheap speakers and poorly-protected audio devices tend to be fairly sensitive to this kind of radiation in my experience.  There is interference on your motherboard that is leaking onto your sound bus. This is usually because of the quality of your motherboard or the age of it. Also the layout of the equipment inside your computer (close together over lapping) often will make interesting EM fields. My old laptop used to do this a lot easier as it got older. So as things are winding up or down you'll hear it. Try to see if it happens on a different computer. Try different computers of different ages and different configurations (external soundcard or a physical sound card etc). Hope that helps.  Computers consume a different amount of power when executing code. This fluctuation of current acts like a RF transmitter and can be picked up by audio equipment and it will be essentially ""decoded"" much like a AM modulated signal. As the execution usually does not produce a recognizable signal it sounds like white noise. A good example of audio equippment picking up a RF signal is if you hold your (GSM) cell phone close to an audio amplifier when receiving a call. You most likely will hear a characteristic pumping buzz from the cell phone's transmitter. Go here to learn more about Electromagnetic compatibility. There are multiple ways a signal can couple into your audio. As you mentioned a power cord to be the source it was most likely magnetic inductive coupling. This is exactly what it is. You either need better sheilding on your cables/speakers or on your computer. If your PC case is plastic it won't block any RF generated from within. If the case is steel it acts like a Faraday Cage. I don't think thats the reason. The current level is too low in the circuits to cause audible sound. Also there is no system in the computer which is built to catch RF frequency. This noise should be generated by actually getting a electric signal.  :) You will be surprised to know that the speaker input is picking up static from the hard disk. When you do something memory/disk intensive (like swapping framebuffers) so that the hard disk has to rotate fast the sound will appear. I had the same problem some years back I solved it too. But I am sorry that I don't remember how I did it. Hope the diagnosis helps in remedying the problem. UPDATE: I remembered. If you are using Windows go to volume control and mute all the external inputs/outputs like CD input etc. Just keep the two basic ones.  Crappy audio hardware on motherboards especially the ones that end up in office PCs. The interior of a PC case is full of electrical noise. If that couples to the audio hardware you'll hear it. Solution: Get a pair of headphones with a volume control on the cord. Turn the volume on the headphones down and turn the volume on the PC up full. This will increase the signal level relative to the noise level in most cases.  tempest dvbt",c++ opengl audio665688,A,"Is stereoscopy (3D stereo) making a come back? I'm working on a stereoscopy application in C++ and OpenGL (for medical image visualization). From what I understand the technology was quite big news about 10 years ago but it seems to have died down since. Now many companies seem to be investing in the technology... Including nVidia it would seem. Stereoscopy is also known as ""3D Stereo"" primarily by nVidia (I think). Does anyone see stereoscopy as a major technology in terms of how we visualize things? I'm talking in both a recreational and professional capacity. With nVidia's 3D kit you don't need to ""make a stereoscopy application"" drivers and video card take care of that. 10 years ago there was good quality stereoscopy with polarized glasses and extremely expensive monitors and low quality stereoscopy with red/cyan glasses. What you have now is both cheap and good quality. Right now all you need is 120Hz LCD entry level graphics card and $100 shutter glasses. So no doubt about it it will be the next big thing. At least in entertainment. I'm struggling to find a 120Hz LCD... Could someone name a few brands or models? Ones explicitly named by Nvidia: Samsung SyncMaster 2233RZ and ViewSonic FuHzion VX2265wm. I'm sure there are more. It's a bit hard to find them though as refresh Hz it's not something that's important LCD spec so most don't even specify this. Ah interesting. I was under the impression that 120Hz LCDs weren't available - perhaps I've been living in the past with the CRT sitting on my desk. Could you point me in the right direction? For example Nvidia bundles it's kit with Samsung SyncMaster 2233RZ. Sony sales 200Hz LCD Bravia Z since last year. 120Hz LCD is pretty much standard now. http://en.wikipedia.org/wiki/Motion_interpolation BTW. You're serious about having CRT on your desk? Wow! Haha yes I'd read in so many places that LCD doesn't support over 80Hz and I believed it since that appeared to be common knowledge; I guess all the material I read must have been ancient and defunct. As a result of this I bought a CRT. Now I feel a little embarrassed! I bought it about 2 years ago mind. Since when has >80Hz been around? Well it was true about 2 years ago. The thing is that fast LCD are TN which don't give you colors as rich as IPS or VA. BTW. most entry level LCD still are 60Hz although as long as you don't need stereoscopy it doesn't really mater. @Zeus one for each eye perfect for stereoscopy ;-) @vartec - I have 2 crt's on my desk :(  Enthusiasm for stereo display seems to come and go in cycles of hype and disappointment (e.g cinema). I don't expect TV and PCs will be any different. For medical visualisation if it was that useful there would be armies of clinicians sitting in front of expensive displays wearing shutter glasses already. Big hint: there aren't. And that market doesn't need 3D display tech to reach ""impulse purchase"" pricing levels as an enabler. You make a very good point. Actually in the medical field stereo 3D is quickly gaining popularity and is actively being used in multiple practices including robotics and surgery. For example with the DaVinci robot surgeons perform cases every day using a 3D display to operate with and the technicians moving tools in and out of the robot/person's body (using a monitor) don't want to push anything too far into the patient and stab them. Normally the robot would prevent you from doing this but it tends to malfunction and people just turn it off. So the need for depth perception is very important.  One reason why it is probably coming back is due to the fact that we know have screens with high enough refreshrate so that 3D is possible. I think I read that you will need somewhere around 100Hz for 3D-TV. So no need for bulky glasses anymore. Edit: To reiterate: You no longer need glasses in order to have 3D TV. This article was posted in a swedish magazine a few weeks ago: http://www.nyteknik.se/nyheter/it_telekom/tv/article510136.ece. What it says is basically that instead of glasses you use a technique with vertical lenses on the screen. Problem with CRT is that they are not flat. Our more modern flat screens obviously hasn't got this problem. The second problem is that you need high frequency (at least 100 Hz as that makes the eye get 50 frames per second) and a lot of pixels since each eye only gets half the pixels. TV sets that support 3D without glasses have been sold by various companies since 2005. It seems to me that 3D TVs are still quite rare I remember when Sharp tried this but I haven't really seen that product recently (I think they stopped marketing it) - I think Zalman do one right? Who else does them? What's the marketing keyword used most ""3D TV""? Zalman does ones that use polarization the 120Hz thing is based shutter glasses. The 3D-without-glasses displays are technically known as ""autosteroscopic"". I've seen the Philips one and it's quite impressive (as a tradeshow gimmick anyway).",c++ opengl nvidia stereo-3d stereoscopy327642,A,"OpenGL and monochrome texture Is it possible to pump monochrome (graphical data with 1 bit image depth) texture into OpenGL? I'm currently using this: glTexImage2D( GL_TEXTURE_2D 0 1 game->width game->height 0 GL_LUMINANCE GL_UNSIGNED_BYTE game->culture[game->phase] ); I'm pumping it with square array of 8 bit unsigned integers in GL_LUMINANCE mode (one 8 bit channel represents brightness of all 3 channels and full alpha) but it is IMO vastly ineffective because the onlu values in the array are 0x00 and 0xFF. Can I (and how) use simple one-bit per pixel array of booleans instead somehow? The excessive array size slows down any other operations on the array :( After some research I was able to render the 1-bit per pixel image as a texture with the following code: static GLubyte smiley[] = /* 16x16 smiley face */ { 0x03 0xc0 /* **** */ 0x0f 0xf0 /* ******** */ 0x1e 0x78 /* **** **** */ 0x39 0x9c /* *** ** *** */ 0x77 0xee /* *** ****** *** */ 0x6f 0xf6 /* ** ******** ** */ 0xff 0xff /* **************** */ 0xff 0xff /* **************** */ 0xff 0xff /* **************** */ 0xff 0xff /* **************** */ 0x73 0xce /* *** **** *** */ 0x73 0xce /* *** **** *** */ 0x3f 0xfc /* ************ */ 0x1f 0xf8 /* ********** */ 0x0f 0xf0 /* ******** */ 0x03 0xc0 /* **** */ }; float index[] = {0.0 1.0}; glPixelStorei(GL_UNPACK_ALIGNMENT1); glPixelMapfv(GL_PIXEL_MAP_I_TO_R 2 index); glPixelMapfv(GL_PIXEL_MAP_I_TO_G 2 index); glPixelMapfv(GL_PIXEL_MAP_I_TO_B 2 index); glPixelMapfv(GL_PIXEL_MAP_I_TO_A 2 index); glTexImage2D(GL_TEXTURE_2D0GL_RGBA16160GL_COLOR_INDEXGL_BITMAPsmiley); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_LINEAR); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_LINEAR); and here is the result: Nice! Have you compared its performance to the 1 byte per pixel variant? I found swapping the internal format to `LUMINANCE` produces the same visuals with a quarter the memory. If there are any formats smaller I would be interested. Idk how to get S3TC formats. I don't think pyOpenGL has those extensions. It does not appear that you can clamp this texture without it changing shape. I was just trying to get rid of the cross border bleeding.  The smallest uncompressed texture-format for luminance images uses 8 bits per pixel. However 1 bit per pixel images can be compressed without loss to the S3TC or DXT format. This will still not be 1 bit per pixel but somewhere between 2 and 3 bits. If you really need 1 bit per pixel you can do so with a little trick. Load 8 1 bit per pixel textures as one 8 bit Alpha-only texture (image 1 gets loaded into bit 1 image 2 into bit 2 and so on). Once you've done that you can ""address"" each of the sub-textures using the alpha-test feature and a bit of texture environment programming to turn alpha into a color. This will of only work if you have 8 1 bit per pixel textures and tricky to get right though. The 8 textures trick sounds interesting but it is not really what I am looking for. I'm using the OpenGL to visualize data from my application so such trick would slow down standard operation on the array (not speaking of programming complications).",c++ opengl textures791687,A,OpenGL: glTexImage2D conflicts with glGenLists & glCallList? I have a simple OpenGL application where I have 2 objects displayed on screen: 1) particle system where each particle is texture mapped with glTexImage2D() call. In the drawEvent function I draw it as a GL_TRIANGLE_STRIP with 4 glVertex3f. 2) a 3D text loaded from an object file where each point is loaded using glNewList/glGenLists and store each point as glVertex. I draw it by making call to glCallList. The problem is as soon as I call glTexImage2D() to map my particle with a .bmp file the 3D text would not show on the screen. The particle would look fine. (this is not expected) If I dont call glTexImage2D I see both the 3D text and particle system. In this case particle system looks horrible because I didnt texture map with anything. (this is expected) Does anyone know why using call list and glTexImage2D might conflict with each other? EDIT i also forgot to mention: I do call glBindTexture(GL_TEXTURE_2D this->texture); inside the drawLoop before particle system is called. EDIT2 i only call glTexImage2D() once at system start up (when I texture mapped the bitmap) glTexImage2D uploads the texture to the video-ram (simplified said). If OpenGL would allow you to place a glTexImage2D call inside the list it had to store the pixel-data in the list as well. Now what happends if you would execute the list? You would upload the same image data into the same texture all over gain. That makes no sense therefore it's left out. If you want to change textures between draw calls use glBindTexure. That call sets the current texture. It's much faster. Regarding your image-upload via glTexImage2D: Do that only once for each texture. Either at the start of your program (if it's small) or each time you load new content from disk. hi nils..yes i only call glTextImage2D once (at the start of the program) if you do so why do you want to put it into a list? hi..i'm sorry i dont explain clearly. i put all of my 3D fonts into a list. for particle system i use glGenTextures(1 &this->texture); glBindTexture(GL_TEXTURE_2D this->texture); glTexParameterf(GL_TEXTURE_2DGL_TEXTURE_WRAP_S GL_REPEAT); glTexParameterf(GL_TEXTURE_2DGL_TEXTURE_WRAP_T GL_REPEAT); glTexParameterf(GL_TEXTURE_2DGL_TEXTURE_MAG_FILTER GL_LINEAR); glTexParameterf(GL_TEXTURE_2DGL_TEXTURE_MIN_FILTER GL_LINEAR);  I already solve this problem. Before use GL_TEXTURE_2D you need set enable function=> glEnable(GL_TEXTURE_2D); And before use glCallList you also need set disable function => glDisable(GL_TEXTURE_2D);  It might not be a conflict of glTexImage2D and glCallList at all. Is your texture mapping ok ? have you set the texture coordinates propperly? Try checking for a vertex to texture coordinates missmatch. texture mapping looks ok for my particle system. the two when instantiated independently work fine. it's only when i to have them both displayed on the same screen it doesnt work.,c++ c opengl1626081,A,"OpenGL - Textures loading improperly UPDATE: I've posted the Renderer code below since this code here doesn't seem to be the problem. I'm having a problem with some code of mine where when I try to upload multiple textures to openGL one at a time it fails somewhat spectacularly with the renderer only ending up using a single texture. I've done a bit of debugging to trace the error to this function but I'm having problems figuring out what part of the function is at fault. Are there are particularly obvious screwups I'm making that I'm simply not seeing or is there a more subtle flaw in my code? Here're the structs I use for storing texture information and generally just keeping track of all my pointers typedef struct { float Width; float Height; } texInfo; typedef struct { dshlib::utfstr ResourceName; texInfo * TextureInfo; GLuint TextureNum; SDL_Surface * Image; } texCacheItem; And here's the current WIP graphics loader. Basically it loads a named .png file out of a .zip archive using a prewritten library (incidentally it's being tested with this program). Then it's loaded with libpng and then loaded up as a texture with caching thrown in to speed loading up and avoid loading a single texture more than once. I omitted the #include statements since they were just cruft. texCacheItem * loadGraphics(dshlib::utfstr FileName) { for(int i = 0; i < NumTexCached; i++) { //First see if this texture has already been loaded if(TextureCache[i]->ResourceName == FileName) return TextureCache[i]; } dshlib::utfstr FullFileName = ""Data/Graphics/""; //If not create the full file path in the archive FullFileName += FileName; dshlib::FilePtr file = resourceCtr.OpenFile(FullFileName); //And open the file if (!file->IsOk()) { //If the file failed to load... EngineState = ENGINESTATE_ERR; return NULL; } SDL_Surface * T = loadPNG(file); texCacheItem * Texture = new texCacheItem; Texture->TextureInfo = new texInfo; glGenTextures(1 &Texture->TextureNum); //Allocate one more texture and save the name to the texCacheItem glBindTexture(GL_TEXTURE_2D Texture->TextureNum); //Then create it glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_NEAREST); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_NEAREST); glTexImage2D(GL_TEXTURE_2D 0 GL_RGBA8 T->w T->h 0 GL_RGBA GL_UNSIGNED_BYTE T->pixels); Texture->TextureInfo->Width = (float)T->w; //Write the useful data Texture->TextureInfo->Height = (float)T->h; Texture->ResourceName = FileName; //And the caching info needed Texture->Image = T; //And save the image for if it's needed later and for deleting if (!TexCacheSize) { //If this is the first load this is 0 so allocate the first 8 Cache slots. TexCacheSize = 8; TextureCache = new texCacheItem*[8]; } if(NumTexCached == TexCacheSize) { //If we're out of cache space if (TexCacheSize == 32768) { //If too many cache items error out EngineState = ENGINESTATE_ERR; return NULL; } TexCacheSize <<= 1; //Double cache size texCacheItem ** NewSet = new texCacheItem*[TexCacheSize]; memcpy(NewSet TextureCache NumTexCached * sizeof(texCacheItem*)); //And copy over the old cache delete TextureCache; //Delete the old cache TextureCache = NewSet; //And assign the pointer to the new one } TextureCache[NumTexCached++] = Texture; //Store the texCacheItem to the Cache file->Close(); //Close the file file = NULL; //And NULL the smart pointer. [NTS: Confirm with Disch this is what won't cause a memory leak] return Texture; //And return the loaded texture in texCacheItem form. } SDL_Surface *loadPNG(dshlib::FilePtr File) { Uint8 *PNGFile = new Uint8[(long)File->GetSize()]; File->GetAr<Uint8>(PNGFile (long)File->GetSize()); return IMG_LoadPNG_RW(SDL_RWFromMem(PNGFile (long)File->GetSize())); } Here's the renderer code file. It's quite messy at the moment apologies for that. level->activeMap basically tells the renderer which ""layer"" of the tilemap (0 being the front 3 the back) to draw the sprites above. #include ""../MegaJul.h"" void render(void) { //Render the current tilemap to the screen glClear(GL_COLOR_BUFFER_BIT|GL_DEPTH_BUFFER_BIT); glLoadIdentity(); glTranslatef(0.0f 0.0f -4.0f); if (level) { glBegin(GL_QUADS); float dT = 32.0f / level->dTex; float sX fX fXa sY tX tY sYa sYb sXa tXa tYa; unsigned long m = level->mapDimensions[0] * level->mapDimensions[1]; float ai; long long t; Sint16 * p; glBindTexture(GL_TEXTURE_2D level->tilemap->TextureNum); for (int i = 3; i >= 0; i--) { if (level->layers[i]->mapPosition[0] > 0) level->layers[i]->mapPosition[0] = 0; if (level->layers[i]->mapPosition[0] < 0 - (signed long)((level->mapDimensions[0] - 21) * 32)) level->layers[i]->mapPosition[0] = 0 - (signed long)((level->mapDimensions[0] - 21) * 32); if (level->layers[i]->mapPosition[1] < 0) level->layers[i]->mapPosition[1] = 0; if (level->layers[i]->mapPosition[1] > (signed long)((level->mapDimensions[1] - 16) * 32)) level->layers[i]->mapPosition[1] = (signed long)((level->mapDimensions[1] - 16) * 32); if (i == level->activeMap) { for (int j = 0; j < NumSprites; j++) { glBindTexture(GL_TEXTURE_2D Sprites[j]->Graphics->TextureNum); Sprites[j]->render(level->layers[i]->mapPosition[0] level->layers[i]->mapPosition[1]); } for (int j = 0; j < NumBullets; j++) { glBindTexture(GL_TEXTURE_2D Bullets[j]->Texture->TextureNum); Bullets[j]->render(level->layers[i]->mapPosition[0] level->layers[i]->mapPosition[1]); } } glBindTexture(GL_TEXTURE_2D level->tilemap->TextureNum); t = 0 - ((level->layers[i]->mapPosition[0] - (level->layers[i]->mapPosition[0] % 32)) /32) + (((level->layers[i]->mapPosition[1] - (level->layers[i]->mapPosition[1] % 32)) /32) * level->mapDimensions[0]); ai = (float)(3 - i); //Invert Z-Index sX = (float)((level->layers[i]->mapPosition[0] % 32)); sY = (float)((level->layers[i]->mapPosition[1] % 32)); if (sX > 0) sX -= 32; if (sY < 0) sY += 32; fX = sX /= 32.0f; sY /= 32.0f; fXa = sXa = sX + 1.0f; sYa = sY + 14.0f; sYb = sY + 15.0f; for (int y = 0; y < 16; y++) { for (int x = 0; x < 21; x++) { p = level->tiles[level->layers[i]->map[t]]->position; tX = p[0] / level->dTex; tY = p[1] / level->dTex; tXa = tX + dT; tYa = tY + dT; glTexCoord2f(tX tYa); glVertex3f(fX sYa ai); // Bottom Left Of The Texture and Quad glTexCoord2f(tXatYa); glVertex3f(fXa sYa ai); // Bottom Right Of The Texture and Quad glTexCoord2f(tXatY); glVertex3f(fXa sYb ai); // Top Right Of The Texture and Quad glTexCoord2f(tX tY); glVertex3f(fX sYb ai); // Top Left Of The Texture and Quad fX += 1.0f; fXa += 1.0f; t++; if (t >= m) break; } sYb -= 1.0f; sYa -= 1.0f; fXa = sXa; fX = sX; t += level->mapDimensions[0] - 21; //21 is the number of tiles drawn on a line (20 visible + 1 extra for scrolling) } } glEnd(); } SDL_GL_SwapBuffers(); } Here's the code segments that set the tilemap data for sprites and the level: Level: void loadLevel(dshlib::utfstr FileName) { -snip- texCacheItem * Tex = loadGraphics(FileName); if (!Tex) { //Load the tile graphics for the level unloadLevel(); EngineState = ENGINESTATE_ERR; return; } else { level->dTex = Tex->TextureInfo->Width; level->tilemap = Tex; } -snip- } Sprite: void SpriteBase::created() { this->Graphics = loadGraphics(DefaultGFX()); -snip- } UPDATE 2: Sid Farkus noted one big mistake I made with the renderer so here's an updated renderer.cpp: #include ""../MegaJul.h"" void render(void) { //Render the current tilemap to the screen glClear(GL_COLOR_BUFFER_BIT|GL_DEPTH_BUFFER_BIT); glLoadIdentity(); glTranslatef(0.0f 0.0f -4.0f); if (level) { float dT = 32.0f / level->dTex; float sX fX fXa sY tX tY sYa sYb sXa tXa tYa; unsigned long m = level->mapDimensions[0] * level->mapDimensions[1]; float ai; long long t; Sint16 * p; for (int i = 3; i >= 0; i--) { if (level->layers[i]->mapPosition[0] > 0) level->layers[i]->mapPosition[0] = 0; if (level->layers[i]->mapPosition[0] < 0 - (signed long)((level->mapDimensions[0] - 21) * 32)) level->layers[i]->mapPosition[0] = 0 - (signed long)((level->mapDimensions[0] - 21) * 32); if (level->layers[i]->mapPosition[1] < 0) level->layers[i]->mapPosition[1] = 0; if (level->layers[i]->mapPosition[1] > (signed long)((level->mapDimensions[1] - 16) * 32)) level->layers[i]->mapPosition[1] = (signed long)((level->mapDimensions[1] - 16) * 32); if (i == level->activeMap) { for (int j = 0; j < NumSprites; j++) { glBindTexture(GL_TEXTURE_2D Sprites[j]->Graphics->TextureNum); glBegin(GL_QUADS); Sprites[j]->render(level->layers[i]->mapPosition[0] level->layers[i]->mapPosition[1]); glEnd(); } for (int j = 0; j < NumBullets; j++) { glBindTexture(GL_TEXTURE_2D Bullets[j]->Texture->TextureNum); glBegin(GL_QUADS); Bullets[j]->render(level->layers[i]->mapPosition[0] level->layers[i]->mapPosition[1]); glEnd(); } } glBindTexture(GL_TEXTURE_2D level->tilemap->TextureNum); glBegin(GL_QUADS); -snipped out renderer since it was bloat glEnd(); } SDL_GL_SwapBuffers(); } Your code looks fine have you verified your PNG loader is working correctly? Create a 4x4 texture and check the values to make sure you've got the right things out of the loader and that the byte ordering matches what you pass to glTexImage2D. Barring that I'd focus on your rendering code. Btw weird naming convention to start variable names with capital letter. I was confused for good 10 seconds when I first looked at your code. (not to say it's wrong just weird) I'm assuming you can't do any sort of debugging or logging for this? If you could I'd expect this would be trivial to diagnose. The main thing that looks dangerous to me is that you're not checking the return value from loadPNG. I'd put something there as the very first thing I did. I'd consider commenting out the initial check for an already-cached texture too. If things start working at that point you know it's a problem with the resource names or filenames (or the comparison of them). As an aside I'm surprised that you're using classes and smart pointers but rolling your own std::vector with bare pointers and arrays. ;) I have done debugging - and I've had no luck which is why I'm asking here. As far as the intermix goes well I'm sure I'll get around to making it make sense soon enough.  In your renderer are you calling glBindTexture appropriately? It sounds like your renderer is just using whatever the last texture you uploaded was since that was the last time you called glBindTexture. glBindTexture is what tells OpenGL texture to use for your polygons. Nope I'm making sure I always call glBindTexture() in the renderer. Would it help if I posted the relevant parts of it for reference? Yeah definitely since there is nothing obvious wrong in the loading code. (This assumes you are actually loading different textures of course. :) ) Print out the TextureNum before you call bind to be sure you are in fact at least setting a different opengl texture. Also try using GLintercept to see if you can spot anything using that. (I use this all the time to track down my opengl problems.) Running a debugger check on those shows that the sprite has TextureNum = 2 and level has TextureNum = 1. Thanks for the glIntercept tip though! ..And that solved my problem thanks! I should clarify; the GLIntercept program showed me what I did wrong. I had the last glEnd() one curly-brace too far down and wasn't noticing that.  With your rendering code I can see you're calling BindTexture in a glBegin/End block. From the opengl docs: GL_INVALID_OPERATION is generated if glBindTexture is executed between the execution of glBegin and the corresponding execution of glEnd. Move your BindTexture calls outside the glBegin()/glEnd() block and you should be golden. You'll probably have to have multiple blocks to accommodate your rendering style. edit: With the updated code make sure of a couple things; your sprite positions are visible on the screen with the current projection/model view matrix and your sprite texture ids are valid textures. There's nothing technically wrong that jumps out at me now but your values may be off. Hm now I'm getting the same issue but instead the *other* texture is used... Copying in the newer version knowing me I completely goofed it up... Make sure inside your render() calls you don't do anything wierd either. Remember there are a limited subset of functions you're permitted to call between glBegin and glEnd. The only things the sprite's render does is calculate some offsets and then call glTexCoord2f and glVertex3f.",c++ opengl textures819953,A,"How to start writing a music visualizer in C++? I'm interested in learning to use OpenGL and I had the idea of writing a music visualizer. Can anyone give me some pointers of what elements I'll need and how I should go about learning to do this? with a ""#include"" perhaps? sorry couldn't help myself :) You can find implementation of FFT algorithms and other useful informations in Numerical Recipes in C book. The book is free AFAIK. There is also Numerical Recipes in C++ book.  For the music analysis part you should study the basis of Fourier series then pick a free implementation of a DFFT (digital fast fourier transform) algorithm.  From my point of view...check this site: http://nehe.gamedev.net/ really good Information and Tutorials for using OpenGL edit: http://www.opengl.org/code/  If you use C++/CLI here's an example that uses WPF four (fourier that is;) display. He references this site that has considerable information about what your asking here's anoutline from the specific page; How do we split sound into frequencies? Our ears do it by mechanical means mathematicians do it using Fourier transforms and computers do it using FFT. The Physics of Sound 1.2. Harmonic Oscillator Sampling Sounds Fourier Analysis Complex Numbers Digital Fourier Transform FFT Ahhh I found this a few minutes later it's a native C++ analyzer. Code included that should get you off and running.  My approach for creating BeatHarness (http://www.beatharness.com) : record audio in real time have a thread that runs an FFT on the audio to get the frequency intensities calculate audio-volume for left and right channel filter the frequencies in bands (bass midtones treble) now you have some nice variables to use in your graphics display. For example show a picture where the size is multiplied by the bass - this will give you a picture that'll zoom in on the beat. From there on it's your own imagination ! :)  Are you trying to write your own audio/music player? Perhaps you should try writing a plugin for an existing player so you can focus on graphics rather than the minutia of codecs dsp and audio output devices. I know WinAMP and Foobar have APIs for visualization plugins. I'm sure Windows Media Player and iTunes also have them. Just pick a media player and start reading. Some of them may even have existing OpenGL plugins from which you can start so you can focus on pure OpenGL. I'm not trying to write a player or anything just something that will take in an MP3 and visualize it but I don't know anything about how to connect all those pieces. I'm on Linux so I'd stick to something simple. Haven't really thought about integrating it into anything else. consider using a library like mpg123 libmad or ffmpeg to decode then mp3 into audio samples. From there you'll want to use DFT(FFT) to convert audio to frequency information (see FFTW). At this point you'll have raw frequency data similar to what you see on most visuliazers (winamp/xmms moving lines w/ peaks). After that you need to figure out what to visual based on frequency and changes in frequency.  If you're just after some basic 3D or accelerated 2D then I'd recommend purchasing a copy of Dave Astle's ""Beginning OpenGL Game Programming"" which covers the basics of OpenGL in C++.  You may want to consider using libvisual's FFT/DCT functions over FFTW; they're much simpler to work with and provide data that's similarly easy to work with for the sake of generating visuals. Several media players and visualization plugins use libvisual to some extent for their visuals. Examples: Totem (player) GOOM (plugin for Totem and other players) PsyMP3 2.x (player)",c++ opengl audio visualization1450023,A,"openGL and STL? I am using openGL and am currently passing it a vertex array. The problem is that I have to create many vertices and add them in between one another (for order). This means that using a regular array is pretty annoying/inefficient. I want to use a data structure from STL so that I can efficiently (and easily) put new vertices at any index. The problem is that openGL expects a regular array. Does anyone know how to go about this? Is there an easy way to convert from an STL vector to an array? I am using openGL 1.1 Thanks vector<int> array; ..... functionThatAcceptsArray(&array[0]); // yes this is standard  It depends on how much control you need over your intermediate data representations and how much you are able to precalculate. For a compromise between freedom and memory usage read about the Winged Edge data structure. The structure allows quick access and traversal between vertices edges and faces and works like a doubled linked-list. If you implement the concept and make an iterator implementation for it you can use std::copy to copy the data into any STL container. As the rest of the folks have already mentioned use std::vector as the final representation when OpenGL needs the data. And lastly: Don't be afraid to have several instances of the same data!  OpenGL requires a contiguous array of elements. For hopefully obvious reasons there is no efficient way to insert a single element into a contiguous array. It is necessarily at least O(N). However you potentially could add N elements in less than the O(N^2) that the vector achieves for N random insertions. For example if you don't actually add new vertices ""at any index"" but always close to the previous one you could add all the elements to a std::list (O(1) per element O(N) total) then copy the std::list to a std::vector. In fact it doesn't have to be the previous element just a previous element so if the order is based on a recursive traversal of some tree then you might still be able to do this. If new vertices are added at an index determined by some linear order then add all the elements to a std::map or std::multi_map (O(log N) per element O(N log N) total) then copy that to a vector. So the lowest-complexity way of doing it depends on how the order is determined. Whether these lower-complexity solutions are actually faster than the vector depends on N. They have much higher overheads (O(N) allocations instead of O(log N) for the vector) so N might have to be pretty big before the asymptotic behaviour kicks in. If you do use either of the solutions I describe then the easy/efficient way to copy either a list or a map to a vector is like this: std::vector<glVertex3f> vec; vec.reserve(listormap.size()); vec.insert(vec.begin() listormap.begin() listormap.end());  You can use a pointer to the first address of the vector as an array pointer. STL vectors are guaranteed to keep their elements in contiguous memory. So you can just do something like: &vertices[0] where vertices is your vector.",c++ opengl stl205522,A,openGL SubTexturing I have image data and i want to get a sub image of that to use as an opengl texture. glGenTextures(1 &m_name); glGetIntegerv(GL_TEXTURE_BINDING_2D &oldName); glBindTexture(GL_TEXTURE_2D m_name); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_LINEAR); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_LINEAR); glTexImage2D(GL_TEXTURE_2D 0 GL_RGBA m_width m_height 0 GL_RGBA GL_UNSIGNED_BYTE m_data); How can i get a sub image of that image loaded as a texture. I think it has something to do with using glTexSubImage2D but i have no clue how to use it to create a new texture that i can load. Calling: glTexSubImage2D(GL_TEXTURE_2D 0 xOffset yOffset xWidth yHeight GL_RGBA GL_UNSIGNED_BYTE m_data); doe nothing that i can see and calling glCopyTexSubImage2D just takes part of my framebuffer. Thanks Edit: Use glPixelStorei. You use it to set GL_UNPACK_ROW_LENGTH to the width (in pixels) of the entire image. Then you call glTexImage2D (or whatever) passing it a pointer to the first pixel of the subimage and the width and height of the subimage. Don't forget to restore GL_UNPACK_ROW_LENGTH to 0 when you're finished with it. Ie: glPixelStorei( GL_UNPACK_ROW_LENGTH img_width ); char *subimg = (char*)m_data + (sub_x + sub_y*img_width)*4; glTexImage2D( GL_TEXTURE_2D 0 GL_RGBA sub_width sub_height 0 GL_RGBA GL_UNSIGNED_BYTE subimg ); glPixelStorei( GL_UNPACK_ROW_LENGTH 0 ); Or if you're allergic to pointer maths: glPixelStorei( GL_UNPACK_ROW_LENGTH img_width ); glPixelStorei( GL_UNPACK_SKIP_PIXELS sub_x ); glPixelStorei( GL_UNPACK_SKIP_ROWS sub_y ); glTexImage2D( GL_TEXTURE_2D 0 GL_RGBA sub_width sub_height 0 GL_RGBA GL_UNSIGNED_BYTE m_data ); glPixelStorei( GL_UNPACK_ROW_LENGTH 0 ); glPixelStorei( GL_UNPACK_SKIP_PIXELS 0 ); glPixelStorei( GL_UNPACK_SKIP_ROWS 0 ); Edit2: For the sake of completeness I should point out that if you're using OpenGL-ES then you don't get GL_UNPACK_ROW_LENGTH. In which case you could either (a) extract the subimage into a new buffer yourself or (b)... glTexImage2D( GL_TEXTURE_2D 0 GL_RGBA sub_width sub_height 0 GL_RGBA GL_UNSIGNED_BYTES NULL ); for( int y = 0; y < sub_height; y++ ) { char *row = m_data + ((y + sub_y)*img_width + sub_x) * 4; glTexSubImage2D( GL_TEXTURE_2D 0 0 y sub_width 1 GL_RGBA GL_UNSIGNED_BYTE row ); } Basically i have an image ( as raw data ) and i want to use part of that image as a texture. I know how to load the entire image as a texture but don't know how to use just a bit of it. Poster answered this. If you have an image in memory it is stored somehow. If you used glTexImage2D(...GL_RGBA GL_UNSIGNED_BYTE) to load then there's a byte for R G B and alpha value. The images are stored with pixel (0 0) starts at position 0. Pixel x at row y starts at image[width*y+x][0] since i am using openGL ES i ended up doing the first option u gave that is extracting subimage into a new buffer. sadly on the device it no longer works so i'm going to rework the texture so that i don't need to solve the problem.,c++ opengl1993431,A,"OpenGL: Rendering more than 8 lights how? How should I implement more than 8 lights in OpenGL? I would like to render unlimited amounts of lights efficiently. So whats the preferred method for doing this? OpenGL lights is a simplistic system that as far as I know is already in the deprecated list. You should handle lights yourself by writing a shader. Take a look here. the tutorial says ""therefore the best approach is to compile different shaders for different numbers of lights."" umm... thats not really what i want to do since i can move in the world and sometimes there might be 100 lights rendered sometimes 10 lights... i wouldnt want to write up to 2000 shaders for every possible combination of visible lights. Or did i understand something horribly wrong :/  Deferred shading. In a nutshell you render your scene without any lights. Instead you store the normals and world positions along with the textured pixels into multiple frame-buffers (so called render targets). You can even do this in a single pass if you use a multiple render-target extension. Once you have your buffers prepared you start to render a bunch of full-screen quads each with a pixel shader program that reads out the normals and positions and computes the light for one or multiple light-sources. Since light is additive you can render as much full-screen quads as you want and accumulate the light for as much light-sources as you want. A final step does a composition between your light and the unlit textured frame-buffer. That's more or less the state-of-the-art way to do it. Getting fog and transparency working with such a system is a challenge though.",c++ opengl lights618829,A,openGL glDrawElements with interleaved buffers Thus far i have only used glDrawArrays and would like to move over to using an index buffer and indexed triangles. I am drawing a somewhat complicated object with texture coords normals and vertex coords. All this data is gathered into a single interleaved vertex buffer and drawn using calls similar to ( Assuming all the serup is done correctly ): glVertexPointer( 3 GL_FLOAT 22 (char*)m_vertexData ); glNormalPointer( GL_SHORT 22 (char*)m_vertexData+(12) ); glTexCoordPointer( 2 GL_SHORT 22 (char*)m_vertexData+(18) ); glDrawElements(GL_TRIANGLES m_numTriangles GL_UNSIGNED_SHORT m_indexData ); Does this allow for m_indexData to also be interleaved with the indices of my normals and texture coords as well as the standard position index array? Or does it assume a single linear list of inidices that apply to the entire vertex format ( POS NOR TEX )? If the latter is true how is it possible to render the same vertex with different texture coords or normals? I guess this question could also be rephrased into: if i had 3 seperate indexed lists ( POS NOR TEX ) where the latter 2 cannot be rearranged to share the same index list as the first what is the best way to render that. You cannot have different indexes for the different lists. When you specify glArrayElement(3) then OpenGL is going to take the 3rd element of every list. What you can do is play with the pointer you specify since essentially the place in the list which is eventually accessed is the pointer offset from the start of the list plus the index you specify. This is useful if you have a constant offset between the lists. if the lists are just a random permutation then this kind of play for every vertex is probably going to be as costy as just using plain old glVertex3fv() glNormal3fv() and glTexCoord3fv() Just to confirm the indices used in glDrawElements apply to your entire vertex format every time a vertex occurs on that mesh it must have the same normal and texture coords? i ask because certain 3D apps export models where a given vertex position might have different normal & texture coords If you want the same vertex to appear in a mesh with two different sets normals and texture coords then you'll need to add the vertex twice to arrays. As far as OpenGL is concerned they are two different vertices.  I am having similar trouble attempting to do the same in Direct3D 9.0 For my OpenGL 3 implementation it was rather easy and my source code is available online if it might help you any... https://github.com/RobertBColton/enigma-dev/blob/master/ENIGMAsystem/SHELL/Graphics_Systems/OpenGL3/GL3model.cpp,c++ opengl vertex-buffer1815513,A,"Problem with a volumetric fog in OpenGL Good day. I am trying to make a volumetric fog in OpenGL using glFogCoordfEXT. Why does a fog affect to all object of my scene even if they're not in fog's volume? And these objects become evenly gray as a fog itself. Here is a pic Code: void CFog::init() { glEnable(GL_FOG); glFogi(GL_FOG_MODE GL_LINEAR); glFogfv(GL_FOG_COLOR this->color); glFogf(GL_FOG_START 0.0f); glFogf(GL_FOG_END 1.0f); glHint(GL_FOG_HINT GL_NICEST); glFogi(GL_FOG_COORDINATE_SOURCE_EXT GL_FOG_COORDINATE_EXT); } void CFog::draw() { glBlendFunc(GL_SRC_ALPHA GL_SRC_ALPHA); glEnable(GL_BLEND); glPushMatrix(); glTranslatef(this->coords[0] this->coords[1] this->coords[2]); if(this->angle[0] != 0.0f) glRotatef(this->angle[0] 1.0f 0.0f 0.0f); if(this->angle[1] != 0.0f) glRotatef(this->angle[1] 0.0f 1.0f 0.0f); if(this->angle[2] != 0.0f) glRotatef(this->angle[2] 0.0f 0.0f 1.0f); glScalef(this->size this->size this->size); GLfloat one = 1.0f; GLfloat zero = 0.0f; glColor4f(0.0 0.0 0.0 0.5); glBegin(GL_QUADS); // Back Wall glFogCoordfEXT( one); glVertex3f(-2.5f-2.5f-15.0f); glFogCoordfEXT( one); glVertex3f( 2.5f-2.5f-15.0f); glFogCoordfEXT( one); glVertex3f( 2.5f 2.5f-15.0f); glFogCoordfEXT( one); glVertex3f(-2.5f 2.5f-15.0f); glEnd(); GLenum err; if((err = glGetError()) != GL_NO_ERROR) { char * str = (char *)glGetString(err); } glBegin(GL_QUADS); // Floor glFogCoordfEXT( one); glVertex3f(-2.5f-2.5f-15.0f); glFogCoordfEXT( one); glVertex3f( 2.5f-2.5f-15.0f); glFogCoordfEXT( zero); glVertex3f( 2.5f-2.5f 15.0f); glFogCoordfEXT( zero); glVertex3f(-2.5f-2.5f 15.0f); glEnd(); glBegin(GL_QUADS); // Roof glFogCoordfEXT( one); glVertex3f(-2.5f 2.5f-15.0f); glFogCoordfEXT( one); glVertex3f( 2.5f 2.5f-15.0f); glFogCoordfEXT( zero); glVertex3f( 2.5f 2.5f 15.0f); glFogCoordfEXT( zero); glVertex3f(-2.5f 2.5f 15.0f); glEnd(); glBegin(GL_QUADS); // Right Wall glFogCoordfEXT( zero); glVertex3f( 2.5f-2.5f 15.0f); glFogCoordfEXT( zero); glVertex3f( 2.5f 2.5f 15.0f); glFogCoordfEXT( one); glVertex3f( 2.5f 2.5f-15.0f); glFogCoordfEXT( one); glVertex3f( 2.5f-2.5f-15.0f); glEnd(); glBegin(GL_QUADS); // Left Wall glFogCoordfEXT( zero); glVertex3f(-2.5f-2.5f 15.0f); glFogCoordfEXT( zero); glVertex3f(-2.5f 2.5f 15.0f); glFogCoordfEXT( one); glVertex3f(-2.5f 2.5f-15.0f); glFogCoordfEXT( one); glVertex3f(-2.5f-2.5f-15.0f); glEnd(); glPopMatrix(); glDisable(GL_BLEND); //glDisable(GL_FOG); } Maybe there's no lighting in the scene? If all light sources are disabled all objects are going to appear in a flat ambient color. Check to see what happens if you disable fog altogether. Does this still happen? No lighting is there if I comment fog draw and init in my scene render functon all is fine  You seem to not be clear on how GL_fog_coord_EXT works. You're saying that an object is ""outside the fog volume"" but OpenGL does not have any notion of a fog volume. At any point either Fog is completely off or it's on in which case the fog equation will be applied with a fog coefficient that depends both on the fog mode (LINEAR in your case) and the fog coordinate. Regarding the fog coordinate. when using  glFogi(GL_FOG_COORDINATE_SOURCE_EXT GL_FOG_COORDINATE_EXT); You're telling OpenGL that every time you'll provide a vertex you'll also provide which fog coordinate to use through glFogCoordfEXT So what does it mean in your case ? Assuming you're not calling glFogCoordfEXT in your teapot drawing code you'll end up with the value of your last call to glFogCoordfEXT which looks like a glFogCoordf(one). So everything drawn in that case will be fully in fog which is what you observe. Now I'm not sure exactly what you're trying to achieve so I don't know how to help you solve the issue exactly. However if the goal is to use your quads to mimic fog simply turn fog off when drawing the scene and turn it on only when drawing the cube (I'm pretty sure it won't look like nice fog though). Thank you Bahbar!! this: ""you'll end up with the value of your last call to glFogCoordfEXT which looks like a glFogCoordf(one). "" helped! I just changed a drawing order and everything became ok:))",c++ opengl graphics648619,A,"Resizing an OpenGL window causes it to fall apart For some reason when I resize my OpenGL windows everything falls apart. The image is distorted the coordinates don't work and everything simply falls apart. I am sing Glut to set it up. //Code to setup glut glutInitWindowSize(appWidth appHeight); glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGBA); glutCreateWindow(""Test Window""); //In drawing function glMatrixMode(GL_MODELVIEW); glLoadIdentity(); glClear(GL_COLOR_BUFFER_BIT); //Resize function void resize(int w int h) { glMatrixMode(GL_PROJECTION); glLoadIdentity(); gluOrtho2D(0 w h 0); } The OpenGL application is strictly 2D. This is how it looks like initially: http://www.picgarage.net/images/Corre_53880_651.jpeg this is how it looks like after resizing: http://www.picgarage.net/images/wrong_53885_268.jpeg The images are no longer available. You should not forget to hook the GLUT 'reshape' event: glutReshapeFunc(resize); And reset your viewport: void resize(int w int h) { glViewport(0 0 width height); //NEW glMatrixMode(GL_PROJECTION); glLoadIdentity(); gluOrtho2D(0 w h 0); } A perspective projection would have to take the new aspect ratio into account: void resizeWindow(int width int height) { double asratio; if (height == 0) height = 1; //to avoid divide-by-zero asratio = width / (double) height; glViewport(0 0 width height); //adjust GL viewport glMatrixMode(GL_PROJECTION); glLoadIdentity(); gluPerspective(FOV asratio ZMIN ZMAX); //adjust perspective glMatrixMode(GL_MODELVIEW); } And replace the C-style cast with static_cast<> since you're working with C++ :)",c++ opengl graphics glut1963157,A,OpenGL Video Memory Usage is there an API or profiler application that can track the video memory usage of my application? I am using C++/OpenGL on Windows but I am open to suggestions on other platforms as well. On Mac OS X you have OpenGL Profiler.app which comes with the Developer Tools (on the OS DVD or from http://developer.apple.com) On Windows you could try gDEBugger - a good commercial OpenGL Profiling tool.,c++ memory opengl profiling video-memory1302025,A,Game engine map editor. SDL->wxWidgets I have been writing an OpenGL game engine for a while which uses SDL for all the window management and for portability. I would like to create a level editor using the full engine. The engine itself isn't at all tied in with SDL except for input. I would like to use wxWidgets for the GUI and I have been looking at some OpenGL samples which are quite simple and easy to understand. Would it be simpler to try and integrate SDL with wxWidgets and use both or switch between them for use in different applications? What would be the best way to switch between the two systems? In all likelihood it would be easier to use one GUI API per application as opposed to merging the two together (i.e. easier to have SDL/OpenGL in your game and wxWidgets/OpenGL in your level editor). Usually these libraries are not built to be merged together or used in conjunction with other libraries so it would be nearly impossible to use them both in one program. For example I don't know much about SDL but a correctly-written wxWidgets program uses internal macros to generate int main() and start up its message pump among other things. If SDL required you to do the same thing (run some special initialization code in your int main() or allow SDL to generate its own int main()) you would be unable to initialize SDL properly without breaking wxWidgets and vice versa. Again I don't know if this particular conflict actually exists between the two libraries but it's just an example of how the two can interact and interfere with each other. That said in a perfect world it would be better to choose one of the libraries and use it both for your engine and level editor (i.e. use SDL/OpenGL for the engine and editor or wxWidgets/OpenGL for the engine and editor) but if you're happy maintaining two different API codebases then if it ain't broke don't fix it. SDL doesn't use a main() macro and can be initialized in parts but I'd guess that the message loops would overlap. (SDL requires you to implement your own loop.) Yeah if not at int main() then at the message loop will there be issues. wxWidgets creates its own native message loop completely hidden from the end-user; modifying it even slightly would easily break the library.,c++ opengl wxwidgets sdl279358,A,"Invalid lock sequence error in an OpenSceneGraph application I have an application that is built against OpenSceneGraph (2.6.1) and therefore indirectly OpenGL. The application initializes and begins to run but then I get the following exception ""attempt was made to execute an invalid lock sequence"" in OpenGL32.dll. When I re-run it I sometimes get this exception and sometimes an exception about a ""privileged instruction"". The call stack looks like it is corrupted so I can't really tell exactly where the exception is being thrown from. I ran the app quite a bit a couple of days ago and never saw this behavior. Since then I have added an else clause to a couple of ifs and that is all. My app is a console application is built with Visual Studio 2008 and it sets OpenScenGraph to SingleThreaded mode. Anybody seen this before? Any debugging tips? Can you reproduce it with one of the standard examples? Can you create a minimal app that causes this? Do you have a machine with a different brand video card you can test it on (eg Nvidia vs. ATI) there are some issues with openscenegraph and bad OpenGL drivers. Have you tried posting to osg-users@lists.openscenegraph.org  The problem turned out to be our app was picking up an incorrect version of the OpenGL DLL  instead of the one installed in System32.",c++ opengl openscenegraph1759397,A,"the quake 2 md2 file format (theory) i am trying to load md2 files in opengl but i noticed that most example programs just use a precompiled list of normals. something like this..... //table of precalculated normals { -0.525731f 0.000000f 0.850651f } { -0.442863f 0.238856f 0.864188f } { -0.295242f 0.000000f 0.955423f } { -0.309017f 0.500000f 0.809017f } ... ... Ok this may sound abit dumb but i thought each model is made of different triangles how then is it possible that you can use one set of precompiled normals to render all models? It seems abit strange and any ideas will be appreciated. You could use a precompiled table of normals and use a lookup table to select one that is 'good enough' for a particular case. Each triangle is on a distinct plane and it's that plane that has a normal not the triangle itself. For instance lets imagine we have a point. Expand that point into a sphere for the purposes of this discussion makes it a little easier to grasp conceptually. If you draw a perfect circle around that sphere on the y axis then rotate that circle in the x axis 1 degree each time you'll end up with 360 circles. If you take a normal at 1 degree intervals along each of those circles you'll end up with 360 ** 2 points. From there your normal is the vector from the center of the sphere to that point on the sphere and it is a normal for a plane constructed tangential to point on the sphere. What you end up with if you calculate these two for every point on that sphere is a precalculated table of normals which will almost certainly be good enough for most situations. Now you just need to design a lookup scheme for that data (plane -> normal). Do you happen to have any literature i can go through on this? No sorry this is just off the top of my head and my understanding of the math involved. Most higher level math books that cover 3d geometry should probably cover it though. +1. That's what I've heard. The table covers a finite subset of the unit sphere. So instead of storing normals in .md2 you would store indices to save space (That's what vector quantization is about).  It's been answered already but I want to shed some more light on it. The table contains vectors that cover the unit sphere's surface pretty uniformly. It seems the set of 162 vectors are the corners of a subdivided icosahedron. This is done to lossily compress 3D vectors of unit length to an index (8 bits) see vector quantization. For storing an arbitrary normal vector you can search the table for the closest match and store the index of this match instead. With this table of 162 well distributed vectors the angle between the original vector and the approximated one is expected to be below 11Îç which seems to be good enough for the Quake2 engine.  The MD2 file format specifies that each vertex has a ""normal index"" and this is a lookup into a well-known table of normals. I would assume that these normals are distributed around a sphere. Presumably the tool that built the model chose the most appropriate of these normals for each vertex. With regard to the first answer: if you want a very faceted model (like a cube) then each polygon does indeed have its own normal and each of the vertices that makes up that polygon should use the same normal vector. However if you want smooth shading (such as a torso) it's common for each vertex in a polygon to have a different normal vector. This allows the lighting to vary across the polygon which is useful in both per-vertex and per-pixel lighting scenarios. Though you will use the polygon plane normal for lighting if you are drawing flat-shaded polygons. If you are talking about vertex normals then you still aren't talking about the polygon itself having a normal. You are still talking about a plane having a normal and that plane is usually taken to be a plane constructed perpendicular to the intended curvature of the shape at the point that the vertex occurs. I was just trying to clarify the point that I think you were making in your first paragraph. When it comes to MD2 models I think it's more useful to consider the tangent plane at each vertex rather than the tangent plane for each triangle (which is the way I read your answer at first). From your comment on my answer I think we're on the same page. I've done enough graphics work to be dangerous but not enough to know all that much. I just happen to be strong enough in the maths to figure out what's going on. The first paragraph was an attempt to answer the question as I percieved it was asked. As an aside the normals of the plane the polygon itself is on isn't useless it's just not used in lighting (it might be used ie in a physics engine though or collision detection or...).",c++ c opengl187057,A,"glBlendFunc and alpha blending I want to know how the glBlendFunc works. For example i have 2 gl textures where the alpha is on tex1 i want to have alpha in my final image. Where the color is on tex1 i want the color from tex2 to be. Seconding the shaders. If you can use a shader its much easier to just do what you want with the data rather than messing with arcane blending functions.  glBlendFunc applies only to how the final color fragment gets blended with the frame buffer. I think what you want is multitexturing to combine the two textures by blending the texture stages using glTexEnv or using a fragment shader to combine the the two textures. Does this require use of ARB extension? DavidG: If the technique uses ARB_texture_env_combine or shaders it will. Both are widely supported.  Sadly this is for openGL ES on the iPhone so no shaders but point taken. My problem was a very simplified version of the questions i needed to apply a simple color ( incl alpha ) to a part of a defined texture. As Lee pointed out texture blending is to allow alpha to show up on the framebuffer. The solution was to insist that the artist makes the ""action bit"" of the texture white and then assigning a color to the vertices that i render. Something like this. glTexCoordPointer( 2 GL_FLOAT 0 sprite->GetTexBuffer() ); glVertexPointer( 3 GL_FLOAT 0 sprite->GetVertexBuffer() ); glColorPointer( 4 GL_FLOAT 0 sprite->GetColorBuffer() ); glDrawArrays( GL_TRIANGLES 0 6 ); // Draw 2 triangles Where even tho it has a texture having the color means it adds to the texture's color so where it's an alpha it remains alpha and where it is white ( as i had to make it ) it becomes the color of the color pointer at the point. What does ""action bit"" mean? Does what you describe here solve your problem? yeah that solved my problem. ""action bit"" is the part that i want drawn in a different color. basically if i want a single texture ( maybe like a font set ) where each non transparent bit needs a custom color i used this.  Sorry can't do this with simple blending. We for instance used to do the same thing using frament shaders.",c++ opengl166356,A,"What are some best practices for OpenGL coding (esp. w.r.t. object orientation)? This semester I took a course in computer graphics at my University. At the moment we're starting to get into some of the more advanced stuff like heightmaps averaging normals tesselation etc. I come from an object-oriented background so I'm trying to put everything we do into reusable classes. I've had good success creating a camera class since it depends mostly on the one call to gluLookAt() which is pretty much independent of the rest of the OpenGL state machine. However I'm having some trouble with other aspects. Using objects to represent primitives hasn't really been a success for me. This is because the actual render calls depend on so many external things like the currently bound texture etc. If you suddenly want to change from a surface normal to a vertex normal for a particular class it causes a severe headache. I'm starting to wonder whether OO principles are applicable in OpenGL coding. At the very least I think that I should make my classes less granular. What is the stack overflow community's views on this? What are your best practices for OpenGL coding? if you do want to roll your own the above answers work well enough. A lot of the principles that are mentioned are implemented in most of the open source graphics engines. Scenegraphs are one method to move away from the direct mode opengl drawing. OpenScenegraph is one Open Source app that gives you a large (maybe too large) library of tools for doing OO 3D graphics there are a lot of other out there. This is the approach that Interactive Computer Graphics by Edward Angel takes towards OOP graphics programming. After reading Chapter 10 I'm convinced this is the correct answer. Thanks for the reference I'll definitely check it out later. Unfortunately our lecturers are a little draconian and we can't use 3rd party tools... :( Scenegraphs have their downsides this is highly recommended reading http://home.comcast.net/~tom_forsyth/blog.wiki.html#%5B%5BScene%20Graphs%20-%20just%20say%20no%5D%5D  I usually have a drawOpenGl() function per class that can be rendered that contains it's opengl calls. That function gets called from the renderloop. The class holds all info needed for its opengl function calls eg. about position and orientation so it can do its own transformation. When objects are dependent on eachother eg. they make a part of a bigger object then compose those classes in a other class that represents that object. Which has its own drawOpenGL() function that calls all the drawOpenGL() functions of its children so you can have surrounding position/orientation calls using push- and popmatrix. It has been some time but i guess something similar is possible with textures. If you want to switch between surface normals or vertex normals then let the object remember if its one or the other and have 2 private functions for each occasion that drawOpenGL() calls when needed. There are certainly other more elegant solutions (eg. using the strategy design pattern or something) but this one could work as far as I understand your problem sry for the late answer. yes im thinking: a mesh class consisting of a list of triangle classes and maybe the function for the avarage normals; the triangle class can generate its own normal. The mesh could do the drawing of the triangles. A primitive can be a mesh with a specific form. This is the approach I'm using now (w.r.t. the 2 private functions). It doesn't quite work out for me since each Triangle class depends on 6 other Triangles for normal averaging. Would you also recommend modelling a mesh instead of primitives as my basic class?  The most practical approach seems to be to ignore most of OpenGL functionality that is not directly applicable (or is slow or not hardware accelerated or is a no longer a good match for the hardware). OOP or not to render some scene those are various types and entities that you usually have: Geometry (meshes). Most often this is an array of vertices and array of indices (i.e. three indices per triangle aka ""triangle list""). A vertex can be in some arbitrary format (e.g. only a float3 position; a float3 position + float3 normal; a float3 position + float3 normal + float2 texcoord; and so on and so on). So to define a piece of geometry you need: define it's vertex format (could be a bitmask an enum from a list of formats; ...) have array of vertices with their components interleaved (""interleaved arrays"") have array of triangles. If you're in OOP land you could call this class a Mesh. Materials - things that define how some piece of geometry is rendered. In a simplest case this could be a color of the object for example. Or whether lighting should be applied. Or whether the object should be alpha-blended. Or a texture (or a list of textures) to use. Or a vertex/fragment shader to use. And so on the possibilities are endless. Start by putting things that you need into materials. In OOP land that class could be called (surprise!) a Material. Scene - you have pieces of geometry a collection of materials time to define what is in the scene. In a simple case each object in the scene could be defined by: - What geometry it uses (pointer to Mesh) - How it should be rendered (pointer to Material) - Where it is located. This could be a 4x4 transformation matrix or a 4x3 transformation matrix or a vector (position) quaternion (orientation) and another vector (scale). Let's call this a Node in OOP land. Camera. Well a camera is nothing more than ""where it is placed"" (again a 4x4 or 4x3 matrix or a position and orientation) plus some projection parameters (field of view aspect ratio ...). So basically that's it! You have a scene which is a bunch of Nodes which reference Meshes and Materials and you have a Camera that defines where a viewer is. Now where to put actual OpenGL calls is a design question only. I'd say don't put OpenGL calls into Node or Mesh or Material classes. Instead make something like OpenGLRenderer that can traverse the scene and issue all calls. Or even better make something that traverses the scene independent of OpenGL and put lower level calls into OpenGL dependent class. So yes all of the above is pretty much platform independent. Going this way you'll find that glRotate glTranslate gluLookAt and friends are quite useless. You have all the matrices already just pass them to OpenGL. This is how most of real actual code in real games/applications work anyway. Of course the above can be complicated by more complex requirements. Particularly Materials can be quite complex. Meshes usually need to support lots of different vertex formats (e.g. packed normals for efficiency). Scene Nodes might need to be organized in a hierarchy (this one can be easy - just add parent/children pointers to the node). Skinned meshes and animations in general add complexity. And so on. But the main idea is simple: there is Geometry there are Materials there are objects in the scene. Then some small piece of code is able to render them. In OpenGL case setting up meshes would most likely create/activate/modify VBO objects. Before any node is rendered matrices would need to be set. And setting up Material would touch most of remaining OpenGL state (blending texturing lighting combiners shaders ...). Your idea for the mesh class seems obvious to me now :) What I was trying to do was to use objects for primitives like triangles. Using objects to manage meshes makes a lot more sense as they tend to be pretty self sufficient correct? Also thanks a lot for the insight into the platform independence stuff and the render trees! That helps a lot! I think this is a great answer! ... Anyone starting to write a 3d engine should base it on these principles. (Or even better: use a engine that does all this for you and save valueable time)  Object transformations Avoid depending on OpenGL to do your transformations. Often tutorials teach you how to play with the transformation matrix stack. I would not recommend using this approach since you may need some matrix later that will only be accessible through this stack and using it is very long since the GPU bus is designed to be fast from CPU to GPU but not the other way. Master object A 3D scene is often thought as a tree of objects in order to know object dependencies. There is a debate about what should be at the root of this tree a list of object or a master object. I advice using a master object. While it does not have a graphical representation it will be simpler because you will be able to use recursion more effectively. Decouple scene manager and renderer I disagree with @ejac that you should have a method on each object doing OpenGL calls. Having a separate Renderer class browsing your scene and doing all the OpenGL calls will help you decouple your scene logic and OpenGL code. This is adds some design difficulty but will give you more flexibility if you ever have to change from OpenGL to DirectX or anything else API related. From what I've seen I definitely agree with your last point. I will have to try out the second pattern but my work isn't really complicated enough to warrant platform independence (it's just a couple of throw-away practical excercises).  A standard technique is to insulate the objects' effect on the render state from each other by doing all changes from some default OpenGL state within a glPushAttrib/glPopAttrib scope. In C++ define a class with constructor containing  glPushAttrib(GL_ALL_ATTRIB_BITS); glPushClientAttrib(GL_CLIENT_ALL_ATTRIB_BITS); and destructor containing  glPopClientAttrib(); glPopAttrib(); and use the class RAII-style to wrap any code which messes with the OpenGL state. Provided you follow the pattern each object's render method gets a ""clean slate"" and doesn't need to worry about prodding every possibly modified bit of openGL state to be what it needs. As an optimisation typically you'd set the OpenGL state once at app startup into some state which is as close as possible to what everything wants; this minimisies the number of calls which need to be made within the pushed scopes. The bad news is these aren't cheap calls. I've never really investigated how many per second you can get away with; certainly enough to be useful in complex scenes. The main thing is to try and make the most of states once you've set them. If you've got an army of orcs to render with different shaders textures etc for armour and skin don't iterate over all the orcs rendering armour/skin/armour/skin/...; make sure you set up the state for the armour once and render all the orcs' armour then setup to render all the skin. It's kinda strange to instantiate an object call its render() function and then destroy it just to insulate the state. Am I understanding correctly? Sorry I didn't explain it very well. The object doing push/pop on the GL state is just a convenience helper... nothing to do with the objects you're rendering. Code would look something like: renderable* thing=new...; { gl_pushed_scope p; thing->render(); }",c++ opengl oop1998251,A,"Basic C++ memory question a friend of mine declared a new type using typedef GLfloat vec3_t[3]; and later used vec3_t to allocate memory vertices=new vec3_t[num_xyz* num_frames]; He freed the memory using delete [] vertices; Question: 1. Since vec3_t is an alias for GLfloat[3] does it mean that vec3_t[num_xyz* num_frames] is equivalent to GLfloat[3][num_xyz* num_frames]; 2. If the above is a 2 dimentional array How is it supporsed to be properly deleted from memory? thanks in advance; from deo GLfloat is an array that is ""statically"" allocated and thus that doesn't need to be explicitly deallocated. From a memory point of view this typedef is equivalent to the following structure: typedef struct { GLfloat f1; GLfloat f2; GLfloat f3; } vec3_t; You can then have the following code which is now less confusing: vec3_t* vertices = new vec3_t [num_xyz* num_frames]; [...] delete[] vertices;  It will be deleted the same way it's been allocated - one contiguous piece of memory. See 2D array memory layout this not entirely correct there is a difference between allocation an array and allocating a single object. that's why you have delete vs delete[] The visualization in the first example of your link is misleading - ttt is defined as an array not as a pointer.  1. a two dimensional array can be thoght of as a one dimensional array where each element is an array. using this definition you can see that new vec3_t[num_xyz* num_frames] is equivalent to a two dimensional array. 2. this array is made of num_xyz* num_frames members each taking a space of sizeof (vec3_t) when new is carried out it allocates num_xyz* num_frames memory blokes in the heap it takes note of this number so that when calling delete[] it will know how many blocks of sizeof (vec3_t) it should mark as free in the heap.  You almost got it right vec3_t[num_xyz* num_frames] is equivalent to GLfloat[num_xyz* num_frames][3] Since you allocated with new[] you have to delete with delete[].  I think that the delete is OK but to reduce confusion I tend to do this: struct vec3_t{ GLFloat elems[3]; }; vec3_t* vertices = new vec3_t[num_xyz* num_frames]; Now you can see the type of vertices and: delete [] vertices; is obviously correct.",c++ opengl1940787,A,"Which IDE should I use for this art project? I have an art project that will require processing a live video feed to use as the basis of a particle system which will be rendered using OpenGL and projected on a stage. I have a CUDA enabled graphics card and I was thinking it would be nice to be able to use that for the image and particle system processing. This project only needs to run on my computer. I am normally a C# asp.net Visual Studio kinda guy but for this project I plan on using c++. Should I do the work in Eclipse on Ubuntu or Visual Studio in Windows? I realize this can be fairly arbitrary but I wondering if one IDE/OS might be better suited for this kind of work than the other As far as the CUDA or OpenGL support is concerned you are fine with either of them. The nVidia examples are also multiplatform. The real question is if you plan on using any GUI Toolkit as there are a only a few choices that are really portable. In the end I'd recommend going with what you feel more comfortable with or where you will have the biggest knowledge gain (if learning something is a goal of the project.).  Are you aware of OpenFrameworks? This might just help shortcut to what you need. No I hadnt heard of it but I am gonna check it out. Dude. OpenFrameworks looks awesome! That is definitely in the same vein as this project I am working on. Thanks for the link Given it's a 'C++ toolkit for creative coding' would be good to know what you think.  +1 for Visual Studio. I haven't heard about any IDE especially good for such tasks. If you already know VS I see no reason to learn anything else.  Since you're already familiar with Visual Studio you should probably stick with it. In addition you'll be able to use the Nexus debugger to debug both the OpenGL and CUDA components.  While the CUDA toolkit is cross-platform i recommend Linux in this case: The debugger is based on gdb and the usability of the gcc toolchain is just much better on *nixes. You also don't seem to have any windows specific dependencies. What do you mean about the usability of the gcc toolchain? On windows you either use gcc-tools via a graphical interface i.e. have to figure out their way to pass flags etc. to the gcc tools or use them on the commandline which ain't fun on windows (using cygwin doesn't help with everything). What do you mean by ""the usability of the gcc toolchain is just much better on *nixes""? What is ""*nixes""? I assume linux/unix based OS's Thats what i meant.",c++ visual-studio-2008 eclipse opengl cuda1080635,A,"Other's library #define naming conflict Hard to come up with a proper title for this problem. Anyway... I'm currently working on a GUI for my games in SDL. I've finished the software drawing and was on my way to start on the OpenGL part of it when a weird error came up. I included the ""SDL/SDL_opengl.h"" header and compile. It throws ""error C2039: 'DrawTextW' : is not a member of 'GameLib::FontHandler'"" which is a simple enough error but I don't have anything called DrawTextW only FontHandler::DrawText. I search for DrawTextW and find it in a #define call in the header ""WinUser.h""! //WinUser.h #define DrawText DrawTextW Apparently it replaces my DrawText with DrawTextW! How can I stop it from spilling over into my code like that? It's a minor thing changing my own function's name but naming conflicts like this seem pretty dangerous and I would really like to know how to avoid them all together. Cheers! Just #undef the symbols you don't want. But Make sure that you include windows.h and do this before you include SDL: #include <windows.h> #undef DrawText #include <SDL/SDL_opengl.h>  You have a couple of options all of which suck. Add #undef DrawText in your own code Don't include windows.h. If another library includes it for you don't include that directly. Instead include it in a separate .cpp file which can then expose your own wrapper functions in its header. Rename your own DrawText. When possible I usually go for the middle option. windows.h behaves badly in countless other ways (for example it doesn't actually compile unless you enable Microsoft's proprietary C++ extensions) so I simply avoid it like the plague. It doesn't get included in my files if I can help it. Instead I write a separate .cpp file to contain it and expose the functionality I need. Also feel free to submit it as a bug and/or feedback on connect.microsoft.com. Windows.h is a criminally badly designed header and if people draw Microsoft's attention to it there's a (slim) chance that they might one day fix it. The good news is that windows.h is the only header that behaves this badly. Other headers generally try to prefix their macros with some library-specific name to avoid name collisions they try to avoid creating macros for common names and they try avoid using more macros than necessary. Yeah Windows.h does collide. I guess it is fair to complain it doesn't compile w/o ms extensions enabled but it is also reasonable that an ms-specific header should (require those extensions).  It's an unfortunate side effect of #includeing <windows.h>. Assuming you're not actually using Windows' DrawText() anywhere in your program it's perfectly safe to #undef it immediately after: // wherever you #include <windows.h> or any other windows header #include <windows.h> #undef DrawText It could. But that would require Microsoft to care. Thanks! It compiles fine now. Quite an annoying side effect indeed. Seems as if the SDL_opengl.h includes the windows.h but the #undef does it's job. Could the windows.h have been written differently to avoid this problem?  There is no general way of avoiding this problem - once you #include a header file using the preprocessor it can redefine any name it likes and there is nothing you can do about it. You can #undef the name but that assumes you know the name was #defined in the first place.",c++ opengl sdl1799070,A,"What might cause OpenGL to behave differently under the ""Start Debugging"" versus ""Start without debugging"" options? I have written a 3D-Stereo OpenGL program in C++. I keep track of the position objects in my display should have using timeGetTime after a timeBeginPeriod(1). When I run the program with ""Start Debugging"" my objects move smoothly across the display (as they should). When I run the program with ""Start without debugging"" the objects occationally freeze for several screen refreshes then jump to a new position. Any ideas as to what may be causing this problem and how to fix it? Edit: It seems like the jerkiness can be resolved after a short delay when I run through ""Start without debugging"" if I click the mouse button. My application is a console application (I take in some parameters when the program first starts). Might there be a difference in window focus between these two options? Is there an explicit way to force the focus to the OpenGL window (in full screen through glutFullScreen();) when I'm done taking input from the console window? Thanks. How does your release build perform and what is your overall CPU usage like? Since I work almost entirely in a development enviroment and CPU usage shouldn't be an issue with the simple displays I render I've never built a release build. My recent attempt to do so was thwarted by a screen capture library that I have been using that refuses to link correctly. CPU utilazation on the core running the process is high but seldom pegged. The most common thing that causes any program to behave differently while being debugged and not being debugged is using uninitialized variables and especially reading uninitialized memory. Check that you're not doing that. Something more OpenGL specific - You might have some problems with flushing of commands. Try inserting glFinish() after drawing every frame. It might also be helpful to somehow really make sure that when the freeze occurs there are actually frames being rendered and not that the whole application is frozen. If there are its more likely that you have some bug in the logic since it seems that OpenGL does its job. Thank you for the advice. Any suggestion on how to determine whether frames are still being rendered during the apparent freeze? I had tried to check that before but found that the slow down due to writing a file was obscuring whatever it was that was going on. As this is a stereo display @ 120Hz I have about 8.33ms to get through my entire display loop. Usually a debug build will initialize memory in exactly the same way whether run through a debugger or not. On windows you would still be using the debug runtime libraries. It can make a big difference when moving to a release build.  The timeGetTime API only has a precision of something like 10ms. If the intervals you're measuring are less than 50ms or so you may simply be seeing the effects of the expected variance in the system timer. I have no idea why the debugger would have an effect on this but then the whole workings of the system are a black box. You could use the QueryPerformanceCounter to get higher-resolution timings which may help. Thanks I'll take a look at that. I had thought that timeBeginPeriod(1) was accurately setting the resolution down to 1ms. If the resolution is @ 10ms that could definately cause some problems for my code. @drknexus The documentation for timeGetTime and timeBeginPeriod implies that it's 1ms but it seems to be highly dependent on what hardware is available. I suppose it's possible that ""modern"" hardware has fixed this it's been a few years since I played with it. This is where I remember the 10ms value from but it's also a few years old: http://support.microsoft.com/kb/172338",c++ windows opengl timer stereo-3d1672926,A,"Setting up a camera in OpenGL I've been working on a game engine for awhile. I've started out with 2D Graphics with just SDL but I've slowly been moving towards 3D capabilities by using OpenGL. Most of the documentation I've seen about ""how to get things done"" use GLUT which I am not using. The question is how do I create a ""camera"" in OpenGL that I could move around a 3D environment and properly display 3D models as well as sprites (for example a sprite that has a fixed position and rotation). What functions should I be concerned with in order to setup a camera in OpenGL camera and in what order should they be called in? Here is some background information leading up to why I want an actual camera. To draw a simple sprite I create a GL texture from an SDL surface and I draw it onto the screen at the coordinates of (SpriteX-CameraX) and (SpriteY-CameraY). This works fine but when moving towards actual 3D models it doesn't work quite right. The cameras location is a custom vector class (i.e. not using the standard libraries for it) with X Y Z integer components. I have a 3D cube made up of triangles and by itself I can draw it and rotate it and I can actually move the cube around (although in an awkward way) by passing in the camera location when I draw the model and using that components of the location vector to calculate the models position. Problems become evident with this approach when I go to rotate the model though. The origin of the model isn't the model itself but seems to be the origin of the screen. Some googling tells me I need to save the location of the model rotate it about the origin then restore the model to its origal location. Instead of passing in the location of my camera and calculating where things should be being drawn in the Viewport by calculating new vertices I figured I would create an OpenGL ""camera"" to do this for me so all I would need to do is pass in the coordinates of my Camera object into the OpenGL camera and it would translate the view automatically. This tasks seems to be extremely easy if you use GLUT but I'm not sure how to set up a camera using just OpenGL. EDIT #1 (after some comments): Following some suggestion here is the update method that gets called throughout my program. Its been updated to create perspective and view matrices. All drawing happens before this is called. And a similar set of methods is executed when OpenGL executes (minus the buffer swap). The xyz coordinates are straight an instance of Camera and its location vector. If the camera was at (256 32 0) then 256 32 and 0 would be passed into the Update method. Currently z is set to 0 as there is no way to change that value at the moment. The 3D model being drawn is a set of vertices/triangles + normals at location X=320 Y=240 Z=-128. When the program is run this is what is drawn in FILL mode and then in LINE mode and another one in FILL after movement when I move the camera a little bit to the right. It likes like may Normals may be the cause but I think it has moreso to do with me missing something extremely important or not completely understanding what the NEAR and FAR parameters for glFrustum actually do. Before I implemented these changes I was using glOrtho and the cube rendered correctly. Now if I switch back to glOrtho one face renders (Green) and the rotation is quite weird - probably due to the translation. The cube has 6 different colors one for each side. Red Blue Green Cyan White and Purple. int VideoWindow::Update(double x double y double z) { glMatrixMode( GL_PROJECTION ); glLoadIdentity(); glFrustum(0.0f GetWidth() GetHeight() 0.0f 32.0f 192.0f); glMatrixMode( GL_MODELVIEW ); SDL_GL_SwapBuffers(); glLoadIdentity(); glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); glRotatef(0 1.0f 0.0f 0.0f); glRotatef(0 0.0f 1.0f 0.0f); glRotatef(0 0.0f 0.0f 1.0f); glTranslated(-x -y 0); return 0; } EDIT FINAL: The problem turned out to be an issue with the Near and Far arguments of glFrustum and the Z value of glTranslated. While change the values has fixed it I'll probably have to learn more about the relationship between the two functions. If you have not checked then may be looking at following project would explain in detail what ""tsalter"" wrote in his post. Camera from OGL SDK (CodeColony) Also look at Red book for explanation on viewing and how does model-view and projection matrix will help you create camera. It starts with good comparison between actual camera and what corresponds to OpenGL API. Chapter 3 - Viewing  You have to do it using the matrix stack as for object hierarchy but the camera is inside the hierarchy so you have to put the inverse transform on the stack before drawing the objects as openGL only uses the matrix from 3D to camera.  Just remember that OpenGl post multiplies.  You need a view matrix and a projection matrix. You can do it one of two ways: Load the matrix yourself using glMatrixMode() and glLoadMatrixf() after you use your own library to calculate the matrices. Use combinations of glMatrixMode(GL_MODELVIEW) and glTranslate() / glRotate() to create your view matrix and glMatrixMode(GL_PROJECTION) with glFrustum() to create your projection matrix. Remember - your view matrix is the negative translation of your camera's position (As it's where you should move the world to relative to the camera origin) as well as any rotations applied (pitch/yaw). Hope this helps if I had more time I'd write you a proper example! Thanks for the push in the right direction. I've made an edit in the post if you could take a look at my code and screenshots. Something is not quite right :) Actually the issue really is with the values I pick for the Near and Far arguments to glFrustum as well as the Z value passed into glTranslated. Thanks.",c++ opengl sdl724060,A,"How do I render text on to a square (4 vertices) in OpenGL? I'm using Linux and GLUT. I have a square as follows: glVertex3f(-1.0 +1.0 0.0); // top left glVertex3f(-1.0 -1.0 0.0); // bottom left glVertex3f(+1.0 -1.0 0.0); // bottom right glVertex3f(+1.0 +1.0 0.0); // top right I guess I can't use glutBitmapCharacter since this is only ideal for 2D ortho. Simple enough I'd like to render ""Hello world!"" anywhere on said square. Should I create a texture and then apply it to the vertices using glTexCoord2f? The simplest way is to load a font map from a image such as those generated by the bitmap font builder (I know it's windows but I can't find one for linux) eg: The example is a 256x256 gif though you may what to convert it to a png/tga/bmp. It's full ASCII mapped gird 16x16 characters. Load the texture and use glTexCoord2f to line it up on your quad and you should be good to go. Here's an example using a bitmap of the above: unsigned texture = 0; void LoadTexture() { // load 24-bit bitmap texture unsigned offset width height size; char *buffer; FILE *file = fopen(""text.bmp"" ""rb""); if (file == NULL) return; fseek(file 10 SEEK_SET); fread(&offset 4 1 file); fseek(file 18 SEEK_SET); fread(&width 1 4 file); fread(&height 1 4 file); size = width * height * 3; buffer = new char[size]; fseek(file offset SEEK_SET); fread(buffer 1 size file); glEnable(GL_TEXTURE_2D); glGenTextures(1 &texture); glBindTexture(GL_TEXTURE_2D texture); glTexParameterf(GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_LINEAR); glTexParameterf(GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_LINEAR); glTexImage2D(GL_TEXTURE_2D 0 GL_RGB width height 0 GL_RGB GL_UNSIGNED_BYTE buffer); fclose(file); printf(""Loaded\n""); } void DrawCharacter(char c) { int column = c % 16 row = c / 16; float x y inc = 1.f / 16.f; x = column * inc; y = 1 - (row * inc) - inc; glBegin(GL_QUADS); glTexCoord2f( x y); glVertex3f( 0.f 0.f 0.f); glTexCoord2f( x y + inc); glVertex3f( 0.f 1.f 0.f); glTexCoord2f( x + inc y + inc); glVertex3f( 1.f 1.f 0.f); glTexCoord2f( x + inc y); glVertex3f( 1.f 0.f 0.f); glEnd(); } Very helpful thanks.  Indeed rendering to a bitmap is a solution. There's a decent tutorial on how to do it here on GameDev.",c++ opengl textures1726122,A,"SDL_image/C++ OpenGL Program: IMG_Load() produces fuzzy images I'm trying to load an image file and use it as a texture for a cube. I'm using SDL_image to do that. I used this image because I've found it in various file formats (tga tif jpg png bmp) The code : SDL_Surface * texture; //load an image to an SDL surface (i.e. a buffer) texture = IMG_Load(""/Users/Foo/Code/xcode/test/lena.bmp""); if(texture == NULL){ printf(""bad image\n""); exit(1); } //create an OpenGL texture object glGenTextures(1 &textureObjOpenGLlogo); //select the texture object you need glBindTexture(GL_TEXTURE_2D textureObjOpenGLlogo); //define the parameters of that texture object //how the texture should wrap in s direction glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_WRAP_S GL_REPEAT); //how the texture should wrap in t direction glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_WRAP_T GL_REPEAT); //how the texture lookup should be interpolated when the face is smaller than the texture glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_LINEAR); //how the texture lookup should be interpolated when the face is bigger than the texture glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_LINEAR); //send the texture image to the graphic card glTexImage2D(GL_TEXTURE_2D 0 GL_RGBA texture->w texture->h 0 GL_RGB GL_UNSIGNED_BYTE texture-> pixels); //clean the SDL surface SDL_FreeSurface(texture); The code compiles without errors or warnings ! I've tired all the files formats but this always produces that ugly result : I'm using : SDL_image 1.2.9 & SDL 1.2.14 with XCode 3.2 under 10.6.2 Does anyone knows how to fix this ? As a note: The reason you find that image in so many formats is because it's the standard image for image compression tests. ""Lenna"" is the name of the image and the model's name is Lena Soderberg. The history of the image is quite interesting. The reason the image is distorted is because it's not in the RGBA format that you've specified. Check the texture->format to find out the format it's in and select the appropriate GL_ constant that represents the format. (Or transform it yourself to the format of your choice.) +1 beat me to it  I think greyfade has the right answer but another thing you should be aware of is the need to lock surfaces. This is probably not the case since you're working with an in-memory surface but normally you need to lock surfaces before accessing their pixel data with SDL_LockSurface(). For example: bool lock = SDL_MUSTLOCK(texture); if(lock) SDL_LockSurface(texture); // should check that return value == 0 // access pixel data e.g. call glTexImage2D if(lock) SDL_UnlockSUrface(texture);  If you have an alpha chanel every pixel is 4 unsigned bytes if you don't it's 3 unsigned bytes. This image has no transpareny and when I try to save it its a .jpg. change glTexImage2D(GL_TEXTURE_2D 0 GL_RGBA texture->w texture->h 0 GL_RGB GL_UNSIGNED_BYTE texture-> pixels); to glTexImage2D(GL_TEXTURE_2D 0 GL_RGB texture->w texture->h 0 GL_RGB GL_UNSIGNED_BYTE texture-> pixels); That should fix it. For a .png with an alpha channel use glTexImage2D(GL_TEXTURE_2D 0 GL_RGBA texture->w texture->h 0 GL_RGBA GL_UNSIGNED_BYTE texture-> pixels); this is actually wrong. the parameter you're modifying is used to tell GL what format to _store_ the texture as. storing to RGBA when your input is RGB is perfectly valid it sets A=1 for all texels.",c++ opengl sdl sdl-image1558505,A,"C++ and OpenGL Help I am wanting to code something with OpenGL but I don't want to have to go through Windows API is this Possible? If so then some links to tutorials on how to do this would be nice. Just keep in mind that graphics processing is very tied to hardware and platform. Anything you use is going to abstract that away from you (perhaps by going through the Windows API when on Windows or another API on other OS's). I reconmend Freeglut its has some nice revisions and is more up to date in fact someone made some updates to this year.  In order to create a Win32 window for displaying OpenGL content - without going through Win32 API GLUT is the only option that I'm aware of.  If you need a complete visualization framework then VTK is the best FREE choice.  Yes. GLFW Qt + OpenGL GLUT or FreeGLUT Or see my question. I'd also add SFML http://www.sfml-dev.org/ SDL is far too slow. Thanks for your help! :) Should probably add SDL to your list. http://www.libsdl.org/ @Anthoni: That's why I didn't recommend it :) I'm personally not very fond of it. Anywho see the ""my question"" link...that lists all of the one's I'm aware of.",c++ opengl724156,A,Keyboard input hesitation when held down? Does anyone know why there is some hesitation when you hold down a keyboard key and try to process it? I'm calling a function right in my WinProc(...) that will move an image on the screen (OpenGL) when a key is held down. I press it and get a single response then there is about .5 seconds of nothing then it behaves as normal (moves 1 pixel every WinMain loop). I'm wondering if the Windows messages are being delayed somehow because of some feature I need to disable??? Here's my code: int WINAPI WinMain(HINSTANCE hinstance HINSTANCE hprevinstance LPSTR lpcmdline int nshowcmd) { bool quit = false; MSG msg; createWindow(hinstance SCRW SCRH SCRD WINDOWED); // Main loop while (!quit) { if (PeekMessage(&msg NULL NULL NULL PM_REMOVE)) { if (msg.message == WM_QUIT) quit = true; TranslateMessage(&msg); DispatchMessage(&msg); } renderFrame(); // processes graphics SwapBuffers(hdc); } return msg.lParam; } and WinProc (there were more cases but same thing...):  LRESULT CALLBACK WinProc(HWND hwnd UINT msg WPARAM wparam LPARAM lparam) { switch(msg) { case WM_KEYDOWN: switch ( wparam ) { case VK_RIGHT: key_RIGHT(); return 0; } return 0; } } and key_RIGHT: void key_RIGHT() { MoveObjectRight1Pixel(); } It's a rather standard keyboard setting to have a small delay between when the key was pressed and when repeat messages get generated. Instead of processing keyboard input in your Windows message handler you could instead keep an array of 256 bits indicating the current state of the keyboard. When you receive a WM_KEYDOWN or WM_KEYUP you update the bit of the corresponding key. Then in your main loop you check the current state of the key and the previous state of the key (by keeping a second array of 256 bits that you make a copy to every frame). If the key is currently down but was not down in the previous frame then you move your object accordingly. Another alternative is to use the GetAsyncKeyState() function. I was afraid I would have to do some silly workaround... There's no way to force Windows to send me messages at a civilized rate? That's a huge keyboard. :) Most standard PC keyboards are around 105 keys so 128 bits sounds like plenty to me. @unwind: True most keyboards have a sane number of keys but the virtual keycodes (VK_* constants) range from 0 to 255.  Well I think you're dealing with a standard windows feature here. Windows usually has a delay before it fires the repititive keystrokes events when thekey is suppressed. I don't know about other methods but on the first key press you could activate a timer which would check whether the key is suppressed every few milliseconds and then process your code accordingly. I think that would solve the problem you're having.,c++ windows opengl input messages1020924,A,"Build errors w/ GLee (GL Easy Extension Library) Using Code::Blocks w/ mingw and trying to use GLee for some OpenGL on windows. I'm getting the following build errors: GLee.c|60|undefined reference to `_wglGetProcAddress@4' GLee.c|10748|undefined reference to `_wglGetProcAddress@4' GLee.c|10751|undefined reference to `_wglGetCurrentDC@0' GLee.c|10797|undefined reference to `_glGetString@4' GLee.c|10910|undefined reference to `_glGetString@4' GLee.c|10976|undefined reference to `_glGetString@4' And I'm just including GLee likes so (with GLee.c not the .dll): #include ""GLee.h"" According to Ben Woodhouse GLee is ""written in pure ANSI C so any C or C++ compiler should work. You can include the source files in your projects directly or compile them into a library"" so I should be having no problems. Google didn't give me much on this so I'm hoping some OpenGL vets (or anyone familiar with GLee) out there can point me in the right direction. It looks like you need to link your application against the OpenGL libraries (specifically Opengl32.lib) which will provide the functions that you are missing. Perhaps the OpenGL FAQ might be of help in figuring this out.",c++ c opengl536168,A,"Why won't my OpenGL draw anything? I'm working on porting my open source particle engine test from SDL to SDL + OpenGL. I've managed to get it compiling and running but the screen stays black no matter what I do. main.cpp: #include ""glengine.h"" int WINAPI WinMain( HINSTANCE hInstance HINSTANCE hPrevInstance LPSTR lpCmdLine int nCmdShow ) { //Create a glengine instance ultragl::glengine *gle = new ultragl::glengine(); if(gle->init()) gle->run(); else std::cout << ""glengine initializiation failed!"" << std::endl; //If we can't initialize or the lesson has quit we delete the instance delete gle; return 0; }; glengine.h: //we need to include window first because GLee needs to be included before GL.h #include ""window.h"" #include <math.h> // Math Library Header File #include <vector> #include <stdio.h> using namespace std; namespace ultragl { class glengine { protected: window m_Window; ///< The window for this lesson unsigned int m_Keys[SDLK_LAST]; ///< Stores keys that are pressed float piover180; virtual void draw(); virtual void resize(int x int y); virtual bool processEvents(); void controls(); private: /* * We need a structure to store our vertices in otherwise we * just had a huge bunch of floats in the end */ struct Vertex { float x y z; Vertex(){} Vertex(float x float y float z) { this->x = x; this->y = y; this->z = z; } }; struct particle { public : double angle; double speed; Vertex v; int r; int g; int b; int a; particle(double angle double speed Vertex v int r int g int b int a) { this->angle = angle; this->speed = speed; this->v = v; this->r = r; this->g = g; this->b = b; this->a = a; } particle() { } }; particle p[500]; float particlesize; public: glengine(); ~glengine(); virtual void run(); virtual bool init(); void glengine::test2(int num); void glengine::update(); }; }; window.h: #include <string> #include <iostream> #include ""GLee/GLee.h"" #include <SDL/SDL.h> #include <SDL/SDL_opengl.h> #include <GL/glu.h> using namespace std; namespace ultragl { class window { private: int w_height; int w_width; int w_bpp; bool w_fullscreen; string w_title; public: window(); ~window(); bool createWindow(int width int height int bpp bool fullscreen const string& title); void setSize(int width int height); int getHeight(); int getWidth(); }; }; glengine.cpp (the main one to look at): #include ""glengine.h"" namespace ultragl{ glengine::glengine() { piover180 = 0.0174532925f; } glengine::~glengine() { } void glengine::resize(int x int y) { std::cout << ""Resizing Window to "" << x << ""x"" << y << std::endl; if (y <= 0) { y = 1; } glViewport(00xy); glMatrixMode(GL_PROJECTION); glLoadIdentity(); gluPerspective(45.0f(GLfloat)x/(GLfloat)y1.0f100.0f); glMatrixMode(GL_MODELVIEW); glLoadIdentity(); } bool glengine::processEvents() { SDL_Event event; while (SDL_PollEvent(&event))//get all events { switch (event.type) { // Quit event case SDL_QUIT: { // Return false because we are quitting. return false; } case SDL_KEYDOWN: { SDLKey sym = event.key.keysym.sym; if(sym == SDLK_ESCAPE) //Quit if escape was pressed { return false; } m_Keys[sym] = 1; break; } case SDL_KEYUP: { SDLKey sym = event.key.keysym.sym; m_Keys[sym] = 0; break; } case SDL_VIDEORESIZE: { //the window has been resized so we need to set up our viewport and projection according to the new size resize(event.resize.w event.resize.h); break; } // Default case default: { break; } } } return true; } bool glengine::init() { srand( time( NULL ) ); for(int i = 0; i < 500; i++) p[i] = particle(0 0 Vertex(0.0f 0.0f 0.0f) 0 0 0 0); if (!m_Window.createWindow(640 480 32 false ""Paricle Test GL"")) { return false; } particlesize = 0.01; glShadeModel(GL_SMOOTH); // Enable Smooth Shading glClearColor(0.0f 0.0f 0.0f 0.5f); // Black Background glClearDepth(1.0f); // Depth Buffer Setup glEnable(GL_DEPTH_TEST); // Enables Depth Testing glDepthFunc(GL_LEQUAL); // The Type Of Depth Testing To Do glEnable(GL_BLEND); glBlendFunc(GL_ONE  GL_ONE_MINUS_SRC_ALPHA); return true; } void glengine::test2(int num) { glPushMatrix(); glTranslatef(p[num].v.x p[num].v.y p[num].v.z); glBegin(GL_QUADS); glColor4i(p[num].r p[num].g p[num].b p[num].a); // Green for x axis glVertex3f(-particlesize -particlesize particlesize); glVertex3f( particlesize -particlesize particlesize); glVertex3f( particlesize particlesize particlesize); glVertex3f(-particlesize particlesize particlesize); glEnd(); glPopMatrix(); } void glengine::draw() { glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); // Clear Screen And Depth Buffer glLoadIdentity(); // Reset The Current Modelview Matrix gluLookAt(0 5 20 0 0 0 0 0 0); for(int i = 0; i < 500; i++) test2(i); } void glengine::update() { for(int i = 0; i < 500; i++) { if(p[i].a <= 0) p[i] = particle(5 + rand() % 360 (rand() % 10) * 0.1 Vertex(0.0f 0.0f 0.0f) 0 255 255 255); else p[i].a -= 1; p[i].v.x += (sin(p[i].angle * (3.14159265/180)) * p[i].speed); p[i].v.y -= (cos(p[i].angle * (3.14159265/180)) * p[i].speed); } } void glengine::run() { while(processEvents()) { update(); draw(); SDL_GL_SwapBuffers(); } } }; And finally window.cpp: #include ""window.h"" namespace ultragl { window::window(): w_width(0) w_height(0) w_bpp(0) w_fullscreen(false) { } window::~window() { SDL_Quit(); } bool window::createWindow(int width int height int bpp bool fullscreen const string& title) { if( SDL_Init( SDL_INIT_VIDEO ) != 0 ) return false; w_height = height; w_width = width; w_title = title; w_fullscreen = fullscreen; w_bpp = bpp; //Set lowest possiable values. SDL_GL_SetAttribute(SDL_GL_RED_SIZE 5); SDL_GL_SetAttribute(SDL_GL_GREEN_SIZE 5); SDL_GL_SetAttribute(SDL_GL_BLUE_SIZE 5); SDL_GL_SetAttribute(SDL_GL_ALPHA_SIZE 5); SDL_GL_SetAttribute(SDL_GL_DEPTH_SIZE 16); SDL_GL_SetAttribute(SDL_GL_DOUBLEBUFFER 1); //Set title. SDL_WM_SetCaption(title.c_str() title.c_str()); // Flags tell SDL about the type of window we are creating. int flags = SDL_OPENGL; if(fullscreen == true) flags |= SDL_FULLSCREEN; // Create window SDL_Surface * screen = SDL_SetVideoMode( width height bpp flags ); if(screen == 0) return false; //SDL doesn't trigger off a ResizeEvent at startup but as we need this for OpenGL we do this ourself SDL_Event resizeEvent; resizeEvent.type = SDL_VIDEORESIZE; resizeEvent.resize.w = width; resizeEvent.resize.h = height; SDL_PushEvent(&resizeEvent); return true; } void window::setSize(int width int height) { w_height = height; w_width = width; } int window::getHeight() { return w_height; } int window::getWidth() { return w_width; } }; Anyway I really need to finish this but I've already tried everything I could think of. I tested the glengine file many different ways to where it looked like this at one point: #include ""glengine.h"" #include ""SOIL/SOIL.h"" #include ""SOIL/stb_image_aug.h"" #include ""SOIL/image_helper.h"" #include ""SOIL/image_DXT.h"" namespace ultragl{ glengine::glengine() { piover180 = 0.0174532925f; } glengine::~glengine() { } void glengine::resize(int x int y) { std::cout << ""Resizing Window to "" << x << ""x"" << y << std::endl; if (y <= 0) { y = 1; } glViewport(00xy); glMatrixMode(GL_PROJECTION); glLoadIdentity(); gluPerspective(45.0f(GLfloat)x/(GLfloat)y1.0f1000.0f); glMatrixMode(GL_MODELVIEW); glLoadIdentity(); } bool glengine::processEvents() { SDL_Event event; while (SDL_PollEvent(&event))//get all events { switch (event.type) { // Quit event case SDL_QUIT: { // Return false because we are quitting. return false; } case SDL_KEYDOWN: { SDLKey sym = event.key.keysym.sym; if(sym == SDLK_ESCAPE) //Quit if escape was pressed { return false; } m_Keys[sym] = 1; break; } case SDL_KEYUP: { SDLKey sym = event.key.keysym.sym; m_Keys[sym] = 0; break; } case SDL_VIDEORESIZE: { //the window has been resized so we need to set up our viewport and projection according to the new size resize(event.resize.w event.resize.h); break; } // Default case default: { break; } } } return true; } bool glengine::init() { srand( time( NULL ) ); for(int i = 0; i < 500; i++) p[i] = particle(0 0 Vertex(0.0f 0.0f 0.0f) 0 0 0 0); if (!m_Window.createWindow(640 480 32 false ""Paricle Test GL"")) { return false; } particlesize = 10.01; glShadeModel(GL_SMOOTH); // Enable Smooth Shading glClearColor(0.0f 0.0f 0.0f 0.5f); // Black Background glClearDepth(1.0f); // Depth Buffer Setup glEnable(GL_DEPTH_TEST); // Enables Depth Testing glDepthFunc(GL_LEQUAL); // The Type Of Depth Testing To Do glEnable(GL_BLEND); glBlendFunc(GL_ONE  GL_ONE_MINUS_SRC_ALPHA); return true; } void glengine::test2(int num) { //glPushMatrix(); //glTranslatef(p[num].v.x p[num].v.y p[num].v.z); glColor4i(255 255 255 255); glBegin(GL_QUADS); glNormal3f( 0.0f 0.0f 1.0f); glVertex3f(-particlesize -particlesize particlesize); glVertex3f( particlesize -particlesize particlesize); glVertex3f( particlesize particlesize particlesize); glVertex3f(-particlesize particlesize particlesize); glEnd(); // Back Face glBegin(GL_QUADS); glNormal3f( 0.0f 0.0f-1.0f); glVertex3f(-particlesize -particlesize -particlesize); glVertex3f(-particlesize particlesize -particlesize); glVertex3f( particlesize particlesize -particlesize); glVertex3f( particlesize -particlesize -particlesize); glEnd(); // Top Face glBegin(GL_QUADS); glNormal3f( 0.0f 1.0f 0.0f); glVertex3f(-particlesize particlesize -particlesize); glVertex3f(-particlesize particlesize particlesize); glVertex3f( particlesize particlesize particlesize); glVertex3f( particlesize particlesize -particlesize); glEnd(); // Bottom Face glBegin(GL_QUADS); glNormal3f( 0.0f-1.0f 0.0f); glVertex3f(-particlesize -particlesize -particlesize); glVertex3f( particlesize -particlesize -particlesize); glVertex3f( particlesize -particlesize particlesize); glVertex3f(-particlesize -particlesize particlesize); glEnd(); // Right face glBegin(GL_QUADS); glNormal3f( 1.0f 0.0f 0.0f); glVertex3f( particlesize -particlesize -particlesize); glVertex3f( particlesize particlesize -particlesize); glVertex3f( particlesize particlesize particlesize); glVertex3f( particlesize -particlesize particlesize); glEnd(); // Left Face glBegin(GL_QUADS); glNormal3f(-1.0f 0.0f 0.0f); glVertex3f(-particlesize -particlesize -particlesize); glVertex3f(-particlesize -particlesize particlesize); glVertex3f(-particlesize particlesize particlesize); glVertex3f(-particlesize particlesize -particlesize); glEnd(); //glPopMatrix(); } void glengine::draw() { glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); // Clear Screen And Depth Buffer glLoadIdentity(); // Reset The Current Modelview Matrix gluLookAt(0 5 20 0 0 0 0 1 0); for(int i = 0; i < 500; i++) test2(i); } void glengine::update() { for(int i = 0; i < 500; i++) { if(p[i].a <= 0) p[i] = particle(5 + rand() % 360 (rand() % 10) * 0.1 Vertex(0.0f 0.0f -5.0f) 0 255 255 255); else p[i].a -= 1; p[i].v.x += (sin(p[i].angle * (3.14159265/180)) * p[i].speed); p[i].v.y -= (cos(p[i].angle * (3.14159265/180)) * p[i].speed); } } void glengine::run() { while(processEvents()) { update(); draw(); SDL_GL_SwapBuffers(); } } }; It still didn't work. I'm really at my wits end on this one. I find you get better responses if you can reduce your source code to the absolute minimum example while still having the same issue. People don't want to do the work looking through 4 pages of source when you could reduce the problem to a 1 page simple example. Reduce your program to as simple a drawing program as possible. Setup your OpenGL window viewport etc and attempt to draw a single line. If it doesn't show up post that code here. Then when people see the issue with that you can apply the fix to your bigger problem. I haven't checked your code but one thing I always do when debugging this kind of problems is to set the clear color to something colorful like (1 0 1) or so. This will help you see if the problem is that your drawn object is completely black or if it's not drawn at all. EDIT: As someone mentioned in the comment: It also shows if you have a correct GL context if the clear operation clears to the right color or if it stays black. And to see if you've created a proper context where at least glClear works.  You're not checking the return values of the SDL-GL-SetAttribute() calls. And is 5/5/5/5 20-bpp color supported by your video card? agreed it's better to avoid being so specific without having a working environment yet!  Okay I managed to fix it using a lot of your suggestions and some other source code I had laying around. Turns out the problem was from 3 different lines. particlesize = 0.01; should have been bigger: particlesize = 1.01; glColor4i(255 255 255 255) was turning the cube the same color as the clear color because I was using it wrong. I couldn't figure out how to use it right so I'm using glColor4f(0.0f1.0f1.0f0.5f) instead and that works. Last of all gluLookAt(0 5 20 0 0 0 0 0 0) needed to be gluLookAt(0 5 20 0 0 0 0 1 0) Thank you all for your help and your time.  Check OpenGL for error states. Use glslDevil glIntercept or gDebugger. Check the glGetError function. Can you test whether SDL actually acquired a device context? Does the Window reflect changes in the glClearColor call? Don't use 0.5 as an alpha value in glClearColor. Try these suggestions and report back with a minimal example as Simucal suggested.",c++ opengl sdl154730,A,"Capturing video out of an OpenGL window in Windows I am supposed to provide my users a really simple way of capturing video clips out of my OpenGL application's main window. I am thinking of adding buttons and/or keyboard shortcuts for starting and stopping the capture; when starting I could ask for a filename and other options if any. It has to run in Windows (XP/Vista) but I also wouldn't like to close the Linux door which I've so far been able to keep open. The application uses OpenGL fragment and shader programs the effects due to which I absolutely need to have in the eventual videos. It looks to me like there might be even several different approaches that could potentially fulfill my requirements (but I don't really know where I should start): An encoding library with functions like startRecording(filename) stopRecording and captureFrame. I could call captureFrame() after every frame rendered (or every second/third/whatever). If doing so makes my program run slower it's not really a problem. A standalone external program that can be programmatically controlled from my application. After all a standalone program that can not be controlled almost does what I need... But as said it should be really simple for the users to operate and I would appreciate seamlessness as well; my application typically runs full-screen. Additionally it should be possible to distribute as part of the installation package for my application which I currently prepare using NSIS. Use the Windows API to capture screenshots frame-by-frame then employ (for example) one of the libraries mentioned here. It seems to be easy enough to find examples of how to capture screenshots in Windows; however I would love a solution which doesn't really force me to get my hands super-dirty on the WinAPI level. Use OpenGL to render into an offscreen target then use a library to produce the video. I don't know if this is even possible and I'm afraid it might not be the path of least pain anyway. In particular I would not like the actual rendering to take a different execution path depending on whether video is being captured or not. Additionally I would avoid anything that might decrease the frame rate in the normal non-capture mode. If the solution were free in either sense of the word then that would be great but it's not really an absolute requirement. In general the less bloat there is the better. On the other hand for reasons beyond this question I cannot link in any GPL-only code unfortunately. Regarding the file format I cannot expect my users to start googling for any codecs but as long as also displaying the videos is easy enough for a basic-level Windows user I don't really care what the format is. However it would be great if it were possible to control the compression quality of the output. Just to clarify: I don't need to capture video from an external device like camcorder nor am I really interested in mouse movements even though getting them does not harm either. There are no requirements regarding audio; the application makes no noise whatsoever. I write C++ using Visual Studio 2008 for this very application also taking benefit of GLUT and GLUI. I have a solid understanding regarding C++ and linking in libraries and that sort of stuff but on the other hand OpenGL is quite new for me: so far I've really only learnt the necessary bits to actually get my job done. I don't need a solution super-urgently so feel free to take your time :) I had to create a demo project of recording an OpenGL rendering into a video. I used glReadPixels to get the pixel data and created the video with OpenCV's cvWriteFrame. OpenCV lets you write in divx or even x264/vp8(with ffmpeg compiled in). I have a more detailed writeup on my blog post along with a sample project. http://tommy.chheng.com/2013/09/09/encode-opengl-to-video-with-opencv/ Hi bluefeet the essential part of the answer is present: ""use glReadPixels to get the pixel data"" and use OpenCV's ""cvWriteFrame"". The blog post goes into more detail but that's the gist of the answer. Thanks for posting your answer! Please note that you should post the essential parts of the answer here on this site or your post risks being deleted [See the FAQ where it mentions answers that are 'barely more than a link'.](http://stackoverflow.com/faq#deletion) You may still include the link if you wish but only as a 'reference'. The answer should stand on its own without needing the link.  The easiest option is going to be saving each rendered frame from within your app and then merging them into an AVI. When you have the AVI there are many libraries available that can convert it into a more optimal format or possibly skip the AVI step altogether. In terms of getting each frame you could accomplish this either by rendering into an offscreen texture as you suggest or using the backbuffer directly as a source if your hardware supports this. Doing either of these (and saving each frame) is going to be difficult without a heavy penalty on framerate. Providing your application is deterministic you could ""record"" the users actions as a series of inputs and then have an export mode that sequentially renders these to an offscreen surface to generate the AVI. The frame rate penalty is quite acceptable as long as it applies only when really capturing a video. The app is deterministic in the sense of not being stochastic but what gets displayed is based in addition to user actions also on results from an external measurement device.  There are two different questions here - how to grab frames from an OpenGL application and how to turn them into a movie file. The first question is easy enough; you just grab each frame with glReadPixels() (via a PBO if you need the performance). The second question is a little harder since the cross-platform solutions (ffmpeg) tend to be GPL'd or LGPL'd. Is LGPL acceptable for your project? The Windows way of doing this (DirectShow) is a bit of a headache to use. Edit: Since LGPL is ok and you can use ffmpeg see here for an example of how to encode video. Yes: LGPL is ok. glReadPixels() indeed seems to be what I need for the first question thanks! @MikeF: that link is bust  This does look pretty relevant for merging into an AVI (as suggested by Andrew) however I was really hoping to avoid the LPBITMAPINFOHEADERs etc. Thanks for the answers I will report on the success if there is going to be any :) In the meantime additional tips for encoding the raw frames from glReadPixels into video clips would be appreciated. Edit: So far ffmpeg suggested by Mike F seems to be the way to go. However I didn't get into the actual implementation yet but hopefully that will change in the near future! Be aware that using VfW and DirectShow can use only whatever codecs are installed on the user's machine so you need to either bundle the codec you plan to use or find out which codecs they're *guaranteed* to already have.",c++ opengl video screenshot video-capture1531023,A,"moving a point in 3d space I have a point at 000 I rotate the point 30 deg around the Y axis then 30 deg around the X axis. I then want to move the point 10 units forward. I know how to work out the new X and Y position MovementX = cos(angle) * MoveDistance; MovementY = sin(angle) * MoveDistance; But then I realised that these values will change because of Z won't they? How do I work out Z and have I worked out X and Y correctly? Thanks! Use rotation matrices. :) They take a considerable investment of effort to learn but once you know how to use them everything becomes much less work. Well a point at (000) rotated at any angle at the xy or z axis will stay a (000). Assuming by ""forward"" you mean the direction pointing along the z-axis the components of the movement vector become: MovementX = 0; MovementY = 0; MovementZ = 10. Seriously try to ask exactly what you want to know. Ok I guess the equivalent in OpenGL would be... glRotatef( 30.0f 0.0f 1.0f 0.0f ); glRotatef( 30.0f 1.0f 0.0f 0.0f ); glTranslate( 0.0f 0.0f 10.0f ); But I want to do it manually so that I know the world coordinates of the point (so that I can compare it to other coordinates) I don't know too much about OpenGL but if your point is starting at (000) then drhirsch is correct and your point won't be moving anywhere through rotations. So the only function that would do anything is the glTranslate. Therefore your new position would be (0010). However I feel like that might not be what you were going for. Are you sure your point doesn't have a direction vector associated with it? You should multiply point coordinates to full rotation matrix which is matRotationTotal = matRotationX * matRotationY * matRotationZ. Check this article for details.",c++ math opengl coordinates1351129,A,Calculating 3D tangent space In order to use normal mapping in GLSL shaders you need to know the normal tangent and bitangent vectors of each vertex. RenderMonkey makes this easy by providing it's own predefined variables (rm_tangent and rm_binormal) for this. I am trying to add this functionality to my own 3d engine. Apparently it is possible to calculate the tangent and bi tangent of each vertex in a triangle using each vertex's xyz coordinates uv texture coordinates and normal vector. After some searching I devised this function to calculate the tangent and bitangent for each vertex in my triangle structure. void CalculateTangentSpace(void) { float x1 = m_vertices[1]->m_pos->Get(0) - m_vertices[0]->m_pos->Get(0); float x2 = m_vertices[2]->m_pos->Get(0) - m_vertices[0]->m_pos->Get(0); float y1 = m_vertices[1]->m_pos->Get(1) - m_vertices[0]->m_pos->Get(1); float y2 = m_vertices[2]->m_pos->Get(1) - m_vertices[0]->m_pos->Get(1); float z1 = m_vertices[1]->m_pos->Get(2) - m_vertices[0]->m_pos->Get(2); float z2 = m_vertices[2]->m_pos->Get(2) - m_vertices[0]->m_pos->Get(2); float u1 = m_vertices[1]->m_texCoords->Get(0) - m_vertices[0]->m_texCoords->Get(0); float u2 = m_vertices[2]->m_texCoords->Get(0) - m_vertices[0]->m_texCoords->Get(0); float v1 = m_vertices[1]->m_texCoords->Get(1) - m_vertices[0]->m_texCoords->Get(1); float v2 = m_vertices[2]->m_texCoords->Get(1) - m_vertices[0]->m_texCoords->Get(1); float r = 1.0f/(u1 * v2 - u2 * v1); Vec3<float> udir((v2 * x1 - v1 * x2) * r (v2 * y1 - v1 * y2) * r (v2 * z1 - v1 * z2) * r); Vec3<float> vdir((u1 * x2 - u2 * x1) * r (u1 * y2 - u2 * y1) * r (u1 * z2 - u2 * z1) * r); Vec3<float> tangent[3]; Vec3<float> tempNormal; tempNormal = *m_vertices[0]->m_normal; tangent[0]=(udir-tempNormal*(Vec3Dot(tempNormal udir))); m_vertices[0]->m_tangent=&(tangent[0].Normalize()); m_vertices[0]->m_bitangent=Vec3Cross(m_vertices[0]->m_normal m_vertices[0]->m_tangent); tempNormal = *m_vertices[1]->m_normal; tangent[1]=(udir-tempNormal*(Vec3Dot(tempNormal udir))); m_vertices[1]->m_tangent=&(tangent[1].Normalize()); m_vertices[1]->m_bitangent=Vec3Cross(m_vertices[1]->m_normal m_vertices[1]->m_tangent); tempNormal = *m_vertices[2]->m_normal; tangent[2]=(udir-tempNormal*(Vec3Dot(tempNormal udir))); m_vertices[2]->m_tangent=&(tangent[2].Normalize()); m_vertices[2]->m_bitangent=Vec3Cross(m_vertices[2]->m_normal m_vertices[2]->m_tangent); } When I use this function and send the calculated values to my shader the models look almost like they do in RenderMonkey but they flicker in a very strange way. I traced the problem to the tangent and bitangent I am sending OpenGL. This leads me to suspect that my code is doing something wrong. Can anyone see any problems or have any suggestions for other methods to try? I should also point out that the above code is very hacky and I have very little understanding of the math behind what is going on. Found the solution. Much simpler (but still a little hacky) code: void CalculateTangentSpace(void) { float x1 = m_vertices[1]->m_pos->Get(0) - m_vertices[0]->m_pos->Get(0); float y1 = m_vertices[1]->m_pos->Get(1) - m_vertices[0]->m_pos->Get(1); float z1 = m_vertices[1]->m_pos->Get(2) - m_vertices[0]->m_pos->Get(2); float u1 = m_vertices[1]->m_texCoords->Get(0) - m_vertices[0]->m_texCoords->Get(0); Vec3<float> tangent(x1/u1 y1/u1 z1/u1); tangent = tangent.Normalize(); m_vertices[0]->m_tangent = new Vec3<float>(tangent); m_vertices[1]->m_tangent = new Vec3<float>(tangent); m_vertices[2]->m_tangent = new Vec3<float>(tangent); m_vertices[0]->m_bitangent=new Vec3<float>(Vec3Cross(m_vertices[0]->m_normal m_vertices[0]->m_tangent)->Normalize()); m_vertices[1]->m_bitangent=new Vec3<float>(Vec3Cross(m_vertices[1]->m_normal m_vertices[1]->m_tangent)->Normalize()); m_vertices[2]->m_bitangent=new Vec3<float>(Vec3Cross(m_vertices[2]->m_normal m_vertices[2]->m_tangent)->Normalize()); } Sorry but that's just wrong. What you do is simply scale the edge v01 by 1/u1. Not only could u1 be zero but it obviously is not correct. For a correct answer refer to http://stackoverflow.com/questions/5255806/how-to-calculate-tangent-and-binormal  You will get zero division in your 'r' calculation for certain values of u1 u2 v1 and v2 resulting in unknown behavior for 'r'. You should guard against this. Figure out what 'r' should be if the denominator is zero and that MIGHT fix your problem. I too have little understanding of the math behind this. Suggested implementation that sets r = 0 if denominator is zero: #include <cmath> ... static float PRECISION = 0.000001f; ... float denominator = (u1 * v2 - u2 * v1); float r = 0.f; if(fabs(denominator) > PRECISION) { r = 1.0f/denominator; } ... Thanks for the reply. Unfortunately your suggestion doesn't help.,c++ opengl shader glsl1715027,A,"DDS DXT1 loading in OpenGL crashes Any idea whats wrong with my code? when i execute glCompressedTexImage2D() the program just crashes (comes the Windows XP crash message thing...) Im trying to load DDS image without mipmaps the image format is DDS DXT1 Am i missing some include file or what did i do wrong? I downloaded the included files from: http://sourceforge.net/projects/glew/files/glew/1.5.1/glew-1.5.1-win32.zip/download I have glew32.dll in the same folder as my .exe is. The code below has only the parts i changed to be able to load DDS images: #pragma comment(lib ""glew32.lib"") #include <GL\glew.h> #include <GL\gl.h> ... typedef struct { GLuint dwSize; GLuint dwFlags; GLuint dwFourCC; GLuint dwRGBBitCount; GLuint dwRBitMask; GLuint dwGBitMask; GLuint dwBBitMask; GLuint dwABitMask; } DDS_PIXELFORMAT; typedef struct { GLuint dwMagic; GLuint dwSize; GLuint dwFlags; GLuint dwHeight; GLuint dwWidth; GLuint dwLinearSize; GLuint dwDepth; GLuint dwMipMapCount; GLuint dwReserved1[11]; DDS_PIXELFORMAT ddpf; GLuint dwCaps; GLuint dwCaps2; GLuint dwCaps3; GLuint dwCaps4; GLuint dwReserved2; } DDS_HEADER; DDS_HEADER DDS_headers; ... FILE *fp = fopen(""test.dds"" ""rb""); fread(&DDS_headers 1 sizeof(DDS_headers) fp); img_width = DDS_headers.dwWidth; img_height = DDS_headers.dwHeight; maxsize = (img_width*img_height)/2; unsigned char *imgdata = (unsigned char *)malloc(maxsize); fread(imgdata 1 maxsize fp); fclose(fp); GLuint texID; glGenTextures(1 &texID); glBindTexture(GL_TEXTURE_2D texID); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_NEAREST); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_NEAREST); glCompressedTexImage2D(GL_TEXTURE_2D 0 GL_PALETTE4_R5_G6_B5_OES img_width img_height 0 maxsize imgdata); // NOTICE: // Ive also tried with function: // glCompressedTexImage2DARB(); // and internalformats: GL_COMPRESSED_RGB_S3TC_DXT1_EXT and all of the possible formats... its not a format error. please if you want DXT1 put DXT1 in the glCompressedTexImage2D call. There's no point in keeping PALETTE in there. Now what at the time of the glCompressedTexImage2D call what are the values of img_width/img_height/maxsize/imgdata ? i think the problem was at initialization/includefiles ive got the DDS loading working now by some other code thanks for help anyways. I remember messing with the DDS loader in glew I don't think the header information there is correct. I never could get it to work correctly. The best way would be to use the header contstucts that are in DDraw.h here's what I was able to use for DXT13and 5 which if I remember correctly are the only ones that can work in OpenGL.  struct DDS_IMAGE_DATA { GLsizei width; GLsizei height; GLint components; GLenum format; int numMipMaps; GLubyte *pixels; }; DDS_IMAGE_DATA* CImage::loadDDSTextureFile( const char *filename ) { DDS_IMAGE_DATA *pDDSImageData; DDSURFACEDESC2 ddsd; char filecode[4]; FILE *pFile; int factor; int bufferSize; // Open the file pFile = fopen( filename ""rb"" ); if( pFile == NULL ) { #if DEBUG char str[255]; printf( str ""loadDDSTextureFile couldn't find or failed to load \""%s\"""" filename ); #endif return NULL; } // Verify the file is a true .dds file fread( filecode 1 4 pFile ); if( strncmp( filecode ""DDS "" 4 ) != 0 ) { #if DEBUG char str[255]; printf( str ""The file \""%s\"" doesn't appear to be a valid .dds file!"" filename ); #endif fclose( pFile ); return NULL; } // Get the surface descriptor fread( &ddsd sizeof(ddsd) 1 pFile ); pDDSImageData = (DDS_IMAGE_DATA*) malloc(sizeof(DDS_IMAGE_DATA)); memset( pDDSImageData 0 sizeof(DDS_IMAGE_DATA) ); // // This .dds loader supports the loading of compressed formats DXT1 DXT3 // and DXT5. // switch( ddsd.ddpfPixelFormat.dwFourCC ) { case FOURCC_DXT1: // DXT1's compression ratio is 8:1 pDDSImageData->format = GL_COMPRESSED_RGBA_S3TC_DXT1_EXT; factor = 2; break; case FOURCC_DXT3: // DXT3's compression ratio is 4:1 pDDSImageData->format = GL_COMPRESSED_RGBA_S3TC_DXT3_EXT; factor = 4; break; case FOURCC_DXT5: // DXT5's compression ratio is 4:1 pDDSImageData->format = GL_COMPRESSED_RGBA_S3TC_DXT5_EXT; factor = 4; break; default: #if DEBUG char str[255]; printf( str ""The file \""%s\"" doesn't appear to be compressed "" ""using DXT1 DXT3 or DXT5!"" filename ); #endif return NULL; } // // How big will the buffer need to be to load all of the pixel data // including mip-maps? // if( ddsd.dwLinearSize == 0 ) { #if DEBUG printf(""dwLinearSize is 0!""); #endif } if( ddsd.dwMipMapCount > 1 ) bufferSize = ddsd.dwLinearSize * factor; else bufferSize = ddsd.dwLinearSize; pDDSImageData->pixels = (unsigned char*)malloc(bufferSize * sizeof(unsigned char)); fread( pDDSImageData->pixels 1 bufferSize pFile ); // Close the file fclose( pFile ); pDDSImageData->width = ddsd.dwWidth; pDDSImageData->height = ddsd.dwHeight; pDDSImageData->numMipMaps = ddsd.dwMipMapCount; if( ddsd.ddpfPixelFormat.dwFourCC == FOURCC_DXT1 ) pDDSImageData->components = 3; else pDDSImageData->components = 4; return pDDSImageData; } void CImage::loadDDS(const char * szFilename tTexture & texData) { DDS_IMAGE_DATA *pDDSImageData = loadDDSTextureFile(szFilename); if( pDDSImageData != NULL ) { texData.m_nHeight = pDDSImageData->height; texData.m_nWidth = pDDSImageData->width; texData.m_nHeight = pDDSImageData->height; texData.m_eFormat = pDDSImageData->format; int nHeight = pDDSImageData->height; int nWidth = pDDSImageData->width; int nNumMipMaps = pDDSImageData->numMipMaps; int nBlockSize; if( pDDSImageData->format == GL_COMPRESSED_RGBA_S3TC_DXT1_EXT ) nBlockSize = 8; else nBlockSize = 16; //glGenTextures( 1 &g_compressedTextureID ); //glBindTexture( GL_TEXTURE_2D g_compressedTextureID ); glTexParameteri( GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_LINEAR ); glTexParameteri( GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_LINEAR ); int nSize; int nOffset = 0; // Load the mip-map levels for( int i = 0; i < nNumMipMaps; ++i ) { if( nWidth == 0 ) nWidth = 1; if( nHeight == 0 ) nHeight = 1; nSize = ((nWidth+3)/4) * ((nHeight+3)/4) * nBlockSize; glCompressedTexImage2DARB( GL_TEXTURE_2D i pDDSImageData->format nWidth nHeight 0 nSize pDDSImageData->pixels + nOffset ); nOffset += nSize; // Half the image size for the next mip-map level... nWidth = (nWidth / 2); nHeight = (nHeight / 2); } } if( pDDSImageData != NULL ) { if( pDDSImageData->pixels != NULL ) free( pDDSImageData->pixels ); free( pDDSImageData ); } } This particular bit of code makes a few assumptions of the DDS file we are trying to load first that is is a compressed file either DXT13 or 5 and that the DDS file has pre-generated mipmaps saved in it hence we don't have to generate them ourselves. I hope this was able to help you it took me some time to get it working correctly myself. If there's anything in this code snippet that seems unclear let me know and I'll help you further. Thanks for your help but i've tested my headers and they are fine i copied them from MSDN and since i only use width/height in my code there cant be header related errors plus i've tested with static numbers without using headers at all. I noticed your code has RGBA so i tried with it too but that didnt make any difference... I cant test your code because i dont have the needed type definitions: CImage tTexture DDSURFACEDESC2 FOURCC_DXT1 FOURCC_DXT3 FOURCC_DXT5. Anyways cant i use DDS images unless i make miplevels in them?  The format argument that you're passing to glCompressedTexImage2D looks a bit odd: glCompressedTexImage2D(GL_TEXTURE_2D 0 GL_PALETTE4_R5_G6_B5_OES img_width img_height 0 maxsize imgdata); I think this is neither a paletted texture nor an OpenGL ES extension. Perhaps something like GL_COMPRESSED_RGB_S3TC_DXT1_EXT would work better. glewIsSupported(""EXT_texture_compression_dxt1"") returns false :/ what can i do to get this thing working? Woops I forgot the GL_ prefix; try GL_EXT_texture_compression_dxt1. If it still returns false then your platform doesn't support DXT1 compression so you'll need to convert your source data to some other format. yeah still returns false i dont quite understand how this is going to help me to make this DDS thing to work? what code you use to use DDS images in your applications? can you share it? my GFX card surely supports DDS thats a fact. i have tried with that too and all the possible format types you can give there every of them results in a crash. Make sure your OpenGL implementation supports the DXT1 extension. You can do so by calling the glewIsSupported function and passing in the following string: ""EXT_texture_compression_dxt1"".",c++ opengl directdraw dds-format328019,A,"How to load bmp into GLubyte array? All I am trying to load up a bmp file into a GLubyte array (without using aux). It is unbelievable how what I thought would have been a trivial task is sucking up hours of my time. Can't seem to find anything on Google! This is what I hacked together but it's not quite working: // load texture GLubyte *customTexture; string fileName(""C:\\Development\\Visual Studio 2008\\Projects\\OpenGL_Test\\Crate.bmp""); // Use LoadImage() to get the image loaded into a DIBSection HBITMAP hBitmap = (HBITMAP)LoadImage( NULL (LPCTSTR)const_cast<char*>(fileName.c_str()) IMAGE_BITMAP 0 0 LR_CREATEDIBSECTION | LR_DEFAULTSIZE | LR_LOADFROMFILE ); customTexture = new GLubyte[3*256*256]; // size should be the size of the .bmp file GetBitmapBits(hBitmap 3*256*256 (LPVOID) customTexture); GetBitmapDimensionEx(hBitmap&szBitmap); What happens is the call to LoadImage seems to be returning Undefined Value (NULL? I am not able to figure out if it's actually loading the bmp or not - a bit confused). At the moment I am converting bmps to raw then it's all easy. Anyone has any better and cleaner snippet? LoadImage() can only load bitmaps that are embedded into your executable file with the resource compiler - it can't load external bitmaps from the filesystem. Fortunately bitmap files are really simple to read yourself. See Wikipedia for a description of the file format. Just open up the file like you would with any other file (important: open it in binary mode i.e. with the ""rb"" option using fopen or the ios::binary flag using the C++ ifstream) read in the bitmap dimensions and read in the raw pixel data. Thanks for your remarks on LoadImage - I know how to open the file with ifstream - I was kinda hoping I could find some snippet instead of going there and figure out from scratch how to read byte-by-byte (I even think I already did it smt like N years ago) since it sounds like a common task  It is a common task that's why glaux among others gives you functions for it. Reading a bitmap is a trivial matter especially if there is only one depth/bpp to account for. Also see this question. I am not using glaux. Since it's a common task I'd expect someone to show me how to get it done or to point out some useful examples on the web since I couldn't find anything. At the moment I am converting bmp to raw.",c++ opengl glut1645309,A,"Help me evaluate this casting I found this in the PowerVR mesh drawing code and I don't really know how to read it. &((unsigned short*)0)[3 * mesh.sBoneBatches.pnBatchOffset[batchNum]] What is going on here? Is this a reference to void cast as an unsigned short pointer and then offset by (3*mesh(etc...) + batchNum)? It's breaking my brain. It's found in the context of a glDrawElements call: glDrawElements(GL_TRIANGLES i32Tris * 3 GL_UNSIGNED_SHORT &((unsigned short*)0)[3 * mesh.sBoneBatches.pnBatchOffset[batchNum]]); It's found in the context of a glDrawElements call: glDrawElements(GL_TRIANGLES i32Tris * 3 GL_UNSIGNED_SHORT &((unsigned short*)0)[3 * mesh.sBoneBatches.pnBatchOffset[batchNum]]); Its an obfuscated way of computing sizeof(unsigned short) * 3 * mesh.sBoneBatches.pnBatchOffset[batchNum] but since it doesn't actually save any characters its not a very good obfuscation Only one caveat - it returns a pointer to address N not N as a number.  It's computing a byte offset -- 3 * mesh.sBoneBatches.pnBatchOffset[batchNum] is the index. Using 0 as the pointer means that the address will be just the offset value nothing else. In essence it's `3 * mesh.sBoneBatches.pnBatchOffset[batchNum] * sizeof(unsigned short)` (though with a different type) assuming that `unsigned short[]` arrays are aligned naturally with no padding. I dont get it . Shouldn't ""((unsigned short*)0)[...]"" dereference a null pointer thus leading in unexpected behavior ? @TheSamFrom1984: No because dereferencing is not needed to take the address. This is a common trick in C and is theoretically illegal in C++ but generally works anyways.  Let's go from the inside out. (unsigned short*)0 This is casting 0 to an unsigned short pointer. This will be used for computing a memory offset computed in terms of the size of an unsigned short. 3 * mesh.sBoneBatches.pnBatchOffset[batchNum] This is presumably the offset in memory of some batch of triangles. A triangle is composed of 3 shorts so it looks like they are storing an offset in terms of numbers of triangles and then multiplying by 3 to get the number of shorts. ((unsigned short*)0)[3 * mesh.sBoneBatches.pnBatchOffset[batchNum]] This is now using that 0 pointer to find the memory location of the given offset. This would normally return the value of that memory location but they want a pointer to pass into glDrawElements so the use the & operator to get a pointer to that memory location: &((unsigned short*)0)[3 * mesh.sBoneBatches.pnBatchOffset[batchNum]] why isn't the applicaiton crashing at step 3 ? (attempt to get the value of a bad memory location) Because of the & operator the value is never accessed. Just the address of the value. It didn't know about this particularity of the language. Doesn't seem ""natural"" to me. Thanks. That was very helpful thank you. One more question is a 0 pointer the same concept as a void pointer? No but C mandates that the NULL pointer converts to an integral 0 and vice versa and C++ mandates that NULL is represented by 0.  Really this kind of hack is due to OpenGL expressing offsets inside Buffer Objects through the pointer argument of glDrawElements. glDrawElements(mode count type void* indices) indices represents either a client-side memory pointer or a server-side memory offset based on the binding of GL_ELEMENT_ARRAY_BUFFER_ARB It's interesting to dig a bit deeper... From the VBO specification: Is it legal C to use pointers as offsets? We haven't come to any definitive conclusion about this. [...] Varying opinions have been expressed as to whether this is legal although no one could provide an example of a real system where any problems would occur.",c++ opengl1617370,A,"OpenGL alpha transparency I am starting to use opengl and I wanted to try alpha transparency. Here's my code: void display(void); int main(int argc char** argv) { glutInit(&argc argv); glutInitDisplayMode(GLUT_SINGLE|GLUT_RGBA); glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); glEnable( GL_BLEND ); glutInitWindowSize(600600); glutInitWindowPosition(20050); glutCreateWindow(""glut test""); glutDisplayFunc(display); glutMainLoop(); return 0; } void display() { glClear(GL_COLOR_BUFFER_BIT); glPointSize(8); glBegin(GL_POINTS); glColor4f(.23.78.321.0); glVertex2f(00); glColor4f(.23.78.320.1); glVertex2f(0.10); glEnd(); glFlush(); } The problem is that these two points appear identical (even when I set the alpha to 0). Is there something I missed to enable alpha transparency? Thank you have you glEnable'd alpha blending? And have you set up your blend parameters? You can't just set the alpha you need to setup various other parameters in OpenGL. glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); glEnable( GL_BLEND ); OpenGL requires most everything to be enabled. A good place to start looking. (Disabling and enabling different operations at different times can lead to the most interesting effects.) Thanks I added them but I forgot to set the background color This is really helpful for a beginner Thank you~  Just a guess but could it be that you dont have a background color ? So when your rendering the second vertex which has alpha 0.1 there is no background to compute the proper color ? Just a guess been years since i used opengl. Yep this was it. I should've added: `glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); glEnable( GL_BLEND ); glClearColor(0.00.00.00.0);` but only after glutCreateWindow()",c++ opengl transparency alpha751840,A,How do I make textures transparent in OpenGL? I've tried to research this on Google but there doesn't appear to me to be any coherent simple answers. Is this because it's not simple or because I'm not using the correct keywords? Nevertheless this is the progress I've made so far. Created 8 vertices to form 2 squares. Created a texture with a 200 bit alpha value (so about 80% transparent). Assigned the same texture to each square which shows correctly. Noticed that when I use a texture with 255 alpha it appears brighter. The init is something like the following: glClearColor(0.0 0.0 0.0 0.0); glShadeModel(GL_FLAT); glEnable(GL_DEPTH_TEST); glEnable(GL_CULL_FACE); glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA GL_ONE_MINUS_SRC_ALPHA); glPixelStorei(GL_UNPACK_ALIGNMENT 1); glGenTextures(1 textureIds); glTexEnvf(GL_TEXTURE_ENV GL_TEXTURE_ENV_MODE GL_REPLACE); int i j; GLubyte pixel; for (i = 0; i < TEXTURE_HEIGHT; i++) { for (j = 0; j < TEXTURE_WIDTH; j++) { pixel = ((((i & 0x8) == 0) ^ ((j & 0x8) == 0)) * 255); texture[i][j][0] = pixel; texture[i][j][1] = pixel; texture[i][j][2] = pixel; texture[i][j][3] = 200; } } glBindTexture(GL_TEXTURE_2D textureIds[0]); glTexParameterf(GL_TEXTURE_2D GL_TEXTURE_WRAP_S GL_REPEAT); glTexParameterf(GL_TEXTURE_2D GL_TEXTURE_WRAP_T GL_REPEAT); glTexParameterf(GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_NEAREST); glTexParameterf(GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_NEAREST); glTexImage2D( GL_TEXTURE_2D 0 GL_RGBA TEXTURE_WIDTH TEXTURE_HEIGHT 0 GL_RGBA GL_UNSIGNED_BYTE texture); This is somewhat similar to the code snippet from page 417 in the book OpenGL Programming Guide and creates a check pattern. And then the display function contains... glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); glEnable(GL_TEXTURE_2D); // Use model view so that rotation value is literal not added. glMatrixMode(GL_MODELVIEW); glPushMatrix(); // ... translation etc ... glBindTexture(GL_TEXTURE_2D textureIds[0]); glBegin(GL_QUADS); glTexCoord2f(0.0 0.0); glVertex3f(-1.0 +1.0 0.0); // top left glTexCoord2f(0.0 1.0); glVertex3f(-1.0 -1.0 0.0); // bottom left glTexCoord2f(1.0 1.0); glVertex3f(+1.0 -1.0 0.0); // bottom right glTexCoord2f(1.0 0.0); glVertex3f(+1.0 +1.0 0.0); // top right glEnd(); // not neccecary to repeat just good practice glBindTexture(GL_TEXTURE_2D textureIds[0]); glBegin(GL_QUADS); glTexCoord2f(0.0 0.0); glVertex3f(-0.5 +1.0 -1.0); // top left glTexCoord2f(0.0 1.0); glVertex3f(-0.5 -1.0 -1.0); // bottom left glTexCoord2f(1.0 1.0); glVertex3f(+1.5 -1.0 -1.0); // bottom right glTexCoord2f(1.0 0.0); glVertex3f(+1.5 +1.0 -1.0); // top right glEnd(); glFlush(); glDisable(GL_TEXTURE_2D); glPopMatrix(); SwapBuffers(); So this renders a 2nd square in the background; I can see this but it looks like they're being blended with the background (I assume this because they are darker with 200 bit alpha than 255 bit) instead of the texture behind... As you can see no transparency... How can I fix this? You have TEXTURE_HEIGHT twice in that loop instead of TEXTURE_WIDTH Ah thanks but that won't matter as they're both 64. So the other answer which was here but was deleted mentioned this - Generally for alpha blending to work correctly you need to sort the objects from far to near in the coordinate system of the camera. This is why your polygons are blended with the background. You can confirm that this is indeed the problem by disabling the depth test. Without depth test all the fragments are displayed and you'll be able to see the alpha blending. More on this in this page.,c++ opengl textures opacity1478355,A,Programmatically block screen saver in Mac OSX Is it possible to programatically ask Mac OS X not to turn on the screen saver while your application is active? You want to use: UpdateSystemActivity(UsrActivity); Here is Apple's example code. Be aware this is deprecated for 64bit binaries and I have not found a suitable replacement but the struggle continues.,c++ osx opengl766127,A,Obtaining current ModelView matrix In OpenGL how do I read the current x/y translation in the modelview matrix? I know that you have to load the current matrix into an array and read the floats from there but I don't know precisely how to do it. Use glGlet GLfloat matrixf[16]; glGetFloatv(GL_MODELVIEW_MATRIX matrixf); GLdouble matrixd[16]; glGetDoublev(GL_MODELVIEW_MATRIX matrixd); GLint matrixi[16]; glGetIntegerv(GL_MODELVIEW_MATRIX matrixi);  In order to retrieve the current modelview matrix you have to call the glGetFloatv function with GL_MODELVIEW_MATRIX parameter. GLfloat matrix[16]; glGetFloatv (GL_MODELVIEW_MATRIX matrix); From the documentation: GL_MODELVIEW_MATRIX params returns sixteen values: the modelview matrix on the top of the modelview matrix stack. Initially this matrix is the identity matrix. Beat me to it :),c++ opengl matrix translation1614393,A,"SDL GL program terminates immediately I'm using Dev-C++ 4.9.9.2 (don't ask why) and SDL 1.2.8. Next I've created new project: SDL&GL. This project contains already some code: #include <SDL/SDL.h> #include <gl/gl.h> int main(int argc char *argv[]){ SDL_Event event; float theta = 0.0f; SDL_Init(SDL_INIT_VIDEO); SDL_SetVideoMode(600 300 0 SDL_OPENGL | SDL_HWSURFACE | SDL_NOFRAME); glViewport(0 0 600 300); glClearColor(0.0f 0.0f 0.0f 0.0f); glClearDepth(1.0); glDepthFunc(GL_LESS); glEnable(GL_DEPTH_TEST); glShadeModel(GL_SMOOTH); glMatrixMode(GL_PROJECTION); glMatrixMode(GL_MODELVIEW); int done; for(done = 0; !done;){ glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); glLoadIdentity(); glTranslatef(0.0f0.0f0.0f); glRotatef(theta 0.0f 0.0f 1.0f); glBegin(GL_TRIANGLES); glColor3f(1.0f 0.0f 0.0f); glVertex2f(0.0f 1.0f); glColor3f(0.0f 1.0f 0.0f); glVertex2f(0.87f -0.5f); glColor3f(0.0f 0.0f 1.0f); glVertex2f(-0.87f -0.5f); glEnd(); theta += .5f; SDL_GL_SwapBuffers(); SDL_PollEvent(&event); if(event.key.keysym.sym == SDLK_ESCAPE) done = 1; } SDL_Quit(); return(0); } Next I compiled project and try to run it. After run the program shows for less than 1 second and immediately terminates. Debugger returns following error: ""An Access Violation (Segmentation Fault) raised in your program"". I'm using Windows 2003 and Radeon x1950 PRO with latest drivers. I've tested program on laptop with Windows XP and it works perfectly. Why this program doesn't work on my computer? I take it checking the error returns on all your SDL and GL calls wasn't informative? Yes it wasn't informative because it returns following error: ""An Access Violation (Segmentation Fault) raised in your program"". It works for me too. I'd try removing SDL_HWSURFACE and add SDL_DOUBLEBUF from the window call. SDL_SetVideoMode(600 300 0 SDL_OPENGL | SDL_NOFRAME | SDL_DOUBLEBUF); while(!done) looks prettier and easier to read. Since it's tagged with C++ why are you not using bools for this? bool done = false; while(!done){ You also want while(SDL_PollEvent(&event)) as there can be more than one event per frame. while(SDL_PollEvent(&event)) { switch(event.type) case SDL_KEYDOWN: if(event.key.keysym.sym == SDLK_ESCAPE) done = true; }  I finally found some time to solve this problem. I have completly uninstalled old card graphic drivers and install 9.8 ATI drivers with Catalyst Control Center. Now everything is working. There where no problem in code itself. The problem was something in my system with graphic drivers. Anyway thanks for your answers!  My guess is it's crashing on SDL_PollEvent(). It returns 1/true if there is an event 0/false if not. When it does return true it will be a certain type of SDL_Event based on event.type. SDL_Event is a union of all SDL events and some info in one event is not guaranteed to be in the same order type etc as another. So you just need to check the type of the event and handle it as necessary.. Check out the docs for more info of course. Something like this: if (SDL_PollEvent(&event)) { switch (event.type) { case SDL_KEYUP: if (event.key.keysym.sym == SDLK_ESCAPE) done = 1; } } That would not _crash_. It will read from uninitialized memory or a previous event value so it could __quit__ prematurely. Good catch though!",c++ opengl sdl1564870,A,"Recommended OpenGL / GLUT Reference What OpenGL / GLUT reference is good for day to day programming as you learn? Ideally I'm looking for something with lots of C++ sample code to help me learn as I develop OpenGL applications as well as details about the APIs similar to what MSDN provides for .net programming. If there isn't a one stop shop then please list the set of references I should use and what the strengths of each one is. The PyOpenGL Documentation is identical to the OpenGL docs but far more readable and user-friendly. Have a look. I also second the OpenGL SuperBible.  I learned OpenGL using the OpenGL Super Bible. It's still the best reference for it that I can find.  The Red Book is the standard book on OpenGL. Don't be discouraged by the fact that the Amazon review for the 7th Edition has only two stars; this is because people are disappointed that there isn't more on the newest OpenGL features in the book. Previous editions got more stars. Another good book is the OpenGL SuperBible. The NeHe Tutorials are one of the most often cited OpenGL tutorials with sample code not only in C++ but in many other programming languages.  I think that by ""Glut"" you mean ""Freeglut"". In this case you should use this specific reference: http://jocelyn.frechot.free.fr/freeglut/freeglut_2.6.0-api_0.3.xhtml It contains latest references for current Freeglut. This way you can use special aptitudes of Freeglut (like controlling your own GL loop with glutMainLoopEvent() which is invaluadble when you're using Freeglut with others libraries.  For all the details about the OpenGL-API there are of course the sdk documentation pages https://www.opengl.org/sdk/docs/ or you could look into the standard specification itself (which I personally avoid most of the time). This most likely only helps if you already have a basic understanding of how to use the GL. The news section on opengl.org also often links to tutorials and books. Just skimmed through it and found this tutorial. As for OpenGL related books I only know the Super Bible which I think is okay to get started. When learning OpenGL without any computer graphics knowledge a book on that topic can be very helpful too. A classic would be Coumputer Graphics Principal and Practice by James D. Foley which is still an excellent read but it doesn't focus much on real time rendering. For that Real-Time Rendering by Akenine-Moller is an excellent choice.",c++ opengl reference glut1105349,A,C++ OpenGL Window and Context creation framework / library I'm searching for an multi platform OpenGL framework that abstracts the creation of windows and gl contexts in C++. I'd like to have an OO representation of Window Context & co where i can instantiate a Window create a Context and maybe later set the window to fullscreen. I'm thinking about implementing this myself for xgl wgl and agl. But before So here comes the Question: Which libraries / frameworks should i check out first before inventing the wheel again? Edit: So far named libraries: glut Qt SDL gtkglext wxwdigets SFML Hmm could be I would be curious if it were that simple. In my case it's just a Win32 reference build for a console game so I hadn't looked into it too deeply. Plus for debugging purposes I actually like/need to see the printfs. I'm using GLUT and wxWidgets successfully in two separate projects. The only downside to GLUT under Win32 is that it opens up a DOS window - good for seeing any printf's but it doesn't look as professional to have an app that opens up that window. @Jim: That's a bit in the executable that can easily be changed with `editbin` and is usually an artefact of compilation flags? wxWidgets is another alternative but may also be too heavyweight.  SMFL is another similar to SDL but takes a more object oriented approach. This one sounds promising ( their site says: SFML is composed of several packages to perfectly suit your needs. You can use SFML as a minimal windowing system to interface with OpenGL or as a fully-featured multimedia library for building games or interactive programs. ). I'm going to implement it myself - but since i think i can reuse some of the SMFL code i will accept this answer SFML is lovely. It doesn't (or maybe didn't) support creating contexts with stencil buffers but hey you can edit the code.  You could look at Glut (C) Qt (C++) SDL (C). I have already worked with glut (it was nice for the little opengl examples back at university but i think it wont fit in a bigger project). The Qt api seems nice - but i don't like the thought to introduce a dependecy to Qt. It seems to heavyweight for my needs. The same goes for SDL. There is also http://GtkGLExt.sf.net @Christoph: I can fully understand what you mean. In an inhouse solution for a former employer I had to solve a similar problem. First attempts were using the platform bindings I mentioned above. After a year or so I switched to your idea of implementing platform specifics myself.  libapril is nice also. It is clean simple and supports newer mobile platforms.,c++ opengl window multiplatform766167,A,What happens to pixels after passing them into glTexImage2D()? If for example I create an array of pixels like so: int *getPixels() { int *pixels = new int[10]; pixels[0] = 1; pixels[1] = 0; pixels[1] = 1; // etc... } glTexImage2D(... getPixels()); Does glTexImage2D use that reference or copy the pixels into it's own memory? If the answer is the former then should I do the following? int *p = getPixels(); glTexImage2D(... p); /* Just changed to delete[] because delete * would only delete the first element! */ delete[] p; I think you would need to call glDeleteTextures() after you have finished drawing your pixels to free the memory.  From this quote in the man page it sounds like glTexImage2D allocates its own memory. This would make sense ideally the OpenGL API would send data to be stored on the graphics card itself (if drivers/implementation/etc permitted). In GL version 1.1 or greater pixels may be a null pointer. In this case texture memory is allocated to accommodate a texture of width width and height height. You can then download subtextures to initialize this texture memory. The image is undefined if the user tries to apply an uninitialized portion of the texture image to a primitive. So yea I'd imagine there is no harm in freeing the memory once you've generated your texture. I'm not sure if that's the case on PC but on consoles texture uploading functions very often simply store pointer to texture and schedule DMA transfer for later time so you can't free memory as soon the function returned.  Yes after the call to geTexImage2D() returns it is safe to discard the data you passed to it. infact if you don't do that you'll have a memory leak like in this code: int *getPixels() { int *pixels = new int[10]; pixels[0] = 1; pixels[1] = 0; pixels[1] = 1; // etc... } glTexImage2D(... getPixels()); You pass the pointer to the buffer to the call but then the pointer is lost and most likely leaks. What you should do is store it and delete it aftet the call retuns: int *pbuf = getPixels(); glTexImage2D(... pbuf); delete[] pbuf; alternativly if the texture is of a constant size you can pass a pointer to an array that is on the stack: { int buf[10]; ... glTexImage2D(... pbuf); } Finally if you don't want to worry about pointers and arrays you can use STL: vector<int> buf; fillPixels(buf); getTexImage2D(... buf.begin()); Oops! My initial snippet used delete instead of delete[] for deleting the pixel buffer. technically buf.begin() might not work but &buf[0] is guaranteed to work. In most STL implementations the vector iterator is a pointer but it doesn't have to be. actually delete[] is what you should be using. my bad fixed now. btw this is exactly why you should use STL :),c++ opengl glteximage2d623127,A,OpenGL coordinate problem I am creating a simple 2D OpenGL application but I seem to be experiencing some camera issues. When I draw a rectangle at (2020) it is drawn at (2520) or so. When I draw it at (100 20) it is drawn at 125 or so. For some reasons everything is being shifted to the right by a few %. I have pasted a trimmed down version here http://pastebin.com/m56491c4c Is there something wrong with the way I am setting up GLUT? I know it's not my objects doing anything weird since the same thing happens when I disable them. Thanks in advance. It depends on what system you are working on but usually most windows coordinate systems start at the bottom left corner and count up to the top and to the right. In this case your gluOrth02D call would be wrong. You Have: gluOrtho2D(0 appWidth appHeight 0); Which has the top of the window mapping to the bottom vice-verse. Most of the time it's: gluOrtho2D(0 appWidth 0 appHeight); As I said it depends on the system platform your working with. I can only speak for most linux implementations. Just something else to check out just in case it affecting your bug.  You seem to be calling your glOrtho2D on your ModelView matrix. I doubt that that's the problem (since I guess in this case your Projection should be the identity) but you should still call it on your Projection matrix instead. You should also print out w and h in your resize call just to make sure that your window size is actually what you think it is (I don't know how glut works but glutInitWindowSize() may include borders which would mess things up). I've already tried setting it up in the order you suggested without any luck. I've messed around with the outputs and am fairly confident that the window size is correct. All out of ideas.  You need to set the projection matrix inside the reshape function (resize()) which also automatically solves the problem of the user resizing the window: void resize(int w int h) { glMatrixMode(GL_PROJECTION); glLoadIdentity(); gluOrtho2D(0 w h 0); } And then in your draw function make sure that the matrix mode is model-view: void draw() { glMatrixMode(GL_MODELVIEW); glLoadIdentity(); ... } Other problems with your code: You probably shouldn't be calling glutPostRedisplay() at the end of draw(). This is going to make your CPU run at 100%. You can instead use glutTimerFunc() to still have updates every some number of milliseconds. In processMouse() you're using wsprintf() on an array of chars: wsprintf() takes an array of wide characters (wchar_t) so you should make the local variable s of type wchar_t[] or use sprintf() and MessageBoxA() instead of wsprintf() and MessageBoxW() (to which MessageBox() expands as a macro when compiling a Unicode application which I'm assuming you're doing). You're also vulnerable to a buffer overflow -- you should use a buffer of at least 12 characters even though realistically you'll never be passed a very large x value. Finally you should also use snprintf()/wsnprintf() instead of sprintf()/wsprintf() to protect against the buffer overflow. Thanks that fixed it! Thanks for your other suggestions. I know it's messy code I just wanted a quick working sample to post. Thanks again!,c++ opengl glut984792,A,Lighting issue in OpenGL I have trouble developing an OpenGL application. The weird thing is that me and a friend of mine are developing a 3d scene with OpenGL under Linux and there is some code on the repository but if we both checkout the same latest version that means the SAME code this happens: On his computer after he compiles he can see the full lighting model whilst on mine I have only the ambient lights activated but not the diffuse or specular ones. Can it be a problem of drivers ?(since he uses an ATi card and I use an nVIDIA one) Or the static libraries ? I repeat it is the same code compiled in different machines.. that's the strange thing it should look the same. Thanks for any help or tip given. This can very easily be a driver problem or one card supporting extensions that the other does not. Try his binaries on your machine. If it continues to fail either your drivers are whack or you're using a command not supported by your card. On the other hand if your screen looks right when using your code compiled on his machine then your static libraries have a problem. Yes you're right it is a drivers issue. I have tried the binaries on my machine and compiled the program in different machines. With the newer nVIDIA cards and Ubuntu it happens the same in all the PCs I tested.,c++ opengl lighting859501,A,"Learning OpenGL in Ubuntu I'm trying to learn OpenGL and improve my C++ skills by going through the Nehe guides but all of the examples are for Windows and I'm currently on Linux. I don't really have any idea how to get things to work under Linux and the code on the site that has been ported for Linux has way more code in it that's not explained (so far the only one I've gotten to work is the SDL example: http://nehe.gamedev.net/data/lessons/linuxsdl/lesson01.tar.gz). Is there any other resource out there that's a bit more specific towards OpenGL under Linux? Maybe you would like to use Qt to draw the windows and widgets. Here's a tutorial based on the Nehe guides to show you how to create OpenGL images with Qt. To learn OpenGL the OpenGL Red Book is a must read. There's an online version. It has very good explanations and examples.  I'll guess that it is the compilation process that is the biggest difference initially. Here is a useful Makefile for compiling simple OpenGL apps on Ubuntu. INCLUDE = -I/usr/X11R6/include/ LIBDIR = -L/usr/X11R6/lib FLAGS = -Wall CC = g++ # change to gcc if using C CFLAGS = $(FLAGS) $(INCLUDE) LIBS = -lglut -lGL -lGLU -lGLEW -lm All: your_app # change your_app. your_app: your_app.o $(CC) $(CFLAGS) -o $@ $(LIBDIR) $< $(LIBS) # The initial white space is a tab Save this too a file called Makefile and should be in the same directory. Compile by writing make from terminal or :make from Vim. Good luck  a little update for the makefile because I found this old answers from @Millthorn and it didn't worked: you dont need to definde the include path since it's in standard lib http://stackoverflow.com/a/2459788/1059828 a minimal makefile to compile open GL could look like this: LDFLAGS=-lglut -lGL -lGLU -lGLEW -lm all: your_app http://surflab.cise.ufl.edu/wiki/Getting_Started_with_OpenGL_in_Ubuntu  The first thing to do is install the OpenGL libraries. I recommend:  freeglut3 freeglut3-dev libglew1.5 libglew1.5-dev libglu1-mesa libglu1-mesa-dev libgl1-mesa-glx libgl1-mesa-dev Once you have them installed link to them when you compile: g++ -lglut -lGL -lGLU -lGLEW example.cpp -o example In example.cpp include the OpenGL libraries like so: #include <GL/glew.h> #include <GL/glut.h> #include <GL/gl.h> #include <GL/glu.h> #include <GL/glext.h> Then to enable the more advanced opengl options like shaders place this after your glutCreateWindow Call: GLenum err = glewInit(); if (GLEW_OK != err) { fprintf(stderr ""Error %s\n"" glewGetErrorString(err)); exit(1); } fprintf(stdout ""Status: Using GLEW %s\n"" glewGetString(GLEW_VERSION)); if (GLEW_ARB_vertex_program) fprintf(stdout ""Status: ARB vertex programs available.\n""); if (glewGetExtension(""GL_ARB_fragment_program"")) fprintf(stdout ""Status: ARB fragment programs available.\n""); if (glewIsSupported(""GL_VERSION_1_4 GL_ARB_point_sprite"")) fprintf(stdout ""Status: ARB point sprites available.\n""); That should enable all OpenGL functionality and if it doesn't then it should tell you the problems.",c++ linux opengl ubuntu1823927,A,"Simulated time in a game loop using c++ I am building a 3d game from scratch in C++ using OpenGL and SDL on linux as a hobby and to learn more about this area of programming. Wondering about the best way to simulate time while the game is running. Obviously I have a loop that looks something like: void main_loop() { while(!quit) { handle_events(); DrawScene(); ... SDL_Delay(time_left()); } } I am using the SDL_Delay and time_left() to maintain a framerate of about 33 fps. I had thought that I just need a few global variables like int current_hour = 0; int current_min = 0; int num_days = 0; Uint32 prev_ticks = 0; Then a function like : void handle_time() { Uint32 current_ticks; Uint32 dticks; current_ticks = SDL_GetTicks(); dticks = current_ticks - prev_ticks; // get difference since last time // if difference is greater than 30000 (half minute) increment game mins if(dticks >= 30000) { prev_ticks = current_ticks; current_mins++; if(current_mins >= 60) { current_mins = 0; current_hour++; } if(current_hour > 23) { current_hour = 0; num_days++; } } } and then call the handle_time() function in the main loop. It compiles and runs (using printf to write the time to the console at the moment) but I am wondering if this is the best way to do it. Is there easier ways or more efficient ways? ""just need a few global variables"" - don't. There are nearly always better alternatives e.g. a `struct` wich contains the information and gets passed around. What exactly are you trying to do? I haven't tried SDL but will the ticks be dependent on the processor rate or is it always locked to milliseconds? You want to have a simulated minute every 30 seconds? SDL_GetTicks -- Gets the number of milliseconds since SDL library initialization. Based on this I am trying to simulate a minute every 30 seconds. Global state like time which is used by everything everywhere really ought to be in a global variable. Otherwise you'd have to pass your ""current time and framecount"" struct to every single function in the entire game. That assumes the entire game needs the current time and framecount which I'm pretty sure it doesn't. In my experience I get the time in the main loop and pass it to the update function that's it. Few places really need this data. I have the opposite experience. We use gpGlobals->currenttime absolutely everywhere: in the particle systems AI behavior speech special effects trigger hysteresis weapon fire rates (and projectile movement) animation scripting on and on. I grepped just now and found 4707 uses in one game DLL alone. Other than the issues already pointed out (you should use a structure for the times and pass it to handle_time() and your minute will get incremented every half minute) your solution is fine for keeping track of time running in the game. However for most game events that need to happen every so often you should probably base them off of the main game loop instead of an actual time so they will happen in the same proportions with a different fps.  I am not a Linux developer but you might want to have a look at using Timers instead of polling for the ticks. http://linux.die.net/man/2/timer_create EDIT: SDL Seem to support Timers: SDL_SetTimer If you look at the handle_time() function it's clear that he's not just counting minutes and hours for the fps ( which is handled by DrawScene()). As far as I understand he wanted to keep a ""clock"" in the game. I accept your comment performance in game development and I won't argue with you here as it's not my field.But as an idea for a different implementation I don't think there was anything fundamentally wrong with my answer While good advice in general this is not a good idea for game development. Not even for displaying the time in the game like he does ? Do you actually use polling instead ? zildjohn01: why are timers are a bad idea for a game? I am assuming they have some sort of performance impact? This is bad because you don't want a game to have a callback that does something every (n) milliseconds -- some frames might finish a little ahead of 33 and some others might lag behind. If you have a frame that takes 37 milliseconds and then set the next frame for 33 after that then you'll be effectively slowing down time as your two frames (representing 66ms of game time) would take place over 70ms of real time. It's much better to have the game loop running at full speed all the time -- never sleeping or pausing -- and use a high-resolution realtime clock to mark constant timesteps. I never suggested handling the frames with a timer. He was asking about Time. That's why he wanted the time: ""I am using the SDL_Delay and time_left() to maintain a framerate of about 33 fps.""  One of Glenn's posts you will really want to read is Fix Your Timestep!. After looking up this link I noticed that Mads directed you to the same general place in his answer.  I've mentioned this before in other game related threads. As always follow the suggestions by Glenn Fiedler in his Game Physics series What you want to do is to use a constant timestep which you get by accumulating time deltas. If you want 33 updates per second then your constant timestep should be 1/33. You could also call this the update frequency. You should also decouple the game logic from the rendering as they don't belong together. You want to be able to use a low update frequency while rendering as fast as the machine allows. Here is some sample code: running = true; unsigned int t_accum=0lt=0ct=0; while(running){ while(SDL_PollEvent(&event)){ switch(event.type){ ... } } ct = SDL_GetTicks(); t_accum += ct - lt; lt = ct; while(t_accum >= timestep){ t += timestep; /* this is our actual time in milliseconds. */ t_accum -= timestep; for(std::vector<Entity>::iterator en = entities.begin(); en != entities.end(); ++en){ integrate(en (float)t * 0.001f timestep); } } /* This should really be in a separate thread synchronized with a mutex */ std::vector<Entity> tmpEntities(entities.size()); for(int i=0; i<entities.size(); ++i){ float alpha = (float)t_accum / (float)timestep; tmpEntities[i] = interpolateState(entities[i].lastState alpha entities[i].currentState 1.0f - alpha); } Render(tmpEntities); } This handles undersampling as well as oversampling. If you use integer arithmetic like done here your game physics should be close to 100% deterministic no matter how slow or fast the machine is. This is the advantage of increasing the time in fixed time intervals. The state used for rendering is calculated by interpolating between the previous and current states where the leftover value inside the time accumulator is used as the interpolation factor. This ensures that the rendering is is smooth no matter how large the timestep is. This is essentially what we do (in our commercial product). We run our game logic at a constant timestep of 10hz but let the rendering thread run as fast as possible and draw frames as quickly as the GPU is ready for them. This means that physics and AI and entity logic isn't impacted by render speed (otherwise the world would go into slow-time when the rendering bogged down). The rendering isn't on a constant timestep it just goes as fast as it can (up to 60hz of course). @Crashworks : Exactly. You don't care about a fixed timestep for the rendering. It would make the rendering choppy. One can make the case that there *should* be a constant rendering timestep too since a variable framerate feels choppier than a consistent one and because the monitor is updating at 30/60hz (or 25/50 for PAL) so any frame that isn't aligned with a vsync interval will ""tear"" in the middle of the screen. It's very subjective though so we made ""wait for vsync"" a customer-settable option. Hah NTSC vs PAL differences was actually the reason why SEGA Genesis games for European consoles ran faster than North American ones. So even game consoles suffered from this issue though less than PC games from the same era. @Mads In which part of the above code (integrate or interpolate) is collision detection done?",c++ opengl sdl1270517,A,"Porting project to my laptop results in a blank screen So I'm making something in openGL using SDL. I'm about to take a long flight and I can't seem to get the project to work on my laptop. I've used SDL on my laptop before so I'm left thinking it is openGL's fault. The laptop is on win xp pro and has an intel 945 graphics ""card."" I've tried updating the drivers but to no avail. The images I'm using can't be the problem because I have it coded so the program closes if it can't locate the file. Also I get no errors at all when compiling it just creates the window and instead of all my images I get white. Just white. Any ideas? Please I don't want to be on this 5 hr flight and go stir crazy =/ Do the SDL NeHe (http://nehe.gamedev.net/lesson.asp?index=02) demos work? You might need to provide a bit more info but at a guess I'd say your textures are invalid. OpenGL draws white when there is a texture problem. Possible reasons are... Image size is bigger than the max texture size of the graphics chip Image isn't power of 2 and the card doesn't support rectangular textures. You have run out of texture memory. Your texture env isn't supported by the graphics chip eg. unsupported format. You aren't drawing what you think you are drawing eg a white quad on a white background in the position you think you are drawing it ie you're looking in the wrong direction. Programmer error. Try drawing a single 128x128 texture on a single quad with a glcolor of purple and a clear colour of orange. This will eliminate most of the above problems and give you something to debug. It's been a while but maybe this can help someone else. I knew about the power of 2 however it slipped my mind that my desktop has a much new/better gfx card than my laptop does. So while my desktop could compensate for the non-power-of-2-sizes my laptop's gfx card could not.",c++ gui opengl sdl721998,A,Why does my colored cube not work with GL_BLEND? My cube isn't rendering as expected when I use GL_BLEND. glEnable(GL_CULL_FACE); glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA GL_ONE); I'm also having a similar problem with drawing some semi-opaque vertices in front which could well be related. Related: Why do my semi-opaque vertices make background objects brighter in OpenGL? Here's what it's supposed to look like: And here's what it actually looks like: Please see the code used to create the colored cube and the code used to actually draw the cube. The cube is being drawn like so: glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); glPushMatrix(); glLoadIdentity(); // ... do some translation rotation etc ... drawCube(); glPopMatrix(); // ... swap the buffers ... Did you get the first picture from your program? It looks like you have lighting enabled on the second one try with a glShadeModel( GL_FLAT ) before drawing Hmm no this makes the sides of the cube solid colours but only 3 of them...  You could try disabling all lighting before drawing the cube: glDisable(GL_LIGHTING);  This has me stomped. What it looks like is that some vertices have some alpha values that are non-opaque. However the code you posted has all 1. for alpha. So... in order to debug more did you try to change your clear color to something non-black ? Say green ? From the code I doubt lighting is turned on since no normals were specified. Last comment offtopic... You should really not use glBegin/glEnd (2 function calls per vertex + 2 per primitive is really not a good usage of the recent developments in OpenGL). Try glDrawElements with QUAD_LIST or even better TRIANGLE_LIST. You already have the data nicely laid out for that.,c++ opengl blend1191093,A,"I'm seeing artifacts when I attempt to rotate an image This is the before: znd after: EDIT:: Now that I look at imageshack's upload the artifacts are diminished a great deal.. but trust me they are more pronounced than that. I don't understand why this is happening. Imageshack uploads them to jpg but in my program they are in the image folder as .tif (The reason for .tif is because I couldn't get ANY other image to maintain their transparent parts). But anyways these artifacts follow the original top of the image as it rotates anywhere except the original. Here's part of my code that loads the image GLuint texture; GLenum texture_format; GLint nofcolors; GLfloat spin; bool Game::loadImage() { SDL_Surface * surface; // this surface will tell us the details of the image if ( surface = SM.load_image(""Images/tri2.tif"") ) { //get number of channels in the SDL surface nofcolors = surface->format->BytesPerPixel; //contains an alpha channel if ( nofcolors == 4 ) { if ( surface->format->Rmask == 0x000000ff ) texture_format = GL_RGBA; else texture_format = GL_BGRA; } else if ( nofcolors == 3 ) //no alpha channel { if ( surface->format->Rmask == 0x000000ff ) texture_format = GL_RGB; else texture_format = GL_BGR; } // Have OpenGL generate a texture object handle for us glGenTextures( 1 &texture ); // Bind the texture object glBindTexture( GL_TEXTURE_2D texture ); // Set the textureŠ—Ès stretching properties glTexParameteri( GL_TEXTURE_2D GL_TEXTURE_MIN_FILTER GL_LINEAR ); glTexParameteri( GL_TEXTURE_2D GL_TEXTURE_MAG_FILTER GL_LINEAR ); glTexImage2D( GL_TEXTURE_2D 0 nofcolors surface->w surface->h 0 texture_format GL_UNSIGNED_BYTE surface->pixels ); glEnable(GL_TEXTURE_2D); glEnable(GL_BLEND); glBlendFunc(GL_ONE GL_ONE_MINUS_SRC_ALPHA); } else { SDL_Quit(); return false; } // Free the SDL_Surface only if it was successfully created if ( surface ) { SDL_FreeSurface( surface ); return true; } else return false; } void Game::drawImage() { // Clear the screen before drawing glClear( GL_COLOR_BUFFER_BIT ); glTranslatef( float(S_WIDTH/2) float(S_HEIGHT/2) 0.0f ); glRotatef( spin 0.0 0.0 1.0 ); // Bind the texture to which subsequent calls refer to glBindTexture( GL_TEXTURE_2D texture ); glBegin( GL_QUADS ); { // Top-left vertex (corner) glTexCoord2i( 0 0 ); glVertex3f( -64 0 0 ); // Top-right vertex (corner) glTexCoord2i( 1 0 ); glVertex3f( 64 0 0 ); // Bottom-right vertex (corner) glTexCoord2i( 1 1 ); glVertex3f( 64 128 0 ); // Bottom-left vertex (corner) glTexCoord2i( 0 1 ); glVertex3f( -64 128 0 ); } glEnd(); glLoadIdentity(); SDL_GL_SwapBuffers(); } lol when I loaded this page I thought your artifacts were dust on my screen and I tried wiping it off. Try saving as PNG? PNG format won't load transparency correctly in my program. Nor will anything else except TIF. It is driving me insane.. Looks like the texture is set to GL_WRAP. Try GL_CLAMP_TO_EDGE instead. Yep it's definitely wrapping. I just started OpenGL like a day or two ago I don't see any place where I typed GL_WRAP... so where do I put the clamp to edge part? Insert the following right after you set the min/mag filters: glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_WRAP_S GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_WRAP_T GL_CLAMP_TO_EDGE); Ah that worked thanks a lot. Now I gotta figure out this annoying (lack of) transparency in images.  In Game::loadImage after your glBindTexture call: glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_WRAP_S GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D GL_TEXTURE_WRAP_T GL_CLAMP_TO_EDGE); Your current setting is GL_REPEAT which is the OpenGL default.",c++ gui opengl789904,A,"OpenGL Color Matrix How do I get the OpenGL color matrix transforms working? I've modified a sample program that just draws a triangle and added some color matrix code to see if I can change the colors of the triangle but it doesn't seem to work.  static float theta = 0.0f; glClearColor( 1.0f 1.0f 1.0f 1.0f ); glClearDepth(1.0); glClear( GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); glPushMatrix(); glRotatef( theta 0.0f 0.0f 1.0f ); glMatrixMode(GL_COLOR); GLfloat rgbconversion[16] = { 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f 0.0f }; glLoadMatrixf(rgbconversion); glMatrixMode(GL_MODELVIEW); glBegin( GL_TRIANGLES ); glColor3f( 1.0f 0.0f 0.0f ); glVertex3f( 0.0f 1.0f  0.5f); glColor3f( 0.0f 1.0f 0.0f ); glVertex3f( 0.87f -0.5f 0.5f ); glColor3f( 0.0f 0.0f 1.0f ); glVertex3f( -0.87f -0.5f 0.5f ); glEnd(); glPopMatrix(); As far as I can tell the color matrix I'm loading should change the triangle to black but it doesn't seem to work. Is there something I'm missing? It looks like you're doing it correctly but your current color matrix sets the triangle's alpha value to 0 as well so while it is being drawn it does not appear on the screen. I added a glEnable(GL_BLEND); but it still doesn't affect the picture. It's still a red/green/blue triangle. It appears that the color matrix is having no effect. Actually the triangle is still drawn in its original red green and blue so I don't believe the color matrix is affecting the alpha component. the alpha component will only affect the final image if transparency is enabled which it apparently is not.  ""Additionally if the ARB_imaging extension is supported GL_COLOR is also accepted."" From the glMatrixMode documentation. Is the extension supported on your machine? As far as I know ARB_imaging is enabled but how do I find out? I'm using VS 2008. I've run the OpenGL Extensions Viewer and it does say that GL_ARB_imaging is a valid extension on my machine.  I have found the possible problem. The color matrix is supported by the ""Image Processing Subset"". In most HW it was supported by driver.(software implementation) Solution: Add this line after glEnd(): glCopyPixels(00 getWidth() getHeight()GL_COLOR); It's very slow....  The color matrix only applies to pixel transfer operations such as glDrawPixels which aren't hardware accelerated on current hardware. However implementing a color matrix using a fragment shader is really easy. You can just pass your matrix as a uniform mat4 then mulitply it with gl_FragColor",c++ opengl colors525227,A,"Console menu updating OpenGL window I am making an application that does some custom image processing. The program will be driven by a simple menu in the console. The user will input the filename of an image and that image will be displayed using openGL in a window. When the user selects some processing to be done to the image the processing is done and the openGL window should redraw the image. My problem is that my image is never drawn to the window instead the window is always black. I think it may have to do with the way I am organizing the threads in my program. The main execution thread handles the menu input/output and the image processing and makes calls to the Display method while a second thread runs the openGL mainloop. Here is my main code: #include <iostream> #include <GL/glut.h> #include ""ImageProcessor.h"" #include ""BitmapImage.h"" using namespace std; DWORD WINAPI openglThread( LPVOID param ); void InitGL(); void Reshape( GLint newWidth GLint newHeight ); void Display( void ); BitmapImage* b; ImageProcessor ip; int main( int argc char *argv[] ) { DWORD threadID; b = new BitmapImage(); CreateThread( 0 0 openglThread NULL 0 &threadID ); while( true ) { char choice; string path = ""TestImages\\""; string filename; cout << ""Enter filename: ""; cin >> filename; path += filename; b = new BitmapImage( path ); Display(); cout << ""1) Invert"" << endl; cout << ""2) Line Thin"" << endl; cout << ""Enter choice: ""; cin >> choice; if( choice == '1' ) { ip.InvertColour( *b ); } else { ip.LineThinning( *b ); } Display(); } return 0; } void InitGL() { int argc = 1; char* argv[1]; argv[0] = new char[20]; strcpy( argv[0] ""main"" ); glutInit( &argc argv ); glutInitDisplayMode( GLUT_DOUBLE | GLUT_RGB | GLUT_DEPTH); glutInitWindowPosition( 0 0 ); glutInitWindowSize( 800 600 ); glutCreateWindow( ""ICIP Program - Character recognition using line thinning Hilbert curve and wavelet approximation"" ); glutDisplayFunc( Display ); glutReshapeFunc( Reshape ); glClearColor(0.00.00.01.0); glEnable(GL_DEPTH_TEST); } void Reshape( GLint newWidth GLint newHeight ) { /* Reset viewport and projection parameters */ glViewport( 0 0 newWidth newHeight ); } void Display( void ) { glClear (GL_COLOR_BUFFER_BIT); // Clear display window. b->Draw(); glutSwapBuffers(); } DWORD WINAPI openglThread( LPVOID param ) { InitGL(); glutMainLoop(); return 0; } Here is my draw method for BitmapImage: void BitmapImage::Draw() { cout << ""Drawing"" << endl; if( _loaded ) { glBegin( GL_POINTS ); for( unsigned int i = 0; i < _height * _width; i++ ) { glColor3f( _bitmap_image[i*3] / 255.0 _bitmap_image[i*3+1] / 255.0 _bitmap_image[i*3+2] / 255.0 ); // invert the y-axis while drawing glVertex2i( i % _width _height - (i / _width) ); } glEnd(); } } Any ideas as to the problem? Edit: The problem was technically solved by starting a glutTimer from the openglThread which calls glutPostRedisplay() every 500ms. This is OK for now but I would prefer a solution in which I only have to redisplay every time I make changes to the bitmap (to save on processing time) and one in which I don't have to run another thread (the timer is another thread im assuming). This is mainly because the main processing thread is going to be doing a lot of intensive work and I would like to dedicate most of the resources to this thread rather than anything else. You need to make OpenGL calls on the thread in which context was created (glutInitDisplayMode). Hence glXX calls inside Display method which is on different thread will not be defined. You can see this easily by dumping the function address hopefully it would be undefined or NULL.  It sounds like the 500ms timer is calling Display() regularly after 2 calls it fills the back-buffer and the front-buffer with the same rendering. Display() continues to be called until the user enters something which the OpenGL thread never knows about but since global variable b is now different the thread blindly uses that in Display(). So how about doing what Jesse Beder says and use a global int call it flag to flag when the user entered something. For example: set flag = 1; after you do the b = new BitmapImage( path ); then set flag = 0; after you call Display() from the OpenGL thread. You loop on the timer but now check if flag = 1. You only need call glutPostRedisplay() when flag = 1 i.e. the user entered something. Seems like a good way without using a sleep/wake mechanism. Accessing global variables among more than one thread can also be unsafe. I think the worst that can happen here is the OpenGL thread miss-reads flag = 0 when it should read flag = 1. It should then catch it after no more than a few iterations. If you get strange behavior go to synchronization. With the code you show you call Display() twice in main(). Actually main() doesn't even need to call Display() the OpenGL thread does it.  Your problem may be in Display() at the line b->Draw(); I don't see where b is passed into the scope of Display(). b is declared globally just above main() Yes I see it now in the morning light.  I've had this problem before - it's pretty annoying. The problem is that all of your OpenGL calls must be done in the thread where you started the OpenGL context. So when you want your main (input) thread to change something in the OpenGL thread you need to somehow signal to the thread that it needs to do stuff (set a flag or something). Note: I don't know what your BitmapImage loading function (here your constructor) does but it probably has some OpenGL calls in it. The above applies to that too! So you'll need to signal to the other thread to create a BitmapImage for you or at least to do the OpenGL-related part of creating the bitmap. That's not entirely accurate the requirement is that the OpenGL context can only be _current_ to any single thread. The context can however be created in a different thread than which it is current. This is useful for offscreen rendering for example. Just to clarify the problem in this case is definitely the multithreaded rendering though since the OP is making gl calls from different threads using the same context or rather a non-existent context (in the main thread). Re comment #1 that's true but I thought it was irrelevant (and unnecessary complication) for this particular example.  A few points: Generally if you're going the multithreaded route it's preferable if your main thread is your GUI thread i.e. it does minimal tasks keeping the GUI responsive. In your case I would recommend moving the intensive image processing tasks into a thread and doing the OpenGL rendering in your main thread. For drawing your image you're using vertices instead of a textured quad. Unless you have a very good reason it's much faster to use a single textured quad (the processed image being the texture). Check out glTexImage2D and glTexSubImage2D. Rendering at a framerate of 2fps (500ms as you mentioned) will have negligible impact on resources if you're using an OpenGL implementation that is accelerated which is almost guaranteed on any modern system and if you use a textured quad instead of a vertex per pixel.",c++ multithreading opengl console679113,A,"Trouble porting OpenGL app to Windows I am trying to move an OpenGL app to Windows. It was my understanding that Windows had a decent OpenGL implementation. But I'm starting to think that it doesn't... Specifically I use array buffers and glDrawArrays. When I tried to compile my code in Visual Studio 2008 Pro I received the following errors: vertexbuffers.cpp(31) : error C3861: 'glGenBuffers': identifier not found vertexbuffers.cpp(32) : error C2065: 'GL_ARRAY_BUFFER' : undeclared identifier vertexbuffers.cpp(32) : error C3861: 'glBindBuffer': identifier not found vertexbuffers.cpp(33) : error C2065: 'GL_ARRAY_BUFFER' : undeclared identifier vertexbuffers.cpp(33) : error C2065: 'GL_STATIC_DRAW' : undeclared identifier vertexbuffers.cpp(33) : error C3861: 'glBufferData': identifier not found When I examined <GL\gl.h> (contained in C:\Program Files\Microsoft SDKs\Windows\v6.0A\Include\gl) I saw: /* ClientArrayType */ /* GL_VERTEX_ARRAY */ /* GL_NORMAL_ARRAY */ /* GL_COLOR_ARRAY */ Update but it would seem that those contants get defined elsewhere. How am I supposed to generate buffers if I don't have access to those functions? The documentation doesn't say that those array types are disabled. How do I get access to the real implementation on OpenGL on Windows? Could you past the specific errors? It is possible that those comments are for documentation and that things are properly defined elsewhere. Yes I jumped the gun with those functions. My real errors come from the Buffer generation functions. Sorry for the confusion I have edited the question. Thanks for posting those it helped me understand and fix up my answer. :) The #defines are commented out in the header file whenever they would otherwise be repeated. Look at line 1054 of gl.h: /* vertex_array */ #define GL_VERTEX_ARRAY 0x8074 If this #define is actually missing then you should probably replace the file with a fresh copy. If you look at the documentation for glGenBuffers you will see that it is only available in OpenGL 1.5 and higher. The header file for Windows only comes with OpenGL 1.2 and you should use the extension mechanism to access the newer functionality. If you call wglGetProcAddress with the function name e.g. void (__stdcall *glGenBuffers)(GLsizeiGLuint*) = wglGetProcAddress(""glGenBuffers""); then you have a pointer to the function. You have better eyes than me. Thank you for the reference. Unfortunately I still have errors revolving around glBindBuffer. edited after i looked at the errors you were recieving. unfortunately the header is 1.2 only but there are easy fixes. :)  Microsoft's support for OpenGL stretches only as far as OpenGL-1.1 up to Windows XP and OpenGL-1.4 starting with Vista. Any OpenGL functionality beyond those must be delivered and supported by the installable client driver (ICD) i.e. the GPU driver's OpenGL implmenentation. To access the advanced functionality OpenGL provides the so called Extension System formed by wglGetProcAddress which is kind of like GetProcAddress for DLLs but gives access to functions of the OpenGL implementation (=driver). To make things easier nice wrapper libraries like GLEW have been developed which do all the grunt work initializing all the available OpenGL extensions providing them to the end user.  It would seem that the buffer functions are only available on Windows as extension methods. OpenGL provides glext.h that declares pointers to all of these functions. It is then up to my app to use wglGetProcAddress to get pointers to the functions. For example: PFNGLGENBUFFERSPROC myglBindBuffers = (PFNGLGENBUFFERSPROC)wglGetProcAddress(""glGenBuffersARB""); Thankfully I only have to do it for about 4 functions. Unfortunately I now have to add platform-dependent code to my app. +1 for the sensible way to find these type definitions - thanks!  You might give GLEW a shot: http://glew.sourceforge.net/ I'm pretty sure I used it at some time in the past and makes this sort of thing a little easier and more portable. Great link thank you very much.",c++ windows visual-studio opengl1854575,A,"glBitmap() without GL_COLOR_INDEX Is it somehow possible to get glBitmap() to draw a GL_RGBA bitmap? glBitmap() is a lot quicker than glDrawPixels() but perhaps that has to do with that the format is GL_COLOR_INDEX instead of GL_RGBA? I'm running my glDrawPixels() in a display list; is there perhaps some smart way to speed it up? From the documentation: ""A bitmap is a binary image"" - Here a ""binary image"" simply means an image in which every pixel has exactly two possible colors which map to ""transparent"" and ""the current raster color"". You can't paint anything else using this function. Some other things you can try to achieve the same effect possibly with better performance: Drawing a screen-aligned quad with a texture Drawing a textured point sprite using texture coordinate replacement",c++ performance opengl1370683,A,Opengl Selective glClipPlane I have a scene drawn in openGL (openGl 1.1 win32). I use glClipPlane to hide foreground objects to allow the user to see/edit distance parts. The selection is done natively without using openGL. But the glClipPlane applies to all openGL elements - coordinate icons gridlines etc and even elements drawn in gluOrtho2D on top - scale bars selection boxes etc. Is there anyway to selective override the clipplanes to allow these elements to be drawn while clipping the main scene? Isn't surrounding only the objects you want to hide with glEnable(GL_CLIP_PLANE); and glDisable(GL_CLIP_PLANE); enough? Yes it would have been even better if I disabled the plane with the same GL_CLIP_PLANEi that I enabled it with ! It's funny how after starring at it for hours you spot the error just after you explain it to someone else.,c++ opengl graphics1975778,A,"OpenGL antialiasing isn't working I'm using the following code in order to antialias only the edges of my polygons: glHint(GL_POLYGON_SMOOTH_HINT GL_NICEST); glEnable(GL_POLYGON_SMOOTH); But it doesn't work. I can force enable antialiasing by the nvidia control panel and it does antialias my application polygons. With the code above I even enabled blending but it has no effect. Also the rendering code shouldn't be changed since the nvidia control panel can turn it on and it certainly cant modify my rendering code it must be some on/off flag. What is it? I've heard of ""multisampling"" but I don't need that. Edit: the nvidia control panel setting is ""application controlled"" when it doesn't work. do you create your render context with multisampling? that's what nvidia's control panel changes. It depends on your window system / framework usually there is a 'samples' value you can set to 4 or 8 somewhere. In windows it goes into the pixel format struct. Have you got the Antialiasing Settings"" in the nVidia control panel set to ""Application-Controlled""? Most likely your hardware does not support it. Not all OpenGL implementations support antialiased polygons; see the OpenGL FAQ. I've definitely run into this problem before on a first-generation MacBook -- its GPU the Intel GMA 950 does not support antialiased polygons. geforce 8800GTS should support though  It may be that your glEnable call is after the glHint call. nope i tried both ways. Interesting I'm unable to replicate what you're seeing with any of my code. I've got a hunch the NVidia Control Panel is not being your friend.  You need to ask for a visual/pixelformat with support for multisampling. This is an attribute in the attribute list you pass to glXChooseFBConfig when using GLX/XLib and wglChoosePixelformatARB when using the Win32 API. See my post here: http://stackoverflow.com/questions/1513811/getting-smooth-big-points-in-opengl/1513979#1513979  Try enabling blending glBlendFunc(GL_SRC_ALPHA_SATURATE GL_ONE); glEnable(GL_BLEND); glEnable(GL_POLYGON_SMOOTH); Also following article might help http://www.edm2.com/0603/opengl.html",c++ opengl536314,A,Texturing Spheres with Cubemaps (not reflection maps) I want to texture a sphere with a cube map. So far my research has thrown up many many results on Google involving making OpenGL auto generate texture coordinates but I want to generate my own coordinates. Given an array of coordinates comprising the vertexes of an imperfect sphere (height mapped but essentially a sphere) centered on 000 how would one generate texture coordinates for a cube map? Are you doing this via GLSL? In that case textureCube accepts a vec3 as texture coordinate which is a unit vector on a sphere. In your case you would take the coordinate of your fragment with respect to the center of the sphere normalize it and pass it as a coordinate. No need to worry about the internal representation as six two-dimensional textures. uniform samplerCube cubemap; varying vec3 pos; // position of the fragment w.r.t. the center of the sphere /* ... */ vec4 color = textureCube(cubemap normalize(pos).stp); It works like that also in fixed-pipeline OpenGL. By the way here is how the coordinates are used internally: the largest coordinate in absolute value is used to select which one of the six textures is read from (the sign selects positive or negative). The other two coordinates are used to lookup the texel in the selected map after being divided by the largest coordinate. *slaps head* thankyou! I'm working in plain C++ atm but eventually moving to GLSL once I know more about it,c++ opengl texture-mapping259890,A,"OpenGL glDrawPixels on dynamic 3D arrays How do you draw the following dynamic 3D array with OpenGL glDrawPixels()? You can find the documentation here: http://opengl.org/documentation/specs/man_pages/hardcopy/GL/html/gl/drawpixels.html float ***array3d; void InitScreenArray() { int i j; int screenX = scene.camera.vres; int screenY = scene.camera.hres; array3d = (float ***)malloc(sizeof(float **) * screenX); for (i = 0 ; i < screenX; i++) { array3d[i] = (float **)malloc(sizeof(float *) * screenY); for (j = 0; j < screenY; j++) array3d[i][j] = (float *)malloc(sizeof(float) * /*Z_SIZE*/ 3); } } I can use only the following header files: #include <math.h> #include <stdlib.h> #include <windows.h> #include <GL/gl.h> #include <GL/glu.h> #include <GL/glut.h> Is this for homework? Yes but it's just a mall part I can't solve. The whole homework will be a ray tracer and this structure stores the screen pixels. Uh ... Since you're allocating each single pixel with a separate malloc() you will have to draw each pixel with a separate call to glDrawPixels() too. This is (obviously) insane; the idea of bitmapped graphics is that the pixels are stored in an adjacent compact format so that it is quick and fast (O(1)) to move from one pixel to another. This looks very confused to me. A more sensible approach would be to allocate the ""3D array"" (which is often referred to as a 2D array of pixels where each pixel happens to consist of a red green and blue component) with a single call to malloc() like so (in C): float *array3d; array3d = malloc(scene.camera.hres * scene.camera.vres * 3 * sizeof *array3d);  Thanks unwind. I got the same advice on gamedev.net so I have implemented the following algorithm: typedef struct { GLfloat R G B; } color_t; color_t *array1d; void InitScreenArray() { long screenX = scene.camera.vres; long screenY = scene.camera.hres; array1d = (color_t *)malloc(screenX * screenY * sizeof(color_t)); } void SetScreenColor(int x int y float red float green float blue) { int screenX = scene.camera.vres; int screenY = scene.camera.hres; array1d[x + y*screenY].R = red; array1d[x + y*screenY].G = green; array1d[x + y*screenY].B = blue; } void onDisplay( ) { glClearColor(0.1f 0.2f 0.3f 1.0f); glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); glRasterPos2i(00); glDrawPixels(scene.camera.hres scene.camera.vres GL_RGB GL_FLOAT array1d); glFinish(); glutSwapBuffers(); } My application doesn't work yet (nothing appears on screen) but I think it's my fault and this code will work.  wouldn't you want to use glTexImage2D() instead: see here",c++ arrays opengl graphics331866,A,Events in cpp/opengl Hello I would like to create infrastructure to handle events for my opengl project. It should be similar to what wpf has - 3 types of events - direct tunneling bubbling. I then want to handle events such as mouse up down move etc. How should i approach this problem? Is there any library to handle this. thanks The OpenGL Utility Toolkit (GLUT) provides precisely this - you set up a bunch of event handlers for things like keyboard input mouse input redrawing the display and window resizing call the glutMainLoop() function and you're good to go.,c++ events opengl793327,A,fixing glCopyTexSubImage2D upside down textures Since I've started learning about rendering to a texture I grew to understand that glCopyTexSubImage2D() will copy the designated portion of the screen upside down. I tried a couple of simple things that came to mind in order to prevent/work around this but couldn't find an elegant solution. there are two problems with doing a ::glScalef(1.0f -1.0f 1.0f) before rendering the texture to the screen: 1 I have to do this every time I'm using the texture. 2 I'm mostly working with 2D graphics and have backface culling turned off for GL_BACKsides. As much as possible I'd love to save switching this on and off. tried switching matrix mode to GL_TEXTURE and doing the ::glScalef(1.0f -1.0f 1.0f) transformation on capturing but the results were the same. (I'm guessing the texture matrix only has an effect on glTexCoord calls?) So how can I fix the up-down directions of textures captured with glCopyTexSubImage2D? If my understanding is correct it depends on where your origin is. That function seems to assume your origin is in the bottom-left whereas most 2D stuff assumes an origin of the top-left which is why it seems upside down. I suppose you could change the origin to the bottom-left do the capture then change the origin back to the top-left and render again before doing the swap. But that's a horrible solution since you're effectively rendering twice but it might be fine if you don't plan to do it every frame.  What are you going to be using the texture images for? Actually trying to render them upside down would usually take more work than moving that code somewhere else. If you're trying to use the image without exporting it just flipping the texture coordinates wherever you're using the result would be the most efficient way. If you're trying to export it then you either want to flip them yourself after rendering. On a related note if you are making a 2D game why is backface culling turned on? Good point. It was a case of guesswork optimization I'm afraid.=) Also I didn't need to flip textures for this game - not until now anyhow. I have still to see how much slower is it going to be but in the meantime turning backface culling off and flipping does seem to be the easiest and most elegant solution. Thank you!  Use glReadPixels() to copy to a buffer flip the image then use glTexImage2D() to write it back.,c++ opengl capture render textures977629,A,"OpenGL Rotation Matrices And ArcBall I have been tasked with creating a OpenGL scene implementing ideas such as simple movement and an Arcball interface. The problem I am having is dealing with the rotation matrix which NeHe's Arcball class (http://nehe.gamedev.net/data/lessons/lesson.asp?lesson=48) computes. What I have so far is a very simple solar system (just the earth moon and sun) which looks great. What I want is for the camera to follow whichever planet the user selects (by clicking on the one they want) and for them to be able to rotate around the planet at a fixed distance using mouse-drag (arcball). As I said at the beginning NeHe's class is generating a rotation matrix based on the mouse clicking and dragging. What I want to apply the matrix to is the camera position. However when I do that my camera just wobbles without ever rotating around the planet. So I am guessing that I am either missing some step or that I have a horrible understanding of what I am trying to do. Here is some code from my camera class to crunch on: // transform is the matrix from NeHe's arcball interface void camera::update(Matrix4fT transform) { glm::mat4 transform_m = glm::mat4(0.0f); // convert nehe's matrices to GLM matrix for(int i=0; i < 4; i++) for(int j=0; j < 4; j++) transform_m[i][j] = transform.M[i*4+j]; // apply matrix to the position glm::vec4 pos4 = glm::vec4(this->pos 1.0f); pos4 = transform_m * pos4; this->pos = glm::vec3(pos4); } void camera::apply(planet *target) { // called at the beginning of GLPaint gluLookAt(this->pos.xthis->pos.ythis->pos.z // cam->position target->pos.xtarget->pos.ytarget->pos.z // moving this->up.xthis->up.ythis->up.z); // (010) } Other than that NeHe's functions are called in the right places (during click and drag)... So really I have no idea where to go from here. I hope someone can help me with this and if you want to see the whole code base (its programmed in C++ and pushed into a QTPanel) just send me an email. Thanks Carl Sverre (carl at carlsverre dot com) What does the ""transform"" matrix at camera::update represent exactly? As far as I understand the transform matrix should represent the required rotation of a sphere according to the arcball class. Hence if the user clicks one point at xyz on the sphere and moves the mouse to x2y2z2 the matrix will represent the required rotation of the sphere to move xyz to x2y2z2. Hope that makes sense. Well maybe I am wrong but what I think that is happening to you is that you are rotating around the center of coordinates and not around the planet (that it's what you want to do). To correct that what you have to do is: Translate the point you want to rotate around (the center of the planet) to the center of coordinates applying a translation of the negation of its position Rotate as you are doing it Undo the translation previously done. The thing to understand is that rotations are done around the center of coordinates and if you want to rotate around somewhere different you must first move that point to the center of coordinates. Hope that it helps. Well I solved the problem but I went down a different path. I made sure that the sphere I was rotating about was at 000 and rather than rotating the camera I just rotated the scene. Anyways long story short its fixed. I will give this one to you because no one else answered and your answer helped me get to my solution. Cheers Hey thanks for the answer! I tried to implement what you mentioned like so: http://2dsquid.pastebin.com/m510b0130 Unfortunately it didn't work and results in my camera flying away from my planet until the whole scene is out of the frustrum. Maybe I have the order wrong in the multiplication... Any suggestions? So I figured out the zooming out problem (my rotation matrix was computed on a sphere around 000 so I was transforming 1 to many times)... Now the camera sorta rotates around the planet like it should except it rotates at light speed and if I rotate to the left for awhile and then try to rotate to the right it keeps rotating to the left until it seems to ""normalize"" and then start rotating to the right. And any up/down motion messes it all up. Any ideas? If it is rotating too fast you must configure your multiplication parameters to make it rotate slower.. I don't know exactly how are you getting the parameters but it's a matter of ""playing"" with the values to get your desired effect.",c++ qt opengl matrix rotation28768,A,"Simple Object to Database Product I've been taking a look at some different products for .NET which propose to speed up development time by providing a way for business objects to map seamlessly to an automatically generated database. I've never had a problem writing a data access layer but I'm wondering if this type of product will really save the time it claims. I also worry that I will be giving up too much control over the database and make it harder to track down any data level problems. Do these type of products make it better or worse in the already tough case that the database and business object structure must change? For example: Object Relation Mapping from Dev Express In essence is it worth it? Will I save ""THAT"" much time effort and future bugs? I was discussing this with a friend over the weekend and it seems like the gains you make on ease of storage are lost if you need to be able to query the database outside of the application. My understanding is that these databases work by storing your object data in a de-normalized fashion. This makes it fast to retrieve entire sets of objects but if you need to select data from a perspective that doesn't match your object model the odbms might have a hard time getting at the particular data you want.  There are lots of choices of ORMs. Linq to Sql nHibernate. For pure object databases there is db4o. It depends on the application but for a high volume enterprise application I would not go this route. You need more control of your data.  I've found iBatis from the Apache group to be an excellent solution to this problem. My team is currently using iBatis to map all of our calls from Java to our MySQL backend. It's been a huge benefit as it's easy to manage all of our SQL queries and procedures because they're all located in XML files not in our code. Separating SQL from your code no matter what the language is a great help. Additionally iBatis allows you to write your own data mappers to map data to and from your objects to the DB. We wanted this flexibility as opposed to a Hibernate type solution that does everything for you but also (IMO) limits your ability to perform complex queries. There is a .NET version of iBatis as well.  I've recently set up ActiveRecord from the Castle Project for an app. It was pretty easy to get going. After creating a new app with it I even used MyGeneration to script out class files for a legacy app that ActiveRecord could use in a pretty short time. It uses NHibernate to interact with the database but takes away all the xml mapping that comes with NHibernate. The nice thing is though if necessary you already have NHibernate in your project you can use its full power if you have some special cases. I'd suggest taking a look at it.  I have used SubSonic and EntitySpaces. Once you get the hang of them I beleive they can save you time but as complexity of your app and volume of data grow you may outgrow these tools. You start to lose time trying to figure out if something like a performance issue is related to the ORM or to your code. So to answer your question I think it depends. I tend to agree with Eric on this high volume enterprise apps are not a good place for general purpose ORMs but in standard fare smaller CRUD type apps you might see some saved time.",c# .net database orm18505,A,"Sending a mouse click to a button in the taskbar using C# In an application that I am currently working on a requirement is to bring a window of an external application to the foreground. Making Win32 API calls such as BringWindowToTop and SetForeground window do not work all the time. This is due to some restrictions within Windows XP. What I would like to do instead is send simulate a mouse click the window's button on the taskbar which I am hoping will bring the window to the front. Does anyone know how this is possible? It's possible. But it's extremely sketchy. Your application may also break with the next version of Windows since it's undocumented. What you need to do is find the window handle of the taskbar then find the window handle of the child window representing the button then send it a WM_MOUSEDOWN (I think) message. Here's a bit on finding the window handle of the taskbar: http://www.codeproject.com/ FWIW the restrictions on BringWindowToTop/SetForeground are there because it's irritating when a window steals focus. That may not matter if you're working on a corporate environment. Just keep it in mind. :)  I used this in a program where I needed to simulate clicks and mouse movements; Global Mouse and Keyboard Library  To be honest I've never had an issue bringing a window to the foreground on XP/Vista/2003/2000. You need to make sure you do the following: Check if IsIconic (minimized) If #1 results in true then call ShowWindow passing SW_RESTORE Then call SetForegroundWindow I've never had problems that I can think of doing it with those steps.  Check out the section ""How to steal focus on 2K/XP"" at http://www.codeproject.com/KB/dialog/dlgboxtricks.aspx as this is exactly what you need. I wouldn't go the taskbar route as the taskbar could be hidden or simply not there.",c# .net windows winapi7990,A,"Printing from a .NET Service I am working on a project right now that involves receiving a message from another application formatting the contents of that message and sending it to a printer. Technology of choice is C# windows service. The output could be called a report I suppose but a reporting engine is not necessary. A simple templating engine like StringTemplate or even XSLT outputting HTML would be fine. The problem I'm having is finding a free way to print this kind of output from a service. Since it seems that it will work I'm working on a prototype using Microsoft's RDLC populating a local report and then rendering it as an image to a memory stream which I will then print. Issues with that are: Multi-page printing will be a big headache. Still have to use PrintDocument to print the memory stream which is unsupported in a Windows Service (though it may work - haven't gotten that far with the prototype yet) If the data coming across changes I have to change the dataset and the class that the data is being deserialized into. bad bad bad. Has anyone had to do anything remotely like this? Any advice? I already posed a question about printing HTML without user input and after wasting about 3 days on that I have come to the conclusion that it cannot be done at least not with any freely available tool. All help is appreciated. EDIT: We are on version 2.0 of the .NET framework. I think we are going to go the third party route. I like the XSL -> HTML -> PDF -> Printer flow... Winnovative's HTML to PDF looks good for the first part but I'm running into a block finding a good PDF printing solution... any suggestions? Ideally the license would be on a developer basis not on a deployed runtime basis.  In answer to your question about PDF printing I have not found an elegant solution. I was ""shell"" ing out to Adobe which was unreliable and required a user to be logged in at all times. To fix this specific problem I requested that the files we process (invoices) be formatted as multi-page Tiff files instead which can be split apart and printed using native .NET printing functions. Adobe's position seems to be ""get the user to view the file in Adobe Reader and they can click print"". Useless. I am still keen to find a good way of producing quality reports which can be output from the web server...  Printing using System.Drawing.Printing is not supported by MS as per Yann Trevin's response. However you might be able to use the new WPF-based System.Printing (I think)  Printing from a Windows service is really painful. It seems to work... sometimes... but finally it craches or throws an exception from time to time without any clear reason. It's really hopeless. Officially it's even not supported without any explanation nor any proposal for an alternate solution. Recently I have been confronted to the problem and after several unsuccessful trials and experimentations I came finally with two viable solutions: Write your own printing DLL using the Win32 API (in C/C++ for instance) then use it from your service with P/Invoke (works fine) Write your own printing COM+ component then uses it from your service. I have chosen this solution with success recently (but it was third party COM+ component not own written) It works absolutely fine too. GDI+ was never designed/tested to work in service context. Thats why it does not work. You should use GDI and it function to draw. Refer to this document to find equivalent Win32 calls : http://msdn.microsoft.com/en-us/library/aa302340.aspx#win32map_printingfunctions  I've done it. It's a pain in the A*s. The problem is that printing requires that GDI engine to be in place which normally means that you have to have the desktop which only loads when you're logged in. If you're attempting to do this from a Service on a Server then you normally aren't logged in. So first you can't run as the normal service user but instead as a real user that has interactive login rights. Then you have to tweak the service registry entries (I forget how at the moment would have to find the code which I can do tonight if you're really interested). Finally you have to pray. Your biggest long term headache will be with print drivers. If you are running as a service without a logged in user some print drivers like to pop up dialogs from time to time. What happens when your printer is out of toner? Or out of paper? The driver may pop up a dialog that will never be seen and hold up the printer queue because nobody is logged in!  We are using DevExpress' XtraReports to print from a service without any problems. Their report model is similar to that of Windows Forms so you could dynamically insert text elements and then issue the print command.  Printing from a service is a bad idea. Network printers are connected ""per-user"". You can mark the service to be run as a particular user but I'd consider that a bad security practice. You might be able to connect to a local printer but I'd still hesitate before going this route. The best option is to have the service store the data and have a user-launched application do the printing by asking the service for the data. Or a common location that the data is stored like a database. If you need to have the data printed as regular intervals setup a Task event thru the Task Scheduler. Launching a process from a service will require knowing the user name and password which again is bad security practice. As for the printing itself use a third-party tool to generate the report will be the easiest.  This may not be what you're looking for but if I needed to do this quick&dirty I would: Create a separate WPF application (so I could use the built-in document handling) Give the service the ability to interact with the desktop (note that you don't actually have to show anything on the desktop or be logged in for this to work) Have the service run the application and give it the data to print. You could probably also jigger this to print from a web browser that you run from the service (though I'd recommend building your own shell IE rather than using a full browser). For a more detailed (also free) solution your best bet is probably to manually format the document yourself (using GDI+ to do the layout for you). This is tedious error prone time consuming and wastes a lot of paper during development but also gives you the most control over what's going to the printer.  Trust me you will spend more money trying to search/develop a solution for this as compared to buying a third party component. Do not reinvent the wheel and go for the paid solution. Printing is a complex problem and I would love to see the day when better framework support is added for this.  To answer your first question this can be fairly straight forward depending on the data. We have a variety of Service-based applications that do exactly what you are asking. Typically we parse the incoming file and wrap our own Postscript or PCL around it. If you layout is fairly simple then there are some very basic PCL codes you can wrap it with to provide the font/print layup you want (I'd be more then happy to give you some guidance here offline). One you have a print ready file you can send it to a UNC printer that is shared directly to a locally installed printer or even to the IP of the device (RAW or LPR type data). If however you are going down the PDF path the simplest method is to send the PDF output to a printer that supports direct PDF printing (many do now). In this case you just send the PDF to the device and away it prints. The other option is to launch Ghostscript which should be free for your needs (check the licensing as they have a few different version some GNU some GPL etc.) and either use it's built in print function or simply convert to Postscript and send to the device. I've used Ghostscript many times in Service apps but not a huge fan as you will basically be shelling out and executing a command line app to do the conversion. That being said it's a stable app that does tend to fail gracefully  If you can output to post script some printers will print anything that gets FTPed to a certain directory on them. We used this to get past the print credits that our university exposed on us but if your service outputs to a ps then you can just ftp the ps file to the printer.",c# .net windows-services printing19589,A,"Loading System.ServiceModel configuration section using ConfigurationManager Using C# .NET 3.5 and WCF I'm trying to write out some of the WCF configuration in a client application (the name of the server the client is connecting to). The obvious way is to use ConfigurationManager to load the configuration section and write out the data I need. var serviceModelSection = ConfigurationManager.GetSection(""system.serviceModel""); Appears to always return null. var serviceModelSection = ConfigurationManager.GetSection(""appSettings""); Works perfectly. The configuration section is present in the App.config but for some reason ConfigurationManager refuses to load the system.ServiceModel section. I want to avoid manually loading the xxx.exe.config file and using XPath but if I have to resort to that I will. Just seems like a bit of a hack. Any suggestions? The <system.serviceModel> element is for a configuration section group not a section. You'll need to use System.ServiceModel.Configuration.ServiceModelSectionGroup.GetSectionGroup() to get the whole group.  http://mostlytech.blogspot.com/2007/11/programmatically-enumerate-wcf.html // Automagically find all client endpoints defined in app.config ClientSection clientSection = ConfigurationManager.GetSection(""system.serviceModel/client"") as ClientSection; ChannelEndpointElementCollection endpointCollection = clientSection.ElementInformation.Properties[string.Empty].Value as ChannelEndpointElementCollection; List<string> endpointNames = new List<string>(); foreach (ChannelEndpointElement endpointElement in endpointCollection) { endpointNames.Add(endpointElement.Name); } // use endpointNames somehow ... Appears to work well. this worked for me today Worked for me thanks! the confusing line for endpointCollection = clientSection.ElementInformation.Properties[string.Empty].Value as ChannelEndpointElementCollection; should be simplified to clientSection.Endpoints;  GetSectionGroup() does not support no parameters (under framework 3.5). Instead use: Configuration config = System.Configuration.ConfigurationManager.OpenExeConfiguration(ConfigurationUserLevel.None); ServiceModelSectionGroup group = System.ServiceModel.Configuration.ServiceModelSectionGroup.GetSectionGroup(config);  Thanks to the other posters this is the function I developed to get the URI of a named endpoint. It also creates a listing of the endpoints in use and which actual config file was being used when debugging: Private Function GetEndpointAddress(name As String) As String Debug.Print(""--- GetEndpointAddress ---"") Dim address As String = ""Unknown"" Dim appConfig As Configuration = ConfigurationManager.OpenExeConfiguration(ConfigurationUserLevel.None) Debug.Print(""app.config: "" & appConfig.FilePath) Dim serviceModel As ServiceModelSectionGroup = ServiceModelSectionGroup.GetSectionGroup(appConfig) Dim bindings As BindingsSection = serviceModel.Bindings Dim endpoints As ChannelEndpointElementCollection = serviceModel.Client.Endpoints For i As Integer = 0 To endpoints.Count - 1 Dim endpoint As ChannelEndpointElement = endpoints(i) Debug.Print(""Endpoint: "" & endpoint.Name & "" - "" & endpoint.Address.ToString) If endpoint.Name = name Then address = endpoint.Address.ToString End If Next Debug.Print(""--- GetEndpointAddress ---"") Return address End Function  This is what I was looking for thanks to @marxidad for the pointer.  public static string GetServerName() { string serverName = ""Unknown""; Configuration appConfig = ConfigurationManager.OpenExeConfiguration(ConfigurationUserLevel.None); ServiceModelSectionGroup serviceModel = ServiceModelSectionGroup.GetSectionGroup(appConfig); BindingsSection bindings = serviceModel.Bindings; ChannelEndpointElementCollection endpoints = serviceModel.Client.Endpoints; for(int i=0; i<endpoints.Count; i++) { ChannelEndpointElement endpointElement = endpoints[i]; if (endpointElement.Contract == ""MyContractName"") { serverName = endpointElement.Address.Host; } } return serverName; }",c# .net xml wcf configurationmanager20952,A,"Is there a way to get a System.Configuration.Configuration instance based on arbitrary xml? I'm trying to unit test a custom ConfigurationSection I've written and I'd like to load some arbitrary configuration XML into a System.Configuration.Configuration for each test (rather than put the test configuration xml in the Tests.dll.config file. That is I'd like to do something like this: Configuration testConfig = new Configuration(""<?xml version=\""1.0\""?><configuration>...</configuration>""); MyCustomConfigSection section = testConfig.GetSection(""mycustomconfigsection""); Assert.That(section != null); However it looks like ConfigurationManager will only give you Configuration instances that are associated with an EXE file or a machine config. Is there a way to load arbitrary XML into a Configuration instance? Looking at the members of the class I'd say the answer is probably no*. I'm not sure why you'd want to do this anyway rather than create your own XML configuration file. *That's no excluding messy reflection hacks  There is actually a way I've discovered.... You need to define a new class inheriting from your original configuration section as follows: public class MyXmlCustomConfigSection : MyCustomConfigSection { public MyXmlCustomConfigSection (string configXml) { XmlTextReader reader = new XmlTextReader(new StringReader(configXml)); DeserializeSection(reader); } } You can then instantiate your ConfigurationSection object as follows: string configXml = ""<?xml version=\""1.0\""?><configuration>...</configuration>""; MyCustomConfigSection config = new MyXmlCustomConfigSection(configXml); Hope it helps someone :-) props for actually answering his question.  I think what you're looking for is ConfigurationManager.OpenMappedExeConfiguration It allows you to open a configuration file that you specify with a file path (wrapped inside a ExeConfigurationFileMap) If what the other poster said is true and you don't wish to create a whole new XML file for testing then I'd recommend you put your Configuration edits in the Test method itself then run your tests against the freshly changed configuration data.",c# .net testing configuration configurationmanager17387,A,"Privatizing a BlogEngine.Net Installation I have a blogengine.net install that requires privatization. I'm doing research work at the moment but I have to keep my blog/journal private until certain conditions are met. How can I privatize my blogEngine.net install so that readers must log in to read my posts? I use this extension. Just save the file as RequireLogin.cs in your App_Code\Extensions folder and make sure the extension is activated. using System; using System.Data; using System.Configuration; using System.Web; using System.Web.Security; using System.Web.UI; using System.Web.UI.HtmlControls; using System.Web.UI.WebControls; using System.Web.UI.WebControls.WebParts; using BlogEngine.Core; using BlogEngine.Core.Web.Controls; using System.Collections.Generic; /// <summary> /// Summary description for PostSecurity /// </summary> [Extension(""Checks to see if a user can see this blog post."" ""1.0"" ""<a href=\""http://www.lavablast.com\"">LavaBlast.com</a>"")] public class RequireLogin { static protected ExtensionSettings settings = null; public RequireLogin() { Post.Serving += new EventHandler<ServingEventArgs>(Post_Serving); ExtensionSettings s = new ExtensionSettings(""RequireLogin""); // describe specific rules for entering parameters s.Help = ""Checks to see if the user has any of those roles before displaying the post. ""; s.Help += ""You can associate a role with a specific category. ""; s.Help += ""All posts having this category will require that the user have the role. ""; s.Help += ""A parameter with only a role without a category will enable to filter all posts to this role. ""; ExtensionManager.ImportSettings(s); settings = ExtensionManager.GetSettings(""PostSecurity""); } protected void Post_Serving(object sender ServingEventArgs e) { MembershipUser user = Membership.GetUser(); if(HttpContext.Current.Request.RawUrl.Contains(""syndication.axd"")) { return; } if (user == null) { HttpContext.Current.Response.Redirect(""~/Login.aspx""); } } }  I would think it's possible to do this in the web config file by doing something like the following: <system.web> <authorization> <allow roles=""Admin"" /> <deny users=""*"" /> </authorization> </system.web> thanks for the answer but this didn't work :( see http://www.codeplex.com/blogengine/Thread/View.aspx?ThreadId=33705  We created a simple tool that gives certain users access to certain posts according to their ASP.NET Membership Roles to acheive a somewhat similar result. http://blog.lavablast.com/post/2008/08/BlogEnginenet-Post-Security.aspx  From: BlogEngine.NET 2.5 - Private Blogs If you go into the control panel Users tab Roles sub-tab (right side) for ""Anonymous"" on the right-side Tools area hover over that and select ""Rights"". You are now on the Rights page for the Anonymous role. Uncheck everything in particular ""View Public Posts"". HOWEVER you do need to keep at least one item checked otherwise everything reverts back to the default. For example you could keep ""View Ratings on Posts"" checked. Then Save. Then anyone who is not logged in should automatically be redirected to the Login page no matter where what page they try to enter the site at. Exactly what I needed thanks.  lomaxx's answer didn't work so I decided to avoid making blogengine.net perform auth for readers. on iis i disabled anonymous access and added a guest users to the win2k3 user list.",c# .net asp.net blogs16833,A,"How do you download and extract a gzipped file with C#? I need to periodically download extract and save the contents of http://data.dot.state.mn.us/dds/det_sample.xml.gz to disk. Anyone have experience downloading gzipped files with C#? Just use the HttpWebRequest class in the System.Net namespace to request the file and download it. Then use GZipStream class in the System.IO.Compression namespace to extract the contents to the location you specify. They provide examples.  Try the SharpZipLib a C# based library for compressing and uncompressing files using gzip/zip. Sample usage can be found on this blog post: using ICSharpCode.SharpZipLib.Zip; FastZip fz = new FastZip(); fz.ExtractZip(zipFile targetDirectory"""");  Here is a post I wrote last year that shows how to decompress a gzip file using C# and the built-in GZipStream class. http://blogs.msdn.com/miah/archive/2007/09/05/zipping-files.aspx As for downloading it you can use the standard WebRequest or WebClient classes in .NET. +1 The link was helpful to me just now using compression for the first time. Nice useful concise blog entry.  The GZipStream class might be what you want.  You can use WebClient in System.Net to download: WebClient Client = new WebClient (); Client.DownloadFile(""http://data.dot.state.mn.us/dds/det_sample.xml.gz"" "" C:\mygzipfile.gz""); then use #ziplib to extract Edit: or GZipStream... forgot about that one",c# .net gzip8763,A,"Best way to play MIDI sounds using C# I'm trying to rebuild an old metronome application that was originally written using MFC in C++ to be written in .NET using C#. One of the issues I'm running into is playing the midi files that are used to represent the metronome ""clicks"". I've found a few articles online about playing MIDI in .NET but most of them seem to rely on custom libraries that someone has cobbled together and made available. I'm not averse to using these but I'd rather understand for myself how this is being done since it seems like it should be a mostly trivial exercise. So am I missing something? Or is it just difficult to use MIDI inside of a .NET application? For completeness cross platform and file format support I would use FMOD.  System.Media.SoundPlayer is a good simple way of playing WAV files. WAV files have some advantages over MIDI one of them being that you can control precisely what each instrument sounds like (rather than relying on the computer's built-in synthesizer).  You can use the media player: using WMPLib; //... WindowsMediaPlayer wmp = new WindowsMediaPlayer(); wmp.URL = Path.Combine(Application.StartupPath ""Resources/mymidi1.mid""); wmp.controls.play();  For extensive MIDI and Wave manipulation in .NET I think hands down NAudio is the solution (Also available via NuGet).  Sorry this question is a little old now but the following worked for me (somewhat copied from Win32 - Midi looping with MCISendString): [DllImport(""winmm.dll"")] static extern Int32 mciSendString(String command StringBuilder buffer Int32 bufferSize IntPtr hwndCallback); public static void playMidi(String fileName String alias) { mciSendString(""open "" + fileName + "" type sequencer alias "" + alias new StringBuilder() 0 new IntPtr()); mciSendString(""play "" + alias new StringBuilder() 0 new IntPtr()); } public static void stopMidi(String alias) { mciSendString(""stop "" + alias null 0 new IntPtr()); mciSendString(""close "" + alias null 0 new IntPtr()); } A full listing of command strings is given here. The cool part about this is you can just use different things besides sequencer to play different things say waveaudio for playing .wav files. I can't figure out how to get it to play .mp3 though. Also note that the stop and close command must be sent on the same thread that the open and play commands were sent on otherwise they will have no effect and the file will remain open. For example: [DllImport(""winmm.dll"")] static extern Int32 mciSendString(String command StringBuilder buffer Int32 bufferSize IntPtr hwndCallback); public static Dictionary<String bool> playingMidi = new Dictionary<String bool>(); public static void PlayMidi(String fileName String alias) { if (playingMidi.ContainsKey(alias)) throw new Exception(""Midi with alias '"" + alias + ""' is already playing""); playingMidi.Add(alias false); Thread stoppingThread = new Thread(() => { StartAndStopMidiWithDelay(fileName alias); }); stoppingThread.Start(); } public static void StopMidiFromOtherThread(String alias) { if (!playingMidi.ContainsKey(alias)) return; playingMidi[alias] = true; } public static bool isPlaying(String alias) { return playingMidi.ContainsKey(alias); } private static void StartAndStopMidiWithDelay(String fileName String alias) { mciSendString(""open "" + fileName + "" type sequencer alias "" + alias null 0 new IntPtr()); mciSendString(""play "" + alias null 0 new IntPtr()); StringBuilder result = new StringBuilder(100); mciSendString(""set "" + alias + "" time format milliseconds"" null 0 new IntPtr()); mciSendString(""status "" + alias + "" length"" result 100 new IntPtr()); int midiLengthInMilliseconds; Int32.TryParse(result.ToString() out midiLengthInMilliseconds); Stopwatch timer = new Stopwatch(); timer.Start(); while(timer.ElapsedMilliseconds < midiLengthInMilliseconds && !playingMidi[alias]) { } timer.Stop(); StopMidi(alias); } private static void StopMidi(String alias) { if (!playingMidi.ContainsKey(alias)) throw new Exception(""Midi with alias '"" + alias + ""' is already stopped""); // Execute calls to close and stop the player on the same thread as the play and open calls mciSendString(""stop "" + alias null 0 new IntPtr()); mciSendString(""close "" + alias null 0 new IntPtr()); playingMidi.Remove(alias); }  I can't claim to know much about it but I don't think it's that straightforward - Carl Franklin of DotNetRocks fame has done a fair bit with it - have you seen his DNRTV?  I'm working on a C# MIDI application at the moment and the others are right - you need to use p/invoke for this. I'm rolling my own as that seemed more appropriate for the application (I only need a small subset of MIDI functionality) but for your purposes the C# MIDI Toolkit might be a better fit. It is at least the best .NET MIDI library I found and I searched extensively before starting the project. Leslie's MIDI Toolkit is definitely the most comprehensive C# solution to playing recording MIDI. I have used it for a very complex project and it worked well.  I think you'll need to p/invoke out to the windows api to be able to play midi files from .net. This codeproject article does a good job on explaining how to do this: vb.net article to play midi files To rewrite this is c# you'd need the following import statement for mciSendString: [DllImport(""winmm.dll"")] static extern Int32 mciSendString(String command StringBuilder buffer Int32 bufferSize IntPtr hwndCallback); Hope this helps - good luck!  A recent addition is MIDI.NET that supports Midi Ports Midi Files and SysEx.",c# .net midi17612,A,"How do you place a file in recycle bin instead of delete? Programmatic solution of course... You need to delve into unmanaged code. Here's a static class that I've been using: public static class Recycle { private const int FO_DELETE = 3; private const int FOF_ALLOWUNDO = 0x40; private const int FOF_NOCONFIRMATION = 0x0010; [StructLayout(LayoutKind.Sequential CharSet = CharSet.Auto Pack = 1)] public struct SHFILEOPSTRUCT { public IntPtr hwnd; [MarshalAs(UnmanagedType.U4)] public int wFunc; public string pFrom; public string pTo; public short fFlags; [MarshalAs(UnmanagedType.Bool)] public bool fAnyOperationsAborted; public IntPtr hNameMappings; public string lpszProgressTitle; } [DllImport(""shell32.dll"" CharSet = CharSet.Auto)] static extern int SHFileOperation(ref SHFILEOPSTRUCT FileOp); public static void DeleteFileOperation(string filePath) { SHFILEOPSTRUCT fileop = new SHFILEOPSTRUCT(); fileop.wFunc = FO_DELETE; fileop.pFrom = filePath + '\0' + '\0'; fileop.fFlags = FOF_ALLOWUNDO | FOF_NOCONFIRMATION; SHFileOperation(ref fileop); } } Addendum: Tsk tsk @ Jeff for ""using Microsoft.VisualBasic"" in C# code. Tsk tsk @ MS for putting all the goodies in VisualBasic namespace. I guess this is one of the areas where VB is just better than C#...besides it's not ""not C#"" just because it's in the VB namespace - an object is an object not to use it just because it's in a namespace you don't like the name of is a little ridiculous don't you think?... ...if the namespace was Microsoft.UsefulUtilities you wouldn't have an reservations about using them so what's the difference? It's not about the namespace of course but that you have to link in VB libraries to use that namespace. Should be obvious.  http://www.daveamenta.com/2008-05/c-delete-a-file-to-the-recycle-bin/ From above: using Microsoft.VisualBasic; string path = @""c:\myfile.txt""; FileIO.FileSystem.DeleteDirectory(path FileIO.UIOption.OnlyErrorDialogs RecycleOption.SendToRecycleBin); I'd use DeleteFile instead of DeleteDirectory to be more clear. +1 for thinking outside the box and referencing a disliked namespace rather than resorting to ugly unmanaged code. What do these FileIO classes and methods have to do with Visual Basic? Putting them in Microsoft.VisualBasic makes absolutely no sense to me. I must be missing something. @I. J. Kennedy If I had to guess it might have been that the Visual basic team implanted the feature and rather than muck around with it the .NET team decided to leave the functionality where it was. any solution without using ""Microsoft.VisualBasic"" ? Is there any way to not show the UI at all? (i.e. raise an exception instead of showing an error dialog) Yeah I'm looking for one without having to use the Visual Basic DLL  The best way I have found is to use the VB function FileSystem.DeleteFile. Microsoft.VisualBasic.FileIO.FileSystem.DeleteFile(file.FullName Microsoft.VisualBasic.FileIO.UIOption.OnlyErrorDialogs Microsoft.VisualBasic.FileIO.RecycleOption.SendToRecycleBin); It requires adding Microsoft.VisualBasic as a reference but this is part of the .NET framework and so isn't an extra dependency. Alternate solutions require a P/Invoke to SHFileOperation as well as defining all the various structures/constants. Including Microsoft.VisualBasic is much neater by comparison.",c# .net c++ windows io4157,A,"ConfigurationManager.AppSettings Performance Concerns I plan to be storing all my config settings in my application's app.config section (using the ConfigurationManager.AppSettings class). As the user changes settings using the app's UI (clicking checkboxes choosing radio buttons etc.) I plan to be writing those changes out to the AppSettings. At the same time while the program is running I plan to be accessing the AppSettings constantly from a process that will be constantly processing data. Changes to settings via the UI need to affect the data processing in real-time which is why the process will be accessing the AppSettings constantly. Is this a good idea with regard to performance? Using AppSettings is supposed to be ""the right way"" to store and access configuration settings when writing .Net apps but I worry that this method wasn't intended for a constant load (at least in terms of settings being constantly read). If anyone has experience with this I would greatly appreciate the input. Update: I should probably clarify a few points. This is not a web application so connecting a database to the application might be overkill simply for storing configuration settings. This is a Windows Forms application. According to the MSDN documention the ConfigurationManager is for storing not just application level settings but user settings as well. (Especially important if for instance the application is installed as a partial-trust application.) Update 2: I accepted lomaxx's answer because Properties does indeed look like a good solution without having to add any additional layers to my application (such as a database). When using Properties it already does all the caching that others suggested. This means any changes and subsequent reads are all done in memory making it extremely fast. Properties only writes the changes to disk when you explicitly tell it to. This means I can make changes to the config settings on-the-fly at run time and then only do a final save out to disk when the program exits. Just to verify it would actually be able to handle the load I need I did some testing on my laptop and was able to do 750000 reads and 7500 writes per second using Properties. That is so far above and beyond what my application will ever even come close to needing that I feel quite safe in using Properties without impacting performance. Could I ask why you're not saving the user's settings in a database? Generally I save application settings that are changed very infrequently in the appSettings section (the default email address error logs are sent to the number of minutes after which you are automatically logged out etc.) The scope of this really is at the application not at the user and is generally used for deployment settings.  I would not use config files for storing user data. Use a db.  one thing I would look at doing is caching the appsettings on a read then flushing the settings from the cache on the write which should minimize the amount of actual load the server has to deal with for processing the appSettings. Also if possible look at breaking the appSettings up into configSections so you can read write and cache related settings. Having said all that I would seriously consider looking at storing these values in a database as you seem to actually be storing user preferences and not application settings.  since you're using a winforms app if it's in .net 2.0 there's actually a user settings system (called Properties) that is designed for this purpose. This article on MSDN has a pretty good introduction into this If you're still worried about performance then take a look at SQL Compact Edition which is similar to SQLite but is the Microsoft offering which I've found plays very nicely with winforms and there's even the ability to make it work with Linq  Someone correct me if I'm wrong but I don't think that AppSettings is typically meant to be used for these type of configuration settings. Normally you would only put in settings that remain fairly static (database connection strings file paths etc.). If you want to store customizable user settings it would be better to create a separate preferences file or ideally store those settings in a database.  The appSettings isn't really meant for what you are trying to do. When your .NET application starts it reads in the app.config file and caches its contents in memory. For that reason after you write to the app.config file you'll have to somehow force the runtime to re-parse the app.config file so it can cache the settings again. This is unnecessary The best approach would be to use a database to store your configuration settings. Barring the use of a database you could easily setup an external XML configuration file. When your application starts you could cache its contents in a NameValueCollection object or HashTable object. As you change/add settings you would do it to that cached copy. When your application shuts down or at an appropriate time interval you can write the cache contents back out to file.  I should probably clarify a few points. This is not a web application so connecting a database to the application might be overkill simply for storing configuration settings. This is a Windows Forms application. According to the MSDN documention the ConfigurationManager is for storing not just application level settings but user settings as well. (Especially important if for instance the application is installed as a partial-trust application.)  Dylan Don't use the application config file for this purpose use a SQL DB (SQLite MySQL MSSQL whatever) because you'll have to worry less about concurrency issues during reads and writes to the config file. You'll also have better flexibility in the type of data you want to store. The appSettings section is just a key/value list which you may outgrow as time passes and as the app matures. You could use custom config sections but then you're into a new problem area when it comes to the design.  Check out SQLite it seems like a good option for this particular scenario.",c# .net performance configuration properties20061,A,Store data from a C# application I've recently taken up learning some C# and wrote a Yahtzee clone. My next step (now that the game logic is in place and functioning correctly) is to integrate some method of keeping stats across all the games played. My question is this how should I go about storing this information? My first thought would be to use a database and I have a feeling that's the answer I'll get... if that's the case can you point me to a good resource for creating and accessing a database from a C# application? Storing in an XML file actually makes more sense to me but I thought if I suggested that I'd get torn apart ;). I'm used to building web applications and for those text files are generally frowned upon. So going with an XML file what classes should I be looking at that would allow for easy manipulation? A database may be overkill - have you thought about just storing the scores in a file? If you decide to go with a database you might consider SQLite which you can distribute just like a file. There's an open source .NET provider - System.Data.SQLite - that includes everything you need to get started. Accessing and reading from a database in .NET is quite easy - take a look at this question for sample code.  I would recommend just using a database. I would recommend using LINQ or an ORM tool to interact with the database. For learning LINQ I would take a look at Scott Guthrie's posts. I think there are 9 of them all together. I linked part 1 below. If you want to go with an ORM tool say nhibernate then I would recommend checking out the Summer of nHibernate screencasts. They are a really good learning resource for nhibernate. I disagree with using XML. With reporting stats on a lot of data you can't beat using a relational database. Yeah XML is lightweight but there are a lot of choices for light weight relational databases also besides going with a full blown service based implementation. (i.e. SQL Server Compact SQLite etc...) Scott Guthrie on LINQ Summer of nHibernate No idea why you've been down-voted so much. In this case I wouldn't myself go to a database (even the lightweight ones you have described) but your point is valid and one day the original poster may have added enough to his stats to make a DB a more usable option (+1 to try and uncondemn this)  Here is one idea: use Xml Serialization. Design your GameStats data structure and optionally use Xml attributes to influence the schema as you like. I like to use this method for small data sets because its quick and easy and all I need to do is design and manipulate the data structure.  using (FileStream fs = new FileStream(....)) { // Read in stats XmlSerializer xs = new XmlSerializer(typeof(GameStats)); GameStats stats = (GameStats)xs.Deserialize(fs); // Manipulate stats here ... // Write out game stats XmlSerializer xs = new XmlSerializer(typeof(GameStats)); xs.Serialize(fs stats); fs.Close(); }  A database would probably be overkill for something like this - start with storing your information in an XML doc (or series of XML docs if there's a lot of data). You get all that nifty XCopy deployment stuff you can still use LINQ and it would be a smooth transition to a database if you decided later you really needed performant relational query logic.  I don't know if a database is necessarily what you want. That may be overkill for storing stats for a simple game like that. Databases are good; but you should not automatically use one in every situation (I'm assuming that this is a client application not an online game). Personally for a game that exists only on the user's computer I would just store the stats in a file (XML or binary - choice depends on whether you want it to be human-readable or not).  For this situation the [Serializable] attribute on a nicely modelled Stats class and XmlSerializer are the way to go IMO.  SQL Express from MS is a great free lightweight version of their SQL Server database. You could try that if you go the DB route. Alternatively you could simply create datasets within the application and serialize them to xml or you could use something like the newly minted Entity Framework that shipped with .NET 3.5 SP1  I'd recommend saving your data in simple POCOs and either serializing them to xml or a binary file like Brian did above. If you're hot for a database I'd suggest Sql Server Compact Edition or VistaDB. Both are hosted inproc within your application.  You can either use the System::Xml namespace or the System::Data namespace. The first gives you raw XML the latter gives you a handy wrapper to the XML.,c# .net25458,A,"How costly is .NET reflection? I constantly hear how bad reflection is to use. While I generally avoid reflection and rarely find situations where it is impossible to solve my problem without it I was wondering... For those who have used reflection in applications have you measured performance hits and is it really so bad? You might also want to check out this question. http://stackoverflow.com/questions/224232/what-is-the-cost-of-reflection Use the api at fasterflect.codeplex.com. It will speed up reflection by like 500x for getters/setters/invokers and some other stuff. Source and info on how it works is there too if you need to extend it. How does this info check out in 2014? Anything changed in these 4 years? I think you will find that the answer is it depends. It's not a big deal if you want to put it in your task-list application. It is a big deal if you want to put it in Facebook's persistence library.  Reflection does not drastically slow the performance of your app. You may be able to do certain things quicker by not using reflection but if Reflection is the easiest way to achieve some functionality then use it. You can always refactor you code away from Reflection if it becomes a perf problem.  As with all things in programming you have to balance performance cost with with any benefit gained. Reflection is an invaluable tool when used with care. I created a O/R mapping library in C# which used reflection to do the bindings. This worked fantastically well. Most of the reflection code was only executed once so any performance hit was quite small but the benefits were great. If I were writing a new fandangled sorting algorithm I would probably not use reflection since it would probably scale poorly. I appreciate that I haven't exactly answered your question here. My point is that it doesn't really matter. Use reflection where appropriate. It's just another language feature that you need to learn how and when to use.  It is. But that depends on what you're trying to do. I use reflection to dynamically load assemblies (plugins) and its performance ""penalty"" is not a problem since the operation is something I do during startup of the application. However if you're reflecting inside a series of nested loops with reflection calls on each I'd say you should revisit your code :) For ""a couple of time"" operations reflection is perfectly acceptable and you won't notice any delay or problem with it. It's a very powerful mechanism and it is even used by .NET so I don't see why you shouldn't give it a try.  In his talk The Performance of Everyday Things Jeff Richter shows that calling a method by reflection is about 1000 times slower than calling it normally. Jeff's tip: if you need to call the method multiple times use reflection once to find it then assign it to a delegate and then call the delegate. I have attended Devscovery too and concur with these results for .NET 3.5. Recompiling the Devscovery performance benchmark program for .NET 4 shows massive improvement! The cost drops down to 100 times slower. Using reflection for typeof() lookups are unchanged between .NET 3.5 and .NET 4.  Reflection is costly because of the many checks the runtime must make whenever you make a request for a method that matches a list of parameters. Somewhere deep inside code exists that loops over all methods for a type verifies its visibility checks the return type and also checks the type of each and every parameter. All of this stuff costs time. When you execute that method internally theres some code that does stuff like checking you passed a compatible list of parameters before executing the actual target method. If possible it is always recommended that one caches the method handle if one is going to continually reuse it in the future. Like all good programming tips it often makes sense to avoid repeating oneself. In this case it would be wasteful to continually lookup the method with certain parameters and then execute it each and everytime. Poke around the source and take a look at whats being done.  Reflection can have noticeable impact on performance if you use it for frequent object creation. I've developed application based on Composite UI Application Block which is relying on reflection heavily. There was a noticeable performance degradation related with objects creation via reflection. However in most cases there are no problems with reflection usage. If your only need is to inspect some assembly I would recommend Mono.Cecil which is very lightweight and fast  Reflection performance will depend on the implementation (repetitive calls should be cached eg: entity.GetType().GetProperty(""PropName"")). Since most of the reflection I see on a day to day basis is used to populate entities from data readers or other repository type structures I decided to benchmark performance specifically on reflection when it is used to get or set an objects properties. I devised a test which I think is fair since it caches all the repeating calls and only times the actual SetValue or GetValue call. All the source code for the performance test is in bitbucket at: https://bitbucket.org/grenade/accessortest. Scrutiny is welcome and encouraged. The conclusion I have come to is that it isn't practical and doesn't provide noticeable performance improvements to remove reflection in a data access layer that is returning less than 100000 rows at a time when the reflection implementation is done well. The graph above demonstrates the output of my little benchmark and shows that mechanisms that outperform reflection only do so noticeably after the 100000 cycles mark. Most DALs only return several hundred or perhaps thousands of rows at a time and at these levels reflection performs just fine. Not necessarily. Your DAL conversions may only be on a few thousand items but multiply that by concurrent users using your application (if it's web) and it may add up just as if you'd convert million items. If particular method is 100-times slower it will be that much slower on small and big sets. Slower is slower. @grenade Good information for single access DAL.  Not massively. I've never had an issue with it in desktop development unless as Martin states you're using it in a silly location. I've heard a lot of people have utterly irrational fears about its performance in desktop development. In the Compact Framework (which I'm usually in) though it's pretty much anethema and should be avoided like the plague in most cases. I can still get away with using it infrequently but I have to be really careful with its application which is way less fun. :( +1 for teaching me a new word: anathema. Also for mention of irrational fears. I fear programmers who fear irrationally - it shows that they don't really know what they're doing and just basing what they do on what other people tell them. *cough cargo cult cough* Ahhhh Cargo Cult. Now there is a fine example of curious human behaviour.  As with everything it's all about assessing the situation. In DotNetNuke there's a fairly core component called FillObject that uses reflection to populate objects from datarows. This is a fairly common scenario and there's an article on MSDN Using Reflection to Bind Business Objects to ASP.NET Form Controls that covers the performance issues. Performance aside one thing I don't like about using reflection in that particular scenario is that it tends to reduce the ability to understand the code at a quick glance which for me doesn't seem worth the effort when you consider you also lose compile time safety as opposed to strongly typed datasets or something like LINQåÊtoåÊSQL.  My most pertinent experience was writing code to compare any two data entities of the same type in a large object model property-wise. Got it working tried it ran like a dog obviously. I was despondent then overnight realised that wihout changing the logic I could use the same algorithm to auto-generate methods for doing the comparison but statically accessing the properties. It took no time at all to adapt the code for this purpose and I had the ability to do deep property-wise comparison of entities with static code that could be updated at the click of a button whenever the object model changed. My point being: In conversations with colleagues since I have several times pointed out that their use of reflection could be to autogenerate code to compile rather than perform runtime operations and this is often worth considering. Considering that Visual Studio has such an excellent template support it is a practical way to use code generation  It's bad enough that you have to be worried even about reflection done internally by the .NET libraries for performance-critical code. The following example is obsolete - true at the time (2008) but long ago fixed in more recent CLR versions. Reflection in general is still a somewhat costly thing though! Case in point: You should never use a member declared as ""Object"" in a lock (C#) / SyncLock (VB.NET) statement in high-performance code. Why? Because the CLR can't lock on a value type which means that it has to do a run-time reflection type check to see whether or not your Object is actually a value type instead of a reference type. to be fair a reflection type check is fast. For such 'performance critical code' should you really be using .NET to begin with? @Seph: Dynamic/reflection portions of .NET no. But usual C#/.NET why not? C++ vs C# speedups are marginal at application layer (C++ is still a few % faster on intensive math routines). And I'm guessing you're not suggesting assembly ... A quick test shows that locking on a boxed struct (like object x = 5; lock (x)) works just fine. I also ran some tests to see if there is a performance difference between locking on ""object"" vs locking on a more specific ""object"". I ran 100 million iterations of locking/math/unlocking where the math was just a single simple addition in order to maximize the time spent locking/unlocking. They perform identically no matter what declared type you lock on. A boxed value type (ie. object) can be locked on. @BryceWagner is correct. ""The CLR can't lock on a value type"" actually means that if you tried e.g. `lock(53)` then the `int` would be boxed and the object produced locked on which would be different to the object locked on by another call and hence not really lock anything. Doing `private lockObj = 53` and then `lock(lockObj)` would work perfectly well. The ""run-time reflection type check` bit of this answer is just plain nonsense. To be fair (to me) it is more accurate to say that the answer is ""obsolete"" rather than ""plain nonsense"". My remarks about the behavior of lock(obj) WERE accurate at the time they were written but that implementation-specific behavior of the CLR is long gone.  If you're not in a loop don't worry about it.",c# .net performance reflection192,A,"Floating Point Number parsing: Is there a Catch All algorithm? One of the fun parts of multi-cultural programming is number formats. Americans use 10000.50 Germans use 10.00050 French use 10 00050 My first approach would be to take the string parse it backwards until I encounter a separator and use this as my decimal separator. There is an obvious flaw with that: 10.000 would be interpreted as 10. Another approach: if the string contains 2 different non-numeric characters use the last one as the decimal separator and discard the others. If I only have one check if it occurs more than once and discard it if it does. If it only appears once check if it has 3 digits after it. If yes discard it otherwise use it as decimal separator. The obvious ""best solution"" would be to detect the User's culture or Browser but that does not work if you have a Frenchman using an en-US Windows/Browser. Does the .net Framework contain some mythical black magic floating point parser that is better than Double.(Try)Parse() in trying to auto-detect the number format? I don't know the ASP.NET side of the problem but .NET has a pretty powerful class: System.Globalization.CultureInfo. You can use the following code to parse a string containing a double value: double d = double.Parse(""100.20"" CultureInfo.CurrentCulture); // -- OR -- double d = double.Parse(""100.20"" CultureInfo.CurrentUICulture); If ASP.NET somehow (i.e. using HTTP Request headers) passes current user's CultureInfo to either CultureInfo.CurrentCulture or CultureInfo.CurrentUICulture these will work fine.  You can't please everyone. If I enter ten as 10.000 and someone enters ten thousand as 10.000 you cannot handle that without some knowledge of the culture of the input. Detect the culture somehow (browser system setting - what is the use case? ASP? Internal app or open to the world?) or provide an example of the expected formatting and use the most lenient parser you can. Probably something like: double d = Double.Parse(""5000.00"" NumberStyles.Any CultureInfo.InvariantCulture);  The difference between 12.345 in French and English is a factor of 1000. If you supply an expected range where max < 1000*min you can easily guess. Take for example the height of a person (including babies and children) in mm. By using a range of 200-3000 an input of 1.800 or 1800 can unambiguously be interpreted as 1 meter and 80 centimeters whereas an input of 912.300 or 912300 can unambiguously be interpreted as 91 centimeters and 2.3 millimeters.  I think the best you can do in this case is to take their input and then show them what you think they meant. If they disagree show them the format you're expecting and get them to enter it again.",c# .net asp.net internationalization globalization20611,A,"Removing nodes from an XmlDocument The following code should find the appropriate project tag and remove it from the XmlDocument however when I test it it says: The node to be removed is not a child of this node. Does anyone know the proper way to do this? public void DeleteProject (string projectName) { string ccConfigPath = ConfigurationManager.AppSettings[""ConfigPath""]; XmlDocument configDoc = new XmlDocument(); configDoc.Load(ccConfigPath); XmlNodeList projectNodes = configDoc.GetElementsByTagName(""project""); for (int i = 0; i < projectNodes.Count; i++) { if (projectNodes[i].Attributes[""name""] != null) { if (projectName == projectNodes[i].Attributes[""name""].InnerText) { configDoc.RemoveChild(projectNodes[i]); configDoc.Save(ccConfigPath); } } } } UPDATE Fixed. I did two things: XmlNode project = configDoc.SelectSingleNode(""//project[@name='"" + projectName + ""']""); Replaced the For loop with an XPath query which wasn't for fixing it just because it was a better approach. The actual fix was: project.ParentNode.RemoveChild(project); Thanks Pat and Chuck for this suggestion. I was looking for just this thing. I spent a half a day looking for xml stuff on the internet and half a minute on SO. Yet another reason why Jeff and Joel were on to something. Looks like you need to select the parent node of projectNodes[i] before calling RemoveChild.  Is it possible that the project nodes aren't child nodes but grandchildren or lower? GetElementsByTagName will give you elements from anywhere in the child element tree IIRC.  Instead of configDoc.RemoveChild(projectNodes[i]); try projectNodes[i].parentNode.RemoveChild(projectNodes[i]);  When you get sufficiently annoyed by writing it the long way (for me that was fairly soon) you can use a helper extension method provided below. Yay new technology! public static class Extensions { ... public static XmlNode RemoveFromParent(this XmlNode node) { return (node == null) ? null : node.ParentNode.RemoveChild(node); } } ... //some_long_node_expression.parentNode.RemoveChild(some_long_node_expression); some_long_node_expression.RemoveFromParent();  It would be handy to see a sample of the XML file you're processing but my guess would be that you have something like this <Root> <Blah> <project>...</project> </Blah> </Root> The error message seems to be because you're trying to remove from the grandparent rather than the direct parent of the project node  try configDoc.DocumentElement.RemoveChild(projectNodes[i]);",c# .net xml xmldocument15828,A,"Reading Excel files from C# Is there a free or open source library to read Excel files (.xls) directly from a C# program? It does not need to be too fancy just to select a worksheet and read the data as strings. So far I've been using Export to Unicode text function of Excel and parsing the resulting (tab-delimited) file but I'd like to eliminate the manual step. Will that work in ASP.NET? You can try using this open source solution that makes dealing with Excel a lot more cleaner. http://excelwrapperdotnet.codeplex.com/  SpreadsheetGear is awesome. Yes it's an expense but compared to twiddling with these other solutions it's worth the cost. It is fast reliable very comprehensive and I have to say after using this product in my fulltime software job for over a year and a half their customer support is fantastic! Hard to justify when there are so many simple and effective ways (for free) of reading from and writing to Excel.  Late to the party but I'm a fan of LinqToExcel  If you have multiple tables in the same worksheet you can give each table an object name and read the table using the OleDb method as shown here: http://vbktech.wordpress.com/2011/05/10/c-net-reading-and-writing-to-multiple-tables-in-the-same-microsoft-excel-worksheet/  ExcelMapper is an open source tool (http://code.google.com/p/excelmapper/) that can be used to read Excel worksheets as Strongly Typed Objects. It supports both xls and xlsx formats.  While you did specifically ask for .xls implying the older file formats for the OpenXML formats (e.g. xlsx) I highly recommend the OpenXML SDK (http://msdn.microsoft.com/en-us/library/bb448854.aspx) A++++ would let some other poor sombitch write it for me again. No thanks the OpenXml API is awful! @Quoo disagree completely.  I recommend the FileHelpers Library which is a free and easy to use .NET library to import/export data from EXCEL fixed length or delimited records in files strings or streams + More. The Excel Data Link Documentation Section http://filehelpers.sourceforge.net/example_exceldatalink.html I won't down you but I recently started using FileHelpers and was shocked at how ... crappy it is. For instance the only way to map columns in a csv to properties... excuse me FIELDS of a model is *to create the fields in the order of the columns*. I don't know about you but I wouldn't rely on a quirk of the compiler for one of the most central design considerations of my f8king framework.  Excel Package is an open-source (GPL) component for reading/writing Excel 2007 files. I used it on a small project and the API is straightforward. Works with XLSX only (Excel 200&) not with XLS. The source code also seems well-organized and easy to get around (if you need to expand functionality or fix minor issues as I did). At first I tried the ADO.Net (Excel connection string) approach but it was fraught with nasty hacks -- for instance if second row contains a number it will return ints for all fields in the column below and quietly drop any data that doesn't fit.  I just used ExcelLibrary to load an .xls spreadsheet into a DataSet. Worked great for me.  If it is just simple data contained in the Excel file you can read the data via ADO.NET. See the connection strings listed here: http://www.connectionstrings.com/?carrier=excel2007 or http://www.connectionstrings.com/?carrier=excel -Ryan Update: then you can just read the worksheet via something like select * from [Sheet1$] This way is by far the fastest. Of course that's not true Stingy. You have to sift through all the data and write crappy DB code (hand craft your models map columns to properties yadda yadda). The quickest way is to let *some other poor SOB do this for you*. That's why people use frameworks instead of writing everything from the bottom up. Besides that I have had times where it didn't give me the right results due to localization problems... the neverending fight of seperators Worthless method! Truncates text columns to 255 characters when read. Beware! See: http://stackoverflow.com/questions/1519288/jet-engine-255-character-truncation ACE engine does same thing! Triynko it has been a super long time since I used this method but IIRC you can get around the 255 char limit by defining an ODBC DSN for the spreadsheet and then define the columns as longer in length and then use the DSN to connect to the spreadsheet. It's a pain to do that but I believe that gets around that. Be aware that using ADO.NET to read data from exel requires Microsoft Access or Microsoft Access Database Engine Redistributable installed. The driver will also guess at the columns types based on the first several rows. If you have a column with what looks like integers in the first rows you will encounter an error when you hit a non-integer (e.g. a float a string) This also will not work at ALL if you are running in a 64 bit process. http://forums.asp.net/p/1128266/1781961.aspx  Excel Data Reader is the way to go! Itå«s Open Source at http://exceldatareader.codeplex.com/ and actively developed. We been using it for reading Tabular (and sometimes not so tabular) worksheets for a couple of years now (In a financial application). Works like a charm to read unit test data from human-readable sheets. Just avoid the feature of trying to return DateTime's as for Excel DateTime's are just double numbers. There is already mention of exceldatareader here http://stackoverflow.com/questions/15828/reading-excel-files-from-c/3665991#3665991 .Why do you think we need another answer. You should comment the link not to create long thread garbage  var fileName = string.Format(""{0}\\fileNameHere"" Directory.GetCurrentDirectory()); var connectionString = string.Format(""Provider=Microsoft.Jet.OLEDB.4.0; data source={0}; Extended Properties=Excel 8.0;"" fileName); var adapter = new OleDbDataAdapter(""SELECT * FROM [workSheetNameHere$]"" connectionString); var ds = new DataSet(); adapter.Fill(ds ""anyNameHere""); DataTable data = ds.Tables[""anyNameHere""]; This is what I usually use. It is a little different because I usually stick a AsEnumerable() at the edit of the tables: var data = ds.Tables[""anyNameHere""].AsEnumerable(); as this lets me use LINQ to search and build structs from the fields. var query = data.Where(x => x.Field<string>(""phoneNumber"") != string.Empty).Select(x => new MyContact { firstName= x.Field<string>(""First Name"") lastName = x.Field<string>(""Last Name"") phoneNumber =x.Field<string>(""Phone Number"") }); If seems like the Select in this approach tries to guess the data type of the column and force upon that guessed data type. For example if you have a column with mostly double values it won't like you passing x.Field but expects x.Field. IS this true? Just looked it up on MSDN. Looks like the is just used to attempt to cast the contents in the column to a type. In this example and just casting the data in the columns to strings. If you wanted a double you would need to call double.Parse(x.Field(""Cost"") or something like that. Field is an extension method for DataRow and it looks like there aren't an non generic versions. Does adding a double.Parse to the Linq query slow it down much? Not that I have noticed. I haven't done any real performance on this. For our uses it isn't being done a lot. +1 for the Linq twist - I LOVE LINQ!! Note that if you're reading `xlsx` you need to use this connection string instead: `string.Format(""Provider=Microsoft.ACE.OLEDB.12.0;Data Source={0}; Extended Properties=Excel 12.0;"" fileName)` Sadly the Jet.OLEDB driver is not 64-bit compatible; you will need to switch to target x86 rather than Any CPU (if you still want to go ahead with this method). Alternatively install the 64-bit ACE driver and change the conn string to use this driver (as indicated by Andreas) - http://www.microsoft.com/en-us/download/details.aspx?displaylang=en&id=13255 Cannot install the 64 bit ACE driver if the target machine has a 32 bit version of office installed. If this helps anyone the Jet driver works fine in Win7 64bit... as long as I actually have the document open in Excel.  Take.io Spreadsheet will do this work for you and at no charge. Just take a look at this. This is a really great little library. It just converts everything into Lists of Lists of strings which is just fine for the kind of work I needed it for.  SmartXLS is another excel spreadsheet component which support most features of excel Chartsformulas engines and can read/write the excel2007 openxml format.  Not free but with the latest Office there's a very nice automation .Net API. (there has been an API for a long while but was nasty COM) You can do everything you want / need in code all while the Office app remains a hidden background process. @Anonymous-type I did read the question and was offering a helpful alternative to a desired OSS implementation ... because well I was pretty sure there was nothing available. And judging by the accepted answer a requirement of having Office installed is not an issue. sorry but i don't think you even read the question.  Just did a quick demo project that required managing some excel files. The .NET component from GemBox software was adequate for my needs. It has a free version with a few limitations. http://www.gemboxsoftware.com/GBSpreadsheet.htm FYI: I tried it and it didn't meet my need to be able to read an encrypted file.  How about Excel Data Reader? http://exceldatareader.codeplex.com/ I've used in it anger in a production environment to pull large amounts of data from a variety of Excel files into SQL Server Compact. It works very well and it's rather robust. I'll second Excel Data Reader; it has also led to the incredibly useful Excel Data Driven Tests library which uses NUnit 2.5's TestCaseSource attribute to make data-driven tests using Excel spreadsheets ridiculously easy. Just beware that Resharper doesn't yet support TestCaseSource so you have to use the NUnit runner. Unfortunately there are some issues with this library that we've just encountered. Firstly we've had some currency fields coming out as dates. Secondly it is crashing if the workbook has any empty sheets in it. So although it was very easy to integrate we are now re-evaluating whether to keep using this library. It does not seem to be being actively developed. It also assumes the presence of some optional elements in xlsx file that cause it to fail to read the data if they're absent. We're having problems with Excel files coming from SQL Server Reporting Services. They just don't work unless you open them and save them (even unedited). @RichieHindle: what optional elements are you talking about (hoping this might help me with my SSRS Excel files)? @Peter: I think it was a missing `` element in the `` that was causing trouble for me. @RichieHindle: ah I think that has been solved now. Thanks As an update to my comment above. We did keep going with this library and in fact I and another guy have become developers on the project and it is now actively being worked on again. The issues I mentioned have now been fixed as has open office support and hopefully SSRS (need someone to test it).  The ADO.NET approach is quick and easy but it has a few quirks which you should be aware of especially regarding how DataTypes are handled. This excellent article will help you avoid some common pitfalls: http://blog.lab49.com/archives/196 You answered my question (in the form of a comment above).  The .NET component Excel Reader .NET may satisfy your requirement. It's good enought for reading XLSX and XLS files. So try it from: http://www.devtriogroup.com/ExcelReader  I did a lot of reading from Excel files in C# a while ago and we used two approaches: The COM API where you access Excel's objects directly and manipulate them through methods and properties The ODBC driver that allows to use Excel like a database. The latter approach was much faster: reading a big table with 20 columns and 200 lines would take 30 seconds via COM and half a second via ODBC. So I would recommend the database approach if all you need is the data. Cheers Carl  We use ClosedXML in rather large systems. Free Easy to install Straight forward coding Very responsive support Developer team is extremly open to new suggestions. Often new features and bug fixes are implemented within the same week  I know that people have been making an Excel ""extension"" for this purpose. You more or less make a button in Excel that says ""Export to Program X"" and then export and send off the data in a format the program can read. http://msdn.microsoft.com/en-us/library/ms186213.aspx should be a good place to start. Good luck  If it's just tabular data. I would recommend file data helpers by Marcos Melli which can be downloaded here. That's a great library!  Here's some code I wrote in C# using .NET 1.1 a few years ago. Not sure if this would be exactly what you need (and may not be my best code :)). using System; using System.Data; using System.Data.OleDb; namespace ExportExcelToAccess { /// <summary> /// Summary description for ExcelHelper. /// </summary> public sealed class ExcelHelper { private const string CONNECTION_STRING = ""Provider=Microsoft.Jet.OLEDB.4.0;Data Source=<FILENAME>;Extended Properties=\""Excel 8.0;HDR=Yes;\"";""; public static DataTable GetDataTableFromExcelFile(string fullFileName ref string sheetName) { OleDbConnection objConnection = new OleDbConnection(); objConnection = new OleDbConnection(CONNECTION_STRING.Replace(""<FILENAME>"" fullFileName)); DataSet dsImport = new DataSet(); try { objConnection.Open(); DataTable dtSchema = objConnection.GetOleDbSchemaTable(OleDbSchemaGuid.Tables null); if( (null == dtSchema) || ( dtSchema.Rows.Count <= 0 ) ) { //raise exception if needed } if( (null != sheetName) && (0 != sheetName.Length)) { if( !CheckIfSheetNameExists(sheetName dtSchema) ) { //raise exception if needed } } else { //Reading the first sheet name from the Excel file. sheetName = dtSchema.Rows[0][""TABLE_NAME""].ToString(); } new OleDbDataAdapter(""SELECT * FROM ["" + sheetName + ""]"" objConnection ).Fill(dsImport); } catch (Exception) { //raise exception if needed } finally { // Clean up. if(objConnection != null) { objConnection.Close(); objConnection.Dispose(); } } return dsImport.Tables[0]; #region Commented code for importing data from CSV file. // string strConnectionString = ""Provider=Microsoft.Jet.OLEDB.4.0;"" +""Data Source="" + System.IO.Path.GetDirectoryName(fullFileName) +"";"" +""Extended Properties=\""Text;HDR=YES;FMT=Delimited\""""; // // System.Data.OleDb.OleDbConnection conText = new System.Data.OleDb.OleDbConnection(strConnectionString); // new System.Data.OleDb.OleDbDataAdapter(""SELECT * FROM "" + System.IO.Path.GetFileName(fullFileName).Replace(""."" ""#"") conText).Fill(dsImport); // return dsImport.Tables[0]; #endregion } /// <summary> /// This method checks if the user entered sheetName exists in the Schema Table /// </summary> /// <param name=""sheetName"">Sheet name to be verified</param> /// <param name=""dtSchema"">schema table </param> private static bool CheckIfSheetNameExists(string sheetName DataTable dtSchema) { foreach(DataRow dataRow in dtSchema.Rows) { if( sheetName == dataRow[""TABLE_NAME""].ToString() ) { return true; } } return false; } } } This code needs some Resharper love Couldn't agree more Cherian. This code is many years old... before I even was proficient with Resharper :) The code is ugly but it shows how to get the sheet names great! This gets the job done. Thanks!  you could write an excel spreadsheet that loads a given excel spreadsheet and saves it as csv (rather than doing it manually). then you could automate that from c#. and once its in csv the c# program can grok that. (also if someone asks you to program in excel it's best to pretend you don't know how) (edit: ah yes rob and ryan are both right)  Koogra is an open-source component written in C# that reads and writes Excel files. I think this link needs updated... http://koogra.sourceforge.net/ Oops! Very wrong url! Fixed now Doesn't look particularly active any more compared to say NPOI  The solution that we used needed to: Allow Reading/Writing of Excel produced files Be Fast in performance (not like using COMs) Be MS Office Independent (needed to be usable without clients having MS Office installed) Be Free or Open Source (but actively developed) There are several choices but we found NPoi (.NET port of Java's long existing Poi open source project) to be the best: http://npoi.codeplex.com/ It also allows working with .doc and .ppt file formats  This is what I used for Excel 2003: Dictionary<string string> props = new Dictionary<string string>(); props[""Provider""] = ""Microsoft.Jet.OLEDB.4.0""; props[""Data Source""] = repFile; props[""Extended Properties""] = ""Excel 8.0""; StringBuilder sb = new StringBuilder(); foreach (KeyValuePair<string string> prop in props) { sb.Append(prop.Key); sb.Append('='); sb.Append(prop.Value); sb.Append(';'); } string properties = sb.ToString(); using (OleDbConnection conn = new OleDbConnection(properties)) { conn.Open(); DataSet ds = new DataSet(); string columns = String.Join("""" columnNames.ToArray()); using (OleDbDataAdapter da = new OleDbDataAdapter( ""SELECT "" + columns + "" FROM ["" + worksheet + ""$]"" conn)) { DataTable dt = new DataTable(tableName); da.Fill(dt); ds.Tables.Add(dt); } } very clean code! worksheet isn't defined... seems a bit odd to me after clearly defining everything else.  Lately partly to get better at LINQ.... I've been using Excel's automation API to save the file as XML Spreadsheet and then get process that file using LINQ to XML. XML Spreadsheet is a fairly clean format :) But like excel files.... can we protect xml files with password? I would suspect you can protect it from Excel but not from man with compiler...like anything...it's just bytes. @gsvirdi post a seperate question on Excel file security this question is on performance.  I want to show a simple method to read xls/xlsx file with .NET. I hope that the following will be helpful for you.  private DataTable ReadExcelToTable(string path) { //Connection String string connstring = ""Provider=Microsoft.ACE.OLEDB.12.0;Data Source="" + path + "";Extended Properties='Excel 8.0;HDR=NO;IMEX=1';""; //the same name //string connstring = Provider=Microsoft.JET.OLEDB.4.0;Data Source="" + path + //"";Extended Properties='Excel 8.0;HDR=NO;IMEX=1';""; using(OleDbConnection conn = new OleDbConnection(connstring)) { conn.Open(); //Get All Sheets Name DataTable sheetsName = conn.GetOleDbSchemaTable(OleDbSchemaGuid.Tablesnew object[]{nullnullnull""Table""}); //Get the First Sheet Name string firstSheetName = sheetsName.Rows[0][2].ToString(); //Query String string sql = string.Format(""SELECT * FROM [{0}]""firstSheetName); OleDbDataAdapter ada =new OleDbDataAdapter(sqlconnstring); DataSet set = new DataSet(); ada.Fill(set); return set.Tables[0]; } } Code is from article: http://www.c-sharpcorner.com/uploadfile/d2dcfc/read-excel-file-with-net/. You can get more details from it. It **was** helpful especially the part about reading the sheetnames.  Forgive me if I am off-base here but isn't this what the Office PIA's are for? Yes but that would involve creating an Excel.Application instance loading the xls file etc. If the requirement is purely to read some data from the file then it's much easier and far more lightweight to use one of the ADO.NET methods described in the other answers. Too slow using Office PIA as the baseline everything else is faster - even just using an Object array passed from .Value2 property. Which is still using the PIA.  SpreadsheetGear for .NET is an Excel compatible spreadsheet component for .NET. You can see what our customers say about performance on the right hand side of our product page. You can try it yourself with the free fully-functional evaluation.",c# .net excel ms-office9173,A,"Lingering assembly dependency in C# .NET My C# project - we'll call it the SuperUI - used to make use of a class from an external assembly. Now it doesn't but the compiler won't let me build the project without the assembly reference in place. Let me elaborate. This project used to throw and catch a custom exception class - the SuperException - which was derived from the standard System.Exception and lived in a separate precompiled assembly SuperAssembly.DLL which I referenced. Eventually I decided this was a pointless exercise and replaced all SuperExceptions with a System.SuitableStandardException in each case. I removed the reference to SuperException.DLL but am now met with the following on trying to compile the project: The type 'SuperException' is defined in an assembly that is not referenced. You must add a reference to assembly 'SuperException Version=1.1.0.0 (...)' The source file referenced by the error doesn't seem relevant; it's the project namespace that gets highlighted in the IDE. Now here's the thing: All uses of SuperException have been eliminated from the project's code. Compared to another project that compiles fine without a reference to SuperException.DLL I only reference one more assembly - and that references nothing that my project doesn't reference itself. While it's possible that any of these dependencies could throw SuperExceptions I'm only catching the base Exception class and in any case... the other project builds fine! I've done Visual Studio's ""Clean Solution"" and cleared everything out by hand many times. It's not the end of the world to include this reference I just don't see why it's necessary any more. Nrrrgg. Any pointers welcome! I agree with the other comments here.. There is a reference in plain text somewhere ! I have had similar problems in the past where searching through the project files returned nothing turns out it was in some other file that wasn't automatically picked up in the search. I don't think that creating a new project is the solution here.. You need to be positive that NONE of the references in your dependency tree use SuperException.. NONE I have never experienced this to the point where I have needed to literally wipe the project I have always found the reference somewhere. Ensure you are searching every file. EDIT: Just a point to add if the location pointed to by the error seems random that can often mean there is a mismatch between the compiled source and the source code file.. Is this a ASP.NET application? I have had it before where the compiled DLL's haven't been replaced on a rebuild in the ASP.NET temp folder causing things to get.. Interesting when debugging :)  I‰Ûªve had a very similar assembly reference issue that was happening when my C# library had a dependent C++/CLI assembly. The problem that was I was inheriting a public class from that C++/CLI assembly in my C# assembly library. That meant that the inheritance chain was spanning across multiple assemblies. I was hoping that any client would be smart enough to indirectly load the C++/CLI assembly any time the C# library needed it but that was not the case even at compile time. I got rid of this problem by breaking the inheritance between the classes that were spanning across those two assembly libraries and using aggregation instead. My client was finally happy and did not require the C++/CLI assembly as a dependency anymore. In your word you would probably have to make sure that SuitableStandardException does not inherit from SuperException in order to eliminate the SuperException.DLL as a reference. Use encapsulation instead of inheritance and create a SuperException data member in your new SuitableStandardException. If that does not solve it you might have more classes spanning inheritance across some assemblies in your case SuperAssembly.DLL and superException.dll. If you can't find all of them try this trick: Make all your public members and classes in SuperAssembly.DLL internal. In the SuperAssembly.DLL make friends with SuperException.DLL: [assembly:InternalsVisibleTo(""SuperException PublicKey=0024000004800000....)] Make sure that they build and remove the SuperAssembly.DLL reference from any client that already references SuperException.DLL.  This is where tools like Resharper really pay off -- a simple Find Usages usually tells me of such ""ghost dependencies"" several times. Maybe you could go to your definition of the SuperException class and try to Find All References(). You might also want to investigate if the assembly SuperException is has a circular dependency on your main assembly (e.g. main assembly depends on exception assembly depends on main assembly...).  grep your project folder. It could be a hidden reference in your project or a project that your project references. Cleanse with Notepad if needed.  Thanks for your answers so far. I've tried every suggestion (except one) to no avail. The suggestion I haven't tried is to create a new project and add all my stuff to it the thought of which really tests my will to live. ;) I may try this tomorrow if I can be bothered. Thanks again.  If you reference any types that inherits from SuperException (even if the type defined in another assembly) you need a reference to the assembly that SuperException is defined in. Seconded on that. You might not be referencing SuperException but you might be referencing SpecializedSuperException which is derived from or somehow otherwise uses SuperException - your grep of the project for SuperException won't be catching it though. Try have a hack with the trial of NDepend  There is really nothing very mysterious about VS projects nowadays - it's all text files etc. SOMETHING must reference that class/dll and that something must be part of your project. Have you really grep'd or findstr'd the whole solution tree every single file for a reference to that exception?  Try creating a new project and adding all your classes to it.  This sounds pretty strange. Here's what I would check next: Check that there's nothing lingering in your Properties/AssemblyInfo.cs file. Check that there's nothing lingering in your SuperUI.csproj file. Delete all references and re-add them.  Since it's a compiler error there must be a reference or use of SuperException somewhere in the project. Do a find/replace in the entire project or solution for that type and remove every reference (it's possible you already did this). If you reference any types that inherits from SuperException (even if the type defined in another assembly) you need a reference to the assembly that SuperException is defined in. Take the line that the compiler is showing the error on and start tracing the inheritance tree of the objects used on that line you might find the source of it that way.  grep -R SuperException * in the base of your project (get grep from somewhere first) just to be sure.  I don't think this is a code issue. What I can see happening is that one of your existing references probably rely on that type in their own types which you are probably creating in your application. If that is the case you do need that reference even if you don't explicitly use the type and even though the other referenced assembly has its own reference. You sometimes get that issue with 3rd party components which need references to types that you haven't referenced. The compiler is obviously seeing something in one of your existing referenced assemblies and is expecting you to referenced the dependent one. Try searching the other referenced assemblies for the SuperException with Reflector to verify that they aren't referencing the assembly.  Exit Visual Studio Delete the bin and obj Folders in your solution directory Restart and see what happens  It's likely a transitive reference where some type method call returns an instance of SuperException boxed (""downcast"") as e.g. Exception but from inspecting the code in the transitively included code i.e. code from your external method calls the compiler knows that you need to be able to have information about that type at some point. Resharper would tell you where it's the case that you need to add a reference and you could use LÌ_tz Roeder's aka RedGate's Reflector to scan compiled IL for a reference to this type in two ways: 1) use the search-facility 2) open each public type you're using and for that one which requires the ""ghost"" assembly it will ask you to specify its location. This most often happends to me when I reference Castle.Windsor but not Castle.MicroKernel. :p",c# .net dependencies9472,A,"WCF Backward Compatibility Issue I have a WCF service that I have to reference from a .net 2.0 project. I have tried to reference it using the ""add web reference"" method but it messes up the params. For example I have a method in the service that expects a char[] to be passed in but when I add the web reference the method expects an int[]. So then I tried to setup svcutil and it worked... kind of. I could only get the service class to compile by adding a bunch of .net 3.0 references to my 2.0 project. This didn't sit well with the architect so I've had to can it (and probably for the best too). So I was wondering if anyone has any pointers or resources on how I can setup a .net 2.0 project to reference a WCF service. One of those instances that you need to edit the WSDL. For a start a useful tool http://codeplex.com/storm  Thanks for the resource. It certainly helped me test out the webservice but it didn't much help with using the WCF service in my .net 2.0 application. What I eventually ended up doing was going back to the architects and explaining that the 3.0 dll's that I needed to reference got compiled back to run on the 2.0 CLR. We don't necessarily like the solution but we're going to go with it for now as there doesn't seem to be too many viable alternatives  What binding are you using - I think if you stick to the basicHttp binding you should be able to generate a proxy using the ""add web reference"" approach from a .net 2 project? Perhaps if you post the contract/interface definition it might help? Cheers Richard  I was using the basicHttp binding but the problem was actually with the XMLSerializer. It doesn't properly recognize the wsdl generated by WCF (even with basicHttp bindings) for anything other than basic value types. We got around this by added the reference to the 3.0 dll's and using the datacontract serializer.",c# .net wcf18421,A,"Best way to bind Windows Forms properties to ApplicationSettings in C#? In a desktop application needing some serious re-factoring I have several chunks of code that look like this: private void LoadSettings() { WindowState = Properties.Settings.Default.WindowState; Location = Properties.Settings.Default.WindowLocation; ... } private void SaveSettings() { Properties.Settings.Default.WindowState = WindowState; Properties.Settings.Default.WindowLocation = Location; ... } What's the best way to replace this? Project-imposed constraints: Visual Studio 2005 C# / .NET 2.0 Windows Forms Update Thanks Tundey that looks like the way to go. For posterity I've also found two useful tutorials: ""Windows Forms User Settings in C#"" and ""Exploring Secrets of Persistent Application Settings"". I've asked a follow-up question about using this technique to bind a form's Size here. I separated them out to help people who search for similar issues. If you open your windows form in the designer look in the properties box. The first item should be ""(ApplicationSetting)"". Under that is ""(PropertyBinding)"". That's where you'll find the option to do exactly what you want.",c# .net6301,A,"Why is Array.Length an int and not an uint Why is Array.Length an int and not an uint. This bothers me (just a bit) because a length value can never by negative. This also forced me to use an int for a length-property on my own class because when you specify an int-value this needs to be cast explicity... So the ultimate question is: is there any use for an unsigned int (uint)? Even Microsoft seems not to use them. Despite the issues raised below I think it should change to UInt. @alan2here making such a change would break almost all code out there so it wont happen if you ask me! Many reasons: uint is not CLS compliant thus making a built in type (array) dependent on it would have been problematic The runtime as originally designed prohibits any object on the heap occupying more than 2GB of memory. Since the maximum sized array that would less than or equal to this limit would be new byte[int.MaxValue] it would be puzzling to people to be able to generate positive but illegal array lengths. Note that this limitation has been somewhat removed in the 4.5 release though the standard Length as int remains. Historically C# inherits much of its syntax and convention from C and C++. In those arrays are simply pointer arithmetic so negative array indexing was possible (though normally illegal and dangerous). Since much existing code assumes that the array index is negative this would have been a factor On a related note the use of signed integers for array indexes in C/C++ means that interop with these languages and unmanaged functions would require the use of ints in those circumstances anyway which may confuse due to the inconsistency. The BinarySearch implementation (a very useful component of many algorithms) relies on being able to use the negative range of the int to indicate that the value was not found and the location at which such a value should be inserted to maintain sorting. When operating on an array it is likely that you would want to take a negative offset of an existing index. If you used an offset which would take you past the start of the array using unit then the wrap around behaviour would make your index possibly legal (in that it is positive). With an int the result would be illegal (but safe since the runtime would guard against reading invalid memory) If nothing on the heap can be over 2Gb then almost all arrays of length int.MaxValue are illegal since most types are larger than 1 byte. indeed but ((uint)(int.MaxValue)) + 1 would be guaranteed wrong for *anything*. int is itself far from perfect but the balance of things makes it legit to stay with int as the type. Starting out with be an explict ArrayIndex type (essentially size_t) that would translate cleanly and safely to an int as needed perhaps would make it easier in future to make really use allowing for > 2GB arrays in future with less pain. But pragmatics say java has same problem so why take the risk This is very informative. In Windows Communication Foundation as of .NET 4.0 - the largest values were 2147483647 for `maxArrayLength` and `maxBytesPerRead` which retrospectively makes a lot of sense with this information. Connecting the dots...  Unsigned int isn't CLS compliant and would therefore restrict usage of the property to those languages that do implement a UInt. Update: See here: Framework 1.1 http://msdn.microsoft.com/en-us/library/hfa3fa08(VS.71).aspx Framework 2.0 http://msdn.microsoft.com/en-us/library/hfa3fa08(VS.80).aspx  I think it also might have to do with simplifying things on a lower level since Array.Length will of course be added to a negative number at some point if Array.Length were unsigned and added to a negative int (two's complement) there could be messy results. Please give an example? `uint lenght = 3;int x = -4;Console.WriteLine(x+lenght);` yields -1 just fine.  Typically integer values are signed unless you explicitly need an unsigned value. It's just the way they are used. I may not agree with that choice but that's just the way it is. For the time being with todays typical memory constraints if your array or similar data structure needs an UInt32 length you should consider other data structures. With an array of bytes Int32 will give you 2GB of values ""but that's just the way it is."" -- no things are never just the way they are. There's always a design decision being made and it always pays to ask why. One might learn something from the pros and cons or engage the designer (in some cases) in a discussion about the them. Always ask questions! :)  Looks like nobody provided answer to ""the ultimate question"". I believe primary use of unsigned ints is to provide easier interfacing with external systems (P/Invoke and the like) and to cover needs of various languages being ported to .NET. Unsigned types are essential when concatenating multiple smaller values to produce a larger one. One can combine two UInt16's to make a UInt32 by computing `(HighPart << 16) + LowPart` and one may split a UInt32 into two UInt16's via `(Uint16)(Value >> 16)` and `(Uint16)(Value & 65535)`. Such operations would be very inconvenient if `LowPart` had to be a signed type. That having been said interactions between signed and unsigned types are often confusing and problematical. Unsigned types should in many ways be considered a world of their own.",c# .net int uint13060,A,"What do ref val and out mean on method parameters? I'm looking for a clear concise and accurate answer. Ideally as the actual answer although links to good explanations welcome. This also applies to VB.Net but the keywords are different - ByRef and ByVal. This article ""Parameter passing in C#"" is the most complete explanation I've read so far.  out means that the parameter will be initialised by the method: int result; //not initialised if( int.TryParse( ""123"" out result ) ) //result is now 123 else //if TryParse failed result has still be // initialised to its default value (0) ref will force the underlying reference to be passed: void ChangeMyClass1( MyClass input ) { input.MyProperty = ""changed by 1""; input = null; //can't see input anymore ... // I've only nulled my local scope's reference } void ChangeMyClass2( ref MyClass input ) { input.MyProperty = ""changed by 2""; input = null; //the passed reference is now null too. } MyClass tester = new MyClass { MyProperty = ""initial value"" }; ChangeMyClass1( tester ); // now tester.MyProperty is ""changed by 1"" ChangeMyClass2( ref tester ); // now tester is null  One of my own questions at stackoverflow handles this topic too. It handles about ""pass by reference"" and ""pass by value"" in different types of languages c# is included so maybe you can find some extra information there as well. Basically it comes down to: ref: the parameter with the ref keyword will be passed by reference out: the parameter with the out keyword will be treated as an output parameter but that's really the most basic answer you can give as it is a little more complex than it is stated here  By default (in C#) passing an object to a function actually passes a copy of the reference to that object. Changing the parameter itself only changes the value in the parameter and not the variable that was specified. void Test1(string param) { param = ""new value""; } string s1 = ""initial value""; Test1(s1); // s1 == ""initial value"" Using out or ref passes a reference to the variable specified in the call to the function. Any changes to the value of an out or ref parameter will be passed back to the caller. Both out and ref behave identically except for one slight difference: ref parameters are required to be initialised before calling while out parameters can be uninitialised. By extension ref parameters are guaranteed to be initialised at the start of the method while out parameters are treated as uninitialised. void Test2(ref string param) { param = ""new value""; } void Test3(out string param) { // Use of param here will not compile param = ""another value""; } string s2 = ""initial value""; string s3; Test2(ref s2); // s2 == ""new value"" // Test2(ref s3); // Passing ref s3 will not compile Test3(out s2); // s2 == ""another value"" Test3(out s3); // s3 == ""another value"" Edit: As dp points out the difference between out and ref is only enforced by the C# compiler not by the CLR. As far as I know VB has no equivalent for out and implements ref (as ByRef) only matching the support of the CLR. ""copy of the reference to that object"" or ""reference to the copy of that object"" ?  One additional note about ref vs. out: The distinction between the two is enforced by the C# compiler. The CLR does not distinguish between between out and ref. This means that you cannot have two methods whose signatures differ only by an out or ref void foo(int value) {} // Only one of the following would be allowed // valid to overload with ref void foo(ref int value) {} // OR with out void foo(out int value) {}",c# .net vb.net6184,A,"How do I make event callbacks into my win forms thread safe? When you subscribe to an event on an object from within a form you are essentially handing over control of your callback method to the event source. You have no idea whether that event source will choose to trigger the event on a different thread. The problem is that when the callback is invoked you cannot assume that you can make update controls on your form because sometimes those controls will throw an expection if the event callback was called on a thread different than the thread the form was run on. To simplify Simon's code a bit you could use the built in generic Action delegate. It saves peppering your code with a bunch of delegate types you don't really need. Also in .NET 3.5 they added a params parameter to the Invoke method so you don't have to define a temporary array. void SomethingHappened(object sender EventArgs ea) { if (InvokeRequired) { Invoke(new Action<object EventArgs>(SomethingHappened) sender ea); return; } textBox1.Text = ""Something happened""; }  I'm a bit late to this topic but you might want to take a look at the Event-Based Asynchronous Pattern. When implemented properly it guarantees that events are always raised from the UI thread. Here's a brief example that only allows one concurrent invocation; supporting multiple invocations/events requires a little bit more plumbing. using System; using System.ComponentModel; using System.Threading; using System.Windows.Forms; namespace WindowsFormsApplication1 { public class MainForm : Form { private TypeWithAsync _type; [STAThread()] public static void Main() { Application.EnableVisualStyles(); Application.Run(new MainForm()); } public MainForm() { _type = new TypeWithAsync(); _type.DoSomethingCompleted += DoSomethingCompleted; var panel = new FlowLayoutPanel() { Dock = DockStyle.Fill }; var btn = new Button() { Text = ""Synchronous"" }; btn.Click += SyncClick; panel.Controls.Add(btn); btn = new Button { Text = ""Asynchronous"" }; btn.Click += AsyncClick; panel.Controls.Add(btn); Controls.Add(panel); } private void SyncClick(object sender EventArgs e) { int value = _type.DoSomething(); MessageBox.Show(string.Format(""DoSomething() returned {0}."" value)); } private void AsyncClick(object sender EventArgs e) { _type.DoSomethingAsync(); } private void DoSomethingCompleted(object sender DoSomethingCompletedEventArgs e) { MessageBox.Show(string.Format(""DoSomethingAsync() returned {0}."" e.Value)); } } class TypeWithAsync { private AsyncOperation _operation; // synchronous version of method public int DoSomething() { Thread.Sleep(5000); return 27; } // async version of method public void DoSomethingAsync() { if (_operation != null) { throw new InvalidOperationException(""An async operation is already running.""); } _operation = AsyncOperationManager.CreateOperation(null); ThreadPool.QueueUserWorkItem(DoSomethingAsyncCore); } // wrapper used by async method to call sync version of method matches WaitCallback so it // can be queued by the thread pool private void DoSomethingAsyncCore(object state) { int returnValue = DoSomething(); var e = new DoSomethingCompletedEventArgs(returnValue); _operation.PostOperationCompleted(RaiseDoSomethingCompleted e); } // wrapper used so async method can raise the event; matches SendOrPostCallback private void RaiseDoSomethingCompleted(object args) { OnDoSomethingCompleted((DoSomethingCompletedEventArgs)args); } private void OnDoSomethingCompleted(DoSomethingCompletedEventArgs e) { var handler = DoSomethingCompleted; if (handler != null) { handler(this e); } } public EventHandler<DoSomethingCompletedEventArgs> DoSomethingCompleted; } public class DoSomethingCompletedEventArgs : EventArgs { private int _value; public DoSomethingCompletedEventArgs(int value) : base() { _value = value; } public int Value { get { return _value; } } } } I think it's a bit misleading to say 'it guarantees that events are always raised from the UI thread'. Wouldn't it be more accurate to say that it ensures that the event handler is executed on the same SynchronizationContext / thread on which the task was created? (Which might not be the UI thread / SynchronizationContext)  As the lazy programmer I have a very lazy method of doing this. What I do is simply this. private void DoInvoke(MethodInvoker del) { if (InvokeRequired) { Invoke(del); } else { del(); } } //example of how to call it private void tUpdateLabel(ToolStripStatusLabel lbl String val) { DoInvoke(delegate { lbl.Text = val; }); } You could inline the DoInvoke inside your function or hide it within separate function to do the dirty work for you. Just keep in mind you can pass functions directly into the DoInvoke method. private void directPass() { DoInvoke(this.directInvoke); } private void directInvoke() { textLabel.Text = ""Directly passed.""; } I'm all for lazy programming :) If you're using .NET 3.5 or higher you can use `Action` or `Action` along with lambda expressions: `Doinvoke(() => textLabel.Text = ""Something"")`  In many simple cases you can use the MethodInvoker delegate and avoid the need to create your own delegate type.  I use anonymous methods a lot in this scenario: void SomethingHappened(object sender EventArgs ea) { MethodInvoker del = delegate{ textBox1.Text = ""Something happened""; }; InvokeRequired ? Invoke( del ) : del(); }  Here are the salient points: You can't make UI control calls from a different thread than the one they were created on (the form's thread). Delegate invocations (ie event hooks) are triggered on the same thread as the object that is firing the event. So if you have a separate ""engine"" thread doing some work and have some UI watching for state changes which can be reflected in the UI (such as a progress bar or whatever) you have a problem. The engine fire's an object changed event which has been hooked by the Form. But the callback delegate that the Form registered with the engine gets called on the engine's thread‰Û_ not on the Form's thread. And so you can't update any controls from that callback. Doh! BeginInvoke comes to the rescue. Just use this simple coding model in all your callback methods and you can be sure that things are going to be okay: private delegate void EventArgsDelegate(object sender EventArgs ea); void SomethingHappened(object sender EventArgs ea) {  //  // Make sure this callback is on the correct thread  //  if (this.InvokeRequired)  {  this.Invoke(new EventArgsDelegate(SomethingHappened) new object[] { sender ea });  return;  }  //  // Do something with the event such as update a control  //  textBox1.Text = ""Something happened""; } It's quite simple really. Use InvokeRequired to find out if this callback happened on the correct thread. If not then reinvoke the callback on the correct thread with the same parameters. You can reinvoke a method by using the Invoke (blocking) or BeginInvoke (non-blocking) methods. The next time the function is called InvokeRequired returns false because we are now on the correct thread and everybody is happy. This is a very compact way of addressing this problem and making your Forms safe from multi-threaded event callbacks. I can see places where a separate ""event bus"" to handle synchronization could be useful but in many cases it would seem easiest for the end user of something like a progress-indicator class if the class simply exposed a MinimumUpdateInterval property. @Supercat... event throttling is an important topic for many applications but it is not something that should be part of the UI layer. A separate event proxy bus should be created to receive queue combine and resend events at appropriate intervals. Any subscriber to the event bus should not know that event throttling is occurring. I generally prefer BeginInvoke to Invoke but there's a caveat: one must avoid queueing up too many events. I use an updateRequired variable which is set to 1 when a BeginInvoke would happen and only perform the BeginInvoke if it had been zero (using Interlocked.Exchange). The display handler has a while loop that clears updateRequired and if it wasn't zero does an update and loops. In some cases a timer is added to further limit update frequency (to avoid having code spend all its time updating the progress readout instead of doing real work) but that's more complicated.",c# .net winforms multithreading events27455,A,"Does Mono support System.Drawing and System.Drawing.Printing? I'm attempting to use Mono to load a bitmap and print it on Linux but I'm getting an exception. Does Mono support printing on Linux? The code/exception are below: EDIT: No longer getting the exception but I'm still curious what kind of support there is. Leaving the code for posterity or something. private void btnPrintTest_Click(object sender EventArgs e) { _printDocTest.DefaultPageSettings.Landscape = true; _printDocTest.DefaultPageSettings.Margins = new Margins(50505050); _printDocTest.Print(); } void _printDocTest_PrintPage(object sender PrintPageEventArgs e) { var bmp = new Bitmap(""test.bmp""); // Determine center of graph var xCenter = e.MarginBounds.X + (e.MarginBounds.Width - bmp.Width) / 2; var yCenter = e.MarginBounds.Y + (e.MarginBounds.Height - bmp.Height) / 2; e.Graphics.DrawImage(bmp xCenter yCenter); e.HasMorePages = false; } Oh..oops looks like I was just specifying the file path wrong (changed it to open the file first then load it into a bitmap). Got it working now -- nothing to see here move along. According to System.Drawing is now complete and in addition to being the underlying rendering engine for Windows.Forms it has also been tested for using third party controls that heavily depend on it.  From the Mono docs I think yes: Managed.Windows.Forms (aka System.Windows.Forms): A complete and cross platform System.Drawing based Winforms implementation. It also useful if you run the Mono Migration Analyzer first.",c# .net linux printing mono9376,A,"ILMerge Best Practices Do you use ILMerge? Do you use ILMerge to merge multiple assemblies to ease deployment of dll's? Have you found problems with deployment/versioning in production after ILMerging assemblies together? I'm looking for some advice in regards to using ILMerge to reduce deployment friction if that is even possible. I recently had issue where I had ilmerged assembly in the assembly i had some classes these were being called via reflection in Umbraco opensource CMS. The information to make the call via reflection was taken from db table that had assembly name and namespace of class that implemented and interface. The issue was that the reflection call would fail when dll was il merged however if dll was separate it all worked fine. I think issue may be similar to the one longeasy is having?  We just started using ILMerge in our solutions that are redistributed and used in our other projects and so far so good. Everything seems to work okay. We even obfuscated the packaged assembly directly. We are considering doing the same with the MS Enterprise Library assemblies. The only real issue I see with it is versioning of individual assemblies from the package.  It seems to me like the #1 ILMerge Best Practice is Don't Use ILMerge. Instead use SmartAssembly. One reason for this is that the #2 ILMerge Best Practice is to always run PEVerify after you do an ILMerge because ILMerge does not guarantee it will correctly merge assemblies into a valid executable. Other ILMerge disadvantages: when merging it strips XML Comments (if I cared about this I would use an obfuscation tool) it doesn't correctly handle creating a corresponding .pdb file Another tool worth paying attention to is Mono.Cecil and the Mono.Linker [2] tool. [2]: http:// www.mono-project.com/Linker ""it doesn't correctly handle creating a corresponding .pdb file"" - under what conditions is this true? I've watched ILMerge generate merged pdb's and used them without issue. When any of the assemblies you want to merge does not already have a .pdb. Also SmartAssembly correctly handles WPF resources such as BAML.  We ran into problems when merging DLLs that have resources in the same namespace. In the merging process one of the resource namespaces was renamed and thus the resources couldn't be located. Maybe we're just doing something wrong there still investigating the issue.  I know this is an old question but we not only use ILMerge to reduce the number of dependencies but also to internalise the ""internal"" dependencies (eg automapper restsharp etc) that are used by the utility. This means they are completely abstracted away and the project using the merged utility doesn't need to know about them. This again reduces the required references in the project and allows it to use / update its own version of the same external library if required.  I use ILMerge for almost all of my different applications. I have it integrated right into the release build process so what I end up with is one exe per application with no extra dll's. You can't ILMerge any C++ assemblies that have native code. You also can't ILMerge any assemblies that contain XAML for WPF (at least I haven't had any success with that). It complains at runtime that the resources cannot be located. I did write a wrapper executable for ILMerge where I pass in the startup exe name for the project I want to merge and an output exe name and then it reflects the dependent assemblies and calls ILMerge with the appropriate command line parameters. It is much easier now when I add new assemblies to the project I don't have to remember to update the build script. How did you do that release build integration? @Svish -- http://www.hanselman.com/blog/MixingLanguagesInASingleAssemblyInVisualStudioSeamlesslyWithILMergeAndMSBuild.aspx Here's a potential workaround for ILMerge + XAML: http://richarddingwall.name/2009/05/14/wpf-how-to-combine-mutliple-assemblies-into-a-single-exe/ http://roman.st/Article/ILMerge-and-GeneratedInternalTypeHelper - Another Workaround for ILMerge + XAML [ILRepack](https://github.com/gluck/il-repack) is an open source alternative and (to some extend) supports WPF repacking.  We use ILMerge on quite a few projects. The Web Service Software Factory for example produces something like 8 assemblies as its output. We merge all of those DLLs into a single DLL so that the service host will only have to reference one DLL. It makes life somewhat easier but it's not a big deal either.  For Console Apps Here is the basic ""Post Build String"" for Visual Studio 2010 SP1 using .NET 4.0. I am building a console .exe with all of the sub-.dll files included in it. ""$(SolutionDir)ILMerge\ILMerge.exe"" /out:""$(TargetDir)$(TargetName).all.exe"" ""$(TargetDir)$(TargetName).exe"" ""$(TargetDir)*.dll"" /target:exe /targetplatform:v4C:\Windows\Microsoft.NET\Framework64\v4.0.30319 /wildcards Basic hints The output is a file ""AssemblyName.all.exe"" which combines all sub-dlls into one .exe. Notice the ""ILMerge\"" directory. You need to either copy the ILMerge utility into your solution directory (so you can distribute the source without having to worry about documenting the install of ILMerge) or change the this path to point to where ILMerge.exe resides. Advanced hints: If you have problems with it not working turn on ""Output"" and select ""Show output from: Build"". Check the exact command that Visual Studio actually generated and see if there was any errors. Update This script replaces all .exe + .dll files with a single combined .exe. It also keeps the debugging .pdb file intact. To use paste this into your ""Post Build"" step under the ""Build Events"" tab in a C# project and make sure you adjust the path in the first line to point to the ILMerge.exe: rem Create a single .exe that combines the root .exe and all subassemblies. ""$(SolutionDir)ILMerge\ILMerge.exe"" /out:""$(TargetDir)$(TargetName).all.exe"" ""$(TargetDir)$(TargetName).exe"" ""$(TargetDir)*.dll"" /target:exe /targetplatform:v4C:\Windows\Microsoft.NET\Framework64\v4.0.30319 /wildcards rem Remove all subassemblies. del *.dll rem Remove all .pdb files (except the new combined pdb we just created). ren ""$(TargetDir)$(TargetName).all.pdb"" ""$(TargetName).all.pdb.temp"" del *.pdb ren ""$(TargetDir)$(TargetName).all.pdb.temp"" ""$(TargetName).all.pdb"" rem Delete the original non-combined .exe. del ""$(TargetDir)$(TargetName).exe"" rem Rename the combined .exe and .pdb to the original project name we started with. ren ""$(TargetDir)$(TargetName).all.pdb"" ""$(TargetName).pdb"" ren ""$(TargetDir)$(TargetName).all.exe"" ""$(TargetName).exe"" exit 0 See http://stackoverflow.com/questions/2961357/using-ilmerge-with-net-4-libraries  We use ILMerge on the Microsoft application blocks - instead of 12 seperate DLL files we have a single file that we can upload to our client areas plus the file system structure is alot neater. After merging the files I had to edit the visual studio project list remove the 12 seperate assmeblies and add the single file as a reference otherwise it would complain that it couldnt find the specific assembly. Im not too sure how this would work on post deployment though could be worth giving it a try. +1 for sharing your own experience.",c# .net deployment ilmerge27757,A,"How can I discover the ""path"" of an embedded resource? I am storing a PNG as an embedded resource in an assembly. From within the same assembly I have some code like this: Bitmap image = new Bitmap(typeof(MyClass) ""Resources.file.png""); The file named ""file.png"" is stored in the ""Resources"" folder (within Visual Studio) and is marked as an embedded resource. The code fails with an exception saying: Resource MyNamespace.Resources.file.png cannot be found in class MyNamespace.MyClass I have identical code (in a different assembly loading a different resource) which works. So I know the technique is sound. My problem is I end up spending a lot of time trying to figure out what the correct path is. If I could simply query (eg. in the debugger) the assembly to find the correct path that would save me a load of headaches. I' guessing that your class is in a different namespace. The canonical way to solve this would be to use the resources class and a strongly typed resource: ProjectNamespace.Properties.Resources.file Use the IDE's resource manager to add resources. You are right my class is in a different namespace. It seems that the Resources folder lives under the namespace specified as the default namespace in the project configuration which for various reasons isn't the namespace that this class is part of. I suspect you're correct also about using a different approach entirely but as I need to be consistent with legacy code that's beyond my control.  The name of the resource is the name space plus the ""pseudo"" name space of the path to the file. The ""pseudo"" name space is made by the sub folder structure using \ (backslashes) instead of . (dots). public static Stream GetResourceFileStream(String nameSpace String filePath) { String pseduoName = filePath.Replace('\\' '.'); Assembly assembly = Assembly.GetExecutingAssembly(); return assembly.GetManifestResourceStream(nameSpace + ""."" + pseduoName); } The following call: GetResourceFileStream(""my.namespace"" ""resources\\xml\\my.xml"") will return the stream of my.xml located in the folder-structure resources\xml in the name space: my.namespace. Also dashes ('-') in the folders are replaced with underscores ('_'). There might be other symbols as well. I'd like to see how the compiler is doing it so we can use the same method.  I find myself forgetting how to do this every time as well so I just wrap the two one-liners that I need in a little class: public class Utility { /// <summary> /// Takes the full name of a resource and loads it in to a stream. /// </summary> /// <param name=""resourceName"">Assuming an embedded resource is a file /// called info.png and is located in a folder called Resources it /// will be compiled in to the assembly with this fully qualified /// name: Full.Assembly.Name.Resources.info.png. That is the string /// that you should pass to this method.</param> /// <returns></returns> public static Stream GetEmbeddedResourceStream(string resourceName) { return Assembly.GetExecutingAssembly().GetManifestResourceStream(resourceName); } /// <summary> /// Get the list of all emdedded resources in the assembly. /// </summary> /// <returns>An array of fully qualified resource names</returns> public static string[] GetEmbeddedResourceNames() { return Assembly.GetExecutingAssembly().GetManifestResourceNames(); } }  This will get you a string array of all the resources: System.Reflection.Assembly.GetExecutingAssembly().GetManifestResourceNames(); Pretty useful! Thanks!",c# .net resources21965,A,Programmatically encrypting a config-file in .NET Could somebody please do a rundown of how to programmatically encrypt a config-file in .NET preferably in C#. What I would like to do is do some kind of check on an application's startup to see if a section is unprotected and if it is then encrypt it. This for both settings and connection-strings. Also if anyone could list the types of encryption-providers and what is the difference between them. I don't know if the code for doing this in a normal WinForms-application is transparent to doing this in ASP.NET. To summarize the answers and what I've found so far here are some good links to answer this question: Encrypting Configuration Information in ASP.NET 2.0 Applications - 4GuysFromRolla.com How To: Encrypt Configuration Sections in ASP.NET 2.0 Using DPAPI - MSDN Please feel free to complement with other links maybe some to WinForms- or WPF-applications.  @TK: a hashing algo can only be 'guessed' not reverse engineered. One can only reconstruct the input to a hash value by completely guessing the input (apart from collisions that is) This can be done by a rainbow crack for example (see an implementation of a rainbow cracker here) I would say that a 3rd party encryption tool is not safer than the .NET framework encryption algorithms these libraries just help you doing your job faster  I haven't used it myself but the Microsoft Enterprise library has good encryption support that will possibly suit your needs: http://msdn.microsoft.com/en-us/library/cc309503.aspx  Encrypting .NET configuration files through code How To: Encrypt Configuration Sections in ASP.NET 2.0 Using DPAPI  The solution at below site working fine for me. http://www.a2zmenu.com/Blogs/CSharp/How-to-encrypt-configuration-file.aspx  There is a good article from 4 guys about Encrypting Configuration Information in ASP.NET 2.0 Applications Hope this helps,c# .net configuration encryption configuration-files29157,A,"How do I make a PictureBox use Nearest Neighbor resampling? I am using StretchImage because the box is resizable with splitters. It looks like the default is some kind of smooth bilinear filtering causing my image to be blurry and have moire patterns. so there is no actual way to do this? in some easy fashion? @Luiscencio: that's what it looks like. You'll have to do it yourself with a new Bitmap of the appropriate size and then Graphics.DrawImage You should mark JYelton answer. :) I suspect you're going to have to do the resizing manually thru the Image class and DrawImage function and respond to the resize events on the PictureBox.  When resizing an image in .net the System.Drawing.Drawing2D.InterpolationMode offers the following resize methods: Bicubic Bilinear High HighQualityBicubic HighQualityBilinear Low NearestNeighbor Default I don't see how this addresses the OP's question.  I did a MSDN search and turns out there's an article on this which is not very detailed but outlines that you should use the paint event. http://msdn.microsoft.com/en-us/library/k0fsyd4e.aspx I edited a commonly available image zooming example to use this feature see below Edited from: http://www.dotnetcurry.com/ShowArticle.aspx?ID=196&AspxAutoDetectCookieSupport=1 Hope this helps  private void Form1_Load(object sender EventArgs e) { // set image location imgOriginal = new Bitmap(Image.FromFile(@""C:\images\TestImage.bmp"")); picBox.Image = imgOriginal; // set Picture Box Attributes picBox.SizeMode = PictureBoxSizeMode.StretchImage; // set Slider Attributes zoomSlider.Minimum = 1; zoomSlider.Maximum = 5; zoomSlider.SmallChange = 1; zoomSlider.LargeChange = 1; zoomSlider.UseWaitCursor = false; SetPictureBoxSize(); // reduce flickering this.DoubleBuffered = true; } // picturebox size changed triggers paint event private void SetPictureBoxSize() { Size s = new Size(Convert.ToInt32(imgOriginal.Width * zoomSlider.Value) Convert.ToInt32(imgOriginal.Height * zoomSlider.Value)); picBox.Size = s; } // looks for user trackbar changes private void trackBar1_Scroll(object sender EventArgs e) { if (zoomSlider.Value > 0) { SetPictureBoxSize(); } } // redraws image using nearest neighbour resampling private void picBox_Paint_1(object sender PaintEventArgs e) { e.Graphics.InterpolationMode = InterpolationMode.NearestNeighbor; e.Graphics.DrawImage( imgOriginal new Rectangle(0 0 picBox.Width picBox.Height) // destination rectangle 0 0 // upper-left corner of source rectangle imgOriginal.Width // width of source rectangle imgOriginal.Height // height of source rectangle GraphicsUnit.Pixel); } What event is wired up to your picBox_Paint_1 method? it would be in some other part of your code. Yeah it's in the form designer code: this.picBox.Paint += new System.Windows.Forms.PaintEventHandler(this.picBox_Paint_1);  I needed this functionality also. I made a class that inherits PictureBox overrides OnPaint and adds a property to allow the interpolation mode to be set: /// <summary> /// Inherits from PictureBox; adds Interpolation Mode Setting /// </summary> public class PictureBoxWithInterpolationMode : PictureBox { public InterpolationMode InterpolationMode { get; set; } protected override void OnPaint(PaintEventArgs paintEventArgs) { paintEventArgs.Graphics.InterpolationMode = InterpolationMode; base.OnPaint(paintEventArgs); } } Very nice. I think PanAndZoomPictureBox of EmguCV do the same. Are you aware of any performance issue doing it? I haven't had any measurable performance differences changing the interpolation mode in this way. Humm good. Jared Updike should mark your answer! :) Lovely answer. I suggest posters be a bit more complete with their code i.e. add a using `System.Drawing.Drawing2D` or put the full namespace in front of the InterpolationMode declaration.",c# .net winforms gdi+ picturebox12045,A,Unit testing a timer based application? I am currently writing a simple timer based mini app in C# that performs an action n times every k seconds. I am trying to adopt a test driven development style so my goal is to unit test all parts of the app. So my question is: Is there a good way to unit test a timer based class? The problem as I see it is that there is a big risk that the tests will take uncomfortably long to execute since they must wait so and so long for the desired actions to happen. Especially if one wants realistic data (seconds) instead of using the minimal time resolution allowed by the framework (1 ms?). I am using a mock object for the action to register the number of times the action was called and so that the action takes practically no time. Len Holgate has a series of 20 articles on testing timer based code.  I think what I would do in this case is test the code that actually executes when the timer ticks rather than the entire sequence. What you really need to decide is whether it is worthwhile for you to test the actual behaviour of the application (for example if what happens after every tick changes drastically from one tick to another) or whether it is sufficient (that is to say the action is the same every time) to just test your logic. Since the timer's behaviour is guaranteed never to change it's either going to work properly (ie you've configured it right) or not; it seems to be to be wasted effort to include that in your test if you don't actually need to. The only problem I see with your approach is that you ll probably have to expose something that happens everytime the polls happens is that a good idea? ie exposing something that you don't have to just for tests. An alternative might be internal (and InternalsVisibleTo) but a lot of people don't like that either  What I have done is to mock the timer and also the current system time that my events could be triggered immediately but as far as the code under test was concerned time elapsed was seconds.  I agree with Danny insofar as it probably makes sense from a unit-testing perspective to simply forget about the timer mechanism and just verify that the action itself works as expected. I would also say that I disagree in that it's wasted effort to include the configuration of the timer in an automated test suite of some kind. There are a lot of edge cases when it comes to working with timing applications and it's very easy to create a false sense of security by only testing the things that are easy to test. I would recommend having a suite of tests that runs the timer as well as the real action. This suite will probably take a while to run and would likely not be something you would run all the time on your local machine. But setting these types of things up on a nightly automated build can really help root out bugs before they become too hard to find and fix. So in short my answer to your question is don't worry about writing a few tests that do take a long time to run. Unit test what you can and make that test suite run fast and often but make sure to supplement that with integration tests that run less frequently but cover more of the application and its configuration.,c# .net unit-testing timer19353,A,"Detecting audio silence in WAV files using C# I'm tasked with building a .NET client app to detect silence in a WAV files. Is this possible with the built-in Windows APIs? Or alternately any good libraries out there to help with this? If you want to efficiently calculate the average power over a sliding window: square each sample then add it to a running total. Subtract the squared value from N samples previous. Then move to the next step. This is the simplest form of a CIC Filter. Parseval's Theorem tells us that this power calculation is applicable to both time and frequency domains. Also you may want to add Hysteresis to the system to avoid switching on&off rapidly when power level is dancing about the threshold level.  Audio analysis is a difficult thing requiring a lot of complex math (think Fourier Transforms). The question you have to ask is ""what is silence"". If the audio that you are trying to edit is captured from an analog source the chances are that there isn't any silence... they will only be areas of soft noise (line hum ambient background noise etc). All that said an algorithm that should work would be to determine a minimum volume (amplitude) threshold and duration (say <10dbA for more than 2 seconds) and then simply do a volume analysis of the waveform looking for areas that meet this criteria (with perhaps some filters for millisecond spikes). I've never written this in C# but this CodeProject article looks interesting; it describes C# code to draw a waveform... that is the same kind of code which could be used to do other amplitude analysis. Link is dead. This is 6 years later.  Use Sox. It can remove leading and trailing silences but you'll have to call it as an exe from your app.  http://www.codeproject.com/Articles/19590/WAVE-File-Processor-in-C This has all the code necessary to strip silence and mix wave files. Enjoy.  See code below from Detecting audio silence in WAV files using C# private static void SkipSilent(string fileName short silentLevel) { WaveReader wr = new WaveReader(File.OpenRead(fileName)); IntPtr format = wr.ReadFormat(); WaveWriter ww = new WaveWriter(File.Create(fileName + "".wav"") AudioCompressionManager.FormatBytes(format)); int i = 0; while (true) { byte[] data = wr.ReadData(i 1); if (data.Length == 0) { break; } if (!AudioCompressionManager.CheckSilent(format data silentLevel)) { ww.WriteData(data); } } ww.Close(); wr.Close(); } The code above is using Alvas.Audio The code above requires a third party library (Alvas Audio) which is not exactly cheap.  I don't think you'll find any built-in APIs for detection of silence. But you can always use good ol' math/discreete signal processing to find out loudness. Here's a small example: http://msdn.microsoft.com/en-us/magazine/cc163341.aspx",c# .net audio10644,A,"Any decent C# profilers out there? I urgently need a C# profiler. Although I'm not averse to paying for one something which is free or at least with a trial version would be ideal since it takes time to raise a purchase order. Any recommendations? possible duplicate of [What Are Some Good .NET Profilers?](http://stackoverflow.com/questions/3927/what-are-some-good-net-profilers) It says a lot about SO that a reason for censoring a question is that it's ""likely to solicit debate"". The current release of SharpDevelop (3.1.1) has a nice integrated profiler. It's quite fast and integrates very well into the SharpDevelop IDE and its NUnit runner. Results are displayed in a flexible Tree/List style (use LINQ to create your own selection). Doublecliking the displayed method jumps directly into the source code.  Although not very good to profile memory usage the profiler included in some versions of Visual Studio does a very good job of profiling execution speed. one way to get to the VS2010 profiler is after a solution is loaded from the ""Debug"" menu find ""Start Performance Analysis"". Details of it's capabilities are at http://msdn.microsoft.com/query/dev10.query?appId=Dev10IDEF1&l=EN-US&k=k(VS.PERFORMANCE.WIZARD.METHODPAGE)&rd=true  The EQATEC profiler is very good and is completely free. It's easy to setup and use and doesn't seem to add too much of an overhead to the application. I've just started using it today and have already found a couple of bottlenecks I wouldn't have spotted otherwise. Not free for a commercial license (but still cheap $200). Yes it looks like they have changed the licencing for the latest version and started charging for commercial use. I'd still highly recommend it though. Update - it looks like they have changed the licence terms again to make it free for commercial use for standard .NET applications (but not CF or Silverlight) The license terms have changed again in release 3.6: it's now free for **all** platforms including CF and Silverlight with a restriction on the number of DLLs that can be instrumented in one session. Agreed it's very easy to use as well I tried out both Equatec and RedGate Ants. I didn't found something like in ants to show which line of code does it used for which amount of time. Is there some hidden setting to see code lines? No longer free and has been bought out by Telerik :( :'((( was looking for a free tool...  We use Ants profiler where I work. It gives very detailed information in a simple manner.  I found the .NET Memory Profiler yesterday and I must say that I'm very impressed by it. I'm going to order my license today.  AQTime (both perf and memory) or ANTS (v4 performance profiler or v5 beta memory profiler) here.  Patrick Smacchia's awesome NDepend is excellent for providing static analysis. I would thoroughly recommend NDepend for static analysis but just be warned that you'll probably need to put aside a day or two to actually analyse the truckload of information that it provides as well as work out what all the stats actually mean in terms of your code.  I have had good luck with the .NET memory profiler  I maintain a comprehensive list of profilers for .NET on SharpToolbox.com. You'll find there the tools suggested here and more each with a short description of what it proposes. This seems out of date (redgate entries are quite stale) Harry thank you for pointing this out. The information about all RedGate products are now up-to-date. http://sharptoolbox.com/authors/red-gate-software  I used Ants profiler on a large c# project a year and a half ago. It really performed very nicely for what it cost and even outperformed a few of the more expensive competitors. It calculates cost on with almost a line by line resolution. I like ANTS too. It is from Redgate.  Currently don't use them a buddy of mine raves about Ants profiler. I know its a for-pay product not sure how expensive. If you happen to staff an MVP you might be able to leverage that to get a license for free. MVP's get the license to redgate products for free its a loop hole that gets you in if you have people on your team who are MVP's making the cost a non-issue. can you provide a bit more detail on the whole MVP thing? thanks Do you have a link describing this loophole and how to capitalize on it?  EQATEC profiler did the job here.  I'll second red gate's ANTS profiler. I've used it to track down some really troubling performance issues and it was dead simple to use (low learning curve) and presented nice detailed data in a way that was easy to understand. The price tag is worth it but it isn't free ...  I have used AQtime and it has never let me down. I am sure there is a trial version. AQTime has a huge benefit over ANTs in that it supports unmanaged code.  You can try the following: nprof (free but kinda old) ProfileSharp (open source) .Net Memory Profiler (really good for memory leaks there's a trial version) Edit: Nprof has been replaced with SlimTune and works with .Net 4.0 applications I've played around with ProfileSharp. It's absolutely awful. nprof is .Net 1.1 only I think. If you can compile to .Net 1.1 then it may still be useful to profile it and then recompile to .Net 2 for release. However this isn't possible if you start using .Net2 features such as generics and nullable types. Agree with Matthew ProfileSharp is terrible couldn't get it to profile even the simplest command line exe. Don't waste your time Development on nprof seems to have picked up recently. I've used .Net Memory Profiler to find a memory leak; it's pretty good. It's got my seal of approval! That website for ProfileSharp seems like spam. ???  SlimTune looks to be very promising. http://code.google.com/p/slimtune/  We use .NET Memory Profiler. Its kinda ugly but very useful for finding dangling references. I originally tried Red Gate's ANTS profiler which is very sexy but from a memory leak point of view it sucks for the following reasons: 1) Its ridiculously slow. It was taking half an hour to get the application into a state to start recording (takes 20 seconds without red-gate). 2) Red Gate needs to run its own tool on its own tool. It was using 900MB of memory by the time I finished two snapshots! It then crashed :( However the timing component of Red Gate ANTS was impressive. Just don't bother with the memory profiler unless you are dealing with a trivial (small footprint) application. Have you tried v4 of both? It's much better all-round now :)  dotTrace from JetBrains is widely used. Patrick Smacchia's awesome NDepend is excellent for providing static analysis. dotTrace is truly an excellent profiler extremely easy to use. dotTrace 3.1 does not work with .NET 4. We have to wait for dotTrace 4.0. As an update both dotTrace 4 Performance and dotTrace 3.5 Memory do support .NET 4.  It's interesting that no-one mentions that there's one in the higher-end versions of Visual Studio - I've always found that to be good enough for execution profiling. For memory profiling I use Memory Profiler which has already been mentioned but isn't what I would generally describe as 'a profiler'. What kind of profiling were you trying to do?  What's your objective? Is it your objective to locate specific statements and get a rough idea of what they are contributing to your total execution time so you can find ways to do them differently? For that I swear by this method.",c# .net profiling profiler4664,A,"Should the folders in a solution match the namespace? Should the folders in a solution match the namespace? In one of my teams projects we have a class library that has many sub-folders in the project. Project Name and Namespace: MyCompany.Project.Section. Within this project there are several folders that match the namespace section: Folder Vehicles has classes in the MyCompany.Project.Section.Vehicles namespace Folder Clothing has classes in theMyCompany.Project.Section.Clothing namespace etc. Inside this same project is another rogue folder Folder BusinessObjects has classes in the MyCompany.Project.Section namespace There are a few cases like this where folders are made for ""organizational convenience"". My question is: What's the standard? In class libraries do the folders usually match the namespace structure or is it a mixed bag? @lassevk: I agree with these rules and have one more to add. When I have nested classes I still split them out one per file. Like this: // ----- Foo.cs partial class Foo { // Foo implementation here } and // ----- Foo.Bar.cs partial class Foo { class Bar { // Foo.Bar implementation here } }  I think the standard within .NET is to try to do it when possible but not to create unnecessarily deep structures just to adhere to it as a hard rule. None of my projects follow the namespace == structure rule 100% of the time sometimes its just cleaner/better to break out from such rules. In Java you don't have a choice. I'd call that a classic case of what works in theory vs what works in practice.  I'd say yes. First it will be easier to find the actual code files by following down the namespaces (say when somebody e-mails you a naked exception call stack). If you let your folders go out of sync with namespaces finding files in big codebases becomes getting tiring. Second VS will generate new classes you create in folders with the same namespace of its parent folder structure. If you decide to swim against this it will be just one more plumbing job to do daily when adding new files. Of course this goes without saying that one should be conservative about how deep xis folder/namespace hierarchy goes.  Yes they should only leads to confusion otherwise.  Also note that if you use the built-in templates to add classes to a folder it will by default be put in a namespace that reflects the folder hierarchy. The classes will be easier to find and that alone should be reasons good enough. The rules we follow are: Project/assembly name is the same as the root namespace except for the .dll ending Only exception to the above rule is a project with a .Core ending the .Core is stripped off Folders equals namespaces One type per file (class struct enum delegate etc.) makes it easy to find the right file +1 for _""Only exception to the above rule is a project with a .Core ending the .Core is stripped off""_ alone. I have a `MyProject.Core.dll` assembly and all classes begin with `MyProject.Core`. Stripping off the `.Core` suffix makes much more sense.",c# .net namespaces17125,A,"What are real life applications of yield? I know what yield does and I've seen a few examples but I can't think of real life applications have you used it to solve some specific problem? (Ideally some problem that cannot be solved some other way) I realise this is an old question (pre Jon Skeet?) but I have been considering this question myself just lately. Unfortunately the current answers here (in my opinion) don't mention the most obvious advantage of the yield statement. The biggest benefit of the yield statement is that it allows you to iterate over very large lists with much more efficient memory usage then using say a standard list. For example let's say you have a database query that returns 1 million rows. You could retrieve all rows using a DataReader and store them in a List therefore requiring list_size * row_size bytes of memory. Or you could use the yield statement to create an Iterator and only ever store one row in memory at a time. In effect this gives you the ability to provide a ""streaming"" capability over large sets of data. Moreover in the code that uses the Iterator you use a simple foreach loop and can decide to break out from the loop as required. If you do break early you have not forced the retrieval of the entire set of data when you only needed the first 5 rows (for example). Regarding: Ideally some problem that cannot be solved some other way The yield statement does not give you anything you could not do using your own custom iterator implementation but it saves you needing to write the often complex code needed. There are very few problems (if any) that can't solved more than one way. Here are a couple of more recent questions and answers that provide more detail: http://stackoverflow.com/questions/384392/yield-keyword-value-added http://stackoverflow.com/questions/317619/is-yield-useful-outside-of-linq  One interesting use is as a mechanism for asynchronous programming esp for tasks that take multiple steps and require the same set of data in each step. Two examples of this would be Jeffery Richters AysncEnumerator Part 1 and Part 2. The Concurrency and Coordination Runtime (CCR) also makes use of this technique CCR Iterators.  You can also use yield return to treat a series of function results as a list. For instance consider a company that pays its employees every two weeks. One could retrieve a subset of payroll dates as a list using this code: void Main() { var StartDate = DateTime.Parse(""01/01/2013""); var EndDate = DateTime.Parse(""06/30/2013""); foreach (var d in GetPayrollDates(StartDate EndDate)) { Console.WriteLine(d); } } // Calculate payroll dates in the given range. // Assumes the first date given is a payroll date. IEnumerable<DateTime> GetPayrollDates(DateTime startDate DateTime endDate int daysInPeriod = 14) { var thisDate = startDate; while (thisDate < endDate) { yield return thisDate; thisDate = thisDate.AddDays(daysInPeriod); } }  Using yield can prevent downcasting to a concrete type. This is handy to ensure that the consumer of the collection doesn't manipulate it.  LINQ's operators on the Enumerable class are implemented as iterators that are created with the yield statement. It allows you to chain operations like Select() and Where() without actually enumerating anything until you actually use the enumerator in a loop typically by using the foreach statement. Also since only one value is computed when you call IEnumerator.MoveNext() if you decide to stop mid-collection you'll save the performance hit of calculating all of the results. Iterators can also be used to implement other kinds of lazy evaluation where expressions are evaluated only when you need it. You can also use yield for more fancy stuff like coroutines.  Another good use for yield is to perform a function on the elements of an IEnumerable and to return a result of a different type for example: public delegate T SomeDelegate(K obj); public IEnumerable<T> DoActionOnList(IEnumerable<K> list SomeDelegate action) { foreach (var i in list) yield return action(i); }  actually I use it in a non traditional way on my site IdeaPipe public override IEnumerator<T> GetEnumerator() { // goes through the collection and only returns the ones that are visible for the current user // this is done at this level instead of the display level so that ideas do not bleed through // on services foreach (T idea in InternalCollection) if (idea.IsViewingAuthorized) yield return idea; } so basically it checks if viewing the idea is currently authorized and if it is it returns the idea. If it isn't it is just skipped. This allows me to cache the Ideas but still display the ideas to the users that are authorized. Else I would have to re pull them each time based on permissions when they are only re-ranked every 1 hour.",c# .net yield26809,A,"What is the best way to deal with DBNull's I frequently have problems dealing with DataRows returned from SqlDataAdapters. When I try to fill in an object using code like this: DataRow row = ds.Tables[0].Rows[0]; string value = (string)row; What is the best way to deal with DBNull's in this type of situation. close: [most-efficient-way-to-check-for-dbnull-and-then-assign-to-a-variable](http://stackoverflow.com/questions/221582/most-efficient-way-to-check-for-dbnull-and-then-assign-to-a-variable) It is worth mentioning that DBNull.Value.ToString() equals String.Empty You can use this to your advantage: DataRow row = ds.Tables[0].Rows[0]; string value = row[""name""].ToString(); However that only works for Strings for everything else I would use the linq way or a extension method. For myself I have written a little extension method that checks for DBNull and even does the casting via Convert.ChangeType(...) int value = row.GetValueOrDefault<int>(""count""); int value = row.GetValueOrDefault<int>(""count"" 15);  Add a reference to System.Data.DataSetExtensions that adds Linq support for querying data tables. This would be something like: string value = ( from row in ds.Tables[0].Rows select row.Field<string>(0) ).FirstOrDefault(); +1: this answer should be more upvoted and probably also accepted - definitely row.Field(""column_name"") is the most efficient readable and clean solution for dealing with null (DBNull.Value). There is also row.SetField(""column_name"" value) for writing value to row.  DBNull implements .ToString() like everything else. No need to do anything. Instead of the hard cast call the object's .ToString() method. DataRow row = ds.Tables[0].Rows[0]; string value; if (row[""fooColumn""] == DBNull.Value) { value = string.Empty; } else { value = Convert.ToString(row[""fooColumn""]); } this becomes: DataRow row = ds.Tables[0].Rows[0]; string value = row.ToString() DBNull.ToString() returns string.Empty I would imagine this is the best practice you're looking for This doesn't work if the value isn't a string though. I was looking for a general case answer. I agree yeah it's good if it's strings keeps it simple but other types wouldn't work e.g. tryng to do bool.Parse(row[""fooColumn""].ToString()).  Brad Abrams posted something related just a couple of days ago http://blogs.msdn.com/brada/archive/2009/02/09/framework-design-guidelines-system-dbnull.aspx In Summary ""AVOID using System.DBNull. Prefer Nullable instead."" And here is my two cents (of untested code :) ) // Or if (row[""fooColumn""] == DBNull.Value) if (row.IsNull[""fooColumn""]) { // use a null for strings and a Nullable for value types // if it is a value type and null is invalid throw a // InvalidOperationException here with some descriptive text. // or dont check for null at all and let the cast exception below bubble value = null; } else { // do a direct cast here. dont use ""as"" ""convert"" ""parse"" or ""tostring"" // as all of these will swallow the case where is the incorect type. // (Unless it is a string in the DB and really do want to convert it) value = (string)row[""fooColumn""]; } And one question... Any reason you are not using an ORM? We are using ORM now. At the time we weren't *Any reason you are not using an ORM?* I use raw ADO .NET for performance. Try to merge 1 million records with EF or NH.  I usually write my own ConvertDBNull class that wraps the built-in Convert class. If the value is DBNull it will return null if its a reference type or the default value if its a value type. Example: - ConvertDBNull.ToInt64(object obj) returns Convert.ToInt64(obj) unless obj is DBNull in which case it will return 0.  If you aren't using nullable types the best thing to do is check to see if the column's value is DBNull. If it is DBNull then set your reference to what you use for null/empty for the corresponding datatype. DataRow row = ds.Tables[0].Rows[0]; string value; if (row[""fooColumn""] == DBNull.Value) { value = string.Empty; } else { value = Convert.ToString(row[""fooColumn""]); } As Manu said you can create a convert class with an overloaded convert method per type so you don't have to pepper your code with if/else blocks. I will however stress that nullable types is the better route to go if you can use them. The reasoning is that with non-nullable types you are going to have to resort to ""magic numbers"" to represent null. For example if you are mapping a column to an int variable how are you going to represent DBNull? Often you can't use 0 because 0 has a valid meaning in most programs. Often I see people map DBNull to int.MinValue but that could potentially be problematic too. My best advice is this: For columns that can be null in the database use nullable types. For columns that cannot be null in the database use regular types. Nullable types were made to solve this problem. That being said if you are on an older version of the framework or work for someone who doesn't grok nullable types the code example will do the trick. The line if(row[""fooColumn""] == DBNull.Value) works but isn't correct. It isn't defined DBNull.Value should be implemented as a Singleton pattern. A better line would be: if(row[""fooColumn""] is DBNull) @doekman - Actually DBNull *is* a singleton class. To quote MSDN: ""DBNull is a singleton class which means only this [DBNull.Value] instance of this class can exist."" http://msdn.microsoft.com/en-us/library/system.dbnull.value.aspx If you want treat dbnull as empty string row[""fooColumn""].ToString() will do it.  For some reason I've had problems with doing a check against DBNull.Value so I've done things slightly different and leveraged a property within the DataRow object: if (row.IsNull[""fooColumn""]) { value = string.Empty(); } { else { value = row[""fooColumn""].ToString; }  If you have control of the query that is returning the results you can use ISNULL() to return non-null values like this: SELECT ISNULL(name'') AS name ISNULL(age 0) AS age FROM names If your situation can tolerate these magic values to substitute for NULL taking this approach can fix the issue through your entire app without cluttering your code.  I always found it clear concise and problem free using a version of the If/Else check only with the ternary operator. Keeps everything on one row including assigning a default value if the column is null. So assuming a nullable Int32 column named ""MyCol"" where we want to return -99 if the column is null but return the integer value if the column is not null: return row[""MyCol""] == DBNull.Value ? -99 : Convert.ToInt32(Row[""MyCol""]); It is the same method as the If/Else winner above - But I've found if you're reading multiple columns in from a datareader it's a real bonus having all the column-read lines one under another lined up as it's easier to spot errors: Object.ID = DataReader[""ID""] == DBNull.Value ? -99 : Convert.ToInt32(DataReader[""ID""]); Object.Name = DataReader[""Name""] == DBNull.Value ? ""None"" : Convert.ToString(DataReader[""Name""]); Object.Price = DataReader[""Price""] == DBNull.Value ? 0.0 : Convert.ToFloat(DataReader[""Price""]);  You should also look at the extension methods. Here are some examples to deal with this scenerio. Recommended read  If you are concerned with getting DBNull when expecting strings one option is to convert all the DBNull values in the DataTable into empty string. It is quite simple to do it but it would add some overhead especially if you are dealing with large DataTables. Check this link that shows how to do it if you are interested Someties it is important to know the difference between a Null and an empty string though. For example setting a value to an empty string as opposed to a value just never being set.  You can also test with Convert.IsDBNull (MSDN).  Nullable types are good but only for types that are not nullable to begin with. To make a type ""nullable"" append a question mark to the type for example: int? value = 5; I would also recommend using the ""as"" keyword instead of casting. You can only use the ""as"" keyword on nullable types so make sure you're casting things that are already nullable (like strings) or you use nullable types as mentioned above. The reasoning for this is If a type is nullable the ""as"" keyword returns null if a value is DBNull. It's ever-so-slightly faster than casting though only in certain cases. This on its own is never a good enough reason to use as but coupled with the reason above it's useful. I'd recommend doing something like this DataRow row = ds.Tables[0].Rows[0]; string value = row as string; In the case above if row comes back as DBNull then value will become null instead of throwing an exception. Be aware that if your DB query changes the columns/types being returned using as will cause your code to silently fail and make values simple null instead of throwing the appropriate exception when incorrect data is returned so it is recommended that you have tests in place to validate your queries in other ways to ensure data integrity as your codebase evolves.  Often when working with DataTables you have to deal with this cases where the row field can be either null or DBNull normally I deal with that like this: string myValue = (myDataTable.Rows[i][""MyDbNullableField""] as string) ?? string.Empty; The 'as' operator returns null for invalid cast's like DBNull to string and the '??' returns the term to the right of the expression if the first is null.",c# .net sql-server24734,A,"SelectNodes not working on stackoverflow feed I'm trying to add support for stackoverflow feeds in my rss reader but SelectNodes and SelectSingleNode have no effect. This is probably something to do with ATOM and xml namespaces that I just don't understand yet. I have gotten it to work by removing all attributes from the feed tag but that's a hack and I would like to do it properly. So how do you use SelectNodes with atom feeds? Here's a snippet of the feed. <?xml version=""1.0"" encoding=""utf-8""?> <feed xmlns=""http://www.w3.org/2005/Atom"" xmlns:creativeCommons=""http://backend.userland.com/creativeCommonsRssModule"" xmlns:thr=""http://purl.org/syndication/thread/1.0""> <title type=""html"">StackOverflow.com - Questions tagged: c</title> <link rel=""self"" href=""http://stackoverflow.com/feeds/tag/c"" type=""application/atom+xml"" /> <subtitle>Check out the latest from StackOverflow.com</subtitle> <updated>2008-08-24T12:25:30Z</updated> <id>http://stackoverflow.com/feeds/tag/c</id> <creativeCommons:license>http://www.creativecommons.org/licenses/by-nc/2.5/rdf</creativeCommons:license> <entry> <id>http://stackoverflow.com/questions/22901/what-is-the-best-way-to-communicate-with-a-sql-server</id> <title type=""html"">What is the best way to communicate with a SQL server?</title> <category scheme=""http://stackoverflow.com/feeds/tag/c/tags"" term=""c"" /><category scheme=""http://stackoverflow.com/feeds/tag/c/tags"" term=""c++"" /><category scheme=""http://stackoverflow.com/feeds/tag/c/tags"" term=""sql"" /><category scheme=""http://stackoverflow.com/feeds/tag/c/tags"" term=""mysql"" /><category scheme=""http://stackoverflow.com/feeds/tag/c/tags"" term=""database"" /> <author><name>Ed</name></author> <link rel=""alternate"" href=""http://stackoverflow.com/questions/22901/what-is-the-best-way-to-communicate-with-a-sql-server"" /> <published>2008-08-22T05:09:04Z</published> <updated>2008-08-23T04:52:39Z</updated> <summary type=""html"">&lt;p&gt;I am going to be using c/c++ and would like to know the best way to talk to a MySQL server. Should I use the library that comes with the server installation? Are they any good libraries I should consider other than the official one?&lt;/p&gt;</summary> <link rel=""replies"" type=""application/atom+xml"" href=""http://stackoverflow.com/feeds/question/22901/answers"" thr:count=""2""/> <thr:total>2</thr:total> </entry> </feed> The Solution XmlDocument doc = new XmlDocument(); XmlNamespaceManager nsmgr = new XmlNamespaceManager(doc.NameTable); nsmgr.AddNamespace(""atom"" ""http://www.w3.org/2005/Atom""); doc.Load(feed); // successful XmlNodeList itemList = doc.DocumentElement.SelectNodes(""atom:entry"" nsmgr); Does -> nsmgr.AddNamespace(""atom"" ""http://www.w3.org/2005/Atom""); <- actually connect over the internet to that url to get the schema? if so what happens if it can't connect to that url? You might need to add a XmlNamespaceManager. XmlDocument document = new XmlDocument(); XmlNamespaceManager nsmgr = new XmlNamespaceManager(document.NameTable); nsmgr.AddNamespace(""creativeCommons"" ""http://backend.userland.com/creativeCommonsRssModule""); // AddNamespace for other namespaces too. document.Load(feed); It is needed if you want to call SelectNodes on a document that uses them. What error are you seeing?  Don't confuse the namespace names in the XML file with the namespace names for your namespace manager. They're both shortcuts and they don't necessarily have to match. So you can register ""http://www.w3.org/2005/Atom"" as ""atom"" and then do a SelectNodes for ""atom:entry"".  I just want to use.. XmlNodeList itemList = xmlDoc.DocumentElement.SelectNodes(""entry""); but what namespace do the entry tags fall under? I would assume xmlns=""http://www.w3.org/2005/Atom"" but it has no title so how would I add that namespace? XmlDocument document = new XmlDocument(); XmlNamespaceManager nsmgr = new XmlNamespaceManager(document.NameTable); nsmgr.AddNamespace("""" ""http://www.w3.org/2005/Atom""); document.Load(feed); Something like that?  You've guessed correctly: you're asking for nodes not in a namespace but these nodes are in a namespace. Description of the problem and solution: http://weblogs.asp.net/wallen/archive/2003/04/02/4725.aspx",c# .net rss atom19933,A,"How to copy a file in C# I want to copy a file from A to B in C#. How do I do that? System.IO.File.Copy  A simple example for copying one file and several files public class SimpleFileCopy static void Main() { string fileName = ""test.txt""; string sourcePath = @""C:\Users\Public\TestFolder""; string targetPath = @""C:\Users\Public\TestFolder\SubDir"";` // Use Path class to manipulate file and directory paths. string sourceFile = System.IO.Path.Combine(sourcePath fileName); string destFile = System.IO.Path.Combine(targetPath fileName); // To copy a folder's contents to a new location: // Create a new target folder if necessary. if (!System.IO.Directory.Exists(targetPath)) { System.IO.Directory.CreateDirectory(targetPath); } // To copy a file to another location and // overwrite the destination file if it already exists. System.IO.File.Copy(sourceFile destFile true); // To copy all the files in one directory to another directory. // Get the files in the source folder. (To recursively iterate through // all subfolders under the current directory see // ""How to: Iterate Through a Directory Tree."") // Note: Check for target path was performed previously // in this code example. if (System.IO.Directory.Exists(sourcePath)) { string[] files = System.IO.Directory.GetFiles(sourcePath); // Copy the files and overwrite destination files if they already exist. foreach (string s in files) { // Use static Path methods to extract only the file name from the path. fileName = System.IO.Path.GetFileName(s); destFile = System.IO.Path.Combine(targetPath fileName); System.IO.File.Copy(s destFile true); } } else { Console.WriteLine(""Source path does not exist!""); } // Keep console window open in debug mode. Console.WriteLine(""Press any key to exit.""); Console.ReadKey(); }}`  The File.Copy method: MSDN Link  Without any error handling code: File.Copy(path path2);  Use the FileInfo class. FileInfo fi = new FileInfo(""a.txt""); fi.CopyTo(""b.txt"");",c# .net2483,A,"Casting: (NewType) vs. Object as NewType Possible Duplicate: Casting vs using the 'as' keyword in the CLR What is actually the difference between these two casts? SomeClass sc = (SomeClass)SomeObject; SomeClass sc2 = SomeObject as SomeClass; Normally they should both be explicit casts to the specified type? See also http://stackoverflow.com/questions/496096/casting-vs-using-the-as-keyword-in-the-clr. This one was first but that one has a good answer. You have posted the second oldest question that is a duplicate of another (the first one is locked)! Congratulations I guess? Which is funny because this one was posted 3 months earlier :) But the other one has more detailed answers. It's like the difference between Parse and TryParse. You use TryParse when you expect it might fail but when you have strong assurance it won't fail you use Parse.  To expand on Rytmis's comment you can't use the as keyword for structs (Value Types) as they have no null value.  The former will throw an exception if the source type can't be cast to the target type. The latter will result in sc2 being a null reference but no exception. [Edit] My original answer is certainly the most pronounced difference but as Eric Lippert points out it's not the only one. Other differences include: You can't use the 'as' operator to cast to a type that doesn't accept 'null' as a value You can't use 'as' to convert things like numbers to a different representation (float to int for example). And finally using 'as' vs. the cast operator you're also saying ""I'm not sure if this will succeed.""  Also note that you can only use the as keyword with a reference type or a nullable type ie: double d = 5.34; int i = d as int; will not compile double d = 5.34; int i = (int)d; will compile. because a casting does not convert  Here is a good way to remember the process that each of them follow that I use when trying to decide which is better for my circumstance. DateTime i = (DateTime)value; // is like doing DateTime i = value is DateTime ? value as DateTime : throw new Exception(...); and the next should be easy to guess what it does DateTime i = value as DateTime; in the first case if the value cannot be cast than an exception is thrown in the second case if the value cannot be cast i is set to null. So in the first case a hard stop is made if the cast fails in the second cast a soft stop is made and you might encounter a NullReferenceException later on.  And for the sake of completeness Eric Lippert has a blog post about the difference and some caveats.  They'll throw different exceptions. () : NullReferenceException as : InvalidCastException Which could help for debugging. The ""as"" keyword attempts to cast the object and if the cast fails null is returned silently. The () cast operator will throw an exception immediately if the cast fails. ""Only use the C# ""as"" keyword where you are expecting the cast to fail in a non-exceptional case. If you are counting on a cast to succeed and are unprepared to receive any object that would fail you should use the () cast operator so that an appropriate and helpful exception is thrown."" For code examples and a further explanation: http://blog.nerdbank.net/2008/06/when-not-to-use-c-keyword.html (-1) as won't throw an InvalidCastException.  Typecasting using ""as"" is of course much faster when the cast fails as it avoids the expense of throwing an exception. But it is not faster when the cast succeeds. The graph at http://www.codeproject.com/KB/cs/csharpcasts.aspx is misleading because it doesn't explain what it's measuring. The bottom line is: If you expect the cast to succeed (i.e. a failure would be exceptional) use a cast. If you don't know if it will succeed use the ""as"" operator and test the result for null.  Don't forget that as only works on classes. You mean reference types and nullable value types like int? (taken from Lippert's blog linked above)  For those of you with VB.NET experience (type) is the same as DirectCast and ""as type"" is the same as TryCast.  A difference between the two approaches is that the the first ((SomeClass)obj) may cause a type converter to be called.  The parenthetical cast throws an exception if the cast attempt fails. The ""as"" cast returns null if the cast attempt fails.  All of this applies to reference types value types cannot use the as keyword as they cannot be null. //if I know that SomeObject is an instance of SomeClass SomeClass sc = (SomeClass) someObject; //if SomeObject *might* be SomeClass SomeClass sc2 = someObject as SomeClass; The cast syntax is quicker but only when successful it's much slower to fail. Best practice is to use as when you don't know the type: //we need to know what someObject is SomeClass sc; SomeOtherClass soc; //use as to find the right type if( ( sc = someObject as SomeClass ) != null ) { //do something with sc } else if ( ( soc = someObject as SomeOtherClass ) != null ) { //do something with soc } However if you are absolutely sure that someObject is an instance of SomeClass then use cast. In .Net 2 or above generics mean that you very rarely need to have an un-typed instance of a reference class so the latter is less often used.  Well the 'as' operator ""helps"" you bury your problem way lower because when it is provided an incompatible instance it will return null maybe you'll pass that to a method which will pass it to another and so on and finally you'll get a NullReferenceException which will make your debugging harder. Don't abuse it. The direct cast operator is better in 99% of the cases.",c# .net17533,A,"Request Windows Vista UAC elevation if path is protected? For my C# app I don't want to always prompt for elevation on application start but if they choose an output path that is UAC protected then I need to request elevation. So how do I check if a path is UAC protected and then how do I request elevation mid-execution? Thanks. If your secondary drive has it's own file permissions like say you have an other copy of windows installed on it. It will prompt. It will also prompt if files are in use which sometimes occurs if you have windows explorer open to the same directory and the file selected with a file previewer displaying the contents... there are some other oddities but generally you get asked for file permission if the file is in use or it's a sensitive directory. If you do loop the FolderBrowserDialog  make sure to notify the user why so they dont get mad at your app. Note: it does stink there is no .net way of asking for permission maybe p/invoke the win32 api...? P/Invoking wouldn't change anything; the rules for UAC are the same whether you're managed or native. It's COM external process or bust.  UAC can elevate object based on their GUID this would (In theory) mean that any class with a GUID can be elevated The UACDemo should also show how to do this  The best way to detect if they are unable to perform an action is to attempt it and catch the UnauthorizedAccessException. However as @DannySmurf correctly points out you can only elevate a COM object or separate process. There is a demonstration application within the Windows SDK Cross Technology Samples called UAC Demo. This demonstration application shows a method of executing actions with an elevated process. It also demonstrates how to find out if a user is currently an administrator. Nice reference to UAC demo exactly what I needed. Thanks very much. Wish I could give more rep sometimes! @Ryan You're welcome. I'm a little frustrated how hard UAC seems to be in a managed environment. Feel free to browse my user profile and upvote my other questions! :) Thanks Matias. Fixed the post now. BTW the exception name is UnauthorizedAccessException with z in Unauthorized. Just that ;)  I'm not sure if it is of any help for you but you can take a look at this blog post: http://haishibai.blogspot.com/2010/01/tiy-try-out-windows-7-uac-using-c-part_26.html  Requesting elevation mid-execution requires that you either: Use a COM control that's elevated which will put up a prompt Start a second process that is elevated from the start. In .NET there is currently no way to elevate a running process; you have to do one of the hackery things above but all that does is give the user the appearance that the current process is being elevated. The only way I can think of to check if a path is UAC elevated is to try to do some trivial write to it while you're in an un-elevated state catch the exception elevate and try again. Note that this is not a .NET limitation -- it's a general limitation of the User Account Control system. Note that is not a UAC limitation -- it's a general limitation of the security model in Windows NT (a running process cannot change its security token). Note that it is a good thing - otherwise malicious attacker could inject code into pre-elevation process and this code would be elevated together with this process.  You may want to notify the user that the path is protected and ask them to output the file to a ""safer"" area. This way your app will not need elevation. I'm sure it depends on your users and what you are trying to do however I don't think it's too much to kindly let the user know you don't feel ok dumping xyz into the Windows/System32 folder.",c# .net windows-vista uac elevated-privileges6557,A,"In C# why can't a List object be stored in a List variable It seems that a List object cannot be stored in a List variable in C# and can't even be explicitly cast that way. List<string> sl = new List<string>(); List<object> ol; ol = sl; results in Cannot implicitly convert type System.Collections.Generic.List<string> to System.Collections.Generic.List<object> And then... List<string> sl = new List<string>(); List<object> ol; ol = (List<object>)sl; results in Cannot convert type System.Collections.Generic.List<string> to System.Collections.Generic.List<object> Of course you can do it by pulling everything out of the string list and putting it back in one at a time but it is a rather convoluted solution. This is gonna change with C# 4.0 so you might wanna lookup covariance and contravariance. It will allow such things in a type safe manner. More or less duplicate: http://stackoverflow.com/questions/317335/why-can-i-not-return-a-listfoo-if-asked-for-a-listifoo John> C#4 will not allow this. Think about ol.Add(new object()); Mike - I believe contravariance isn't allowed in C# either See Generic type parameter variance in the CLR for some more info.  Such covariance on generics is not supported but you can actually do this with arrays: object[] a = new string[] {""spam"" ""eggs""}; C# performs runtime checks to prevent you from putting say an int into a.  That's actually so that you don't try to put any odd ""object"" in your ""ol"" list variant (as List<object> would seem to allow) - because your code would crash then (because the list really is List<string> and will only accept String type objects). That's why you can't cast your variable to a more general specification. On Java it's the other way around you don't have generics and instead everything is List of object at runtime and you really can stuff any strange object in your supposedly-strictly typed List. Search for ""Reified generics"" to see a wider discussion of java's problem...  The reason is that a generic class like List<> is for most purposes treated externally as a normal class. e.g. when you say List<string>() the compiler says ListString() (which contains strings). [Technical folk: this is an extremely plain-English-ified version of what's going on] Consequently obviously the compiler can't be smart enough to convert a ListString to a ListObject by casting the items of its internal collection. That's why there's extension methods for IEnumerable like Convert() that allow you to easily supply conversion for the items stored inside a collection which could be as simple as casting from one to another.  You cannot cast between generic types with different type parameters. Specialized generic types don't form part of the same inheritance tree and so are unrelated types. To do this pre-NET 3.5: List<string> sl = new List<string>(); // Add strings to sl List<object> ol = new List<object>(); foreach(string s in sl) { ol.Add((object)s); // The cast is performed implicitly even if omitted } Using Linq: var sl = new List<string>(); // Add strings to sl var ol = new List<object>(sl.Cast<object>()); // OR var ol = sl.Cast<object>().ToList(); // OR (note that the cast to object here is required) var ol = sl.Select(s => (object)s).ToList();  I have a: private List<Leerling> Leerlingen = new List<Leerling>(); And I was going to fill it with data collected in an List<object> What finally worked for me was this one: Leerlingen = (List<Leerling>)_DeserialiseerLeerlingen._TeSerialiserenObjecten.Cast<Leerling>(); .Cast it to the type you want to get an IEnumerable from that type then typecast the IEnemuerable to the List<> you want.  Yes you can from .NET 3.5: List<string> sl = new List<string>(); List<object> ol = sl.Cast<object>().ToList();  I think that this (contravariance) will actually be supported in C# 4.0. http://blogs.msdn.com/charlie/archive/2008/10/27/linq-farm-covariance-and-contravariance-in-visual-studio-2010.aspx  If you're using .NET 3.5 have a look at the Enumerable.Cast method. It's an extension method so you can call it directly on the List. List<string> sl = new List<string>(); IEnumerable<object> ol; ol = sl.Cast<object>(); It's not exactly what you asked for but should do the trick. Edit: As noted by Zooba you can then call ol.ToList() to get a List  Here is another pre-.NET 3.5 solution for any IList whose contents can be cast implicitly. public IList<B> ConvertIList<D B>(IList<D> list) where D : B { List<B> newList = new List<B>(); foreach (D item in list) { newList.Add(item); } return newList; } (Based on Zooba's example)  This has a lot to do with covariance e.g. generic types are considered as parameters and if the parameters do not resolve properly to a more specific type then the operation fails. The implication of such is that you really cannot cast to a more general type like object. And as stated by Rex the List object won't convert each object for you. You might want to try the ff code instead: List<string> sl = new List<string>(); //populate sl List<object> ol = new List<object>(sl); or: List<object> ol = new List<object>(); ol.AddRange(sl); ol will (theoretically) copy all the contents of sl without problems.  Think of it this way if you were to do such a cast and then add an object of type Foo to the list the list of strings is no longer consistent. If you were to iterate the first reference you would get a class cast exception because once you hit the Foo instance the Foo could not be converted to string! As a side note I think it would be more significant whether or not you can do the reverse cast: List<object> ol = new List<object>(); List<string> sl; sl = (List<string>)ol; I haven't used C# in a while so I don't know if that is legal but that sort of cast is actually (potentially) useful. In this case you are going from a more general class (object) to a more specific class (string) that extends from the general one. In this way if you add to the list of strings you are not violating the list of objects. Does anybody know or can test if such a cast is legal in C#? I think your example suffers from the same problem. What happens if ol has something in it that is not a string? The problem is some methods on List would work fine such as adding/inserting. But iterating might be a real problem. Eric Lippert has a great series of blog posts about this topic: why it might work to add covariance and contravariance contraints to generic methods but may never work the way we'd like at the class level. http://is.gd/3kQc @ChrisAmmerman: If `ol` had something in it that's not a string I suppose I would expect the cast to fail at runtime. But where you really would run into trouble is if the cast succeeded and *then* something were added to `ol` that's not a string. Because `sl` references the same object now your `List` would contain a non-string. The `Add` is the problem which I guess justifies why this code won't compile but it will compile if you change `List ol` to `IEnumerable ol` which doesn't have an `Add`. (I checked this in C# 4.) With that change it compiles but throws an `InvalidCastException` because the runtime type of `ol` is still `List`.",c# .net generics covariance type-safety13170,A,"A ThreadStateException occures when trying to restart a thread From time to time I get a System.Threading.ThreadStateException when attempting to restart a thread. The code in question is as follows: // Make sure the thread is done stopping while (this.mThread.ThreadState == ThreadState.Running) { Thread.Sleep(0); } // Respawn a thread if the current one is stopped or doesn't exist if (this.mThread == null || this.mThread.ThreadState == ThreadState.Stopped) { this.mThread = new Thread(new ParameterizedThreadStart(Monitor)); } // Start the thread if (check) { this.mThread.Start(60000); } else { this.mThread.Start(0); } So two questions - is this the correct way of doing things and it is is there a way to prevent the error from occurring? It's possible for a thread to be in more than one state at once therefore the ThreadState property is actually a bitmap of possible states. So testing for equality with just one state will not give you the right result. You would need to do something like: if((mThread.ThreadState & ThreadState.Running) != 0) However checking thread state is the wrong to do anything. I'm not entirely clear what you're trying to achieve but I will guess that you're waiting for a thread to terminate before restarting it. In that case you should do: mThread.Join(); mThread = new Thread(new ParameterizedThreadStart(Monitor)); if(check) mThread.Start(60000); else mThread.Start(0); Although if you describe the problem you're trying to solve in more detail I'm almost certain there will be a better solution. Waiting around for a thread to end just to restart it again doesn't seem that efficient to me. Perhaps you just need some kind of inter-thread communication? John.  A ThreadStateException is thrown because you're trying to start a thread that's not in a startable state. The most likely situations would be that it's already running or that it has fully exited. There are potentially a couple things that might be happening. First is the thread might have transitioned from Running to StopRequested which isn't fully stopped yet so your logic doesn't create a new thread and you're trying to start a thread which has just finished running or is about to finish running (neither of which is a valid state for restarting). The other possibility is that the thread was aborted. Threads which are aborted go to the Aborted state not the Stopped state and of course are also not valid for restarting. Really the only kind of thread that is still alive that can be ""restarted"" is one that's suspended. You might want to use this conditional instead: if (this.mThread == null || this.mThread.ThreadState != ThreadState.Suspended)  The problem is that you have code that first checks if it should create a new thread object and another piece of code that determines wether to start the thread object. Due to race conditions and similar things your code might end up trying to call .Start on an existing thread object. Considering you don't post the details behind the check variable it's impossible to know what might trigger this behavior. You should reorganize your code so that .Start is guaranteed to only be called on new objects. In short you should put the Start method into the same if-statement as the one that creates a new thread object. Personally I would try to reorganize the entire code so that I didn't need to create another thread but wrap the code inside the thread object inside a loop so that the thread just keeps on going.",c# .net multithreading exception8966,A,"Using C#/WIA version 2.0 on Vista to Scan I want to implement a paperless filing system and was looking to use WIA with C# for the image acquisition. There are quite a few sample projects on CodeProject etc. However after downloading every one of them that I can find I have run into a problem. In each and every one of them the reference to WIALib is broken. When I go to add ""Microsoft Windows Image Acquisition"" as a reference the only version available on my development workstation (also the machine that will run this) is 2.0. Unfortunately every one of these sample projects appear to have been coded against 1.x. The reference goes in as ""WIA"" instead of ""WIALib"". I took a shot just changing the namespace import but clearly the API is drastically different. Is there any information on either implementing v2.0 or on upgrading one of these existing sample projects out there? Quick question. Do you absolutely need WIA? Or can you get by with Twain? If Twain is OK I might have some code to donate. It doesn't need to be WIA. I was mostly looking at the WIA setup because it offers the same basic interface for different scanners. I've got 3 scanners on this machine and the TWAIN drivers/software for all of them suck (like blocking the screen during scanning). For document management I'm really looking for simple 200dpi grayscale scans so most of the stuff in the TWAIN drivers is overkill. That said asking here was part of my last attempt to figure out how to do it in WIA before moving on to TWAIN.  Update: I'm adding this separately since its a different answer (a year later). I learnt XP has WIA 1.0 and Vista onward has WIA2.0. You can however install WIA 2.0 for Windows XP Sp1+ from here. I then also made a small library with code I found somewhere on the interweb here it also has the ability to scan multiple pages: http://adfwia.codeplex.com/  Another note: You have to download the WIA 2.0 dll from Microsoft.com and then browse to the dll and add it to your project.  To access WIA you'll need to add a reference to the COM library ""Microsoft Windows Image Acquisition Library v2.0"" (wiaaut.dll). add a ""using WIA;"" const string wiaFormatJPEG = ""{B96B3CAE-0728-11D3-9D7B-0000F81EF32E}""; CommonDialogClass wiaDiag = new CommonDialogClass(); WIA.ImageFile wiaImage = null; wiaImage = wiaDiag.ShowAcquireImage( WiaDeviceType.UnspecifiedDeviceType WiaImageIntent.GrayscaleIntent WiaImageBias.MaximizeQuality wiaFormatJPEG true true false); WIA.Vector vector = wiaImage.FileData; (System.Drawing) Image i = Image.FromStream(new MemoryStream((byte[])vector.get_BinaryData())); i.Save(filename) Thats a basic way works with my flatbed/doc feeder. If you need more than one document/page at a time though there is probably a better way to do it (from what I could see this only handles one image at a time although I'm not entirely sure). While it is a WIA v1 doc Scott Hanselman's Coding4Fun article on WIA does contain some more info on how to do it for multiple pages I think (I'm yet to go further than that myself) If its for a paperless office system you might want also check out MODI (Office Document Imaging) to do all the OCR for you. I'll give this a shot. I""m not messing with OCR because I haven't seen any of the systems get anywhere close enough on my stuff to be more useful than just doing some decent metadata and tagging. This should give me most of what I need as once it's referenced I can dig through the API. Instead of that magic GUID you can use System.Drawing.Imaging.ImageFormat.Jpeg.Guid.ToString(""B""). Or you can use the guid defined in Interop.WIA.dll. FormatID.wiaFormatJPEG The code above will throw an exception with the message ""Exception from HRESULT: 0x80210015"" if there aren't any valid WIA devices available. You can check for devices using: WIA.DeviceManagerClass wiaDM = new DeviceManagerClass(); if (wiaDM == null || wiaDM.DeviceInfos == null || wiaDM.DeviceInfos.Count == 0) // No devices  Heres how to target WIA 1.0 also so you can ship your app to Windows Xp. Something I was desperately looking for!! http://stackoverflow.com/questions/678844/how-to-develop-using-wia-1-under-vista",c# .net .net-3.5 wia image-scanner11288,A,"WPF - Sorting a composite collection So WPF doesn't support standard sorting or filtering behavior for views of CompositeCollections so what would be a best practice for solving tihs problem. There are two or more object collections of different types. You want to combine them into a single sortable and filterable collection (withing having to manually implement sort or filter). One of the approaches I've considered is to create a new object collection with only a few core properties including the ones that I would want the collection sorted on and an object instance of each type. class MyCompositeObject { enum ObjectType; DateTime CreatedDate; string SomeAttribute; myObjectType1 Obj1; myObjectType2 Obj2; { class MyCompositeObjects : List<MyCompositeObject> { } And then loop through my two object collectiosn to build the new composite collection. Obviously this is a bit of a brute force method but it would work. I'd get all the default view sorting and filtering behavior on my new composite object collection and I'd be able to put a data template on it to display my list items properly depending on which type is actually stored in that composite item. What suggestions are there for doing this in a more elegant way? Update: I found a much more elegant solution: class MyCompositeObject { DateTime CreatedDate; string SomeAttribute; Object Obj1; { class MyCompositeObjects : List<MyCompositeObject> { } I found that due to reflection the specific type stored in Obj1 is resolved at runtime and the type specific DataTemplate is applied as expected!  Have you looked at CollectionViewSource and ICollectionView? With those classes you're able to customize grouping sorting and filtering. I'm not sure if it applies to CompositeCollections though. Have you ever tried? I tried and failed. Would love to see some code or links anything. ageektrapped: No it doesn't which is the problem.  ""Brute force"" method you mention is actually ideal solution. Mind you all objects are in RAM there is no I/O bottleneck so you can pretty much sort and filter millions of objects in less than a second on any modern computer. The most elegant way to work with collections is System.Linq namespace in .NET 3.5 Thanks - I also considered LINQ to objects but my concern there is loss of flexibility for typed data templates which I need to display the objects in my list. If you can't predict at this moment how people will sort and filter your object collection then you should look at System.Linq.Expressions namespace to build your lambda expressions on demand during runtime (first you let user to build expression then compile run and at the end you use reflection namespace to enumerate through results). It's more tricky to wrap your head around it but invaluable feature probably (to me definitively) even more ground-breaking feature than LINQ itself. lubos: Thanks - I also considered LINQ to objects but my concern there is loss of flexibility for typed data templates which I need to display the objects in my list.  itowlson answers a simple and powerful answer that solves all your pain. take a look and vote on his answer. Nevermind do whatever works best for you. There are sometimes cases that you do want to use a CompositeCollection and sort it out. From the answer itself: ""Regarding filtering sorting and grouping as per Aron's answer these are not available on a view over a CompositeCollection."" the accepted answer above works perfectly without all the Composite Collection fuss.  I'm not yet very familiar with WPF but I see this as a question about sorting and filtering List<T> collections. (withing having to manually implement sort or filter) Would you reconsider implementing your own sort or filter functions? In my experience it is easy to use. The examples below use an anonymous delegate but you could easily define your own method or a class to implement a complex sort or filter. Such a class could even have properties to configure and change the sort and filter dynamically. Use List<T>.Sort(Comparison<T> comparison) with your custom compare function: // Sort according to the value of SomeAttribute List<MyCompositeObject> myList = ...; myList.Sort(delegate(MyCompositeObject a MyCompositeObject b) { // return -1 if a < b // return 0 if a == b // return 1 if a > b return a.SomeAttribute.CompareTo(b.SomeAttribute); }; A similar approach for getting a sub-collection of items from the list. Use List<T>.FindAll(Predicate<T> match) with your custom filter function: // Select all objects where myObjectType1 and myObjectType2 are not null myList.FindAll(delegate(MyCompositeObject a) { // return true to include 'a' in the sub-collection return (a.myObjectType1 != null) && (a.myObjectType2 != null); } Brian: Once MyCompositeObject is built I get sorting and filtering for free as part of an ICollectionView.. The crux of the problem is dealing with the separate object type collections and treating them as one collection. Composite collections are the answer for creating the collection but not the sorting filtering.",c# .net wpf data-binding collections11762,A,"CryptographicException: Padding is invalid and cannot be removed I needed some simple string encryption so I wrote the following code (with a great deal of ""inspiration"" from here):  // create and initialize a crypto algorithm private static SymmetricAlgorithm getAlgorithm(string password) { SymmetricAlgorithm algorithm = Rijndael.Create(); Rfc2898DeriveBytes rdb = new Rfc2898DeriveBytes( password new byte[] { 0x530x6f0x640x690x750x6d0x20 // salty goodness 0x430x680x6c0x6f0x720x690x640x65 } ); algorithm.Padding = PaddingMode.ISO10126; algorithm.Key = rdb.GetBytes(32); algorithm.IV = rdb.GetBytes(16); return algorithm; } /* * encryptString * provides simple encryption of a string with a given password */ public static string encryptString(string clearText string password) { SymmetricAlgorithm algorithm = getAlgorithm(password); byte[] clearBytes = System.Text.Encoding.Unicode.GetBytes(clearText); MemoryStream ms = new MemoryStream(); CryptoStream cs = new CryptoStream(ms algorithm.CreateEncryptor() CryptoStreamMode.Write); cs.Write(clearBytes 0 clearBytes.Length); cs.Close(); return Convert.ToBase64String(ms.ToArray()); } /* * decryptString * provides simple decryption of a string with a given password */ public static string decryptString(string cipherText string password) { SymmetricAlgorithm algorithm = getAlgorithm(password); byte[] cipherBytes = Convert.FromBase64String(cipherText); MemoryStream ms = new MemoryStream(); CryptoStream cs = new CryptoStream(ms algorithm.CreateDecryptor() CryptoStreamMode.Write); cs.Write(cipherBytes 0 cipherBytes.Length); cs.Close(); return System.Text.Encoding.Unicode.GetString(ms.ToArray()); } The code appears to work fine except that when decrypting data with an incorrect key I get a CryptographicException - ""Padding is invalid and cannot be removed"" - on the cs.Close() line in decryptString. example code:  string password1 = ""password""; string password2 = ""letmein""; string startClearText = ""The quick brown fox jumps over the lazy dog""; string cipherText = encryptString(startClearText password1); string endClearText = decryptString(cipherText password2); // exception thrown My question is is this to be expected? I would have thought that decrypting with the wrong password would just result in nonsense output rather than an exception. This saved me so much time with your comment: `""The code appears to work fine except that when decrypting data with an incorrect key""` I _swore_ I had copied the keys but looking 2x I didn't. Hopefully this helps someone else before looking at the padding mechanism or changing code. Although this have been already answered I think it would be a good idea to explain why it is to be expected. A padding scheme is usually applied because most cryptographic filters are not semantically secure and to prevent some forms of cryptoatacks. For example usually in RSA the OAEP padding scheme is used which prevents some sorts of attacks (such as a chosen plaintext attack or blinding). A padding scheme appends some (usually) random garbage to the message m before the message is sent. In the OAEP method for example two Oracles are used (this is a simplistic explanation): Given the size of the modulus you padd k1 bits with 0 and k0 bits with a random number. Then by applying some transformation to the message you obtain the padded message wich is encrypted and sent. That provides you with a randomization for the messages and with a way to test if the message is garbage or not. As the padding scheme is reversible when you decrypt the message whereas you can't say anything about the integrity of the message itself you can in fact make some assertion about the padding and thus you can know if the message has been correctly decrypted or you're doing something wrong (i.e someone has tampered with the message or you're using the wrong key) Jorge thanks for the explanation. I'm seeing the same behavior as described the data that is decrypted is correct. am I supposed to eat this exception or (hopefully) there is something I'm doing incorrectly that I can correct? what is going wrong when the exception is thrown? all the posts I've read seem to be written by people who are more interested in making the exception going away. in my case I want my usage to be correct :)  If you want your usage to be correct you should add authentication to your ciphertext so that you can verify that it is the correct pasword or that the ciphertext hasn't been modified. The padding you are using ISO10126 will only throw an exception if the last byte doesn't decrypt as one of 16 valid values for padding (0x01-0x10). So you have a 1/16 chance of it NOT throwing the exception with the wrong password where if you authenticate it you have a deterministic way to tell if your decryption is valid. Implementing crypto deceptively easy but rather is easy to make mistakes. For example you use a fixed salt for for you key and iv derivation that means every ciphertext encrypted with the same password will reuse it's IV with that key that breaks semantic security with CBC mode the IV needs to be both unpredictable and unique for a given key. For that reason I have a code snippet that I try to keep reviewed and up to date (comments issues welcome): Modern Examples of Symmetric Authenticated Encryption of a string C#. If you use it's AESThenHMAC.AesSimpleDecryptWithPassword(ciphertext password) when the wrong password is used null is returned if the ciphertext or iv has been modified post encryption null is returned you will never get junk data back or a padding exception.  I experienced a similar ""Padding is invalid and cannot be removed."" exception but in my case the key IV and padding were correct. It turned out that flushing the crypto stream is all that was missing. Like this:  MemoryStream msr3 = new MemoryStream(); CryptoStream encStream = new CryptoStream(msr3 RijndaelAlg.CreateEncryptor() CryptoStreamMode.Write); encStream.Write(bar2 0 bar2.Length); // unless we flush the stream we would get ""Padding is invalid and cannot be removed."" exception when decoding encStream.FlushFinalBlock(); byte[] bar3 = msr3.ToArray(); This did it for me! The same should do the `encStream.Close();`.  Yes this is to be expected or at least its exactly what happens when our crypto routines get non-decryptable data  There may be some unread bytes in the CryptoStream. Closing before reading the stream completely was causing the error in my program.",c# .net exception encryption8348,A,"Using unhandled exceptions instead of Contains()? Imagine an object you are working with has a collection of other objects associated with it for example the Controls collection on a WinForm. You want to check for a certain object in the collection but the collection doesn't have a Contains() method. There are several ways of dealing with this. Implement your own Contains() method by looping through all items in the collection to see if one of them is what you are looking for. This seems to be the ""best practice"" approach. I recently came across some code where instead of a loop there was an attempt to access the object inside a try statement as follows: try { Object aObject = myCollection[myObject]; } catch(Exception e) { //if this is thrown then the object doesn't exist in the collection } My question is how poor of a programming practice do you consider the second option be and why? How is the performance of it compared to a loop through the collection? The latter is an acceptable solution. Although I would definitely catch on the specific exception (ElementNotFound?) that the collection throws in that case. Speedwise it depends on the common case. If you're more likely to find the element than not the exception solution will be faster. If you're more likely to fail then it would depend on size of the collection and its iteration speed. Either way you'd want to measure against normal use to see if this is actually a bottle neck before worrying about speed like this. Go for clarity first and the latter solution is far more clear than the former.  The general rule of thumb is to avoid using exceptions for control flow unless the circumstances that will trigger the exception are ""exceptional"" -- e.g. extremely rare! If this is something that will happen normally and regularly it definitely should not be handled as an exception. Exceptions are very very slow due to all the overhead involved so there can be performance reasons as well if it's happening often enough.  In general using exception handling for program flow and logic is bad practice. I personally feel that the latter option is unacceptable use of exceptions. Given the features of languages commonly used these days (such as Linq and lambdas in C# for example) there's no reason not to write your own Contains() method. As a final thought these days most collections do have a contains method already. So I think for the most part this is a non-issue.  Take a look at this blog post from Krzystof: http://blogs.msdn.com/kcwalina/archive/2008/07/17/ExceptionalError.aspx Exceptions should be used for communicating error conditions but they shouldn't be used as control logic (especially when there are far simpler ways to determine a condition such as Contains). Part of the issue is that exceptions while not expensive to throw are expensive to catch and all exceptions are caught at some point.  Exceptions should be exceptional. Something like 'The collection is missing because the database has fallen out from underneath it' is exceptional Something like 'the key is not present' is normal behaviour for a dictionary. For your specific example of a winforms Control collection the Controls property has a ContainsKey method which is what you're supposed to use. There's no ContainsValue because when dealing with dictionaries/hashtables there's no fast way short of iterating through the entire collection of checking if something is present so you're really discouraged from doing that. As for WHY Exceptions should be exceptional it's about 2 things Indicating what your code is trying to do. You want to have your code match what it is trying to achieve as closely as possible so it is readable and maintainable. Exception handling adds a bunch of extra cruft which gets in the way of this purpose Brevity of code. You want your code to do what it's doing in the most direct way so it is readable and maintainable. Again the cruft added by exception handling gets in the way of this.  I would have to think about it more as to how much I like it... my gut instinct is eh not so much... EDIT: Ryan Fox's comments on the exceptional case is perfect I concur As for performance it depends on the indexer on the collection. C# lets you override the indexer operator so if it is doing a for loop like the contains method you would write then it will be just as slow (with maybe a few nanoseconds slower due to the try/catch... but nothing to worry about unless that code itself is within a huge loop). If the indexer is O(1) (or even O(log(n))... or anything faster than O(n)) then the try/catch solution would be faster of course. Also I am assuming the indexer is throwing the exception if it is returning null you could of course just check for null and not use the try/catch.  I would have to say that this is pretty bad practice. Whilst some people might be happy to say that looping through the collection is less efficient to throwing an exception there is an overhead to throwing an exception. I would also question why you are using a collection to access an item by key when you would be better suited to using a dictionary or hashtable. My main problem with this code however is that regardless of the type of exception thrown you are always going to be left with the same result. For example an exception could be thrown because the object doesn't exist in the collection or because the collection itself is null or because you can't cast myCollect[myObject] to aObject. All of these exceptions will get handled in the same way which may not be your intention. These are a couple of nice articles on when and where it is usally considered acceptable to throw exceptions: Foundations of Programming Throwing exceptions in c# I particularly like this quote from the second article: It is important that exceptions are thrown only when an unexpected or invalid activity occurs that prevents a method from completing its normal function. Exception handling introduces a small overhead and lowers performance so should not be used for normal program flow instead of conditional processing. It can also be difficult to maintain code that misuses exception handling in this way.  If while writing your code you expect this object to be in the collection and then during runtime you find that it isn't I would call that an exceptional case and it is proper to use an exception. However if you're simply testing for the existence of an object and you find that it is not there this is not exceptional. Using an exception in this case is not proper. The analysis of the runtime performance depends on the actual collection being used and the method if searching for it. That shouldn't matter though. Don't let the illusion of optimization fool you into writing confusing code.",c# .net error-handling1760,A,".NET Unit Testing packages? Getting back into a bit more .NET after a few-years of not using it full-time and wondering what the good unit testing packages are these days. I'm familiar with NUnit (a few years ago) and have played briefly around with IronRuby with the goal of getting something like rspec going but don't know much beyond that. I realise I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-) Suggestions? wow an incredibly useful question with lots of upvotes that hasn't been ""closed as not constructive""... the SO fun police must have fallen asleep on their shift I have made a small example of testing a .net lib using ironRuby: http://khebbie.dk/post/2008/08/Example-of-using-ironRubys-mini_rspec-library.aspx Thanks for that. I've actually played around with this extensively myself. Unfortunately IronRuby isn't capable of running full rspec yet only mspec which is a lot more cut down. Even so it's nicer than nunit/etc :-)  Stick to NUnit. Don't go anywhere near MSTest. NUnit + ReSharper is an absolute joy to work with. Why should you stear away from MSTest? I'd appreciate if you'd actually bothered to share WHY you wanna stear away from it. And R# works with MSTest as well (with the Gallio plugin). Hi Kjetil. It's mainly for three reasons. 1. The meta-data that the MS tests create. Why? Reflect like NUnit. 2. The test runner is horrid. 3. NUnit does everything better - why change. I did for a while but then changed back. I also very much concur with the accepted answer. MS test is slow and clunky. Why repeat what's already been answered? I've also encountered various bugs with the MS test ""runner"". Basically VS leaves it running in the background and under certain circumstances tests you ran 10 minutes ago can interfere with the one you're about to run right now :-(  I like MbUnit er Gallio. Most importantly to me is having good tools support inside Visual Studio. For that I use Resharper which has an MbUnit test runner. A lot of folks seem to like TestDriven.NET as their test runner as well.  There are so many it's crazy. Crazy good I guess. For the conservative types (me) NUnit is still available and still more than capable. For the Microsoft-types MSTest is adequate but slow and clunky compared to Nunit. It also lacks code coverage without paying the big bucks for the pricey versions of Visual Studio. There's also MbUnit. It's like NUnit but has nifty features like RowTest (run the same test with different parameters) and Rollback (put the database back like you found it after a test) And finally xUnit.net is the trendy option with some attitude. Oh and TestDriven.NET will give you IDE integration for both Nunit and MBunit. I'm sure they're all just fine. I'd steer away from MSTest though unless you just enjoy the convenience of having everything in one IDE out of the box. Scott Hanselman has a podcast on this very topic. +1 note NUnit 2.5 has the nice RowTest features plus Combinatorial testing of arguments etc. The difference between MSTest and NUnit are not that big if you ask me. It mostly boils down to preferred syntax and if you use TesteDriven.Net which also supports MSTest the performance is pretty much the same. Aye NUnit 2.5 has RowTest features via the [TestCase] attribute.  I like TestDriven.NET (even though I use ReSharper) and I'm pretty happy with XUnit.net. It uses Facts instead of Tests which many people dislike but I like the difference in terminology. It's useful to think of a collection of automatically provable Facts about your software and see which ones you violate when you make a change. Be aware that Visual Studio 2008 Professional (and above) now comes with integrated Unit Testing (it used to be available only with the Team System Editions) and may be suitable for your needs.  I used to use NUnit but now tend to use MbUnit for two key features: 1. The RowTest feature allows you to easily run the same test on different sets of parameters which is important if you really want thorough coverage. 2. The Rollback feature allows you to run tests against your database while rolling back changes after every test keeping your database in exactly the same state every time. And it's as easy as adding the [Rollback] attribute. Another nice aspect of MbUnit is that its syntax is nearly identical to NUnit so if you have a whole test bed already in place under NUnit you can just switch out the references without the need to change any (very much?) code.  This is an old question but you might find it interesting that Gallio v3.1 now supports RSpec via IronRuby.  This is really a personal opinion on my part (I guess that's redundant since it is a forum). NUnit MSTest ect all do pretty mutch the same thing. However I find NMock indispensable. NMock or any mocking package is not unit testing but it makes it so much easier to do unit testing that it mught as well be.  I use the following: TestDriven.NET - Unit Testing add on for Visual Studio Typemock Isolator- Mocking framework for .Net Unit Testing NUnit - An open source unit testing framework that is in C#.  We use NUnit and MBUnit here. We use TestDriven.NET to run the unit tests from within Visual Studio. We use the excellent highly recommended RhinoMocks as a mock framework.  xUnit.net looks like it provides a slightly different approach to N/MB/MS/Unit which is interesting. In my search for an rspec-like solution (because I LOVE the rspec) I also came across NSpec which looks a bit wordy but combined with the NSpec Extensions addon to use C#3 extension methods it looks pretty nice. You may want to look at this NSpec (http://nspec.org). It's almost identical to RSpec.  I used to use NUnit but I switched to MbUnit since it has more features. I love RowTest. It lets you parametrize your tests. NUnit does have a litter bit better tool support though. I am using ReSharper to run MbUnit Tests. I've had problems with TestDriven.NET running my SetUp methods for MbUnit.",c# .net unit-testing testing15066,A,"Cycle Button Background Images in C# I have a form in C# that has a button that when clicked I want the background image to cycle through a set of images (which I have as resources to the project). The images are named '1' '2' etc. and each time I click the button I want its background image to increment to the next one and go back to ""_1"" when it gets to the highest. Is there a way to do this? I tried getting button1.BackgroundImage.ToString() but that yields System.Drawing.Bitmap instead of Resources._1 like I was thinking it would (in which case I could just get the last character and switch on that to change the background to the appropriate new image). Thanks for your help. class YourClass { private IEnumerator<Image> enumerator; YourClass(IEnumerable<Image> images) { enumerator = (from i in Enumerable.Range(0 int.Max) from image in images select image).GetEnumerator(); enumerator.MoveNext(); } public Image CurrentImage { get { return enumerator.Current; } } public void OnButtonClick() { enumerator.MoveNext(); } } You can use this code as a backing class for your control under the assumption that user wont click the button more than two billion times. Just note that once this class is created you cannot modify given image list outside. If you want to do such things you need to implement disposable pattern and dispose the enumerator accordingly.  You could subclass Button and override the BackgroundImage property so you can better keep track of the current resource that represents the image. You might also override the onclick method to internally handle cycling to the next image though that might be a little weird if the resources are handled outside of your derived button class.  Why don't you just put the images in an array?",c# .net winforms1304,A,"How to check for file lock? Is there any way to check whether a file is locked without using a try/catch block? Right now the only way I know of is to just open the file and catch any System.IO.IOException. The trouble is that an IOException could be thrown for many reasons other than a locked file. This is an old question and all of the old answers are incomplete or wrong. I added a complete and correct answer. Then between the two lines another process could easily lock the file giving you the same problem you were trying to avoid to begin with: exceptions. However this way you would know that the problem is temporary and to retry later. (E.g. you could write a thread that if encountering a lock while trying to write keeps retrying until the lock is gone.) The IOException on the other hand is not by itself specific enough that locking is the cause of the IO failure. There could be reasons that aren't temporary.  A variation of DixonD's excellent answer (above).  public static bool TryOpen( string path FileMode fileMode FileAccess fileAccess FileShare fileShare TimeSpan timeout out Stream stream) { var endTime = DateTime.Now + timeout; while (DateTime.Now < endTime) { if (TryOpen(path fileMode fileAccess fileShare out stream)) return true; } stream = null; return false; } public static bool TryOpen( string path FileMode fileMode FileAccess fileAccess FileShare fileShare out Stream stream) { try { stream = File.Open(path fileMode fileAccess fileShare); return true; } catch (IOException e) { if (!FileIsLocked(e)) throw; stream = null; return false; } } private const uint HRFileLocked = 0x80070020; private const uint HRPortionOfFileLocked = 0x80070021; private static bool FileIsLocked(IOException ioException) { var errorCode = (uint)Marshal.GetHRForException(ioException); return errorCode == HRFileLocked || errorCode == HRPortionOfFileLocked; } Usage:  private void Sample(string filePath) { Stream stream = null; try { var timeOut = TimeSpan.FromSeconds(1); if (!TryOpen( filePath FileMode.Open FileAccess.ReadWrite FileShare.ReadWrite timeOut out stream)) return; // Use stream... } finally { if (stream != null) stream.Close(); } } This is the only practical solution so far. And it works. Boooyyyyy... You better put some Thread.Sleep(200) in there and get off my CPU! What part do you want to sleep? Why? @Tristan I guess Paul Knopf meant to use Thread.Sleep between access tries.  You can see if the file is locked by trying to read or lock it yourself first. Please see my answer here for more information.  No unfortunately and if you think about it that information would be worthless anyway since the file could become locked the very next second (read: short timespan). Why specifically do you need to know if the file is locked anyway? Knowing that might give us some other way of giving you good advice. If your code would look like this: if not locked then open and update file Then between the two lines another process could easily lock the file giving you the same problem you were trying to avoid to begin with: exceptions. If file is locked we can wait some time and try again. If it is another kind of issue with file access then we should just propagate exception. Yes but the standalone check for whether a file is locked is useless the only correct way to do this is to try to open the file for the purpose you need the file and then handle the lock problem at that point. And then as you say wait or deal with it in another way. You could argue the same for access rights though it would of course be more unlikely. @LasseV.Karlsen Another benefit of doing a preemptive check is that you can notify the user before attempting a possible long operation and interrupting mid-way. The lock occurring mid-way is still possible of course and needs to be handled but in many scenarios this would help the user experience considerably. @Bart Please elaborate where is that method defined can you provide a link to it? And please note that my answer was posted 3rd quarter 2008 different .NET runtime and all but still.... What is `File.ReadWaitForUnlock`? I think the best to do is a File.ReadWaitForUnlock(file timeout) method. and returns null or the FileStream depending on success. I'm following the logic right here? @LasseV.Karlsen checkout my answer for what I ended up using based on your answer. ReadWaitForUnlock is my own method changed to TryOpenRead at the end. It is now possible to get the process that is locking a file. See http://stackoverflow.com/a/20623302/141172  You can also check if any process is using this file and show a list of programs you must close to continue like an installer does. public static string GetFileProcessName(string filePath) { Process[] procs = Process.GetProcesses(); string fileName = Path.GetFileName(filePath); foreach (Process proc in procs) { if (proc.MainWindowHandle != new IntPtr(0) && !proc.HasExited) { ProcessModule[] arr = new ProcessModule[proc.Modules.Count]; foreach (ProcessModule pm in proc.Modules) { if (pm.ModuleName == fileName) return proc.ProcessName; } } } return null; } This can only tell which process keeps an _executable module_ (dll) locked. It will not tell you which process has locked say your xml file.  Here's a variation of DixonD's code that adds number of seconds to wait for file to unlock and try again:  public bool IsFileLocked(string filePath int secondsToWait) { bool isLocked = true; int i = 0; while (isLocked && ((i < secondsToWait) || (secondsToWait == 0))) { try { using (File.Open(filePath FileMode.Open)) { } return false; } catch (IOException e) { var errorCode = Marshal.GetHRForException(e) & ((1 << 16) - 1); isLocked = errorCode == 32 || errorCode == 33; i++; if (secondsToWait !=0) new System.Threading.ManualResetEvent(false).WaitOne(1000); } } return isLocked; } if (!IsFileLocked(file 10)) { ... } else { throw new Exception(...); } Well I was doing a kind of the same thing in my original answer till somebody decided to simplify it:) http://stackoverflow.com/posts/3202085/revisions  Instead of using interop you can use the .NET FileStream class methods Lock and Unlock: FileStream.Lock http://msdn.microsoft.com/en-us/library/system.io.filestream.lock.aspx FileStream.Unlock http://msdn.microsoft.com/en-us/library/system.io.filestream.unlock.aspx This is really the correct answer as it gives the user the ability to not just lock/unlock files but sections of the files as well. All of the ""You can't do that without transactions"" comments may raise a valid concern but are not useful since they're pretending that the functionality isn't there or is somehow hidden when it's not. Actually this is not a solution because you cannot create an instance of FileStream if the file is locked. (an exception will be thrown)  You could call LockFile via interop on the region of file you are interested in. This will not throw an exception if it succeeds you will have a lock on that portion of the file (which is held by your process) that lock will be held until you call UnlockFile or your process dies.  What I ended up doing is: internal void LoadExternalData() { FileStream file; if (TryOpenRead(""filepath/filename"" 5 out file)) { using (file) using (StreamReader reader = new StreamReader(file)) { // do something } } } internal bool TryOpenRead(string path int timeout out FileStream file) { bool isLocked = true; bool condition = true; do { try { file = File.OpenRead(path); return true; } catch (IOException e) { var errorCode = Marshal.GetHRForException(e) & ((1 << 16) - 1); isLocked = errorCode == 32 || errorCode == 33; condition = (isLocked && timeout > 0); if (condition) { // we only wait if the file is locked. If the exception is of any other type there's no point on keep trying. just return false and null; timeout--; new System.Threading.ManualResetEvent(false).WaitOne(1000); } } } while (condition); file = null; return false; } You should consider a Using block for file Use `System.Threading.Thread.Sleep(1000)` instead of `new System.Threading.ManualResetEvent(false).WaitOne(1000)`  When I faced with a similar problem I finished with the following code: public bool IsFileLocked(string filePath) { try { using (File.Open(filePath FileMode.Open)){} } catch (IOException e) { var errorCode = Marshal.GetHRForException(e) & ((1 << 16) - 1); return errorCode == 32 || errorCode == 33; } return false; } +1 Just what i needed for my issue :-) Oh it seems that I haven't read that question has part ""...without using a try catch block""( Thanks for the code! it helps me :D too bad opening sqlite db used by firefox will leave program hang waiting for just the exception to be thrown @kite: There is a better way now http://stackoverflow.com/a/20623302/141172 What if between `return false` and your attempt to open the file again something else snatches it up? Race conditions ahoy!  The other answers rely on old information. This one provides a better solution. Long ago it was impossible to reliably get the list of processes locking a file because Windows simply did not track that information. To support the Restart Manager API that information is now tracked. I put together code that takes the path of a file and returns a List<Process> of all processes that are locking that file. static public class FileUtil { [StructLayout(LayoutKind.Sequential)] struct RM_UNIQUE_PROCESS { public int dwProcessId; public System.Runtime.InteropServices.ComTypes.FILETIME ProcessStartTime; } const int RmRebootReasonNone = 0; const int CCH_RM_MAX_APP_NAME = 255; const int CCH_RM_MAX_SVC_NAME = 63; enum RM_APP_TYPE { RmUnknownApp = 0 RmMainWindow = 1 RmOtherWindow = 2 RmService = 3 RmExplorer = 4 RmConsole = 5 RmCritical = 1000 } [StructLayout(LayoutKind.Sequential CharSet = CharSet.Unicode)] struct RM_PROCESS_INFO { public RM_UNIQUE_PROCESS Process; [MarshalAs(UnmanagedType.ByValTStr SizeConst = CCH_RM_MAX_APP_NAME + 1)] public string strAppName; [MarshalAs(UnmanagedType.ByValTStr SizeConst = CCH_RM_MAX_SVC_NAME + 1)] public string strServiceShortName; public RM_APP_TYPE ApplicationType; public uint AppStatus; public uint TSSessionId; [MarshalAs(UnmanagedType.Bool)] public bool bRestartable; } [DllImport(""rstrtmgr.dll"" CharSet = CharSet.Unicode)] static extern int RmRegisterResources(uint pSessionHandle UInt32 nFiles string[] rgsFilenames UInt32 nApplications [In] RM_UNIQUE_PROCESS[] rgApplications UInt32 nServices string[] rgsServiceNames); [DllImport(""rstrtmgr.dll"" CharSet = CharSet.Auto)] static extern int RmStartSession(out uint pSessionHandle int dwSessionFlags string strSessionKey); [DllImport(""rstrtmgr.dll"")] static extern int RmEndSession(uint pSessionHandle); [DllImport(""rstrtmgr.dll"")] static extern int RmGetList(uint dwSessionHandle out uint pnProcInfoNeeded ref uint pnProcInfo [In Out] RM_PROCESS_INFO[] rgAffectedApps ref uint lpdwRebootReasons); /// <summary> /// Find out what process(es) have a lock on the specified file. /// </summary> /// <param name=""path"">Path of the file.</param> /// <returns>Processes locking the file</returns> /// <remarks>See also: /// http://msdn.microsoft.com/en-us/library/windows/desktop/aa373661(v=vs.85).aspx /// http://wyupdate.googlecode.com/svn-history/r401/trunk/frmFilesInUse.cs (no copyright in code at time of viewing) /// /// </remarks> static public List<Process> WhoIsLocking(string path) { uint handle; string key = Guid.NewGuid().ToString(); List<Process> processes = new List<Process>(); int res = RmStartSession(out handle 0 key); if (res != 0) throw new Exception(""Could not begin restart session. Unable to determine file locker.""); try { const int ERROR_MORE_DATA = 234; uint pnProcInfoNeeded = 0 pnProcInfo = 0 lpdwRebootReasons = RmRebootReasonNone; string[] resources = new string[] { path }; // Just checking on one resource. res = RmRegisterResources(handle (uint)resources.Length resources 0 null 0 null); if (res != 0) throw new Exception(""Could not register resource.""); //Note: there's a race condition here -- the first call to RmGetList() returns // the total number of process. However when we call RmGetList() again to get // the actual processes this number may have increased. res = RmGetList(handle out pnProcInfoNeeded ref pnProcInfo null ref lpdwRebootReasons); if (res == ERROR_MORE_DATA) { // Create an array to store the process results RM_PROCESS_INFO[] processInfo = new RM_PROCESS_INFO[pnProcInfoNeeded]; pnProcInfo = pnProcInfoNeeded; // Get the list res = RmGetList(handle out pnProcInfoNeeded ref pnProcInfo processInfo ref lpdwRebootReasons); if (res == 0) { processes = new List<Process>((int)pnProcInfo); // Enumerate all of the results and add them to the // list to be returned for (int i = 0; i < pnProcInfo; i++) { try { processes.Add(Process.GetProcessById(processInfo[i].Process.dwProcessId)); } // catch the error -- in case the process is no longer running catch (ArgumentException) { } } } else throw new Exception(""Could not list processes locking resource.""); } else if (res != 0) throw new Exception(""Could not list processes locking resource. Failed to get size of result.""); } finally { RmEndSession(handle); } return processes; } } The only answer here that actually answers the OP question... nice!",c# .net io filelock21715,A,"List or BusinessObjectCollection? Prior to C# generics everyone would code collections for their business objects by creating a collection base that implemented IEnumerable IE: public class CollectionBase : IEnumerable and then would derive their Business Object collections from that. public class BusinessObjectCollection : CollectionBase Now with the generic list class does anyone just use that instead? I've found that I use a compromise of the two techniques: public class BusinessObjectCollection : List<BusinessObject> I do this because I like to have strongly typed names instead of just passing Lists around. What is your approach? It's recommended that in public API's not to use List<T> but to use Collection<T> If you are inheriting from it though you should be fine afaik.  Use the type List<BusinessObject> where you have to declare a list of them. However where you return a list of BusinessObject consider returning IEnumerable<T> IList<T> or ReadOnlyCollection<T> - i.e. return the weakest possible contract that satisfies the client. Where you want to ""add custom code"" to a list code extension methods on the list type. Again attach these methods to the weakest possible contract e.g. public static int SomeCount(this IEnumerable<BusinessObject> someList) Of course you can't and shouldn't add state with extension methods so if you need to add a new property and a field behind it use a subclass or better a wrapper class to store this.  6 of 1 half dozen of another Either way its the same thing. I only do it when I have reason to add custom code into the BusinessObjectCollection. With out it having load methods return a list allows me to write more code in a common generic class and have it just work. Such as a Load method.  I prefer just to use List<BusinessObject>. Typedefing it just adds unnecessary boilerplate to the code. List<BusinessObject> is a specific type it's not just any List object so it's still strongly typed. More importantly declaring something List<BusinessObject> makes it easier for everyone reading the code to tell what types they are dealing with they don't have to search through to figure out what a BusinessObjectCollection is and then remember that it's just a list. By typedefing you'll have to require a consistent (re)naming convention that everyone has to follow in order for it to make sense.  I tend to do it with my own collection if I want to shield the access to the actual list. When you are writing business objects chance is that you need a hook to know if your object is being added/removed in such sense I think BOCollection is better idea. Of coz if that is not required List is more lightweight. Also you might want to check using IList to provide additional abstraction interface if you need some kind of proxying (e.g. a fake collection triggers lazy load from database) But... why not consider Castle ActiveRecord or any other mature ORM framework? :)  If you choose to create your own collection class you should check out the types in System.Collections.ObjectModel Namespace. The namespace defines base classes thare are ment to make it easier for implementers to create a custom collections.  try out this: System.Collections.ObjectModel.Collection<BusinessObject> it makes unnecessary to implement basic method like CollectionBase do  You should probably avoid creating your own collection for that purpose. It's pretty common to want to change the type of data structure a few times during refactorings or when adding new features. With your approach you would wind up with a separate class for BusinessObjectList BusinessObjectDictionary BusinessObjectTree etc. I don't really see any value in creating this class just because the classname is more readable. Yeah the angle bracket syntax is kind of ugly but it's standard in C++ C# and Java so even if you don't write code that uses it you're going to run into it all the time.  I would do this: using BusinessObjectCollection = List<BusinessObject>; This just creates an alias rather than a completely new type. I prefer it to using List<BusinessObject> directly because it leaves me free to change the underlying structure of the collection at some point in the future without changing code that uses it (as long as I provide the same properties and methods).  I use generic lists for almost all scenarios. The only time that I would consider using a derived collection anymore is if I add collection specific members. However the advent of LINQ has lessened the need for even that.  At the most of the time I simply go with the List way as it gives me all the functionality I need at the 90% of the time and when something 'extra' is needed I inherit from it and code that extra bit.  I do the exact same thing as you Jonathan... just inherit from List<T>. You get the best of both worlds. But I generally only do it when there is some value to add like adding a LoadAll() method or whatever. You could do the LoadAll() as an extension method that hangs from List. That would give you LoadAll() on every List/Collection and it could read in from any IEnumerable... some people might say this is an abuse of extension methods. But I say it allows you to act like you have multiple inheritance. Good idea although my LoadAll() method isn't really generic. It loads from different tables depending on the underlying object type. There might be a way to do it generically but I haven't really looked into that so far.  this is the way: return arrays accept IEnumerable<T> =) accept IEnumerable returns IEnumerable or ReadOnlyCollection but never an array. Read this : http://blogs.msdn.com/ericlippert/archive/2008/09/22/arrays-considered-somewhat-harmful.aspx ! Nice thing about returning IEnumerable is you can easily add lazy eval to your entire app.  You can use both. For laziness - I mean productivity - List is a very useful class it's also ""comprehensive"" and frankly full of YANGNI members. Coupled with the sensible argument / recommendation put forward by the MSDN article already linked about exposing List as a public member I prefer the ""third"" way: Personally I use the decorator pattern to expose only what I need from List i.e: public OrderItemCollection : IEnumerable<OrderItem> { private readonly List<OrderItem> _orderItems = new List<OrderItem>(); void Add(OrderItem item) { _orderItems.Add(item) } //implement only the list members which are required from your domain. //ie. sum items calculate weight etc... private IEnumerator<string> Enumerator() { return _orderItems.GetEnumerator(); } public IEnumerator<string> GetEnumerator() { return Enumerator(); } } Further still I'd probably abstract OrderItemCollection into IOrderItemCollection so I can swap my implementation of IOrderItemCollection over in the future in (I may prefer to use a different inner enumerable object such as Collection or more likley for perf use a Key Value Pair collection or Set.  I've been going back and forth on 2 options: public class BusinessObjectCollection : List<BusinessObject> {} or methods that just do the following: public IEnumerable<BusinessObject> GetBusinessObjects(); The benefits of the first approach is that you can change the underlying data store without having to mess with method signatures. Unfortunately if you inherit from a collection type that removes a method from the previous implementation then you'll have to deal with those situations throughout your code.  I generally only derive my own collection classes if I need to ""add value"". Like if the collection itself needed to have some ""metadata"" properties tagging along with it.  I am generally in the camp of just using a List directly unless for some reason I need to encapsulate the data structure and provide a limited subset of its functionality. This is mainly because if I don't have a specific need for encapsulation then doing it is just a waste of time. However with the aggregate initializes feature in C# 3.0 there are some new situations where I would advocate using customized collection classes. Basically C# 3.0 allows any class that implements IEnumerable and has an Add method to use the new aggregate initializer syntax. For example because Dictionary defines a method Add(K key V value) it is possible to initialize a dictionary using this syntax: var d = new Dictionary<string int> { {""hello"" 0} {""the answer to life the universe and everything is:"" 42} }; The great thing about the feature is that it works for add methods with any number of arguments. For example given this collection: class c1 : IEnumerable { void Add(int x1 int x2 int x3) { //... } //... } it would be possible to initialize it like so: var x = new c1 { {123} {456} } This can be really useful if you need to create static tables of complex objects. For example if you were just using List<Customer> and you wanted to create a static list of customer objects you would have to create it like so: var x = new List<Customer> { new Customer(""Scott Wisniewski"" ""555-555-5555"" ""Seattle"" ""WA"") new Customer(""John Doe"" ""555-555-1234"" ""Los Angeles"" ""CA"") new Customer(""Michael Scott"" ""555-555-8769"" ""Scranton PA"") new Customer(""Ali G"" """" ""Staines"" ""UK"") } However if you use a customized collection like this one: class CustomerList : List<Customer> { public void Add(string name string phoneNumber string city string stateOrCountry) { Add(new Customer(name phoneNumber city stateOrCounter)); } } You could then initialize the collection using this syntax: var customers = new CustomerList { {""Scott Wisniewski"" ""555-555-5555"" ""Seattle"" ""WA""} {""John Doe"" ""555-555-1234"" ""Los Angeles"" ""CA""} {""Michael Scott"" ""555-555-8769"" ""Scranton PA""} {""Ali G"" """" ""Staines"" ""UK""} } This has the advantage of being both easier to type and easier to read because their is no need to retype the element type name for each element. The advantage can be particularly strong if the element type is long or complex. That being said this is only useful if you need static collections of data defined in your app. Some types of apps like compilers use them all the time. Others like typical database apps don't because they load all their data from a database. My advice would be that if you either need to define a static collection of objects or need to encapsulate away the collection interface then create a custom collection class. Otherwise I would just use List<T> directly.  As someone else pointed out it is recommended not to expose List publicly and FxCop will whinge if you do so. This includes inheriting from List as in: public MyTypeCollection : List<MyType> In most cases public APIs will expose IList (or ICollection or IEnumerable) as appropriate. In cases where you want your own custom collection you can keep FxCop quiet by inheriting from Collection instead of List.",c# .net generics collections class-design16556,A,"VS.NET Application Diagrams Have you used VS.NET Architect Edition's Application and System diagrams to start designing a solution? If so did you find it useful? Did the ""automatic implementation"" feature worked ok? I used to use it a lot. This designer worked good for stubbing out prototype projects but ultimately I found myself wasting a lot of time moving the mouse around when I could be typing. It seemed like an awesome idea to be able to print out the class diagrams to show APIs to other developers while I was prototyping but it proved quite limiting and it looks awful on a non-color printer. Now I just use the text editor and some AutoHotkey macros to get everything done.  Yes and no it's not very useful in my opinion. It's not very stable it's easy to get out of sync and the ""look how fast I generate this"" advantage is virtually nil when compared to more mundane things such as code snippets. Then again I am a total ""Architect"" luddite so take this with a grain of salt.  I agree with Stu and I don't consider myself an Architect luddite :-). Kind of like a lot of MS frameworks over the years you are tied to their particular way of thinking which doesn't always gel with the ideas that come out of the rest of the architecture community at large. Generating stubs in my opinion doesn't really add that much value and the round trip half of the equation has messed up some of my project files and made me have to re-write the things manually.",c# .net visual-studio architecture diagram22322,A,"How to late bind 32bit/64 bit libs at runtime I've got a problem similar tobut subtly different from that described here (Loading assemblies and their dependencies). I have a C++ DLL for 3D rendering that is what we sell to customers. For .NET users we will have a CLR wrapper around it. The C++ DLL can be built in both 32 and 64bit versions but I think this means we need to have two CLR wrappers since the CLR binds to a specific DLL? Say now our customer has a .NET app that can be either 32 or 64bit and that it being a pure .NET app it leaves the CLR to work it out from a single set of assemblies. The question is how can the app code dynamically choose between our 32 and 64bit CLR/DLL combinations at run-time? Even more specifically is the suggested answer to the aforementioned question applicable here too (i.e. create a ResolveEvent handler)? Thanks in advance. I encountered a similar scenario a while back. A toolkit I was using did not behave well in a 64-bit environment and I wasn't able to find a way to dynamically force the assemblies to bind as 32 bit. It is possible to force your assemblies to work in 32 bit mode but this requires patching the CLR header (there is a tool that does that in the Framework) and if your assemblies are strongly-named this does not work out. I'm afraid you'll need to build and publish two sets of binaries for 32 and 64 bit platforms.  I was able to do this about a year ago but I no longer remember all of the details. Basically you can use IntPtr.Size to determine which DLL to load then perform the actual LoadLibrary through p/Invoke. At that point you've got the module in memory and you ought to be able to just p/Invoke functions from inside of it -- the same module name shouldn't get reloaded again. I think though that in my application I actually had the C++ DLL register itself as a COM server and then accessed its functionality through a generated .NET wrapper -- so I don't know if I ever tested p/Invoking directly.  I finally have an answer for this that appears to work. Compile both 32 & 64 bit versions - both managed & unmanaged - into separate folders. Then have the .NET app choose at run time which directory to load the assemblies from. The problem with using the ResolveEvent is that it only gets called if assemblies aren't found so it is all to easy to accidentally end up with 32 bit versions. Instead use a second AppDomain object where we can change the ApplicationBase property to point at the right folder. So you end up with code like: static void Main(String[] argv) { // Create a new AppDomain but with the base directory set to either the 32-bit or 64-bit // sub-directories. AppDomainSetup objADS = new AppDomainSetup(); System.String assemblyDir = System.IO.Path.GetDirectoryName(Application.ExecutablePath); switch (System.IntPtr.Size) { case (4): assemblyDir += ""\\win32\\""; break; case (8): assemblyDir += ""\\x64\\""; break; } objADS.ApplicationBase = assemblyDir; // We set the PrivateBinPath to the application directory so that we can still // load the platform neutral assemblies from the app directory. objADS.PrivateBinPath = System.IO.Path.GetDirectoryName(Application.ExecutablePath); AppDomain objAD = AppDomain.CreateDomain("""" null objADS); if (argv.Length > 0) objAD.ExecuteAssembly(argv[0]); else objAD.ExecuteAssembly(""MyApplication.exe""); AppDomain.Unload(objAD); } You end up with 2 exes - your normal app and a second switching app that chooses which bits to load. Note - I can't take credit for the details of this myself. One of my colleagues sussed that out given my initial pointer. If and when he signs up to StackOverflow I'll assign the answer to him",c# .net 64bit clr x86-643927,A,"What Are Some Good .NET Profilers? What profilers have you used when working with .net programs and which would you particularly recommend? Don't forget nProf - a prefectly good freeware profiler. Looks kind of abandoned... only an alpha release from 2006 :-( Worked great for me. It's now a Google Code project. Had a release in July 2009. The nProf page now states: NProf is not actively developed anymore. If you are looking for an open source .NET profiler take a look at SlimTune (http://code.google.com/p/slimtune/)  I would like to add yourkit java and .net profiler I love it for Java haven't tried .NET version though.  I recently discovered EQATEC Profiler http://www.eqatec.com/tools/profiler. It works with most .NET versions and on a bunch of platforms. It is easy to use and parts of it is free even for commercial use. Fails on tail calls too :( Reported bug. Only profiles methods unfortunately. This one is only free for non-commercial use. -1 Trialware!=Freeware It was completely free back in Aug '08 when TrolleFar wrote his answer. Now as Jon says it is only free for non-commercial use. Turns out that they changed the license terms again. Parts of it is free for commercial use again. As of FEB2011 normal .NET edition for self/commercial is free. This tool is nice because it works on client/server model and can profile/by-pass repeated boundaries (e.g. Native->COM->NET->COM->NET can be profiled). The UI is rather awful though :-)  I've worked with RedGate's profiler in the past. Did the job for me.  Unfortunate most of the profilers I tried failed when used with tail calls most notably ANTS. I just end up writing my own. There is a simple implementation on CodeProject that you can use as a base.  If Licensing is an issue you could try WINDBG for memory profiling  I've been working with JetBrains dotTrace for WinForms and Console Apps (not tested on ASP.net yet) and it works quite well: They recently also added a ""Personal License"" that is significantly cheaper than the corporate one. Still if anyone else knows some cheaper or even free ones I'd like to hear as well :-)  I have found dotTrace Profiler by JetBrains to be an excellent profiling tool for .NET and their ASP.NET mode is quality.  AutomatedQA AQTime for timing and SciTech MemProfiler for memory. MemProfiler has save our team when we had a memory leak. I tried other tools but no other tool gave the same detail.  [Full Disclosure] While not yet as full-featured as some of the other .NET memory profilers listed here there is a new entry on the market called JustTrace. It's made by Telerik and it's primary goal is to make tracing/profiling easier and faster to do for all types of apps (web/Silverlight/desktop). If you've ever found profiling and optimization intimidating or slow with other tools then JustTrace might be worth a look. Thanks for trying Kyralessa. We know that process can be improved. We're working on that right now. We hope to remove those hurdles soon. For now just uncheck the boxes and in 2 min you can have an account and free JustTrace download. Sorry for the short-term trouble. -T When I go to download it and try it out Telerik wants me to ""register"" and ""create an account."" And all those newsletter subscription buttons are checkmarked by default. I'd be happy to give JustTrace a try but not if Telerik makes it this difficult. post back and let me know when I can download without creating an account and I'll give it a try. Update: Today I was able to download using the link in the answer without having to create an account.  Don't forget the awesome scitech .net memory profiler It's great for tracking down why your .net app is running out of memory. Very nice tool. Easy to use and allows you to navigate through your object graph. I espacially like the 'realtime' memory tracking. It shows you how your object counts develop during the runtime of the application.  Intelå¨ VTune‰ã¢ Performance Analyzer for quick sampling @utility73 - really great line-by-line CPU cost breakdown in vtune -- which is exactly what I was hunting for today. Thanks for suggesting this.  Haven't tried it myself but maybe dotTrace? Their ReSharper application is certainly a good one. Maybe dotTrace is too :) I've used dotTrace and can recommend it.  I doubt that the profiler which comes with Visual Studio Team System is the best profiler but I have found it to be good enough on many occasions. What specifically do you need beyond what VS offers? EDIT: Unfortunately it is only available in VS Team System but if you have access to that it is worth checking out. It's a fine profiler but it's not quite up to the standard of the new version of ANTS. You mean vs2010? In vs2008 I haven't seen a profiler. Visual studio has a profiler? I was talking about the one in VS2008 but it may not be available in all version (I'm using VSTS). From the PDC2008 videos it seems like the profiler will improve a lot in VS2010. That profiler is only available with the Team Systems versions of Visual Studio. Visual Studio Team System (Developer Edition) has a profiler. See . Thanks yeah even at work we use the regular VS. Visual Studio has a profiler since VS 2005. It is only available with Team System. That is in fact the reason I use team system (at work I have professional). It is a very good profiler in my opinion. In vs2010 pro it's also available right?  If you're looking for something quick easy and free http://code.google.com/p/slimtune/ seems to do the job fine.  The current release of SharpDevelop (3.1.1) has a nice integrated profiler. It's quite fast and integrates very well into the SharpDevelop IDE and its NUnit runner. Results are displayed in a flexible Tree/List style (use LINQ to create your own selection). Doubleclicking the displayed method jumps directly into the source code.  AQTime is reasonable but has a bit of a learning curve and isn't as easy to use as the built in one in Team Suite  In the past I‰Ûªve used the profiler that ships with Visual Studio Team System.  Others have covered performance profiling but with regards to memory profiling I'm currently evaluating both the Scitech .NET Memory Profiler 3.1 and ANTS Memory Profiler 5.1 (current versions as of September 2009). I tried the JetBrains one a year or two ago and it wasn't as good as ANTS (for memory profiling) so I haven't bothered this time. From reading the web sites it looks like it doesn't have the same memory profiling features as the other two. Both ANTS and the Scitech memory profiler have features that the other doesn't so which is best will depend upon your preferences. Generally speaking the Scitech one provides more detailed information while the ANTS one is really incredible at identifying the leaking object. Overall I prefer the ANTS one because it is so quick at identifying possible leaks. Here are the main the pros and cons of each from my experience: Common Features of ANTS and Scitech .NET Memory Profiler Real-time analysis feature Excellent how-to videos on their web sites Easy to use Reasonably performant (obviously slower than without the profiler attached but not so much you become frustrated) Show instances of leaking objects Basically they both do the job pretty well ANTS One-click filters to find common leaks including: objects kept alive only by event handlers objects that are disposed but still live and objects that are only being kept alive by a reference from a disposed object. This is probably the killer feature of ANTS - finding leaks is incredibly fast because of this. In my experience the majority of leaks are caused by event handlers not being unhooked and ANTS just takes you straight to these objects. Awesome. Object retention graph. While the same info is available in Scitech it's much easier to interpret in ANTS. Shows size with children in addition to size of the object itself (but only when an instance is selected unfortunately not in the overall class list). Better integration to Visual Studio (right-click on graph to jump to file) Scitech .NET Memory Profiler Shows stack trace when object was allocated. This is really useful for objects that are allocated in lots of different places. With ANTS it is difficult to determine exactly where the leaked object was created. Shows count of disposable objects that were not disposed. While not indicative of a leak it does identify opportunities to fix this problem and improve your application performance as a result of faster garbage collection. More detailed filtering options (several columns can be filtered independently). Presents info on total objects created (including those garbage collected). ANTS only shows 'live' object stats. This makes it easier to analyze and tune overall application performance (eg. identify where lots of objects being created unnecessarily that aren't necessarily leaking). By way of summary I think ANTS helps you find what's leaking faster while Scitech provides a bit more detail about your overall application memory performance and individual objects once you know what to look at (eg. stack trace on creation). If the stack trace and tracking of undisposed disposable objects was added to ANTS I wouldn't see the need to use anything else. +1. Great summary. +1 Would like to upvote several times! Thanks for this summary! The 4.0 version of .NET Memory Profiler (now in preview) now has a graph view. This was the one feature I liked in the ANTS profiler that Scitech one didn't have (in 3.1/3.5).  If you're on ASP.NET MVC you can try MVCMiniProfiler (http://benjii.me/2011/07/using-the-mvc-mini-profiler-with-entity-framework/)  I've been testing Telerik's JustTrace recently and although it is well away from a finished product the guys are going in the right direction.  We selected YourKit Profiler for .NET in my company as it was the best value (price vs. feature). For a small company that wants to have flexible licensing (floating licenses) it was a perfect choice - ANTS was developer seat locket at the time. Also it provided us with the ability to attach to the running process which was not possible with dotTrace. Beware though that attaching is not the best option as everything .NET will slow down but this was the only way to profile .NET applications started by other processes. Feature wise ANTS and dotTrace were better - but in the end YourKit was good enough. Starting from January 2012 YourKit have raised the pricing for the YourKit profiler. Therefore the price advantage may no longer be valid.  The latest version of ANTS memory profiler (I think it's 5) simply rocks!!! I was haunting a leak using WinDbg and SOS since it proved to be the best way before then I tried ANTS and I got it in minutes. Really a wonderful piece of software.  The NuMega True Time profiler lives on in DevPartner Studio by Micro Focus. It provides line and method level detail for .NET apps requiring only PDBs no source needed (but it helps.) It can discriminate between algorithmically heavy routines versus those with long I/O waits using our proprietary per thread kernel mode timing driver. Version 10.5 ships with new 64-process support on February 4 2011. Shameless plug: I work on the DevPartner product line. Follow up at http://www.DevPartner.com for news of the 10.5 launch. Disclaimer: I am the Product Manager for DevPartner at Micro Focus. welcome to SO. You will need to disclose any relationship to DevPartner or you will be considered a spammer and dealt with as such. I see you've answered a number of profiling questions...  ANTS Profiler. I haven't used many but I don't really have any complaints about ANTS. The visualization is really helpful.  For me SpeedTrace is the best tool on the market because it does not only help you to find bottlenecks inside your applications. It also helps you in troubleshooting scenarios to find out why your application was crashing your setup did not install your application hung up your application performance is sometimes poor depending on the data input e.g. to identify slow db transactions.  I have used JetBrains dotTrace and Redgate ANTS extensively. They are fairly similar in features and price. They both offer useful performance profiling and quite basic memory profiling. dotTrace integrates with Resharper which is really convenient as you can profile the performance of a unit test with one click from the IDE. However dotTrace often seems to give spurious results (e.g. saying that a method took several years to run) I prefer the way that ANTS presents the profiling results. It shows you the source code and to the left of each line tells you how long it took to run. dotTrace just has a tree view. EQATEC profiler is quite basic and requires you to compile special instrumented versions of your assemblies which can then be run in the EQATEC profiler. It is however free. Overall I prefer ANTS for performance profiling although if you use Resharper then the integration of dotTrace is a killer feature and means it beats ANTS in usability. The free Microsoft CLR Profiler (.Net framework 2.0 / .Net Framework 4.0) is all you need for .NET memory profiling. 2011 Update: The Scitech memory profiler has quite a basic UI but lots of useful information including some information on unmanaged memory which dotTrace and ANTS lack - you might find it useful if you are doing COM interop but I have yet to find any profiler that makes COM memory issues easy to diagnose - you usually have to break out windbg.exe. The ANTS profiler has come on in leaps and bounds in the last few years and its memory profiler has some truly useful features which now pushed it ahead of dotTrace as a package in my estimation. I'm lucky enough to have licenses for both but if you are going to buy one .Net profiler for both performance and memory make it ANTS. The profiler in Visual Studio is also really easy to use Visual Studio 2010 is in Beta and hence is free also. There have been multiple enhancements in 2010 for viewing contention and concurrency. try it... @Rick Unfortunately the profiler of Visual Studio is not present in Professional Edition... I strongly disagree about the CLR profiler being all you need for .NET memory profiling although it's possibly true if you place no value on your time. See my answer below for a summary of the best couple of memory profilers - they *will* help you find memory leaks and potential issues much faster. Current releases of the EQUATEC profiler are not free anymore. Seems like EQATEC Profiler has become free for .NET (full framework) again EQATEC Profiler is free for **all platforms** now with some DLL-limit restrictions: desktop CF Silverlight and WP7. It's still the only profiler to support all .NET 2.0+ platforms. +1 for improving your answer 2+ years after the fact. Bravo! Be careful to read the license terms. DotTrace is extremely restrictive regarding transfer of license keys among developers. The CLR Profiler linked is the old version- the new one is [here](http://www.microsoft.com/download/en/details.aspx?displaylang=en&id=13382) I've had excellent results with the latest version of the CLR Profiler. It's free it comes with source and most importantly it gave me all I needed. It might not have the polish of commercial projects but it had more than enough detail for me. I use dotTrace with dotMemory (a separate app from JetBrains) and have found them to always deliver what I need. No experience with the others so I can't speak to how good it is in comparison.  I've found plenty of problems in a big C# app using this. Usually the problem occurs during startup or shutdown as plugins are being loaded and big data structures are being created destroyed serialized or deserialized. Often they are created and initialized more than once and change handlers get added multiple times further compounding the problem. In cases like this the program can be so sluggish that only 2 samples are sufficient to pinpoint the guilty method / function / property call sites.  I would add that dotTrace's ability to diff memory and performance trace sessions is absolutely invaluable (ANTS may also have a memory diff feature but I didn't see a performance diff). Being able to run a profiling session before and after a bug fix or enhancement then compare the results is incredibly valuable especially with a mammoth legacy .NET application (as in my case) where performance was never a priority and where finding bottlenecks could be VERY tedious. Doing a before-and-after diff allows you to see the change in call count for each method and the change in duration for each method. This is helpful not only during code changes but also if you have an application that uses a different database say for each client/customer. If one customer complains of slowness you can run a profiling session using their database and compare the results with a ""fast"" database to determine which operations are contributing to the slowness. Of course there are many database-side performance tools but sometimes I really helps to see the performance metrics from the application side (since that's closer to what the user's actually seeing). Bottom line: dotTrace works great and the diff is invaluable.  I must bring an amazing tool to your notice which i have used sometime back. AVICode Interceptor Studio. In my previous company we used this wonderful tool to profile the webapplication (This is supposed to be the single largest web application in the world and the largest civilian IT project ever done). The performance team did wonders with the help of this magnificent tool. It is a pain to configure it but that is a one time activity and i would say it is worth the time. Checkout this page for details. Thanks James",c# .net profiling profiler6406,A,"How to access .Net element on Master page from a Content page? Is it possible to access an element on a Master page from the page loaded within the ContentPlaceHolder for the master? I have a ListView that lists people's names in a navigation area on the Master page. I would like to update the ListView after a person has been added to the table that the ListView is data bound to. The ListView currently does not update it's values until the cache is reloaded. We have found that just re-running the ListView.DataBind() will update a listview's contents. We have not been able to run the ListView.DataBind() on a page that uses the Master page. Below is a sample of what I wanted to do but a compiler error says ""PeopleListView does not exist in the current context"". GIS.master - Where ListView resides ...<asp:ListView ID=""PeopleListView""... GISInput_People.aspx - Uses GIS.master as it's master page GISInput_People.aspx.cs AddNewPerson() {  // Add person to table  ....  // Update Person List  PeopleListView.DataBind();  ... } What would be the best way to resolve an issue like this in C# .Net? I believe you could do this by using this.Master.FindControl or something similar but you probably shouldn't - it requires the content page to know too much about the structure of the master page. I would suggest another method such as firing an event in the content area that the master could listen for and re-bind when fired.  Option 1 :you can create public property of your master page control  public TextBox PropMasterTextBox1 { get { return txtMasterBox1; } set { txtMasterBox1 = value; } } access it on content page like  Master.PropMasterTextBox1.Text=""SomeString""; Option 2: on Master page:  public string SetMasterTextBox1Text { get { return txtMasterBox1.Text; } set { txtMasterBox1.Text = value; } } on Content Page:  Master.SetMasterTextBox1Text=""someText""; option 3 : you can create some public method that works for you these approach is not so useful but it helps if you just want to use some limited and predefined control Thank you this works. However You need to cast it: ((myMasterPage)Master).SetMasterTextBox1Text=""someText""; it depends on your implementation... for single master page it doesn't require to do so. and your actual implementation would be far complex then such basic example (like Print ""Hello World!"") This is the method I used without Serguei's additional change. Works very well doing exactly what I needed. Probably should have been marked as the answer too. +1  Assuming the control is called ""PeopleListView"" on the master page ListView peopleListView = (ListView)this.Master.FindControl(""PeopleListView""); peopleListView.DataSource = [whatever]; peopleListView.DataBind(); But @palmsey is more correct especially if your page could have the possibility of more than one master page. Decouple them and use an event.  One think to remember is the following ASP.NET directive. <%@ MasterType attribute=""value"" [attribute=""value""...] %> MSDN Reference It will help you when referencing this.Master by creating a strongly typed reference to the master page. You can then reference your ListView without needing to CAST.  you can access with the code this.Master.FindControl(ControlID) which control you wish. It returns the reference of the control so that the changes are effective. about firing an event could not be possible each situation.  Assuming your master page was named MyMaster: (Master as MyMaster).PeopleListView.DataBind(); Edit: since PeopleListView will be declared protected by default you will either need to change this to public or create a public property wrapper so that you can access it from your page.",c# .net7586,A,"How do I generate WPF controls through code I was trying to get my head around XAML and thought that I would try writing some code. Trying to add a grid with 6 by 6 column definitions then add a textblock into one of the grid cells. I don't seem to be able to reference the cell that I want. There is no method on the grid that I can add the textblock to. There is only grid.children.add(object) no Cell definition. XAML: <Page x:Class=""WPF_Tester.Page1"" xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation"" xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml"" Title=""Page1"" Loaded=""Page_Loaded""> </Page> C#: private void Page_Loaded(object sender RoutedEventArgs e) { //create the structure Grid g = new Grid(); g.ShowGridLines = true; g.Visibility = Visibility.Visible; //add columns for (int i = 0; i < 6; ++i) { ColumnDefinition cd = new ColumnDefinition(); cd.Name = ""Column"" + i.ToString(); g.ColumnDefinitions.Add(cd); } //add rows for (int i = 0; i < 6; ++i) { RowDefinition rd = new RowDefinition(); rd.Name = ""Row"" + i.ToString(); g.RowDefinitions.Add(rd); } TextBlock tb = new TextBlock(); tb.Text = ""Hello World""; g.Children.Add(tb); } Update Here is the spooky bit: Using VS2008 Pro on XP WPFbrowser Project Template (3.5 verified) I don;t get the methods in autocomplete. The cell location is an attached property - the value belongs to the TextBlock rather than Grid. However since the property itself belongs to Grid you need to use either the property definition field or the provided static functions. TextBlock tb = new TextBlock(); // // Locate tb in the second row third column. // Row and column indices are zero-indexed so this // equates to row 1 column 2. // Grid.SetRow(tb 1); Grid.SetColumn(tb 2);  WPF makes use of a funky thing called attached properties. So in your XAML you might write this: <TextBlock Grid.Row=""0"" Grid.Column=""0"" /> And this will effectively move the TextBlock into cell (00) of your grid. In code this looks a little strange. I believe it'd be something like: g.Children.Add(tb); Grid.SetRow(tb 0); Grid.SetColumn(tb 0); Have a look at that link above - attached properties make things really easy to do in XAML perhaps at the expense of intuitive-looking code.  Here is some sample Grid grid = new Grid(); // Set the column and row definitions grid.ColumnDefinitions.Add(new ColumnDefinition() { Width = new GridLength(1 GridUnitType.Auto) }); grid.ColumnDefinitions.Add(new ColumnDefinition() { Width = new GridLength(1 GridUnitType.Star) }); grid.RowDefinitions.Add(new RowDefinition() { Height = new GridLength(1 GridUnitType.Auto) }); grid.RowDefinitions.Add(new RowDefinition() { Height = new GridLength(1 GridUnitType.Auto) }); // Row 0 TextBlock tbFirstNameLabel = new TextBlock() { Text = ""First Name: ""}; TextBlock tbFirstName = new TextBlock() { Text = ""John""}; grid.Children.Add(tbFirstNameLabel ); // Add to the grid Grid.SetRow(tbFirstNameLabel  0); // Specify row for previous grid addition Grid.SetColumn(tbFirstNameLabel  0); // Specity column for previous grid addition grid.Children.Add(tbFirstName ); // Add to the grid Grid.SetRow(tbFirstName  0); // Specify row for previous grid addition Grid.SetColumn(tbFirstName  1); // Specity column for previous grid addition // Row 1 TextBlock tbLastNameLabel = new TextBlock() { Text = ""Last Name: ""}; TextBlock tbLastName = new TextBlock() { Text = ""Smith""}; grid.Children.Add(tbLastNameLabel ); // Add to the grid Grid.SetRow(tbLastNameLabel  1); // Specify row for previous grid addition Grid.SetColumn(tbLastNameLabel  0); // Specity column for previous grid addition grid.Children.Add(tbLastName ); // Add to the grid Grid.SetRow(tbLastName  1); // Specify row for previous grid addition Grid.SetColumn(tbLastName  1); // Specity column for previous grid addition  Use attached properties of the Grid class. in C#: Grid.SetRow( cell rownumber ) In XAML: <TextBlock Grid.Row=""1"" /> Also I would advice if you do not use dynamic grids use the XAML markup language. I know it has a learning curve but once you mastered it it is so much easier especially if you are going to use ControlTemplates and DataTemplates! ;)",c# .net wpf xaml20465,A,".NET - Excel ListObject autosizing on databind I'm developing an Excel 2007 add-in using Visual Studio Tools for Office (2008). I have one sheet with several ListObjects on it which are being bound to datatables on startup. When they are bound they autosize correctly. The problem comes when they are re-bound. I have a custom button on the ribbon bar which goes back out to the database and retrieves different information based on some criteria that the user inputs. This new data comes back and is re-bound to the ListObjects - however this time they are not resized and I get an exception: ListObject cannot be bound because it cannot be resized to fit the data. The ListObject failed to add new rows. This can be caused because of inability to move objects below of the list object. Inner exception: ""Insert method of Range class failed"" Reason: Microsoft.Office.Tools.Excel.FailureReason.CouldNotResizeListObject I was not able to find anything very meaningful on this error on Google or MSDN. I have been trying to figure this out for a while but to no avail. Basic code structure: //at startup DataTable tbl = //get from database listObj1.SetDataBinding(tbl); DataTable tbl2 = //get from database listObj2.SetDataBinding(tbl2); //in buttonClick event handler DataTable tbl = //get different info from database //have tried with and without unbinding old source listObj1.SetDataBinding(tbl); <-- exception here DataTable tbl2 = //get different info from database listObj2.SetDataBinding(tbl2); Note that this exception occurs even when the ListObject is shrinking and not only when it grows. I've got a similar issue with refreshign multiple listobjects. We are setting each listObject.DataSource = null then rebinding starting at the bottom listobject and working our way up instead of the top down.  If anyone else is having this problem I have found the cause of this exception. ListObjects will automatically re-size on binding as long as they do not affect any other objects on the sheet. Keep in mind that ListObjects can only affect the Ranges which they wrap around. In my case the list object which was above the other one had fewer columns than the one below it. Let's say the top ListObject had 2 columns and the bottom ListObject had 3 columns. When the top ListObject changed its number of rows it had no ability to make any changes to the third column since it wasn't in it's underlying Range. This means that it couldn't shift any cells in the third column and so the second ListObject couldn't be properly moved resulting in my exception above. Changing the positions of the ListObjects to place the wider one above the smaller one works fine. Following the logic above this now means that the wider ListObject can shift all of the columns of the second ListObject and since there is nothing below the smaller one it can also shift any cells necessary. The reason I wasn't having any trouble on the initial binding is that both ListObjects were a single cell. Since this is not optimal in my case I will probably use empty columns or try to play around with invisible columns if that's possible but at least the cause is now clear.  Just an idea of something to try to see if it gives you more info: Try resizes the list object before the exception line and see if that also throws an exception. If not try and resize the range object to the new size of the DataTable. You say that this happens when the ListObject shrinks and grows. Does it also happen if the ListObject remains the same size?",c# .net excel data-binding vsto12135,A,"FileNotFoundException for mscorlib.XmlSerializers.DLL which doesn't exist I'm using an XmlSerializer to deserialize a particular type in mscorelib.dll XmlSerializer ser = new XmlSerializer( typeof( [.Net type in System] ) ); return ([.Net type in System]) ser.Deserialize( new StringReader( xmlValue ) ); This throws a caught FileNotFoundException when the assembly is loaded: ""Could not load file or assembly 'mscorlib.XmlSerializers Version=2.0.0.0 Culture=neutral PublicKeyToken=b77a5c561934e089' or one of its dependencies. The system cannot find the file specified."" FusionLog: === Pre-bind state information === LOG: User = ### LOG: DisplayName = mscorlib.XmlSerializers Version=2.0.0.0 Culture=neutral PublicKeyToken=b77a5c561934e089 processorArchitecture=x86 (Fully-specified) LOG: Appbase = file:///C:/localdir LOG: Initial PrivatePath = NULL Calling assembly : System.Xml Version=2.0.0.0 Culture=neutral PublicKeyToken=b77a5c561934e089. === LOG: This bind starts in default load context. LOG: Using application configuration file: C:\localdir\bin\Debug\appname.vshost.exe.Config LOG: Using machine configuration file from c:\WINDOWS\Microsoft.NET\Framework\v2.0.50727\config\machine.config. LOG: Post-policy reference: mscorlib.XmlSerializers Version=2.0.0.0 Culture=neutral PublicKeyToken=b77a5c561934e089 processorArchitecture=x86 LOG: Attempting download of new URL file:///C:/localdir/bin/Debug/mscorlib.XmlSerializers.DLL. LOG: Attempting download of new URL file:///C:/localdir/bin/Debug/mscorlib.XmlSerializers/mscorlib.XmlSerializers.DLL. LOG: Attempting download of new URL file:///C:/localdir/bin/Debug/mscorlib.XmlSerializers.EXE. LOG: Attempting download of new URL file:///C:/localdir/bin/Debug/mscorlib.XmlSerializers/mscorlib.XmlSerializers.EXE. As far as I know there is no mscorlib.XmlSerializers.DLL I think the DLL name has bee auto generated by .Net looking for the serializer. You have the option of creating a myApplication.XmlSerializers.DLL when compiling to optimise serializations so I assume this is part of the framework's checking for it. The problem is that this appears to be causing a delay in loading the application - it seems to hang for a few seconds at this point. Any ideas how to avoid this or speed it up? The type I'm dealing with is `RSAParameters` which is being used as part if some system cryptography stuff. I've worked around this now by storing the encrypted key by another means and creating a new RSAParameters myself. It seems like a relatively common thing to want to serialise (i.e. encryption/decryption keys). I'm guessing now. but: The system might be generating a serializer for the whole of mscorlib which could be very slow. You could probably avoid this by wrapping the system type in your own type and serialising that instead - then you'd get a serializer for your own assembly. You might be able to build the serializer for mscorlib with sgen.exe which was the old way of building serializer dlls before it got integrated into VS. Thanks again. I think it is (1) but I can't do (2) as it's a struct. I'll try (3) > but I can't do (2) as it's a struct. I know I'm being dim here but what's the problem with it being a struct - obviously there may be some extra copying going on but relative to the costs of xml serialisation it seems unlikely that's very significant. What is the system.xx type anyway?  Okay so I ran into this problem and have found a solution for it specific to my area. This occurred because I was trying to serialize a list into an XML document (file) without an XML root attribute. Once I added the following files the error goes away. XmlRootAttribute rootAttribute = new XmlRootAttribute(); rootAttribute.ElementName = ""SomeRootName""; rootAttribute.IsNullable = true; Dunno if it'll fix your problem but it fixed mine.  The delay is because having been unable to find the custom serializer dll the system is building the equivalent code (which is very time-consuming) on the fly. The way to avoid the delay is to have the system build the DLL and make sure it's available to the .EXE - have you tried this? Thanks @Will Dean that's kinda what I figured but it seems too slow even for that. If it were my own assembly creating the serialisation assembly shouldn't be an issue but how would I do that for mscorlib?",c# .net serialization assemblies10456,A,"HowTo Disable WebBrowser 'Click Sound' in your app only The 'click sound' in question is actually a system wide preference so I only want it to be disabled when my application has focus and then re-enable when the application closes/loses focus. Originally I wanted to ask this question here on stackoverflow but I was not yet in the beta. So after googling for the answer and finding only a little bit of information on it I came up with the following and decided to post it here now that I'm in the beta. using System; using Microsoft.Win32; namespace HowTo { class WebClickSound { /// <summary> /// Enables or disables the web browser navigating click sound. /// </summary> public static bool Enabled { get { RegistryKey key = Registry.CurrentUser.OpenSubKey(@""AppEvents\Schemes\Apps\Explorer\Navigating\.Current""); string keyValue = (string)key.GetValue(null); return String.IsNullOrEmpty(keyValue) == false && keyValue != ""\""\""""; } set { string keyValue; if (value) { keyValue = ""%SystemRoot%\\Media\\""; if (Environment.OSVersion.Version.Major == 5 && Environment.OSVersion.Version.Minor > 0) { // XP keyValue += ""Windows XP Start.wav""; } else if (Environment.OSVersion.Version.Major == 6) { // Vista keyValue += ""Windows Navigation Start.wav""; } else { // Don't know the file name so I won't be able to re-enable it return; } } else { keyValue = ""\""\""""; } // Open and set the key that points to the file RegistryKey key = Registry.CurrentUser.OpenSubKey(@""AppEvents\Schemes\Apps\Explorer\Navigating\.Current"" true); key.SetValue(null keyValue RegistryValueKind.ExpandString); isEnabled = value; } } } } Then in the main form we use the above code in these 3 events: Activated Deactivated FormClosing private void Form1_Activated(object sender EventArgs e) { // Disable the sound when the program has focus WebClickSound.Enabled = false; } private void Form1_Deactivate(object sender EventArgs e) { // Enable the sound when the program is out of focus WebClickSound.Enabled = true; } private void Form1_FormClosing(object sender FormClosingEventArgs e) { // Enable the sound on app exit WebClickSound.Enabled = true; } The one problem I see currently is if the program crashes they won't have the click sound until they re-launch my application but they wouldn't know to do that. What do you guys think? Is this a good solution? What improvements can be made? I had a problem with this line: isEnabled = value; I've just commented it but i want to know what it was intended to be You disable it by changing Internet Explorer registry value of navigating sound to ""NULL"": Registry.SetValue(""HKEY_CURRENT_USER\\AppEvents\\Schemes\\Apps\\Explorer\\Navigating\\.Current""""""""NULL""); And enable it by changing Internet Explorer registry value of navigating sound to ""C:\Windows\Media\Cityscape\Windows Navigation Start.wav"": Registry.SetValue(""HKEY_CURRENT_USER\\AppEvents\\Schemes\\Apps\\Explorer\\Navigating\\.Current""""""""C:\Windows\Media\Cityscape\Windows Navigation Start.wav""); This does not even apply to the question....  Definitely feels like a hack but having done some research on this a long time ago and not finding any other solutions probably your best bet. Better yet would be designing your application so it doesn't require many annoying page reloads.. for example if you're refreshing an iframe to check for updates on the server use XMLHttpRequest instead. (Can you tell that I was dealing with this problem back in the days before the term ""AJAX"" was coined?)  I've noticed that if you use WebBrowser.Document.Write rather than WebBrowser.DocumentText then the click sound doesn't happen. So instead of this: webBrowser1.DocumentText = ""<h1>Hello world!</h1>""; try this: webBrowser1.Document.OpenNew(true); webBrowser1.Document.Write(""<h1>Hello world!</h1>""); your suggested solution prevents the control from making that click noise but on the other side this approach causes the control to have serious focus issues. In my case the webbrowser control steals back the focus at the end of the event loop. As far as I can tell there's no workaround for that. In my case I needed to get back to the DocumentText solution - but still I'm looking for disabling that annoying sound. Any other ideas? Just found out that James on this thread: http://stackoverflow.com/questions/393166/how-to-disable-click-sound-in-webbrowser-control has a great solution - at least for IE7 and IE8. I can use the DocumentText property have no focus issues and best of all I have no click sound.  If you want to use replacing Windows Registry use this: // backup value RegistryKey key = Registry.CurrentUser.OpenSubKey(@""AppEvents\Schemes\Apps\Explorer\Navigating\.Current""); string BACKUP_keyValue = (string)key.GetValue(null); // write nothing key = Registry.CurrentUser.OpenSubKey(@""AppEvents\Schemes\Apps\Explorer\Navigating\.Current"" true); key.SetValue(null """" RegistryValueKind.ExpandString); // do navigation ... // write backup key RegistryKey key = Registry.CurrentUser.OpenSubKey(@""AppEvents\Schemes\Apps\Explorer\Navigating\.Current"" true); key.SetValue(null BACKUP_keyValue RegistryValueKind.ExpandString);   const int FEATURE_DISABLE_NAVIGATION_SOUNDS = 21; const int SET_FEATURE_ON_PROCESS = 0x00000002; [DllImport(""urlmon.dll"")] [PreserveSig] [return: MarshalAs(UnmanagedType.Error)] static extern int CoInternetSetFeatureEnabled( int FeatureEntry [MarshalAs(UnmanagedType.U4)] int dwFlags bool fEnable); static void DisableClickSounds() { CoInternetSetFeatureEnabled( FEATURE_DISABLE_NAVIGATION_SOUNDS SET_FEATURE_ON_PROCESS true); } +1 for InterOp way this actually works! Thank you I needed this. Awesome works like a charm and only disables it for just your app and doesn't rely on form focus. Nice solution works perfectly. Great solution! Thank you very much!",c# .net winforms4227,A,"Accessing a Dictionary.Keys Key through a numeric index I'm using a Dictionary<string int> where the int is a count of the key. Now I need to access the last-inserted Key inside the Dictionary but i do not know the name of it. The obvious attempt: int LastCount = mydict[mydict.keys[mydict.keys.Count]]; does not work because Dictionary.Keys does not implement a []-indexer. I just wonder if there is any similar class? I thought about using a Stack but that only stores a string. I could now create my own struct and then use a Stack<MyStruct> but I wonder if there is another alternative essentially a Dictionary that implements an []-indexer on the Keys? What happens if you box that variable? In case you decide to use dangerous code that is subject to breakage this extension function will fetch a key from a Dictionary according to its internal indexing (which for Mono and .NET currently appears to be in the same order as you get by enumerating the Keys property). It is much preferable to use Linq: dict.Keys.ElementAt(i) but I don't know if that function is smart enough to not iterate O(N). The following is O(1) but with a reflection performance penalty. using System; using System.Collections.Generic; using System.Reflection; public static class Extensions { public static TKey KeyByIndex<TKeyTValue>(this Dictionary<TKey TValue> dict int idx) { Type type = typeof(Dictionary<TKey TValue>); FieldInfo info = type.GetField(""entries"" BindingFlags.NonPublic | BindingFlags.Instance); if (info != null) { // .NET Object element = ((Array)info.GetValue(dict)).GetValue(idx); return (TKey)element.GetType().GetField(""key"" BindingFlags.Public | BindingFlags.Instance).GetValue(element); } // Mono: info = type.GetField(""keySlots"" BindingFlags.NonPublic | BindingFlags.Instance); return (TKey)((Array)info.GetValue(dict)).GetValue(idx); } };  You could always do this: string[] temp = new string[mydict.count]; mydict.Keys.CopyTo(temp 0) int LastCount = mydict[temp[mydict.count - 1]] But I wouldn't recommend it. There's no guarantee that the last inserted key will be at the end of the array. The ordering for Keys on MSDN is unspecified and subject to change. In my very brief test it does seem to be in order of insertion but you'd be better off building in proper bookkeeping like a stack--as you suggest (though I don't see the need of a struct based on your other statements)--or single variable cache if you just need to know the latest key.  Why don't you just extend the dictionary class to add in a last key inserted property. Something like the following maybe? public class ExtendedDictionary : Dictionary<string int> { private int lastKeyInserted = -1; public int LastKeyInserted { get { return lastKeyInserted; } set { lastKeyInserted = value; } } public void AddNew(string s int i) { lastKeyInserted = i; base.Add(s i); } } Eh? No I'm not(?) You are setting lastKeyInserted to the last value inserted. Either you meant to set it to the last key inserted or you need better names for the variable and property.  I don't know if this would work because I'm pretty sure that the keys aren't stored in the order they are added but you could cast the KeysCollection to a List and then get the last key in the list... but it would be worth having a look. The only other thing I can think of is to store the keys in a lookup list and add the keys to the list before you add them to the dictionary... it's not pretty tho. I didnt test the code but the method is documented on [MSDN][1] maybe its another version the framework? [1]: http://msdn.microsoft.com/en-us/library/bb908406.aspx @Juan: there is no .Last() method on the KeyCollection 2 years late but it might help someone... see my reply to Juan's post below. Last() is an extension method.  The way you worded the question leads me to believe that the int in the Dictionary contains the item's ""position"" on the Dictionary. Judging from the assertion that the keys aren't stored in the order that they're added if this is correct that would mean that keys.Count (or .Count - 1 if you're using zero-based) should still always be the number of the last-entered key? If that's correct is there any reason you can't instead use Dictionary<int string> so that you can use mydict[ mydict.Keys.Count ]?  I think you can do something like this the syntax might be wrong havent used C# in a while To get the last item Dictionary<string int>.KeyCollection keys = mydict.keys; string lastKey = keys.Last(); or use Max instead of Last to get the max value I dont know which one fits your code better. I would add that since ""Last()"" is an extension method you would need the .NET Framework 3.5 and to add ""using System.Linq"" at the top of your .cs file. Try this for last (when using a Dist obviously :-) KeyValuePair last = oAuthPairs.Last(); if (kvp.Key != last.Key) { _oauth_ParamString = _oauth_ParamString + ""&""; }  One alternative would be a KeyedCollection if the key is embedded in the value. Just create a basic implementation in a sealed class to use. So to replace Dictionary<string int> (which isn't a very good example as there isn't a clear key for a int). private sealed class IntDictionary : KeyedCollection<string int> { protected override string GetKeyForItem(int item) { // The example works better when the value contains the key. It falls down a bit for a dictionary of ints. return item.ToString(); } } KeyedCollection<string int> intCollection = new ClassThatContainsSealedImplementation.IntDictionary(); intCollection.Add(7); int valueByIndex = intCollection[0]; Regarding your comments on the key see my follow up answer to this one.  To expand on Daniels post and his comments regarding the key since the key is embedded within the value anyway you could resort to using a KeyValuePair<TKey TValue> as the value. The main reasoning for this is that in general the Key isn't necessarily directly derivable from the value. Then it'd look like this: public sealed class CustomDictionary<TKey TValue> : KeyedCollection<TKey KeyValuePair<TKey TValue>> { protected override TKey GetKeyForItem(KeyValuePair<TKey TValue> item) { return item.Key; } } To use this as in the previous example you'd do: CustomDictionary<string int> custDict = new CustomDictionary<string int>(); custDict.Add(new KeyValuePair<string int>(""key"" 7)); int valueByIndex = custDict[0].Value; int valueByKey = custDict[""key""].Value; string keyByIndex = custDict[0].Key;  Its very simple. But you need use linq. int LastCount = mydict.Keys.ElementAt(mydict.Count -1);  A Dictionary is a Hash Table so you have no idea the order of insertion! If you want to know the last inserted key I would suggest extending the Dictionary to include a LastKeyInserted value. E.g.: public MyDictionary<K T> : IDictionary<K T> { private IDictionary<K T> _InnerDictionary; public K LastInsertedKey { get; set; } public MyDictionary() { _InnerDictionary = new Dictionary<K T>(); } #region Implementation of IDictionary public void Add(KeyValuePair<K T> item) { _InnerDictionary.Add(item); LastInsertedKey = item.Key; } public void Add(K key T value) { _InnerDictionary.Add(key value); LastInsertedKey = key; } .... rest of IDictionary methods #endregion } You will run into problems however when you use .Remove() so to overcome this you will have to keep an ordered list of the keys inserted.  You can use an OrderedDictionary. Represents a collection of key/value pairs that are accessible by the key or index. Erhm after 19 upvotes no one mentioned that OrderedDictionary still does not allow to get the key by index? You can access a value with an integer index with an **OrderedDictionary** but not with a **System.Collections.Generic.SortedDictionary** where the index need to be a TKey  I agree with the second part of Patrick's answer. Even if in some tests it seems to keep insertion order the documentation (and normal behavior for dictionaries and hashes) explicitly states the ordering is unspecified. You're just asking for trouble depending on the ordering of the keys. Add your own bookkeeping (as Patrick said just a single variable for the last added key) to be sure. Also don't be tempted by all the methods such as Last and Max on the dictionary as those are probably in relation to the key comparator (I'm not sure about that).",c# .net29664,A,"How to catch SQLServer timeout exceptions I need to specifically catch SQL server timeout exceptions so that they can be handled differently. I know I could catch the SqlException and then check if the message string Contains ""Timeout"" but was wondering if there is a better way to do it? try { //some code } catch (SqlException ex) { if (ex.Message.Contains(""Timeout"")) { //handle timeout } else { throw; } } Are you looking for a ConnectionTimeout or a CommandTimeout ie are you expecting the connection to fail or the executed command to fail? I'm looking for a CommandTimeout which is set to a default of 30 secs i think Whats the value for the SqlException.ErrorCode property? Can you work with that? Seems like this guy is having timeouts may be worth checking the code for -2146232060. I would set this up as a static const in your data code. Looking at the docs for ErrorCode it seems to me that it's reporting Interop-Level errors. So it may be more on the level of COM errors or that a provider encountered an exception (generally) instead of a specific error relating to what you're doing. @Eric is correct - that is an HRESULT code for the SqlException type not for the source of the exception.  here: http://www.tech-archive.net/Archive/DotNet/microsoft.public.dotnet.framework.adonet/2006-10/msg00064.html You can read also that Thomas Weingartner wrote: Timeout: SqlException.Number == -2 (This is an ADO.NET error code) General Network Error: SqlException.Number == 11 ... We handle the ""General Network Error"" as a timeout exception too. It only occurs under rare circumstances e.g. when your update/insert/delete query will raise a long running trigger.  To check for a timeout I believe you check the value of ex.Number. If it is -2 then you have a timeout situation. -2 is the error code for timeout returned from DBNETLIB the MDAC driver for SQL Server. This can be seen by downloading Reflector and looking under System.Data.SqlClient.TdsEnums for TIMEOUT_EXPIRED. Your code would read: if (ex.Number == -2) { //handle timeout } Code to demonstrate failure: try { SqlConnection sql = new SqlConnection(@""Network Library=DBMSSOCN;Data Source=YourServer1433;Initial Catalog=YourDB;Integrated Security=SSPI;""); sql.Open(); SqlCommand cmd = sql.CreateCommand(); cmd.CommandText = ""DECLARE @i int WHILE EXISTS (SELECT 1 from sysobjects) BEGIN SELECT @i = 1 END""; cmd.ExecuteNonQuery(); // This line will timeout. cmd.Dispose(); sql.Close(); } catch (SqlException ex) { if (ex.Number == -2) { Console.WriteLine (""Timeout occurred""); } Yes that's pretty much what I'm doing at the moment but it's not very elegant checking for -2 Download Red Gate's Reflector and search for TIMEOUT_EXPIRED. It lives in System.Data.SqlClient.TdsEnums and its value is -2. :o) For those who do not have access to Reflector: [link](http://www.dotnetframework.org/default.aspx/4@0/4@0/untmp/DEVDIV_TFS/Dev10/Releases/RTMRel/ndp/fx/src/Data/System/Data/SqlClient/TdsEnums@cs/1305376/TdsEnums@cs)",c# .net sql-server error-handling21078,A,"What's the best string concatenation method using C#? What's the most efficient way to concatenate strings? It's also important to point it out that you should use the + operator if you are concatenating string literals. When you concatenate string literals or string constants by using the + operator the compiler creates a single string. No run time concatenation occurs. How to: Concatenate Multiple Strings (C# Programming Guide)  There are 5 types of string concatenations: using plus (+) symbol. using string.Concat(). using string.Format(). using string.Append(). using stringBuilder. In an experiment it has been proved that string.Concat() is the best way to approach if the strings are less than 1000(approximately) and if the strings are more than 1000 then stringBuilder should be used. For more information check this site. i am new to .net while referring this question i also got this link through google search. so i just forwarded here thinking it may help others. Could be a 1000 strings or a string 1000 characters long... 1000? 1000 strings chars carrots? @MatthewCanty carrots.. carrots because I am no longer working on this field (.NET). you can edit my post or add a post which explains more clearly than mine or downvote my post or better one is to comment here so that I can improve it. :) btw I made the statement as strings in my post -- _if the strings are less than 1000_.  For just two strings you definitely do not want to use StringBuilder. There is some threshold above which the StringBuilder overhead is less than the overhead of allocating multiple strings. So for more that 2-3 strings use DannySmurf's code. Otherwise just use the + operator.  If you're operating in a loop StringBuilder is probably the way to go; it saves you the overhead of creating new strings regularly. In code that'll only run once though String.Concat is probably fine. However Rico Mariani (.NET optimization guru) made up a quiz in which he stated at the end that in most cases he recommends String.Format. I've been recommending the use of string.format over string + string for years to people I've worked with. I think the readability advantages are an additional advantage beyond the performance benefit. This is the actual correct answer. The currently accepted answer for StringBuilder is incorrect as it does not mention single line appends for which string.concat or + is faster. Little known fact is that the compiler actually translates +'s into string.concat's. Also for loops or for multiple line concats I use a custom built string builder that only appends when .ToString is called - overcoming the indeterminate buffer problem that StringBuilder has  It really depends on your usage pattern. A detailed benchmark between string.Join stringConcat and string.Format can be found here: String.Format Isn't Suitable for Intensive Logging (This is actually the same answer I gave to this question)  The most efficient is to use StringBuilder like so: StringBuilder sb = new StringBuilder(); sb.Append(""string1""); sb.Append(""string2""); ...etc... String strResult = sb.ToString(); @jonezy: String.Concat is fine if you have a couple of small things. But if you're concatenating megabytes of data your program will likely tank.  The StringBuilder.Append() method is much better than using the + operator. But I've found that when the concatenations are less than 1000 String.Join() is even more efficient than StringBuilder. StringBuilder sb = new StringBuilder(); sb.Append(someString); The only problem with String.Join is that you have to concatenate the strings with a common delimiter. string key = String.Join(""_"" new String[] { ""Customers_Contacts"" customerID database SessionID }); funny but good point :) Isn't the 'ToString' call on 'someString' unnecessary? Unless 'someString' is really an int and it's a big lying liar. ;) It would be good to note that though String.Join adds a delimiter you can make that delimiter String.Empty. `StringBuilder` has a huge comparable start-up cost it's only efficient when used with very large strings or very many concatenations. It isn't trivial to find out for any given situation. If performance is of issue profiling is your friend (check ANTS). This is not true for single line concatenation. Say you do myString = ""foo"" + var1 + ""bar"" + var2 + ""hello"" + var3 + ""world"" the compiler automatically turns that into a string.concat call which is as efficient as it gets. This answer is incorrect there are plenty of better answers to choose from @csuave - true and noted below in Lee's answer. I suppose the original question is not specific enough to choose a single answer. For trivial string concatentation use what ever is most readable. string a = b + c + d; will almost always be faster than doing it with StringBuilder but the difference is typically irrelevant. Use StringBuilder (or other option of your choice) when repeatedly adding to the same string (eg. building up a report) or when dealing with large strings. Why haven't you mentioned `string.Concat`? 1000 what? Chars?  Rico Mariani the .NET Performance guru had an article on this very subject. It's not as simple as one might suspect. The basic advice is this: If your pattern looks like: x = f1(...) + f2(...) + f3(...) + f4(...) that's one concat and it's zippy StringBuilder probably won't help. If your pattern looks like: if (...) x += f1(...) if (...) x += f2(...) if (...) x += f3(...) if (...) x += f4(...) then you probably want StringBuilder. This answer is the correct one not the answer by ""TheImirOfGroofunkistan"" as that does not take into account single-line concats. +1 I didn't know that :) Neither of my books mentions that. Thanks I'm really used to single line +'s syntax  From Chinh Do - StringBuilder is not always faster: Rules of Thumb When concatenating three dynamic string values or less use traditional string concatenation. When concatenating more than three dynamic string values use StringBuilder. When building a big string from several string literals use either the @ string literal or the inline + operator. Most of the time StringBuilder is your best bet but there are cases as shown in that post that you should at least think about each situation. afaik @ only turns off escape sequences processing. http://msdn.microsoft.com/en-us/library/362314fe.aspx agree  It would depend on the code. StringBuilder is more efficient generally but if you're only concatenating a few strings and doing it all in one line code optimizations will likely take care of it for you. It's important to think about how the code looks too: for larger sets StringBuilder will make it easier to read for small ones StringBuilder will just add needless clutter.  From this MSDN article: There is some overhead associated with creating a StringBuilder object both in time and memory. On a machine with fast memory a StringBuilder becomes worthwhile if you're doing about five operations. As a rule of thumb I would say 10 or more string operations is a justification for the overhead on any machine even a slower one. So if you trust MSDN go with StringBuilder if you have to do more than 10 strings operations/concatenations - otherwise simple string concat with '+' is fine. Simple and sound if - I repeat - you decide to trust MSDN.  System.String is immutable. When we modify the value of a string variable then a new memory is allocated to the new value and the previous memory allocation released. System.StringBuilder was designed to have concept of a mutable string where a variety of operations can be performed without allocation separate memory location for the modified string.",c# .net string optimization10274,A,"When should I not use the ThreadPool in .Net? When should I not use the ThreadPool in .Net? It looks like the best option is to use a ThreadPool in which case why is it not the only option? What are your experiences around this? MSDN has a list some reasons here: http://msdn.microsoft.com/en-us/library/0ka9477y.aspx There are several scenarios in which it is appropriate to create and manage your own threads instead of using thread pool threads: You require a foreground thread. You require a thread to have a particular priority. You have tasks that cause the thread to block for long periods of time. The thread pool has a maximum number of threads so a large number of blocked thread pool threads might prevent tasks from starting. You need to place threads into a single-threaded apartment. All ThreadPool threads are in the multithreaded apartment. You need to have a stable identity associated with the thread or to dedicate a thread to a task.  To quarrelsome's answer I would add that it's best not to use a ThreadPool thread if you need to guarantee that your thread will begin work immediately. The maximum number of running thread-pooled threads is limited per appdomain so your piece of work may have to wait if they're all busy. It's called ""queue user work item"" after all. Two caveats of course: You can change the maximum number of thread-pooled threads in code at runtime so there's nothing to stop you checking the current vs maximum number and upping the maximum if required. Spinning up a new thread comes with its own time penalty - whether it's worthwhile for you to take the hit depends on your circumstances.  I'm not speaking as someone with only theoretical knowledge here. I write and maintain high volume applications that make heavy use of multithreading and I generally don't find the thread pool to be the correct answer. Ah argument from authority - but always be on the look out for people who might be on the Windows kernel team. Neither of us were arguing with the fact that if you have some specific requirements then the .NET ThreadPool might not be the right thing. What we're objecting to is the trivialisation of the costs to the machine of creating a thread. The significant expense of creating a thread at the raison d'etre for the ThreadPool in the first place. I don't want my machines to be filled with code written by people who have been misinformed about the expense of creating a thread and don't for example know that it causes a method to be called in every single DLL which is attached to the process (some of which will be created by 3rd parties) and which may well hot-up a load of code which need not be in RAM at all and almost certainly didn't need to be in L1. The shape of the memory hierarchy in a modern machine means that 'distracting' a CPU is about the worst thing you can possibly do and everybody who cares about their craft should work hard to avoid it.  Threadpool threads are appropriate for tasks that meet both of the following criteria: The task will not have to spend any significant time waiting for something to happen Anything that's waiting for the task to finish will likely be waiting for many tasks to finish so its scheduling priority isn't apt to affect things much. Using a threadpool thread instead of creating a new one will save a significant but bounded amount of time. If that time is significant compared with the time it will take to perform a task a threadpool task is likely appropriate. The longer the time required to perform a task however the smaller the benefit of using the threadpool and the greater the likelihood of the task impeding threadpool efficiency.  @Eric @Derek I don't exactly agree with the scenario you use as an example. If you don't know exactly what's running on your machine and exactly how many total threads handles CPU time RAM etc that your app will use under a certain amount of load you are in trouble. Are you the only target customer for the programs you write? If not you can't be certain about most of that. You generally have no idea when you write a program whether it will execute effectively solo or if it will run on a webserver being hammered by a DDOS attack. You can't know how much CPU time you are going to have. Assuming your program's behavior changes based on input it's rare to even know exactly how much memory or CPU time your program will consume. Sure you should have a pretty good idea about how your program is going to behave but most programs are never analyzed to determine exactly how much memory how many handles etc. will be used because a full analysis is expensive. If you aren't writing real-time software the payoff isn't worth the effort. In general claiming to know exactly how your program will behave is far-fetched and claiming to know everything about the machine approaches ludicrous. And to be honest if you don't know exactly what method you should use: manual threads thread pool delegates and how to implement it to do just what your application needs you are in trouble. I don't fully disagree but I don't really see how that's relevant. This site is here specifically because programmers don't always have all the answers. If your application is complex enough to require throttling the number of threads that you use aren't you almost always going to want more control than what the framework gives you? No. If I need a thread pool I will use the one that's provided unless and until I find that it is not sufficient. I will not simply assume that the provided thread pool is insufficient for my needs without confirming that to be the case. I'm not speaking as someone with only theoretical knowledge here. I write and maintain high volume applications that make heavy use of multithreading and I generally don't find the thread pool to be the correct answer. Most of my professional experience has been with multithreading and multiprocessing programs. I have often needed to roll my own solution as well. That doesn't mean that the thread pool isn't useful or appropriate in many cases. The thread pool is built to handle worker threads. In cases where multiple worker threads are appropriate the provided thread pool should should generally be the first approach.  The only reason why I wouldn't use the ThreadPool for cheap multithreading is if I need to‰Û_ interract with the method running (e.g. to kill it) run code on a STA thread (this happened to me) keep the thread alive after my application has died (ThreadPool threads are background threads) in case I need to change the priority of the Thread. We can not change priority of threads in ThreadPool which is by default Normal. P.S.: The MSDN article ""The Managed Thread Pool"" contains a section titled ""When Not to Use Thread Pool Threads"" with a very similar but slightly more complete list of possible reasons for not using the thread pool. There are lots of reasons why you would need to skip the ThreadPool but if you don't know them then the ThreadPool should be good enough for you. Alternatively look at the new Parallel Extensions Framework which has some neat stuff in there that may suit your needs without having to use the ThreadPool. u said :- keep the thread alive after my application has died (ThreadPool threads are background threads) but how far i know background thread always end with main thread. so what do u say?? @Mou: I say that I have no idea what you're trying to say unfortunately.  Thread pools make sense whenever you have the concept of worker threads. Any time you can easily partition processing into smaller jobs each of which can be processed independently worker threads (and therefore a thread pool) make sense. Thread pools do not make sense when you need thread which perform entirely dissimilar and unrelated actions which cannot be considered ""jobs""; e.g. One thread for GUI event handling another for backend processing. Thread pools also don't make sense when processing forms a pipeline. Basically if you have threads which start process a job and quit a thread pool is probably the way to go. Otherwise the thread pool isn't really going to help. Can you explain the remark ""thread pools don't make sense when processing forms a pipeline""? Suppose I have work items that need to be compressed then encrypted and compression uses 10x the compute as encryption. Why not use a threadpool with a 10:1 ratio of compressor to encryptor threads? Thread pools are generally for when a program has independent discrete pieces of work to do. If there's communication between the worker threads (such as in a pipeline) then you don't really have a thread pool scenario.  When you're going to perform an operation that is going to take a long time or perhaps a continuous background thread. I guess you could always push the amount of threads available in the pool up but there would be little point in incurring the management costs of a thread that is never going to be given back to the pool.  @Eric I'm going to have to agree with Dean. Threads are expensive. You can't assume that your program is the only one running. When everyone is greedy with resources the problem multiplies. I prefer to create my threads manually and control them myself. It keeps the code very easy to understand. That's fine when it's appropriate. If you need a bunch of worker threads though all you've done is make your code more complicated. Now you have to write code to manage them. If you just used a thread pool you'd get all the thread management for free. And the thread pool provided by the language is very likely to be more robust more efficient and less buggy than whatever you roll for yourself. Thread t = new Thread(new ThreadStart(DoSomething)); t.Start(); t.Join(); I hope that you would normally have some additional code in between Start() and Join(). Otherwise the extra thread is useless and you're wasting resources for no reason. People are way too afraid of the resources used by threads. I've never seen creating and starting a thread to take more than a millisecond. There is no hard limit on the number of threads you can create. RAM usage is minimal. Once you have a few hundred threads CPU becomes an issue because of context switches so at that point you might want to get fancy with your design. A millisecond is a long time on modern hardware. That's 3 million cycles on a 3GHz machine. And again you aren't the only one creating threads. Your threads compete for the CPU along with every other program's threads. If you use not-quite-too-many threads and so does another program then together you've used too many threads. Seriously don't make life more complex than it needs to be. Don't use the thread pool unless you need something very specific that it offers. Indeed. Don't make life more complex. If your program needs multiple worker threads don't reinvent the wheel. Use the thread pool. That's why it's there. Would you roll your own string class? Some people rolls their own wrapper over an array of char's and use it like a string.. so it's possible... and it's sad too. I down voted this. This is isn't an answer; it's a reply to someone else's. Tis well enough an answer. But 22 upvotes at this moment? Its not *that* good. There isn't a huge votering being run out of Redmond is there? @Will it's a 4-year old comment. It's averaging less than half an upvote per month. Hardly an unbelievable level of votes. @hwiechers it's half answer half reply. SO didn't have comments when this was posted and I'm not willing to waste the time to go through all my old answers and convert them to comments. @DerekPark: And you shouldn't. I showed up here because of an NAA flag. Then out of a burning jealousy left the comment. Just jokes. @Will no worries. I knew you were joking about the votering (we could manage better than 22 votes in 4 years) but wasn't sure how serious you were about the ""It's not *that* good"" comment. :)",c# .net multithreading design design-decisions1995,A,"Most Efficient Way to Test Object Type I have values stored as strings in a DataTable where each value could really represent an int double or string (they were all converted to strings during an import process from an external data source). I need to test and see what type each value really is. What is more efficient for the application (or is there no practical difference)? Try to convert to int (and then double). If conversion works the return true. If an exception is thrown return false. Regular expressions designed to match the pattern of an int or double Some other method? I would say don't worry so much about such micro performance. It is much better to just get something to work and then make it as clear and concise and easy to read as possible. The worst thing you can do is sacrifice readability for an insignificant amount of performance. In the end the best way to deal with performance issues is to save them for when you have data that indicates there is an actual performance problem... otherwise you will spend a lot of time micro-optimizing and actually cause higher maintenance costs for later on. If you find this parsing situation is really the bottleneck in your application THEN is the time to try and figure out what the fastest way to solve the problem is. I think Jeff (and many others) have blogged about this sort of thing a lot.  I'd personally use int.tryparse then double.tryparse. Performance on those methods is quite fast. They both return a Boolean. If both fail then you have a string per how you defined your data.  Would use double.TryParse it has performance benefits.  You'll get different results for the different methods depending on whether you compile with optimisations on. You basically have a few options: object o; //checking with is o is int //check type o.GetType() != typeof( int ) //cast and catch exception try{ int j = (int) o; } catch {} //use the tryparse int.TryParse( Convert.ToString( o ) out j ) You can easily set up a console app that tries each of these 10000 times and returns durations for each (test when o is an int and when it's something else). The try-catch method is the quickest if the object does hold an int and by far the slowest if it doesn't (even slower than GetType). int.TryParse is pretty quick if you have a string but if you have an unknown object it's slower. Interestingly with .Net 3.5 and optimisations turned on the o is int check takes the same time as try-catch when o actually is an int. o is int is only slightly slower if o actually is something else. Annoyingly FxCop will throw up warnings if you do something like: if( o is int ) int j = (int) o; But I think that's a bug in FxCop - it doesn't know int is a value type and recommends you to use o as int instead. If your input is always a string int.TryParse is best otherwise the is operator is quickest. As you have a string I'd look at whether you need to know that it's an int rather than a double. If int.TryParse passes then so will double.TryParse so you could half the number of checks - return either double or string and floor the doubles when you expect an int.  The trouble you have is that there could be situations where the answer could be all three types. 3 could be an int a double or a string! It depends upon what you are trying to do and how important it is that they are a particular type. It might be best just to leave them as they are as long as you can or alternatively some up with a method to mark each one (if you have control of the source of the original string). The ultimate goal was to try to determine the most exclusive data type for the object. 3 would be an int. 3.5 would be a double. ""Three"" would be a string. I eventually put together a function that tried a bunch of object.TryParse calls until it could determine what was the ""best fit"" data type.",c# .net double int26903,A,"How can you require a constructor with no parameters for types implementing an interface? Is there a way? I need all types that implement a specific interface to have a parameterless constructor can it be done? I am developing the base code for other developers in my company to use in a specific project. There's a proccess which will create instances of types (in different threads) that perform certain tasks and I need those types to follow a specific contract (ergo the interface). The interface will be internal to the assembly If you have a suggestion for this scenario without interfaces I'll gladly take it into consideration... So you need a thing that can create instances of an unknown type that implements an interface. You've got basically three options: a factory object a Type object or a delegate. Here's the givens: public interface IInterface { void DoSomething(); } public class Foo : IInterface { public void DoSomething() { /* whatever */ } } Using Type is pretty ugly but makes sense in some scenarios: public IInterface CreateUsingType(Type thingThatCreates) { ConstructorInfo constructor = thingThatCreates.GetConstructor(Type.EmptyTypes); return (IInterface)constructor.Invoke(new object[0]); } public void Test() { IInterface thing = CreateUsingType(typeof(Foo)); } The biggest problem with it is that at compile time you have no guarantee that Foo actually has a default constructor. Also reflection is a bit slow if this happens to be performance critical code. The most common solution is to use a factory: public interface IFactory { IInterface Create(); } public class Factory<T> where T : IInterface new() { public IInterface Create() { return new T(); } } public IInterface CreateUsingFactory(IFactory factory) { return factory.Create(); } public void Test() { IInterface thing = CreateUsingFactory(new Factory<Foo>()); } In the above IFactory is what really matters. Factory is just a convenience class for classes that do provide a default constructor. This is the simplest and often best solution. The third currently-uncommon-but-likely-to-become-more-common solution is using a delegate: public IInterface CreateUsingDelegate(Func<IInterface> createCallback) { return createCallback(); } public void Test() { IInterface thing = CreateUsingDelegate(() => new Foo()); } The advantage here is that the code is short and simple can work with any method of construction and (with closures) lets you easily pass along additional data needed to construct the objects.  Not to be too blunt but you've misunderstood the purpose of interfaces. An interface means that several people can implement it in their own classes and then pass instances of those classes to other classes to be used. Creation creates an unnecessary strong coupling. It sounds like you really need some kind of registration system either to have people register instances of usable classes that implement the interface or of factories that can create said items upon request.  I would like to remind everyone that: Writing attributes in .NET is easy Writing static analysis tools in .NET that ensure conformance with company standards is easy Writing a tool to grab all concrete classes that implement a certain interface/have an attribute and verifying that it has a parameterless constructor takes about 5 mins of coding effort. You add it to your post-build step and now you have a framework for whatever other static analyses you need to perform. The language the compiler the IDE your brain - they're all tools. Use them!  You do not need a parameterless constructor for the Activator to instantiate your class. You can have a parameterized constructor and pass all the parameters from the Activator. Check out MSDN on this.  Juan Unfortunately there is no way to get around this in a strongly typed language. You won't be able to ensure at compile time that the classes will be able to be instantiated by your Activator-based code. (ed: removed an erroneous alternative solution) The reason is that unfortunately it's not possible to use interfaces abstract classes or virtual methods in combination with either constructors or static methods. The short reason is that the former contain no explicit type information and the latter require explicit type information. Constructors and static methods must have explicit (right there in the code) type information available at the time of the call. This is required because there is no instance of the class involved which can be queried by the runtime to obtain the underlying type which the runtime needs to determine which actual concrete method to call. The entire point of an interface abstract class or virtual method is to be able to make a function call without explicit type information and this is enabled by the fact that there is an instance being referenced which has ""hidden"" type information not directly available to the calling code. So these two mechanisms are quite simply mutually exclusive. They can't be used together because when you mix them you end up with no concrete type information at all anywhere which means the runtime has no idea where to find the function you're asking it to call.  You can use type parameter constraint interface ITest<T> where T: new() { //... } class Test: ITest<Test> { //... }  No you can't do that. Maybe for your situation a factory interface would be helpful? Something like: interface FooFactory { Foo createInstance(); } For every implementation of Foo you create an instance of FooFactory that knows how to create it.  Call a RegisterType method with the type and constrain it using generics. Then instead of walking assemblies to find ITest implementors just store them and create from there. void RegisterType<T>() where T:ITest new() { }  Juan Manuel said: that's one of the reasons I don't understand why it cannot be a part of the contract in the interface It's an indirect mechanism. The generic allows you to ""cheat"" and send type information along with the interface. The critical thing to remember here is that the constraint isn't on the interface that you are working with directly. It's not a constraint on the interface itself but on some other type that will ""ride along"" on the interface. This is the best explanation I can offer I'm afraid. By way of illustration of this fact I'll point out a hole that I have noticed in aku's code. It's possible to write a class that would compile fine but fail at runtime when you try to instantiate it: public class Something : ITest<String> { private Something() { } } Something derives from ITest<T> but implements no parameterless constructor. It will compile fine because String does implement a parameterless constructor. Again the constraint is on T and therefore String rather than ITest or Something. Since the constraint on T is satisfied this will compile. But it will fail at runtime. To prevent some instances of this problem you need to add another constraint to T as below: public interface ITest<T> where T : ITest<T> new() { } Note the new constraint: T : ITest<T>. This constraint specifies that what you pass into the argument parameter of ITest<T> must also derive from ITest<T>. Even so this will not prevent all cases of the hole. The code below will compile fine because A has a parameterless constructor. But since B's parameterless constructor is private instantiating B with your process will fail at runtime. public class A : ITest<A> { } public class B : ITest<A> { private B() { } }  I don't think so. You also can't use an abstract class for this.",c# .net constructor interface oop18533,A,"C#: What Else Do You Use Besides DataSet I've found myself increasingly unsatisfied with the DataSet/DataTable/DataRow paradigm in .Net mostly because it's often a couple of steps more complicated than what I really want to do. In cases where I'm binding to controls DataSets are fine. But in other cases there seems to be a fair amount of mental overhead. I've played a bit with SqlDataReader and that seems to be good for simple jaunts through a select but I feel like there may be some other models lurking in .Net that are useful to learn more about. I feel like all of the help I find on this just uses DataSet by default. Maybe that and DataReader really are the best options. I'm not looking for a best/worst breakdown just curious what my options are and what experiences you've had with them. Thanks! -Eric Sipple I have used typed and untyped DataSets DataViewManagers DataViews DataTables DataRows DataRowViews and just about anything you can do with the stack since it firsts came out in multiple enterprise projects. It took me awhile to get used to how allow of it worked. I have written custom components that leverage the stack as ADO.NETdid not quite give me what I really needed. One such component compares DataSets and then updates backend stores. I really know how all of these items work well and those that have seen what I have done are very impressed that I managed to get beyond there feel that it was only useful for demo use. I use ADO.NET binding in Winforms and I also use the code in console apps. I most recently have teamed with another developer to create a custom ORM that we used against a crazy datamodel that we were given from contractors that looked nothing like our normal data stores. I searched today for replacement to ADO.NET and I do not see anything that I should seriously try to learn to replace what I currently use.  DataSets are great for demos. I wouldn't know what to do with one if you made me use it. I use ObservableCollection Then again i'm in the client app space WPF and Silverlight. So passing a dataset or datatable through a service is ... gross. DataReaders are fast since they are a forward only stream of the result set.  I've been using the Data Transfer Objects pattern (originally from the Java world I believe) with a SqDataReader to populate collections of DTOs from the data layer for use in other layers of the application. The DTOs themselves are very lightweight and simple classes composed of properties with gets/sets. They can be easily serialized/deserialized and used for databinding making them pretty well suited to most of my development needs.  We've moved away from datasets and built our own ORM objects loosely based on CSLA. You can get the same job done with either a DataSet or LINQ or ORM but re-using it is (we've found) a lot easier. 'Less code make more happy'.  I NEVER use datasets. They are big heavyweight objects only usable (as someone pointed out here) for ""demoware"". There are lot's of great alternatives shown here. Yes there is a significant meaning. Serialize a dataset with even just a few rows to an XML file and take a look how big it is. Then make a simple Data Transfer Object (Jesse's response). Just define a simple class with members for each column - and then a List class. Serialize that to an XML file - and take a look at the difference. ""Heavyweight objects""? Does that term really have any meaning? If you're really serializing DataSets and then passing them over the wire or something and there's a genuine performance problem that's one thing. But I've seen ""DataSet bloat"" used as justification for making hideous string-literal-laden code that uses DataReaders everywhere in far too many shops I've worked in. Certainly replacing one bad implementation with another is a lousy solution - but I've yet to see a solution using dataset's that can't be implemented better as more effectively without one. Datasets are usefull for ""DEMOware"" and a holdover from pre-.NET ADO Now see that makes me think you haven't worked with ADO.NET DataSets much and perhaps just don't know much about them at all. ADO.NET DataSets are disconnected; they're containers for data. They enforce things like database relations and nullability which is why they have so many methods and properties that people refer to as ""bloat"". I can understand why people wouldn't prefer them as a matter of style but they're a solid alternative for those who don't mind a more database-oriented (rather than object-model-oriented) style.  I just build my business objects from scratch and almost never use the DataTable and especially not the DataSet anymore except to initially populate the business objects. The advantages to building your own are testability type safety and intellisense extensibility (try adding to a DataSet) and readability (unless you enjoy reading things like Convert.ToDecimal(dt.Rows[i][""blah""].ToString())). If I were smarter I'd also use an ORM and 3rd party DI framework but just haven't yet felt the need for those. I'm doing lots of smaller size projects or additions to larger projects.  I was fed up with DataSets in .Net 1.1 at least they optimised it so that it doesn't slow as exponentially for large sets any more. It was always a rather bloated model - I haven't seen many apps that use most of its features. SqlDataReader was good but I used to wrap it in an IEnumerable<T> where the T was some typed representation of my data row. Linq is a far better replacement in my opinion.  I've used typed DataSets for several projects. They model the database well enforce constraints on the client side and in general are a solid data access technology especially with the changes in .NET 2.0 with TableAdapters. Typed DataSets get a bad rap from people who like to use emotive words like ""bloated"" to describe them. I'll grant that I like using a good O/R mapper more than using DataSets; it just ""feels"" better to use objects and collections instead of typed DataTables DataRows etc. But what I've found is that if for whatever reason you can't or don't want to use an O/R mapper typed DataSets are a good solid choice that are easy enough to use and will get you 90% of the benefits of an O/R mapper. EDIT: Some here suggest that DataReaders are the ""fast"" alternative. But if you use Reflector to look at the internals of a DataAdapter (which DataTables are filled by) you'll see that it uses...a DataReader. Typed DataSets may have a larger memory footprint than other options but I've yet to see the application where this makes a tangible difference. Use the best tool for the job. Don't make your decision on the basis of emotive words like ""gross"" or ""bloated"" which have no factual basis. I'm not sure your comment is valid - a DataSet is populated via a DataAdaptor that uses a DataReader but when is the data available? If you have to wait until the read of all rows is completed of course it has to be slower. It depends on what you're doing with the data though. Maybe you're processing a large set of data row-by-row; maybe you're operating on the full set and can't do anything till you have it all anyway. Maybe you're getting the equivalent of one row and it doesn't matter which you use. *Always* eschewing DataSets is premature optimization. And if you need to edit and persist data DataSets are much easier to work with than DataReaders and temporary objects. To avoid them is to obfuscate your code for no reason.  I use them extensively but I don't make use of any of the ""advanced"" features that Microsoft was really pushing when the framework first came out. I'm basically just using them as Lists of Hashtables which I find perfectly useful. I have not seen good results when people have tried to make complex typed DataSets or tried to actually set up the foreign key relationships between tables with DataSets. Of course I am one of the weird ones that actually prefers a DataRow to an entity object instance.  Selecting a modern stable and actively supported ORM tool has to be probably the single biggest boost to productivity just about any project of moderate size and complexity can get. If you're concluding that you absolutely absolutely absolutely have to write your own DAL and ORM you're probably doing it wrong (or you're using the world's most obscure database). If you're doing raw datasets and rows and what not spend the day to try an ORM and you'll be amazed at how much more productive you can be w/o all the drudgery of mapping columns to fields or all the time filling Sql command objects and all the other hoop jumping we all once went through. I love me some Subsonic though for smaller scale projects along with demos/prototypes I find Linq to Sql pretty damn useful too. I hate EF with a passion though. :P  Since .NET 3.5 came out I've exclusively used LINQ. It's really that good; I don't see any reason to use any of those old crutches any more. As great as LINQ is though I think any ORM system would allow you to do away with that dreck. Do you mean LINQ To SQL (aka L2S)? Obviously since we're talking about database access. Though LINQ to Everything Else is just as good.  Pre linq I used DataReader to fill List of my own custom domain objects but post linq I have been using L2S to fill L2S entities or L2S to fill domain objects. Once I get a bit more time to investigate I suspect that Entity Framework objects will be my new favourite solution!  I'm a huge fan of SubSonic. A well-written batch/CMD file can generate an entire object model for your database in minutes; you can compile it into its own DLL and use it as needed. Wonderful model wonderful tool. The site makes it sound like an ASP.NET deal but generally speaking it works wonderfully just about anywhere if you're not trying to use its UI framework (which I'm moderately disappointed in) or its application-level auto-generation tools. For the record here is a version of the command I use to work with it (so that you don't have to fight it too hard initially): sonic.exe generate /server [servername] /db [dbname] /out [outputPathForCSfiles] /generatedNamespace [myNamespace] /useSPs true /removeUnderscores true That does it every time ... Then build the DLL off that directory -- this is part of an NAnt project fired off by CruiseControl.NET -- and away we go. I'm using that in WinForms ASP.NET even some command-line utils. This generates the fewest dependencies and the greatest ""portability"" (between related projects EG). Note The above is now well over a year old. While I still hold great fondness in my heart for SubSonic I have moved on to LINQ-to-SQL when I have the luxury of working in .NET 3.5. In .NET 2.0 I still use SubSonic. So my new official advice is platform version-dependent. In case of .NET 3+ go with the accepted answer. In case of .NET 2.0 go with SubSonic.",c# .net sql dataset14934,A,"Parameter Binding: What happens under the hood? .NET Java and other high level database API's in various language often provide techniques known as prepared statements and parameter binding as opposed to sending plain text commands to the Database server. What I would like to know is what happens when you execute a statement like this: SqlCommand cmd = new SqlCommand(""GetMemberByID""); cmd.CommandType = CommandType.StoredProcedure; SqlParameter param = new SqlParameter(""@ID"" memberID); para.DbType = DbType.Integer; cmd.Parameters.Add(param); I know this is a best practice. SQL injection attacks are minimized this way. But what exactly happens under the hood when you execute these statements? Is the end result still a SQL safe string? If not what is the end result? And is this enough to prevent SQL injection attacks? in layman terms: if a prepared statement is sent then the DB will use a plan if it is available it doesn't not have to recreate a plan every time this query is sent over but only the values of the params have changed. this is very similar to how procs work the additional benefit with procs is that you can give permission through procs only and not to the underlying tables at all  The MySQL manual page on prepared statements provides lots of information (which should apply to any other RDBMS): http://dev.mysql.com/doc/refman/5.0/en/c-api-prepared-statements.html Basically your statement is parsed and processed ahead of time and the parameters are sent separately instead of being handled along with the SQL code. This eliminates SQL-injection attacks because the SQL is parsed before the parameters are even set.  If you're using MS SQL load up the profiler and you'll see what SQL statements are generated when you use parameterised queries. Here's an example (I'm using Enterprise Libary 3.1 but the results are the same using SqlParameters directly) against SQL Server 2005: string sql = ""SELECT * FROM tblDomains WHERE DomainName = @DomName AND DomainID = @Did""; Database db = DatabaseFactory.CreateDatabase(); using(DbCommand cmd = db.GetSqlStringCommand(sql)) { db.AddInParameter(cmd ""DomName"" DbType.String ""xxxxx.net""); db.AddInParameter(cmd ""Did"" DbType.Int32 500204); DataSet ds = db.ExecuteDataSet(cmd); } This generates: exec sp[underscore]executesql N'SELECT * FROM tblDomains WHERE DomainName = @DomName AND DomainID = @Did' N'@DomName nvarchar(9) @Did int' @DomName=N'xxxxx.net' @Did=500204 You can also see here if quotation characters were passed as parameters they are escaped accordingly: db.AddInParameter(cmd ""DomName"" DbType.String ""'xxxxx.net""); exec sp[underscore]executesql N'SELECT * FROM tblDomains WHERE DomainName = @DomName AND DomainID = @Did' N'@DomName nvarchar(10) @Did int' @DomName=N'''xxxxx.net' @Did=500204",c# .net sql database api26522,A,".NET Multi Dimensional Array Printing Let's say I have a .NET Array of n number of dimensions. I would like to foreach through the elements and print out something like: [0 0 0] = 2 [0 0 1] = 32 And so on. I could write a loop using some the Rank and dimension functions to come up with the indices. Is there a built in function instead? Thanks for the answer here is what I wrote while I waited: public static string Format(Array array) { var builder = new StringBuilder(); builder.AppendLine(""Count: "" + array.Length); var counter = 0; var dimensions = new List<int>(); for (int i = 0; i < array.Rank; i++) { dimensions.Add(array.GetUpperBound(i) + 1); } foreach (var current in array) { var index = """"; var remainder = counter; foreach (var bound in dimensions) { index = remainder % bound + "" "" + index; remainder = remainder / bound; } index = index.Substring(0 index.Length - 2); builder.AppendLine("" ["" + index + ""] "" + current); counter++; } return builder.ToString(); }  Take a look at this: might helpful for you.",c# .net arrays22623,A,"Throwing Exceptions best practices What are the best practices to consider when catching exceptions and re-throwing them? I want to make sure that the Exception object's InnerException and stack trace are preserved. Is there a difference between the following code blocks in how they handle this? try { //some code } catch (Exception ex) { throw ex; } //...... try { //some code } catch { throw; } I would definitely use: try { //some code } catch { throw; } That will preserve your stack. -1: this code is equivalent to not having a try/catch block at all.  The way to preserve the stack trace is through the use of the throw; This is valid as well try { // something that boms here } catch (Exception ex) { throw; } throw ex; is basically like throwing an exception from that point so the stack trace would only go to where you are issuing the throw ex; statement Mike is also correct assuming the exception allows you to pass an exception (which is recommended). Karl Seguin has a great write up on exception handling in his foundations of programming e-book as well which is a great read. That exception handling writeup is wonderful. Thank you for sharing. I'm not so sure if that write-up is wonderful it suggests try { // ... } catch(Exception ex) { throw new Exception(ex.Message + ""other stuff""); } is good. The problem is that you're completely unable to handle that exception any further up the stack unless you catch all exceptions a big no-no (you sure you want to handle that OutOfMemoryException?)  You may also use: try { // Dangerous code } finally { // clean up or do nothing } And any exceptions thrown will bubble up to the next level that handles them.  When you throw ex you're essentially throwing a new exception and will miss out on the original stack trace information. throw is the preferred method.  A few people actually missed a very important point - 'throw' and 'throw ex' may do the same thing but they don't give you a crucial piece of imformation which is the line where the exception happened. Consider the following code: static void Main(string[] args) { try { TestMe(); } catch (Exception ex) { string ss = ex.ToString(); } } static void TestMe() { try { //here's some code that will generate an exception - line #17 } catch (Exception ex) { //throw new ApplicationException(ex.ToString()); throw ex; // line# 22 } } When you do either a 'throw' or 'throw ex' you get the stack trace but the line# is going to be #22 so you can't figure out which line exactly was throwing the exception (unless you have only 1 or few lines of code in the try block). To get the expected line #17 in your exception you'll have to throw a new exception with the original exception stack trace. +1 beat me to it.  You should always use ""throw;"" to rethrow the exceptions in .NET Refer this http://weblogs.asp.net/bhouse/archive/2004/11/30/272297.aspx Basically MSIL (CIL) has two instructions - ""throw"" and ""rethrow"": C#'s ""throw ex;"" gets compiled into MSIL's ""throw"" C#'s ""throw;"" - into MSIL ""rethrow""! Basically I can see the reason why ""throw ex"" overrides the stack trace.  Acctually there are some situations which the throw statment will not preserve the StackTrace information. For example in the code below: try { int i = 0; int j = 12 / i; // Line 47 int k = j + 1; } catch { // do something // ... throw; // Line 54 } The StackTrace will indicate that line 54 raised the exception although it was raised at line 47. Unhandled Exception: System.DivideByZeroException: Attempted to divide by zero. at Program.WithThrowIncomplete() in Program.cs:line 54 at Program.Main(String[] args) in Program.cs:line 106 In situations like the one described above there are two options to preseve the original StackTrace: Calling the Exception.InternalPreserveStackTrace As it is a private method it has to be invoked by using reflection: private static void PreserveStackTrace(Exception exception) { MethodInfo preserveStackTrace = typeof(Exception).GetMethod(""InternalPreserveStackTrace"" BindingFlags.Instance | BindingFlags.NonPublic); preserveStackTrace.Invoke(exception null); } I has a disadvantage of relying on a private method to preserve the StackTrace information. It can be changed in future versions of .NET Framework. The code example above and proposed solution below was extracted from Fabrice MARGUERIE weblog. Calling Exception.SetObjectData The technique below was suggested by Anton Tykhyy as answer to In C# how can I rethrow InnerException without losing stack trace question. static void PreserveStackTrace (Exception e) { var ctx = new StreamingContext (StreamingContextStates.CrossAppDomain) ; var mgr = new ObjectManager (null ctx) ; var si = new SerializationInfo (e.GetType () new FormatterConverter ()) ; e.GetObjectData (si ctx) ; mgr.RegisterObject (e 1 si) ; // prepare for SetObjectData mgr.DoFixups () ; // ObjectManager calls SetObjectData // voila e is unmodified save for _remoteStackTraceString } Although it has the advantage of relying in public methods only it also depends on the following exception constructor (which some exceptions developed by 3rd parties do not implement): protected Exception( SerializationInfo info StreamingContext context ) In my situation I had to choose the first approach because the exceptions raised by a 3rd-party library I was using didn't implement this constructor. You can catch the exception and publish this exception anywhere you want to. Then throw a new one explaining what happened to the user. This way you can see what happened at the current time the exception was caught the user can careless what the actual exception was.  FYI I just tested this and the stack trace reported by 'throw;' is not an entirely correct stack trace. Example:  private void foo() { try { bar(3); bar(2); bar(1); bar(0); } catch(DivideByZeroException) { //log message and rethrow... throw; } } private void bar(int b) { int a = 1; int c = a/b; // Generate divide by zero exception. } The stack trace points to the origin of the exception correctly (reported line number) but the line number reported for foo() is the line of the throw; statement hence you cannot tell which of the calls to bar() caused the exception. Which is why it's best not to try to catch exceptions unless you plan to do something with them  The rule of thumb is to avoid Catching and Throwing the basic Exception object. This forces you to be a little smarter about exceptions; in other words you should have an explicit catch for a SqlException so that your handling code doesn't do something wrong with a NullReferenceException. In the real world though catching and logging the base exception is also a good practice but don't forget to walk the whole thing to get any InnerExceptions it might have. I think it's best to deal with unhandled exceptions for logging purposes by using the AppDomain.CurrentDomain.UnhandledException and Application.ThreadException exceptions. Using big try { ... } catch(Exception ex) { ... } blocks everywhere means a lot of duplication. Depends whether you want to log handled exceptions in which case (at least minimal) duplication might be inevitable. Plus using those events means you *do* log all unhandled exceptions whereas if you use big ol' try { ... } catch(Exception ex) { ... } blocks you might miss some.  If you throw a new exception with the initial exception you will preserve the initial stack trace too.. try{ } catch(Exception ex){ throw new MoreDescriptiveException(""here is what was happening"" ex); }",c# .net exception-handling13353,A,Override tab behavior in WinForms I have a UserControl that consists of three TextBoxes. On a form I can have one or more or my UserControl. I want to implement my own tab behavior so if the user presses Tab in the second TextBox I should only move to the third TextBox if the the second TextBox has anything entered. If nothing is entered in the second TextBox the next control of the form should get focus as per the normal tab behavior. If the user hasn't entered anything in the first or second TextBox and the presses tab there is this special case where a control on the form should be skipped. By using the ProcessDialogKey I have managed to get it work kind of ok but I still have one problem. My question is if there is a way to detect how a WinForms control got focus since I would also like to know if the my UserControl got focus from a Tab or Shift-Tab and then do my weird stuff but if the user clicks the control I don't want to do anything special. I agree with DannySmurf. Messing with the tab order might give you hell later on if the requirements for the application change. Another thing that you could do is to implement some kind of wizard for the user to go through.  As a general rule I would say overriding the standard behavior of the TAB key would be a bad idea. Maybe you can do something like disabling the 3rd text box until a valid entry is made in the 2nd text box. Now having said this I've also broken this rule at the request of the customer. We made the enter key function like the tab key where the enter key would save the value in a text field and advance the cursor to the next field.  I don't think there's a built-in way that you could do it. All of the WinForms focus events (GotFocusLostFocusEnterLeave) are called with empty EventArgs parameters which will not give you any additional information. Personally I would disable the third textbox as Rob Thomas said. If you're determined to do this though it wouldn't be difficult to set up a manual (read: hackish) solution. Once the tab key is pressed (if the focus is on the second textbox) set a variable inside your form. If the next object focused is then the third textbox then you know exactly how it happened.  The reason for this odd tab behavior is all about speed in the input process. It was really good to get some input I hadn't thought about disabling a textbox but that could actually work. But using the Enter key to accept the input hadn't even crossed my mind. That will work so much better. The user can enter the numbers and then press enter to accept the input and the next possible textbox will be the active one. It's like having the cake and eating it too The speed factor is there since when using the enter key no unnecessary tabing must be done to get to the correct field and using the enter key next to the numeric keyboard makes it really smooth. Thanks for the input!  Better than disabling controls try monkeying around with TabStop - if this is false the control will be simply skipped when tabbing. I'd also suggest that the Changed event of the TextBox is the place to be updating TabStop on the other controls. I've done something similar to this with a login control where users could enter either a username or an email address (in separate fields) plus their password and tabStop is what I used to get the job done.,c# .net winforms20156,A,"Is there an easy way to create ordinals in C#? Is there an easy way in C# to create Ordinals for a number? For example: 1 returns 1st 2 returns 2nd 3 returns 3rd ...etc Can this be done through String.Format() or are there any functions available to do this? Another alternative that I used based on all the other suggestions but requires no special casing:  public static string DateSuffix(int day) { Math.DivRem(day 10 out day); switch (day) { case 1: return ""st""; case 2: return ""nd""; case 3: return ""rd""; default: return ""th""; } } Fails for `11`.  My version of Jesse's version of Stu's and samjudson's versions :) Included unit test to show that the accepted answer is incorrect when number < 1  /// <summary> /// Get the ordinal value of positive integers. /// </summary> /// <remarks> /// Only works for english-based cultures. /// Code from: http://stackoverflow.com/questions/20156/is-there-a-quick-way-to-create-ordinals-in-c/31066#31066 /// With help: http://www.wisegeek.com/what-is-an-ordinal-number.htm /// </remarks> /// <param name=""number"">The number.</param> /// <returns>Ordinal value of positive integers or <see cref=""int.ToString""/> if less than 1.</returns> public static string Ordinal(this int number) { const string TH = ""th""; string s = number.ToString(); // Negative and zero have no ordinal representation if (number < 1) { return s; } number %= 100; if ((number >= 11) && (number <= 13)) { return s + TH; } switch (number % 10) { case 1: return s + ""st""; case 2: return s + ""nd""; case 3: return s + ""rd""; default: return s + TH; } } [Test] public void Ordinal_ReturnsExpectedResults() { Assert.AreEqual(""-1"" (1-2).Ordinal()); Assert.AreEqual(""0"" 0.Ordinal()); Assert.AreEqual(""1st"" 1.Ordinal()); Assert.AreEqual(""2nd"" 2.Ordinal()); Assert.AreEqual(""3rd"" 3.Ordinal()); Assert.AreEqual(""4th"" 4.Ordinal()); Assert.AreEqual(""5th"" 5.Ordinal()); Assert.AreEqual(""6th"" 6.Ordinal()); Assert.AreEqual(""7th"" 7.Ordinal()); Assert.AreEqual(""8th"" 8.Ordinal()); Assert.AreEqual(""9th"" 9.Ordinal()); Assert.AreEqual(""10th"" 10.Ordinal()); Assert.AreEqual(""11th"" 11.Ordinal()); Assert.AreEqual(""12th"" 12.Ordinal()); Assert.AreEqual(""13th"" 13.Ordinal()); Assert.AreEqual(""14th"" 14.Ordinal()); Assert.AreEqual(""20th"" 20.Ordinal()); Assert.AreEqual(""21st"" 21.Ordinal()); Assert.AreEqual(""22nd"" 22.Ordinal()); Assert.AreEqual(""23rd"" 23.Ordinal()); Assert.AreEqual(""24th"" 24.Ordinal()); Assert.AreEqual(""100th"" 100.Ordinal()); Assert.AreEqual(""101st"" 101.Ordinal()); Assert.AreEqual(""102nd"" 102.Ordinal()); Assert.AreEqual(""103rd"" 103.Ordinal()); Assert.AreEqual(""104th"" 104.Ordinal()); Assert.AreEqual(""110th"" 110.Ordinal()); Assert.AreEqual(""111th"" 111.Ordinal()); Assert.AreEqual(""112th"" 112.Ordinal()); Assert.AreEqual(""113th"" 113.Ordinal()); Assert.AreEqual(""114th"" 114.Ordinal()); Assert.AreEqual(""120th"" 120.Ordinal()); Assert.AreEqual(""121st"" 121.Ordinal()); Assert.AreEqual(""122nd"" 122.Ordinal()); Assert.AreEqual(""123rd"" 123.Ordinal()); Assert.AreEqual(""124th"" 124.Ordinal()); }  This page gives you a complete listing of all custom numerical formatting rules: http://msdn.microsoft.com/en-us/library/0c899ak8.aspx As you can see there is nothing in there about ordinals so it can't be done using String.Format. However its not really that hard to write a function to do it. public static string AddOrdinal(int num) { if( num <= 0 ) return num.ToString(); switch(num % 100) { case 11: case 12: case 13: return num + ""th""; } switch(num % 10) { case 1: return num + ""st""; case 2: return num + ""nd""; case 3: return num + ""rd""; default: return num + ""th""; } } Update: Technically Ordinals don't exist for <= 0 so I've updated the code above. Also removed the redundant ToString() methods. Also note this is not internationalised. I've no idea what ordinals look like in other languages. Assert.AreEqual(""0"" AddOrdinal(0)); See http://www.wisegeek.com/what-is-an-ordinal-number.htm Using an extention method (or whatever it's called -- see @Stu's answer) would work great here. @Si Adding that condition would be very easy if it is required. If I made it an extension method I would call it ""ToOrdinalString"". Forgot about '11th 12th 13th'... should be an interview question. :-) Nice answer. As a note the .ToString() calls are redundant removing these improves readability (slightly)  I rather liked elements from both Stu's and samjudson's solutions and worked them together into what I think is a usable combo:  public static string Ordinal(this int number) { const string TH = ""th""; var s = number.ToString(); number %= 100; if ((number >= 11) && (number <= 13)) { return s + TH; } switch (number % 10) { case 1: return s + ""st""; case 2: return s + ""nd""; case 3: return s + ""rd""; default: return s + TH; } } what's the rationale behind using a constant for ""th""? because it's used twice in the code. Just utilizing the age-old wisdom that you shouldn't repeat yourself :) In this case the .NET runtime should only create one copy of the string while with two ""th""s in the code there'd be two strings created and referenced in memory. and also if the value of TH ever changes you'll be set. @Jesse - You get my +1 but I don't believe .NET handles strings this way see http://www.yoda.arachsys.com/csharp/strings.html#interning my reading of that is each reference to the ""th"" literal would reference the same bit of memory. But I agree about DRY :) @Si - Rereading my last response I'm reversing what I said and agree with your assessment. .NET is pretty darn smart when it comes to string handling and you have to go out of your way to make it work badly. Removing duplication like this just hinders readability I think hence the confusion ""Why the TH?"". I don't think DRY should be interpreted as 'remove all duplication whatever the cost'.  You'll have to roll your own. From the top of my head: public static string Ordinal(this int number) { var work = number.ToString(); if ((number % 100) == 11 || (number % 100) == 12 || (number % 100) == 13) return work + ""th""; switch (number % 10) { case 1: work += ""st""; break; case 2: work += ""nd""; break; case 3: work += ""rd""; break; default: work += ""th""; break; } return work; } You can then do Console.WriteLine(432.Ordinal()); Edited for 11/12/13 exceptions. I DID say from the top of my head :-) Edited for 1011 -- others have fixed this already just want to make sure others don't grab this incorrect version. This function doesn't work: Ordinal(1011) -> 1011st  Remember internationalisation! The solutions here only work for English. Things get a lot more complex if you need to support other languages. For example in Spanish ""1st"" would be written as ""1.o"" ""1.a"" ""1.os"" or ""1.as"" depending on whether the thing you're counting is masculine feminine or plural! So if your software needs to support different languages try to avoid ordinals. Excellent point and very easy to forget. How can 1st be plural? @ Andomar: ""The first 2 readers"" => in Italian (and Spanish too I suppose) ""first"" is plural here. So you have singular masculine singulare feminine plural masculine plural feminine; maybe some language has also a neutral case (distinguing things from men/animals) That said you don't have to avoid ordinals: include them in localization once you know all the case you could face or (make your customer) accept some limitations. This explains why the .NET team steered clear of adding it to the DateTime formatters I still wish they had done it.  public static string OrdinalSuffix(int ordinal) { //Because negatives won't work with modular division as expected: var abs = Math.Abs(ordinal); var lastdigit = abs % 10; return //Catch 60% of cases (to infinity) in the first conditional: lastdigit > 3 || lastdigit == 0 || (abs % 100) - lastdigit == 10 ? ""th"" : lastdigit == 1 ? ""st"" : lastdigit == 2 ? ""nd"" : ""rd""; }  While I haven't benchmarked this yet you should be able to get better performance by avoiding all the conditional case statements. This is java but a port to C# is trivial: public class NumberUtil { final static String[] ORDINAL_SUFFIXES = { ""th"" ""st"" ""nd"" ""rd"" ""th"" ""th"" ""th"" ""th"" ""th"" ""th"" }; public static String ordinalSuffix(int value) { int n = Math.abs(value); int lastTwoDigits = n % 100; int lastDigit = n % 10; int index = (lastTwoDigits >= 11 && lastTwoDigits <= 13) ? 0 : lastDigit; return ORDINAL_SUFFIXES[index]; } public static String toOrdinal(int n) { return new StringBuffer().append(n).append(ordinalSuffix(n)).toString(); } } Note the reduction of conditionals and the use of the array lookup should speed up performance if generating a lot of ordinals in a tight loop. However I also concede that this isn't as readable as the case statement solution.  Similar to Ryan's solution but even more basic I just use a plain array and use the day to look up the correct ordinal: private string[] ordinals = new string[] {""""""st""""nd""""rd""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""th""""st""""nd""""rd""""th""""th""""th""""th""""th""""th""""th""""st"" }; DateTime D = DateTime.Now; String date = ""Today's day is: ""+ D.Day.ToString() + ordinals[D.Day]; I have not had the need but I would assume you could use a multidimensional array if you wanted to have multiple language support. From what I can remember from my Uni days this method requires minimal effort from the server.",c# .net ordinals9,A,"How do I calculate someone's age in C#? Given a DateTime representing a person's birthday how do I calculate their age? Do we need to account in our code for cases where the person in question have travelled large distances near the speed of light? what all of the answers so far have missed is that it depends where the person was born and where they are right now. @Yaur: Just convert the time of now + birth into GMT/UTC age is only a relative value hence timezones are irrelevant. For determining the user's current timezone you can use GeoLocating. Why not consider [Julian Date][1]? [1]: http://stackoverflow.com/questions/7103064/java-calculate-the-number-of-days-between-two-dates/14278129#14278129 Pretty crazy how a post that doesn't even follow site guidelines gets 776 votes.. I want to add Hebrew calendar calculations (or other System.Globalization calendar can be used in the same way) using rewrited functions from this thread:  Public Shared Function CalculateAge(BirthDate As DateTime) As Integer Dim HebCal As New System.Globalization.HebrewCalendar () Dim now = DateTime.Now() Dim iAge = HebCal.GetYear(now) - HebCal.GetYear(BirthDate) Dim iNowMonth = HebCal.GetMonth(now) iBirthMonth = HebCal.GetMonth(BirthDate) If iNowMonth < iBirthMonth Or (iNowMonth = iBirthMonth AndAlso HebCal.GetDayOfMonth(now) < HebCal.GetDayOfMonth(BirthDate)) Then iAge -= 1 Return iAge End Function  Do we need to consider people who is smaller than 1 year? as Chinese culture we describe small babies' age as 2 months or 4 weeks. Below is my implementation it is not as simple as what I imagined especially to deal with date like 2/28.  public static string HowOld(DateTime birthday DateTime now) { if (now < birthday) throw new ArgumentOutOfRangeException(""birthday must be less than now.""); TimeSpan diff = now - birthday; int diffDays = (int)diff.TotalDays; if (diffDays > 7)//year month and week { int age = now.Year - birthday.Year; if (birthday > now.AddYears(-age)) age--; if (age > 0) { return age + (age > 1 ? "" years"" : "" year""); } else {// month and week DateTime d = birthday; int diffMonth = 1; while (d.AddMonths(diffMonth) <= now) { diffMonth++; } age = diffMonth-1; if (age == 1 && d.Day > now.Day) age--; if (age > 0) { return age + (age > 1 ? "" months"" : "" month""); } else { age = diffDays / 7; return age + (age > 1 ? "" weeks"" : "" week""); } } } else if (diffDays > 0) { int age = diffDays; return age + (age > 1 ? "" days"" : "" day""); } else { int age = diffDays; return ""just born""; } } This implementation has passed below test cases.  [TestMethod] public void TestAge() { string age = HowOld( new DateTime(2011 1 1) new DateTime(2012 11 30)); Assert.AreEqual(""1 year"" age); age = HowOld( new DateTime(2011 11 30) new DateTime(2012 11 30)); Assert.AreEqual(""1 year"" age); age = HowOld( new DateTime(2001 1 1) new DateTime(2012 11 30)); Assert.AreEqual(""11 years"" age); age = HowOld( new DateTime(2012 1 1) new DateTime(2012 11 30)); Assert.AreEqual(""10 months"" age); age = HowOld( new DateTime(2011 12 1) new DateTime(2012 11 30)); Assert.AreEqual(""11 months"" age); age = HowOld( new DateTime(2012 10 1) new DateTime(2012 11 30)); Assert.AreEqual(""1 month"" age); age = HowOld( new DateTime(2008 2 28) new DateTime(2009 2 28)); Assert.AreEqual(""1 year"" age); age = HowOld( new DateTime(2008 3 28) new DateTime(2009 2 28)); Assert.AreEqual(""11 months"" age); age = HowOld( new DateTime(2008 3 28) new DateTime(2009 3 28)); Assert.AreEqual(""1 year"" age); age = HowOld( new DateTime(2009 1 28) new DateTime(2009 2 28)); Assert.AreEqual(""1 month"" age); age = HowOld( new DateTime(2009 2 1) new DateTime(2009 3 1)); Assert.AreEqual(""1 month"" age); // NOTE. // new DateTime(2008 1 31).AddMonths(1) == new DateTime(2009 2 28); // new DateTime(2008 1 28).AddMonths(1) == new DateTime(2009 2 28); age = HowOld( new DateTime(2009 1 31) new DateTime(2009 2 28)); Assert.AreEqual(""4 weeks"" age); age = HowOld( new DateTime(2009 2 1) new DateTime(2009 2 28)); Assert.AreEqual(""3 weeks"" age); age = HowOld( new DateTime(2009 2 1) new DateTime(2009 3 1)); Assert.AreEqual(""1 month"" age); age = HowOld( new DateTime(2012 11 5) new DateTime(2012 11 30)); Assert.AreEqual(""3 weeks"" age); age = HowOld( new DateTime(2012 11 1) new DateTime(2012 11 30)); Assert.AreEqual(""4 weeks"" age); age = HowOld( new DateTime(2012 11 20) new DateTime(2012 11 30)); Assert.AreEqual(""1 week"" age); age = HowOld( new DateTime(2012 11 25) new DateTime(2012 11 30)); Assert.AreEqual(""5 days"" age); age = HowOld( new DateTime(2012 11 29) new DateTime(2012 11 30)); Assert.AreEqual(""1 day"" age); age = HowOld( new DateTime(2012 11 30) new DateTime(2012 11 30)); Assert.AreEqual(""just born"" age); age = HowOld( new DateTime(2000 2 29) new DateTime(2009 2 28)); Assert.AreEqual(""8 years"" age); age = HowOld( new DateTime(2000 2 29) new DateTime(2009 3 1)); Assert.AreEqual(""9 years"" age); Exception e = null; try { age = HowOld( new DateTime(2012 12 1) new DateTime(2012 11 30)); } catch (ArgumentOutOfRangeException ex) { e = ex; } Assert.IsTrue(e != null); } Hope it's helpful.  A one Linear Answer  DateTime dateOfBirth = Convert.ToDateTime(""01/16/1990""); var age = ((DateTime.Now - dateOfBirth).Days) / 365;  I use this: public static class DateTimeExtensions { public static int Age(this DateTime birthDate) { return Age(birthDate DateTime.Now); } public static int Age(this DateTime birthDate DateTime offsetDate) { int result=0; result = offsetDate.Year - birthDate.Year; if (offsetDate.DayOfYear < birthDate.DayOfYear) result--; return result; } }  2 Main problems to solve are: 1. Calculate Exact age - in years months days etc. 2. Calculate Generally perceived age - people usually do not care how old they exactly are they just care when their birthday in the current year is. Solution for 1 is obvious: DateTime birth = DateTime.Parse(""1.1.2000""); DateTime today = DateTime.Today; //we usually don't care about birth time TimeSpan age = today - birth; //.NET FCL should guarantee this as precise double ageInDays = age.TotalDays; //total number of days ... also precise double daysInYear = 365.2425; //statistical value for 400 years double ageInYears = ageInDays / daysInYear; //can be shifted ... not so precise Solution for 2 is the one which is not so precise in determing total age but is perceived as precise by people. People also usually use it when they calculate their age ""manually"": DateTime birth = DateTime.Parse(""1.1.2000""); DateTime today = DateTime.Today; int age = today.Year - birth.Year; //people perceive their age in years if ( today.Month < birth.Month || ((today.Month == birth.Month) && (today.Day < birth.Day)) ) { age--; //birthday in current year not yet reached we are 1 year younger ;) //+ no birthday for 29.2. guys ... sorry just wrong date for birth } Notes to 2.: This is my preferred solution We cannot use DateTime.DayOfYear or TimeSpans as they shift number of days in leap years I have put there little more lines for readability Just one more note ... I would create 2 static overloaded methods for it one for universal usage second for usage-friendliness: public static int GetAge(DateTime bithDay DateTime today) { //chosen solution method body } public static int GetAge(DateTime birthDay) { return GetAge(birthDay DateTime.Now); }  Keeping it simple (and possibly stupid:)). DateTime birth = new DateTime(1975 09 27 01 00 00 00); TimeSpan ts = DateTime.Now - birth; Console.WriteLine(""You are approximately "" + ts.TotalSeconds.ToString() + "" seconds old.""); TimeSpan was my first choice but found that it doesn't offer a TotalYears property. You could try (ts.TotalDays / 365) - but it doesn't account for leap years etc.  How come the MSDN help did not tell you that? It looks so obvious: System.DateTime birthTime = AskTheUser(myUser); // :-) System.DateTime now = System.DateTime.Now; System.TimeSpan age = now - birthTime; //as simple as that double ageInDays = age.TotalDays; // will you convert to whatever you want yourself?  How about this solution? static string CalcAge(DateTime birthDay) { DateTime currentDate = DateTime.Now; int approximateAge = currentDate.Year - birthDay.Year; int daysToNextBirthDay = (birthDay.Month * 30 + birthDay.Day) - (currentDate.Month * 30 + currentDate.Day) ; if (approximateAge == 0 || approximateAge == 1) { int month = Math.Abs(daysToNextBirthDay / 30); int days = Math.Abs(daysToNextBirthDay % 30); if (month == 0) return ""Your age is: "" + daysToNextBirthDay + "" days""; return ""Your age is: "" + month + "" months and "" + days + "" days""; ; } if (daysToNextBirthDay > 0) return ""Your age is: "" + --approximateAge + "" Years""; return ""Your age is: "" + approximateAge + "" Years""; ; }  private int GetAge(int _year int _month int _day { DateTime yourBirthDate= new DateTime(_year _month _day); DateTime todaysDateTime = DateTime.Today; int noOfYears = todaysDateTime.Year - yourBirthDate.Year; if (DateTime.Now.Month < yourBirthDate.Month || (DateTime.Now.Month == yourBirthDate.Month && DateTime.Now.Day < yourBirthDate.Day)) { noOfYears--; } return noOfYears; }  I think the TimeSpan has all that we need in it without having to resort to 365.25 (or any other approximation). Expanding on Aug's example: DateTime myBD = new DateTime(1980 10 10); TimeSpan difference = DateTime.Now.Subtract(myBD); textBox1.Text = difference.Years + "" years "" + difference.Months + "" Months "" + difference.Days + "" days""; Nope. TimeSpan as Days but no Months or Years  Here's yet another answer: public static int AgeInYears(DateTime birthday DateTime today) { return ((today.Year - birthday.Year) * 372 + (today.Month - birthday.Month) * 31 + (today.Day - birthday.Day)) / 372; } This has been extensively unit-tested. It does look a bit ""magic"". The number 372 is the number of days there would be in a year if every month had 31 days. The explanation of why it works (lifted from here) is: Let's set Yn = DateTime.Now.Year Yb = birthday.Year Mn = DateTime.Now.Month Mb = birthday.Month Dn = DateTime.Now.Day Db = birthday.Day age = Yn - Yb + (31*(Mn - Mb) + (Dn - Db)) / 372 We know that what we need is either Yn-Yb if the date has already been reached Yn-Yb-1 if it has not. a) If Mn<Mb we have -341 <= 31*(Mn-Mb) <= -31 and -30 <= Dn-Db <= 30 -371 <= 31*(Mn - Mb) + (Dn - Db) <= -1 With integer division (31*(Mn - Mb) + (Dn - Db)) / 372 = -1 b) If Mn=Mb and Dn<Db we have 31*(Mn - Mb) = 0 and -30 <= Dn-Db <= -1 With integer division again (31*(Mn - Mb) + (Dn - Db)) / 372 = -1 c) If Mn>Mb we have 31 <= 31*(Mn-Mb) <= 341 and -30 <= Dn-Db <= 30 1 <= 31*(Mn - Mb) + (Dn - Db) <= 371 With integer division (31*(Mn - Mb) + (Dn - Db)) / 372 = 0 d) If Mn=Mb and Dn>Db we have 31*(Mn - Mb) = 0 and 1 <= Dn-Db <= 30 With integer division again (31*(Mn - Mb) + (Dn - Db)) / 372 = 0 e) If Mn=Mb and Dn=Db we have 31*(Mn - Mb) + Dn-Db = 0 and therefore (31*(Mn - Mb) + (Dn - Db)) / 372 = 0  This gives ""more detail"" to this question. Maybe this is what you're looking for DateTime birth = new DateTime(1974 8 29); DateTime today = DateTime.Now; TimeSpan span = today - birth; DateTime age = DateTime.MinValue + span; // Make adjustment due to MinValue equalling 1/1/1 int years = age.Year - 1; int months = age.Month - 1; int days = age.Day - 1; // Print out not only how many years old they are but give months and days as well Console.Write(""{0} years {1} months {2} days"" years months days); This does not work all the time. Adding a Span to the DateTime.MinValue could work boes this does not account for leap years etc. If you add the Years months and days to Age using the AddYears() AddMonths and AddDays() function it will not always return the Datetime.Now date. Consider the following TWO senarios. 1st DateTime.Now is 1/1/2001 and a child is born on 1/1/2000. 2000 is a leap year and the result will be 1years 0 months and 1 days. In the second senarion DateTime.Now is 1/1/2002 and the child is born on 1/1/2001. In this case the result will be 1 years 0 months and 0 days. That will happen because you are adding the timespan on a non-leap year. If DateTime.MinValue was a leap year then the results would be 1 year at the first and 0 years 11 months and 30 days. (Try it in your code). timespan itself automatically takes into account leap years between 2 dates so I'm not sure what your getting on about. I have asked on microsoft forums and microsoft has confirmed it takes into account leap years between 2 dates.  The simple answer to this is to apply AddYears as shown below because this is the only native method to add years to the 29th of Feb. of leap years and obtain the correct result of the 28th of Feb. for common years. Some feel that 1th of Mar. is the birthday of leaplings but neither .Net nor any official rule supports this nor does common logic explain why some born in February should have 75% of their birthdays in another month. Further an Age method lends itself to be added as an extension to DateTime. By this you can obtain the age in the simplest possible way: List item int age = birthDate.Age(); public static class DateTimeExtensions { /// <summary> /// Calculates the age in years of the current System.DateTime object today. /// </summary> /// <param name=""birthDate"">The date of birth</param> /// <returns>Age in years today. 0 is returned for a future date of birth.</returns> public static int Age(this DateTime birthDate) { return Age(birthDate DateTime.Today); } /// <summary> /// Calculates the age in years of the current System.DateTime object on a later date. /// </summary> /// <param name=""birthDate"">The date of birth</param> /// <param name=""laterDate"">The date on which to calculate the age.</param> /// <returns>Age in years on a later day. 0 is returned as minimum.</returns> public static int Age(this DateTime birthDate DateTime laterDate) { int age; age = laterDate.Year - birthDate.Year; if (age > 0) { age -= Convert.ToInt32(laterDate.Date < birthDate.Date.AddYears(age)); } else { age = 0; } return age; } } } Now run this test: class Program { static void Main(string[] args) { RunTest(); } private static void RunTest() { DateTime birthDate = new DateTime(2000 2 28); DateTime laterDate = new DateTime(2011 2 27); string iso = ""yyyy-MM-dd""; for (int i = 0; i < 3; i++) { for (int j = 0; j < 3; j++) { Console.WriteLine(""Birth date: "" + birthDate.AddDays(i).ToString(iso) + "" Later date: "" + laterDate.AddDays(j).ToString(iso) + "" Age: "" + birthDate.AddDays(i).Age(laterDate.AddDays(j)).ToString()); } } Console.ReadKey(); } } The critical date example is this: Birth date: 2000-02-29 Later date: 2011-02-28 Age: 11 Output: { Birth date: 2000-02-28 Later date: 2011-02-27 Age: 10 Birth date: 2000-02-28 Later date: 2011-02-28 Age: 11 Birth date: 2000-02-28 Later date: 2011-03-01 Age: 11 Birth date: 2000-02-29 Later date: 2011-02-27 Age: 10 Birth date: 2000-02-29 Later date: 2011-02-28 Age: 11 Birth date: 2000-02-29 Later date: 2011-03-01 Age: 11 Birth date: 2000-03-01 Later date: 2011-02-27 Age: 10 Birth date: 2000-03-01 Later date: 2011-02-28 Age: 10 Birth date: 2000-03-01 Later date: 2011-03-01 Age: 11 } And for the later date 2012-02-28: { Birth date: 2000-02-28 Later date: 2012-02-28 Age: 12 Birth date: 2000-02-28 Later date: 2012-02-29 Age: 12 Birth date: 2000-02-28 Later date: 2012-03-01 Age: 12 Birth date: 2000-02-29 Later date: 2012-02-28 Age: 11 Birth date: 2000-02-29 Later date: 2012-02-29 Age: 12 Birth date: 2000-02-29 Later date: 2012-03-01 Age: 12 Birth date: 2000-03-01 Later date: 2012-02-28 Age: 11 Birth date: 2000-03-01 Later date: 2012-02-29 Age: 11 Birth date: 2000-03-01 Later date: 2012-03-01 Age: 12 } +1 this is the closest I've come to a perfect answer to this question. I was about to downvote this question because this solution handles February 29 birth dates by increasing their age by one on February 28 in non-leap years. However asking around I discovered that people born on February 29 will celebrate their birthday February 28 if needed (this is probably culture specific though). I'm curious how for instance air plane companies that sell differently priced tickets based on age handles this. Will you have to pay the full price already on February 28 or will you still get the child discount?  Another function not my me but found on the web and a bit refined: public static int GetAge(DateTime birthDate) { DateTime n = DateTime.Now; // To avoid a race condition around midnight int age = n.Year - birthDate.Year; if (n.Month < birthDate.Month || (n.Month == birthDate.Month && n.Day < birthDate.Day)) age--; return age; } Just two things that come into my mind: What about people from countries that do not use the gregorian calendar? DateTime.Now is in the server-specific culture i think. I have absolutely 0 knowledge about actually working with Asian calendars and I do not know if there is an easy way to convert dates between calendars but just in case you're wondering about those chinese guys from the year 4660 :-) @SimonHewitt Indeed somehow that typo got unseen for 4 years oO Thanks! Corrected. You are still calling DateTime.Now twice??  I have a customized Function to calculate Age + a message if selected date in not matching //This function will validate the date private bool ValidateDate(string dob) { DateTime dobdate = DateTime.Parse(dob); DateTime nowdate = DateTime.Now; TimeSpan ts = nowdate - dobdate; int Years = ts.Days / 365; if (Years < 18) { message = ""Date of Birth must not be less then 18""; return false; } else if (Years > 65) { message = ""Date of Birth must not be greater then 65""; return false; } dobvalue = dob; return true; } //Below here you call that function and pass out datetime value (MM/DD/YYYY) you can format by any way you like //Function Call if (ValidateDate(""03/10/1982"") == false) { lbldatemessaeg.Visible = true; lbldatemessaeg.Text = message; //you can replace anything a messageboxor any container to display return; }  My suggestion int age = (int) ((DateTime.Now - bday).TotalDays/365.242199); That seems to have the year changing on the right date. (I spot tested up to age 107) 365 for the days in a year. +0.25 for leap years. +0.005 for other corrections Where does 365.255 come from? I don't think this will work in general. I don't think Harry Patch would have appreciated your spot-testing methodology: http://www.latimes.com/news/obituaries/la-me-harry-patch26-2009jul2607608030.story I like this answer because it is *exactly* what I was going to add as my own answer! Google says `days in a year = 365.242199` The average length of a year in the Gregorian Calendar is 365.2425 days. Google is not always right. I would say this is one of the simplest solutions and it's *good enough*. Who cares if I am half a day before my Xth birthday and the program says I am X years old. The program is more or less right although not mathematically. I really like this solution. ^^ Because sometimes it's important. In my testing this fails on the persons birthday it reports them younger than they are.  I don't think any of the answers so far provide for cultures that calculate age differently. See for example East Asian Age Reckoning versus that in the West. Any real answer has to include localization. The Strategy Pattern would probably be in order in this example. From the wikipedia article that you provided: ""In China and Japan it is used for traditional fortune-telling or religion and it is disappearing in daily life between peoples in the city."" @some -- Koreans still use this system primarily. Actually this concept can be pretty important - people don't like being told their personal information incorrectly. As an example half of my family lives in Malaysia and half in the UK. Right now my age is considered two years higher when I'm with one side of my family than with the other. Not only us this system used primarily in Korea but as a tourist discussing ages with locals locals will politely refer to yourself an each other by their birth year. I'm not 25 I'm 87. I like this approach better. more of an 'international birthdatetime format'  With less conversions and UtcNow this code can take care of someone born on the Feb 29 on a leap year: public int GetAge(DateTime DateOfBirth) { var Now = DateTime.UtcNow; return Now.Year - DateOfBirth.Year - ( ( Now.Month > DateOfBirth.Month || (Now.Month == DateOfBirth.Month && Now.Day >= DateOfBirth.Day) ) ? 0 : 1 ); }  I've created an Age struct which looks like this: public struct Age : IEquatable<Age> IComparable<Age> { private readonly int _years; private readonly int _months; private readonly int _days; public int Years { get { return _years; } } public int Months { get { return _months; } } public int Days { get { return _days; } } public Age( int years int months int days ) : this() { _years = years; _months = months; _days = days; } public static Age CalculateAge( DateTime dateOfBirth DateTime date ) { // Here is some logic that ressembles Mike's solution although it // also takes into account months & days. // Ommitted for brevity. return new Age (years months days); } // Ommited Equality Comparable GetHashCode functionality for brevity. }  This is the version we use here. It works and it's fairly simple. It's the same idea as Jeff's but I think it's a little clearer because it separates out the logic for subtracting one so it's a little easier to understand. public static int GetAge(this DateTime dateOfBirth DateTime dateAsAt) { return dateAsAt.Year - dateOfBirth.Year - (dateOfBirth.DayOfYear < dateAsAt.DayOfYear ? 0 : 1); } You could expand the ternary operator to make it even clearer if you think that sort of thing is unclear. Obviously this is done as an extension method on DateTime but clearly you can grab that one line of code that does the work and put it anywhere. Here we have another overload of the Extension method that passes in DateTime.Now just for completeness. I think this can be off by one day when exactly one of dateOfBirth or dateAsAt falls in a leap year. Consider the age of a person born on March 1 2003 on February 29 2004. To rectify this you need to do a lexicographic comparison of (Month DayOfMonth) pairs and use that for the conditional. it's also not going to show the right age as of your birthday.  This classic question is deserving of a Noda Time solution. static int GetAge(LocalDate dateOfBirth) { Instant now = SystemClock.Instance.Now; // The target time zone is important. // It should align with the *current physical location* of the person // you are talking about. When the whereabouts of that person are unknown // then you use the time zone of the person who is *asking* for the age. // The time zone of birth is irrelevant! DateTimeZone zone = DateTimeZoneProviders.Tzdb[""America/New_York""]; LocalDate today = now.InZone(zone).Date; Period period = Period.Between(dateOfBirth today PeriodUnits.Years); return (int) period.Years; } Usage: LocalDate dateOfBirth = new LocalDate(1976 8 27); int age = GetAge(dateOfBirth); You might also be interested in the following improvements: Passing in the clock as an IClock instead of using SystemClock.Instance would improve testability. The target time zone will likely change so you'd want a DateTimeZone parameter as well. See also my blog post on this subject: Handling Birthdays and Other Anniversaries  This is a strange way to do it but if you format the date to yyyymmdd and subtract the date of birth from the current date then drop the last 4 digits you've got the age :) I don't know C# but I believe this will work in any language. 20080814 - 19800703 = 280111 Drop the last 4 digits = 28. C# Code: var now = float.Parse(DateTime.Now.ToString(""yyyy.MMdd"")); var dob = float.Parse(dateOfBirth.ToString(""yyyy.MMdd"")); var age = (int)(now - dob); Or alternatively without all the type conversion in the form of an extension method. Error checking omitted: public static Int32 GetAge(this DateTime dateOfBirth) { var today = DateTime.Today; var a = (today.Year * 100 + today.Month) * 100 + today.Day; var b = (dateOfBirth.Year * 100 + dateOfBirth.Month) * 100 + dateOfBirth.Day; return (a - b) / 10000; } there is a subtract method in the datetime class .... It's the most elegant way IMO +1  I used ScArcher2's solution for an accurate Year calculation of a persons age but I needed to take it further and calculate their Months and Days along with the Years.  public static Dictionary<stringint> CurrentAgeInYearsMonthsDays(DateTime? ndtBirthDate DateTime? ndtReferralDate) { //---------------------------------------------------------------------- // Can't determine age if we don't have a dates. //---------------------------------------------------------------------- if (ndtBirthDate == null) return null; if (ndtReferralDate == null) return null; DateTime dtBirthDate = Convert.ToDateTime(ndtBirthDate); DateTime dtReferralDate = Convert.ToDateTime(ndtReferralDate); //---------------------------------------------------------------------- // Create our Variables //---------------------------------------------------------------------- Dictionary<string int> dYMD = new Dictionary<stringint>(); int iNowDate iBirthDate iYears iMonths iDays; string sDif = """"; //---------------------------------------------------------------------- // Store off current date/time and DOB into local variables //---------------------------------------------------------------------- iNowDate = int.Parse(dtReferralDate.ToString(""yyyyMMdd"")); iBirthDate = int.Parse(dtBirthDate.ToString(""yyyyMMdd"")); //---------------------------------------------------------------------- // Calculate Years //---------------------------------------------------------------------- sDif = (iNowDate - iBirthDate).ToString(); iYears = int.Parse(sDif.Substring(0 sDif.Length - 4)); //---------------------------------------------------------------------- // Store Years in Return Value //---------------------------------------------------------------------- dYMD.Add(""Years"" iYears); //---------------------------------------------------------------------- // Calculate Months //---------------------------------------------------------------------- if (dtBirthDate.Month > dtReferralDate.Month) iMonths = 12 - dtBirthDate.Month + dtReferralDate.Month - 1; else iMonths = dtBirthDate.Month - dtReferralDate.Month; //---------------------------------------------------------------------- // Store Months in Return Value //---------------------------------------------------------------------- dYMD.Add(""Months"" iMonths); //---------------------------------------------------------------------- // Calculate Remaining Days //---------------------------------------------------------------------- if (dtBirthDate.Day > dtReferralDate.Day) //Logic: Figure out the days in month previous to the current month or the admitted month. // Subtract the birthday from the total days which will give us how many days the person has lived since their birthdate day the previous month. // then take the referral date and simply add the number of days the person has lived this month. //If referral date is january we need to go back to the following year's December to get the days in that month. if (dtReferralDate.Month == 1) iDays = DateTime.DaysInMonth(dtReferralDate.Year - 1 12) - dtBirthDate.Day + dtReferralDate.Day; else iDays = DateTime.DaysInMonth(dtReferralDate.Year dtReferralDate.Month - 1) - dtBirthDate.Day + dtReferralDate.Day; else iDays = dtReferralDate.Day - dtBirthDate.Day; //---------------------------------------------------------------------- // Store Days in Return Value //---------------------------------------------------------------------- dYMD.Add(""Days"" iDays); return dYMD; }  Here is a very simple and easy to follow example. private int CalculateAge() { //get birthdate DateTime dtBirth = Convert.ToDateTime(BirthDatePicker.Value); int byear = dtBirth.Year; int bmonth = dtBirth.Month; int bday = dtBirth.Day; DateTime dtToday = DateTime.Now; int tYear = dtToday.Year; int tmonth = dtToday.Month; int tday = dtToday.Day; int age = tYear - byear; if (bmonth < tmonth) age--; else if (bmonth == tmonth && bday>tday) { age--; } return age; }  The best way that I know of because of leap years and everything is: DateTime birthDate = new DateTime(200031); int age = (int)Math.Floor((DateTime.Now - birthDate).TotalDays / 365.25D); Hope this helps. That's not a correct answer because like you say there are leap years and therefore not each year has 365 days. By just counting the number of days and dividing by 365 you'll get slippage every 4 years or so.  Try this solution it's working. int age = (Int32.Parse(DateTime.Today.ToString(""yyyyMMdd"")) - Int32.Parse(birthday.ToString(""yyyyMMdd rawrrr""))) / 10000;  Seems most of codes are very large  So I have here a small code and that will give you the result that you are expecting int _output = new DateTime ( DateTime.Now.Subtract(person_sBirthDate).Ticks ).Year -1;  Many years ago to provide an age calculator gimmick on my website I wrote a function to calculate age to a fraction. This is a quick port of that function to C# (from the PHP version). I'm afraid I haven't been able to test the C# version but hope you enjoy all the same! (Admittedly this is a bit gimmicky for the purposes of showing user profiles on Stack Overflow but maybe readers will find some use for it. :-)) double AgeDiff(DateTime date1 DateTime date2) {  double years = date2.Year - date1.Year;  /*  * If date2 and date1 + round(date2 - date1) are on different sides  * of 29 February then our partial year is considered to have 366  * days total otherwise it's 365. Note that 59 is the day number  * of 29 Feb.  */  double fraction = 365  + (DateTime.IsLeapYear(date2.Year) && date2.DayOfYear >= 59  && (date1.DayOfYear < 59 || date1.DayOfYear > date2.DayOfYear)  ? 1 : 0);  /*  * The only really nontrivial case is if date1 is in a leap year  * and date2 is not. So let's handle the others first.  */  if (DateTime.IsLeapYear(date2.Year) == DateTime.IsLeapYear(date1.Year))  return years + (date2.DayOfYear - date1.DayOfYear) / fraction;  /*  * If date2 is in a leap year but date1 is not and is March or  * beyond shift up by a day.  */  if (DateTime.IsLeapYear(date2.Year)) {  return years + (date2.DayOfYear - date1.DayOfYear  - (date1.DayOfYear >= 59 ? 1 : 0)) / fraction;  }  /*  * If date1 is not on 29 February shift down date1 by a day if  * March or later. Proceed normally.  */  if (date1.DayOfYear != 59) {  return years + (date2.DayOfYear - date1.DayOfYear  + (date1.DayOfYear > 59 ? 1 : 0)) / fraction;  }  /*  * Okay here date1 is on 29 February and date2 is not on a leap  * year. What to do now? On 28 Feb in date2's year the ``age''  * should be just shy of a whole number and on 1 Mar should be  * just over. Perhaps the easiest way is to a point halfway  * between those two: 58.5.  */  return years + (date2.DayOfYear - 58.5) / fraction; }  Would this work? public override bool IsValid(DateTime value) { _dateOfBirth = value; var yearsOld = (double) (DateTime.Now.Subtract(_dateOfBirth).TotalDays/365); if (yearsOld > 18) return true; return false; } Negative rater please explain the reason!!! Wow. Why is value an object rather than a DateTime? The method signature should be `public override bool Is18OrOlder(DateTime birthday)` What about people who were born on February 29? Who said that we were trying to check whether or not the user was at least 18 years old? The question was ""how do I calculate someone's age?"" How did that happen? I don't even remember putting IsValid as object. It should be DateTime!  I've made one small change to Mark Soen's answer: I've rewriten the third line so that the expression can be parsed a bit more easily.  public int AgeInYears(DateTime bday) { DateTime now = DateTime.Today; int age = now.Year - bday.Year; if (bday.AddYears(age) > now) age--; return age; } I've also made it into a function for the sake of clarity.  int age = DateTime.Now.Year - birthday.Year; if (DateTime.Now.Month < birthday.Month || DateTime.Now.Month == birthday.Month && DateTime.Now.Day < birthday.Day) age--; @AndrewBarber: I changed my answer I hope its fine now No it's not at all as simple as that. Not in the least. You also don't seem to have understood the question very well. Actually it's not right. Your conditional is clumsy and does not actually work right. It should be: `if (DateTime.Now.Month <= birthday.Month && DateTime.Now.Day < birthday.Day)` I removed your middle condition; combined the `<` and `==`. The way you had it it would not check the date; the `||` being true would cause the `&&` not even to be evaluated.  This is simple and appears to be accurate for my needs. I am making an assumption for the purposes of leap years that regardless of when the person chooses to celebrate the birthday they are not technically a ","ear older until a full 365 days has passed since there last birthday (i.e 28th February does not make them a year older) DateTime now = DateTime.Today; DateTime birthday = new DateTime(1991 02 03);//3rd feb int age = now.Year - birthday.Year; if (now.Month < birthday.Month || (now.Month == birthday.Month && now.Day < birthday.Day))//not had bday this year yet age--; return age; Let us know if you spot any problems ;)  To calculate the age with nearest age: var ts = DateTime.Now - new DateTime(1988 3 19); var age = Math.Round(ts.Days / 365.0); not necessarily true. I guess the correct would be to divide by 365.25 to account for leap years somehow  TimeSpan diff = DateTime.Now - birthdayDateTime; string age = String.Format(""""{0:%y} years {0:%M} months {0:%d} days old"""" diff); I'm not sure how exactly you'd like it returned to you so I just made a readable string.  Here is a solution.  DateTime dateOfBirth = new DateTime(2000 4 18); DateTime currentDate = DateTime.Now; int ageInYears = 0; int ageInMonths = 0; int ageInDays = 0; ageInDays = currentDate.Day - dateOfBirth.Day; ageInMonths = currentDate.Month - dateOfBirth.Month; ageInYears = currentDate.Year - dateOfBirth.Year; if (ageInDays < 0) { ageInDays += DateTime.DaysInMonth(currentDate.Year currentDate.Month); ageInMonths = ageInMonths--; if (ageInMonths < 0) { ageInMonths += 12; ageInYears--; } } if (ageInMonths < 0) { ageInMonths += 12; ageInYears--; } Console.WriteLine(""""{0} {1} {2}"""" ageInYears ageInMonths ageInDays);  I am late to the party but here's a one-liner: int age = new DateTime(DateTime.Now.Subtract(birthday).Ticks).Year-1; Gotta love one-liners This is broken. Made testable: public static int CalculateAge(DateTime dateOfBirth DateTime dateToCalculateAge) { return new DateTime(dateToCalculateAge.Subtract(dateOfBirth).Ticks).Year - 1; } ...Gives age 14 when I input 1990-06-01 and calculate the age on the day BEFORE his 14th birthday (1990-05-31). As Kjensen says it's broken folks - take away your upvotes... -1 for incorrect answer. Yes it's wrong because you need to compare the month and day!  var now = DateTime.Now; var age = (int)Math.Floor(now.Substract(birdth).TotalYears); `TotalYears` property does not exist.  Here's a little code sample for C# I knocked up be careful around the edge cases specifically leap years not all the above solutions take them into account. Pushing the answer out as a DateTime can cause problems as you could end up trying to put too many days into a specific month e.g. 30 days in Feb. public string LoopAge(DateTime myDOB DateTime FutureDate) { int years = 0; int months = 0; int days = 0; DateTime tmpMyDOB = new DateTime(myDOB.Year myDOB.Month 1); DateTime tmpFutureDate = new DateTime(FutureDate.Year FutureDate.Month 1); while (tmpMyDOB.AddYears(years).AddMonths(months) < tmpFutureDate) { months++; if (months > 12) { years++; months = months - 12; } } if (FutureDate.Day >= myDOB.Day) { days = days + FutureDate.Day - myDOB.Day; } else { months--; if (months < 0) { years--; months = months + 12; } days = days + (DateTime.DaysInMonth(FutureDate.AddMonths(-1).Year FutureDate.AddMonths(-1).Month) + FutureDate.Day) - myDOB.Day; } //add an extra day if the dob is a leap day if (DateTime.IsLeapYear(myDOB.Year) && myDOB.Month == 2 && myDOB.Day == 29) { //but only if the future date is less than 1st March if(FutureDate >= new DateTime(FutureDate.Year 31)) days++; } return """"Years: """" + years + """" Months: """" + months + """" Days: """" + days; } I like this solution the best however when calculating the months it needs to be if(months >= 12). Try 6-8-2012 - 6-4-1993 to test.  This is not a direct answer but more of a philosophical reasoning about the problem at hand from a quasi-scientific point of view. I would argue that the question does not specify the unit nor culture in which to measure age most answers seem to assume an integer annual representation. The SI-unit for time is second ergo the correct generic answer should be (of course assuming normalized DateTime and taking no regard whatsoever to relativistic effects): var lifeInSeconds = (DateTime.Now.Ticks - then.Ticks)/TickFactor; In the Christian way of calculating age in years: var then = ... // Then in this case the birthday var now = DateTime.UtcNow; int age = now.Year - then.Year; if (now.AddYears(-age) < then) age--; In finance there is a similar problem when calculating something often referred to as the Day Count Fraction which roughly is the amount of years for a given period. And the age issue is really a time measuring issue. Example for the actual/actual (counting all days """"correctly"""") convention: DateTime start end = .... // Whatever assume start is before end double startYearContribution = 1 - (double) start.DayOfYear / (double) (DateTime.IsLeapYear(start.Year) ? 366 : 365); double endYearContribution = (double)end.DayOfYear / (double)(DateTime.IsLeapYear(end.Year) ? 366 : 365); double middleContribution = (double) (end.Year - start.Year - 1); double DCF = startYearContribution + endYearContribution + middleContribution; Another quite common way to measure time generally is by """"serializing"""" (the dude who named this date convention must seriously have been trippin'): DateTime start end = .... // Whatever assume start is before end int days = (end - start).Days; I wonder how long we have to go before a relativistic age in seconds becomes more useful than the rough approximation of earth-around-sun-cycles during ones lifetime so far :) Or in other words when a period must be given a location or a function representing motion for itself to be valid :)  For some reason Jeff's code didn't seem simple enough. To me this seems simpler and easier to understand: DateTime today = DateTime.Today; int age = today.Year - bday.Year; if (bday > today.AddYears(-age)) age--; Just wanted to comment on DateTime.Now performance. If you don't need an accurate time zone value use DateTime.UtcNow it's much faster. Given we're talking birthdays you can just use DateTime.Today given the time part has no relevance. This answer does not work with all locales and all ages. Several countries have skipped dates after the birth of current living people including Russia (1918) Greece (1924) and Turkey (1926). So we have a different age according to different countries and calendar ? What a scoop... @JAG: DateTime.Today should be even faster. Good catch Danvil! Changed last line to: if (bday > now.AddYears(-age)) age--; I think that fixes it. It passed my measly 3 tests :-) This is wrong! Try it with a person born 2000/02/29. If now is 2009/02/28 your code will state that the person is 9 years old. Actually it's still not entirely correct. This code presumes that 'bday' is the date-portion of a DateTime. It's an edge-case (I guess most people will just be passing dates and not date-times) but if you pass in a birthday as a date-and-time where the time is greater than 00:00:00 then you'll run into the bug Danvil pointed out. Setting bday = bday.Date fixes this. The last line made me think too much. Instead how about: if (bday.AddYears(age) > now) age--; This seems to be a more intuitive expression. Good idea cdiggins but it doesn't work as bday.AddYears(age) when age is 2/29 returns 2/28 on years that are not leap years...keep trying Or just do if (BirthDate.DayOfYear > Today.DayOfYear); no need to forther modify the date variables @NKCSS: That does not handle the leap year correctly. My testing shows that only `if (bday > now.AddYears(-age))` works. Since `DayOfYear` returns `61` in 2012 and `60` in 2011 for March 1. @Guvante Thanks...I lost my test last year when I lost my hard drive...I should have tested more @Danvil is it really wrong? Take a simpler example. Birthday = 2000/02/29 Today = 2001/02/28. Days elapsed: 365. Isn't that one year and therefore isn't the person one year old on the 28th? Or is the definition of a year 365-1/4 days? I'm just sayin' it's complicated. Wouldn't it be easier to just do `DateTime dateDifference = subject.Birthday - DateTime.Now; int age = dateDifference.Year;`? Also I don't think age depends on leap years. After all a year is defined as 365 DateTime.Today.AddYears(-age)) ? age-- : age;`  I have created a SQL Server User Defined Function to calculate someone's age given their birthdate. This is useful when you need it as part of a query: using System; using System.Data; using System.Data.Sql; using System.Data.SqlClient; using System.Data.SqlTypes; using Microsoft.SqlServer.Server; public partial class UserDefinedFunctions { [SqlFunction(DataAccess = DataAccessKind.Read)] public static SqlInt32 CalculateAge(string strBirthDate) { DateTime dtBirthDate = new DateTime(); dtBirthDate = Convert.ToDateTime(strBirthDate); DateTime dtToday = DateTime.Now; // get the difference in years int years = dtToday.Year - dtBirthDate.Year; // subtract another year if we're before the // birth day in the current year if (dtToday.Month < dtBirthDate.Month || (dtToday.Month == dtBirthDate.Month && dtToday.Day < dtBirthDate.Day)) years=years-1; int intCustomerAge = years; return intCustomerAge; } }; This method work perfectly.  The following approach (extract from Time Period Library for .NET class DateDiff) considers the calendar of the culture info: // ---------------------------------------------------------------------- private static int YearDiff( DateTime date1 DateTime date2 ) { return YearDiff( date1 date2 DateTimeFormatInfo.CurrentInfo.Calendar ); } // YearDiff // ---------------------------------------------------------------------- private static int YearDiff( DateTime date1 DateTime date2 Calendar calendar ) { if ( date1.Equals( date2 ) ) { return 0; } int year1 = calendar.GetYear( date1 ); int month1 = calendar.GetMonth( date1 ); int year2 = calendar.GetYear( date2 ); int month2 = calendar.GetMonth( date2 ); // find the the day to compare int compareDay = date2.Day; int compareDaysPerMonth = calendar.GetDaysInMonth( year1 month1 ); if ( compareDay > compareDaysPerMonth ) { compareDay = compareDaysPerMonth; } // build the compare date DateTime compareDate = new DateTime( year1 month2 compareDay date2.Hour date2.Minute date2.Second date2.Millisecond ); if ( date2 > date1 ) { if ( compareDate < date1 ) { compareDate = compareDate.AddYears( 1 ); } } else { if ( compareDate > date1 ) { compareDate = compareDate.AddYears( -1 ); } } return year2 - calendar.GetYear( compareDate ); } // YearDiff Usage: // ---------------------------------------------------------------------- public void CalculateAgeSamples() { PrintAge( new DateTime( 2000 02 29 ) new DateTime( 2009 02 28 ) ); // > Birthdate=29.02.2000 Age at 28.02.2009 is 8 years PrintAge( new DateTime( 2000 02 29 ) new DateTime( 2012 02 28 ) ); // > Birthdate=29.02.2000 Age at 28.02.2012 is 11 years } // CalculateAgeSamples // ---------------------------------------------------------------------- public void PrintAge( DateTime birthDate DateTime moment ) { Console.WriteLine( """"Birthdate={0:d} Age at {1:d} is {2} years"""" birthDate moment YearDiff( birthDate moment ) ); } // PrintAge Interesting article. Thanks for the post.  Here's a DateTime extender that adds the age calculation to the DateTime object.  public static class AgeExtender { public static int GetAge(this DateTime dt) { int d = int.Parse(dt.ToString(""""yyyyMMdd"""")); int t = int.Parse(DateTime.Today.ToString(""""yyyyMMdd"""")); return (t-d)/10000; } } ugh don't do this. ToString and int.Parse are both relatively expensive and while i'm anti micro-optimization hiding expensive functions in extension methods that should be trivial operations is not a good idea. Also this is a duplicate of ScArcher2's answer: http://stackoverflow.com/questions/9/how-do-i-calculate-someones-age-in-c/11942#11942 Yaur I really like Elmer's solution that relies on DayOfYear probably more efficient than mine. Note that my goal wasn't to change ScArcher2's algorithm I felt that would be rude. It was simply to show how to implement an extension method.  The simplest way I've ever found is this. It works correctly for the US and western europe locales. Can't speak to other locales especially places like China. 4 extra compares at most following the initial computation of age. public int AgeInYears( DateTime birthDate  DateTime referenceDate ) { Debug.Assert( referenceDate >= birthDate  """"birth date must be on or prior to the reference date"""" ) ; DateTime birth = birthDate.Date ; DateTime reference = referenceDate.Date ; int years = ( reference.Year - birth.Year ) ; // // an offset of -1 is applied if the birth date has // not yet occurred in the current year. // if ( reference.Month > birth.Month ) ; else if ( reference.Month < birth.Month ) --years ; else // in birth month { if ( reference.Day < birth.Day ) --years ; } return years ; } I was looking over the answers to this and noticed that nobody has made reference to regulatory/legal implications of leap day births. For instance per Wikipedia if you're born on February 29th in various jurisdictions you're non-leap year birthday varies: In the United Kingdom and Hong Kong: it's the ordinal day of the year so the next day March 1st is your birthday. In New Zealand: it's the previous day February 28th for the purposes of driver licencing and March 1st for other purposes. Taiwan: it's February 28th. And as near as I can tell in the US the statutes are silent on the matter leaving it up to the common law and to how various regulatory bodies define things in their regulations. To that end an improvement: public enum LeapDayRule { OrdinalDay = 1  LastDayOfMonth = 2  } static int ComputeAgeInYears( DateTime birth  DateTime reference  LeapYearBirthdayRule ruleInEffect ) { bool isLeapYearBirthday = CultureInfo.CurrentCulture.Calendar.IsLeapDay( birth.Year  birth.Month  birth.Day ) ; DateTime cutoff ; if ( isLeapYearBirthday && !DateTime.IsLeapYear(reference.Year) ) { switch ( ruleInEffect ) { case LeapDayRule.OrdinalDay : cutoff = new DateTime( reference.Year  1  1 ) .AddDays( birth.DayOfYear-1 ) ; break ; case LeapDayRule.LastDayOfMonth : cutoff = new DateTime( reference.Year  birth.Month  1 ) .AddMonths(1) .AddDays(-1) ; break ; default : throw new InvalidOperationException() ; } } else { cutoff = new DateTime(reference.Yearbirth.Monthbirth.Day) ; } int age = ( reference.Year - birth.Year ) + ( reference >= cutoff ? 0 : -1 ) ; return age < 0 ? 0 : age ; } It should be noted that this code assumes: A western (European) reckoning of age and A calendar like the Gregorian calendar that inserts a single leap day at the end of a month.  I don't know how the wrong solution can be accepted. The correct C# snippet was written by Michael Stum Here is a test snippet: DateTime bDay = new DateTime(2000 2 29); DateTime now = new DateTime(2009 2 28); MessageBox.Show(string.Format(""""Test {0} {1} {2}"""" CalculateAgeWrong1(bDay now) // outputs 9 CalculateAgeWrong2(bDay now) // outputs 9 CalculateAgeCorrect(bDay now))); // outputs 8 Here you have the methods: public int CalculateAgeWrong1(DateTime birthDate DateTime now) { return new DateTime(now.Subtract(birthDate).Ticks).Year - 1; } public int CalculateAgeWrong2(DateTime birthDate DateTime now) { int age = now.Year - birthDate.Year; if (now < birthDate.AddYears(age)) age--; return age; } public int CalculateAgeCorrect(DateTime birthDate DateTime now) { int age = now.Year - birthDate.Year; if (now.Month < birthDate.Month || (now.Month == birthDate.Month && now.Day < birthDate.Day)) age--; return age; } And the outputs?? this is the correct answer it needs to be voted up! +1 for your TDD approach to the answer! Output was -Test 9 9 8 While this code works it asserts that a person born on a leap day attains the next year of age on March 1st on non-leap years rather than on February 28th. In reality *either option may be correct*. [Wikipedia has something to say about this](http://en.wikipedia.org/wiki/Leap_day#Births). So while your code is not """"wrong"""" neither is the accepted solution.  I've spent some time working on this and came up with this to calculate someone's age in years months and days. I've tested against the Feb 29th problem and leap years and it seems to work I'd appreciate any feedback: public void LoopAge(DateTime myDOB DateTime FutureDate) { int years = 0; int months = 0; int days = 0; DateTime tmpMyDOB = new DateTime(myDOB.Year myDOB.Month 1); DateTime tmpFutureDate = new DateTime(FutureDate.Year FutureDate.Month 1); while (tmpMyDOB.AddYears(years).AddMonths(months) < tmpFutureDate) { months++; if (months > 12) { years++; months = months - 12; } } if (FutureDate.Day >= myDOB.Day) { days = days + FutureDate.Day - myDOB.Day; } else { months--; if (months < 0) { years--; months = months + 12; } days += DateTime.DaysInMonth( FutureDate.AddMonths(-1).Year FutureDate.AddMonths(-1).Month ) + FutureDate.Day - myDOB.Day; } //add an extra day if the dob is a leap day if (DateTime.IsLeapYear(myDOB.Year) && myDOB.Month == 2 && myDOB.Day == 29) { //but only if the future date is less than 1st March if (FutureDate >= new DateTime(FutureDate.Year 3 1)) days++; } }""",c# .net datetime,,28637,A,"Is DateTime.Now the best way to measure a function's performance? I need to find a bottleneck and need to accurately as possible measure time. Is the following code snippet the best way to measure the performance? DateTime startTime = DateTime.Now; // Some execution process DateTime endTime = DateTime.Now; TimeSpan totalTimeTaken = endTime.Subtract(startTime); @dbasnett Can you go into more detail in an answer? In the above example change start and endtime to long and assign Stopwatch.GetTimestamp to them instead of DateTime.Now. The time taken is (end-start)/Stopwatch.Frequency. If you need greater precision use Stopwatch.GetTimestamp otherwise the answer is good. By the way if you are not looking for something quick and dirty performance counters can be used. See also: [The Case Against DateTime.Now](http://codeofmatt.com/2013/04/25/the-case-against-datetime-now/) This is the correct way: using System; using System.Diagnostics; class Program { public static void Main() { Stopwatch stopWatch = Stopwatch.StartNew(); // some other code stopWatch.Stop(); // this not correct to get full timer resolution Console.WriteLine(""{0} ms"" stopWatch.ElapsedMilliseconds); // Correct way to get accurate high precision timing Console.WriteLine(""{0} ms"" stopWatch.Elapsed.TotalMilliseconds); } } For more information go through Use Stopwatch instead of DataTime for getting accurate performance counter.  These are all great ways to measure time but that is only a very indirect way to find bottleneck(s). The most direct way to find a bottneck in a thread is to get it running and while it is doing whatever makes you wait halt it with a pause or break key. Do this several times. If your bottleneck takes X% of time X% is the probability that you will catch it in the act on each snapshot. Here's a more complete explanation of how and why it works  @Sean Chambers FYI the .NET Timer class is not for diagnostics it generates events at a preset interval like this (from MSDN): System.Timers.Timer aTimer; public static void Main() { // Create a timer with a ten second interval. aTimer = new System.Timers.Timer(10000); // Hook up the Elapsed event for the timer. aTimer.Elapsed += new ElapsedEventHandler(OnTimedEvent); // Set the Interval to 2 seconds (2000 milliseconds). aTimer.Interval = 2000; aTimer.Enabled = true; Console.WriteLine(""Press the Enter key to exit the program.""); Console.ReadLine(); } // Specify what you want to happen when the Elapsed event is // raised. private static void OnTimedEvent(object source ElapsedEventArgs e) { Console.WriteLine(""The Elapsed event was raised at {0}"" e.SignalTime); } So this really doesn't help you know how long something took just that a certain amount of time has passed. The timer is also exposed as a control in System.Windows.Forms... you can find it in your designer tool box in VS05/VS08  The way I use within my programs is using the StopWatch class as shown here. Stopwatch sw = new Stopwatch(); sw.Start(); int a = 5; // Critical lines of code long elapsedMs = se.Elapsed.TotalMilliseconds;  No it's not. Use the Stopwatch (in System.Diagnostics) Stopwatch sw = Stopwatch.StartNew(); PerformWork(); sw.Stop(); Console.WriteLine(""Time taken: {0}ms"" sw.Elapsed.TotalMilliseconds); Stopwatch automatically checks for the existence of high-precision timers. It is worth mentioning that DateTime.Now often is quite a bit slower than DateTime.UtcNow due to the work that has to be done with timezones DST and such. DateTime.UtcNow typically has a resolution of 15åÊms. See John Chapman's blog post about DateTime.Now precision for a great summary. Interesting trivia: The stopwatch falls back on DateTime.UtcNow if your hardware doesn't support a high frequency counter. You can check to see if Stopwatch uses hardware to achieve high precision by looking at the static field Stopwatch.IsHighResolution. I'd place one PerformWork(); before Stopwatch for ""heating up"". Must also add recommendation that if your `PerformWork()` is very short that you may be able to call it repeatedly and compute the average of the batch of calls. Also time an entire batch of calls rather than starting/stopping your `Stopwatch` to avoid a strobe-effect that will muddy your timing measurements. Stopwatch is not threadsafe on multicore. See http://stackoverflow.com/questions/6664538/is-stopwatch-elapsedticks-threadsafe and http://stackoverflow.com/questions/1149485/best-practise-for-stopwatch-in-multi-processors-machine sw.ElapsedMilliseconds; can also  This article says that first of all you need to compare three alternatives Stopwatch DateTime.Now AND DateTime.UtcNow. It also shows that in some cases (when performance counter doesn't exist) Stopwatch is using DateTime.UtcNow + some extra processing. Because of that it's obvious that in that case DateTime.UtcNow is the best option (because other use it + some processing) However as it turns out the counter almost always exists - see Explanation about high-resolution performance counter and its existence related to .NET Stopwatch?. Here is a performance graph. Notice how low performance cost UtcNow has compared to alternatives: The X axis is sample data size and the Y axis is the relative time of the example. One thing Stopwatch is better at is that it provides higher resolution time measurements. Another is its more OO nature. However creating an OO wrapper around UtcNow can't be hard. The first link appears to be broken. became broken yep.. time machine can show it I would guess. Btw why you edit ""the three""  the isn't needed here I believe.  I've done very little of this sort of performance checking (I tend to just think ""this is slow make it faster"") so I have pretty much always gone with this. A google does reveal a lot of resources/articles for performance checking. Many mention using pinvoke to get performance information. A lot of the materials I study only really mention using perfmon.. Edit: Seen the talks of StopWatch.. Nice! I have learned something :) This looks like a good article  I just found a post in Vance Morrison's blog about a CodeTimer class he wrote that makes using StopWatch easier and does some neat stuff on the side.  Use the System.Diagnostics.Stopwatch class. Stopwatch sw = new Stopwatch(); sw.Start(); // Do some code. sw.Stop(); // sw.ElapsedMilliseconds = the time your ""do some code"" took.  Ditto Stopwatch it is way better. Regarding performance measuring you should also check whether your ""// Some Execution Process"" is a very short process. Also bear in mind that the first run of your ""// Some Execution Process"" might be way slower than subsequent runs. I typically test a method by running it 1000 times or 1000000 times in a loop and I get much more accurate data than running it once.  If you want something quick and dirty I would suggest using Stopwatch instead for a greater degree of precision. Stopwatch sw = new Stopwatch(); sw.Start(); // Do Work sw.Stop(); Console.WriteLine(""Elapsed time: {0}"" sw.Elapsed.TotalMilliseconds); Alternatively if you need something a little more sophisticated you should probably consider using a 3rd party profiler such as ANTS. Does ANTS work with F# yet?  The stopwatch functionality would be better (higher precision). I'd also recommend just downloading one of the popular profilers though (DotTrace and ANTS are the ones I've used the most... the free trial for DotTrace is fully functional and doesn't nag like some of the others).  It's useful to push your benchmarking code into a utility class/method. The StopWatch class does not need to be Disposed or Stopped on error. So the simplest code to time some action is public partial class With { public static long Benchmark(Action action) { var stopwatch = Stopwatch.StartNew(); action(); stopwatch.Stop(); return stopwatch.ElapsedMilliseconds; } } Sample calling code public void Execute(Action action) { var time = With.Benchmark(action); log.DebugFormat(‰ÛÏDid action in {0} ms.‰Û time); } Here is the extension method version public static class Extensions { public static long Benchmark(this Action action) { return With.Benchmark(action); } } And sample calling code public void Execute(Action action) { var time = action.Benchmark() log.DebugFormat(‰ÛÏDid action in {0} ms.‰Û time); } What about better granularity? Many things happen in less than one ms. Return the Elapsed property then it's a TimeSpan. I'm just showing you the pattern. Have fun implementing it. Return `Elapsed.TotalMilliseconds` for higher precision. See this question too http://stackoverflow.com/questions/8894425/difference-between-elapsedticks-elapsedmilliseconds-elapsed-milliseconds-and-e  Visual Studio Team System has some features that may help with this problem. Essentially you can write unit tests and mix them in different scenarios to run against your software as part of a stress or load test. This may help to identify areas of code that impact your applications performance the most. Microsoft' Patterns and Practices group has some guidance in Visual Studio Team System Performance Testing Guidance.",c# .net performance datetime timer20346,A,".NET: What are attributes? What are they what are they good for and how do I create my own attributes? Many people have answered but no one has mentioned this so far... Attributes are used heavily with reflection. Reflection is already pretty slow. It is very worthwhile marking your custom attributes as being sealed classes to improve their runtime performance. It is also a good idea to consider where it would be appropriate to use place such an attribute and to attribute your attribute (!) to indicate this via AttributeUsage. The list of available attribute usages might surprise you: Assembly Module Class Struct Enum Constructor Method Property Field Event Interface Parameter Delegate ReturnValue GenericParameter All It's also cool that the AttributeUsage attribute is part of the AttributeUsage attribute's signature. Whoa for circular dependencies! [AttributeUsageAttribute(AttributeTargets.Class Inherited = true)] public sealed class AttributeUsageAttribute : Attribute  An attribute is a class that contains some bit of functionality that you can apply to objects in your code. To create one create a class that inherits from System.Attribute. As for what they're good for... there are almost limitless uses for them. http://www.codeproject.com/KB/cs/dotnetattributes.aspx  In the project I'm currently working on there is a set of UI objects of various flavours and an editor to assembly these objects to create pages for use in the main application a bit like the form designer in DevStudio. These objects exist in their own assembly and each object is a class derived from UserControl and has a custom attribute. This attribute is defined like this: [AttributeUsage (AttributeTargets::Class)] public ref class ControlDescriptionAttribute : Attribute { public: ControlDescriptionAttribute (String ^name String ^description) : _name (name) _description (description) { } property String ^Name { String ^get () { return _name; } } property String ^Description { String ^get () { return _description; } } private: String ^ _name ^ _description; }; and I apply it to a class like this: [ControlDescription (""Pie Chart"" ""Displays a pie chart"")] public ref class PieControl sealed : UserControl { // stuff }; which is what the previous posters have said. To use the attribute the editor has a Generic::List <Type> containing the control types. There is a list box which the user can drag from and drop onto the page to create an instance of the control. To populate the list box I get the ControlDescriptionAttribute for the control and fill out an entry in the list: // done for each control type array <Object ^> // get all the custom attributes ^attributes = controltype->GetCustomAttributes (true); Type // this is the one we're interested in ^attributetype = ECMMainPageDisplay::ControlDescriptionAttribute::typeid; // iterate over the custom attributes for each (Object ^attribute in attributes) { if (attributetype->IsInstanceOfType (attribute)) { ECMMainPageDisplay::ControlDescriptionAttribute ^description = safe_cast <ECMMainPageDisplay::ControlDescriptionAttribute ^> (attribute); // get the name and description and create an entry in the list ListViewItem ^item = gcnew ListViewItem (description->Name); item->Tag = controltype->Name; item->SubItems->Add (description->Description); mcontrols->Items->Add (item); break; } } Note: the above is C++/CLI but it's not difficult to convert to C# (yeah I know C++/CLI is an abomination but it's what I have to work with :-( ) You can put attributes on most things and there are whole range of predefined attributes. The editor mentioned above also looks for custom attributes on properties that describe the property and how to edit it. Once you get the whole idea you'll wonder how you ever lived without them.  Attributes are essentially bits of data you want to attach to your types (classes methods events enums etc.) The idea is that at run time some other type/framework/tool will query your type for the information in the attribute and act upon it. So for example Visual Studio can query the attributes on a 3rd party control to figure out which properties of the control should appear in the Properties pane at design time. Attributes can also be used in Aspect Oriented Programming to inject/manipulate objects at run time based on the attributes that decorate them and add validation logging etc. to the objects without affecting the business logic of the object.  You could check out Martin Flower's article How .NET‰Ûªs Custom Attributes Affect Design.  Attributes are a kind of meta data for tagging classes. This is often used in WinForms for example to hide controls from the toolbar but can be implemented in your own application to enable instances of different classes to behave in specific ways. Start by creating an attribute: [AttributeUsage(AttributeTargets.Class AllowMultiple=false Inherited=true)] public class SortOrderAttribute : Attribute { public int SortOrder { get; set; } public SortOrderAttribute(int sortOrder) { this.SortOrder = sortOrder; } } All attribute classes must have the suffix ""Attribute"" to be valid. After this is done create a class that uses the attribute. [SortOrder(23)] public class MyClass { public MyClass() { } } Now you can check a specific class' SortOrderAttribute (if it have one) by doing the following: public class MyInvestigatorClass { public void InvestigateTheAttribute() { // Get the type object for the class that is using // the attribute. Type type = typeof(MyClass); // Get all custom attributes for the type. object[] attributes = type.GetCustomAttributes( typeof(SortOrderAttribute) true); // Now let's make sure that we got at least one attribute. if (attributes != null && attributes.Length > 0) { // Get the first attribute in the list of custom attributes // that is of the type ""SortOrderAttribute"". This should only // be one since we said ""AllowMultiple=false"". SortOrderAttribute attribute = attributes[0] as SortOrderAttribute; // Now we can get the sort order for the class ""MyClass"". int sortOrder = attribute.SortOrder; } } } If you want to read more about this you can always check out MSDN which have a pretty good description. I hope this helped you out!  Introduction to Attributes Programming C#: Attributes and Reflection (a great article excerpted from a book)  Attributes are also commonly used for Aspect Oriented Programming. For an example of this check out the PostSharp project.  To get started creating an attribute open a C# source file type attribute and hit [TAB]. It will expand to a template for a new attribute.  Attributes are like metadata applied to classes methods or assemblies. They are good for any number of things (debugger visualization marking things as obsolete marking things as serializable the list is endless). Creating your own custom ones is easy as pie. Start here: http://msdn.microsoft.com/en-us/library/sw480ze8(VS.71).aspx  You can use custom attributes as a simple way to define tag values in sub classes without having to write the same code over and over again for each subclass. I came across a nice concise example by John Waters of how to define and use custom attributes in your own code. There is a tutorial at http://msdn.microsoft.com/en-us/library/aa288454(VS.71).aspx  Metadata. Data about your objects/methods/properties. For example I might declare an Attribute called: DisplayOrder so I can easily control in what order properties should appear in the UI. I could then append it to a class and write some GUI components that extract the attributes and order the UI elements appropriately. public class DisplayWrapper { private UnderlyingClass underlyingObject; public DisplayWrapper(UnderlyingClass u) { underlyingObject = u; } [DisplayOrder(1)] public int SomeInt { get { return underlyingObject .SomeInt; } } [DisplayOrder(2)] public DateTime SomeDate { get { return underlyingObject .SomeDate; } } } Thereby ensuring that SomeInt is always displayed before SomeDate when working with my custom GUI components. However you'll see them most commonly used outside of the direct coding environment. For example the Windows Designer uses them extensively so it knows how to deal with custom made objects. Using the BrowsableAttribute like so: [Browsable(false)] public SomeCustomType DontShowThisInTheDesigner { get{/*do something*/} } Tells the designer not to list this in the available properties in the Properties window at design time for example. You could also use them for code-generation pre-compile operations (such as Post-Sharp) or run-time operations such as Reflection.Emit. For example you could write a bit of code for profiling that transparently wrapped every single call your code makes and times it. You could ""opt-out"" of the timing via an attribute that you place on particular methods. public void SomeProfilingMethod(MethodInfo targetMethod object target params object[] args) { bool time = true; foreach (Attribute a in target.GetCustomAttributes()) { if (a.GetType() is NoTimingAttribute) { time = false; break; } } if (time) { StopWatch stopWatch = new StopWatch(); stopWatch.Start(); targetMethod.Invoke(target args); stopWatch.Stop(); HandleTimingOutput(targetMethod stopWatch.Duration); } else { targetMethod.Invoke(target args); } } Declaring them is easy just make a class that inherits from Attribute. public class DisplayOrderAttribute : Attribute { private int order; public DisplayOrderAttribute(int order) { this.order = order; } public int Order { get { return order; } } } And remember that when you use the attribute you can omit the suffix ""attribute"" the compiler will add that for you. For what it's worth this is a list of all (built in) .NET attributes: http://msdn.microsoft.com/en-us/library/aa311259(VS.71).aspx  As said Attributes are relatively easy to create. The other part of the work is creating code that uses it. In most cases you will use reflection at runtime to alter behavior based on the presence of an attribute or its properties. There are also scenarios where you will inspect attributes on compiled code to do some sort of static analysis. For example parameters might be marked as non-null and the analysis tool can use this as a hint. Using the attributes and knowing the appropriate scenarios for their use is the bulk of the work.",c# .net attributes glossary4335,A,High availability Is there anyway to configure a WCF service with a failover endpoint if the primary endpoint dies? Kind of like being able to specify a failover server in a SQL cluster... Specifically I am using the TCP/IP binding for speed but on the rare occurrence that the machine is not available I would like to redirect traffic to the failover server. Not too bothered about losing messages... I'd just prefer not to write the code to handle re-routing! You need to use a layer 4 load balancer in front of the two endpoints. Prob best to stick with a dedicated piece of hardware.  We've had good luck with BigIP as a solution though it's not cheap or easy to set up. One nice feature is it allows you to set up your SSL certificate (and backdoor to the CA) at the load balancer's common endpoint. Then you can use protocols to transfer the requests back to the WCF servers so the entire transmission is encrypted.  Without trying to sound too vague but I think Windows Network Load Balancing (NLB) should handle this for you.  Haven't done it yet with WCF but plan to have a local DNS entry pointing to our Network Load Balancing (NLB) virtual iP address which will direct all traffic to one of our servers hosting services within IIS. I have used NLB for this exact scenario in the past for web sites and see no reason why it will not work well with WCF. The beauty of it is that you can take servers in and out of the virtual cluster at will and NLB takes care of all the ugly re-directing to an available node. It also comes with a great price tag: $FREE with your Windows Server license.,c# .net wcf soa16795,A,"PHPs htmlspecialcharacters equivalent in .NET? PHP has a great function called htmlspecialcharacters() where you pass it a string and it replaces all of HTML's special characters with their safe equivalents it's almost a one stop shop for sanitizing input. Very nice right? Well is there an equivalent in any of the .NET libraries? If not can anyone link to any code samples or libraries that do this well? System.Web.HttpUtility.HtmlEncode(string)  Try this. var encodedHtml = HttpContext.Current.Server.HtmlEncode(...);  Don't know if there's an exact replacement but there is a method HtmlUtility.HtmlEncode that replaces special characters with their HTML equivalents. A close cousin is HtmlUtility.UrlEncode for rendering URL's. You could also use validator controls like RegularExpressionValidator RangeValidator and System.Text.RegularExpression.Regex to make sure you're getting what you want.  Actually you might want to try this method: HttpUtility.HtmlAttributeEncode() Why? Citing the HtmlAttributeEncode page at MSDN docs: The HtmlAttributeEncode method converts only quotation marks ("") ampersands (&) and left angle brackets (<) to equivalent character entities. It is considerably faster than the HtmlEncode method.",c# .net php asp.net17772,A,"Anyone know a quick way to get to custom attributes on an enum value? This is probably best shown with an example. I have an enum with attributes: public enum MyEnum { [CustomInfo(""This is a custom attrib"")] None = 0 [CustomInfo(""This is another attrib"")] ValueA [CustomInfo(""This has an extra flag"" AllowSomething = true)] ValueB } I want to get to those attributes from an instance: public CustomInfoAttribute GetInfo( MyEnum enumInput ) { Type typeOfEnum = enumInput.GetType(); //this will be typeof( MyEnum ) //here is the problem GetField takes a string // the .ToString() on enums is very slow FieldInfo fi = typeOfEnum.GetField( enumInput.ToString() ); //get the attribute from the field return fi.GetCustomAttributes( typeof( CustomInfoAttribute ) false ). FirstOrDefault() //Linq method to get first or null as CustomInfoAttribute; //use as operator to convert } As this is using reflection I expect some slowness but it seems messy to convert the enum value to a string (which reflects the name) when I already have an instance of it. Does anyone have a better way? Have you compared with `Enum.GetName()`? I generally find reflection to be quite speedy as long as you don't dynamically invoke methods. Since you are just reading the Attributes of an enum your approach should work just fine without any real performance hit. And remember that you generally should try to keep things simple to understand. Over engineering this just to gain a few ms might not be worth it.  This is probably the easiest way. A quicker way would be to Statically Emit the IL code using Dynamic Method and ILGenerator. Although I've only used this to GetPropertyInfo but can't see why you couldn't emit CustomAttributeInfo as well. For example code to emit a getter from a property public delegate object FastPropertyGetHandler(object target); private static void EmitBoxIfNeeded(ILGenerator ilGenerator System.Type type) { if (type.IsValueType) { ilGenerator.Emit(OpCodes.Box type); } } public static FastPropertyGetHandler GetPropertyGetter(PropertyInfo propInfo) { // generates a dynamic method to generate a FastPropertyGetHandler delegate DynamicMethod dynamicMethod = new DynamicMethod( string.Empty typeof (object) new Type[] { typeof (object) } propInfo.DeclaringType.Module); ILGenerator ilGenerator = dynamicMethod.GetILGenerator(); // loads the object into the stack ilGenerator.Emit(OpCodes.Ldarg_0); // calls the getter ilGenerator.EmitCall(OpCodes.Callvirt propInfo.GetGetMethod() null); // creates code for handling the return value EmitBoxIfNeeded(ilGenerator propInfo.PropertyType); // returns the value to the caller ilGenerator.Emit(OpCodes.Ret); // converts the DynamicMethod to a FastPropertyGetHandler delegate // to get the property FastPropertyGetHandler getter = (FastPropertyGetHandler) dynamicMethod.CreateDelegate(typeof(FastPropertyGetHandler)); return getter; }",c# .net reflection enums attributes7719,A,"Capture MouseDown event for .NET TextBox Is there any way to capture the MouseDown even from the .NET 2.0 TextBox control? I know the inherited Control class has the event but it's not exposed in TextBox. Is there a way to override the event handler? I also tried the OpenNETCF TextBox2 control which does have the MouseDown event exposed but no matter what I do it doesn't fire the handler. Any suggestions? What kind of crazy mobile device do you have that has a mouse? :) Yes windows mobile does not have an actual mouse but you are mistaken that Windows Mobile .NET does not support the Mouse events. A click or move on the screen is still considered a ""Mouse"" event. It was done this way so that code could port over from full Windows easily. And this is not a Windows Mobile specific issue. The TextBox control on Windows does not have native mouse events either. I just happened to be using Windows Mobile in this case. Edit: And on a side note...as Windows Mobile is built of the WindowsCE core which is often used for embedded desktop systems and Slim Terminal Services clients or ""WinTerms"" it has support for a hardware mouse and has for a long time. Most devices just don't have the ports to plug one in. According to the .Net Framework the MouseDown Event Handler on a TextBox is supported. What happens when you try to run the code? Actually that's only there because it inherits it from ""Control"" as does every other Form control. It is however overridden (and changed to private I believe) in the TextBox class. So it will not show up in IntelliSense in Visual Studio. However you actually can write the code: textBox1.MouseDown += new System.Windows.Forms.MouseEventHandler(this.textBox1_MouseDown); and it will compile and run just fine the only problem is that textBox1_MouseDown() will not be fired when you tap the TextBox control. I assume this is because of the Event being overridden internally. I don't even want to change what's happening on the event internally I just want to add my own event handler to that event so I can fire some custom code as you could with any other event. What kind of crazy mobile device do you have that has a mouse? :) Seriously the reason there is no MouseDown event is because Windows Mobile doesn't have a mouse. What are you trying to do in the MouseDown event handler? Maybe there is another way. I know this answer is way late but hopefully it ends up being useful for someone who finds this. Also I didn't entirely come up with it myself. I believe I originally found most of the info on the OpenNETCF boards but what is typed below is extracted from one of my applications. You can get a mousedown event by implementing the OpenNETCF.Windows.Forms.IMessageFilter interface and attaching it to your application's message filter.  static class Program { public static MouseUpDownFilter mudFilter = new MouseUpDownfilter(); public static void Main() { Application2.AddMessageFilter(mudFilter); Application2.Run(new MainForm()); } } This is how you could implement the MouseUpDownFilter:  public class MouseUpDownFilter : IMessageFilter { List ControlList = new List(); public void WatchControl(Control buttonToWatch) { ControlList.Add(buttonToWatch); } public event MouseEventHandler MouseUp; public event MouseEventHandler MouseDown; public bool PreFilterMessage(ref Microsoft.WindowsCE.Forms.Message m) { const int WM_LBUTTONDOWN = 0x0201; const int WM_LBUTTONUP = 0x0202; // If the message code isn't one of the ones we're interested in // then we can stop here if (m.Msg != WM_LBUTTONDOWN && m.Msg != WM_LBUTTONDOWN) { return false; } // see if the control is a watched button foreach (Control c in ControlList) { if (m.HWnd == c.Handle) { int i = (int)m.LParam; int x = i & 0xFFFF; int y = (i >> 16) & 0xFFFF; MouseEventArgs args = new MouseEventArgs(MouseButtons.Left 1 x y 0); if (m.Msg == WM_LBUTTONDOWN) MouseDown(c args); else MouseUp(c args); // returning true means we've processed this message return true; } } return false; } } Now this MouseUpDownFilter will fire an MouseUp/MouseDown event when they occur on a watched control for example your textbox. To use this filter you add some watched controls and assign to the events it might fire in your form's load event:  private void MainForm_Load(object sender EventArgs e) { Program.mudFilter.WatchControl(this.textBox1); Program.mudFilter.MouseDown += new MouseEventHandler(mudFilter_MouseDown); Program.mudFilter.MouseUp += new MouseEventHandler(mudFilter_MouseUp); } void mudFilter_MouseDown(object sender MouseEventArgs e) { if (sender == textBox1) { // do what you want to do in the textBox1 mouse down event :) } }  is there an 'OnEnter' event that you could capture instead? it'd presumably also capture when you tab into the textbox as well as enter the text box by tapping/clicking on it but if that isn't a problem then this may be a more straightforward work-around  According to the .Net Framework the MouseDown Event Handler on a TextBox is supported. What happens when you try to run the code?  Looks like you're right. Bummer. No MouseOver event. One of the fallbacks that always works with .NET though is P/Invoke. Someone already took the time to do this for the .NET CF TextBox. I found this on CodeProject: http://www.codeproject.com/KB/cs/TextBox_subclassing.aspx Hope this helps  Fair enough. You probably know more than I do about Windows Mobile. :) I just started programming for it. But in regular WinForms you can override the OnXxx event handler methods all you want. A quick look in Reflector with the CF shows that Control TextBoxBase and TextBox don't prevent you from overriding the OnMouseDown event handler. Have you tried this?: public class MyTextBox : TextBox { public MyTextBox() { } protected override void OnMouseDown(MouseEventArgs e) { //do something specific here base.OnMouseDown(e); } }",c# .net events windows-mobile7367,A,"Visual Studio - new ""default"" property values for inherited controls I'm looking for help setting a new default property value for an inherited control in Visual Studio: class NewCombo : System.Windows.Forms.ComboBox { public NewCombo() { DropDownItems = 50; } } The problem is that the base class property DropDownItems has a 'default' attribute set on it that is a different value (not 50). As a result when I drag the control onto a form the designer file gets an explicit mycontrol.DropDownItems = 50; line. At first this doesn't matter. But if later I change my inherited class to DropDownItems = 45; in the constructor this does not affect any of the controls on any form since all those designer files still have the value 50 hard-coded in them. And the whole point was to have the value set in one place so I can deal with the customer changing his mind. Obviously if I were creating my own custom property in the subclass I could give it its own designer default attribute of whatever I wanted. But here I'm wanting to change the default values of properties in the base. Is there any way to apply Visual Studio attributes to a base class member? Or is there some other workaround to get the result I want? In your derived class you need to either override (or shadow using new) the property in question and then re-apply the default value attribute.",c# .net vb.net visual-studio8223,A,Connection Pooling in .NET/SQL Server? Is it necessary or advantageous to write custom connection pooling code when developing applications in .NET with an SQL Server database? I know that ADO.NET gives you the option to enable/disable connection pooling -- does that mean that it's built into the framework and I don't need to worry about it? Why do people talk about writing their own connection pooling software and how is this different than what's built into ADO.NET? I'm no real expert on this matter but I know ADO.NET has its own connection pooling system and as long as I've been using it it's been faultless. My reaction would be that there's no point in reinventing the wheel... Just make sure you close your connections when you're finished with them and everything will be fine! I hope someone else can give you some more firm anwers!  Well it is going to go away as the answer to all these questions will be LINQ. Incidentally we have never needed custom connection pooling for any of our applications so I am not sure what all the noise is about.  The connection pooling built-in to ADO.Net is robust and mature. I would recommend against attempting to write your own version.  With the advent of ADO.Net and the newer version of SQL connection pooling is handled on two layers first through ADO.Net itself and secondly by SQL Server 2005/2008 directly eliminating the need for custom connection pooling. I have been informed that similar support are being planned or have been implemented in Oracle and MySQL out of interest.  My understanding is that the connection pooling is automatically handled for you when using the SqlConnection object. This is purposefully designed to work with MSSQL and will ensure connections are pooled efficiently. You just need to be sure you close them when you are finished with them (and ensure they are disposed of). I have never heard of people needing to roll their own myself. But I admit my experience is kind of limited there.,c# .net sql-server connection-pooling4816,A,"How do you resolve a domain name to an IP address with .NET/C#? How do you resolve a domain name to an IP address with .NET/C#? Try using the System.Net.Dns class  using System.Net; foreach (IPAddress address in Dns.GetHostAddresses(""www.google.com"")) { Console.WriteLine(address.ToString()); }",c# .net dns reverse-dns2209,A,"How can I change the background of a masterpage from the code behind of a content page? I specifically want to add the style of background-color to the <body> tag of a master page from the code behind (C#) of a content page that uses that master page. I have different content pages that need to make the master page has different colors depending on which content page is loaded so that the master page matches the content page's theme. I have a solution below: I'm looking for something more like: Master.Attributes.Add(""style"" ""background-color: 2e6095""); Inside of the page load function of the content page. But I can't get the above line to work. I only need to change the background-color for the <body> tag of the page. I believe you are talking about a content management system. The way I have delt with this situation in the past is to either: Allow a page/content to define an extra custom stylesheet or Allow a page/content to define inline style tags  This is what I came up with: In the page load function: HtmlGenericControl body = (HtmlGenericControl)Master.FindControl(""default_body""); body.Style.Add(HtmlTextWriterStyle.BackgroundColor ""#2E6095""); Where default_body = the id of the body tag.  What I would do for the particular case is: i. Define the body as a server side control <body runat=""server"" id=""masterpageBody""> ii. In your content aspx page register the MasterPage with the register: <% MasterPageFile=""..."" %> iii. In the Content Page you can now simply use Master.FindControl(""masterpageBody"") and have access to the control. Now you can change whatever properties/style that you like!",c# asp.net .net master-pages11804,A,"Returning Large Results Via a Webservice I'm working on a web service at the moment and there is the potential that the returned results could be quite large ( > 5mb). It's perfectly valid for this set of data to be this large and the web service can be called either sync or async but I'm wondering what people's thoughts are on the following: If the connection is lost the entire resultset will have to be regenerated and sent again. Is there any way I can do any sort of ""resume"" if the connection is lost or reset? Is sending a result set this large even appropriate? Would it be better to implement some sort of ""paging"" where the resultset is generated and stored on the server and the client can then download chunks of the resultset in smaller amounts and re-assemble the set at their end? I have seen all three approaches paged store and retrieve and massive push. I think the solution to your problem depends to some extent on why your result set is so large and how it is generated. Do your results grow over time are they calculated all at once and then pushed do you want to stream them back as soon as you have them? Paging Approach In my experience using a paging approach is appropriate when the client needs quick access to reasonably sized chunks of the result set similar to pages in search results. Considerations here are overall chattiness of your protocol caching of the entire result set between client page requests and/or the processing time it takes to generate a page of results. Store and retrieve Store and retrieve is useful when the results are not random access and the result set grows in size as the query is processed. Issues to consider here are complexity for clients and if you can provide the user with partial results or if you need to calculate all results before returning anything to the client (think sorting of results from distributed search engines). Massive Push The massive push approach is almost certainly flawed. Even if the client needs all of the information and it needs to be pushed in a monolithic result set I would recommend taking the approach of WS-ReliableMessaging (either directly or through your own simplified version) and chunking your results. By doing this you ensure that the pieces reach the client can discard the chunk as soon as you get a receipt from the client can reduce the possible issues with memory consumption from having to retain 5MB of XML DOM or whatever in memory (assuming that you aren't processing the results in a streaming manner) on the server and client sides. Like others have said though don't do anything until you know your result set size how it is generated and overall performance to be actual issues.  So it sounds like you'd be interested in a solution that adds 'starting record number' and 'final record number' parameter to your web method. (or 'page number' and 'results per page') This shouldn't be too hard if the backing store is sql server (or even mysql) as they have built in support for row numbering. Despite this you should be able to avoid doing any session management on the server avoid any explicit caching of the result set and just rely on the backing store's caching to keep your life simple.  I somewhat disagree with secretGeek's comment: That's already happening for you -- it's called tcp/ip ;-) Re-implementing that could be overkill. There are times when you may want to do just this but really only from a UI perspective. If you implement some way to either stream the data to the client (via something like a pushlets mechanism) or chunk it into pages as you suggest you can then load some really small subset on the client and then slowly build up the UI with the full amount of data. This makes for a slicker speedier UI (from the user's perspective) but you have to evaluate if the extra effort will be worthwhile... because I don't think it will be an insignificant amount of work.  There's no hard law against 5 Mb as a result set size. Over 400 Mb can be hard to send. You'll automatically get async handlers (since you're using .net) implement some sort of ""paging"" where the resultset is generated and stored on the server and the client can then download chunks of the resultset in smaller amounts and re-assemble the set at their end That's already happening for you -- it's called tcp/ip ;-) Re-implementing that could be overkill. Similarly -- entire resultset will have to be regenerated and sent again If it's MS-SQL for example that is generating most of the resultset -- then re-generating it will take advantage of some implicit cacheing in SQL Server and the subsequent generations will be quicker. To some extent you can get away with not worrying about these problems until they surface as 'real' problems -- because the platform(s) you're using take care of a lot of the performance bottlenecks for you.  The first question that you need to ask yourself is how fast is the network you client and server exist in. If both are inside the same network and it is your standard corporate LAN then you are likely looking at 100 Mbit/s. Most people aren't even going to notice the network delay in these cases so I would say that it is nothing to worry about. .NET should throw an exception if something goes wrong once again network speeds come in to play here as you might be able to just re-download the data without the user noticing. You might want to examine the data to make sure you are only getting the data that you need but if you need all of the data to do the task at hand I don't see why there would be an issue with the size. You might also want to look into compression to see if there are any ways to make it a bit smaller if size and speed are a major issue.",c# .net web-services20168,A,"C# application detected as a virus Regarding the same program as my question a few minutes ago... I added a setup project and built an MSI for the program (just to see if I could figure it out) and it works great except for one thing. When I tried to install it on my parent's laptop their antivirus (the free Avast Home Edition) set off an alarm and accused my setup.exe of being a Trojan. Does anyone have any idea why this would be happening and how I can fix it? The very first thing to do would be to scan your build PC for viruses.  Rebuild the setup file check the exact file size. Check the exact file size of the ""suspected"" setup file. If the source code hasn't changed and the two file sizes are different there's a pretty good chance it got contaminated in transit. I'd do that as a bit of a sanity check first.  I don‰Ûªt know ‰ÛÏAvast‰Û but in Kaspersky if the configuration is set to high almost every installer fires an alarm (iTunes Windows Update everything) especially if the installer modify some registry key or open a port. If avast checks for behavior and your program open a port probably that‰Ûªs be the cause.  I would do what jsight suggested and make sure that your machine did not have a virus. I would also submit the .msi file to Avast's online scanner and see what they identified as being in your package. If that reports your file as containing a trojan contact Avast and ask them to verify that your .msi package does contain a trojan. If it doesn't contain a trojan find out from Avast what triggered their scanner. There may be something in your code that matches a pattern that Avast looks for They may be able to adjust their pattern to ignore your file or you could tweak your code so that it doesn't trigger their scanner.  Indeed boot from a clean CD (use a known good machine to build BartPE or something similar) and scan your machine thoroughly. Another good thing to check though would be exactly which virus Avast! thinks your program is. Once you know that you should be able to look it up in one of the virus databases and insure that your software can't contain it. The odds are that Avast! is just getting a false positive for some reason and I don't know that there's much you can do about that other than contacting Avast! and hoping for a reply. @Justin Bennett: so which of the two alternatives did you choose? Did you contact Avast?",c# .net antivirus944,A,"Unhandled Exception Handler in .NET 1.1 I'm maintaining a .NET 1.1 application and one of the things I've been tasked with is making sure the user doesn't see any unfriendly error notifications. I've added handlers to Application.ThreadException and AppDomain.CurrentDomain.UnhandledException which do get called. My problem is that the standard CLR error dialog is still displayed (before the exception handler is called). Jeff talks about this problem on his blog here and here. But there's no solution. So what is the standard way in .NET 1.1 to handle uncaught exceptions and display a friendly dialog box? Edit: Jeff's response was marked as the correct answer because the link he provided has the most complete information on how to do what's required. AppDomain.UnhandledException is an event not a global exception handler. This means by the time it is raised your application is already on its way down the drain and there is nothing you can do about it except for doing cleanup and error logging. What happened behind the scenes is this: The framework detected the exception walked up the call stack to the very top found no handlers that would recover from the error so was unable to determine if it was safe to continue execution. So it started the shutdown sequence and fired up this event as a courtesy to you so you can pay your respects to your already-doomed process. This happens when an exception is left unhandled in the main thread. There is no single-point solution to this kind of error. You need to put a real exception handler (a catch block) upstream of all places where this error occurs and forward it to (for example) a global handler method/class that will determine if it is safe to simply report and continue based on exception type and/or content. Edit: It is possible to disable (=hack) the error-reporting mechanism built into Windows so the mandatory ""crash and burn"" dialog does not get displayed when your app goes down. However this becomes effective for all the applications in the system not just your own.  Unhandled exception behavior in a .NET 1.x WinForms app depends on: The type of thread that threw the exception Whether it occurred during window message processing Whether a debugger was attached to the process The DbgJitDebugLaunchSetting registry setting The jitDebugging flag in App.Config Whether you overrode the WinForms exception handler Whether you handled the CLR‰Ûªs exception event The phase of the moon The default behaviour of unhandled exceptions is: If the exception occurs on the main thread when pumping window messages it's intercepted by the Windows Forms exception handler. If the exception occurs on the main thread when pumping window messages it will terminate the app process unless it's intercepted by the Windows Forms exception handler. If the exception occurs on a manual threadpool or finalizer thread it's swallowed by the CLR. The points of contact for an unhandled exception are: Windows Forms exception handler. The JIT-debug registry switch DbgJitDebugLaunchSetting. The CLR unhandled exception event. The Windows Form built-in exception handling does the following by default: Catches an unhandled exception when: exception is on main thread and no debugger attached. exception occurs during window message processing. jitDebugging = false in App.Config. Shows dialog to user and prevents app termination. You can disable the latter behaviour by setting jitDebugging = true in App.Config. But remember that this may be your last chance to stop app termination. So the next step to catch an unhandled exception is registering for event Application.ThreadException e.g. : Application.ThreadException += new Threading.ThreadExceptionHandler(CatchFormsExceptions); Note the registry setting DbgJitDebugLaunchSetting under HKEY_LOCAL_MACHINE\Software.NetFramework. This has one of three values of which I'm aware: 0: shows user dialog asking ""debug or terminate"". 1: lets exception through for CLR to deal with. 2: launches debugger specified in DbgManagedDebugger registry key. In Visual Studio go to Tools>Options>Debugging>JIT to set this key to 0 or 2. But a value of 1 is usually best on an end-user's machine. Note that this registry key is acted on before the CLR unhandled exception event. This last event is your last chance to log an unhandled exception. It's triggered before your Finally blocks have executed. You can intercept this event as follows: AppDomain.CurrentDomain.UnhandledException += new System.UnhandledExceptionEventHandler(CatchClrExceptions);  Oh in WinForms you definitely should be able to get it to work. The only thing you have to watch out for is things happening on different threads. I have an old CodeProject article here which should help: http://www.codeproject.com/KB/exception/ExceptionHandling.aspx  It's a WinForms app. The exceptions that are caught by Application.ThreadException work fine and I don't get the ugly .NET exception box (OK to terminate cancel to debug? who came up with that??). I was getting some exceptions that weren't being caught by that and ended up going to the AppDomain.UnhandledException event that were causing problems. I think I've caught most of those exceptions and I am displaying them in our nice error box now. So I'll just have to hope there are not some other circumstances that would cause exceptions to not be caught by the Application.ThreadException handler.  is this a console app or a winforms app? If it's a .NET 1.1 console app this is sadly by design -- it's confirmed by a MSFT dev in the second blog post you referenced: BTW on my 1.1 machine the example from MSDN does have the expected output; it's just that the second line doesn't show up until after you've attached a debugger (or not). In v2 we've flipped things around so that the UnhandledException event fires before the debugger attaches which seems to be what most people expect. Sounds like .NET 2.0 does this better (thank goodness) but honestly I never had time to go back and check.",c# .net exception exception-handling260,A,"Adding scripting functionality to .NET applications I have a little game written in C#. It uses a database as back-end. It's a trading card game and I wanted to implement the function of the cards as a script. What I mean is that I essentially have an interface ICard which a card class implements (public class Card056 : ICard) and which contains function that are called by the game. Now to make the thing maintainable/moddable I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card I'll just add it to the database and tell my application to refresh without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies). Is that possible? Register a class from a source file and then instantiate it etc. ICard Cards[current] = new MyGame.CardLibrary.Card056(); Cards[current].OnEnterPlay(ref currentGameState); The language is C# but extra bonus if it's possible to write the script in any .NET language. @mattytommo No don't have anything left it was in the really early stages and essentially was just working like I outlined above. Nowadays I would look into Roslyn to do C# compilation: http://blogs.msdn.com/b/csharpfaq/archive/2011/10/19/introducing-the-microsoft-roslyn-ctp.aspx - Alternatively JavaScript using Jint - http://jint.codeplex.com/ That's funny me and a friend were thinking of writing a trading card game in C# a while back don't suppose you still have the source for this? Interested on how you'd approached this. ah thanks but I was looking more for the implementation of the trading card game itself and the structure you'd used as opposed to the scripting engine. Thanks anyway :) If you don't want to use the DLR you can use Boo (which has an interpreter) or you could consider the Script.NET (S#) project on CodePlex. With the Boo solution you can choose between compiled scripts or using the interpreter and Boo makes a nice scripting language has a flexible syntax and an extensible language via its open compiler architecture. Script.NET looks nice too though and you could easily extend that language as well as its an open source project and uses a very friendly Compiler Generator (Irony.net).  The main application that my division sells does something very similar to provide client customisations (which means that I can't post any source). We have a C# application that loads dynamic VB.NET scripts (although any .NET language could be easily supported - VB was chosen because the customisation team came from an ASP background). Using .NET's CodeDom we compile the scripts from the database using the VB CodeDomProvider (annoyingly it defaults to .NET 2 if you want to support 3.5 features you need to pass a dictionary with ""CompilerVersion"" = ""v3.5"" to its constructor). Use the CodeDomProvider.CompileAssemblyFromSource method to compile it (you can pass settings to force it to compile in memory only. This would result in hundreds of assemblies in memory but you could put all the dynamic classes' code together into a single assembly and recompile the whole lot when any change. This has the advantage that you could add a flag to compile on disk with a PDB for when you're testing allowing you to debug through the dynamic code.  You might be able to use IronRuby for that. Otherwise I'd suggest you have a directory where you place precompiled assemblies. Then you could have a reference in the DB to the assembly and class and use reflection to load the proper assemblies at runtime. If you really want to compile at run-time you could use the CodeDOM then you could use reflection to load the dynamic assembly. MSDN article which might help.  I'd suggest using LuaInterface as it has fully implemented Lua where it appears that Nua is not complete and likely does not implement some very useful functionality (coroutines etc). If you want to use some of the outside prepacked Lua modules I'd suggest using something along the lines of 1.5.x as opposed to the 2.x series that builds fully managed code and cannot expose the necessary C API.  The next version of .NET (5.0?) has had a lot of talk about opening the ""compiler as a service"" which would make things like direct script evaluation possible. Yes. Although Roslyn is still on the horizon [Mono.CSharp (available on NuGet)](http://blog.davidebbo.com/2012/02/quick-fun-with-monos-csharp-compiler-as.html) packs all the same functionality. I believe this refers to Roslyn? http://en.wikipedia.org/wiki/Microsoft_Roslyn  Oleg Shilo's C# Script solution (at The Code Project) really is a great introduction to providing script abilities in your application. A different approach would be to consider a language that is specifically built for scripting such as IronRuby IronPython or Lua. IronPython and IronRuby are both available today. For a guide to embedding IronPython read How to embed IronPython script support in your existing app in 10 easy steps. Lua is a scripting language commonly used in games. There is a Lua compiler for .NET available from CodePlex -- http://www.codeplex.com/Nua That codebase is a great read if you want to learn about building a compiler in .NET. A different angle altogether is to try PowerShell. There are numerous examples of embedding PowerShell into an application -- here's a thorough project on the topic: Powershell Tunnel By the way I've chosen this as the accepted answer because I wanted to loo at Python and IronPython anyway so the IronPython approach works best for *me*. LuaInterface is a lua interpreter that works fantastic as well. I implemented C# Script in a workflow system in Nov 09. It has performed really well for us.  I didn't try it but I did see an article on Code Project that implements C# scripting in a .NET application. http://www.codeproject.com/KB/cs/cs-script_for_cp.aspx While this link may answer the question it is better to include the essential parts of the answer here and provide the link for reference. Link-only answers can become invalid if the linked page changes.  You could use any of the DLR languages which provide a way to really easily host your own scripting platform. However you don't have to use a scripting language for this. You could use C# and compile it with the C# code provider. As long as you load it in its own AppDomain you can load and unload it to your heart's content.  I'm using LuaInterface1.3 + Lua 5.0 for NET1.1 application. The issue with Boo is that everytime you parse/compile/eval your code on the fly it creates a set of boo classes so you will get memory leaks. Lua in the other hand does not do that so it's very very stable and works wonderful (I can pass objects from C# to Lua and backwards). So far I havent put it in PROD yet but seems very promising. UPDATE: I did have memory leaks issues in PROD using LuaInterface + Lua 5.0 therefore I used Lua 5.2 and linked directly into C# with DllImport. The memory leaks were inside the LuaInterface library. Lua 5.2: from http://luabinaries.sourceforge.net and http://sourceforge.net/projects/luabinaries/files/5.2/Windows%20Libraries/Dynamic/lua-5.2_Win32_dll7_lib.zip/download Once I did this all my memory leaks were gone and the app was very stable.  Yes I thought about that but I soon figured out that another Domain-Specific-Language (DSL) would be a bit too much. Essentially they need to interact with my gamestate in possibly unpredictable ways. For example a card could have a rule ""When this cards enter play all your undead minions gain +3 attack against flying enemies except when the enemy is blessed"". As trading card games are turn based the GameState Manager will fire OnStageX events and let the cards modify other cards or the GameState in whatever way the card needs. If I try to create a DSL I have to implement a rather large feature set and possibly constantly update it which shifts the maintenance work to another part without actually removing it. That's why I wanted to stay with a ""real"" .NET language to essentially be able to just fire the event and let the card manipulate the gamestate in whatever way (within the limits of the code access security). (No need to flag this; while this should be a comment/answer update but is grandfathered in from before those were options)",c# .net scripting compiler21288,A,"Which .NET Dependency Injection frameworks are worth looking into? Which C#/.NET Dependency Injection frameworks are worth looking into? And what can you say about their complexity and speed. [IoC Container Benchmark - Performance comparison](http://www.palmmedia.de/blog/2011/8/30/ioc-container-benchmark-performance-comparison) has performance and features comparison tables for 20+ products and keep them up-to-date. It recommendsåÊ[Simple Injector](http://simpleinjector.codeplex.com/) I appreciate Ninject & Maestro. I'm happy that the top rated answer reffer Ninject as ""an absolute pleasure"" Autofac. http://code.google.com/p/autofac/ It is really fast and pretty good. Here is a link with comparisons (made after Ninject fixed a memory leak issue). http://www.codinginstinct.com/2008/05/ioc-container-benchmark-rerevisted.html Autofac is the first DI container I've really tried out and thus far it's been brilliant. Simple quick and powerful +1 for Autofac. I love it. Is it faster than the others? Or was that a general comment?  I think a good place to start is with Ninject it is new and has taken into account alot of fine tuning and is really fast. Nate the developer really has a great site and great support.  We use Unity from the Microsoft Enterprise Library  I suppose I might be being a bit picky here but it's important to note DI (Dependency Injection) is a programming pattern and is facilitated by (but does not require) an IoC (Inversion of Control) Framework. IoC Frameworks just make DI much easier but it's not only DI that they do they provide a host of other benefits over and above DI. That being said I'm sure that's what you were asking: about IoC Frameworks: I used to use Spring.Net and CastleWindsor a lot but the real pain in the beehiind was all that pesky XML config you had to write! They're pretty much all moving this way now but I started using StructureMap for the last year or so and since it has moved to a fluent config using strongly typed generics and a registry my pain barrier in using IoC has dropped below zero! I get an absolute kick out of knowing now that my IoC config is checked at compile-time (for the most part) and I have had nothing but joy with StructureMap and its speed. I won't say that the others were slow (runtime) but they were more difficult for me to setup and frustration often won the day. I believe they're all moving towards a more strongly typed config now - or at least providing the option but some people love putting all the config in XML - personally I can't bare it so I have stuck to StructureMap now. I can't comment much on Ninject except that I listened to Nate on one of the Herding Code podcasts and he's one switched-on guy and the screencasts I've watched have really tempted me to try it out - maybe on the next project - who knows. Update: In a follow up to my comments here I've been using Ninject (as promised) on my latest project and it has been an absolute pleasure to use. Words fail me a bit here but (as we say in the UK) this framework is the Dogs'. I highly recommend it for any green fields projects where you want to be up and running quickly. I got all I needed from a fantastic set of Ninject screencasts by Justin Etheredge. I also can't see that retro-fitting Ninject into existing (above average) code being a problem at all - but then the same could be said of StructureMap in my experience. It'll be a tough choice going forward between those two but I'd rather have competition than stagnation and there's a decent amount of healthy competition out there. Other IoC screencasts can also be found here on Dimecasts. Hope that helps Rob G It's great to see a quality well thought out answer rise about the one liners. You convinced me to check out StructureMap. Excellent answer with good references I like it! The dog's what? ;) Nice but to be fair - Windsor has a very nice fully-fledged fluent interface now as well. Could you explain what are the ""host of other benefits"" IoC frameworks provide besides easy implementation of DI? If performance is a factor this post provides a regularly updated benchmark for most of them: http://www.palmmedia.de/blog/2011/8/30/ioc-container-benchmark-performance-comparison @fearofawhackplanet one of the only things an IoC container can do that can't be done with *poor man's DI* is **Interception**. Good summary here: http://www.kenneth-truyers.net/2013/05/16/why-choose-di-interception-over-aspect-oriented-programming/  It depends on what you are looking for as they each have their pros and cons. Spring.NET is the most mature as it comes out of Spring from the java world. Spring has a very rich set of framework libraries that extend it to support Web Windows etc. Castle Windsor is one of the most widely used in the .NET platform and has the largest ecosystem is highly configurable / extensible has custom lifetime management AOP support has inherent NHibernate support and is an all around awesome container. Windsor is part of an entire stack which includes Monorail Active Record etc. NHibernate itself builds on top of Windsor. Structure Map has very rich and fine grained configuration through an internal DSL. Autofac is an IoC container of the new age with all of it's inherent functional programming support. It also takes a different approach on managing lifetime than the others. Autofac is still very new but it pushes the bar on what is possible with IoC. Ninject I have heard is more bare bones with a less is more approach (heard not experienced). The biggest discriminator of Unity is it's from and supported by Microsoft (p&p). Unity has very good performance and great documentation. It is also highly configurable. It doesn't have all the bells and whistles of say Castle / Structure Map. So in summary it really depends on what is important to you. I would agree with others on going and evaluating and seeing which one fits. The nice thing is you have a nice selection of donuts rather than just having to have a jelly one. :-) Good description. I would stay away from Unity though as it's simply a PITA to use. Autofac is actually not so new it is older than Unity :) Did I say it was newer than Unity? I said it is of the new age...ie I meant it's functional nature. OK what I said it's still very new what I meant though was it's nature not that IT was new. :-) @Krzysztof - I find Unity dead easy (at least when configured fluently in code). What did you find painful? That's funny considering Unity does not have fluent API :D @Krzysztof - [Using the UnityContainer Fluent Interface](http://msdn.microsoft.com/en-us/library/ff660904%28v=PandP.20%29.aspx) Here's an interesting performance benchmark: http://www.palmmedia.de/Blog/2011/8/30/ioc-container-benchmark-performance-comparison  Spring.Net is quite solid but the documentation took some time to wade through. Autofac is good and while .Net 2.0 is supported you need VS 2008 to compile it or else use the command line to build your app.  I've used Spring.NET in the past and had great success with it. I never noticed any substantial overhead with it though the project we used it on was fairly heavy on its own. It only took a little time reading through the documentation to get it set up.  I haven't used any other DI frameworks besides Unity from the Microsoft Patterns & Practices group but I was pretty surprised at how lightweight it seems. There's a great screencast that outlines the common usages and had me up to speed in under 30 minutes.  I use the Simple Service Locator. The Simple Service Locator is an easy-to-use Dependency Injection library that is a complete implementation of the Common Service Locator interface. It solely supports code-based configuration and is an ideal starting point for developers unfamiliar with larger DI libraries. Simple Injector project. Beware some consider the service locator an anti-pattern including someone who used it for some time and even wrote a library for it: http://blog.ploeh.dk/2010/02/03/ServiceLocatorisanAnti-Pattern/  Ninject is great. It seems really fast but I haven't done any comparisons. I know Nate the author did some comparisons between Ninject and other DI frameworks and is looking for more ways to improve the speed of Ninject. I've heard lots of people I respect say good things about StructureMap and CastleWindsor. Those in my mind are the big three to look at right now.  I'm a huge fan of Castle. I love the facilities it also provides beyond the IoC Container story. It really simplfies using NHibernate logging AOP etc. I also use Binsor for configuration with Boo and have really fallen in love with Boo as a language because of it.  I spent the better part of a day struggling without success to get the simplest Spring.NET example working. Could never figure out how to get it to find my assembly from the XML file. In about 2 hours on the other hand I was able to get Ninject working including testing integration with both NUnit and MSTest.  I can recommend Ninject. It's incredibly fast and easy to use but only if you don't need XML configuration else you should use Windsor.  The great thing about C# is that it is following a path beaten by years of Java developers before it. So my advice generally speaking when looking for tools of this nature is to look for the solid Java answer and see if there exists a .NET adaptation yet. So when it comes to DI (and there are so many options out there this really is a matter of taste) is Spring.NET. Additionally it's always wise to research the people behind projects. I have no issue suggesting SourceGear products for source control (outside of using them) because I have respect for Eric Sink. I have seen Mark Pollack speak and what can I say the guy just gets it. In the end there are a lot of DI frameworks and your best bet is to do some sample projects with a few of them and make an educated choice. Good luck!",c# .net dependency-injection inversion-of-control23391,A,"Increases Skills what should I learn? My path to a 'fulltime'- developer stated as a analyst using VBA with Excel Access and then onto C#. I went to college part time once I discovered I had a passion for coding not business. I do about most of my coding in C# but being an ASP.NET developer I also write in HTML JavaScript SQL etc. . . the usual suspects. I like to keep moving forward find the edge that will get me to the next level the next job and of course more money. Most importantly I just want to learning something new and challenge me. I have spent time recently learning LINQ but was wondering what should I learn next? Something on the .NET Framework or a new language technology? As you continue to gain more experience in ASP.Net C# etc - it's always good to go check out the competition and see if it sparks ideas on how you can do things better in what you're doing. Taking a look at something like Rails or Django might change how you look at designing or building your apps.  @ Michael DSL=Domain Specific Language As for what you should learn that depends on what you're interested in. Are you looking to challenge yourself while staying in the same medium (web-centric applications)? I would suggest learning about Apache and the LAMP (Linux Apache MySQL PHP) architecture and challenge yourself to build a web application that you could readily build with ASP .NET using it. Want to learn something completely different? Try Prolog or LISP and see what you can do with those. Maybe you'd like to get into embedded software? Learn C to start. You have a wide variety of ways to improve your skills and each one has career paths attached to them. (Well maybe not Prolog but it's fun!)  The more languages you know the more marketable you are. Look and see what the more popular (market for not fan base) languages are then add on some cutting edge tech that is not in much use yet rounded out by general programming skill. With your skill set I would recommend (as far as languages): Java as a starting point For .Net add in the .Net MVC (you have LINQ or that would be here also) Language agnostic skills: Design Patterns (includes the MVC) Domain Driven Design Test Driven Design  Yeah the more I get into software I start to see myself focusing less on the language and more on the design.. Yeah there are framework bits we need to get our head around but most of the time ( most not all ) you can look those up as-and-when you need them.. But a good design head? That takes years of experience to start getting it working right.. And that is what the companies really pay for.. ""Build it and they will come"" and all that...  Here would be my suggestions: 1) Design Patterns - These are really neat as well as being very useful in some situations. 2) AJAX - Assuming you haven't already done some of this it is an interesting part of Web Development from my view. 3) Determine which parts of the chain do you enjoy the most: Front-end work(HTML CSS Javascript) middleware(C# for business logic parts) or back-end(MS-SQL with stored procedures indexes triggers and all that stuff). If it is all of it then try to stay where the team doing web development is small as otherwise you may be asked to choose. 4) Algorithm design and analysis - Do you know various sorting algorithms? Do you know various techniques to create an algorithm e.g. greedy recursion divide and conquer dynamic programming using custom data types like heap in heapsort etc. This can be new and cool. 5) Determine if there is a part of the development process you favor: Analyst designer programmer tester debugger? All can have varying degrees of being near the code IMO.  If you want to be one of the best you need to specialise. If you become very good in many skills then you may never become truly excellent in one. I know because I have taken this route myself and have found it difficult to get employment at times. After all who wants someone who is capable at many languages when there is someone who excels at the specific thing they need. If a company develops in C# then who would want someone who is OK at C# but also is good at C Visual Basic Perl and Cobol when all they really want is the best possible C# developer for the money they can afford. After all you will only ever be employed for one maybe two of your skills. There are very few jobs for people who are good in 10 or 15 skills. If you are looking to a new skill then maybe check out the job boards and find which skills are particularly in need but be aware that what is the flavour of the month this year may not even be on the scene next year which will make all of that effort to learn the skill futile and wasted. What I would say is: do one thing and do it well. This may include supporting skills (C# ASP.Net SQL LINQ etc). If you want to choose something else then choose something complementary. Possibly most importantly choose something you will enjoy. Maybe Ruby on Rails is the current flavour of the month but if you don't enjoy doing it then don't do it. Really it's not worth it. You will never wish on your death bed that you had worked more in something you didn't enjoy. Another direction you could look at is maybe not for a particular development skill but look for something else maybe soft skills like people management better business understanding or even look to something like literary skills to help improve your communications skills. All of these will help to allow you to do what you want to do more and cut down on the stuff you really don't enjoy thus helping to make your job more enjoyable. Apologies for the waffling here. Hope you are still awake :) Although I agree that you should focus on a particular language I still think that if you are versed in lower level languages such as C and C++ it will make you a better programmer in higher level languages such as C# or Java...so I still think that you should at least try to learn other languages. Other than that not every language is suitable for every particular job so the more the know the more you can apply for specific tasks...which in turn will make you more productive and ofcourse employers like that. I agree that specialization is important but I don't entirely agree with you. I worked in the data capture group at an analytics company and our group had SDK's for all the mobile platforms (there's 3 languages and 4 runtime environments alone) as well as projects in C# C++ Java and JavaScript. Any developer with truly good fundamentals should be able to become proficient in any language/runtime fairly quickly. I still think you should specialize but a deep understanding of software is more valuable than know .NET well for example. I would still encourage people to learn many languages.  Why don't you swap stacks and look at the LAMP stack? Or how about a functional language like haskell? Or write a DSL? Or an app for your phone? What is the point of swapping the stack? Whichever that is?  Maybe learn more about Usability (best practices testing etc.) if you haven't already done so. Steve Krug's ""Don't Make Me Think"" is a good book to start with. Jakob Nielsen always has interesting stuff as well.  If you're now proficient with the languages and technologies you use then start spending more time focusing on the design solution architecture and systems integration. The ""bigger picture"" that will set you apart from your contemporaries. Check out some Martin Fowler books like ""Patterns of Enterprise Application Architecture"" or Eric Evans' ""Domain-Driven Design"".  Check out OOAD & UML maybe... Ooo! And DDD - definitely. (Yes I just had to throw in the obligatory Wikipedia links! It is my first time doing so and now I feel dirty!)",c# .net22012,A,"Loading assemblies and its dependencies My application dynamically loads assemblies at runtime from specific subfolders. These assemblies are compiled with dependencies to other assemblies. The runtime trys to load these from the application directory. But I want to put them into the modules directory. Is there a way to tell the runtime that the dlls are in a seperate subfolder? One nice approach I've used lately is to add an event handler for the AppDomain's AssemblyResolve event. AppDomain currentDomain = AppDomain.CurrentDomain; currentDomain.AssemblyResolve += new ResolveEventHandler(MyResolveEventHandler); Then in the event handler method you can load the assembly that was attempted to be resolved using one of the Assembly.Load Assembly.LoadFrom overrides and return it from the method. EDIT: Based on your additional information I think using the technique above specifically resolving the references to an assembly yourself is the only real approach that is going to work without restructuring your app. What it gives you is that the location of each and every assembly that the CLR fails to resolve can be determined and loaded by your code at runtime... I've used this in similar situations for both pluggable architectures and for an assembly reference integrity scanning tool. A good example of this technique is the application LINQPad. It ships as a single exe so all the libraries are included as embedded resources. See http://www.albahari.com/nutshell/ch16.aspx for code and http://www.linqpad.net/HowLINQPadWorks.aspx for insight.  You can use the <probing> element in a manifest file to tell the Runtime to look in different directories for its assembly files. http://msdn.microsoft.com/en-us/library/823z9h8w.aspx e.g.: <configuration> <runtime> <assemblyBinding xmlns=""urn:schemas-microsoft-com:asm.v1""> <probing privatePath=""bin;bin2\subbin;bin3""/> </assemblyBinding> </runtime> </configuration>  You can use the <codeBase> element found in the application configuration file. More information on ""Locating the Assembly through Codebases or Probing"". Well the loaded assembly doesn't have an application configuration file. Well if you know the specific folders at runtime you can use Assembly.LoadFrom.",c# .net20467,A,"Path Display in Label Are there any automatic methods for trimming a path string in .NET? For example: C:\Documents and Settings\nick\My Documents\Tests\demo data\demo data.emx becomes C:\Documents...\demo data.emx It would be particularly cool if this were built into the Label class and I seem to recall it is--can't find it though! Not hard to write yourself though:  public static string TrimPath(string path) { int someArbitaryNumber = 10; string directory = Path.GetDirectoryName(path); string fileName = Path.GetFileName(path); if (directory.Length > someArbitaryNumber) { return String.Format(@""{0}...\{1}"" directory.Substring(0 someArbitaryNumber) fileName); } else { return path; } } I guess you could even add it as an extension method.  What you are thinking on the label is that it will put ... if it is longer than the width (not set to auto size) but that would be c:\Documents and Settings\nick\My Doc... If there is support it would probably be on the Path class in System.IO  You could use the System.IO.Path.GetFileName method and append that string to a shortened System.IO.Path.GetDirectoryName string.  Use TextRenderer.DrawText with TextFormatFlags.PathEllipsis flag void label_Paint(object sender PaintEventArgs e) { Label label = (Label)sender; TextRenderer.DrawText(e.Graphics label.Text label.Font label.ClientRectangle label.ForeColor TextFormatFlags.PathEllipsis); } Your code is 95% there. The only problem is that the trimmed text is drawn on top of the text which is already on the label. Yes thanks I was aware of that. My intention was only to demonstrate use of DrawText method. I didn't know whether you want to manually create event for each label or just override OnPaint() method in inherited label. Thanks for sharing your final solution though.  @ lubos hasko Your code is 95% there. The only problem is that the trimmed text is drawn on top of the text which is already on the label. This is easily solved:  Label label = (Label)sender; using (SolidBrush b = new SolidBrush(label.BackColor)) e.Graphics.FillRectangle(b label.ClientRectangle); TextRenderer.DrawText( e.Graphics label.Text label.Font label.ClientRectangle label.ForeColor TextFormatFlags.PathEllipsis);",c# .net winforms path752,A,"Get a new object instance from a Type One may not always know the Type of an object at compile-time but may need to create an instance of the Type. How do you get a new object instance from a Type? The Activator class within the root System namespace is pretty powerful. There are a lot of overloads for passing parameters to the constructor and such. Check out the documentation at: http://msdn.microsoft.com/en-us/library/system.activator.createinstance.aspx Here are some simple examples: ObjectType instance = (ObjectType)Activator.CreateInstance(objectType); ObjectType instance = (ObjectType)Activator.CreateInstance(""MyNamespace.ObjectType MyAssembly""); Exactly! Thanks Karl! Glad to have finally found this but second call is not exactly right missing a quote and parms reversed should be: ObjectType instance = (ObjectType)Activator.CreateInstance(""MyAssembly""""MyNamespace.ObjectType""); You need to call 'Unwrap()' to get the actual type of object you want: ConcreteType instance = (ConcreteType)Activator.CreateInstance(objectType).Unwrap();  ObjectType instance = (ObjectType)Activator.CreateInstance(objectType); The Activator class has a generic variant that makes this a bit easier:  ObjectType instance = Activator.CreateInstance<ObjectType>(); I was drawn to this question because I recently needed to create boxed value types of an unknown `Type t` in order to use reflection's `FieldInfo.SetValue(object)` to populate field members of a struct or class that hold value types (int char enum etc.) To do this I used `Type t = FieldInfo.FieldType` to determine the field type then created the proper boxed `object` using `Convert.ChangeType(value t)` where `value` is a `ulong`. For enums (where `t.IsEnum`) I use `Enum.ToObject(t value)`. I suppose this is really just a cast-and-box not a `new()`. :-) @Kevin Of course. Such an operation *can‰Ûªt* work in a statically typed language because it doesn‰Ûªt make sense. You cannot invoke methods on an object of unknown type. In the meantime (= since writing this answer) C# has got the `dynamic` construct which *does* allow such constructs but for most purposes this answer still covers it. Except this doesn't work for runtime `Type t`.  If you want to use the default constructor then the solution using System.Activator presented earlier is probably the most convenient. However if the type lacks a default constructor or you have to use a non-default one then an option is to use reflection or System.ComponentModel.TypeDescriptor. In case of reflection it is enough to know just the type name (with its namespace). Example using reflection: ObjectType instance = (ObjectType)System.Reflection.Assembly.GetExecutingAssembly().CreateInstance( typeName: objectType.FulName // string including namespace of the type ignoreCase: false bindingAttr: BindingFlags.Default binder: null // use default binder args: new object[] { args to constructor } culture: null // use CultureInfo from current thread activationAttributes: null ); Example using TypeDescriptor: ObjectType instance = (ObjectType)System.ComponentModel.TypeDescriptor.CreateInstance( provider: null // use standard type description provider which uses reflection objectType: objectType argTypes: new Type[] { types of args } args: new object[] { args to constructor } );  Wouldnt the generic ""new T();"" work? Actually it would in a generic class/method but not for a given ""Type"".  If this is for something that will be called a lot in an application instance it's a lot faster to compile and cache dynamic code instead of using the activator or ConstructorInfo.Invoke(). Two easy options for dynamic compilation are compiled Linq Expressions or some simple IL opcodes and DynamicMethod. Either way the difference is huge when you start getting into tight loops or multiple calls.   public AbstractType New { get { return (AbstractType) Activator.CreateInstance(GetType()); } }  tags2k: If the issue is that the class is throwing an exception on instantiation this will also be thrown when default(T) is called This is not true. default() does not call constructors it initializes to null for reference types (classes) 0 for value types (eg. ints) and initializes each member of a struct to one of null or 0 based on the same rules. You're right but I don't think commenting was available in 2008 when this answer was written :P This is more a comment than an answer. Ah ok then. I tried to remove my downvote but it won't take it. Sorry.  One implementation of this problem is to attempt to call the parameter-less constructor of the Type:  public static object GetNewObject(Type t)  {  try  {  return t.GetConstructor(new Type[] { }).Invoke(new object[] { });  }  catch  {  return null;  }  } Here is the same approach contained in a generic method:  public static T GetNewObject<T>()  {  try  {  return (T)typeof(T).GetConstructor(new Type[] { }).Invoke(new object[] { });  }  catch  {  return default(T);  }  } Exception driven programming? This seems like a very poor implementation when you can simply reflect over the type to determine constructors.",c# .net reflection9508,A,C# 2.0 code consuming assemblies compiled with C# 3.0 This should be fine seeing as the CLR hasn't actually changed? The boxes running the C# 2.0 code have had .NET 3.5 rolled out. The background is that we have a windows service (.NET 2.0 exe built with VS2005 deployed to ~150 servers) that dynamically loads assemblies (almost like plug-ins) to complete various work items asked of it. Whenever we roll out a new version of the bus logic we just drop the assemblies on an FTP server and the windows service knows how to check for grab and store the latest versions. New assemblies are now built using VS2008 and targetting .NET 2.0 we know that works ok. However we'd like to start taking advantage of C# 3.0 language features such as LINQ and targetting the assemblies against .NET 3.5 without having to build and deploy a new version of the windows service. C#3 and .Net 3.5 adds new assemblies but the IL is unchanged. This means that with .Net 2 assemblies you can compile and use C#3 as long as you don't use Linq or anything else that references System.Linq or System.Core yield var lambda syntax anon types and initialisers are all compiler cleverness. The IL they produce is cross-compatible. If you can reference the new assemblies for 3.5 it should all just work. There is no new version of ASP.Net - it should still be 2.0.50727 - but you should still compile for 3.5  yield var lambda syntax anon types and initialisers are all compiler cleverness. The IL they produce is cross-compatible. Minor nit-picking point but yield was a 2.0 feature anyway.  This is interesting stuff. I was looking at LinqBridge yesterday after someone on this forum suggested it to me and they are doing a similar thing. I find it strange that Microsoft named the frameworks 2.0 3.0 and 3.5 when they all compile down to produce the same IL required by the 2.0 CLR. I would have thought adding versions onto 2.0 would have made more sense altho I suppose it also is hard to get people to get their head around the fact that there are different versions of runtimes compilers and languages.,c# .net .net-3.59304,A,"C# 3.0 auto-properties - useful or not? Note: This was posted when I was starting out C#. With 2014 knowledge I can truly say that auto-properties are among the best things that ever happened to the C# language. I am used to create my properties in C# using a private and a public field: private string title; public string Title { get { return title; } set { title = value; } } Now with .NET 3.0 we got auto-properties: public string Title { get; set; } I know this is more a philosophical/subjective questions but is there any reason to use these auto-properties except from saving five lines of code for each field? My personal gripe is that those properties are hiding stuff from me and I am not a big fan of black magic. In fact the hidden private field does not even show up in the debugger which is OK given the fact that the get/set functions do nothing. But when I want to actually implement some getter/setter logic I have to use the private/public pair anyway. I see the benefit that I save a lot of code (one vs six lines) without losing the ability to change the getter/setter logic later but then again I can already do that by simply declaring a public field ""Public string Title"" without the need of the { get; set; } block thus even saving more code. So what am I missing here? Why would anyone actually want to use auto-properties? ""My personal gripe is that those properties are hiding stuff from me and I am not a big fan of black magic."" Huh? You ARE aware that the compiler hides a ton from you all the time right? Unless you are writing assembly (or more accurately the actual 1's and 0's for your code) EVERYTHING you write is hiding stuff from you. Well with code snippets an auto-property of the same name would be seven keystrokes in total ;)  @Domenic : I don't get it.. can't you do this with auto-properties?: public string Title { get; } or public string Title { get; private set; } Is this what you are referring to? Word of caution only structs are immutable when flagged readonly classes are just unassignable. You can (the latter; the former will not compile) but then the field is not immutable inside your object.  I think any construct that is intuitive AND reduces the lines of code is a big plus. Those kinds of features are what makes languages like Ruby so powerful (that and dynamic features which also help reduce excess code). Ruby has had this all along as: attr_accessor :my_property attr_reader :my_getter attr_writer :my_setter  One thing to note here is that to my understanding this is just syntactic sugar on the C# 3.0 end meaning that the IL generated by the compiler is the same. I agree about avoiding black magic but all the same fewer lines for the same thing is usually a good thing.  I use auto-properties all the time. Before C#3 I couldn't be bothered with all the typing and just used public variables instead. The only thing I miss is being able to do this: public string Name = ""DefaultName""; You have to shift the defaults into your constructors with properties. tedious :-( ~ I know this is like a dollar late and a day short but try http://msdn.microsoft.com/en-us/library/system.componentmodel.defaultvalueattribute.aspx @Matthew Whited ~ Good call must not have noticed the glaring yellow box because I use the scriptfree it blended in but c'est la vie ... @drachenstern check out the big yellow box on that page. DefaultValueAttribute only gives you something that can be used by reflection to tell what the default value should be. It doesn't set the value for you.  From Bjarne Stroustrup creator of C++: I particularly dislike classes with a lot of get and set functions. That is often an indication that it shouldn't have been a class in the first place. It's just a data structure. And if it really is a data structure make it a data structure. An you know what? He's right. How often are you simply wrapping private fields in a get and set without actually doing anything within the get/set simply because it's the ""object oriented"" thing to do. This is Microsoft's solution to the problem; they're basically public fields that you can bind to.  We use them all the time in Stack Overflow. You may also be interested in a discussion of Properties vs. Public Variables. IMHO that's really what this is a reaction to and for that purpose it's great.  Yes it does just save code. It's miles easier to read when you have loads of them. They're quicker to write and easier to maintain. Saving code is always a good goal. You can set different scopes: public string PropertyName { get; private set; } So you don't lose any functionality. In the original posters example how do you find when myObj.Title is changing from one value to another? we may need to take this outside Keith. :) But ok assume you have many setter calls to myObj.Title...you want to see where the value changes from ""text"" to null ie a conditional breakpoint. how do u acheive that? you cant even set a breakpoint on the setter @wal - You can put a breakpoint on them just like you can access of a member variable you just can't step into them. But why would you want to? What the auto-properties actually do is both trivial and auto-generated if you've got bugs that's one place they're extremely unlikely to be. ""So you don't lose any functionality."" how do you debug them? @wal - what's there to debug? From that point of view you're basically dealing with member variables. Just wondering about the readonly ""private set"" its cool thanks.  I always create properties instead of public fields because you can use properties in an interface definition you can't use public fields in an interface definition.  Auto-properties are as much a black magic as anything else in C#. Once you think about it in terms of compiling down to IL rather than it being expanded to a normal C# property first it's a lot less black magic than a lot of other language constructs.  I use CodeRush it's faster than auto-properties. To do this:  private string title; public string Title { get { return title; } set { title = value; } } Requires eight keystrokes total. If I hold down CTRL and V I can paste lots and lots of stuff /really quickly/ but that doesn't make it 'better'. How does this answer the original question?  I personally love auto-properties. What's wrong with saving the lines of code? If you want to do stuff in getters or setters there's no problem to convert them to normal properties later on. As you said you could use fields and if you wanted to add logic to them latter you'd convert them to properties. But this might present problems with any use of reflection (and possibly elsewhere?). Also the properties allow you to set different access levels for the getter and setter which you can't do with a field. I guess it's the same as the var keyword. A matter of personal preference.  One thing nobody seems to have mentioned is how auto-properties are unfortunately not useful for immutable objects (usually immutable structs). Because for that you really should do: private readonly string title; public string Title { get { return this.title; } } (where the field is initialized in the constructor via a passed parameter and then is read only.) So this has advantages over a simple get/private set autoproperty. @Keith: Your first sentence seems factually incorrect. If you have a struct changing any property on it results in a new struct. This would only be an issue if you wanted an internally immutable reference type - I can't see a reason why you ever would need one. @Domenic: I think he's confining his definition of structs to immutable ones. Wouldn't `public string Title { get; private set; }` kind of result in exactly the same thing? You would be able to change it from inside the class then of course but if you do that you have other problems... :p The idea is defensive coding. @Domenic: No problems like working on a team where the developers do stuff they shouldn't do. Like ""hey I know this is supposed to be an immutable object but let's just mutate this one variable to get this to work""-kind of thing... I just mean that from an outside API kind of view it wouldn't make much difference. And so auto-properties could be used if wanted. Best thing would of course be if you could do something like `public string Title { get; private readonly set; }` @zooone9243 Yeah and like i said if we can't stop ourselves from setting a value inside a class that should be immutable then we have different problems. @Svish: problems like working on a team consisting of programmers of different skill levels? @Svish it is not exactly the same thing because a readonly field can only be set on construction or declaration where as a private setter can be set on non-constructor methods in the same class as well. @Svish - by that argument the readonly keyword in C# should never be used because its use would mean that we were hiding these ""different problems"" I sometimes split .NET types into 2 groups:The types that can be written in .NET (`HttpRequest` `Button`) and those that can only be written below .NET and have a .NET ""interface"" so we can use them (`object` `Thread`).One might think that `BinaryFormatter` is of the later type. Well it isn't.Anyone could rewrite it in C#.It becomes clear that readonly fields MUST be updatable at any given time because deserializing a graph would otherwise require magic since in the general case there's no certain relation between ctor params and readonly fields: `FormatterServices.PopulateObjectMembers`  In my opinion you should always use auto-properties instead of public fields. That said here's a compromise: Start off with an internal field using the naming convention you'd use for a property. When you first either need access to the field from outside its assembly or need to attach logic to a getter/setter Do this: rename the field make it private add a public property Your client code won't need to change. Someday though your system will grow and you'll decompose it into separate assemblies and multiple solutions. When that happens any exposed fields will come back to haunt you because as Jeff mentioned changing a public field to a public property is a breaking API change.  It's simple it's short and if you want to create a real implementation inside the property's body somewhere down the line it won't break your type's external interface. As simple as that.  My biggest gripe with auto-properties is that they are designed to save time but I often find I have to expand them into full blown properties later. What VS2008 is missing is an Explode Auto-Property refactor. The fact we have an encapsulate field refactor makes the way I work quicker to just use public fields.  The three big downsides to using fields instead of properties are: You can't databind to a field whereas you can to a property If you start off using a field you can't later (easily) change them to a property There are some attributes that you can add to a property that you can't add to a field ""If you start off using a field you can't later (easily) change them to a property"" sorry but why ? @Homam Mainly any consumer code that uses reflection on your fields would break since they would have to switch from using FieldInfo to PropertyInfo. @Homam Also changing a field to a property breaks binary compatability requiring all consumers of the field to recompile. recompilation & reflection issues aside it's very easy to encapsulate fields using Visual Studio: Ctrl-R+E will allow you to turn a field into a property with appropriate getters/setters. (or right-click the field re-factor encapsulate field).  The only problem I have with them is that they don't go far enough. The same release of the compiler that added automatic properties added partial methods. Why they didnt put the two together is beyond me. A simple ""partial On<PropertyName>Changed"" would have made these things really really useful. You can put multiple partial methods inside of another method. Creating an auto-pattern of some sort for them would be confusing.",c# .net automatic-properties6325,A,"Why are unsigned int's not CLS compliant? Why are unsigned integers not CLS compliant? I am starting to think the type specification is just for performance and not for correctness. Part of the issue I suspect revolves around the fact that unsigned integer types in C are required to behave as members of an abstract algebraic ring rather than as numbers [meaning for example that if an unsigned 16-bit integer variable equals zero decrementing it is required to yield 65535 and if it's equal to 65535 then incrementing it is required to yield zero.] There are times when such behavior is extremely useful but numeric types exhibit such behavior may have gone against the spirit of some languages. I would conjecture that the decision to omit unsigned types probably predates the decision to support both checked and unchecked numeric contexts. Personally I wish there had been separate integer types for unsigned numbers and algebraic rings; applying a unary minus operator to unsigned 32-bit number should yield a 64-bit signed result [negating anything other than zero would yield a negative number] but applying a unary minus to a ring type should yield the additive inverse within that ring. In any case the reason unsigned integers are not CLS compliant is that Microsoft decided that languages didn't have to support unsigned integers in order to be considered ""CLS compatible"".  Unsigned integers are not CLS compliant because they're not interoperable between certain languages.  Not all languages have the concept of unsigned ints. For example VB 6 had no concept of unsigned ints which I suspect drove the decision of the designers of VB7/7.1 not to implement as well (it's implemented now in VB8). To quote: http://msdn.microsoft.com/en-us/library/12a7a7h3.aspx The CLS was designed to be large enough to include the language constructs that are commonly needed by developers yet small enough that most languages are able to support it. In addition any language construct that makes it impossible to rapidly verify the type safety of code was excluded from the CLS so that all CLS-compliant languages can produce verifiable code if they choose to do so. Update: I did wonder about this some years back and whilst I can't see why a UInt wouldn't be type safety verifiable I guess the CLS guys had to have a cut off point somewhere as to what would be the baseline minimum number of value types supported. Also when you think about the longer term where more and more languages are being ported to the CLR why force them to implement unsigned ints to gain CLS compliance if there is absolutely no concept ever? @Kevin: I just wondered about the topic. You answer seems logic. I just like to think about the topic. I think it's a shame Pascal-like types didn't make it into the CLR. But your argument about other languages: that didn't stop IronPython using strongly dynamic typing (DLR) in an stongly static typed CLR? @doekman: Whilst yes IronPython and IronRuby demonstrates that the CLR can provide a platform onto which you can build dynamically typed languages the goal of the CLS was to provide a set of standards that transcend language functionality and allow them to interoperate sucessfully and safely. I don't think what a language can do in terms of say adding DL features is directly related to the what should go into the CLS/CTS.  Unsigned int's don't gain you that much in real life however having more than 1 type of int gives you pain so a lot of languages only have singed ints. CLS compliant is aimed at allowing a class to be made use of from lots of languages‰Û_ @nicodemus13 when is the last time that you saw a business admin system that had bit-wise arithmetic in its problem domain? (E.g. the sort of software that VB.NET programmers write) Anything with a checksum will use bit-wise arithmetic that's fairly common and it seems odd to me to drag every other language down because VB didn't support unsigned integers. .NET is meant to be generic as well not just for VB-writers of LOB apps. When you say '1 type of int' you don't think having byte short int long is also a pain? I don't quite see why signing is any more awkward. They're pretty-much essential if you're doing any bit-wise arithmetic.",c# .net unsigned-integer cls-compliant14731,A,"UrlEncode through a console application? Normally I would just use: HttpContext.Current.Server.UrlEncode(""url""); But since this is a console application HttpContext.Current is always going to be null. Is there another method that does the same thing that I could use? I ran into this problem myself and rather than add the System.Web assembly to my project I wrote a class for encoding/decoding URLs (its pretty simple and I've done some testing but not a lot). I've included the source code below. Please: leave the comment at the top if you reuse this don't blame me if it breaks learn from the code. ''' <summary> ''' URL encoding class. Note: use at your own risk. ''' Written by: Ian Hopkins (http://www.lucidhelix.com) ''' Date: 2008-Dec-23 ''' </summary> Public Class UrlHelper Public Shared Function Encode(ByVal str As String) As String Dim charClass = String.Format(""0-9a-zA-Z{0}"" Regex.Escape(""-_.!~*'()"")) Dim pattern = String.Format(""[^{0}]"" charClass) Dim evaluator As New MatchEvaluator(AddressOf EncodeEvaluator) ' replace the encoded characters Return Regex.Replace(str pattern evaluator) End Function Private Shared Function EncodeEvaluator(ByVal match As Match) As String ' Replace the "" ""s with ""+""s If (match.Value = "" "") Then Return ""+"" End If Return String.Format(""%{0:X2}"" Convert.ToInt32(match.Value.Chars(0))) End Function Public Shared Function Decode(ByVal str As String) As String Dim evaluator As New MatchEvaluator(AddressOf DecodeEvaluator) ' Replace the ""+""s with "" ""s str = str.Replace(""+""c "" ""c) ' Replace the encoded characters Return Regex.Replace(str ""%[0-9a-zA-Z][0-9a-zA-Z]"" evaluator) End Function Private Shared Function DecodeEvaluator(ByVal match As Match) As String Return """" + Convert.ToChar(Integer.Parse(match.Value.Substring(1) System.Globalization.NumberStyles.HexNumber)) End Function End Class Seems to work. Thanks. downvoted... writing your own code so you can avoid a reference to a standard lib that doesn't write is ""A Bad Thing"" typically. I have to agree with Justin here  Try using the UrlEncode method in the HttpUtility class. http://msdn.microsoft.com/en-us/library/system.web.httputility.urlencode.aspx  HttpUtility.UrlEncode(""url"") in System.Web.  You'll want to use System.Web.HttpUtility.urlencode(""url"") Make sure you have system.web as one of the references in your project. I don't think it's included as a reference by default in console applications.  use the static HttpUtility.UrlEncode method.  I'm not a .NET guy but can't you use: HttpUtility.UrlEncode Method (String) Which is described here: HttpUtility.UrlEncode Method (String) on MSDN I don't want to rain on everyone's parade but the mentioned HttpUtility.UrlEncode doesn't seem to be visible even when I include ""using System.Web"". Does this actually work for someone and if so can you include the actual code? You need (must) add System.Web as a reference. Simply putting using System.Web is not enough I knew about System.Web.HttpContext but it wasn't resolving. Thanks Anjisan for pointing out that I needed to add System.Web as a reference. +1 from me! Problem is you will get something like this: The referenced assembly "".."" could not be resolved because it has a dependency on ""System.Web ..."". Two options - either change the target framework to not use the client profile or use the C# example given by t3rse elsewhere on this page. why does this have so many votes for a NOT answer?  Try this! Uri.EscapeUriString(url); No need to reference System.Web. Not sure why this was down-voted; maybe the edit fixed something? Anyhow it's a good answer. For more info see [this answer](http://stackoverflow.com/a/8451941/530545) from another similar question. Works great and you don't need to add any refference. thank you for providing an answer not a NOT answer. This is a far better answer because you don't have to import new references to the console app since the `Uri` class is in `System`.  The code from Ian Hopkins does the trick for me without having to add a reference to System.Web. Here is a port to C# for those who are not using VB.NET: /// <summary> /// URL encoding class. Note: use at your own risk. /// Written by: Ian Hopkins (http://www.lucidhelix.com) /// Date: 2008-Dec-23 /// (Ported to C# by t3rse (http://www.t3rse.com)) /// </summary> public class UrlHelper { public static string Encode(string str) { var charClass = String.Format(""0-9a-zA-Z{0}"" Regex.Escape(""-_.!~*'()"")); return Regex.Replace(str String.Format(""[^{0}]"" charClass) new MatchEvaluator(EncodeEvaluator)); } public static string EncodeEvaluator(Match match) { return (match.Value == "" "")?""+"" : String.Format(""%{0:X2}"" Convert.ToInt32(match.Value[0])); } public static string DecodeEvaluator(Match match) { return Convert.ToChar(int.Parse(match.Value.Substring(1) System.Globalization.NumberStyles.HexNumber)).ToString(); } public static string Decode(string str) { return Regex.Replace(str.Replace('+' ' ') ""%[0-9a-zA-Z][0-9a-zA-Z]"" new MatchEvaluator(DecodeEvaluator)); } } Great work both t3rse and Ian Hopkins. I ran into this issue building a wpf application. wpf uses the slimmed down 'client profile' of .net while my class library was using the full version. Only the full version of .net has access to System.Web which contains HttpUtility.UrlEncode.  Kibbee offers the real answer. Yes HttpUtility.UrlEncode is the right method to use but it will not be available by default for a console application. You must add a reference to System.Web. To do that In your solution explorer right click on references Choose ""add reference"" In the ""Add Reference"" dialog box use the .NET tab Scroll down to System.Web select that and hit ok NOW you can use the UrlEncode method. You'll still want to add using System.Web at the top of your console app or use the full namespace when calling the method System.Web.HttpUtility.UrlEncode(someString)",c# .net console26147,A,"Is it possible to Embed Gecko or Webkit in a Windows Form just like a WebView? I'd love to know if there is such a thing as a Gecko.NET ;) I mean just like we can embed a WebView and that is an ""instance"" of IE7 inside any Windows Forms application (and tell it to navigateto(fancy_url);). I'd love to use Firefox or WebKit. Anybody tried this? UPDATE: Please bear in mind that although it is possible to embed Gecko using the mentioned controls it is still impossible to print while using Gecko. UPDATE March 2010: It‰Ûªs still not possible to print natively using GeckoFX however a couple of methods exist that may be enough depending upon what you‰Ûªre trying to do. See: http://geckofx.org/viewtopic.php?id=796 for more information. UPDATE October 2013: I am no longer doing Windows development so I have no interest in this but seems like the development of Gecko can be found here: https://bitbucket.org/geckofx and it seems to be recently updated. Leaving this here for future Windows devs ;) http://code.google.com/p/geckofx/ This is a nice .NET-wrapped version of Gecko Active developed project is available at: https://bitbucket.org/geckofx  I'd just like to point out to all looking to embed Gecko into their applications that the GeckoFX project appears to have been abandoned by its creators (Skybound Software). MozNET while previously based on GeckoFX sorta' picked up the ball and ran with it. It has the full ability to print do print previews and allows you to set it all up via the native Windows print dialog even - and a whole lot more.  It certainly is possible. All you need to do is register the Mozilla ActiveX control (mozctlx.dll I believe) and you can drag it onto your form as any ActiveX control. The programming interface is similar (though not identical) to the IE one and you can even use the Microsoft.MSHTML.dll managed library for control in some cases. I believe this is packaged with Firefox. If not you can get just the embeddable bits from Mozilla as well. Just do a Google search for Mozilla ActiveX control or Mozilla Embedding C# and that should take you down the right path. The answer below should be the answer. GeckoFX is an updated .NET wrapper the ActiveX control has not been updated since 2005.  As of October 30 2011 there is new information to add since the time of the previous posts. Specifically while Skybound stopped maintaining their version there is at least one actively maintained free open-source fork available. I'm using Hindle's fork at BitBucket which by virtue of his tool which parses XpCom idls and creates c# wrappers is rapidly updated with support for each new version of Firefox/Gecko. See this post for an overview of other choices.  GeckoFX is no longer being updated. The alternative is the MozNet XulRunner wrapper by Se7en Soft. MozNet has a ton of features that GeckoFX doesn't and is being actively updated and maintained. MozNet's EULA contradicts LGPL making it illegal. Don't use it. worse than that there is now no longer a free demo. It's unlikely one is going to purchase an alternative to an IE plugin component they can verify that it's capable of performing whatever task you weren't able to accomplish with the IE component Active developed project of GeckoFX is available at: https://bitbucket.org/geckofx  OpenWebKitSharp is a wrapper arount the WebKit engine (nightly) and is very advanced. Take a look at here (OpenWebKitSharp section): http://code.google.com/p/open-webkit-sharp/ By far the best WebBrowser Control for non-IE needs for .Net OpenWebkitSharp was disabandoned and is therefore useless. Existing errors are not fixed anymore and one can not live with them.  @Martin: Yes the Adam Locke version is outdated. But that's because a separate distribution is not necessary. It's built with the rest of the Mozilla codebase now. If you download Prism (ie XulRunner) that will give you a base that you can customize to your needs and this includes the most recent version of the control (in the \Prism\xulrunner directory you'll find mozctlx.dll). @Greg: Actually it is an ActiveX control. Incidentally all ActiveX controls are COM controls. ActiveX is built on COM. I want to transfer winform data to Firefox browser. It can be possible through OpenWebKitSharp class Library also can it works for FF 26.0 version  I Belive ""Gecko FX""[1] is the thing you need. To Quote from the web site """""" GeckoFX is a Windows Forms control written in clean commented C# that embeds the Mozilla Gecko browser control in any Windows Forms Application. It also contains a simple class model providing access to the HTML and CSS DOM. """""" 1) I can't post a link as ""new users aren't allowed to add hyperlinks"" Search for ""geckofx"" on google code. The link is at http://code.google.com/p/geckofx/ Active developed vesrion of GeckoFX is available at: https://bitbucket.org/geckofx  Additionally if you find yourself using Gtk instead of Windows.Forms there is a tarball of webkit-sharp available that allows for easy embedding of WebViews into Gtk# applications.",c# .net winforms webkit gecko709,A,".NET Testing Framework Advice I'm looking to introduce a unit testing framework into the mix at my job. We're using Visual Studio 2005 (though we may be moving to 2008 within the next 6 months) and work primarily in C#. If the framework has some kind of IDE integration that would be best but I'm open to frameworks that don't have integration but are still relatively simple to get set up. I'm going to get resistance to it one way or another so if I can make sure what I'm pushing isn't a pain in the neck that would help my case. The obvious choice from the research I've done so far points to nUnit but I'd like to get the impressions of someone who's actually used it before recommending it to my team. Has anyone out there used nUnit? If so are there any pitfalls or limitations of which I should be aware? Are there other good options out there? If so if you've used both nUnit at that I'd greatly appreciate an idea of the strengths and weaknesses of them. 2008. Facepalm. You should be using 2010 if your upgrading Try also PEX tool It Microsoft's own probably soon to be integrated into VSTS and does support NUnit  MbUnit and xUnit.net I use also small Console Application for testing one class or small library. You could copy paste the code from here  We've been using xUnit.net. It seems to combine all the best of nUnit mbUnit and MSTest. I majorly regret the wasted time not having tried it before I switched.  The built in unit testing in VS 2008 is alright but its difficult to integrate with CruiseControl.net certainly a lot harder than normal NUnit. So go with NUnit if you plan to have nice automated tests.  mbUnit is worth alook it has a set of features comparable to NUnit it has its own GUI or can be integrated into VS if you have Resharper. I would also recommend Rhino Mocks if you are doing any sort of TDD.  Scott Hanselman had a good Podcast about this entitled: ""The Past Present and Future of .NET Unit Testing Frameworks"" : Hanselminutes #112 That is was a money podcast. It highlights all the major unit test frameworks. I personally started using xUnit because of what I heard on this pod cast.  I think NUnit is your best bet. With TestDriven.NET you get great integration within VS.NET. (Resharper also has a unit test runner if you're using it). NUnit it simple to use and follows an established paradigm. You'll also find plenty of projects/tutorials/guides using it which always helps. Your other main choice is probably MBUnit which is more and more position itself as the BDD framework of choice (in conjunction with Gallio http://www.gallio.org).  Visual Studio 2008 has a built in test project type that works in a similar way to NUnit but obviously has much tighter integration with Visual Studio (can run on every build and shows the results in a similar way to the conversion results page when upgrading solution files) but it is obviously not as mature as NUnit as it's pretty new and I'm not sure about how it handles mocking. But it would be worth looking into when your team moves to VS2008  I would say mbUnit also I like being able to run a single test many times just by specifying inputs and result right above the test function. Horrible description of what I mean so here is a link that shows you what I mean.  VSTT 2010 should be a good bet if you are looking for functional test automation. Web Services Testing UI testing Biztalk testing and Data Driven Testing Support. Please look at VSTT  When I started unit testing I started with NUnit as it is simple to set up and use currently I am using the built in test runner that comes with Resharper that way I can easily flip between code and test results. Incidently NUnit detects when you have compiled your code so you do not need to do any refresh in NUnit. Resharper automatically does a build when you choose to run a specific test.",c# .net visual-studio unit-testing25349,A,"What would be the fastest way to remove Newlines from a String in C#? I have a string that has some Environment.Newline in it. I'd like to strip those from the string and instead replace the Newline with something like a comma. What would be in your opinion the best way to do this using C#.NET 2.0? Thanks in advance. Why not: string s = ""foobar\ngork""; string v = s.Replace(Environment.NewLine""""); System.Console.WriteLine(v);  Like this: string s = ""hello\nworld""; s = s.Replace(Environment.NewLine """");  Don't reinvent the wheel - just use myString.Replace(Environment.NewLine """")  The best way is the builtin way: Use string.Replace. Why do you need alternatives?  string sample = ""abc"" + Environment.NewLine + ""def""; string replaced = sample.Replace(Environment.NewLine """");",c# .net string replace19147,A,"What is the correct way to create a single instance application? Using C# and WPF under .net (rather than WindowsForms or console) what is the correct way to create an application that can only be run as a single instance? I know it has something to do with some mythical thing called a mutex rarely can I find someone that bothers to stop and explain what one of these are. The code needs to also inform the already running instance that the user tried to start a second one and maybe also pass any command line arguments if any existed. @San Saffron - Do you have an answer that does? Doesn't the CLR automatically release any unreleased mutexes when the application terminates anyway? @Cocowalla: the finalizer should dispose the unmanaged mutexes unless it can't know if the mutex was created by the managed app or attached to an existing one. Having only one instance of your app is reasonable. But passing arguments to an already existing app appears to me a bit silly. I can't see any reason to do so. If you associate an app with file extension you should open as many app as user want to open documents. That's the standard behavior which every users would expect. Just want to make correction about my previous state. Passing arguments to an existing app means that you want to do an MDI (multi document interface). I thought that MDI was a way that Microsoft was pushing out (Word and Excel are now SDI). But I realize that Chrome and IE are both MDI. Perharps we are in years where MDI is back ??? (But I still prefer SDI over MDI) @Cocowalla The CLR does not manage native resources. However if a process terminates all handles are freed by the system (the OS not the CLR). I prefer the answer by @huseyint. It uses Microsoft's own 'SingleInstance.cs' class so you don't have to worry about Mutexes and IntPtrs. Also no dependency on VisualBasic (yuk). See http://codereview.stackexchange.com/questions/20871/wpf-single-instance-best-practices/25667#25667 for more... You should never use a named mutex to implement a single instance application (or at least not for production code). Malicious code can easily DOS(Denial of Service) your ass... ""You should never use a named mutex"" - never say never. If malicious code is running on my machine I'm probably already hosed. Actually it doesn't even have to be malicious code. It could just be a accidental name collision. Then what should you do? The better question is what possible reason would you want that behavior. Don't design your app as a single instance application=). I know that's a lame answer but from a design standpoint it is almost always the correct answer. Without knowing more about the app its hard to say much more. At least under Windows Mutexes have access control so one one can toy with your object. As to name collisions themselves that's why UUID/GUID's where invented.  Well I have a disposable Class for this that works easily for most use cases: Use it like this: static void Main() { using (SingleInstanceMutex sim = new SingleInstanceMutex()) { if (sim.IsOtherInstanceRunning) { Application.Exit(); } // Initialize program here. } } Here it is: /// <summary> /// Represents a <see cref=""SingleInstanceMutex""/> class. /// </summary> public partial class SingleInstanceMutex { #region Fields /// <summary> /// Indicator whether another instance of this application is running or not. /// </summary> private bool isNoOtherInstanceRunning; /// <summary> /// The <see cref=""Mutex""/> used to ask for other instances of this application. /// </summary> private Mutex singleInstanceMutex = null; /// <summary> /// An indicator whether this object is beeing actively disposed or not. /// </summary> private bool disposed; #endregion #region Constructor /// <summary> /// Initializes a new instance of the <see cref=""SingleInstanceMutex""/> class. /// </summary> public SingleInstanceMutex() { this.singleInstanceMutex = new Mutex(true Assembly.GetCallingAssembly().FullName out this.isNoOtherInstanceRunning); } #endregion #region Properties /// <summary> /// Gets an indicator whether another instance of the application is running or not. /// </summary> public bool IsOtherInstanceRunning { get { return !this.isNoOtherInstanceRunning; } } #endregion #region Methods /// <summary> /// Closes the <see cref=""SingleInstanceMutex""/>. /// </summary> public void Close() { this.ThrowIfDisposed(); this.singleInstanceMutex.Close(); } public void Dispose() { this.Dispose(true); GC.SuppressFinalize(this); } private void Dispose(bool disposing) { if (!this.disposed) { /* Release unmanaged ressources */ if (disposing) { /* Release managed ressources */ this.Close(); } this.disposed = true; } } /// <summary> /// Throws an exception if something is tried to be done with an already disposed object. /// </summary> /// <remarks> /// All public methods of the class must first call this. /// </remarks> public void ThrowIfDisposed() { if (this.disposed) { throw new ObjectDisposedException(this.GetType().Name); } } #endregion } this one was pretty easy to get working. It would not close the second application until I changed Application.Exit(); to a simple return; but other than that its great. Although i admit I am going to look at the previous solution closer since it uses an interface. http://blogs.microsoft.co.il/blogs/arik/archive/2010/05/28/wpf-single-instance-application.aspx  From here. A common use for a cross-process Mutex is to ensure that only instance of a program can run at a time. Here's how it's done: class OneAtATimePlease { // Use a name unique to the application (eg include your company URL) static Mutex mutex = new Mutex (false ""oreilly.com OneAtATimeDemo""); static void Main() { // Wait 5 seconds if contended ‰ÛÒ in case another instance // of the program is in the process of shutting down. if (!mutex.WaitOne(TimeSpan.FromSeconds (5) false)) { Console.WriteLine(""Another instance of the app is running. Bye!""); return; } try { Console.WriteLine(""Running - press Enter to exit""); Console.ReadLine(); } finally { mutex.ReleaseMutex(); } } } A good feature of Mutex is that if the application terminates without ReleaseMutex first being called the CLR will release the Mutex automatically. I've got to say I like this answer a lot more than the accepted one simply due to the fact that it isn't dependent on WinForms. Personally most of my development has been moving to WPF and I don't want to have to pull in WinForm libraries for something like this. Of course to be a full answer you have to also describe passing the arguments to the other instance :) @EricOuellet: The problems with MDI were probably far more about having windows within windows than tabs being confusing and there's a strong push to all tabs being pulled out into their own top-level window mitigating it. These are all UI concerns though which shouldn't have any connection to how you split up your processes (multiple processes can be contained in the same window and vice-versa). @Simon you are right. I just question myself about a very old thing... MDI vs SDI (Multi documentinterface vs Single document interface). When you talk about tabs you refer to MDI. In 1998 a Microsoft book suggests to eliminate every MDI app. Microsoft switched Word Excel... to SDI which I think it is simplier and better. I understand that Chrome and others (now IE) want back to MDI. I personnaly (based on nothing / personal feelings) that it is still better to open a new app when file assoc is selected. But I understand better the question asked now. Thanks ! @Jason good thanks! But I prefer not passing any timeout. It is so much subjective and depends on so many variables. If you ever want to enable another app to start just release your mutex quicker.. for example as soon as the user confirm close @EricOuellet: Just about every program that has tabs does this - Photoshop Sublime Text Chrome .... If you have a good reason to have a ""master"" process (say you have a in-proc DB for settings) you might want to have it show UI as if it were a new process too.  A good solution by WPF disciple Daniel Vaughan using memory mapped files for IPC is here: http://danielvaughan.org/post/Enforcing-Single-Instance-WPF-Applications.aspx  So many answers to such a seemingly simple question. Just to shake things up a little bit here is my solution to this problem. Creating a Mutex can be troublesome because the JIT-er only sees you using it for a small portion of your code and wants to mark it as ready for garbage collection. It pretty much wants to out-smart you thinking you are not going to be using that Mutex for that long. In reality you want to hang onto this Mutex for as long as your application is running. The best way to tell the garbage collector to leave you Mutex alone is to tell it to keep it alive though out the different generations of garage collection. Example: var m = new Mutex(...); ... GC.KeepAlive(m); I lifted the idea from this page: http://www.ai.uga.edu/~mc/SingleInstance.html Wouldn't it be easier to store a shared copy of it in the application class?  Here's a lightweight solution I use which allows the application to bring an already existing window to the foreground without resorting to custom windows messages or blindly searching process names. [DllImport(""user32.dll"")] static extern bool SetForegroundWindow(IntPtr hWnd); static readonly string guid = ""<Application Guid>""; static void Main() { Mutex mutex = null; if (!CreateMutex(out mutex)) return; // Application startup code. Environment.SetEnvironmentVariable(guid null EnvironmentVariableTarget.User); } static bool CreateMutex(out Mutex mutex) { bool createdNew = false; mutex = new Mutex(false guid out createdNew); if (createdNew) { Process process = Process.GetCurrentProcess(); string value = process.Id.ToString(); Environment.SetEnvironmentVariable(guid value EnvironmentVariableTarget.User); } else { string value = Environment.GetEnvironmentVariable(guid EnvironmentVariableTarget.User); Process process = null; int processId = -1; if (int.TryParse(value out processId)) process = Process.GetProcessById(processId); if (process == null || !SetForegroundWindow(process.MainWindowHandle)) MessageBox.Show(""Unable to start application. An instance of this application is already running.""); } return createdNew; } Edit: You can also store and initialize mutex and createdNew statically but you'll need to explicitly dispose/release the mutex once you're done with it. Personally I prefer keeping the mutex local as it will be automatically disposed of even if the application closes without ever reaching the end of Main.  Here is a very good article regarding the Mutex solution. The approach described by the article is advantageous for two reasons. First it does not require a dependency on the Microsoft.VisualBasic assembly. If my project already had a dependency on that assembly I would probably advocate using the approach shown in the accepted answer. But as it is I do not use the Microsoft.VisualBasic assembly and I'd rather not add an unnecessary dependency to my project. Second the article shows how to bring the existing instance of the application to the foreground when the user tries to start another instance. That's a very nice touch that the other Mutex solutions described here do not address. UPDATE As of 8/1/2014 the article I linked to above is still active but the blog hasn't been updated in a while. That makes me worry that eventually it might disappear and with it the advocated solution. I'm reproducing the content of the article here for posterity. The words belong solely to the blog owner at Sanity Free Coding. Today I wanted to refactor some code that prohibited my application from running multiple instances of itself. Previously I had use System.Diagnostics.Process to search for an instance of my myapp.exe in the process list. While this works it brings on a lot of overhead and I wanted something cleaner. Knowing that I could use a mutex for this (but never having done it before) I set out to cut down my code and simplify my life. In the class of my application main I created a static named Mutex: static class Program { static Mutex mutex = new Mutex(true ""{8F6F0AC4-B9A1-45fd-A8CF-72F04E6BDE8F}""); [STAThread] ... } Having a named mutex allows us to stack synchronization across multiple threads and processes which is just the magic I'm looking for. Mutex.WaitOne has an overload that specifies an amount of time for us to wait. Since we're not actually wanting to synchronizing our code (more just check if it is currently in use) we use the overload with two parameters: Mutex.WaitOne(Timespan timeout bool exitContext). Wait one returns true if it is able to enter and false if it wasn't. In this case we don't want to wait at all; If our mutex is being used skip it and move on so we pass in TimeSpan.Zero (wait 0 milliseconds) and set the exitContext to true so we can exit the synchronization context before we try to aquire a lock on it. Using this we wrap our Application.Run code inside something like this: static class Program { static Mutex mutex = new Mutex(true ""{8F6F0AC4-B9A1-45fd-A8CF-72F04E6BDE8F}""); [STAThread] static void Main() { if(mutex.WaitOne(TimeSpan.Zero true)) { Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); Application.Run(new Form1()); mutex.ReleaseMutex(); } else { MessageBox.Show(""only one instance at a time""); } } } So if our app is running WaitOne will return false and we'll get a message box. Instead of showing a message box I opted to utilize a little Win32 to notify my running instance that someone forgot that it was already running (by bringing itself to the top of all the other windows). To achieve this I used PostMessage to broadcast a custom message to every window (the custom message was registered with RegisterWindowMessage by my running application which means only my application knows what it is) then my second instance exits. The running application instance would receive that notification and process it. In order to do that I overrode WndProc in my main form and listened for my custom notification. When I received that notification I set the form's TopMost property to true to bring it up on top. Here is what I ended up with: Program.cs static class Program { static Mutex mutex = new Mutex(true ""{8F6F0AC4-B9A1-45fd-A8CF-72F04E6BDE8F}""); [STAThread] static void Main() { if(mutex.WaitOne(TimeSpan.Zero true)) { Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); Application.Run(new Form1()); mutex.ReleaseMutex(); } else { // send our Win32 message to make the currently running instance // jump on top of all the other windows NativeMethods.PostMessage( (IntPtr)NativeMethods.HWND_BROADCAST NativeMethods.WM_SHOWME IntPtr.Zero IntPtr.Zero); } } } NativeMethods.cs // this class just wraps some Win32 stuff that we're going to use internal class NativeMethods { public const int HWND_BROADCAST = 0xffff; public static readonly int WM_SHOWME = RegisterWindowMessage(""WM_SHOWME""); [DllImport(""user32"")] public static extern bool PostMessage(IntPtr hwnd int msg IntPtr wparam IntPtr lparam); [DllImport(""user32"")] public static extern int RegisterWindowMessage(string message); } Form1.cs (front side partial) public partial class Form1 : Form { public Form1() { InitializeComponent(); } protected override void WndProc(ref Message m) { if(m.Msg == NativeMethods.WM_SHOWME) { ShowMe(); } base.WndProc(ref m); } private void ShowMe() { if(WindowState == FormWindowState.Minimized) { WindowState = FormWindowState.Normal; } // get our current ""TopMost"" value (ours will always be false though) bool top = TopMost; // make our form jump to the top of everything TopMost = true; // set it back to whatever it was TopMost = top; } } On the basis that this answer uses less code and less libraries and provides the raise to top functionality I'm going to make this the new accepted answer. If anyone knows a more correct way to bring the form to the top using API's feel free to add that. That's a nice little example - works beautifully in my application. Add it's simple to implement. Not sure I understand - why use Native Messages? That's what events are for... (if it's for the decoupling you should really be using cab or [EventBroker](http://www.codeproject.com/KB/dotnet/EventBroker.aspx)...) @BlueRaja you start up the first app instance. When you start up the second app instance it detects that another instance is already running and prepares to shutdown. Before doing so it sends a ""SHOWME"" native message to the first instance which brings the first instance to the top. Events in .NET don't allow cross-process communication which is why the native message is used. @Matt: Ah I understand. Thank you. Is there a way to pass the command lines from the other instance maybe? @matt david - don't worry about 'shipping' Microsoft.VisualBasic - it is already in the GAC. http://stackoverflow.com/questions/226517/is-the-microsoft-visualbasic-namespace-true-net-code @Simon_Weaver the issue is not whether it is in the GAC or not but the fact that it is delivered with the .NET Framework. I was not aware of that. Thanks for the link. @matt - i just wish they'd named the damn thing something else! i've just started using that component myself and it works quite well (my users will never know i stooped so low as to include a VB namespace - heh). its very convenient to be able to pass parameters and/or have the dormant application bring itself to the front without having to mess with any communication code yourself @Matt: How can we choose the name for the Mutex? In the sample it is `{8F6F0AC4-B9A1-45fd-A8CF-72F04E6BDE8F}` Where is it from :) ? @Nam the `Mutex` constructor simply requires a string so you could supply any string name you want e.g. ""This Is My Mutex"". Because a 'Mutex' is a system object that is available to other processes you typically want the name to be unique so it doesn't clash with other 'Mutex' names on the same system. In the article the cryptic-looking string is a 'Guid'. You can generate this programmatically by calling `System.Guid.NewGuid()`. In the case of the article the user probably generated it via Visual Studio as shown here: http://msdn.microsoft.com/en-us/library/ms241442(VS.80).aspx @Matt Davis you CANNOT use System.Guid.NewGuid() because each time you get different GUID and in effect each instance of your program will claim it is single instance. You have to use some token common to ALL instances defined at compile time. VS generated GUID is the way. @macias I never said that you would call `System.Guid.NewGuid()` and then pass the result to the Mutex. That would obviously be wrong as you have deftly pointed out. The question was where the string came from. I was simply saying that a GUID could be generated programmatically or using Visual Studio. Following the article worked like a charm for my WinForms application as well. Thanks! Does the mutex approach assume that the same user is attempting to start the application again? Certainly bringing ""the existing instance of the application to the foreground"" does not make sense after a 'switch user' article link broken. @Joshua no it's still there; just tried it. If you're attempting to access it at work it's very possible that your company's firewall is preventing access. @MattDavis Hmm it does show up now. My bad. The question asked for an approach for WPF not WinForms as the answer proposes. I used [this answer](http://stackoverflow.com/a/5484315/433718) for a WPF application. It's also posted as answer here: http://stackoverflow.com/a/2932076/433718 @OneWorld this solution is agnostic to the UI framework. The example shows how to do it using WinForms but it'd be just as easy to use in WPF. The solution you posted uses .NET Remoting a legacy technology that Microsoft retains for backward compatibility only. That's hardly a solution I would endorse. http://msdn.microsoft.com/en-us/library/kwdt6w2k(v=vs.100).aspx @MattDavis Didn't know about that. Good that we clarified that. The autor Arik Poznanski seemed to express high confidence that his approach has done it right. And several people said this is a ""novice"" approach since it was from 2010. I did not use your solution because I could not find a method `protected override void WndProc(ref Message m)` @OneWorld see the answers here. http://stackoverflow.com/questions/624367/how-to-handle-wndproc-messages-in-wpf  Here is an example that allows you to have a single instance of an application. When any new instances load they pass their arguments to the main instance that is running. public partial class App : Application { private static Mutex SingleMutex; public static uint MessageId; private void Application_Startup(object sender StartupEventArgs e) { IntPtr Result; IntPtr SendOk; Win32.COPYDATASTRUCT CopyData; string[] Args; IntPtr CopyDataMem; bool AllowMultipleInstances = false; Args = Environment.GetCommandLineArgs(); // TODO: Replace {00000000-0000-0000-0000-000000000000} with your application's GUID MessageId = Win32.RegisterWindowMessage(""{00000000-0000-0000-0000-000000000000}""); SingleMutex = new Mutex(false ""AppName""); if ((AllowMultipleInstances) || (!AllowMultipleInstances &amp;&amp; SingleMutex.WaitOne(1 true))) { new Main(); } else if (Args.Length > 1) { foreach (Process Proc in Process.GetProcesses()) { SendOk = Win32.SendMessageTimeout(Proc.MainWindowHandle MessageId IntPtr.Zero IntPtr.Zero Win32.SendMessageTimeoutFlags.SMTO_BLOCK | Win32.SendMessageTimeoutFlags.SMTO_ABORTIFHUNG 2000 out Result); if (SendOk == IntPtr.Zero) continue; if ((uint)Result != MessageId) continue; CopyDataMem = Marshal.AllocHGlobal(Marshal.SizeOf(typeof(Win32.COPYDATASTRUCT))); CopyData.dwData = IntPtr.Zero; CopyData.cbData = Args[1].Length*2; CopyData.lpData = Marshal.StringToHGlobalUni(Args[1]); Marshal.StructureToPtr(CopyData CopyDataMem false); Win32.SendMessageTimeout(Proc.MainWindowHandle Win32.WM_COPYDATA IntPtr.Zero CopyDataMem Win32.SendMessageTimeoutFlags.SMTO_BLOCK | Win32.SendMessageTimeoutFlags.SMTO_ABORTIFHUNG 5000 out Result); Marshal.FreeHGlobal(CopyData.lpData); Marshal.FreeHGlobal(CopyDataMem); } Shutdown(0); } } } public partial class Main : Window { private void Window_Loaded(object sender RoutedEventArgs e) { HwndSource Source; Source = HwndSource.FromHwnd(new WindowInteropHelper(this).Handle); Source.AddHook(new HwndSourceHook(Window_Proc)); } private IntPtr Window_Proc(IntPtr hWnd int Msg IntPtr wParam IntPtr lParam ref bool Handled) { Win32.COPYDATASTRUCT CopyData; string Path; if (Msg == Win32.WM_COPYDATA) { CopyData = (Win32.COPYDATASTRUCT)Marshal.PtrToStructure(lParam typeof(Win32.COPYDATASTRUCT)); Path = Marshal.PtrToStringUni(CopyData.lpData CopyData.cbData / 2); if (WindowState == WindowState.Minimized) { // Restore window from tray } // Do whatever we want with information Activate(); Focus(); } if (Msg == App.MessageId) { Handled = true; return new IntPtr(App.MessageId); } return IntPtr.Zero; } } public class Win32 { public const uint WM_COPYDATA = 0x004A; public struct COPYDATASTRUCT { public IntPtr dwData; public int cbData; public IntPtr lpData; } [Flags] public enum SendMessageTimeoutFlags : uint { SMTO_NORMAL = 0x0000 SMTO_BLOCK = 0x0001 SMTO_ABORTIFHUNG = 0x0002 SMTO_NOTIMEOUTIFNOTHUNG = 0x0008 } [DllImport(""user32.dll"" SetLastError=true CharSet=CharSet.Auto)] public static extern uint RegisterWindowMessage(string lpString); [DllImport(""user32.dll"")] public static extern IntPtr SendMessageTimeout(IntPtr hWnd uint Msg IntPtr wParam IntPtr lParam SendMessageTimeoutFlags fuFlags uint uTimeout out IntPtr lpdwResult); } Please don't crucify me if this is too much code. This is a really nice example of what I what to do. Nathan are all the args sent using this method? I have 7 or so in my app and i *think* that this code will work. In my example only the first argument is sent but it can be changed so that all of them are sent.  Use mutex solution: using System; using System.Windows.Forms; using System.Threading; namespace OneAndOnlyOne { static class Program { static String _mutexID = "" // generate guid"" /// <summary> /// The main entry point for the application. /// </summary> [STAThread] static void Main() { Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); Boolean _isNotRunning; using (Mutex _mutex = new Mutex(true _mutexID out _isNotRunning)) { if (_isNotRunning) { Application.Run(new Form1()); } else { MessageBox.Show(""An instance is already running.""); return; } } } } }  Just some thoughts: There are cases when requiring that only one instance of an application is not ""lame"" as some would have you believe. Database apps etc. are an order of magnitude more difficult if one allows multiple instances of the app for a single user to access a database (you know all that updating all the records that are open in multiple instances of the app on the users machine etc.). First for the ""name collision thing don't use a human readable name - use a GUID instead or even better a GUID + the human readable name. Chances of name collision just dropped off the radar and the Mutex doesn't care. As someone pointed out a DOS attack would suck but if the malicious person has gone to the trouble of getting the mutex name and incorporating it into their app you are pretty much a target anyway and will have to do MUCH more to protect yourself than just fiddle a mutex name. Also if one uses the variant of: new Mutex(true ""some GUID plus Name"" out AIsFirstInstance) you already have your indicator as to whether or not the Mutex is the first instance.  See my solution for this problem... Very interesting solution. Sadly the comments seems to be a bit neglected? i agree - interesting solution  Here is what I use. It combined process enumeration to perform switching and mutex to safeguard from ""active clickers"": public partial class App { [DllImport(""user32"")] private static extern int OpenIcon(IntPtr hWnd); [DllImport(""user32.dll"")] private static extern bool SetForegroundWindow(IntPtr hWnd); protected override void OnStartup(StartupEventArgs e) { base.OnStartup(e); var p = Process .GetProcessesByName(Process.GetCurrentProcess().ProcessName); foreach (var t in p.Where(t => t.MainWindowHandle != IntPtr.Zero)) { OpenIcon(t.MainWindowHandle); SetForegroundWindow(t.MainWindowHandle); Current.Shutdown(); return; } // there is a chance the user tries to click on the icon repeatedly // and the process cannot be discovered yet bool createdNew; var mutex = new Mutex(true ""MyAwesomeApp"" out createdNew); // must be a variable though it is unused - // we just need a bit of time until the process shows up if (!createdNew) { Current.Shutdown(); return; } new Bootstrapper().Run(); } }  Here is a new one that uses Mutex and IPC stuff and also passes any command line args to the running instance: http://blogs.microsoft.co.il/blogs/arik/archive/2010/05/28/wpf-single-instance-application.aspx +1 Comparing all the different solutions I'm going to give this a try. Sounds promising. I use this with great success. If you incorporate NamedPipes with this you can also pass command-line arguments to the original application. The class 'SingleInstance.cs' was written by Microsoft. I have added another link to a more readable version of Arik Poznanski's blog on CodeProject.  The code C# .NET Single Instance Application that is the reference for the marked answer is a great start. However I found it doesn't handle very well the cases when the instance that already exist has a modal dialog open whether that dialog is a managed one (like another Form such as an about box) or an unmanaged one (like the OpenFileDialog even when using the standard .NET class). With the original code the main form is activated but the modal one stays unactive which looks strange plus the user must click on it to keep using the app. So I have create a SingleInstance utility class to handle all this quite automatically for Winforms and WPF applications. Winforms: 1) modify the Program class like this: static class Program { public static readonly SingleInstance Singleton = new SingleInstance(typeof(Program).FullName); [STAThread] static void Main(string[] args) { // NOTE: if this always return false close & restart Visual Studio // this is probably due to the vshost.exe thing Singleton.RunFirstInstance(() => { SingleInstanceMain(args); }); } public static void SingleInstanceMain(string[] args) { // standard code that was in Main now goes here Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); Application.Run(new Form1()); } } 2) modify the main window class like this: public partial class Form1 : Form { public Form1() { InitializeComponent(); } protected override void WndProc(ref Message m) { // if needed the singleton will restore this window Program.Singleton.OnWndProc(this m true); // TODO: handle specific messages here if needed base.WndProc(ref m); } } WPF: 1) modify the App page like this (and make sure you set its build action to page to be able to redefine the Main method): public partial class App : Application { public static readonly SingleInstance Singleton = new SingleInstance(typeof(App).FullName); [STAThread] public static void Main(string[] args) { // NOTE: if this always return false close & restart Visual Studio // this is probably due to the vshost.exe thing Singleton.RunFirstInstance(() => { SingleInstanceMain(args); }); } public static void SingleInstanceMain(string[] args) { // standard code that was in Main now goes here App app = new App(); app.InitializeComponent(); app.Run(); } } 2) modify the main window class like this: public partial class MainWindow : Window { private HwndSource _source; public MainWindow() { InitializeComponent(); } protected override void OnSourceInitialized(EventArgs e) { base.OnSourceInitialized(e); _source = (HwndSource)PresentationSource.FromVisual(this); _source.AddHook(HwndSourceHook); } protected virtual IntPtr HwndSourceHook(IntPtr hwnd int msg IntPtr wParam IntPtr lParam ref bool handled) { // if needed the singleton will restore this window App.Singleton.OnWndProc(hwnd msg wParam lParam true true); // TODO: handle other specific message return IntPtr.Zero; } And here is the utility class: using System; using System.ComponentModel; using System.Runtime.InteropServices; using System.Threading; namespace SingleInstanceUtilities { public sealed class SingleInstance { private const int HWND_BROADCAST = 0xFFFF; [DllImport(""user32.dll"")] private static extern bool PostMessage(IntPtr hwnd int msg IntPtr wparam IntPtr lparam); [DllImport(""user32.dll"" CharSet = CharSet.Unicode)] private static extern int RegisterWindowMessage(string message); [DllImport(""user32.dll"")] private static extern bool SetForegroundWindow(IntPtr hWnd); public SingleInstance(string uniqueName) { if (uniqueName == null) throw new ArgumentNullException(""uniqueName""); Mutex = new Mutex(true uniqueName); Message = RegisterWindowMessage(""WM_"" + uniqueName); } public Mutex Mutex { get; private set; } public int Message { get; private set; } public void RunFirstInstance(Action action) { RunFirstInstance(action IntPtr.Zero IntPtr.Zero); } // NOTE: if this always return false close & restart Visual Studio // this is probably due to the vshost.exe thing public void RunFirstInstance(Action action IntPtr wParam IntPtr lParam) { if (action == null) throw new ArgumentNullException(""action""); if (WaitForMutext(wParam lParam)) { action(); ReleaseMutex(); } } public static void ActivateWindow(IntPtr hwnd) { if (hwnd == IntPtr.Zero) return; FormUtilities.ActivateWindow(FormUtilities.GetModalWindow(hwnd)); } public void OnWndProc(IntPtr hwnd int m IntPtr wParam IntPtr lParam bool restorePlacement bool activate) { if (m == Message) { if (restorePlacement) { WindowPlacement placement = WindowPlacement.GetPlacement(hwnd false); if (placement.IsValid && placement.IsMinimized) { const int SW_SHOWNORMAL = 1; placement.ShowCmd = SW_SHOWNORMAL; placement.SetPlacement(hwnd); } } if (activate) { SetForegroundWindow(hwnd); FormUtilities.ActivateWindow(FormUtilities.GetModalWindow(hwnd)); } } } #if WINFORMS // define this for Winforms apps public void OnWndProc(System.Windows.Forms.Form form int m IntPtr wParam IntPtr lParam bool activate) { if (form == null) throw new ArgumentNullException(""form""); if (m == Message) { if (activate) { if (form.WindowState == System.Windows.Forms.FormWindowState.Minimized) { form.WindowState = System.Windows.Forms.FormWindowState.Normal; } form.Activate(); FormUtilities.ActivateWindow(FormUtilities.GetModalWindow(form.Handle)); } } } public void OnWndProc(System.Windows.Forms.Form fo","m System.Windows.Forms.Message m bool activate) { if (form == null) throw new ArgumentNullException(""""form""""); OnWndProc(form m.Msg m.WParam m.LParam activate); } #endif public void ReleaseMutex() { Mutex.ReleaseMutex(); } public bool WaitForMutext(bool force IntPtr wParam IntPtr lParam) { bool b = PrivateWaitForMutext(force); if (!b) { PostMessage((IntPtr)HWND_BROADCAST Message wParam lParam); } return b; } public bool WaitForMutext(IntPtr wParam IntPtr lParam) { return WaitForMutext(false wParam lParam); } private bool PrivateWaitForMutext(bool force) { if (force) return true; try { return Mutex.WaitOne(TimeSpan.Zero true); } catch (AbandonedMutexException) { return true; } } } // NOTE: don't add any field or public get/set property as this must exactly map to Windows' WINDOWPLACEMENT structure [StructLayout(LayoutKind.Sequential)] public struct WindowPlacement { public int Length { get; set; } public int Flags { get; set; } public int ShowCmd { get; set; } public int MinPositionX { get; set; } public int MinPositionY { get; set; } public int MaxPositionX { get; set; } public int MaxPositionY { get; set; } public int NormalPositionLeft { get; set; } public int NormalPositionTop { get; set; } public int NormalPositionRight { get; set; } public int NormalPositionBottom { get; set; } [DllImport(""""user32.dll"""" SetLastError = true)] private static extern bool SetWindowPlacement(IntPtr hWnd ref WindowPlacement lpwndpl); [DllImport(""""user32.dll"""" SetLastError = true)] private static extern bool GetWindowPlacement(IntPtr hWnd ref WindowPlacement lpwndpl); private const int SW_SHOWMINIMIZED = 2; public bool IsMinimized { get { return ShowCmd == SW_SHOWMINIMIZED; } } public bool IsValid { get { return Length == Marshal.SizeOf(typeof(WindowPlacement)); } } public void SetPlacement(IntPtr windowHandle) { SetWindowPlacement(windowHandle ref this); } public static WindowPlacement GetPlacement(IntPtr windowHandle bool throwOnError) { WindowPlacement placement = new WindowPlacement(); if (windowHandle == IntPtr.Zero) return placement; placement.Length = Marshal.SizeOf(typeof(WindowPlacement)); if (!GetWindowPlacement(windowHandle ref placement)) { if (throwOnError) throw new Win32Exception(Marshal.GetLastWin32Error()); return new WindowPlacement(); } return placement; } } public static class FormUtilities { [DllImport(""""user32.dll"""")] private static extern IntPtr GetWindow(IntPtr hWnd int uCmd); [DllImport(""""user32.dll"""" SetLastError = true)] private static extern IntPtr SetActiveWindow(IntPtr hWnd); [DllImport(""""user32.dll"""")] private static extern bool IsWindowVisible(IntPtr hWnd); [DllImport(""""kernel32.dll"""")] public static extern int GetCurrentThreadId(); private delegate bool EnumChildrenCallback(IntPtr hwnd IntPtr lParam); [DllImport(""""user32.dll"""")] private static extern bool EnumThreadWindows(int dwThreadId EnumChildrenCallback lpEnumFunc IntPtr lParam); private class ModalWindowUtil { private const int GW_OWNER = 4; private int _maxOwnershipLevel; private IntPtr _maxOwnershipHandle; private bool EnumChildren(IntPtr hwnd IntPtr lParam) { int level = 1; if (IsWindowVisible(hwnd) && IsOwned(lParam hwnd ref level)) { if (level > _maxOwnershipLevel) { _maxOwnershipHandle = hwnd; _maxOwnershipLevel = level; } } return true; } private static bool IsOwned(IntPtr owner IntPtr hwnd ref int level) { IntPtr o = GetWindow(hwnd GW_OWNER); if (o == IntPtr.Zero) return false; if (o == owner) return true; level++; return IsOwned(owner o ref level); } public static void ActivateWindow(IntPtr hwnd) { if (hwnd != IntPtr.Zero) { SetActiveWindow(hwnd); } } public static IntPtr GetModalWindow(IntPtr owner) { ModalWindowUtil util = new ModalWindowUtil(); EnumThreadWindows(GetCurrentThreadId() util.EnumChildren owner); return util._maxOwnershipHandle; // may be IntPtr.Zero } } public static void ActivateWindow(IntPtr hwnd) { ModalWindowUtil.ActivateWindow(hwnd); } public static IntPtr GetModalWindow(IntPtr owner) { return ModalWindowUtil.GetModalWindow(owner); } } }  Just as reference this is how I did without passing arguments (which I can't find any reason to do so... I mean a single app with arguments that as to be passed out from one instance to another one). If file association is required then an app should (per users standard expectation) be instanciated for each doc. If you have to pass args to existing app I think I would used vb dll. Not passing args (just single instance app) I prefer not registering a new Window message and not override the message loop as defined in Matt Davis Solution. Although it's not a big deal to add a VisualBasic dll but I prefer not add a new reference just to do single instance app. Also I do prefer instanciate a new class with Main instead of calling Shutdown from App.Startup override to ensure to exit as soon as possible. In hope that anybody will like it... or will inspire a little bit :-) Project startup class should be set as 'SingleInstanceApp'. public class SingleInstanceApp { [STAThread] public static void Main(string[] args) { Mutex _mutexSingleInstance = new Mutex(true """"MonitorMeSingleInstance""""); if (_mutexSingleInstance.WaitOne(TimeSpan.Zero true)) { try { var app = new App(); app.InitializeComponent(); app.Run(); } finally { _mutexSingleInstance.ReleaseMutex(); _mutexSingleInstance.Close(); } } else { MessageBox.Show(""""One instance is already running.""""); var processes = Process.GetProcessesByName(Assembly.GetEntryAssembly().GetName().Name); { if (processes.Length > 1) { foreach (var process in processes) { if (process.Id != Process.GetCurrentProcess().Id) { WindowHelper.SetForegroundWindow(process.MainWindowHandle); } } } } } } } WindowHelper: using System; using System.Runtime.InteropServices; using System.Windows; using System.Windows.Interop; using System.Windows.Threading; namespace HQ.Util.Unmanaged { public class WindowHelper { [DllImport(""""user32.dll"""")] [return: MarshalAs(UnmanagedType.Bool)] public static extern bool SetForegroundWindow(IntPtr hWnd);  You could use the Mutex class but you will soon find out that you will need to implement the code to pass the arguments and such yourself. Well I learned a trick when programming in WinForms when I read Chris Sell's book. This trick uses logic that is already available to us in the framework. I don't know about you but when I learn about stuff I can reuse in the framework that is usually the route I take instead of reinventing the wheel. Unless of course it doesn't do everything I want. When I got into WPF I came up with a way to use that same code but in a WPF application. This solution should meet your needs based off your question. First we need to create our application class. In this class we are going override the OnStartup event and create a method called Activate which will be used later. public class SingleInstanceApplication : System.Windows.Application { protected override void OnStartup(System.Windows.StartupEventArgs e) { // Call the OnStartup event on our base class base.OnStartup(e); // Create our MainWindow and show it MainWindow window = new MainWindow(); window.Show(); } public void Activate() { // Reactivate the main window MainWindow.Activate(); } } Second we will need to create a class that can manage our instances. Before we go through that we are actually going to reuse some code that is in the Microsoft.VisualBasic assembly. Since I am using C# in this example I had to make a reference to the assembly. If you are using VB.NET you don't have to do anything. The class we are going to use is WindowsFormsApplicationBase and inherit our instance manager off of it and then leverage properties and events to handle the single instancing. public class SingleInstanceManager : Microsoft.VisualBasic.ApplicationServices.WindowsFormsApplicationBase { private SingleInstanceApplication _application; private System.Collections.ObjectModel.ReadOnlyCollection<string> _commandLine; public SingleInstanceManager() { IsSingleInstance = true; } protected override bool OnStartup(Microsoft.VisualBasic.ApplicationServices.StartupEventArgs eventArgs) { // First time _application is launched _commandLine = eventArgs.CommandLine; _application = new SingleInstanceApplication(); _application.Run(); return false; } protected override void OnStartupNextInstance(StartupNextInstanceEventArgs eventArgs) { // Subsequent launches base.OnStartupNextInstance(eventArgs); _commandLine = eventArgs.CommandLine; _application.Activate(); } } Basically we are using the VB bits to detect single instance's and process accordingly. OnStartup will be fired when the first instance loads. OnStartupNextInstance is fired when the application is re-run again. As you can see I can get to what was passed on the command line through the event arguments. I set the value to an instance field. You could parse the command line here or you could pass it to your application through the constructor and the call to the Activate method. Third it's time to create our EntryPoint. Instead of newing up the application like you would normally do we are going to take advantage of our SingleInstanceManager. public class EntryPoint { [STAThread] public static void Main(string[] args) { SingleInstanceManager manager = new SingleInstanceManager(); manager.Run(args); } } Well I hope you are able to follow everything and be able use this implementation and make it your own. This is the way we do it and I've never been too happy about it because of the dependency on WinForms. I'd stick with the mutex solution because it has nothing to do with forms. I've used this because I had issues with other approaches but I'm fairly sure it uses remoting under the hood. My app has had two related issues - some customers say it tries to phone home even though they've told it not to. When they look more carefully the connection is to localhost. Still they don't initially know that. Also I can't use remoting for a different purpose (I think?) because it's already being used for this. When I tried the mutex approach I could then use remoting again. Forgive me but unless I a missing something you avoided writing 3 lines of code and instead you re-used framework just to write pretty heavy code to do it. So where are the savings? it's possible do it in winforms? If you don't call InitializeComponent() on the application instance you won't be able to resolve resources... _application = new SingleInstanceApplication(); _application.InitializeComponent(); _application.Run();  MSDN actually has a sample application for both C# and VB to do exactly this: http://msdn.microsoft.com/en-us/library/ms771662(v=VS.90).aspx The most common and reliable technique for developing single-instance detection is to use the Microsoft .NET Framework remoting infrastructure (System.Remoting). The Microsoft .NET Framework (version 2.0) includes a type WindowsFormsApplicationBase which encapsulates the required remoting functionality. To incorporate this type into a WPF application a type needs to derive from it and be used as a shim between the application static entry point method Main and the WPF application's Application type. The shim detects when an application is first launched and when subsequent launches are attempted and yields control the WPF Application type to determine how to process the launches. For C# people just take a deep breath and forget about the whole 'I don't wanna include VisualBasic DLL'. Because of this and what Scott Hanselman says and the fact that this pretty much is the cleanest solution to the problem and is designed by people who know a lot more about the framework than you do. From a usability standpoint the fact is if your user is loading an application and it is already open and you're giving them an error message like 'Another instance of the app is running. Bye' then they're not gonna be a very happy user. You simply MUST (in a GUI application) switch to that application and pass in the arguments provided - or if command line parameters have no meaning then you must pop up the application which may have been minimized. The framework already has support for this - its just that some idiot named the DLL Microsoft.VisualBasic and it didn't get put into Microsoft.ApplicationUtils or something like that. Get over it - or open up Reflector. Tip: If you use this approach exactly as is and you already have an App.xaml with resources etc. you'll want to take a look at this too. I prefer your answer to be the selected one :) Thank you for including the 'take a look at this too' link. That's exactly what I needed. By the way solution #3 in your link is the best one. Excellent answer. This should be the selected answer.  Normally this is the code I use for single instance winform applications: [STAThread] public static void Main() { String assemblyName = Assembly.GetExecutingAssembly().GetName().Name; using (Mutex mutex = new Mutex(false assemblyName)) { if (!mutex.WaitOne(0 false)) { Boolean shownProcess = false; Process currentProcess = Process.GetCurrentProcess(); foreach (Process process in Process.GetProcessesByName(currentProcess.ProcessName)) { if (!process.Id.Equals(currentProcess.Id) && process.MainModule.FileName.Equals(currentProcess.MainModule.FileName) && !process.MainWindowHandle.Equals(IntPtr.Zero)) { IntPtr windowHandle = process.MainWindowHandle; if (NativeMethods.IsIconic(windowHandle)) NativeMethods.ShowWindow(windowHandle ShowWindowCommand.Restore); NativeMethods.SetForegroundWindow(windowHandle); shownProcess = true; } } if (!shownProcess) MessageBox.Show(String.Format(CultureInfo.CurrentCulture """"An instance of {0} is already running!"""" assemblyName) assemblyName MessageBoxButtons.OK MessageBoxIcon.Asterisk MessageBoxDefaultButton.Button1 (MessageBoxOptions)0); } else { Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); Application.Run(new Form()); } } } Where native components are: [DllImport(""""User32.dll"""" CharSet = CharSet.Unicode ExactSpelling = true SetLastError = true)] [return: MarshalAs(UnmanagedType.Bool)] internal static extern Boolean IsIconic([In] IntPtr windowHandle); [DllImport(""""User32.dll"""" CharSet = CharSet.Unicode ExactSpelling = true SetLastError = true)] [return: MarshalAs(UnmanagedType.Bool)] internal static extern Boolean SetForegroundWindow([In] IntPtr windowHandle); [DllImport(""""User32.dll"""" CharSet = CharSet.Unicode ExactSpelling = true SetLastError = true)] [return: MarshalAs(UnmanagedType.Bool)] internal static extern Boolean ShowWindow([In] IntPtr windowHandle [In] ShowWindowCommand command); public enum ShowWindowCommand : int { Hide = 0x0 ShowNormal = 0x1 ShowMinimized = 0x2 ShowMaximized = 0x3 ShowNormalNotActive = 0x4 Minimize = 0x6 ShowMinimizedNotActive = 0x7 ShowCurrentNotActive = 0x8 Restore = 0x9 ShowDefault = 0xA ForceMinimize = 0xB } The problem by this implementation is that you can't provide any command-line arguments from the second instance back to the first one. For a better explanation [look here](http://www.hanselman.com/blog/TheWeeklySourceCode31SingleInstanceWinFormsAndMicrosoftVisualBasicdll.aspx).  It looks like there is a really good way to handle this. http://blogs.microsoft.co.il/blogs/arik/archive/2010/05/28/wpf-single-instance-application.aspx This provides a class you can add that manages all the mutex and messaging cruff to simplify the your implementation to the point where it's simply trivial. This didn't seem to bring the existing window to the foreground when I tried it.  The following code is my WCF named pipes solution to register a single instance application. It's nice because it also raises an event when another instance attempts to start and receives the command line of the other instance. It's geared toward WPF because it uses the System.Windows.StartupEventHandler class but this could be easily modified. This code requires a reference to PresentationFramework and System.ServiceModel. Usage: class Program { static void Main() { var applicationId = new Guid(""""b54f7b0d-87f9-4df9-9686-4d8fd76066dc""""); if (SingleInstanceManager.VerifySingleInstance(applicationId)) { SingleInstanceManager.OtherInstanceStarted += OnOtherInstanceStarted; // start the application } } static void OnOtherInstanceStarted(object sender StartupEventArgs e) { // Do something in response to another instance starting up. } } Source Code: /// <summary> /// A class to use for single-instance applications. /// </summary> public static class SingleInstanceManager { /// <summary> /// Raised when another instance attempts to start up. /// </summary> public static event StartupEventHandler OtherInstanceStarted; /// <summary> /// Checks to see if this instance is the first instance running on this machine. If it is not this method will /// send the main instance this instance's startup information. /// </summary> /// <param name=""""guid"""">The application's unique identifier.</param> /// <returns>True if this instance is the main instance.</returns> public static bool VerifySingleInstace(Guid guid) { if (!AttemptPublishService(guid)) { NotifyMainInstance(guid); return false; } return true; } /// <summary> /// Attempts to publish the service. /// </summary> /// <param name=""""guid"""">The application's unique identifier.</param> /// <returns>True if the service was published successfully.</returns> private static bool AttemptPublishService(Guid guid) { try { ServiceHost serviceHost = new ServiceHost(typeof(SingleInstance)); NetNamedPipeBinding binding = new NetNamedPipeBinding(NetNamedPipeSecurityMode.None); serviceHost.AddServiceEndpoint(typeof(ISingleInstance) binding CreateAddress(guid)); serviceHost.Open(); return true; } catch { return false; } } /// <summary> /// Notifies the main instance that this instance is attempting to start up. /// </summary> /// <param name=""""guid"""">The application's unique identifier.</param> private static void NotifyMainInstance(Guid guid) { NetNamedPipeBinding binding = new NetNamedPipeBinding(NetNamedPipeSecurityMode.None); EndpointAddress remoteAddress = new EndpointAddress(CreateAddress(guid)); using (ChannelFactory<ISingleInstance> factory = new ChannelFactory<ISingleInstance>(binding remoteAddress)) { ISingleInstance singleInstance = factory.CreateChannel(); singleInstance.NotifyMainInstance(Environment.GetCommandLineArgs()); } } /// <summary> /// Creates an address to publish/contact the service at based on a globally unique identifier. /// </summary> /// <param name=""""guid"""">The identifier for the application.</param> /// <returns>The address to publish/contact the service.</returns> private static string CreateAddress(Guid guid) { return string.Format(CultureInfo.CurrentCulture """"net.pipe://localhost/{0}"""" guid); } /// <summary> /// The interface that describes the single instance service. /// </summary> [ServiceContract] private interface ISingleInstance { /// <summary> /// Notifies the main instance that another instance of the application attempted to start. /// </summary> /// <param name=""""args"""">The other instance's command-line arguments.</param> [OperationContract] void NotifyMainInstance(string[] args); } /// <summary> /// The implementation of the single instance service interface. /// </summary> private class SingleInstance : ISingleInstance { /// <summary> /// Notifies the main instance that another instance of the application attempted to start. /// </summary> /// <param name=""""args"""">The other instance's command-line arguments.</param> public void NotifyMainInstance(string[] args) { if (OtherInstanceStarted != null) { Type type = typeof(StartupEventArgs); ConstructorInfo constructor = type.GetConstructor(BindingFlags.Instance | BindingFlags.NonPublic null Type.EmptyTypes null); StartupEventArgs e = (StartupEventArgs)constructor.Invoke(null); FieldInfo argsField = type.GetField(""""_args"""" BindingFlags.Instance | BindingFlags.NonPublic); Debug.Assert(argsField != null); argsField.SetValue(e args); OtherInstanceStarted(null e); } } } }  I found the simpler solution similar to Dale Ragan's but slightly modified. It does practically everything you need and based on the standard Microsoft WindowsFormsApplicationBase class. Firstly you create SingleInstanceController class which you can use in all other single-instance applications which use Windows Forms: using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Windows.Forms; using Microsoft.VisualBasic.ApplicationServices; namespace SingleInstanceController_NET { public class SingleInstanceController : WindowsFormsApplicationBase { public delegate Form CreateMainForm(); public delegate void StartNextInstanceDelegate(Form mainWindow); CreateMainForm formCreation; StartNextInstanceDelegate onStartNextInstance; public SingleInstanceController(CreateMainForm formCreation StartNextInstanceDelegate onStartNextInstance) { // Set whether the application is single instance this.formCreation = formCreation; this.onStartNextInstance = onStartNextInstance; this.IsSingleInstance = true; this.StartupNextInstance += new StartupNextInstanceEventHandler(this_StartupNextInstance); } void this_StartupNextInstance(object sender StartupNextInstanceEventArgs e) { if (onStartNextInstance != null) { onStartNextInstance(this.MainForm); // This code will be executed when the user tries to start the running program again // for example by clicking on the exe file. } // This code can determine how to re-activate the existing main window of the running application. } protected override void OnCreateMainForm() { // Instantiate your main application form this.MainForm = formCreation(); } public void Run() { string[] commandLine = new string[0]; base.Run(commandLine); } } } Then you can use it in your program as follows: using System; using System.Collections.Generic; using System.Linq; using System.Windows.Forms; using SingleInstanceController_NET; namespace SingleInstance { static class Program { /// <summary> /// The main entry point for the application. /// </summary> static Form CreateForm() { return new Form1(); // Form1 is used for the main window. } static void OnStartNextInstance(Form mainWindow) // When the user tries to restart the application again // the main window is activated again. { mainWindow.WindowState = FormWindowState.Maximized; } [STAThread] static void Main() { Application.EnableVisualStyles(); Application.SetCompatibleTextRenderingDefault(false); SingleInstanceController controller = new SingleInstanceController(CreateForm OnStartNextInstance); controller.Run(); } } } Both the program and the SingleInstanceController_NET solution should reference Microsoft.VisualBasic . If you just want to reactivate the running application as a normal window when the user tries to restart the running program the second parameter in the SingleInstanceController can be null. In the given example the window is maximized.  look at this code.great and simple solution about prevent multiple instance of wpf app  private void Application_Startup(object sender StartupEventArgs e) { Process thisProc = Process.GetCurrentProcess(); if (Process.GetProcessesByName(thisProc.ProcessName).Length > 1) { MessageBox.Show(""""Application running""""); Application.Current.Shutdown(); return; } var wLogin = new LoginWindow(); if (wLogin.ShowDialog() == true) { var wMain = new Main(); wMain.WindowState = WindowState.Maximized; wMain.Show(); } else { Application.Current.Shutdown(); } }  This code should go to the main method. Look at here for more information about the main method in WPF. [DllImport(""""user32.dll"""")] private static extern Boolean ShowWindow(IntPtr hWnd Int32 nCmdShow); private const int SW_SHOWMAXIMIZED = 3; static void Main() { Process currentProcess = Process.GetCurrentProcess(); var runningProcess = (from process in Process.GetProcesses() where process.Id != currentProcess.Id && process.ProcessName.Equals( currentProcess.ProcessName StringComparison.Ordinal) select process).FirstOrDefault(); if (runningProcess != null) { ShowWindow(runningProcess.MainWindowHandle SW_SHOWMAXIMIZED); return; } } Method 2 static void Main() { string procName = Process.GetCurrentProcess().ProcessName; // get the list of all processes by that name Process[] processes=Process.GetProcessesByName(procName); if (processes.Length > 1) { MessageBox.Show(procName + """" already running""""); return; } else { // Application.Run(...); } } I find your Method 2 very clean and simple. Thanks! Method 1 has a nice touch -- it puts focus onto the running app. Method 2 will not work if run as administrator""",c# .net wpf mutex,,2871,A,Reading a C/C++ data structure in C# from a byte array What would be the best way to fill a C# struct from a byte[] array where the data was from a C/C++ struct? The C struct would look something like this (my C is very rusty): typedef OldStuff { CHAR Name[8]; UInt32 User; CHAR Location[8]; UInt32 TimeStamp; UInt32 Sequence; CHAR Tracking[16]; CHAR Filler[12]; } And would fill something like this: [StructLayout(LayoutKind.Explicit Size = 56 Pack = 1)] public struct NewStuff { [MarshalAs(UnmanagedType.ByValTStr SizeConst = 8)] [FieldOffset(0)] public string Name; [MarshalAs(UnmanagedType.U4)] [FieldOffset(8)] public uint User; [MarshalAs(UnmanagedType.ByValTStr SizeConst = 8)] [FieldOffset(12)] public string Location; [MarshalAs(UnmanagedType.U4)] [FieldOffset(20)] public uint TimeStamp; [MarshalAs(UnmanagedType.U4)] [FieldOffset(24)] public uint Sequence; [MarshalAs(UnmanagedType.ByValTStr SizeConst = 16)] [FieldOffset(28)] public string Tracking; } What is best way to copy OldStuff to NewStuff if OldStuff was passed as byte[] array? I'm currently doing something like the following but it feels kind of clunky. GCHandle handle; NewStuff MyStuff; int BufferSize = Marshal.SizeOf(typeof(NewStuff)); byte[] buff = new byte[BufferSize]; Array.Copy(SomeByteArray 0 buff 0 BufferSize); handle = GCHandle.Alloc(buff GCHandleType.Pinned); MyStuff = (NewStuff)Marshal.PtrToStructure(handle.AddrOfPinnedObject() typeof(NewStuff)); handle.Free(); Is there better way to accomplish this? Would using the BinaryReader class offer any performance gains over pinning the memory and using Marshal.PtrStructure? FYI If your program runs on various machines you might need to handle little vs big endian. How can you handle that on the level of the struct i.e. without having to individually reverse the bytes for each value in the struct? From what I can see in that context you don't need to copy SomeByteArray into a buffer. You simply need to get the handle from SomeByteArray pin it copy the IntPtr data using PtrToStructure and then release. No need for a copy. That would be: NewStuff ByteArrayToNewStuff(byte[] bytes) { GCHandle handle = GCHandle.Alloc(bytes GCHandleType.Pinned); NewStuff stuff = (NewStuff)Marshal.PtrToStructure( handle.AddrOfPinnedObject() typeof(NewStuff)); handle.Free(); return stuff; } Generic version: T ByteArrayToStructure<T>(byte[] bytes) where T: struct { GCHandle handle = GCHandle.Alloc(bytes GCHandleType.Pinned); T stuff = (T)Marshal.PtrToStructure(handle.AddrOfPinnedObject() typeof(T)); handle.Free(); return stuff; } ...  object ByteArrayToStructure(byte[] bytearray object structureObj int position) { int length = Marshal.SizeOf(structureObj); IntPtr ptr = Marshal.AllocHGlobal(length); Marshal.Copy(bytearray 0 ptr length); structureObj = Marshal.PtrToStructure(Marshal.UnsafeAddrOfPinnedArrayElement(bytearray position) structureObj.GetType()); Marshal.FreeHGlobal(ptr); return structureObj; } Have this  Watch out for packing issues. In the example you gave all fields are at the obvious offsets because everything is on 4 byte boundaries but this will not always be the case. Visual C++ packs on 8 byte boundaries by default.  If you have a byte[] you should be able to use the BinaryReader class and set values on NewStuff using the available ReadX methods.,c# .net data-structures marshalling26570,A,"sizeof() equivalent for reference types? I'm looking for a way to get the size of an instance of a reference type. sizeof is only for value types. Is this possible? It's not a problem just a curiosity exercise. I have a bunch of items going into HttpContext.Items throughout a request and I was just curious how much memory they were taking up (if it even matters). I'm going through a ""measure everything"" phase. There are other ways to determine this (without code modification). Just use a memory profiler. Any decent profiler will show you number of bytes allocated per particular instance and also all memory that is held by the instance including memory taken by referenced instances. You need Marshal.SizeOf Edit: This is for unsafe code but then so is sizeof(). Marshal.SizeOf might return a different number of bytes than the number used. From MS : Returns the unmanaged size in bytes of a class.  Please refer my answer in the below link. It is possible via .sos.dll debugger extension Find out the size of a .net object  If you don't mind it being a little less accurate than perfect and for comparative purposes you could serialize the object/s and measure that (in bytes for example) EDIT (I kept thinking after posting): Because it's a little more complicated than sizeof for valuetypes for example: reference types can have references to other objects and so on... there's not an exact and easy way to do it that I know of...  If you can - Serialize it! Dim myObjectSize As Long Dim ms As New IO.MemoryStream Dim bf As New Runtime.Serialization.Formatters.Binary.BinaryFormatter() bf.Serialize(ms myObject) myObjectSize = ms.Position  I had a similar question recently and wanted to know the size of Object and LinkedListNode in C#. To solve the problem I developed a program that would: Measure the program's ""Working Set"" Allocate a lot of objects. Measure the ""Working Set"" again. Divide the difference by the number of allocated objects. On my computer (64-bit) I got the following data: Measuring Object: iter working set size estimate -1 11190272 1000000 85995520 74.805248 2000000 159186944 73.998336 3000000 231473152 73.4276266666667 4000000 306401280 73.802752 5000000 379092992 73.580544 6000000 451387392 73.3661866666667 7000000 524378112 73.3125485714286 8000000 600096768 73.613312 9000000 676405248 73.9127751111111 Average size: 73.7577032239859 Measuring LinkedListNode<Object>: iter working set size estimate -1 34168832 1000000 147959808 113.790976 2000000 268963840 117.397504 3000000 387796992 117.876053333333 4000000 507973632 118.4512 5000000 628379648 118.8421632 6000000 748834816 119.110997333333 7000000 869265408 119.299510857143 8000000 993509376 119.917568 9000000 1114038272 119.985493333333 Average size: 118.296829561905 Estimated Object size: 29.218576886067 Estimated LinkedListNode<reference type> size: 44.5391263379189 Based on the data the average size of allocating millions of Objects is approximately 29.2 bytes. A LinkedListNode object is approximately 44.5 bytes. This data illustrates two things: It's very unlikely that the system is allocating a partial byte. The fractional measure of bytes indicates the overhead the CLR requires to allocate and track millions of reference types. If we simply round-down the number of bytes we're still unlikely to have the proper byte count for reference types. This is clear from the measure of Objects. If we round down we assume the size is 29 bytes which while theoretically possible is unlikely because of padding. In order to improve performance object allocations are usually padded for alignment purposes. I would guess that CLR objects will be 4 byte aligned. Assuming CLR overhead and 4-byte alignment I'd estimate an Object in C# is 28 bytes and a LinkedListNode is 44 bytes. BTW Jon Skeet had the idea for the method above before I did and stated it in this answer to a similar question.  Beware that Marshal.SizeOf is for unsafe code... I don't think it's possible for managed code though maybe you can explain your problem there may be another way to solve it",c# .net39,A,Reliable timer in a console application I am aware that in .NET there are three timer types (see Comparing the Timer Classes in the .NET Framework Class Library). I have chosen a threaded timer as the other types can drift if the main thread is busy and I need this to be reliable. The way this timer works in the control of the timer is put on another thread so it can always tick along with the work begin completed on the parent thread when it is not busy. The issue with this timer in a console application is that while the timer is ticking along on another thread the main thread is not doing anything so the application closes. I tried adding a while true loop but then the main thread is too busy when the timer does go off. You can use something like Console.ReadLine() to block the main thread so other background threads (like timer threads) will still work. You may also use an AutoResetEvent to block the execution then (when you need to) you can call Set() method on that AutoResetEvent object to release the main thread. Also ensure that your reference to Timer object doesn't go out of scope and garbage collected. yeah thanks fixed :) congradulations on being the [most relevant answer on Stack Overflow!](http://stackoverflow.com/search?tab=relevance&q=is%3aanswer) (as of Mar26 2012)  Consider using a ManualResetEvent to block the main thread at the end of its processing and call Reset() on it once the timer's processing has finished. If this is something that needs to run constantly consider moving this into a service process instead of a console app.,c# .net vb.net timer9314,A,"""Could not find type"" error loading a form in the Designer I have a .NET 2.0 windows forms app which makes heavy use of the ListView control. I've subclassed the ListView class into a templated SortableListView<T> class so it can be a bit smarter about how it displays things and sort itself. Unfortunately this seems to break the Visual Studio Forms Designer in both VS2005 and 2008. The program compiles and runs fine but when I try view the owning form in the designer I get these Errors: Could not find type 'MyApp.Controls.SortableListView'. Please make sure that the assembly that contains this type is referenced. If this type is a part of your development project make sure that the project has been successfully built. There is no stack trace or error line information available for this error The variable 'listViewImages' is either undeclared or was never assigned. At MyApp.Main.Designer.cs Line:XYZ Column:1 Call stack: at System.ComponentModel.Design.Serialization.CodeDomSerializerBase.Error(IDesignerSerializationManager manager String exceptionText String helpLink) at System.ComponentModel.Design.Serialization.CodeDomSerializerBase.DeserializeExpression(IDesignerSerializationManager manager String name CodeExpression expression) at System.ComponentModel.Design.Serialization.CodeDomSerializerBase.DeserializeExpression(IDesignerSerializationManager manager String name CodeExpression expression) at System.ComponentModel.Design.Serialization.CodeDomSerializerBase.DeserializeStatement(IDesignerSerializationManager manager CodeStatement statement) The line of code in question is where it is actually added to the form and is this.imagesTab.Controls.Add( this.listViewImages ); listViewImages is declared as private MyApp.Controls.SortableListView<Image> listViewImages; and is instantiated in the InitializeComponent method as follows: this.listViewImages = new MyApp.Controls.SortableListView<Image>(); As mentioned earlier the program compiles and runs perfectly and I've tried shifting the SortableListView class out to a seperate assembly so it can be compiled seperately but this makes no difference. I have no idea where to go from here. Any help would be appreciated! I've had a problem like this (tho not the same) in the past where my control was in a different namespace to my form even tho it was in the same project. To fix it I had to add a using My.Other.Namespace; to the top of the designer generated code file. The annoying thing was it kept getting blown away when the designer regenerated the page.  when you added the listview did you add it to the toolbox and then add it to the form?  I had this problem too related to merging massive SVN changes (with conflicts) in the *.Designer.cs file. The solution was to just open up the design view graphically edit a control (move it to the left then right) and resave the design. The *.Designer.cs file magically changed and the warning went away on the next compilation. This is simply not true. If you get any of these warnings then the graphical view is broken. Nothing will show and so you cannot ""move something around to magically fix it"". There is just a list of errors and no gui as the op is complaining about. I disagree strongly; this worked for me like a charm (using Framework 4.0). When initially displaying the designer warnings shoed up for a few seconds then the form was drawn properly. I added a button deleted the button and rebuilt the solution; the warnings all disappeared. Dirk - you can think it is not true but this is what happened to me. I spent hours to trying to fix it. I wish I still had the before and after versions of the Designer.cs file but I don't. There's clearly a bug in Visual Studio that doesn't properly refresh some internal meta data and the only way I found to fix it is to force a refresh by resaving the graphical view.  I had something similar - a user control was referring to a remote serice (which I couldn't guarantee being available at design time). This post on MSDN suggested that I add if (this.DesignMode) return; to the Load function of the control or in my case to the point before the WCF client was initialised. That did the trick. So private readonly Client _client = new Client(); becomes private Client _client; public new void Load() { if(DesignMode) return; _client = new Client(); }  In my case the problem was the folder's name of my project! Why i think this: I use SVN and in the 'trunk\SGIMovel' works perfectly. But in a branch folder named as 'OS#125\SGIMovel' I can't open the designer for a form that uses a custom control and works in the trunk folder. Just get off the # and works nice. Thanks for nothing.  I had the same issue. In my case this issue was due to resource initialization. I moved the following code from InitializeComponent method to ctor(After calling InitializeComponent). After that this issue was resolved: this->resources = (gcnew System::ComponentModel::ComponentResourceManager(XXX::typeid));  The assembly that contains MyApp.Controls.SortableListView isn't installed in the GAC by any chance is it?  when you added the listview did you add it to the toolbox and then add it to the form? No I just edited Main.Designer.cs and changed it from System.Windows.Forms.ListView to MyApp.Controls.SortableListView<Image> Suspecting it might have been due to the generics led me to actually finding a solution. For each class that I need to make a SortableListView for I defined a 'stub class' like this class ImagesListView : SortableListView<Image> { } Then made the Main.Designer.cs file refer to these stub classes instead of the SortableListView. It now works hooray! Thankfully I am able to do this because all my types are known up front and I'm only using the SortableListView as a method of reducing duplicate code.  Perhaps you forgot to add that:  /// <summary> /// Required designer variable. /// </summary> private System.ComponentModel.IContainer components = null; /// <summary> /// Release all resources used. /// </summary> /// <param name=""disposing"">true if managed resources should be removed otherwise; false.</param> protected override void Dispose(bool disposing) { if (disposing && (components != null)) { components.Dispose(); } base.Dispose(disposing); } private void InitializeComponent() { // ... this.components = new System.ComponentModel.Container(); // Not necessarily if You do not use // ... }",c# .net winforms visual-studio-2008 visual-studio-2005