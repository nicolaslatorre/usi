0,A,"MySQL Connection Error with JSP I am trying to connect to mysql database from jsp page. The connection code is as below  InitialContext ic=new InitialContext(); DataSource ds=(DataSource)ic.lookup(""jdbc:mysql://localhost:3306/""); Connection con=ds.getConnection(); Statement stmt = con.createStatement(); when i open the page i get the following error javax.servlet.ServletException: javax.naming.NamingException: Lookup failed for 'jdbc:mysql://localhost:3306/' in SerialContext [Root exception is javax.naming.NameNotFoundException: jdbc:mysql:] can some one please tell me what is wrong with this... Classmate: http://stackoverflow.com/questions/1994073/glassfish-error You're trying to look up a persistent connection using JNDI. JNDI is used to store and access resources in a servlet container but you're using a JDBC connection string instead of a JNDI reference. If you want to connect direct to your database via JDBC in the page you want something like the following to get your connection.  Connection conn = null; try { String userName = ""myuser""; String password = ""mypassword""; String url = ""jdbc:mysql://localhost:3306/mydb""; Class.forName (""com.mysql.jdbc.Driver"").newInstance (); conn = DriverManager.getConnection (url userName password); } catch (Exception e) { System.err.println (""Cannot connect to database server""); } If on the other hand you want to use JNDI you need to store the connection in JNDI first then access it in your JSP via the name you used to store it. It's a more complex process so here's a link to the appropriate place in the Tomcat documentation that explains how to do it.  In the simplest case you do: Class.forName(driverClass); Connection connection = DriverManager.getConnection( ""jdbc:mysql://localhost:3306/"" userName password); If you want to use a container-defined connection pool and you are using tomcat take a look at this page As a sidenote I don't recommend connecting to a database from a .jsp. Use a servlet for that. JSP is a presentation technology and isn't supposed to have database connectivity logic in it."
1,A,What are all the possible values for SQLException.getSQLState? SQLException.getSQLState retrieves the SQLState for the SQLException object. What are all the possible values that can be returned by this method? Can I use the value to identify specific errors that ocured in the database (i.e. can this value tell me if it was a PK violation or a unique constraint or column value to large etc)? Also the DatabaseMetaData.getSQLStateType() method is supposed to indicate whether the SQLSTATE returned by SQLException.getSQLState is X/Open (now known as Open Group) SQL CLI or SQL99. The only possible value for this should be DatabaseMetaData.sqlStateXOpen == 1 and DatabaseMetaData.sqlStateSQL99 == 2 but I am getting the value 0. Am I missing something? Is there a way that I can determine the specific type of error that occurred in the DB using combinations from the above mentioned methods? Can I count on the values of SQLException.getSQLState? Are these values different from DB provider to DB provider? MySQL provides some info here: http://dev.mysql.com/doc/refman/4.1/en/connector-j-reference-error-sqlstates.html  Official documents that include SQLStates can obviously be purchased at a relatively high price from ANSI and XOpen. But the documentation for most databases have lists of SQLStates. Probably the most complete ( and accessible ) online listings are in the DB2 manuals. Check the DB2 Universal Messages manual for instance. Oracle ( TechNet password required ) and Sybase among others also have online listings. As to the second question this is the intent of SQLState however the various databases have varying degrees of compliance. For example some map multiple native error messages to the same SQLState. For generic use one should probably concentrate on the major code ( the first two characters of SQLState ) then determine if more specific info is available in the minor code ( beyond 000. ) http://www.jguru.com/faq/view.jsp?EID=46397  This is to some degree JDBC driver-dependent. There do seem to be standard values plus some proprietary values. As a guide to what's possible Spring's JDBC layer includes SQL error code and state translation. It provides a SQLState translator which gives rather vague exception translation as well as a SQLErrorCode translator which is much more fine-grained using known proprietary error codes. If you can't use Spring then download the source code and extract the sql-error-codes.xml file which contains the mapping from codes to exception types.
2,A,"Looking for a comparison of Scala persistence frameworks I would like to use Scala to persist data to a relational database so what I am looking for are examples of CRUD operations using Scala. I would like to code on a lower level of abstraction than an ORM like Hibernate/Toplink (read:JDBC) but between us I would like to see examples of all types. I am experimenting with mybatis too. mybatis is a mature framework. some examples here: http://www.fdmtech.org/mybatis-for-scala/ Since version 2.0 Querydsl supports Scala as well. It works well with JPA JDO Mongodb and SQL. for JPA JDO and Mongodb see Querying with Scala for SQL see SQL queries in Scala The SQL example is an example of a low abstraction level and Querying with Scala for a high ORM-style abstraction. I am the maintainer of Querydsl so this answer is biased.  EDIT: There's now a pretty good wiki about Scala libraries and frameworks here. I know of five usable non-ORM database libraries for Scala. There's also one ORM which I mention below because it doesn't hide SQL which might just make it a good fit. Slick (previsously named Scalaquery) The first one is Slick. It is the most mature one and it tries to make queries use the same for-comprehension as Scala collections do. As an example of syntax style (which might be slightly out of date): import java.lang.Integer import com.novocode.squery._ import com.novocode.squery.Implicit._ import com.novocode.squery.session._ import com.novocode.squery.session.SessionFactory._ // Define table: object Users extends Table[(Integer String String)](""users"") { def id = intColumn(""id"" O.AutoInc O.NotNull) def first = stringColumn(""first"") def last = stringColumn(""last"") def * = id ~ first ~ last } // Basic usage val sf = new DriverManagerSessionFactory(""org.h2.Driver"" ""jdbc:h2:mem:test1"") sf withSession { // Prepare a simple query val q1 = for(u <- Users) yield u // Print SQL statement to be executed: println(q1.selectStatement) // displays SELECT t1.idt1.firstt1.last FROM users t1 // Print query result: for(t <- q1) println(""User tuple: ""+t) // Query statements can also be used with updates: val q = for(u <- Users if u.id is 42) yield u.first ~ u.last q.update(""foo"" ""bar"") } As the project was renamed recently some resources are still under scalaquery name (website groups). Slick will soon be included in Typesafe stack which can be seen as a proof of its maturity. Querulous The second one is Querulous which is a open source project from Twitter. This one gives you direct access to SQL while dealing with a bunch of jdbc annoyances. Here's a simple example: import com.twitter.querulous.evaluator.QueryEvaluator val queryEvaluator = QueryEvaluator(""host"" ""username"" ""password"") val users = queryEvaluator.select(""SELECT * FROM users WHERE id IN (?) OR name = ?"" List(123) ""Jacques"") { row => new User(row.getInt(""id"") row.getString(""name"")) } queryEvaluator.execute(""INSERT INTO users VALUES (? ?)"" 1 ""Jacques"") queryEvaluator.transaction { transaction => transaction.select(""SELECT ... FOR UPDATE"" ...) transaction.execute(""INSERT INTO users VALUES (? ?)"" 1 ""Jacques"") transaction.execute(""INSERT INTO users VALUES (? ?)"" 2 ""Luc"") } Squeryl The third one is Squeryl. Style-wise it sits midway between ScalaQuery -- which hides SQL behind Scala comprehensions as much as possible -- and Querulous -- which uses SQL strings directly. Squeryl provides a SQL-like DSL which gives you type safety and give you a strong likelyhood that the statements won't fail at run-time if they compile at all. Again a simple example: // Defining tables and a schema: import org.squeryl.PrimitiveTypeMode._ class Author(var id: Long var firstName: String var lastName: String) class Book(var id: Long var title: String @Column(""AUTHOR_ID"") // the default 'exact match' policy can be overriden var authorId: Long var coAuthorId: Option[Long]) { def this() = this(0""""0Some(0L)) } object Library extends Schema { //When the table name doesn't match the class name it is specified here : val authors = table[Author](""AUTHORS"") val books = table[Book] } // Basic usage Class.forName(""org.postgresql.Driver""); val session = Session.create( java.sql.DriverManager.getConnection(""jdbc:postgresql://localhost:5432/squeryl"" ""squeryl"" ""squeryl"") new PostgreSqlAdapter ) //Squeryl database interaction must be done with a using block : import Library._ using(session) { books.insert(new Author(1 ""Michel""""Folco"")) val a = from(authors)(a=> where(a.lastName === ""Folco"") select(a)) } O/R Broker The fourth is O/R Broker which despite the name is not an ORM. Classes can be designed in any way desired. No interfaces/traits to implement no conventions to uphold no annotations needed. case class Song(id: Option[Long] title: String seconds: Short) case class Album(id: Option[Long] title: String year: Short songs: IndexedSeq[Song]) case class Artist(id: Option[Long] name: String albums: Set[Album]) Extractors are declarative written in Scala. Can be reused in other queries that fit the expectation of the extractor. object SongExtractor extends JoinExtractor[Song] { val key = Set(""SONG_ID"") def extract(row: Row join: Join) = { new Song( row.bigInt(""SONG_ID"") row.string(""TITLE"").get row.smallInt(""DURATION_SECONDS"").get ) } } object AlbumExtractor extends JoinExtractor[Album] { val key = Set(""ALBUM_ID"") def extract(row: Row join: Join) = { new Album( row.bigInt(""ALBUM_ID"") row.string(""TITLE"").get row.smallInt(""YEAR_ISSUED"").get join.extractSeq(SongExtractor Map(""TITLE""->""SONG_TITLE"")) ) } } object ArtistExtractor extends JoinExtractor[Artist] { val key = Set(""ARTIST_ID"") def extract(row: Row join: Join) = { new Artist( row.bigInt(""ARTIST_ID"") row.string(""NAME"") join.extractSeq(AlbumExtractor) ) } } One could then use that like this: val ds: javax.sql.DataSource = ... val builder = new SQLFileBuilder(ds new java.io.File(""sql/"")) val broker = builder.build() // Print all artists with their albums (if any) val artists = broker.readOnly() { session => session.selectAll[Artist]('selectArtist) // ' I wish they could fix the Scala Symbol formatting } for (ar <- artists) { println(a.name) if (ar.albums.isEmpty) println(""\t<No albums>"") else for (al <- ar.albums) { println(""\t"" + al.title) for (s <- al.songs) { println(""\t\t"" + (al.songs.indexOf(s)+1) + "". "" + s.title) } } } Anorm Anorm comes from Play Framework and I don't know if it can be used stand alone or not. Basically it ditches mappings and DSL completely giving you direct access to SQL. A simple query may look like this: // Create an SQL query val selectCountries = SQL(""Select * from Country"") // Transform the resulting Stream[Row] as a List[(StringString)] val countries = selectCountries().map(row => row[String](""code"") -> row[String](""name"") ).toList It also supports pattern matching for row extraction: val countries = SQL(""Select namepopulation from Country"")().collect { case Row(""France"" _) => France() case Row(name:String pop:Int) if(pop > 1000000) => BigCountry(name) case Row(name:String _) => SmallCountry(name) } Binding variables in queries uses this syntax: SQL( """""" select * from Country c join CountryLanguage l on l.CountryCode = c.Code where c.code = {countryCode}; """""" ).on(""countryCode"" -> ""FRA"") And it also has support for use of parse combinators to translate queries or even table schemas into data structures. You can either define the parser yourself or use some default conventions (like a case class mapping field names to column names) and let it do the work for you. Circumflex ORM Finally there's Circumflex ORM. I'm copying here a few examples from their site: class Category extends Record[Category] { val id = field(Category.id) val name = field(Category.name) val books = oneToMany(Book.category) // allows navigating between associations transparently } object Category extends Table[Category] with LongIdPK[Category] { val name = stringColumn(""name"") // creates a column .notNull // creates NOT NULL constraint .unique // creates UNIQUE constraint .validateNotEmpty // adds NotEmpty validation .validatePattern(""^[a-zA-Z]{18}$"") // adds Pattern validation } class Book extends Record[Book] { val id = field(Book.id) val title = field(Book.title) val category = manyToOne(Book.category) } object Book extends Table[Book] with LongIdPK[Book] { val title = stringColumn(""title"") .notNull .validateNotEmpty val category = longColumn(""category_id"") .references(Category) // creates an association with Category .onDeleteSetNull // specifies a foreign-key action .onUpdateCascade } new DDLExport(Category Book).create // creates database schema // find category by id val c = Category.get(2l) // find all books val allBooks = Book.all // find books for category val cBooks = c.get.books // find books by title Book.criteria.add(""title"" like ""a%"").list select() .from(Category as ""c"" join (Book as ""b"") Category as ""c1"") .where(""c1.name"" like ""a%"") .addOrder(asc(""c.name"")) .list select(count(""b.id"") ""c.name"").from(Category as ""c"" join (Book as ""b"")).list If I missed any existing project just drop a comment and I'll add them to this answer. Don't bother with blogs papers wikis or the like though. jOOQ Although jOOQ is currently a mostly Java-based solution it still renders SQL quite nicely in Scala thanks to Scala's capabilities of omitting dots and parentheses for some method calls. The following example was taken from an authoritative blog post. Other examples here. // Fetch book titles and their respective authors into // a result and print the result to the console. val result = (create select ( BOOK.TITLE as ""book title"" AUTHOR.FIRST_NAME as ""author's first name"" AUTHOR.LAST_NAME as ""author's last name"") from AUTHOR join BOOK on (AUTHOR.ID equal BOOK.AUTHOR_ID) where (AUTHOR.ID in (1 2 3)) orderBy (AUTHOR.LAST_NAME asc) fetch) and also // Iterate over authors and the number of books they've written // Print each value to the console for (r <- (create select (AUTHOR.FIRST_NAME AUTHOR.LAST_NAME count) from AUTHOR join BOOK on (AUTHOR.ID equal BOOK.AUTHOR_ID) where (AUTHOR.ID in (1 2 3)) groupBy (AUTHOR.FIRST_NAME AUTHOR.LAST_NAME) orderBy (AUTHOR.LAST_NAME asc) fetch)) { print(r.getValue(AUTHOR.FIRST_NAME)) print("" "") print(r.getValue(AUTHOR.LAST_NAME)) print("" wrote "") print(r.getValue(count)) println("" books "") } @Daniel Thanks. Also once I started playing around with it I realized it works only for MySQL. I'd appreciate if you could mention it. Could you update the Querulous link to https://github.com/twitter/querulous? The latest development have moved to that fork. @Eugene Well I could mention it but it is the kind of thing that it is likely to evolve out of and I wouldn't be aware of it. I think it is better to leave this kind of detail to each project. @Eugene Done thanks! @Bill I'm not familiar with them but aren't they rather tied to Lift and besides ORMs? Don't forget about Mapper and Record in the Lift framework. Also I cannot comment on individual libraries here. Querulous seems to be poorly maintained and Anorm does not work out of the box with non Play applications. +=Prequel https://github.com/jpersson/prequel/ @DanielC.Sobral I was looking for an examples for MongoDB (http://www.mongodb.org/) and just thought your great list of examples may be the ideal home for such? Their tutorial may prove sufficient although not in your concise style and not on this post. Here's the link: http://api.mongodb.org/scala/casbah/current/tutorial.html @JacobusR There's so much MongoDB stuff for Scala... I have kind of given up updating this -- there's just too many options. The wiki I linked to at the beginning is far more complete than I could possibly be but if you want to edit the question and add it I won't object to it. I'm having trouble deciding between Twitter's Querelous and Prequel. Does anyone have experience with both? Activate-framework is another one - http://activate-framework.org/ Would you be so kind to update your Slick example? I can't figure out what imports do I need to make with current Slick and Scala versions for the example to work. I think it would be worth mentioning [jOOQ](http://www.jooq.org) in your answer. [jOOQ renders quite beautifully in Scala](http://www.jooq.org/doc/3.1/manual/getting-started/jooq-and-scala/) OK thanks Daniel. I added a section about jOOQ. @LukasEder There are _so many_ things that could be added! I like [SQLTyped](https://github.com/jonifreeman/sqltyped) for instance but it's not worth editing this answer anymore. Even the question is closed. You have reputation enough to edit the answer and add `jOOQ` so go ahead. +1 Prequel https://github.com/jpersson/prequel which now has an JavaRx scala wrapper to run the queries on background threads with the results pushed to you through an rx observer at https://github.com/simbo1905/prequel  A quick google search for ""scala database dsl"" gave me. Scala Query http://github.com/szeiger/scala-query http://szeiger.de/blog/category/scala/scala-query/ www.cs.uwm.edu/~dspiewak/papers/scalaql.pdf I didn't find any others out there maybe there is if I kept searching but this one looks ok.  I created a new one named ScalikeJDBC. It's a simple JDBC wrapper library. Maybe 'Executable SQL template' is the unique feature. https://github.com/seratch/scalikejdbc It also has source code generator. Especially if you access the existing legacy database it's much convenient. https://github.com/seratch/scalikejdbc-mapper-generator Futhermore it's easy to integrate with Play20. https://github.com/seratch/scalikejdbc-play-plugin Please take a look at it. I really enjoy working with ScalikeJDBC. My favourite db lib. Been trying Anorm Squeryl Slick - but this fits my needs just perfect.  IMO JPA2.0 is still one of the most flexible and advanced concepts (especially using it with BeanValidation JTA JNDI existing/complex relational schema etc.). It is true that JPA (as well as the most Java and Java annotation based specifications) does not fit nicely into Scala's concepts (especially collections that have to be converted). Nevertheless it can be used rather easily with some wrapper Classes and Objects. some Advantages: Pluggable Implementations Widely used standard Widely available experience Supported by application server vendors Three major JPA 2.0 implementations: EclipseLink OpenJPA Hibernate Examples using some simple wrapping: Entity Manager and Entity Manager Factory class MyClass extends Something with SimpleEntityManagerFactory with ThreadLocalEntityManager { def getPersistenceUnitName = ""mip"" . . . } Object Item Entity Uses inheritance strategy joined and a sequence for primary key @Entity @Table(name = ""obj_item"") @Inheritance(strategy = InheritanceType.JOINED) @SequenceGenerator(name = ""obj_item_id_seq"" sequenceName = ""obj_item_id_sequence"" allocationSize = 1) class ObjectItem extends MIPEntity { @Id @GeneratedValue(strategy = GenerationType.SEQUENCE generator = ""obj_item_id_seq"") @Column(name = ""obj_item_id"" nullable = false length = 20) @BeanProperty var id: BigInteger = _ @Column(name = ""cat_code"" nullable = false length = 6) @BeanProperty var objItemCatCode: String = _ } Using Id Class Identity More complex association using Id Class for Entity Identity Fields. @Entity @Table(name = ""org_struct"") @IdClass(classOf[OrganisationStructureId]) @SequenceGenerator(name = ""org_struct_index_seq"" sequenceName = ""org_struct_index_sequence"" allocationSize = 1) class OrganisationStructure extends MIPEntity { @Id @GeneratedValue(strategy = GenerationType.SEQUENCE generator = ""org_struct_index_seq"") @Column(name = ""org_struct_ix"" nullable = false length = 20) @BeanProperty protected var ix: BigInteger = _ @Id @ManyToOne(fetch = FetchType.EAGER) @JoinColumn(name = ""org_struct_root_org_id"" nullable = false updatable = false) @BeanProperty protected var orgStructRootOrg: Organisation = _ . . . } Id Class for Entity Identity Fields: class OrganisationStructureId { @BeanProperty var orgStructRootOrg: BigInteger = _ @BeanProperty var ix: BigInteger = _ . . . } All this is provided by ScalaJPA and JPA-for-Scala (see Github). Both are rather small wrapper around usual JPA classes. The latter one provides some ideas for externalized query strings filter objects and transaction scope wrappers. F.e.: Using Filter and executing query: . . . val filter: NameFilter = newFilterInstance(QueryId(""FindObjectItemFromNameWithFilter"")) filter.name = ""%Test%"" var i = 0 forQueryResults { oi: ObjectItem => i = i + 1 } withQuery (filter) i must_== 10 . . . Remove user: withTrxAndCommit { findAndApply(id ) { u:User => remove(u) } } Execute a native PostGIS SQL query and expect one result: withTrxAndCommit { oneResultQueryAndApply { d: Double => eStatRet.setDistance(d) } withNativeQuery (QueryId(""DistancePointFromTextToLocID"") postGISPoint user.getUsersLocation.getId) } I'am not sure I'am for the 'more advanced concepts'. A data access library is here to make things easier... For that ScalaQuery from Tweeter is perfect. You get the expressivity of SQL that you miss in most ORM dialects you can use features specific to your database vendor or stick to a standard like SQL92. JPA can do nearly the same for CRUD operations but when you start to use it for complex mappings strategies you hit the famous impedance mismatch problem. Naming it 'ORM' doesn't solve it magically. Relations are not objects and theses mapping strategies tend to have huge drawbacks. Honestly JPA is a nice idea but often generates so much database chatter and so many unnecessary queries that it has become a blight on the face of Java development. Once you annotate a domain object for JPA then again for some XML framework then again for some other view system you end up with a pretty nasty looking class. It's a hard problem to solve but JPA is not a good answer it's at best mediocre. I don't really have a problem with database chatter or unnecessary queries with Hibernate/ JPA and since I still prefer .hbm.xml mappings files my code is fairly clean :) I've always been dubious both with Hibernate and Spring/DI about the real logical & architectural benefits (or not) of shovelling all that into the actual code.. for configuration/DI at least it spoils the goal of code reusability which was the _purpose_ of configuration/DI in the first place.  For those who like me nearly bypassed Querulous because it seemed to be MySQL-only that's not the case (at least not anymore). It's not documented but if you look at the signatures for QueryEvaluator you'll see that you can pass in the driverName. The following worked for me for postgres: # dbhost(s) dbname username password urlOptions driverName val queryEvaluator = QueryEvaluator(""host"" ""dbname"" ""username"" ""password"" Map[StringString]() ""jdbc:postgresql"")  Here's a complete Scala + JDBC example this worked out to be the simplest solution I found. import java.sql.{Connection DriverManager ResultSet}; // Change to Your Database Config val conn_str = ""jdbc:mysql:/localhost:3306/DBNAME?user=DBUSER&password=DBPWD"" // Load the driver classOf[com.mysql.jdbc.Driver] // Setup the connection val conn = DriverManager.getConnection(conn_str) try { // Configure to be Read Only val statement = conn.createStatement(ResultSet.TYPE_FORWARD_ONLY ResultSet.CONCUR_READ_ONLY) // Execute Query val rs = statement.executeQuery(""SELECT quote FROM quotes LIMIT 5"") // Iterate Over ResultSet while (rs.next) { println(rs.getString(""quote"")) } } finally { conn.close } I wrote up my complete experience here: http://mkaz.com/archives/1259/using-scala-with-jdbc-to-connect-to-mysql/ So basically you are not handling exceptions correctly and this answer is not really *Scala* at all: it's just using the basic JDBC classes. This code will leak connections I updated to include a try {} finally {} block the goal was not to make it the most ""pure"" Scala answer but a working example without version conflicts which is what I had with Queroulous and others I just needed something simple for importing data and you reminded me that this is still nice and simple for that puropse.  MapperDao has evolved since my last post it now supports 5 databases (mysqlpostgresqloraclesqlserverderby) and pretty much any mapping that can be done with other ORM tools. Queries and pagination is quite cool: val pe=PersonEntity //alias val people=query(QueryConfig.pagination(2 10)select from pe where pe.lives === house) The wiki covers everything from transactions to paginating and creating dao's mixing CRUD traits. https://code.google.com/p/mapperdao/ There are now circumflex web and liftweb examples which use mapperdao for persistence: https://code.google.com/p/mapperdao-examples/ Enjoy! Good work Κώστα !  This was recently announced on the Scala-Announce mailing list: http://code.google.com/p/orbroker/ Full freedom on class design. O/R Broker does not place any limitations on how you design your classes. No restrictions whatsoever. You write the SQL. This allows you to hand tune any query even after deployment is faster than configuring some obscure XML syntax. Full support for JOIN queries both one-to-one and one-to-many. No N+1 select problem and no transactionally inconsistent lazy loading Support for stored procedure calls. You write the query-to-object extractor code in Scala (or Java). No tired old XML mapping needed. SQL can be in code or preferably in simple text files ready for editing and optimizing if needed. Dynamic SQL using Velocity or FreeMarker template engines. Both are supported but neither are required. Dealing with new database schema legacy schema JavaBeans or immutable classes? All possible full flexibility.  I am happy to announce the 1st release of a new ORM library for Scala. MapperDao maps domain classes to database tables. It currently supports mysql postgresql (oracle driver to be available soon) one-to-one many-to-one one-to-many many-to-many relationships autogenerated keys transactions and optionally integrates nicely with spring framework. It allows freedom on the design of the domain classes which are not affected by persistence details encourages immutability and is type safe. The library is not based on reflection but rather on good Scala design principles and contains a DSL to query data which closely resembles select queries. It doesn't require implementation of equals() or hashCode() methods which can be problematic for persisted entities. Mapping is done using type safe Scala code. Details and usage instructions can be found at the mapperdao's site: http://code.google.com/p/mapperdao/ The library is available for download on the above site and also as a maven dependency (documentation contains details on how to use it via maven) Examples can be found at: https://code.google.com/p/mapperdao-examples/ Very brief introduction of the library via code sample: class Product(val name: String val attributes: Set[Attribute]) class Attribute(val name: String val value: String) ... val product = new Product(""blue jean"" Set(new Attribute(""colour"" ""blue"") new Attribute(""size"" ""medium""))) val inserted = mapperDao.insert(ProductEntity product) // the persisted entity has an id property: println(""%d : %s"".format(inserted.idinserted)) Querying is very familiar: val o=OrderEntity import Query._ val orders = query(select from o where o.totalAmount >= 20.0 and o.totalAmount <= 30.0) println(orders) // a list of orders I encourage everybody to use the library and give feedback. The documentation is currently quite extensive with setup and usage instructions. Please feel free to comment and get in touch with me at kostas dot kougios at googlemail dot com. Thanks Kostantinos Kougios  Here's another one: ScalaSQL https://github.com/chochos/scalasql I wrote this one; it's loosely based on the Groovy SQL component which I find to be very practical and easy to use."
3,A,"Tomcat 6 can't find mysql driver There is a similar question here but regarding the class path. http://stackoverflow.com/questions/1585811/classnotfoundexception-com-mysql-jdbc-driver I've had everything working great until some days ago. Suddenly my little application can't find the mysql driver. And i don't understand why (really I've checked everything) I got the driver jar in the WEB-INF/lib but tomcat just seems unable to find it. Anyone got any ideas why? I'm using Ubuntu with tomcat 6 and mysql installed from the synaptics packadge manager The error that is giving is: ClassNotFoundException: com.mysql.jdbc.Driver I've even changed the permissions into 777 to see if it could be invisibile but it isn't :( The colon in the message ""com.mysql.jdbc:Driver"" is not what I'd expect to see. Is that for real or a typing error? typing error i was copying this by hand from another computer. How are you trying to create a datasource? From within your application or from a JNDI bound connection pool (DBCP)? If you created a datasource which requires this driver then it should be placed directly in the classpath of the container which manages the datasource. In this case it's Tomcat which manages the datasource. Thus with placing the driver in Tomcat/lib you'll be fine. Apart from that you told you're using Ubuntu. It ships by default with a GNU JDK. I would only highly recommend that you ensure that you get rid of it and install the Sun JDK instead. The GNU JDK is cluttered of bugs which may cause at first sight unexplainable problems. Hope you take this into consideration. I changed it and now it finds the driver in web-inf/lib ty CATALINA_HOME is more appropriate than ""Tomcat"" to avoid confusion with CATALINA_BASE. Also the reference to buggy GNU JDK while certainly valid at the time of writing does no longer apply (although Oracle JDK vs OpenJDK is debatable but that's another topic).  Try putting the MySQL JDBC driver in $CATALINA_HOME/lib and restart the web server. Also make sure the tomcat user (or whatever user you are running tomcat as) has permissions to read it.  Download ""mysql-connector-java-5.1.13-bin.jar"" from following link http://sqlworkbench.mgm-tp.com/viewvc/trunk/sqlworkbench/junit/mysql-connector-java-5.1.13-bin.jar?revision=2294&pathrev=2294 and copy it to ""Tomcat/lib"" folder ie...""$CATALINA_HOME/lib"" folder and restart Tomcat  Add the jar file in tomcat lib. I think you can delete the jar file from application's WEB-INF/lib because then there might be two definitions for one class. So just copy the jar file in tomcat lib. hope this helps. :)"
4,A,"How can I set the current schema for DB2 using Hibernate/JDBC? I used to use currentSchema=MYSCHEMA; in my JDBC URL connection but the version of DB2 we're using no longer supports that showing the error 'The ""currentSchema"" property is not allowed on the target server'. I've tried using hibernate.default_schema but it's not automatically adding the schema to my table names. I don't want to set the schema on every @Table annotation since I'll need to change it between test and production. Is there another way to set on the connection or via Hibernate? Update: it must have been a driver version issue. I upgraded to later drivers and currentSchema worked. what is the URL to connect to a database on AS400 using the driver 'com.ibm.as400.access.AS400JDBCDriver'... 'currentSchema' included in the URL is not working in this case...  With DB2 JDBC type 4 driver (com.ibm.db2.jcc.DB2Driver) I'm using this URL to connect : jdbc:db2://<HOST>:<PORT>/<DATABASE>:currentSchema=<SCHEMA>; Source: http://publib.boulder.ibm.com/infocenter/db2luw/v8/index.jsp?topic=/com.ibm.db2.udb.doc/ad/rjvdsprp.htm  All the properties for the 9.7 (Latest) db are here... https://publib.boulder.ibm.com/infocenter/db2luw/v9r7/index.jsp?topic=/com.ibm.db2.luw.apdv.java.doc/doc/r0052607.html use: currentSchema Specifies the default schema name that is used to qualify unqualified database objects in dynamically prepared SQL statements. The value of this property sets the value in the CURRENT SCHEMA special register on the database server. The schema name is case-sensitive and must be specified in uppercase characters. Right I mentioned that I had tried that and it didn't work. It looks like I had an older version of the JDBC driver and updating fixed it. Thanks."
5,A,"how to check for duplicate entries in database? I need to apply a check so that a user cannot register using an email id which already exists in the database. It's not clear: are you interfacing to mysql in Java? Just select that email in database and see if its in. You might wanna tell what database your using and so on. yes i am using my sql database. and i have set emailid fied as primary key You may: make the email field unique try to insert and catch the exception or make a select before each insert  Put a constraint on the email column or select before insert. +1 - *""or select before insert""* ... in the same transaction! +1 - Enforce data constraints at the database level whenever possible (or practical). +1 This is the right way to solve it  Probably something like this DAO method : public boolean isDuplicateEntry(String email) { Session session = getSession(); try { User user = (User) session.get(User.class email); session.close(); return (null != user); } catch (RuntimeException e) { log.error(""get failed"" e); session.close(); throw e; } } I would recommend putting session.close() in a finally block. Not that its a huge deal but this is a classic example where you would want to use a finally block in my opinion. where should i put this code? thankyou.....i did it @tkeE2036 you are right @bhavna raghuvanshi you should put it somewhere where your DAO classes are  There are indeed basically two ways to achieve this: Test if record exists before inserting inside the same transaction. The ResultSet#next() of the SELECT should return false. Then do INSERT. Just do INSERT anyway and determine if SQLException#getSQLState() of any catched SQLException starts with 23 which is a constraint violation as per the SQL specification. It can namely be caused by more factors than ""just"" a constraint violation. You should namely not handle every SQLException as a constraint violation. public static boolean isConstraintViolation(SQLException e) { return e.getSQLState().startsWith(""23""); } I would opt for the first way as it is semantically more correct. It is in fact not an exceptional circumstance. You namely know that it is potentially going to happen. But it may potentially fail in heavy concurrent environment where transactions are not synchronized (either unawarely or to optimize performance). You may then want to determine the exception instead. That said you normally don't want to put a PK on an email field. They are namely subject to changes. Rather use a DB-managed autogenerated PK (MySQL: BIGINT UNSIGNED AUTO_INCREMENT Oracle/PostgreSQL: SERIAL SQLServer: IDENTITY) and give the email field an UNIQUE key. I would prefer the second to avoid two calls to the database. Agree with you about the email field. Not a good candidate for a primary key. @HLGEM: A query on an indexed field is cheap. Creating an exception is expensive. I am not sure. Profile before microoptimizing or just don't microoptimize at all ;) Exception should hit very rarely so it can be more expensive one hit to the database vice two happens with every insert. Ergo it will in the long run be more expensive. But you are right when faced with multiple choices it is a good idea to profile.  Put a unique constraint on the relevant column in the database table. For example (MySQL): ALTER TABLE Users ADD UNIQUE (Email) edit - If the e-mail field is already a primary key as you write in a comment above then you don't need this because primary keys are by definition unique. Then in Java you could catch the SQLException that you get if you'd insert a record with a primary key that already exists or you can do a SELECT ... WHERE Email=? before you try the insert to see if there is already a record with that e-mail address."
6,A,"How to obtain the list of Oracle's SIDs I have the host port user id and password but missing SID for connecting to Oracle DBMS. How can I find the list of SIDs on that server? There is an nmap script that maybe could help oracle-sid-brute: http://nmap.org/nsedoc/scripts/oracle-sid-brute.html It was installed with nmap on my system. nmap --script oracle-sid-brute -p 1521-1560 [host] This would only help if the SID can be matched in a list. The default list is here: http://www.red-database-security.com/scripts/sid.txt  Another option to consider is the file /etc/oratab on Unix or its equivilent on Windows which I think is a registry hive. The oratab should list all SIDs on a host whether currently running or not. Comment from @saritonin who does not have the privileges to comment: ""Please note that the /etc/oratab may not be helpful if the $ORACLE_SID parameter is the wildcard `*`"".  The question comes down to : which ORACLE_SID's or services are supported by the listener that is running on host X port Y. Depending on how secure this listener is configured you can see this using the lsnrctl command from a client that has lsnrctl installed. To be able to do this you do need an oracle server installation on that client. When you have that you can issue lsnrctl set current_listener (description=(address=(host=X)(port=Y)(protocol=tcp))) status The default setting of the 10g listener fill cause the following result: TNS-01189: The listener could not authenticate the user This is because from 10g oracle default has Security ON: Local OS Authentication meaning that only the local OS user that started the listener can issue lsnrctl commands to the listener. The listener will refuse to answer any other user.  A better way is if you have access to the host machine and the Oracle install is to use the command: lsnrctl status. This works on both Unix Linux and Windows machines. The status command will show you all the listeners (and their associated SIDs). C:\>lsnrctl status LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 15-JUN-2009 16:16:34 Copyright (c) 1991 2005 Oracle. All rights reserved. Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC_FOR_XE))) STATUS of the LISTENER ------------------------ Alias LISTENER Version TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production Start Date 13-JUN-2009 12:04:14 Uptime 2 days 4 hr. 12 min. 19 sec Trace Level off Security ON: Local OS Authentication SNMP OFF Default Service XE Listener Parameter File C:\oracle\XE\app\oracle\product\10.2.0\server\network\admin\listener.ora Listener Log File C:\oracle\XE\app\oracle\product\10.2.0\server\network\log\listener.log Listening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=\\.\pipe\EXTPROC_FOR_XEipc))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=ThinkpadT61)(PORT=1521))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=8080))(Presentation=HTTP)(Session=RAW)) Services Summary... Service ""CLRExtProc"" has 1 instance(s). Instance ""CLRExtProc"" status UNKNOWN has 1 handler(s) for this service... Service ""PLSExtProc"" has 1 instance(s). Instance ""PLSExtProc"" status UNKNOWN has 1 handler(s) for this service... Service ""XEXDB"" has 1 instance(s). Instance ""xe"" status READY has 1 handler(s) for this service... Service ""XE_XPT"" has 1 instance(s). Instance ""xe"" status READY has 1 handler(s) for this service... Service ""xe"" has 1 instance(s). Instance ""xe"" status READY has 1 handler(s) for this service... The command completed successfully In the above example you can connect to the XE database using the Conect Strings XEXDB XE_XPT or XE. I had considered this approach for my answer but technically this only works if for the default listener. The more convoluted approach to using lsnrctl is first get a list of listeners via ps-ef|grep lsnr  and then issue the STATUS command for each of the listeners. Didn't want to overcomplicate the answer since probably 99% of installations use the default listener setup  The short answer is that you need access to the host OS: For Unix ps -ef|grep pmon will show you one or more processes with names like ora_pmon_xxxx and xxxx is the instance name. In Windows I guess there is a similar signature in the task list. In practice this information is usually given to you by whoever administers the database when your connecting account is created. In Windows SID wouldn't be visible under taskmanager you will have to check the running services (services.msc) to check for SID. Eg: OracleServiceORCL assuming ORCL is the SID Thanks - for the clarification - no experience on Windows platform"
7,A,"Java: MySQL query. Get generated ID I have a table that contains a column called 'id' that is an INT that auto increments and is set to be the primary key. I need to get the value of the generated ID after the query is run. I have the following: String sql = ""INSERT...""; Statement statement = sqlConnection.createStatement(); int result = statement.executeUpdate(sql Statement.RETURN_GENERATED_KEYS); this.id = statement.getGeneratedKeys().getInt(""id""); I get the following exception on the last line of code: javax.servlet.ServletException: java.sql.SQLException: Column 'id' not found. com.joelj.music.rest.NewUser.doPost(NewUser.java:44) javax.servlet.http.HttpServlet.service(HttpServlet.java:754) javax.servlet.http.HttpServlet.service(HttpServlet.java:847) com.joelj.music.rest.filters.Prefilter.doFilter(Prefilter.java:44) If I change it to statement.getGeneratedKeys().getInt(0); I get the following: javax.servlet.ServletException: java.sql.SQLException: Before start of result set com.joelj.music.rest.NewUser.doPost(NewUser.java:44) javax.servlet.http.HttpServlet.service(HttpServlet.java:754) javax.servlet.http.HttpServlet.service(HttpServlet.java:847) com.joelj.music.rest.filters.Prefilter.doFilter(Prefilter.java:44) I've gone through the other methods and have tried this and that. I have looked at example code found on the internet. I just can't see what I'm doing wrong. Note: The query is run in both of the solutions I've included. So the connection works fine. It's getting back the value of the ID that isn't working. Thanks for the help. Have you tried using statement.getGeneratedKeys().getInt(1)? The Result set is one based. That doesn't work. Gives me the same exception as using a 0. Ahh you have a second problem check this out: http://stackoverflow.com/questions/2120255/java-resultset-exception-before-start-of-result-set had to call `.next()` on the result set before calling `.getInt(1)`. Awesome. Thanks Michael"
8,A,"Whats the difference between using out parameters vs. result fetching by column in stored procedures that return a single result called through JDBC? I know for more than one result you don't have much choice for using out parameters but I'm wondering whats the difference between the following 2 cases where there's one out parameter. Say I have two stored procedures: CREATE PROCEDURE no_out_params(IN foo INT) BEGIN SELECT foo + 1 as result; END and CREATE PROCDURE with_out_params(IN foo INT OUT result INT) BEGIN SET result = foo + 1; END Then using JDBC I can either: CallableStatement c1 = conn.prepareCall(""{ call no_out_params(?)}""); c1.setInt(1 5); ResultSet rs = c1.executeQuery(); if (rs.next()) { return rs.getInt(""result""); // or rs.getInt(1) } or CallableStatement c1 = conn.prepareCall(""{ call with_out_params(? ?)}""); c1.setInt(1 5); c1.registerOutParameter(2 Types.INT); c1.executeQuery(); return c1.getInt(2); Assuming you're properly closing everything in try/finally's (omitted for brevity) does the non-out parameter method provide any advantage? If not is it reasonable to assume that one should always use out parameters (if only to to be consistent in cases where there's more than one result)? Assuming you're properly closing everything in try/finally's (omitted for brevity) does the non-out parameter method provide any advantage? The advantage is being able to retrieve the result set (in any language Java/etc) without having to define all the OUT parameters (extra work for no value). If you're only returning one value you might want to see if a FUNCTION would work instead. Unfortunately my particular case requires transactions with rollback so I think that rules out using a FUNCTION. I did notice in a somewhat related but different issue that if you call a stored procedure from within a stored procedure you need an out parameter (I think I believe you could also use temporary tables)."
9,A,"How to create a database deadlock using jdbc and JUNIT I am trying to create a database deadlock and I am using JUnit. I have two concurrent tests running which are both updating the same row in a table over and over again in a loop. My idea is that you update say row A in Table A and then row B in Table B over and over again in one test. Then at the same time you update row B table B and then row A Table A over and over again. From my understanding this should eventually result in a deadlock. Here is the code For the first test. public static void testEditCC() { try{ int rows = 0; int counter = 0; int large=10000000; Connection c=DataBase.getConnection(); while(counter<large) { int pid = 87855; int cCode = 655; String newCountry=""Egypt""; int bpl = 0; stmt = c.createStatement(); rows = stmt.executeUpdate(""UPDATE main "" + //create lock on main table ""SET BPL=""+cCode+ ""WHERE ID=""+pid); rows = stmt.executeUpdate(""UPDATE BPL SET DESCRIPTION='SomeWhere' WHERE ID=602""); //create lock on bpl table counter++; } assertTrue(rows == 1); //rows = stmt.executeUpdate(""Insert into BPL (ID DESCRIPTION) VALUES (""+cCode+"" '""+newCountry+""')""); } catch(SQLException ex) { ex.printStackTrace(); //ex.getMessage(); } } And here is the code for the second test. public static void testEditCC() { try{ int rows = 0; int counter = 0; int large=10000000; Connection c=DataBase.getConnection(); while(counter<large) { int pid = 87855; int cCode = 655; String newCountry=""Jordan""; int bpl = 0; stmt = c.createStatement(); //stmt.close(); rows = stmt.executeUpdate(""UPDATE BPL SET DESCRIPTION='SomeWhere' WHERE ID=602""); //create lock on bpl table rows = stmt.executeUpdate(""UPDATE main "" + //create lock on main table ""SET BPL=""+cCode+ ""WHERE ID=""+pid); counter++; } assertTrue(rows == 1); //rows = stmt.executeUpdate(""Insert into BPL (ID DESCRIPTION) VALUES (""+cCode+"" '""+newCountry+""')""); } catch(SQLException ex) { ex.printStackTrace(); } } I am running these two separate JUnit tests at the same time and am connecting to an apache Derby database that I am running in network mode within Eclipse. Can anyone help me figure out why a deadlock is not occurring? Perhaps I am using JUnit wrong. How are you running two test methods at the same time? JUnit is executing test methods sequentially. I have two JUnit test cases and run one then switch over to the other one and run that one and it shows both of them running. I see. What transaction isolation level are you using? That is something that I didn't set. I am not sure what that means but I remember the Professor telling us to not change the timeout for the transactions. I am not sure if that is related. You should check the transaction isolation level as it determines whether or not the DB locks rows touched by a transaction. If the isolation level is too low no locking occurs so no deadlock either. Update: according to this page the default tx isolation level for Derby is read committed which should be OK. The page is worth reading btw as it explains tx isolation and its different levels and what problems it solves. Next question then: what is DataBase in your code? This seems to be a nonstandard way to get a connection. Update2: I think I got it. Quote from the API doc: Note: By default a Connection object is in auto-commit mode which means that it automatically commits changes after executing each statement. If auto-commit mode has been disabled the method commit must be called explicitly in order to commit changes; otherwise database changes will not be saved. In other words rows are not locked because your effective transactions last only for the lifetime of individual updates. You should switch off autocommit before starting to work with your connection: Connection c=DataBase.getConnection(); c.setAutoCommit(false); Ok so it must be the transactions I am doing are not the type that cause deadlocks. I am not sure what else to try so I will have to do some more reading. I have a class that I called 'DataBase' that has all my methods in it. One of them is getConnection. It just uses the DriverManager.getConnection(url) method from JDBC. @Isawpalmetto OK I think I got it - see my last update. There we go now I am getting them thanks a lot. Update: What I am getting is actually just a lock timeout. A deadlock is not happening and I am pretty sure it is not the code because I have tried various deadlock examples from the internet. It must be some settings with JUnit. @Isawpalmetto Or the DB. I guess the DB detects that the lock can not be acquired and interrupts the transaction after a certain amount of time passed. I observed the same some time ago. @Isawpalmetto And this is indeed the case with Derby - see http://db.apache.org/derby/docs/10.0/manuals/develop/develop75.html @Isawpalmetto One more note: in order to achieve a proper deadlock (where thread A and B wait for each other indefinitely) you should ensure that test 1 gets to lock row 1 and test 2 locks row 2 first. With your current setup it is IMHO unlikely: what probably happens is that one of the connections gets _both_ locks and then runs on happily while the other blocks. If you start both tests _exactly_ the same time you have _some_ chance of achieving deadlock. To increase your chances you could insert a sleep period (of e.g. 10 seconds) after the first `executeUpdate` in both tests. I actually changed the tests from the one that I had posted and was still having the same problem. Then I was thinking that maybe the timeOut lock I was getting was because the updates were happening too fast so that the other thread couldn't even get a lock on the row. I added the sleep period and now I am getting deadlocks. Thanks"
10,A,how to display a table retrieved from database to a jsp page via a controller page in Struts framework i have created a model class to connect with database with a function that retrives a table data.now this function should return whole resultset back to a Controller action page. further controller action should send the data to jsp page for client viewing. or simply how to hold Resultset data from query like..select * from table Related: http://stackoverflow.com/questions/1831053/displaying-multiple-records-by-using-resultset/1832524#1832524 In Model class you can convert your ResultSet into List which subsequently returned to view.The only code you need to write is converting ResultSet into List of Object i used ArrayList.i got class cast exception:ResultSet cannot be cast to ArrayList Yeah ResultSet can't be converted into ArrayList. You need to iterate over ResultSet and insert each object from ResultSet into ArrayList
11,A,"JDBC DatabaseMetaData.getColumns() returns duplicate columns I'm busy on a piece of code to get alle the column names of a table from an Oracle database. The code I came up with looks like this: DriverManager.registerDriver (new oracle.jdbc.driver.OracleDriver()); Connection conn = DriverManager.getConnection( ""jdbc:oracle:thin:@<server>:1521:<sid>"" <username> <password>); DatabaseMetaData meta = conn.getMetaData(); ResultSet columns = meta.getColumns(null null ""EMPLOYEES"" null); int i = 1; while (columns.next()) { System.out.printf(""%d: %s (%d)\n"" i++ columns.getString(""COLUMN_NAME"") columns.getInt(""ORDINAL_POSITION"")); } When I ran this code to my surprise too many columns were returned. A closer look revealed that the ResultSet contained a duplicate set of all the columns i.e. every column was returned twice. Here's the output I got: 1: ID (1) 2: NAME (2) 3: CITY (3) 4: ID (1) 5: NAME (2) 6: CITY (3) When I look at the table using Oracle SQL Developer it shows that the table only has three columns (ID NAME CITY). I've tried this code against several different tables in my database and some work just fine while others exhibit this weird behaviour. Could there be a bug in the Oracle JDBC driver? Or am I doing something wrong here? Update: Thanks to Kenster I now have an alternative way to retrieve the column names. You can get them from a ResultSet like this: DriverManager.registerDriver (new oracle.jdbc.driver.OracleDriver()); Connection conn = DriverManager.getConnection(""jdbc:oracle:thin:@<server>:1521:<sid>"" <username> <password>); Statement st = conn.createStatement(); ResultSet rset = st.executeQuery(""SELECT * FROM \""EMPLOYEES\""""); ResultSetMetaData md = rset.getMetaData(); for (int i=1; i<=md.getColumnCount(); i++) { System.out.println(md.getColumnLabel(i)); } This seems to work just fine and no duplicates are returned! And for those who wonder: according to this blog you should use getColumnLabel() instead of getColumnName(). What happens if you look a meta.getTables(null null ""EMPLOYEES"" null)? Are you getting only one table or more than one? In oracle Connection.getMetaData() returns meta-data for the entire database not just the schema you happen to be connected to. So when you supply null as the first two arguments to meta.getColumns() you're not filtering the results for just your schema. You need to supply the name of the Oracle schema to one of the first two parameters of meta.getColumns() probably the second one e.g. meta.getColumns(null ""myuser"" ""EMPLOYEES"" null); It's a bit irritating having to do this but that's the way the Oracle folks chose to implement their JDBC driver. Thanks. I'll try your solution tomorrow. However during one of my debugging sessions I also printed the values of ""TABLE_SCHEM"" and for every column they were the same... So I hope filtering on that will work.  This doesn't directly answer your question but another approach is to execute the query: select * from tablename where 1 = 0 This will return a ResultSet even though it doesn't select any rows. The result set metadata will match the table that you selected from. Depending on what you're doing this can be more convenient. tablename can be anything that you can select on--you don't have to get the case correct or worry about what schema it's in. Wow thanks! As a matter of fact I was trying to get the column names from a ResultSet in the first place because that's the way I'm used to do it in ADO.Net (i.e. retrieve Fields from a RecordSet). But I didn't know how to retrieve column data from a ResultSet. Then I found the approach using DatabaseMetaData.getColumns(). However your answer put me in the right direction. I had totally missed the ResultSet.getMetaData() method which is perfect for my solution. I'll update the question above. Also works perfectly with MySQL.  In the update to your question I noticed that you missed one key part of Kenster's answer. He specified a 'where' clause of 'where 1 = 0' which you don't have. This is important because if you leave it off then oracle will try and return the ENTIRE table. And if you don't pull all of the records over oracle will hold unto them waiting for you to page through them. Adding that where clause still gives you the metadata but without any of the overhead. Also I personally use 'where rownum < 1' since oracle knows immediately that all rownums are past that and I'm not sure if it's smart enough to not try and test each record for '1 = 0'.  In addition to skaffman's answer - use the following query in Oracle: select sys_context( 'userenv' 'current_schema' ) from dual; to access your current schema name if you are restricted to do so in Java.  This is the behavior mandated by the JDBC API - passing nulls as first and second parameter to getColumns means that neither catalog name nor schema name are used to narrow the search. Link to the documentation . It is true that some other JDBC drivers have different behavior by default (e.g MySQL's ConnectorJ by default restricts to the current catalog) but this is not standard and documented as such"
12,A,"Spring Framework JDBC DAO with agrgegation/composition I have an application that is already using the Spring Framework and Spring JDBC with a DAO layer using the SimpleJdbcTemplate and RowMapper classes. This seems to work very well with small class structures being read from the database. However we have the need to load objects that hold collections of other objects which hold collections of other objects still. The ""obvious"" solution to this problem is to create a named RowMapper class or our objects and pass references to the proper DAO objects in the constructor. For example: public class ProjectRowMapper implements ParameterizedRowMapper { public ProjectRowMapper(AccountDAO accountDAO ) { this.accountDAO = accountDAO; } public Project mapRow(ResultSet rs int rowNum) throws SQLException { Project project= new Project (); project.setProjecttId( rs.getString(""project_id"") ); project.setStartDate( rs.getDate(""start_date"") ); // project.setEtcetera(...); // this is where the problems start project.setAccounts( accountDAO.getAccountsOnProject(project.getProjectId()) ); } } The problem is that even though the ProjectDAO and the Account DAO share the same DataSource instance (in our case this is a connection pool) any database accesses are done through a different connection. If the object hierarchy is even three levels deep using this implementation results in (a) many calls by the framework to datasource.getConnection() and (2) even worse since we cap the number of connections allowed in our connection pool potential race conditions while multiple threads are trying to load a Project from the database. Is there a better way in Spring (without another full-fledged ORM tool) to achieve the loading of such object hierarchies? Thanks Paul A full-fledged ORM tool is exactly what you need here. These problems are hard don't reinvent them. Is there any transaction around your code? We use the same nested dao pattern for loading complex objects but Spring JDBC is only using one connection I guess you have reasons for not using an ORM which is the ideal tool for this kind of problem. The problem with multiple connections is the recursive call to another DAO. To avoid consuming additional connections Account objects should be to be retrieved later after the project instance has been fetched. When fetching the Project the accountIDs are also fetched but not ""instantiated"" to account instances - they remain as a list of IDs which are then populated after the project DAO has done it's work. For example you can build a custom List type that takes a list of IDs and a DAO implementation. The list is populated with just the IDs in the ProjectRowMapper and assigned to the project's accounts property. The IDs are private to the list - they are not the ""contents"" of the list but a means to produce the real contents later. Once the Project DAO has fetched the projects from the RowMapper it can then instruct the list to then fetch the accounts for the IDs that were saved in the list. The accounts are fetched as s non-nested operation and so the whole process only uses one connection at any time. Yetthe fetch is done within the scope of the DAO method so the fetch is done eagerly - so there are no lazy-loading issues to deal with. This is what I did and it works wonderfully for now."
13,A,DB Connection pool in Servlet or Listener? I'm thinking of using DB Connection Pool in J2EE. Database: MySQL Servlets: http://www.webdevelopersjournal.com/columns/connection_pool.html Listeners: http://onjava.com/onjava/2006/04/19/database-connection-pooling-with-tomcat.html now which is a better option & why? Also any working source code will help me save time. Warm Regards I really wouldn't go for a homegrown connection pool as in your 1st link. There are a lot of factors you need to take account with and those are surely not covered by the example given in that article. Forget about it don't homegrow a connection pool it's a way too important core piece of your webapplication. Go for a container managed connection pool with an existing connection pooling implementation like mentioned in your 2nd link. You have nowadays the choice of under each DBCP and C3P0. DBCP is already inbuilt in Tomcat but it's singlethreaded and thus not really performant when talking about a busy-visited website. Alternatively (and Tomcat-specific) there's also a tomcat-jdbc which removes this DBCP limitation but as it's fairly new I'd rather go for C3P0 as it's already been thoroughly developed and maintained for ages and is nowadays been very robust and performant. It says the last update on C3P0 is 2007-05-21 ?? Does that mean there are NO updates in the recent times and NO issues found ??? It's so good that they couldn't make it better.
14,A,delete derby tables when program ends I'm using in-memory derby db for my java application. I would like to delete all the tables/databases it created once the application ends. So when it starts back up I want it to start fresh. i know i can add delete statements at the end of the class...i was wondering if there was a setting that i could turn on/off If you application uses only a single database connection then derby global temporary tables would provide what you need.
15,A,Specify IBatis query timeout There is a way to specify IBatis query timeout using oracle jdbc and Java? Thanks From the iBatis manual : in the <settings> element : defaultStatementTimeout (iBATIS versions 2.2.0 and later) This setting is an integer value that will be applied as the JDBC query timeout for all statements. This value can be overridden with the “statement” attribute of any mapped statement. If not specified no query timeout will be set unless specified on the “statement” attribute of a mapped statement. The specified value is the number of seconds the driver will wait for a statement to finish. Note that not all drivers support this setting. on the statement paremeters : timeout (iBATIS versions 2.2.0 and later only) Sets the JDBC query timeout for this statement. Any value specified here will override the value specified in the “defaultStatementTimeout” setting in the SQLMapConfig.xml file. If you specify a default timeout and decide that you don't want a timeout for a particular statement set the timeout value to 0. The specified value is the number of seconds the driver will wait for a statement to finish. Note that not all drivers support this setting. The oracle drivers support this functionality so this should work. Hi Peter is there any list available that shows the drivers are supported? We are trying to use these parameters using the driver com.ibm.as400.access.AS400JDBCDriver. Do you know if this driver is supported or if there is another approach to specifying this timeout value The setQueryTimeout function is supported according to the javadoc http://publib.boulder.ibm.com/infocenter/iseries/v5r3/index.jsp?topic=%2Frzahh%2Fjavadoc%2Fcom%2Fibm%2Fas400%2Faccess%2FAS400JDBCStatement.html . Maybe post a specific question with the error someone might shed more light?
16,A,"JDBC postgres query with a timeout Unfortunately setTimeout is not implemented for JDBC/postgres. Is there some way I can simulate or workaround this? Functionally I want to execute the query and the then break if it takes longer than N seconds I found this question and answer helpful also for a python/psycopg2 issue I encountered. Psycopg2 seems to have allow timeout setting at connection time but this interface was abstracted away in my case. Adding this comment to benefit others searching on SO. One way might be to try running the query in a Timer class. Throw an exception if the Timer ends without a value returned. Hibernate and JDO supply such a construct. Maybe they'd be good alternatives for you.  The ""statement_timeout"" looks like what you want. SET statement_timeout TO 1000; -- for a second <your_query_here>; RESET statement_timeout; -- reset You're better off using RESET statement_timeout; after the query has completed - in case there is a default value... Fixed now thanks! Tested this on pgAdmin3. Only worked when the SET statement_timeout is executed separately from the actual query. When executed together pgAdmin3 uses whatever the timeout value was already set and dosen't use the one provided with the query.  What if you were to use c3p0 for your dataSource? It has lots of configurable options and for cranky databases and networks for example acquireRetryAttempts acquireRetryDelay and breakAfterAcquireFailure."
17,A,extract data from .xls file I want to extract data from a Excel file and store them into a access database how to do this? among these api's that has been mentioned which is considered good for the beginners to start with You can use the Java Excel API to extract the data. You can find the javadoc here. There is also a programmer's guide on how to use JExcel I found this API extremely easy to use for extracting information from an existing Excel file.  The Apache POI library provides access to Microsoft Office formats including Excel. To insert into a database you'll need JDBC (and possibly additional frameworks if you want an ORM). Here's a tutorial on JDBC to get you started. You may want to check out Hibernate as a useful Java ORM.  First do you really need Java for this? The MSAccess software itself provides functionality to import data from an Excel file. It's much easier to do so. If you really need Java for this then you need to realize that this is in fact a two-step task: Extract data from Excel into Java objects (e.g. List<List<String>> or List<Data>). Save data from those Java objects into MSAccess. For step 1 you need a Java API which is capable to extract data from an Excel file. Which one to use depends on the actual file format. If it is a .xls file you have in general two options: the aforementioned Apache POI HSSF and JExcelAPI. The POI HSSF is known to be memory hogging and its API is a bit opaque in use. Andy Khan's JExcelAPI is the better choice. If it is a .xlsx file (the last x indicates that it's in OpenXML format instead of binary format) then you have next to the aforementioned Apache POI XSSF also the choice to to use OpenXML4J which is -again- generally a better choice than the POI XSSF for the same reasons as the POI HSSF. Now for step 2 you need a Java API which can save data into a MSAccess file. You can use the JDBC API for this in combination with the builtin JDBC-ODBC bridge driver. A good starting point is the JDBC tutorial.
18,A,"What purpose does Class.forName() serve if you don't use the return value? I've seen this line in a sample application for using a commercial JDBC driver: Class.forName(""name.of.a.jcdb.driver"") The return value is not used. What purpose does this line serve? Nowadays I'd call this an antipattern and favour something like 'DriverManager.register(JdbcDriver.class)'... using register directly requires you to know the driver class before hand. i'd call that an anti-pattern. having the class as a configuration property (and thus Class.forName) makes far more sense to me. See http://stackoverflow.com/q/8053095/632951 for more information. In the case of JDBC drivers the static initializer of the requested class will register the driver with JDBC’s DriverManager so that getting a connection for a driver-specific URL works.  In your specific example the JDBC driver class contains a static intializer that registers the driver will the DriverManager.  This is used in particular for JDBC drivers. The JDBC driver class has a static initializer block that registers the class with the JDBC DriverManager so that DriverManager knows about the driver when you later open a database connection. In a newer version of JDBC (JDBC 3.0 I think) this is not necessary anymore a different mechanism is used by DriverManager to find JDBC drivers. edit - This page explains in detail how loading a JDBC driver works and how the driver registers itself with the DriverManager (the old way). Anybody with a link to a description of the new mechanism? I need something similar. The javadoc for DriverManager from JDK 6 tells about a couple of methods for the DriverManager to find drivers: http://java.sun.com/javase/6/docs/api/java/sql/DriverManager.html  Maybe some code snippet will help. This is from Sun's JDBC-ODBC bridge driver //-------------------------------------------------------------------- // Static method to be executed when the class is loaded. //-------------------------------------------------------------------- static { JdbcOdbcTracer tracer1 = new JdbcOdbcTracer(); if (tracer1.isTracing ()) { tracer1.trace (""JdbcOdbcDriver class loaded""); } JdbcOdbcDriver driver = new JdbcOdbcDriver (); // Attempt to register the driver try { DriverManager.registerDriver (driver); } catch (SQLException ex) { if (tracer1.isTracing ()) { tracer1.trace (""Unable to register driver""); } } } the DriverManager.registerDriver() call in a static block is executed whenever the driver is loaded through Class.forName(). This used to be the only way to register the driver. JDBC 4.0 introduced a new service registration mechanism so you don't need to do this anymore with newer JDBC 4.0 compliant drivers. +1 for showing the actual code.  to manul load class in current classloader  It performs a static loading of that class. So anything in the static { } block will run. Which lets the driver class register itself with the JDBC framework. This is needed to allow JDBC to properly recognize the connection URL you pass in in the later calls. a ""static"" loading? is it not just loading the class which starts any static initializer (static block AND static variables/constants)?"
19,A,"jsp coding problem I am a programmer new to jsp trying to write some code. i have written like  <% int i=1; String connectionURL = ""jdbc:mysql://localhost:3306/registration""; Connection connection = null; Statement stmt = null; ResultSet rset = null; Statement stmt1 = null; ResultSet rset1 = null; Class.forName(""com.mysql.jdbc.Driver"").newInstance(); int updateQuery = 0; try { connection = DBUtil.createConnection();//DriverManager.getConnection(connectionURL ""root"" ""root""); String queryString = ""select * from course""; System.out.println(""select all from course table""); stmt = connection.createStatement(); System.out.println(""Statment object ""+ stmt ); rset = stmt.executeQuery(queryString); System.out.println(""Result set "" + rset ); while (rset.next()) { System.out.println("" Results...""); String s1 = rset.getString(1); Double amount = rset.getDouble(""amount""); String loginid = rset.getString(""loginid""); String queryString1 = ""select * from users where loginid = '""+ loginid +""'""; System.out.println(""select user details from users table""); System.out.println(queryString1); stmt1 = connection.createStatement(); System.out.println(""Statment object ""+ stmt1 ); rset1 = stmt1.executeQuery(queryString1); System.out.println(""Result set "" + rset1 ); System.out.println("" name -> "" + rset1.getString(2)); %> <tr class=""subtext1""> <td align=""left""><%=i%> </td> <td align=""left""><%=rset.getString(""name"")%></td> <td align=""left""><%=rset.getString(""loginid"")%></td> <td align=""left""><%=rset.getString(""name"")%></td> <td align=""left""><%=rset.getString(""email"")%></td> <td align=""left""><%=rset.getString(""iimbtrack"")%></td> <td align=""left""><%=rset.getString(""result"")%></td> <td align=""left"">CourseFee/<%=rset.getString(""product"")%></td> <td align=""left""><%=amount%></td> <td align=""left""><%=rset.getString(""fdate"")%></td> </tr> When I try to print this it gives error. But when I remove this line: System.out.println("" name -> "" + rset1.getString(2)); It works. Where am I going wrong? This is the error I get statment object com.mysql.jdbc.Statement@429be9 Result set com.mysql.jdbc.ResultSet@10a0d51 java.sql.SQLException: Before start of result set at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:910) at com.mysql.jdbc.ResultSet.checkRowPos(ResultSet.java:703) at com.mysql.jdbc.ResultSet.getStringInternal(ResultSet.java:5653) at com.mysql.jdbc.ResultSet.getString(ResultSet.java:5597) at org.apache.jsp.WEB_002dINF.jsp.secure.transaction.feesreports_jsp._jspService(feesreports_jsp.java:235) at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:98) at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:331) at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:329) at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:265) at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:269) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:188) at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:679) at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:461) at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:399) at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:301) at org.apache.struts.action.RequestProcessor.doForward(RequestProcessor.java:1056) at org.apache.struts.tiles.TilesRequestProcessor.doForward(TilesRequestProcessor.java:261) at org.apache.struts.action.RequestProcessor.processForwardConfig(RequestProcessor.java:388) at org.apache.struts.tiles.TilesRequestProcessor.processForwardConfig(TilesRequestProcessor.java:316) at org.apache.struts.action.RequestProcessor.process(RequestProcessor.java:231) at org.apache.struts.action.ActionServlet.process(ActionServlet.java:1158) at org.apache.struts.action.ActionServlet.doGet(ActionServlet.java:397) at javax.servlet.http.HttpServlet.service(HttpServlet.java:627) at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:269) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:188) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:213) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:172) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:117) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:108) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:174) at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:875) at org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection(Http11BaseProtocol.java:665) at org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpoint.java:528) at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFollowerWorkerThread.java:81) You should use a PreparedStatement for your second query because (1) it's called once for every loop iteration and (2) it has a parameter. Create the object outside of the while loop then set the parameter inside the while loop. `PreparedStatement ps = conn.preparedStatement(""select * from users where loginid = ?""); ps.setString(1 loginId);` You should explicitly list the columns you are requesting rather than using a wildcard. There's no guarantee as to the order of columns in your result set otherwise. Consider what would happen if somebody added a column in the middle of the table (and yes this does happen).  What is the exact error you are getting? My suspicion is that there is only one column in ""users"" table while you are asking for second column data. Or if there is no data then the ""rset1"" will be null. I strongly suggest you to look for the MVC pattern. nope there are more then 2 columns. now that you have posted the stack trace the solution is as suggested by ""BalusC"" `ResultSet` is never **never** `null`. If there is no data then `ResultSet#next()` will simply return `false`. Or if something fails during obtaining the data then just a `SQLException` will be thrown. Also see the **Returns:** entry of the [Statement#executeQuery() javadoc](http://java.sun.com/javase/6/docs/api/java/sql/PreparedStatement.html#executeQuery%28%29) you are right...becaz of a quick galnace on the javadoc i got confused ""never null"" with ""null""  You need to call ResultSet#next() to move the cursor to the next row otherwise you cannot access any data from the row. If you expect multiple rows do this in a while loop: while (rset1.next()) { System.out.println("" name -> "" + rset1.getString(2)); } Or if you expect only one row then do this in an if statement: if (rset1.next()) { System.out.println("" name -> "" + rset1.getString(2)); } See also: JDBC tutorial How to iterate through a ResultSet That said this code is honestly said not the right way to achieve the functional requirement of displaying the data from a DB in a HTML table. This database interaction task shouldn't be done inside a JSP file but in a real Java class. The JSP page should be kept scriptlet-free. See also: How to avoid Java code in JSP files How to display data from database in a HTML table in JSP page"
20,A,"mixing basic DataSource with connection pooling DataSource: when to call close()? I'm in the process of adding connection pooling to our java app. The app can work with different rdbmses and both as a desktop app and as a headless webservice. The basic implementation works fine in desktop mode (rdbms = derby). When running as a webservice (rdbms = mysql) we see that connection pooling is needed to get good concurrent behaviour. My initial approach was to use dependency injection to decide between a basic DataSource or a connection pooling DataSource at startup time. The problem in this scenario is that I don't know when to call connection.close(). My understanding is that when using connection pooling you should close() after each query so the connection object can be recycled. But the current non-pooling implementation tries to hang on to the Connection object as long as possible. Is there a solution to this problem? Is there a way to recycle a basic connection object? What happens if I don't call connection.close() with a thread pooled connection object? Or is it simply a bad design to mix these two connection strategies? If I understand you correctly essentially you are doing your own pooling implementation by holding on to the connection as long as possible. If this strategy is successful (that is the program is behaving as you describe it) then you have your own pool already. The only thing adding a pool will gain you is to improve the response time when you make a new connection (as you won't really be making one you will be getting it from the pool) which is apparently not happening all that often. So I would cycle back to the assumption underlying this question: Is it in fact the case that your concurrent performance problems are related to database pooling? If you are using transactions in the MySQL and not the Derby that could be a big cause of concurrency issues as an example of a different potential cause. To answer your question directly use a database pool all the time. They are very little overhead and of course change the code to release connections quickly (that is when the request is done not as long as the user has a screen open for example) rather than holding on to them forever. upvoted for ""use a database pool all the time"" That's only part of the reason connection pooling also helps to make more efficient use of resources because if there is only one Connection then only one thread at a time can do database work - at least this seems to be the case for MySQL. @amarillion pooling helps with that but the underlying issue there is that you have to make one connection per thread. You could do that without out a pool (just make a new one in the thread). I don't fully understand... Why is holding on to single connection also a connection pool? That doesn't make sense to me. But you may be right that my concurrency problems are caused by something different. It appears that what I need is more fine-grained synchronization. @amarillion basically what a database pool gets you is that it avoids the (usually expensive) network hit of authenticating to the database. If a process could take 500ms the authentication can be 2s making something 2.5s instead of ~500ms. If you are ""tr[ying] to hang on to the Connection object as long as possible."" you are essentially using a different technique to accomplish the same thing: Minimize the impact of authentication time to the database."
21,A,"How can I add a InterBase JDBC connection pool in GlassFish V3? Using: InterBase 2007 latest interclient.jar (8.1.8) GlassFish v3 b68. I try to configure the connection pool in the web admin console page ""Edit Connection Pool"" with these settings: Resource Type: javax.sql.DataSource Datasource Classname: interbase.interclient.DataSource A 'ping' in the same screen returns this error message: java.lang.NullPointerException: ""null"" interbase.interclient.Connection.(Unknown Source) interbase.interclient.DataSource.getConnection(Unknown Source) interbase.interclient.DataSource.getConnection(Unknown Source) com.sun.gjc.spi.DSManagedConnectionFactory.createManagedConnection(DSManagedConnectionFactory.java:102) com.sun.enterprise.connectors.service.ConnectorConnectionPoolAdminServiceImpl.getManagedConnection(ConnectorConnectionPoolAdminServiceImpl.java:517) com.sun.enterprise.connec... The interclient.jar 8.1.8 (Interbase 2007) is in the domain lib directory. The exception is not clear but that's an implementation detail. At least the getConnection() usually expects a non-null JDBC URL. So did you specify a valid JDBC URL for the datasource? The same URL works fine in a simple JDBC test. I will accept you answer so that the points will not be lost ;)"
22,A,"How to use mysql IN comparison function with JDBC This seems simple but it is impossible to search the web for... I have a legacy application that uses JDBC directly with no frameworks and I'm having to add some new features. I'm having issues finding out how to use the IN() function via JDBC. I would like to have a query like the following SELECT * from animals WHERE animal_name IN (...) Where the ... is an array of values. Using JDBC i would think I would do the following. PreparedStatement st = conn.prepareStatement(""SELECT * from animals WHERE animal_name IN (?);""); st.setArray(arrayVals); ResultSet rs = st.executeQuery(); .... But this does not work and I'm finding it next to impossible to find any reference to this on the web. That's because PreparedStatement parameters are a single value based on the data type not a list of comma delimited fields. Create the SQL Statement as a string before the `conn.prepareStatement(...` if you want to use dynamic SQL outside of the database. Just an observation but are you sure you need the semicolon at the end of the statement? possible duplicate of [What is the best approach using JDBC for parameterizing an IN clause?](http://stackoverflow.com/questions/2861230/what-is-the-best-approach-using-jdbc-for-parameterizing-an-in-clause) @BalusC you're right about it being a dupe...If I could have found that i probably wouldnt have posted. As I said in the question its very hard to search for anything about the IN clasue Enough results for [preparedstatement in clause site:stackoverflow.com](http://www.google.com/search?q=preparedstatement+in+clause+site%3Astackoverflow.com) Replace your code with something like: StringBuilder sb = new StringBuilder(""SELECT * from animals WHERE animal_name IN (""); // 1. assemble query parameters for (int i = 0; i < arrayVals.size(); i++) { sb.append(""?""); if (i + 1 < arrayVals.size()) sb.append(""""); } sb.append("")""); // 2. add the variables PreparedStatement st = conn.prepareStatement(sb.toString()); for (int i = 0; i < arrayVals.size(); i++) { // May need to replace setter depending on type of object st.setObject(i + 1 o); } As an alternative using spring JDBCs JdbcTemplate you would replace part 2 with this: jdbcTemplate.query(sb.toString() arrayVals.toArray() animalRowMapper); JdbcTemplate will determine the sql types needed for each parameter."
23,A,Java PreparedStatement UTF-8 character problem I have a prepared statement: PreparedStatement st; and at my code i try to use st.setString method. st.setString(1 userName); Value of userName is şakça. setString methods changes 'şakça' to '?akça'. It doesnt recognize UTF-8 characters. How can i solve this problem? Thanks. What database are you using? And is it configured to accept Unicode (or whatever you need for şakça) in that column? The number of ways this can get screwed up is actually quite impressive. If you're using MySQL try adding a characterEncoding=UTF-8 parameter to the end of your JDBC connection URL: jdbc:mysql://server/database?characterEncoding=UTF-8 You should also check that the table / column character set is UTF-8.  Whenever a database changes a character to ? then it simply means that the codepoint of the character in question is completely out of the range for the character encoding as the table is configured to use. As to the cause of the problem: the ç lies within ISO-8859-1 range and has exactly the same codepoint as in UTF-8 (U+00E7). However the UTF-8 codepoint of ş lies completely outside the range of ISO-8859-1 (U+015F while ISO-8859-1 only goes up to U+00FF). The DB won't persist the character and replace it by ?. So I suspect that your DB table is still configured to use ISO-8859-1 (or in one of other compatible ISO-8859 encodings where ç has the same codepoint as in UTF-8). The Java/JDBC API is doing its job perfectly fine with regard to character encoding (Java uses Unicode all the way) and the JDBC DB connection encoding is also configured correctly. If Java/JDBC would have incorrectly used ISO-8859-1 then the persisted result would have been ÅakÃ§a (the ş exist of bytes 0xC5 and 0x9F which represents Å and a in ISO-8859-1 and the ç exist of bytes 0xC3 and 0xA7 which represents Ã and § in ISO-8859-1).  setString methods changes 'şakça' to '?akça' How do you know that setString changes this? Or do you see the content in the database and decide this? It could be that the database is not configured for UTF-8 or simply that the tool you use to see the contects of the database (SQL*PLUS for Oracle...) is not capable of diaplaying UTF-8.
24,A,How to accept REF cursor in JAVA without importing Oracle Package I am writting JAVA programme using JDBC for database conntectivity  I am calling one stored procedure in that which is returning ORACLE REF CURSOR  IS there any way I can handle that without importing ORACLE PACKAGES ? I think I tried to do this a while ago and kind of gave up (I guess you could figure out what int value the OracleTypes.REF_CURSOR is and then use that int value but that's a hack). If you got the patience you could define a record (or object) type and define the the cursor as a cursor with type since that can be cast using table to a value that is selectable like regular tables ie select * from table( sp_returning( ? ) ) I did a quick google on ref cursor and jdbc and it looks like it might be an oracle extension which would explain why there is no standard way to access the data.  Doing select * from table( sp_returning( ? ) ) is slower than returning a ref cursor. I can use a ref cursor in combination with C# why can't you do it with Java? I'm sure there are plenty examples. That is not an answer. It is merely conjecture.
25,A,"Java Database Connectivity (JDBC) session handling? I am using MySql 5 Hi I am using/start learing JDBC. Well I got stuck here: After an user authenticated I would like to start/generate the session for the user. How do I do that? In php I know we can start by using the ""start_session()"" function. Is there any similar function in JDBC? If there is no such kind of functions how do we create/start session? I am really new to JDBC so this question may sound stupid to you all but I really cant find the answer over the internet and thats why I ask this question here. (My best resource) Oh ya btw if its possible can you include in the answer about the session destroy/delete as well? Thanks in millions EDIT Okay looks like this question abit too easy(or too tough??). Maybe could try this one is there any other way that java can unique identify an logged in user beside using session?? Use the database authentication itself. Which DB engine are you talking about? I am using Mysql for database. Java for server-side scripting. Use database authentication? What do you mean?? You're looking at the wrong technology. The Web-Layer of Java is built from Servlets/JSPs. Those are the parts that will handle your session. JDBC is *only* used for Database-access and has absolutely no relevancy for this problem. Assuming you are talking in the context of web application. There is a session provided by the Servlet container. You authenticate the user and set the credentials in the session of that user to re-use whenever necessary for example to know the privileges of the user etc.. Regarding JDBC we usually go with connection pooling mechanism. So it has nothing to do with the HTTP session of the user. We get the connection from the pool and place it back once done. If you need to manage transaction or something you can look into JTA. [Edited] Try to look at the code of this Simple Login application. I am sure it will help. Thanks Vinegar. It does help me :) I am glad......  JDBC is only about interacting with databases (and things that look like them); the concept of a user session doesn't have anything to do with interacting with a database. As the user Vinegar has suggested if you are doing Java web development there is a session implementation available. I suggest you provide more info on what you are doing and if that includes some sort of web development (I'm assuming yes since you come from a PHP background).  start_session in php creates a user session if it does not exist. In the jave web app we have a HttpSession class whose instance is created by doing: request.getSession(boolean) This call : Gets the current valid session associated with this request if create is false or if necessary creates a new session for the request if create is true. This has nothing to do with JDBC calls - that are mainly related to connection establishment and execution of queries. +1 for noting that star_session() doesn't have anything to do with the Database and that JDBC handles *only* the database.  Maybe the JDBC programming modl doesn't look quite the same as php. Have you tried turorials auch as this note the use use of Statements and ResultSets. You don't see a ""Session"""
26,A,"enterprise with jdbc I have enterprise project but all queries are implemented using oracle stored procedures I use jbdc and Spring framework to get results like this :  public class HoaDonDAOimpl extends JdbcDaoSupport implements HoaDonDAO { public List<HoaDon> getDsTatcaHoadonPhathanh(int vthang int vnam String vmaDvqltb) throws Exception { CallableStatement cs = getDataSource().getConnection().prepareCall( ""{call PKG_QLNO.GetDsTatcaHoadonPhathanh(????)}""); cs.setInt(1 vthang); cs.setInt(2 vnam); cs.setString(3 vmaDvqltb); cs.registerOutParameter(4 OracleTypes.CURSOR); cs.execute(); ResultSet rs = (ResultSet) cs.getObject(4); List<HoaDon> list = new ArrayList<HoaDon>(); while (rs.next()) { HoaDon hoadon = new HoaDon(); hoadon.setChon(rs.getString(""chon"")); hoadon.setMa_so(rs.getString(""ma_so"")); hoadon.setMa_kh(rs.getString(""ma_kh"")); hoadon.setNam(rs.getString(""nam"")); hoadon.setThang(rs.getString(""thang"")); hoadon.setTien_PS(rs.getString(""tien_PS"")); hoadon.setThue_ps(rs.getString(""thue_ps"")); hoadon.setTien_khmai(rs.getString(""tien_khmai"")); hoadon.setTien_tbi(rs.getString(""tien_tbi"")); hoadon.setTong_ps(rs.getString(""tong_ps"")); hoadon.setTenkh(rs.getString(""tenkh"")); hoadon.setMa_dvqltb(rs.getString(""ma_dvqltb"")); hoadon.setSo_hd_in(rs.getString(""so_hd_in"")); hoadon.setNgay_in(rs.getString(""ngay_in"")); hoadon.setMa_httt(rs.getString(""ma_pttt"")); hoadon.setMa_httt(rs.getString(""ma_httt"")); hoadon.setDchi_khang(rs.getString(""dchi_khang"")); hoadon.setLoaitb(rs.getString(""loaitb"")); hoadon.setKh_hd(rs.getString(""kh_hd"")); hoadon.setLoai_hoadon(rs.getString(""loai_hoadon"")); hoadon.setLoaihd(rs.getString(""loaihd"")); hoadon.setKieu_in(rs.getString(""kieu_in"")); list.add(hoadon); } return list; } but the problem is where I submit or refresh to get data again about 4 to 5 times my program doesn't run.So what should I do plz give me some solutions thanks you. could you add some console output or strack trace if an exception has been thrown? my project hasn't any exception. What do you mean exactly by ""doesn't run"" ? the first and second time when I run my project It run ok but next time it let me wait forever and nothing happen. The Connection returned by getDataSource().getConnection() is never closed. This can cause trouble if the DataSource returned by getDataSource() is pooling database connections. This is because pools will often have a maximum number of connections that may be open simultaneously. If the maximum number of connections are currently open getDataSource() will wait until one of them is ""closed"" releasing it back to the pool. Because you never call close() on your Connection it will never be released back to the pool. You may want to try this to ensure that your connection is always closed after you are done using it: public List<HoaDon> getDsTatcaHoadonPhathanh(int vthang int vnam String vmaDvqltb) throws Exception { Connection con = getDataSource().getConnection(); try { CallableStatement cs = con.prepareCall(""{call PKG_QLNO.GetDsTatcaHoadonPhathanh(????)}""); cs.setInt(1 vthang); cs.setInt(2 vnam); cs.setString(3 vmaDvqltb); cs.registerOutParameter(4 OracleTypes.CURSOR); cs.execute(); ResultSet rs = (ResultSet) cs.getObject(4); List<HoaDon> list = new ArrayList<HoaDon>(); while (rs.next()) { HoaDon hoadon = new HoaDon(); hoadon.setChon(rs.getString(""chon"")); hoadon.setMa_so(rs.getString(""ma_so"")); hoadon.setMa_kh(rs.getString(""ma_kh"")); hoadon.setNam(rs.getString(""nam"")); hoadon.setThang(rs.getString(""thang"")); hoadon.setTien_PS(rs.getString(""tien_PS"")); hoadon.setThue_ps(rs.getString(""thue_ps"")); hoadon.setTien_khmai(rs.getString(""tien_khmai"")); hoadon.setTien_tbi(rs.getString(""tien_tbi"")); hoadon.setTong_ps(rs.getString(""tong_ps"")); hoadon.setTenkh(rs.getString(""tenkh"")); hoadon.setMa_dvqltb(rs.getString(""ma_dvqltb"")); hoadon.setSo_hd_in(rs.getString(""so_hd_in"")); hoadon.setNgay_in(rs.getString(""ngay_in"")); hoadon.setMa_httt(rs.getString(""ma_pttt"")); hoadon.setMa_httt(rs.getString(""ma_httt"")); hoadon.setDchi_khang(rs.getString(""dchi_khang"")); hoadon.setLoaitb(rs.getString(""loaitb"")); hoadon.setKh_hd(rs.getString(""kh_hd"")); hoadon.setLoai_hoadon(rs.getString(""loai_hoadon"")); hoadon.setLoaihd(rs.getString(""loaihd"")); hoadon.setKieu_in(rs.getString(""kieu_in"")); list.add(hoadon); } return list; } finally { con.close(); } } As well some pooling Connection objects don't comply with Sun's documentation regarding close(): Releases this Connection object's database and JDBC resources immediately instead of waiting for them to be automatically released You may have to explicitly close cs and rs yourself if you're still suffering from strange issues: public List<HoaDon> getDsTatcaHoadonPhathanh(int vthang int vnam String vmaDvqltb) throws Exception { List<HoaDon> list = new ArrayList<HoaDon>(); Connection con = getDataSource().getConnection(); try { CallableStatement cs = con.prepareCall(""{call PKG_QLNO.GetDsTatcaHoadonPhathanh(????)}""); try { cs.setInt(1 vthang); cs.setInt(2 vnam); cs.setString(3 vmaDvqltb); cs.registerOutParameter(4 OracleTypes.CURSOR); cs.execute(); ResultSet rs = (ResultSet) cs.getObject(4); try { while (rs.next()) { HoaDon hoadon = new HoaDon(); hoadon.setChon(rs.getString(""chon"")); hoadon.setMa_so(rs.getString(""ma_so"")); hoadon.setMa_kh(rs.getString(""ma_kh"")); hoadon.setNam(rs.getString(""nam"")); hoadon.setThang(rs.getString(""thang"")); hoadon.setTien_PS(rs.getString(""tien_PS"")); hoadon.setThue_ps(rs.getString(""thue_ps"")); hoadon.setTien_khmai(rs.getString(""tien_khmai"")); hoadon.setTien_tbi(rs.getString(""tien_tbi"")); hoadon.setTong_ps(rs.getString(""tong_ps"")); hoadon.setTenkh(rs.getString(""tenkh"")); hoadon.setMa_dvqltb(rs.getString(""ma_dvqltb"")); hoadon.setSo_hd_in(rs.getString(""so_hd_in"")); hoadon.setNgay_in(rs.getString(""ngay_in"")); hoadon.setMa_httt(rs.getString(""ma_pttt"")); hoadon.setMa_httt(rs.getString(""ma_httt"")); hoadon.setDchi_khang(rs.getString(""dchi_khang"")); hoadon.setLoaitb(rs.getString(""loaitb"")); hoadon.setKh_hd(rs.getString(""kh_hd"")); hoadon.setLoai_hoadon(rs.getString(""loai_hoadon"")); hoadon.setLoaihd(rs.getString(""loaihd"")); hoadon.setKieu_in(rs.getString(""kieu_in"")); list.add(hoadon); } } finally { rs.close(); } } finally { cs.close(); } } finally { con.close(); } return list; } thank in advance my problem was solved. :)  I think you're going to need to get in there with a debugger to find out where the program is hanging. It's probably either the cs.Execute or the cs.GetObject but you're going to have to figure out where. Once you know that you'll be in a better position to determine what exactly is going on but from what I can see here there's no way to offer better advice. Good luck.  If it stays stucked there's probably a problem in the stored procedure...You should try executing each part of the stored procedure and see which part hangs... it runs okay. : ("
27,A,"How to ignore all erroneous statements and execute all good ones in JDBC executeBatch? I have java.sql.Statement with lots of batch statements added with addBatch. Executing executeBatch will throw BatchUpdateException after first statement which violates database constrains and won't execute all remaining statements in batch. Is there any way I can execute all statements in batch ignoring erroneous ones? See BatchUpdateException: the batch will not terminate for a similar question and answers.  well if you want to save all data that were possible to insert just execute commit and were saved. looping over each statement in the batch is not possible only when you call execute batch you will get the exception not on each statement (addbatch) so it is not possible to find exactly where the error is: you can save part of them or nothing you decide (commit or rollback).  I think a better solution would be to fix the erroneous ones. What's wrong? The SQL? The underlying tables? The data? Exceptions are supposed to be ""exceptional"". What situation is so common that you're likely to see it more often with this batch? The exception is telling you that something is amiss. I would not want to recommend a fix that would allow you to ignore the message. If there's an exception thrown that means you have an opportunity to ameliorate its root problem in the catch block. If you're looping over each statement in the batch you can catch the exception from each one individually and simply log the error. Just don't ignore it completely. But unless you can think of another recovery strategy you're out of luck."
28,A,"How do I in JDBC read a possibly null double value from resultSet? I have a column in my database that is typed double and I want to read the value from it using a JDBC ResultSet but it may be null. What is the best way of doing this? I can think of three options none of which seem very good. Option 1: Bad because exception handling verbose and smelly double d; try { d = rs.getDouble(1); // do something } catch(SQLException ex) { if(rs.wasNull()) { // do something else } else { throw ex; } } Option 2: Bad because two fetches s = rs.getString(1); // or getObject() if(s == null) { // do something else } else { double d = rs.getDouble(1); // do something } Option 3: Bad because Java rather than SQL conversion s = rs.getString(1); // or getObject() if(s == null) { // do something else } else { double d = Double.parseDouble(s); // do something } Any suggestions on which way is better or is there another superior way? And please don't say ""Use Hibernate"" I'm restricted to JDBC code only here. Use a boxed type and cast: Double doubleValueOrNull = (Double)rs.getObject(1); // or .getObject(""columnName"") It will be null if the column was NULL. This is not working for me when querying HSQLDB with oracle syntax for tests.  Use: rs.getObject(1)==null?null:rs.getBigDecimal(1).doubleValue()  Option 1 is closest: double d = rs.getDouble(1); if (rs.wasNull()) { // do something } else { // use d } It's not very nice but that's JDBC. If the column was null the double value is considered ""bad"" so you should check using wasNull() every time you read a primitive that is nullable in the database. omg. thanks though note that there's no sqlexception when retrieving null primitives from a result set. the default value for that primitive is returned in such cases (0 for int 0.0 for double etc....). Hence why .wasNull() is a necessary evil."
29,A,Reusing a PreparedStatement multiple times in the case of using PreparedStatement with a single common connection without any pool can I recreate an instance for every dml/sql operation mantaining the power of prepared statements? I mean: for (int i=0; i<1000; i++) { PreparedStatement preparedStatement = connection.prepareStatement(sql); preparedStatement.setObject(1 someValue); preparedStatement.executeQuery(); preparedStatement.close(); } instead of: PreparedStatement preparedStatement = connection.prepareStatement(sql); for (int i=0; i<1000; i++) { preparedStatement.clearParameters(); preparedStatement.setObject(1 someValue); preparedStatement.executeQuery(); } preparedStatement.close(); my question arises by the fact that I want to put this code into a multithreaded environment can you give me some advice? thanks The second way is a tad more efficient but a much better way is to execute them in batches: PreparedStatement preparedStatement = connection.prepareStatement(sql); for (int i = 0; i < 1000; i++) { preparedStatement.setObject(1 someValue); preparedStatement.addBatch(); } preparedStatement.executeBatch(); preparedStatement.close(); // Do this in the finally block! You're however dependent on the JDBC driver implementation how many batches you could execute at once. You may for example want to execute them every 100 batches: PreparedStatement preparedStatement = connection.prepareStatement(sql); for (int i = 0; i < 1000; i++) { preparedStatement.setObject(1 someValue); preparedStatement.addBatch(); if ((i + 1) % 100 == 0) { preparedStatement.executeBatch(); } } preparedStatement.executeBatch(); preparedStatement.close(); // Do this in the finally block! As to the multithreaded environments you don't need to worry about this if you acquire and close the connection and the statement in the shortest possible scope inside the same method block according the normal JDBC idiom. Here's a basic example: public void executeBatch(/* ... */) throws SQLException { Connection connection = null; PreparedStatement preparedStatement = null; try { connection = database.getConnection(); preparedStatement = connection.prepareStatement(SQL); // ... } finally { close(preparedStatement); close(connection); } } Update: as per the comments depending on the functional requirement you would often indeed like to only commit the transaction when all batches are finished else it may be unpredictable which ones of the batches are already inserted/updated and which not. The DB would get dirty then. Here's how you could do it: public void executeBatch(/* ... */) throws SQLException { Connection connection = null; PreparedStatement preparedStatement = null; try { connection = database.getConnection(); connection.setAutoCommit(false); preparedStatement = connection.prepareStatement(SQL); // ... connection.commit(); } catch (SQLException e) { connection.rollback(); throw e; } finally { close(preparedStatement); close(connection); } } No mention of auto commit rollback or transactions from anyone? I'm surprised. +1 for mentioning closing in finally block - so key. Yes for batching you should turn off auto-commit otherwise it could get hairy. Yes valid point I'll update the answer soon. Yours is the best answer at all thanks Do rollback also setautocommit back to true?  The loop in your code is only an over-simplified example right? It would be better to create the PreparedStatement only once and re-use it over and over again in the loop. In situations where that is not possible (because it complicated the program flow too much) it is still beneficial to use a PreparedStatement even if you use it only once because the server-side of the work (parsing the SQL and caching the execution plan) will still be reduced. To address the situation that you want to re-use the Java-side PreparedStatement some JDBC drivers (such as Oracle) have a caching feature: If you create a PreparedStatement for the same SQL on the same connection it will give you the same (cached) instance. About multi-threading: I do not think JDBC connections can be shared across multiple threads (i.e. used concurrently by multiple threads) anyway.Every thread should get his own connection from the pool use it and return it to the pool again. In fact the connection has its exclusive thread and every statement is executed in it but I access via an exposed stack of prepared statements to that thread. So other concurrent threads initially pass only params needed to build all prepared statement but then they can modify params concurrently
30,A,"Using JDBCTemplate with a Hibernate SessionFactory? We have a Spring/Hibernate app and would like to add a small amount of JDBC for reasons involving performance and development time. I can make this dao subclass HibernateDaoSupport and use the session's connection to perform my JDBC but I'd rather use JdbcTemplate. JdbcTemplate however is initialized using a java.sql.Datasource. How can I use my existing Hibernate SessionFactory to initialize it? You can always use a hibernate session's doWork method - this gives you a java.sql.Connection. You can use this connection to construct a construct a SingleConnectionDataSource (note: the second argument should always be true as you don't want to close the underlying connection) and pass this datasource to your JDBCTemplate...  ""extracting a datasource from our hibernate configuration seems like a lot of work for what I need"" I don't see why it would take that much work. It's just a matter of creating cut-and-copying a couple of tags and properties. For example: <bean id=""sessionFactory"" class=""org.springframework.orm.hibernate3.annotation.AnnotationSessionFactoryBean""> <property name=""dataSource""> <ref bean=""dataSource""/> </property> ... </bean> ""Which SessionFactory implementation are you using? If you're using the Spring implementations see AbstractSessionFactoryBean.html#getDataSource()"" Apparently getDataSource() is only available for Spring 2.5. Here's the reference: Click here Spring 2.0 doesn't have the getDataSource(). Here's the reference: Click here Our session factory was created using AnnotationSessionFactoryBean initialized with hibernate properties ... hibernateSessionFactory is a SessionFactory. How would I get a reference to the SessionFactoryBean? I'm wondering why you used a SessionFactory instead of a LocalSessionFactoryBean which is a subclass of AnnotationSessionFactoryBean? Isn't the line bean id=""hibernateSessionFactory"" references the SessionFactoryBean already? I guess ""a lot of work"" is a relative term. In my case I would need to create a c3p0-based data source and translate all our settings from the original properties file to this one. Property names change on some settings between Hibernate and c3p0 so I would need to verify them all. It would probably take about an hour to do and verify but considering the gain is simply use of JDBCTemplate in one dao it's not worth the time. AnnotationSessionFactoryBean subclasses LocalSessionFactoryBean. The reference to the session factory doesn't help me initialize JDBCTemplate. I need the datasource.  Aren't you required to provide a DataSource to the SessionFactory implementation? Why don't you wire that in to the JDBC Template? Which SessionFactory implementation are you using? If you're using the Spring implementations see AbstractSessionFactoryBean.html#getDataSource() Our session factory was created using AnnotationSessionFactoryBean initialized with hibernate properties. We didn't create and initialize a DataSource. I can't pull the DataSource from the SessionFactoryBean because I don't get to keep a reference to it: ... hibernateSessionFactory is a SessionFactory. How would I get a reference to the SessionFactoryBean? What is your custom SessionFactoryBean doing to build the SessionFactory? In the worst case are you at least providing the JDBC driver name and connection URL in the hibernate properties? If so you should be able to instantiate a DataSource from that. Better yet build a DataSource and share it between the SessionFactoryBean and the JDBCTemplate The custom FactoryBean is unreleated to this issue. It's a subclass of AnnotationSessionFactoryBean. I don't wan't to introduce another datasource for maintaince reasons and extracting a datasource from our hibernate configuration seems like a lot of work for what I need. In retrospect it should have been created that way in the first place but the app was essentially converted to Spring after the fact. I'm just going to use hibernate's createSQLQuery() rather than JdbcTemplate. Thanks for the help."
31,A,Remove padding added by legacy DB2 databases on query results I have the following setup. 'Apps/Reports' <---------> 'DB2 Connect' <------------> 'Legacy DB2 on AS400' `Hibernate` `native calls` When data is retrieved from by the application it will be padded with extra spaces if the length is less that the column length. Of note when running a query if the WHERE cause parameter is not padded its automatically padded with extra spaces such that the query will retrieve the same records for a padded and non-padded parameter. Is there a way (preferably on IBM DB2 Connect or connection string parameter) to remove extra whitespaces from a resultset? maybe this will help you...I don't really know hibernate... http://www.coderanch.com/t/218344/ORM/java/Trim-function-Hibernate you can trim all of the fields in the query... @Leslie - how would i do that using hibernate? possible duplicate of [Trim string field in JPA](http://stackoverflow.com/questions/5725491/trim-string-field-in-jpa) Are the columns in the iSeries defined as CHAR()? I'm assuming so because this is how CHAR() works -- it's a fixed field length not a variable field length (that's what VARCHAR is for).  You could implement an hibernate UserType that automatically trim the strings. There are good exmaples on https://forum.hibernate.org/viewtopic.php?t=928294 http://java.dzone.com/articles/annotating-custom-types http://santescas.blogspot.de/2014/02/creando-un-usertype-de-hibernate-que-se.html
32,A,"PreparedStatement IN clause alternatives? What are the best workarounds for using a SQL IN clause with instances of java.sql.PreparedStatement which is not supported for multiple values due to SQL injection attack security issues: One ? placeholder represents one value rather than a list of values. Consider the following SQL statement: SELECT my_column FROM my_table where search_column IN (?) Using preparedStatement.setString( 1 ""'A' 'B' 'C'"" ); is essentially a non-working attempt at a workaround of the reasons for using ? in the first place. What workarounds are available? @Chris: I was about to ask the same. What approach did you use at the end? Oscar I think the dynamic generation of (??....) is the simplest workaround if you need an IN clause but I left it to individual calls since performance was sufficient in my specific case. One of advantages of prepared statements is that sohuld can be compiled once for efficiency. By making the in clause dynamic this effectively negates the prepared statement. Actually this works for MySQL (using setObject to set an array of String as the parameter value). What DB are you using? Here's an [Oracle specific answer](http://stackoverflow.com/a/15302767/4265) Here's a related question: http://stackoverflow.com/q/6956025/521799 I suppose you could (using basic string manipulation) generate the query string in the PreparedStatement to have a number of ?'s matching the number of items in your list. Of course if you're doing that you're just a step away from generating a giant chained OR in your query but without having the right number of ? in the query string I don't see how else you can work around this. Not really a solution for me since I want to send in a different number of ? each time I call the ps. But don't think I hadn't considered it. :P Another hack: you can use a large number of parameter placeholders -- as many as the longest list of values you'll have -- and if your list of values is shorter you can repeat values: ...WHERE searchfield IN (? ? ? ? ? ? ? ?) and then provide values: A B C D A B C D But overall I favor Adam's solution: generate the SQL dynamically and concatenate ? placeholders to match the number of values you have to pass. Bill that solution is workable if I don't want to reuse the PreparedStatement. Another solution is to make the single param call multiple times and accumulate the results on the client side. Likely it would be more efficient to build/execute a new Statement with custom number of ? each time though.  My workaround is: create or replace type split_tbl as table of varchar(32767); / create or replace function split ( p_list varchar2 p_del varchar2 := '' ) return split_tbl pipelined is l_idx pls_integer; l_list varchar2(32767) := p_list; l_value varchar2(32767); begin loop l_idx := instr(l_listp_del); if l_idx > 0 then pipe row(substr(l_list1l_idx-1)); l_list := substr(l_listl_idx+length(p_del)); else pipe row(l_list); exit; end if; end loop; return; end split; / Now you can use one variable to obtain some values in a table: select * from table(split('onetwothree')) one two three select * from TABLE1 where COL1 in (select * from table(split('value1value2'))) value1 AAA value2 BBB So the prepared statement could be:  ""select * from TABLE where COL in (select * from table(split(?)))"" Regards Javier Ibanez this is Oracle PLSQL? or does it work for other databases?  I came across a number of limitations related to prepared statement: The prepared statements are cached only inside the same session (Postgres) so it will really work only with connection pooling A lot of different prepared statements as proposed by @BalusC may cause the cache to overfill and previously cached statements will be dropped The query has to be optimized and use indices. Sounds obvious however e.g. the ANY(ARRAY...) statement proposed by @Boris in one of the top answers cannot use indices and query will be slow despite caching The prepared statement caches the query plan as well and the actual values of any parameters specified in the statement are unavailable. Among the proposed solutions I would choose the one that doesn't decrease the query performance and makes the less number of queries. This will be the #4 (batching few queries) from the @Don link or specifying NULL values for unneeded '?' marks as proposed by @Vladimir Dyuzhev  I've never tried it but would .setArray() do what you're looking for? Update: Evidently not. setArray only seems to work with a java.sql.Array that comes from an ARRAY column that you've retrieved from a previous query or a subquery with an ARRAY column. Doesn't work with all databases but it's the ""correct"" approach. You mean all drivers. Some drivers have proprietary equivalents of this years old (last century?) standard. Another way is to bung a batch of values into a temporary table but not all databases support that... http://java.sun.com/j2se/1.3/docs/guide/jdbc/getstart/mapping.html#996857 According to Sun Array content [typically] remains on the server side and is pulled as needed. PreparedStatement.setArray() can send back an Array from a previous ResultSet not create a new Array on the client side.  Sormula supports SQL IN operator by allowing you to supply a java.util.Collection object as a parameter. It creates a prepared statement with a ? for each of the elements the collection. See Example 4 (SQL in example is a comment to clarify what is created but is not used by Sormula).  There are different alternative approaches that we can use for IN clause in PreparedStatement. Using Single Queries - slowest performance and resource intensive Using StoredProcedure - Fastest but database specific Creating dynamic query for PreparedStatement - Good Performance but doesn't get benefit of caching and PreparedStatement is recompiled every time. Use NULL in PreparedStatement queries - Optimal performance works great when you know the limit of IN clause arguments. If there is no limit then you can execute queries in batch. Sample code snippet is;  int i = 1; for(; i <=ids.length; i++){ ps.setInt(i ids[i-1]); } //set null for remaining ones for(; i<=PARAM_SIZE;i++){ ps.setNull(i java.sql.Types.INTEGER); } You can check more details about these alternative approaches here. I agree with you however ""Good Performance"" here is for this specific scenario. It's better performing than approach 1 however approach 2 is fastest. ""Creating dynamic query for PreparedStatement - Good Performance but doesn't get benefit of caching and PreparedStatement is recompiled every time."" caching and avoiding recompiles is what makes a prepared statement perform well. Therefore I don't agree with your claim. This will however prevent SQL injection since you are limiting the concatenated / dynamic input to a comma.  Following Adam's idea. Make your prepared statement sort of select my_column from my_table where search_column in (#) Create a String x and fill it with a number of ""???"" depending on your list of values Then just change the # in the query for your new String x an populate  Generate the query string in the PreparedStatement to have a number of ?'s matching the number of items in your list. Here's an example: public void myQuery(List<String> items int other) { ... String q4in = generateQsForIn(items.size()); String sql = ""select * from stuff where foo in ( "" + q4in + "" ) and bar = ?""; PreparedStatement ps = connection.prepareStatement(sql); int i = 1; for (String item : items) { ps.setString(i++ item); } ps.setInt(i++ other); ResultSet rs = ps.executeQuery(); ... } private String generateQsForIn(int numQs) { String items = """"; for (int i = 0; i < numQs; i++) { if (i != 0) items += "" ""; items += ""?""; } return items; } There's no need to use StringBuilder anymore. The compiler converts the + signs to StringBuilder.append() anyway so there is no performance hit. Try yourself :) Please use `StringBuilder` and `String#format()`. @neu242: Oh yes the compiler uses `StringBuilder`. But not in the way you think. Decompiling `generateQsForIn` you can see that per loop iteration __two__ new `StringBuilder` are allocated and `toString` is called on each. The `StringBuilder` optimization only catches stuff like `""x"" + i+ ""y"" + j` but does not extend beyond one expression. @neu242 Can't you use `ps.setObject(1items)` instead of iterating over the list and then setting the `paramteres`?  try using the instr function? select my_column from my_table where instr(? ''||search_column||'') > 0 then ps.setString(1 ""ABC""); Admittedly this is a bit of a dirty hack but it does reduce the opportunities for sql injection. Works in oracle anyway. Oh and I am aware that it will not utilise indexes it wouldn't work for some strings for instance if the string contains a ''.  Just for completeness: So long as the set of values is not too large you could also simply string-construct a statement like ... WHERE tab.col = ? OR tab.col = ? OR tab.col = ? which you could then pass to prepare() and then use setXXX() in a loop to set all the values. This looks yucky but many ""big"" commercial systems routinely do this kind of thing until they hit DB-specific limits such as 32 KB (I think it is) for statements in Oracle. Of course you need to ensure that the set will never be unreasonably large or do error trapping in the event that it is. Yes you're right. My goal in this case was to reuse the PreparedStatement with different numbers of items each time. Using ""OR"" would obfuscate the intent. Stick with ""IN"" as its easier to read and the intent is more clear. The only reason to switch is if the query plans were different.  Here's how I do it: public static String preparePlaceHolders(int length) { StringBuilder builder = new StringBuilder(); for (int i = 0; i < length;) { builder.append(""?""); if (++i < length) { builder.append(""""); } } return builder.toString(); } public static void setValues(PreparedStatement preparedStatement Object... values) throws SQLException { for (int i = 0; i < values.length; i++) { preparedStatement.setObject(i + 1 values[i]); } } and how I use it: private static final String SQL_FIND = ""SELECT id name value FROM data WHERE id IN (%s)""; public List<Data> find(Set<Long> ids) throws SQLException { Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; List<Data> list = new ArrayList<Data>(); String sql = String.format(SQL_FIND preparePlaceHolders(ids.size())); try{ connection = database.getConnection(); statement = connection.prepareStatement(sql); setValues(statement ids.toArray()); resultSet = statement.executeQuery(); while (resultSet.next()) { Data data = new Data(); data.setId(resultSet.getLong(""id"")); data.setName(resultSet.getString(""name"")); data.setValue(resultSet.getInt(""value"")); list.add(data); } } finally { close(connection statement resultSet); } return list; } You can simplify the `preparePlaceHolders()` method and not incur much of a performance hit using Guava: `return Strings.repeat(""? "" length - 1) + ""?"";` I don't think you achieve statement caching with that approach... only when the size of the list repeats itself. Also the statement has to be recompiled every time you give it a different # of parameters. So I don't think that actually leads to any optimizations... correct me if I'm wrong. @ktm5124 you don't have other choice if you don't know how many fields are passing to begin with... This worked perfectly for me. Since my 'in' clause wasn't my first parameter I updated your setValues: `setValues(PreparedStatement preparedStatement int firstIndex Object... values)` and increment `firstIndex` in my loop instead of `i+1` @ggrigery: just merge the first value as 1st item in the array before passing to `setValues()`  An analysis of the various options available and the pros and cons of each is available here. The suggested options are: Prepare SELECT my_column FROM my_table WHERE search_column = ? execute it for each value and UNION the results client-side. Requires only one prepared statement. Slow and painful. Prepare SELECT my_column FROM my_table WHERE search_column IN (???) and execute it. Requires one prepared statement per size-of-IN-list. Fast and obvious. Prepare SELECT my_column FROM my_table WHERE search_column = ? ; SELECT my_column FROM my_table WHERE search_column = ? ; ... and execute it. [Or use UNION ALL in place of those semicolons. --ed] Requires one prepared statement per size-of-IN-list. Stupidly slow strictly worse than WHERE search_column IN (???) so I don't know why the blogger even suggested it. Use a stored procedure to construct the result set. Prepare N different size-of-IN-list queries; say with 2 10 and 50 values. To search for an IN-list with 6 different values populate the size-10 query so that it looks like SELECT my_column FROM my_table WHERE search_column IN (1234566666). Any decent server will optimize out the duplicate values before running the query. None of these options are super great though. Duplicate questions have been answered in these places with equally sane alternatives still none of them super great: JDBC Prepared Statement how to set a list? PreparedStatement with list of parameters in a IN clause How to set list of parameters on prepared statement? The Right Answer if you are using JDBC4 and a server that supports x = ANY(y) is to use PreparedStatement.setArray as described here: PreparedStatement IN clause alternatives? There doesn't seem to be any way to make setArray work with IN-lists though. Hmm nowadays this answer would be removed as it qualifies as a link-only answer... Past is read-only ;) Downvoted basically because the whole ""stored procedures are weird and wrong!"" bit is weird and wrong. @LukasEder: it is amusing that the author has not bothered to fix this link-only answer... @LaszloPapp do I get an upvote for my hilarity? Click link copy click edit paste... is that what peeps want ? @BenGeorge Personally I agree that copy-pasting seems like unnecessary duplication but this is in fact what ""the laws"" of stackoverflow want you to do. My understanding is that the reason for this is because the page that is linked to might not be around forever or the content on the page might change. However when I posted this answer (6 years ago) I don't think this law had been passed. This is a good analysis of the theoretical workarounds to not being able to pass in a list. However some databases allow you to pass in a list and a better answer would show how to actually do it like Boris' answer.  No simple way AFAIK. If the target is to keep statement cache ratio high (i.e to not create a statement per every parameter count) you may do the following: create a statement with a few (e.g. 10) parameters: ... WHERE A IN (??????????) ... Bind all actuall parameters setString(1""foo""); setString(2""bar""); Bind the rest as NULL setNull(3Types.VARCHAR) ... setNull(10Types.VARCHAR) NULL never matches anything so it gets optimized out by the SQL plan builder. The logic is easy to automate when you pass a List into a DAO function: while( i < param.size() ) { ps.setString(i+1param.get(i)); i++; } while( i < MAX_PARAMS ) { ps.setNull(i+1Types.VARCHAR); i++; } ""NULL never matches anything"" — Would `NULL` in the query match a `NULL` value in the database? @CraigMcQueen No it wouldn't. Null doesn't even match null according to the ANSI standard.  Solution for PostgreSQL: final PreparedStatement statement = connection.prepareStatement( ""SELECT my_column FROM my_table where search_column = ANY (?)"" ); final String[] values = getValues(); statement.setArray(1 connection.createArrayOf(""text"" values)); final ResultSet rs = statement.executeQuery(); try { while(rs.next()) { // do some... } } finally { rs.close(); } or final PreparedStatement statement = connection.prepareStatement( ""SELECT my_column FROM my_table "" + ""where search_column IN (SELECT * FROM unnest(?))"" ); final String[] values = getValues(); statement.setArray(1 connection.createArrayOf(""text"" values)); final ResultSet rs = statement.executeQuery(); try { while(rs.next()) { // do some... } } finally { rs.close(); } looks good. what part of this code is PostreSQL specific? the ""where search_column = ANY(?)""? or the connection.createArrayOf? or something else? I think it is more JDBC4-specific than PostgreSQL-specific because of the `.createArrayOf()` part but I am not sure the strict semantics for user's `Array`s are defined by JDBC specification. If `.createArrayOf` doesn't work you can do your own manual creation of array literal like `String arrayLiteral = ""{A\""B \"" CD}""` _(note that ""B "" has a space while C doesn't)_ and then `statement.setString(1arrayLiteral)` where the prepared statement is `... IN (SELECT UNNEST(?::VARCHAR[]))` or `... IN (SELECT UNNEST(CAST(? AS VARCHAR[])))`. (PS: I don't think `ANY` works with a `SELECT`.) Great solution! Really saved the day for me. For integer array I used ""int"" in the first parameter of createArrayOf() and it's looking good. That first parameter appears DB-specific based on the documentation though. This seems the cleanest solution. If anyone is looking for the HSQLDB specific syntax: I managed to get this to work with IN(UNNEST(?))  An unpleasant work-around but certainly feasible is to use a nested query. Create a temporary table MYVALUES with a column in it. Insert your list of values into the MYVALUES table. Then execute select my_column from my_table where search_column in ( SELECT value FROM MYVALUES ) Ugly but a viable alternative if your list of values is very large. This technique has the added advantage of potentially better query plans from the optimizer (check a page for multiple values tablescan only once instead once per value etc) may save on overhead if your database doesn't cache prepared statements. Your ""INSERTS"" would need to be done in batch and the MYVALUES table may need to be tweaked to have minimal locking or other high-overhead protections. What advantages would that have over querying my_table one value at a time? The query optimizer can reduce I/O load by retrieving all possible matches from a loaded page. Tablescans or index scans may be performed once instead of once per value. Overhead for inserting values can be reduced with batch operations and may be less than several queries. it looks good but there could be problems with concurrency. does jdbc specification containt a way to create a temporal anonymous table in memory? or something like that if possible not jdbc-vendor specific? Not that I'm aware of.  instead of using SELECT my_column FROM my_table where search_column IN (?) use the Sql Statement as select id name from users where id in (? ? ?) and preparedStatement.setString( 1 'A'); preparedStatement.setString( 2'B'); preparedStatement.setString( 3 'C'); or use a stored procedure this would be the best solution since the sql statements will be compiled and stored in DataBase server"
33,A,"DAO methods and synchronized The following are methods I currently have in an Abstract DAO class. If there are concurrent calls are they safe as they are or should synchronization be used? I know synchronization should be used if there is a reference to an attribute outside the scope of a method but it's unclear to me how should things be handled with an outside ressource. public Connection getConnection() { // Call to singleton handling JDBC stuff return Database.getInstance().getCon(); } public boolean isConnectionAvailable(){ if( getConnection() != null ){ return true; } return false; } public PreparedStatement getPreparedStatement( String sqlStatement ){ Connection connection = getConnection(); PreparedStatement pS = null; if( connection != null ){ try { pS = connection.prepareStatement( sqlStatement ); } catch (SQLException e) { return null; } } return pS; } Edit: I might reformulate this question to include information on writing DAOs as it's what's important here. I often hear that. But what is the alternative when you're working with plain Java? do not do not do not do not use singletons for database connection access You shouldn't use the same connection in every thread. JDBC drivers aren't supposed to be thread safe. If you want a thread safe code you should create one connection for every thread. The rest of your code seems safe. It's not your DAO which isn't thread safe it's the connection part. Like @Bozho said if getCon() return each time a specific connection for each thread then there is no race condition. Ok so what you're saying is that I should isolate any accesses to a connection. I've had a look in the singleton and it returns the same connection each time so that might be an issue. No the connection should be passed into the DAO. Let the object that knows about units of work - the service - instantiate the Connection give it to the DAO and then clean it up in method scope. Do you think I should add some sort of threading mecanism inside the DAO?  Look at how Spring does it they have already figured out all this stuff and there is no need to re-invent it. Check out the petclinic sample code that is bundled with the full distribution of Spring or (for a non-Spring approach) read the DAO chapter of the Bauer/King Hibernate book. Definitely the DAO shouldn't be in charge of getting the database connection because you will want to group multiple DAO calls in the same transaction. The way Spring does it is there's a service layer that gets its transactional methods wrapped in an interceptor that pulls the connection from the datasource and puts it in a threadlocal variable where the DAOs can find it. Eating your SQLException and returning null is bad. As duffymo points out letting the PreparedStatement get passed around with no assurance that it will ever get closed is very bad. Also nobody should use raw JDBC anymore Ibatis or spring-jdbc are better alternatives. -1 for ""nobody should use raw JDBC anymore"". the -1 seems a bit harsh. Have you ever used spring jdbc ? It is nearly raw jdbc where you will still manipulate ps and rs (if you wish) but with all the exception handling (and resource management) and interaction with tx taken care of. So you have the advantage of raw access to data with less risk of leak. I think it's a defendable position GreenieMeanie. I'd prefer that people use Spring just for JDBC instead of the heinous JDBC code I see on SO. I voted Nathan Hughes up. @stepanian: why? my position is JDBC is too painful to do right even for experts. the result is either cut-n-paste code or an in-house framework that is probably inferior to spring-jdbc or Mybatis (both of which have had a lot of work put into them). what is so wrong with that? -1 for ""nobody should use raw JDBC anymore"". Nathan Hughes: It's one thing to say that you prefer to use spring-jdbc mybaits ibatis unnecessarybatis or whatever framework you love. It's another thing to say something absolute like ""nobody should use raw JDBC anymore"". Java development is all about choice. I don't want to debate with you on the merits and shortcomings of frameworks and how they relate to various categories of projects there is a lot of that on the web. But I hope you realize that your preferences of coding techniques are not always shared by everyone.  Looks fine to me. The functions are Thread safe.  The JDBC Connection class is not guaranteed to be thread safe. If your Database.getInstance().getCon() method is always returning the same connection then you will run into problems. If however it is using a pool such that each call to getInstance().getCon() returns a different connection you will be fine. That said if you are returning a different connection with each call to getCon() then the getPreparedStatement() won't work if you want two Prepared Statement calls to use the same connection (and same transaction). I like Spring's JDBCTemplate class as a basis for my DAO classes. Good point. I updated my answer to clarify this. `Connection` is just an interface whether or not the implementations are thread-safe are not are completely up to the JDBC driver being used  I don't agree with this implementation at all. First DAOs should be given their connection information by the services that own units of work and transactions. Second I don't see an interface. Third I don't see model or domain objects. Fourth prepared statements should only be part of the internal implementation. If they're leaking out of your DAO you're doing it wrong. Fifth passing a prepared statement out of the object makes responsibility for closing it and cleaning up far less clear. Your DAO will die a resource leak death in no time. Here's an interface for a generic DAO. You'll notice that it's all CRUD operations with no mention of connnections or any interfaces from java.sql package: package persistence; import java.io.Serializable; import java.util.List; public interface GenericDao<T K extends Serializable> { T find(K id); List<T> find(); List<T> find(T example); List<T> find(String queryName String [] paramNames Object [] bindValues); K save(T instance); void update(T instance); void delete(T instance); } You can go a long way with this. It's a better abstraction. The T is your business object type and K is the primary key. @James: that is really unfortunate I have a hard time understanding the motivation behind requests like that (that you not use a framework). Spring in particular has been a huge time-saver for me. Spring has a decent DAO framework: http://static.springsource.org/spring/docs/2.5.x/reference/dao.html More than decent. This is the model to follow. Thanks for the answer duffymo. I have to admit that I am struggling a bit as I've been asked to not use a framework such as Spring. if you have an example that could be used as a template it would be more than welcome :) .  If getCon() returns a new Connection each time it is called or returns a ThreadLocal connection then you are safe and there is no need to use synchronized If you return the same connection to everyone you might still save in terms of synchronization because there is no state in the connection that gets changed (in your current code). But you should avoid this practice. Consider a connection pool instead. And a few notes on general design principles. DAOs form a separate layer. Each layer exists for a reason not juts for the sake of having cool names. The DAO layer exists in order to abstract or in other words - hide the database access from the services that use the DAO objects. In order to imagine it more clearly - the DAO has to be written in a way that if tomorrow you decide to switch from RDBMD storage (via JDBC) to XML storage you should be able to do that by changing only the DAO objects and nothing else. The concrete DAO classes work as you've explained. The methods above were just an idea to add some utility methods in the Asbtract class but perhaps this is a bad approach. What I probably haven't understood yet is how it should interact with JDBC and a database."
34,A,"SQLite 3 - JDBC driver throws ""ResultsSet Closed"" exception on empty resultset I a problem in JDBC driver for SQLite. I am executing a query with SELECT statement. If I get an empty resultset (0 rows) then I see a ""Closed ResultSet"" exception thrown when checking GetString(1). Without much prior JDBC experience my theory (which I could not confirm via JavaDocs for ResultSet) is that GetString(1) does NOT work on an empty (zero-row) resultset (by design or due to a bug) Resultset's ""open"" flag is set to false on zero rows (again by design or a bug) I saw this bug report but am not sure if it's related. My qeustions are: Is the theory above correct? Is it a bug? Feature? (and if so can someone point to documentation please?) Is it specific to SQLIte's JDBC or to generic ResultSet in all JDBC drivers? What is the correct way of doing stuff like that?? For #4 my solution was to use isFirst() call right after executeQuery() to check whether any rows are there in result set. Is this the best practices approach? (I could also have simply selected a count insetad since I didn't really need a result set merely zero-nonzero flag but I want to know the correct thingh to do if I did care about select's results) Thanks! Thanks everyone! Very illuminating! From the JavaDocs for ResultSet: A ResultSet object maintains a cursor pointing to its current row of data. Initially the cursor is positioned before the first row. The next method moves the cursor to the next row and because it returns false when there are no more rows in the ResultSet object it can be used in a while loop to iterate through the result set. You'll need to position the ResultSet on a row e.g. by calling calling next() before attempting to read any data. If the call to next() returns false then the result set is empty. This answers #4. What abiout #1-3? :) @DVK It doesn't make sense to be calling `getString` until the `ResultSet` is positioned on a row so it makes sense that it raises an exception (this applies for any JDBC driver). I'm not sure what you're referring to by the 'Resultset's ""open"" flag'. In Eclipse's debugger when examining the result set the ""open"" member has a ""false"" value. That is the reason for the ""ResultSet closed"" exception (not the underlying cause but the immediate variable that is examined to generate the exception in JDBC source)  while (rs.next()) { // process the row } This answers #4. What abiout #1-3? :)  Empty or not but doing the following is always faulty: resultSet = statement.executeQuery(sql); string = resultSet.getString(1); // Epic fail. The cursor isn't set yet. This is not a bug. This is documented behaviour. Every decent JDBC tutorial mentions it. You need to set the ResultSet's cursor using next() before being able to access any data. If you're actually interested whether the supposedly unique row exist or not then just check the outcome of next(). For example in a fictive UserDAO class: public boolean exist(String username String password) throws SQLException { Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; boolean exist = false; try { connection = database.getConnection(); statement = connection.prepareStatement(""SELECT id FROM user WHERE username = ? AND password = MD5(?)""); statement.setString(1 username); statement.setString(2 password); resultSet = statement.executeQuery(); exist = resultSet.next(); } finally { close(resultSet statement connection); } return exist; } If you actually expect only zero or one row then just do something like: public User find(String username String password) throws SQLException { Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; User user = null; try { connection = database.getConnection(); statement = connection.prepareStatement(""SELECT id username email age FROM user WHERE username = ? AND password = MD5(?)""); statement.setString(1 username); statement.setString(2 password); resultSet = statement.executeQuery(); if (resultSet.next()) { user = new User( resultSet.getLong(""id"") resultSet.getString(""username"") resultSet.getString(""email"") resultSet.getInteger(""age"")); } } finally { close(resultSet statement connection); } return user; } and then just handle it accordingly in the business/domain object e.g. User user = userDAO.find(username password); if (user != null) { // Login? } else { // Show error? } If you actually expect only zero or many rows then just do something like: public List<User> list() throws SQLException { Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; List<User> users = new ArrayList<User>(); try { connection = database.getConnection(); statement = connection.prepareStatement(""SELECT id username email age FROM user""); resultSet = statement.executeQuery(); while (resultSet.next()) { users.add(new User( resultSet.getLong(""id"") resultSet.getString(""username"") resultSet.getString(""email"") resultSet.getInteger(""age""))); } } finally { close(resultSet statement connection); } return users; } and then just handle it accordingly in the business/domain object e.g. List<User> users = userDAO.list(); if (!users.isEmpty()) { int count = users.size(); } else { // Help no users? } I'm choosing to ""Accept"" this one due to the breadth of code examples and the doc links."
35,A,"What do I need to use SQLite in Java? I'm using SQLite for a simple attendance tracking application to be implemented in Java. I am using the driver found in http://www.zentus.com/sqlitejdbc and I want to know if i need the dll's still or if i only need the jar i retrieved from the site. The jar you retrieved from the site should be sufficient. Toward the bottom of the page you cite it says: Run with: java -cp .:sqlitejdbc-v056.jar Test I just (re)tested that jar on an Ubuntu system and on my Snow Leopard system. The same jar worked fine in both places. thanks. i was just worried cause i read somewhere that you had to include the dll in the folder. The JAR includes the DLLs at least for ""common"" environments. Use `jar tvf sqlitejdbc.jar` to see exactly which ones it has."
36,A,"Java Prepared Statement arguments! I am planning to replace repeatedly executed Statement objects with PreparedStatement objects to improve performance. I am using arguments like the MySQL function now() and string variables. Most of the PreparedStatement queries I have seen contained constant values (like 10 and strings like ""New York"") as arguments used for the ""?"" in the queries. How would I go about using functions like now() and variables as arguments? Is it necessary to use the ""?""s in the queries instead of actual values? I am quite confounded. Are you asking if you can use a String-valued function in place of a String literal? Are you asking if you can use an int-valued function in place of a literal integer? Can you provide a code snippet? If you are calling built in functions of your SQL server then use PreparedStatement. If you are calling stored procedures that have been loaded onto your SQL server then use CallableStatement. Use question marks as placeholders for function/procedure parameters that you are passing and function return values you are receiving.  I've developed a function that allows you to use named parameters in your SQL queries: private PreparedStatement generatePreparedStatement(String query Map<String Object> parameters) throws DatabaseException { String paramKey = """"; Object paramValue = null; PreparedStatement statement = null; Pattern paramRegex = null; Matcher paramMatcher = null; int paramIndex = 1; try { //Create the condition paramRegex = Pattern.compile(""(:[\\d\\w_-]+)"" Pattern.CASE_INSENSITIVE | Pattern.MULTILINE); paramMatcher = paramRegex.matcher(query); statement = this.m_Connection.prepareStatement(paramMatcher.replaceAll(""?"") ResultSet.TYPE_FORWARD_ONLY ResultSet.CONCUR_READ_ONLY ResultSet.HOLD_CURSORS_OVER_COMMIT); //Check if there are parameters paramMatcher = paramRegex.matcher(query); while (paramMatcher.find()) { paramKey = paramMatcher.group().substring(1); if(parameters != null && parameters.containsKey(paramKey)) { //Add the parameter paramValue = parameters.get(paramKey); if (paramValue instanceof Date) { statement.setDate(paramIndex (java.sql.Date)paramValue); } else if (paramValue instanceof Double) { statement.setDouble(paramIndex (Double)paramValue); } else if (paramValue instanceof Long) { statement.setLong(paramIndex (Long)paramValue); } else if (paramValue instanceof Integer) { statement.setInt(paramIndex (Integer)paramValue); } else if (paramValue instanceof Boolean) { statement.setBoolean(paramIndex (Boolean)paramValue); } else { statement.setString(paramIndex paramValue.toString()); } } else { throw new DatabaseException(""The parameter '"" + paramKey + ""' doesn't exists in the filter '"" + query + ""'""); } paramIndex++; } } catch (SQLException l_ex) { throw new DatabaseException(tag.lib.common.ExceptionUtils.getFullMessage(l_ex)); } return statement; } You can use it this way: Map<String Object> pars = new HashMap<>(); pars.put(""name"" ""O'Really""); String sql = ""SELECT * FROM TABLE WHERE NAME = :name"";  You don't have to use placeholders in a PreparedStatement. Something like: PreparedStatement stmt = con.prepareStatement(""select sysdate from dual""); would work just fine. However you can't use a placeholder and then bind a function call to it. Something like this can't be used to call the sysdate function: PreparedStatement stmt = con.prepareStatement(""select ? from dual""); stmt.setSomethingOrOther(1 ""sysdate"");  If you have a variable that comes from user input it's essential that you use the ? rather than concatenating the strings. Users might enter a string maliciously and if you drop the string straight into SQL it can run a command you didn't intend. I realise this one is overused but it says it perfectly: I believe you mean SQL Injections.  If you have variables use the '?' int temp = 75; PreparedStatement pstmt = con.prepareStatement( ""UPDATE test SET num = ? due = now() ""); pstmt.setInt(1 temp); pstmt.executeUpdate(): Produces an sql statment that looks like: UPDATE test SET num = 75 due = now();"
37,A,Accessing Access over JDBC (using ODBC?) I'm looking for a way to open an Access MDB file inside a Java App (using JDBC). A quick Google Search suggests that I need the JDBC-ODBC Bridge for this... Does this mean that I need to configure every system I want to run my app on to provide a ODBC DSN for the MDB I want to open? And one more question (since I've never used ODBC before): will the communication happen over some sort of a socket (in a client/server-style) or through method/function calls (like with an embeded Derby db)? 1) You won't need to configure every system with a SYSTEM or USER ODBC DSN to access the MDB you want. You can still provide all the information you need in your JDBC URL: jdbc:odbc:Driver={Microsoft Access Driver (*.mdb)};DBQ=c:/yourdb.mdb But keep in mind that the system will need to have the driver you are using installed. 2) The communication will happen the way your ODBC driver communicates. If it opens a socket to the server (the way an Oracle ODBC connection takes place) it will open a socket. If it uses library function calls it will communicate through library function calls. JDBC to ODBC communication uses JNI to communicate. ok the code would be windows-only then... thank you! I guess you could have a JDBC proxy driver. That is to say a JDBC driver that connects over a socket to another Java process which then executes the calls on a real JDBC driver (JDBC-ODBC bridge). I think such things exist for JDBC OBDC and UDBC. @Buttercup: The specific code I posted is Windows only. But you can still use JDBC-ODBC bridge under Linux (provided you have ODBC installed of course). @Tin Hawtin: I think what you are referring to are JDBC Type 3 (middleware) drivers.
38,A,How can I retrieve a JDBC NUMERIC column value that may be NULL without incurring a conversion cost? I have a simple query using JDBC of an Oracle database which is proving slow to retrieve even though the query itself doesn't seem to be the problem. A profiler reveals that a lot of time is spent in: ResultSet#getString(String) methods some of which are retrieving Oracle NUMBER columns which are of Java long precision or thereabouts. These values may also be null. I am guessing that getString(String) is slow when returning a column value that is defined as a number - and thought about using getLong(String) but of course that returns a primitive that cannot be null. Is there a better way? Can a JDBC NUMERIC value be returned as an object without converting it to a String or incurring any other conversion cost? Something like this? long value = resultSet.getLong(colName); if (resultSet.wasNull()) { return null; } else { return Long.valueOf(value); } Thank you! I suppose it's not reasonable for me to have gripes about the JDBC API at this stage in the game. It does seem not optimal to have to carry out two operations for this. @EBCDIC: See http://stackoverflow.com/questions/2777214/when-accessing-resultsets-in-jdbc-is-there-an-elegant-way-to-distinguish-between
39,A,What is the right way to use JDBC transactions in Java? I'm using this template: try { connection.setAutoCommit(false); try { // ... do something with that connection ... connection.commit(); catch (SQLException exception) { connection.rollback(); throw exception; } finally { connection.setAutoCommit(true); } } catch (SQLException exception) { // log error } Is this the right way? How can this template be improved? Your code should work fine. Do you get any errors or anything else? Here's an example on using JDBC Transaction anyway http://www.java2s.com/Code/Java/Database-SQL-JDBC/JDBCTransaction.htm P.S. Specify your problem and I'll try to help. I don't have any particular problems with this code I'm trying to avoid them in future :) Then just check link in my answer for an example. You won't have problems your code is correct. Good Luck.
40,A,"Accessing a ColdFusion datasource from Java code I have a servlet that I would like to run within ColdFusion MX 7. I would like to make use of an existing ColdFusion DSN as a javax.sql.DataSource if possible. I thought something like coldfusion.server.ServiceFactory.getDataSourceService().getDatasource(dsname); would work but unfortunately the servlet returns java.lang.NoClassDefFoundError: coldfusion/server/ServiceFactory It seems the simplest way to do this is to add an additional JNDI datasource into jrun-resources.xml. This can then be accessed in the conventional way: Context context = new InitialContext(); DataSource ds = (DataSource)context.lookup(""mydatasource""); It does mean duplicating database connection configuration but I would rather do this than work with the largely undocumented coldfusion.server.* classes.  That code will work fine you just don't have ServiceFactory in your classpath. Ie Java can't load that class. Try including a dependency on cfusion.jar from C:\CFusionMX7\lib. Now getting: coldfusion.server.ServiceFactory$ServiceNotAvailableException: The DataSource service is not available. neo-query.xml is fine queries from .cfm pages still work. Hmm I have only done this is a java class being called from ColdFusion with CFOBJECT. Is that what you're doing? You may need to be in that context to get to the datasources. It is looking that way. I've got a servlet that needs access to a database. I'll see if creating a new JNDI datasource in jrun-resources.xml works should do."
41,A,DatabaseMetaData.getTables() returns how many columns? I was playing around with the DatabaseMetaData class to see how it works. The java doc comments seem to state one thing while the code does a different. I know it is an interface so it is really up to the vendor that supplied the JDBC driver to implement this correctly. But I was wondering if I am missing something or not? I am using this with a version of Oracle 10g. Basically the comment implies that it will return the following 10 columns in the resultset: TABLE_CAT TABLE_SCHEM TABLE_NAME TABLE_TYPE REMARKS TYPE_CAT TYPE_SCHEM TYPE_NAME SELF_REFERENCING_COL_NAM REF_GENERATION In reality I only get 5 columns in the result set: TABLE_CAT TABLE_SCHEM TABLE_NAME TABLE_TYPE REMARKS So what gives? Am I misreading the javadocs or is this pretty much par for the course with jdbc drivers. For instance if I swapped out oracle for MySQL (of course getting the appropriate driver) would I probably get a number of columns? JDBC is a spec. Some features are required to conform to the spec; others are optional. I don't know the complete spec but this must be one feature that Oracle has chosen not to return all the values expressed in the interface. Other vendors like MySQL may choose to do so. You'll have to try it and see. Are the missing columns crucial to your app's operation? It seems like a trivial reason to switch database vendors. You could Google for the spec but it's expressed in those java.sql interfaces. No I am not missing anything crucial at all and the columns returned are definitely enough for what I am trying to accomplish. It was more that I was trying to write this particular set of code to be database agnostic. You mentioned a spec where would one find this so that you would know what was optional before hand? Also this is really all for learning purposes not anything crucial at all. Pure curiosity.  The JDBC driver for Oracle 10g that you are using is just fulfilling an older spec. Here is a JavaDoc to which it conforms. You have to know the JDBC version of your JDBC drivers to work with them effectively when you do more than the absolute basics. that makes since thanks for the link.
42,A,"Can I load mysql data trunk by trunk in java? Currently I am using statement.executeQuery(qStr) in java to select a large amount of data from mysql. Unfortunatly java keeps running out of memory at the statement.executeQuery(qStr) statement with exception java.lang.OutOfMemoryError: Java heap space. I am wondering if there is a method to stream load data from mysql. So that I can handle the selected data trunk by trunk to avoid running out of memory? Note that: I am using eclipse and this post shows me how to increase the heap memory for java to use inside eclipse. But after I followed it's method i am still running into the same problem. Thanks in advance. By default ResultSets are completely retrieved and stored in memory. If you are dealing with huge result sets your heap will quickly be exhausted. You can change this behavior by creating the Statement instance like this:  stmt = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY); stmt.setFetchSize(Integer.MIN_VALUE); This creates a forward-only read-only result set with a fetch size of Integer.MIN_VALUE serves as a signal to the driver to stream result sets row-by-row. After this any result sets created with the statement will be retrieved row-by-row. See the MySQL documentation for more details and the caveats: http://dev.mysql.com/doc/refman/5.5/en/connector-j-reference-implementation-notes.html Thanks bunting my mysql server is in version 5.1.43. And as I mentioned above my mysql-connector is 5.1.13. Thanks. Thanks guys for your answers. I tried it but comes out with another exception: ""com.mysql.jdbc.RowDataDynamic$OperationNotSupportedException: Operation not supported for streaming result set"". I am using the mysql-connector-java-5.1.13-bin.jar. Also if I replaced Integer.MIN_VALUE with a specific number 100. Then the out of heap memory exception still appears. Any idea? Thanks. Thank bunting I found out the problem in my code now. It's because I still used resultSet.getRow() and it cause the exception threw... Thanks. For MySQL you must set the fetch size to Integer.MIN_VALUE otherwise the driver reverts to the usual caching strategy of ResultSets. The OperationNotSupportedException can have a number of reasons. To begin with which MySQL version are you using (there's a known bug with version 5.1.6) ?  Yes you can set the FetchSize on a Statement to Integer.MIN_VALUE  the ResultSet should be TYPE_FORWARD_ONLY as well though I believe that's the default.. MySQL treats that specially and enables streaming of the ResultSet instead of reading it all into memory it's documented here PreparedStatement stmt = conn.prepareStatement(sqlResultSet.TYPE_FORWARD_ONLYResultSet.CONCUR_READ_ONLY); stmt.setFetchSize(Integer.MIN_VALUE); Integer.MIN_VALUE is special within the mysql setting it to anything else gives the default behavior. I don't know where you get that exception - so post the code where it happens. Thanks guys for your answers. I tried it but comes out with another exception: ""com.mysql.jdbc.RowDataDynamic$OperationNotSupportedException: Operation not supported for streaming result set"". I am using the mysql-connector-java-5.1.13-bin.jar. Also if I replaced Integer.MIN_VALUE with a specific number 100. Then the out of heap memory exception still appears. Any idea? Thanks. Thanks nos I was trying to extract the relavent code to past here then I found the problem source. it's the problem of calling the resultSet.getRow()...... Ok.. that's for help me.. I appreciate for your help. Thanks."
43,A,"How to connect to SQL Server using activerecord JDBC JTDS and Integrated Security As per the above I've tried: establish_connection(:adapter => ""jdbcmssql"" :url => ""jdbc:jtds:sqlserver://myserver:1433/mydatabase;domain='mynetwork';"" :username => 'user' :password=>'pass' ) establish_connection(:adapter => ""jdbcmssql"" :url => 'jdbc:jtds:sqlserver://myserver:1433/mydatabase;domain=""mynetwork"";user=""mynetwork\user""' ) establish_connection(:adapter => ""jdbcmssql"" :url => ""jdbc:jtds:sqlserver://myserver:1433/mydatabase;domain='mynetwork';"" :username=>'user' ) establish_connection(:adapter => ""jdbcmssql"" :url => ""jdbc:jtds:sqlserver://myserver:1433/mydatabase;domain='mynetwork';integratedSecurity='true'"" :username=>'user' ) .. and various other combinations. Each time I get: net/sourceforge/jtds/jdbc/SQLDiagnostic.java:368:in `addDiagnostic': java.sql.SQLException: Login failed for user ''. The user is not associated with a trusted SQL Server connection. (NativeException) If I try it with no user info: establish_connection(:adapter => ""jdbcmssql"" :url => ""jdbc:jtds:sqlserver://myserver/mydatabase"") I get this response: net/sourceforge/jtds/jdbc/SQLDiagnostic.java:368:in `addDiagnostic': java.sql.SQLException: Login failed for user 'sa'. (NativeException) Any tips? Thanks activerecord (2.3.5) activerecord-jdbc-adapter (0.9.6) activerecord-jdbcmssql-adapter (0.9.6) jdbc-jtds (1.2.5) jruby 1.4.0 (ruby 1.8.7 patchlevel 174) (2009-11-02 69fbfa3) (Java HotSpot(TM) Client VM 1.6.0_18) [x86-java] File ruby/lib/ruby/gems/1.8/gems/activerecord-jdbc-adapter-0.9.6-java/lib/active_record/connection_adapters/jdbc_adapter.rb line 54 substitutes 'sa' when no user is given. To work around this specify a blank username e.g.: establish_connection(:adapter => ""jdbcmssql"" :url => ""jdbc:jtds:sqlserver://myserver/mydatabase"" :username=>'') (Big thanks to limc whose answer got me looking in this direction)  Can you try removing domain user and password all together? I connect to SQL Server through integrate security using JTDS in Java and the only thing I specified is the server and database because it picks up the rest of the credential from the machine that I logged into. In fact you can also omit the 1433 port because I believe that's the standard port for SQL Server thus it can be omitted. thanks limc - I tried this and updated the question"
44,A,Are addBatch() and executeBatch() thread-safe? Can i call executeBacth from a thread while another one keeps calling addBatch() on the same Statement ( or PreparedStatement ) object? Update: Does anyone have exprerience with this issue? 'cause i get incorrect results. Not all updates i added to the the batch is executed. I would take a step back and deeply reconsider the design. Why on earth would you like to share the same Statement (and thus implicitly also the Connection) between two threads? The normal JDBC practice is that you should acquire and close the Connection Statement and ResultSet in the shortest possible scope. That is inside the very same method block. Here's a basic example: public void update(List<Item> items) throws SQLException { Connection connection = null; PreparedStatement statement = null; try { connection = database.getConnection(); statement = connection.prepareStatement(sql); for (Item item : items) { statement.setObject(1 item.getSomething()); statement.addBatch(); } statement.executeBatch(); } finally { if (statement != null) try { statement.close(); } catch (SQLException ignore) {} if (connection != null) try { connection.close(); } catch (SQLException ignore) {} } } If all you want is just improving connecting performance then use a connection pool. For example C3P0. But certainly do not share expensive DB resources among threads! This way you also don't need to worry about threadsafety. That's an implementation detail. Oh if that's not clear yet: you will not improve database performance by sharing the same statement and connection among multiple threads. Even worse it would only slowdown and you'll run into threadsafety issues at both the Java and the Database side. I have 50+ threads reading large number of 'keys' from database calculating values and updating corresponding rows. I call executeBatch() in a seperate thread and now modified it so it creates a new PreparedStatement for other threads to use while executeBatch() is in progress. I merely asked this question to learn because the original answer to this question was misleading. Consider placing a work-queue to which the 50+ threads add row updates and 1 consuming thread picking up those updates issuing `addBatch()` and `executeBatch()` calls. @rsp has the right answer decouple reading & processing from updating.  It might be very vendor specific for JDBC. I'd rather never rely on concurrent access to batch and delegate the complexity of concurrency to database server. why not to have just more independent connections ?  Yes. According to the JDBC specification all JDBC driver implementations must be thread safe: Compliance with the JDBC 3.0 API section A.1.6 If I understand your comment on BalusC' response correctly you are iterating through the ResultSet from one Statement and operate with other PreparedStatements in a separate thread simultaneously to update other rows. This does not necessarily have to work (again it depends on the JDBC driver but is not directly related to thread safety). I am not sure about the most recent versions but older Oracle JDBC drivers did e.g. not support multiple statements did of course not fail properly but produced unexpected results as you describe. If I remember correctly creating a second statement on a connection while iterating through the result set from the first statement would cause the first statement to be silently closed and the first result set only to return the rows already fetched from the database although more rows could have been available. Your implementation sound similar and may show similar behaviour also with other databases. @jambjo: Yes i am updating rows as i select them. But creating a new PreparedStatement before calling executeBatch solved my problem.  PreparedStatement don't force the implementing classe to make these method thread safe. So quite obvious it depends on implementing class. For ex:- DelegatingPreparedStatement is having these methods but those are not thread safe whereas 'OraclePreparedStatement' is also having these methods and those are thread safe.  As jambjo pointed out the spec requires thread safety. However as Rakesh Juyal pointed out there is no way to ensure such safety in practice. So if you want to be truly portable and robust avoid multi-threaded access to the variables as much as possible unless you are sure the drivers you are using are spec compliant. As for addBatch and executeBatch these methods are themselves unreliable in certain cases. I know that whenever I've tried to use these with Oracle drivers (single thread) I got unpredictable results. So maybe thread safety isn't your problem but rather batches.
45,A,"JDBC: Can I share a connection in a multithreading app and enjoy nice transactions? It seems like the classical way to handle transactions with JDBC is to set auto-commit to false. This creates a new transaction and each call to commit marks the beginning the next transactions. On multithreading app I understand that it is common practice to open a new connection for each thread. I am writing a RMI based multi-client server application so that basically my server is seamlessly spawning one thread for each new connection. To handle transactions correctly should I go and create a new connection for each of those thread ? Isn't the cost of such an architecture prohibitive? Yes in general you need to create a new connection for each thread. You don't have control over how the operating system timeslices execution of threads (notwithstanding defining your own critical sections) so you could inadvertently have multiple threads trying to send data down that one pipe. Note the same applies to any network communications. If you had two threads trying to share one socket with an HTTP connection for instance. Thread 1 makes a request Thread 2 makes a request Thread 1 reads bytes from the socket unwittingly reading the response from thread 2's request If you wrapped all your transactions in critical sections and therefore lock out any other threads for an entire begin/commit cycle then you might be able to share a database connection between threads. But I wouldn't do that even then unless you really have innate knowledge of the JDBC protocol. If most of your threads have infrequent need for database connections (or no need at all) you might be able to designate one thread to do your database work and have other threads queue their requests to that one thread. That would reduce the overhead of so many connections. But you'll have to figure out how to manage connections per thread in your environment (or ask another specific question about that on StackOverflow). update: To answer your question in the comment most database brands don't support multiple concurrent transactions on a single connection (InterBase/Firebird is the only exception I know of). It'd be nice to have a separate transaction object and to be able to start and commit multiple transactions per connection. But vendors simply don't support it. Likewise standard vendor-independent APIs like JDBC and ODBC make the same assumption that transaction state is merely a property of the connection object. Thank you very much for your answer !!! Ok... Just by curiosity do you have an idea of why the transaction's definition is that coupled with definition of connection on JDBC? I'd really appreciate a transaction object. The statement ""you could inadvertently have multiple threads trying to send data down that one pipe"" in this answer is definitively wrong for postgresql. See http://doc.postgresintl.com/jdbc/ch10.html . The connection is at least thread safe albeit not fully parallelized as it could be. Thanks that's a nice reference. I also found that the JDBC driver was made fully thread-safe in release 6.4 circa 1998. Oh did computers already exist by then? ;-) Watch it sonny! :-)  The same connection object can be used to create multiple statement objects and these statemet objects can then used by different threads concurrently. Most modern DBs interfaced by JDBC can do that. The JDBC is thus able to make use of concurrent cursors as follows. Postgresql is no exception here see for example: http://doc.postgresintl.com/jdbc/ch10.html This allows connection pooling where the connection are only used for a short time namely to created the statement object and but after that returned to the pool. This short time pooling is only recommended when the JDBC connection does also parallelisation of statement operations otherwise normal connection pooling might show better results. Anyhow the thread can continue work with the statement object and close it later but not the connection. 1. Thread 1 opens statement 3. Thread 2 opens statement 4. Thread 1 does something Thread 2 does something 5. ... ... 6. Thread 1 closes statement ... 7. Thread 2 closes statment The above only works in auto commit mode. If transactions are needed there is still no need to tie the transaction to a thread. You can just partition the pooling along the transactions that is all and use the same approach as above. But this is only needed not because of some socket connection limitation but because the JDBC then equates the session ID with the transaction ID. If I remember well there should be APIs and products around with a less simplicistic design where teh session ID and the transaction ID are not equated. In this APIs you could write your server with one single database connection object even when it does transactions. Will need to check and tell you later what this APIs and products are.  It's uncommon practice to open a new connection for each thread. Usually you use a connection pool like c3po library. If you are in an application server or using Hibernate for example look at the documentation and you will find how to configure the connection pool. What's the problem with LGPL ? You can use it with commercial applications ( it's Lesser GPL). Thank you for your contribution. I should be ok without a connection pool in my case : I'm not very likely to request for connections too often anyway. For other reader : I am pretty sure that c3po is a great library however be sure that it is ok for you to use LGPL."
46,A,"Problem connectiong to a SQL Server 2008 named instance using Hibernate I'm using Hibernate to connect to an SQL Server 2008 named instance. This works if I use the default instance name but not when using the ""named"" instance. config.setProperty(""hibernate.connection.url""""jdbc:sqlserver://127.0.0.1\INSTANCE_NAME:1433;databaseName=DB_NAME;autoReconnect=true""); Any ideas why this happens? Thanks in advance. A named instance does not listen on port 1433 only the default instance You should not need the :1433 bit Default vs named instances is mentioned in the MS JDBC info on MSDN Thanks that was the problem."
47,A,How do I use oracle.jdbc.driver.OracleLog? I am receiving an error from the Oracle JDBC driver (ojdbc14_g.jar) when trying to obtain a connection to a 10g database. The driver has an oracle.jdbc.driver.OracleLog class which could help but the Oracle documentation is unclear how best to use it. Has anyone had any success using this class? If so some guidance on its use would be appreciated. For info the error I'm getting from the JDBC driver is: java.sql.SQLException: No more data to read from socket at oracle.jdbc.driver.DatabaseError.throwSqlException (DatabaseError.java:112) at oracle.jdbc.driver.DatabaseError.throwSqlException (DatabaseError.java:146) at oracle.jdbc.driver.DatabaseError.throwSqlException (DatabaseError.java:208) at oracle.jdbc.driver.T4CMAREngine.unmarshalUB1 (T4CMAREngine.java:1118) at oracle.jdbc.driver.T4CMAREngine.unmarshalSB1 (T4CMAREngine.java:1070) at oracle.jdbc.driver.T4CTTIoauthenticate.receiveOsesskey (T4CTTIoauthenticate.java:266) at oracle.jdbc.driver.T4CConnection.logon (T4CConnection.java:357) at oracle.jdbc.driver.PhysicalConnection.<init> (PhysicalConnection.java:414) at oracle.jdbc.driver.T4CConnection.<init> (T4CConnection.java:165) at oracle.jdbc.driver.T4CDriverExtension.getConnection (T4CDriverExtension.java:35) at oracle.jdbc.driver.OracleDriver.connect (OracleDriver.java:801) at oracle.jdbc.pool.OracleDataSource.getPhysicalConnection (OracleDataSource.java:297) at oracle.jdbc.pool.OracleDataSource.getConnection (OracleDataSource.java:221) at oracle.jdbc.pool.OracleDataSource.getConnection (OracleDataSource.java:165) Google just found this for me. Also try using java.sql.DriverManager.setLog(Stream|Writer) and see if that gets you any more information about what is going on. I'm using a DataSource (rather than the DriverManager). The equivalent functionality on that class does not seem to be supported by Oracle...  The logging is usually too low to be interpreted by anyone except Oracle support. Anyway the above code indicates there is some network connectivity issue between the client and the server (more data was expected to be read from the TCP socket but it somehow got interrupted). What kind of a network are you using? You checked the status and error logs on the server listener?
48,A,"Are anonymous blocks stored parsed in the SGA? I have discovered recently that's possible to call anoymous blocks from jdbc like this:  String plsql = ""BEGIN"" + "" :result := foobar( booleanparameter => :mypar > 2);"" + ""END;""; con.prepareCall(plsql); Which is great because I can use this to ""wrap"" some function calls and overcome some jdbc limitations. For example I can't pass boolean vars to pl/sql procedures and can't change the procedures signature since there is lots of code which depends on them. Adding new ""wrapping"" procedures isn't easy too because of internal policy reasons. So it's seems like an acceptable solution but I'm concerned about parsing overhead. Are anonymous blocks like this stored parsed in the SGA or are they parsed every time they are called? Thanks Update 1: I have made a quick beanshell script to look into v$sqlarea as egorius suggests:  String plsql = ""BEGIN :myresult := dbms_random.random ; END;""; OracleDriver oracledrv = new OracleDriver(); Connection con = oracledrv.connect(connstr new Properties()); for (int i = 0 ; i < 1000 ; i++ ) { CallableStatement cb = con.prepareCall(plsql); cb.registerOutParameter(""myresult"" Types.INTEGER); cb.execute(); System.out.println(""random ->"" +cb.getInt(""myresult"")); cb.close(); } con.close(); And this is what I get int v$sqlarea (I have run it twice):  SQL_TEXT -------------------------------------------------------------------------------- PARSE_CALLS EXECUTIONS ----------- ---------- BEGIN :myresult := dbms_random.random ; END; 2000 2000 Does this mean that is preparsed or not? Last time I checked (Oracle 10g) there isn't a boolean data type. May be not in Oracle's SQL but PL/SQL sure has one. I've edited my answer concerning your update1. In regards to always soft parsing that is not necessarily so. Oracle allows both Java and PL/SQL have the ability to parse a statement just once per session. This happens when a cursor is not closed but reused - no parsing. SQL Parsing Info: http://docs.oracle.com/cd/E11882_01/server.112/e25789/sqllangu.htm Private SQL area: http://docs.oracle.com/cd/E11882_01/server.112/e25789/memory.htm#i17716  Anonymous blocks are cached as well. You can check it by querying V$SQLAREA. SQL> declare abcabc number; begin null; end; 2 / PL/SQL procedure successfully completed. SQL> / PL/SQL procedure successfully completed. SQL> select sql_text executions from v$sqlarea where sql_text like '%abcabc%'; SQL_TEXT -------------------------------------------------------------------------------- EXECUTIONS ---------- declare abcabc number; begin null; end; 2 select sql_text executions from v$sqlarea where sql_text like '%abcabc%' 1 EDIT: You'll always have what is called SOFT PARSE. It's needed for syntax and semantic check of a query. After that if exactly the same query exists in library cache HARD PARSE will be skipped. (See this Ask Tom question for a good explanation). Here is excerpt from tkprofed 10046 trace file: declare abcabc number; begin null; end; call count cpu elapsed disk query current rows ------- ------ -------- ---------- ---------- ---------- ---------- ---------- Parse 2 0.00 0.00 0 0 0 0 Execute 2 0.00 0.00 0 0 0 2 Fetch 0 0.00 0.00 0 0 0 0 ------- ------ -------- ---------- ---------- ---------- ---------- ---------- total 4 0.00 0.00 0 0 0 2 Misses in library cache during parse: 1 The last line shows the point. +1 Another thing: PrepareCall() returns CallableStatement object which can by invoked many times to get result of concrete already prepared statement without parsing. Thanks a lot egorius."
49,A,"How do I store a string longer than 4000 characters in an Oracle Database using Java/JDBC? I’m not sure how to use Java/JDBC to insert a very long string into an Oracle database. I have a String which is greater than 4000 characters lets say it’s 6000. I want to take this string and store it in an Oracle database. The way to do this seems to be with the CLOB datatype. Okay so I declared the column as description CLOB. Now when it comes time to actually insert the data I have a prepared statement pstmt. It looks like pstmt = conn.prepareStatement(“INSERT INTO Table VALUES(?)”). So I want to use the method pstmt.setClob(). However I don’t know how to create a Clob object with my String in it; there's no constructor (presumably because it can be potentially much larger than available memory). How do I put my String into a Clob? Keep in mind I’m not a very experienced programmer; please try to keep the explanations as simple as possible. Efficiency good practices etc. are not a concern here I just want the absolute easiest solution. I’d like to avoid downloading other packages if it all possible; right now I’m just using JDK 1.4 and what is labelled ojdbc14.jar. I've looked around a bit but I haven't been able to follow any of the explanations I've found. If you have a solution that doesn’t use Clobs I’d be open to that as well but it has to be one column. Here is an example at oracle.com for using LOB columns with Oracle and JDBC. Basically it's inserting a LOB locator for an empty LOB (actually two since it's demonstrating both BLOBs and CLOBs) locking the row for update and then using the BLOB and CLOB OutputStream interfaces to write the data into the LOBs. When the ""SELECT ... FOR UPDATE"" is released the LOBs will be refreshed in the database and the newly inserted data will be visible.  There are several methods see Java Database Connectivity (JDBC) - Convert String to CLOB and Insert into Oracle database  You have (at least) two options: use connection.createClob() to create a Clob set the data on it and set it on the prepared statement. This will work for smaller data use preparedStatement.setClob(position reader) - here you will have a Reader instance. Ah createClob() is exactly what I was looking for. Thanks. Actually I'm getting the error: Exception in thread ""main"" java.lang.AbstractMethodError: oracle.jdbc.driver.OracleConnection.createClob()Ljava/sql/Clob; when I run it. It comes from the line: Clob description = conn.createClob(); that might mean your jdbc driver isn't up to date. Well the database is 10.1.0.3 I don't see any JDBC driver downloads for that version on Oracle's website...I'm presuming that what I have is 10.1.0.3 but I can't be certain. It might be worth noting that I'm using Class.forName(""oracle.jdbc.driver.OracleDriver""); rather than an import statement. I don't really know much about this but it seems like it could be relevant. Okay I got the 10.1.0.5 drivers. I decided to use the Property class and set ""SetBigStringTryClob"" to ""true"" so that I can just use pstmt.setString and it won't complain if the string is long."
50,A,"Why isn't querying a JDBC-compliant database from Oracle as easy as pie? Ok so it's almost as easy as pie already. But it really should be as easier than it is. I think I should be able to connect to another database just by putting a JDBC connection string into TNSNAMES. Every database vendor has a type-4 JDBC driver and there's usually a good free alternative. With Oracle being such keen Java fans and with a JVM built-in to the database I'd have thought a JDBC-based linking technology would have been a no-brainer. It seems a natural extension to have a JDBC connection string in TNSNAMES and everything would ""just work"" - you could ""sql*plus"" to anything. But it doesn't work this way. If you want to connect to another non-Oracle database You have to buy something called Oracle Gateways or mess around with ODBC (through something called Generic Connectivity). [Originality warning... This is related to a previous question of mine but someone suggested I enter a supplementary comment as a separate question. Who am I to argue?] There's a JVM in the database and JDBC drivers to every other database - it should ""just work"" so I can only assume it hasn't been made to ""just work"" for a reason. My question is whether anyone knows that reason. Does anyone? I don't get why this question is getting down-voted. Think I've missed the mood. :-) It's a real question - perhaps slightly jokey but certainly not rhetorical. It is entirely in Oracle's interest to make it really easy to access other people's data. At the moment there's lots of ways to do it but none sufficiently straightforward. There's a JVM in the database and JDBC drivers to every other database - it should ""just work"" so I can only assume it hasn't been made to ""just work"" for a reason. My question is whether anyone knows that reason. Does anyone?  TNS is a bit of a mess imho. It seems to behave inconsistently between different platforms in my (admittedly limited) experience. Far be it for me to defend Oracle but I've had no problems with the JDBC thin driver. (If you read the oracle jdbc docs they discourage you from using oci unless you have a very good reason. Pair it with JNDI (on a j2ee app server) and all your connection management problems are taken care of. Using JDBC from an application is really easy - I agree. I can write a Java stored procedure to pull data directly from MS SQL Server to Oracle - no problems. But if TNSNAMES was JDBC-friendly I could just set up a database link and pull the data over in standard SQL.  The answer is the same as for the following questions: Why doesn't Oracle provide an efficient way of unloading data into a non-proprietary format (e.g. comma-delimited or XML) Why do most Oracle non-DB products only work with the Oracle RDBMS? (without having to use Oracle Database Gateways) You've ever heard of the concept of Vendor lock-in? Oracle would probably answer you back: you should migrate any other databases to Oracle (with e.g. Oracle Migration Workbench) and then for online distributed queries use DB Links or import the data through flat files... Thanks for the answer Andrew. I take your point about Vendor lock-in but isn't this the reverse case? I'm talking about pulling data FROM anywhere INTO Oracle. It's certainly in Oracle interest to make externally available data as accessible as possible.  I certainly think the question was somewhat rhetorical and to be taken with a large pinch of salt. :-) In that spirit a suitably flipant answer might be ""because they don't want you to use anyone else's database""?"
51,A,How to cancel a postgres query in java/JDBC How do I cancel a long running postgres query via JDBC or Java? The usecase would be that an user starts a query on a postgres database via a front end but then he decides otherwise and wants to abort/cancel the currently running query. Call java.sql.PreparedStatement.cancel() method. Check whether postgres JDBC driver supports this method. As far as I can see from the source code of the latest postgres JDBC driver it does stop the query. Thanks Boris thats it. Works like a charm.
52,A,"SQLServerException: The statement did not return a result set when executing SQL I'm using using the sqljdbc4.jar (sqljdbc_2.0) version. I'm executing an insert + a select back to get the identity like this: BEGIN INSERT INTO DateRangeOptions (DescriptionCode) VALUES ('dateRange.quickPick.option.all''ALL'); SELECT SCOPE_IDENTITY() END and I get:  com.microsoft.sqlserver.jdbc.SQLServerException: The statement did not return a result set. The line is: st.executeQuery(updateQuery) Any ideas? Not all drivers allow statement blocks to be executed as one query. If this works in one and not another that is the likely culprit. that would not be very prudent of Microsoft donnie a select scope_identity() MUST happen before any other inserts and on a connection with the same job id. You can of course perform the queries back to back but it restricts how a open connection can be used by applications. Also SQL server has no problem executing multiple queries and the driver is not T-SQL aware so it has no clue what it is executing. – Vainstah 0 secs ago The row you inserted failed therefore there is no identity ? set a breakpoint query is generated in Java copy out the query string and run it in management studio to see what the result is. This might show you what you are doing wrong. No the insert works fine in the query analyzer. ery odd if the query is syntactically correct it should not casue a problem. Are the drivers plug-swappable ? The microsoft driver - might- require different initialization function calls. This is certainly the case with different ODBC drivers. Have you changed to the correct catalog ?  Upgraded from SQL 2000 to SQL 2005 and switched to Microsoft SQL Server 2005 JDBC Driver version 1.2. I got the error ""The statement did not return a result"" when executing an Insert followed by SELECT SCOPE_IDENTITY()"".I solved the issue using executeUpdate() and getGeneratedKeys instead of executeQuery. Here is the before and after code. Note: The connection used in this example is java.sql.connection not the com.microsoft.sqlserver.jdbc.SqlServerConnection. SQL 2000 code String dbURL = ""jdbc:sqlserver"" + ""://"" + dbServer + "":"" + dbServerPort + "";SelectedMethod=cursor;databaseName="" + dbName + "";user=xxx;password=xxx""; Class.forName(""com.microsoft.sqlserver.jdbc.SQLServerDriver""); java.sql.Connection connection = DriverManager.getConnection(dbURL); sql = ""insert into Contact (name) values ('ABC'); SELECT SCOPE_IDENTITY()""; PreparedStatement ps = connection.prepareStatement(sql); ResultSet rs = ps.executeQuery(); if (rs.next()) { long id = rs.getLong(1); System.out.println(""Id="" + id); } SQL 2005 code String dbURL = ""jdbc:sqlserver"" + ""://"" + dbServer + "":"" + dbServerPort + "";SelectedMethod=cursor;databaseName="" + dbName + "";user=xxx;password=xxx""; Class.forName(""com.microsoft.sqlserver.jdbc.SQLServerDriver""); java.sql.Connection connection = DriverManager.getConnection(dbURL); sql = ""insert into Contact (name) values ('ABC'); SELECT SCOPE_IDENTITY()""; PreparedStatement ps = connection.prepareStatement(sql); ps.executeUpdate(); // do not use execute() here otherwise you may get the error // The statement must be executed before // any results can be obtained on the next // getGeneratedKeys statement. ResultSet rs = ps.getGeneratedKeys(); if (rs.next()) { long id = rs.getLong(1); System.out.println(""Id="" + id); } Thanks for this this is really bizarre and makes little sense. I need to research why this works.  Any option to upgrade the driver? Then you can just use Statement#getGeneratedKeys(). Also see this article: http://msdn.microsoft.com/en-us/library/ms378445%28SQL.90%29.aspx If that is not an option then you need to fire the INSERT and SELECT separately after each other on the same connection."
53,A,What causes a Spring 1.2 NullPointerException when creating prepared statement? Using Spring 1.2.1 and oracle.jdbc.pool.OracleDataSource 10.2.0.3.0 I sometimes get a stack trace like below. I think it is caused by the connection pool being full. Does anyone know the cause for sure? Also do newer versions of spring or Oracle JDBC handle this better? java.lang.NullPointerException at org.springframework.jdbc.core.PreparedStatementCreatorFactory$PreparedStatementCreatorImpl.createPreparedStatement(PreparedStatementCreatorFactory.java:213) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:444) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:491) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:522) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:543) at org.springframework.jdbc.object.SqlQuery.execute(SqlQuery.java:114) at org.springframework.jdbc.object.SqlQuery.execute(SqlQuery.java:124) at sps.wfds.biz.glacier.MemberDAO.create(MemberDAO.java:44) at sps.wfds.biz.glacier.MemberDAO.create(MemberDAO.java:23) at sps.wfds.biz.glacier.AbstractDAO.createAndValidate(AbstractDAO.java:22) at sps.wfds.web.interceptor.AbstractPrincipal.init(AbstractPrincipal.java:87) at sps.wfds.web.interceptor.AbstractPrincipal.getAttributes(AbstractPrincipal.java:66) at sps.wfds.web.interceptor.AbstractPrincipal.getAttribute(AbstractPrincipal.java:60) at sps.wfds.web.interceptor.AbstractPrincipal.setLocale(AbstractPrincipal.java:38) at sps.wfds.web.util.LocaleUtil.setLocale(LocaleUtil.java:24) at sps.wfds.web.interceptor.SSOPrincipal.(SSOPrincipal.java:22) at sps.wfds.web.interceptor.SSOAuthority.getPrincipal(SSOAuthority.java:18) at sps.wfds.web.interceptor.Authorization.preHandle(Authorization.java:44) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:674) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:625) at org.springframework.web.servlet.FrameworkServlet.serviceWrapper(FrameworkServlet.java:386) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:346) at javax.servlet.http.HttpServlet.service(HttpServlet.java:689) I've updated my answer - please take a look This has nothing to do with Spring. DataSource.getConnection() should never return null; it should either return a valid connection or throw a SQLException. The error is caused by oracle.jdbc.pool.OracleDataSource misbehaving. Update: According to Oracke documentation this happens when: the maximum number of connections has already been allocated in pool; ConnectionWaitTimeout has been set to non-zero value you've been waiting on getConnection() for that duration and no connections have been returned to the pool. So with that in mind you can: Review your code to make sure there's no connection leak Increase your pool size Increase your connection wait timeout Use a different pool :-) or write a simple wrapper around OracleDataSource that would check for 'null' being returned and throw an SqlException instead. In that last scenario you'd only be trading one exception for the other though (NPE -> SqlException). Granted it'll be more appropriate but it's not really going to solve the problem. Thank you for providing the cause -- are you able to help with the cause of that?  public PreparedStatement createPreparedStatement(Connection con) throws SQLException { As you can see the signature takes a Connection object like ChssPly76 said and can't find it. Based on the signature how can you tell that the NullPointerException is caused by the method parameter instead of something else in the method?
54,A,"How can I get a custom CallableStatement object out of a prepareCall method I want to create a subclass that extends the CallableStatement object. I want to do this so I can override the execute and executeQuery methods to track some metrics on each SP call. Currently I have code that looks like this: Connection db = poolingDataSource.getConnection(); CallableStatement cstmt = db.prepareCall(""{call pSampleStoredProc()}""); ResultSet rs = cstmt.executeQuery(); where poolingDataSource is from the apache commons dbcp package. My implementation is hooked into a MySQL database using JDBC. Currently the prepareCall method returns a com.mysql.jdbc.JDBC4CallableStatement. I'd like to be able to change this so that it returns a class of my own that extends JDBC4CallableStatement but overrides the execute() and executeQuery() methods. Any ideas about the best way to do this? If you have a manageable number of places where you need to do this I suggest an easy way to do it (easier than trying to get that database driver to return your custom CallableStatement object) would be to make a wrapper or decorator to wrap over the CallableStatement object you get from db. Basically make a class that implements all the methods of CallableStatement takes a CallableStatement object as a parameter to its constructor and delegates all the method calls right through to the other object with the exception that for execute() and executeQuery() you also call your logging methods before and after delegating to the other objects execute() method. Certainly there are other ways to do this this just struck me as easier. Connection db = poolingDataSource.getConnection(); CallableStatement cstmt = db.prepareCall(""{call pSampleStoredProc()}""); MyCallableStatement mystmt = new MyCallableStatement( cstmt ); ResultSet rs = mystmt.executeQuery(); This is a good idea although not as elegant as I was hoping. :-) Tom your comment gave me an idea about how I could do this in a way that is more reusable so that other programmers on the team won't have to remember to use MyCallableStatement. Unless someone else can come up with a more elegant solution this is it. @tackline If the goal is encapsulating then I would wrap the whole thing (`DataSource` `Connection` `CallableStatement`). So to client code it would be absolutely transparent. I've found it pretty helpful to wrap the code where I get a connection in some generic utility method of my own so that if/when I need to go back and change something or add something (like logging) then I can just do whatever I needed to do in that utility method instead of changing every piece of code in the app that gets a db connection. This would be a good example. :) `CallableStatement mystmt = new MyCallableStatement( cstmt );`. Actually you could wrap the `Connection` too. I ended up creating a decorate Connection object which returned a decorated CallableStatement. Since my connection creation process was in common code (which isn't represented in the example I gave above) this presented an ideal way to create these decorated objects with a minimum of code changes (and new code should pick up these changes without even thinking about it.)"
55,A,"Insert Java variable using Java in SQL I was trying to do:  String sql = ""INSERT INTO CURRENT_WEATHER_US VALUES(""+city_code+"" ""+object.city+""""+object.region+""""+object.country+""""+object.wind_chill+"" ""+object.wind_direction+"" ""+object.wind_speed+""""+object.humidity+""""+object.visibility+"" ""+object.pressure+""""+object.rising+"" ""+object.sunrise+""""+object.sunset+""""+object.textual_description+"" ""+object.condition_code+""""+object.temp+""""+object.for_temp_high+"" ""+object.for_temp_low+""""+object.for_description+""""+object.forecast_code+"")""; stmt.execute(sql); Error is missing comma Please Help This is the worst possible way to work with SQL statements in Java. See BalusC's answer for the right way. This is not really the way you're supposed to construct and execute an INSERT. This is not only prone to SQL Injections but it is also pretty .. cumbersome ;) Possibly a value contained a singlequote and caused your query to be syntactically invalid. I recommend you to replace Statement by PreparedStatement (tutorial here). This way you can nicely put fullworthy Java objects in a SQL statement by value index without worrying about strings which may syntactically break the SQL query (and thus also SQL injection risks). Here's a kickoff example: private static final String SQL_INSERT = ""INSERT INTO CURRENT_WEATHER_US"" + "" VALUES(? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)""; public void create(String cityCode Weather weather) throws SQLException { Connection connection = null; PreparedStatement statement = null; try { connection = database.getConnection(); statement = connection.prepareStatement(SQL_INSERT); statement.setString(1 cityCode); statement.setString(2 weather.getCity()); statement.setString(3 weather.getRegion()); // ... statement.setString(20 weather.getForecastCode()); statement.executeUpdate(); } finally { if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } } To learn more about using basic JDBC the proper way you may find this article useful. Hope this helps.  Like all the others say you really should convert it to use PreparedStatements for a number of reasons. You are most likely getting the error (you didn't post the exact ORA error) because you passing in String type values but you didn't wrap them in single quotes in your hard coded query. If textual_description and for_description where the only String type columns in your query then your query would need to look like this: String sql = ""INSERT INTO CURRENT_WEATHER_US VALUES( "" + city_code + "" "" + object.city + "" "" + object.region + "" "" + object.country + "" "" + object.wind_chill + "" "" + object.wind_direction + "" "" + object.wind_speed + "" "" + object.humidity + "" "" + object.visibility + "" "" + object.pressure + "" "" + object.rising + "" "" + object.sunrise + "" "" + object.sunset + "" "" + ""'"" + object.textual_description + ""' "" + object.condition_code + "" "" + object.temp + "" "" + object.for_temp_high + "" "" + object.for_temp_low + "" "" + ""'"" + object.for_description + ""' "" + object.forecast_code + "" )""; stmt.execute(sql); Notice the single quotes surrounding those values now.  You should look into using PrepairedStatements instead of building Strings. They are quicker and take care of many pitfalls related to quoting and escaping values."
56,A,"Weblogic 10.0: advantages with database connectivity and gotchas? What advantages (if any) does Weblogic 10.0 provide in terms of database connectivity (to any database) over open source or commercial alternatives? Are there any Weblogic specific gotchas with using a Weblogic database connection? I'm a Java EE Weblogic newbie so please excuse the simple questions. What advantages (if any) does Weblogic 10.0 provide in terms of database connectivity (to any database) over open source or commercial alternatives? Weblogic supports clustering of JDBC objects (data sources connection pools and multipools) and failover and load balancing of JDBC connections and the administration part is very mature. Having that said I'm sure some other products (some of them not all) do have equivalent features and wonder if the support of such things can thus be considered as an advantage. All I know is that Weblogic support for these features is really good. Actually Weblogic is well know for being a rock solid application server and is frequently used for ""mission critical"" applications. But most applications do not have such needs. Are there any Weblogic specific gotchas with using a Weblogic database connection? I'm not sure what you mean by a ""weblogic database connection"" but AFAIK no.  As of today transparent datasource failover is still a rare feature in opensource servers. Especially the ability to switch in the middle of a connection being used is something you don't see often. Jboss does allow to enter a second URL for a datasource but it's a bit of a crude mechanism (the documentation mentions this) and it hasn't been much improved over the years.  Connectivity to any database is accomplished through JDBC drivers; it has nothing to do with WebLogic. If I recall correctly WebLogic ships with drivers for Oracle Sybase and perhaps SQL Server but you have to add any others that you need. This is true of all Java EE app servers commercial or open source. The value that WebLogic adds is JNDI services and connection pooling. It allows to configure pools so that connections are checked before users are allowed to use them stale connections are recycled etc. These are features that would be laborious to code on your own. WebLogic makes it easy to do via configuration. Isn't connection pooling provided by most JEE servers? Is that a WebLogic only feature? Yes of course they do. Not all of them are as easy to administer as WebLogic is. I don't know if they all support features for checking connections for freshness as they go in and out."
57,A,"Determine if column in ResultSet contains values in all rows In my application I perform a costly query that takes minutes to produce a report. I am trying to make a generic class that transforms a ResultSet to and Excel spreadsheet where a column is excluded from the spreadsheet if it only contains nulls. I can remove the columns from the Excel sheet after the fact easily but it is difficult to ""glue"" worksheets back together after I have already split them when there are too many columns. I could do a query to check if each column is null but this would entail running the costly query all over again perhaps multiple times which would make the generation of the spreadsheet take too long. Is there a way that I can query the ResultSet object that I already have (a little like ColdFusion) and remove columns from it? EDIT I ended up adding a pre-processing step where I added the column numbers of the used columns to a List<Integer> and then iterating through that collection rather than the set of all columns in the ResultSet. A few off-by-one errors later and it works great. Can you extract the data from the ResultSet and store it in memory first before creating the work sheet or is it too large? If so then while you're extracting it you could remember whether a non-null value has been seen in each column. Once you're done extracting you know exactly which columns can be omitted. Of course this doesn't work so well if the amount of data is so large that you wouldn't want to store it in memory. Another solution would be to store the results of the costly query in a ""results"" table in the database. Each row for a given query execution would get stamped with a ""query id"" taken from a database sequence. Once the data is loaded into this table subsequent queries to check whether ""all values in column X are null"" should be pretty speedy. Note: if you're going to take this second approach don't pull all the query data up to your application before storing it back to the results table. Rewrite the original ""costly"" query to do the insert. ""insert into query_result(columns...) select {costly query}"".  I could do a query to check if each column is null Better still you could incorporate that check into the original query via a COUNT etc. This will be miles quicker than writing Java code to the same effect."
58,A,"WebSphere local transaction containment boundary issue J2CA0086W In WebSphere if you code opens two concurrent database connections you get an error of the form: J2CA0086W: Shareable connection MCWrapper id 556e556e Managed connection WSRdbManagedConnectionImpl@52365236 State:STATE_TRAN_WRAPPER_INUSE from resource jdbc/abc was used within a local transaction containment boundary. Our framework allows us to do so (nested transactions which can be on a separate connection or multiple named transactions). I've seen lots of references to turning off some switch in WebSphere to turn on connection sharing but no details on how to set this flag. Can someone point me to the steps to achieve this? Specifically if you see this article: http://www-01.ibm.com/support/docview.wss?rs=180&context=SSEQTP&dc=DB520&dc=D600&dc=DB530&dc=D700&dc=DB500&dc=DB540&dc=DB510&dc=DB550&q1=j2ca0086w&uid=swg21121449&loc=en_US&cs=utf-8&lang=en under ""Resolving the problem"" I want to know how to set the connection pool to be unshareable (assuming that indeed solves the problem). Found out the root cause is the fact that because J2EE 2.0 didn't mention what the container's behavior should be when not using global transactions WebSphere introduced ""Local Transaction Containment"" and imposed this requirement that within a servlet call (in our case) you cannot have a thread have two physical database connections. Bummer! I guess I'll run from WebSphere next time! ok Unshareable sets the datasource as unshareable except when accessing via Hibernate/JPA I continue to get the same error (as if WebSphere was treating the connection as shareable). The message happens when dataSource.getConnection() is called twice in a servlet. The datasource jdbc/oracle is lookup from local reference. Call it once and reuse the connection or call con.close() before doing the 2nd getConnection()  What version of IBM WAS are you using? If you have WAS 8 go to Resources-> JDC-> Datasources-> your datasources -> WebSphere Application Server properties -> Datasources no transactional. Sorry for my english."
59,A,"Drop all tables in sql server database using ant script Can anybody help me with this? I prefer if I don't have to explicitly list the table names. How about dropping the database? DROP DATABASE <database name> Of course that's rough on stored procedures triggers etc. But if the purpose is to eliminate all the tables in order to recreate them it makes sense that you'd recreate all the other associated components as well such as indexes. Why drop the database? One would loose all the other objects as well. It seems you anticipated my addendum. Without the tables there's very little value in the other objects. That may work but i'm not sure what will happen to various settings like users roles etc i don't think i can recreate them via ant. It's been 8+ years since I've touched SQLserver but Oracle and MySQL store the user roles separately from the database. For permissions specific to a table it would be unreasonable to expect those to survive a dropped table.  Saw this before... exec sp_MSforeachtable ""DROP TABLE ? PRINT '? to be dropped' "" Source - http://sqlserver-qa.net/blogs/t-sql/archive/2008/05/20/4266.aspx Can i execute this via ant ? Yes - If you can install ant on windows and then use the sql command line SQLCMD.exe located here http://www.microsoft.com/downloads/details.aspx?FamilyId=C6C3E9EF-BA29-4A43-8D69-A2BED18FE73C&displaylang=en . Or if you're on Linux you can probably find some kind of sql connectivity yes?"
60,A,"java.sql.SQLException: No suitable driver found for jdbc:derby: I'm a beginner with jdbc ... I have a problem running this code : This code uses appache derby and in order to make it work I first started the derby server..  java -jar ""C:\Program Files\Sun\JavaDB\lib\derbyrun.jar"" server start And then started the program  java -classpath derbyclient.jar -jar TestDB.jar I set the class path C:\Program Files\Sun\JavaDB\lib\derby.jar And I'm always getting that exception java.sql.SQLException: No suitable driver found for jdbc:derby://localhost:1527/ BOOKDB;create=true at java.sql.DriverManager.getConnection(DriverManager.java:602) at java.sql.DriverManager.getConnection(DriverManager.java:185) at TestDB.getConnection(TestDB.java:63) at TestDB.runTest(TestDB.java:20) at TestDB.main(TestDB.java:11) import java.sql.*; import java.io.*; import java.util.*; class TestDB { public static void main(String args[]) { try { runTest(); } catch (SQLException ex) { for (Throwable t : ex) t.printStackTrace(); } catch (IOException ex) { ex.printStackTrace(); } } public static void runTest() throws SQLException IOException { Connection conn = getConnection(); try { Statement stat = conn.createStatement(); stat.executeUpdate(""CREATE TABLE Greetings (Message CHAR(20))""); stat.executeUpdate(""INSERT INTO Greetings VALUES ('Hello World!')""); ResultSet result = stat.executeQuery(""SELECT * FROM Greetings""); if (result.next()) System.out.println(result.getString(1)); result.close(); stat.executeUpdate(""DROP TABLE Greetings""); } finally { conn.close(); } } public static Connection getConnection() throws SQLException IOException { Properties props = new Properties(); FileInputStream in = new FileInputStream(""database.properties""); props.load(in); in.close(); String drivers = props.getProperty(""jdbc.drivers""); if (drivers != null) System.setProperty(""jdbc.drivers"" drivers); String url = props.getProperty(""jdbc.url""); String username = props.getProperty(""jdbc.username""); String password = props.getProperty(""jdbc.password""); return DriverManager.getConnection(url username password); } } When you use -jar -classpath is ignored. From the java command tool docs: When you use this option the JAR file is the source of all user classes and other user class path settings are ignored. Either use -classpath without -jar and specify the type containing the main method explicitly or make your jar file manifest reference the derby jar file.  When you invoke the java command with the -jar and -classpath parameters the -classpath parameter is ignored. See the documentation for the Java launcher. You can either use: Unix/Linux: java -classpath derbyclient.jar:TestDB.jar TestDB Windows: java -classpath derbyclient.jar;TestDB.jar TestDB or make a manifest which adds derbyclient.jar to the classpath. sorry.. but I'm now having this !! Exception in thread ""main"" java.lang.NoClassDefFoundError: TestDB well.. sorry again simonn it's working.. I made a little mistake !!"
61,A,"Java: JDBC ResultSet not populated with all query results I'm working on getting our system's java beans to be able to use the SQL IN clause when running queries down through the database but am running into a perplexing problem. I am build the SQL query for the PreparedStatement in the following generic pattern: select [column names] from [table name] where [a column name] IN (? ?  ? ... ?) The ... represents any number of ?'s depending on the number of values the user is deciding to build into the IN clause. I run a loop to get these into the query string. From here I use the PreparedStatement's setString( idx String ) method and iterate through the list of values and run from index 1 - # of values. The PreparedStatement runs the query via the executeQuery() method and the returned ResultSet seems to be incorrect. In a specific instance using 4 values when I take the query in the PreparedStatement to SQL and replace each ? with the exact values in ' ' I get 3 results (as one of the values is purposely not in the DB). The ResultSet on the other hand only has 1 row in its set and that row always corresponds to the first ? parameter in the IN clause. I even tried faking the IN clause with ([column name] = ? OR [column name] = ? ... OR column name] = ?) but the same issue occurs here too. Any ideas what is going on here? Connecting to an Oracle database by the way. Logs: 2010-02-10 11:16:28505 DEBUG basic.BasicCursor - Preparing statement SELECT MERCHANT_ID M_NAME M_AUTHEN M_ADMIN_AUTHEN M_CONTACT_ADDR M_PAYMENT_ADDR M_HAS_MPROXY M_DISABLED M_FREETEXT TXN_ID M_TAX_NAME M_TAX_RATE MERCHANT_PARENT_ID MERCHANT_ROOT_ID RESERVED_1 RESERVED_2 RESERVED_3 RESERVED_4 EMAIL LOGICAL_TYPE CHANNEL_MASK FROM MERCHANT0 WHERE MERCHANT_ID IN (? ? ? ?) ORDER BY MERCHANT_ID 2010-02-10 11:16:28505 DEBUG basic.BasicCursor - Adding string to slot 1: 6172222222 2010-02-10 11:16:28505 DEBUG basic.BasicCursor - Adding string to slot 2: 6177740603 2010-02-10 11:16:28505 DEBUG basic.BasicCursor - Adding string to slot 3: 6177740602 2010-02-10 11:16:28505 DEBUG basic.BasicCursor - Adding string to slot 4: 6172441111 2010-02-10 11:16:28512 DEBUG basic.BasicCursor - scanCursor() calling... checking for next row. Current row is : 0 2010-02-10 11:16:28512 DEBUG basic.BasicCursor - scanCursor() called hit 2010-02-10 11:16:28512 DEBUG basic.BasicCursor - scanCursor() got object 6172222222 2010-02-10 11:16:28512 DEBUG basic.BasicCursor - scanCursor() calling... checking for next row. Current row is : 1 2010-02-10 11:16:28512 DEBUG basic.BasicCursor - scanCursor() called not hit 2010-02-10 11:16:28505 DEBUG basic.BasicCursor - The size of variables list = 4 EDIT: Found the issues with the PreparedStatement. I'll leave it as an exercise to those curious to figure it out. It's visible in the log statements above. Unfortunately now my problem has cascaded to some annoying proprietary code we have that limits the rows from the now expected ResultSet to displaying only 1 record anyway. sigh What happens if you fix the query in your code (make the string the same as what you executed to get 3 results) rather than replacing the `?` s? The problem is the space in front of the values 2-4 right? double-check the complete constructed query and compare that it is actually what you expect double-check that you actually call setString() with different values for the index and the String and that you're not using the same value over and over again double-check that you're not calling next() on your ResultSet more than once per loop iteration. edit: System.out.println() and check (and possibly post) the following: The complete SQL query string toString() of the newly created PreparedStatement both parameters of each setString() call and toString() of the PreparedStatement each time you call setString() the return value of next() each time you call it check check  and check @Rich: I said double-check you need at least 6 ""check""s here. ;-) I left out the checks for the countless times I've done this before you posted. So here. Check check check check check check check check check check check check check check check check check check. by the way toString() of PreparedStatement isn't overridden and appears to just inherit from Object meaning all it gives is a memory address. @Rich: I know that you probably checked most of that before that's why I said double-check: check even 'though you are **sure** that that's not the problem. And regarding the `toString()` I was suspecting that it prints the default stuff. But even that helps to find out if you're using the same `PreparedStatement` everywhere.  So you used this construct? private static final String SQL = ""SELECT * FROM MERCHANT0 WHERE MERCHANT_ID IN (%s)""; public List<Merchant> list(List<Long> ids) { StringBuilder placeHolders = new StringBuilder(); for (int i = 0; i < ids.size(); i++) { placeHolders.append(""?""); if (i + 1 < ids.size()) { placeHolders.append(""""); } } String sql = String.format(SQL placeHolders.toString()); // ... try { // ... preparedStatement = connection.prepareStatement(SQL); for (int i = 0; i < ids.size(); i++) { preparedStatement.setLong(i + 1 ids.get(i)); } resultSet = preparedStatement.executeQuery(); while (resultSet.next()) { Long id = resultSet.getLong(""MERCHANT_ID""); System.out.println(id); // Should print all of the `ids`. } // ... Apart from the fact that Oracle has a limitation of about 1000 values inside the IN clause this is supposed to work. Essentially yes. I noticed I inserted a space after each ? whereas you didn't but after recompiling with that in the code the results are no different. Then either there's a bug in the JDBC driver or you overlooked something. Are you using latest JDBC driver version?"
62,A,"JDBC-appender Log4j [RESOLVED] Re-thinked IDEA! So I've been thinking over the weekend and couldn't let this one go. I've decided to re-try the idea of getting log4j to work. I've been doing some coding and think I got it to work. Except I do not really understand how to insert into the logger. I've created an JDBC-appender and the SQL looks like this:  <layout class=""org.apache.log4j.PatternLayout""> <param name=""ConversionPattern"" value=""INSERT INTO audit (timestamp user operation source resourceRange additionalInfo) VALUES ('%d{yyyy-MM-dd H:mm:sSSS}''%m' '%m' '%m' '%m' '%m')"" /> </layout> Is this correct? All values has the VARCHAR datatype. But the real question for me is how do I log this in the Java-code? Can't really understand what values to insert to get the correct values to insert the database.  logger.log(?); EDIT Problem RESOLVED. Apparently I've mixed up how the original JDBC-appender for Log4j works. It is not doable to get several inserts to the database through a log message. Instead I used ""jdbcplus"" made by a German1. Thank you all for the help./Edit Replacing log4j logging in a big application by a self-developed logging framework? Boy what did you do wrong this time? This logging is ""simply"" for auditing what types of functionality used. Still use log4j in other types of logging. So it's not that big might been a bad explanation :). Fix typo in the title. Just to make sure; you can not use log4j and use JDBCAppender or DBAppender? ( http://stackoverflow.com/questions/1364322/log-to-a-database-using-log4j ) EDIT: My suggestion would be to have a named appender that logs to the database. By turning off additivity (log4j.additivity.database=false) it won't ""push"" log statements to the root logger keeping that data out of the default log file/console. The named logger can be retrieved by Logger.getLogger(""database""); from different places in the source code. EDIT 2: I think it would've been better to let the original question stand and ask a new one but here goes. :) The appender must contain information about the database connection either as a reference to the connection: <param name=""connector"" value=""name.of.existing.ConnectionHandler"" /> or by specifying url username and password. Setting up the logger the name is the important bit for getting the logger. By setting the loggers additivity to fale you stop it from adding this logging to the default logger specified by <root> in the config: <appender name=""JDBC"" class=""org.apache.log4j.jdbcplus.JDBCAppender""> [...] </appender> <logger name=""myLogger"" additivity=""false""> <appender-ref ref=""JDBC""/> [...] </logger> Now you can reference the logger in java code with: private static final Logger usageLog = Logger.getLog(""myLogger""); from any java file. Then you use the logger like always with usageLog.debug(""Debug message""); or something. EDIT 3: See PatternLayout javaDoc for which flags to use in the ConversionPattern. Edited to answer your edited question @Fredrik_jakob why is it not an option? Perhaps there is a misconception about using JDBCAppender/DBAppender/log4j which we can clear up for you. It is likely far simpler to re-use a proven library and code than attempting to roll your own. I followed your idea and posted a new question about Log4j. I kind of managed to create a Java-logging-thingy but I can't say I'm satisfied so I'm prepared to do this idea instead and try counter its problems. Thank you! I got the jdgbc-appender to work and it inserts information to the database. the problem is that I cant figure out how to get different information into the database? because I have %m as VALUES in the SQL-query all columns will be filled with 'abc' if I do this: logger.log(""abc"");. Unfortunately because of various reasons that is not an option but I'm aware of that it is normally a great option. Thanks for your answer!  LogBack offers logging to a database out of the box."
63,A,"is there any limit on the number of rows one can select in MySQL? There are 1652487 rows in my table in MYSQL. I want to copy all the values corresponding to one field into a file. I wrote a java program in netbeans using jdbc driver for this. I'm unable to do this at one go. Is there a way out ? < Is there any limit on the number of rows one can select > [ EDIT ] my code : action performed when a button is pressed :  private void jButton2ActionPerformed(java.awt.event.ActionEvent evt) { // TODO add your handling code here: try { File fo=new File(""D:\\dmoz_externalpages.txt""); FileWriter fro=new FileWriter(fo); BufferedWriter bro=new BufferedWriter(fro); Connection con=null; Class.forName(""com.mysql.jdbc.Driver"").newInstance(); con=DriverManager.getConnection(""jdbc:mysql://localhost:3306/dmozphp""""root""""""); PreparedStatement ps=con.prepareStatement(""select externalpage from content_description""); ResultSet rs=ps.executeQuery(); while(rs.next()) { bro.write(rs.getString(1)); bro.newLine(); bro.flush(); } } catch(Exception e) { System.out.println(e); } } when i run this  i get the following exception : Exception in thread ""AWT-EventQueue-0"" java.lang.OutOfMemoryError: Java heap space What does your code look like and what is the problem? There is no MySQL limit on this. My strong guess is you're limited by the memory on the client side. I've been able to export entire tables with >25mil rows without problems before. If you want to export the data the quickest way use SELECT INTO OUTFILE or give Maatkit a go. i found that i could do this when i just execute that command < but it displayed them in 82625 pages each having about 20 rows >  which meant that manually copying this data into a file would be time consuming.. So  i wrote a program to automate this writing to a file. and when i executed it  i got the exception i mentioned above < in my EDIT > Thanks  i got just what i needed .( SELECT INTO OUTFILE option )"
64,A,How do I use JDBC's data source? I've tried researching how to use the DataSource method of connecting to a database but never could find out how. I know that a DataSource is first configured and registered to JNDI in an application that is separate from the user application and all the user application will do is retrieve it using JNDI. What I don't understand is where the DataSource is configured. Is it automatically registered when I turn on MySQL do I need to download another application to register it or do I make a new class that will do that for me? You usually have a Java EE app server like Glassfish WebLogic JBOSS Tomcat or Jetty have a JNDI provider that you should be using for the lookup. Here's how you do it with Oracle. Here's how you do it with MySQL. The JDK 6 javadocs say that a basic DataSource can supply a connection if your driver has such an implementation. I would recommend looking at the Connector-J docs to see if you can do it without JNDI lookup services. do you really need an EE app to register it? You need a JNDI naming service to do the lookup. so... you examples of the naming service are stuff like servers?
65,A,"when to roll back a jdbc transaction I have been reading an interesting statement in http://download.oracle.com/javase/tutorial/jdbc/basics/transactions.html The interesting part is: ""Catching an SQLException tells you that something is wrong but it does not tell you what was or was not committed. Since you cannot count on the fact that nothing was committed calling the method rollback is the only way to be sure."" Is that really so? If I don't call commit but I got an SQLException then can I not count on nothing being committed? What if my program exits without calling commit or rollback? I thought the transaction will be rolled back automatically for me but this statement takes away my certainty. @GyozoGasper : Actually it has happened with me. I am using jdbc with postgresql. Basically any modern database you would consider using in its default isolation level would not exhibit this behavior. But ultimately what happens down there is out of JDBC's control and for all it knows you might be using Informix 5 or a 1988 Sybase with an adaper layer under the hood. Hence from the high level language API specification point of view they have to make the statement that nothing is guaranteed if you don't use it properly. Basically it's saying that it would not be considered a bug at the JDBC level if the result of abandoning a connection with neither a commit nor a rollback results in some executed statements showing up in the database level. (Usually for most databases we'd consider that bug at the database level but again JDBC is a high level API.)  you can test it out to see what happens. I would recommend using Spring for this stuff. It will automatically handle your tx rollbacks for you. Even if a test shows that everything is ok I can still be wrong and can still do it the wrong way. A positive test only means that in a real life situation it is working fine but does not mean that in all situation it will work fine. Under certain conditions it can still fail. What if I have to change my db to some other engine? Will my program tested with Oracle work on a MySQL ISAM table as well? I trust my code only when it is theoretically right and tested. A code that is tested only is more likely to fail later."
66,A,"Mysql read data immediately after writing? I am using a MySQL DB and a Java JDBC client to access it. I have a Table that contains session information. Each session is associated with a SessionToken. This token is a Base64 encoded String of a Hash of some of the session values. It should be unique. And is defined as varchar(50) in the db. When I try to lookup a session by its token I query the database using an sql statement like this: select SessionId ClientIP PersonId LastAccessTime SessionCreateTime from InkaSession where SessionToken like 'exK/Xw0imW/qOtN39uw5bddeeMg=' I have a UnitTest that tests this functionality and it consistently fails because the query does not return any Session even tough I have just written the session to the DB. My Unit test does the following: Create Connection via DriverManager.getConnection Add a session via Sql Insert query close the connection create Connection via DriverManager.getConnection look for the session via sql select unit test fails because nothing found When I step through this UnitTest with the debugger and copy past the select sql that is about to be sent to the db into a mysql command line it works fine and I get the session row back. I also tried to retrive an older session from the db by asking for an older SessionToken. This works fine as well. It only fails if I ask for the SessionToken immediately after I inserted it. All connections are on AutoCommit. Nevertheless I tried to set the Transaction Level to ""Read Uncommited"". This did not work either. Has anyone any further suggestions? Solved: The two token strings where not identical. One of them had a couple of Zero bytes at the end. (Due to the encrypting and decrypting and padding...) The two strings where visually identical but MySQL and Java both said they where not. (And they where right as usual)  This is typically caused by the connection not being committed between insert and select. Did you basically do the following? statement.executeUpdate(""INSERT INTO session (...) VALUES (...)""); connection.commit(); resultSet = statement.executeQuery(""SELECT ... FROM session WHERE ...""); Edit I tried the following SSCCE on MySQL 5.1.30 with Connector/J 5.1.7: public static void main(String[] args) throws Exception { Class.forName(""com.mysql.jdbc.Driver""); Connection connection = null; Statement statement = null; ResultSet resultSet = null; try { connection = DriverManager.getConnection(""jdbc:mysql://localhost/javabase"" ""root"" null); statement = connection.createStatement(); statement.executeUpdate(""INSERT INTO foo (foo) VALUES ('foo')""); resultSet = statement.executeQuery(""SELECT id FROM foo WHERE foo = 'foo'""); if (resultSet.next()) { System.out.println(resultSet.getLong(""id"")); } else { System.out.println(""Not inserted?""); } } finally { SQLUtil.close(connection statement resultSet); } } Works flawlessly. Maybe an issue with your JDBC driver. Try upgrading. Yep thats basically what I have done. Except that the commit() will fail because of an SQL Syntax error. Which I find strange. I close() the connection instead. Anyway in Autocommit mode this should not be necessary should it? Also the data stays in the db so I don't think there is any unfinished transaction. Is there any way to be sure? Also tried to disable AutoCommit and explicitly commit. This works (i.e. the commit() no longer raises an exception) but does not solve the problem. Already have vrsion 5.1.10 of Connector."
67,A,"JDBC Thin Driver: Invalid Packet Lenght [sic] I have encountered a strange ""Invalid Packet Lenght"" (that is how the error is spelled) error when I run an automated bulk test on some of my Java code and I hope that someone has either encountered this error before or can point me in the right direction. I do not encounter this error when testing my code via JUnit unit tests or from the GUI. I only encounter this error on my automated bulk test. A little bit about my bulk test: for some inputs my code will run for a long time (that's to be expected) but in order to speed up the results to a more reasonable time frame I'm creating a new thread to run each individual test so that I can stop the test after some given maximum elapsed time. Note that both the test and the actual code need to connect to the same database instance to load data. The actual code uses a single connection to read from the database (it is not multi-threaded). I'm still trying to figure out the best way for the test to connect to the database (hence this question). My first thought was that I am doing something unfriendly in the way I close my test thread to quit the run early. I'm calling the deprecated threadObject.stop(); method since my actual code is not multi-threaded an there is no ""friendly"" way to kill the thread built in. After a few (~2-3) stopped threads my JDBC connection throws one ""Invalid Packet Lenght"" error followed by ""Socket closed"" exceptions for the rest of the tests. I've tried all of these with the same results: Reuse the same connection that the actual code uses Create one new connection an reuse that same second connection for all tests Close and recreate the test connection every time I stop() a long-running test Create a new connection for each test (this works until I max out my connection count) I have determined that of the two connections ""test"" and ""actual"" the ""test"" connection is the one that throws the exception. Configuration: Eclipse 3.4 Java Compliance 1.6 ojdbc14_g.jar JDBC Driver Oracle 9 DB What am I doing wrong? Is there a different way I should handle my ""test"" connection? Do I need to re-architect my ""actual"" connection just to run a bulk test? What causes the ""Invalid Packet Lenght"" error? This is actually the oldest appearance of ""lenght"" in a post _title_ in StackOverflow. It will always stay as such because it would be incorrect to fix it. I don't really understand what are you trying to accomplish with your bulk test so I will offer some general advice regarding threading and Connections that I know of: Perhaps one of your threads is leaving a connection in invalid state. What happens to connection when thread is stopped? In general terms you should have a place where you wait() for an InterruptedException instead of stopping the thread in mid-operation. A Connection should be closed in a finally block regardless of whether an exception occurred or not. If you want a timeout for a JDBC operation use Statement.setQueryTimeout(). Consider using a connection pool like C3P0. It's really easy to set up in code have a look at this in particular. It will take care of most of the connection set-up/tear-down and provide your code with valid ready-to-use connection. Consider using Java's own java.util.concurrent package rather than rolling out your own execution strategy. Have a look at Executors and ExecutorService classes - they provide means of executing a task in separate thread and setting up a timeout. Hope some of this helps. I'm going to accept this answer because #1 is pretty much the issue in a nutshell. Calling Thread.stop() left my connection in an inconsistent state. Unfortunately I can't think of a great way to test unthreaded code in a threaded manner so I'm going to have to refactor to build in a timeout."
68,A,"Tips on Speeding up JDBC writes? I am writing a program that does a lot of writes to a Postgres database. In a typical scenario I would be writing say 100000 rows to a table that's well normalized (three foreign integer keys the combination of which is the primary key and the index of the table). I am using PreparedStatements and executeBatch() yet I can only manage to push in say 100k rows in about 70 seconds on my laptop when the embedded database we're replacing (which has the same foreign key constraints and indices) does it in 10. I am new at JDBC and I don't expect it to beat a custom embedded DB but I was hoping it to be only 2-3x slower not 7x. Anything obvious that I maybe missing? does the order of the writes matter? (i.e. say if it's not the order of the index?). Things to look at to squeeze out a bit more speed? Update: I should have added that all of the above updates were done in a single transaction and that I tried dropping the indices w/o much impact (maybe a 20% improvement at best w/o counting the re-addition of indices). What is the embedded database you are replacing it with? try disabling indexes and reenabling them after the insert. also wrap the whole process in a transaction  You can obviously try to change the size of your batch to find the best size for your configuration but I doubt that you will gain a factor 3. You could also try to tune your database structure. You might have better performances when using a single field as a primary key than using a composed PK. Depending on the level of integrity you need you might save quite some time by deactivating integrity checks on your DB. You might also change the database you are using. MySQL is supposed to be pretty good for high speed simple inserts ... and I know there is a fork of MySQL around that tries to cut functionalities to get very high performances on highly concurrent access. Good luck !  Check if your connection is set to autoCommit. If autoCommit is true then if you have 100 items in the batch when you call executeBatch it will issue 100 individual commits. That can be a lot slower than calling executingBatch() followed by a single explicit commit(). I would avoid the temptation to drop indexes or foreign keys during the insert. It puts the table in an unusable state while your load is running since nobody can query the table while the indexes are gone. Plus it seems harmless enough but what do you do when you try to re-enable the constraint and it fails because something you didn't expect to happen has happened? An RDBMS has integrity constraints for a reason and disabling them even ""for a little while"" is dangerous.  This is an issue that I have had to deal with often on my current project. For our application insert speed is a critical bottleneck. However we have discovered for the vast majority of database users the select speed as their chief bottleneck so you will find that there are more resources dealing with that issue. So here are a few solutions that we have come up with: First all solutions involve using the postgres COPY command. Using COPY to import data into postgres is by far the quickest method available. However the JDBC driver by default does not currently support COPY accross the network socket. So if you want to use it you will need to do one of two workarounds: A JDBC driver patched to support COPY such as this one. If the data you are inserting and the database are on the same physical machine you can write the data out to a file on the filesystem and then use the COPY command to import the data in bulk. Other options for increasing speed are using JNI to hit the postgres api so you can talk over the unix socket removing indexes and the pg_bulkload project. However in the end if you don't implement COPY you will always find performance disappointing. Thanks for the tips; by 'using JNI' do you mean using JNI to access COPY or for issuing regular SQL commands? i.e. do you expect JNI->C->SQL to be faster than JDBC for the same number of INSERTs? I have not benchmarked it in postgres but I believe that it is the strategy that the oracle driver takes. There is a performance overhead when going through tcp versus the unix socket. So in the end a custom solution for performance may not be worth the effort so I look at it as a last resort."
69,A,How to override TOMCAT Oracle ojdbc14 driver in the application? The TOMCAT server is using an Oracle 9G ojdbc14 driver to its jndi connections in the /common/lib folder. My web application uses Maven + Spring and I'm getting the dataSource using Spring jndi features. I'm trying to bypass TOMCAT old ojdbc14 driver with a newer one (ojdbc14 10.2.0.4.0). I've tried putting the jars in the WEB-INF/lib folder as a project dependency but it doesn't work the application keeps using the old oracle driver that is in the TOMCAT folder. I'm trying to bypass the TOMCAT oracle driver because I cannot update it to the newest version because there are lots of other projects using it. Does anyone have a clue? This won't work Tomcat won't use the JDBC driver of your webapp to create a connection pool. In other words you'll have to either replace the version in common/lib or to use a standalone connection pool at the application level.
70,A,"JDBC: default holdability of a ResultSet is there a defined default for the holdability of ResultSet if Connection.setHoldability() is never invoked or a holdability is never specified during the creation of a statement? I could not find anything in the JDBC api docs - so is it implementation specific? Thank you. The default holdability is implementation specific but you can get the default holdability by calling the getResultSetHoldability method on the DatabaseMetaData for the Connection. You can also see section 6.1.9 in the Oracle / Sun JDBC docs for details: http://download.oracle.com/javase/1.4.2/docs/guide/jdbc/getstart/resultset.html Right on Riaan.  ""The default holdability property of a ResultSet object is implementation defined. The default holdability of ResultSet objects returned by the underlying data source can be determined using the APIs provided by JDBC 3.0."" Please see this link for reference."
71,A,"ResultSet method ""last"" is this an optimal way? I have this java code which does this ResulSet rs = stmt.executeQuery(); while (rs.next()) { .... //do regular processing if (rs.last()) { //do last record processing } } Personally I would declare the variables that are retrieved from the query outside the loop and then do the ""last record processing"" after the loop. ResulSet rs = stmt.executeQuery(); long primaryKey; while (rs.next()) { primaryKey = rs.getLong(1); .... //do regular processing } // Do last record processing. System.out.println(""last primary key = "" + primaryKey);  You should use: isLast() instead. Be warned not all the JDCB drivers support this feature. Obviously you have to check it with your installation. Most major DB work fine. The fixed code should look like this. if( rs.isLast() ) { // do last record processing }  No: rs.last() will actually send the cursor to the last row in the ResultSet which is definitely not what you want to do. You would only ever process at most 2 rows (first and last) from the result set."
72,A,assigning a specific record in a ResultSet to a variable I want to retrieve a set of records from a database do a rs.next() and then assign the result of this to a variable to pass to a method that will use this record in the same way that I would without assigning it to a variable and passing it to a method is there any way to do this? I'm using JAVA (1.5) Thank you for all the answers I do not want to pass the whole resultSet to a method only the current row but as I understand it is not possible to do this I think I understood you now. :) No it’s not possible to do it that way. The ResultSet changes its internal state on each call to ResultSet.next() so storing the reference to it won’t get you anywhere. You have to extract the data you want into some custom object and store that. CustomData cd = new CustomData(); cd.setString1(rs.getString(1)); cd.setInt1(rs.getInt(2)); ... You can then store the cd variable and get on with processing your ResultSet.  You want to assign the result of rs.next() to a variable? I'm afraid you cannot do that. You can have a reference from that rs and process it in other method ( the same way you would without assign it to a var ) When you pass the rs as an argument to a method that is exactly what you're doing already. while( rs.next() ) { list.add( createFrom( rs ) ); } ... public Object createFrom( ResultSet rs ) { // Here rs is a copy of the reference in the while above. } Did I get right your question? Yes it is the same! So you cannot pass the result set without the possibility the other is calling next() I realise now that my question was not correct as rs.next() returns a boolean value not the current row. If the resultSet is passed to a method is it passed with the current row being the same as the row in the calling method? Technically you can it returns a bool :P  No that is not supported out of the box but maybe the following idea may help you: ResultSetMetaData meta = rs.getMetaData(); while (rs.next()) { Map<StringObject> row = new HashMap<StringObject>(); for (int i = 1; i <= meta.getColumnCount(); ++i) { row.put(meta.getColumnName(i) rs.getObject(i)); } processRow(row); } The problem is you need to cast the values from the row-map in processRow() and it will not work for all type/driver combinations (BLOBs ...).  I often find List> data structure very useful while working with result sets.
73,A,"DB2 database using unicode I have a problem with DB2 databases that should store unicode characters. The connection is established using JDBC. What do I have to do if I would like to insert a unicode string into the database? INSERT INTO my_table(id string_field) VALUES(1 N'my unicode string'); or INSERT INTO my_table(id string_field) VALUES(1 'my unicode string'); I don't know if I have to use the N-prefix or not. For most of the databases out there it works pretty well when using it but I am not quite sure about DB2. I also have the problem that I do not have a DB2 database at hand where I could test these statements. :-( Thanks a lot! FYI: the Express-C edition might be useful to you for testing. Thanks for this information! Enclosing the unicode string constant within N'' worked through JDBC application for DB2 DB.  The documentation on constants (as of DB2 9.7) says this about graphic strings: A graphic string constant specifies a varying-length graphic string consisting of a sequence of double-byte characters that starts and ends with a single-byte apostrophe (') and that is preceded by a single-byte G or N. The characters between the apostrophes must represent an even number of bytes and the length of the graphic string must not exceed 16 336 bytes. Interesting didn't knew that but that smells like a ""workaround"" for inserting unicode data in a database/table which is not configured to use unicode. I would rather just configure the db to use unicode instead of messing SQL statements. To be honest I don't know how this is going to play out via the JDBC driver and Java Strings expressions that are implicitly UTF-16. That support looks geared more towards code that uses octet characters. It wouldn't be my first choice but I'm not going to jump to conclusions either - there may be some legacy schema that the poster needs to work with. There is one concern about this statement that I have: When using this notation I can only use UCS-2 right? What about UTF-8 encoded strings? The reason why I have posted this question is that I am working on a system that should support different types of databases. Currently I am trying to find out if it would harm any database if every string literal is prefixed with an N.  I have never heard of this in context of DB2. Google learns me that this is more MS SQL Server specific. In DB2 and every other decent RDBMS you only need to ensure that the database is using the UTF-8 charset. You normally specify that in the CREATE statement. Here's the DB2 variant: CREATE DATABASE my_db USING CODESET UTF-8; That should be it in the DB2 side. You don't need to change the standard SQL statements for that. You also don't need to worry about Java as it internally already uses Unicode."
74,A,"Long type with SQLite and Zentus Jdbc driver I am using SQLite in Java code through Zentus. I need to map Java long primitive type in my database. For that I tried to create tables with the following statement: CREATE TABLE MY TABLE (.... LONG time ...). Insertion into the database through Java with Zentus works perfectly but when retrieving the data always through Java and Zentus the LONG value is shrinked to 32 bit value. I tried to query the database directly with SQlite and it works thus I guess the problem is the JDBC driver. Did some of you already experienced such issues and how did you solved it ? SQLite has 4 primitive types: Text Integer Real Blob Some key words are converted to these types unknown keywords default to Text. The ""Integer"" type is a bit particular in that SQLite will only keep the minimum size necessary to record the largest number. If your largest number is smaller than 2^31 it will be recorded on 32 bits. I don't know that it shrinks back if it is expanded to 64 bits then all the values above 2^31 are removed or if it just stays the same. It will definitely shrink back if the database is vacuumed. I can suggest keeping a dummy record with a 64 bit value try and see if JDBC behaves after that. Thanks for the answer. This means I can create my table with Type ""LONGFOOBAR"" for example and the result will be the same ? As mentioned I think there is no problem at SQLite level but in the JDBC driver I am using. Do you use SQLite from Java code ? No I use SQLite but with different code so that's why I can't give you a 100% enlightened answer. As for type ""LONGFOOBAR"" it would default internally to ""TEXT but so would ""LONG"". Only if the type has the letters ""INT"" the column be declared as INTEGER. Inserting integers will make a TEXT column keep them as ... well I don't know what. But for your connector prefer declaring as INTEGER. Thanks again. I read SQLite typing info and I know now thanks to you how it works and I would modify my types to have INTEGER columns for numerical values. Even knowing and modifying that I still have my issue and think that there is a problem in the Zentus JDBC driver I am using. I'am investigating ... That is as far as I can help. Sorry."
75,A,"How to connect to Access Database via Data Sources (ODBC) using a mapped network drive? I need to make a connection to an Access Database. In order to do that I created a System DSN. I had success making that connection using local files. However the database must be at a remote server and I mapped a network drive so I can access the database files. Mapping the drive and using the remote files an error arises when I try to access the database: ""[Microsoft][ODBC Microsoft Access Driver] Cannot start your application. The workgroup information file is missing or opened exclusively by another user. "" If I use the database files in the local machine the error doesn't appear. But accessing the file from the network drive the exception is throw. Do you know why it happens? Thanks.... Are you specifying the right workgroup file? Is it accessible via the path you've provided? Are you specifying a workgroup file? I tried also using UNC paths but the error continues. The file is not being in use... I have full control of it. I believe that is some Authentication issue because the application is running under the SYSTEM user context... I have been reading some posts with the same problem but using IIS context and the problem is related to Kerberos configurations. Using a connection string or creating and DSN connection the error is the same.... :( Yes I am... :( Are you using a mapped drive or UNC paths? Doesn't the second paragraph say that he's using a mapped drive? Have you tried accessing the files using the UNC path (i.e. what the drive is mapped to)? Is the workgroup file being explicitly called somewhere such as in the shortcut you're using? Or is it possible the default workgroup file on the PC is set to a mapped drive that is no longer defined? I found the problem. The application invoking my code is a windows service that is running under the SYSTEM account. This account doesn't have permissions to access files outside the server. A system administrator will create a special account and I need to use it as the service log on account.  This will sound odd but add your AD domain to your Trusted Sites in your internet options. So if your computer is a member of ad.mycompany.com use that. I had something similar happen with two people trying to open up the same MDB on a network drive. I just tried without success... :("
76,A,Safe to convert Java.sql.date to Java.util.date by up casting? Java.sql.date extends java.util.date so is it save to convert between the two by casting a java.sql.date as a java.util.date? Or is there some other way to convert them? You don't necessarily need to cast you can just treat a SQL Date as if it was a util Date: java.sql.Date sqlDate = new java.sql.Date(whenever); java.util.Date utilDate = sqlDate; Compiles and runs just fine.  Yes you can just upcast it. The java.sql.Date is in fact nothing less or more than a representation of the SQL Date type which has only year month and day filled.  Though you can easily obtain the java.sql.Date from java.util.Date you need to be careful that java.sql.Date has only Date information minus time details. If needed you need to look at java.sql.Time or java.sql.Timestamp.
77,A,Connecting to Informix 3.30 with SimbaServer middleware I have a client that I'm trying to do some data migration out of an old route-accounting system for. The system has an Informix 3.30 database with SimbaServer middleware sitting on top of it. From what I gather ODBC and JDBC support was not added to Informix until version 5.x so that's out. Also I have been unable to find the SimbaClient ODBC or JDBC driver to connect to the SimbaServer middleware. I'm trying to get connected to this database with JasperETL from JasperSoft. Anybody have any thoughts on how I might be able to accomplish this? Are you serious about meaning Informix 3.30? As in 3.30.14? As in a product that was last released in 1986? It creeps out of the woodwork every so often but hasn't done so for quite a few years now. This is the pre-SQL product with the database dictionary (catalog) in a file 'database.dbd' and the data in files such as 'table.dat' and the indexes in files such as 'table.idx'? If so then there are extremely unlikely to be any ODBC or JDBC drivers to connect to it. However you should contact me directly - see my profile page - and we can discuss what options you have. Suffice to say I still have access to the source code and I know how to get data out of the system. I'll need to know a lot more about your environment and whether you have any of the Informix 3.30 software still running etc. (I have Informix 3.30 running on MacOS X 10.6.2 compiled in 64-bit mode if that reassures you at all. But I thought it was just a joke.) If you don't have files such as the '.dbd' and so on then you (probably) don't have Informix 3.30. We'll also need to discuss what you do have. I presume you've found Simba and their discussion of their DSI (Data Store Interface) technology. Is the 3.30 database still in active use or is this a one-time data transfer? Your options will be somewhat different depending on which applies. If it is a one-time transfer then we can do the work with a tool kit I assembled over the period 1986-1996 (approximately); the result will be ASCII files in a format that can be loaded into the DBMS of your choice. If it is an ongoing operation - the Informix 3.30 database is still in production use despite being somewhat beyond the end of its normal life - then you should be looking at the services Simba provides and a custom DSII (DSI Implementation). Informix 3.30 comes with the A.L.L (Application Language Library) that you can use to access the data from C (and hence C++) code. You'd be using that to get to the data in the DSII module that you implement - or find someone else has already implemented. It looks like we've gotten it sorted out to use the connectivity offered by Simba on top of the Informix database.
78,A,"Hibernate 3: unable to query PostgreSQL database I am setting up a project using Hibernate 3.3.1 GA and PostgreSQL 8.3. I've just created a database the first table added one row there and now configuring Hibernate. However even the simplest query: Criteria criteria = session.createCriteria(Place.class); List result = criteria.list(); could not be executed (empty list is returned though there is one record in the database). I looked to the PostgreSQL logs and could see: 2008-09-17 22:52:59 CEST LOG: connection received: host=192.168.175.1 port=2670 2008-09-17 22:52:59 CEST LOG: connection authorized: user=... database=... 2008-09-17 22:53:00 CEST LOG: execute : SHOW TRANSACTION ISOLATION LEVEL 2008-09-17 22:53:02 CEST LOG: could not receive data from client: Connection reset by peer 2008-09-17 22:53:02 CEST LOG: unexpected EOF on client connection 2008-09-17 22:53:02 CEST LOG: disconnection: session time: 0:00:03.011 user=... database=... host=192.168.175.1 port=2670 I wrote a simple program using plain JDBC to fetch the same data and it worked. PostgreSQL logs in this case look like this (for comparison): 2008-09-17 22:52:24 CEST LOG: connection received: host=192.168.175.1 port=2668 2008-09-17 22:52:24 CEST LOG: connection authorized: user=... database=... 2008-09-17 22:52:25 CEST LOG: execute : SELECT * from PLACE 2008-09-17 22:52:25 CEST LOG: disconnection: session time: 0:00:00.456 user=... database=... host=192.168.175.1 port=2668 Hibernate debug log does not indicate any errors. If I take the query listed in the logs:  15:17:01859 DEBUG org.hibernate.loader.entity.EntityLoader: Static select for entity com.example.data.Place: select place0_.ID as ID0_0_ place0_.NAME as NAME0_0_ place0_.LATITUDE as LATITUDE0_0_ place0_.LONGITUDE as LONGITUDE0_0_ from PLACE place0_ where place0_.ID=? and execute it agains the database in the psql it works (this means that Hibernate has generated a proper SQL). Below is the Hibernate configuration: <hibernate-configuration> <session-factory> <property name=""hibernate.connection.url"">jdbc:postgresql://192.168.175.128:5433/...</property> <property name=""hibernate.connection.driver_class"">org.postgresql.Driver</property> <property name=""hibernate.connection.username"">...</property> <property name=""hibernate.connection.password"">...</property> <property name=""dialect"">org.hibernate.dialect.PostgreSQLDialect</property> <property name=""hibernate.show_sql"">true</property> <property name=""hibernate.use_outer_join"">true</property> <mapping resource=""com/example/data/Place.hbm.xml""/> </session-factory> </hibernate-configuration> ...and the mapping file: <hibernate-mapping package=""com.example.data""> <class name=""com.example.data.Place"" table=""PLACE""> <id column=""ID"" name=""id"" type=""java.lang.Integer""> <generator class=""native""/> </id> <property column=""NAME"" name=""name"" not-null=""true"" type=""java.lang.String""> <meta attribute=""use-in-tostring"">true</meta> </property> <property column=""LATITUDE"" name=""latitude"" not-null=""true"" type=""java.lang.Float""> <meta attribute=""use-in-tostring"">true</meta> </property> <property column=""LONGITUDE"" name=""longitude"" not-null=""true"" type=""java.lang.Float""> <meta attribute=""use-in-tostring"">true</meta> </property> </class> </hibernate-mapping> Googling for ""unexpected EOF"" log entry was not friutful. Any ideas community? It looks like the issue is probably in your configuration. Can you post it without the username/password? After applying debugger to the Hibernate code it is fixed! It is not visible in the question's text but the problem is that Place passed to the createCriteria() method is from another package not com/example/data specified in the configuration XML files. Hibernate invokes Class.isAssignableFrom() and if false is returned it exits silently breaking the connection. I'll open a ticket for Hibernate developers on this matter."
79,A,"SQL syntax error with Derby and Circumflex ORM I'm trying to use Circumflex ORM (as suggested on StackOverflow - here here and here) to connect to a local (embedded) Apache Derby database over JDBC from a Scala project (built with simple build tool). I've followed the instructions carefully but am having some interesting problems. Here's the driver and URL components of the cx.properties file: orm.connection.driver=org.apache.derby.jdbc.EmbeddedDriver orm.connection.url=jdbc:derby:derbyDB (These map to the ""instance creation of the reflected driver and create Connection"" model with raw JDBC or the equivalents in persistence.xml - Circumflex is using a short and sweet properties file because you know it's not XML and that's a good thing.) The dependencies I've added in my sbt project file that are directly relevant are:  ""ru.circumflex"" % ""circumflex-orm"" % ""1.0"" ""org.apache.derby"" % ""derby"" % ""10.6.1.0"" I have created a short example model which defines a simplified version of the table that the documentation describes: import java.sql.DriverManager import ru.circumflex.orm._ class Country extends Record[Country] { val code = ""code"" VARCHAR(2) val name = ""name"" TEXT } object Country extends Table[Country] This seems to compile okay and I can instantiate the Country object (using a Scala 2.8.0 RC5 shell invoked with sbt console) and create an object ActiveRecord-style and then save it like this: val c = new Country c.code := ""US"" c.name := ""United States of America"" c.save According to the documentation this should run a validation over the object and then insert it into the database. I get the following exception: java.sql.SQLSyntaxErrorException: Syntax error: Encountered ""public"" at line 1 column 13. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source) at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source) at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source) at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement20.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement30... I found this thread where someone is having a similar problem with 'Encountered ""public""' and Apache Derby but the replies don't seem to suggest a useful way of going forward. Any ideas what might be causing this? Sorry if this isn't a particularly interesting question - I'm still finding my way in Javaland after being spoiled by the pure out-of-the-box simplicity of Rails' ActiveRecord implementation. I'm open to being told that Circumflex ORM sucks and choosing something else. I've been using Circumflex ORM with Hypersonic. It only supports Postgres MySql and Oracle by default. You need to extend ru.circumflex.orm.Dialect to supply the correct SQL syntax for Derby and declare this class in your cx.properties file. ie orm.dialect=com.magmanics.circumflex.orm.dialect.HsqldbDialect Here is my Hypersonic dialect file it might help you if you are just looking for a simple in memory database... import ru.circumflex.orm._ /** * @author James Baxter <j.w.baxter(at)gmail> * @since 19-Jun-2010 */ class HsqldbDialect extends Dialect { override def timestampType = ""TIMESTAMP"" override def createSchema(schema: Schema) = ""CREATE SCHEMA "" + schema.name + "" AUTHORIZATION DBA"" override def createTable(table: Table[_]) = ""CREATE TABLE "" + table.qualifiedName + "" ("" + table.fields.map(_.toSql).mkString("" "") + "")"" override def columnDefinition(field: Field[_]): String = { var result = field.name + "" "" + field.sqlType field.default match { case Some(expr) => result += "" "" + expr case _ => } if (!field.nullable_? && !result.contains(""PRIMARY KEY"")) result += "" NOT NULL"" return result } override def primaryKeyExpression(record: Record[_]) = ""IDENTITY PRIMARY KEY"" override def initializeRelation(relation: Relation[_]) = {} override def lastIdExpression(node: RelationNode[_]) = node.alias + ""."" + node.relation.primaryKey.name + "" = IDENTITY()"" } Would you mind us borrowing this into Circumflex 1.1? =) Go for it. Thanks for creating such a great framework its nice to be able to contribute back to it :)  It's possible you need to tell Circumflex to use Derby syntax explicitly instead of expecting it to be inferred from the JDBC driver classname and URL. e.g. in Hibernate you need to set the dialect... And it seems you can work around it by setting the ""orm.defaultSchema"" property to something other than ""public"" which seems to be a reserved word in Derby. And final edit most of the time people don't bother to use an explicit schema name when creating tables and they just get the default but Circumflex seems to always add it so for Derby you should be able to use ""APP"" as the schema name or create your own schema beforehand and use its name. Thanks Alex for this and for the help on IRC. The `Dialect` trait also has `supportsSchema_?()` method -- you can override it in your dialect and Circumflex will forget about explicit schema. Forever."
80,A,"tomcat db2-jdbc datasource configure i'm trying to configure a datasource of an db2 database in tomcat (using eclipse as IDE) but i cant solve the problem Tomcat trow me the following exception: org.apache.tomcat.dbcp.dbcp.SQLNestedException: Cannot load JDBC driver class 'com.ibm.db2.jcc.DB2Driver' at org.apache.tomcat.dbcp.dbcp.BasicDataSource.createDataSource(BasicDataSource.java:1136) at org.apache.tomcat.dbcp.dbcp.BasicDataSource.getConnection(BasicDataSource.java:880) at com.azurian.lce.usuarios.ConnectionManager.getConnection(ConnectionManager.java:65) at com.azurian.lce.usuarios.db2.UsuarioDAOImpl.autenticar(UsuarioDAOImpl.java:101) at com.azurian.lce.usuarios.UsuarioServiceImpl.autenticar(UsuarioServiceImpl.java:31) at com.azurian.lce.web.admin.actions.LoginAction.execute(LoginAction.java:49) at org.apache.struts.action.RequestProcessor.processActionPerform(RequestProcessor.java:484) at org.apache.struts.action.RequestProcessor.process(RequestProcessor.java:274) at org.apache.struts.action.ActionServlet.process(ActionServlet.java:1482) at org.apache.struts.action.ActionServlet.doPost(ActionServlet.java:525) at javax.servlet.http.HttpServlet.service(HttpServlet.java:637) at javax.servlet.http.HttpServlet.service(HttpServlet.java:717) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:298) at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:852) at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:588) at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489) at java.lang.Thread.run(Unknown Source) Caused by: java.lang.ClassNotFoundException: com.ibm.db2.jcc.DB2Driver at java.net.URLClassLoader$1.run(Unknown Source) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at java.lang.ClassLoader.loadClassInternal(Unknown Source) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Unknown Source) at org.apache.tomcat.dbcp.dbcp.BasicDataSource.createDataSource(BasicDataSource.java:1130) ... 23 more where i put the jdbc files of DB2? i try in every place (in the libraries of the project in the lib folder of the tomcat install directory in the WEB-INF/lib folder of the Dinamic Web Project in the tomcat classpath in the eclipse ""tomcat server"" configuration an so far) Regards ps.: I'm using: DB2 9.7 Tomcat 6 JDK 1.6 Eclipse Galileo You need to put it outside Eclipse in the /lib folder of Tomcat or in any of the paths as specified in the shared.loader or common.loader properties in /conf/catalina.properties. If it doesn't solve the problem then it is not the right Tomcat instance you think Eclipse is using. If everything went well (dropping the JDBC driver in server's library) then you should see it show up in the [ProjectName]/Java Resources (src)/Libraries/[ServerName] listing in the Project Explorer. thanks you are right :)"
81,A,Refreshing data in a java.sql.ResultSet I have a java.sql.ResultSet object containg data from a query that was run. How do I refresh the data in the ResultSet to reflect the current data in the database? Thanks! The best answer is that you need to close the ResultSet and issue the query again to get a new ResultSet. The slightly longer answer is that it's possible to set the transaction isolation level to let you see other transaction updates while iterating but that's not probably what you mean. +1 for hitting the point about the transaction isolation. That will be a very big driver of what is possible here.
82,A,"Associating Postgres Connections with Java code I'm trying to track down leaky connections. (In particular I'm noticing connections staying open past the closure of the last DataSource using C3P0 for connection pooling. I suspect a bug but want to ensure I'm not just being stupid first.) Is there a good way to associate open connections from the Postgres view  postgres=# select * from pg_stat_activity; datid | datname | procpid | usesysid | usename | current_query | waiting | xact_start | query_start | backend_start | client_addr | client_port 11564 | postgres | 95709 | 10 | postgres | select * from pg_stat_activity; | f | 2010-07-25 14:20:24.97529-07 | 2010-07-25 14:20:24.97529-07 | 2010-07-25 14:20:19.066576-07 | | -1 (1 row) with the location they were opened in the Java / JDBC code? (Or perhaps some unique string etc) Seems like this ought to be a useful thing to have! Postgresql 9 supports an application_name setting that can be read in this way but there is nothing similar in the server for versions before that. With JBoss we had a connection guard system that would throw and catch an exception internally whenever a connection was opened in order to capture the backtrace and then store that along with the connection. Then if the connection wasn't closed at the end of the transaction that backtrace was logged with a warning. It's possible I guess to adapt that strategy into a generic datasource-decorator layer and periodically sweep the tracked connections for ones that haven't been used in 10 minutes (or sth greater than the expected lifetime) but not closed. Guess I'll just have to wait! Well Postgres 9 is out and this solution works brilliantly.  This is impossible to check from in the PostgreSQL side. It knows nothing about the Java code. The caller has just to pass-in the username password and DB name. Nothing more. It's however possible to check it from in the Java side. Tools like log4jdbc may be helpful in this. I understand that it's not **required** from the Postgres side but what I'm hoping for is that there is some unused connection parameter or even just a ""name"" parameter somewhere that is handy for using for things like this. Your best bet is to use (if possible) a login role which is used only by your application. You still wouldn't be able to track individual connections but at least you'll see if your application is the problem."
83,A,"adding new users to the database upon registering on a website using JSP and JDBC I am now working on a web application project for the first time the application includes registering and adding users to the database now i wrote a java class called DatabaseManager that implements all database operations and wrote the JSP page responsible for adding new users if the registration is successful I need to add the user's details to the database so I was wondering do I need to create a instance of DatabaseManager and load the database driver and initialise the connection everytime a new user registers or is there a more efficient way to do it? thanks Loading the database driver can be done just only once during webapp's startup. You can use a ServletContextListener for this. You could do the driver loading task in the constructor of the DatabaseManager class and instantiate it during contextInitialized() and store the instance in the application scope so that it is available to all servlets in the context (noted should be that JSP is in essence the wrong place for business logic). Opening (and closing!) the Connection should really be done directly in the very same method block as you're executing the SQL query. It should certainly not be ""cached"" as a static/instance variable somewhere in your application logic. To improve connecting performance the normal practice is to configure a connection pool to obtain the connections from. In every decent servletcontainer you can do this in flavor of a JNDI datasource. Long story short you can find a JSP/Servlet example utilizing the above techniques in this article which is by coincidence also using an use case of ""register user"". thanks BalusC having followed your tutorial and your explanation here helped me connect all the stuff that I read about servlets. You're welcome."
84,A,Can RowSets be used with PreparedStatements? I have just found RowSets for database querying with JDBC. They are stateless and cacheable they look to be superior to ResultSets. Can PreparedStatements be used with them though? PreparedStatements are a performance booster for querying very large databases and not something I would want to give up (before something is said this is not premature optimization we have a proven speed need!!). I need the fastest query return to a set here caching is secondary. The default implementation of RowSet use prepared statements internally. I would have been surprised if that was not the case. See the code JDBCRowSetImpl code your self http://www.google.com/codesearch/p?hl=en#TTY8xLpnKOE/src/share/classes/com/sun/rowset/JdbcRowSetImpl.java&q=JDBCRowSetImpl you will want to look at prepare() method. Note: Poking around the code is why i love Open Source :D Thanks. clears up some issues but the link you have is for java7 unreleased code. I do not think there is to be any changes to the JDBC package. Just to let you know.
85,A,Portable JDBC vs SQLite on Android I am using SQLite in a project used by an android application. Currently I am using the SQLite implementation provided in android.database.sqlite. I want to make a desktop application which uses the same codebase. So I need to separate all the shared behaviour into a separate portable project/jar. My problem is I'm currently making heavy use of android.database.sqlite. If possible I do not want to re-write every database access call to be compatible with JDBC or whatever I will have to use without using the android provided SQLite. To solve this problem with minimal impact on the existing code. I intent to write a SQLite interface (compatible with android.database.sqlite) which the shared code will use... on android it will be implemented trivially by android.database.sqlite and on the desktop it will be implemented by somehow mutilating SQLite through JDBC to match android.database.sqlite. This is proving difficult as I often supply Object[] arrays to be bound to prepared statements which JDBC requires strict typing and I am not familiar with JDBC at all. Is there any other way to use SQLite in Java which is similar to android.database.sqlite or any other approaches which may save me the effort (and inevitable debugging) associated with re-writing many database access points? Disclamer: I have never until now tried using JDBC. Simplified question: What is the best way to use SQLite in java? JDBC other? I think creating a wrapper would be a good idea but may involve a lot of effort in terms of development as well as testing. Maybe you can start a project on google and get a few more people involved. On a side note I believe there's already such a project on google code called sqldroid Thanks for the link it looks promising. I was thinking of making the reverse interface 'JDBC looking like SQLite' as opposed to the other which did not seem to be workable.  Here is what I would do: Create an interface for database operations. It would include methods to add modify delete records and save/commit if required. This interface could be extended as and when required. Create an implementation for JDBC/SQLite. Have a configuration entry to select appropriate implementation preferably at build time. What this means in your case is: Create the interface. Create an implementation which internally makes use of SQLite. Create an implementation which internally makes use of some JDBC implementation. This way your application will become abstracted from the underlying database which is being used. This will improve the portability. I'm not sure if you mean a domain specific interface. If so then the problem would be I would need to re-do the bindings for each project (thinking ahead). If not then that again seems like a waste in that JDBC is _supposed_ to be just that... why re-create the wheel. But I do think your philosophy is right +1. @Akusete He's talking about the DAO pattern  You can create something like a DataMapper for your domain so extending the BCE pattern to BCDE. The role of a data mapper is to abstract from the underlying database technology so increasing later reuse
86,A,Is there a NoSQL / key-value store abstraction library like there is JDBC is for databases? I have used many SQL abstraction libraries such as ODBC JDBC and ActiveRecord. What are the abstraction options in the NoSQL / key-value store world? I am mostly asking this so that if I choose a key-value store then I can use an abstraction library and not be locked in which I think is important given the number of key value stores around. No. Right now NoSql databases are very disparate therefore they cannot be wrapped under a standard interface while remaining non trivial.  We have such an abstraction in InfoGrid called the Store interface. It is very simplistic but was created exactly for that purpose: a common API that allows InfoGrid to talk to different key-value store implementations without requiring changes on the higher levels. Some links: Store summary Store interface IterableStore interface -- same but iterable: some key-value stores can be iterated over easily some can't Which key-value datastores do you currently have drivers for?  Even if the NOSQL databases are very different from each other they can be divided into meaningful groups see this blog post. A new project aiming at defining abstractions on top of different NOSQL databases is Gremlin see InfoQ: Gremlin a Language for Working with Graphs. Starting out from the graph database end of the NOSQL spectrum the project has since moved on to document stores creating an Object Document Model with implementations planned for MongoDB and CouchDB see here and here. Are there any projects which actually have drivers available for them? There's drivers for RDF+SAIL Neo4j and MongoDB AFAIK. You'd better ask on the Gremlin mailing list I can't keep track of everything happening over there at the moment!  Gremlin runs on top of Tinkerpop Blueprints. Yesterday has been released the new version of Gremlin (0.5) with the support of new storages such as OrientDB a new open source document-graph dbms.
87,A,Dao methods manipulating single/multiple objects and closing resources The usual advice is to close JDBC ressources once they're no longer needed. This could be done in a catch and finally. However what if a DAO method only manipulates one domain object and an operation requires several of these to be retrieved/created in one go? Would getting a statement and then closing it repeatedly be an issue in terms of performance? If so should a separate method be made to handle several objects in one go or should closing be delayed in some way? You could add an extra transaction layer on top of the DAO layer and call setAutoCommit(false) on the Connection in the beginning of the transaction/session let the DAO methods use the same Connection instance and then commit() the Connection when the transaction/session is finished/closed. You'll however need to change the DAO methods to take a Connection as an extra argument or to store it ThreadLocal (which however needs to be done very carefully since threads may be pooled). Creating statements shouldn't be that expensive as long as you're consistently using PreparedStatement which are usually been compiled and cached in DB side.  i think it would be no difference if the application is Dao based or not. Those resources should be closed. If you work without any framework (spring hibernate etc) java.sql.Connection should be put back to the pool if there was a pool. ResultSet and Statement objects should be closed after the execution of the query. Depends on your architecture those resource management codes could be placed in Dao classes or other classes. for example there are classes focusing on building up and executing sql queries. The resource mgmt codes could be in those classes. If you work with some frameworks the framework will usually do the resource mgmt for you.
88,A,Have Oracle automatically roll back abandoned sessions? Is there any way to guarantee that an application won't fail to release row locks in Oracle? If I make sure to put commit statements in finally blocks that handles the case of unexpected errors but what if the app process just suddenly dies before it commits (or someone kicks the power cord / lan cable out). Is there a way to have Oracle automatically roll back idle sessions after X amount of time? Or roll back when I somehow detects that the connection was lost? From the experiments I've done if I terminate an app process before it commits the rows locks stay forever until I log into the database and manually kill the session. Thanks. COMMIT inside finally is probably the last thing you should do since you should (almost) never commit anything that threw an exception. Oops you're right.  Try setting SQLNET.EXPIRE_TIME in your sqlnet.ora. SQLNET.EXPIRE_TIME=10 From the documentation: Purpose To specify a time interval in minutes to send a check to verify that client/server connections are active. According to the linked documentation it just checks whether the client is still alive after the EXPIRE_TIME. If the client responds every time the query can take as long as it needs. http://richard-e-hall.blogspot.com/2007/09/sqlnet-expiretime.html I'm not a DBA myself but I did not find any other disadvantages than the ones listed. Give it a try to find out if it works for you. Disadvantage is that if you have hundreds of connections (which was frequent in the days before app servers) this 'check' could use up significant resources if the expire_time was low. This sounds like the answer. Are there any major disadvantages to using this feature? Why doesn't Oracle do this by default? The docs list a few disadvantages but I don't see how any of them justify disabling this feature by default. What if your queries take 2 hours to complete? :)  I am not a DBA so I am sure you can find a better solution... but there are certain deadlock conditions that seem to happen that will not roll back on our own. My last DBA had a process that would run every minute and kill anything that had been running more than 10 minutes. That's a very bad idea. If your database gets very large at all you could very easily end up killing the gather stats job for instance (or worse a backup). Well you have to be careful what you allow it to kill this was stuff started by an app server (which gather stats or backup would not be)
89,A,"Moving a database with pg_dump and psql -U postgres db_name < ... results in ""ERROR: relation ""table_name"" does not exist"" I moved my PostgresQL database from one hard drive to another using pg_dump -U postgres db_name > db_name.dump and then psql -U postgres db_name < db_name.dump I created the database db_name the same way in both instances. In the new database when I run my Java program with a JPA query (or a JDBC query) I get this error: ""ERROR: relation ""table1"" does not exist"" The query is: select count(0) from table1 I know I've got a connection because if I change the password in the connection parameters I get an error. For some reason in the new PostgresQL instance it thinks that table1 does not exist in the imported schema. If I change the query to select count(0) from myschema.table1 Then it complains about permissions: ""ERROR: permission denied for schema myschema"" Why would the permissions be different? The table table1 exists in myschema because I can see it in the pgAdmin tool. All the rows were imported into the new PostgresQL instance. When I do a query from Java the combination of pg_dump and psql created a problem. What do I need to do to solve this issue? Thanks in advance. I was able to solve it by changing the database privileges to public CONNECT and the schema privileges for public and postgres = USAGE and CREATE. My backup scripts apparently didn't preserve the privileges at least not when moving from 8.3 to 8.4.  Are you moving to the same version of PostgreSQL? There might be issues if you make a dump with pg_dump 8.3 and try to restore it in Postgresql 8.4. Anyway assuming that it is the same version try the following: Dump all global objects such as users and groups (don't know if they were missing in your dump): pg_dumpall -g -U postgres > globals.sql Dump schema of database: pg_dump -Fp -s -v -f db-schema.sql -U postgres dbname Dump contents of database: pg_dump -Fc -v -f full.dump -U postgres dbname Now restore. psql -f globals.sql psql -f schema.sql dbname pg_restore -a -d dbname -Fc full.dump That is my $0.02. Hope it helps. I am moving from 8.3 to 8.4. I'll change my backup scripts to use your more comprehensive approach. Thanks for the response. I would add verbose flag(-v) to pg_restore for large database. `pg_restore -a -v -d dbname -Fc full.dump`"
90,A,"How to use a JDBC driver from an arbitrary location I need to test a JDBC connection to a database. The java code to do that should be as simple as: DriverManager.getConnection(""jdbc connection URL"" ""username"" ""password""); The driver manager will lookup the appropriate the driver for the given connection URL. However I need to be able to load the JDBC driver (jar) at runtime. I.e I don't have the JDBC driver on the classpath of the java application that runs the snippet of code above. So I can load the driver using this code for example: URLClassLoader classLoader = new URLClassLoader(new URL[]{""jar URL""} this.getClass().getClassLoader()); Driver driver = (Driver) Class.forName(""jdbc driver class name"" true classLoader).newInstance(); But then the driver manager still won't pick it up as I can't tell it which classloader to use. I tried setting the current thread's context classloader and it still doesn't work. Anyone has any idea on the best way to achieve that? Is there a good reason why you don't have the driver on the classpath? Yes. The application can connect to many databases. Moreover I can't bundle all the drivers for licensing reasons. What I want to achieve is a simple dialog for the user to load the jar while the application is running. There I was thinking like a server-side developer again... :) The problem is DriverManager performs ""tasks using the immediate caller's class loader instance"". See Guideline 6-3 of Secure Coding Guidelines for the Java Programming Language version 2.0. The system class loader is in no way special in this case. Just for kicks I wrote a blog entry on this subject a while back. My solution though more complicated then Nick Sayer's solution is more complete and even works from untrusted code. Also note URLClassLoader.newInstance is preferred over new URLClassLoader.  From the article Pick your JDBC driver at runtime; I am just going to post the code here for reference. The idea is to trick the driver manager into thinking that the driver was loaded from the system classloader. To do this we use this class: public class DelegatingDriver implements Driver { private final Driver driver; public DelegatingDriver(Driver driver) { if (driver == null) { throw new IllegalArgumentException(""Driver must not be null.""); } this.driver = driver; } public Connection connect(String url Properties info) throws SQLException { return driver.connect(url info); } public boolean acceptsURL(String url) throws SQLException { return driver.acceptsURL(url); } public DriverPropertyInfo[] getPropertyInfo(String url Properties info) throws SQLException { return driver.getPropertyInfo(url info); } public int getMajorVersion() { return driver.getMajorVersion(); } public int getMinorVersion() { return driver.getMinorVersion(); } public boolean jdbcCompliant() { return driver.jdbcCompliant(); } } This way the driver you register is of type DelegatingDriver which is loaded with the system classloader. You now just have to load the driver you really want to use using whatever classloader you want. For example: URLClassLoader classLoader = new URLClassLoader(new URL[]{""path to my jdbc driver jar""} this.getClass().getClassLoader()); Driver driver = (Driver) Class.forName(""org.postgresql.Driver"" true classLoader).newInstance(); DriverManager.registerDriver(new DelegatingDriver(driver)); // register using the Delegating Driver DriverManager.getDriver(""jdbc:postgresql://host/db""); // checks that the driver is found"
91,A,"java web app run in netbeans - SQLException: No suitable driver I am trying to run an application developed on another machine where it was perfectly running so it should have something to do with the configurations on the machine I am trying to run it on now. I'm using netbeans 6.9 tomcat 6.0.26 and maven. When I try to run it it gives me the following error: Sep 19 2010 12:51:02 AM org.hibernate.cfg.SettingsFactory buildSettings WARNING: Could not obtain connection metadata org.apache.tomcat.dbcp.dbcp.SQLNestedException: Cannot create JDBC driver of class 'com.mysql.jdbc.Driver' for connect URL 'http://maven.apache.org' at org.apache.tomcat.dbcp.dbcp.BasicDataSource.createDataSource(BasicDataSource.java:1150) at org.apache.tomcat.dbcp.dbcp.BasicDataSource.getConnection(BasicDataSource.java:880) at org.hibernate.connection.DatasourceConnectionProvider.getConnection(DatasourceConnectionProvider.java:69) at org.hibernate.cfg.SettingsFactory.buildSettings(SettingsFactory.java:84) at org.hibernate.cfg.Configuration.buildSettings(Configuration.java:2073) at org.hibernate.cfg.Configuration.buildSessionFactory(Configuration.java:1298) at org.hibernate.cfg.AnnotationConfiguration.buildSessionFactory(AnnotationConfiguration.java:859) at AppConfiguration.loadConfig(AppConfiguration.java:164) at Listener.contextInitialized(Listener.java:40) at Org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:3972) at org.apache.catalina.core.StandardContext.start(StandardContext.java:4467) at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:791) at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:771) at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:546) at org.apache.catalina.startup.HostConfig.deployDescriptor(HostConfig.java:637) at org.apache.catalina.startup.HostConfig.deployDescriptors(HostConfig.java:563) at org.apache.catalina.startup.HostConfig.deployApps(HostConfig.java:498) at org.apache.catalina.startup.HostConfig.start(HostConfig.java:1277) at org.apache.catalina.startup.HostConfig.lifecycleEvent(HostConfig.java:321) at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:119) at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1053) at org.apache.catalina.core.StandardHost.start(StandardHost.java:785) at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1045) at org.apache.catalina.core.StandardEngine.start(StandardEngine.java:443) at org.apache.catalina.core.StandardService.start(StandardService.java:519) at org.apache.catalina.core.StandardServer.start(StandardServer.java:710) at org.apache.catalina.startup.Catalina.start(Catalina.java:581) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:289) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:414) Caused by: java.sql.SQLException: No suitable driver at java.sql.DriverManager.getDriver(DriverManager.java:264) at org.apache.tomcat.dbcp.dbcp.BasicDataSource.createDataSource(BasicDataSource.java:1143) ... 32 more I should mention that: 1 I have mysql-connector-java-5.1.13-bin.jar in Apache Tomcat 6.0.26\lib and in my pom.xml I have:  <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd""> <modelVersion>4.0.0</modelVersion> <url>http://maven.apache.org</url> and <dependency> <groupId>mysql</groupId> <artifactId>mysql-connector-java</artifactId> <version>5.1.13</version> <scope>provided</scope> </dependency> 2 I have the jar in my local maven repository. 3 Netbeans seems to come now with 'embedded maven version 3.0' which is a beta version. So I've configured it to use as External Maven Home: C:\Program Files\apache-maven-2.2.1. Running mvn --version gives the correct version so maven 2.2.1 seems to be properly installed on my system. But for some reason whenever I run the app I also get this: WARNING: You are running embedded Maven builds some build may fail due to incompatibilities with latest Maven release. To set Maven instance to use for building click here. The build does not fail but the link that the above warning points me to gets me to the same window where I've already configured 'External Maven Home' as mentioned above. 4 Adding DriverManager.registerDriver(new com.mysql.jdbc.Driver()); (as seen in another post here on stackoverflow) before anything related to the database did not help. 5 The same code was running on another machine. I would appreciate any ideas as to why I am getting the jdbc driver error. And please keep in mind that the application was running on another machine. context.xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Context path=""/app/test""> <Resource auth=""Container"" defaultAutoCommit=""false"" description=""dbcp"" driverClassName=""com.mysql.jdbc.Driver"" initialSize=""1"" maxActive=""10"" maxIdle=""5"" maxWait=""1000"" minIdle=""10"" name=""jdbc/Test"" password=""${database.password}"" poolPreparedStatements=""true"" type=""javax.sql.DataSource"" url=""${database.url}"" username=""${database.username}""/> <Realm className=""org.apache.catalina.realm.DataSourceRealm"" dataSourceName=""jdbc/Test"" localDataSource=""true"" roleNameCol=""role"" userCredCol=""pass"" userNameCol=""user"" userRoleTable=""roles"" userTable=""users""/> <Valve className=""org.apache.catalina.valves.AccessLogValve"" fileDateFormat=""yyyy-MM-dd"" pattern=""combined"" prefix=""test-access"" resolveHosts=""false"" rotatable=""true"" suffix="".log""/> </Context> where database.url is jdbc:mysql://127.0.0.1:3306/test?autoReconnect=true hibernate.cfg.xml: <?xml version=""1.0"" encoding=""UTF-8""?> <!DOCTYPE hibernate-configuration PUBLIC ""-//Hibernate/Hibernate Configuration DTD 3.0//EN"" ""http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd""> <hibernate-configuration> <session-factory> <property name=""connection.datasource"">java:/comp/env/jdbc/Test</property> <property name=""hibernate.dialect"">org.hibernate.dialect.MySQLDialect</property> <property name=""cache.provider_class"">org.hibernate.cache.NoCacheProvider</property> <property name=""cache.use_query_cache"">false</property> <property name=""cache.use_minimal_puts"">false</property> <property name=""max_fetch_depth"">3</property> <property name=""show_sql"">true</property> <property name=""format_sql"">true</property> <property name=""generate_statistics"">true</property> <property name=""hbm2ddl.auto"">validate</property> <property name=""current_session_context_class"">thread</property> <mapping class=""Test.Users""/> <mapping class=""Test.Roles""/> <!-- entity bean defs --> </session-factory> </hibernate-configuration> This looks like you have told Hibernate to use a container provided DataSource which in turn cannot locate the JDBC-driver. If so the problem is that code loaded by the container class loader cannot see code provided in your WAR . You must add the driver jar to the extension folder of the container. I have mysql-connector-java-5.1.13-bin.jar in Apache Tomcat 6.0.26\lib if this is what you are referring to. The problem is that DriverManager cannot locate a driver for the JDBC string provided. You should have that covered by point 4 - does the class load? The problem is that the JDBC string *is* wrong (it is currently `http://maven.apache.org`). It is not a classloading problem. It seems that the problem was what Pascal Thivent pointed out but I appreciate your trying to help me. Thank you. @Pascal ah. Thought that this message came _after_ the driver had been chosen not before. How did the MySQL driver get chosen then? @Thorbjørn The driver class name is part of the datasource definition. Anyway errors are really very poorly reported. Ok didn't know that about the data source. Agree on the poor reporting.  Common causes for java.sql.SQLException: No suitable driver are the URL is wrong followed by the driver isn't loaded. And indeed the following line clearly indicates something wrong. Cannot create JDBC driver of class 'com.mysql.jdbc.Driver' for connect URL 'http://maven.apache.org' The JDBC connection string can't be http://maven.apache.org. Check your build something IS wrong (it looks like some unexpected filtering is occurring). But you're not giving enough details for a more detailed answer. I've seen the two possible causes in other posts but I don't know how to rule out any of them. Please tell me what more details I should give. The only place where I have that URL is in my pom.xml this is why I have posted the relevant lines of code from it. @mihaela Where is the jdbc connection string declared? Do you have a `context.xml`? In a `hibernate.cfg.xml`? What's the content (before/ after the build)? I have now provided these details as an Edit to my original post. @mihaela Where is `database.url` defined? Did you check the ""filtered"" version of your `context.xml` (after the build)? It looks like it gets the value of `${project.url}`. Indeed that was the problem. I've now seen that after build my context.xml does not have database.password database.user and database.url replaced with the correct values which are found in a .properties file that I am using for switching between development and production configurations. These files seem not to be interpreted and project.url ends up being replaced by http://maven.apache.org. Thank you so much for your time."
92,A,"Hibernate Communications Link Failure in Hibernate Based Java Servlet application powered by MySQL Let me describe my question - I have a Java application - Hibernate as the DB interfacing layer over MySQL. I get the communications link failure error in my application. The occurence of this error is a very specific case. I get this error  When I leave mysql server unattended for more than approximately 6 hours (i.e. when there are no queries issued to MySQL for more than approximately 6 hours). I am pasting a top 'exception' level description below and adding a pastebin link for a detailed stacktrace description. javax.persistence.PersistenceException: org.hibernate.exception.JDBCConnectionException: Cannot open connection - Caused by: org.hibernate.exception.JDBCConnectionException: Cannot open connection - Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure - The last packet successfully received from the server was 1274868181212 milliseconds ago. The last packet sent successfully to the server was 0 milliseconds ago. - Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure - The last packet successfully received from the server was 1274868181212 milliseconds ago. The last packet sent successfully to the server was 0 milliseconds ago. - Caused by: java.net.ConnectException: Connection refused: connect the link to the pastebin for further investigation - http://pastebin.com/4KujAmgD What I understand from these exception statements is that MySQL is refusing to take in any connections after a period of idle/nil activity. I have been reading up a bit about this via google search and came to know that one of the possible ways to overcome this is to set values for c3p0 properties as c3p0 comes bundled with Hibernate. Specifically I read from here http://www.mchange.com/projects/c3p0/index.html that setting two properties idleConnectionTestPeriod and preferredTestQuery will solve this for me. But these values dont seem to have had an effect. Is this the correct approach to fixing this? If not what is the right way to get over this? The following are related Communications Link Failure questions at stackoverflow.com but I've not found a satisfactory answer in their answers. http://stackoverflow.com/questions/2121829/java-db-communications-link-failure http://stackoverflow.com/questions/298988/how-to-handle-communication-link-failure Note 1 - i dont get this error when I am using my application continuosly. Note 2 - I use JPA with Hibernate and hence my hibernate.dialectetc hibernate properties reside within the persistence.xml in the META-INF folder (does that prevent the c3p0 properties from working?) edit - the c3p0 parameters I tried out are in the comments Please update your question to include the full Hibernate c3p0 configuration. Here they are - select 1; 2 I had issue before. It looks like MySQL server times out your connection. Timeout is 28800 by default which is 8 hours. Please refer to this link for more details. http://shengchien.blogspot.com/2009/10/hibernate-c3p0-and-mysql.html Hope it is useful to you. let me try this out and I shall let you know Thanks Sheng this works! thanks!  Here is an account of how I finally solved this - http://vatsalad.wordpress.com/2010/09/28/hibernate-communications-link-error-c3p0mysql-and-broken-pipe-error/ i have changed accordingly hope so it works.  Even I faced this error I got it solved only after enabling autoReconnect=true in c3p0 config <property name=""hibernate.connection.url"">jdbc:mysql://localhost:3306/ex_app?autoReconnect=true</property>"
93,A,"connecting to MySQL using JDBC in eclipse So I want to create a JDBC connection to MySQL server that is installed on my pc here are the steps I installed MySQL with the username and password ""root"" downloaded mysql-connector-java and from theere I coped the JAR ""mysql-connector-java-5.1.12-bin"" to ""C:\Sun\SDK\jdk\jre\lib\ext"" I then added it as an external JAR in my project in eclipse now in my class I have this code: public void initialiseDatabase() { try { // Load the Driver class. Class.forName(""com.mysql.jdbc.Driver""); //Create the connection using the static getConnection method databaseConnection = DriverManager.getConnection (databaseUrl+databaseName dbUserName dbPassword); sqlStatement = databaseConnection.createStatement(); } catch (SQLException e) {e.printStackTrace();} catch (Exception e) {e.printStackTrace();} } (this is going to be psuedocode cause I am reading from a properties file and don't want the one helping me reading through long lines of code from main to figure out all the variables) where databaseUrl = ""127.0.0.1"" dbUserName = ""root"" dbPassword = ""root"" databaseName = ""MySQL"" //this one I am not sure of do I need to create it or is it set inherenrly? now the MySQL server is up and running but when I call the method initialiseDatabase the following exception is thrown: ""java.sql.SQLException: No suitable driver found for rootroot at java.sql.DriverManager.getConnection(Unknown Source) at java.sql.DriverManager.getConnection(Unknown Source) at Proxy$JDBCConnection.initialiseDatabase(Proxy.java:721)"" when line 721 is: sqlStatement = databaseConnection.createStatement(); Where have I gone wrong? thanks Your database url should look like this: jdbc:mysql://host:port/database Example if you use localhost the default port and a database named cachedb your url would be: jdbc:mysql://localhost/cachedb what about the databasename? databaseName = ""MySQL"" //this one I am not sure of do I need to create it or is it set inherenrtly? You need to create the database on the MySQL server that you want to access. Yeah I needed to start MYSQL command client and type there create database cachedb Ok if i want to execute this query in the database cachedb: CREATE TABLE Cache( String URL PRIMARY KEY NOT NULL Response TEXT LastModified VARCHAR(40)) how do I tell it to create it on the database cachedb? because I am getting the error ""No database selected"" and I found out that I need to type this in MySQL client to select my database: mysql> use cachedb"
94,A,Performance differences between jconn2 and jconn3 I have tested jconn2 and jconn3 on same application which is connected to sybase ase15.03 server . But I encountered the really big performance differences between these two api. For example I have run a simple select query on a big table (which contains 7051328 rows 20 cols). JCONN2 returns the resultset in 5.3sec but jconn3 returns the resultset for same query in 11.6sec.(I tested more complex queries too and still have differences. ) So actually I couldn't find any clear explanation about this differences. Could anyone explain this? Note: I tested both jonn2 and jconn3 on same application and same sybase server. Thanks and regards. jconn is the Sybase JDBC driver right? yes skaffman. and thx for jdbc tag. i missed it. It is caused by difference in implementation of DateTime type of columns in resultsets data of Jconn2 and Jconn3. One of them is fast and incorrect and another is slow but correct. The incorrectness is related to taking/not taking into account local timezones. Have you tested difference with samples of data without any DateTime columns ?. actuallyno. I will test this case soon and write the result to here. hanks. In later version of Jconn Sybase used Calendar object which is slow. Well it will be great to see your result. Appreciate
95,A,Service bus Vs direct database access What are the advantages of using an ESB instead of directly accessing a database (via Hibernate or JDBC). I know you can reuse the messages on the bus but could you not just package up your database access code into a jar and distribute it to the different systems that need access (Assuming all the accessing systems support Java)? ESB adds a layer of abstraction to your service/database layer. You could distribute jars to all the applications that require service access but what if the services change its contract or business logic needs to be updated. It would be really difficult for all the applications to change their jar files. Especially in an Enterprise setting changing just a jar file would require a big CHANGE CONTROL PROCESS which ultimately adds on to the cost of change. If you are using an ESB adding removing or routing services could be done at a single point. Hence the cost per change would be minimal. That said there are several disadvantages such as ESB can become a single point of failure in your application. Therefore it is required that you have sufficient redundancies in place to counter any failure. Taking this a bit further the behaviours on the transports can vary as well. Some consuming systems may require guarenteed delivery while others can completely miss or skip based on a variety of factors. Enrichment (or obfuscation) of select data is also a common requirement when publishing/distributing data. Neither of these things need to be a concern of either the database or the consuming applications and can reasonably be a function of the BUS fabric.
96,A,"database connectivity? How to establish SQL 2005 database connectivity with Java application. Actually I don't know how to set path for JDBC. Any help would be great. while trying to run .jar file it showing an error msg ""Failed to load main class manifest attribute from c:\program files\sqljdbc_2.0.1803.100_enu\sqljdbc_2.0\enu\sqljdbc4.jar "" how i can proceed further???? The JDBC driver is **not** an executable JAR it is a library that you should use from your code. You thus need make it available on the classpath when running your code. For the programming details check the example bundled with the driver you downloaded and that I mentioned in my answer. Download the jdbc driver from http://www.microsoft.com/sqlserver/2005/en/us/java-database-connectivity.aspx. You can either download the Windows or Unix version. It does not really matter which one you use. If you chosed the Windows version run the downloaded exe file; this will create a directory called Microsoft SQL Server 2005 JDBC Driver in the directory you downloaded the file to. Add the file Microsoft SQL Server 2005 JDBC Driver\sqljdbc_1.2\enu\sqljdbc.jar to your classpath (either using the -cp option of java or if you are using an application server by putting it in the appropriate directory). Set your connection. Basically the information required for this are: the driver class name: com.microsoft.sqlserver.jdbc.SQLServerDriver the connection url: jdbc:sqlserver://[serverName[\instanceName][:portNumber]][;property=value[;property=value]] Check Connecting to SQL Server with the JDBC Driver for more details and/or the resources available in the help directory (sample code available in help/samples/connections/ConnectURL.java).  This link will help you with this jdbc connection mssql Code Snippet  private java.sql.Connection getConnection(){ try{ Class.forName(""com.microsoft.jdbc.sqlserver.SQLServerDriver""); con = java.sql.DriverManager.getConnection(getConnectionUrl()userNamepassword); if(con!=null) System.out.println(""Connection Successful!""); }catch(Exception e){ e.printStackTrace(); System.out.println(""Error Trace in getConnection() : "" + e.getMessage()); } return con; } private String getConnectionUrl(){ return url+serverName+"":""+portNumber+"";databaseName=""+databaseName+"";selectMethod=""+selectMethod+"";""; }  This is a HOWTO from Microsoft on where to get the driver and how to configure it. Briefly download the .jar from Microsoft reference it in your classpath and use: String connectionUrl = ""jdbc:sqlserver://localhost:1433;"" + ""databaseName=AdventureWorks;user=MyUserName;password=*****;""; Connection con = DriverManager.getConnection(connectionUrl); substituting the relevant info. thanks much Mr.Brian but actually i dont know how to run jar files.. You need to add the jar to your classpath. Run java -cp {sql_jar_file.jar} ... and/or Google for how to use jar files.  Your actual problem is thus that you don't know what to do with the phenomenon ""classpath"". Actually the classpath is kind of a collection of disk file system paths which points to the whole .jar file(s) and/or to some root folder with .class file(s) where the Java Virtual Machine should lookup for classes to be imported and loaded. You can specify the classpath during compile and runtime using the -classpath or -cp argument of javac.exe and java.exe. The -cp is just a shorthand it does nothing different. Then you have the mysterious %CLASSPATH% environment variable which you should just entirely forget. It is a poor thing which was intented to make starters easy to manage the classpath but at end it just confused them more. As you're using Class#forName() to load the driver you only need to have it in the classpath during runtime not during compiletime. So here's a basic example how to execute it: java -cp .;c:/path/to/mssql-jdbc-driver.jar com.example.YourClass You see the classpath exist of two parts the . which represents the current working directory and the c:/path/to/mssql-jdbc-driver.jar which should be the absolute path to the JAR file. The ; is just a path separator (in Windows; in Unix and clones it should be a colon :). Note: if a path contains spaces e.g. c:/spacy path to/file.jar then you need to wrap the individual path with doublequotes. If you're using an IDE such as Eclipse then normal practice is that you create a folder in the project where in you can drop all of those 3rd party JAR files which are required by the project. Create a project folder called lib drop the JDBC driver in there and rightclick project > Properties > Java Build Path > Libraries > Add JARs > Select the JAR file which you dropped in project's lib > OK. That should be it. Hope this helps."
97,A,"Storing Result set into an array i know this should be simpel and im probably staring straight at the problem but once again im stuck and need the help of the code gurus. im trying too take one row from a column in jdbc and put them in an array. i do this as follows: public void fillContactList() { createConnection(); try { Statement stmt = conn.createStatement(); ResultSet namesList = stmt.executeQuery(""SELECT name FROM Users""); try { while (namesList.next()) { contactListNames[1] = namesList.getString(1); System.out.println("""" + contactListNames[1]); } } catch(SQLException q) { } conn.commit(); stmt.close(); conn.close(); } catch(SQLException e) { } creatConnection is an already defined method that does what it obviously does. i creat my result set while theres another one i store the string of that column into an array. then print it out for good measure. too make sure its there. the problem is that its storing the entire column into contactListNames[1] i wanted to make it store column1 row 1 into [1] then column 1 row 2 into [2] i know i could do this with a loop. but i dont know too take only one row at a time from a single column. any ideas? p.s ive read the api i jsut cant see anything that fits. The `ResultSet` has only one column (i.e. `name` as you can see that from your query) but you don't know the number of rows ahead of time. So instead of using an array you should consider using a `List`. The `close` should happen in `finally`. You can get [here](http://balusc.blogspot.com/2008/07/dao-tutorial-data-layer.html) some useful ideas. well the max size of the array was 5 so thats all i really needed You should use an ArrayList which provides all the logic to automatically extend the array. List rowValues = new ArrayList(); while (namesList.next()) { rowValues.add(namesList.getString(1)); } // You can then put this back into an array if necessary contactListNames = (String[]) rowValues.toArray(new String[rowValues.size()]); Or.. just stick to `List` instead of array. To the OP: learn [here](http://java.sun.com/docs/books/tutorial/collections/index.html) more about collection API. ive never used arraylist before. im havin trouble following the code there. ill give it a shot in a sec @BalusC: Agreed no need for the array unless another API requires that.  Did you mean something like: int i = 0; ResultSet rs = stmt.executeQuery(""select name from users""); while (rs.next()) { String name = rs.getString(""name""); names[i++] = name; } This requires allocating the `names` array to the correct size. One way would be to execute a count() SQL statement first. I would recommend though using a collection (e.g. ArrayList). pretty much. thats kinda what it started out likle. but i got rid of the loop until i could figure out how to take one row at a time. somethign liek this while(rs.next()) { int i = 0; contactListNames[i] = namesList.getString(i); System.out.println("" "" + contactListNames[i]); }"
98,A,"com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure I'm working on getting my database to talk to my Java programs. What do I need to get started? Having already read through (and been thoroughly confused something that does not happen often) with some other turorials I figured I'd best ask here. How do I import a jar file from the local directory? Can someone give me a quick and dirty sample program using the JDBC? I'm getting a rather stupendous error: Exception in thread ""main"" com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:513) at com.mysql.jdbc.Util.handleNewInstance(Util.java:409) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1122) at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2260) at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:787) at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:49) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:513) at com.mysql.jdbc.Util.handleNewInstance(Util.java:409) at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:357) at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:285) at java.sql.DriverManager.getConnection(DriverManager.java:582) at java.sql.DriverManager.getConnection(DriverManager.java:207) at SqlTest.main(SqlTest.java:22) Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:513) at com.mysql.jdbc.Util.handleNewInstance(Util.java:409) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1122) at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:344) at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2181) ... 12 more Caused by: java.net.ConnectException: Connection refused at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333) at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195) at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:432) at java.net.Socket.connect(Socket.java:529) at java.net.Socket.connect(Socket.java:478) at java.net.Socket.<init>(Socket.java:375) at java.net.Socket.<init>(Socket.java:218) at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:256) at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:293) ... 13 more Contents of the test file: import com.mysql.jdbc.*; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; public class SqlTest { public static void main(String [] args) throws Exception { // Class.forName( ""com.mysql.jdbc.Driver"" ); // do this in init // // edit the jdbc url Connection conn = DriverManager.getConnection( ""jdbc:mysql://localhost:3306/projects?user=user1&password=123""); // Statement st = conn.createStatement(); // ResultSet rs = st.executeQuery( ""select * from table"" ); System.out.println(""Connected?""); } } I might be barking up the wrong tree here but your exception seems to indicate your MySQL server isn't available. Exception in thread ""main"" com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failureThe last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at... What happens if you try (from the terminal) mysql -u username -p You will be prompted for the password associated with the username. After you give the correct password does the mysql client connect? You may have to start MySQL from the Preferences if not. You can also set it to run at startup. +1 for the right tree. I'm using MAMP to run my MySQL server. Would that be an issue? When I connect (via Sequal Pro) to my `localhost` I use the correct username / password and it works fine.  So you have a CommunicationsException: Communications link failure I'm quoting from this answer which also contains a step-by-step MySQL+JDBC tutorial: If you get a SQLException: Connection refused or Connection timed out or a MySQL specific CommunicationsException: Communications link failure then it means that the DB isn't reachable at all. This can have one or more of the following causes: IP address or hostname in JDBC URL is wrong. Hostname in JDBC URL is not recognized by local DNS server. Port number is missing or wrong in JDBC URL. DB server is down. DB server doesn't accept TCP/IP connections. DB server has run out of connections. Something in between Java and DB is blocking connections e.g. a firewall or proxy. To solve the one or the other follow the following advices: Verify and test them with ping. Refresh DNS or use IP address in JDBC URL instead. Verify it based on my.cnf of MySQL DB. Start the DB. Verify if mysqld is started without the --skip-networking option. Restart the DB and fix your code accordingly that it closes connections in finally. Disable firewall and/or configure firewall/proxy to allow/forward the port. +1 and accepted. I had local access only turned on in my mysql configuration. Thanks for adding the link to the explanation! Up-vote. MAMP/ MAMP Pro sets MAMP_skip-networking_MAMP by default. You've to disable this line in your my.cfn @Jurik: Do you know that you saved my day! Thank you very much !  What do I need to get started? a JDBC driver depending on what SQL / Database you're using. e.g: MS SQL use jtds http://jtds.sourceforge.net/ How do I import a jar file from the local directory? Add it to classpath using -cp option or in MANIFEST.MF file in your jar add Class-Path: thejdbcdriver.jar When I add it to my CLASSPATH [link](http://dev.mysql.com/doc/refman/5.1/en/connector-j-installing-classpath.html) then run `import com.mysql.jdbc.*;` it says ""package com.mysql.jdbc does not exist"". What is the package structure of class files in the jar file? The driver class is just a guide line. If the package structure has changed then you should use the changed structure name.  Just experienced this. Got to make it work by: (this can be placed in the static block intializer) static{ // would have to be surrounded by try catch Class.forName(""com.mysql.jdbc.Driver""); // this will load the class Driver } Also by obtaining the connection through: conn = DriverManager.getConnection(DBURL<username><password>); instead of specifying the login parameters  Connection conn = DriverManager.getConnection( ""jdbc:mysql://localhost:3306/projects?user=user1&password=123""); Regards.  I catch this exception when Java out of heap. If I try to put in RAM many data items - first I catch ""Communications link failure"" and next ""OutOfMemoryError"". I logged it and I decrease memory consumption (delete 1/2 data) and all ok.  I got the same error because I was trying to run my program without starting mysql server. After starting the mysql server everything went right. user error gets us all!  Have a look at Sun's JDBC tutorial. It's not specifically about MySQL but the idea of JDBC is that it's database agnostic - it doesn't matter which database you use you just have to use the appropriate JDBC driver and connection string. For MySQL you can download the JDBC driver here. It consists of a JAR file which you need to put in your classpath. See the documentation of the driver which also contains examples of how to use it.  This is best solution Connection con = DriverManager.getConnection( ""jdbc:mysql://localhost:3306/DBname"" ""root"" ""root""); Connection con = DriverManager.getConnection( ""jdbc:mysql://192.100.0.000:3306/DBname"" ""root"" ""root""); Replacement of Localhost to your IP address  Please update your IP address in /etc/mysql/my.cnf file `bind-address = <IP_ADDRESS>` Restart mysql deamon and mysql services.  Download MySQL-JDBC-Type-4-Treiber (i.g. 'mysql-connector-java-5.1.11-bin.jar' from 'mysql-connector-java-5.1.11.zip') at Mysql. You need to inculde the driver jar during compile- and runtime in your classpath. Class.forName( ""com.mysql.jdbc.Driver"" ); // do this in init // edit the jdbc url Connection conn = DriverManager.getConnection( ""jdbc:mysql://MyDbComputerNameOrIP:3306/myDatabaseName"" username password ); Statement st = conn.createStatement(); ResultSet rs = st.executeQuery( ""select * from table"" ); Nope gives me a storm of errors about not finding anything. Would it be possible to import this without the JAR file? @Josh this works you really just need to setup your classpath properly. (Or copy the jar into your %JAVA_HOME%\jre\lib\ext directory but this is considered bad-practice)  My same problem is solved by following steps: go to my.cnf vi /etc/mysql/my.cnf modify its bind-address ""#bind-address = 127.0.0.1"" restart mysql sudo /etc/init.d/mysql restart  I had the same problem and here's how it was fixed: My .jsp was calling attributes that I had not yet defined in the servlet. I had two column names that I was passing into an object through ResultSet (getString(""columnName"")) that didn't match the column names in my database. I'm not exactly sure which one fixed the problem but it worked. Also be sure that you create a new Statement and ResultSet for each table query."
99,A,"Variable column names using prepared statements I was wondering if there was anyway to specify returned column names using prepared statements. I am using MySQL and Java. When I try it: String columnNames=""def""; //Actually from the user... String name = ""some_table""; //From user... String query = ""SELECT abc? FROM "" + name + "" WHERE d=?"";//... stmt = conn.prepareStatement(query); stmt.setString(1 columnNames); stmt.setString(2 ""x""); I get this type of statement (printing right before execution). SELECT abc'def' FROM some_table WHERE d='x' I would like to see however: SELECT abcdef FROM some_table WHERE d='x' I know that I cannot do this for table names as discussed here but was wondering if there was some way to do it for column names. If there is not then I will just have to try and make sure that I sanitize the input so it doesn't lead to SQL injection vulnerabilities. Thank you so much for your help! This site is a really great resource! Prepare a whitelist of allowed column names. Use the 'query' to look up in the whitelist to see if the column name is there. If not reject the query.  This indicates a bad DB design. The user shouldn't need to know about the column names. Create a real DB column which holds those ""column names"" and store the data along it instead. At any way no you cannot set column names as PreparedStatement values. You can only set column values as PreparedStatement values If you'd like to continue in this direction you need to sanitize the column names and concatenate/build the SQL string yourself. Quote the separate column names and use String#replace() to escape the same quote inside the column name. Well the user doesn't actually need to know the column names but the column names needed are deduced based on forms submitted by the user. This is handled on the client side though so I wanted to see if there was some way to ensure the data is safe. Should I then just move the whole lot to the server-side thereby ensuring the column data is untainted? Handle it on the server side instead. Don't do business stuff in client side.  I think this case can't work because the whole point of the prepared statement is to prevent the user from putting in unescaped query bits - so you're always going to have the text quoted or escaped. You'll need to sanitize this input in Java if you want to affect the query structure safely."
100,A,Custom oracle exceptions through JDBC In a stored procedure I have used to; raise_application_error (-20010 'My Message'); to raise a custom error in a certain situation. What I am trying to do is when I make my JDBC call from java to be able to identify this error as not just being a SQLException so that I can handle it differently. I though I could identify it by the errorCode but that seems to always be 17062 and not -20010. Is there another way to do this or am I missing something? you should get 20010 as your errorCode. the ORA-17062 is an error for invalid ref cursors. Are you sure the procedure you are calling throws the custom error ? Wow I feel foolish. It was throwing the error but I was also catching the exception in the package logging it and then returning null causing the ORA-17062. Didn't think about it until I read your post. Thanks for the help. Glad to help =)
101,A,"Why do I get an ArrayIndexOutOfBoundsException in my JDBC connection? I am new to Java and I am attempting to use JDBC to connect to an UniVerse database. I'm using Sun Java 6 JDK to using NetBeans to build the project. My simple test below builds however it gives the errors below: > run: driver loaded Exception in thread ""main"" java.lang.ExceptionInInitializerError Connecting... at com.ibm.u2.jdbc.UniJDBCProtocolU2Impl.initDefaultMarks(UniJDBCProtocolU2Impl.java:1239) at com.ibm.u2.jdbc.UniJDBCProtocolU2Impl.<init>(UniJDBCProtocolU2Impl.java:116) at com.ibm.u2.jdbc.UniJDBCConnectionImpl.<init>(UniJDBCConnectionImpl.java:137) at com.ibm.u2.jdbc.UniJDBCDriver.connect(UniJDBCDriver.java:111) at java.sql.DriverManager.getConnection(DriverManager.java:582) at java.sql.DriverManager.getConnection(DriverManager.java:207) at testjdbc.Main.main(Main.java:36) Caused by: java.lang.ArrayIndexOutOfBoundsException: 3 at asjava.uniclientlibs.UniTokens.<clinit>(UniTokens.java:109) ... 7 more Java Result: 1 BUILD SUCCESSFUL (total time: 0 seconds) My Test Code: /* * To change this template choose Tools | Templates * and open the template in the editor. */ package testjdbc; import java.sql.*; import java.io.*; /** * * @author norm */ public class Main { /** * @param args the command line arguments */ public static void main(String[] args) { Connection con = null ; try{ // generate URL String url = ""jdbc:ibm-u2://my.uv.db:31438/DB-ACCOUNT;user=me;password=pass""; //testing I remove user and password from here and use them below. Still FAILS!!! ARGGGG!!! String user = ""me""; String password = ""pass""; String driver = ""com.ibm.u2.jdbc.UniJDBCDriver""; //Load driver and connect to server Class.forName(driver); System.out.println(""driver loaded""); System.out.println(""Connecting...""); con = DriverManager.getConnection(url); //This is line 36 // con = DriverManager.getConnection(url user password); // gives the same error //con = DriverManager.getConnection(""jdbc:ibm-u2://my.uv.db:31438/D:/PathTo/DB;"" ); //and yet the same error for this as well System.out.println(""Connection String sent""); System.out.println(""Querying...""); testQuery( con ) ; } catch ( SQLException e ) { System.out.println(""Ex-Message :"" + e.getMessage()); System.out.println(""Ex-Code :"" + e.getErrorCode()) ; System.out.println(""Ex-SQLState:"" + e.getSQLState()); System.out.println(""Ex-Next :"" + e.getNextException()); e.printStackTrace() ; System.gc(); } catch ( Exception e) { System.out.println(""Exception caught:""+e) ; e.printStackTrace() ; } } public static void testQuery(Connection con) throws SQLException { Statement stmt = con.createStatement(); String sql = ""select FIRST.NAME from EMPCEL""; //""select @ID CITY STATE ZIP PHONE from CUSTOMER""; // Execute the SELECT statement ResultSet rs = stmt.executeQuery(sql); // Get result of first five records System.out.println(""\tlist selected columns for the first five records:""); int i = 1; while (rs.next() && i < 6) { System.out.println(""\nRecord ""+ i +"" :""); System.out.println(""\tFirst Name : \t"" + rs.getString(1)); // System.out.println(""\tCITY :\t"" + rs.getString(2)); // System.out.println(""\tSTATE :\t"" + rs.getString(3)); // System.out.println(""\tZIP : \t"" + rs.getString(4)); // System.out.println(""\tPHONE :\t"" + rs.getString(5)); i++; System.out.println(""Finished.""); } rs.close(); stmt.close() ; System.out.println(""\n\t*--- QUERY test is done successful ---*\n""); } } Ass you can see I have tried the DriverManager.getConnection a few different ways including some that are not reflected in this iteration. This appears to be Netbeans related. See also this topic at their forum. It appears to work in Eclipse (and possibly all other environments). This is clearly a bug in the UniVerse JDBC driver. It is apparently inside the static initializer relying on some specific environmental condition which is different in Netbeans. If it wasn't a bug it would have thrown a much more self-explaining exception not such a silly runtime exception. I'd report this bug to IBM/UniVerse. HOLY CRAP!!! That was it. And to think I was banging my head against the desk all day yesterday over this. I am so going to be on the phone with Rocket about this. Thank you BalusC!! And Thank you Stackoverflow. I guess this settles the debate over which IDE I'll be using. You're welcome.  I experienced this problem too. UniTokens is assuming that there is a one-for-one conversion of bytes to chars but it is not true for all platforms. Passing an argument to the JVM avoids this issue. Try -Dfile.encoding=""windows-1252"" or -Dfile.encoding=""US-ASCII""  If the presented code is the one that actually caused the exception then I guess it fails because url is null at the time you try to get the connection. But the error stacktrace shows an error at line 36 which is comment line. So if my guess is wrong please edit your question and present matching code and error message and mark the line of code that throws the exception. You're not alone: same problem I edited the code to further explain what I have tried on the various lines. Thanks for the reply. I have also used the ip address as well as the domain name. Still no avail."
102,A,PACKAGE.TABLENAME%ROWTYPE in JDBC We have a stored proc where it returns a record which is of type PACKAGE.TABLENAME%ROWTYPE. we are finding it difficult to map in JDBC? Does anyone shed some light on this? yes oracle 10 g This is Oracle you're working with? It's a shot in the dark considering the vague way the question is worded but here's a Sun Java forum link to check out on the matter of making %ROWTYPE work with JDBC: http://forums.sun.com/thread.jspa?threadID=5363452 Couldn't find a better solution. So changed the stored proc to return a REF cursor.
103,A,"PostgreSQL: Which connectivity uses psql tool of PostgreSQL Does anybody know how psql accesses PostgreSQL database? What it uses odbc jdbc or some native database library? It uses libpq. Thanks are you developer or it is written somewhere in the documentation? @Tim If you click on a poster's name you can see his profile. @Peter: Don't misunderstand me I do not offend anybody just want to see official information by myself. Btw it is written ""PHP programmer; SVN and PostgreSQL administrator"" I am not sure if every PostgreSQL administrator knows such details. Comment on my 1st comment: by developer I meant developer of psql not developer in general as it may seem.. That's right Makefile of psql shows that: psql: $(OBJS) $(libpq_builddir)/libpq.a No I'm not related to the PGDG (PostgreSQL Global Development Group) in any way though I'm satisfied ""customer"" and enthusiast. And I have built Postgres from source quite a few times."
104,A,"Using a java class to create a database I'm working in an application that uses servlets and mysql. I'd like to create a .jar file able to create the database that the application will be using. This will only be done once in order to create the db. I've no problem in getting to access to a database doing something like this: Class.forName(""com.mysql.jdbc.Driver"").newInstance(); Connection conexion = (Connection)DriverManager.getConnection(""jdbc:mysql://localhost/test""""admin""""admin""); if (!conexion.isClosed()) { Statement st = (Statement) conexion.createStatement(); ResultSet rs = st.executeQuery(""select * from table_name"" ); } conexion.close(); This is ok but what I need to do is to create a new database (and its tables) from a java class is that possible? Thanks I'm trying this: Class.forName(""com.mysql.jdbc.Driver"").newInstance(); Connection conexion = (Connection)DriverManager.getConnection(""jdbc:mysql://localhost/mysql""""admin""""admin""); Statement st = (Statement) conexion.createStatement(); st.executeUpdate(""CREATE DATABASE hrapp""); but I'm getting the following error: Exception in thread ""main"" com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Access denied for user 'admin'@'localhost' to database 'hrapp' at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) at java.lang.reflect.Constructor.newInstance(Unknown Source) at com.mysql.jdbc.Util.handleNewInstance(Util.java:406) at com.mysql.jdbc.Util.getInstance(Util.java:381) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1030) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3491) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2536) at com.mysql.jdbc.StatementImpl.executeUpdate(StatementImpl.java:1564) at com.mysql.jdbc.StatementImpl.executeUpdate(StatementImpl.java:1485) at BaseDatosSetup.BaseDatosSetup.main(BaseDatosSetup.java:18) I solved it by granting the create action to the user. I don't know why I was doing it as an administrator. I don't know if I make a connection to one of my databases and then use: ResultSet rs = st.executeQuery(""select * from audiolist2"" ); That works. If you can program a SELECT why can't you program CREATE TABLE/INSERT/LOAD? Why do you want to do this? I think what you would have to do is perform some Runtime commands to interface with the OS directly to do accomplish this feat. However I would recommend not doing it this way.  First this problem isn't servlet-specific. You would struggle with exactly the same problem/question when doing/trying so in any other Java class ;) Second creating databases/tables programmatically honestly smells. In real world with well-designed data models you normally create the databases/tables only once during installing/setup of the application in question and then use it forever during application's lifetime. You shouldn't need to create a new DB/table for every hiccup. Unless you intend to develop (reinvent) a webbased database manager of course. As to your actual question this actually depends on the JDBC driver used but most of them just allows executing CREATE or any other DDL statements using Statement#executeUpdate(). If yours don't then you need to look for another JDBC driver make or version which allows that. You should also take into account that the DB user in question has sufficient rights this is to be configured at DB level. re. creating databases/tables outside of code another reason i could see a need for this is perhaps in some sort of a test suite where the setup and teardown require creation/deletion of database/table/test data. Still then one wouldn't explicitly mention to use a servlet for this ;) I didn´t know what was I thinking when I wrote the question. It is edited now. Apologies for the confusion :)  W3CSchools.com -- SQL CREATE DATABASE Statement. You wouldn't use executeQuery though. Instead use executeUpdate. Here is a simple example. As mentioned by other users you probably don't want to be creating databases from your code. It just isn't good practice. I tried that but I got an error. I've added the information to my question. Thanks"
105,A,"java.lang.ClassNotFoundException: com.mysql.jdbc.Driver I am trying to connect to mysql database using java on windows7. Inspite of adding the complete url of jdbcdriver jar file in CLASSPATH java.lang.ClassNotFoundException: com.mysql.jdbc.Driver is thrown. Could anyone tell me what i am missing here?? it works if i add the jar file in project library but i want to do it by CLASSPATH itself. My classpath looks like this- C:\jython2.5.1\javalib\mysql-connector-java-5.1.12-bin.jar I want to make it clear that this is not the actual project i am working on.Actually i am using django with jython which requires jdbc driver to access db. that is the reason why i have to do it using CLASSPATH only. with what are you building your project? ...and if you're doing this from a command prompt can you also show the exact command-line you're using? i am using netbeans ide. Actually i was getting this error while using django with jython so i thought i should try connecting to mysql database from plain java. What finally helped me out was to copy the mysql-connector-java-5.1.15-bin.jar to \jre\lib and to \jre\lib\ext both(!) even though I did all the classpathing circus Java offers :) Environment was pure notepad/commandline though. This one helped me out. Here is a link as of today you can download the platform independent one from here: http://dev.mysql.com/downloads/connector/j/#downloads @Raido Valgeväli: +1 Upvoted ! thanks !!!  What worked with me using Netbeans was: Run > Set Project Configuration > Customize. Under Libraries > Add Library. Added MySQL JDBC Driver (I assume it appeared in list because I copied the jar file to the jre\lib\ext folder. And it worked seamlessly. I tried setting classpath but that did not work. I am using Netbeans 7.0 Thank god for this answer. I've been fighting with this problem for the last 2 1/2 hours and you fixed it for me. OMG you're the best! Setting classpath didn't work for me either! I'm using eclipse but it's similar. So for those of you that are using eclipse: right click on the project -> Run Configuration -> Classpath -> add it there.  I had this same problem in Netbeans. Because I was using a tomcat connection pool as defined in context.xml I needed to add the jdbc jar to both the project (Properties->Libraries) and to the lib/ folder within my Tomcat server so it could be seen on startup.  The CLASSPATH environment variable is only used by the java.exe command and even then only when used without any of the -cp -classpath -jar arguments. It is ignored by IDEs. That environment variable is in real world also considered a poor practice since it breaks portability. It's only ""useful"" for Sun Oracle to prevent that starters get tired of typing the same classpath again and again in the -cp or -classpath arguments when following Java tutorials. In real world batch/shell files are preferred where just the entire command with -cp/-classpath argument is specified. In your case you're using an IDE. The classpath is there called the ""build path"" (in plain Java projects it represents both the compiletime and runtime classpath). You can configure it in the project's properties. You can add a complete folder you can add individual/external JAR files you can link projects etcetera. Make use of it. Forget the whole CLASSPATH environment variable. Thanx for you reply Actually my project is on django and jython. jython runs on jvm and it needs jdbc drivers to access db. I dnt know of any other way to include a jar file. The detailed answer depends on the runtime environment. At least you can use `sys.path` environment variable (which is by the way similar to `CLASSPATH` and thus also unportable) or the command argument `-Dpython.path`.  Open Netbeans IDE Right-click your Project. Select Properties. On the left-hand side click Libraries. Under ""Compile"" tab - click Add Jar/Folder button. Select Downloaded ""mysql-connector-java-5.1.25-bin.jar"" file (Download Connector/J from dev.mysql.com) Click OK Run Again... Its work.  In Netbeans IDE just Check the properties of Project on which you working onin properties window go to 'library' tag in diolog box just add your mysql-connector-java-**.jar file.  simply do a right click on your project in ""Netbeans"" select properties then click on ""libraries "" then click on ""add library..."" button then select ""MySQL JDBC Driver"" and click on ""add library"" button then on ""OK"" button"
106,A,Prepared Statement Failing (With an Error Message!) I am getting this error when trying to insert data into a data table Error Saving data. [Microsoft][ODBC Microsoft Access Driver]COUNT field incorrect I looked at the appropriate data table and there does not exist a field called COUNT either hidden or not hidden. Is this some SQL terminology that I should be familiar with? An Extension of this Question Please post your code especially the query you are using for the prepared statement. passing null values into the prepared statement is what caused the problem I just have to wait another 6 hours before I can accept my own answer. You like have SQL syntax that Jet doesn't support. Post the SQL or nobody is going to be able to help you. This is a generic error message which is usually caused by incorrect statement syntax (like missing quote somewhere). Double check your SQL and post it here along with parameters / table schema if you need further help.  It seems that passing null values into the prepared statement also causes this errror.
107,A,"How many JDBC connections in Java? I have a Java program consisting of about 15 methods. And these methods get invoked very frequently during the exeuction of the program. At the moment I am creating a new connection in every method and invoking statements on them (Database is setup on another machine on the network). What I would like to know is: Should I create only one connection in the main method and pass it as an argument to all the methods that require a connection object since it would significantly reduce the number of connections object in the program instead of creating and closing connections very frequently in every method. I suspect I am not using the resources very efficiently with the current design and there is a lot of scope for improvement considering that this program might grow a lot in the future. Many JDBC drivers do connection pooling for you so there is little advantage doing additional pooling in this case. I suggest you check the documentation for you JDBC driver. Another approach to connection pools is to Have one connection for all database access with synchronised access. This doesn't allow concurrency but is very simple. Store the connections in a ThreadLocal variable (override initialValue()) This works well if there is a small fixed number of threads. Otherwise I would suggest using a connection pool.  You should use a connection pool for that. That way you could ask for the connection and release it when you are finish with it and return it to the pool If another thread wants a new connection and that one is in use a new one could be created. If no other thread is using a connection the same could be re-used. This way you can leave your app somehow the way it is ( and not passing the connection all around ) and still use the resources properly. Unfortunately first class ConnectionPools are not very easy to use in standalone applications ( they are the default in application servers ) Probably a microcontainer ( such as Sping ) or a good framework ( such as Hibernate ) could let you use one. They are no too hard to code one from the scratch though. :) This google search will help you to find more about how to use one. Skim through if 'retiring' of connections is not considered; Why do we need of multiple connections? one single connection can be used everywhere rit; since statement objs are always different? When we requires multiple connection in the application?  You can either pass in the connection or better yet use something like Jakarta Database Connection Pooling. http://commons.apache.org/dbcp/  Yes you should consider re-using connections rather than creating a new one each time. The usual procedure is: make some guess as to how many simultaneous connections your database can sensibly handle (e.g. start with 2 or 3 per CPU on the database machine until you find out that this is too few or too many-- it'll tend to depend on how disk-bound your queries are) create a pool of this many connections: essentially a class that you can ask for ""the next free connection"" at the beginning of each method and then ""pass back"" to the pool at the end of each method your getFreeConnection() method needs to return a free connection if one is available else either (1) create a new one up to the maximum number of connections you've decided to permit or (2) if the maximum are already created wait for one to become free I'd recommend the Semaphore class to manage the connections; I actually have a short article on my web site on managing a resource pool with a Semaphore with an example I think you could adapt to your purpose A couple of practical considerations: For optimum performance you need to be careful not to ""hog"" a connection while you're not actually using it to run a query. If you take a connection from the pool once and then pass it to various methods you need to make sure you're not accidentally doing this. Don't forget to return your connections to the pool! (try/finally is your friend here...) On many systems you can't keep connections open 'forever': the O/S will close them after some maximum time. So in your 'return a connection to the pool' method you'll need to think about 'retiring' connections that have been around for a long time (build in some mechanism for remembering e.g. by having a wrapper object around an actual JDBC Connection object that you can use to store metrics such as this) You may want to consider using prepared statements. Over time you'll probably need to tweak the connection pool size Could you elaborate how Prepared Statements could help here? One single connection be used to run a (theoretically) infinite number of queries as you say. But it can only run one query at a time. On a moderately complex system you generally need to allow for the possibility of running several queries concurrently. @neilCoffey if 'retiring' of connections is not considered; Why do we need of multiple connections? one single connection can be used everywhere rit; since statement objs are always different? When we requires multiple connection in the application?  If your application is single-threaded or does all its database operations from a single thread it's ok to use a single connection. Assuming you don't need multiple connections for any other reason this would be by far the simplest implementation. Depending on your driver it may also be feasible to share a connection between threads - this would be ok too if you trust your driver not to lie about its thread-safety. See your driver documentation for more info. Typically the objects below ""Connection"" cannot safely be used from multiple threads so it's generally not advisable to share ResultSet Statement objects etc between threads - by far the best policy is to use them in the same thread which created them; this is normally easy because those objects are not generally kept for too long."
108,A,"Java + MySQL integrity violation handling I write Java program using JDBC (mysql database). When I violate mysql integrity (f.e. I try to insert same primary key value) I catch SQL exception. Should I write it in way it may never happen (f.e. at first boolean function checking whether primary key value isn't already in DB and then calling insert) or is it okay to handle it just by exception? Example : catch (SQLException ex) {ex.printStackTrace(); showSomeErrorDialog(); } Correct me if I am wrong but by default don't you have to perform a `try` and `catch` block for `SQLException` when performing queries to begin with? if you are executing query from statement you have to. Statement st = connection.createStatement(); st.executeQuery(""SELECT * FROM table""); those needs try and catch How about when doing `INSERT`? My reason for asking is that if it requires a try-block by default when executing a query you have to do so anyways but like I said I could be wrong I don't work with JDBC at all. insert is kind of query isn't it? I dont see special command for insert only for update (not executeQuery but executeUpdate) besides every executing throws SQLException There are indeed basically two ways to achieve this: Test if record exists before inserting --inside the same transaction. Determine if SQLException#getSQLState() of the catched SQLException starts with 23 which is a constraint violation as per the SQL specification. It can namely be caused by more factors than ""just"" a constraint violation. You should not amend every SQLException as a constraint violation. public static boolean isConstraintViolation(SQLException e) { return e.getSQLState().startsWith(""23""); } I would opt for the first one as it is semantically more correct. It is in fact not an exceptional circumstance. You namely know that it is potentially going to happen. But it may potentially fail in heavy concurrent environment where transactions are not synchronized (either unawarely or to optimize performance). You may then want to determine the exception instead. That said you normally shouldn't get a constraint violation on a primary key. In well designed datamodels which uses technical keys as primary keys they are normally to be managed by the database itself. Isn't the field supposed to be an unique key? It is unique so insert will just fail :) nothing bad will actually happen only error message  There are two possible answers : if you know that your application is designed to avoid this kind of behaviour use the exception if your application can make these errors often use a test. about performance - it is not very probable that this kind of exception will happen in my application. Therefore testing before every insert will consume much more time than just insert itself with occasional exception. On the other hand if the application is already believed to be generating unique keys then it would be quite appropriate to handle a failure for this as an exception - since after all it would be considered an exceptional case. changed my answer according to your remarks I see thanx .... I was actually hoping for some1 who will say exact other thing than you bishiboosh :-D But it is just my laziness probably"
109,A,"Cannot connect to Oracle DB from Java - ORA-12560: TNS:protocol adapter error This is my first Java application I am creating (using Eclipse IDE) and the second Oracle based app (I'm a .NET/MSSQL guy for years). The first Oracle app I wrote in .NET did not have any issues and I'm trying to connect to the same server. I have installed: 'Java 2 Platform Enterprise Edition 1.4 SDK' 'Java DB `10.5.3.0' -'Java(TM) 6 Update 21 'Java(TM) SE Development Kit 6 update 21 'Oracle IRM Client' (11g) Oracle 11g Release 2 JDBC Drivers (ojdbc6.jar) My code is very simple. Here it is:  OracleDataSource ods = new OracleDataSource(); ods.setURL(""jdbc:oracle:oci:@""); ods.setUser(""username""); ods.setPassword(""password""); ods.setServerName(""servername""); ods.setPortNumber(1549); ods.setServiceName(""foo.myservice.com""); Connection conn = ods.getConnection(); I get below exception: Exception in thread ""main"" java.sql.SQLException: ORA-12560: TNS:protocol adapter error at oracle.jdbc.driver.T2CConnection.checkError(T2CConnection.java:737) at oracle.jdbc.driver.T2CConnection.logon(T2CConnection.java:401) at oracle.jdbc.driver.PhysicalConnection.<init>(PhysicalConnection.java:531) at oracle.jdbc.driver.T2CConnection.<init>(T2CConnection.java:148) at oracle.jdbc.driver.T2CDriverExtension.getConnection(T2CDriverExtension.java:53) at oracle.jdbc.driver.OracleDriver.connect(OracleDriver.java:503) at oracle.jdbc.pool.OracleDataSource.getPhysicalConnection(OracleDataSource.java:280) at oracle.jdbc.pool.OracleDataSource.getConnection(OracleDataSource.java:207) at oracle.jdbc.pool.OracleDataSource.getConnection(OracleDataSource.java:157) at Select.GetScalar(Select.java:47) at Job.Run(Job.java:20) at Main.main(Main.java:19) I have google'd the hack out of this.. I've tried adding a 'TNS entry to the tnsnames.ora file'. I've tried adding '##NAMES.DIRECTORY_PATH = (TNSNAMES EZCONNECT)' to the sqlnet.ora file. I've tried various other things but nothing is working. Has anyone experienced this before and has any clue on how to get this to work?? Am I using the wrong version? Server is remote (I don't have Oracle server installed locally just client). Maybe I have wrong version of Java SDK or the wrong version of the JDBC .jar file?? I just need to connect to Oracle and run a single simple query! Thanks much for any help. If you want something simple you should try using the THIN client instead of OCI client. Don't forget to include the right jar (ojdbc5.jar for Java 5 ojdbc6.jar for Java 6). where to download thin client? or is it already inside ojdbc6.jar and I just change the URL?? I didnt see download for thin client on above oracle JDBC drivers link... It's part of ojdbcXX.jar. You need to change ""oci"" to ""thin"" in the URL. Note that the URL format is not the same for thin driver and OCI driver. See http://www.orafaq.com/wiki/JDBC It's just to force the OracleDriver class to be loaded. There is some static code being executed during this class initialization the driver register itself to the DriverManager. thanks. but why use this reflection magic (e.g. Class.forName) instead of good old static typing??  Try using the type IV JDBC driver instead of OCI if you can. The thin url looks like this: jdbc:oracle:thin:@host[:port]/service I'd try code that looked more like this (fill in your defaults for the driver URL username and password):  package persistence; import java.sql.*; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; public class DatabaseUtils { private static final String DEFAULT_DRIVER = """"; private static final String DEFAULT_URL = """"; private static final String DEFAULT_USERNAME = """"; private static final String DEFAULT_PASSWORD = """"; public static void main(String[] args) { String driver = ((args.length > 0) ? args[0] : DEFAULT_DRIVER); String url = ((args.length > 1) ? args[1] : DEFAULT_URL); String username = ((args.length > 2) ? args[2] : DEFAULT_USERNAME); String password = ((args.length > 3) ? args[3] : DEFAULT_PASSWORD); Connection connection = null; try { connection = createConnection(driver url username password); DatabaseMetaData meta = connection.getMetaData(); System.out.println(meta.getDatabaseProductName()); System.out.println(meta.getDatabaseProductVersion()); } catch (Exception e) { e.printStackTrace(); } finally { close(connection); } } public static Connection createConnection(String driver String url String username String password) throws ClassNotFoundException SQLException { Class.forName(driver); if ((username == null) || (password == null) || (username.trim().length() == 0) || (password.trim().length() == 0)) { return DriverManager.getConnection(url); } else { return DriverManager.getConnection(url username password); } } public static void close(Connection connection) { try { if (connection != null) { connection.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void close(Statement st) { try { if (st != null) { st.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void close(ResultSet rs) { try { if (rs != null) { rs.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void rollback(Connection connection) { try { if (connection != null) { connection.rollback(); } } catch (SQLException e) { e.printStackTrace(); } } public static List<Map<String Object>> map(ResultSet rs) throws SQLException { List<Map<String Object>> results = new ArrayList<Map<String Object>>(); try { if (rs != null) { ResultSetMetaData meta = rs.getMetaData(); int numColumns = meta.getColumnCount(); while (rs.next()) { Map<String Object> row = new HashMap<String Object>(); for (int i = 1; i <= numColumns; ++i) { String name = meta.getColumnName(i); Object value = rs.getObject(i); row.put(name value); } results.add(row); } } } finally { close(rs); } return results; } } Thanks a lot for the code sample. But where can I download the jar file for the thin driver? Or are you saying I need only change the URL?? On the above linked page it says 'thin driver' but just has a 'JavaDoc' file and a README with just instructions... Can you provide me with the string that should go into the 'driver' here?? this is what always confused me and why I liked the OracleConnection class. This dynamic class creation stuff just 'smells' to me... OracleConnection ties you to Oracle forever. That's a bigger smell to me. The driver class name is the one in your ojdbc6.jar: Looks like it's oracle.jdbc.driver.OracleDriver.  Is the ServiceName you specified the service name of the Oracle instance you're trying to connect to? You're sure the port is correct? Yes and Yes. Thanks! same exact 'connection string' parameters are being used in .NET application without issues (service name port number etc..) .NET and Java aren't the same in this case. That explains why you're using OCI driver because .NET can't use the thin driver. If you're using Java switch to thin."
110,A,"jdbc - java - method query I am using JDBC to query a MySQL database for specific records from two tables. My MySQL query sample is this: SELECT r.name  r.network  r.namestring  i.name  r.rid  i.id  d.dtime  d.ifInOctets FROM router AS r INNER JOIN interface AS i ON r.rid = i.rid INNER JOIN 1278993600_1_60 AS d ON i.id = d.id AND dtime BETWEEN 1279027200 AND 1279029000 WHERE r.network = ""ITPN"" AND i.status = ""active"" WHERE i.id BETWEEN 1418 AND 1518 Now is it possible for me to add all the specific records which I need:  r.name  r.network  r.namestring  i.name  r.rid  i.id  d.dtime  d.ifInOctets to an array specifically and print it out to an excel sheet? I tried creating different classes for the 3 tables: r i d. Then as I queried the database I created objects and added them to ArrayLists which I printed out to a different sheet. (The goal is to print it out to an excel sheet) But this method is making me store and iterate over millions of objects. Is there any method to add all records dynamically in an easier less time consuming way and send it to the sheet? Did you consider CSV? Do you know `LOAD DATA INFILE`? It would be something like that: PreparedStatement stmt = cnt.prepareStatement(""...""); try { /* ... */ ResultSetMetaData meta = stmt.getMetaData(); Object row[] = new Object[meta.getColumnCount()]; ResultSet rs = stmt.executeQuery(); while (rs.next()) { for (int i = 0; i < row.length; ++i) { row[i] = rs.getObject(i+1); } processRow(row); } } finally { stmt.close(); } Yes but if you have millions of rows I wouldn't recommend it hi thanks. Is it possible to get the whole column in an Array? I was trying to use rs.getArray() function with no luck. Also if there are multiple data ids which map to the same time what could I use to keep track of it as every id would have a different list of values??? Loop through the resultset and add the column value to an `ArrayList` on every iteration."
111,A,"DAO design pattern and using it across multiple tables I'm looking for feedback on the Data Access Object design pattern and using it when you have to access data across multiple tables. It seems like that pattern which has a DAO for each table along with a Data Transfer Object (DTO) that represents a single row isn't too useful for when dealing with data from multiple tables. I was thinking about creating a composite DAO and corresponding DTO that would return the result of let's say performing a join on two tables. This way I can use SQL to grab all the data instead of first grabbing data from one using one DAO and than the second table using the second DAO and than composing them together in Java. Is there a better solution? And no I'm not able to move to Hibernate or another ORM tool at the moment. Just straight JDBC for this project. Ideally how you store your data in a database and then how you access them should be derived from the nature of the relationship among the domain entities in your domain model. That is Relational Model should follow from Domain Model. For example if you have two entities say User and Address. Scenario #1: Address are never accessed independently they are always an attribute of User. In this case Address is a Value Object and User is an Entity and there are guides on how to store this relationship. One way is to store Address attributes of Address alongside of attributes of User in a single table. In this case UserDao will handle both objects. Scenario #2: Address can be associated to a User but also can be separate on its own an entity. In this case an approach different from the first one is needed. You may have a separate DAO and table for the Address type. My point is that more often this important idea is ignored that Domain Model should be the core of the application driving other layers. For instance if your domain model is properly define and you are well aware of the type of entities you have and the relationship among them then your persistence (relational tables and their relationships your DAOs etc) will evolve as a very logical consequence of what you have in the domain model. In other words if you spend some time studying your model you will be able to trace your problem in determining how to organize your DAOs to a place in the domain model. If you can clearly define the type of the objects and the nature of relationship among them in the domain model it will help you resolve your problem in DAL layer.  I would agree with your approach. My DAOs tend to be aligned more at the object level rather than from a DB Table perspective. I may manage more than one object through a DAO but they will very likely be closely related. There is no reason not to have SQL accessing two tables living in one DAO. And for the record I have banished the acronym DTO from my vocabulary and code. I see. Pretty much the same way I use them. Thanks. I just don't see the point to call an object a 'Data Transfer Object'. I populate domain objects directly in my DAOs use them in my services and expose them in my views (sometimes I may create alternate view objects). DTOs typically have no behavior and are dumb property holders. I don't see a reason to limit my objects thusly in a modern Java project architecture. And by modern I generally mean non-EJB with a framework like Spring. ""I have banished the acronym DTO from my vocabulary and code."" Can you explain more? Can you give an example of why this is error prone? I'm having a hard time visualizing it. Is this a best practice? So in a DAO you would have getWhatever() which calls getSomethingElse() to construct Whatever. I feel that this is error prone because the ordering is very important in both inserting and updating."
112,A,"Select BigSerial Column Data from Informix Table The scenario is like that. User will specify a database table name and the system will retrieve and display all the data stored in the specified informix database table. Class.forName(""com.informix.jdbc.IfxDriver""); Connection conn = DriverManager.getConnection(connUrl) Statement stmt = conn.createStatement(); ResultSet rs = stmt.executeQuery(""select * from an_ifx_table""); The an_ifx_table is any table name specified by user. The problem is there is a column defined with BigSerial data type. So the code will always throw an exception: java.sql.SQLException: bigserial at com.informix.jdbc.IfxSqli.a(IfxSqli.java:3204) at com.informix.jdbc.IfxSqli.E(IfxSqli.java:3518) at com.informix.jdbc.IfxSqli.dispatchMsg(IfxSqli.java:2353) at com.informix.jdbc.IfxSqli.receiveMessage(IfxSqli.java:2269) at com.informix.jdbc.IfxSqli.executeStatementQuery(IfxSqli.java:1428) at com.informix.jdbc.IfxSqli.executeStatementQuery(IfxSqli.java:1401) at com.informix.jdbc.IfxResultSet.a(IfxResultSet.java:204) As which table the system is retrieving the data from is going to be specified by user we can't skip or cast the column with BigSerial data type. Any suggestion to handle this scenario? Add version information of your OS and JDBC driver. I have just created table with SERIAL8 column filled it with some data and I can read all data from ResultSet. Maybe your JDBC driver is old? I use JDBC driver from JDBC.3.50.JC5.tar. You can also try JDBC-ODBC bridge. Install Informix ClientSDK create ODBC source and then as driver use: sun.jdbc.odbc.JdbcOdbcDriver and as connUrl: jdbc:odbc:[ODBC_source_name] On my Windows machine I use clientsdk.3.50.TC5.WIN.zip and on Linux I use clientsdk.3.50.UC5.LINUX.tar Thanks friend! I just checked. My Informix JDBC Driver is obsolete. Just downloaded JDBC.3.50.JC5.tar and tested it. Everything works fine now."
113,A,"Help me create a jTDS connection string my sql server instance name is MYPC\SQLEXPRESS and I'm trying to create a jTDS connection string to connect to the database 'Blog'. Can anyone please help me accomplish that ? I'm trying to do like this: DriverManager.getConnection(""jdbc:jtds:sqlserver://127.0.0.1:1433/Blog"" ""user"" ""password""); and I get this:  java.sql.SQLException: Network error IOException: Connection refused: connect at net.sourceforge.jtds.jdbc.ConnectionJDBC2.<init>(ConnectionJDBC2.java:395) at net.sourceforge.jtds.jdbc.ConnectionJDBC3.<init>(ConnectionJDBC3.java:50) at net.sourceforge.jtds.jdbc.Driver.connect(Driver.java:184) at java.sql.DriverManager.getConnection(Unknown Source) at java.sql.DriverManager.getConnection(Unknown Source) at SqlConnection.Connect(SqlConnection.java:19) at main.main(main.java:11) Caused by: java.net.ConnectException: Connection refused: connect at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.PlainSocketImpl.doConnect(Unknown Source) at java.net.PlainSocketImpl.connectToAddress(Unknown Source) at java.net.PlainSocketImpl.connect(Unknown Source) at java.net.SocksSocketImpl.connect(Unknown Source) at java.net.Socket.connect(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at net.sourceforge.jtds.jdbc.SharedSocket.createSocketForJDBC3(SharedSocket.java:305) at net.sourceforge.jtds.jdbc.SharedSocket.<init>(SharedSocket.java:255) at net.sourceforge.jtds.jdbc.ConnectionJDBC2.<init>(ConnectionJDBC2.java:323) ... 6 more jdbc:jtds:sqlserver://x.x.x.x/database replacing x.x.x.x with the IP or hostname of your SQL Server machine. jdbc:jtds:sqlserver://MYPC/Blog;instance=SQLEXPRESS or jdbc:jtds:sqlserver://MYPC:1433/Blog;instance=SQLEXPRESS If you are wanting to set the username and password in the connection string too instead of against a connection object separately: jdbc:jtds:sqlserver://MYPC/Blog;instance=SQLEXPRESS;user=foo;password=bar (Updated my incorrect information and add reference to the instance syntax) where do you specify the DB name ? i tried but i get an error i posted it in the question As Pratik and Pascal mentioned you should verify that the server is running on port 1433. sqlexpress is not the database name it is the instance name  Really really really check if the TCP/IP protocol is enabled in your local SQLEXPRESS instance. Follow these steps to make sure: Open ""Sql Server Configuration Manager"" in ""Start Menu\Programs\Microsoft SQL Server 2012\Configuration Tools\"" Expand ""SQL Server Network Configuration"" Go in ""Protocols for SQLEXPRESS"" Enable TCP/IP If you have any problem check this blog post for details as it contains screenshots and much more info. Also check if the ""SQL Server Browser"" windows service is activated and running: Go to Control Panel -> Administrative Tools -> Services Open ""SQL Server Browser"" service and enable it (make it manual or automatic depends on your needs) Start it. That's it. After I installed a fresh local SQLExpress all I had to do was to enable TCP/IP and start the SQL Server Browser service. Below a code I use to test the SQLEXPRESS local connection. Of course you should change the IP DatabaseName and user/password as needed.: import java.sql.Connection; import java.sql.DatabaseMetaData; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.SQLException; public class JtdsSqlExpressInstanceConnect { public static void main(String[] args) throws SQLException { Connection conn = null; ResultSet rs = null; String url = ""jdbc:jtds:sqlserver://127.0.0.1;instance=SQLEXPRESS;DatabaseName=master""; String driver = ""net.sourceforge.jtds.jdbc.Driver""; String userName = ""user""; String password = ""password""; try { Class.forName(driver); conn = DriverManager.getConnection(url userName password); System.out.println(""Connected to the database!!! Getting table list...""); DatabaseMetaData dbm = conn.getMetaData(); rs = dbm.getTables(null null ""%"" new String[] { ""TABLE"" }); while (rs.next()) { System.out.println(rs.getString(""TABLE_NAME"")); } } catch (Exception e) { e.printStackTrace(); } finally { conn.close(); rs.close(); } } } And if you use Maven add this to your pom.xml: <dependency> <groupId>net.sourceforge.jtds</groupId> <artifactId>jtds</artifactId> <version>1.2.4</version> </dependency> And make sure that you are using Static port = 1433 - not a dynamic Port under your 'IP All' settings.  A shot in the dark but From the looks of your error message it seems that either the sqlserver instance is not running on port 1433 or something is blocking the requests to that port  As detailed in the jTDS Frequenlty Asked Questions the URL format for jTDS is: jdbc:jtds:<server_type>://<server>[:<port>][/<database>][;<property>=<value>[;...]] So to connect to a database called ""Blog"" hosted by a MS SQL Server running on MYPC you may end up with something like this: jdbc:jtds:sqlserver://MYPC:1433/Blog;instance=SQLEXPRESS;user=sa;password=s3cr3t Or if you prefer to use getConnection(url ""sa"" ""s3cr3t""): jdbc:jtds:sqlserver://MYPC:1433/Blog;instance=SQLEXPRESS EDIT: Regarding your Connection refused error double check that you're running SQL Server on port 1433 that the service is running and that you don't have a firewall blocking incoming connections. your last connection string worked after i've enabled some tcp via pipes in the Protocols for SQLEXPRESS in the sql server configuration manager Thanks mate the first one worked for me using SQL SERVER 2000 add a `instance` property for datasources and don't add the instance to the `databaseName`."
114,A,"Load Java classes based on a classpath in a properties file My application uses JDBC database drivers. I load these from a jar file db2jcc.jar in the case of DB2 which I'm currently working with. With this jar in the classpath everything is fine but I have a requirement to find the jar from a property in the application's config file instead - for example database.driver=/opt/IBM/db2/V9.5/java/db2jcc.jar I can load the class via a URLClassLoader ok but the problem is that I need to treat the object thus created as an explicit DB2XADataSource. For example: URLClassLoader dbClassLoader = new URLClassLoader(new URL[]{driverJar}); xaClass = dbClassLoader.loadClass(""com.ibm.db2.jcc.DB2XADataSource""); DB2XADataSource dataSource = (DB2XADataSource) xaClass.newInstance(); dataSource.setCurrentSchema(DATABASE_SCHEMA); // <- dataSource has to be a dataSource.setDatabaseName(DATABASE_NAME); // DB2XADataSource to do this (rearranged and renamed somewhat; I actually do the loadClass in the constructor of the class that contains this code while the newInstance is in one of its methods.) I guess I'm getting into a classloader tangle because the classloader that loaded my class is trying to find DB2XADataSource in order to do the cast but the URL classloader is not above it in the tree. The trouble is it being long after I should have stopped working for the day (here in the UK) I can't think how best to solve it in a vaguely neat and sane manner. Ideas? Thanks. Yep - the class can't load its own dependencies. You could do some ClassLoader magic but I imagine it would get messy very quickly. One way to reduce the amount of reflection would be to put any code that depends on DB2XADataSource into an implementation that is invoked via an interface available to the calling ClassLoader. //in mydb2driver.jar public class MyDb2Driver implements IDriver { private DB2XADataSource dataSource = new DB2XADataSource(); public void init() { dataSource.setCurrentSchema(DATABASE_SCHEMA); } //etc. } This is loaded with your driver: database.driver=/opt/IBM/db2/V9.5/java/db2jcc.jar:/foo/mydb2driver.jar Invoking code is in the regular classpath: public interface IDriver { public void init(); //etc. } ... URLClassLoader dbClassLoader = new URLClassLoader(new URL[]{driverJar}); xaClass = dbClassLoader.loadClass(""foo.MyDb2Driver""); IDriver dataSource = (IDriver) xaClass.newInstance(); dataSource.init();  The simplest approach is to just use the java.beans API (or direct reflection if you must) to invoke the setter methods. Alternatively: Your database code requires to link to the dynamically loaded code. Therefore dynamically load your database code. How much is up to you. You might load almost everything except the ""bootstrap""."
115,A,Is there an Oracle Open Cursor (ORA-01000) leak in ColdFusion? using CFMX7 and Oracle 10g ent on a query-intensive and active web site I'm having a problem that some of the Oracle connections in my web server connection pool are accumulating open cursors. (In JDBC parlance this might be called a ResultSet object leak.) This is a confusing situation in Oracle; read here for an explanation. http://www.orafaq.com/node/758 Any how it's not cached PreparedStatements that are leaking it's actually ResultSets. My DBAs have set the OPEN_CURSORS parameter to 500 per connection. Fairly frequently my connections get up to 450+ which triggers a DBA alarm (because we hope to avoid smacking web app users with ORA-01000 cursor exhaustion errors). Does anybody know if there's a bug in ColdFusion (MX7) that causes this problem? Is there any way programatically to use CF to generate a ResultSet object leak (called a cfquery leak in CF)? Any suggestions? Here is some information that might be helpful. http://jehiah.cz/a/maximum-open-cursors-exceeded
116,A,"Updating RowSet if table content is changed? Is it possible to update/refresh a RowSet's in case the table content is changed (for e.g. another application modifies it)? So this way I 'always' have an up-to-date version of the table. I looked into RowSetListener but these events seem to get invoked only if I make modifications to the RowSet directly. It would be enough to know that there was a change I know... that's a lot :) Please share your thoughts! Thanks in advance! Daniel No there are no any way for most traditional RDBMS. Just because of http://en.wikipedia.org/wiki/ACID#Isolation  Yes a RowSet can be refreshed. Just call its ""execute()"" method again. Per the docs: If this method is successful the current contents of the rowset are discarded and the rowset's metadata is also (re)set. A rowSetChanged event fires upon this refresh. If you are asking if a RowSet can be automatically refreshed when data is changed on the database server: No way that I know of. You may not want to know of such changes depending on your isolation level locking and MVCC strategy."
117,A,"How to convert Oracle ""TIME"" to JDBC Time in query? Oracle doesn't support the TIME datatype but you can use DATE to store a TIME. My problem: select to_date('2009-06-30' 'YYYY-MM-DD') as ""DATE"" to_date('16:31:59' 'HH24:MI:SS') as ""TIME"" from dual yields: DATE TIME 2009-06-30 2009-08-01 when I run it through JDBC (in SQuirrel SQL in fact). ""2009-08-01"" isn't a very useful time. In my code I can use ResultSet.getTime(). But how can I get the time in a generic query? Is there a way to cast the result? Oracle does not have a ""Time"" datatype. It has a DATE which is the date and time accurate to the second. It also has a Timestamp with greater accuracy. When you perform a to_date() call you get back a...DATE! Depending upon how you have your NLS settings established you can have the text for that date show however you want. The NLS settings control things like date formats timestamp formats currency characters decimal separators etc. Obviously your NLS settings are defined to show the DATE data as yyyy-mm-dd. If you're trying to do generic JDBC stuff with Oracle DATEs you need to specify a ""static"" value for the ""day"" portion of the date and then specify the time as well. Consider this example: String sql = ""Select to_date('1970-01-01 ' || ? 'YYYY-MM-DD HH24:MI:SS) as MY_TIME from dual""; Connection conn = null; //get Connection from somewhere PreparedStatement stmt = conn.prepareStatement(sql); stmt.setString(1 ""16:31:59""); ResultSet rs = stmt.executeQuery(); rs.next(); //get to first element of result set; java.sql.Time myTime = rs.getTime(1); The result of myTime will be a java.sql.Time value containing the value for 16:31:59. Remember to keep the day portion some constant value (like the 1970-01-01 above) so that queries with the Time in the where clause will work properly. Thanks. For some reason I was expecting the Oracle engineers to use a constant day part when I only specify a time in TO_DATE().  If I get the point you could use string Time value: select to_date('2009-06-30' 'YYYY-MM-DD') as ""DATE"" '16:31:59' as ""TIME"" from dual; String time_str = ResultSet.getString(""Time""); java.sql.Time jsqlT = java.sql.Time.valueOf( time_str); it should produce the result you need.  The DATE type is stored as a fractional value -- the date as the integer portion and the time of day as the fractional portion. So every DATE has the time which you can extract with something like this. select TO_CHAR(sysdate 'DD-MON-YYYY HH24:MI:SS') from dual;"
118,A,"Public SQL database for educational purposes I am looking for a publicly available SQL database with free access where one can run some SELECT queries for free on some meaningful data (not item1 item2 item3). Have you seen any? Even better if it came together with some tutorial. Vendor is not that relevant as long as one can connect using a generic JDBC client. Do you mean a hosted version or something that you host yourself? A hosted solution is preferred but I will go for self-hosting as a second choice. Try SQL Exercises Start with learning stage I like this one. This even exceeds my expectations although JDBC connectivity is not provided. I believe their web interface is enough. That's a fab site @msi77. I just worked my way through all the learning exercises and my brain hurts a bit now :) Matt Gibson - Somebody called it as drug but I nevertheless invite you to the rating stages. :-)  If SQL Server is an option then Northwind/Adventureworks are the standard ""training"" DBs. Do a search. For mySql this project looks promising: http://sourceforge.net/projects/awmysql/ Also this might be a dupe: http://stackoverflow.com/questions/2036395/is-there-a-northwind-type-database-available-for-mysql http://stackoverflow.com/questions/2585643/where-can-i-download-northwind-database-for-postgresql  If you're intersted Eve Online a rather large MMO make their static data (in-game items NPCs anything that doesn't really change) available via download. **edit: http://www.eveonline.com/community/toolkit.asp It's a very heavily normalized data set with over a dozen table and thousands of records. If you want to dive into the deep end of enterprise data warehousing I'd recommend this. Downloads as a MS SQL Server 2008 Backup file which can be imported directly into MS SQL Server 2008 Express (The free edition) I do not recommend this if you are brand new to databasing however.  I found SQLZoo which is something similar too.  I suggest to ask your government for some statistical data (just browse their website; there should be plenty). Then import the data in a H2 database and import it. Save the resulting DB files somewhere and give them to your students for their work.  I would suggest setting up Microsoft SQL Server 2008 Express (or the R2) and adding the Northwind or Adventureworks database. It's pretty big so I'm sure you can play with it."
119,A,"Mysql not reconnecting with JNDI Tomcat 6 I am using JNDI with Tomcat6 to manage Mysql connections my Catalina/domain.com/ROOT.xml has: <Resource name=""jdbc/db"" auth=""Container"" type=""javax.sql.DataSource"" username=""db1"" password=""somepass"" driverClassName=""com.mysql.jdbc.Driver"" url=""jdbc:mysql://localhost:3306/db?autoReconnect=true"" maxActive=""15"" maxIdle=""3"" maxWait=""5000"" removeAbandoned=""true"" removeAbandonedTimeout=""20"" /> I though autoReconnect will do the job reconnecting to database but it does not after about 8 hours of inactivity my app spits out lost connection to database errors. Any ideas? Thanks Fedor Dont use autoReconnect. There are problems with it and it's been deprecated. For example you could have a disconnect/reconnect event happen while a thread is using the connection. I would instead have your connection pool test connections with testOnBorrow before passing them to the app. Here is an example: <Resource name=""jdbc/db"" auth=""Container"" type=""javax.sql.DataSource"" username=""db1"" password=""somepass"" driverClassName=""com.mysql.jdbc.Driver"" url=""jdbc:mysql://localhost:3306/db"" maxActive=""15"" maxIdle=""3"" maxWait=""5000"" removeAbandoned=""true"" removeAbandonedTimeout=""20"" logAbandoned=""true"" factory=""org.apache.tomcat.dbcp.dbcp.BasicDataSourceFactory"" validationQuery=""select 1"" minEvictableIdleTimeMillis=""3600000"" timeBetweenEvictionRunsMillis=""1800000"" numTestsPerEvictionRun=""10"" testWhileIdle=""true"" testOnBorrow=""true"" testOnReturn=""false"" /> thank you that will work"
120,A,Can I and should I use Eclipselink for non OR database interactions? We are using Eclipselink for ORM but we have a need for some more lightweight database interactions that are more equivalent to JDBC. My question is whether Eclipselink supports such an idiom and whether there are any advantages of it to straight JDBC. I can see one advantage being consistency and being able to use the existing connection handling. Others? Specifically what I'm looking for is something equivalent to Hibernate's Native SQL Query. EclipseLink implements JPA - you can run SQL queries via an EntityManager. If you start running SQL queries not related to the model of your application you'll have no advantages over JDBC - on the contrary you'll be using a much heavier infrastructure. If you tie the SQL to the model however you'll have the advantage of making additional optimizations to queries utilizing the full db potential. I'm not sure if that's what you want to do however...  If you are using both JPQL and SQL queries in your application then JPA 2 native queries are probably the right approach. Here are some examples : http://www.oracle.com/technology/pub/articles/vasiliev-jpql.html If your app only uses SQL queries and updates then ORM is just an overhead. You can get declarative transactions also differently for example via Spring's JDBC support. But looking at it it appears that using a native query only means that I'm using SQL instead of JPQL. I'm still tied to the/an object model as far as I can see or a single scalar result. If I just want to get a row out of the database do I necessarily have to create a Class to map to the result? I believe for more flexible result set mapping you should consider using Spring JDBC support.
121,A,"MS Jdbc driver sqljdbc 2.0 driver fails to connect to SQL Server 2008 We have a well-defined problem that points to a problem with Microsoft's JDBC 2.0 driver for JDK 1.6 (""sqljdbc4.jar""). I may be wrong. I've been wrong before. I wanted to see if I'm missing anything. any insights? Anyone seen this before? Usecase: use ant ""sql"" task to run a simple sql query. All queries fail jdbc driver throws an exception when connecting: ""The server version is not supported. The target server must be SQL Server 2000 or later."" (stack trace excerpt below) This works fine on sql server versions 2000 and 2005 Data: The only 'players' here are a) ant and b) the jdbc drivers. No custom code. we are using the 2.0 driver i.e. from this file sqljdbc_2.0.1803.100_enu.tar.gz we are using the 'sqljdbc4.jar' version i.e. the version required for JDK6. Md5sum is: 249734b9b7dafaccd92de99eee95d7d6 Sql server's properties are as follows: product version:10.0.2531.0 Productlevel: SP1 Edition: Enterprise Edition We're using a jdbc url that looks like this: ""jdbc:sqlserver://prodsql2;"" (i.e. no extra properties passed at the end) Stack Trace: com.microsoft.sqlserver.jdbc.SQLServerException: The server version is not supported. The target server must be SQL Server 2000 or later. at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDriverError(Unknown Source) at com.microsoft.sqlserver.jdbc.DBComms.Prelogin(Unknown Source) at com.microsoft.sqlserver.jdbc.DBComms.<init>(Unknown Source) at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectHelper(Unknown Source) at com.microsoft.sqlserver.jdbc.SQLServerConnection.loginWithoutFailover(Unknown Source) at com.microsoft.sqlserver.jdbc.SQLServerConnection.connect(Unknown Source) at com.microsoft.sqlserver.jdbc.SQLServerDriver.connect(Unknown Source) at org.apache.tools.ant.taskdefs.JDBCTask.getConnection(JDBCTask.java:31 thanks in advance bill File under ""D"" for ""D'oh!!!"" Turns out someone had a while ago checked in sqljdbc.jar to $ANT_HOME/lib We updated sqljdbc.jar in our application lib directories and pointed the sql task explicitly to that library. < sql classpath='jdbc.classpath' .... /> Ant in fact ignores the classpath setting task and loads the class from $ANT_HOME/lib if it finds it there. This log message threw me off. It suggested that ant in fact looked ""in the place I specified"". In fact it looked in ANT_HOME/lib. Loading com.microsoft.sqlserver.jdbc.SQLServerDriver using AntClassLoader with classpath c:\projects\devtools\mssql_jdbc\sqljdbc_2.0.1803.100\sqljdbc_2.0\enu\sqljdbc4.jar Sorry. bill"
122,A,"Data type not found error in JDBC connection in java? I am using Microsoft Access database for storing data. In that I stored date as ""DATE/TIME"" data type. While getting date from the following code it produces error..  String sql = ""Select prev_date from StaffAdvance where Staff_ID='""+date+""'""; ResultSet rs = st.executeQuery(sql); What is wrong with this code? Staff_ID is a date? (btw posting the full stacktrace is always a good idea). Yes Staff_ID is date.. what is the type of a date object. is it java.util.Date or java.sql.Date It is java.util.Date.. Staff_ID has no proper business being a date... Think what you're doing... Yes Mr. Martin Milan.. I used no proper name but used correct way in application.. As you told the type of date object is java.util.Date change the type to java.sql.Date and try. Yes i got it.. My friend told should use ""#"" instead of ""'"" in that query.. That is String sql = ""Select prev_date from StaffAdvance where Staff_ID=#""+date+""#""; ResultSet rs = st.executeQuery(sql); did you change the type of date to sql.Date Yes But i didn't got date. After changing # only it produces the result.. The hash marks work because this is the date delimiter for Jet/ACE SQL."
123,A,Can JDBC connection strings specify multiple databases? Here's my current connection string: jdbc:amazon;moduleName=Foobar:oracle:thin:@ab1na-orasvr.db.foobar.com:42111:ab1na But I need JDBC to access multiple databases. Can I simply append the second module name separated by a semi-colon? Sorry this is a really basic yes/no question. Just want to be sure before I go chasing my tail. No I don't think you can do this. You can do this with Hibernate though by creating multiple persistence units and creating entity managers based on the name you give each unit. http://schuchert.wikispaces.com/JPA+Tutorial+1+-+Persistence+Unit  jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS_LIST = (ADDRESS =(PROTOCOL=TCP) (HOST=1)(PORT=1521))(ADDRESS=(PROTOCOL=TCP) (HOST=2)(PORT=1521))(ADDRESS =(PROTOCOL=TCP) (HOST=3)(PORT=1521))(ADDRESS =(PROTOCOL=TCP) (HOST=4)(PORT=1521))(ADDRESS =(PROTOCOL=TCP) (HOST=5)(PORT=1521))(ADDRESS =(PROTOCOL=TCP) (HOST=6)(PORT=1521))(ADDRESS =(PROTOCOL=TCP) (HOST=7)(PORT=1521))(ADDRESS =(PROTOCOL=TCP) (HOST=8)(PORT=1521))(FAILOVER=on) (LOAD_BALANCE=ON)) (CONNECT_DATA = (SERVER=DEDICATED) (SERVICE_NAME =ccbfsinterface.comp.pge.com)))
124,A,"What is the best way to encrypt a clob? I am using Oracle 9 and JDBC and would like to encyrpt a clob as it is inserted into the DB. Ideally I'd like to be able to just insert the plaintext and have it encrypted by a stored procedure: String SQL = ""INSERT INTO table (ID VALUE) values (? encrypt(?))""; PreparedStatement ps = connection.prepareStatement(SQL); ps.setInt(id); ps.setString(plaintext); ps.executeUpdate(); The plaintext is not expected to exceed 4000 characters but encrypting makes text longer. Our current approach to encryption uses dbms_obfuscation_toolkit.DESEncrypt() but we only process varchars. Will the following work? FUNCTION encrypt(p_clob IN CLOB) RETURN CLOB IS encrypted_string CLOB; v_string CLOB; BEGIN dbms_lob.createtemporary(encrypted_string TRUE); v_string := p_clob; dbms_obfuscation_toolkit.DESEncrypt( input_string => v_string key_string => key_string encrypted_string => encrypted_string ); RETURN UTL_RAW.CAST_TO_RAW(encrypted_string); END; I'm confused about the temporary clob; do I need to close it? Or am I totally off-track? Edit: The purpose of the obfuscation is to prevent trivial access to the data. My other purpose is to obfuscate clobs in the same way that we are already obfuscating the varchar columns. The oracle sample code does not deal with clobs which is where my specific problem lies; encrypting varchars (smaller than 2000 chars) is straightforward. There is an example in Oracle Documentation: http://download.oracle.com/docs/cd/B10501_01/appdev.920/a96612/d_obtoo2.htm You do not need to close it DECLARE input_string VARCHAR2(16) := 'tigertigertigert'; raw_input RAW(128) := UTL_RAW.CAST_TO_RAW(input_string); key_string VARCHAR2(8) := 'scottsco'; raw_key RAW(128) := UTL_RAW.CAST_TO_RAW(key_string); encrypted_raw RAW(2048); encrypted_string VARCHAR2(2048); decrypted_raw RAW(2048); decrypted_string VARCHAR2(2048); error_in_input_buffer_length EXCEPTION; PRAGMA EXCEPTION_INIT(error_in_input_buffer_length -28232); INPUT_BUFFER_LENGTH_ERR_MSG VARCHAR2(100) := '*** DES INPUT BUFFER NOT A MULTIPLE OF 8 BYTES - IGNORING EXCEPTION ***'; double_encrypt_not_permitted EXCEPTION; PRAGMA EXCEPTION_INIT(double_encrypt_not_permitted -28233); DOUBLE_ENCRYPTION_ERR_MSG VARCHAR2(100) := '*** CANNOT DOUBLE ENCRYPT DATA - IGNORING EXCEPTION ***'; -- 1. Begin testing raw data encryption and decryption BEGIN dbms_output.put_line('> ========= BEGIN TEST RAW DATA ========='); dbms_output.put_line('> Raw input : ' || UTL_RAW.CAST_TO_VARCHAR2(raw_input)); BEGIN dbms_obfuscation_toolkit.DESEncrypt(input => raw_input key => raw_key encrypted_data => encrypted_raw ); dbms_output.put_line('> encrypted hex value : ' || rawtohex(encrypted_raw)); dbms_obfuscation_toolkit.DESDecrypt(input => encrypted_raw key => raw_key decrypted_data => decrypted_raw); dbms_output.put_line('> Decrypted raw output : ' || UTL_RAW.CAST_TO_VARCHAR2(decrypted_raw)); dbms_output.put_line('> '); if UTL_RAW.CAST_TO_VARCHAR2(raw_input) = UTL_RAW.CAST_TO_VARCHAR2(decrypted_raw) THEN dbms_output.put_line('> Raw DES Encyption and Decryption successful'); END if; EXCEPTION WHEN error_in_input_buffer_length THEN dbms_output.put_line('> ' || INPUT_BUFFER_LENGTH_ERR_MSG); END; dbms_output.put_line('> '); This doesn't really answer the question; for one it doesn't use CLOBS and for two it doesn't have the same semantics as the original function: function encrypt (plaintext in clob) returning clob -- returns cypher text  Slightly off-topic: What's the point of the encryption/obfuscation in the first place? An attacker having access to your database will be able to obtain the plaintext -- finding the above stored procedure will enable the attacker to perform the decryption. The goal here is more about preventing users with authorized access from accidentally revealing sensitive data. The key should not be stored in your database but passed in from the application. I agree with the comment but the original code isn't passing any keys to the encryption function. Having a backup with the unencripted data can be a security problem. Anyway I agree that the document will travel unencripted over the network but for that purpose is better to encrypt the whole connection with https. Decent sysadmins encrypt backups anyway -- you don't need to have the database data encrypted to have the backups of the database encypted. It appears here that the goal of encryption here is to prevent users having unauthorized access to the database from reading the CLOBs.  I note you are on Oracle 9 but just for the record in Oracle 10g+ the dbms_obfuscation_toolkit was deprecated in favour of dbms_crypto. dbms_crypto does include CLOB support: DBMS_CRYPTO.ENCRYPT( dst IN OUT NOCOPY BLOB src IN CLOB CHARACTER SET ANY_CS typ IN PLS_INTEGER key IN RAW iv IN RAW DEFAULT NULL); DBMS_CRYPT.DECRYPT( dst IN OUT NOCOPY CLOB CHARACTER SET ANY_CS src IN BLOB typ IN PLS_INTEGER key IN RAW iv IN RAW DEFAULT NULL);"
125,A,"How do I setQueryTimeout on SimpleJdbcTemplate? The Spring Framework has two similar classes: JdbcTemplate is the old Java 1.4 class and SimpleJdbcTemplate is newer with nicer methods. JdbcTemplate has a method setQueryTimeout which basically gives me access to a method with the same name on the underlying Statement object. Is there any way to do something similar with a SimpleJdbcTemplate? Solution: Based on skaffman's answer I create the SimpleJdbcTemplate object myself from a JdbcTemplate so now I can do whatever I want. Code: JdbcTemplate jdbcTemplate = this.getJdbcTemplate(); jdbcTemplate.setQueryTimeout(30); SimpleJdbcTemplate simpleJdbcTemplate = new SimpleJdbcTemplate(jdbcTemplate); A bit of a mouthful but gets the job done. Update: This is indeed more complicated than necessary. See the answer. Proably more complex than necessary see my edited answer. What is the unit for the query timeout? @akirekadu - seconds. SimpleJdbcTemplate isn't a replacement for JdbcTemplate it's just a java5-friendly supplement to it for certain operations which can take best advantage of varargs and generics. If you look at the source for SimpleJdbcTemplate you'll see that it delegates all of its work to a JdbcTemplate object and so by setting the timeout (or the other options) on JdbcTemplate you implicitly set them on the SimpleJdbcTemplate also. If you're obtaining the SimpleJdbcTemplate via SimpleJdbcDaoSupport.getSimpleJdbcTemplate() then the JdbcTemplate will already have been wired up correctly. edit: For example: public class MyDao extends SimpleJdbcDaoSupport { public void doStuff() { getJdbcTemplate().setQueryTimeout(x); getSimpleJdbcTemplate().execute(...); } } The SimpleJdbcTemplate contains the same JdbcTemplate as is retrieved by getJdbcTemplate(). If you don't extend SimpleJdbcDaoSupport then yes you need to manually construct a SimpleJdbcTemplate yourself. But how do I access the JdbcTemplate thats ""trapped"" inside the SimpleJdbcTemplate? All I have is access to a JdbcOperations interface which doesn't have setTimeout. Care to show some code? You didn't mention that in your question you were asking about SimpleJdbcTemplate. Please modify your question to clarify what you actually want. No my comment was unclear. I meant that having a SimpleJdbcTemplate object all I have is the `getJdbcOperations()` method. There's no `getUnderlyingJdbcTemplate()` method. Anyway I think I got it (see update in question). Thanks!"
126,A,"Putting timeouts on Prepared statements I am trying to use prepared statements which operate on a database located quite far away there is considerable lag and unreliability involved in the network connection used to access this database. Downtimes of up to a minute are common. The problem is that in case of such a failure if my program tries to execute any prepared statement the whole thread goes into infinite wait. It never times out and just remains stuck waiting for a response from the database. I tried using the method setQueryTimeout() to explicitly put a timeout on the execution but seems there is some problem with this method wherein it cant work properly if the network fails. Is there any alternative way around this ? Are there any alternative ways to get around this problem  also  i am not really inclined to use a transaction Manager  because it seems to be overkill for a simple timeout In my knowledge there is no such alternative if the network itself fails. The exact details of setQueryTimeout involve the JDBC driver being instructed to send an Out Of Band signal (atleast in the case of the Oracle JDBC driver) to the database to halt the execution of the Prepared Statement; this part is important as it depends on the support built into the driver and the database. Following this it is upto the database to schedule execution of this 'cancel' operation; this could take a while if things have to be rolled back or if other transactions have to be executed etc. Given the first part of the nature of the implementation it is quite unlikely that a ""clean"" implementation of a timeout feature can be established. You might want to investigate the use of a transaction manager here (JTA perhaps) but I'm not sure if will encounter another set of bizarre exceptions (think heuristic exceptions). Addendum Using a thread monitor that monitors the execution of other threads and kills the 'stuck' threads might be a bad idea. This SO question would help answer why such an activity should be avoided. This is also the tactic chosen by WebLogic Server. Are there any alternative ways to get around this problem  also  i am not really inclined to use a transaction Manager  because it seems to be overkill for a simple timeout. If your database allows for it establish a cap on the amount of time that a query can execute. The Oracle DB allows for this via the use of resource plans that specify the value of the MAX_EST_EXEC_TIME - queries that exceed the limit specified as the MAX_EST_EXEC_TIME value. will result in the Oracle session being killed."
127,A,"How do you access the value of an SQL count () query in a Java program I want to get to the value I am finding using the COUNT command of SQL. Normally I enter the column name I want to access into the getInt() getString() method what do I do in this case when there is no specific column name. I have used 'AS' in the same manner as is used to alias a table I am not sure if this is going to work I would think not. Statement stmt3 = con.createStatement(); ResultSet rs3 = stmt3.executeQuery(""SELECT COUNT(*) FROM ""+lastTempTable+"") AS count""); while(rs3.next()){ count = rs3.getInt(""count""); } Use aliases: SELECT COUNT(*) AS total FROM .. and then rs3.getInt(""total"")  The answers provided by Bohzo and Brabster will obviously work but you could also just use: rs3.getInt(1); to get the value in the first and in your case only column. From Javadoc: ""Values can be retrieved using either the index number of the column or the name of the column. In general using the column index will be more efficient."" This level of performance tuning really isn't important for most applications. Using column indexes exposes you to errors from columns moving around in your SQL query which can be difficult to trace down. In this particular example (merely grabbing a record count) this isn't a problem but it's something to keep in mind for application sustainability. @PederRicer couldn't agree more. Far too often people focus on micro-optimisations when clarity should (almost always) be the main goal of code  I would expect this query to work with your program: ""SELECT COUNT(*) AS count FROM ""+lastTempTable+"")"" (You need to alias the column not the table)  Statement stmt3 = con.createStatement(); ResultSet rs3 = stmt3.executeQuery(""SELECT COUNT(*) AS count FROM ""+lastTempTable+"" ;""); count = rs3.getInt(""count"");  I have done it this way (example): String query=""SELECT count(t1.id) from t1 t2 where t1.id=t2.id and t2.email='""r@r.com""'""; int count=0; try { ResultSet rs = DatabaseService.statementDataBase().executeQuery(query); while(rs.next()) count=rs.getInt(1); } catch (SQLException e) { e.printStackTrace(); } finally { //... }"
128,A,"How to SELECT items from from an array (IN clause details)? I would like to do something in Java (using iBatis JDBC etc. really in SQL) like: SELECT SUM(rowName) FROM myTable WHERE id = [myArrayOfIds] Where myArrayOfIds can be almost any length. Now I know you can do: SELECT SUM(rowName) FROM myTable WHERE id IN (x y z) but what happens for longer lists? For example my list could be as little as a few items to hundreds or more items. How can I do this? I think it depends on your flavour of SQL. For instance Oracle does not allow more than 1000 values in an IN() list. Other flavours may vary.  Oracle definitely allows more than 1000 items in the IN clause. It's your persistence tool that is limiting this. iBatis or Hibernate whatever. Use Oracle Sqlplus and you'll see this is not an Oracle limit. Suggestion from BlackTigerX would work or you could call the query multiple times passing 1000 items at a time and aggregating the results. Either way you're just working around your persistence tool limitation. No it doesn't. Oracle allows a maximum of 1000 values in the in clause.  one alternative would be to insert those ids to a table then do a join SELECT SUM(rowName) FROM myTable ta inner join tempTable tb on ta.id = tb.id it's still the same problem you've just moved the array (IN) to the insert command. you can't do inserts using ""in"" but you can build a batch of statements within a transaction I'd say test first to see if the performance is actually bad I have done similar select statements using ""in"" and the performance is good enough that I don't have to try other alternatives batching is great if you can do it at set times but as part of a normal day to day usage you wouldn't want to do that on a system. Generally when you're doing updates it's based on user interaction to which I wouldn't recommend the use of batching..."
129,A,"Can I ask JDBCTemplate to expand a list parameter for use in an in() clause? Can I do something like this: select * from mytable m where m.group_id in (?) ... and pass in a list or array of arguments to be expanded in to my parameter ie: select * from mytable m where m.group_id in (1234) Specifically I'm using Spring and the JdbcTemplate/SimpleJdbcTemplate classes. My recollection is No - the `?` placeholder signifies a single value as it would in SQL so it can't contain a comma separated list. Possible duplicate of both http://stackoverflow.com/questions/1981683/how-to-generate-a-dynamic-in-sql-list-through-spring-jdbctemplate and http://stackoverflow.com/questions/1327074/how-to-execute-in-sql-queries-with-springs-jdbctemplate-effectivly Sorry can't do that. You can write yourself a convenience method to do that but there's no setParameterList() like Hibernate as far as I know. The simplest convenience method for a list of numeric types might be list.toString().replace(""[""""("").replace(""]"""")"")  Please find the below code IN CLAUSE EXAMPLE public Collection<Employee> findByIds(List<String> ids) { Map<String Object> params = new HashMap<String Object>(); params.put(""ids"" ids); List<Employee> employees = namedParameterJdbcTemplate.query( ""SELECT * FROM trn_employee where employee_id IN (:ids)"" params ParameterizedBeanPropertyRowMapper.newInstance(Employee.class)); return employees; }  Yes you can in Spring 3 using a named parameter. See http://static.springsource.org/spring/docs/3.0.x/spring-framework-reference/html/jdbc.html#jdbc-in-clause It should take any list of primitives and expand the list. Just be careful that your list does not go over the max size your DB supports. (Oracle limit is 1000). Something like this should work:  List<Integer> ids = new ArrayList<Integer>(); ids.add(1); ids.add(2); ids.add(3); Map<StringObject> params = new HashMap<String Object>(); String sql = ""SELECT PERSON.ID PERSON.USERNAME PERSON.EMAIL_ADDRESS PERSON.FIRST_NAME PERSON.LAST_NAME PERSON.ACCOUNT_STATUS FROM PERSON WHERE ID IN (:ids)""; params.put(""ids""ids); return getSimpleJdbcTemplate().query(sql rowMapper params);  You can do it by using NamedParameterJdbcTemplate. With your sample it would go something like: NamedParameterJdbcTemplate db = ...; List paramList = ...; Map idsMap = Collections.singletonMap(""ids"" paramList); db.query(""select * from mytable m where m.group_id in (:ids)"" idsMap);"
130,A,What would cause this query to stop working? I'm working with a legacy Java app that's pulling data from Oracle. One of the queries appears to no longer work: select {hier.*} from ecadmin.dept_hier_cache hier connect by prior parent_deptid = deptid start with deptid = '1234'; When I remove the '{}' brackets from around hier.* everything works as normal. Now as far as I can tell the app hasn't changed for over a year so this means a change to Oracle is the most likely culprit. Any ideas on what might have changed? Version upgrade a setting was changed something else? Is it possible that it has never worked but noone has ever pushed that button? No the button has definitely been pushed regularly...;) As far as I can tell that never would have worked. It was never valid syntax and I can't understand why anyone would even try curly brackets in the code. Assuming you have source control I'd check whether the code ever had a version without the brackets. If so I'd suspect that the code got changed in the source but never promoted. Possibly the string got filtered/cleaned before being executed. Can you tell when it stopped working and what happened around that date ? The code has apparently not been changed since 2006 and the {} are there since almost the beginning of the CVS history. I know it stopped working at the start of 2010 after a bunch of systems were changed (the company split into two separate corporations). I was thinking that the oracle DBs might have been updated to a newer version or had the settings tweaked in some way... Now that I look more closely it's possible that the code was never actually run before and the recent data changes could have caused it to be called for the first time. If this was never valid syntax then I guess this is probably what happened. Ah the joy's of working with somebody else's non-tested code... AgreeI've been using Oracle for over 15 years and I've never seen the curly braces in any query.  The only thing I see about the curly brace syntax with Oracle and JDBC is here under Embedded SQL92 Syntax. Like Gary says I would not expect right off hand for that query to execute regardless. But potentially has the underlying Oracle driver or version of Oracle changed? Have the columns in that table dept_hier_cache changed so that the .* now returns something entirely different than it used to? Is dept_hier_cache a view? If so has the view or the permissions of the users regarding that view changed?
131,A,"Finding Installed JDBC Drivers I'm writing a database validation tool in Java and have preference screens so the user can define their database connections. The tool should be able to cope with DB2 Oracle Postgresql and Mysql as a minimum. What I would really like is to be able to present the user with a list of their installed jdbc drivers as part of this process. Can anyone supply a code snippet for discovering installed JDBC drivers ? This should help: java.sql.DriverManager.getDrivers() Since this is IMHO incorrectly accepted I would only emphasize more: this works *only* if the drivers are **actually** loaded; either manually by `Class#forName()` or automagically by `META-INF/services`. This does NOT detect drivers which *are* in classpath but which are *not* loaded.  To the point you need to scan the entire classpath (and subfolders) for classes implementing java.sql.Driver. This way you will also cover drivers which are not loaded manually by Class#forName() or automagically by META-INF/services. Here's a basic example: public static void main(String[] args) throws Exception { List<Class<Driver>> drivers = findClassesImplementing(Driver.class); System.out.println(drivers); } public static <T extends Object> List<Class<T>> findClassesImplementing(Class<T> cls) throws IOException { List<Class<T>> classes = new ArrayList<Class<T>>(); for (URL root : Collections.list(Thread.currentThread().getContextClassLoader().getResources(""""))) { for (File file : findFiles(new File(root.getFile()) "".+\\.jar$"")) { JarFile jarFile = new JarFile(file); for (JarEntry jarEntry : Collections.list(jarFile.entries())) { String name = jarEntry.getName(); if (name.endsWith("".class"")) try { Class<?> found = Class.forName(name.replace(""/"" ""."").replaceAll(""\\.class$"" """")); if (cls.isAssignableFrom(found)) { classes.add((Class<T>) found); } } catch (Throwable ignore) { // No real class file or JAR not in classpath or missing links. } } } } return classes; } public static List<File> findFiles(File directory final String pattern) throws IOException { File[] files = directory.listFiles(new FileFilter() { public boolean accept(File file) { return file.isDirectory() || file.getName().matches(pattern); } }); List<File> found = new ArrayList<File>(files.length); for (File file : files) { if (file.isDirectory()) { found.addAll(findFiles(file pattern)); } else { found.add(file); } } return found; } Instead you can also consider to use the Google Reflections API which does this all in a single line: Set<Class<? extends Driver>> drivers = reflections.getSubTypesOf(Driver.class); In this solution aren't you executing static blocks on the classes you are testing? Yes they would get executed. You can't go around that. Minor (very minor) comment: ""//."" doesn't seem to work in a regex pattern - but substituting "".+[.]jar$"" for "".+\\.jar$"" works OK Thx bigtime BalusC It should be `\\.` not `//.`. The code snippet is an exact copypaste and just works fine here. my exact copypaste doesn't ! - I don't know why - but you're right I mistyped ""//."" instead of ""\\."" in my comment. A couple more comments : 1. getContextClassLoader().getResources("""") only returns directory names from the classpath specified jar files are not returned. I've substituted a method based on System.getProperty(""java.class.path"") to retrieve all of the named jar files in the classpath as well as the dirs 2. I added an ""if (directory.canRead()) {"" statement at the top of the findFiles method which stops null pointer exceptions (I know this shouldn't happen but then again.... ) ...but I've gotta say this is a great code snippet Sure I already protected myself by saying ""basic example"" ;) Good luck and happy coding. Also if your directories contain spaces you may want to URL decode the directory name before trying to find files in it the directory.  java.sql.DriverManager.getDrivers() is not all. As the doc says Retrieves an Enumeration with all of the currently loaded JDBC drivers to which the current caller has access. That means loaded drivers (with Class.forName()) not installed (say available thru a JAR). Normally you would deliver your software with all JDBC driver jars that your program can work. Dependent what the user will connect to (oracle access db2) the program must load the appropiated driver. I was under the impression that distributing 3rd party drivers in my own jars would violate copyright - or something legal anyway Actually it'll include drivers referred to via the `jdbc.drivers` system property and those made available through the service provider (`META-INF/services`) mechanism."
132,A,Regular expressions in JDBC I have a java-application using JDBC for database interaction. I want to do a search based on a series of regular-expressions however the application should be generic we do not know if the database-engine will by mysqloraclesql server etc but we are pretty sure it's gonna be either mysql or oracle. Will regular-expressions limit my application to a specific database or can i use them without worrying about compatibility? Well using regular expressions will limit you to DBMS that support them :-). That said at least Oracle MySQL PostgreSQL and MS-SQL support some sort of regexp so it should not be a problem in principle. You might still run into compatibility problems of course. Your best bet probably is to confine the use of regular expressions to some defined parts of the application such as a few stored procedures or one module in your app that generates the SQL queries. That is good practice anyway and will make later changes doable.  Yes using non-standard SQL features like regular expression search will limit your application to a specific database. Like slekse suggested a good solution is to confine your use of non-standard SQL features to one specific module. Then you'll only need to change that module if you change DBMS.  While in theory I believe both MySQL and Oracle are meant to support POSIX ERE MySQL uses REGEXP where Oracle uses REGEXP_LIKE and regular-expressions.info notes quirks with Oracle's implementation (there are likely similar ones for MySQL). So you probably can't use this.
133,A,"Lightweight Java database with Maven plugin for starting/stopping? For unit tests demonstrations and Hibernate tasks I would like to use a small and simple Java database like Derby / Java DB or HSQLDB which can be called from within Maven. So far I have not found a Maven plugin which can download and launch Java DB (which is my favorite at the moment) or something similar. why would you need a plugin to start a specific db?? continuous integration unit tests demonstrations with as little interaction and configuration as possible - just launch ""mvn test"" and then use JPA to create a table for example I've no idea whether it supports what you need but SQLite is so immensely popular that it seems to have integration plugins with about anything. Check it out.  As described in my answer here you can use Derby as your database via the derby-maven-plugin which I wrote and is available on GitHub and via Maven Central. With Derby as your in-memory database for tests you life would be simple in terms of CI -- no need to install and setup an external bit of software just for your tests when you can just do it all with Maven.  An simple setup for unit tests is to start hsqldb in memory: db.connection.driver_class=org.hsqldb.jdbcDriver db.connection.url=jdbc:hsqldb:mem:aname db.connection.username=sa db.connection.password= hibernate.dialect=org.hibernate.dialect.HSQLDialect No start and stop needed. The JDBC driver will ""start"" the database. You could use that for demonstrations too. If you're initializing the database while the applications starts. The database setup can be done with hibernate.hbm2ddl.auto. Edit by kdgregory: To have Maven include HSQLDB in the dependencies for the test phase only use this in your POM: <dependency> <groupId>hsqldb</groupId> <artifactId>hsqldb</artifactId> <version>1.8.0.7</version> <scope>test</scope> </dependency>"
134,A,Options to Replicate Microsoft SQL Server Database to MySQL/PostgreSQL on Linux I need to replicate data from Microsoft SQL Server to MySQL or PostgreSQL. The data includes images stored in BLOB columns. Could you please comment on your experiences with the following strategies and suggest others I may have missing? custom script written in Java using JDBC linux odbc driver with perl script Setup my own windows box and use SSIS or DTS w/Postgres ODBC driver write .net program and schedule execution on Windows machine FreeTDS Looking at SQL Server Replication Technologies you can use Non-SQL Server Subscribers although only Oracle and DB2 are officially supported at this time custom solutions have been implemented successfully. http://msdn.microsoft.com/en-us/library/ms151835.aspx Using SQL Server Integration Services would be a good approach in my opinion. You could easily create custom components to interface with Non-SQL Server Subscribers if necessary.  You can also follow instructions from http://blog.hagander.net/archives/103-Replicating-from-MS-SQL-Server-to-PostgreSQL.html I had to re-create table msrepl7 changing fields indagent and subtype to type integer (some problem with character = integer query on Postgres 8.3) Good luck.  Python has good libraries for all three databases and SQLAlchemy makes writing db stuff easy. I use freetds and unixodbc for SQL Server. If you actually want the same table structure SQLAlchemy makes this particularly easy as you can define the structure once in a generic way and have it create the structure in each of the three databases. The FreeTDS driver doesn't support BLOBs and I can't create any tables or views on the source db. I will take a look at SQLAlchemy. Thanks for the tip.
135,A,"Creating package-level associative array in java Is it possible to create a java representation of a package-level oracle associative array. For example given the following: CREATE OR REPLACE PACKAGE MyPackage AS TYPE t_numbers IS TABLE OF NUMBER INDEX BY PLS_INTEGER; I find I cannot write the following java: ArrayDescriptor descriptor = ArrayDescriptor.createDescriptor(""MyPackage.t_numbers"" connection); (throws a SQLException ""Invalid name pattern""). What is the correct syntax for an ArrayDescriptor referencing a package-level associative array? Does such a thing even exist? See http://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:3696816290928 and especially http://download.oracle.com/docs/cd/B10501_01/java.920/a96654/oci_func.htm#1017512 . Second link was spot on thanks. To summarize - don't use ArrayDescriptor when referencing package-level associative arrays. Cast the callable statement to an OracleCallableStatement and use setPlsqlIndexTable. Doesn't support records though... @Andy many thanks for your comment. It helped me solve the same issue you had even with link rot affecting the answer's second link."
136,A,"Are enums supported by JDBC? I really can't find a nice enum JDBC mapping example. Is enum actually supported by JDBC? I am working with MySQL. I have an enum column and would like to map to some Java enum. JDBC does not support enums. You can convert a string to an enum though so if you have a Java enum you can do something like  MyEnum enumVal = MyEnum.valueOf(rs.getString(""EnumColumn"")); You'll have to keep your java enum and mysql enum in sync though. MyEnum.valueOf() can throw IllegalArgumentException if there's no mapping from the string or NullPointerException if you get a null value from the db.  Here is some generic solution were are using in converting JDBC values to Java enums. param = Enum.valueOf((Class<? extends Enum>)dbField.getField().getType() (String) param); where param is the value of the field in the db  and the dbField is the java.reflect.util.Field  where to put the value to"
137,A,"Oracle doesn't remove cursors after closing result set Note: we reuse single connection. ************************************************ public Connection connection() {                try {            if ((connection == null) || (connection.isClosed()))            {               if (connection!=null) log.severe(""Connection was closed !"");                connection = DriverManager.getConnection(jdbcURL username password);            }        } catch (SQLException e) {            log.severe(""can't connect: "" + e.getMessage());        }        return connection;            } ************************************************** public IngisObject[] select(String query String idColumnName String[] columns) { Connection con = connection(); Vector<IngisObject> objects = new Vector<IngisObject>(); try {     Statement stmt = con.createStatement();     String sql = query;     ResultSet rs =stmt.executeQuery(sql);//oracle increases cursors count here     while(rs.next()) {        IngisObject o = new IngisObject(""New Result"");        o.setIdColumnName(idColumnName);                    o.setDatabase(this);        for(String column: columns) o.attrs().put(column rs.getObject(column));        objects.add(o);        }     rs.close();// oracle don't decrease cursor count here while it's expected     stmt.close();     } catch (SQLException ex) {     System.out.println(query);     ex.printStackTrace(); } Are you refering to ""ORA-01000: maximum open cursors exceeded""? If so see http://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:685336504294 for an explanation. @Oliver Michels that looks helpful. Could you add it as an answer? It tried to write a short summary. Best Regards. The init.ora parameter open_cursors defines the maximum of opened cursors a session can have at once. It has a default value of 50. If the application exceeds this number the error ""ORA-01000: maximum open cursors exceeded"" is raised. Therefore it's mandatory to close the JDBC resources when they are not needed any longer in particular java.sql.ResultSet and java.sql.Statement. If they are not closed the application has a resource leak. In case of reusing the Connection object you must be aware of the fact that the opened oracle cursors are kept open and in use as long the connection exists and the transaction has not ended. When the application commits the opened cursors are released. Therefore as an application designer you need to know a rough estimation of the needed open cursors for your most complex transaction. The difficulty lies in the inability of oracle's internal parameter views (v$open_cursor v$sesstat et. al.) to show the difference between opened cursors which are reusable and opened cursors which are still blocked (not reusable!) by an unclosed ResulSet or Statement. If you close all Statement and ResultSet objects in your finally block your application is perfectly fine. Adjusting the init.ora parameter works like this (our application needs 800 cursors at a maximum) ALTER SYSTEM SET open_cursors = 800 SCOPE=BOTH; I think it should be emphasized that one has to close ResultSet **AND** Statement.  The correct way to do it is to close every resource in a finally block in its own try/catch block. I usually use a static utility class like this: public class DatabaseUtils { public static void close(Connection connection) { try { if (connection != null) { connection.close(); } } catch (SQLException e) { // log exception here. } } // similar methods for ResultSet and Statement } So I'd write your code like this: public IngisObject[] select(String query String idColumnName String[] columns) { Vector<IngisObject> objects = new Vector<IngisObject>(); Connection con = null; Statement stmt = null; ResultSet rs = null; try { connection = connection(); stmt = con.createStatement(); // This is a SQL injection attack waiting to happen; I'd recommend PreparedStatemen String sql = query; rs =stmt.executeQuery(sql);//oracle increases cursors count here while(rs.next()) { IngisObject o = new IngisObject(""New Result""); o.setIdColumnName(idColumnName); o.setDatabase(this); for(String column: columns) o.attrs().put(column rs.getObject(column)); objects.add(o); } } catch (SQLException ex) { System.out.println(query); ex.printStackTrace(); } finally { DatabaseUtils.close(rs); DatabaseUtils.close(stmt); DatabaseUtils.close(con); }  I just had the same problem and found that - if you do not close the connection (because you will maybe reuse it later on) - you at least have to do a connection.rollback() or connection.commit() to free the open cursors togehther with closing the ResultSet and Statements. @Amandeep Jiddewar Of corse you should close the ResultSet. But as the question is about open cursors after closing the ResultSet I just pointed out that you also have to do a connection rollback/commit to free the cursor. So nothing to contradict :-) I would contradict with your opinion it is always better to close your ResultSet instead of depending on Garbage Collector to do it for you.  Normally you would put the close statements for your ResultSet and Statement into a finally block to ensure that they are called even if an exception occurs (could be the issue you are having here). In your current code if a SQLException occurs then the two close( ) method calls will never occur and cursors would be left open. Also what query are you using in Oracle to see the count of open cursors? Edit: That code should be closing the cursor. If it isn't then you should be able to see a 1 to 1 correlation of calling your method and the cursor count going up by 1. Be sure there isn't some unexpected process that is causing the cursor count to go up. If you have the privileges you can run this query against the database to see the open cursor count by sid to see if maybe it is some other process that is increasing the cursors and not yours specifically. It will pull back any with more than 10 cursors open you can raise this to filter out the noise or narrow it specifically by username or osuser: select oc.sid count(*) numCur s.username username s.osuser osuser oc.sql_text s.program from v$open_cursor oc v$session s where s.sid = oc.sid group by oc.sid oc.sql_text s.username s.osuser s.program having count(*) > 10 order by oc.sid; Another query that may be helpful in case multiple sid's are using the same query string so the above does not reveal the offender well:  select oc.sql_text count(*) from v$open_cursor oc group by oc.sql_text having count(*) > 10 order by count(*) desc; @Vladimir: I added additional info to my answer. Your code should be working if no exception is being thrown. Look at the sid level and make sure it is your process alone that is affecting the cursor count. thank you. I will try that. @Dougman I am using Oracle database manager console. I know that it's better to close them in finally. But excpetion is not an issue. It doesn't occur in my testing. this query helped me figure out the problem (in the end I was accidentally ""leaking"" preparedstatements in java oops)"
138,A,"Oracle ADF on JBoss: Wrapped Jdbc Connection problem I'm trying to run an application using Oracle ADF Business Components on a JBoss Server. I've maneged to deploy it but when I try to load the page I get this: java.lang.ClassCastException: org.jboss.resource.adapter.jdbc.jdk6.WrappedConnectionJDK6 cannot be cast to oracle.jdbc.OracleConnection Is there a way solve this? Maybe configure JBoss to not use this wrapped connection or configure the ADF framework to unwrap it? This is a while back but I'll just follow up on my own question. There is a guide on Oracle Metalink (Needs login) wich explains how to deploy ADF/BC on JBoss. I'm pretty sure this is what solved this for me (it's a while ago..) Here is a copy of it: Abstract The purpose of this note is to show how you create an ADF BC Application Module and how you deploy it on a JBoss Application Server. It will also show you what configurations you need to perform on the JBoss side in order for the Application Module to work correctly. Scope & Application This note is intended for anyone who is about to deploy an ADF BC Module to a JBoss Application Server. How To Deploy an ADF BC Module to a JBoss Application Server The steps necessary for deploying an ADF BC Module to a JBoss Application Server are the following: Setup the ADF Runtime Libraries on the JBoss Server Setup data source(s) on the JBoss Server Configure the ADF BC Module Deploy the ADF BC Module I will go through each of these steps more detailed. There is also a complete example attached for download here. Setup the ADF Runtime Libraries on the JBoss Server Shutdown the Application Server. Invoke the ADF Runtime Installer wizard. Choose Tools | ADF Runtime Installer and choose a server type from the submenu. Proceed through the pages of the wizard. For detailed instructions for any page of the wizard click Help. On the Location page select the home (or root) directory of the server on which the libraries are to be installed. On the Installation Options page you may choose the operation that you wish to perform. * Install the ADF runtime libraries from your JDeveloper installation. * Uninstall previously installed ADF runtime libraries. * Restore an archived version of the ADF runtime libraries as the active version. On the Summary page click Migrate if you wish to prepare any existing UIX JSP projects for deployment. On the Summary page confirm the details of the installation and click Finish. Restart the application server. Setup data source(s) on the JBoss Server To create an Oracle data source in the JBoss server you need to take the following steps: Create a file called oracle-ds.xml. This file will contain your data source configuration. Below is an example on how such a file can look like. <?xml version=""1.0"" encoding=""UTF-8""?> <datasources> <local-tx-datasource> <jndi-name>OracleDS</jndi-name> <use-java-context>false</use-java-context> <connection-url>jdbc:oracle:thin:@mydbhost.com:1521:mysid</connection-url> <driver-class>oracle.jdbc.driver.OracleDriver</driver-class> <user-name>hr</user-name> <password>******</password> <exception-sorter-class-name>org.jboss.resource.adapter.jdbc.vendor.OracleExceptionSorter</exception-sorter-class-name> </local-tx-datasource> </datasources> Copy the file to the /deploy. This will install it on the JBoss server. Configure the ADF BC Module There are a few steps that need to be taken upon the ADF BC Module in order for it to run on the JBoss server. When creating an ADF BC Module that will be used on a JBoss application server one needs to set the SQL Flavor to SQL92 and the Type Map to Java. This change is required when using JBoss as the Application Server. **Package the ADF Business Components project as an EJB session bean.** Right Click on the Application Module select Business Components Deployment. In the profiles Dialog select EJB Session Beans. In the EJB Session Beans dialog select Deploy To: Other EJB Container In the AppModules dialog configure the Application Module as seen in the figure 1 below. Figure 1. Configuration of the Application Module Once done your Project will look similar to the one shown in the figure 2 below. Figure 2. The JDeveloper Project The final step is to configure the Application Module to use the data source we created in the previous step. This is done as follows: Edit the application module. In the Navigator right-click the Business Components application module icon and choose Configurations. Select the appropriate configuration. Select this configuration and click Edit. In the Connection Type list choose JDBC DataSource. Enter a DataSource Name. For example: java:/OracleDS. Deploy the ADF BC Module If you have your JBoss server either locally or mapped on your local machine you can deploy it directly from inside JDeveloper. If your JBoss server is remote and not mapped to the local machine or you have a JSP application that later will use this module you cannot deploy it directly from within JDeveloper. Both methods are described below. Deploying the Module from within JDeveloper 1. Create a connection to the target application server. 2. If you want to support JBoss-specific configuration options for the EJB add a jboss.xml deployment descriptor file. For more information on this file see http://www.jboss.org. 3. If your project is a Business Components UIX JSP project add required Cabo resources to it. 4. Select the deployment profile in the Navigator right-click and choose Deploy to | < application server connection> to package the application as an archive file and deploy it via the selected application server connection. Deploying the Module outside of JDeveloper If your JBoss server is remote and not mapped to the local machine or you have a JSP application that later will use this module you will have to do as follows: Choose Deploy to EAR file from the context menu to deploy it as an EAR file. You must deploy this application to an EAR file and not a WAR file as JBoss will not add the EJB references under the java:comp/env/ JNDI namespace for a WAR file. Copy this file manually to the /deploy directory."
139,A,"Unable to get ResultSet from the MySql DataBase When I execute the following query on a database containing a table ""comm_list"" and a field ""sr_no"" of type ""Int"" in the table ""comm_list"" I get the correct resultset SELECT MAX(sr_no) FROM comm_list; The above query is to get the max. serial no. so that when I enter a new record I enter the (serial no. + 1) in the ""sr_no"" coloum so that I can keep track the no. of records in the database. I know that it can be done automatically by making the field ""sr_no"" primary key and make it to auto increement itself whenever a new record is entered but I have another primary key in the table already so I can not make this ""sr_no"" field as the primary key. When I execute the above query from my java program to get the max. serial no the returned resultset doesn't contain any entries. I don't understand where is the problem. I am storing records from the java program to the Database by using jdbc driver. The following is the code-snippet of my java program.  PreparedStatement getSerial = con.prepareStatement(""select max(sr_no) from comm_list""); // ""con"" is the connection with the database getSerial.execute(); ResultSet rs = getSerial.getResultSet(); System.out.println(rs.toString()); System.out.println(rs.getFetchSize()); // output - 0 srNo = rs.getInt(1) + 1; System.out.println(srNo); Statement getSerial = con.createStatement(); ResultSet rs = getSerial.executeQuery(""select max(sr_no) from comm_list""); if(rs.next()){ srNo = rs.getInt(1) + 1; System.out.println(srNo);  Try using the next method to move the specified result set to the next row and return whether there is a next row: PreparedStatement getSerial = con.prepareStatement(""select max(sr_no) from comm_list""); // ""con"" is the connection with the database getSerial.execute(); ResultSet rs = getSerial.getResultSet(); if(rs.next()) { srNo = rs.getInt(1) + 1; } System.out.println(srNo);  ResultSets need to be iterated to be used. This is mentioned in the javadocs. The javadocs are always an invaluable reference for these APIs. You need to call ResultSet's next() method to get the first result. There are some getting started examples here."
140,A,"Hitting some limit under z/OS with DB2 Connect JDBC t4 driver We have an application connecting to DB2 under z/OS and after a while there seems to be some resource limit being hit on the mainframe side. Since we're using BIRT it seems the only control we have over the JDBC code is with stanzas in the URL itself. we don't have direct Java control over the connection or statements (except for the SQL itself of course) although it may be possible by using Javascript within the report design. So we can turn on debugging with something like: jdbc:db2://machine.com:1234/INSTANCE:traceFile=c:/db2.txt;traceLevel=-1; Eventually the application using JDBC will simply stop and no more data will be written to the log file. Doing a TSO NETSTAT on the mainframe shows about 50 sessions in ESTABLISHED state. Now we know this is a problem on the mainframe side since when it happens no JDBC connection to that instance will work (from any client). At that point we have to restart the database to continue. I've googled quite a lot of stuff some of which seems to indicate that you may need to commit queries before you close a session. It may be that the sessions may be being held open because there's something wrong in the BIRT close code (at least in terms of what DB2 expects). Has anyone experienced anything like this before? How did you fix it (if at all)? Is there a way to solve it by using just the JDBC URL stanzas or Javascript code within the report design? FWIW we're using DB2 9.1 and BIRT 2.2.1. This was actually solved in another forum I'm copying the solution here for posterity. It turns out there's a parameter called IDTHTOIN in the DSN6FAC section of the DB2 parameters assembly/link job (generally db2prefix.SDSNSAMP(DSNTIJUZ) though your setup may be different) which was set to zero in our case. This parameter is the IDLE TIME OUT for DDF threads and zero means ""no timeout"". Setting this to 180 solved our problem. The threads that were holding locks were shut down if they hadn't had any activity in those three minutes. Setting it to less than 120 is not useful since the threads are only checked every two minutes anyway (in DB2 v9 at least). You should also set CMTSTAT=INACTIVE to protect well-behaved threads (those that have released all their resource locks but are still holding the thread open). Keep in mind this was okay for our particular problem since the threads were for reports. Their behavior was such that the opened a session got the data for reporting then didn't need the session any more. If you have long-running sessions you need to be careful (although any session that holds locks for more than three minutes is suspect anyway). You should edit the DSNTIJUZ member run the job then either recycle the DB2 instance or execute SET SYSPARM. Thanks to the helpful bods at IBM Australia (West Perth Lab) for nutting this out for me. What forum are you referring to? It was a combination between the IBM developerWorks forum for DB2/z (the top level of developerWorks is a *must* for anyone using or just interested in IBM products: http://www.ibm.com/developerworks/) and the helpful folk at the IBM labs in West Perth."
141,A,"Java not giving Error! Here is my code - i am simply checking my MySQL database connection. But first i have compiled and run the program successfully. but then i have commented the line Class.forName . Still when i compile it runs successfully without any error.Why? import java.sql.Connection; import java.sql.DriverManager; public class FirstJbdc { public static void main(String[] args) { Connection cn=null; try { //Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver""); System.out.println(""Driver loaded successfully""); cn=DriverManager.getConnection(""jdbc:odbc:myDSN""""root"" ""java""); System.out.println(""Database connected successfully....""); System.out.println(cn); } catch (Exception e) { // TODO: handle exception e.printStackTrace(); } } } lovely: the answer is in the question // TODO: handle exception FirstJdbc you mean.. :) I have an answer below. :) Java 1.6 can find JDBC driver even without using Class.forName. Here is relevant part of documentation: The DriverManager methods getConnection and getDrivers have been enhanced to support the Java Standard Edition Service Provider mechanism. JDBC 4.0 Drivers must include the file META-INF/services/java.sql.Driver. This file contains the name of the JDBC drivers implementation of java.sql.Driver. For example to load the my.sql.Driver class the META-INF/services/java.sql.Driver file would contain the entry: my.sql.Driver Applications no longer need to explictly load JDBC drivers using Class.forName(). Existing programs which currently load JDBC drivers using Class.forName() will continue to work without modification. Hey Peter - please can you point to the docs that detail this been searching but can't find anything - cheers Nick. Don't you have to put the JDBC driver in a special folder for this to work? @pjp - would've thought you'd have to do something like putting the driver in a 'special folder'. Otherwise you'd be trawling through every class checking for which ones implement java.sql.Driver. which is gonna suck. @Nick: check out Javadoc for [DriverManager](http://java.sun.com/javase/6/docs/api/java/sql/DriverManager.html) in JDK 1.6 especially part beginning with ""The DriverManager methods getConnection and getDrivers have been enhanced to support the Java Standard Edition Service Provider mechanism."" @Peter: cheers that's a tick on my learnt something new today list :-) @Nick Holt: ditto. cheers Peter.  I throws an error alright. It's just that the catch (Exception e){ // here the exception is instantiated but nothing is done about it } clause silently swallows your exception. Try a System.out.println( e.getMessage() ); in the catch clause Or e.printStackTrace(); Agree - it runs without (displaying) an error but it does not run successfully (doesn't print the last two lines). Never ever ever (...) catch 'Exception' without handling it ;) tried handling exception but still it's running successfully @peter - can you give any link related to this! @Pradyumna Dandwate: Maybe you can edit the question with your updated code. Not sure what you meant by ""tried handling exception."" I updated my answer with relevant info and link to authoritative documentation.  Without Class.forName() the JDBC-ODBC bridge driver is not loaded. By JDBC specification getConnection() returns null if no driver is found for the URL no exception is thrown. So this is expected behavior. Except if you're using JDBC 4.0 (Java 6) because there it's not necessary anymore to load the driver with Class.forName(...). See the JavaDoc of java.sql.DriverManager. The JDBC-ODBC driver from Sun is so old. It doesn't know the new tricks. Oh yes it does. Check out META-INF/services/ava.sql.Driver file inside jre/lib/resources.jar -- it contains ""sun.jdbc.odbc.JdbcOdbcDriver"" i.e. JDBC-ODBC driver from Sun! So it can be definitely used *without* Class.forName() on Java 6. You are right. I forgot we use a customized version of the driver.  try {  //Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver""); System.out.println(""Driver loaded successfully""); cn=DriverManager.getConnection(""jdbc:odbc:myDSN""""root"" ""java""); System.out.println(""Database connected successfully....""); System.out.println(cn); } catch (Exception e) { // add the following statement System.out.println(e.getMessage()); } If you add the statement inside the catch block then compile and run you should see the error message like- [Some Com][Some Driver Manager] Data source name not found and no default driver specified  NOTE: this only applies to pre-JDBC 4.0 Drivers. JDBC drivers are meant to have a static section that registers them with the java.sql.DriverManager when the class is loaded hence the Class.forName(String) is required. It's detailed here: http://java.sun.com/j2se/1.3/docs/guide/jdbc/getstart/drivermanager.html"
142,A,"How to differentiate SQL statements that modify data from those that are read only? I need to write a jdbc compliant driver wrapper whose purpose is to log all SQL statements that modify data. What is the easiest way to differentiate those statements that modify data from those that only read data? I guess that only way is to parse SQL code on the fly any libraries that can do that? What if the statement is a call to a stored procedure? if SP i'd consider it modifies data by default. For more elaborate solution I might implement a list of read-only (or list of modifying) SP. You could probably find some full blown sql parsers such as this one but if your wrapper will intercept only single statements then you might (not enough detail) consider SELECT statements as read only and everything else as statements that modify data. ""Many people have attempted to write a full SQL grammar with parser generate tool and failed."" they say. Seems to be more complex than I initially thought.. @Dan yes especially due to extensions to the standard. For example you can find grammar for SQL here http://savage.net.au/SQL/ and it is in BNF for which you can find parsers and do nice things; however if you aim for full conformance then you are most likely talking about full conformance with some existing RDBMS (or even worse multiple RDBMSes) and that has many more versions and is much more undocumented :)  If this is not a general purpose wrapper I would just log every call to the executeXXX() methods except calls to executeQuery() and then just call the appropiate method in client code. If you want it to be general purpose and would like to avoid parsing SQL you can investigate the getUpdateCount()method and the return values of the executeXXX() methods. That would imply logging after the statement was executed and I do not think it would be 100% correct.  I think a pretty good start is looking for queries starting with INSERT UPDATE or DELETE. Make sure to trim leading whitespace before testing the strings. If you want to include schema altering statements include commands such as CREATE ALTER DROP and TRUNCATE. The specifics of the above approach will depend on the database you are using. E.g. there may be batch commands in one string separated by a semicolon. You will need to parse the string to look for instances such as this. Don't forget MERGE on modern SQL DBMS. In some RDBMS systems you can have modifying statements that do not being with insert update or delete. (For example in SQL Server any of these could be embedded within a cte and so start with a ""WITH"" statement.) It's a complex problem and findint a third-party tool for your system might be the safest bet."
143,A,"Pattern for connecting to different databases using JDBC I'm writing an application which has to be configurable to connect to Oracle SQL Server and MySQL depending on client whim. Up till now I'd been planning on using the JDBC-ODBC bridge and just connecting to the databases using different connection strings. I'm told this is not very efficient. Is there a pattern or best practice for connecting to multiple database systems? Or for selecting which driver to use? Should I have it configurable? but include all three drivers or build three separate clients? I'm not doing anything complex just pumping (inserting) data into the database from an event stream. I would suggest that you make it configurable and include the three drivers. You can use a pattern like this: Create a super class (lets call it DAO) that provides the functionality of connecting to the database. This could be abstract. Create a concrete sub class for each type of database that you wish to connect to. So you may end up with MySQLDAO MSSQLDAO and OracleDAO. each one will load the respective driver and use its respective connection string. Create another class (lets call it DAOFactory) with a method getDAO(DB) that will create an instance of the DAO depending on the value of DB. So for instance(in Pseudocode):  if(DB.equals(""MySQL"")){ DAO = new MySQLDAO(); } return DAO; So any code that needs to connect to the database will call the DAOFactory and ask for a DAO instance. You may store the DB value in an external file (like a properties file) so that you do not have to modify code to change the type of database. this way your code does not need to know which type of database it is connecting to and if you decide to support a fourth type of database later you will have to add one more class and modify the DAOFactory not the rest of your code.  Take a look at Datasource. This is the preferred mechanism for obtaining a database connection. IMO this provides an adminstrator the greatest flexibility for choosing database connection pooling and transaction strategies. If you're using tomcat then see here for how to register a Datasource with tomcat's JNDI. If you're using Spring then you can obtain a Datasource using jee:jndi-lookup. If you're using Spring but don't want to use JNDI take a look at DriverManagerDataSource for a discussion of how to obtain a pooled Datasource (DBCP or C3P0). Fixed the links. Thanks Paresh. The link you provided for data source is giving 404!  If you're careful (and you test) you can do this with straight JDBC and just vary the driver class and connection information. You definitely want to stay away from the JDBC-ODBC bridge as it's generally slow and unreliable. The bridge is more likely to behave differently across dbs than JDBC is. I think the DAO path is overkill if your requirements are as simple as listed. If you're doing a lot of inserts you might want to investigate prepared statements and batched updates as they are far more efficient. This might end up being less portable - hard to say without testing.  If you need anything complex Hibernate is a good choice. otherwise what I would do is store your connection details in a properties file (or some other form of configuration) - namely: driver classname JDBC url username and password. Then all you need to do is load up the connection details from your properties file and include the correct JAR file on your classpath and you're done. You could use a library such as Commons-DBCP if you wanted it to be a little easier to configure but other than that it's all you need to do (provided your SQL statements work on every database of course)."
144,A,"Change Oracle JDBC Thin Client Identifier When connecting to Oracle the JDBC driver identifies itself as ""JDBC Thin Client"" to Oracle (in v$session as the 'program'). There is also a 'ClientInfo' column in v$session that might be used for this but it's always empty. We have a need to identify different applications connecting to Oracle (which are running on the same host so the 'machine' column in v$session is all the same) so is it possible to change how the Oracle JDBC Thin Client driver identifies itself (so we could put the application name in for example)? Or is there a recommended way to do this? One restriction is that we're doing this within Struts for some of the applications which is handling the connection setup internally. possible duplicate of [How do I make my Java application identify itself to Oracle on connection?](http://stackoverflow.com/questions/1548400/how-do-i-make-my-java-application-identify-itself-to-oracle-on-connection) Identical to java.util.Properties props = new java.util.Properties(); props.setProperty(""password""""mypassword""); props.setProperty(""user""""myusername""); props.put(""v$session.osuser"" System.getProperty(""user.name"").toString()); props.put(""v$session.machine"" InetAddress.getLocalHost().getCanonicalHostName()); props.put(""v$session.program"" ""My Program Name""); DriverManager.registerDriver (new oracle.jdbc.OracleDriver()); Connection conn= DriverManager.getConnection(""jdbc:oracle:thin:@myhostname:1521:mysid""props); query v$session SQL>select usernameosuserprogrammachine from v$session where username = 'ROB'; USERNAME OSUSER PROGRAM MACHINE --------- ----------- ------------------ ----------- ROB rmerkw My Program Name machine At application level you can use dbms_application_info.set_module and dbms_application_info.set_client_info to set clientinfomoduleaction in v$session Cheers that should help for some of the applications - does this work with a OracleConnectionPoolDataSource? I see there's a setConnectionProperties method there. Do I have to specify all the fields listed even if I'm using the .setUser() .setPassword() etc methods on OracleConnectionPoolDataSource? I know it works on a OracleConnectionPoolDataSource. It's long ago so I don't remember the specifics. setConnectionProperties takes a java.util.Properties as an argument. Don't think this empties the user and password set earlier with .setUser() .setPassword(). Do I make sense ? ;-) Hi! Yes that makes sense and it works with just the v$session.program set. Cheers.  There is also an Oracle function: dbms_application_info.set_client_info('Client Info'); which sets the ClientInfo column in v$session."
145,A,"how can we use prepareStatement()? I use prepareStatement() when the id is a key of my SQL table and it will be created by SQL and I want to use this statement :(what should I write instead of X in the first column of SQL table(reminder:SQL create it automatically) File file = new File(pathFile); FileInputStream input = new FileInputStream(file); query = (""insert into birthtable VALUES(????????)""); pstmt = (PreparedStatement) conn.prepareStatement(query); pstmt.setInt(1**X** ) pstmt.setString(2 name); pstmt.setString(3 family); pstmt.setString(4 fatherName); pstmt.setString(5 mName); pstmt.setString(6 dOfBirth); pstmt.setString(7 pOfBirth); // Method used to insert a stream of bytes pstmt.setBinaryStream(8 input); pstmt.executeUpdate(); I have done what you all say but I have this exception?? java.sql.SQLException: Column count doesn't match value count at row 1 at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1055) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3491) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734) at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:2019) at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:1937) at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:1922) at database.Manager.addBirth(Manager.java:76) at AdminGUI.AddNewBornInformation.submit(AddNewBornInformation.java:358) at AdminGUI.AddNewBornInformation.setButtonActionPerformed(AddNewBornInformation.java:282) at AdminGUI.AddNewBornInformation.access$800(AddNewBornInformation.java:28) at AdminGUI.AddNewBornInformation$9.actionPerformed(AddNewBornInformation.java:139) at javax.swing.AbstractButton.fireActionPerformed(AbstractButton.java:1995) at javax.swing.AbstractButton$Handler.actionPerformed(AbstractButton.java:2318) at javax.swing.DefaultButtonModel.fireActionPerformed(DefaultButtonModel.java:387) at javax.swing.DefaultButtonModel.setPressed(DefaultButtonModel.java:242) at javax.swing.plaf.basic.BasicButtonListener.mouseReleased(BasicButtonListener.java:236) at java.awt.Component.processMouseEvent(Component.java:6038) at javax.swing.JComponent.processMouseEvent(JComponent.java:3265) at java.awt.Component.processEvent(Component.java:5803) at java.awt.Container.processEvent(Container.java:2058) at java.awt.Component.dispatchEventImpl(Component.java:4410) at java.awt.Container.dispatchEventImpl(Container.java:2116) at java.awt.Component.dispatchEvent(Component.java:4240) at java.awt.LightweightDispatcher.retargetMouseEvent(Container.java:4322) at java.awt.LightweightDispatcher.processMouseEvent(Container.java:3986) at java.awt.LightweightDispatcher.dispatchEvent(Container.java:3916) at java.awt.Container.dispatchEventImpl(Container.java:2102) at java.awt.Window.dispatchEventImpl(Window.java:2429) at java.awt.Component.dispatchEvent(Component.java:4240) at java.awt.EventQueue.dispatchEvent(EventQueue.java:599) at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:273) at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:183) at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:173) at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:168) at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:160) You shouldn't do `(PreparedStatement)` cast. I did not NetBeans did it for me!!!!? But you still reserve the right to say no. Exception: With the explicitly named columns? What's the SQL? @Johanna with regards to you latest exception check you have: 7 column names 7 ?'s and 7 sets that's really all there is to it beyond what everyone has already suggested. You don't need to put that much exclamation marks or question marks in comments. Otherwise you overcome offensive. One (or none) is enough. You don't need to specify it yourself so you can just leave it away. But you should however specify the columns yourself e.g. ""INSERT INTO tablename (columnname1 columnname2 columnname3) VALUES (? ? ?);"" otherwise the DB wouldn't know where to insert the values because there is one column missing. wooow I get ithow tricky is this!!!!  My only 2 cents is that if you want a generated ID you may call pstmt.getGeneratedKeys( ); If it's going to return anything valid depends on your JDBC driver implementation though.  You do not set the id parameter in the prepared statement assuming you're using auto increment and the column names are valid: query = (""insert into birthtable (name family fatherName mName dOfBirth pOfBirth input) VALUES(???????)""); pstmt = conn.prepareStatement(query); pstmt.setString(1 name); pstmt.setString(2 family); pstmt.setString(3 fatherName); pstmt.setString(4 mName); pstmt.setString(5 dOfBirth); pstmt.setString(6 pOfBirth); pstmt.setBinaryStream(7 input); You should state the column names explicitly otherwise you depend on the order in the table create statement. in your query you have 7 column with 8 question marks ? @Johanna - That's right. Fixed ? and idx #. thanks I get it  If you have specified the type of that column as int and auto-increment e.g. `ID` int(10) unsigned NOT NULL AUTO_INCREMENT then you don't need to supply any value at all so you can start the prepared statement params at 1 with name.  query = (""insert into birthtable (nameCol familyCol fatherNameCol mNameCol dOfBirthCol pOfBirthCol inputCol) VALUES(???????)""); pstmt = (PreparedStatement) conn.prepareStatement(query); pstmt.setString(1 name); pstmt.setString(2 family); pstmt.setString(3 fatherName); pstmt.setString(4 mName); pstmt.setString(5 dOfBirth); pstmt.setString(6 pOfBirth); // Method used to insert a stream of bytes pstmt.setBinaryStream(7 input); Note that as others have said you must include the column names whatever they might be. we have 8 question marks and then I start with 1so where is the value of eight question mark??? you need to remove one - so there will only be seven"
146,A,"Multiple dynamic data sources for a servlet context I'm developing a java servlet web application that manages information from multiple databases (all structurally the same) each corresponding to a different ""business"". The user selects ""the current business"" which is stored in the session and the application can display or modify that ""current business"". I would like to use tomcat Resources in a dynamic way to have access to these businesses using jndi. In this way I can use the jstl sql tags or context lookups in servlets. I can not define each Resource in the web.xml file because they are stored in a SQL table. The end result is to be able to write simple jsp that has lines like these: <%@ taglib uri=""http://java.sun.com/jstl/sql"" prefix=""sql"" %> <sql:query var = ""users"" dataSource=""sources/${sessionScope.currentBusiness}""> select id firstName lastName FROM user </sql:query> or servlets that can have lines like these String request.getSession().getAttribute(""currentBusiness""); Context initial = new InitialContext(); Context context = (Context) initial.lookup(""java:comp/env""); DataSource source = (DataSource) context.lookup(""sources/"" + currentBusiness); where I can get the correct datasource for the ""current business"". I have experimented with writing my own ObjectFactories derived from javax.naming.spi.ObjectFactory without success. Any pointers on how to easily do this? I finally settled for the following solution consisting on a SessionListener and a Servlet that work as follows. The SessionListener has the following form: public class SessionListener implements HttpSessionListener { public void sessionCreated(HttpSessionEvent event) { HttpSession session = event.getSession(); // get list of possible data sources available to this session List<DataSource> sources = new ArrayList<DataSource>(); ... code to get the available sources // get the current data source DataSource source = null; ... code to get the current source source = sources.get(0); // for example // setup the session attributes session.setAttribute(""availableSources"" sources); session.setAttribute(""currentSource"" source); } } Whenever a user logs in and a session is created the list of available DataSources and the current one are placed into the session. This is done at the Session level because DataSources depend on the user login in. It is now possible to have access at them from within the application. To change the current DataSource I created a Servlet with this simplified version: public abstract class BoxletServlet extends HttpServlet { protected void doGet(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { HttpSession session = request.getSession(true); String s = request.getParameter(""source""); // based on 's' choose from the available DataSource List<DataSource> sources = (List<DataSource>) session.getParameter(""availableSources""); Source source = chooseFrom(sources s); session.setParameter(""currentSource"" source); // forward to a page saying that the DataSource changed } } With this implementation it is now possible to create the following jsps: <%@ taglib uri=""http://java.sun.com/jstl/sql"" prefix=""sql"" %> <sql:query var = ""users"" dataSource=""${sessionScope.currentSource}""> select id firstName lastName FROM user </sql:query> Hope it helps someone else.  This approach will certainly ""work"" but the notion of a separate identical database for each business seems wrong to me. Surely being able to delineate business somewhere in the schema seems possible. Separating them this way requires a new database per business where a schema would only require a new business identifier. I'd also argue that any possibility of cross-business data mining is lost unless you ETL data from separate databases into a dimensional cube for ad hoc reporting and querying. And JSTL <sql> tags should only be used in the simplest web apps. You leave yourself open to the possibility of SQL injection attacks when you forego validation on a middle tier. UPDATE: You have to declare resources in your web.xml AFAIK so whenever you have a new database you have to stop the application configure the new JNDI source and restart Tomcat. I hope you're clustered because all the previous clients will be affected by the app being down every time you add a new business/database. The restriction of the multiple databases is the fact they different administrative systems (not under my control) representing multiple companies. I'm writing an account receivables tracking module for all the companies (not very glamorous) and need access to each company separately. As for the jstl sql tags I'm only using them to display information for each of the companies.  Create the data sources in a ServletContextListener and place them in the ServletContext. How would you then access it via the JNDI interface? You wouldn't be able to do so. Perhaps in the same listener you can use context.bind(name object) ? Tried that but the context that tomcat creates is read only. Forgot about that. Can you change the context factory shipping with Tomcat with a full-fledged one? Not sure how that is done though."
147,A,glassfish connection pool additionnal delay while re-creating after idle timeout We are currently deploying some applications on a glassfish 3.0.1 using a postgres database through postgresql-9.0-801.jdbc4.jar Our actual configuration regarding the connexion pool is : Idle Timeout : 120 seconds Max Wait Time : 60000 millisecondes Initial and Mimimum Pool Size : 1 Maximum Pool Size : 1 Pool Resize Quantity : 1 We have noticed that the database connexions are droped and created every 140 seconds instead of 120 seconds. Is there something we have missed ? Thank you It's probably being active for 20 seconds. Checking that the connection is valid etc. After some test with and without xa transactions I noticed as well a significant increase of the recycling delay. Without xa the idle timeout work fine. with xa 120 seconds became 180 and 240 seconds became 480. We are going to take care of this weird behavior. If someone know what make glassfish (or postgres JDBC) behave like that please enlighten us. thanks. We are carefully monitoring the network for activity and we have absolutely no traffic the server is started alone and nothing get through it and the database. Additionally the database and the glassfish are not on the same machine. Have you got a DBA which can analyse the connection at the DB end? With Sybase we've found that things like having XA txns switched on can affect these timings
148,A,"jBPM + Spring transactions sharing and scope I've inherited an app using jBPM and Spring and am trying to figure out if it is configured the way it should be. First question: Does jBPM span a single JTA (JDBC and/or Hibernate) transaction across multiple actions in the same transition by default? If not can it be configured to? So in the example below is there a way to span a transaction across Action1 and Action2. jBPM actions in this project retrieve services or DAOs (JDBC) from Spring context. For the configuration described below are jBPM actions and the service / DAO methods they invoke encapsulated in one transaction? DAO and service methods are annotated with @Transactional themselves. State definition: <state name=""SomeState""> <event type=""node-enter""> <action class=""SomeAction""/> </event> <transition name=""transition1"" to=""finish""> <action class=""Action1""/> <action class=""Action2""/> </transition> <transition name=""transition.stop"" to=""finish""/> </state> My jBPM config: <jbpm-configuration> <jbpm-context> <!--<service name=""persistence"" factory=""org.jbpm.persistence.db.DbPersistenceServiceFactory"" />--> <service name=""persistence""> <factory> <bean class=""org.jbpm.persistence.jta.JtaDbPersistenceServiceFactory""> <field name=""isTransactionEnabled""> <false /> </field> </bean> </factory> </service> <service name=""tx"" factory=""org.jbpm.tx.TxServiceFactory"" /> <service name=""message"" factory=""org.jbpm.msg.db.DbMessageServiceFactory"" /> <service name=""scheduler"" factory=""org.jbpm.scheduler.db.DbSchedulerServiceFactory"" /> <service name=""logging"" factory=""org.jbpm.logging.db.DbLoggingServiceFactory"" /> <service name=""authentication"" factory=""org.jbpm.security.authentication.DefaultAuthenticationServiceFactory"" /> </jbpm-context> <!-- configuration property used by persistence service impl org.jbpm.persistence.db.DbPersistenceServiceFactory --> <string name=""resource.hibernate.cfg.xml"" value=""hibernate.jbpm.cfg.xml"" /> <!-- configuration resource files pointing to default configuration files in jbpm-{version}.jar --> <string name=""resource.business.calendar"" value=""org/jbpm/calendar/jbpm.business.calendar.properties"" /> <string name=""resource.default.modules"" value=""org/jbpm/graph/def/jbpm.default.modules.properties"" /> <string name=""resource.converter"" value=""org/jbpm/db/hibernate/jbpm.converter.properties"" /> <string name=""resource.action.types"" value=""org/jbpm/graph/action/action.types.xml"" /> <string name=""resource.node.types"" value=""org/jbpm/graph/node/node.types.xml"" /> <string name=""resource.parsers"" value=""org/jbpm/jpdl/par/jbpm.parsers.xml"" /> <string name=""resource.varmapping"" value=""org/jbpm/context/exe/jbpm.varmapping.xml"" /> <string name=""resource.mail.templates"" value=""jbpm.mail.templates.xml"" /> <int name=""jbpm.byte.block.size"" value=""1024"" singleton=""true"" /> <bean name=""jbpm.task.instance.factory"" class=""org.jbpm.taskmgmt.impl.DefaultTaskInstanceFactoryImpl"" singleton=""true"" /> <bean name=""jbpm.variable.resolver"" class=""org.jbpm.jpdl.el.impl.JbpmVariableResolver"" singleton=""true"" /> <string name=""jbpm.mail.smtp.host"" value=""localhost"" /> <bean name=""jbpm.mail.address.resolver"" class=""org.jbpm.identity.mail.IdentityAddressResolver"" singleton=""true"" /> <string name=""jbpm.mail.from.address"" value=""jbpm@noreply"" /> <bean name=""jbpm.job.executor"" class=""org.jbpm.job.executor.JobExecutor""> <field name=""jbpmConfiguration""><ref bean=""jbpmConfiguration"" /></field> <field name=""name""><string value=""JbpmJobExecutor"" /></field> <field name=""nbrOfThreads""><int value=""1"" /></field> <field name=""idleInterval""><int value=""5000"" /></field> <field name=""maxIdleInterval""><int value=""3600000"" /></field> <!-- 1 hour --> <field name=""historyMaxSize""><int value=""20"" /></field> <field name=""maxLockTime""><int value=""600000"" /></field> <!-- 10 minutes --> <field name=""lockMonitorInterval""><int value=""60000"" /></field> <!-- 1 minute --> <field name=""lockBufferTime""><int value=""5000"" /></field> <!-- 5 seconds --> </bean> </jbpm-configuration> Relevant spring config: <tx:annotation-driven transaction-manager=""transactionManager""/> <bean class=""org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator""/> <bean class=""org.springframework.transaction.interceptor.TransactionAttributeSourceAdvisor""> <property name=""transactionInterceptor"" ref=""txInterceptor""/> </bean> <bean id=""txInterceptor"" class=""org.springframework.transaction.interceptor.TransactionInterceptor""> <property name=""transactionManager"" ref=""transactionManager""/> <property name=""transactionAttributeSource""> <bean class=""org.springframework.transaction.annotation.AnnotationTransactionAttributeSource""/> </property> </bean> <bean id=""transactionManager"" class=""org.springframework.transaction.jta.JtaTransactionManager""/> I know it's a late reply (1 year old question) but maybe it will help others coming from Google or site search. You haven't specified which version of JBPM you are using so I'm assuming 4.x because 5 wasn't ready back then ;) JBPM runs each command (task) in it's own transaction by default and uses it's own transaction manager for this job. So in order for it to use Spring you have to make some changes to the jbpm.cfg.xml namely inject <spring-transaction-interceptor /> and <hibernate-session current=""true"" />. This blog post should help configure all of it though: http://blog.aparnachaudhary.net/2010/08/19/jbpm4-4-with-spring3/"
149,A,Encryption / Decryption sqlite database using java Is there any free library / Java API to encrypt and decrypt sqlite database in java ? I am using SQLite JDBC driver as part of xerial project. Thanks Deep Thanks for your response. So do you mean I can simply encrypt it as a normal file and then decrypt it like a normal file before reading the records from the tables. Do you want to decrypt / encrypt the database while it's closed? That's relatively easy - but then you should change the title of the question to 'how to decrypt / encrypt a file'... If not then there are various SQLite encryption extensions. But I don't know a Java library. There is an encryption library (sqlite-crypt) available in C but if you want to do it in Java I would simply encrypt the file like any other file. See this example of file encryption/decryption in Java. Just a question won't encrypting and decrypting the file like that leave the file vulnerable? i mean jdbc picks up the file which means you will have to decrypt the file to let's say the temp folder and then use that fine in stead of the encrypted one. Won't this leave a small window of attack? I'd like my data to go from my encrypted database straight to my memory.
150,A,"Multiple row insert in sql server from java I need to insert multiple row's into sql server database (100 at a time) from my java code. How can i do this..? Currently i am inserting one by one and this does not look efficient... Kaddy found an example of batching using jdbc. check this out: http://www.exampledepot.com/egs/java.sql/BatchUpdate.html  You can pass one very long string to SQL with multiple inserts as one statement to SQL Server. This won't work if you're doing parameterized queries though. And concatenated SQL strings are ""Generally a Bad Idea."" You might be better off looking at the BULK INSERT command. It has the problem of being rigid about column orders and such. But its WAY FAST!! i cant use this because i dont have a file...thanks anyways... yeah its a PITA to write the file and such but its a good command to be aware of. :)  You can use PreparedStatement#addBatch() to create a batch and executeBatch() to execute it. Connection connection = null; PreparedStatement statement = null; try { connection = database.getConnection(); statement = connection.prepareStatement(SQL); for (int i = 0; i < items.size(); i++) { Item item = items.get(i); statement.setString(1 item.getSomeValue()); // ... statement.addBatch(); if ((i + 1) % 100 == 0) { statement.executeBatch(); // Execute every 100 items. } } statement.executeBatch(); } finally { if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } See also: JDBC tutorial - using PreparedStatement JDBC tutorial - batch updates in this approach if one record from the batch fails what will happen..? will the records after the failed record be inserted...how do i make sure that except the record that fails all other records be inserted...? That actually depends on the driver used. See [`executeBatch()` javadoc](http://java.sun.com/javase/6/docs/api/java/sql/Statement.html#executeBatch%28%29).  Use a batch. Check out the addBatch() executeBatch() etc. methods of Java's Statement For a simple example check here (but I would suggest using a PreparedStatement) is there a batch statement in sql server or do i need to use a api...? @Kaddy - I would recommend doing it on the Java side with a batch using PreparedStatement"
151,A,"Spring JdbcTemplate ConnectionPooling Configuration I am working on a Spring MVC application in which I have recently been convinced to revamp my database code. Before I was using very traditional JDBC code that I have been told was very ""old school"" because of the boilerplate code. I have been making the transition to using JdbcTemplate with Spring. I have configured a bean like shown below in my applicationContext.xml file. <bean id=""dataSource"" class=""org.apache.commons.dbcp.BasicDataSource""> <property name=""driverClassName"" value=""com.mysql.jdbc.Driver""/> <property name=""url"" value=""jdbc:ip-address:port/dbName""/> <property name=""username"" value=""myUsername""/> <property name=""password"" value=""mypassword""/> </bean> I have run tests just to make sure everything is working and it is. My question is I am aware that I am using the Commons DBCP package which uses the following packages  commons-dbcp package commons-pool package Again I am very inexperienced with this so I apologize if I am mis referencing something or am explaining something incorrectly. I have followed what most of the tutorials have said to do and specified a jdbcTemplate and injected the dataSource bean into it but this doesnt really refer to my question. What I would really like to know is am I using ConnectionPooling with this configuration? If so is it being done behind the scenes or do I need to specify to do it somewhere? I have looked at the documentation at Here which gives the following but I am not sure exactly how to interpret it. ""here are several Database Connection Pools already available both within Apache products and elsewhere. This Commons package provides an opportunity to coordinate the efforts required to create and maintain an efficient feature-rich package under the ASF license. The commons-dbcp package relies on code in the commons-pool package to provide the underlying object pool mechanisms that it utilizes."" I also looked at the Configuration Page and based on this page I would think that I am able to do ConnectionPooling but may need to specify additional parameters in my dataSource bean. Can somebody please answer my questions or point me in the right direction? Yes you are using connection pooling. here is another thread you might find interesting http://forum.springsource.org/showthread.php?t=40598 Also most of the links you specified above will provide additional information on parameters that can be set."
152,A,"JDBC: Is it possible to execute another query on the results of a previous query? I want to first get some result set (that includes two joins and selection) and then get the maximum value for one of the columns in the result set. I need both the data in the original results set and the max. Is this possible with JDBC and how? You can do it with standard SQL although it's a bit awkward: SELECT a b c (SELECT MAX(c) FROM table1 JOIN table2 ON table1.id = table2.table_id) max_c FROM table1 JOIN table2 ON table1.id = table2.table_id thanks I am aware of that method but I would like to know whether it's possible to actually pefrom it in JDBC with two consecutive queries so as to not add the redundant column to the results.  I think it is. Should look like this: SELECT MAX(derivedTable.myRow) FROM (SELECT * FROM table1 JOIN table2 ON table1.id = table2.some_id) derivedTable The key is to assign your inner select an alias (""derivedTable"" above) and perform another selection on that. --- Edit based on comment: No I don't think that's possible. Even without the JDBC layer - say in a direct SQL console - I don't think there is a way to query data in a result set in any RDBMS I know. Depending on the speed of your query and the size of the result either performing a second query or just iterating through the results to find the maximum are your best options. Also not good - then I can't access the derivedtable's data... In that case I didn't understand what you were after. So you want one query then get the results and then get the maximum of one column of that previous query result - the motivation being that you don't want to repeat the first query as you've already performed it? yeah you got it. Just wondering if it's possible."
153,A,"How can I determine if the column name exist in the ResultSet? As the ResultSet contains the data returned from the dynamic SQL if there are any method to determine if the ResultSet contains a particular column name ? For example  if I run rs.getString(""Column_ABC""); but Column_ABC does not really exist it will throw out the exception . How can I test if the ResultSet can get a data from a column named ""Column_ABC"" ? Not sure if this is more or less efficient than Erick's answer but it's easier. String str; try { str = rs.getString(columnName); } catch (java.sql.SQLException e) { str = null; } It's without a doubt easier to understand. However and regardless that fact that I don't see the JDBC driver returning ""SQLServer"" Exceptions the ResultSet methods return SQLException if the column name is invalid or if a more generic SQL error occurs (which dificults the job of knowing what happened: if wrong column name or if an actual error occurred) +info @ [ResultSet Javadoc](http://docs.oracle.com/javase/8/docs/api/java/sql/ResultSet.html#getObject-java.lang.String-) -1 Exceptions should be used only in exceptional circumstances and then they should be logged. Taking the easy way out tends to create code that's difficult to understand and maintain. If you are using a server-side resultset and lost connection to the database before making this call then this method will throw an exception even if the column exists. This type of scenario can lead to disasterous consequences if the code uses this check (for example) to determine if the entire database needs initialization. Thanks João you're right. I meant SQLException. Tried to pick a generic one.  if not rs.getString(""Column_ABC"")= nothing then ' your code here This is a bad idea and it's also wrong. When a column doesn't exist it doesn't return nothing. It throws an SQLException which you have to catch and handle. You should never use an exception being thrown for a simple check like this. You should always look for a method that would actually return a boolean - something that will actually perform a proper check.  Use the ResultSetMetaData class. public static boolean hasColumn(ResultSet rs String columnName) throws SQLException { ResultSetMetaData rsmd = rs.getMetaData(); int columns = rsmd.getColumnCount(); for (int x = 1; x <= columns; x++) { if (columnName.equals(rsmd.getColumnName(x))) { return true; } } return false; } The thing I don't understand is why this function would ever be needed. The query or stored procedure being executed should have known results. The columns of the query should be known. Needing a function like this may be a sign that there is a design problem somewhere. When executing user queries in tools like TOAD the application does not know the query structure and must use `ResultSetMetaData`. But yes searching for a particular column name is strange. Just commenting... in your example you're retrieving all column info. For a user query I expect this to be standard. This is still not searching to see if a specific column is included. This is basically correct but `getColumnName` takes its parameter starting from 1 not 0. You need `for (int x = 1; x <= columns; x++)` @AdrianSmith You are correct. I have fixed the answer. take in mind that if you use spring with JdbcTemplate you need to close the connection by your one. Nothing strange about searching for a column name. In a highly dynamic user-configurable system column sets may vary widely based on user selections. Yes the set can be determined but to assume it's always hard-coded and therefore known is incorrect."
154,A,"Why would number columns' scale and/or precision differ in JDBC from Oracle 10 to 11? For our database development we have on one hand a full schema DDL script for scratch installs and on the other a set of sequential ""delta"" scripts for upgrades (each script is recorded as executed or not in a special database table). To test this we have an ant target that install an older version upgrades it and compares the schema to a newly created one. We use JDBC MetaData to compare the schemas and with Oracle 10 this worked just great. Now we've upgraded to Oracle 11 and moved from ojdbc14.jar to ojdbc6.jar. The test still runs green on Oracle 10 but on Oracle 11 we get (two typical examples): Table <table X> has column <column A> as NUMBER(10) NOT NULL in <new schema> but as NUMBER(00) NOT NULL in <upgraded schema> Table <table Y> has column <column B> as NUMBER(0-127) NOT NULL in <new schema> but as NUMBER(00) NOT NULL in <upgraded schema> Looks almost (-127 is not a nice scale now is it) OK if we had done something wrong. But the very same files worked before and here are the script statements: DDL script: CREATE TABLE <table X> ( ... <column B> NUMBER(1) DEFAULT 0 NOT NULL ... ) CREATE TABLE <table Y> ( ... <column B> NUMBER DEFAULT 1 NOT NULL ... ) Delta script: ALTER TABLE <table X> ADD ( <column A> NUMBER(1) DEFAULT 0 NOT NULL ) ALTER TABLE <table Y> ADD (<column B> NUMBER DEFAULT 1 NOT NULL) And here is the JDBC MetaData code: public class Column { String name; int scale; int precision; boolean nullable; String type; public Column(ResultSetMetaData metaData int column) throws SQLException { name = metaData.getColumnName(column); type = metaData.getColumnTypeName(column); scale = metaData.getScale(column); precision = metaData.getPrecision(column); nullable = metaData.isNullable(column) == ResultSetMetaData.columnNullable; } @Override public String toString() { return type + ""("" + precision + """" + scale + "") "" + (nullable ? ""NULL"" : ""NOT NULL""); } } Yes the column index starts from 1 and it is the toString() value that is used to compare the different columns (also used in the error output above). I've debugged this code and as far as I can see the Oracle JDBC driver gets these values when internally ""describing"" the table to produce the MetaData. Note that both schemas are in the very same database instance and the JDBC connections are both made by the very same JDBC library. The same discrepancies are produced when using the older ojdbc14.jar but never in Oracle 10. Does anybody have any input on how this can be? I'm stuck and we're left without a trustable test of our database upgrade scripts. It looks that getScale() returns negative value for columns defined as just NUMBER instead of NUMBER(x) or NUMBER(xy). There are some discussions you can find on Google which deals with the same issue e.g.: http://www.experts-exchange.com/Programming/Languages/Java/Q_21360469.html Not sure why it works differently between oracle 10 and 11 though. Could be a bug in JDBC driver? It might be a good idea to always specify precision and scale explicitly for datatypes in your DDL statements btw. +1 for asking Tom - he always has the answer probably before you even ask the question :-) Go see what Tom has to say about it. http://asktom.oracle.com/ I'd vote for it being a bug in the ojdbc driver. That said I would probably call the DBMS_METADATA packages for extracting DDL. The ResultSetMetaData seems more focused on determining the types in a result set as opposed to determining the metadata of database objects themselves. I'll accept this as the answer as I ended up using ALL_TAB_COLUMNS instead ..."
155,A,Batch Stored procedures insertion in database with Callable statement We have 4 stored procedures which we are using to insert the entries in database These 4 are interdependent If any of this fails Whole operation has to be rolled back only if everything goes well I want to commit the transaction. How do I achieve that. Thanks Rohit. You need to use JDBC's transaction support which is described in the JDBC Tutorial here. Pseudo-code: Connection conn = ... conn.setAutoCommit(false); try { doAction1(connection); doAction2(connection); doAction3(connection); doAction4(connection); connection.commit(); } catch (Exception ex) { connection.rollback(); } Plus all the usual closing of connections statements etc. The link describes the specifics. Thanks for the answer Implemented in same way.Really appreciate your help. Thanks Rohit.
156,A,"JDBC Query excecution I am facing an issue while executing queries.I use the same resultSet and statement for excecuting all the queries.Now I face an intermittent SQlException saying that connection is already closed.Now we have to either have separate resultSet for each query or have lock like structure.Can anyone tell which is better.I think introducing locks will slow down the process.Am I right? Update: To be more clear.The error may happen because the finally block gets called before all the queries get executed and the connection gets closed and exception will be thrown. This is the exception I get java.sql.SQLException: Connection has already been closed. at weblogic.jdbc.wrapper.PoolConnection.checkConnection(PoolConnection.java:81) at weblogic.jdbc.wrapper.ResultSet.preInvocationHandler(ResultSet.java:68) at weblogic.jdbc.wrapper.ResultSet_com_informix_jdbc_IfxResultSet.next(Unknown Source) at com.test.test.execute(test.java:76) at org.apache.struts.action.RequestProcessor.processActionPerform(RequestProcessor.java:413) at org.apache.struts.action.RequestProcessor.process(RequestProcessor.java:225) at org.apache.struts.action.ActionServlet.process(ActionServlet.java:1858) at org.apache.struts.action.ActionServlet.doPost(ActionServlet.java:459) at javax.servlet.http.HttpServlet.service(HttpServlet.java:760) at javax.servlet.http.HttpServlet.service(HttpServlet.java:853) at weblogic.servlet.internal.ServletStubImpl$ServletInvocationAction.run(ServletStubImpl.java:1077) at weblogic.servlet.internal.ServletStubImpl.invokeServlet(ServletStubImpl.java:465) at weblogic.servlet.internal.ServletStubImpl.invokeServlet(ServletStubImpl.java:348) at weblogic.servlet.internal.WebAppServletContext$ServletInvocationAction.run(WebAppServletContext.java:7047) at weblogic.security.acl.internal.AuthenticatedSubject.doAs(AuthenticatedSubject.java:321) at weblogic.security.service.SecurityManager.runAs(SecurityManager.java:121) at weblogic.servlet.internal.WebAppServletContext.invokeServlet(WebAppServletContext.java:3902) at weblogic.servlet.internal.ServletRequestImpl.execute(ServletRequestImpl.java:2773) at weblogic.kernel.ExecuteThread.execute(ExecuteThread.java:224) at weblogic.kernel.ExecuteThread.run(ExecuteThread.java:183) Sample code: ResultSet rst=null; Statement stmt=null; Connection con=DBConnection.getConnection(); stmt=con.createStatement(); rst=stmt.executeQuery(""select * from dual""); while(rst.next()) { : ://Some code } rst=stmt.executeQuery(""select * from doctor where degree=""BM""); while(rst.next()) { //blah blah } finally { //close conrst and stmt } Most likely the problem is somewhere in the code that you don't show us. It appears that the code in question has issues in multi-threaded environment. DBConnection.getConnection() is probably returning the same connection to all threads. When multiple threads are processing multiple requests the first thread that finishes execution of the method will close the connection leaving all other threads high and sundry. I'm speculating here but is appears that the connection object returned by DBConnection is an instance member of the DBConnection object and that would qualify as a bad practice for a connection manager in a multi-threaded environment. A code fix would avoid the usage of instance members for Connection Statement (and the like) and the ResultSet objects.  I'm not sure what's going on without knowing more about your code. Is it threaded ? Is the underlying database going down (or are you losing connectivity to it). One thing I would do is to implement connection pooling (via Apache DBCP say). This framework will maintain a pool of connections to your database and validate these connections before handing them out to you. You would ask for a new connection each time you make a query (or perhaps set of queries) but because they're pooled this shouldn't be a major oeverhead. No its not threaded.I am using a single connectionresultset and statement.I am using the same statement and resultset for every query How can you use the same resultset ? You mean that you're using the same code for every query and instantiating a new result set each time ? I think an example would be good.  Unless your connection to the database has really been closed I think you did something more like this: try { return resultSet.getBoolean(""SUCCESS""); } finally { resultSet.close(); } This code will actually close the connection before your result set is being evaluated resulting in the exception you show. I did not do that actually... No that can't be right. The finally clause is indeed executed before the method returns but not before the return statement is _evaluated_.  you are not reusing the resultset you are leaking resultsets. rst=stmt.executeQuery... generates a new resultset and the previous resultset is never closed :("
157,A,"Embedded Glassfish v3: deploying sun-resources.xml programmatically fails I would like to be able to package my jpa-ejb-web project as a standalone application by using Glassfish embedded API. To use the JPA layer I need to deploy the sun-resource.xml configuration which should be possible with the asadmin command add-resources path\to\sun-resources.xml. I've this code to do it:  String command = ""add-resources""; ParameterMap params = new ParameterMap(); params.add("""" ""...\sun-resources.xml"" ); CommandRunner runner = server.getHabitat().getComponent(CommandRunner.class); ActionReport report = server.getHabitat().getComponent(ActionReport.class); runner.getCommandInvocation(command report).parameters(params).execute(); but Glassfish refuses it with: 15-Jul-2010 16:34:12 org.glassfish.admin.cli.resources.AddResources execute SEVERE: Something went wrong in add-resources java.lang.Exception: ...\gfembed6930201441546233570tmp\lib\dtds\sun-resources_1_4.dtd (The system cannot find the path specified) at org.glassfish.admin.cli.resources.ResourcesXMLParser.initProperties(ResourcesXMLParser.java:163) at org.glassfish.admin.cli.resources.ResourcesXMLParser.<init>(ResourcesXMLParser.java:109) at org.glassfish.admin.cli.resources.ResourcesManager.createResources(ResourcesManager.java:67) at org.glassfish.admin.cli.resources.AddResources.execute(AddResources.java:106) at com.sun.enterprise.v3.admin.CommandRunnerImpl$1.execute(CommandRunnerImpl.java:305) at com.sun.enterprise.v3.admin.CommandRunnerImpl.doCommand(CommandRunnerImpl.java:320) at com.sun.enterprise.v3.admin.CommandRunnerImpl.doCommand(CommandRunnerImpl.java:1176) at com.sun.enterprise.v3.admin.CommandRunnerImpl.access$900(CommandRunnerImpl.java:83) at com.sun.enterprise.v3.admin.CommandRunnerImpl$ExecutionContext.execute(CommandRunnerImpl.java:1235) at com.sun.enterprise.v3.admin.CommandRunnerImpl$ExecutionContext.execute(CommandRunnerImpl.java:1224) at javaapplication4.Main.main(Main.java:55) and indeed there is no lib directory on the indicated path ... is there something wrong in my code? (I use glassfish-embedded-all-3.0.1.jar) Thanks I solved it by specifying an Embedded File System for the embedded Glassfish and prepopulated the /path/to/my/glassfish/lib/dtds folder with the files which were missing.  EmbeddedFileSystem.Builder efsb = new EmbeddedFileSystem.Builder(); efsb.autoDelete(false); efsb.installRoot(new File(""/path/to/my/glassfish"") true); EmbeddedFileSystem efs = efsb.build(); Server.Builder builder = new Server.Builder(""test""); builder.embeddedFileSystem(efs); builder.logger(true); Server server = builder.build(); server.addContainer(ContainerBuilder.Type.all); server.start(); and asking Glassfish not to delete the folder at the end of the execution. +1 Good to know.  I'm not sure this is possible Running asadmin Commands Using the Sun GlassFish Embedded Server API doesn't mention such a use case (passing a sun-resources.xml). But I would use a preconfigured domain.xml instead of trying to deploy a sun-resource.xml file the result should be similar. From the Sun GlassFish Enterprise Server v3 Embedded Server Guide: Using an Existing domain.xml File Using an existing domain.xml file avoids the need to configure embedded Enterprise Server programmatically in your application. Your application obtains domain configuration data from an existing domain.xml file. You can create this file by using the administrative interfaces of an installation of nonembedded Enterprise Server. To specify an existing domain.xml file invoke the installRoot instanceRoot or configurationFile method of the EmbeddedFileSystem.Builder class or a combination of these methods. The documentation provides code samples showing how to do this (should be pretty straightforward). I don't really agree with the first part of your answer it's only two examples that they provide on the page! +1 however for suggesting the idea of preconfiguring the system @Kevin: As I wrote I'm not sure and I don't really use this API (I use a `domain.xml` that I bundle in my projects) so I might be wrong. Actually now that I rethink about it it should be indeed possible. Did you try to build an absolute path?"
158,A,"How to overcome ""java.sql.SQLException: Too many connections"" exception? I have a simple web application written in java which has servlets accessing the Mysql Database to generate reports. The report generation happens very frequently. I am using the apache commons DBCP to get connections to the DB. I also close the connection explicity in the finally block always. But i do not explicitly close the Statements and ResultSets i create. I'm forced to restart the tomcat instance everytime i get the Exception which says ""java.sql.SQLException: Too many connections"". How do i overcome this.... do i need to increase the maxconnections in Mysql ?. Any help is appreciated. Are you sure your connection is closed? have you tried ConnectionPool? Use connection pooling and always close (return to pool) the connection once work is done. http://dev.mysql.com/tech-resources/articles/connection_pooling_with_connectorj.html The OP is already returning the connection to the pool by calling close() on the Connection.  Yes you should close your Statements / ResultSets - These will typically reference the raw JDBC Connection rather than the PooledConnection proxy Connection returned by the DBCP PooledDataSource. Consider using C3P0 rather than DBCP. Consider using Spring to manage your JDBC operations and you will never have to worry about this kind of thing. Yes. I think the real real problem is the Statements/ResultSets because of the first point. When you close the delegated connection (the one who in fact returns to the pool) it doesn't close it's underlying-actual connection (it wants to keep it). So the RS and ST don't close never and ersources are exhausted. I don't know if C3P0 has something to automatically overcome this but if you take care of this it must work very well. With DBCP. Sorry - My 2nd point about C3P0 was unrelated; you still need to close the Connection and all Statements / ResultSets correctly. It just seems to be preferred over DBCP (if you search for DBCP C3P0 you'll see what I mean)."
159,A,"Postgres Exception : No results were returned by the query I am trying to insert some rows in to a table... I am using postgressql-7.2.jar. I get the following exception org.postgresql.util.PSQLException: No results were returned by the query. at org.postgresql.jdbc2.AbstractJdbc2Statement.executeQuery(AbstractJdbc2Statement.java:255) I have already Googled and the possible reasons suggested are 1) Use executeUpdate() method or execute() method instead of executeQuery() method. 2) This could be seen possibly because of jar problem try out other postgres version jars. 3) In some places they save it could be because of heap space error. I have tried all the three solutions but none of them work... I am not pasting the code since I have just used statement.executeUpdate(queryString). The insert statements load the data in to the table but still I get this error. Can some one help me out in this. Thanks in advance... Post more of your code - I'd put money on the error being caused by your code rather than the driver. A statement inserting rows does not return any rows back as a result as opposed to a SELECT.  What type of SQL statement are you trying to run with executeQuery()? It should not be an INSERT or UPDATE - these are not queries. Without posting the actual SQL statement code samples or what the table looks like - it's pretty hard to actually help you with your problem. Without specifics all we can do is guess. I am not using executeQuery ....I am using executeUpdate() and I am trying to insert in to the table executeUpdate() changes a row that already exists doesn't it? @Balaji you seem to state in your question about using both which is a little confusing. Can you simply post a code sample and the SQL statement? The actual fields tablenames etc are irrelevant these can be obfuscated if this is what you are concerned about. Can I ask why you are using such an old version of the Postgres JDBC driver? [This page][http://jdbc.postgresql.org/download.html] states that even the newest Postgres JDBC driver is compatible with 7.2. Perhaps there is a bug in the driver? @Balaji I just had the same problem and fixed it using the 'execute()' function as matt b alludes to.  This code works perfectly for me running PostgreSQL 8.1 and its driver. Perhaps it can be a template for finding what's wrong with yours. You need a single table named PERSON with columns PERSON_ID FIRST_NAME LAST_NAME. I made PERSON_ID the auto incremented primary key. package persistence; import java.sql.*; import java.util.*; public class DatabaseUtils { private static final String DEFAULT_DRIVER = ""org.postgresql.Driver""; private static final String DEFAULT_URL = ""jdbc:postgresql://localhost:5432/party""; private static final String DEFAULT_USERNAME = ""pgsuper""; private static final String DEFAULT_PASSWORD = ""pgsuper""; public static void main(String[] args) { String driver = ((args.length > 0) ? args[0] : DEFAULT_DRIVER); String url = ((args.length > 1) ? args[1] : DEFAULT_URL); String username = ((args.length > 2) ? args[2] : DEFAULT_USERNAME); String password = ((args.length > 3) ? args[3] : DEFAULT_PASSWORD); Connection connection = null; try { connection = createConnection(driver url username password); DatabaseMetaData meta = connection.getMetaData(); System.out.println(meta.getDatabaseProductName()); System.out.println(meta.getDatabaseProductVersion()); String sqlQuery = ""SELECT PERSON_ID FIRST_NAME LAST_NAME FROM PERSON ORDER BY LAST_NAME""; System.out.println(""before insert: "" + query(connection sqlQuery Collections.EMPTY_LIST)); connection.setAutoCommit(false); String sqlUpdate = ""INSERT INTO PERSON(FIRST_NAME LAST_NAME) VALUES(??)""; List parameters = Arrays.asList( ""Foo"" ""Bar"" ); int numRowsUpdated = update(connection sqlUpdate parameters); connection.commit(); System.out.println(""# rows inserted: "" + numRowsUpdated); System.out.println(""after insert: "" + query(connection sqlQuery Collections.EMPTY_LIST)); } catch (Exception e) { rollback(connection); e.printStackTrace(); } finally { close(connection); } } public static Connection createConnection(String driver String url String username String password) throws ClassNotFoundException SQLException { Class.forName(driver); if ((username == null) || (password == null) || (username.trim().length() == 0) || (password.trim().length() == 0)) { return DriverManager.getConnection(url); } else { return DriverManager.getConnection(url username password); } } public static void close(Connection connection) { try { if (connection != null) { connection.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void close(Statement st) { try { if (st != null) { st.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void close(ResultSet rs) { try { if (rs != null) { rs.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void rollback(Connection connection) { try { if (connection != null) { connection.rollback(); } } catch (SQLException e) { e.printStackTrace(); } } public static List<Map<String Object>> map(ResultSet rs) throws SQLException { List<Map<String Object>> results = new ArrayList<Map<String Object>>(); try { if (rs != null) { ResultSetMetaData meta = rs.getMetaData(); int numColumns = meta.getColumnCount(); while (rs.next()) { Map<String Object> row = new HashMap<String Object>(); for (int i = 1; i <= numColumns; ++i) { String name = meta.getColumnName(i); Object value = rs.getObject(i); row.put(name value); } results.add(row); } } } finally { close(rs); } return results; } public static List<Map<String Object>> query(Connection connection String sql List<Object> parameters) throws SQLException { List<Map<String Object>> results = null; PreparedStatement ps = null; ResultSet rs = null; try { ps = connection.prepareStatement(sql); int i = 0; for (Object parameter : parameters) { ps.setObject(++i parameter); } rs = ps.executeQuery(); results = map(rs); } finally { close(rs); close(ps); } return results; } public static int update(Connection connection String sql List<Object> parameters) throws SQLException { int numRowsUpdated = 0; PreparedStatement ps = null; try { ps = connection.prepareStatement(sql); int i = 0; for (Object parameter : parameters) { ps.setObject(++i parameter); } numRowsUpdated = ps.executeUpdate(); } finally { close(ps); } return numRowsUpdated; } } There's nothing wrong with this example - and that's the sad part about it. Man I remember now why I use the JdbcTemplate/SimpleJdbcTemplate classes Spring provides - could they have made JDBC more obnoxious if they actually tried to do so? I like Spring too MetroidFan2002. Sad indeed. 8)"
160,A,java connectivity with mysql How to set up type 1 connectivity with MySql datasource and java application in windows xp service pack 3 environment? Type I? Why not Type IV the 100% Java solution using the JDBC driver? This MySQL forum response agrees with me - it's not the right way to go. I'd recommend sticking with Type IV JDBC connector. +1: The higher the type number the better... usually.
161,A,How do I get at the sql statement that caused an SQLException using the Postgres JDBC driver in Java? Background In my current project - a server product with no GUI front-end I'm trying to write in better error handling support. Errors currently are outputted to the logs and are typically not read by users. We use PostgreSQL as our database backend and we access it using direct JDBC calls and DAOs via a database pooler. Most database related exceptions are wrapped in a generic DatabaseException class that implements RuntimeException and attempts to pull out debugging and state information from the exception it was passed. In our particular case it will access the underlying PostgreSQL database driver - PSQLException. So far this approach has worked well for getting more verbose information about what caused the database error with the notable exception described below. Furthermore since we have very specific performance and legacy support requirements we have a lot of custom SQL magic that makes the following the stack trace back a bit more time intensive but not impossible or difficult. Problem Described I have noticed that when we get a SQLException as a result of a faulty SQL statement the driver's implementation does not return the SQL statement that caused the error. After doing a little searching I found out that there is a way to drop the PostgreSQL driver into a debug mode on startup and have it display properties about its internal query. However it is undesirable for us to run the driver in debug mode in our production environment (and honestly I haven't been able to figure out how to get it into the freakin mode!). Question Has anyone else dealt with this same issue before and found a solution? If not is there some OOP pattern out there for storing query information before execution and then assigning that information to the exception thrown? Or do most developers just feel that they don't need the full query to troubleshoot database issues? Honestly I don't need it because I have the full stack trace and I can look up the invoking query but it definitely speeds up my debugging by having it be the first thing that I see in the error logs. I am assuming that when you make the call to execute the query you have the statement and you receive the Exception so at that point you have both. It seems like you could do your analysis there. However maybe you're catching things further up. So what you might do is on your own custom subclass of Exception DatabaseException add a triggeringSQLStatement member with a getter and setter and then at the place where you attempt to execute the statement catch the original Exception from PostgreSQL create a new DatabaseException set the triggeringSQLStatement to be the statement you just executed and call initCause() on the DatabaseException to set the Exception caught from PostgreSQL as the cause of your exception; then throw your DatabaseException and the calling code which catches it will have an object that prints out a very decent stack trace of what happened plus provides access to the SQL statement that caused the problem. For more information on this approach you might want to research Java Exception chaining. Even if you don't use all of what I just described I think you should definitely be using Java Exception chaining already. If there's not a spot anywhere in the code where you have access to both the SQL statement that caused the problem and the Exception that gets thrown I'd be very curious as to why and how that is possible. And I'd suggest you redesign your code so that you do have such a spot. Edit: Since you're wanting to see the SQL statement first thing in the log you could probably also override your DatabaseException's toString() method (or other appropriate methods; I'm not sure what gets called when an Exception is printed out) to print out the included SQL statement assuming you included it as I described above.  The stacktrace can point you to the DAO method that caused the problem isn't that the case? Edit after comment: If your SQL query is complex and dynamically generated from previous parts of the code then you could log (level TRACE or DEBUG) these statements before executing them. In the logging configuration you could enable logs only for the DAO(s). For the case of DAO methods that approach works fairly well. However in the case of some of our more complex SQL statements invoked via JDBC it is a little more complicated because we get a trace to the execute method and we then have to work are we back to where the statement/prepare was defined.  The easiest way to do this I think is to use a third party product like p6spy. It gets in between your jdbc driver and your database and reports the exact queries that are run. It's very easy to run on demand as it's implemented as another JDBC driver that will delegate to your actual JDBC driver. Very powerful tool that I can't imagine working without. http://www.p6spy.com/  Another solution to spy on the queries you are executing is pgFouine which analyses and reports on the logs generated by Postgres  Why not add a file logger around all JDBC calls (log4j)? Whenever you make a SQL call you log the SQL and how long it took to execute. Simple stuff. We do this for any call to an external system E.g. SOAP calls RMI Corba etc. Its proved invaluable almost every day and if it affects performance.. I haven't noticed! If you have security concerns i.e. don't want it to go to a log file on a client machine you could use a SocketAppender and send it to a remote machine for centralised logging purposes. This won't be totally secure but would stop the casual snooper.  I used to add the SQL query in my custome Exception object when ever there is an SQLException. In the code where ever I am logging the exception details in log file I used to log the SQL also. Its better to log the parameters as well. +1
162,A,"how to get the result query one by one in jsp and mysql I am trying to implement as Online Mock exam in JSP but I have a problem to get the questions one by one it get connceted for the first time and show me the first question and answers but when I click on ""next"" again it still show me the first question I think by clicking on ""next"" it start querying again. please help me. this is my bean : database.SQLSelectStatement sqlselect; database.SQLSelectStatement sqlselect2; static ResultSet questions; static ResultSetMetaData rsm; static ResultSet answers; public void setConnection() throws SQLException { if (database.DatabaseManager.getInstance().connectionOK()) { sqlselect = new database.SQLSelectStatement(""question"" ""question"" ""0""); sqlselect2 = new database.SQLSelectStatement(""answers"" ""question_id"" ""0""); questions = sqlselect.executeWithNoCondition(); } } public int i=0; public String getQuestions() throws SQLException { String result = """"; rsm = questions.getMetaData(); for (int i = 0; i < rsm.getColumnCount(); i++) { result += ""<th>"" + rsm.getColumnName(i + 1) + ""</th>""; } if (!questions.isLast()) { questions.next(); System.out.println(i+1); result += ""<tr>""; result += ""<td>"" + questions.getInt(1) + ""</td>""; result += ""<td>"" + questions.getString(2) + ""</td>""; result += ""</tr>""; result += ""<tr>""; sqlselect2.setValue(String.valueOf(questions.getInt(1))); answers = sqlselect2.Execute(); while (answers.next()) { result += ""<tr> <td colspan='2'><input type='radio' name='answer' value='"" + answers.getString(2) + ""'> "" + answers.getString(2) + ""</td></tr>""; } result += ""</tr>""; answers.close(); } return result; } this is the HTML: <html> <head> <meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8""> <title>JSP Page</title> </head> <body> <h1>JSP Page</h1> <jsp:useBean id=""exam"" class=""exam.ExamQuestions""></jsp:useBean> <% exam.setConnection(); %> <form method=""post""> <table > <%=exam.getQuestions()%> </table> <input type=""submit"" name=""action"" value=""next""/> </form> <% String action = request.getParameter(""action""); if (""next"".equals(action)) { out.println(request.getParameter(""answer"")); } %> </body> </html> Sorry if I sound harsh but there's too much wrong with the given code that I don't know where to start with answering/correcting. The basic concepts are completely misunderstood. You basically need to rewrite everything from the beginning on. I suggest you to leave this project completely aside for now and start with those tutorials. Once you have a decent understanding how it's supposed to work/fit all together then restart developing from blank based on what you've learnt from those tutorials. To the point: use a JSP page for view. Use a Servlet class to control preprocess and postprocess the model/view. Use HTML inputs/buttons in JSP to send request parameters. Use those request parameters in servlet to take actions accordingly. Use a model object (Javabean class) to hold the data. Use a DAO class to interact with database and take/return model objects. Use taglibs like JSTL in JSP to control page flow. Use EL in JSP to access model data. Good luck. thanks I think you are right too much mess. thanks for the tutorials I am going to review them again. :)"
163,A,"JDBC Batch Insert OutOfMemoryError I have written a method insert() in which I am trying to use JDBC Batch for inserting half a million records into a MySQL database: public void insert(int nameListId String[] names) { String sql = ""INSERT INTO name_list_subscribers (name_list_id name date_added)""+ "" VALUES (? ? NOW())""; Connection conn = null; PreparedStatement ps = null; try{ conn = getConnection(); ps = conn.prepareStatement(sql); for(String s : names ){ ps.setInt(1 nameListId); ps.setString(2 s); ps.addBatch(); } ps.executeBatch(); }catch(SQLException e){ throw new RuntimeException(e); }finally{ closeDbResources(ps null conn); } } But whenever I try to run this method I get the following error: java.lang.OutOfMemoryError: Java heap space com.mysql.jdbc.ServerPreparedStatement$BatchedBindValues.<init>(ServerPreparedStatement.java:72) com.mysql.jdbc.ServerPreparedStatement.addBatch(ServerPreparedStatement.java:330) org.apache.commons.dbcp.DelegatingPreparedStatement.addBatch(DelegatingPreparedStatement.java:171) If I replace ps.addBatch() with ps.executeUpdate() and remove ps.executeBatch() it works fine though it takes some time. Please let me know if you know if using Batch is appropriate in this situation and if it is then why does it give OurOfMemoryError? Thanks It is out of memory because it hold all the transaction in memory and only send it over to the database when you call executeBatch. If you don't need it to be atomic and would like the get better performance you can keep a counter and call executeBatch every n number of records. and what should be the value of n? The value is up to you you have to benchmark your application to get the best value for that you want for the trade off between memory and performance.  addBatch and executeBatch give you the mechanism to perform batch inserts but you still need to do the batching algorithm yourself. If you simply pile every statement into the same batch as you are doing then you'll run out of memory. You need to execute/clear the batch every n records. The value of n is up to you JDBC can't make that decision for you. The larger the batch size the faster things will go but too large and you'll get memory starvation and things will slow down or fail. It depends how much memory you have. Start off with a batch size of 1000 for example and experiment with different values from there. final int batchSize = 1000; int count = 0; for(String s : names ) { ps.setInt(1 nameListId); ps.setString(2 s); ps.addBatch(); if (++count % batchSize == 0) { ps.executeBatch(); ps.clearBatch(); //not sure if this is necessary } } ps.executeBatch(); // flush the last few records."
164,A,NoClassDefFound error - Spring JDBC Right now I'm compiling my .class files in eclipse and moving them over to my %tomcat_home%\webapps\myapp\WEB-INF\classes directory. They compile just fine. I also have in the ...\classes directory a org.springframework.jdbc-3.0.2.RELEASE.jar which I have verified has the org.springframework.jdbc.datasource.DriverManagerDataSource class inside it. However I get a NoClassDefFound error when I run my class and it tries to DriverManagerDataSource source = new DriverManagerDataSource(); I don't understand why it wouldn't be finding that jar. Any help is appreciated! Jar files in webapp should be placed in WEB-INF/lib not in WEB-INF/classes. I knew it would be something simple like that... thanks! Now on to the next roadblock...
165,A,"connect Ms Access to java I extracted data from excel using poi api. Now I want to store the data in access please clarify Why would you do that when you can go directly from Excel to Access? Try to use ucanaccess instead of odbc just follow this [http://stackoverflow.com/questions/21955256/manipulating-an-access-database-from-java-without-odbc][1]][1] You need something like JetProxy -- a JDBC driver interfacing to Jet (the internal name of Microsoft Access's own quasi-relational sort-of-SQL DB engine). There are other products much in the same vein but I have no personal experience to help suggest which product is best for your purposes -- just try a few!-)  To the point you just want to ""convert"" Excel to MSAccess using Java code? Here are the steps: 1) Extract data from Excel into Java objects (List String Number Javabean etc). 2) Insert the data in flavor of those Java objects into MSAccess. That's basically all. For 1) you can use under each the Apache POI as you already found out. For 2) you can use the JDBC. I think your problem is more that you don't understand what JDBC is and how to work with it. In that case you may find the Sun's JDBC tutorial useful. Good luck.  You can either use the commercial JDBC drivers by HXTT or the JDBC-ODBC bridge by Sun"
166,A,"Getting Number of Rows in a Group By Query with Microsoft Access I have basically the same problem outlined in this question however I am using Microsoft Access as a database instead of MySQL. The result of which is that SQL_CALC_FOUND_ROWS doesn't seem to be available to me. Believe me I want to switch but for the moment it is out of the question. I have a query that aggregates a number of rows essentially looking for repeat rows based on certain keys using a group by. It looks something like this: Select key1 key2 key3 Count(id) from table group by key1 key2 key3 having Count(id) > 1 I need to determine the number of rows (or groupings) that query will return. The database is being accessed through Java so in theory I could simply run the query and cycle through it twice but I was hoping for something faster and preferably SQL based. Any ideas? MS Access's record count should give you what you need or am I missing something? If you need distinct values from keys try this SELECT COUNT(*) AS Expr2 FROM ( SELECT DISTINCT [key1] & ""-"" & [key2] & ""-"" & [key3] AS Expr1 FROM Table1 ) AS SUB; How is this answer not the same as running the query twice? @David It is running the query twice but the second time contains only the answer I need. And it runs it in SQL twice. When I said running it twice I meant running the original query and then scrolling all the way through it's rows (which could be thousands or even millions) twice. Which I would really rather avoid. I'd prefer to let SQL do the counting since it will likely do it faster than Java will. Which is exactly what this answer does. *The database is being accessed through Java* but I guess Java has an equivalent of RecordCount Can you elaborate? How do I view the Record count? Note I'm accessing this through Java and not the Access front end... @Andomar No it doesn't. There is no way to get the record count out of a Java ResultSet Object. See edited answer Awesome that worked thank you! Am glad am busy working on some access and havent done it in YEARS!!! X-)  When you create the Statement object you can declare it to be scrollable. Then the first thing you do is scroll to the end and get the record number. As you're looking at the last record this will be the number of records in the result set. Then scroll back to the beginning and process normally. Something like: Statement st=connection.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE ResultSet.CONCUR_READ_ONLY); ResultSet rs=st.executeQuery(myQueryString); boolean any=rs.last(); int count = any ? count=getRow() : 0; ... do whatever with the record count ... rs.first(); while (rs.next()) { ... whatever processing you want to do ... } rs.close(); ... etc ... I have no idea what the performance implications of doing this with MS Access will be whether it can jump directly to the end of the result set or if it will have to sequentially read all the records. Still it should be faster than executing the query twice. I found this answer in multiple places however the value returned from getRow was wrong (in the thousands when it should be hundreds). And for some unknown reason - probably some issue with access - scrolling seemed to screw up the cursor. Hmm. I've used getRow many times with MySQL and Oracle and it's always worked fine. I guess it's possible that there's a bug in MS Access or the JDBC driver. My first thought would be to do the last/getRow and check the count read some identifying field in that record and dump it out then do first and loop through the records counting. If last/getRow really says 1000 but looping through only finds 100 or whatever like wow that's bizarre. I'd run some tests to make very sure before I concluded there was this blatant a bug."
167,A,"How do I get the row count in JDBC? I've executed a JDBC query to obtain a resultset. Before iterating over it I'd like to quickly find out how many rows were returned. How can I do this with high performance? I'm using Java 6 Oracle 11g and the latest Oracle JDBC drivers. Short answer: you can't. Long answer: you can't partly because the database may be lazily evaluating the query only returning rows as you ask for them. EDIT: Using a scrollable ResultSet you can :) Indeed I asked this very question in the Java databases newsgroup a long time ago (back in 2001!) and had some helpful responses.  You're going to have to do this as a separate query for example: SELECT COUNT(1) FROM table_name Some JDBC drivers might tell you but this is optional behaviour and more to the point the driver may not know yet. This can be due to how the query is optimised eg two example execution strategies in Oracle are to get all rows as quickly as possible or to get the first row as quickly as possible. If you do two separate queries (one a count and the other the query) then you'll need to do them within the same transaction. This will work well on Oracle but can be problematic on other databases (eg SQL Server will either show you uncommitted data or block on an external uncommitted update depending on your isolation level whereas Oracle supports an isolation level that gives you a transactionally consistent view of the data without blocking on external updates). Normally though it doesn't really matter how many rows there are. Typically this sort of query is either batch processed or paged and either way you have progress information in the form of rows loaded/processed and you can detect the end of the result set (obviously). Good answer though I don't understand the final comment about having progress information. Where is this coming from?  To get the number of rows from JDBC: ResultSet rs = st.executeQuery(""select count(*) from TABLE_NAME""); rs.next(); int count = rs.getInt(1);  //Create a Statement class to execute the SQL statement Statement stmt = con.createStatement(); ResultSet rs = stmt.executeQuery(""SELECT COUNT(*) AS COUNT FROM TABLENAME""); while(rs.next()) { System.out.println(""The count is "" + rs.getInt(""COUNT"")); } //Closing the connection con.close();  see the example for Tom's solution and also an Oracle specific (and faster?) solution: http://www.oracle.com/technology/sample_code/tech/java/codesnippet/jdbc/rs/CountResult.html  If your driver supports it(!) you can call ResultSet.afterLast() ResultSet.getRow() ResultSet.beforeFirst(). Performance may or may not be good. A better solution would be to rewrite your algorithm not to require the size up front.  ResultSet rs = stmt.executeQuery(sql); int rowCount = rs.last() ? rs.getRow() : 0; // Number of rows in result set. Don't forget to set cyrsor to beforeFirst() row! :) Works nice. You should add that you need a scrollable result set for this.  Maybe late answer but what about this solution: //Create a Statement class to execute the SQL statement Statement s = con.createStatement(); s.execute(""CREATE TABLE tmp AS SELECT COUNT(*) AS nb FROM TABLENAME"");//CREATAS ResultSet rs = s.executeQuery(""SELECT nb FROM tmp""); if(rs.next()) { System.out.println(""The count is "" + rs.getLong(""nb"")); } s.execute(""DROP TABLE tmp;"");//DROP //Close the connection con.close(); ADVANTAGES Avoidance of using a loop to determine line by line the final count The DB do all the work Guarantee of only 3 queries are performed against the DB CONS A little more code Calculation is less easily stoppable than with a while loop (see BONUS 2) For small datasets this solution may be an overkill BONUS If your DB supports temporary tables you can save the final DROP statement. If the CREATEAS takes too long you can call s.cancel() from a timeout thread to abort it. Instead of * it's possible to pass only one field to the COUNT function for speeding things up"
168,A,"Value from last inserted row in DB Is there some way to get a value from the last inserted row? I am inserting a row where the PK will automatically increase due to sequence created and I would like to get this sequence number. Only the PK is guaranteed to be unique in the table. I am using Java with a JDBC and Oracle. I forgot to add that I would like to retrieve this value using the resultset below. (I have tried this with mysql and it worked successfully but I had to switch over to Oracle and now I get a string representation of the ID and not the actually sequence number) Statement stmt = conn.createStatement(); stmt.executeUpdate(insertCmd Statement.RETURN_GENERATED_KEYS); stmt.RETURN_GENERATED_KEYS; ResultSet rs = stmt.getGeneratedKeys(); if(rs.next()){ log.info(""Successful insert""); id = rs.getString(1); } The above snippet would return the column int value stored in a mysql table. But since I have switched over to Oracle the value returned is now a strange string value. have you seen this? http://stackoverflow.com/questions/201887/primary-key-from-inserted-row-jdbc @Nathan Yes I have seen that I just updated my question with an example which is similar to the link you just posted. This question is **not a duplicate** of the linked question because this question is for Oracle and the other question is for PostgreSQL. The top answer for the other question **cannot be used** as an answer for this question because of feature differences between Oracle and PostgreSQL. This is not consistent with other databases but when using Oracle getGeneratedKeys() returns the ROWID for the inserted row when using Statement.RETURN_GENERATEDKEYS. So you need to use the oracle.sql.ROWID proprietary type to ""read"" it: Statement stmt = connection.createStatement(); stmt.executeUpdate(insertCmd Statement.RETURN_GENERATED_KEYS); ResultSet rs = stmt.getGeneratedKeys(); oracle.sql.ROWID rid = (oracle.sql.ROWID) rs.getObject(1); But this won't give you the generated ID of the PK. When working with Oracle you should either use the method executeUpdate(String sql int[] columnIndexes) or executeUpdate(String sql String[] columnNames) instead of executeUpdate(String sql int autoGeneratedKeys) to get the generated sequence value. Something like this (adapt the value to match the index or the name of your primary key column): stmt.executeUpdate(INSERT_SQL new int[] {1}); ResultSet rs = stmt.getGeneratedKeys(); Or stmt.executeUpdate(INSERT_SQL new String[] {""ID""}); ResultSet rs = stmt.getGeneratedKeys(); While digging a bit more on this it appears that this approach is shown in the Spring documentation (as mentioned here) so well I guess it can't be totally wrong. But unfortunately it is not really portable and it may not work on other platforms. What I don't get Pascal is you are against the RETURNING clause but have proposed a solution that requires two database calls. The benefit of Adam's solution is it's a single database call. No sucess I'm getting syntax errors. I'll see what I'm doing wrong and give an update. @David I don't really like triggers mostly because they do some ""magic"" stuff behind the scene stealthy and because I don't think that spreading logic over Java and the database is a good idea. So I don't use them if I can avoid them. Regarding the *""two database calls""* can you elaborate on this I'm not sure I'm following you.  Can you not do something like this? SELECT value FROM table ORDER BY id DESC LIMIT 1 No. What happens if someone else inserts a row between the time you insert and the time you select? You get the wrong value.  What you're trying to do is take advantage of the RETURNING clause. Let's setup an example table and sequence: CREATE TABLE ""TEST"" ( ""ID"" NUMBER NOT NULL ENABLE ""NAME"" VARCHAR2(100 CHAR) NOT NULL ENABLE CONSTRAINT ""PK_TEST"" PRIMARY KEY (""ID"") ); CREATE SEQUENCE SEQ_TEST; Now your Java code should look like this: String insertSql = ""BEGIN INSERT INTO TEST (ID NAME) VALUES (SEQ_TEST.NEXTVAL() ?) RETURNING ID INTO ?; END;""; java.sql.CallableStatement stmt = conn.prepareCall(insertSql); stmt.setString(1 ""John Smith""); stmt.registerOutParameter(2 java.sql.Types.VARCHAR); stmt.execute(); int id = stmt.getInt(2); I didn't say that ""I"" do it but I made an assumption based upon the question. Yeah I guess that does make my answer a bit more complicated than necessary. I may update the SQL but the crux of my answer was to use the `RETURNING` clause to get the value of the PK. @Pascal that trigger is absolutely portable. I really think that using a trigger for this is an horrible solution: it makes the code even less portable and adds extra complexity for nothing. The original question states ""I am inserting a row where the PK will automatically increase due to sequence created...."" How else would you do this in Oracle if not using a trigger to populate the primary key? @Adam Using a trigger absolutely **not** necessary you can include `seq.nextval` in the INSERT statement. No really I find this approach unnecessary cumbersome and I don't get why people do like it.  You should use ResultSet#getLong() instead. If in vain try ResultSet#getRowId() and eventually cast it to oracle.sql.ROWID. If the returned hex string is actually the ID in hexadecimal flavor then you can try converting it to decimal by Long#valueOf() or Integer#valueOf(). Long id = Long.valueOf(hexId 16); That said Oracle's JDBC driver didn't support ResultSet#getGeneratedKeys() for a long time and is still somewhat troublesome with it. If you can't get that right then you need to execute a SELECT CURRVAL(sequencename) on the same statement as you did the insert or a new statement inside the same transaction if it was a PreparedStatement. Basic example: public void create(User user) throws SQLException { Connection connection = null; PreparedStatement preparedStatement = null; Statement statement = null; ResultSet generatedKeys = null; try { connection = daoFactory.getConnection(); preparedStatement = connection.prepareStatement(SQL_INSERT); preparedStatement.setValue(1 user.getName()); // Set more values here. int affectedRows = preparedStatement.executeUpdate(); if (affectedRows == 0) { throw new SQLException(""Creating user failed no rows affected.""); } statement = connection.createStatement(); generatedKeys = statement.executeQuery(SQL_CURRVAL); if (generatedKeys.next()) { user.setId(generatedKeys.getLong(1)); } else { throw new SQLException(""Creating user failed no generated key obtained.""); } } finally { close(generatedKeys); close(statement); close(preparedStatement); close(connection); } } Oh from your code example the following line stmt.RETURN_GENERATED_KEYS; is entirely superfluous. Remove it. You can find here another example which I posted before about getting the generated keys it uses the normal getGeneratedKeys() approach. I tried the ResultSet#getLong() it didn't work. Error returned was ""Invalid column type: getLong not implemented for class oracle.jdbc.driver.T4CRowidAccessor"" Am going to try your second suggestion. Try `java.sql.RowId` or `oracle.sql.ROWID`. The following: oracle.sql.ROWID rid = rs.getObject(1); ID = rid.stringValue(); ID contains a hexadecimal value which is exactly I was getting before with the rs.getString(1); Will try your last suggestion. Maybe it's just the ID in hexadecimal format. Try converting it to decimal. Your suggestion should have worked but perhaps it's because the value I'm getting back from oracle.sql.ROWID is not a hexadecimal value? I get this error: java.lang.NumberFormatException: For input string: ""AAAS+XAAGAAAAEvAAP"" ~~~~ The value in quotes is the value that I get back from ROWID.stringValue(); That's indeed not hexadecimal. How did you come to this conclusion? Well I don't do Oracle extensively so I can't help you further with this. Your last resort will be a `SELECT CURRVAL` or to wait for someone else with more Oracle experience. @BalusC Can you suggest how I can use the SELECT CURRVAL in the insert stmt? I tried the following but I keep getting errors. stmt.executeUpdate(insertCmd + ""SELECT CURRVAL(CONTACT_SEQ)"" Statement.RETURN_GENERATED_KEYS); ORA-00933: SQL command not properly ended Execute it on the same (or a new) statement **after** the insert. Thus first `executeUpdate()` the `insert` and then `executeQuery()` the `select currval`. The ID should be available by `ResultSet#getLong()`. After 4 hours of searching the internet I find BalusC's answer and it works the best for me. As long I use the same connection I think I can confidently say that I will always get the correct value even if another INSERT happens simultaneously."
169,A,"jdbc connectivity error while establishing database connectivity with java applicationi tried to run .jar file it showing an error msg ""Failed to load main class manifest attribute from c:\program files\sqljdbc_2.0.1803.100_enu\sqljdbc_2.0\enu\sqljdbc4.jar "" how i can proceed further? dupe: http://stackoverflow.com/questions/1858782/database-connectivity First pick one from here The .jar file with the driver is not supposed to be run - it is supposed to provide low-level implementation of the communication between your java application and the database in question. Anyway what are you doing ""while establishing db connectivity"" ?  Don't run the .jar file. It's a library. Instead you need to reference it whilst running your class file e.g. java -cp c:\program files\..\sqljdbc_2.0\enu\sqljdbc4.jar {yourclassfile} You can run a .jar file if it's configured as such. However a JDBC .jar won't have the appropriate configuration and you should think of it as similar to a (say) .DLL. Don't forget to wrap the path in quotes. There's a space in it. Good point re. the spaces"
170,A,"Problem with adding rows with JDBC and MySQL? I'm using JDBC in sync with MySQL to add and define rows to a MySQL database's Table. The problem is that I don't know why it is throwing an Exception when I use methods from the ResultSet class to add rows to the table. Bear in mind that I've earlier tried just reading the table via ResultSet methods and it successfully printed out the cell values. The following is the concerned code fragement: public void run(){ try { Class.forName(""com.mysql.jdbc.Driver""); Connection con = DriverManager.getConnection( ""jdbc:mysql://localhost:3306/temp_book_database""""root""""1234""); ResultSet set = con.createStatement(ResultSet.TYPE_SCROLL_SENSITIVE ResultSet.CONCUR_UPDATABLE).executeQuery(""SELECT * FROM book_info""); set.moveToInsertRow(); set.updateString(1 ""Osama's POV""); set.updateString(2 ""Osama B Laden""); set.updateInt(3 2800); set.updateString(4 ""Osama bin Laden's debute book on terrorism""); set.insertRow(); set.moveToCurrentRow();set.beforeFirst(); //I'm guessing the bottom while loop is not executed because the above is generating the Exception while (set.next()){ System.out.println(set.getString(""Book_Title"")+ set.getString(""Book_Author"")+ set.getString(""MRP"")+set.getString(""Comments"")); } } catch (ClassNotFoundException e) { // TODO Auto-generated catch block e.printStackTrace(); } catch (Exception e){System.out.println(""prob with code""); e.printStackTrace();} And this is the Console: prob with code com.mysql.jdbc.NotUpdatable: Result Set not updatable (referenced table has no primary keys).This result set must come from a statement that was created with a result set type of ResultSet.CONCUR_UPDATABLE the query must select only one table can not use functions and must select all primary keys from that table. See the JDBC 2.1 API Specification section 5.6 for more details. at com.mysql.jdbc.UpdatableResultSet.moveToInsertRow(UpdatableResultSet.java:1013) at testJDBCDriver.run(testJDBCDriver.java:21) at testJDBCDriver.main(testJDBCDriver.java:9) [UPDATE] After adding the id column in the table as INTEGER AUTO_INCREMENT PRIMARY KEY the ResultSet successfully added the row to the table now I just want to know why MySQL doesn't accept request to add new row from ResultSet if the id column isn't present in the table? Is this true: ""referenced table has no primary keys""? I would set the table up with a PK like a GUID and see if that helps @ Boden Yes. This is not a joke. Like I mentioned I've tried using ONLY the while loop and it printed the cells properly OH! So you meant to say that I need to create another column entitled ""id"" ? But why because my already existing database handling code weren't meant to handle another column titled ""id"" The JDBC 2.X API with Mysql doesn't work in update mode if you don't set primary key in the table. could you tell me what exactly *is* primary key? The primary key of a relational table uniquely identifies each record in the table. It can either be a normal attribute that is guaranteed to be unique (such as Social Security Number in a table with no more than one record per person) or it can be generated by the DBMS (such as a globally unique identifier or GUID in Microsoft SQL Server). Primary keys may consist of a single attribute or multiple attributes in combination. So could you tell me how to insert Primary Keys inside (I guess) each cell. @Catfish: A primary key is typically a single column in a table. You need to create a new column that uniquely identifies each row. Since you appear to be working with books you might try setting your ISBN column to be the primary key. ""alter table MYTABLE add primary key (KEYFIELD)"" where MYTABLE is the name of the table and KEYFIELD is the name of the field you are using as a key. If you want to use an auto-incrementing key you'll have to first create the key field with a statement like ""alter table MYTABLE add column KEYFIELD integer auto_increment"". Or you could do it all at once with ""alter table MYTABLE add column KEYFIELD integer auto_increment primary key"". Read the documentation on create statements and keys for more info."
171,A,"How to find that a SQL query executed has returned nothing? import java.net.URL; import java.net.URLConnection; import java.sql.*; public class searchlink{ public static void main(String args[]) throws Exception { //String link=""http://hosted.ap.org""; Connection con=null; Statement stmt=null; Statement stmtR=null; if(con==null){ SQLConnection.setURL(""jdbc:sqlserver://192.168.2.53\\SQL2005;user=sa;password=365media;DatabaseName=LN_ADWEEK""); con=SQLConnection.getNewConnection(); stmt=con.createStatement(); stmtR=con.createStatement(); } ResultSet rs; rs=stmt.executeQuery(""select url from urls where url='http://www.topix.com/rty/elyria-oh'""); while(rs.next()){ String mem=rs.getString(1); System.out.println(""Result is ""+mem);} } } The above program prints the output if the query returns a row. If the query does not return any the program stops without printing anything. Instead of it getting stopped without printing anything I want the program to identify that the query has returned nothing and print the output saying something like this "" There is nothing returned after SQL query execution "". How to identify using some method or variable that the query has been executed without returning any row? Place a counter in your loop... int count = 0; while ( rs.next() ) { count++; String mem=rs.getString(1); System.out.println(""Result is ""+mem);} . . . } then ... if (count==0) { // show your message ""There is nothing returned after SQL query execution"" } Any call to rs.next() moves the cursor so if (rs.next() == false) would bump you one ahead and make you skip the first result if you had 2 or more or miss it entirely if you had one result. Good Luck Rick Which fails if it returns 2**32 rows. With all due respect the statement while(rs.next()) works for 01many results... count is incremented for any scenerio of 1 or more so testing count for non-zero yeilds the answer that you either found 1 or more records or none. At least thats what it looks like to me. Rick  bool hasRows = false; while(rs.next()){ hasRows = true; // do other stuff required. } if(!hasRows) { // do stuff when no rows present. } -- or if(!rs.next()) { // do stuff when no rows prsent. } else { do{ // do stuff required }while(rs.next()); } keeping in mind that the check if(!rs.next()) will advance the cursor in the result set. Don't advance it again before you get the values. Thanks Mathew :) +1 for the elegant second version. Unfortunately the logic is harder to read and you missed a semicolon. @tc thanks got that semicolon in there I always forget them in do-whiles. I agree it's not immediately obvious what you are doing in the second example. Like anything else it's all about personal tastes and team standards which side of the readability / elegance spectrum you choose to error on (though thankfully they aren't always mutually exclusive).  if(!rs.isBeforeFirst()) System.out.println(""no data is returned"");  The first (rs.next()) will tell you if any data was returned. React to that one then loop through the rest (if there are any). Below I extract the logic for what to do when there is a row into a separate method and then call that after the ""if"" and within each ""where"".  . . . ResultSet rs; rs=stmt.executeQuery(""select url from urls where url='http://www.topix.com/rty/elyria-oh'""); if (rs.next() { printRow(rs); while(rs.next()){ printRow(rs); } } else { System.out.println(""no data returned""); } } static public printRow(ResultSet rs) { String mem=rs.getString(1); System.out.println(""Result is ""+mem);} } }  boolean got_result = false; while (...) { got_result = true; ... } if (!got_result) { ... }  if (rs.hasNext()) { while(rs.next()) { String mem=rs.getString(1); System.out.println(""Result is ""+mem); } } else { System.out.println(""There is nothing returned after SQL query execution ""); } maybe~ I don't believe the ResultSet will be null but rather instantiated and empty. Thanks edited my reponse accordingly. Still not right. ""rs.next()"" will move it to the next row. You mean ""rs.hasNext()""  The normal JDBC idiom is to collect the results in a collection like List<Entity>. The another normal idiom is to properly close resources in finally. Your code is leaking DB resources. If you run this repeatedly in a short time then the DB will run out of resources. Here's a kickoff example: public List<Entity> list() throws SQLException { // Declare resources. Connection connection = null; Statement statement = null; ResultSet resultSet = null; List<Entity> entities = new ArrayList<Entity>(); try { // Acquire resources. connection = database.getConnection(); statement = connection.createStatement(""SELECT id name value FROM entity""); resultSet = statement.executeQuery(); // Gather data. while (resultSet.next()) { Entity entity = new Entity(); entity.setId(resultSet.getLong(""id"")); entity.setName(resultSet.getString(""name"")); entity.setValue(resultSet.getInteger(""value"")); entities.add(entity); } } finally { // Close resources in reversed order. if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } // Return data. return entities; } This way you can use the usual List methods to determine the state of the result: List<Entity> entities = entityDAO.list(); if (entities.isEmpty()) { // It is empty! if (entities.size() == 1) { // It has only one row! } else { // It has more than one row! } See also: Answer with another method examples expecting zero-or-one row zero-or-many rows DAO tutorial - basic kickoff tutorial how to write JDBC the proper way Thanks Balus... Ur answers are really helpful and very brief. Hope you will guide me till I become a good java programmer :) You're welcome."
172,A,"Spring JDBC support and large dataset When using one of the various JDBC template methods I am confused on how to iterate/scroll over large result sets (which won't fit into memory). Even without a direct exposure of an Iterable interface I would at least expect instances of RowCallbackHandler to get called while the query is executing not after it's finished (or the heap overfloats). I did have a look a at this (which changed nothing for me despite being similar in spirit to this post on stack overflow) and at this post in the spring forums. The latter seems to suggest that the callback handler should indeed get called while the cursor is fetching data. My tests however show no such behaviour. The database is an Oracle10g. I am using the 11.1.0.7.0-Production driver and Spring 2.5.6.SEC01. Any ideas anyone how to iterate over result sets preferably while keeping the mapping logic of RowMapper etc.? It's a property of the driver/connection whether to stream data back to you or whether to send it back in one chunk. For example in SQL Server you use the SelectMethod property on the connection URL: jdbc:microsoft:sqlserver://gsasql03:1433;DatabaseName=my_db;SelectMethod=direct The value of direct means that the results should come in one go. The other choice is cursor which allows you to specify that you want the connection to stream results back to you. I'm not sure what the analog for an Oracle data source is I'm afraid the RowCallbackHandler certainly works for me. Yes ideally you don't put into a dataset you would grab the records while keepin the connection open asking if there are more records. I did this in .NET and got a pretty good improvement in performance. I imagine something similar for java would exist especially in spring. @*Zoidberg* - the OP appears to be doing the correct thing using a row callback handler This sounds promising. Unfortunately I couldn't find anything similar to this SQL Server URL setting in the Oracle JDBC documentation.  You may use springjdbc-iterable library: CloseableIterator<MyObj> iter = jt.queryForIter(""select ..."" params mapper); Iterator will be auto-closed on exhaustion or may be closed manually. It will work only within transaction bounds. Disclaimer: I wrote this library  The Oracle JDBC driver has proper support for the setFetchSize() method on java.sql.Statement which allows you to control how many rows the driver will fetch in one go. However RowMapper as used by Spring works by reading each row into memory getting the RowMapper to translate it into an object and storing each row's object in one big list. If your result set is huge then this list will get big regardless of how JDBC fetches the row data. If you need to handle large result sets then RowMapper isn't scaleable. You might consider using RowCallbackHandler instead along with the corresponding methods on JdbcTemplate. RowCallbackHandler doesn't dictate how the results are stored leaving it up to you to store them. setFetchSize did not change things for me I tried using it before. Do you develop against an Oracle instance? For me RowCallBackHandler just hangs waiting for the query to finish as I wrote in my OP. Apparently I forgot the call afterPropertiesSet() on the JDBC template in my test. Embarrassing but now it works :*)  here's a good library for pulling java sql resultsets all into memory. http://casperdatasets.googlecode.com you can scroll / iterate through the dataset you can issue queries against it and build indexes for optimization. it also implements the java.sql.resultset interface so you can continue to operate on results from this dataset with minimals chnages to your jdbc code. it also has an adapter that will convert a jdbc resultset into an in-memory resultset - i assume you can invoke this adapter in your spring jdbc results callback method. Sorry but ""how to iterate/scroll over large result sets (which *won't fit into memory*)""."
173,A,"Performance problem on Java DB Derby Blobs & Delete I’ve been experiencing a performance problem with deleting blobs in derby and was wondering if anyone could offer any advice. This is primarily with 10.4.2.0 under windows and solaris although I’ve also tested with the new 10.5.1.1 release candidate (as it has many lob changes) but this makes no significant difference. The problem is that with a table containing many large blobs deleting a single row can take a long time (often over a minute). I’ve reproduced this with a small test that creates a table inserts a few rows with blobs of differing sizes then deletes them. The table schema is simple just: create table blobtest( id integer generated BY DEFAULT as identity b blob ) and I’ve then created 7 rows with the following blob sizes : 1024 bytes 1Mb 10Mb 25Mb 50Mb 75Mb 100Mb. I’ve read the blobs back to check they have been created properly and are the correct size. They have then been deleted using the sql statement ( “delete from blobtest where id = X” ). If I delete the rows in the order I created them average timings to delete a single row are: 1024 bytes: 19.5 seconds 1Mb: 16 seconds 10Mb: 18 seconds 25Mb: 15 seconds 50Mb: 17 seconds 75Mb: 10 seconds 100Mb: 1.5 seconds If I delete them in reverse order the average timings to delete a single row are: 100Mb: 20 seconds 75Mb: 10 seconds 50Mb: 4 seconds 25Mb: 0.3 seconds 10Mb: 0.25 seconds 1Mb: 0.02 seconds 1024 bytes: 0.005 seconds If I create seven small blobs delete times are all instantaneous. It thus appears that the delete time seems to be related to the overall size of the rows in the table more than the size of the blob being removed. I’ve run the tests a few times and the results seem reproducible. So does anyone have any explanation for the performance and any suggestions on how to work around it or fix it? It does make using large blobs quite problematic in a production environment… I've edited my post to explain this performance problem and suggested another way to fix this (besides changing DBs): moving the bigger files out of the DB. As far as I can tell Derby will only store BLOBs inline with the other database data so you end up with the BLOB split up over a ton of separate DB page files. This BLOB storage mechanism is good for ACID and good for smaller BLOBs (say image thumbnails) but breaks down with larger objects. According to the Derby docs turning autocommit off when manipulating BLOBs may also improve performance but this will only go so far. I strongly suggest you migrate to H2 or another DBMS if good performance on large BLOBs is important and the BLOBs must stay within the DB. You can use the SQuirrel SQL client and its DBCopy plugin to directly migrate between DBMSes (you just need to point it to the Derby/JavaDB JDBC driver and the H2 driver). I'd be glad to help with this part since I just did it myself and haven't been happier. Failing this you can move the BLOBs out of the database and into the filesystem. To do this you would replace the BLOB column in the database with a BLOB size (if desired) and location (a URI or platform-dependent file string). When creating a new blob you create a corresponding file in the filesystem. The location could be based off of a given directory with the primary key appended. For example your DB is in ""DBFolder/DBName"" and your blobs go in ""DBFolder/DBName/Blob"" and have filename ""BLOB_PRIMARYKEY.bin"" or somesuch. To edit or read the BLOBs you query the DB for the location and then do read/write to the file directly. Then you log the new file size to the DB if it changed.  I'm sure this isn't the answer you want but for a production environment with throughput requirements I wouldn't use Java DB. MySQL is just as free and will handle your requirements a lot better. I think you are really just beating your head against a limitation of the solution you've chosen. I generally only use Derby as a test case and especially only when my entire DB can fit easily into memory. YMMV.  Have you tried increasing the page size of your database? There's information about this and more in the Tuning Java DB manual which you may find useful. I have tried but still slow...  I have exact the same issue you have. I found that when I do DELETE derby actually ""read through"" the large segment file completely. I use Filemon.exe to observe how it run. My file size it 940MB and it takes 90s to delete just a single row. I believe that derby store the table data in a single file inside. And some how a design/implementation bug that cause it read everything rather then do it with a proper index. I do batch delete rather to workaround this problem. I rewrite a part of my program. It was ""where id=?"" in auto-commit. Then I rewrite many thing and it now ""where ID IN(?.......?)"" enclosed in a transaction. The total time reduce to 1/1000 then it before. I suggest that you may add a column for ""mark as deleted"" with a schedule that do batch actual deletion."
174,A,"""Cursor is closed"" error - when trying to execute an Oracle SP using JDBC The Oracle version of our database is 10g. The stored procedure selects all the elements in a table and returns a REF CURSOR type as follows: create or replace PROCEDURE S_S_TEST( test_OUT OUT OAS_TYPES.REFCURSOR ) AS BEGIN OPEN test_OUT FOR SELECT * FROM table_p; CLOSE test_OUT; END S_S_TEST; When this stored procedure is executed in JAVA the following exception is obtained- java.sql.SQLException: Cursor is closed. at oracle.jdbc.driver.T4CResultSetAccessor.getCursor(T4CResultSetAccessor.java:323) at oracle.jdbc.driver.ResultSetAccessor.getObject(ResultSetAccessor.java:85) at oracle.jdbc.driver.OracleCallableStatement.getObject(OracleCallableStatement.java:1401) at com.ibm.ws.rsadapter.jdbc.WSJdbcCallableStatement.getObject(WSJdbcCallableStatement.java:443) I am trying to understand what the error is and how it could be fixed. Could someone please help me out? Thanks! The client calling the stored procedure is responsible for closing the cursor. Please remove the code: CLOSE test_OUT; The client closes it. In this case the client is the JDBC program that calls the stored procedure."
175,A,"Where are JDBC4 annotations? Some time ago jdk 6 announced JDBC4 with the ""Annotation-Based SQL Queries"". I was looking for testing the approach but didn't find the required classes (like java.sql.BasicQuery) in the JDK 6. Googling a little on the subject I found a thread on java.net that tells these ""Ease of User"" features haven't finally been included in the JDK because of a lack of time. Does someone here tell me more about the future availability of these features ? I don't know what happened to that idea but JPA (Java Persistence API) is based on annotations: http://java.sun.com/javaee/reference/faq/persistence.jsp If it goes anywhere it looks like it will be for jdk 8. Annotation based SQL queries never made it into the final JDBC 4.0 and there havn't been much talk about bringing them back work seems rather to have been focused on JPA. If you still want something similar look at iBatis. Here's some examples iBatis has moved on to [MyBatis](http://www.mybatis.org/)  JLibs DAOPattern provides similar functionality that you are looking for..."
176,A,"Transaction state in JDBC Is there a way to know if a transaction is in an ""ongoing"" state in JDBC? I found nothing in the Connection API. Thanks how would you define ""ongoing state""? I meant something like ""dirty"" - update insert and delete rows. JDBC does not track the transaction state. It is the job of DB to track the transaction state. Given that you still have two ways on tracking/knowing the transaction states. You can make a sql call to your db to ask for transaction specific detail. for oracle it will be in v$transaction table in suggested in this post. SELECT COUNT(*) FROM v$transaction t v$session s v$mystat WHERE t.ses_addr = s.saddr AND s.sid = m.sid AND ROWNUM = 1; Another solution is to use transaction manager code in some common frameworks such as hibernate (I believe Spring has it too). public interface Session { public abstract org.hibernate.Transaction getTransaction(); } public Transaction { public abstract boolean wasRolledBack() throws org.hibernate.HibernateException; public abstract boolean wasCommitted() throws org.hibernate.HibernateException; public abstract boolean isActive() throws org.hibernate.HibernateException; } Thanks for the oracle tip it will help me."
177,A,"Which approach is better to load a JDBC driver? There are two ways to load a driver: Class.forName() DriverManager.registerDriver() Method 1 internally also calls DriverManager.registerDriver and method 1 is the preferred way. But why? Is there any small difference or is performance etc. better? Any views are appreciated.. The JDBC API Tutorial and Reference is the best reference for such questions a section of which addresses the role played by the Driver and DriverManager classes. All Driver classes are expected to have a static initializer that is responsible for creating an instance of that Driver and register it with the DriverManager when the Driver class is loaded. Additionally the DriverManager.getConnection() is probably the only user-space friendly method in the class. Most of the other methods are usually not used by most developers using the JDBC API. So the old adage still stands - use Class.forName() to load the driver and then use DriverManager.getConnection() to get a connection to the database.  I have to say your life will be much easier if you construct a driver instance by statically reference the driver. Once you have that you can ignore DriverManager which made of evil.  ""is performance etc. better?"" I would say that performance for this one-time operation is the least of your worries. If you're using a Java EE app server the answer is ""neither"". You should be setting up a connection pool and let it handle loading the driver and handing out the connections. i agree with your point.  Reading the JavaDoc it looks like Class.forName was required to start with and then things changed so that it was no longer the prefered way (or the required way). Um... I don't think that link is correct. fixed thanks (I was reading up on what it was saying and I guess I forgot to re-grab the link :-)  If you use Class.forName() then you are not required to have any compile-time dependencies on a particular JDBC driver. This is particularly useful when you are writing code that can work with a variety of databases. Consider the following code: // Register the PostgreSQL driver Class.forName(""org.postgresql.Driver""); Now compare it to: import org.postgresql.Driver; // Register the PostgreSQL driver DriverManager.registerDriver(new Driver()); And consider that in the first example the class name could also have come from a properties file XML file etc. depending on what's convenient for your application."
178,A,"how to reload jsp page on every request? i have a jsp page with jdbc connection and on first load it shows the data accurately but after that it shows empty tables i think 2nd time it loads from memory not from server what is problem behind i don't know ok here are the details i have a servlet that maintains the session for a user that log in and then after creating the session the servlet redirect the user to a view page that is a jsp page and displays the existing records in DB when the servlet redirects the page the jsp can show the records in but when i access this page from any other html page it is unable to display the records here is the code for jsp page to view. <%@ page import=""java.sql.ResultSet"" %> <%@ page import=""java.math.BigDecimal"" %> <%@ page import=""java.sql.SQLException"" %> <%@ page import=""java.util.logging.Level"" %> <%@ page import=""java.util.logging.Logger"" %> <%@ page import=""iEHR.cDBProcessor"" %> <HTML> <HEAD> <TITLE>View Patient</TITLE> <META HTTP-EQUIV=""Content-Type"" CONTENT=""text/html; charset=windows-1251""> <script type=""text/javascript"" language=""javascript"" src=""datepicker/main.js""></script> <script type=""text/javascript"" language=""javascript"" src=""datepicker/prototype-1.js""></script> <script type=""text/javascript"" language=""javascript"" src=""datepicker/prototype-base-extensions.js""></script> <script type=""text/javascript"" language=""javascript"" src=""datepicker/prototype-date-extensions.js""></script> <script type=""text/javascript"" language=""javascript"" src=""datepicker/behaviour.js""></script> <script type=""text/javascript"" language=""javascript"" src=""datepicker/ratingbar.js""></script> <script type=""text/javascript"" language=""javascript"" src=""datepicker/datepicker.js""></script> <link rel=""stylesheet"" href=""datepicker/datepicker.css""> <script type=""text/javascript"" language=""javascript"" src=""datepicker/behaviors.js""></script> <style type=""text/css""> <!-- img { border: none; } .tah10 { font-family: ""Times New Roman"" Times serif; font-size: 14px; text-decoration: none; color: #000000; font-style: italic; } .tah11 { font-family: Tahoma; font-size: 11px; text-decoration: none; color: #000000; } .ver10 { font-family: Verdana Arial Helvetica sans-serif; font-size: 10px; text-decoration: none; color: #000000; } .ver11 { font-family: Verdana Arial Helvetica sans-serif; font-size: 11px; text-decoration: none; color: #000000; } .tah9 { font-family: Tahoma; font-size: 9px; text-decoration: none; color: #000000; } .ver9 { font-family: Verdana Arial Helvetica sans-serif; font-size: 9px; text-decoration: none; color: #000000; } td { vertical-align: top; color: 497B99; font-size: 12px; font-style: normal; font-weight: bolder; } --> </style> <style type=""text/css""> <!-- .bgtop { background-repeat: repeat-x; background-position: top; } --> </style> <style type=""text/css""> <!-- a { font-family: Times New Roman Times serif; font-size: 12px; font-weight: bolder; color: 467B99; text-decoration: none; } .datepicker{ font-family: Times New Roman Times serif; font-size: 12px; font-weight: bolder; color: 467B99; text-decoration: none; } a:hover { font-size: 10px; font-weight: bold; color: FF8400; } .style1 { color: 467B99; font-family: Times New Roman Times serif; font-size: 12px; text-decoration: none; font-style: normal; font-weight: bolder; } .style2 { font-family: Times New Roman Times serif; font-size: 12px; font-style: normal; font-weight: bolder; color: 467B99; text-decoration: none; } --> </style> </HEAD> <BODY BGCOLOR=#FFFFFF LEFTMARGIN=0 TOPMARGIN=0 MARGINWIDTH=0 MARGINHEIGHT=0> <!-- ImageReady Slices (0005_red.psd - Slices: 03 04 05) --> <TABLE WIDTH=100% height=""100%"" BORDER=0 CELLPADDING=0 CELLSPACING=0 bgcolor=""#FFFFFF""> <TR> <TD width=""12%""> <TABLE WIDTH=159 BORDER=0 CELLPADDING=0 CELLSPACING=0> <TR> <TD COLSPAN=6> <IMG SRC=""images/logo.gif"" WIDTH=159 HEIGHT=128 ALT=""""></TD> </TR> <TR> <TD> <IMG SRC=""images/s1.gif"" WIDTH=20 HEIGHT=20 ALT=""""></TD> <TD> <A HREF=""#""> <IMG SRC=""images/r1.gif"" WIDTH=29 HEIGHT=20 BORDER=0 ALT=""""></A></TD> <TD> <A HREF=""#""> <IMG SRC=""images/r2.gif"" WIDTH=31 HEIGHT=20 BORDER=0 ALT=""""></A></TD> <TD> <A HREF=""#""> <IMG SRC=""images/r3.gif"" WIDTH=31 HEIGHT=20 BORDER=0 ALT=""""></A></TD> <TD> <A HREF=""#""> <IMG SRC=""images/r4.gif"" WIDTH=28 HEIGHT=20 BORDER=0 ALT=""""></A></TD> <TD> <IMG SRC=""images/s2.gif"" WIDTH=20 HEIGHT=20 ALT=""""></TD> </TR> <TR> <TD COLSPAN=6> <IMG SRC=""images/s3.gif"" WIDTH=159 HEIGHT=93 ALT=""""></TD> </TR> <TR> <TD COLSPAN=6> <IMG SRC=""images/h1.jpg"" WIDTH=159 HEIGHT=32 ALT=""""></TD> </TR> <TR> <TD COLSPAN=6> <IMG SRC=""images/img1.jpg"" WIDTH=159 HEIGHT=76 ALT=""""></TD> </TR> <TR> <TD COLSPAN=6> <IMG SRC=""images/img2.jpg"" WIDTH=159 HEIGHT=81 ALT=""""></TD> </TR> <TR> <TD COLSPAN=6> <IMG SRC=""images/img3.jpg"" WIDTH=159 HEIGHT=79 ALT=""""></TD> </TR> <TR> <TD COLSPAN=6> <IMG SRC=""images/but1.jpg"" ALT="""" WIDTH=159 HEIGHT=42 border=""0"" usemap=""#Map""></TD> </TR> </TABLE> </TD> <TD width=""12%""> <TABLE WIDTH=167 BORDER=0 CELLPADDING=0 CELLSPACING=0> <TR> <TD COLSPAN=2> <IMG SRC=""images/h2.jpg"" WIDTH=167 HEIGHT=25 ALT=""""></TD> </TR> <TR> <TD COLSPAN=2 background=""images/bg1.gif"" HEIGHT=94> <div style=""padding:20;padding-top:5;padding-right:10;padding-bottom:0;color:ffffff"" class=""tah10""> <strong>Noesis</strong><br><br> <strong>Inovative EHR Services </strong> <br> <br> </div> </TD> </TR> <TR> <TD COLSPAN=2> <IMG SRC=""images/s4.jpg"" WIDTH=167 HEIGHT=52 ALT=""""></TD> </TR> <TR> <TD COLSPAN=2 background=""images/bg2.gif""> <div style=""padding-left:0px;padding-top:12px;padding-bottom:2""><a href=""AddPatient.jsp""><span style=""padding-left:20;padding-top:5"">Add Patient </span></a></div> </TD> </TR> <TR> <TD COLSPAN=2 background=""images/bg3.gif"" HEIGHT=18> <div style=""padding-left:20;padding-top:5""><a href=""AddPastMedicalHistory.jsp"">Add Patient History</a> </div> </TR> <TR> <TD COLSPAN=2 background=""images/bg4.gif"" HEIGHT=18> <div style=""padding-left:20;padding-top:5""><a href=""AddPatientInsurance.jsp"">Add Patient Insurance</a></div> </TD> </TR> <TR> <TD COLSPAN=2 background=""images/bg5.gif"" HEIGHT=18 > <div style=""padding-left:20;padding-top:5"">View Patient Records</div></TD> </TR> <TR> <TD COLSPAN=2 background=""images/bg6.gif"" HEIGHT=18 > <div style=""padding-left:20;padding-top:5""><a href=""#""></a><a href=""AboutUs.jsp"">About Us</a></div> </TD> </TR> <TR> <TD COLSPAN=2 background=""images/bg7.gif"" HEIGHT=18 > <div style=""padding-left:20;padding-top:5""><a href=""#""></a><a href=""ContactUs.jsp"">Contact Us</a></div> </TD> </TR> <TR> <TD COLSPAN=2 background=""images/bg8.gif"" HEIGHT=18 > <div style=""padding-left:20;padding-top:5""><a href=""#""></a></div> </TD> </TR> <TR> <TD COLSPAN=2> <IMG SRC=""images/h3.gif"" WIDTH=167 HEIGHT=65 ALT=""""></TD> </TR> <TR> <TD COLSPAN=2 background=""images/bg9.gif"" HEIGHT=94> <div style=""padding:15;padding-top:3;padding-bottom:3;color:737373"" class=""tah10""></div> </TD> </TR> <TR> <TD COLSPAN=2> <IMG SRC=""images/h4.jpg"" WIDTH=167 HEIGHT=41 ALT=""""></TD> </TR> <TR> <TD background=""images/bg10.jpg"" WIDTH=123 HEIGHT=32> <div style=""padding-left:15;padding-top:1""> <input name=""text"" type=""text"" size=""11""> </div></TD> <TD width=""44""> <IMG SRC=""images/but2.jpg"" ALT="""" WIDTH=44 HEIGHT=32 border=""0"" usemap=""#Map2""></TD> </TR> <TR> <TD COLSPAN=2> <IMG SRC=""images/s5.jpg"" WIDTH=167 HEIGHT=48 ALT=""""></TD> </TR> <TR> <TD COLSPAN=2>&nbsp;</TD> </TR> </TABLE> </TD> <TD width=""72%""> <table width=100% height=""193"" border=0 cellpadding=0 cellspacing=0> <tr> <td height=172 colspan=""4"" ><span class=""bgtop""><img src=""images/f_m.jpg""></span></td> <td height=172 colspan=""2"" width=""63%"" background=""images/bg_tile_1.gif"" class=""bgtop"">&nbsp;</td> </tr> <tr> <td height=19 colspan=""4"" background=""images/bg11.gif"" >&nbsp;</td> </tr> </table> <%! private ResultSet rsResult; %> <%! cDBProcessor DBProcess = new cDBProcessor(); %> <% DBProcess.ConnectTODB(); if(request.getAttribute(""dbrec"") != null) { rsResult = DBProcess.statement.executeQuery(""SELECT * FROM patients""); }//end if out.println(""<table border=\""0\""><tr><td valign=\""top\"" >""); out.println(""<tr><th>Patient ID</th><th>First Name</th><th>Middle Name</th><th>Last Name</th><th>Gender</th><th>Marital Status</th><th>Phone No.</th><th>Address</th>""); out.println(""<th>Date Of Birth</th><th>Last Date Of Exam</th><th>Status</th></tr>""); //data display on page if(rsResult!= null) { try { while (rsResult.next()) { BigDecimal bdPatientID = rsResult.getBigDecimal(""patient_id""); String strFirstname = rsResult.getString(""first_name""); String strLastname = rsResult.getString(""last_name""); String strMiddlename = rsResult.getString(""middle_name""); String strGeneder = rsResult.getString(""gender""); String strMeritalStatus = rsResult.getString(""marital_status""); BigDecimal bdPhoneNo = rsResult.getBigDecimal(""phone_no""); String strAddress = rsResult.getString(""address""); String strDOB = rsResult.getDate(""birth_dt"") == null ? """" : rsResult.getDate(""birth_dt"").toString(); String strDOE = rsResult.getDate(""dt_of_exam"") == null ? """" :rsResult.getDate(""dt_of_exam"").toString(); String strStatus; Byte bPatientStatus= rsResult.getByte(""status""); if(bPatientStatus == 1) { strStatus = ""Active""; }//end if else { strStatus = ""Inactive""; }//end else out.println(""<tr><td>""+bdPatientID+""</td><td>""+strFirstname+""</td><td>""+strMiddlename+""</td><td>""+strLastname+""</td>""); out.println(""<td>""+strGeneder+""</td><td>""+strMeritalStatus+""</td><td>""+bdPhoneNo+""</td><td>""+strAddress+""</td>""); out.println(""<td>""+strDOB+""</td><td>""+strDOE+""</td><td>""+strStatus+""</td></tr>""); }//end while out.println(""</table>""); }//end try catch (SQLException ex) { out.println(""<I>exception</I><br>""); }//end catch }//end if DBProcess.CloseDB(); %> </TD> <TD width=""4%"" background=""images/bg_tile_1.gif"" class=""bgtop"">&nbsp;</TD> </TR> <TR> <TD height=""100%"" colspan=""4"">&nbsp;</TD> </TR> <TR> <TD colspan=""3""> <TABLE WIDTH=768 BORDER=0 CELLPADDING=0 CELLSPACING=0> <TR> <TD width=""326""> <IMG SRC=""images/s7.gif"" WIDTH=326 HEIGHT=48 ALT=""""></TD> <TD background=""images/bg16.gif"" WIDTH=442 HEIGHT=48> <div style=""padding-top:12;color:A8A8A8"" class=""tah11""> 2010 © Copyright iAS. <Br> All rights Reserved. Read <a href=""#"" style=""color:467B99"" class=""tah11"">Privacy Policy</a>.</div> </TD> </TR> </TABLE> </TD> <TD width=""4%"" background=""images/bg_tile_2.gif"">&nbsp;</TD> </TR> </TABLE> <!-- End ImageReady Slices --> <map name=""Map""> <area shape=""rect"" coords=""39213327"" href=""#""> </map> <map name=""Map2""> <area shape=""circle"" coords=""9129"" href=""#""> </map> </BODY> </HTML> read your question and ask yourself whether you are providing sufficient information. *it shows empty tables* - could be a variety of problems - has it lost DB connectivity - are there any errors in the logs - check all this and post more details. ok i think now i have provided enough info to ans this question plz let me know if some important is missing @Bozho @JoseK beside those issues pointed out by BalusC base on the described symptom ""when the servlet redirects the page the jsp can show the records in but when i access this page from any other html page it is unable to display the records"" and code ""if(request.getAttribute(""dbrec"") != null) "". My prime suspect for the issue's cause is the use of request.getAttribute(""dbrec"") for those direct access from other html page this value likely to be null. I suspect for redirect case there may be some code that perform request.setAttribute(""dbrec""....)  It smells like threadsafety/scoping problem. You've declared the ResultSet and DBProcess as instance variable of the JSP using <%! %> scriptlet declarations so it's been shared among all HTTP requests. I am not sure about the DBProcess but this is certainly a bad idea for ResultSet (and also for Connection and Statement by the way). How the DBProcess is been used in the remnant of the code is also pretty scary e.g. DBProcess.statement.executeQuery(). Is the Statement really a public field? I don't know how the class' internals look like but yes this smells too much like threadsafety/scoping problem. Also this 90's style writing of HTML and using scriptlets in JSP really don't suit a ""Copyright 2010"" application. Are you reading the right tutorials/books?"
179,A,Access to jdbc/ jndi properties associated with the Datasource in BIRT Is there a way to access jdbc/ jndi resource properties associated with a Datasource in BIRT? I would like to access the properties (esp. driverClass) to modify the query associated with the datasets to address database engine specific variations. TIA You can access the properties of a datasource at design time by right-clicking on the datasource in the report designer and selecting Edit - this will enable you to edit driver class driver URL JNDI URL etc. It should be possible to access these properties programmatically in the events associated with the Datasource (especially the beforeOpen event) if not elsewhere. Mark Please point me to the documentation on how to access it programmatically in an event. I have tried looking for it but I have not been able to find it. TIA @shikari I find the documentation on scripting in BIRT to be very limited. You should be able to see the BIRT Report Developer Guide in the Help Contents on the Eclipse platform Help menu (if not see here: http://www.linuxtopia.org/online_books/eclipse_documentation/eclipse_birt_report_guide/ ). This includes limited guidance on scripting BIRT events. You may also be able to find some useful information on the BIRT project site: http://www.eclipse.org/birt/phoenix/  or the BIRT World blog- particularly this post: http://birtworld.blogspot.com/2005/12/using-supplied-connection-with-birt.html
180,A,"Why doesn't jrunscript honor my classpath? I'm trying to do some JDBC access from JavaScript using the Rhino included in Java 6. But I cannot make the DriverManager find the Driver I want to use. These two examples should be equivalent: Java: public class DbTest { public static void main(String[] argv) { java.sql.Connection c = null; try { java.lang.Class.forName(""net.sourceforge.jtds.jdbc.Driver""); c = java.sql.DriverManager.getConnection( ""jdbc:jtds:sqlserver://myserver/mydb"" ""user"" ""password""); } catch (Exception e) { c = null; System.out.println(e); }; if(c != null) { System.out.println(""yay got c!""); try { c.close(); } catch(Exception e) {} } else { System.out.println(""awww.""); } } } JavaScript: importPackage(Packages.net.sourceforge.jtds.jdbc); java.lang.Class.forName('net.sourceforge.jtds.jdbc.Driver'); var c = null; try { c = java.sql.DriverManager.getConnection( 'jdbc:jtds:sqlserver://myserver/mydb' 'user' 'password'); } catch (e) { c = null; println(e); }; if(c) { println('yay got c!'); c.close(); } else { println('awww.'); } ... but when I run them I get this behaviour: Java: > java -cp .;jtds-1.2.5.jar DbTest java.sql.SQLException: Unknown server host name 'myserver'. awww. That's great it managed to load the driver and tried to resolve the server. JavaScript: > jrunscript -cp .;jtds-1.2.5.jar dbtest.js script error in file dbtest.js : sun.org.mozilla.javascript.internal.WrappedException: Wrapped java.lang.ClassNotFoundException: net.sourceforge.jtds.jdbc.Driver (dbtest.js#2) in dbtest.js at line number 2 Why doesn't it find the class? I have tried with and without importPackage() and importClass() with and without the Packages prefix. If I comment out forName then DriverManager doesn't find a suitable driver. Tried it in Linux now as well exact same behaviour. Also tried running `java -cp blabla com.sun.tools.script.shell.Main dbtest.js` no difference. Suspecting that this is a security issue and that the scripting engine runs using its own classloader. So the question is where that can be modified. Tried running an Ant ` ` which has a classpath attribute obviously for the benefit of the script. Also does not work. `java -cp $JAVA_HOME/lib/tools.jar -Xbootclasspath:""$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/jre/lib/resources.jar:jtds-1.2.5.jar"" com.sun.tools.script.shell.Main dbtest.js` works. But I want to know why neither `jrunscript` nor ` ` seem to be using the normal classpath and which one they _do_ use. According to an IBM DeveloperWorks forum post ""the jrunscript -classpath value is used by a separate ""scripting"" classloader that parallels the usual application classloader and that is used to resolve classes that have been mentioned in importClass() and importPackage()"". And according to this SO answer ""... DriverManager performs ""tasks using the immediate caller's class loader instance"" "". So unless you put the driver jar into the bootclasspath or find a way to modify how jrunscript (and Ant <script />) set the system classloader of the script environment the only way to get this to work seems to be to skip DriverManager entirely: var c = null; try { var p = new java.util.Properties(); p.setProperty('user' 'user'); p.setProperty('password' 'password'); c = (new net.sourceforge.jtds.jdbc.Driver()).connect( 'jdbc:jtds:sqlserver://myserver/mydb' p); } catch (e) { c = null; println(e); }; if(c) { println('yay got c!'); c.close(); } else { println('awww.'); } It removes one layer of indirection which may or may not be ones cup of tea but it works (with real server/user/passwd inserted): $ jrunscript -cp jtds-1.2.5.jar dbtest_realparams.js yay got c!"
181,A,"What's the proper way to handle JDBC connections with Spring and DBCP? I'm using the Spring MVC to build a thin layer on top of a SQL Server database. When I began testing it seems that it doesn't handle stress very well :). I'm using Apache Commons DBCP to handle connection pooling and the data source. When I first attempted ~10-15 simultaneous connections it used to hang and I'd have to restart the server (for dev I'm using Tomcat but I'm gonna have to deploy on Weblogic eventually). These are my Spring bean definitions: <bean id=""dataSource"" destroy-method=""close"" class=""org.apache.commons.dbcp.BasicDataSource""> <property name=""driverClassName"" value=""com.microsoft.sqlserver.jdbc.SQLServerDriver""/> <property name=""url"" value=""[...]""/> <property name=""username"" value=""[...]"" /> <property name=""password"" value=""[...]"" /> </bean> <bean id=""partnerDAO"" class=""com.hp.gpl.JdbcPartnerDAO""> <constructor-arg ref=""dataSource""/> </bean> <!-- + other beans --> And this is how I use them: // in the DAO public JdbcPartnerDAO(DataSource dataSource) { jdbcTemplate = new JdbcTemplate(dataSource); } // in the controller @Autowired private PartnerDAO partnerDAO; // in the controller method Collection<Partner> partners = partnerDAO.getPartners(...); After reading around a little bit I found the maxWait maxActive and maxIdle properties for the BasicDataSource (from GenericObjectPool). Here comes the problem. I'm not sure how I should set them performance-wise. From what I know Spring should be managing my connections so I shouldn't have to worry about releasing them. <bean id=""dataSource"" destroy-method=""close"" class=""org.apache.commons.dbcp.BasicDataSource""> <property name=""driverClassName"" value=""com.microsoft.sqlserver.jdbc.SQLServerDriver""/> <property name=""url"" value=""[...]""/> <property name=""username"" value=""[...]"" /> <property name=""password"" value=""[...]"" /> <property name=""maxWait"" value=""30"" /> <property name=""maxIdle"" value=""-1"" /> <property name=""maxActive"" value=""-1"" /> </bean> First I set maxWait so that it wouldn't hang and instead throw an exception when no connection was available from the pool. The exception message was: Could not get JDBC Connection; nested exception is org.apache.commons.dbcp.SQLNestedException: Cannot get a connection pool error Timeout waiting for idle object There are some long-running queries but the exception was thrown regardless of the query complexity. Then I set maxActive and maxIdle so that it wouldn't throw the exceptions in the first place. The default values are 8 for maxActive and maxIdle (I don't understand why); if I set them to -1 there are no more exceptions thrown and everything seems to work fine. Considering that this app should support a large number of concurrent requests is it ok to leave these settings to infinite? Will Spring actually manage my connections considering the errors I was receiving? Should I switch to C3P0 considering it's kinda dead? If you are getting any exceptions posting the stacktrace will help identify the problem easily Are there any long running queries where you are seeing the issues? I've updated my post with the exception message and some extra info. DBCP maxWait parameter should be defined in milliseconds. 30 ms is very low value consider increasing it to 30000 ms and try again.  Let's change the perspective. but the exception was thrown regardless of the query complexity It could be because the table or the records in the table which you are querying against has been locked (by some other active transaction) and hence it times out. Try running the same query from SQLServer Client and if it takes a long time then you can be sure that it is the table or record lock that is causing this. I see your point but the issue disappears completely when I set the `maxActive` and `maxIdle` parameters of the datasource to a large value (or to infinite). This leads me to think that the issue is from the ConnectionPool as the exception message states.  As you already found out the default dbcp connection pool is 8 connections so if you want to run 9 simultaneous queries one of them will be blocked. I suggest you connect to your database and run exec sp_who2 which will show you what is connected and active and whether any queries are being blocked. You can then confirm whether the issue is on the db or in your code. As long as you are using Spring's JdbcTemplate family of objects your connections will be managed as you expect and if you want to use a raw DataSource make sure you use DataSourceUtils to obtain a Connection. One other suggestion - prior to Spring 3 don't ever using JdbcTemplate stick to SimpleJdbcTemplate you can still access the same methods using SimpleJdbcTemplate.getJdbcOperations() but you should find yourself writing much nicer code using generics and remove the need to ever create JdbcTemplate/NamedParameterJdbcTemplate instances."
182,A,"SQL Server / JDBC Connectivity Issues I am experiencing some strange behaviour in my Java server application whereby database operations that usually take a few milliseconds are sporadically taking much longer (30s - 170s) to complete. This isn't isolated to a specific query as I've seen the delays occurring for both SQL update and select statements. Also all of my select statements use the NOLOCK option so I've ruled out possible lock contention. The last time I saw a delay I managed to capture the following stack trace from JConsole; the update in question typically takes 5ms to complete but this stack trace was accessible for at least 10 - 20 seconds. The trace suggests to me that the statement has been executed but there is some delay in retrieving the result although I could be wrong? Obviously as this was an update statement the only result I'd expect would be the row count (i.e. not a large result set of data). I saw a ""transport level error"" in SQL Server Management Studio at around the time of the delay. One suggestion I've had is that these problems are due to SQL Server resources being exhausted. Has anyone seen anything similar? Can anyone shed any light on this problem? Thanks in advance. Stack Trace: Name: MessageRouterImplThread-2 State: RUNNABLE Total blocked: 0 Total waited: 224 Stack trace: java.net.SocketInputStream.socketRead0(Native Method) java.net.SocketInputStream.read(SocketInputStream.java:129) com.microsoft.util.UtilSocketDataProvider.getArrayOfBytes(Unknown Source) com.microsoft.util.UtilBufferedDataProvider.cacheNextBlock(Unknown Source) com.microsoft.util.UtilBufferedDataProvider.getArrayOfBytes(Unknown Source) com.microsoft.jdbc.sqlserver.SQLServerDepacketizingDataProvider.signalStartOfPacket(Unknown Source) com.microsoft.util.UtilDepacketizingDataProvider.getByte(Unknown Source) com.microsoft.util.UtilByteOrderedDataReader.readInt8(Unknown Source) com.microsoft.jdbc.sqlserver.tds.TDSRequest.getTokenType(Unknown Source) com.microsoft.jdbc.sqlserver.tds.TDSRequest.processReply(Unknown Source) com.microsoft.jdbc.sqlserver.SQLServerImplStatement.getNextResultType(Unknown Source) com.microsoft.jdbc.base.BaseStatement.commonTransitionToState(Unknown Source) com.microsoft.jdbc.base.BaseStatement.postImplExecute(Unknown Source) com.microsoft.jdbc.base.BasePreparedStatement.postImplExecute(Unknown Source) com.microsoft.jdbc.base.BaseStatement.commonExecute(Unknown Source) com.microsoft.jdbc.base.BaseStatement.executeUpdateInternal(Unknown Source) com.microsoft.jdbc.base.BasePreparedStatement.executeUpdate(Unknown Source) - locked com.microsoft.jdbc.sqlserver.SQLServerConnection@c4b83f org.apache.commons.dbcp.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:101) org.springframework.jdbc.core.JdbcTemplate$2.doInPreparedStatement(JdbcTemplate.java:798) org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:591) org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:792) org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:850) org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:858) org.springframework.jdbc.core.simple.SimpleJdbcTemplate.update(SimpleJdbcTemplate.java:237) ""...whereby database operations that usually take a few milliseconds are sporadically taking much longer (30s - 170s) to complete."" What you are describing sounds like an incorrectly cached query plan due to out of date statistics (and/or indexes that need rebuilding) or incorrect parameter sniffing. The timeout could be occuring because the server is taking longer than the default connection timeout. I would talk to your DBA and first get statistics updated and if that doesn't work get the indexes of the tables involved in the query rebuilt. Run this on your Database (with the usual caveat about not runninhg in Production without talking to your admin/DBA and run at own risk etc.): EXEC sp_updatestats EXEC sp_refreshview EXEC sp_msForEachTable 'EXEC sp_recompile ''?''' Alternatively you mention time of day being a factor. Could it be that a backup or scheduled job is occuring at that time? Update: You could kick off a profiler trace: MS SQL Server 2008 - How Can I Log and Find the Most Expensive Queries? but don't restrict to your DB. Such a trace as long as it is started from SSMS as per that post is relatively low impact (3-5% ish). Mitch Currently the tables are so small that even an incorrect query (i.e. table scan) would be negligable. So I'm more inclined to think that a backup job (or something else) may be causing a drain on server resources. Unfortunately it's a shared production server so any culprit is going to be difficult to track down. @Adamski: perhaps you could run a trace. I'll updated my answer with details...  The ""transport level error"" seems to indicate connectivity problems. Is the database on a separate machine? "" Is the database on a seperate machine?"" - they usually are! :) Yes it is on a separate machine (although my dev one isn't!). In the past a ""transport level error"" in Management Studio that won't go away (i.e. if I rerun the query from the IDE) has been indicative of a network problem. However this error goes away when I rerun the same query so I'm wondering if this points more towards a resource issue."
183,A,"JTDS and JBOSS JDBC Connection Pool Problem any solution? Maybe a custom ValidConnectionChecker? I'm facing a weird production problem. Environment is the following: JBOSS 4.0.2 SQL Server 2005 Driver JTDS 1.2.5 From time to time the following szenario occurs. A SQL command fails to Excute with  java.sql.SQLException: I/O Error: Read timed out (I can live with that if it just happens twice a day or so) But from that moment on the connection seems to be wasted without the pool recognizing it as I continously receive java.sql.SQLException: Invalid state the Connection object is closed. from that moment on. The only thing that helps is restarting JBOSS. This occurs despite of the fact that I have  <check-valid-connection-sql>select getdate()</check-valid-connection-sql> set up in my Datasource definition. I was wondering if I can use a custom ValidConnectionChecker that either rebuilds the connection itself or explicitly throws a Exception to fix this. Maybe anyone has other suggestions. Here is my complete DS definition.  <local-tx-datasource> <jndi-name>MyDS</jndi-name> <connection-url>jdbc:jtds:sqlserver://192.168.35.235:1433/MyDb;user=user1;password=pwd;appName=MyApp;loginTimeout=15;socketTimeout=120</connection-url> <driver-class>net.sourceforge.jtds.jdbc.Driver</driver-class> <user-name>user1</user-name> <password>pwd</password> <min-pool-size>10</min-pool-size> <max-pool-size>25</max-pool-size> <blocking-timeout-millis>60000</blocking-timeout-millis> <idle-timeout-minutes>1</idle-timeout-minutes> <check-valid-connection-sql>select getdate()</check-valid-connection-sql> </local-tx-datasource> Any help appriciated. Regards Try changing your driver class line to net.sourceforge.jtds.jdbcx.JtdsDataSource. net.sourceforge.jtds.jdbc.Driver doesn't implement the javax.sql.ConnectionPoolDataSource interface. source: http://jtds.sourceforge.net/faq.html#features Is this possible? Can you really use a DataSource in place of a Driver in JBoss?  Probably too late the solution but I am stuck with the jtds driver here. Hope this saves half an hour of your productive time. The fix is to specify a validationQuery to the Apache dbcp2 Connection Pool implementation. For jtds/sql server I specified the spring configuration as follows: <bean id=""sqlServerDS"" class=""org.apache.commons.dbcp2.BasicDataSource"" destroy-method=""close"" > <property name=""driverClassName"" value=""${jdbc.driverClassName}"" /> <property name=""url"" value=""${jdbc.url}"" /> <property name=""username"" value=""${jdbc.username}"" /> <property name=""password"" value=""${jdbc.password}"" /> <property name=""defaultReadOnly"" value=""true"" /> <property name=""validationQuery"" value=""select 1"" /> </bean> In case you are not using Spring call setValidationQuery method on BasicDataSource in your java code. BasicDataSource bds = new BasicDataSource(); bds.setValidationQuery(""select 1"");  Connection.isValid() isn't implemented in JTDS. I found even catching the exception and forcing a complete restart of the connection didn't work."
184,A,"Retrieve column names from java.sql.ResultSet With java.sql.ResultSet is there a way to get a column's name as a String by using the column's index? I had a look through the API doc but I can't find anything. ResultSet rsTst = hiSession.connection().prepareStatement(queryStr).executeQuery(); ResultSetMetaData meta = rsTst.getMetaData(); int columnCount = meta.getColumnCount(); // The column count starts from 1 String nameValuePair = """"; while (rsTst.next()) { for (int i = 1; i < columnCount + 1; i++ ) { String name = meta.getColumnName(i); // Do stuff with name String value = rsTst.getString(i); //.getObject(1); nameValuePair = nameValuePair + name + ""="" +value + """"; //nameValuePair = nameValuePair + "" ""; } nameValuePair = nameValuePair+""||"" + ""\t""; }  You can use the the ResultSetMetaData (http://java.sun.com/javase/6/docs/api/java/sql/ResultSetMetaData.html) object for that like this:   ResultSet rs = stmt.executeQuery(""SELECT * FROM table""); ResultSetMetaData rsmd = rs.getMetaData(); String firstColumnName = rsmd.getColumnName(1); thanx it helped me... i used it as: resultSet.getString(resultSet.findColumn(""fullname""))  This question is old and so are the correct previous answers. But what I was looking for when I found this topic was something like this solution. Hopefully it helps someone. // Loading required libraries import java.util.*; import java.sql.*; public class MySQLExample { public void run(String sql) { // JDBC driver name and database URL String JDBC_DRIVER = ""com.mysql.jdbc.Driver""; String DB_URL = ""jdbc:mysql://localhost/demo""; // Database credentials String USER = ""someuser""; // Fake of course. String PASS = ""somepass""; // This too! Statement stmt = null; ResultSet rs = null; Connection conn = null; Vector<String> columnNames = new Vector<String>(); try { // Register JDBC driver Class.forName(JDBC_DRIVER); // Open a connection conn = DriverManager.getConnection(DB_URL USER PASS); // Execute SQL query stmt = conn.createStatement(); rs = stmt.executeQuery(sql); if (rs != null) { ResultSetMetaData columns = rs.getMetaData(); int i = 0; while (i < columns.getColumnCount()) { i++; System.out.print(columns.getColumnName(i) + ""\t""); columnNames.add(columns.getColumnName(i)); } System.out.print(""\n""); while (rs.next()) { for (i = 0; i < columnNames.size(); i++) { System.out.print(rs.getString(columnNames.get(i)) + ""\t""); } System.out.print(""\n""); } } } catch (Exception e) { System.out.println(""Exception: "" + e.toString()); } finally { try { if (rs != null) { rs.close(); } if (stmt != null) { stmt.close(); } if (conn != null) { conn.close(); } } catch (Exception mysqlEx) { System.out.println(mysqlEx.toString()); } } } }  You can get this info from the ResultSet metadata. See ResultSetMetaData e.g.  ResultSet rs = stmt.executeQuery(""SELECT a b c FROM TABLE2""); ResultSetMetaData rsmd = rs.getMetaData(); String name = rsmd.getColumnName(1); and you can get the column name from there. If you do select x as y from table then rsmd.getColumnLabel() will get you the retrieved label name too. Perfect that's exactly what I needed :) See also `rsmd.getColumnLabel` if you retrieves columns with labels (for example `SELECT columnName AS ColumnLabel` @T30 - that's very useful and I've amended my answer to reflect your comment  @Cyntech is right. Incase your table is empty and you still need to get table column names you can get your column as type Vectorsee the following: ResultSet rs = stmt.executeQuery(""SELECT a b c FROM TABLE2""); ResultSetMetaData rsmd = rs.getMetaData(); int columnCount = rsmd.getColumnCount(); Vector<Vector<String>>tableVector = new Vector<Vector<String>>(); boolean isTableEmpty = true; int col = 0; while(rs.next()) { isTableEmpty = false; //set to false since rs.next has data: this means the table is not empty if(col != columnCount) { for(int x = 1;x <= columnCount;x++){ Vector<String> tFields = new Vector<String>(); tFields.add(rsmd.getColumnName(x).toString()); tableVector.add(tFields); } col = columnCount; } } //if table is empty then get column names only if(isTableEmpty){ for(int x=1;x<=colCount;x++){ Vector<String> tFields = new Vector<String>(); tFields.add(rsmd.getColumnName(x).toString()); tableVector.add(tFields); } } rs.close(); stmt.close(); return tableVector;  The SQL statements that read data from a database query return the data in a result set. The SELECT statement is the standard way to select rows from a database and view them in a result set. The **java.sql.ResultSet** interface represents the result set of a database query. Get methods: used to view the data in the columns of the current row being pointed to by the cursor. Using MetaData of a result set to fetch the exact column count ResultSet rs = stmt.executeQuery(""SELECT a b c FROM TABLE2""); ResultSetMetaData rsmd = rs.getMetaData(); int numberOfColumns = rsmd.getColumnCount(); boolean b = rsmd.isSearchable(1); http://docs.oracle.com/javase/7/docs/api/java/sql/ResultSetMetaData.html and further more to bind it to data model table  public static void main(String[] args) { Connection conn = null; Statement stmt = null; try{ //STEP 2: Register JDBC driver Class.forName(""com.mysql.jdbc.Driver""); //STEP 3: Open a connection System.out.println(""Connecting to a selected database...""); conn = DriverManager.getConnection(DB_URL USER PASS); System.out.println(""Connected database successfully...""); //STEP 4: Execute a query System.out.println(""Creating statement...""); stmt = conn.createStatement(); String sql = ""SELECT id first last age FROM Registration""; ResultSet rs = stmt.executeQuery(sql); //STEP 5: Extract data from result set while(rs.next()){ //Retrieve by column name int id = rs.getInt(""id""); int age = rs.getInt(""age""); String first = rs.getString(""first""); String last = rs.getString(""last""); //Display values System.out.print(""ID: "" + id); System.out.print("" Age: "" + age); System.out.print("" First: "" + first); System.out.println("" Last: "" + last); } rs.close(); }catch(SQLException se){ //Handle errors for JDBC se.printStackTrace(); }catch(Exception e){ //Handle errors for Class.forName e.printStackTrace(); }finally{ //finally block used to close resources try{ if(stmt!=null) conn.close(); }catch(SQLException se){ }// do nothing try{ if(conn!=null) conn.close(); }catch(SQLException se){ se.printStackTrace(); }//end finally try }//end try System.out.println(""Goodbye!""); }//end main }//end JDBCExample very nice tutorial here : http://www.tutorialspoint.com/jdbc/ ResultSetMetaData meta = resultset.getMetaData(); // for a valid resultset object after executing query Integer columncount = meta.getColumnCount(); int count = 1 ; // start counting from 1 always String[] columnNames = null; while(columncount <=count){ columnNames [i] = meta.getColumnName(i); } System.out.println (columnNames.size() ); //see the list and bind it to TableModel object. the to your jtbale.setModel(your_table_model);  I can't create comments yet so posting this as an answer. In addition to the above answers if you're working with a dynamic query and you want the column names but do not know how many columns there are you can use the ResultSetMetaData object to get the number of columns first and then cycle through them. Ammending Brian's code: ResultSet rs = stmt.executeQuery(""SELECT a b c FROM TABLE2""); ResultSetMetaData rsmd = rs.getMetaData(); int columnCount = rsmd.getColumnCount(); // The column count starts from 1 for (int i = 1; i < columnCount + 1; i++ ) { String name = rsmd.getColumnName(i); // Do stuff with name }  import java.sql.*; public class JdbcGetColumnNames { public static void main(String args[]) { Connection con = null; Statement st = null; ResultSet rs = null; try { Class.forName(""com.mysql.jdbc.Driver""); con = DriverManager.getConnection( ""jdbc:mysql://localhost:3306/komal"" ""root"" ""root""); st = con.createStatement(); String sql = ""select * from person""; rs = st.executeQuery(sql); ResultSetMetaData metaData = rs.getMetaData(); int rowCount = metaData.getColumnCount(); System.out.println(""Table Name : "" + metaData.getTableName(2)); System.out.println(""Field \tDataType""); for (int i = 0; i < rowCount; i++) { System.out.print(metaData.getColumnName(i + 1) + "" \t""); System.out.println(metaData.getColumnTypeName(i + 1)); } } catch (Exception e) { System.out.println(e); } } } Table Name : person Field DataType id VARCHAR cname VARCHAR dob DATE"
185,A,Oracle connection/query timeout Is it possible to specify connection/query timeout for the Oracle database queries? Either on Oracle side or in Oracle's JDBC driver (10.2.0.4)? So that Java client just got an error back after let's say 2 minutes instead of waiting until Oracle finishes executing the query? If you are executing the query in the context of a transaction the transaction timeout value of the JTA transaction monitor will be the determinant to query timeout. The configuration for this depends from one application server to another. At an individual query level (in the absence of a JTA transaction monitor) the setQueryTimeout method can be used to set the timeout on the execution of a Statement/PreparedStatement/CallableStatement object. Update setQueryTimeout is not to be relied on although it works (atleast from a J2SE client). It works via the JDBC driver performing a full round-trip to the Oracle database server. Then it is upto the database to halt execution of the query. Don't rely on it for time critical applications. We are having problems with JTA timeout as it does not affect running query. And actually WebLogic server which we run on tries to kill the long running connection and creates another thread to kill it but it hits Java lock in Oracle JDBC driver thus causing both threads to wait. The problem becomes even worse as WebLogic tries to create even more killer-threads and eventualy runs out of them. The point about setQueryTimeout seems very intresting and I haven't thought of that before actuallly :). We don't really care if setQueryTimeout will take some time to cancel the query the main thing here is the result :). I will get back on the test results. The reason setQueryTimeout() might not work in WLS is more so because of JTA. I don't think the driver will respond to setQueryTimeout calls in a transaction context but I might be incorrect. You were right setQueryTimeout didn't work in JTA context :( In case your transaction timeout value is too high you could verify the timeouts set in the JTA service for WLS and in trans-timeout-seconds property in ejb-jar-xml (for CMTs) and in UserTransaction.setTransactionTimeout() for BMTs. It seems that setQueryTimout actually works in JTA context but not always. Sometimes it times out the query after 5 minutes (the value I set in the method) sometimes after 20 minutes sometimes after 60 minutes. The JTA timeout value was actualy not that high in our environments and equals to 30 seconds. Oh well when I said that it should not be relied on for time critical applications I did not anticipate this kind of behavior. By the way Weblogic and most other application servers will rollback the transaction (thus timing out the query) on transaction timeout almost immediately. You might want to check if there is a bug related to your current setup or whether the load on either the application server or database is higher than anticipated.  Have a look at Oracle profiles. This allows you to specify several limits at the database level. One of them is a maximum CPU time per query. If you have queries running for more than 2 minutes on a regular basis you might want to do some tuning of your queries first. Oracle profiles affect all queries for the user. The OP might be interested in just one particular query that needs to be cancelled. But this would work as a brute force solution ;-) Oracle profiles will be our next step if the setQueryTimeout will not work :).
186,A,"JDBC Realm: GlassFish v2.1 = OK; GlassFish v3 = fail with invaliduserreason In my J2EE 5 application I have a JDBC Realm based security with Form method. Encrypt method is MD5 as default. The database is PostgreSQL 8.4 installed locally (or 8.3 available via lan). My app used to work finely on GlassFish v2.1 server with PostgreSQL 8.3 but now I need to deploy it on GlassFish v3. I am absolutely sure I have done all the same config on GFv3 like creating Connection Pool (which pings with no problem) JDBC Resource and JDBC Realm. But on GFv3 I get login exception with ""invaliduserreason"" while the database schema is just created from the working database script. I have checked the data and entered login/password thousand times and it seems that data is all right. So where can I find the reason of unworking security? Please advice. NetBeans 6.8 Thanks. try adding database name to the property Url in your connection pool.. the sqlexception hidden here states that database name is not specified.. worked for me  Setting Digest Algorithm to ""none"" worked for me. I am using Glassfish 3.1 with Derby. In realm config i have name of tables in lowercase and userid and groupid are columns in the same table so these things do not cause problems on Derby.  Here is a nice article about jdbc security realm in glassfish and how to configure it: http://jugojava.blogspot.com/2011/02/jdbc-security-realm-with-glassfish-and.html  You might want to increase the logging for the security system. Go to Logger Settings -> Log Warnings and set logger name 'javax.enterprise.system.core.security' to trace. Try again and check the logs.  I had the same issue here. I resolved setting the security log to finest. I saw that jaas was querying the db in lowercase even though I used a camel notation in naming my fields in postgresql table. The only solution I found was to name all my table and fields in lowercase in Postgresql server as well.  Try changing database tablenames to UPPERCASE. I had the exactly same problem as you have and changing tablenames to uppercase solved the problem for me."
187,A,Microsoft ODBC for Oracle and JDBC Is the Microsoft ODBC driver for Oracle compatible with JDBC? If so could an example be given? Java ships with a JDBC-ODBC bridge so if you can make a connection with ODBC you can use the JDBC-ODBC bridge. However the Oracle JDBC driver is to be preferred since this is software provided by Oracle for connecting to their database. There is a driver for each database server version. The Oracle JDBC driver is a free download (after you create an account)
188,A,"ResultSet.getTimestamp(""date"") vs ResultSet.getTimestamp(""date"" Calendar.getInstance(tz)) java.util.Date java.util.Timetamp were seems to be causing great confusion for many. Within StackOverflow there are so many questions Unfortunately my question is bit twisted. There are 2 JDBC api. How they should perform? Was there any consistencies among RDBMS’es? ResultSet.getTimestamp(""dateColumn"") ResultSet.getTimestamp(""dateColumn"" Calendar.getInstance(tz)) If someone has knowledge in Sybase could you please share your experience? Why is this marked community wiki? First you're confusing java.util with java.sql. When using PreparedStatement#setDate() and ResultSet#getDate() you need java.sql.Date. Analogous when using PreparedStatement#setTimestamp() and ResultSet#getTimestamp() you need java.sql.Timestamp. Second it's important to understand that java.sql.Date represents solely the date (year month day) and nothing less or more. This is to be mapped to a SQL DATE field type. The java.sql.Timestamp represents the timestamp (year month day hour minute second millisecond) exactly as the java.util.Date and java.util.Calendar does. This is to be mapped to a SQL TIMESTAMP or DATETIME field type. As to the timezones you need it when the database does not store timezone information (thus all timestamps are stored in UTC (GMT)). You can then pass a Calendar in which contains information about the current timezone so that the JDBC driver can adjust the UTC timestamp to the timestamp conforming the timezone. If it is for example GMT+1 then the JDBC driver will add one hour to the timestamp before returning. Good answer. For more info on on the variations of the various Date classes in JDBC you may refer to my post here: http://stackoverflow.com/questions/2305973/java-util-date-vs-java-sql-date/2306051#2306051"
189,A,"Indexing File Names To a Database I have a folder with more than 2000 files and I need to index their file names on a database(MySQL) using Java but how could I do this? PS: The MySQL connection part I already know. Do you need help with getting the filenames from the OS setting up tables in MySQL writing an INSERT statement (all of the above)... ? Yeah that's what I need. Check File.listFiles public File[] listFiles() Returns an array of abstract pathnames denoting the files in the directory denoted by this abstract pathname. If this abstract pathname does not denote a directory then this method returns null. Otherwise an array of File objects is returned one for each file or directory in the directory. Pathnames denoting the directory itself and the directory's parent directory are not included in the result. Each resulting abstract pathname is constructed from this abstract pathname using the File(File String) constructor. Therefore if this pathname is absolute then each resulting pathname is absolute; if this pathname is relative then each resulting pathname will be relative to the same directory.  I'm not sure what precisely the problem is. If it's reading the filenames from the directory take a look at File.listFiles().  You can recursively list all the files in a directory like this: import java.io.*; public class ListDir { public static void main(String args[]) { File root; if (args.length > 0) root = new File(args[0]); else root = new File(System.getProperty(""user.dir"")); ls(root); } private static void ls(File f) { File[] list = f.listFiles(); for (File file : list) { if (file.isDirectory()) ls(file); else System.out.println(file); } } } See also Using Prepared Statements. Maybe something like this: PreparedStatement ps = conn.prepareStatement(""INSERT INTO Files VALUES(?)""); File userDir = new File(System.getProperty(""user.dir"")); File[] files = userDir.listFiles(); for (File f : files) { if (f.isFile()) { ps.setString(1 f.getAbsolutePath()); ps.executeUpdate(); } } And I could do this: `""INSERT "" + filenames ""rest of the SQL statement""` with `filenames` as the returned variable from `ls(root)`? I'd use a `PreparedStatement` and call `setString()` instead of `println()` to insert a row for each file. Thanks I'm reading that docs and I'm sure that I can continue from here. Excellent! Also thank you for fixing my typo. :-) @trashgod: How could I put `file` inside a `String` that will have the commas to be used on the `setString()`? I outlined some code above; update your question with your `CREATE TABLE...` statement. Thanks very much! If it's getting slow consider using `addBatch()` instead of `executeUpdate()` and do `executeBatch()` on every 1000th item or so."
190,A,"Accessing the Custom Object Return type from ojdbc6 JDBC Thin Drivers I'm writing some JDBC code which calls a Oracle 11g PL/SQL procdedure which has a Custom Object return type. I can get the code to call the procedure but how do I access the returned Custom Object to obtain it's contained values?. An example of my code calling the procedure is below: PLSQL Code: Procedure GetDataSummary (p_my_key IN KEYS.MY_KEY%TYPE p_recordset OUT data_summary_tab p_status OUT VARCHAR2); Java Code: String query = ""begin manageroleviewdata.getdatasummary(? ? ?); end;""); CallableStatement stmt = conn.prepareCall(query); // Single IN parameter stmt.setInt(1 83); // Two OUT parameters one a Custom Object the other a VARCHAR stmt.registerOutParameter(2 OracleTypes.ARRAY ""DATA_SUMMARY_TAB""); stmt.registerOutParameter(3 OracleTypes.VARCHAR); stmt.execute(stmt); How do I get the result back fron this? We've cracked it: oracle.sql.ARRAY result2 = (oracle.sql.ARRAY) stmt.getObject(2); ResultSet rs = result2.getResultSet(); oracle.sql.STRUCT elements = (oracle.sql.STRUCT) rs.getObject(2); String result = null; if (elements != null) { Object[] objs = elements.getAttributes(); result = objs[2]; } System.out.println(""Result: "" + result); In our case this prints the third element in our Custom Object type."
191,A,"JDBC ResultSet total rows I am implementing Paging in my application. For this I run a query and get a ResultSet. Now I want to get total number of records in this ResultSet for my paging calculation. How can I get this ? I don't want to execute extra SQL which gives me total rows. Just curious is this a web application? If we are not talking about 1000+ records from the query you can very easily implement a java script pagination and avoid having to hit the backend for each page. int totalRows = 0; try { resultSet.last(); totalRows = resultSet.getRow(); resultSet.beforeFirst(); } catch(Exception ex) { return 0; } return totalRows ;  If I'm not mistaken the default behavior for a ResultSet is not to obtain all the rows at once so there is no way to know from the object itself how many rows would be returned from the query without first iterating (and thus retrieving) all of them. You might get different behavior with specific JDBC drivers for specific databases. May I ask why it is too costly for you to run a COUNT() query first ? Compared to the cost of retrieving the actual values it shouldn't be too expensive. Is this best practice ? is this best practice To run a query to get count ? Is there any way ? I don't know if it's the best practice but if you run a count query first (e.g. SELECT COUNT(*) as NumExpectedRows FROM table WHERE whatever;) you could predict the number of rows you would get from the resultset without building the whole set. Databases should optimize this (check with your specific vendor docs). The caveat is that the number of rows should not change until you perform the ""real"" query. yes the count could change between the two queries so it may be inaccurate. But in this application the count could also change between the time that the user requests page 1 and page 2 so we can't guarantee perfect accuracy anyway.  in addition to Fathah solution you can use this code also note that because its a memory pointer this solution has no performance issues: int totalRows = 0; if(rowSet.last()) { totalRows = rowSet.getRow(); } rowSet.beforeFirst();  Another option is to add the count aggregation as a sub queried column in your query. If your database is just a little bit smart it will only execute that once. You should be able to check this easily using the query analyzer in your favorite database. SELECT idusername(SELECT COUNT(id) FROM users) FROM users; i recommended using java solution because if we have a complex query this will has a performance cost Unless you are using a database with a very primitive query optimizer counting the number of rows in the result set will be no more costly than doing it later on the Java side.  The normal practice is to map the ResultSet to a List<Entity> where Entity is a javabean representing the actual data e.g. User Product Order etc. Then you can just use List methods like List#size() to obtain the rowcount. List<Entity> entities = entityDAO.list(); int rows = entities.size(); if (entities.isEmpty()) { // It is empty! } else if (entities.size() == 1) { // It has only one row! } else { // It has more than one row! } Thanks for your reply Actually i dont want to get all rows in a collection because i want to display only 10 rows on page thus my paging calculation helps me to get only 10 rows from resultset. For this i need total no of rows in resultset. Then fire two queries: one to get the `COUNT(*)` (or better `COUNT(pk)`) and another to get the rows of interest. Although pribably not fully suited for your requirement (JSF webapplication) you may get some useful insights out of [this article](http://balusc.blogspot.com/2008/10/effective-datatable-paging-and-sorting.html).  There is no point in counting List size to get record count as we are implementing pagination and SHOULD NOT load entire resultset at a time. I use ROW_NUM at database level to implement pagination logic. We need to get the as many records as we need to show it on the screen. Example: select * from Emp where rownum>=:beginRecord and rownum<=:endRecord Logic will be the same but syntax may change depending up on the type of the database. Need to use nested query if we need to do order by of any column. I believe count(*) is expensive operation rather i prefer partition by. Select Eno Ename  (select count(*) from emp) as record_count from Emp -- Expensive Select Eno Ename  count(*) over (partition by eno) as record_count from Emp -- Preferred one. Partition by syntax may change depending up on the type of the database. I have considered Oracle database. Feel free to comment/discuss. Thanks & Regards Lokesh Rangineni.  From a comment to BalusC's answer: [...] Actually i dont want to get all rows in a collection because i want to display only 10 rows on page thus my paging calculation helps me to get only 10 rows from resultset. For this i need total no of rows in resultset You want nothing but asking the database for about 10 rows and the size of the table. so you actually have two (2) questions to your data store which is equal to two (2) select queries. Do it as Uri suggested and don't care about 'best practice'. If one day someone comes around with a better practice you still can decide whether to adapt your code or not."
192,A,"Strange Exception on getGeneratedKeys() with JDBC for MySQL 5.1 I'm using JDBC to insert a row into a MYSQL database. I build a parameterized command execute it and attempt to retrieve the auto generated keys as follows: String sql = ""INSERT IGNORE INTO `users` (`email` `pass-hash`) VALUES (? ?)""; Connection conn = SQLAccess.getConnection(); PreparedStatement ps = conn.prepareStatement(sql); ps.setString(1 login); ps.setString(2 passHash); int count = ps.executeUpdate(); if (count == 1) { ResultSet rs = ps.getGeneratedKeys(); rs.next(); //some more stuff... } For some reason I get the following SQLException on the line containing ResultSet rs = ps.getGeneratedKeys();: !Statement.Generated Keys Not Requested! Any thoughts? When I run the same query as generated by running the app through the debugger in a MySQL browser it executes without incident. Thanks brian I think you want to call prepareStatement(sql RETURN_GENERATED_KEYS)  The method getGeneratedKeys() is in JDBC 3.0 API and this is not useable on all platform. And PreparedStatement does not have getGenerateKeys() 's implement and it is only in Statement and is a abstract method. Here is a topic about this method's issue : http://forums.sun.com/thread.jspa?threadID=260818"
193,A,"Parameters to tune when retrieving a lot of small BLOBs (2-10kb) from Oracle DB? We have a table in which we store millions of small BLOBs (2-10kb). And we need to access a portion of this table at a time iterating through it while retrieving all these BLOBs (this ""portion"" is usually in the order of 10**5 rows). We use oracle 11g R1. Right now I am thinking about tuning the OracleConnection.setDefaultRowPrefetch() and give it a hint it's read-only. What other tuning could be possible? Also does somebody have experience with handling small BLOBs with oracle 11g R2? Somebody told me that it is better optimized compared to R1 for handling small BLOBs but I was wondering whether it's worth the try. Any advice is appreciated! EDIT: All rows in the ""portion"" will be used -- they will be processed into a special big binary file that will be consumed by another entity. So the iteration itself cannot be avoided. EDIT: Our current DDL (partial modified) TABLESPACE ""BLOB_STUFF"" LOB( ""STUFF"" ) STORE AS BASICFILE ""BLOBS_FILE""( TABLESPACE ""BLOBS"" ENABLE STORAGE IN ROW CHUNK 8192 NOCACHE LOGGING STORAGE (INITIAL 65536 NEXT 1048576 MINEXTENTS 1 MAXEXTENTS 2147483645 PCTINCREASE 0 FREELISTS 1 FREELIST GROUPS 1 BUFFER_POOL DEFAULT) ); The given reason for closure is ""Belongs on ServerFault"" - guess they think this is a server/middle tier configuration question rather than a programming one. Oh. Thanks. Well I might have to tune SQL so.. Heh somebody voted to close this question? Care to explain?? we need to access a portion of this table at a time iterating through it while retrieving all these BLOBs There is a common anti-pattern for OO programmers to write their application so that it just grabs a slack handful of rows from the database and then iterate through them in the middle tier to winnow the rows which are required from the chaff. A more efficient approach is to write a focused query which retrieves just the precise rows. If this is not what you're doing then you should edit your question to clarify your processing. If it is what you're doing you should explain why you need to iterate through one hundred thousand records at a time. Thanks for the comment! I edited the question per your advice.  Something to consider at the Oracle level: Ensure the LOB column is created (or altered) with the CACHE and ENABLE STORAGE IN ROW clauses -- otherwise every read for every row will require a two direct path reads which will be slooooow. Smaller LOBs will be stored inline and larger LOBs will then be stored out-of-line. Both are important: Direct Path Reads require synchronous I/O operations for every row in the data set. Thanks Adam. I posted our current DDL. Guess we are already storing in-line.. Thanks for your follow up. Unfortunately something else came up and I can't test your suggestion right now but I'll try as soon as I have my hands free!"
194,A,"MySQL 'create schema' and 'create database' - Is there any difference Taking a peak into the 'information_schema' database and peaking at the metadata for one of my pet projects I'm having a hard time understanding what (if any) differences there are between the 'create schema' command and the 'create database' command for MySQL. Are there any differences? If not is this a rather typical pattern of behavior for relational databases (I've heard that for other databases such as Oracle a schema exists in a database rather than being on the same level as a database). Thanks! Mysql documentation says : CREATE SCHEMA is a synonym for CREATE DATABASE as of MySQL 5.0.2. this all goes back to an ANSI standard for SQL in the mid-80s. That standard had a ""CREATE SCHEMA"" command and it served to introduce multiple name spaces for table and view names. All tables and views were created within a ""schema"". I do not know whether that version defined some cross-schema access to tables and views but I assume it did. AFAIR no product (at least back then) really implemented it that whole concept was more theory than practice. OTOH ISTR this version of the standard did not have the concept of a ""user"" or a ""CREATE USER"" command so there were products that used the concept of a ""user"" (who then had his own name space for tables and views) to implement their equivalent of ""schema"". This is an area where systems differ. As far as administration is concerned this should not matter too much because here you have differences anyway. As far as you look at application code you ""only"" have to care about cases where one application accesses tables from multiple name spaces. AFAIK all systems support a syntax ""."" and for this it should not matter whether the name space is that of a user a ""schema"" or a ""database"". What is `ISTR`? @DerMike I Seem To Recall http://www.internetslang.com/ISTR-meaning-definition.asp It would be correct to give a reference to the original source from where this answer was taken: http://lists.mysql.com/mysql/211647  The documentation of MySQL says : CREATE DATABASE creates a database with the given name. To use this statement you need the CREATE privilege for the database. CREATE SCHEMA is a synonym for CREATE DATABASE as of MySQL 5.0.2. So it would seem normal that those two instruction do the same.  CREATE SCHEMA is a synonym for CREATE DATABASE. CREATE DATABASE Syntax"
195,A,"Using sql column names in hibernate createSQlquery result i have a couple of sql views with composite primary keys that i want to query and since Hibernate makes it a pain to work with composite keyes im using createSQLQuery. The problem is that this method can only return a List and i need to refer to the colums by their index. Any chance i could do like jdbc and refer to the columns by their sql name insted of their index? thanks Your question is ambiguous - in the first paragraph you want to refer to columns by index and in the second by sql name. Since by index is easy I'll assume by name. First of all you can use the doWork method to access the underlying JDBC connection and handle it as you would with pure JDBC: session.doWork(new Work() { public void execute(Connection connection) throws SQLException { connection.prepareStatement(... } }); Or you can use query.getReturnAliases which returns a String[] of the column names. For effciency I'd probably build a Map of alias to index and then you can do something like result[map.get(""column name"")]. But really Hibernate handles composite keys pretty easily when using xml mappings (haven't tried with annotations). It's a little more work up front and there are a few issues with complex relationships (mainly when foreign key names/spans don't match) but once you create the id class and map it you can stick with HQL/Criteria and get all the benefits of lazy loading simple joins dirty checking etc. @Brian thanks! yes i meant access by name not index ;) @Adi yes that's the answer i wanted thanks!  Method stated in above comment:  query.getReturnAliases() does not work for me actually: Caused by: java.lang.RuntimeException: SQL queries do not currently support returning aliases in query:  Query query=session.createSQLQuery(""your query""); query.setResultTransformer(AliasToEntityMapResultTransformer.INSTANCE); List<Map<StringObject>> aliasToValueMapList=query.list(); As you can figure out from code the list contains Map objects representing each row. Each Map object will have column name as key and value as value. Note: This work for SQLQuery if your using AliasToEntityMapResultTransformer on hql query without specifying aliases you will get index value as key. If you are again transforming aliasToValueMapList to your POJO list I advice you to create your own ResultTransformer and return your custom object from 'transformTuple' method. btw i have a sql query in the form ""select table1.price as price1 from ..."" and for some reason the AliasToEntityMapResultTransformer is not mapping price1. If i do ""select (table1.price*1) as price1 from ..."" it works though. So i think i found a bug in the transformer.. Remember to add `addScalar` declarations (e.g. `query.addScalar(""myAlias"" IntegerType.INSTANCE)`). Otherwise you might get incorrect aliases (e.g. converted to upper-case) or incorrect data types."
196,A,Java library for reading database schema I'm looking for a lightweight open source more or less cross-database Java library that would allow me to read off metainformation on columns tables and integrity constraints given a DataSource. I have found an answer to my question Apache DDLUtils. My question was really a duplicate of this one. Nice library thanks.  Depends what you want to do afterwards of course but if you just want to visualise an existing datatbase I recommend SchemaSpy. Of course JDBC already lets you read metainformation using Connection.getMetaData(). This gives you a DatabaseMetaData instance.
197,A,"designing database tables using JDBC I am creating a users table using JDBC and mysql each user has a permissions list that comprises Integer values. I am wondering if I should use an array for storing these values and then have only 1 record for this user in the table or simply create a new table that comprises 2 columns: user ID and permissions and then have multiple records for each user that specify the user name in one columns and one permission value in the second column. the second option seems to be redundant since a permission value is a simple object that isn't associated with any other objects (like a student and courses list for example because the course is associated with many other objects like grade teacher etc so in this case it is natural to have multiple records) but the first one seems to be a bit unnatural to me so if someone has experience with these things and can direct me to a ""natural"" design? thanks ""This isn't what I need like I said permission is only an integer value (no name or id). I'd like an answer that can walk me through my question's details"" Consider the following statements User noona has permissions 5 6 and 7 User apc has permissions 1 and 9 Which is the more powerful user? What can user noona do with permissions 5 6 and 7? What do those permissions mean? Without storing a name or identifier the meaning of the data exists outside the database. There are occasions when this is valid but usually it is an indicator of a poor design decision. That's why everybody is pushing for a Permissions table and a UserPermissions as an intersection table between that and Users. Having a separate UserPermissions table is the right choice (regardless of where you store the meaning of permissions) because having one column for the value makes it easy to find all users who have permission 4 or to query whether user noona has permission 7. In any event arrays are unnatural. Yes the cases that you mentioned are analogous to my case. thank you. @Noona - It is usual for access permissions to map to something in the real world such as job or role e.g. MANAGER OPERATOR SYSADMIN AUDITOR etc. That's all. If your permissions have such analogues it is good practice to store them in the database. But if not then no worries. the permission value signifies the permission needed for the user to access a certain instrument from a list of instruments maintained in a database so for example if the user APC wants to access instrument x which requires permission level 2 then APC needs to have permission level 2 so practically what I need is the second query: check if user APC has permission 2.  If you want to store multiple permissions for a single user I would properly use three tables. One for the users and one for the permissions. It's bad design to store multiple informations i a single attribute (ex. comma separated). To store multiple informations will give you a lots of limitations. It's not possible to sort the attribute sensible It's no possible to use the attribute to join tables And probably more user idUser name permission idPermission permission userPermission idUser idPermission +1 I agree with this This isn't what I need like I said permission is only an integer value (no name or id). I'd like an answer that can walk me through my question's details. thanks  If you find yourself thinking about storing a comma separated list (or whatever separator) of values in a column this is a very strong hint that you should use another table (actually two since what you have is you have a many to many relationship). Not doing so breaks normalization. That being said I've seen (old) systems that were storing a list of permissions as ""a permission mask"" (e.g. '101101'). But I think it's a poor practice that goes against the above rule and don't have a good argument to justify it (except that you avoid joins... which aren't a problem if you don't do 7+ of them)."
198,A,"Spring Integration as embedded alternative to standalone ESB Does anybody has an experience with Spring Integration project as embedded ESB? I'm highly interesting in such use cases as: Reading files from directory on schedule basis Getting data from JDBC data source Modularity and possibility to start/stop/redeploy module on the fly (e.g. one module can scan directory on schedule basis another call query from jdbc data source etc.) repeat/retry policy UPDATE: I found answers on all my questions except ""Getting data from JDBC data source"". Is it technically possible? The Spring Integration JDBC adapters are available in 2.0 and we just released GA last week. Here's the relevant section from the reference manual: http://static.springsource.org/spring-integration/docs/latest-ga/reference/htmlsingle/#jdbc  Remember ""ESB"" is just a marketing term designed to sell more expensive software it's not a magic bullet. You need to consider the specific jobs you need your software to do and pick accordingly. If Spring Integration seems to fit the bill I wouldn't be too concerned if it doesn't look much like an uber-expensive server installation. I know :). I'm using in projects Mule ESB but often it's overqualified and wish to use simplified and embedded one.  JDBC Adapters appear to be a work in progress. Even if there is no specific adapter available remember that Spring Integration is a thin wrapper around POJOs. You'll be able to access JDBC in any component e.g. your service activators. See here for a solution based on a polling inbound channel adapter too.  This link describes the FileSucker with Spring Integration. Read up on your Enterprise Integration patterns for more info I think. I kinda think you need to do a bit more investigation your self or do a couple of tries on some of your usecases. Then we can discuss whats good and bad"
199,A,"java.sql.SQLException: Io exception: Got minus one from a read call during JDBC connection with oracle Hi I am new to java when I tried to connect oracle with my java sample code I got the above exception My Code is import java.sql.*; import java.io.IOException; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class DbConnectivity extends HttpServlet { protected void doGet(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { try { Class.forName(""oracle.jdbc.driver.OracleDriver""); Connection con = DriverManager.getConnection(""jdbc:oracle:thin:@localhost:8080:orcl"" ""system"" ""tiger"");\\ The Exception thrown here Statement stmt = con.createStatement(); ResultSet rst = stmt.executeQuery(""select * from users""); System.out.println(rst.getString(1)); stmt.close(); con.close(); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); } } } and The exception thrown is java.sql.SQLException: Io exception: Got minus one from a read call at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:112) at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:146) at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:255) at oracle.jdbc.driver.T4CConnection.logon(T4CConnection.java:387) at oracle.jdbc.driver.PhysicalConnection.<init>(PhysicalConnection.java:441) at oracle.jdbc.driver.T4CConnection.<init>(T4CConnection.java:165) at oracle.jdbc.driver.T4CDriverExtension.getConnection(T4CDriverExtension.java:35) at oracle.jdbc.driver.OracleDriver.connect(OracleDriver.java:801) at java.sql.DriverManager.getConnection(Unknown Source) at java.sql.DriverManager.getConnection(Unknown Source) at com.wipro.connnection.DbConnectivity.doGet(DbConnectivity.java:16) at javax.servlet.http.HttpServlet.service(HttpServlet.java:690) at javax.servlet.http.HttpServlet.service(HttpServlet.java:803) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:298) at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:852) at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:588) at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489) at java.lang.Thread.run(Unknown Source) Help me to sort out this Typically Oracle uses port 1521 for database access and you appear to be using port 8080 instead. You should check to make sure you have specified the correct port. I tried with 1521 also but in that case it refused to connect with database and ora 12505 error was occured  First the connection URL is wrong. Post 8080 is normally used by a webserver like Apache Tomcat. Oracle itself uses a default port of 1521. Also see this Oracle JDBC documentation. Further you forgot to call ResultSet#next(). This will set the cursor to the next row in the result set. The result set is returned with the cursor before the first row. Any getXXX() calls on the ResultSet will fail if you don't move the cursor. If you expect multiple rows in a result set then you need to use while loop: resultSet = statement.executeQuery(); while (resultSet.next()) { String columnname = resultSet.getString(""columnname""); // ... } Or if you expect only one row then you can also go ahead with an if statement: resultSet = statement.executeQuery(); if (resultSet.next()) { String columnname = resultSet.getString(""columnname""); // ... } For more hints and examples of using basic JDBC the right way (also in JSP/Servlet) you may find this article useful. The way you closed the statement and connection for example is prone to resource leaking. Also loading the JDBC driver on GET request is unnecessarily expensive. Just do it once during application's startup or servlet's initialization. When I debug the program I found that the exception thrown at Connection con = DriverManager.getConnection(""jdbc:oracle:thin:@localhost:8080:orcl"" ""system"" ""tiger""); Can you please go through this line Fix the connection URL first. Oracle certainly doesn't listen on port 8080. It's usually Tomcat who listens on 8080 and that's not a DB server. Oracle uses by default 1521. I see in the other comment that you got an ORA 12505 when using 1521 in that case just check ora-code.com: http://ora-12505.ora-code.com/  One error i see is that you need to do a rs.next(); This will get tot he first resultset. for example while (!rs.next()){ //read rs.getString(1); }  package testing; import java.sql.DriverManager; import java.sql.Connection; import java.sql.SQLException; import java.sql.*; public class OracleJDBC { public static void main(String[] argv) { System.out.println(""-------- Oracle JDBC Connection Testing ------""); try { Class.forName(""oracle.jdbc.driver.OracleDriver""); } catch (ClassNotFoundException e) { System.out.println(""Where is your Oracle JDBC Driver?""); e.printStackTrace(); return; } System.out.println(""Oracle driver registered""); Connection conn=null; try { conn = DriverManager.getConnection( ""jdbc:oracle:thin:@localhost:1521:orclh"" ""scott"" ""tiger""); Statement stmt= conn.createStatement(); ResultSet r=stmt.executeQuery(""Select * from emp""); while(r.next()){ String str= r.getString(""ename""); System.out.println (str); } } catch (SQLException e) { System.out.println(""Connection Failed! Check output console""); e.printStackTrace(); return; } } }  solution 1 : I think this exception is due to operating system internal environment problem. I have got same problem with type 4 driver. But type 1 driver not giving this exception. So that currently I'm using type 1 driver. Check port number sid at tnsnames.ora C:\oraclexe\app\oracle\product\10.2.0\server\NETWORK\ADMIN\SAMPLE\tnsnames.ora solution 2 : install vmware on your computer install OS then program will work with type 4 driver."
200,A,Performance difference of Native SQL(using MySQL) vs using Hibernate ORM? I am using Spring MVC for an application that involved a multilevel back end for management and a customer/member front end. The project was initially started with no framework and simple native JDBC calls for database access. As the project has grown significantly(as they always do) I have made more significant database calls sometimes querying large selection sizes. I am doing what I can to treat my db calls to closely emulate Object Relational Mapping best practices but am still just using JDBC. I have been contemplating on whether or not I should make the transition to hibernate but was unsure if it would be worth it. I would be willing to do it if it was worth a performance gain. Is there any performance gain from using Hibernate( or even just Object Relational Mapping) over native SQL using JDBC? Is there any performance gain from using Hibernate (or even just Object Relational Mapping) over native SQL using JDBC? Using an ORM a datamapper etc won't make the same SQL queries run faster. However when using Hibernate you can benefit from things like lazy loading second level caching query caching and these features might help to improve the performances. I'm not saying Hibernate is perfect for every use case (for the special cases Hibernate can't handle well you can always fall back to native SQL) but it does a very decent job and definitely improves development time (even after adding time spent on optimization). But the best way to convince yourself would be to measure things and in your case I would probably create an Hibernate prototype covering some representative scenarios and bench it.  Hibernate will make the development and maintenance of your app easier but it won't necessarily make DB access quicker. If your native JDBC calls use inefficient SQL then you might see some performance improvement as HIbernate tends to generate good SQL.  ORM lets you stay inside OOP world but this comes at the cost of performance especially with many to many relations in our case. We were using Hibernate as default doing performance optimization with jdbc where required.
201,A,"Seeing the underlying SQL in the Spring JdbcTemplate? I am learning about the wonders of JdbcTemplate and NamedParameterJdbcTemplate. I like what I see but is there any easy way to see the underlying SQL that it ends up executing? I'd like to see this for debug purposes (in order to for example debug the resulting SQL in an outside tool). To clarify I'd like to see the SQL with the '?' inside to make sure that whole process worked correctly. Hi ArtemDid u achieve this in your code ? Parameter values seem to be printed on TRACE level. This worked for me: log4j.logger.org.springframework.jdbc.core.JdbcTem plate=DEBUG file log4j.logger.org.springframework.jdbc.core.StatementCreatorUtils=TRACE file Console output: 02:40:56519 TRACE http-bio-8080-exec-13 core.StatementCreatorUtils:206 - Setting SQL statement parameter value: column index 1 parameter value [Tue May 31 14:00:00 CEST 2005] value class [java.util.Date] SQL type unknown 02:40:56528 TRACE http-bio-8080-exec-13 core.StatementCreatorUtils:206 - Setting SQL statement parameter value: column index 2 parameter value [61] value class [java.lang.Integer] SQL type unknown 02:40:56528 TRACE http-bio-8080-exec-13 core.StatementCreatorUtils:206 - Setting SQL statement parameter value: column index 3 parameter value [80] value class [java.lang.Integer] SQL type unknown Not working with jdbcTemplate and logback  The Spring documentation tells that they're logged at DEBUG level: All SQL issued by this class is logged at the DEBUG level under the category corresponding to the fully qualified class name of the template instance (typically JdbcTemplate but it may be different if you are using a custom subclass of the JdbcTemplate class). In XML terms you need to configure the logger something like as <category name=""org.springframework.jdbc.core.JdbcTemplate""> <priority value=""debug"" /> </category> This subject was however discussed here a month ago and it seems not as easy to get to work as in Hibernate and/or it didn't return the expected information: argh - can't get spring to log sql This topic under each suggests to use P6Spy which can also be integrated in Spring according this article. Use as name ""org.springframework.jdbc"" to also see the real SQL queries.  I'm not 100% sure what you're getting at since usually you will pass in your SQL queries (parameterized or not) to the JdbcTemplate in which case you would just log those. If you have PreparedStatements and you don't know which one is being executed the toString method should work fine. But while we're on the subject there's a nice Jdbc logger package here which will let you automatically log your queries as well as see the bound parameters each time. Very useful. The output looks something like this: executing PreparedStatement: 'insert into ECAL_USER_APPT (appt_id user_id accepted scheduler id) values (? ? ? ? null)' with bind parameters: {1=25 2=49 3=1 4=1} That the `PreparedStatement#toString()` would return the SQL string is nowhere specified in JDBC API and is thus an implementation detail. You're dependent on the JDBC driver make and/or version whether it works or not. The link referenced in your comment to http://rkbloom.net/logdriver/ appears to be dead now. can you provide any more details about this logger - I can't find any reference to it on the parent site. Thanks  This works for me with org.springframework.jdbc-3.0.6.RELEASE.jar. I could not find this anywhere in the Spring docs (maybe I'm just lazy) but I found (trial and error) that the TRACE level did the magic. I'm using log4j-1.2.15 along with slf4j (1.6.4) and properties file to configure the log4j: log4j.logger.org.springframework.jdbc.core = TRACE This displays both the SQL statement and bound parameters like this: Executing prepared SQL statement [select HEADLINE_TEXT NEWS_DATE_TIME from MY_TABLE where PRODUCT_KEY = ? and NEWS_DATE_TIME between ? and ? order by NEWS_DATE_TIME] Setting SQL statement parameter value: column index 1 parameter value [aaa] value class [java.lang.String] SQL type unknown Setting SQL statement parameter value: column index 2 parameter value [Thu Oct 11 08:00:00 CEST 2012] value class [java.util.Date] SQL type unknown Setting SQL statement parameter value: column index 3 parameter value [Thu Oct 11 08:00:10 CEST 2012] value class [java.util.Date] SQL type unknown Not sure about the SQL type unknown but I guess we can ignore it here For just an SQL (i.e. if you're not interested in bound parameter values) DEBUG should be enough. This is not working for me !! I think this may work with jdbc but no jdbctemplate. Not working for me too"
202,A,"Handling data maintenance in Object Databases like db4o One thing I have continually found very confusing about using an object database like db4o is how you are supposed to handle complex migrations that would normally be handled by SQL/PL-SQL. For example imagine you had a table in a relational database called my_users. Originally you had a column named ""full_name"" now that your software is in V2 you wish to remove this column split the full names on a blank space and put the first part in a column named ""first_name"" and the second in a column named last_name. In SQL I would simply populate the ""first_name"" and ""second_name"" columns then remove the original column named ""full_name"". How would I do this in something like db4o? Do I write a Java program that scripts looking up all objects of User.class setting full_name to null while setting first_name and last_name? When I do my next svn commit there will be no field/bean-property corresponding to full_name would this be a problem? It seems as though to use it in a production application where my ""schema"" changes I would want to write a script to migrate data from version x to version x+1 and then in version x+2 actually remove the properties I am trying to get rid of for version x+1 as I cannot write a Java script to modify properties that no longer are part of my type. It seems that part of the problem is that an RDBMS resolves what object you are referring to based on a simple case insensitive string-based name in a language like Java typing is more complicated than this you cannot refer to a property if the getter/setter/field are not a member of the class loaded at runtime so you essentially need to have 2 versions of your code in the same script (hmm custom classloaders sound like a pain) have the new version of your class stored belong to another package (sounds messy) or use the version x+1 x+2 strategy I mentioned (requires a lot more planning). Perhaps there is some obvious solution I never gleaned from the db4o documents. Any ideas? Hopefully this makes some sense. First db4o handles the 'simple' scenarios like adding or removing a field automatically. When you adding the field all existing object have the default value stored. When you remove a field the data of existing object is still in the database and you can still access it. Renaming field etc are special 'refactoring'-calls. Now your scenario you would do something like this: Remove the field 'full_name' add the new fields 'first_name' and 'second_name' Iterate over all 'Address'-objects Access the old field via the 'StoredClass'-API Split change update etc the value. Set the new values on the new field and store the object. Let's assume we have a 'Address'-class. The 'full_name' field has been removed. Now we wan't to copy it to the 'firstname' and 'surname'. Then it could go like this (Java):  ObjectSet<Address> addresses = db.query(Address.class); StoredField metaInfoOfField = db.ext().storedClass(Address.class).storedField(""full_name"" String.class); for (Address address : addresses) { String fullName = (String)metaInfoOfField.get(address); String[] splitName = fullName.split("" ""); address.setFirstname(splitName[0]); address.setSurname(splitName[1]); db.store(address); } As you suggested you would write migration-code for each version-bump. It a field isn't part of your class anymore you have to access it with 'StoredField'-API like above. You can get a list of all 'stored' classes with ObjectContainer.ext().storedClasses(). With StoredClass.getStoredFields() you can get a list of all store fields no mather is the field doesn't exist anymore in your class. If a class doesn't exist anymore you can still get the objects and access it via 'GenericObject'-class. Update: For complexer scenarios where a database needs to migrated over multiple-version-steps. For example it in the version v3 the address-object looks completely different. So the 'migration-script' for v1 to v2 hasn't got the fields anymore it requires (firstname and surename in my example). I think there are multiple possibilities for handling this. (Assuming Java for this idea. Certainly there's an equivalent in .NET). You could make the migration-step a Groovy-script. So each that each script does not interfere with another. Then you define 'classes' the needed classes for the migration there. So each migration has its own migration-classes. With aliases you would bind your groovy-migration-classes to the actual java-classes. Creating refactoring-classes for complex scenarios. Also bind this classes with aliases.  I'm taking a bit of a wild shot here because I didn't refactor too much data in my life. You're making a strange comparison: If you wanted to 'hot-migrate' the db you'd probably have to do the x+1 x+2 versioning approach you described but I don't really know - I wouldn't know how to do this with SQL either since I'm not a db expert. If you're migrating 'cold' however you could just do it in one step by instantiating a new object from the old data store the new object delete the old object for each object in the store. See db4o reference. But honestly: the same process in a RDBMS is complicated too because you will have to de-activate constraint checks (and possibly triggers etc.) to actually perform the operation - perhaps not in the example you provided but for most real-world cases. After all the string split is so easy that there will be little gain. In SQL I would simply populate ""first_name"" and ""second_name"" columns Yes with a simple string split operation you can simply do that. But in a typical refactoring scenario you're re-structuring objects based on large and complicated sets of rules that might not be easily expressed in SQL might need complex calculation or external data sources. To do that you'd have to write code too. After all I don't see too much difference in the two processes. You will always have to be careful with live data and you will certainly make a backup in both cases. Refactoring is fun but persistence is tricky so synchronizing it is a challenge in any case."
203,A,"How to get equivalent of ResultSetMetaData without ResultSet I need to resolve a bunch of column names to column indexes (so as to use some of the nice ResultSetMetaData methods). However the only way that I know how to get a ResultSetMetaData object is by calling getMetaData() on some ResultSet. The problem I have with that is that grabbing a ResultSet takes up uneccesary resources in my mind - I don't really need to query the data in the table I just want some information about the table. Does anyone know of any way to get a ResultSetMetaData object without getting a ResultSet (from a potentially huge table) first? Maybe you could use DatabaseMetaData databaseMetaData = connection.getMetaData(); databaseMetaData.getColumns(null null tableName ""%""); It returns one row for each table column. In this case you'd use the returned ResultSet itself not its ResultSetMetaData. One advantage of this approach is that it doesn't interfere with database locking and transactions. ^^^ This!!! However with the caveat it puked out on my on Sybase running on HP. This was on 2001 mind you. But in general this is the way to do it. You're correct - looking into this method made it clear that it works in a cleaner manner.  Assuming you're doing a select * from mytable you could just add a where clause that ensures no records will be returned and the ResultSet will be empty? That way you are still just getting the metadata for the table you are interested in instead of the entire database. Yep this is what I figured out as well. I ended up using a LIMIT 1 clause instead of the WHERE clause for clarity but it seems to be doable both ways. This is however a bit hacky. Just using the `DatabaseMetaData` is more neat. WHERE 1=0 would work with any database."
204,A,Finding the actual Job number for a particular JDBC SQL connection to iSeries? I am using the JTOpen JDBC driver to connect to the iSeries (aka AS/400 IBM System-i IBMi WTH?!...). I am having problems with a particular statement and it appears I need to go back to the actual SQL job QSQSRVR (or QZDASOINIT?) to find more details. Only problem is that there are hundreds of these on the system. Is there an easy way to determine the job which is actually handling my SQL connection or a particular statement? If the remote app can't be modified there are a couple possibilities on the server side. The most common method is to search for jobs that have a lock on the user profile (*USRPRF) that logged on through a connection. The system won't allow a user profile to be deleted while it's active in a job so the lock can be handy: WRKOBJLCK logonuser *USRPRF The connection itself can also be useful. The NETSTAT command can list connections: NETSTAT *CNN The remote IP address can be checked against the listed services to determine the particular connection. The matching system job can be accessed from there.  From the JT400 javadoc of the class AS400JDBCConnectionHandle : getServerJobIdentifier public String getServerJobIdentifier() throws SQLException Returns the job identifier of the host server job corresponding to this connection. Every JDBC connection is associated with a host server job on the system. The format is:  * 10 character job name * 10 character user name * 6 character job number Note: Since this method is not defined in the JDBC Connection interface you typically need to cast a Connection object returned from PooledConnection.getConnection() to an AS400JDBCConnectionHandle in order to call this method:  String serverJobIdentifier = ((AS400JDBCConnectionHandle)connection).getServerJobIdentifier(); Returns: The server job identifier or null if not known. Throws: SQLException - If the connection is not open. This answer works
205,A,"Accessing an SDF SQLServer Mobile file from Java Here at work we want to access the data inside a .sdf file generated in a PDA with SQLServer Mobile Edition. We use the SqlJDBC4 packet for JDBC but can't get into the server. We know it's running because we can telnet into it but from the Java code we just get once and again that we can't connect to server. We use this connection String: String connectionUrl=""jdbc:sqlserver://localhost;databaseName=d:\\file.sdf;""+ ""SelectMethod=cursor;Password=test;integratedSecurity=true""; Any fellow stackoverflower can tell us the right connection string or whatever we are doing wrong? This is from a question about a CE-Database. But maybe it can help you anyway. From my understanding the problem is similar - getting access to the sdf. Thanks for answering this old question. Sadly I can't test it anymore but I appreciate your effort."
206,A,"What options are available for connecting to a Microsoft SQL Server database from an Oracle database? At the moment I pull data from remote MS SQL Server databases using custom-built JDBC connectors. This works fine but doesn't feel like the way to do it. I feel I should be able to put a JDBC connection string into tnsnames on the server and have it ""just work"". I've looked around a little for this functionality but it doesn't seem to be there. In this way I could connect to pretty much any database just using a database link. Have I missed something? It looks like the two options are Generic Connectivity and Oracle Gateways but I'm surprised that's all there is. Generic Connectivity comes with the database license and Oracle Gateways is an add-on. For Generic Connectivity if you're running on Linux (like me) you need to get hold of an ODBC driver as it isn't bundled with the database. However... with Oracle being such keen Java fans and with a JVM built-in to the database I'd have thought a JDBC-based linking technology would have been a no-brainer. It seems a natural extension to have a JDBC connection string in TNSNAMES and everything would ""just work"". Anyone any ideas why this isn't available? Generic Connectivity is what you are after it will let you setup a remote database link against MS SQL Server so you can do queries like select * from mytable@my_ms_sql_server; I've only used it in Oracle 9i against mysql and found that in our cases it didn't work very well as it ended up using up MASSIVE amounts of ram we still use it but now just use it for syncing to a local table rather than doing 'live' queries against it. BUT it might be completely different against MS SQL Server and in 10g/11g  Another product to look at is Oracle Gateways. Have a look at: http://www.oracle.com/technology/documentation/gateways10g.html"
207,A,"SQL (Java h2): What's the best way to retrieve the unique ID of the single item I just inserted into my database? My current method is this: SELECT TOP 1 ID FROM DATAENTRY ORDER BY ID DESC This assumes the latest inserted item always has the highest unique ID (primary key autoincrementing). Something smells wrong here. Alternatives? If the JDBC driver supports it you can also just use Statement#getGeneratedKeys() for that. String sql = ""INSERT INTO tbl (col) VALUES (?)""; preparedStatement = connection.prepareStatement(sql Statement.RETURN_GENERATED_KEYS); preparedStatement.setString(1 col); preparedStatement.executeUpdate(); generatedKeys = preparedStatement.getGeneratedKeys(); if (generatedKeys.next()) { long id = generatedKeys.getLong(1); } else { // Throw exception? } Let me see if this works... To my experience and knowledge all current JDBC driver versions of the major RDBMS servers like MySQL MSSQL PostgreSQL Oracle and DB2 supports it (it took a while for Oracle and PostgreSQL up to about one year ago they didn't support it). Unfortunately I don't have experience with H2 so I can't tell from top of head but a quick glance on Google learns me that it does support it. Okay great it works! Is this better than IDENTITY() though? It *does* `IDENTITY()` ""under the hoods"" but now in a more abstract and DB-agnostic way using pure JDBC API. You have less maintenance headache whenever you'd like to switch of database. If you did it all the right and standard-SQL way then all you basically need to do is to replace JDBC driver and URL/login. You can keep the coding intact.  If using MySQL you can do select last_insert_id(); If using MS SQL select scope_identity(); For H2 I believe it's CALL SCOPE_IDENTITY(); but I don't have any experience with that DB Hmm. I wonder if there's an H2 equivalent... Sorry didn't see the h2 tag initially. Updated my answer with what I believe to be the equivalent. Well I will be inserting with PreparedStatement instances in Java so I might need IDENTITY() instead. But yeah that should do it. Thanks. H2's `SCOPE_IDENTITY()` won't work as expected. See https://groups.google.com/d/msg/h2-database/0xJsP993RHY/0LERpBvtLNUJ"
208,A,"Insert a record with a value partly from another table I have two tables Proteins and Species. Protein has Species.Id as foreign key constraint. When I insert the data I know the name of the species that protein belongs to but not the Id. So I do the following:  PreparedStatement query = connection.prepareStatement( ""SELECT Id FROM Species WHERE ShortName = ?""); query.setString(1 protein.getSpecies().getShortName()); ResultSet result = query.executeQuery(); if (result.next()) { PreparedStatement statement = connection.prepareStatement( ""INSERT INTO Proteins(SpeciesId UniProtKBAccessionNumber) VALUES (? ?)""); statement.setString(1 result.getString(1)); statement.setString(2 protein.getUniProtKBAccessionNumber().toString()); statement.execute(); } else throw new IllegalArgumentException(""The species of this protein is not recognized!""); Basically I get the Id that corresponds to the name and then insert the protein. This seems very clumsy in many ways. Is there a more elegant way to achieve this? I am working on an SQLite database. Try this INSERT INTO Proteins(SpeciesId UniProtKBAccessionNumber) VALUES ((SELECT Id FROM Species WHERE ShortName = ?) ?) And then use Shortname and UniProtKBAccessionNumber as your parameters"
209,A,"Connection hangs after time of inactivity In my application Spring manages connection pool for database access. Hibernate uses these connections for its queries. At first glance I have no problems with the pool: it works correctly with concurrent clients and a pool with only one connection. I can execute a lot of queries so I think that I (or Spring) don't leave open connections. My problem appears after some time of inactivity (sometimes 30 minutes sometimes more than 2 hours). Then when Hibernate does some search it lasts too much. Setting log4j level to TRACE I get this logs: ... 18:27:01 DEBUG nsactionSynchronizationManager - Retrieved value [org.springframework.orm.hibernate3.SessionHolder@99abd7] for key [org.hibernate.impl.SessionFactoryImpl@7d2897] bound to thread [http-8080-Processor24] 18:27:01 DEBUG HibernateTransactionManager - Found thread-bound Session [org.hibernate.impl.SessionImpl@8878cd] for Hibernate transaction 18:27:01 DEBUG HibernateTransactionManager - Using transaction object [org.springframework.orm.hibernate3.HibernateTransactionManager$HibernateTransactionObject@1b2ffee] 18:27:01 DEBUG HibernateTransactionManager - Creating new transaction with name [com.acjoventut.service.GenericManager.findByExample]: PROPAGATION_REQUIREDISOLATION_DEFAULT 18:27:01 DEBUG HibernateTransactionManager - Preparing JDBC Connection of Hibernate Session [org.hibernate.impl.SessionImpl@8878cd] 18:27:01 TRACE SessionImpl - setting flush mode to: AUTO 18:27:01 DEBUG JDBCTransaction - begin 18:27:01 DEBUG ConnectionManager - opening JDBC connection Here it gets frozen for about 2 - 10 minutes. But then continues: 18:30:11 DEBUG JDBCTransaction - current autocommit status: true 18:30:11 DEBUG JDBCTransaction - disabling autocommit 18:30:11 TRACE JDBCContext - after transaction begin 18:30:11 DEBUG HibernateTransactionManager - Exposing Hibernate transaction as JDBC transaction [jdbc:oracle:thin:@212.31.39.50:30998:orcl UserName=DEVELOP Oracle JDBC driver] 18:30:11 DEBUG nsactionSynchronizationManager - Bound value [org.springframework.jdbc.datasource.ConnectionHolder@843a9d] for key [org.apache.commons.dbcp.BasicDataSource@7745fd] to thread [http-8080-Processor24] 18:30:11 DEBUG nsactionSynchronizationManager - Initializing transaction synchronization ... After that it works with no problems until another period of inactivity. IMHO it seems like connection pool returns an invalid/closed connection and when Hibernate realizes that ask another connection to the pool. I don't know how can I solve this problem or things I can do for delimiting it. Any help achieving this will be appreciate. Thanks. EDIT: Well it finally was due a firewall rule. Database detects the connection is lost but pool (dbcp or c3p0) not. So it tries to query the database with no success. What is still strange for me is that timeout period is very variable. Maybe the rule is specially strange or firewall doesn't work correctly. Anyway I have no access to that machine and I can only wait for an explanation. :( Check the config of your pool implementation. Usually it's Apache DBCP which has a timeout for each connection after it will close it. In your code you shouldn't keep connections around. Get one use it close it immediately. The pool will make sure that this doesn't cost too much. There are two other sources of trouble: There might be a firewall between you and the database server (but a 2h timeout on idle TCP connections is a bit short). Or your database is configured to close idle connections after some time. See the other config options of DBCP to check for dead connections and for pinging the DB in regular intervals to keep the pipe open. As for close: No you shouldn't close it but you should end the transaction (which will make Spring see that the connection can be returned to the pool). Spring manages my connections so I'm not the one who must explicitely call Connection.close(). Am I? As you say I'm using org.apache.commons.dbcp.BasicDataSource with destroy-method=""close"". I'll research about it.  I've had problems like this before when the database is on a seperate box and there's a firewall in between which is set to timeout idle connections. In some circumstances the firewall cuts off the connection in such a way that the JDBC end doesn't detect and attempting to use it results in an indefinite block. In my case it was a custom connection pool which sent a test query down the connection before returning it from the pool. I configured this test query to have a timeout (using Statement.setQueryTimeout) so that it didn't block indefinitely. I am not sure why you would use a custom pool to only send a test query. A little decent connection pool and/or container managed datasource is already capable of this. So does for example DBCP and Tomcat JNDI. Refer the config documentation using under each the keyword `validationQuery`. This was in a project (a long long time ago) that used a bespoke connection pool and was in the section of code that did indeed do a similar thing to validationQuery in DBCP. You're right. It seems that the problem is some firewall rule out of my control. I think that the best solutions would be change firewall behaviour. Thanks.  We solved problem with similar symptoms which also turned out to be caused by a firewall. We were able to work around the problem by changing the testWhileIdle connection pool property which prevents the connection from going idle and from the firewall shutting down the connection. See Apache commons dbcp BasicDataSource. Here is an exert from the configuration file persistentce-context.xml that fixed the problem: <property name=""testWhileIdle""> <value>true</value> </property> <property name=""minEvictableIdleTimeMillis""> <value>600000</value> </property> <property name=""timeBetweenEvictionRunsMillis""> <value>600000</value> </property> Most likely we only need to add the testWhileIdle (false by default) but added the other two properties for good measure. In our case here are some of the logs which we were seeing. Notice in this debug logs it would take 16 minutes to open the connection before the connection could be used and this is what caused everything to hang. There were no errors which made it hard to track down. 09-06-13 @ 16:36:34 [DEBUG] HibernateTransactionManager - Preparing JDBC Connection of Hibernate Session [org.hibernate.impl.SessionImpl@db17ab] 09-06-13 @ 16:36:34 [DEBUG] ConnectionManager - opening JDBC connection 09-06-13 @ 16:52:00 [DEBUG] DataSourceUtils - Setting JDBC Connection 09-06-13 @ 16:52:00 [DEBUG] JDBCTransaction - begin 09-06-13 @ 16:52:00 [DEBUG] JDBCTransaction - current autocommit status: true  you have to add some parameters in your DataSource: more important add testOnBorrow and validationQuery  One way to resolve idle time out issue is to have dual connection pools one is active and other one is standby (no connections created yet). Have a timer with trigger time much less than FIREWALL_IDLE_TIMEOUT and switch between connection pools. I tried this and ITS WORKING."
210,A,"Binding a null variable in a PreparedStatement I swear this used to work but it's not in this case. I'm trying to match col1 col2 and col3 even if one or more of them is null. I know that in some languages I've had to resort to circumlocutions like ((? is null AND col1 is null) OR col1 = ?). Is that required here?  PreparedStatement selStmt = getConn().prepareStatement( ""SELECT * "" + ""FROM tbl1 "" + ""WHERE col1 = ? AND col2 = ? and col3 = ?""); try { int col = 1; setInt(selStmt col++ col1); setInt(selStmt col++ col2); setInt(selStmt col++ col3); ResultSet rs = selStmt.executeQuery(); try { while (rs.next()) { // process row } } finally { rs.close(); } } finally { selStmt.close(); } // Does the equivalient of stmt.setInt(col i) but preserves nullness. protected static void setInt(PreparedStatement stmt int col Integer i) throws SQLException { if (i == null) stmt.setNull(col java.sql.Types.INTEGER); else stmt.setInt(col i); } See also http://en.wikipedia.org/wiki/Null_%28SQL%29#Three-valued_logic_.283VL.29 This may depend on the JDBC driver but for the most part yes you would need to use the more extended form you show above. JDBC prepared statements are usually relatively thin wrappers around a native implementation of a parameterized query i.e. the query with ? in place of parameters are passed to the query compiler and compiled so later when you call stmt.executeQuery() the statement cannot be adjust from a column = ? to column IS NULL. This isn't so much a limitation of JDBC as it the semantics of NULL in SQL. For SQL x = NULL is undefined as is x <> NULL. That said some JDBC drivers may violate the notion of NULL-ity in SQL and allow setNull() to transform the statement from = ? to IS NULL this would be highly non-standard behavior (though it could be easily accomplished by writing some sort of query pre-processing method).  What database are you using? But at least with Oracle equality (and inequality) never matches NULL you have to write IS NOT NULL.  Generally something being equal to NULL is always false (even NULL so SELECT * FROM tbl WHERE NULL=NULL; will be an empty set) so you probably do need to do it the long way if you want to accept null equality like that @michael-mrozek `WHERE NULL = NULL` actually returns `NULL`. Thus for example `SELECT * FROM tbl WHERE NOT (NULL = NULL)` also results in an empty set."
211,A,"Is statement.close() explicitly required in connection pooled environment? I am using connection pooling in my application. My question is: Is it explicitly required to close statement before closing connection in case of connection pooled environment? In connection pooled environment connection is not getting closed (but returns back to free connection pool). I had checked jdbc 4.0 functional specs. In point number 9.4.4 it clearly states that : Closing Connection Objects An application calls the method Connection.close to indicate that it has finished using a connection. All Statement objects created from a given Connection object will be closed when the close method for the object is called. Once a Connection has been closed any attempt to access any of its methods with the exception of the close isClosed or isValid methods will result in a SQLException being thrown. So jdbc specs mandates closing all statement at a time of closing connection. So is it applicable to only non connection pooled environment only or it applies to connection pooled environment also ? According to me it should not matter in case of pooled environment because we are coding for interface (java.sql.Connection & java.sql.Statement). So we are not bothering about implementation and parent class (java.sql.Connection) doesn't have any information about child/impementation class (Vendor implementation class). If jdbc specs mandates to all implementation to close statement at a time of closing connection then we can easily skips statement.close method in case of we are using connection.close method (in connection pooled or non pooled environment). ...is that a question? Absolutely. It's possible that the Statement implementation will have other resources which should be released or have some other relationship with the connection. You don't and shouldn't know the implementation details. Your approach is absolutely right: code to the interface and avoid little ""short-cuts"" which could easily bite you later. (Even if it works now it might not in a future version of the pool or connection classes.) The other students in my database class in college can attest to the importance of calling .close. My application neglected to call close and ended up creating lots of lingering connections on the DB server. So much so that it started preventing new connections from being created. The night before the project was due.  Any object which has close() release() destroy() etc suggests automatically(of course you should read the API documentation there might be different names used for this purpose) that the object needs an invoke of this method to ensure that the object resources are released when the object is not in use anymore.There will be no reason to provide such a method if the object can do that by itself. In case of pooled java.sql.Connection the connection is not really closed is just pushed back in the pool as available connection but this is internal stuff aka you should not care.  In my experience some JDBC drivers have bugs. They seem to work best if you close all Statements (and ResultSets) manually. Otherwise I have seen resource leaks that shouldn't have persisted past the closing of the Connection."
212,A,"SQL Server Exception: ""The column name xxx is not valid"" when using JDBC I'm getting a strange error from the SQL Server JDBC driver. It is telling me that a column name is invalid even though the column is present correctly named and the same query works fine when executed in SqlServer Management Studio. The error is: Caused by: com.microsoft.sqlserver.jdbc.SQLServerException: The column name MarginCall is not valid. at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDriverError(SQLServerException.java:170) at com.microsoft.sqlserver.jdbc.SQLServerResultSet.findColumn(SQLServerResultSet.java:626) at com.microsoft.sqlserver.jdbc.SQLServerResultSet.getBigDecimal(SQLServerResultSet.java:2570) at org.apache.commons.dbcp.DelegatingResultSet.getBigDecimal(DelegatingResultSet.java:305) ... Can you include the offending code? Does the name match the values you get in ResultSet.getColumnNames? Try to enclose the column name inside square brackets: [MarginCall] Just a guess. I'm afraid that wasn't the problem but thanks very much for the suggestion.  Problem solved. It was a simple mistake by me. My query was using an 'AS' clause in the select statement. I was trying to retrieve the column value from the ResultSet using the actual column name instead of the column alias defined in the AS clause. Schoolboy error. Apologies for the time wasting. Many thanks to Steve B. for his suggestion to use ResultSet.getColumnNames(). Although the actual method call I used was ResultSet.getMetaData().getColumnName(columnIndex);  Check the case of your table name. if collation is set to case sensitive on ms sql server the table names are affected too."
213,A,How can I expose a C ODBC connection to a JVM using JNI? I'm embedding a JRE in an existing C application using the invocation API and I'd like to be able to use JDBC to work with the database in that code. This application is a transaction processing application and the database transaction is managed by code in the C portion of the application and the java code must run within that transaction. This means that I can't open a new connection I must re-use the existing one. So is there a way to provide JDBC access to an existing ODBC connection handle when setting up the JRE? Some JDBC-ODBC bridge perhaps but unlike the existing driver by that name one that can be set up to use an existing connection and transaction. My other options as I see them are as follows: Provide java equivalents for every C operation that is possible in the application (this is not desirable for a great many reasons -- we have a great many methods and duplicating them is a pain in the ass. Write my own JDBC driver that wraps the ODBC connection with JNI. Sure it'd be a fun weekend (month) project but I expect to need something done faster than that. Help me Stack-Overflow you're my only hope! Don't know whether this'll work but... I had a quick look at the decompiled source code of Sun's JDBC-ODBC bridge. Seems like you could subclass the JdbcOdbcConnection so that it initializes itself with a known connection handle and an already-opened state. This assumes that the connection handles on the Java side are actual ODBC connection handles or pointers to connection objects and that ODBC libraries used by the JDBC-ODBC bridge and your code are compatible in the sense that they can share connection handles. You need to check whether Sun's license allows developers to perform such trickery though. Alexander this is what I ended up doing; in fact as I asked the question I was already pursuing that approach and it turns out to work very well. Thanks for the independent verification!  Sun provides a JDBC-ODBC bridge in the JDK. EDIT: Rereading sounds like you already know about it and don't want to use it. The JDBC-ODBC brige provides a way to create a new connection not re-use an existing one; I noted this in the question itself.
214,A,"Strange problem with JDBC select returns null I am trying to use JDBC and my query is working in some cases but not working in others. I would really appreciate any help. Some of my code: public Result getSpecificTopic() { String query = ""Select msg_body msg_author from lawers_topic_msg"";// where msg_id=2 order by msg_id desc""; try { con = mysql.getConnection(); //Statement stmt = con.createStatement(); PreparedStatement stmt = con.prepareStatement(query); //stmt.setInt(1 topicId); ResultSet rs = stmt.executeQuery(query); int rowCount = rs.getRow(); specificTopic = ResultSupport.toResult(rs); con.close(); stmt.close(); } catch(Exception e) { } return this.specificTopic; } public void setTopicId(String num) { this.topicId = Integer.parseInt(num); } public int getTopicId() { return this.topicId; } However if i change String query = ""Select msg_body msg_author from lawers_topic_msg""; to the String query = ""Select msg_body msg_author from lawers_topic_msg where msg_id = "" + topicId; Then the resultset retunrs nothing.... I am breaking my head here and still cannot figure out what is the problem Did you try printing the query to the console before running it? Take the output of that and then run it against your database directly. Thanks you were right. I wish i could give you on the comment accepted answer. As a first step it'd be worth making sure an exception's not being thrown - at the very least log something in your catch() block. Also be worth logging the SQL generated and making sure that actually returns what you expect from the database when running it directly. If you have multiple databases it'd be worth confirming you're running against the one you think you are - I'm embarrassed to admit I've been caught out that way before. +1 for ""do something in your catch block"".  You still aren't closing your resources properly. That should be done in a finally block: http://www.java-blog.com/correct-closing-jdbc-resources Thanks for the link and advice. I changed it.  my first guess would be Integer.parseInt(num) could throw an exception. if so the sql statement will be broken. secondly as Makach pointed out there are several issues. first the catch-all you should not use string concatenation like  ....where msg_id = "" + topicId; but rather  ....where msg_id = ?"" stmt.set Int(1topicId) edit: it seems thats what you were trying anyways SO sucks in some characters. Thanks for the advice regarding my code. I changed it now to the proper way.  several issues with your code i'll keep it short: don't encapuslate with try / catch at this layer aspecially not since you're doing no error management. this.specificTopic looks global so if your query fails it will return whatever was stored in this.specificTopic. also try what BobbyShaftoe said. print in console or use your debugger. This should give you a good indication on what is wrong. topicId is just private variable in same class. But you spot on about running query directly trough database."
215,A,"What is a Connection in JDBC? What is a Connection Object in JDBC ? How is this Connection maintained(I mean is it a Network connection) ? Are they TCP/IP Connections ? Why is it a costly operation to create a Connection every time ? Why do these connections become stale after sometime and I need to refresh the Pool ? Why can't I use one connection to execute multiple queries ? These connections are TCP/IP connections. To not have to overhead of creating every time a new connection there are connection pools that expand and shrink dynamically. You can use one connection for multiple queries. I think you mean that you release it to the pool. If you do that you might get back the same connection from the pool. In this case it just doesn't matter if you do one or multiple queries The cost of a connection is to connect which takes some time. ANd the database prepares some stuff like sessions etc for every connection. That would have to be done every time. Connections become stale through multiple reasons. The most prominent is a firewall in between. Connection problems could lead to connection resetting or there could be simple timeouts Thanks Norbert. My question was can I run two or more queries on One Connection object at the same time ? I don't know for sure but I would just try. If you send a query you get back handle for your result set. So theoretically there isn't much of a reason what that shouldn't work. Maybe it differs between databases but with the bigger ones I wouldn't expect this to be a problem Norbert I think we can not execute two queries on the same Conenction. There might be Synchronization issues. I too am not sure but the logic would be if you could do it then you would never need a Pool. One connection would be sufficient. You can surely do it the only thing to remember is you will share the same properties of connection and same session between queries. Possibly same transaction would be used unless otherwise commit or rollback in any possible way. Further let me make this clear too. When you send the connection back to pool the API would reset the state of that connection as its newly instantiated. For example you may have changed the setAutoCommit() but when you send it back to pool the underlying pool library would revert back the default value. @Geek You would need the pool anyway because the creation of a simple connection is actually quite heavy. So you keep and reuse TCP/IP connections and the already set up connection inside the database. That is the main issue about having a pool. By sharing a pool the average needed connection is at the possible lowest value. So you might need 3 connections at max per web server. That lowers the overall amount of connections at the database which is a big speedup @Geek I forgot to add that having this scenario you speed up everything if you hold the connection only if you need it. Than the average will be lower. Consider not fetching a connection at the beginning of a method but first prepare everything than fetch a connection send a query and give back the connection at earliest possible time  To add to the other answers: Yes you can reuse the same connection for multiple queries. This is even advisable as creating a new connection is quite expensive. You can even execute multiple queries concurrently. You just have to use a new java.sql.Statement/PreparedStatement instance for every query. Statements are what JDBC uses to keep track of ongoing queries so each parallel query needs its own Statement. You can and should reuse Statements for consecutive queries though. Yescon.createStatement() produces a new instance everytime. But you can use it repeatedly to execute statements as in: stmt.execute(""my sql 1""); stmt.getResultSet; // do stuff with ResultSet; stmt.execute(""my sql 2"")... But you must not use a ResultSet after you have reused its Statement b/c then the ResultSet will have been reset. What do you mean by your last statement. We can only reuse the variable not the statement object as we usually do con.createStatement() or con.prepareStatement(). And I believe it gives you a new instance everytime.  The answers to your questions is that they are implementation defined. A JDBC connection is an interface that exposes methods. What happens behind the scenes can be anything that delivers the interface. For example consider the Oracle internal JDBC driver used for supporting java stored procedures. Simultaneous queries are not only possible on that they are more or less inevitable since each request for a new connection returns the one and only connection object. I don't know for sure whether it uses TCP/IP internally but I doubt it. So you should not assume implementation details without being clear about precisely which JDBC implementation you are using. For Oracle JDBC drvier use the TCP/IP protocol that emulates Oracle's Net8. I hope it makes the thing clear.  since I cannot comment yet wil post answer just to comment on Vinegar's answer situation with setAutoCommit() returning to default state upon returning connection to pool is not mandatory behaviour and should not be taken for granted also as closing of statements and resultsets; you can read that it should be closed but if you do not close them they will be automatically closed with closing of connection. Don't take it for granted since it will take up on your resources on some versions of jdbc drivers. We had serious problem on DB2 database on AS400 guys needing transactional isolation were calling connection.setAutoCommit(false) and after finishing job they returned such connection to pool (JNDI) without connection.setAutoCommit(old_state) so when another thread got this connection from pool inserts and updates have not commited and nobody could figure out why for a long time..."
216,A,"Using JDBC how can I substitute multiple IDs into ""DELETE FROM T WHERE id IN (?)"" I have some code that produces a set of primary key values that I want to delete from a database table. long[] keysToDelete = { 0 1 2 3 }; and I'd like to use a PreparedStatement to execute the equivalent of DELETE FROM MyTable WHERE myPrimaryKey IN (0 1 2 3); Any idea how? See similar (*near* duplicate) question here: http://stackoverflow.com/questions/337704/parameterizing-a-sql-in-clause Not totally sure but this might help: PreparedStatement pstmt = Connection.prepareStatement(""DELETE FROM MyTable WHERE myPrimaryKey IN (?)""); pstmt.setArray(1 idArray);  I've written a class to dynamically generate such a multi-parameter query. It currently has some limitations (for quickness of writing) and has not been thoroughly tested but may be a good way to get you started. Limitations: Only handles one multi-argument parameter (??) Falsely recognizes question marks in quotes as parameters API is not pretty but the alternative was writing a full-on PreparedStatement decorator with lots of state management and that was more work than I was willing to put into it. Source: /** * A PreparedStatement decorator that can bind a set of arguments * * A specialized ?? placeholder in a string can be bound to a set of * values instead of just single values. Currently only one such * specialized placeholder is supported and you must bind it before * obtaining the prepared statement. * * If you want to bind additional values to the PreparedStatement after * producing it you must run the parameter index through the param() * method. * * Example use: * * * MultiValueBinder binder = new MultiValueBinder( * ""UPDATE table SET value = ? WHERE id IN (??)"" conn); * binder.setInts(myIds); * * PreparedStatement stmt = binder.statement(); * stmt.setString(binder.param(1) ""myValue""); * * ResultSet rs = stmt.executeQuery(); * * Note: this class is not robust against using question marks in literal * strings. Don't use them :). */ public class MultiValueBinder { private Connection connection; private PreparedStatement statement; private String sql; private int argumentsBefore = 0; private int setSize = 0; public MultiValueBinder(String sql Connection connection) { this.sql = sql; this.connection = connection; } /** * Bind a collection of integers to the multi-valued argument */ public void setInts(Collection<Integer> ints) throws SQLException { explodeQuery(ints.size()); buildStatement(); try { int i = 0; for (Integer integer: ints) statement.setInt(1 + argumentsBefore + i++ integer); } catch (Exception ex) { cleanStatement(); throw (ex instanceof SQLException) ? (SQLException) ex : new SQLException(ex); } } /** * Bind a collection of strings to the multi-valued argument */ public void setStrings(Collection<String> strings) throws SQLException { explodeQuery(strings.size()); buildStatement(); try { int i = 0; for (String str: strings) statement.setString(1 + argumentsBefore + i++ str); } catch (Exception ex) { cleanStatement(); throw (ex instanceof SQLException) ? (SQLException) ex : new SQLException(ex); } } /** * Explode the multi-value parameter into a sequence of comma-separated * question marks. */ private void explodeQuery(int size) throws SQLException { int mix = sql.indexOf(""??""); if (mix == -1) throw new SQLException(""Query does not contain a multi-valued argument.""); if (size == 0) throw new SQLException(""Can't bind an empty collection; generated SQL won't parse.""); // Count the number of arguments before the multi-marker argumentsBefore = 0; for (int i = 0; i < mix; i++) { if (sql.charAt(i) == '?') argumentsBefore++; } setSize = size; // Generate the exploded SQL query StringBuilder sb = new StringBuilder(sql.substring(0 mix)); // Start for (int i = 0; i < setSize; i++) { // ? ? ... if (i > 0) sb.append("" ""); sb.append('?'); } sb.append(sql.substring(mix + 2)); // Remainder sql = sb.toString(); } /** * Create the statement if it hasn't been created yet */ private void buildStatement() throws SQLException { if (statement != null) return; if (sql.contains(""??"")) throw new SQLException(""Multi-valued argument not bound yet.""); statement = connection.prepareStatement(sql); } private void cleanStatement() { if (statement != null) { try { statement.close(); } catch (Exception ex) { /* Ignore */ } statement = null; } } public PreparedStatement statement() throws SQLException { buildStatement(); return statement; } /** * Transform the 1-based-index of the given argument before query expansion * into the index after expansion. * * The ?? placeholder takes up one index slot. */ public int param(int ix) { if (ix <= argumentsBefore) return ix; if (ix == argumentsBefore + 1) throw new RuntimeException(ix + "" is the index of the multi-valued parameter.""); return argumentsBefore + 1 + setSize; } }  Two steps: Build up the PreparedStatement SQL String with the appropriate # of parameters. Loop over the array of values and bind each one to its parameter. Unfortunately there's no good way to bind an array all at once."
217,A,"What characters will PreparedStatement escape? I noticed that when I use a PreparedStatement it doesn't seem to escape certain wild-card characters like '%' or '_'. I know these can be escaped in MySql using a backslash. This made me wonder what characters will a PreparedStatement escape? Naughty ones. :-p PreparedStatement doesn't escape anything - it relies on database support for precompiled statements. That is PreparedStatement never substitutes ?s for parameter values in order to form a literal query string. Instead it sends a query string with placeholders to the database and uses database support to bind query parameters (however it may depend on JDBC driver implementation). Interesting what does that support look like for MySql? MySql supports prepared statements in the same way on the server side. How it looks in your code depends on the driver you are using. I believe many drivers actually do insert escaped argument text into the SQL text. @stevebot: Quick googling showed this: http://dev.mysql.com/tech-resources/articles/4.1/prepared-statements.html @Tom: I don't think it's the case for major databases. @axtavt The link is broken now what _did_ it show?  In my test it escapes single quotation marks \r \t \n and so forth. It works pretty nice: String sql = ""INSERT INTO test(title) VALUES(?)""; PreparedStatement stmt = con.prepareStatement(sql); String title = ""I'm a \""student\"" in a \t (university) \r\n""; stmt.setString(1 title); stmt.executeUpdate(); That may be specific to your driver/db. As axtavt mentioned most do not automatically escape input."
218,A,"Failing to connect to oracle database I'm trying to write a jruby script that connects to an oracle database using jdbc. Thusfar I've got: require 'rubygems' require 'jdbc_adapter' require 'active_record' require 'active_record/version' ActiveRecord::Base.establish_connection( :adapter => 'jdbc' :driver => 'oracle.jdbc.driver.OracleDriver' :url => 'jdbc:oracle:thin:@mydatabase:1521:mydb' :user => ""user"" :password => ""password"" ) ActiveRecord::Base.connection.execute(""SELECT * FROM MYTABLE"") The error I'm getting: C:/Program Files/jruby-1.4.0/lib/ruby/gems/1.8/gems/activerecord-jdbc-adapter-0.9.2/lib/active_record/connection_adapters/jdbc_adapter.rb:326:in `initialize': The driver encountered an error: java.sql.SQLException: invalid arguments in call (RuntimeError) Suggestions? I think Dougman is correct. My JRuby code is Rails-based so I can't verify your 'requires' but my database.yml uses ""username"": test: adapter: jdbc driver: oracle.jdbc.driver.OracleDriver url: jdbc:oracle:thin:@mydatabase:1521:mydb username: login_name password: password  The post below implies that you should use :username instead of :user in your connection call: http://www.ruby-forum.com/topic/143105 as well as the thread of this posting: http://osdir.com/ml/lang.jruby.user/2007-05/msg00182.html"
219,A,"Writing desktop app that uses database. Suggestions for how to manage user access to tables? I'm writing a depsktop application (in Java) that interacts with a database which stores mostly requirements documentsbut I have a bit of a dilemma. Specifically a problem with managing user access. To illustrate I store all details on the folder structures in a single table. However I would like to institute a user-group mechanism similar to Linux/Unix systems where you can only add/mod/del the folders that you have permissions for. Of course I can only assign database permissions to a table or columns not individual rows which represent the folders they have access to. One solution to this is to give each folder its own table and then only give update/insert/delete access to certain users but that would be nothing short of a nightmare as the # of tables would explode to an unmanageable level. The second option is to create a server side process that sits between the database and clients which would return the list of folders that the user is stated to have (removing the whole issue of table privileges buy requiring now that I write a network protocol to talk with this process instead of just using the jdbc driver directly) Final option is triggers though the database I have to support (mysql) doesn't make it easy for me to reject. I was also hoping given the frequency of access to avoid triggers due to the added computation and slower performance. None are ideal but I'm running out of ideas. Recommendations? In PostgreSQL this is a fairly common approach to your dilemma. While I've not tried it in MySQL sepecifically it may be worth considering. That being said it may well be preferable to manage this in your application rather than MySQL. Read on. You can use a mixture of permission tables views and the user() function. For example say you had a table called Document: Document_ID | Name | Content ------------+------+-------- 1234 | Doc1 | Bla bla 2345 | Doc2 | Bla bla 3456 | Doc3 | Bla bla ------------+------+-------- And you had a permission table called Document_User. Document_ID | User ------------+------+-------- 1234 | smith@'%' 2345 | smith@'%' 3456 | smith@'%' 1234 | jones@'%' 2345 | jones@'%' 1234 | white@'%' ------------+------+-------- From the above structure it is obvious that User Smith has access to all three documents User Jones has access to the first two and User White only has access to the first one. Finally create a view like this: CREATE VIEW SQL SECURITY DEFINER `User_Document` AS SELECT * FROM `Document` WHERE Document_ID IN (SELECT Document_ID FROM Document_User WHERE User = USER()) The currently logged in user will see a set of records in the User_Document table that are only the records that they have permission to see.  You should not conflate DB rights and permissions with user rights and permissions. User code should go through a DAL or service layer which implements the access restriction functionality. Where you store information about rights depends largely on your authentication mechanism. If you have an existing user authentication system like active directory or LDAP you can integrate either authentication & authorization into that or integrate only aUthentication and push authorization into the DB. Basically for your model it sounds like you should have a table for authenticated entities tables for users and groups which both have a FK into it and then a permissions table that has a FK relationships into the auth entities table.  Why don't you manage access within the app itself instaed of relying on the rdbms to do it? You could just have a table of users versus tables and access levels and consult it before access.  How secure does this app need to be? If you are just trying to protect naive users from accidentally screwing each other's folders up and you really want your client program to have direct database access it sounds like you need to handle the folder permissions in the desktop client itself. Yes this means that a clever ""hacker"" could connect to the DB directly after decompiling your java code and discovering the connection info for the database but for many small intranet apps that is ok. For any app that you expect to grow or that needs real fine grained security it's probably worth the effort to implement a server of some sort between the DB and your desktop client."
220,A,"How do I connect to an Access database over a LAN using Java? Do you know of any good guides on how to access an Access database using Java? I know the basics and basic SQL but I'm thinking more about access control. If you mean using relational databases in Java you'll need to know JDBC. You won't be able to do much with security using JDBC. You'll have to build it into the application using something like JAAS or Spring Security.  JDBC is the way to go. Google for ""JDBC tutorial"" + mysql you will get all you need. You clearly didn't read the question. I know how to use google. Thanks. On the contrary I did read the question. I was just giving you the right terms to search for. It is infinitely better to know what you want but not have it (for now) that to not know at all. @jharshath: I don't see any version in the edit history of this question that mentioned MySQL.  You can share a database over a shared drive on LAN n then add it to System DSN of other PCs and you can share access database over LAN .. Worked for me like that I know string is old but maybe useful for someone like me i was frustrated finding a proper and easy way for sharing  private static final String accessDBURLPrefix = ""jdbc:odbc:Driver={Microsoft Access Driver (*.mdb)};DBQ=""; private static final String accessDBURLSuffix = "";DriverID=22;READONLY=false}""; // Initialize the JdbcOdbc Bridge Driver static { try { Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver""); } catch(ClassNotFoundException e) { System.err.println(""JdbcOdbc Bridge Driver not found!""); } } /** Creates a Connection to a Access Database */ public static Connection getAccessDBConnection(String filename) throws SQLException { filename = filename.replace('' '/').trim(); String databaseURL = accessDBURLPrefix + filename + accessDBURLSuffix; return DriverManager.getConnection(databaseURL """" """"); } Some useful links: http://blog.taragana.com/index.php/archive/how-to-access-ms-access-database-from-jdbc/ http://www.planet-source-code.com/vb/scripts/ShowCode.asp?txtCodeId=2691&lngWId=2 Brilliant exactly what I was looking for! Few links and some code. Cheers. I'm getting an error java.sql.SQLException: [Microsoft][Drivrutin f?r ODBC Microsoft Access] bad filename. I'm guessing it has to do something with this part of the code: ""jdbc:odbc:Driver={Microsoft Access Driver (*.mdb)};DBQ="". I don't get how that part is formatted is it supposed to automatically locate the driver? Can I just download the driver as a file and point to it?"
221,A,"Java MySQL Update Query I am getting the error ""cannot issue data"". Here is the SSCCE //package mysqltest; import java.awt.*; import java.awt.event.*; import javax.swing.*; import java.applet.Applet; import java.awt.TextArea.*; import java.sql.*; import java.util.*; import javax.swing.plaf.*; import javax.swing.plaf.basic.*; import java.net.*; import java.applet.*; public class test extends JApplet { public JTextArea c; public void init() { c = new JTextArea(); add(c); c.append(""Looking for database...""); Connection conn = null; Properties props = new Properties(); String url = ""jdbc:mysql://localhost:3306/""; String dbName = ""mystik""; String driver = ""com.mysql.jdbc.Driver""; String userName = ""root""; String password = """"; String loggedusername = getParameter(""name""); try { Class.forName(driver).newInstance(); props.put(""user"" ""root""); conn = DriverManager.getConnection(""jdbc:mysql://localhost:3306/mystik"" props); c.append(""\nConnected to the database""); c.append(""\nGetting stats for: "" + loggedusername); PreparedStatement statement = conn.prepareStatement( ""select * from `user` where `username` = '""+loggedusername+""'""); ResultSet result = statement.executeQuery(); // just a dumb mysql statement! while(result.next()) { c.append(""\nUsername: ""+result.getString(2)+ ""\nLevel: ""+result.getString(6)+""\nEXP: ""+result.getString(8)+""\n""); } PreparedStatement updateEXP = conn.prepareStatement( ""update`user` set `exp` = '666' where `username` = '""+loggedusername+""'""); ResultSet updateEXP_done = updateEXP.executeQuery(); while(result.next()) { c.append(""\nUsername: ""+result.getString(2)+ ""\nLevel: ""+result.getString(6)+""\nEXP: ""+result.getString(8)+""\n""); } conn.close(); c.append(""\nDisconnected from database""); } catch (Exception e) { e.printStackTrace(); } } } and it works... and it's just that update java query doesn't. Here is what the JTextArea sees: Looking for database... Connected to the database Getting stats for: weka Username: weka Level: 1 EXP: 1 and here is my error: added manifest adding: test.class(in = 2440) (out= 1308)(deflated 46%) adding: mysql-connector-java-5.1.13-bin.jar(in = 767492) (out= 735869)(deflated 4%) Warning: The signer certificate will expire within six months. java.sql.SQLException: Can not issue data manipulation statements with executeQu ery(). at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1075) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:989) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:984) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:929) at com.mysql.jdbc.StatementImpl.checkForDml(StatementImpl.java:436) at com.mysql.jdbc.PreparedStatement.executeQuery(PreparedStatement.java: 2176) at test.init(test.java:53) at sun.applet.AppletPanel.run(AppletPanel.java:424) at java.lang.Thread.run(Thread.java:619) Lastly here is how i compile using a .bat file. @ECHO OFF C: CD \wamp\www\mystikrpg\mysqltest javac -cp mysql-connector-java-5.1.13-bin test.java jar cvf mysqlTry.jar test.class mysql-connector-java-5.1.13-bin.jar jarsigner -keystore dankey -storepass soccer -keypass soccer mysqlTry.jar gamerpg appletviewer -J-Djava.security.policy=game.policy mysqltry.html How do I fix this error? Thanks. executeUpdate(query) instead of executeQuery()  As per the Javadoc DML queries (INSERT UPDATE DELETE) needs to be executed using executeUpdate() not executeQuery(). It returns an int with amount of affected rows. PreparedStatement updateEXP = conn.prepareStatement( ""update`user` set `exp` = '666' where `username` = '""+loggedusername+""'""); int affectedRows = updateEXP.executeUpdate(); That said closing the conn (and Statement and ResultSet!) should be done in the finally block else it will still be open when an exception is been thrown before close() is called. Also your use of PreparedStatement is wrong. You're still inlining the column values by simple string concatenation instead of setting them as parameterized values. You're not taking benefit of its SQL injection prevention capabilities. See also: Basic JDBC tutorial Using PreparedStatement  AS PreparedStatement documentation: Executes the SQL statement in this PreparedStatement object which must be an SQL INSERT UPDATE or DELETE statement; or an SQL statement that returns nothing such as a DDL statement. To execute querys that update delete or insert any data in your DB you can't use executeQuery... You must use: .executeUpdate(query) So this code (WRONG):  PreparedStatement updateEXP = conn.prepareStatement(""update`user` set `exp` = '666' where `username` = '""+loggedusername+""'""); ResultSet updateEXP_done = updateEXP.executeQuery(); Must look like (GOOD): Correct usage  PreparedStatement updateEXP = conn.prepareStatement(""update`user` set `exp` = '666' where `username` = '""+loggedusername+""'""); ResultSet updateEXP_done = updateEXP.executeUpdate(); Ok thanks! I got it. Now my when I call the second result whiel loop... it will be invisible and go directly to ""Disconnected from database."" Can you only use Prepared statements once? The `next()` method of `ResultSet` moves forward to the next row after the first `while` is end the `ResultSet` is at the end. If you want to go around (again) in the `ResultSet` call `result.first()`  Also consider using a parameter for the username: PreparedStatement updateEXP = conn.prepareStatement(""updateusersetexp= '666' whereusername= ? ""); updateEXP.setString(1 loggedusername); ResultSet updateEXP_done = updateEXP.executeUpdate();"
222,A,"Java skips else condition I'm not sure why but for some reason the following code skips the else condition. I've tried just about everything I can think of including switching the code blocks but it still skips the else part. Basically I want this method to return String temp = ""no"" if String docID that is passed to the method is not found in the FILESTATUS database and String temp = ""yes"" if it is found. static String checkDocID(String docID) { String temp = null; System.out.println(""Checking if data already exists in database...""); try { Main.stmt = Main.con.createStatement(); String command = ""SELECT * FROM FILESTATUS WHERE ID='"" + docID + ""'""; ResultSet queryResult = Main.stmt.executeQuery(command); if (!queryResult.next()) { temp = ""no""; } else { while (queryResult.next()) { String result = queryResult.getString(""ID""); if (result.equals(docID)) { temp = ""yes""; break; } } } Main.stmt.close(); } catch (Exception ex) {ex.printStackTrace();} return temp; } Thanks! Usually resource that require an explicit call to a close() method are closed inside a finally block. Just a little friendly advice. You are calling queryResult.next twice before you are trying to read it. To prove this put a println or something right after the else (before the while). Since you are selecting by a particular ID moving to next() twice will in fact fail the second time (presumably) and never execute the while block.  Might be better to restructure this loop as: static String checkDocId(String docId) { String temp = ""no""; while (queryResult.next()) { String result = queryResult.getString(""ID""); if (result.equals(docID)) { temp = ""yes""; break; } } return temp; } Some people don't like using break (I usually don't) so you can use a boolean in your while (I find that it reads more like english and you can tell the terminating condition right from the while instead of looking for an if inside): static String checkDocId(String docId) { boolean found = false; while (queryResult.next() && !found) { String result = queryResult.getString(""ID""); found = result.equals(docID); } return found ? ""yes"" : ""no""; } You're performing a needless comparison otherwise. Remember a while is just an if with a goto at the end ;) As far as your problem is concerned what Paul said is correct. Eitherway I would still restructure the loop so that it's more elegant. why not just `return ""yes""` as soon as result is found. That would mean you need another `return` outside the loop. I'm not a fan of multiple `return`s unless absolutely necessary. 9 times out of 10 you can rewrite your algorithm to be more elegant and remove the use of multiple `return`s.  After a bit astonishment about the code (leaking DB resources not trusting the DB that it returns the right docID doing a SELECT * while you don't need all of the columns at all not taking benefit of SQL-injection-sanitization powers of PreparedStatement using String instead of boolean to denote a true/false value a messy code flow) here's how it should really be done instead: private static final String SQL_EXIST_DOCID = ""SELECT id FROM filestatus WHERE id = ?""; public boolean exist(String docID) throws SQLException { Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; boolean exist = false; try { connection = database.getConnection(); statement = connection.prepareStatement(SQL_EXIST_DOCID); statement.setString(1 docID); // Shouldn't it be a Long instead? Characterbased PK's are *far* from efficient. resultSet = statement.executeQuery(); exist = resultSet.next(); } finally { if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } return exist; } Clear concise and simple as that. For more insights about using basic JDBC the right way you may find this article useful. I hope that you take it serious to learn from it. Really. I personally like your answer the best but to be pedantic there is no good reason to put the connection creation inside the try/catch and at least two reasons not to. 1) it makes the finally block needless complicated for connection 2) if the try {} block gets large and some joker manages to set connection = null then you'll never close it... versus getting an NPE. 1) can be refactored away 2) is a programmer error. Certainly the connection should be closed in the finally else you're leaking resources. @BalusC yes the connection should be closed in the finally but it should not be created in the try... if you get an exception from create there will _never_ be a connection to close. Why create extra complexity/problems? @PSpeed: the connection still needs to be closed if its creation succeeds but the creation of statement or resultSet not. Although I cannot use your code exactly (as the connection is already established at this point and needs to remain open past this point) you did open my eyes to several problems with my code... A software engineer I am not! Thanks! You're welcome. You can in theory also replace `getConnection()` by `getTransaction()`. @BalusC move connection = database.getConnection() above the try {... then don't bother checking for connection != null in the finally... just close it. @PSpeed: that's true when you leave out the `catch` on `SQLException` from the `try` block. But sometimes you'd like to add the `catch` so that you can do some logging and/or wrap it more abstractly in a custom `DAOException` or something like that. Yeah I can only comment on the methods that exist... not the hypothetical ones that architected differently. :) Given the code if I wanted to catch and wrap the exception I'd probably still push this code into a method that throws SQLException and just wrap the method. It tends to be cleaner and since we're talking about hypothetical future changes you never know what other exceptions you might want to catch and log and keeping the SQL code together is a good thing.  Because you end up calling queryResult.next() in the ""if"" and again in the while you're skipping the first result. If there is only one result the while loop will never execute. If I can make a couple of suggestions: Use bound variables in a PreparedStatement rather than putting ""docID"" in the query string Don't test result.equals(docID) since the query already assured that. prefer boolean to String ""yes"" or ""no"" set the result to ""no"" or false then set it to ""yes"" or true in the loop. The extra assignment is probably faster than the extra test plus you can skip the do{}while which most people find harder to read. concise and correct it's probably worth pointing out that `ResultSet.next` is not like `Iterator.hasNext` Wow - I figured it was just a case of my logical brain taking a vacation. Solved it using a `do{}-while{}` as opposed to just a `while{}` as suggested by splix. Thank you! I am surprised that this isn't accepted. It covers all of the unnecessary clutter in the code logic (expect of closing in finally). Maybe because you omitted the code sample?  rs.next() rolling current cursor after each call try with static String checkDocID(String docID) { String temp = null; System.out.println(""Checking if data already exists in database...""); try { Main.stmt = Main.con.createStatement(); String command = ""SELECT * FROM FILESTATUS WHERE ID='"" + docID + ""'""; ResultSet queryResult = Main.stmt.executeQuery(command); boolean found = queryResult.next(); if (!found) { temp = ""no""; } else { do { String result = queryResult.getString(""ID""); if (result.equals(docID)) { temp = ""yes""; break; } } while (queryResult.next()) } Main.stmt.close(); } catch (Exception ex) {ex.printStackTrace();} return temp; } This works perfectly - just changing it to do {} while {} was all it needed. Thanks! It may work but this code would be what others might call a minor WTF. Paul gave the real answer to the problem and vivin has a much better code implementation. Agree with Tim regarding the WTF'ness of the accepted solution. Although vivin's would work too I only had to change two lines to get this (and I'm lazy!). Are there any major problems with this code? (If it makes any difference stability is more important than speed/efficiency with this code.) Thanks! If you want your code to be stable and maintainable then I would not go with the current solution. Using the current structure is what led you to this problem in the first place. Using the `while` without the `if` is far more maintainable. Laziness is not an excuse. You cannot be lazy and write stable/maintainable code!"
223,A,MySQL and SQLite differences in SQL I'm writing java application that is using both SQLite and MySQL using JDBC. Are there any differences in SQL for those databases? Can I use same queries for both SQLite and MySQL or is there any db specific stuff that doesn't work on the other one? As far I've worked only with MySQL so I don't really know much about SQLite. A big difference is the type system. SQLite lets you put any type of data in any column. It does however cast data to the declared type of the column if possible.  I'm doing something similar. There are a few differences in addition to the ones mentioned that I ran into: in the newer versions of SQLite3 with the Xerial JDBC driver foreign keys are indeed supported. SQLite supports inline foreign key constraint definition: CREATE TABLE Blah (foreignId Integer REFERENCES OtherTable (id)); MySQL (with InnoDB) will accept the same syntax but won't actually enforce the constraint unless you use a separate FOREIGN KEY clause which explicitly names the foreign table and key column(s): CREATE TABLE Blah (foreignId INTEGER FOREIGN KEY foreignId REFERENCES OtherTable (id)); old versions of the SQLite JDBC driver don't support Statement.RETURN_GENERATED_KEYS; fixed in newer Xerial drivers. the syntax for auto-incrementing keys differs; SQLite: (id INTEGER PRIMARY KEY ASC ...); MySQL: (id INTEGER PRIMARY KEY AUTO_INCREMENT ...) SQLite accepts n-way comma-delimited joins: SELECT * FROM A B C ON (A.x = B.y AND B.y = C.z); MySQL does not; the following works in both: SELECT * FROM A INNER JOIN B ON A.x = B.y INNER JOIN C ON B.y = C.z; With respect to the type differences a related annoyance with SQLite's JDBC drivers is that the same column can produce different types via ResultSet.getObject(.); for example an Integer or a Long depending on the magnitude of the number contained. auto-incrementing keys in SQLite MUST be declared type INTEGER; in MySQL any numeric integer type works. can you verify which version of sqlite jdbc driver you are using which seems to support RETURN_GENERATED_KEYS ? I have tried many different versions with no luck http://www.xerial.org/trac/Xerial/wiki/SQLiteJDBC working at least as of 3.6.20.1  If you stick to ANSI SQL92 you'll should be fine. There are some SQL92 features missing from both MySQL and SQLite (e.g. FULL OUTER JOIN). MySQL has both RIGHT JOIN and LEFT JOIN SQLite only the LEFT JOIN. SQLite doesn't support FOREIGN KEY constraints neither does MySQL with MyISAM tables. SQLite of course doesn't have GRANT/REVOKE as permission system is based on underlying OS's file permissions. SQLite supports FOREIGN KEY constraints since version 3.6.19 see http://www.sqlite.org/foreignkeys.html.
224,A,"Does a ResultSet load all data into memory or only when requested? I have a .jsp page where I have a GUI table that displays records from an Oracle database. This table allows typical pagination behaviour such as ""FIRST"" ""NEXT"" ""PREVIOUS"" and ""LAST"". The records are obtained from a Java ResultSet object that is returned from executing a SQL statement. This ResultSet might be very big so my question is: If I have a ResultSet containing one million records but my table only displays the data from the first ten records in the ResultSet is the data only fetched when I start requesting record data or does all of the data get loaded into memory entirely once the ResultSet is returned from executing a SQL statement? While the JDBC spec does not specify whether or not the all data in the result set would get fetched any well-written driver won't do that. That said a scrollable result set might be more what you have in mind: http://www.exampledepot.com/egs/java.sql/CreateScrollableResultSet.html You may also consider a disconnected row set that's stored in the session (depending on how scalable your site needs to be): http://java.sun.com/j2se/1.4.2/docs/api/javax/sql/RowSet.html  The JDBC spec does not specify whether the data is streamed or if it is loaded into memory. Oracle streams by default. MySQL does not. To get MySQL to stream the resultset you need to set the following on the Statement:  pstmt = conn.prepareStatement( sql ResultSet.TYPE_FORWARD_ONLY ResultSet.CONCUR_READ_ONLY); pstmt.setFetchSize(Integer.MIN_VALUE);  The Java ResultSet is a pointer (or cursor) to the results in the database. The ResultSet loads records in blocks from the database. So to answer your question the data is only fetched when you request it but in blocks. If you need to control how many rows are fetched at once by the driver you can use the setFetchSize() method on the ResultSet. This will allow you to control how big the blocks it retrieves at once. Thanks now it's almost clear for me Does MySql driver (mysql-connector-j) support such ""intelligent"" behavior? @Roman The JDBC API does not indicate that it is an optional method. I would assume all implementations including mysql would support this. If ""all implementation supports"" then how JDBC-ODBC bridge can do this for MS Access? Access doesn't support ""limits"" or something similar does it? The fetch size is basically a ""suggestion"" to the driver how many records to fetch at a given time and it is up to the driver whether to use the suggested size or to ignore it. I imagine most well designed drivers use it. jTDS (for SQL Server) uses it.  The best idea is make a sub query and display 100 or 1000 rows at a time/in single page. And managing the connection by connection pooling. To make a sub query you can use Row count in oracle and Limit in MY SQL."
225,A,"mysql query which selects from another mysql query i am migrating from ms access database to mysql database with java frontend so that my application can be used in linux as well . in ms access here's what i would do go to create query . write a select statement . call give the name of the query as query1. when double clicking on query1 you would get the result of select statement in a tabular form. next i would write a query2 which is also a select query. this query would be fetching data not from a table but query1 e.g select ab from query1; now i am on a mysql database using java what would be the java statement for select ab from query1 ? what i mean to say is that i would connect to mysql using jdbc. have query1 like this string query1 = "" select * from users "" ; then execute query using executeQuery(query1) but i dont think i can do something like this. string query2 = "" select ab from query1 "" ; and then executeQuery(query2) so what is the way out ? You can either do nested queries (subqueries) like @muffinista suggested. But i think you are looking for Views: http://dev.mysql.com/doc/refman/5.0/en/create-view.html. In short a view is a ""pseudo table"" that is a result of a query. you can create view q1 as select * from table1 where f1>1 select * from q1 where f2<100  You can do this all in MySQL. The query would look like SELECT * FROM ( SELECT * FROM users ) query1;  select * from table2 where user_id in (select user_id from users)  I ran into the exact same problems when I went from using MS Access to using a lot of SQL queries against a MySQL DB. There are two ways I would approach this: VIEWS: Views are a great way to emulate a lot of the functionality you found in Access. One of the things I really liked about Access was the ability to separate my SQL into smaller queries and then re-use those queries in other queries. Views allow you to do essentially the same thing in that you define a query in a View and then you can write another query or View against that original View. In my experience however Views tend to be really slow especially when referencing calculated columns. With MySQL I very rarely use Views (though perhaps others have found for efficient ways of implementing them). SUBQUERIES (NESTED QUERIES) As others have mentioned subqueries are a great way to write multiple queries within one query. With a subquery instead of putting the query name (as in Access) or View name (as explained above) within the SELECT portion of your code you simply paste the entire SQL statement of the subquery. You might write code like this to find only the 2009 sales and salesperson name for customers in a database: SELECT customer.Name customer.AccountNumber customer.SalespersonName ch.`2009 Sales` FROM customer Left Join ( SELECT customerhistory.AccountNumber SUM ( CASE WHEN customerhistory.`Year` = 2009 THEN customerhistory.`Sales` ELSE 0 END ) AS `2009 Sales` FROM customerhistory GROUP BY customerhistory.AccountNumber ) ch ON customer.AccountNumber = ch.AccountNumber In my work I tend to use mostly subqueries since I find they run a lot faster than views but your experience may vary."
226,A,"jdbc datatype API/Reference I am getting an exception: org.hibernate.MappingException: No Dialect mapping for JDBC type: -9 I found a list of JDBC Data type here Apache DB Project . How do I find out ""-9"" maps to one of the data types listed? From googling people seem to say -9 represents nvarchar but is there an authoritative source? http://download.oracle.com/javase/6/docs/api/constant-values.html#java.sql.Types.REAL from the javadocs themselves"
227,A,Oracle connection compression? I have an application that uses JDBC to connect to Oracle 11g. Unfortunately the machine my app is running on and the Oracle machine are connected via a somewhat low bandwidth connection. I haven't sniffed the connection but I am pretty sure the data streaming across the connection is not compressed. For my application I'm more concerned about bandwidth than latency. Is there any way to tell the JDBC driver and Oracle to compress the data going through the connection? Google comes up with a lot of answers for data file compression but I couldn't find anything about network protocol compression. I'm using Oracle's thin driver but if this is only supported by the OCI driver I could switch to that. Thanks for any suggestions! To directly answer the question the drivers (thin or OCI) have no such mechanism for compression. And since the data sent is likely in some funky binary format I'm not sure that it will compress well over SSL. Some other mechanism for improving network performance will need to be employed.  In my experience high latency harms performance using the Oracle JDBC drivers far more than low bandwidth. (at least in the application I work on). You say you aren't worried about latency but could you give an estimate on the latency of your low-bandwidth environment? How big is the data you're sending? Are there BLOB columns? Are there other technologies involved like a connection pool or Hibernate? There are a lot of potential factors not just if your data is being compressed. Have you done any WAN emulation to try to isolate what is degrading your performance most? WANem is pretty easy to setup. I've spent weeks on this problem and 100-200ms latency hurt us much more than a 1Mbit bandwidth limitation. Hopefully you are in a different boat - compression an easier problem to solve. 64 bytes pings are only taking 4ms to be ack-ed so that's not so bad. No BLOBs but a lot of INSERT activity. No connection pooling it's a single connection. Staffing is a little light for the holidays so I can't get into deep WAN diagnostics for the moment. That seemed like the next obvious thing to look at. But thanks for the pointer to WANem I'll look into that! If it's only 4ms I'm going to say you're right in that latency should play a very minimal role.  I don't know specifics about Oracle's thin and OCI drivers. But you could use SSH tunnels to achieve compression. So in your Oracle machine you setup a SSH daemon. If your Oracle server is running under RedHat Linux you're done On your client machine (the one that hosts your application that connects through JDBC) setup a SSH connection enabling a compressed tunnel. You can use command line SSH or Putty (if you are under windows) to do that. Setup the connection to something like this: $ ssh -L1521:localhost:1521 username@oracleserver_ip Then in your application use localhost:1521 as Oracle's address. No a VPN connection will certainly **not** work. There's a limited amount of bandwidth - adding VPN overhead is going to ensure that *less* actual data is stored per packet. While that is a possibility I'm hoping to see if the Oracle driver has this built-in to keep it simple. This is not a VPN. It's just a tunnel. And it **will** work. If you use a compressed tunnel and what you are trying to transmit can be compressed (like huge amounts of text or XML) it will be compressed. @joev I know that it will be easier to just have a flag in the driver or a parameter in the URL but this is all I know. :-) Maybe there's something on URL connection parameters documentation... SSH is an encrypted tunnel (http://en.wikipedia.org/wiki/Tunneling_protocol) making it a defacto VPN. That said it could well work if the compression ratio is good enough to overcome the VPN/tunnel overhead.
228,A,"Derby INSERT SELECT null pointer exception I'm writing a Java application that's working with Apache Derby via JDBC. I'm having problems with the code in the following snippet: byte md5[] = md5sum(file); PreparedStatement s = con.prepareStatement(""INSERT INTO input_files (job_ID hash) SELECT job_id ? FROM job WHERE job_name = ?""); s.setBytes(1 md5); s.setString(2 jobName); s.executeUpdate(); s.close(); This inserts into the following tables: CREATE TABLE input_files ( hash char(16) for bit data job_id integer REFERENCES job PRIMARY KEY(job_id hash) ); CREATE TABLE job ( job_id integer PRIMARY KEY GENERATED ALWAYS as IDENTITY job_name character varying(50) UNIQUE NOT NULL #other fields ); The idea is that there is an internal integer job_id which is used internally by the database but we want to reference it as much as possible with the human-readable String job_name This consistently throws the following exception. java.sql.SQLException: Java exception: ': java.lang.NullPointerException'. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.javaException(Unknown Source) at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(UnknownSource) at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source) at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement20.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement30.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement40.<init>(Unknown Source) at org.apache.derby.jdbc.Driver40.newEmbedPreparedStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) at [line 3 of snippet above] As you can see this is thrown from the line where the prepared statement is created - it doesn't get as far as executing it. What am I doing wrong? The exact same prepared statement works fine with PostgreSQL. [edit] Derby.log: ---------------------------------------------------------------- 2010-08-18 08:47:08.779 GMT: Booting Derby version The Apache Software Foundation - Apache Derby - 10.6.1.0 - (938214): instance a816c00e-012a-8461-611c-0000046700d0 on database directory /path/to/myDatabase with class loader sun.misc.Launcher$AppClassLoader@6d6f0472 Database Class Loader started - derby.database.classpath='' 2010-08-18 08:47:12.067 GMT Thread[SwingWorker-pool-1-thread-15main] (XID = 316) (SESSIONID = 1) (DATABASE = myDatabase) (DRDAID = null) Cleanup action starting 2010-08-18 08:47:12.067 GMT Thread[SwingWorker-pool-1-thread-15main] (XID = 316) (SESSIONID = 1) (DATABASE = myDatabase) (DRDAID = null) Failed Statement is: INSERT INTO input_files (job_id hash) SELECT job_id ? FROM job WHERE job_name = ? java.lang.NullPointerException at org.apache.derby.impl.sql.compile.BitTypeCompiler.storable(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumn.checkStorableExpression(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumn.checkStorableExpression(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumnList.checkStorableExpressions(Unknown Source) at org.apache.derby.impl.sql.compile.InsertNode.bindStatement(Unknown Source) at org.apache.derby.impl.sql.GenericStatement.prepMinion(Unknown Source) at org.apache.derby.impl.sql.GenericStatement.prepare(Unknown Source) at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.prepareInternalStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement20.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement30.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement40.<init>(Unknown Source) at org.apache.derby.jdbc.Driver40.newEmbedPreparedStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) at [line 3 of snippet] Cleanup action completed 2010-08-18 08:47:12.084 GMT: Shutting down instance a816c00e-012a-8461-611c-0000046700d0 with class loader sun.misc.Launcher$AppClassLoader@6d6f0472 ---------------------------------------------------------------- and unrolled exception: java.sql.SQLException: Java exception: ': java.lang.NullPointerException'. at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.javaException(Unknown Source) at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source) at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source) at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement20.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement30.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement40.<init>(Unknown Source) at org.apache.derby.jdbc.Driver40.newEmbedPreparedStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) at [line 3 of snippet above] Caused by: java.sql.SQLException: Java exception: ': java.lang.NullPointerException'. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) ... 26 more Caused by: java.lang.NullPointerException at org.apache.derby.impl.sql.compile.BitTypeCompiler.storable(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumn.checkStorableExpression(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumn.checkStorableExpression(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumnList.checkStorableExpressions(Unknown Source) at org.apache.derby.impl.sql.compile.InsertNode.bindStatement(Unknown Source) at org.apache.derby.impl.sql.GenericStatement.prepMinion(Unknown Source) at org.apache.derby.impl.sql.GenericStatement.prepare(Unknown Source) at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.prepareInternalStatement(Unknown Source) ... 19 more SQLState: XJ001 Error code: 0 Message: Java exception: ': java.lang.NullPointerException'. Cause: java.sql.SQLException: Java exception: ': java.lang.NullPointerException'. at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(Unknown Source) at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source) at org.apache.derby.impl.jdbc.Util.javaException(Unknown Source) at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source) at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source) at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement20.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement30.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement40.<init>(Unknown Source) at org.apache.derby.jdbc.Driver40.newEmbedPreparedStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) at [line 3 of snippet above] Caused by: java.lang.NullPointerException at org.apache.derby.impl.sql.compile.BitTypeCompiler.storable(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumn.checkStorableExpression(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumn.checkStorableExpression(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumnList.checkStorableExpressions(Unknown Source) at org.apache.derby.impl.sql.compile.InsertNode.bindStatement(Unknown Source) at org.apache.derby.impl.sql.GenericStatement.prepMinion(Unknown Source) at org.apache.derby.impl.sql.GenericStatement.prepare(Unknown Source) at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.prepareInternalStatement(Unknown Source) ... 19 more Cause: java.lang.NullPointerException at org.apache.derby.impl.sql.compile.BitTypeCompiler.storable(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumn.checkStorableExpression(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumn.checkStorableExpression(Unknown Source) at org.apache.derby.impl.sql.compile.ResultColumnList.checkStorableExpressions(Unknown Source) at org.apache.derby.impl.sql.compile.InsertNode.bindStatement(Unknown Source) at org.apache.derby.impl.sql.GenericStatement.prepMinion(Unknown Source) at org.apache.derby.impl.sql.GenericStatement.prepare(Unknown Source) at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.prepareInternalStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement20.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement30.<init>(Unknown Source) at org.apache.derby.impl.jdbc.EmbedPreparedStatement40.<init>(Unknown Source) at org.apache.derby.jdbc.Driver40.newEmbedPreparedStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source) at [line 3 of snippet above]  PreparedStatement s = con.prepareStatement(""INSERT INTO input_files (job_ID hash) SELECT job_id ? FROM job WHERE job_name = ?""); ""job_ID"" vs ""job_id"" match the case and see if that corrects the problem. @Scott: SQL is case-insensitive unless you are using delimited identifiers (double quotes in the standard square brackets in MS SQL Server back ticks in MySQL etc). No joy. I thought SQL was case-insensitive anyway.  I suspect you won't be able to jam the literal hash code directly into the select column list because Derby doesn't understand that you want to put a literal value there rather than a column name. A reasonable workaround might be to re-code your application to perform the INSERT statement from inside a loop which is reading the values from the SELECT. Something along the lines of: updateStatement = prepareStatement(""insert into input_files (job_id hash) values (??)"") ResultSet rs = executeQuery(""select job_id from job where job_name = ?"") while (rs.next()) updateStatement.setString(1 rs.getString(1)) updateStatement.setBytes(2 md5sum) updateStatement.executeUpdate() As a workaround I think this is what we'll end up doing. We actually do similar queries in a few places so if we cache the value of job_id we may actually end up improving our database performance.  A null pointer exception in this context - especially if the same JDBC code works with another DBMS - looks like you've hit a bug in the Derby JDBC driver. Even if you'd made a mistake and passed erroneous data or a null pointer the driver should be detecting that and reporting an error not crashing. I agree this looks like a bug in Derby. You can probably get more information (that is a more complete stack trace) by unwinding the exception chain: http://wiki.apache.org/db-derby/UnwindExceptionChain Also have a look in derby.log for more information. For the record apparently this was a known bug and has been fixed in the Derby source. The work around is to add a cast around the parameter - i.e. `INSERT INTO input_files (job_ID hash) SELECT job_id CAST(? as CHAR(16) FOR BIT DATA) FROM job WHERE job_name = ?` Bug filed: https://issues.apache.org/jira/browse/DERBY-4780"
229,A,"java.lang.UnsatisfiedLinkError while loading DB2 JDBC driver I try to use jboss-seam with a db2 database the following error occurs com.ibm.db2.jcc.a.SqlException: [jcc][10389][12245][3.52.95] while loading the native library db2jcct2 java.lang.UnsatisfiedLinkError: no db2jcct2 in java.library.path an error occurred ERRORCODE=-4472 SQLSTATE=null I tried setting -Djava.library.path=/opt/IBM/db2/V9.5/lib64 as well as -Djava.library.path=/opt/IBM/db2/V9.5/lib32 Both paths include libdb2jcct2.so I also tried to set LD_LIBRARY_PATH with no effect. OS is MacOs EDIT I also tried to use a JDBC4 driver  db2jcc4.jar since jdbc4 drivers shouldn't rely on native libs. Have you tried setting DYLD_LIBRARY_PATH too? Might be worth a shot. +1 DYLD_LIBRARY_PATH is used on MacOs instead of LD_LIBRARY_PATH thanks I checked this unfortunately without success.  The IBM Data Server Driver for JDBC and SQLJ includes both Type 2 and Type 4 JDBC drivers. Please check the following: 1) Make sure the driver is in your classpath: db2jcc.jar. Alternatively you can use the JDBC4 driver (db2jcc4.jar) but don't put both in the classpath. 2) Make sure that you're specifying the JCC driver (com.ibm.db2.jcc.DB2Driver) in your app configuration. 3) Use a Type-4 URL like jdbc:db2://server:port/database. If you specify a Type-2 URL like jdbc:db2:database then the driver will start looking for native libraries.  Append a ""driverType=4;"" to your URL.  If the java.library.path (assigned using LD_LIBRARY_PATH env. variable) is wrong you should actually get something like: ""failure in load of t2 native library"". You can check the java.library.path to se if the path is included like this. System.out.println(System.getProperty(""java.library.path"")); Could you be missing another jar like db2jcc_license_cu.jar Maybe post your classpath. You can get it by reading the property java.class.path from the coide (like above).  From the path this looks a linux /unix platform. Try running strace/truss to see which directories are getting opened for library. +1 good hint for the records the tool on a mac is called dtrace. dtrace -n 'syscall::open*:entry { printf(""%s %s""execnamecopyinstr(arg0)); }'"
230,A,JDBC profiling tools We need to profile the JDBC operations of several web applications number of queries time spent rows returned ... Have you used any free/commercial JDBC profiling tool? What are your experiences? Thank you. Check out JAMon (Java Application Monitor) too. Also older but works.  There is a JDBC profiler built in a JProfiler (go to Hotspots view -> JDBC) best thing I've seen so far...  The only JDBC profiling tool that I know is P6Spy. Ancient but still works.  I have never used it but have come across Elvyx. Again it has not been updated recently.
231,A,"Connection problem in Win2k3 server 64 bit with JDBC DriverManager#getConnection() returns null when I am deploying my JSP/Servlet package in a Windows 2003 Server environment (64 bit). The database is Microsoft SQL 2005 Enterprise Edition. The code is: Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver""); con = DriverManager.getConnection(""jdbc:odbc:calsoft2k""""xxx""""xxx""); The same code is working without any problems in Windows XP (32 bit) box. I am using Apache Tomcat 6.X server in both production and development environment. Any pointers? Use a real JDBC driver instead of the (pardon me) lousy ODBC bridge driver. Decent DB vendors supplies their own JDBC drivers. The one for SQL2005 can just be found at microsoft.com. This driver is however known not to be very optimal in both the performance and the level of JDBC API support. You could also consider the much faster and better jTDS driver instead. as always BalusC is great now i am fan of BalusC :-)"
232,A,"Is there how I could programmatically ask eclipselink to drop and create all tables? This helps in unit testing. The following should work for you: ServerSession session = entityManager.unwrap(ServerSession.class); SchemaManager schemaManager = new SchemaManager(session); schemaManager.replaceDefaultTables(true true); I've replaced your code with my database destroying code but then tests fail. Why could that be? Do I have to run this code inside a transaction? No this code should be run outside of a transaction. (haven't tried)  One way to do that is to execute the sql scripts eclipselink generates specifying:  <property name=""eclipselink.ddl-generation.output-mode"" value=""both""/> in persistence.xml"
233,A,IllegalArgumentException with Date value in jdbc; Openbase sql I have a WebObjects app Openbase db and I'm getting a never before seen exception when doing a raw rows (non ORM) query during a batch operation. It looks like the jdbc adaptor is throwing on a date value in the db and is unable to coerce the raw data into the proper type. It literally kills the app and ends the export process. Here's the top two relevant lines from the trace: java.lang.IllegalArgumentException at java.sql.Date.valueOf(Date.java:138) at com.openbase.jdbc.f.getDate(Unknown Source) I've tried changing the column type from date to datetime to timestamp and adjusting the eo model accordingly but the exception remains. I'm wondering what I can do to resolve this specifically if anybody knows a more sophisticated query mechanism I can employ to identify the possibly bad rows? Openbase's documentation is pretty sparse and I'm hoping maybe somebody knows how to use patterns to identify possible bad values using openbase sql. Or some other means of identifying the issue. Thanks. I just found by painful small set querying a load of rows that have a date format like '-001-12-31 12:00:00 -0500' I found this highly suspect so I did a simple test and there were no errors; openbase and jdbc adaptor didn't complain about these rows at all. Furthermore using like '-001%' per the docs doesn't work. Maybe like doesn't work with timestamps in openbase. Maddeningly stumped... Turns out the problem was due to a version mismatch between the Openbase version and the java version. Unfortunately I had no choice but to rewrite the dump routine to use the bulk save openbase function and then parse out the resulting csv. Interestingly the same dates that were causing problems printed just fine which enabled saving a lot more rows. Summary: stick with the open source db's; unless you're going high end there's no advantage to solutions like Openbase anymore.
234,A,Getting the last inserted record id of a database table in java? I have a database table A which stores records A has a primary key (recordid) with auto_increment each time i insert a record in to A i get the inserted recordid and store it in another masterTable. I am using a select statement as soon i do an insert into A to get the recordid like this: select recordid from A order by recordid DESC LIMIT 1; But i ran into a problem today where in two records were inserted(by different threads) at the same time and i ended up storing wrong recordid in the master id( the same recordid for both the txns) I heard about Statement.getGeneratedKeys() I would like to know if that really helps resolve the issue. Or what is the best way to handle this. You can use the getGeneratedKeys method. This forum post will help. May I also recommend that you use an ORM tool like Hibernate. In Hibernate you would do something like this: myTable = new myTable(); myTable.prop1 = prop1; myTable.prop2 = prop2; int id = session.save(myTable); Hibernate will issue the appropriate SQL commands (depending on the database selected) and return you the auto-generated id. If MySQL JDBC driver implements it. That's true. If the JDBC driver doesn't support it you need to rely on database specific methods to get the ID. Thanks for this! @kgiannakakis - `session.save(myTable)` doesn't return an `int`. It however returns `java.io.serializable` and the `getGeneratedKeys()` method is not supported by any implementation of the JDBC drivers until now. So neither of the two cases which you mentioned would be successful as obvious. Do they really work? @Lion - `Integer` does implement `Serializable`. So using boxing you can get an int out of `session.save(myTable)` provided of course that the mapping of your table is such as to return an int. This method works. I have successfully tested getGeneratedKeys method with MySQL JDBC driver.  The MySQL JDBC driver does support the getGeneratedKey() method. Have a look at the section 20.3.5.1.4. Retrieving AUTO_INCREMENT Column Values of the MySQL manual where: we demonstrates the use of the new JDBC-3.0 method getGeneratedKeys() which is now the preferred method to use if you need to retrieve AUTO_INCREMENT keys.  In databases that don't support generatedKeys you may be able to get the ID into a return parameter. Oracle for example provides the RETURNING xxx INTO ? syntax where xxx is your column name.
235,A,"CallableStatement vs Statement When calling a Stored Procedure with no arguments and no output is there any advantage to using a CallableStatement over a regular Statement or PreparedStatement? CallableStatement allows you to use a generic JDBC syntax for calling procedures rather than a Database specific one. Sadly we didn't do that for Oracle in one of the projects I've worked on so all our procedure calls look something like this: String query = ""begin package.sp_Procedure(? ?); end;"";"
236,A,"How do I set a full date & time sql using java and not just the date? I am trying to set a timestamp in my database using java however in my table all I get is the date and no time (i.e. looks like ""2010-09-09 00:00:00""). I am using a datetime field on my mysql database (because it appears that datetime is more common than timestamp). My code to set the date looks like this: PreparedStatement ps = conn.prepareStatement(""INSERT INTO mytable (datetime_field) VALUES (?)"") java.util.Date today = new java.util.Date(); java.sql.Date timestamp = new java.sql.Date(today.getTime()); ps.setDate(1 timestamp); ps.executeUpdate(); How do I set the date to include the time? Edit: I changed the code as per below and it sets both the date and the time. PreparedStatement ps = conn.prepareStatement(""INSERT INTO mytable (datetime_field) VALUES (?)"") java.util.Date today = new java.util.Date(); java.sql.Timestamp timestamp = new java.sql.Timestamp(today.getTime()); ps.setTimestamp(1 timestamp); ps.executeUpdate(); Use java.sql.Timestamp and setTimestamp(int Timestamp). java.sql.Date is date-only regardless of the type of the column it's being stored in. Thanks - that worked perfectly!  Not exactly sure what you need to use but ps.setDate(); expects a column type of Date. So it's normalizing it removing the time. Try ps.setTimetamp();  You could use : private static String getTimeStamp() { SimpleDateFormat f = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss""); return f.format(new Date()); } You shouldn't deal with string formats for dates/times when saving them to or reading them from a database. JDBC's abstractions such as `setTimestamp` and `getTimestamp` are there to make that unnecessary. thx I misread and didn't notice sql. My error"
237,A,How to retrieve previous query using Swing JButton I wrote a code sometime ago in which the object of ResultSet class res was able to retreive the next row of the database by using res.next(). But when res.previous() was used it was not working even though the method is defined in the resultset class. public void actionPerformed(ActionEvent e) { if (e.getSource() == next) { try { res.next(); } catch(Exception ee) { } showRecord(res); } } Here res.next() was fine but res.previous() was not working even though it never gave any error or warning. It never worked even though I made it TYPE INSENSITIVE? showRecord(res); is used for printing the row. This is a bad idea. You shouldn't be passing ResultSet instances around. I'd recommend mapping it into an object or data structure closing all the JDBC resources in a finally block and passing the object or data structure back to the UI layer. If you insist on ResultSet all the other comments above still apply. Just use a CachedRowSet instead of ResultSet. You can navigate that data structure or object any way you like then because you're not tethered to the database anymore. You'll just have to be smart about how much data you bring back at a time. You'll also need a strategy for going back and getting the next chunk if you need it. then in which case can we use res.previous();
238,A,"JDBC converting dates to UTC I have some code inserting a timestamp in a Postgres table. Here is the definition of the field where the timestamp is inserted: datelast timestamp without time zone I use this Java code to update data in the field: PreparedStatement sqlStatement = connection.prepareStatement( ""UPDATE datetest SET datelast = ? WHERE id = ? ""); sqlStatement.setTimestamp(1 new java.sql.Timestamp((new Date()).getTime())); sqlStatement.setInt(2 1); sqlStatement.executeUpdate(); My problem is that it inserts the UTC timestamp instead of my local timestamp (eastern time). So when I check the data in my table I see ""2010-02-08 19:07:21.261"" instead of ""2010-02-08 14:07:21.261"". Actually I had this code running has I would like to on an old server but after migrating the code I got that problem. The problem is not whit Postgres because I still use the same DB. I also checked the OS timezone and they are the same. I also tried a ""System.out.println(""TZ = "" + TimeZone.getDefault());"" and I get the same timezone on both servers. So my conclusion is that the JDBC driver is converting the date in UTC before inserting it in the table. Can anyone help me to figure out why the timestamp is converted? Thanks If your column is specifically ""without time zone"" would you want all dates to be stored in Universal Time so that you have a constant reference point? See answer to related question at http://stackoverflow.com/questions/508019/jpa-hibernate-store-date-in-utc-time-zone/3430957#3430957. When you say ""check the data in my table"" I suppose you are using some database-viewing tool? It would help to know how you are getting those values. It wouldn't surprise me to find that your database stores the values internally as UTC. It would then be up to the software that extracts the data to display it in a chosen time-zone. In fact I wouldn't expect to find that it stores the data internally as something dependent on the default time-zone on the database server because then changing that default time-zone (or moving the database to a different server with a different default) would change all the data. That would be a bad thing. I use the command-line ""psql"" interface and I do a simple ""select * from datetest""  As Paul Clapham mentions postgres does indeed always store timestamp values in UTC: For timestamp with time zone the internally stored value is always in UTC (Universal Coordinated Time traditionally known as Greenwich Mean Time GMT). An input value that has an explicit time zone specified is converted to UTC using the appropriate offset for that time zone. If no time zone is stated in the input string then it is assumed to be in the time zone indicated by the system's timezone parameter and is converted to UTC using the offset for the timezone zone. When a timestamp with time zone value is output it is always converted from UTC to the current timezone zone and displayed as local time in that zone. To see the time in another time zone either change timezone or use the AT TIME ZONE construct (see Section 9.9.3). This section of the manual is referring to timestamp with timezone but one can assume that the same internal storage applies to without timezone It's very interesting but that doesn't explain me why it currently work correctly from my old server and not from my new one... is there something I should add in my Java code to have it working as it was before?  my problem was related to the JAR file for Postgres. On my old server I was using a Postgres 7 JAR file and everything was working well. For some reason it wasn't working anymore on my new server. I replaced the JAR file by the Postgres 8 one and now everything is working well. When I insert a timestamp in the DB it now inserts my local time and not GMT time. Thanks everyone for your help."
239,A,"How can I set the application information on a session using the Oracle thin JDBC driver? I'd like to change the application information that is shown when inspecting Oracle 10g sessions using the Oracle Enterprise Manager application: Application Information Program 'my program' Module 'something' Command UNKNOWN I'm using the JDBC thin driver to connect and I have to admit I'd rather not use the OCI driver if at all possible. Can I do this with the thin driver and if so how? use the appropriate method within the DBMS_APPLICATION_INFO package (.SET_ACTION .SET_CLIENT_INFO .SET_MODULE uh... at risk of coming off as dense what is the ""DBMS_APPLICATION_INFO"" package?  DBMS_APPLICATION_INFO should take care of that: http://download.oracle.com/docs/cd/B19306_01/appdev.102/b14258/d_appinf.htm"
240,A,"Resultset To List I want to convert my Resultset to List in my JSP page. and want to display all the values. This is my query: SELECT userId userName FROM user; I have executed that using preparedstatement and got the Resultset. But how to convert it as a List and want to display the result like this: userID userName ------------------ 1001 user-X 1006 user-Y 1007 user-Z Is there an instance of ResultSet available in the JSP (e.g. created within scriptlet tags) or is this being created in a servlet and passed into the JSP? A ResultSet should never get as far as a JSP. It should be mapping into a data structure or object and closed inside the method scope in which it was created. It's a database cursor a scarce resource. Your app will run out of them soon if you persist with such a design.  You need to iterate over the ResultSet object in a loop row by row to pull out each column value: List ll = new LinkedList(); ResultSet rs = stmt.executeQuery(""SELECT userid username FROM USER""); // Fetch each row from the result set while (rs.next()) { int i = rs.getInt(""userid""); String str = rs.getString(""username""); //Assuming you have a user object User user = new User(i str); ll.add(user); } only thing that could be fixed is to change the statement to prepared statement (as the OP) True but it doesn't really matter because the question only regards getting data out of the ResultSet object. Thanks for your answer and discussions on this. I got it. I added those resultset in the List and Iterate it.  You could always use Commons DbUtils and the MapListHandler. From the doc: ResultSetHandler implementation that converts a ResultSet into a List of Maps so it'll take a lot of boilerplate code out of your hands."
241,A,"What is the equivalent of Oracle's REF CURSOR in Postgresql when using JDBC? In Oracle I can declare a reference cursor... TYPE t_spool IS REF CURSOR RETURN spool%ROWTYPE; ...and use it to pass a cursor as the return value... FUNCTION end_spool RETURN t_spool AS v_spool t_spool; BEGIN COMMIT; OPEN v_spool FOR SELECT * FROM spool WHERE key = g_spool_key ORDER BY seq; RETURN v_spool; END end_spool; ...and then capture it as a result set using JDBC... private Connection conn; private CallableStatement stmt; private OracleResultSet rset; [...clip...] stmt = conn.prepareCall(""{ ? = call "" + call + ""}""); stmt.registerOutParameter(1 OracleTypes.CURSOR); stmt.execute(); rset = (OracleResultSet)stmt.getObject(1); What is the equivalent in Postgresql? Maybe this will help: http://jdbc.postgresql.org/documentation/83/callproc.html#callproc-resultset-setof I haven't really messed with that before :P Looks very promising."
242,A,"Is jdbc by itself compatible with mysql I'd like to know if jdbc by itself is compatible with mysql or do I have to intsall something extra? I was told it is not compatible and that I'd have to use a different database. JDBC is a specification for Java/database interaction. As a specification it's compatible with almost every DB. However you need a JDBC compliant driver written for your database. Googling ""jdbc driver {databasevendor}"" should get you an the right track.  It does. You have to use the correct mysql jdbc driver and that's it! Some useful links: Little old but still helpful: Using JDBC with MySQL Getting Started Official reference: Official JDBC Driver JDBC reference You have to look at your specific version. MySQL belogs to Sun Microsystems now after all Using MySQL from Java +1: they were lied to. Thanks for the thorough answer."
243,A,How to configure a connection pool to access a Postgis database? I am using Glassfish v2 Hibernate with Annotations+EntityManager and Postgresql 8.4. I am also using on top HibernateSpatial and PostGis. It works fine to persist entities with spatial properties ( com.vividsolutions.jts.geom.Point ) into the Postgis database. However when trying to fetch objects using myEntityManager.find(MyClass.class key) I have the following exception : Can't convert object of type org.postgresql.util.PGobject I am not sure but googling around it seems that the connection pool that I use to access the Postgres database lacks an org.postgis.DriverWrapper and this is why the database PGobject corresponding to the Point property can not be converted back. I can't find how to add this wrapper to the connection pool. Can someone explain how to configure a connection pool for a PostGis connection ? Or indicate if this exception comes from another error ? Thank you Tartox For anyone interested the problem was that the postgis.jar was missing in the Glassfish lib along with the postgres.jdbc.jar.
244,A,How can I limit memory usage when generating a CSV from a large resultset? I have a web application in Spring that has a functional requirement for generating a CSV/Excel spreadsheet from a result set coming from a large Oracle database. The expected rows are in the 300000 - 1000000 range. Time to process is not as large of an issue as keeping the application stable -- and right now very large result sets cause it to run out of memory and crash. In a normal situation like this I would use pagination and have the UI display a limited number of results at a time. However in this case I need to be able to produce the entire set in a single file no matter how big it might be for offline use. I have isolated the issue to the ParameterizedRowMapper being used to convert the result set into objects which is where I'm stuck. What techniques might I be able to use to get this operation under control? Is pagination still an option? I would push back on those requirements- they sound pretty artificial. What happens if your application fails or the power goes out before the user looks at that data? From your comment above sounds like you know the answer- you need filesystem or oracle access in order to do your job. You are being asked to generate some data- something that is not repeatable by sql? If it were repeatable you would just send pages of data back to the user at a time. Since this report I'm guessing has something to do with the current state of your data you need to store that result somewhere if you can't stream it out to the user. I'd write a stored procedure in oracle- it's much faster not to send data back and forth across the network. If you have special tools or its just easier sounds like there's nothing wrong with doing it on the java side instead. Can you schedule this report to run once a week? I think unfortunately this is the answer. I'll have to push back and possibly build in a check not to process a result that will be too big.  Instead of loading an entire file in memory you can process each row individually and use output stream to send the output directly to the web browser. E.g. in servlets API you can get the output stream from ServletResponse.getOutputStream() and then simply write result CSV lines to that stream. Bypassing the Spring View functionality right? This is also an option if needed. For now I'm making sure the results are small enough by having a stricter query but I can't guarantee that they won't grow over time. Exactly. And this is actually supported well in Spring MVC you just need to declare OutputSteream or Writer as one of your handler method parameters.  A simple answer: Use a JDBC recordset (or something similar with an appropriate array/fetch size) and write the data back a LOB either temporary or back into the database. Another choice: Use PL/SQL in the database to write a file using UTL_FILE for your recordset in CSV format. As the file will be on the database server not on the client Use UTL_SMTP or JavaMail using Java Stored Procedures to mail the file. After all I'd be surprised if someone was going to watch the hourglass turn over repeatedly waiting for a 1 million row recordset to be generated. Just to get clarification on your suggestion -- I control the application server (to a degree) but I do not have access to the database either through the filesystem or creating new tables. Is this still possible? JavaMail is an interesting idea but I'd have to go through an administrative process to get that set up. It's something I'll keep in mind. Bulk fetch N thousand write dispose of set bulk fetch next N thousand etc. You should be able to do that at the JDBC level  Have you considered the performance of an Excel spreadsheet with 1000000 rows?
245,A,"msql table name with $ sign I have tables in Mysql 5 db with names prefixed with a dollar sign '$' ie tablename $MYTABLE I am using Spring 3.0 JdbcTemplate to do my select query but couldn't get it to work. ie  String tablename = ""$AAPL""; private static final String STOCK_SELECT = ""select symbol open high low close vol ev from ?""; jdbcTemplate.query(STOCK_SELECT new Object[] { tablename } new RowMapper() { .... } ); This will always throws InvalidSqlException presumably because of the $ sign. If I just do a normal query with no param ie.  private static final String STOCK_SELECT = ""select symbol open high low close vol ev from $AAPL""; Then everything works. How can I escape the $ sign using jdbcTemplate? -- Edit what I ended up doing -- Instead of passing the table name ""$AAPL"" to jdbcTemplate I just create the SQL string manually i.e.  jdbcTemplate.query( getStockSelect(""$AAPL"" .. .. )); How in the world did you even manage that? Your easiest solution would be to take the punctuation out of your table names... Database information like table and column names/identifers are not meant to be parameterized. MySQL uses the backtick (`) for table and column names/identifiers. Your parameterized query is probably going in as:  select symbol open high low close vol ev from ""$AAPL"" I'm not aware of any standard API for parameterizing/escaping identifiers like that. I'd recommend if you can just to have it in there statically. Since they're the same columns partitioning the table might also be an option. Finally if you still need it to be dynamic you'll have to escape the table name yourself I'd recommend only pulling it in from a whitelist. You may want to take a look at the mysql documentation on how to escape identifiers.  SQL supports delimited identifiers so you can use punctuation white space special symbols international characters or SQL keywords as table names or column names. See my past answer to Do different databases use different name quote? In MySQL use back-quotes: private static final String STOCK_SELECT = ""select symbol open high low close vol ev from `$AAPL`""; Or set SQL_MODE to ANSI mode and use double-quotes: private static final String STOCK_SELECT = ""select symbol open high low close vol ev from \""$AAPL\""""; You can't use a ? placeholder for a table name in SQL. That's just not supported by the language. You can use a parameter only where you could normally use a literal value like an integer or a single-quoted string."
246,A,Execute dynamic sql and pl/sql in Java via web interface Currently I'm making sort of SQL command line interface for web-based application. It should act roughly like sqlPlus. I have encountered a problem how to execute sql's. They can be both as SQL and/or PL/SQL. First way I thought that I can split them (by ';' or ';/') and detect separately if it's sql select or delete/update/insert or pl/sql. Now I cant find for PL/SQL Backus–Naur Form to make regexp. May be there exists easier way? Generally What is the best way to make such logic ? TIA I think the best way is to use ANTLR which have a PLSQL grammar. You can generate code for java and other languages.  Use regexp to separate SQL statement and PLSQL in a sql script is almost impossible. declare begin select sysdate from dual; dbms.output('hello'); end; / Do you have any ideas how to recognize such a simple PLSQL code using regexp. A SQL Parser is what you need to achieve this here is an article that may helpful.
247,A,"What is the most ""database independent"" way of creating a variable length text field in a database I want to create a text field in the database with no specific size (it will store text of length unknown in some case) - the particular text are serialized simple object (~ JSON) What is the most database independent way to do this : - a varchar with no size specified (don't think all db support this) - a 'text' field this seems to be common but I don't believe it's a standard - a blob or other object of that kind ? - a varchar of a a very large size (that's inefficient and wastes disk space probably) - Other ? I'm using JDBC but I'd like to use something that is supported in most DB (oracle mysql postgresql derby HSQL H2 etc...) Thanks. if you're having trouble on this what happens when you start doing queries with dates and time anything with row numbers or fancy query tuning techniques?? if you are just writing serialized simple object look at flat files. Most ""basic"" types would be stored int the proper database type (Number-> BIGINT String -> varchar) etc... Only the 'other' types would be serialized into a string. a varchar of a a very large size (that's inefficient and wastes disk space probably) That's gonna be the most portable option. Limit yourself to 2000 characters and you should be fine for most databases (oracle being the current 2000 limiter but be wary of old mysql versions as well). I wouldn't worry too much about disk space either. Most databases only use disk for the actual data saved in the field.  Use a framework like hibernate so you won't have the problem to find a universal solution. I don't think that you can use one universal type in every mentioned database. The databases differ to much I guess. Well what I'm actually writing is sort of a basic ORM (like a basic hibernate) for a new language that does not have any yet ... I'm trying to stay away from having DB vendor specific code ... but might be forced to.  text is perhaps best but to be removed shortly from SQL Server and there is no DBMS independent option for all you listed. Saying that portability is overrated when it comes to SQL. You're more likely to change your client code before you change DBMS. Pick one and go with that....  Use a BLOB. JDBC2.0 API supports it and so any driver that supports JDBC2.0 (J2SE 5.0 on) should support it. The advantages of BLOB are : 1. Size can be as large as 4G-1 (Oracle. other databases not so sure) 2. Can store any data you wish (even images serialized into some field in your JSON structure) 3. Completely neutral to transport across OS 4. You can still take advantage of indexes on keys that reference the BLOB so that searches on ids etc don;t have to be done by getting at the structure. I just see that JDBC also support CLOB that might be a good option.  Do you really need to support all six of those databases? (hint: No.) I've come to the opinion that writing universally portable SQL DDL is not worth the trouble. YAGNI. You should support the databases you are currently using and be prepared to adapt to a database that you adopt in the future. Re your comment: The only standard SQL variable-length data types are VARCHAR and BLOB. VARCHAR is for string data and its declaration includes a character set and collation. BLOB is for binary data and does not support charset/collation. Other data types such as VARCHAR(max) CLOB or TEXT are vendor extensions: VARCHAR(max): MS SQL Server NVARCHAR(max): MS SQL Server LONGVARCHAR: Derby H2 HSQLDB CLOB: Derby H2 HSQLDB Oracle SQLite NCLOB: Oracle TEXT: MS SQL Server MySQL PostgreSQL SQLite NTEXT: MS SQL Server @Thibaut: Remember to upvote answers that helped you. Do I need all those myself -> No. But since the code is part of an API and i don't want to tell the end user they have to use a particular DB the more 'compatible' the better ... although i know SQL implementation are all over the places. That's why I'm asking for the ""most"" database independent of doing this. Thanks that's very useful."
248,A,"JDBC Null pointer Exception thrown Hi I'm getting nullpointerexception at rs.next() or rs.getString(1) it is really weird that sometimes rs.next() works fine and it throws nullpointerexception at rs.getString(""PRODUCTCODE"")sometimes it throws npe at rs.getString(""PRODDATE"") i dont understand why rs.getString() thows npe while rs.next() works fine Here is my code { ResultSet rs = null; String query = """"; BarcodeBean bi = null; try { query = ""SELECT * FROM TABLE(GET_BARCODEINFO('""barcode.trim()""'))""; statement = connection.createStatement(); Logger.getInstance().getLogger().logInfo(query); rs = statement.executeQuery(query); bi = new BarcodeBean(); if (rs == null){ if(rs.next()){ bi.setUrunKodu(rs.getString(""PRODUCTCODE"")); bi.setImalatMakineKodu(rs.getString(""PRODMACHINECODE"")); bi.setOperatorSicilNo(rs.getString(""OPERATORID"")); bi.setImalatTarihi(rs.getString(""PRODDATE"")); bi.setImalatVardiyasi(rs.getString(""PRODSHIFT"")); bi.setSeriNumarasi(rs.getString(""SERIALNUMBER"")); bi.setSirtTarihi(rs.getString(""SIRTTARIHI"")); } } } catch (SQLException e) { e.printStackTrace(); throw e; } catch (Exception e) { e.printStackTrace(); } finally { DatabaseUtility.close(rs); DatabaseUtility.close(statement); } } you miss also a couple of + in the code that builds the query @dfa: that's because it's a crosspost from here: http://forums.sun.com/thread.jspa?threadID=5435361 Unfortunately the Sun/Oracle forums mangles source code when it's not posted with code-tags. Please post the stacktrace. Statement#executeQuery() never returns null. The whole nullcheck is superfluous. The normal idiom is the following: public Entity find(Long id) throws SQLException { Connection connection = null; PreparedStatement preparedStatement = null; ResultSet resultSet = null; Entity entity = null; try { connection = database.getConnection(); preparedStatement = connection.prepareStatement(SQL_FIND); preparedStatement.setLong(1 id); resultSet = preparedStatement.executeQuery(); if (resultSet.next()) { entity = new Entity(); entity.setId(resultSet.getLong(""id"")); entity.setName(resultSet.getString(""name"")); // ... } } finally { close(connection preparedStatement resultSet); // In reversed order. } return entity; } Your actual problem lies somewhere else. This is clearly a misinterpretation of the stacktrace. To nail it correctly down you need to lookup the line number of the first line in the stacktrace and point us the exact code at this line number.  From Statement javadocs: public ResultSet executeQuery(String sql) throws SQLException Returns: a ResultSet object that contains the data produced by the given query; never null So you don't need to verify whether rs == null. The standard way to proceed resultset rows is: while (rs.next ()) { doSmth (rs); }  probably you want: if (rs != null) { if (rs.next()) { or even better: if (rs != null && rs.next()) { Your test is simply wrong. you meant if `(rs != null && rs.next())` probably Your test is wrong as well. In harigm's code rs can't possibly be null when rs.next() is invoked. In harigm's code the first test is whether rs is null. So any calls to an instance of rs will automatically trigger a NullPointerException. Also the && operator allows to test if an instance is null before calling a method on it.  You made a wrong notation in if condition So change it as if(rs!=null){ ...... .......}"
249,A,"tomcat 6.0 with JDBC throws ClassNotFoundException com.mysql.jdbc.Connection I've successfully connected to MySQL database through Eclipse without getting tomcat involved so at lease it's some good progress. But when I try from my web page (Tomcat 6.0) it throws an error. I followed the tutorials read documentations and looked countless forums but cannot figure out for 2 days now. Let's look at the step one by one. I'm running tomcat 6.0.26 and I have MySQL installed and up and running fine. 1. Place connectorj to CATALINA_HOME/lib makun /home/makun/tomcat/apache-tomcat-6.0.26/lib ->ls | grep -i mysql* mysql-connector-java-5.1.13-bin.jar 2. Tell Tomcat about my MySQL info. (declare resource requirements) and also map the servlet used to invoke db test (i.e. /tmp_db_test) (/WEB-INF/web.xml) <?xml version=""1.0"" encoding=""ISO-8859-1""?> <web-app xmlns=""http://java.sun.com/xml/ns/j2ee"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd"" version=""2.4""> <servlet> <servlet-name>DatabaseTest</servlet-name> <servlet-class>com.masatosan.tmp.Tmp</servlet-class> </servlet> <servlet-mapping> <servlet-name>DatabaseTest</servlet-name> <url-pattern>/tmp_db_test</url-pattern> </servlet-mapping> <resource-ref> <description>DB Connection</description> <res-ref-name>jdbc/MasatoDB</res-ref-name> <res-type>javax.sql.DataSource</res-type> <res-auth>Container</res-auth> </resource-ref> </web-app> 3. Configure tomcat resource factory. (CATALINE_HOME/conf/context.xml) <!-- Default set of monitored resources --> <WatchedResource>WEB-INF/web.xml</WatchedResource> <!-- Masato added the line below to setup JDBC --> <Resource name=""jdbc/MasatoDB"" auth=""Container"" type=""javax.sql.DataSource"" maxActive=""100"" maxIdle=""30"" maxWait=""10000"" username=""masato"" password=""mypass"" driverClassName=""com.mysql.jdbc.Driver"" url=""jdbc:mysql://localhost:3306/masatosan""/> 4. create JSP page that invoke servlet This is just a page with one button that send POST request.  <html> <head> </head> <body> <!-- click button to send request to servlet --> <form method=""POST"" action=""tmp_db_test""> <p><input type=""submit"" value=""Submit"" name=""submit_button""></p> </form> </body> </html> 5. Finally implement the servlet that tries to connect to MySQL database. (Tmp.java) package com.masatosan.tmp; import java.io.IOException; //import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.SQLException; import javax.naming.Context; import javax.naming.InitialContext; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import javax.sql.DataSource; import com.masatosan.dateformatter.DateFormatter; import com.masatosan.logger.Logger; import com.mysql.jdbc.Connection; public class Tmp extends HttpServlet { private Connection conn; public void doPost(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { try { Context initCtx = new InitialContext(); Context envCtx = (Context) initCtx.lookup(""java:comp/env""); DataSource ds = (DataSource)envCtx.lookup(""jdbc/MasatoDB""); conn = (Connection) ds.getConnection(); String template = ""INSERT INTO users(username email password created_date) VALUES (? ? ? ?);""; PreparedStatement inserter = conn.prepareStatement(template); inserter.setString(1 ""test_username""); inserter.setString(2 ""test@test.com""); inserter.setString(3 ""test_pass""); inserter.setString(4 DateFormatter.formatToSqlDate(null)); inserter.executeUpdate(); } catch(Exception e) { Logger.log(e.getMessage()); } finally { if(conn != null) { try { conn.close(); } catch (SQLException e) { Logger.log(e.getMessage()); } } } } } I complied Tmp.javaand put in /WEB-INF/classes/com/masatosan/tmp/Tmp.class Then redeployed Tomcat server and tested on browser. When I click submit button I get the error: javax.servlet.ServletException: Error instantiating servlet class com.masatosan.tmp.Tmp org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102) org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:298) org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:852) org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:588) org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489) java.lang.Thread.run(Thread.java:619) root cause java.lang.NoClassDefFoundError: Lcom/mysql/jdbc/Connection; java.lang.Class.getDeclaredFields0(Native Method) java.lang.Class.privateGetDeclaredFields(Class.java:2291) java.lang.Class.getDeclaredFields(Class.java:1743) org.apache.catalina.util.DefaultAnnotationProcessor.processAnnotations(DefaultAnnotationProcessor.java:181) org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102) org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:298) org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:852) org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:588) org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489) java.lang.Thread.run(Thread.java:619) root cause java.lang.ClassNotFoundException: com.mysql.jdbc.Connection org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1516) org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1361) java.lang.Class.getDeclaredFields0(Native Method) java.lang.Class.privateGetDeclaredFields(Class.java:2291) java.lang.Class.getDeclaredFields(Class.java:1743) org.apache.catalina.util.DefaultAnnotationProcessor.processAnnotations(DefaultAnnotationProcessor.java:181) org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102) org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:298) org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:852) org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:588) org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489) java.lang.Thread.run(Thread.java:619) Please let me know if you need more clarification. EDIT As per suggestion connectorj jar stays in CATALINA_HOME/lib I've fixed import line to in Tmp.java to: import java.sql.Connection instead of com.mysql.jdbc.Connection Now that I'm getting new error when click submit button on browser. Cannot create JDBC driver of class '' for connect URL 'null' I attempted to tail the log: makun /home/makun/tomcat/apache-tomcat-6.0.26/logs ->tail -f localhost.2010-08-30.log and nothing comes up when I clicked the submit button. (it is correct log I think since other pages that have error will output message in the log) UPDATE I'm not sure why but it started working while I was trying to print exception stacktrace to my log. I've been reloading Tomcat from manager page so many times that might caused something weird and getting same error page even though I've made code change (it was freaking out giving me 404 and 500 interchangeably. I wish I could provide exact detail but my steps described in the question section appeared to work (after fixing few things that were suggested) The class it can't find ""com.mysql.jdbc.Connection"" should be in mysql-connector-java-5.1.13-bin.jar. I think tomcat should be able to pick it up from $CATALINE_HOME/lib. So from what you say it ""should"" be working... Perhaps check that the user tomcat runs as has read permissions on the file? Could the jar file have got corrupted - perhaps by ftp in text mode? Are you certain that CATALINA_HOME is /home/makun/tomcat/apache-tomcat-6.0.26 - maybe check the tomcat startup scripts to see if it is configured to be somewhere else? If its still not working you could try putting the jar file into web-inf/lib. Thanks for the tip! Putting in /WEB-INF/lib did make some change but root cause for class not found exception was due to importing wrong connection package (please see the EDIT section)  This exception is telling you that it cannot find the com.mysql.jdbc.Connection class while investigating the declared fields of the servlet during its loading/instantiation in order to collect any annotations for the annotation cache. You should be using java.sql.Connection not com.mysql.jdbc.Connection. In fact all your JDBC code should be importing/using the java(x).sql interfaces/classes only. Otherwise your JDBC code is tight coupled to the DB and JDBC driver used and not reuseable with other DB's and/or drivers this violates the whole abstract idea of JDBC. That said declaring the Connection as an instance variable of a servlet is an extremely bad idea. A servlet is been instantiated only once and shared among all requests during the webapp's lifetime. You should be acquiring and closing the connection in the shortest possible scope i.e. already in the very same method block. Better yet place all the JDBC logic in a reuseable DAO class which you just import in your servlet. See also: Servlet instantiation session variables and multithreading Basic JDBC-DAO tutorial (second part contains JSP/Servlet targeted examples) I noticed there are 2 different Connection that I can import too. Very confusing... I've fixed and got new error so I will take a look what is the error indicate. (also added to my EDIT section) @Adam: This exception was thrown during loading/instantiating the servlet not during loading the resource. @masato: That's a wrapped/nested exception. Read the server logs for the **root cause**. It contains detail about the root cause of the problem. Big chance that you should keep the MySQL JDBC driver there in `Tomcat/lib` where it belonged and get rid of the one in `/WEB-INF/lib`. @BalusC: Thanks for the tip! I will post the result in edit shortly. @masato: Are you using Tomcat plugin in Eclipse? Everything get logged into Eclipse console. You may need to switch the displayed console. @BalusC: nope I'm not using the plugin. I compile java classes manually and put them in corresponding WEB-INF then reload tomcat server from manager page (http://localhost:8080/manager/html/reload?path=/head_first). @BalusC: meanwhile I will mark this as an answer since topic's subject's exception has been solved and I'm dealing with new error. I'll spend sometime to try plugin and see if I can get some useful log messages. Thanks for the help! OK check the `catalina` logfile in `/logs` folder for the exact exception. That's Tomcat's own root logfile. The `localhost` logfile is only for the deployed webapplication(s) on the domain."
250,A,"Using DB Api in a portable manner I need to develop some kind of application and use DB in it. Let's say i want to develop it over Windows currently however in a couple months i may have to migrate it to Linux. I started reading a little bit about it but couldn't get to point i needed. Is there or isn't a generic/protable/standart api for using DB ? I read there is ODBCJDBC iOBDCunixODBC ? why all of these exist ? Can someone help clearing and setting my head straight regarding the issue ? Edit - I'm using C++ - so please advise to that direction even though i'll appreciate inter-language/inter-platform recommendations There's a bunch of C++ ""wrapper"" libraries for generic DB access here's couple of top of my head: SOCI - modern C++ syntax active development plays nice with boost supports multiple backends OTL - header-only (templates) very light-weight Both of these grew out of Oracle-specific work but support at least several other databases now. Of course you can't really hide vendor differences but that is general law of leaky abstractions.  Just use the JDBC API in combination with a JDBC driver. Do not use the ODBC (bridge) driver.  I recommend you using SQLite if your DB load is not very heavy. you need only one header file and one source file only(amalgamation version). and It's highly portable. I have been using it on Windows and Linux."
251,A,Out of Memory allocLargeObjectOrArray from ResultSet I'm using JDBC to get a large amount of data. The call completes successfully but when resultSet.next() is called I get the following error: java.lang.OutOfMemoryError: allocLargeObjectOrArray - Object size: 15414016 Num elements: 7706998 I've attempted to increase the JVM memory size but this does not fix the problem. I'm not sure this problem can even be addressed as I'm not using JDBC to access a database rather the system is accessing a BEA AquaLogic service through JDBC. Has anyone run into this error? can you post a more complete stack trace? What are you trying to read from the database? You can try setting the setFetchSize(int rows) method on your statement. But setFetchRows is only a hint which means it may not be implemented. This won't work as only one row is being returned.  Try increasing the memory size to 1.2g e.g. -mx1200m or something just less than the physical memory of your machine. You may find it is reading more data at once than your think. I increased my memory so far that the JVM wouldn't start the application because it said I specified too high memory. My machine isn't the beefiest either.  Beware that until the first resultSet.next() call the results may not yet be read from the database or still be in another caching structure somewhere. You should try limit your Select to return a sane amount of results and maybe repeat the call until there are no more results left if you need all the data. Increasing the JVM memory size won't help unless you can be sure that there is an absolute limit on the amount of data which will be returned by your JDBC call. Furthermore accessing any service through JDBC essentially boils down to using JDBC :) Another (unlikely) possibility could be that there is a bug in the JDBC driver you're using. Try a different implementation if it is possible and check if the problem persists. I wouldn't doubt the JDBC driver being the culprit. I can not however try any other implementation as this is BEA specific. There are other ways at getting at the information I am looking for but that would be a big back-step at this time. I haven't really had time to figure out the issue. In the meantime I seem to be able to get the data returned without any errors. I believe my case was an edge case anyway. Accepting this answer because it was the most robust.  First-- figure out if you really need to get that much data in memory at once. RDBMS's are good at aggregating/sorting/etc large data sets and you should try to take advantage of that if possible. If not (and you really really do need that much data in working memory for some reason)... and bumping up the JVM's memory args doesn't raise the bar enough... look into an in-memory distributed caching solution like Coherence (COTS) or TerraCotta (open source).  How many rows are you returning from the database? like kosi2801 I would suggest to only fetch a subset of the data start with a reasonable number and then increase to find the threshold.
252,A,Retrieving a max date from DB2 in Java throwing wrong column type conversion exception I have the following SQL that returns the max BILL_DATE based on some criteria. BILL_DATE is defined in the database as a DATE. SELECT MAX(BILL_DATE) FROM BILLTABLE WHERE col1 = ? and col2 = ? But when I read the value from the resultSet. bill.setBillDate(resultSet.getDate(1)); An exception is thrown: Invalid data conversion: Wrong result column type for requested conversion. ERRORCODE=-4461 SQLSTATE=42815 I have also tried bill.setBillDate(resultSet.getString(1)); But that doesn't return a date. It returns either 100 200 or 300 which is obviously not correct. Is there another way to do this? Am I doing something wrong? Thanks Randall EDIT I had two resultSets open in the function where I was reading in the BILL_DATE. I changed the code to the following and it works fine. bill.setBillDate(resultSet1.getDate(1)); I have updated my question reflecting your questions. What do you see if you print out getString(1)? How are you defining the date field in your table? Ash is right how are you defining the date column? Is it possible the column is timestamp? In that case try resultSet.getTimestamp(1)) I have updated my question reflecting your questions.  I had two resultSets open in the function where I was reading in the BILL_DATE. I changed the code to the following and it works fine. bill.setBillDate(resultSet1.getDate(1));
253,A,"Java web application DAO writing authenticated UserID and IP Address to DB I'd like to write to my Oracle DB the user ID and IP address of the logged in user (web app) whenever I perform SQL UPDATEs and INSERTs. Such as public static int updateUser(STKUser user STKUser loggedIn) throws DAOException { Connection connection = null; connection = DB.getConnFromCache(); PreparedStatement ps = null; String query = ""INSERT INTO xtblPersonnel (pID pPssWrd pAdminDate pAdminIP pAdminBy) VALUES (??SYSDATE??)""; try { ps = connection.prepareStatement(query); ps.setString(1 user.getBadge()); ps.setString(2 user.getPassword()); ps.setString(3 loggedIn.getIpAddress()); ps.setString(4 loggedIn.getBadge()); return ps.executeUpdate(); } catch (Exception e) { System.out.println(""SQL Exception inserting new user with badge: "" + user.getBadge() + "". Error Message: "" + e.getMessage()); LOGGER.log(Level.INFO ""SQL Exception inserting new user with badge: "" + user.getBadge() + "". Error Message: "" + e.getMessage() user); throw new DAOException(""SQL Exception inserting new user!""); // return 0; } finally { DB.closePreparedStatement(ps); DB.releaseConnToCache(connection); } } STKuser is a Javabean My application uses a general Oracle db username and password so that is the reason why I want to record who did the update or insert and from which machine. Is this an acceptable approach. I used to pass in the session but have realized this is a no no. Difficult to tell from the given information. Why 2 STKUser objects? They seem to be representing the same user is my guess. Where are you initializing the PreparedStatement and the Connection? Where is the catch block? Why is this method declared static? one STKUser object was representing the employee data being added to the database and the second STKUser object was representing the administer logged in doing the SQL INSERT. I've edited my answer to include more code Assuming that you're properly closing all DB resources as Connection Statement and ResultSet in the finally block of the try block where you acquired them and the code is doing what it should do I don't forsee problems with the approach in question. There is no risk for SQL injections since you're using PreparedStatement if that was your actual concern. Declaring the method static is however a bit a smell but then we need to know more about the context the code is running in. Static because method is just CRUD. But I'm still learning J2EE. The way I call it eclipse prompted me to change it to staic. if everything is good on the form then I call: STKUserDAO.insert(formUser loggedInUser);"
254,A,"JDBC connection to Oracle Clustered I would like to connect to a clustered Oracle database described by this TNS:  MYDB= (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = host1)(PORT = 41521)) (ADDRESS = (PROTOCOL = TCP)(HOST = host2)(PORT = 41521)) (LOAD_BALANCE = yes) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME= PDSALPO) ) ) I connect normally from my application to non-clustered Oracle using the following configuration: <group name=""jdbc""> <prop name=""url"">jdbc:oracle:thin:@host1:41521:PDSALPO</prop> <prop name=""username"">user</prop> <prop name=""password"">pass</prop> </group> Do you know how I can change that to connect to the clustered database? Thanks Tam You can use this format unless you make use of JTA transactions. In that case you must use some different setup. See http://forums.oracle.com/forums/thread.jspa?messageID=2860653&#2860653 (applies for BEA Weblogic but I think it also applies for other setups and application servers)  Apparently you can do this jdbc:oracle:thin:@(DESCRIPTION=(LOAD_BALANCE=on) (ADDRESS=(PROTOCOL=TCP)(HOST=host1) (PORT=1521)) (ADDRESS=(PROTOCOL=TCP)(HOST=host2) (PORT=1521)) (CONNECT_DATA=(SERVICE_NAME=service)))"
255,A,Does JDBC ResultSet getString always return a String representation? I'm formatting a ResultSet to output to a CSV file. As such I really don't care about the Java types of the result set beyond maybe knowing if it's text or numbers. Does JDBC guarantee getString will always give a string representation of the valuesatleast for single values (I don't need to concern myself about java.sql.Types.ARRAYjava.sql.Types.JAVA_OBJECT and a few others). e.g. given resultSetMetaData.getColumnType(i) is a Types.FLOAT or a Types.BIGDECIMAL. will rs.GetString(i) always yield some String ? i.e. Are there cases getString will throw an SQLException or return null when a getXXX would give me the value ? Yup check this : http://java.sun.com/docs/books/tutorial/jdbc/basics/retrieving.html JDBC allows a lot of latitude as far as which getXXX methods you can use to retrieve the different SQL types. For example the method getInt can be used to retrieve any of the numeric or character types. The data it retrieves will be converted to an int; that is if the SQL type is VARCHAR  JDBC will attempt to parse an integer out of the VARCHAR. The method getInt is recommended for retrieving only SQL INTEGER types however and it cannot be used for the SQL types BINARY VARBINARY LONGVARBINARY DATE  TIME or TIMESTAMP. But be careful different JDBC driver may yield different result. **Update on the linked guide:** `Note that although the method getString is recommended for retrieving the SQL types CHAR and VARCHAR it is possible to retrieve any of the basic SQL types with it. Getting all values with getString can be very useful but it also has its limitations. For instance if it is used to retrieve a numeric type getString converts the numeric value to a Java String object and the value has to be converted back to a numeric type before it can be operated on as a number. In cases where the value is treated as a string anyway there is no drawback.`  java.lang.String is a final class - it cannot ever have a subclass. So any method that returns String will either return an instance of the class java.lang.String or a null or throw an exception. As for conversion it is up to the JDBC driver if it will allow you to convert from non-String types. I suspect many will have an issue with it. I would suggest that you do this instead: Object item = resultSet.getObject(i); String strValue = (item == null ? null : item.toString()); That should be more robust since getObject() will always do the sensible thing. Or throw `SQLException` And that is the question are there cases getString will throw an SQLException or return null when a getXXX would give me the value ?
256,A,"JDBC: How can I query by time in Oracle? I have this JDBC SQL query: select * from table where TX_DATE = {d '2009-01-05'} and TX_TIME = {t '15:23:39'} This returns some rows. Note that since Oracle has no TIME type both columns are of type DATE. But it fails when I use JDBC parameters: select * from table where TX_DATE = ? and TX_TIME = ? where the first parameter is new java.sql.Date(...) and the second is new java.sql.Time(...). I print both parameters to stdout and they look good so the values are correct. But I don't get any rows. Why? What's different between {t '15:23:39'} and new java.sql.Time()? [EDIT] Here is the code that fills the PreparedStatement: public static void setParameters (final PreparedStatement stmt final Object... param) { for (int i=0; i<param.length; i++) { Object debug = param[i]; String type = null; if (param[i] == null) stmt.setString(i+1 null); else if (param[i] instanceof java.sql.Time) stmt.setTime (i+1 (java.sql.Time)param[i]); I've set a breakpoint in setTime() and it gets called. param[1].toString() prints 15:23:39 so I know the value is correct. My guess is that since Oracle doesn't have a TIME type there is a bug in the driver and the DATE part of the time is not ignored. If I use select * on the whole table I get TX_DATE TX_TIME 2009-01-08 2009-08-01 As you can seem the time column is treated like a date by default. If I use TO_CHAR(TX_TIME 'HH24:MI:SS') I get: TX_DATE TX_TIME 2009-01-08 15:23:39 Where does 2009-08-01 come from? I assume that you are using a PreparedStatement in this? PrepapredStatement stmt = conn.prepareStatement( ""select * from table where TX_DATE = ? and TX_TIME = ?"") stmt.setDate(1 new java.sql.Date(myDate.getTime)); stmt.setTimestamp(2 new java.sql.Timestamp(myDate.getTime)); ResultSet rs = stmt.executeQuery(); As I wrote I'm using java.sql.Time not java.sql.Timestamp. I'm initializing the time with a SimpleDateFormat.parse() with the format ""HH:mm:ss"" and the value ""15:23:39"". Can you post yuour *actual code*. It's difficult to debug code which I can't see! Are you using `PreparedStatement` and saetting the parameters as I said (albeit with a time)? Have you tried using a timestamp instead or just used the date bit to see if that worked? See my edit; my guess is that there is a bug in the Oracle driver due to the fact that Oracle doesn't have a real ""TIME"" type. Note that the type of both columns is DATE (since there is no native TIME type in Oracle).  Oracle does not have a Java type for time. The java.sql.Time class is mapped to the oracle.sql.DATE class even in the latest drivers. Documentation Here What you should do is have the ""day"" portion of TX_TIME be some standard value (say 1970-01-01). Then you can query on this column with a static ""day"" and have the time work as expected. Depending upon what version of the Oracle drivers you're using the handling of java.sql.Date and java.sql.Timestamp for an Oracle DATE column type is different. Check the JDBC FAQ for more info. Good luck! public static void setParameters (final PreparedStatement stmt final Object... param) { for (int i=0; i<param.length; i++) { Object debug = param[i]; String type = null; if (param[i] == null) stmt.setString(i+1 null); else if (param[i] instanceof java.sql.Time) { stmt.setTime ( i+1 java.sql.Timestamp.valueof(""1970-01-01 "" + param[i] + "".000000000"") ); } Thanks; I was somehow expecting that Oracle would use the same ""day"" part if I didn't specify one instead of ""1st of the current month""."
257,A,"NLS_LANG setting for JDBC thin driver? I am using the thin Oracle JDBC driver ver 10.2.0 (ojdbc14.jar). I would like to configure its NLS_LANG setting manually. Is there a way? Currently it fetches this setting from the VM variable user.language (which is set automatically by setting the current locale or on startup from the system environment). This is a problem when the users switch the application locale to a one that is unsupported by the Oracle JDBC driver (e.g. mk_MK). In this case the next time I fetch a connection I get the following exception:  ORA-00604: error occurred at recursive SQL level 1 ORA-12705: Cannot access NLS data files or invalid environment specified I can change the locale on the fly just before I fetch the connection and switch back to the user's selected one back and forth but this seems unelegant and unefficient. You should use the old Oracle 9.2 JDBC driver that is fully compatible and certified with Oracle 10g. The old driver does not use ALTER SESSION SET NLS_LANGUAGE commands.  Invoking java with the following works for me : -Duser.country=us -Duser.language=en if ""en"" for country also causes ORA-12705. That is because there is no ""EN"" country. There are: US GB and many others that have English as official language  See also: http://serverfault.com/questions/63216/ora-12705-cannot-access-nls-data-files-or-invalid-environment-specified/64536 For me the best response was by FoxyBOA to invoke java app with: -Duser.country=en -Duser.language=en +1 as it's a lot less invasive than the currently accepted answer. Funny. Vote for own answer cross-posted here :D Thanks. Worked for SQLDeveloper and also for web-logic data-source This one solved my problem: -Duser.language=en -Duser.region=US  I was fighting the same problem and found out that thin jdbc Oracle drivers do not require NLS_LANG or system locale to be specified. But when you connect to non-english databases you are to have orai18n.jar in the classpath. from Oracle® Database JDBC Developer’s Guide and Reference Providing Globalization Support The basic Java Archive (JAR) files ojdbc5.jar and ojdbc6.jar contain all the necessary classes to provide complete globalization support for: Oracle character sets for CHAR VARCHAR LONGVARCHAR or CLOB data that is not being retrieved or inserted as a data member of an Oracle object or collection type. CHAR or VARCHAR data members of object and collection for the character sets US7ASCII WE8DEC WE8ISO8859P1 WE8MSWIN1252 and UTF8. To use any other character sets in CHAR or VARCHAR data members of objects or collections you must include orai18n.jar in the CLASSPATH environment variable of your application.  The NLS_LANG settings are derived from the java.util.Locale . Therefore you will need to make a call similar to this before connecting: Locale.setDefault(Locale.<your locale here>); Yes this is exactly what I did end up doing. It works fine but it is not very pretty. Thanks!"
258,A,"pass ResultSet from servlet to JSP Hi I am doing the following in my SampleServlet.java //Fill resultset from db ..... try { ArrayList Rows = new ArrayList(); while (resultSet.next()){ ArrayList row = new ArrayList(); for (int i = 1; i <= 7 ; i++){ row.add(resultSet.getString(i)); } Rows.add(row); } request.setAttribute(""propertyList"" Rows); RequestDispatcher requestDispatcher = getServletContext().getRequestDispatcher(""/DisplayProperties.jsp""); requestDispatcher.forward(requestresponse); and then in my jsp DisplayPropeties.jsp i have  <% ArrayList rows = new ArrayList(); if (request.getSession().getAttribute(""propertyList"") != null) { rows = (ArrayList ) request.getSession().getAttribute(""propertyList""); } %> but rows is allways null. Can anyone help with what I am doing wrong please. You should also not be using a ResultSet in a JSP. That's a database cursor a scarce resource. You may get this to ""work"" on a simple page but I'd bet that you don't have clear responsibility for closing the ResultSet Statement or Connection in your code. You'll soon run out and wonder why your code is crashing with exceptions. None of the java.sql interface implementations should escape out of a well-defined persistence layer. Acquire the connection get the ResultSet map it into an object or data structure and close all your resources in reverse order of acquisition then return the object or data structure to your JSP written only with JSTL and no scriplets for display. That's the right thing to do. If you MUST use SQL in a JSP use the JSTL <sql> tags to do it. +1. That's the answer that I was hoping to find in question titled like that! (so I don't need to write my own to ask if servlet is good place for ResultSet :))  I don't understand how rows can be null given your if statement there. Anyway shouldn't it be request.getAttribute(""propertyList"") in the DisplayProperties.jsp? Thank you Murali... very much appriciated. That worked like a treat!  You've the answer so I am only going to do an enhancement suggestion: do not use scriptlets in JSP. Use taglibs and EL where appropriate. An example to generate a list would be: <ul> <c:forEach items=""${propertyList}"" var=""item""> <li>${item}</li> </c:forEach> </ul> You can do the same for HTML tables and dropdown options. Hope this helps.  Use request.getSession().setAttribute(""propertyList"" Rows); instead of request.setAttribute(""propertyList"" Rows); in your servlet code. It will work perfectly."
259,A,Lazy Loading DTO fields in Spring I have a project that is using Spring and is broken down into a couple dozen DAOs and associated DTOs. I'm using JdbcTemplate but not much else as it's exactly the level of abstraction I'm happy with. I'm currently performing lazy loading on my DTOs by placing some rather hairy code in their getters. Basic boilerplate logic is: 1. If field is not null return its value and exit 2. Contact appropriate DAO and fetch relevant DTOs 3. Store them until next time. It works fine except that my lowly DTOs are coupled with a whole bunch of DAOs and aren't so POJOey. Another code smell appears if I place the logic in the DAO since it would be handling both CRUD for its DTOs and Lazy Loading and as I understand it Objects should have a single responsibility. I'm hoping that there's a relatively simple Spring approach that I can use to inject a Lazy Loader object between the DAOs and the DTOs to achieve this but any other solution would work for me. Any ideas? It's easier to wrap DAO's around DAO's... it depends on how much of the model you want to bring across. DTO's aren't typically used to bring a one to many over with them as two or more separate database/dao calls. In that case you really want an ORM. Since your looking for a dao answer...... There's nothing stopping you from linking DAO's together to give you one single DTO. It's easier then have a DTO connected to a DAO. It's not really a service layer it's just building blocks of DAO's. So you might have a PersonDao and a TelephoneNumberDao. A person can have more then one telephone number so you could also have PersonModelDAo that uses PersonDao and TelephoneNumberDao under the hood to do it's work. Alternatively avoid the whole problem and don't try to map the 1-N between person and telephone number at the DTO level. Just have your UI make the right calls to the right DAO's. I actually like this better when using DTO's. I like this answer (+1) it's a shame to lose the clarity of person.getTelephoneNumbers()  It's common to introduce a service layer that wraps your DAOs and handles concerns such as that. If you're afraid you are putting too much boilerplate code into your DTOs to handle lazy loading perhaps using AOP could be a way to achieve this. You might want to look into AspectJ and weaving either at compile-time or load-time. Since you would be modifying the byte-code directly you wouldn't have to worry about the performance overhead of proxy-based AOP.
260,A,Why can't I access column data by integer from executeQuery obj? I'm a two day newbie in both NetRexx and Java. I tried to modify the IBM red book examples to create a multi-threaded tcp server that executes SQL on a firebird database. The first attempt is here http://www.compkarori.co.nz:8000/NetRexx/JDBC-bridge.nrx When I try to loop thru the column data loop col=1 to nbr_columns say 'Column' col -- say rs.getString(col) -- gives error Message: Column name 1 not found in result set. if buffer = '' then buffer = rs.getString(column_name).trim() else buffer = buffer || '|' || rs.getString(column_name).trim() end I get an error as in the code comments if I use the loop counter as the index viz: rs.getString(col) and so I am resorting to using the columnname. But if I do this: say rs.getString(1) it's fine. Is this because col is a Rexx string and not a Java integer or something? Also I have to close the socket and thread after each query otherwise I don't get any response back. Is this necessary or can I somehow leave the thread running to accept new queries? ( ps: can someone add a NetRexx tag?? ) Solved it. Need to force the compiler to recognise the integer value `say rs.getString(int col)` Still wondering though about whether I can re-use the thread/socket. The getString method is overloaded which is why I need to force the int value. And I figured out on how to reuse the thread and socket .. noting that only the Oracle and Firebird/Interbase JDBC connection objects appear to be thread safe. I'd submit an answer to this and then check it off (after a couple of days). Otherwise folks come thinking you are still looking for an answer. The getString method is overloaded which is why I need to force the int value. And I figured out on how to reuse the thread and socket .. noting that only the Oracle and Firebird/Interbase JDBC connection objects appear to be thread safe
261,A,"Interrupt/Cancel a stuck connect() call Sometimes when I call connect() on a third-party proprietary JDBC driver it never returns and a stack trace shows that it is stuck waiting for a socket read (usually). Is there a generic way to forcibly cancel this operation from another thread? It's a blocking I/O call so Thread.interrupt() won't work and I can't directly close the socket because I don't have access to it since it's created inside the proprietary code. I'm looking for generic solutions because I have a heterogeneous DB environment (Oracle MySQL Sybase etc). But driver-specific suggestions are also welcome. Thanks At least one JDBC driver (not one of those you listed though) will cleanly close the connection if the thread this connection attempt is running on is interrupted. I don't know if this will work for all drivers though.  Ah ... the joys of using closed-source libraries ... If interrupt() doesn't work and you cannot set some kind of timeout then I think there is no safe way to do it. Calling Thread.kill() might do the job but the method is deprecated because it is horribly unsafe. And this is the kind of scenario where the unsafe-ness of Thread.kill() could come back and bite you. I suggest that you simply code your application to abandon the stuck thread. Assuming that your application doesn't repeatedly try to connect to the DB a stuck thread isn't a huge overhead. Alternatively use a better JDBC driver. (And on your way out of the door complain to the supplier about their driver being too inflexible. There is a slight chance that someone might listen to you ...) That's one option I've played with but it actually amounts to the same thing as abandoning the thread because Thread.stop() doesn't affect blocking I/O operations.  There is no standard JDBC interface to set connection or read timeouts so you are bound to use proprietary extensions if the JDBC driver supports timeouts at all. For the Oracle JDBC thin driver you can e.g. set the system properties ""oracle.net.CONNECT_TIMEOUT"" and or ""oracle.jdbc.ReadTimeout"" or pass a Properties instance to DriverManager.getConnection with these properties set. Although not particulary well documented the Oracle specific properties are listed in the API documentation. For other JDBC drivers the documentation should contain the relevant references.  This is a problem with Java not the JDBC driver. In certain circumstances the socket connect call ignores the timeout parameters and can take minutes to return. This happens to us when firewall blocks the port. It happens to all TCP connections (HTTP RMI). The only solution I find is to open connection in a different thread like this private static final ExecutorService THREADPOOL = Executors.newCachedThreadPool(); private static <T> T call(Callable<T> c long timeout TimeUnit timeUnit) throws InterruptedException ExecutionException TimeoutException { FutureTask<T> t = new FutureTask<T>(c); THREADPOOL.execute(t); return t.get(timeout timeUnit); } try { Data data = call(new Callable<Data>() { public Data call() throws Exception { // Open connection get data here return data; } 2 TimeUnit.SECONDS); } catch (TimeoutException e) { System.err.println(""Data call timed-out""); } I'll try that. I can't just abandon the main thread because it's in the managed pool of a servlet container but this should work."
262,A,"Java - saving data in BLOB file i want to save a lot of binary data files(pdf images office docs...) into one single ""blob"" file. now i'm not sure what is better saving stuff with java Serializable and save things to disc or to use a database like sqlite to make things happen. or is there a third maybe better way? my question is how well do those methods perform in terms of access speed and data-integrety. in this one single blob file there will be one day maybe a hundreds of pdf files in. what way would you prefer? This method to get your binary file or it bytes from your data base static void BackfileToDecktop(String s) { File outFile=new File(""URL"");//example (C:\\Users\\osama\\Desktop) search(4);//search the file in data base to fetch it try{ FileOutputStream fos=new FileOutputStream(outFile); byte[]l=columnByte;//column of bytes come by search method get it from database by its primary key for(int i=0;i<l.length;i++) { fos.write(l[i]); } if(fos!=null) { fos.close();//write all file bytes } JOptionPane.showMessageDialog(null""File was fetched successfully""""Untitled pane""JOptionPane.INFORMATION_MESSAGE); } catch(java.io.IOException e){ System.err.println(e); } }  Assuming you want to create one big file (and not some kind of database entry) you might want to use the java.util.zip package to create a ZIP file of those PDFs preferably uncompressed (because it's faster and PDFs usually don't compress well). By doing that you can easily use third-party-tools to extract those PDFs from your ""blob file"" i.e. zip archive.  Definitely don't use java.io.Serializable. Just write binary data as-is to its target. Serializing would only add unnecessary overhead and would make the saved data unusable for other tools than Java. I also wouldn't push it all in a single field in a single row. It makes it all tight coupled and storing/retrieving the individual entries may be more expensive. Rather store each in its own row. You can if necessary link/reference the one and other by another column with a foreign key. Now the Java code the JDBC API offers PreparedStatement#setBinaryStream() to save binary data in flavor of an InputStream into the database. There's also the setBytes() method for the case you've it in a (memory hogging) byte[]. Then to retrieve it you can just use either ResultSet#getBinaryStream() or getBytes(). You can on the other hand also just store those files in the local disk file system the usual Java IO way using FileOutputStream and read them using FileInputStream. You can if necessary store file paths/names in the database. This decouples the binary data from the database which makes it less portable but better reuseable for other purposes. See also JDBC PreparedStatement tutorial Java IO tutorial"
263,A,"Eclipse JPA project - defining connection to Oracle RAC Recently I wanted to play a bit with Eclipse and JPA. Thus I wanted to create a JPA project. I got stuck when specifying the database connection as editing the ""Connection URL"" (shown on the image) is not possible and I want to enter a (good working) connection string to an Oracle RAC server which looks more or less like that: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS= (PROTOCOL=TCP) (HOST=... Am I doing something obviously wrong? Or is it a ""feature"" of the Data Source Explorer? See Oracle's FAQ for syntax of the database connection string. It is not the problem of the JDBC syntax (well to some point it is as Eclipse forces me to stick with the @:: format). As I have said I have a good connection string in a given format and would like to use it with Eclipse DataSource. Found a blog comment that suggests the following syntax: `jdbc:oracle:thin:@host1^host2:1521:service_name` (see http://www.jugpadova.it/articles/2007/04/11/jdbc-url-for-oracle-rac). Other than that I'm out of ideas... Good luck! If Eclipse doesn't allow you to edit the Connection URL field why not specify the SID/Host/Port number/User name/Password fields separately? If I understand correctly you should be able to extract those parameters from your good connection string. No I cannot this will not work for RAC (at least in my setup). Answered proved to be pretty trivial. I have added the Oracle Thin driver as the 'Other Driver'. After that I was ably to put any connection string I wanted for the connection using this driver."
264,A,DB.Null equivalent in JDBC Is there an equivalent of (ADO.NET) DB.Null in JDBC? Or do I simply pass null in the parameter? Particularly in the context of Mysql? You use PreparedStatement.setNull(). To set a parameter in a PreparedStatement object to null.
265,A,"best practices for using sqlite for a database queue I am using an sqlite database for a producer-consumer queue. One or more producers INSERT one row at a time with a new autoincremented primary key. There is one consumer (implemented in java uses the sqlite-jdbc library) and I want it to read a batch of rows and delete them. It seems like I need transactions to do this but trying to use SQLite with transactions seems to not work right. Am I overthinking this? If I do end up needing transactions what's the right way to do this in Java?  Connection conn; // assign here boolean success = false; try { // do stuff success = true; } finally { if (success) conn.commit(); else conn.rollback(); } See this trail for an introduction on transaction handling with Java JDBC. As for your use case I think you should use transactions especially if the consumer is complex. The tricky part is always to decide when a row has been consumed and when it should be considered again. For example if you have an error before the consumer can actually do its job you'll want a rollback. But if the row contains illegal data (like a text in a number field) then the rollback will turn into an infinite loop.  Normally with SQLite there are explicit (not implicit!) transactions. So you need something like ""START TRANSACTION"" of course it could be that your Java binding has this incorporated -- but good bindings don't. So you might want to add the necessary transaction start (there might be a specialiced method in your binding). Hi Jason at least you need BEGIN TRANSACTION (in some libs there are specialiced methods to do this). END TRANSACTION should be in result the same like COMMIT. that seems to do it; when I execute ""BEGIN TRANSACTION"" and ""END TRANSACTION"" SQL statements instead of using JDBC's commit/rollback functions it seems to work properly."
266,A,"Why does JDBC driver pad some blank characterS other a queried field from an Oracle Database? So here is the code which create the table in an Oracle 10g / UTF-8 database : CREATE TABLE TEST_SEMANTIC ( SEMANTIC_COLBYTE char(2 byte)  SEMANTIC_COLCHAR char(2 char) ); meaning that I use two differents types of semantic for the two columns byte and char. I then insert inside the database these corresponding data : insert into test_semantic(SEMANTIC_COLBYTESEMANTIC_COLCHAR) values('é''é'); So when I use the JDBC driver to query the database in a java program and display the result I expect an output like this : Byte>é< Char>é< Whereas I get this : Byte>é< Char>é < When I query the database like this : select dump(semantic_colbyte16)dump(semantic_colchar16) from test_semantic; I get this : Typ=96 Len=2: c3a9 Typ=96 Len=3: c3a920 Here is the java code : public static void main(String[] args){ Connection con = null; try { Class.forName(""oracle.jdbc.driver.OracleDriver""); } catch (java.lang.ClassNotFoundException e) { System.err.print(""ClassNotFoundException:""); System.err.println(e.getMessage()); } try { Properties props = new Properties(); props.put(""user"" ""XXX""); props.put(""password"" ""XXX""); con = DriverManager.getConnection(""jdbc:oracle:thin:@xxx:1521:xxx"" props); Statement stmt = (Statement) con.createStatement(); stmt.execute(""SELECT SEMANTIC_COLBYTESEMANTIC_COLCHAR FROM TEST_SEMANTIC""); ResultSet result = stmt.getResultSet(); result.next(); String output_byte = result.getString(1); String output_char = result.getString(2); System.out.println(""Byte>""+output_byte+""<""); System.out.println(""Char>""+output_char+""<""); } catch (SQLException ex) { System.err.println(""SQLException: "" + ex.getMessage()); } } Have you already read the Oracle documentation on Oracle length semantics for character datatypes? http://download.oracle.com/docs/cd/B19306%5F01/server.102/b14220/datatype.htm#sthref3787 yes of course It seems to me that my question imply the understanding of Oracle length semantics. Just checkin' and others who find this question in search of an answer to a problem they've got have might not have read it.  Which characterset is the database (and your session) actually in. Mine was in AL32UTF8 and wouldn't accept 'é' in a 2 byte CHAR field. In a 4 byte field it went to Typ=96 Len=4: efbfbd20 A UTF-8 character can be four bytes and therefore the CHAR(2 char) can be up to eight bytes. So I could understand a string of length 8 coming out. Seven is a bit odd almost like it was told the first character is three bytes and the second character can be up to four. Can you play with ResultSetMetaData (eg getColumnDisplaySize getColumnTypeName) and see what comes out. Not seven bytes - seven characters. The é will be two bytes. The remaining 6 bytes are padding - space characters taking one byte each. Given that the dump function shows only 3 bytes though this does look like a problem with the JDBC driver as Vinegar has suggested. Don't know how you got to ef bf bd. That's U+FFFD the replacement character for characters that are unknown or unrepresentable. My database is in UTF-8 charset  Don't forget to trim your values while using char. Or don't use char use varchar2 until you are providing the exact sized value as the column size. You might want to know why so here it is. Ah! I got your point. Sorry for misunderstanding. The value is from the driver actually. So this the way driver implemented it. Can't be done much trimming the value is your best bet. BTW is your SQL client is also Java based? Exactly which version of ojdbc14.jar? Yep as far as I know SqlDevelopper is java based but I don't know which driver it uses. What jar are you using? Try ojdbc5 or ojdbc6. Or if nothing work then you might want to try OCI drivers. I suppose SQL Developer uses the same as they are having platform specific downloads for SQL Developer and OCI suits stand-alone apps. Just got to know that it uses Thin Driver by default (http://www.oracle.com/technology/obe/sqldev/plsql_debug/plsql_debug.htm). Anyways try other latest drivers or the same driver used by SQL Developer. You might look for that into its `lib` directory. Good idea I'm going to check if it can solve my problem by using the same driver as Sql Developper Actually I use the ojdbc14.jar Thanks for your answer and the link. Actually I know the difference between char and varchar2. And the corresponding string I store in database is not variable but predefined on 2 character but in UTF-8 semantic (under Oracle). More precisely my question is : By knowing the UTF-8 rule to convert non ascii char(http://fr.wikipedia.org/wiki/UTF-8) why does my java program don't give me a least : >é < with one blank char (the output I get by querying the database using sqlDevelopper for instance) but give me >é < 6 blanks ? Ok the problem is the driver ojdbc14.jar ==> when using this one I Get >é < instead of >é< When I use either ojdbc5.jar or ojdbc6.jar driver it gets me the same results as in SqlDevelopper: >é < Thanks you for the answers  CHAR Datatype: The CHAR datatype specifies a fixed-length character string. Oracle ensures that all values stored in a CHAR column have the length specified by size. If you insert a value that is shorter than the column length then Oracle blank-pads the value to column length. So why six spaces?"
267,A,"INSERT SQL in Java I have a Java application and I want to use SQL database. I have a class for my connection :  public class SQLConnection{ private static String url = ""jdbc:postgresql://localhost:5432/table""; private static String user = ""postgres""; private static String passwd = ""toto""; private static Connection connect; public static Connection getInstance(){ if(connect == null){ try { connect = DriverManager.getConnection(url user passwd); } catch (SQLException e) { JOptionPane.showMessageDialog(null e.getMessage() ""Connection Error"" JOptionPane.ERROR_MESSAGE); } } return connect; } } And now in another class I succeeded to print my values but when I attempt to insert a value nothing is happening ... Here's my code :  try { Statement state = SQLConnection.getInstance().createStatement(ResultSet.TYPE_SCROLL_INSENSITIVEResultSet.CONCUR_READ_ONLY); Statement state2 = SQLConnection.getInstance().createStatement(ResultSet.TYPE_SCROLL_INSENSITIVEResultSet.CONCUR_UPDATABLE); state2.executeUpdate(""INSERT INTO table(field1) VALUES (\""Value\"")""); // Here's my problem ResultSet res = state.executeQuery(""SELECT * FROM table""); I wonder why and how you tagged this as `prepared-statement` while you aren't using it in your code at all (you *should* however do). Copuld just be a copy over to SO error but looking but shoulding INSERT INTO table(field1) be INSERT INTO plateau(field1)? Yes sorry I modified my code just for stackoverflow . The error is not that ;) (I edited my code)  state2.executeUpdate(""INSERT INTO table(field1) VALUES (\""Value\"")""); should be: state2.executeUpdate(""INSERT INTO plateau(field1) VALUES (\""Value\"")""); Yes sorry I modified my code just for stackoverflow . The error is not that ;) (I edited my code)  You need to commit (and close) the connection (and statement) after use. You also need to ensure that you aren't swallowing any SQLExceptions which may cause that you see ""nothing"" to happen. That said private static Connection connect; This is a terribly bad idea. You should never declare external resources as static in your application. Your application will break when the other side decides to close the resource because it's been released for a too long time. You really need to acquire and close those resources (Connection Statement and ResultSet in the shortest possible scope. I.e. inside the very same method block as where the query is to be executed. Also I strongly recommend to use PreparedStatement instead of Statement since that will prevent your code from SQL injection attacks. You may find this article useful to learn more about how to do basic JDBC interaction the right way. Default is for autocommit to be on. Unless you override it there's no need to do commit call. Close is also not strictly necessary (since it'll close on it's own anyways eventually) but it IS a best practice. @Brian: In the years I've done JDBC I've learnt that there are only 2 possible causes for a query not being executed. 1) Connection is not committed. 2) An exception is swallowed. The OP might not have posted all the necessary information in the question (also see the other answers they were based on misinformation from the OP)."
268,A,"JDBC and MS-Access problem I'm trying to connect to an MSAccess database and retrieve some data. With simple examples all runs well but if i'm going to use some where clauses i get no data. This example is ok: PreparedStatement stm = con.prepareStatement(""SELECT A.* FROM A""); ResultSet rs = stm.executeQuery(); rs.next(); The next example get no rows: PreparedStatement stm = con.prepareStatement(""SELECT A.* FROM A WHERE (((A.Name) LIKE ?))""); stm.setString(1""*""); ResultSet rs = stm.executeQuery(); rs.next(); I don't know where the error lies: in the driver or in the sql syntax. The sql statement is taken from the query builder in MSAccess. All what is a little bit more complex in a where clause is a really hard to figure out. Is there any documentation reagrding sql syntax of MSAccess ? Update Yes in the jdbc sql statement i have to use ""SQL standard"" % wildcard while the Access sql builder is using *. Now going to query with dates =8-o For the like statement to work you have to put the parameter between %: PreparedStatement stm = con.prepareStatement(""SELECT A.* FROM A WHERE (((A.Name) LIKE ?))""); stm.setString(1""%like text%"");  Do you by any chance mean the SQL wildcard character '%' instead of '*' or are you literally looking for the character '*'?"
269,A,Problem with not closing db connection while debugging? I have a Java app that opens a connection to a database at the beginning and closes it at the end. However the program doesn't always finish because an exception is thrown or I am debugging it and stop it halfway through. Will this cause open connections to pile up and slow the database or will it be cleaned up automatically? Nope. If your program continues and your connections is alive then the BD simply rejected your sentence. If something happened with your connection (by example a timeout) then the BD was who closed that connection and it's not consuming resources. If you released your connection and the garbage collector was called (it can be a while) the connection will close itself before get freed. If your program terminated without closing your connection then all the (operating system) process will release its native resources and between them the native resource that connected to the BD (probable a network socket). The BD will then receive the connection aborted/closed and release your connection. The only thing that could happen is that one only execution would connect many times to the BD and do things very bad to keep them open ocuppying all the connections available. But it's not your case I think. Edit: in general BD's are made bad-client-behavior-proof  A database Connection is owned and managed by the database the class just gives you access to that database resource. If you don't close the connection then the Java class may be garbage collected but the database may not be able to tell that the connection is no longer in use which may result in database resources being wasted (until a timeout on the database side) or even leak. So when you're done with using your Connection you should be sure to explicitly close it by calling its close() method. This will allow the garbage collector to recollect memory as early as possible and more important it releases any other database resources (cursors handles etc) the connection may be holding on to. The traditional way to do this in Java is to close your ResultSet Statement and Connection (in that order) in a finally block when you are done with them and the safe pattern looks like that: Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { // Do stuff ... } catch (SQLException ex) { // Exception handling stuff ... } finally { if (rs != null) { try { rs.close(); } catch (SQLException e) { /* ignored */} } if (ps != null) { try { ps.close(); } catch (SQLException e) { /* ignored */} } if (conn != null) { try { conn.close(); } catch (SQLException e) { /* ignored */} } } The finally block can be slightly improved into (to avoid the null check): } finally { try { rs.close(); } catch (Exception e) { /* ignored */ } try { ps.close(); } catch (Exception e) { /* ignored */ } try { conn.close(); } catch (Exception e) { /* ignored */ } } But still this is extremely verbose so you generally end up using an helper class to close the objects in null-safe helper methods and the finally block becomes something like that: } finally { DbUtil.closeQuietly(rs); DbUtil.closeQuietly(ps); DbUtil.closeQuietly(conn); } And actually the Apache Commons DbUtils has a DbUtils class which is precisely doing that so there is no need to write your own. In your case this will solve the problem of the exception but not the debugging one (and you will waste database resources until the timeout occur on the database side). So 1. don't debug your code using a production database 2. try to execute your debug session until the end. The guys at Sun were INSANE when they decided to not have destructors. It was way easier to close any open resources in destructors like in C++. Now just look at all that garbage we need to write for just a small database query... It should have been done in 3 lines of code: connect to db execute query get result.  Your db server will have a timeout setting. It will close the connection and roll back any uncommitted transactions. This has been happening for decades on any production capable db product. If you want to do it properly use a try { ..your code..} finally { ..close connections..} Plus most DB protocols ping the other side to see whether it's alive.  Here's what Sun (err...Oracle?) says: It is recommended that programmers explicitly close connections and statements they have created when they are no longer needed. A programmer writing code in the Java programming language and not using any outside resources does not need to worry about memory management. The garbage collector automatically removes objects when they are no longer being used and frees the memory they were using. When memory is running low it will recycle discarded objects making the memory they currently occupy available for quick reuse. However if an application uses external resources as it does when it accesses a DBMS with the JDBC API the garbage collector has no way of knowing the status of those resources. It will still recycle discarded objects but if there is lots of free memory in the Java heap it may garbage collect infrequently even though the (small) amount of Java garbage is holding open large amounts of expensive database resources. Therefore it is recommended that programmers explicitly close all connections (with the method Connection.close) and statements (with the method Statement.close) as soon as they are no longer needed thereby freeing DBMS resources as early as possible. This applies especially to applications that are intended to work with different DBMSs because of variations from one DBMS to another. I would put the database access in a try block and make sure to close all statements and connections in a finally block.
270,A,"Different results from .mdb vs .odb why? I use the following query to retrieve data from a .mdb file through JDBC however when I try it on an .odb file it goes does not throw any exceptions but there are no results at all. I am wondering is .odb case sensitive where .mdb is not or is there something else I am missing? ""SELECT DISTINCT column-one + ':' + column-two As ResultColumn FROM datatable;"" How can I go about creating one statement that will work on both these file types? Some suggestions: 1) Try using single quotes in place of double quotes e.g. SELECT DISTINCT column-one + ':' + column-two As ResultColumn FROM datatable; 2) Perhaps the .odb source's SQL syntax handles concatenation differently e.g. with the .mdb the '+' NULLs will propagate meaning that if at least one the the column's values is NULL then the result will be NULL; the '&' concatenation symbol will ignore NULL values e.g. this in .mdb land SELECT DISTINCT column-one & ':' & column-two As ResultColumn FROM datatable; is equivalent to this in Standard ANSI/ISO SQL-92 (which isn't supported in .mdb land) SELECT DISTINCT COALESCE(column-one '') + ':' + COALESCE(column-two '') As ResultColumn FROM datatable; 3) If the two sources do not support the same syntax can you use the .mdb's linked table functionality to link the tables(s) from the .odb source in the .mdb and only use the SQL code in the .mdb? ""&"" token not recoginized in odb land  They would be differnt because they are two differnt products written by two differnt companies and the programmers made different choices as to how to handle things. Have you tried using a column alias you specify perhaps something more descriptive than Expr1000? SELECT DISTINCT column-one + "":"" + column-two As Expr1000 FROM datatable That's how I would write it in SQL Server check your database to see if this would work. worsk now for both thank you that works for the mdb but not for the odb and have modified the original question to reflect this thank you."
271,A,"How should I connect to a MySQL data source from Eclipse? I have an external MySQL server that's set up and working fine. I created a database connection in Eclipse and can view the database in the Data Source Explorer tab. Now I have a servlet that needs to access that database. How do I do it? Is there a way to reference that database connection created in the data source explorer or do I have to define everything twice? Also what's the best way to open the connection? I've got the mysql-connector-java-5.1.11-bin.jar file included and I've found two methods that work: MysqlDataSource d = new MysqlDataSource(); d.setUser(""user""); d.setPassword(""pass""); d.setServerName(""hostname.com""); d.setDatabaseName(""db""); Connection c = d.getConnection(); and Connection c = DriverManager.getConnection(""jdbc:mysql://hostname.com/db""""user""""pass""); Neither is optimal because first of all they both use hard-coded strings for everything. This is a J2EE web app project so is there a good place to put connection data? Or is there a way to forgo all that and just use the connection in the data source explorer? You could set up a data source in whatever app server you're deploying your WAR to and fetch a reference to it with JNDI. Or you could package your WAR in an EAR and define the data source in the EAR's data-sources.xml file (and fetch a reference to it with JNDI).  A common practice is to configure this as a DataSource in the webserver in question. It will provide you connection pooling facilities which will greatly improve performance. Also a common practice is to externalize the raw settings in some configuration file which is been placed in the classpath. It's unclear which webserver (servletcontainer/appserver) you're using so I'll just give a Tomcat example. You need to configure the datasource as per the webserver-supplied JNDI documentation. In case of Tomcat it's here: JNDI Resources HOW-TO. You'll see that there are several ways. Easiest way is to create a /META-INF/context.xml in the webcontent of your dynamic web project (to be clear the /META-INF is at the same level as the /WEB-INF of the webapp) and fill it with something like: <?xml version=""1.0"" encoding=""UTF-8""?> <Context> <Resource name=""jdbc/db"" type=""javax.sql.DataSource"" maxActive=""100"" maxIdle=""30"" maxWait=""10000"" url=""jdbc:mysql://hostname.com/db"" driverClassName=""com.mysql.jdbc.Driver"" username=""user"" password=""pass"" /> </Context> This roughly means that the webapplication context should create a datasource with the JNDI name jdbc/db with a maximum of 100 active connections a maximum of 30 idle connections and a maximum wait time of 10000 milliseconds before a connection should be returned from your application (actually: closed by your application so your application has 10 seconds time between acquiring the connection and closing the connection). The remnant of the settings should be familiar and self-explaining enough to you; those are the JDBC settings. Finally in your web project edit the file /WEB-INF/web.xml to add the following entry: <resource-env-ref> <resource-env-ref-name>jdbc/db</resource-env-ref-name> <resource-env-ref-type>javax.sql.DataSource</resource-env-ref-type> </resource-env-ref> This roughly means that the webapplication should use the datasource with the name jdbc/db. Then change your connection manager to something like this: private DataSource dataSource; public Database(String jndiname) { try { dataSource = (DataSource) new InitialContext().lookup(""java:comp/env/"" + jndiname); } catch (NamingException e) { // Handle error that it's not configured in JNDI. throw new SomeRuntimeException(jndiname + "" is missing in JNDI!"" e); } } public Connection getConnection() { return dataSource.getConnection(); } ..and replace all DriverManager.getConnection() calls by new Database(""jdbc/db"") and use database.getConnection() to acquire the Connection. You can obtain the value jdbc/db from some config file (Properties file?). That should be it. Just deploy your webapplication with the above changes and run it. Don't forget to place the database JDBC driver in the Tomcat/lib or to add its path to the shared.loader property of Tomcat/conf/catalina.properties because the responsibility of loading the driver is now moved to Tomcat. For more hints and other basic JDBC/JNDI examples you may find this article useful as well. This looks very helpful. Just two more questions. 1: I don't know if this is just me or it's normal but there's no tomcat/lib directory there are several lib directories at common/lib server/lib and shared/lib. Which should my jar go into? And Question 2: Will this handle connection pooling as it is set up here? Should I call close() on the connection returned from getConnection() after each use? 1) You're apparently using the 6~8-year old Tomcat 5.x. Upgrade to Tomcat 6.0 if you can (strongly recommend) or grab Tomcat 5.x's `/shared/lib`. 2) Yes it will handle connection pooling. And yes you should ALWAYS call `close()` in `finally`. The connection pooling implementation will itself worry about closing or releasing. Also check the last chapter of the lastmentioned link. @BalusC I have a question though the post is bit old. Are there anyways to make the password encrypted? In context.xml password is clear text so anyways to integrate datasource creation with web application in Eclipse?"
272,A,"How to make a database service in Netbeans 6.5 to connect to SQLite databases? I use Netbeans IDE (6.5) and I have a SQLite 2.x database. I installed a JDBC SQLite driver from zentus.com and added a new driver in Nebeans services panel. Then tried to connect to my database file from Services > Databases using this URL for my database: jdbc:sqlite:/home/farzad/netbeans/myproject/mydb.sqlite but it fails to connect. I get this exception: org.netbeans.modules.db.dataview.meta.DBException: Unable to Connect to database : DatabaseConnection[name='jdbc:sqlite://home/farzad/netbeans/myproject/mydb.sqlite [ on session]'] at org.netbeans.modules.db.dataview.output.SQLExecutionHelper.initialDataLoad(SQLExecutionHelper.java:103) at org.netbeans.modules.db.dataview.output.DataView.create(DataView.java:101) at org.netbeans.modules.db.dataview.api.DataView.create(DataView.java:71) at org.netbeans.modules.db.sql.execute.SQLExecuteHelper.execute(SQLExecuteHelper.java:105) at org.netbeans.modules.db.sql.loader.SQLEditorSupport$SQLExecutor.run(SQLEditorSupport.java:480) at org.openide.util.RequestProcessor$Task.run(RequestProcessor.java:572) [catch] at org.openide.util.RequestProcessor$Processor.run(RequestProcessor.java:997) What should I do? :( It's againg me... I have made two mistakes during my first attempt. After setting CLASSPATH as a system variable (hope I didn’t broke smth else :)) putting sqlite_jni.dll to the system32 folder and correcting JDBC url I have got a success :) I also have downloaded their SQLite ODBC wrapper. Installed it and made a connection to my SQLite2 database via ordinary and UTF8 based ODBC driver. I also used built in NetBeans JDBC-ODBC Bridge driver to be able to set up this connection. All three connections have been created but: ordinary ODBC driver: I see text data in a wrong encoding. All other columns are displayed correctly UTF8 ODBC driver: I don’t see text data at all. All other columns are displayed correctly JDBC driver: I don’t see any column at all. ""Select * from my_any_table"" always returns an empty single column I have Russian based data in my database. So...currently I have returned to sqlite command line interface :))  The current version of Zentus SQLiteJDBC is v053 based on SQLite 3.6.1. It will not open a 2.x SQLite database. Perhaps you can use SQLite 2.x command line tool to .dump your database and the Sqlite3 command line tool to .load it. The use Zentus SQLiteJDBC to access the new SQLite 3.x database. Alternatively use a JDBC driver that supports SQLite 2 such as this one."
273,A,"Where to keep large SQL queries when using Spring's JdbcTemplate classes I'm developing a DAO using Spring JdbcDaoSupport and would like to know if anyone can suggest best practice for externalizing the SQL from the Java code. I'm used to using Hibernate and iBatis for this kind of project and like the way that the queries are not held in the Java code. Due to the complexity of the data access (accessing different DBs on different servers) I cannot use a framework like Hibernate/JPA/iBatis in this project and feel that JDBC is a much better fit anyway. I've considered injecting the queries but this would lead to horrible Spring config files and my Unit test configs would become a burden to manage. I don't really want to write a XML parser just for this and property files get a bit messy when values are split across multiple lines. Any suggestions? How about using JPA annotations to store the (more complicated) queries as named queries on the domain objects? @Entity @Indexed @NamedQueries( @NamedQuery(name = ""MyDomainObject.myNamedQuery"" query = ""select id from MyDomainObject where myProperty.id = :propertyId"") ) public class MyDomainObject { ... } I can't use a persistence framework or I'd have done something like this.  You can use native SQL queries with Hibernate. See here Otherwise you can store your queries in .properties file(s) and load them in a application-wide Map which you can inject into your beans. You can also use some XML format of your choice and parse it easily with commons-configuration. I've used a PropertiesFactoryBean to load the properties file and inject it into my DAO."
274,A,"JDBC - Resultset data processing : Strange behaviour : default fetchsize returned I have a oracle(10.2) PLSQL procedure which fetches 15 records from a table in a sysrefcursor. I then pass this cursor to a java class as a resultset. This java class is loaded to oracle. Driver name : Oracle JDBC driver Driver Version : 10.2.0.1.0 Driver Major Version : 10 Driver Minor Version : 2 Observations: 1 Inside the java class when I iterate through the resultset I get only the first 10 records. 2 If the cursor fetched (20 or more records) or (10 or less) I could get all the records while iterating the resultset. 3 I found that the default fetchsize for the resultset is 10. If I change the fetchSize to 5 and the cursor fetches 8 records I could get the first 5 records while iterating the resultset. 4 If the cursor fetched (10 or more records) or (5 or less) I could get all the records while iterating the resultset. 5 If I change the resultset fetchSize to 1 I could get all the records in the resultset no matter how many records are fetched by the cursor. Why is the resultset behaving weirdly? public static BLOB createZip(BLOB prevBlob String outPrefix ResultSet entries ResultSet rs Long[] resultRows) throws Exception { OracleConnection conn = null; BLOB retBLOB = null; int page = 1; int curRow = 0; long totalRows = 0; try { conn = (OracleConnection) new OracleDriver().defaultConnection(); ArrayList entryList = loadEntries(entries); retBLOB = BLOB.createTemporary(conn true BLOB.DURATION_SESSION); retBLOB.open(BLOB.MODE_READWRITE); OutputStream bOut = retBLOB.setBinaryStream(0L); ZipOutputStream zipOut = new ZipOutputStream(bOut); PrintStream out = new PrintStream(zipOut); zipOut.putNextEntry(new ZipEntry(outPrefix + ""-p"" + page + "".csv"")); writeHeader(out entryList); while (rs.next()) { curRow++; totalRows++; if (curRow >= maxPageSize) { zipOut.closeEntry(); page++; zipOut.putNextEntry(new ZipEntry(outPrefix + ""-p"" + page + "".csv"")); writeHeader(out entryList); curRow = 0; } for (int i = 0; i < entryList.size(); i++) { Entry e = (Entry) entryList.get(i); if (i != 0) { out.print(""""); } if (e.isEscape()) out.print(""\"""" + escapeExcel(rs.getString(e.getColumn())) + ""\""""); else out.print(""\"""" + emptyExcel(rs.getString(e.getColumn())) + ""\""""); } out.println(); } if (totalRows == 0) { out.println(""\""No Entries Found\""""); } resultRows[0] = new Long(totalRows); out.flush(); zipOut.closeEntry(); if (prevBlob != null) { byte[] buf = new byte[1024]; InputStream bIn = prevBlob.binaryStreamValue(); ZipInputStream zipIn = new ZipInputStream(bIn); ZipEntry inEntry = zipIn.getNextEntry(); while (inEntry != null) { zipOut.putNextEntry(new ZipEntry(inEntry.getName())); int len; while ((len = zipIn.read(buf)) > 0) { out.write(buf 0 len); } inEntry = zipIn.getNextEntry(); } zipIn.close(); try { prevBlob.freeTemporary(); } catch (SQLException e) { } } zipOut.close(); retBLOB.close(); return retBLOB; } catch (Exception sex) { if (retBLOB != null) { try { retBLOB.freeTemporary(); } catch (SQLException e) { } } throw sex; } finally { try { entries.close(); } catch (SQLException sex) { } try { rs.close(); } catch (SQLException sex) { } try { if (conn != null || !conn.isClosed()) { conn.close(); } } catch (SQLException ex) { ex.printStackTrace(); } } } If I fetch the value using the column index it works fine rs.getString(index). But if I try to fetch even the column name then the issue surfaces.rs.getMetaData().getColumnName(j) Looks complex but okay... Does this also happen when you remove all other code (opening another connection creating a blob reading from the second result set) except the loop over rs (and maybe rs.getString in the loop)? You were right. Thanks. It behaved normally without the 'other codes'. Let me debug more into it. *Why is the resultset behaving weirdly?* statistically it is a lot more likely that you have a bug in your code and that the ResultSet is behaving as intended. Can you share a sample of your code ? If I have rs.getString(e.getColumn()) in my code then the issue crops up. Otherwise its fine. I have shared the code. It doesn't look like I m doing something wrong. There is a workaround. I fetched the column index before while(rs.next()). The below snippet works absolutely fine for me. But I still fail to understand why resultSet.getString(columnName); failed inside while(rs.next()).  ArrayList entryList = loadEntries(entries); int[] colIndx = new int[entryList.size()]; ResultSetMetaData rsmd = rs.getMetaData(); int numberOfColumns = rsmd.getColumnCount(); for (int i = 0; i < entryList.size(); i++){ Entry e = (Entry) entryList.get(i); for (int j = 1; j <= numberOfColumns; j++){ if(rsmd.getColumnName(j).equalsIgnoreCase(e.getColumn())) colIndx[i] = j; } } try{ while (rs.next()){ for (int i = 0; i < colIndx.length ; i++){ System.out.println(""Column Values[""+colIndx[i]+""] : ""+rs.getString(colIndx[i])); } } } It seems strange indeed. You may have found a bug. By any chance does the cursor have two columns with the same name ? No all the column names are unique. If it were easy to do that I'd say file a bug with Oracle."
275,A,Invoking a PL/SQL function from EclipseLink I'm trying to execute a PL/SQL function in EclipseLink which uses Oracle Specific types(eg. Boolean). I've tried using PLSQLStoredProcedureCall which complains that I'm not executing a procedure and I have tried using StoredFunctionCall but that returns PLS-00382: expression is of wrong type Has anyone developed a solution to invoke functions in EclipseLink with Oracle Types? I have heard that it would be possible to extend StoredFunctionCall but I'd rather leverage existing functionality as much as possible. When did Oracle add a Boolean data type? I'm not sure but I have plenty of PL/SQL Functions which are defined to return BOOLEAN. PL/SQL functions can receive or return a BOOLEAN. However these cannot be called from SQL because Oracle SQL doesn't understand the concept of boolean. Since the primary difference between a function and a procedure is that the former can be called from SQL I've never seen the point of a creating a function that receives or returns a boolean. So I'd replace it with a procedure with an out parameter or at least have a wrapper procedure that calls the function.. CREATE OR REPLACE FUNCTION f_x (p_id IN NUMBER) RETURN BOOLEAN IS BEGIN RETURN TRUE; END f_x; CREATE OR REPLACE PROCEDURE p_x (i_id IN NUMBER o_val OUT BOOLEAN) IS BEGIN o_val := f_x(i_id); END p_x;
276,A,"Is it an error of PostgreSQL SQL engine and how to avoid (workaround) it? I'm parsing text documents and inserting them into PostgreSQL DB. My code is written in Java and I use JDBC for DB connectivity. I have encountered very strange error when adding data to DB - it seems that at unpredictable moment (different number of iteration of main loop) Postgres does not see rows just added to tables and fails to perform updates properly. Maybe I am doing something wrong so maybe there is a way to correct my code? Or is it serious error of PostgreSQL and I should post it at PostgreSQL home page (as bug report)? Here are the details of what I'm doing and what is going wrong. I've simplified my code to isolate the error - simplified version doesn't parse any text but I simulate it with generated words. Source files are included (java and sql) at the end of my question. In simplified example of my problem I have one-threaded code one JDBC Connection 3 tables and few SQL statements involved (full Java sources are less than 90 lines). Main loop works for ""documents"" - 20 words with subsequent doc_id (integer). Buffer table spb_word4obj is cleared for doc_id to be just inserted. Words are inserted into buffer table (spb_word4obj) Then unique new words are inserted into table spb_word And finally - document's words are inserted into spb_obj_word - with word bodies replaced by word-ids from spb_word (references). While iterating this loop for some time (e.g. 2000 or 15000 iterations - it is unpredictable) it fails with SQL error - cannot insert null word_id into spb_word. It gets more strange as repeating this very last iteration by hand gives no error. It seems like PostgreSQL have some issue with record insertion and statement execution speed - it loses some data or makes it is visible for subsequent statement after small delay. Sequence of generated words is repeatable - every time code is run it generates the same sequence of words but iteration number when code fails is different every time. Here is my sql code to create tables: create sequence spb_word_seq; create table spb_word ( id bigint not null primary key default nextval('spb_word_seq') word varchar(410) not null unique ); create sequence spb_obj_word_seq; create table spb_obj_word ( id int not null primary key default nextval('spb_obj_word_seq') doc_id int not null idx int not null word_id bigint not null references spb_word (id) constraint spb_ak_obj_word unique (doc_id word_id idx) ); create sequence spb_word4obj_seq; create table spb_word4obj ( id int not null primary key default nextval('spb_word4obj_seq') doc_id int not null idx int not null word varchar(410) not null word_id bigint null references spb_word (id) constraint spb_ak_word4obj unique (doc_id word_id idx) constraint spb_ak_word4obj2 unique (doc_id word idx) ); And here goes Java code - it may just be executed (it has static main method). package WildWezyrIsAstonished; import java.sql.Connection; import java.sql.DriverManager; import java.sql.Statement; public class StrangePostgresBehavior { private static final String letters = ""abcdefghijklmnopqrstuvwxyząćęłńóśźż""; private static final int llen = letters.length(); private Connection conn; private Statement st; private int wordNum = 0; public void runMe() throws Exception { Class.forName(""org.postgresql.Driver""); conn = DriverManager.getConnection(""jdbc:postgresql://localhost:5433/spb"" ""wwspb"" ""*****""); conn.setAutoCommit(true); st = conn.createStatement(); st.executeUpdate(""truncate table spb_word4obj spb_word spb_obj_word""); for (int j = 0; j < 50000; j++) { try { if (j % 100 == 0) { System.out.println(""j == "" + j); } StringBuilder sb = new StringBuilder(); for (int i = 0; i < 20; i++) { sb.append(""insert into spb_word4obj (word idx doc_id) values ('"" + getWord() + ""'"" + i + """" + j + "");\n""); } st.executeUpdate(""delete from spb_word4obj where doc_id = "" + j); st.executeUpdate(sb.toString()); st.executeUpdate(""update spb_word4obj set word_id = w.id "" + ""from spb_word w "" + ""where w.word = spb_word4obj.word and doc_id = "" + j); st.executeUpdate(""insert into spb_word (word) "" + ""select distinct word from spb_word4obj "" + ""where word_id is null and doc_id = "" + j); st.executeUpdate(""update spb_word4obj set word_id = w.id "" + ""from spb_word w "" + ""where w.word = spb_word4obj.word and "" + ""word_id is null and doc_id = "" + j); st.executeUpdate(""insert into spb_obj_word (word_id idx doc_id) "" + ""select word_id idx doc_id from spb_word4obj "" + ""where doc_id = "" + j); } catch (Exception ex) { System.out.println(""error for j == "" + j); throw ex; } } } private String getWord() { int rn = 3 * (++wordNum + llen * llen * llen); rn = (rn + llen) / (rn % llen + 1); rn = rn % (rn / 2 + 10); StringBuilder sb = new StringBuilder(); while (true) { char c = letters.charAt(rn % llen); sb.append(c); rn /= llen; if (rn == 0) { break; } } return sb.toString(); } public static void main(String[] args) throws Exception { new StrangePostgresBehavior().runMe(); } } So again: is it me doing something wrong (what exactly?) or is it serious flaw in PosgreSQL SQL Engine (than - is there a way for work-around)? I've tested above on Windows Vista box with: Java 1.6 / PostgreSQL 8.3.3 and 8.4.2 / JDBC PostgreSQL drivers postgresql-8.2-505.jdbc3 and postgresql-8.4-701.jdbc4. All combinations lead to error described above. To be sure that it is not something with my machine I've tested in in similar environment on other machine. UPDATE: I've turned on Postgres logging - as suggested by Depesz. Here are latest sql statements that were executed: 2010-01-18 16:18:51 CETLOG: execute <unnamed>: delete from spb_word4obj where doc_id = 1453 2010-01-18 16:18:51 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('ouc'01453) 2010-01-18 16:18:51 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('rbjb'11453) 2010-01-18 16:18:51 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('pvr'21453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('gal'31453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('cai'41453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('żjg'51453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('egf'61453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('śne'71453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('ęęd'81453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('lnd'91453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('cbd'101453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('dąc'111453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('łrc'121453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('zmł'131453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('zxo'141453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('oćj'151453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('zlh'161453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('lńf'171453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('cóe'181453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word4obj (word idx doc_id) values ('uge'191453) 2010-01-18 16:18:52 CETLOG: execute <unnamed>: update spb_word4obj set word_id = w.id from spb_word w where w.word = spb_word4obj.word and doc_id = 1453 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_word (word) select distinct word from spb_word4obj where word_id is null and doc_id = 1453 2010-01-18 16:18:52 CETLOG: execute <unnamed>: update spb_word4obj set word_id = w.id from spb_word w where w.word = spb_word4obj.word and word_id is null and doc_id = 1453 2010-01-18 16:18:52 CETLOG: execute <unnamed>: insert into spb_obj_word (word_id idx doc_id) select word_id idx doc_id from spb_word4obj where doc_id = 1453 2010-01-18 16:18:52 CETERROR: null value in column ""word_id"" violates not-null constraint 2010-01-18 16:18:52 CETSTATEMENT: insert into spb_obj_word (word_id idx doc_id) select word_id idx doc_id from spb_word4obj where doc_id = 1453 Now - code to check what is wrong in table spb_word4obj: select * from spb_word4obj w4o left join spb_word w on w4o.word = w.word where w4o.word_id is null and it shows that two words: 'gal' 'zxo' caused the problem. But... they are found in spb_word table - just freshly inserted with sql statements from log (included above). So - it is not issue with JDBC driver it is rather Postgres itself? UPDATE2: If I eliminate polish national chars (ąćęłńóśźż) from generated words there is no error - code performs all 50000 iterations. I've tested it few times. So for this line:  private static final String letters = ""abcdefghijklmnopqrstuvwxyz""; there is no error everything seems to be fine but with this line (or with original line in full source above):  private static final String letters = ""ąćęłńóśźżjklmnopqrstuvwxyz""; I get error described above. UPDATE3: I've just posted similar question without Java usage - fully ported to pure plpgsql look here: Why this code fails in PostgreSQL and how to fix it (work-around)? Is it Postgres SQL engine flaw?. Now I know that it is not related to Java - it is Postgres alone problem. If you are trying to index natural language documents with Postgres (for all I can see you are trying to build an inverted index on the words of the documents) I would recommend you to take a look at Full text search in Postgres instead. If that is not an option then check your encoding settings: database (In Postgres you cannot actually change the database encoding - you will have to recreate the database from scratch.) JDBC driver/Postgres client setting (sorry can't remember the details) and your Java source (editor) I suggest to set them all to UTF-8. If that still did not help then I suspect some kind of escaping/encoding issue between the source of the data (your Java source code file) and the destination of the data (the database). @WildWezyr: Ok in that case I recommend you update the question with a cleaner more direct testcase consisting of the actual SQL queries that are needed to get issued against Postgres to cause an error. Then we will be able to clearly decide whether it is a problem with Postgres or with the queries issued. And then we can work backwards to see what you will have to fix to solve your problem. Because I must admit I find your code too complex to actually follow in depth. @Bandi-T: look at my answer - I've managed to simplify my code. It is now quite simple... This is not an issue with selecting proper way of full text searching or any thing like that. I've found very strange error while doing my original task and separated very simple example code to expose this error. Code shown in my question has now nothing to do with FTS parsing etc. It is just to demonstrate serious problem with executing simplest statements (insert/update) in PostgreSQL. All my encodings are set to UTF-8 all values are correctly stored in DB - I've checked that. So my encoding is not an issue as it is set properly. here is pure sql version of the problem: http://stackoverflow.com/questions/2089772/why-this-code-fails-in-postgresql-and-how-to-fix-it-work-around-is-it-postgres I do understand FTS is not technically related to your problem; I was only suggesting it as a possible workaround since you were asking for workarounds. @Bandi-T: I'm looking for a work-around with provided code - how to change it to get it working. IMHO it is just an example of serious flaw in PostgreSQL. Without a fix - I must escape and move to other DB with my app (but I wish there is work-around or will be a fix for Postgres).  My further investigation of the problem revealed that the problem is related to pure Postgres SQL I developed pure plpgsql version which is one-to-one port of the code above. Restated question for pure plpgsql is here: http://stackoverflow.com/questions/2089772/why-this-code-fails-in-postgresql-and-how-to-fix-it-work-around-is-it-postgres. So - it is not Java/JDBC related problem. Furthermore I've managed to simplify test code - now it uses one table. Simplified problem was posted on pgsql-bugs mailing list: http://archives.postgresql.org/pgsql-bugs/2010-01/msg00182.php. It is confirmed to occur on other machines (not only mine). Here is workaround: change database collation from polish to standard 'C'. With 'C' collation there is no error. But without polish collation polish words are sorted incorrectly (with respect to polish national characters) so problem should be fixed in Postgres itself. Glad to see you found an answer then. Please accept your own answer in this case to flag the question answered.  Turn on query logging (log_statement = all) in postgresql.conf and check the queries. My bet is that it's the problem of driver (JDBC). I've done that. It does not seem like problem with JDBC driver but rather Postgres itself. I've updated my question to give details of last log entries and table rows which caused error. here is pure sql version of the problem: http://stackoverflow.com/questions/2089772/why-this-code-fails-in-postgresql-and-how-to-fix-it-work-around-is-it-postgres"
277,A,"How to Use Different META-INF/context.xml Files For Development and Production Environments In Tomcat (and some other servlet containers) I can store information about my JDBC DataSource in META-INF/context.xml. This is very useful. However the settings for my JDBC DataSource can be different in my development and production environments. I'd like to know how other people deal with these differences in an elegant way specifically how can I set up a context.xml for my development environment and one for my production environment in the most hassle-free manner. You can create different files for specific builds. For example create: development.context.xml production.context.xml Then you can control which context file is used in your build.xml file. Basically setup a prompt for which type of build you would like to use. When you select development it uses the development context file. When you select production it uses the production context file. How well does this work with Eclipe's Dynamic Web Application support? I am not sure. I am not familiar with using Eclipse for web development. I have only used Netbeans for that. I am sure it is possible though. Ant should be able to handle it.  Personally I wouldn't store configuration information like that in context.xml (perhaps in another properties file or something) but the general way for something like this is to have your build script package different versions of the configuration file into the WAR/EAR/whatever. You could have your build script decide whether to use the ""dev"" or ""production"" configuration file based on parameters you pass in running different targets etc. Something I use often is the task in ant to replace certain tokens in files with values from a filters file; and swap which filters file is used depending on which environment I am targeting.  If you want to learn more about Maven profiles read this: Introduction to Build Profiles  I would do the same as Kevin mentioned. If you're using Maven you would use ""profiles""."
278,A,appfuse: Embedded error: java.sql.SQLException: Field 'x' doesn't have a default value appfuse: Embedded error: java.sql.SQLException: Field 'x' doesn't have a default value You need to specify a value for that column in sample-data.xml
279,A,"Should I catch exceptions thrown when closing java.sql.Connection Connection.close() may throw SqlException but I have always assumed that it is safe to ignore any such exceptions (and I have never seen code that does not ignore them). Normally I would write:  try{ connection.close(); }catch(Exception e) {} Or  try{ connection.close(); }catch(Exception e) { logger.log(e.getMessage() e); } The question is: Is it bad practice (and has anyone had problems when ignoring such exceptions). When Connection.close() does throw any exception. If it is bad how should I handle the exception. Comment: I know that discarding exceptions is evil but I'm reffering only to exceptions thrown when closing a connection (and as I've seen this is fairly common in this case). Does anyone know when Connection.close() may throw anything? I've always just ignored them seeing as how I'm usually done with the database at this point. Empty catch blocks are evil. Like worthy of firing. And by firing I mean burning at the stake. Even a simple log statement would suffice people! Those having empty catch statements ""volunteer"" automaticaly to be on top of the list to call when there is production issues at 3 AM. Its a better practice to handle the exception at the time of closing the connection to the database. Because at later some point of time in your code if you are trying to access the statement or resultset objects then it will automatically raise an exception. So Better to handle the exception.  if this is an ""error that never happens"" case then I will just rethrow an Exception and hope no one catches it. if this is any other case I will probably log it  In an ideal world you should never do nothing on an exception of course in an ideal world you would never get an exception either 8-) So you have to examine the impacts of the various options. Log only: Database operations are all finished nothing left to do but clean up the resources. If an exception occurs at this point it most likely has no impact on the work performed so logging the error should suffice. Of course if an error occurs during logging then you basically have to handle failed database operation that didn't actually fail. Empty handler: Database operations are all finished nothing left to do but clean up the resources. If an exception occurs at this point it most likely has no impact on the work performed so the method returns successfully. The next database access may run into the same problem but it should occur at the start of a transaction where it will rightly fail and then get handled appropriately. If the problem has fixed itself then there will be no indication that anything ever went wrong. It is a pretty typical scenario to put a close() operation(s) in a finally block to ensure that cleanup occurs since we don't want any other failures to inhibit the resource cleanup. If no error has occurred then your method should not fail when its operation has successfully completed. In this case empty exception handling is quite normal. Of course opinions will vary.  Note that Apache Commons DButils provides a closeQuietly() method that you can use to avoid cluttering your code with 'redundant' catches. Note I'm not advocating swallowing exceptions but for this close() scenario I think it's generally acceptable. Proper error handling of closes is actually hard to get right.  In general I've had days wasted by people throwing away exceptions like that. I recommend following a few basic rules with exceptions: If you are ABSOLUTELY SURE you will NEVER cause a problem with a checked exception catch JUST that exception and comment exactly why you don't need to handle it. (Sleep throws an InterruptedException that can always be ignored unless you actually are interested in it but honestly this is the only case I usually ignore--even at that if you never get it what's the cost of logging it?) If you are not sure but you may get it occasionally catch and log a stack trace just so that if it is causing a problem it can be found. Again catch only the exception you need to. If you don't see any way the checked exception can be thrown catch it and re-throw it as an unchecked exception. If you know exactly what is causing the exception catch it and log exactly why you don't really need a stack trace in this case if you are very clear as to what's causing it (and you might mention the class that's logging it if you're not already using log4j or something. It sounds like your problem would fall into the last category and for this kind of a catch never do what you wrote (Exception e) always do the specific exception just in case some unchecked exception is thrown (bad parameters null pointer ...) Update: The main problem here is that Checked Exceptions are ungood. The only highly used language they exist in is Java. They are neat in theory but in action they cause this behavior of catch and hide that you don't get with unchecked exceptions. A lot of people have commented on the fact that I said that hiding them is okay sometimes. To be specific the one case I can think of is: try { Thread.sleep(1000); catch (InterruptedException e) { // I really don't care if this sleep is interrupted! } I suppose the main reason I feel this use is okay is because this use of InterruptedException is an abuse of the checked exception pattern in the first place it's communicating the result of a sleep more than indicating an exception condition. It would have made much more sense to have: boolean interrupted=Thread.sleep(1000); But they were very proud of their new checked exception pattern when they first created Java (understandably so it's really neat in concept--only fails in practice) I can't imagine another case where this is acceptable so perhaps I should have listed this as the single case where it might be valid to ignore an exception. I once worked on a system that was littered with suppressed try catches and most were commented with ""this should never happen"". They're right errors should never happen but they do. Lesson I learned never suppress an exception. Inevitably they do happen. Jeremy: I clarified my post re ""eating"" an exception. If you think we weren't in agreement you misunderstood the post a little though because I recommend that anything that ""Should never happen"" should be caught and rethrown as a unchecked exception because you are completely right. It is *never* a good idea to ignore an exception even if you comment why. There is minimal overhead to logging the exception and that is the minimum that should be done cause while you are ""...ABSOLUTELY SURE you will NEVER cause a problem..."" problems occur later not now. My biggest case for this is sleep() It throws a checked exception that more often than not can never be reached and if it is reached who cares? If I cared (of course) I'd handle it. But still comment it. Um.... sleep throws an InterruptedException for a reason. If you're actually writing a multithreaded program and some other thread calls Thread.interrupt() on the thread that is currently in a sleep block that's where the exception is thrown. It's an indicator to the programmer that they should stop executing what they're doing and allow the background process (whatever the thread is doing) to terminate gracefully. @Matt yeah I agree. but it's really rarely needed. Even at that it should throw an exception in the catch or something... but I've almost never seen the catch actually used.  If you can handle it then do so (and log it if it was unexpected). If you cannot handle it then rethrow it properly so some code above can handle it. Silently swallowing exceptions is leaving out crucial information for the person to fix the code.  You could also throw a RuntimeException: try { connection.close(); } catch(Exception e) { throw new RuntimeException(e); } You won't have to change your method signature and will be able to use the Exception.getCause method later on to find the cause of the problem. This is a really good solution to a lot of checked exceptions. I'm not sure why you were voted down for it I fixed it for you :) In practice you probably want to create a more specific runtime exception to rethrow it as. What is the reason to throw it as a runtime exception? ALWAYS include the _reason_ why you are wrapping and rethrowing as the message. Remember the more information you have in a stack trace the more helpful it is to the person trying to figure out what happened. Especially if that person is not familiar with the code.  At the very minimum always always always log exceptions that you are catching and not acting on. Silently caught exceptions that are swallowed without the tiniest peep are the worst. I believe you have had to debug such code before you see the value of doing so.  I personally like your second idea of at least logging the error. Because you're catching Exception it's theoretically possible to catch something other than a SQL Exception. I'm not sure what could happen or how rare (like out of memory exceptions etc) but supressing all errors doesn't seem right to me. If you want to suppress errors I would do it only to very specific ones you know should be handled that way. Hypothecial situation: what if your sql had an open transaction and closing the connection caused an exceptino because of that would you want to suppress that error? Even suppressing SQLExceptions might be a little dangerous.  Actually what you're doing is (almost) best practice :-) here's what I saw in Spring's JdbcUtils.java. So you might want to add another Catch block. /** * Close the given ResultSet and ignore any thrown exception. * This is useful for typical finally blocks in manual code. * @param resultSet the ResultSet to close * @see javax.resource.cci.ResultSet#close() */ private void closeResultSet(ResultSet resultSet) { if (resultSet != null) { try { resultSet.close(); } catch (SQLException ex) { logger.debug(""Could not close ResultSet"" ex); } catch (Throwable ex) { // We don't trust the driver: It might throw RuntimeException or Error. logger.debug(""Unexpected exception on closing ResultSet"" ex); } } }  From my experience ignoring an exception is never a good idea. Believe me the production support engineers and analysts will thank you a tonne if you logged the exception. Also if you are using the right Logging framework there would be zero or minimal performance impact of the exception.  You have to handle the exception. It is not a bad practice. Imagine you lost the network just before closing the dabatase connection. It will probably throw the exception. Is it rare ? Yes. I suppose that's what they are called exceptions and that is not a reason to ignore it. Remember that if it could fail it will fail. You should also think about whether it is possible to have a null connection at this point (it would cause a NullPointerException) or not. if (connection != null) { try { connection.close(); } catch (SQLException sqle) { logger.log(e.getMessage() e); } }"
280,A,What happens to the original resultSet when it is returned from a method into a new object? pseudo code to explain my self better. I'm learning Java at this point in time. if I have a method public resultSet getEverything() { resultSet rs = blabla; return rs } I can't rs.close() as I need to use it in the method I retrieve it hence then I will use it and maybe 'close' the new resultSet I create. What happens from the previous resultSet? Is it left to be collected by the garbage collector? Does it close itself when I close the 'new' resultSet? Does it have any impact on code efficiency/performance? Any feedback would be greatly appreciated :) as this has confused me a bit. It is more of an OOP question rather than Java I think. Thanks! There's only one resultSet here. You create it and return it in this method; the calling method (the one that calls getEverything()) now has it - it doesn't have a copy or anything like that; it has the resultSet you create in this method. But the calling method must assign the result of getEverything() if it is to close it - like this: resultSet rs = getEverything(); versus simply calling the method like this: getEverything(); In the second case the result set would be created then made available to the behind-the-scenes garbage collector (essentially deleted) without an opportunity to close it. thanks.. you made it really clear :) On the other hand it is also interesting what duffymo has pointed out in his reply... its better if you close any connections to DB in the same method.  You should not be returning a java.sql.ResultSet from a method. It should always be created mapping into an object or data structure and closed in the scope of the method in which it was created in a finally block. A java.sql.ResultSet is associated with a database cursor a scarce resource. You don't want to keep those open for a long time. Garbage collectors do not clean up result sets statements or connections to databases. It will remove the reference from memory but the cursor or connection will still be open on the database side. It's your responsibility to close them properly or you'll exhaust the supply. An object data structure or CachedRowSet is the right thing to return.
281,A,"Why is Oracle so slow when I pass a java.sql.Timestamp for a DATE column? I have a table with a DATE column with time (as usual in Oracle since there isn't a TIME type). When I query that column from JDBC I have two options: Manually convert the values with Oracle's to_date() Use a java.sql.Timestamp Both approaches work and have exclusive areas of hideousness. My problem is when I'm SELECTing data. Here are two sample queries: select * from TABLE where TS between {ts '2009-12-08 00:00:00.000'} and {ts '2009-12-09 00:00:00.000'} select * from TABLE where TS between trunc({ts '2009-12-08 00:00:00.000'}) and trunc({ts '2009-12-09 00:00:00.000'}) Both queries work return the same results and produce the exact same output in EXPLAIN PLAN. This right indexes are used. Only query one runs 15 minutes while the second query takes 0.031s. Why is that? Is there a central place to fix this or do I have to check all my queries for this column and make utterly sure that the trunc() is in there? How do I fix this issue when I need to select down to a certain second? [EDIT] The table is partitioned and I'm on Oracle 10.2.0. As you noted using the {ts ''} syntax makes your code database-agnostic but is there a way to find out what SQL is really being passed to the database? And how important is it to be database agnostic? If you could post the EXPLAIN PLAN results we might be able to understand more of what's going on. Bob: Explain plan shows the exact same results even when I use TO_DATE(). Is your table partitioned? Oracle JDBC doesn't seem to use partition pruning when you set parameters as Timestamp for reasons I've never understood. Yes it's partitioned. +1 I would like to understand this also. Does this happen only on a huge table? Well I guess you won't notice with a small table :) This is because TIMESTAMP datatype is more accurate than DATE so when you supply TIMESTAMP parameter value into DATE column condition Oracle has to convert all DATE values into TIMESTAMP to make a comparison (this is the INTERNAL_FUNCTION usage above) and therefore index has to be full scanned. Makes sense; the optimizer is probably too ""dumb"" to understand that downcasting the type would be more efficient in this case.  I had this problem on a project a while ago and setting the connection property oracle.jdbc.V8Compatible=true fixed the problem. Dougman's link tells you how to set it: You set the connection property by adding it to the java.util.Properties object passed to DriverManager.getConnection or to OracleDataSource.setConnectionProperties. You set the system property by including a -D option in your java command line. java -Doracle.jdbc.V8Compatible=""true"" MyApp Note for 11g and this property is apparently not used. From http://forums.oracle.com/forums/thread.jspa?messageID=1659839 : One additional note for those who are using the 11gR1 (and on) JDBC thin driver: the V8Compatible connection property no longer exist so you can't rely on that to send your java.sql.Timestamp as a SQLDATE. What you can do however is call: setObject(i aTimestamp java.sql.Types.DATE) sends data as SQLDATE setObject(i aDate) sends data as SQLDATE setDate(i aDate) sends data as SQLDATE setDATE(i aDATE) (non standard) sends data as SQLDATE setObject(i aTimestamp) sends data as SQLTIMESTAMP setTimestamp(i aTimestamp) sends data as SQLTIMESTAMP setObject(i aTimestamp) sends data as SQLTIMESTAMP setTIMESTAMP(i aTIMESTAMP) (non standard) sends data as SQLTIMESTAMP  I don't understand what {ts '2009-12-08 00:00:00.000'} actually mean since this isn't Oracle SQL as far as I know. Can you show exactly what the query is you're running? One possible problem is that you're specifying your range with milliseconds. Oracle's DATE type only goes down to seconds. (Use TIMESTAMP type if you need to store fractions of seconds). But what might be happening is that in the first query Oracle is converting each DATE value to a TIMESTAMP in order to do the comparison to your specified TIMESTAMP. In the second case it knows TRUNC() will effectively round your value to something that can be expressed as a DATE so no conversion is needed. If you want to avoid such implicit conversions make sure you're always comparing like with like. eg select * from my_table t where t.ts between to_date('2009-12-08''YYYY-MM-DD') and to_date('2009-12-09''YYYY-MM-DD') @CMG: Doesn't work. I wonder how other people use JDBC with Oracle. Is everyone using Strings and TO_DATE()??? Where I work we don't use those magic jdbc {} expressions but strings and to_date(). We like to know what SQL is being passed to Oracle rather than let something between Java and Oracle invent the SQL on the way through. +1 The syntax of this query seem simpler more understandable. We use stuff like that and have no problem. `{ts ...}` `{d ...}` is a hidden feature of JDBC which allows you to specify a java.sql.Timestamp java.sql.Date in a DB agnositic way. As for your query my question is more: How can I avoid this without going through all the sources? Hidden feature ... I start to understand ;-) So you don't really know what is the exact SQL received by Oracle! ;-) To find out maybe you can reproduce the problem directly in Oracle by comparing the performance of several queries varying only the date format used (in this answer)? But don't forget to keep us updated! :-) I'm pretty sure the problem is one of implicit type conversion. If you give Oracle a timestamp value to compare against a DATE type column then it will have to do a conversion and it will avoid rounding. So the only option is to convert all its DATE values to TIMESTAMP. Hence it will be extremely slow and won't be able to use an index on the DATE col. You might be able to get round this by creating a FUNCTION BASED INDEX on the date col where the date is expressed as a timestamp. @Aaron What do you mean by ""without going through all the sources""? Do you have hundreds of these queries in your source code that you would like to fix changing a simple configuration parameter? :-) @KLE: I can fix the 10+ places where its broken. I'm wary that someone might break the performance again by creating a new query somewhere. @KLE: The JDBC driver sends a java.sql.Timestamp to the DB. But I'm pretty sure that CMG is right: It will cause a widening conversion on the existing column. @CMG: I really want to avoid TO_DATE(). What is the correct JDBC type to use for Oracle DATE columns? java.sql.Date will truncate the seconds java.sql.Time will truncate the date part. There is no sql.DateTime. Do I have to use oracle.sql.DATE? In the example you gave you don't seem to be interested in the time-element anyway (just the date part) so have you tried using the {d ...} shorthand to pass in just the date instead of a timestamp {ts ...} ? Or if you are interested in the time element maybe try using an expression which adds {d ...} and {t ...} together eg select * from my_table t where t.ts between ({d '2009-12-08'} + {t '12:01:02'}) and ({ d '2009-12-09'} + {t '12:01:02'} ) No idea if this will work or how it will perform but worth a try  I have a similar problem here: Non-negligible execution plan difference with Oracle when using jdbc Timestamp or Date In my example it essentially comes down to the fact that when using JDBC Timestamp an INTERNAL_FUNCTION is applied to the filter column not the bind variable. Thus the index cannot be used for RANGE SCANS or UNIQUE SCANS anymore: // execute_at is of type DATE. PreparedStatement stmt = connection.prepareStatement( ""SELECT /*+ index(my_table my_index) */ * "" + ""FROM my_table "" + ""WHERE execute_at > ? AND execute_at < ?""); These two bindings result in entirely different behaviour (to exclude bind variable peeking issues I actually enforced two hard-parses): // 1. with timestamps stmt.setTimestamp(1 start); stmt.setTimestamp(2 end); // 2. with dates stmt.setDate(1 start); stmt.setDate(2 end); 1) With timestamps I get an INDEX FULL SCAN and thus a filter predicate -------------------------------------------------------------- | Id | Operation | Name | -------------------------------------------------------------- | 0 | SELECT STATEMENT | | |* 1 | FILTER | | | 2 | TABLE ACCESS BY INDEX ROWID| my_table | |* 3 | INDEX FULL SCAN | my_index | -------------------------------------------------------------- Predicate Information (identified by operation id): --------------------------------------------------- 1 - filter(:1<:2)"" 3 - filter((INTERNAL_FUNCTION(""""EXECUTE_AT"""")>:1 AND INTERNAL_FUNCTION(""""EXECUTE_AT"""")<:2)) 2) With dates I get the much better INDEX RANGE SCAN and an access predicate -------------------------------------------------------------- | Id | Operation | Name | -------------------------------------------------------------- | 0 | SELECT STATEMENT | | |* 1 | FILTER | | | 2 | TABLE ACCESS BY INDEX ROWID| my_table | |* 3 | INDEX RANGE SCAN | my_index | -------------------------------------------------------------- Predicate Information (identified by operation id): --------------------------------------------------- 1 - filter(:1<:2)"" 3 - access(""""EXECUTE_AT"""">:1 AND """"EXECUTE_AT""""<:2)"
282,A,JDBC: Does the connection break if i lose reference to the Connection object? If i have the following method - public static void C() { Connection con = DriverManager.getConnection(); .... // code return; } and i dont call con.close()  will the connection terminate automatically once the method returns? ...will the connection terminate automatically once the method returns? No it won't. It may or may not eventually close but it's going to be a long time before it does if ever. The connection class's finalizer probably closes the connection if it's open but there are lots of situations where finalizers aren't ever run. It's essential to call con.close() explicitly. Here's how I usually handle it (although I've factored a lot of this logic out into helpers since this is verbose otherwise): public static void C() throws SQLException { Connection con = DriverManager.getConnection(); try { .... // code // done with the connection con.close(); con = null; } finally { if (con != null) { try { con.close(); } catch (Exception e) { // Eat it to avoid masking any exception that // got us here } } } } Note that having detected the unclosed connection in the finally clause I close it but don't allow any exception doing so may cause to get thrown. This is because the main logic closes the connection correctly which means that if I've found an open connection in the finally block an exception has already been thrown and we're handling it so I don't want to mask that by throwing a different exception from con.close(). With decent helpers that gets a lot shorter and easier to write: public static void C() throws SQLException { Connection con = DriverManager.getConnection(); try { .... // code // done with the connection con = JDBCHelper.close(con); // <== This one *allows* any exception that occurs } finally { con = JDBCHelper.quietClose(con); // <== This one *eats* any exception that occurs } } ...where JDBCHelper (a hypothetical class) contains: public static final Connection close(Connection con) throws SQLException { con.close(); return null; } public static final Connection quietClose(Connection con) { if (con != null) { try { con.close(); } catch (Exception e) { } } return null; } If you want a 'JDBCHelper' see Apache Commons DbUtils and DbUtils.closeQuietly() in particular. This closes the resultset/statement/connection tuple. I look forward to Java7's Automatic Resource Management (http://wikis.sun.com/display/ProjectCoin/Proposal2009AutomaticResourceManagement) which ought to make this sort of thing much easier. @Brian: Thanks I figured Commons would have something but didn't have time when doing the answer to go look (since my internal `JDBCHelper` predates Commons by...some margin :-) ). @Donal: Ah glad to see that that's in there. (Another link: http://docs.google.com/View?docid=dffxznxr_1nmsqkz from http://tech.puredanger.com/java7/#resourceblock) Now we just have to see whether Oracle is going to actually you know **do** Java 7 (the spec + RI + TCK) as they still haven't done a JSR for it. *JDK* 7 either is or is nearly feature complete (http://tech.puredanger.com/2010/06/01/java-jdk-7-plan/) despite that which is odd and backward but life is messy sometimes and rarely more so when dealing with licensing disputes and acquisitions.  http://java.sun.com/j2se/1.4.2/docs/api/java/sql/Connection.html#close%28%29 Note: A Connection object is automatically closed when it is garbage collected. Certain fatal errors also close a Connection object. That said you should probably close your connections explicitly. Which is true but misleading; when (if ever) GC runs is nondeterminate. The OP asked if the connection was closed on return from the method. Good clarification my mistake to simplify things which in this case would be dangerous ..  It will not close immediately when the method returns. Eventually the Connection object will be garbage collected and probably a finalizer will then close the connection. But there's no guarantee for when this will happen. Don't write programs that rely on the connection being closed automatically somehow if you lose all references to the Connection object. Always close the connection from a finally block (so that it happens even in case of an exception): Connection conn = DriverManager.getConnection(...); try { // ... code that uses the connection } finally { // Close the connection conn.close(); } I wish it were that simple. :-) What if you're processing an exception when the `finally` block gets called and `conn.close()` triggers a different exception? You'll end up causing the original exception to get lost masking the real problem. @T.J. catch the exception in the `finally` block etc. I didn't want to make this a basic Java course... Fair enough but in general questioners are likely to copy what they've been given. IMV it's important not to give them information that's sufficiently incomplete as to lead to bad patterns. Just my take.
283,A,"JDBC & MSSQL seem to be truncating large fields I'm using jython 2.2.1 and jdbc 1.2 and connecting to a mssql 2000 database writing the contents of an email to it. When I get to the body of the email which can be quite large sometimes I need to truncate the data at 5000 chars. Except mssql & jdbc gang up on me like school yard bullies when i check the database loads of my data is missing every time with max chars = 256 chars. I have checked the size of the field and it is set to 5000. what gives? I am pretty sure it is related to jdbc as the previous version used .... vb6 & odbc without a hitch. here is some code: BODY_FIELD_DATABASE=5000 def _execute_insert(self): try: self._stmt=self._con.prepareStatement(\ ""INSERT INTO EmailHdr (EntryID MailSubject MailFrom MailTo MailReceive MailSent AttachNo MailBody)\ VALUES (? ? ? ? ? ? ? cast(? as varchar ("" + str(BODY_FIELD_DATABASE) + "")))"") self._stmt.setString(1self._emailEntryId) self._stmt.setString(2self._subject) self._stmt.setString(3self._fromWho) self._stmt.setString(4self._toWho) self._stmt.setString(5self._emailRecv) self._stmt.setString(6self._emailSent) self._stmt.setString(7str(int(self._attachmentCount) + 1)) self._stmt.setString(8self._format_email_body()) self._stmt.execute() self._prepare_inserting_attachment_data() self._insert_attachment_data() except: raise def _format_email_body(self): if not self._emailBody: return "" "" if len(self._emailBody) > BODY_FIELD_DATABASE: return self._clean_body(self._emailBody[:BODY_FIELD_DATABASE]) else: return self._clean_body(self._emailBody) def _clean_body(selfdirty): '''used to clean =20 occurrence in email body that contains chinese characters http://en.wikipedia.org/wiki/Quoted-printable''' dirty=str(dirty) return dirty.replace(r""=20"""""") Deleted my answer - it was totally wrong. Keeping it here though so comments & conversation hang around. EDIT: As you can read in the comments here's what happened: The data was being put into the database fine but the MSSQL Query Manager could not display the Chinese characters. no there are still spaces in the text and it is well formatted just minus the =20s. =20 is related to this http://stackoverflow.com/questions/320166/emailretr-retrieves-strange-20-characters-when-the-email-body-has-chinese-chara it is solved this issue also there are no =20 when it is an ascii only email but still im sitting at 256 chars in the db. I know what =20 is but the fact remains that if your email was full of them after you remove them it'll be smaller. =20 is not really specific to chinese chars either. no you right it isnt specific to chinese characters but the probability is higher when there are chinese characters. Im not sure of a correct or optimal way of delivering an output without the =20 so i wack em this way. the occurrence is not so great to reduce 5000 chars to 256 chars in the db Hmm I seem to have misread the question. Anyway have you tried printing the body before committing it to the database? Would be interesting to see if that is the proper length. sure and i get the full length no problem well formatted (no blasted =20s) but as it goes through jdbc it falls over. Can you access the database in another way and add a heap of text to that field? let me try: good idea oh my word: the problem was in the actual Query manager. It couldnt display chinese characters. the software packed up as soon as it hit a character. all the data was being written in correctly. False alarm"
284,A,"PreparedStatement.setString() method without quotes I'm trying to use a PreparedStatement with code similar to this: SELECT * FROM ? WHERE name = ? Obviously what happens when I use setString() to set the table and name field is this: SELECT * FROM 'my_table' WHERE name = 'whatever' and the query doesn't work. Is there a way to set the String without quotes so the line looks like this: SELECT * FROM my_table WHERE name = 'whatever' or should I just give it up and use the regular Statement instead (the arguments come from another part of the system neither of those is entered by a user)? The fact that you are contemplating doing this suggests to me that you should consider remodeling your data. Perhaps you should make a view that merges all of the tables with an added column being the 'table name'. I think u r trying to make a generic method which will perform a common task U can try this:: **String tableName= ../* from parameter */ String column1=.../* from parameter */ StringBuilder query = new StringBuilder("" Select * from ""); query.append(tableName); query.append("" where ""); query.append(column1); query.append("" =? "");** then use the set string method ....  Unfortunately you cannot parameterize table names for prepared statements. If desired you could construct a String and execute it as dynamic SQL.  Parameters cannot be used to parameterize the table or parameterize any database objects. They're mostly used for parameterizing WHERE/HAVING clauses. To do what you want you'll need to do the substitution yourself and create a regular statement as needed. When you use a prepared statement this is a hint to the database to do up front processing on the statement - e.g. parse the string and possibly determine an execution plan. If the objects used in the query can change dynamically then the database could not do much up front preparation. To further this it's not that using setString puts quotes around the strings because it doesn't (bind variables don't work that way). It's just that you can't use a variable for that part of the query. Got it thank you! Would you say using PreparedStatement dosn't make much sense here given the paramenters are not user entered? I mean it's probably more costly versus using regular Statement. Or should I use PreparedStatement everywhere no matter what? You can still use a PreparedStatement just don't try to parameterize the table name - parameterize the 'whoever'. There is some debate over the use of prepared vs regular statements but I believe the concensus is to use prepared statements unless you discover good reasons not to.  The mistake you did is that you cannot pass the table name as a parameter. You should only pass the values to a SQL Statement. Ex: If you're wantto : Select * from LoggedUsers where username='whatever' and privilege='whatever'; then you've to build the PreparedStatement as : Select * from LoggedUsers where username=? and privilege=? setString(1 usernameObject); setString(2 privilegeObject); The purpose of PreparedStatement is to reduce the difficulty and readability of the database connection code. when the developer has to use so many column values with Statement's instance it's so difficult to put semicolons commas and plus (concat operator). I think you're mistakenly wanted to take advantage of it which is not designed to be....  I doubt that your SQL is really infinitely flexible that way. You only have a finite number of tables so the number of static final Strings to express the SQL you need is finite as well. Continue to use PreparedStatement and bind your variables. It's totally worth it especially helpful when avoiding SQL injection problems. You have obvious not read enough TheDailywtf.com. Having a table per customer(And the number of customers are not bound) is a used anti pattern. Apparently not. Thanks for the heads up. 8)"
285,A,"Connecting to Teradata via PHP We need to access a Teradata database via php application We don't have odbc (unixodbc etc) on the server. How might one go about connecting to a teradata database quickly. Keep in mind - this app needs to be as portable as possible. You may be out of luck. PDO doesn't have a native driver ADODb doesn't have a native driver judging from what I find from a cursory web search I'd say it is not possible to connect from PHP to a Teradata database without ODBC.  Teradata provides an ODBC driver. Once installed it can be accessed via the unixODBC driver manager assuming your php was built with ""--with-unixODBC=shared/usr"". PHP can then connect to a Teradata database with odbc_connect($dsn $user $passwd); The Teradata ODBC driver installation includes a sample odbc.ini file which you can cp to .odbc.ini in your home directory then modify to contain the DSN for your Teradata database. Set the environment variable ODBCINI to the location of your odbc.ini file to use (/home/johndoe/.odbc.ini is common). Be warned: the Teradata ODBC driver provides a rich set of DML statements but very few are exposed through the unixODBC driver manager. The collection of PHP's odbc_xxxx() functions is a crippled subset of what the Teradata ODBC driver offers.  This method would help you if u are ok with the memory implications and this would help you if you have teradata command line utility BTEQ installed on your machine. But better method would be by ODBC as it gives you the flexibility. In the above method of command line execution of SQL scripts by system() function you can use an easier language like R for parsing the output resultset. I think you may also do it by jdbc connection. You can also download any of these odbc/jdbc drivers from this link."
286,A,"Is it safe to use connection.createStatement().executeQuery(String query);? Is it safe to do connection.createStatement().executeQuery(String query); or should each java.sql.Statement object be created and closed by ""hand"" on every use even if the connection is closed in a finally block? If multiple queries are executed in one method by one connection it would use much less code if instantiating and closing each statement wasn't strictly necessary. Move all the boilerplate code to a helper method/class. That way you can acquire/release resource in the manner consistent with JDBC (or any other limited resource package) documentation and yet have your business logic not be polluted by JDBC clutter. And though it may seem like a waste to you now but there is nothing wrong with dedicating single query to a single method in your business logic class. Could you elaborate on that last point a bit? ""there is nothing wrong with dedicating single query to a single method in your business logic class."" I think you are talking about some sort of query wrapper but I'm curious how you would implement something of the sort that doesn't have gigantic set of arguments. @javanix. It looked from your original question that you want to run a few SQL commands in a single method and are concerned with necessary SQL clutter. The last paragraph suggests that you can dedicate a single method to run a single query that's sets up and tears down JDBC artifacts. As I don't know anything about your requirements from your original posting this may not be practical in your case. Also remember gigantic set or arguments can be hidden behind a concrete implementation of a simple interface. That is what are classes for to carry the state information.  It's true that closing a Connection in almost all JDBC driver implementations also implicitly closes the Statement. But a big but when you're using a connection pool (and you would like to use one because that greatly improves connecting performance) the close() will not close the Connection but release it back to the pool hereby leaving the Statement open. And when you do this too often you will run out of resources sooner or later which may kill your application. Always acquire and close all the three resources Connection Statement and ResultSet in the shortest possible scope no excuses. Yeah nothing is going to teach you to use try/finally faster than running out of resources in production one fine day. As someone who's worked Saturdays because lazy developers didn't understand you can't re-use the same Statement reference with pooled connections (thus running the database out of cursors) I would like to double-encourage you to heed BalusC's words! Ah ha! Though I am not using a connection pool at the moment (no real current need in my mind) it seems like it would make my life easier in the future if I closed and used everything ""correctly"" now and decide to use a pool in the future. Thanks! Exactly! You're welcome :) A side note because I see in your question history that you're doing webapps I just want to warn you about this bit: when you use a container managed datasource to have an easy management of DB connectivity you should realize that it's underhand usually already a connection pool!"
287,A,"Specifying a variable name in QUERY WHERE clause in JDBC Could someone please give me a link on how to create a query in JDBC that gets a variable name in the WHERE statement or write an example to be more specific my code looks something like this:  private String getLastModified(String url) { String lastModified = null; ResultSet resultSet; String query = ""select LastModified from CacheTable where "" + "" URL.equals(url)""; try { resultSet = sqlStatement.executeQuery(query); } Now I need the syntax that enables me to return a ResultSet object where URL in the cacheTable equals url from the method's argument. thanks The easiest way would be String query = ""select LastModified from CacheTable where url = '"" + url +""'""; You should use bind variables though: String query = ""select LastModified from CacheTable where url = ?""; prepStmt = conn.prepareStatement(query); prepStmt.setString(1 url); rs = prepStmt.executeQuery(); Thanks for your answer what are the other ways and how do I bind variables? oh.. I thought prepareStatement was just for update queries. thank you very much +1 I was far too slow. More coffee! I have another question how do I execute the query in particular how do i get the ResultSet object ? (you can ignore it i noticed the edit now thanks) your first query reminded me of my PHP days :)  To take it one step further you should really use DBUtils from apache-commons or Sping JDBC framework. A lot of JDBC work is mundane and error prone due to the number of steps involved with it. Both links have working examples for you to get started. These helper libraries will make your life much more comfortable :-).  To clear a misconception: JDBC and SQL are two entirely different things. Databases only understand the SQL language. It's a (semi)standard which you can learn here. JDBC is just a Java API which enables you to execute SQL language using Java code. Nothing less nothing more. JDBC is not a Java way of writing SQL language or so. It's just the messenger between Java code and the database. You can learn JDBC here. That said yes the PreparedStatement is the way to go to set values in a SQL query. It not only eases setting fullworthy Java objects in a SQL string using the setXXX() methods but it also saves you from SQL injection attacks."
288,A,"Spring's Stored Procedure - results coming back from procedure always empty I am using Spring's JdbcTemplate and StoredProcedure classes. I am having trouble getting the stored procedure class to work for me. I have a stored procedure on an oracle database. Its signature is CREATE OR REPLACE PROCEDURE PRC_GET_USERS_BY_SECTION (user_cursor OUT Pkg_Types.cursor_type  section_option_in IN Varchar2  section_in IN Varchar2) AS .... where TYPE cursor_type IS REF CURSOR; I have create the following stored procedure class to get information from the oracle procedure  private class MyStoredProcedure extends StoredProcedure { public MyStoredProcedure(JdbcTemplate argJdbcTemplate) { super(argJdbcTemplate ""PRC_GET_USERS_BY_SECTION""); declareParameter(new SqlOutParameter(""output"" OracleTypes.CURSOR)); declareParameter(new SqlParameter(""input1"" Types.VARCHAR)); declareParameter(new SqlParameter(""input2"" Types.VARCHAR)); compile(); } public Map<String Object> execute() { Map<String Object> inParams = new HashMap<String Object>(); inParams.put(""input1"" ""BG""); inParams.put(""input2"" ""FE""); Map output = execute(inParams); return output; } } I am calling this in a method in one of my DAO classes  public List<String> getUserListFromProcedure() throws BatchManagerException { MyStoredProcedure sp = new MyStoredProcedure( this.jdbcTemplate ); Map<String Object> result = new HashMap<String Object>(); try { result = sp.execute(); } catch( DataAccessException dae) { } System.out.println(result.size()); return null; } However the size of the map is always 0 so nothing comes back. I know that there are rows on the database which match my input criteria. Also I had code working which used java.sql.CallableStatement to interact with the oracle stored proc - so the proc is good. Is it wrong to mix OraceleTypes.CURSOR with Spring's Stored Procedure? What else can I use? I also tried SqlReturnResultSet and that didn't work either. The problem here is that Oracle's way of doing stored procedures is not JDBC compliant. Oracle's SPs return resultset data via OUT parameters or return values that are cursors and they have to be handled specially. This means you cannot use any of Spring's JDBC stuff that assumes compliance with JDBC you have to do it yourself. In practice this means you have to use JdbcTemplate and CallableStatementCallback which means a lot more manual JDBC coding than you'd ideally like but I've yet to find a way to avoid this. On a slight aside I rather suspect that the JDBC spec was written to conform closely to the Sybase (and by association SQL Server) way of doing things because the way stored procedures are handled in JDBC is a remarkably good fit for those systems (and a poor fit for Oracle's). Hi Thanks for your feedback. I got this working with my Oracle stored procedure. The problem was with the output parameter I had declared. The following works declareParameter( new SqlOutParameter( ""output"" oracle.jdbc.OracleTypes.CURSOR new RowMapper() { public String mapRow(ResultSet argResults int argRowNum ) throws SQLException { return argResults.getString(1); } }) ); This is working for me now. Thanks You should have answered your own question and selected it as the accepted answer. Thanks for posting anyway.  The problem is simple if you don't pass a RowMapper while declaring the outparam which is a CURSOR. Spring is going to return {} I.e empty cursor.  declareParameter(new SqlOutParameter(""output"" OracleTypes.CURSOR)); - returns empty {} declareParameter(new SqlOutParameter(""output"" OracleTypes.CURSOR new ApplicationMapper()); - returns result Where ApplicationMapper is my custom mapper which implements RowMapper."
289,A,"Oracle & java dynamic 'Order by' clause I am trying to build a dynamic sql query in java (shown below)  sqlStr = ""Select * "" + ""from "" + tableName if(tableName!=null){ if(tableName.equals(""Table1""){ sqlStr = sqlStr.concat(""order by city desc""); }else if(tableName.equals(""Table2""){ sqlStr = sqlStr.concat(""order by country desc""); }else if(tableName.equals(""Table3""){ sqlStr = sqlStr.concat(""order by price desc""); } } Now what i would like to do is to add a final 'else' statement which would order the query based on whether the table contains a column named 'custID'. There will be several tables with that column so i want to sort the ones that have that column by custID. (Rather than having hundreds of additional if statements for each table that does have that column name.) Is this possible? i have seen people using the 'decode' function but i cant work out how to use it here. You should adda space before your `order` or you will have a syntax problem. Plus it isn't a good idea to work with a table which you know nothing about you problem is a more general design problem. while composing dynamic query please use StringBuilder instead of using string ""+"" and concat. The most straight-forward way to do it is to read the column definitions from USER_TAB_COLUMNS or ALL_TAB_COLUMNS and check for the existence of a custID column. Without crazy PL/SQL tricks you won't be able to solve this in SQL alone. BTW there is a "" "" missing between tableName and the order by clauses. USER_TAB_COLUMNS is Oracle specific. DatabaseMetaData is portable between RDBMS. Agreed. Though Oracle and portable hardly go hand-in-hand. @Ashsish: I don't think so. Why should a user not be allowed to read the definitions of his own tables? Using user_tab_columns requires the use of pl/sql which im trying to avoid. ziggy: No you don't need PL/SQL to read USER_TAB_COLUMNS. You can read it like any other table or view with a simple SQL query. `USER_TAB_COLUMNS` requires extra permissions from DBA.  If you are happy with hardcoding things a way to avoid multiple conditionals would be to store a list of all the tables that include custID. private final static String tablesWithCustID = ""/TableX/TableY/TableZ/""; ... if (tablesWithCustID.contains( tableName )) { sqlStr = sqlStr.concat(""order by custID"") } You could use a List instead of a simple delimited string if you like. Perhaps better you could store a map with table names as the key and the sort string as the value. Load it up once then you don't need any conditional at all. Tom has a good point. Best of both worlds is to build the lookup table using metadata once. You might even be able to avoid hardcoding this by building it at application startup from database metadata. Enumerate all tables and look through the columns in each to choose a sort key (eg ""the custID column if it has one else country if it has one oh but always price for Table3"") and store that.  How about ArrayList.contains()? You can create a list of tables which have that column and just check for tables.contains(tablename) in the final if condition.  I understand that you're looking for a solution that can do this in one query i.e. without running a separate metadata query beforehand. Unfortunately this won't be possible. The decode function can do some dynamic things with column values but not with column name. And you're looking for a solution dynamically derive the column name. An alternative might be to just add ORDER BY 1 2. This is an old syntax that means order by the first and than by the second column. It might be a good solution if the custID column is the first column. Otherwise it at least gives you some sorting.  Use DatabaseMetaData to get the table information. You can use the getTablexxx() and getColumnxx() methods to get the table information. Connection conn = DriverManager.getConnection(.....); DatabaseMetaData dbmd = conn.getMetaData(); dbmd.getxxxx(); Note: you forgot space in your code before ORDER BY clause. Hi yes i noticed the missing space. Is it possible to use this in a single query? Or do i have to issue one query to find out the column names first then build the final query? I guess the other option is to use the metadata and sort the resultset rather than sort using SQL but that would be expensive. I think you will have to fire atleast 2 queries."
290,A,"Hibernate or JDBC I have a thick client java swing application with a schema of 25 tables and ~15 JInternalFrames (data entry forms for the tables). I need to make a design choice of straight JDBC or ORM (hibernate with spring framework in this case) for DBMS interaction. Build out of the application will occur in the future. Would hibernate be overkill for a project of this size? An explanation of either yes or no answer would be much appreciated (or even a different approach if warranted). TIA. There are other possibilities. What about iBATIS http://iBATIS.apache.org/ overkill? Conceptual overkill ? Another jar ? I was thinking overkill in extra processing overhead to add a layer extra developer skills needed to maintain it (I have the skills but I have to think about when I'm not the one maintaining it) coupling to a 3rd party instead of native (though the extra jars are not an issue AFAIC). That type of thing. +1 for good questionning attitude and clear question Good question with no single simple answer. I used to be a big fan of Hibernate after using it in multiple projects over multiple years. I used to believe that any project should default to hibernate. Today I am not so sure. Hibernate (and JPA) is great for some things especially early in the development cycle. It is much faster to get to something working with Hibernate than it is with JDBC. You get a lot of features for free - caching optimistic locking and so on. On the other hand it has some hidden costs. Hibernate is deceivingly simple when you start. Follow some tutorial put some annotations on your class - and you've got yourself persistence. But it's not simple and to be able to write good code in it requires good understanding of both it's internal workings and database design. If you are just starting you may not be aware of some issues that may bite you later on so here is an incomplete list. Performance The runtime performance is good enough I have yet to see a situation where hibernate was the reason for poor performance in production. The problem is the startup performance and how it affects your unit tests time and development performance. When hibernate loads it analyzes all entities and does a lot of pre-caching - it can take about 5-10-15 seconds for a not very big application. So your 1 second unit test is going to take 11 secods now. Not fun. Database Independency It is very cool as long as you don't need to do some fine tuning on the database. In-memory Session For every transaction Hibernate will store an object in memory for every database row it ""touches"". It's a nice optimization when you are doing some simple data entry. If you need to process lots of objects for some reason though it can seriously affect performance unless you explicitly and carefully clean up the in-memory session on your own. Cascades Cascades allow you to simplify working with object graphs. For example if you have a root object and some children and you save root object you can configure hibernate to save children as well. The problem starts when your object graph grow complex. Unless you are extremely careful and have a good understanding of what goes on internally it's easy to mess this up. And when you do it is very hard to debug those problems. Lazy Loading Lazy Loading means that every time you load an object hibernate will not load all it's related objects but instead will provide place holders which will be resolved as soon as you try to access them. Great optimization right? It is except you need to be aware of this behaviour otherwise you will get cryptic errors. Google ""LazyInitializationException"" for an example. And be careful with performance. Depending on the order of how you load your objects and your object graph you may hit ""n+1 selects problem"". Google it for more information. Schema Upgrades Hibernate allows easy schema changes by just refactoring java code and restarting. It's great when you start. But then you release version one. And unless you want to lose your customers you need to provide them schema upgrade scripts. Which means no more simple refactoring as all schema changes must be done in SQL. Views and Stored Procedures Hibernate requires exclusive write access to the data it works with. Which means you can't really use views stored procedures and triggers as those can cause changes to data with hibernate not aware of them. You can have some external processes writing data to the database in a separate transactions. But if you do your cache will have invalid data. Which is one more thing to care about. Single Threaded Sessions Hibernate sessions are single threaded. Any object loaded through a session can only be accessed (including reading) from the same thread. This is acceptable for server side applications but might complicate things unnecessary if you are doing GUI based application. I guess my point is that there are no free meals. Hibernate is a good tool but it's a complex tool and it requires time to understand it properly. If you or your team members don't have such knowledge it might be simpler and faster to go with pure JDBC (or Spring JDBC) for a single application. On the other hand if you are willing to invest time into learning it (including learning by doing and debugging) than in the future you will be able to understand the tradeoffs better. +1 excellent answer. I'm glad my vote sets it as first with 4 votes +1 Great answer.. I used to think Hibernate was the best thing ever but as our application grew in complexity (Larger object graphs) I have ran into a few scenarios where debuging was a nightmare because I had no idea what hibernate was doing. (Luckily it's open source so I was able to dig through the source to figure it out. NOT FUN) Anyway I agree.. No Free Meals. Hibernate is great but there are tradeoffs.  Hibernate best suits for the middleware applications. Assume that we build a middle ware on top of the data base The middelware is accessed by around 20 applications in that case we can have a hibernate which satisfies the requirement of all 20 applications.  Straight JDBC would fit the simplest cases at best. If you want to stay within Java and OOD then going Hibernate or Hibernate/JPA or any-other-JPA-provider/JPA should be your choice. If you are more comfortable with SQL then having Spring for JDBC templates and other SQL-oriented frameworks won't hurt. In contrast besides transactional control there is not much help from having Spring when working with JPA.  ... In-memory Session ... LazyInitializationException ... You could look at Ebean ORM which doesn't use session objects ... and where lazy loading just works. Certainly an option not overkill and will be simpler to understand.  Hibernate can be good but it and other JPA ORMs tend to dictate your database structure to a degree. For example composite primary keys can be done in Hibernate/JPA but they're a little awkward. There are other examples. If you're comfortable with SQL I would strongly suggest you take a look at Ibatis. It can do 90%+ of what Hibernate can but is far simpler in implementation. I can't think of a single reason why I'd ever choose straight JDBC (or even Spring JDBC) over Ibatis. Hibernate is a more complex choice. Take a look at the Spring and Ibatis Tutorial. thanks I will check out Ibatis.  No doubt Hibernate has its complexity. But what I really like about the Hibernate approach (some others too) is the conceptual model you can get in Java is better. Although I don't think of OO as a panacea and I don't look for theoritical purity of the design I found so many times that OO does in fact simplify my code. As you asked specifically for details here are some examples : the added complexity is not in the model and entities but in your framework for manipulating all entities for example. For maintainers the hard part is not a few framework classes but your model so Hibernate allows you to keep the hard part (the model) at its cleanest. if a field (like an id or audit fields etc) is used in all your entities then you can create a superclass with it. Therefore : you write less code but more importantly ... there are less concepts in your model (the unique concept is unique in the code) for free you can write code more generic that provided with an entity (unknown no type-switching or cast) allows you to access the id. Hibernate has also many features to deal with other model caracteristics you might need (now or later add them only as needed). Take it as an extensibility quality for your design. You might replace inheritance (subclassing) by composition (several entities having a same member that contains a few related fields that happen to be needed in several entities). There can be inheritance between a few of your entities. It often happens that you have two tables that have pretty much the same structure (but you don't want to store all data in one table because you would loose referential integrity to a different parent table). With reuse between your entities (but only appropriate inheritance and composition) there is usually some additional advantages to come. Examples : there is often some way to read the data of the entities that is similar but different. Suppose I read the ""title"" field for three entities but for some I replace the result with a differing default value if it is null. It is easy to have a signature ""getActualTitle"" (in a superclass or an interface) and implement the default value handling in the three implementations. That means the code out of my entities just deals with the concept of an ""actual title"" (I made this functional concept explicit) and the method inheritance takes care of executing the correct code (no more switch or if no code duplication). ... Over time the requirements evolve. There will be a point where your database structure has problems. With JDBC alone any change to the database must impact the code (ie. double cost). With Hibernate many changes can be absorbed by changing only the mapping not the code. The same happens the other way around : Hibernate lets you change your code (between versions for example) without altering your database (changing the mapping although it is not always sufficient). To summarize Hibernate lets your evolve your database and your code independtly. For all these reasons I would choose Hibernate :-)  I think either is a fine choice but personally I would use hibernate. I don't think hibernate is overkill for a project of that size. Where Hibernate really shines for me is dealing with relationships between entities/tables. Doing JDBC by hand can take a lot of code if you deal with modifying parent and children (grandchildren siblings etc) at the same time. Hibernate can make this a breeze (often a single save of the parent entity is enough). There are certainly complexities when dealing with Hibernate though such as understanding how the Session flushing works and dealing with lazy loading."
291,A,Connecting to SQLServer using JDBC-ODBC Bridge I'm writing an applicationt hat was prototyped on MySQL and is now connecting to an Oracle database. All I had to do to connect to the oracle database (having built up the table structure) was change the connection string. What is the format to connect to a SQL Server DB on another machine? I've read some tutorials which tell you to use the SQL Server JDBC adaptor but I'd rather configure the application so that it's database agnostic and just have the connection string specify the protocol etc. Any references I've seen which tell you how to use the bridge with SQL Server require the ODBC Data Source to be installed this is less than ideal as my app may run on Linux or windows. I'm not doing anything complicated just inserts. Do NOT use the JDBC-ODBC bridge driver. That was meant purely for testing not for production. You can still make your application database agnostic using drivers that are optimized for the database you want to connect to. Just externalize the username password database driver name and connect string and don't use any DB-specific SQL and you should be fine. For connecting to SQL Server use the jTDS driver http://jtds.sourceforge.net/ The connect string format looks like this: jdbc:jtds:sqlserver://localhost/my_database There are a few other parameters you can include separated by semicolons but I think this is all that's required. Obviously when you connect you'll need to supply a username and password.  You should not use the JDBC-ODBC bridge in a production environment. It is much slower than other JDBC drivers and only necessary when a JDBC driver is not available. SQL Server has a JDBC driver available from Microsoft. If you use it then you will get the required result. With the ODBC bridge you have no choice but to install the ODBC driver. This article describes the connection string you will need to use to connect to the SQL Server. As Joey Gibson mentioned you could consider using jTDS driver instead of Microsoft's own JDBC driver.  These days its quite easy to use Factory pattern and then load JDBC drivers to work with given databse. This architecture gives best of both worlds i.e. Flexibility and efficiency. The one downside of this is bit configuration/programming to handle dynamic loading but i hope so if you want to make it database agnostic that's the way to go.
292,A,"What to keep alive and what to recreate in a simple embedded database? In a desktop application with an embedded Derby database what should I keep alive (as opposed to recreating each time when talking with the database) for the whole lifetime of the application? Connection and Statement using the same statement throughout the lifetime of the program? Connection recreating statement repeatedly? Neither of these. That is recreating connection and statement repeatedly? From a database amateur's viewpoint it would seem reasonable to avoid recreating anything that doesn't need to be recreated but is option 1 (or 2) against standard practices or are there some obvious cons? Is (re)creating connections and statements expensive or not? In an embedded Derby application both Connection and Statement objects are quite cheap and I think you should not worry about creating them as you need them. In the Derby unit test suites we create tens of thousands of connections and hundreds of thousands of statements without problems. It is also fine to keep your Connection and Statement objects around as long as you wish. Embedded Derby has no time limit and will not drop the connection or statement objects unless you tell it to (by closing them) or unless you leak them away in which case the Garbage Collector will clean them up (eventually). Although it is fine to keep the connection around you should commit() the transaction when it is complete (unless you run in autocommit mode of course). And if you are keeping a result set around be aware that committing the transaction will usually also close the result set less you specifically construct the special result sets that are held open across commit.  Connecting is indeed expensive (may cost a few hundred milliseconds). The connection has however a limited lifetime and the statement and resultset depends on its lifetime. The average DB will timeout and drop the connection whenever it's been released for more than 30 minutes. You can add some timeout checker in your code so that it will re-acquire the connection ""automatically"" but that's a tedious work and very prone to bugs if you don't know how it ought to work under the hoods. Rather use an existing thoroughly developed and robust connection pool like C3P0 and write the JDBC code the usual way (acquire and close all the resources in the shortest possible scope). That should be it. Although in theory (and apparently also in practice) in embedded databases connecting will be less expensive and a connection can survive forever I would strongly disagree to approach embedded databases differently in JDBC code. It would make your JDBC code semantically flawed and completely unportable. You have to rewrite/reimplement everything whenever you'd like to distribute it and/or change to a real RDBMS server with more powers. Does that stand true for embedded dbs ? I imagined that since there is no server behind it the life-time of the connection could be pretty much infinite ?"
293,A,"Does Oracle support Server-Side Scrollable Cursors via JDBC? Currently working in the deployment of an OFBiz based ERP we've come to the following problem: some of the code of the framework calls the resultSet.last() to know the total rows of the resultset. Using the Oracle JDBC Driver v11 and v10 it tries to cache all of the rows in the client memory crashing the JVM because it doesn't have enough heap space. After researching the problem seems to be that the Oracle JDBC implements the Scrollable Cursor in the client-side instead of in the server by the use of a cache. Using the datadirect driver that issue is solved but it seems that the call to resultset.last() takes too much to complete thus the application server aborts the transaction is there any way to implemente scrollable cursors via jdbc in oracle without resorting to the datadirect driver? and what is the fastest way to know the length of a given resultSet?? Thanks in advance Ismael I gave an example of getting the 'total rows' in a resultset and the result set itself in the same SQL query in Oracle here: http://stackoverflow.com/questions/2840/paging-sql-server-2005-results/11352#11352 I'll ask a tangent question first; Do you need the data and the size of the resultset at the same time or could you just do a COUNT(*) type query to find the number of rows? Do you REALLY need the number of rows also I've seen this too many times where a program does the very expensive operation of getting the total number of rows for pagination when it's really not needed. It's need to determine the number of pages in a pagination scheme. We're trying to avoid the use of last and counting the currentIndex using the iterator next() method checking for null. Is there a fast way to know the number of pages without using the last() method. Our workaround is to execute a COUNT query with the same conditions and then perform the query for the data Does the user need to know the number of pages? Is there a valid user case where a user would want to go directly to the last page? We generally just ask for 1 more entry then needed for a page then if that entry exists put a link for the ""next"" page - requery to get the next page. Assuming your data has some form of order that you could sort by. ""what is the fastest way to know the length of a given resultSet"" The ONLY way to really know is to count them all. You want to know how many 'SMITH's are in the phone book. You count them. If it is a small result set and quickly arrived at it is not a problem. EG There won't be many Gandalfs in the phone book and you probably want to get them all anyway. If it is a large result set you might be able to do an estimate though that's not generally something that SQL is well-designed for. To avoid caching the entire result set on the client you can try select id count(1) over () n from junk; Then each row will have an extra column (in this case n) with the count of rows in the result set. But it will still take the same amount of time to arrive at the count so there's still a strong chance of a timeout. A compromise is get the first hundred (or thousand) rows and don't worry about the pagination beyond that. +1: while it would be nice to know the number of rows that a query will return this information WILL have to be computed and therefore will have a cost. Gary's answer is probably the least expensive way to do this.  your proposed ""workaround"" with count basically doubles the work done by DB server. It must first walk through everything to count number of results and then do the same + return results. Much better is the method mentioned by Gary (count(*) over() - analytics). But even here the whole result set must be created before first output is returned to the client. So it is potentially slow a memory consuming for large outputs. Best way in my opinion is select only the page you want on the screen (+1 to determine that next one exists) e.g. rows from 21 to 41. And have another button (usecase) to count them all in the (rare) case someone needs it."
294,A,"trying to get a query to use the LIKE function with a variable in JSP I have a query that is being used to pull usernames and info about the user. In Access I had the LIKE function so that the user didn't have to type in a specific name. I am now transferring it over to JSP. Here is the line in the query that I am having troubles with in JSP: WHERE ObjectName Like '"" + ""%""+ VariableName + ""%"" +""'; The query runs fine but does not show any information even if I put in the entire name. If I change it to: WHERE ObjectName = '"" + VariableName +""'; it works but I would like to give the user a chance to have to ability to put in partial names in case they do not know how to spell the name or typ eit incorrectly. Any help would be apprecited. Thanks The line you've shown is a bit odd but syntactically valid. So the problem lies somewhere else. What does variableName actually contain? That said you shouldn't be writing raw Java code in JSP files. Do that in a Java class. You can use a Servlet class to preprocess or postprocess requests. Also grab PreparedStatement to avoid SQL injections. Here's a kickoff example: public List<User> search(String username) throws SQLException { Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; List<User> users = new ArrayList<User>(); try { connection = database.getConnection(); statement = connection.prepareStatement(""SELECT id username age email FROM user WHERE username LIKE ?""); statement.setString(1 ""%"" + username + ""%""); resultSet = statement.executeQuery(); while (resultSet.next()) { users.add(mapUser(resultSet)); } } finally { close(connection statement resultSet); } return users; }  Avoid writing SQL queries in JSP ""SELECT * FROM something WHERE ObectName LIKE '%"" + VariableName + ""%'"" should work  this is an answer for starting users i am created a data base in a name ASHRAF then i create a table in name CASH. the code is given below CREATE TABLE CASH(NO INT NOT NULL PRIMARY KEY AUTO_INCREMENTNAME VARCHAR(50) NOT NULLADDRESS VARCHAR(100)PET_NAME VARCHAR(50)PLACE VARCHAR(50)TYPE VARCHAR(20)TYPE_OF_PAY VARCHAR(20)AMOUNT INT(6) NOT NULL); here the NO is auto increment ant it is primary key anyway you can search the contents from the table using jsp code that i given below am search here using both NAME ADDRESS you can pass the parameters using a html page and a servlet The html page(show.html) that i created is given below <!DOCTYPE html PUBLIC ""-//W3C//DTD HTML 4.01 Transitional//EN"" ""http://www.w3.org/TR/html4/loose.dtd""> <html> <head> <meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8""> <title>show.html</title> </head> <body> <h1><b><font color=020202>SHOW</font></b></h1><br><br> <form name=""f6"" action=""getshow"" method=""POST"" onsubmit=""return check(this)""> <table border=""0""> <tr> <td>Name :</td><td><input type=""text"" name=""name""></td> </tr> <tr> <td>House Name :</td><td><input type=""text"" name=""address""></td> </tr> <tr> <td><br><input type=""SUBMIT"" value=""submit""></td> </tr> </table> </form> </body> </html> The servlet is(getshow.java) given below package Servlets; import java.io.IOException; import javax.servlet.RequestDispatcher; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; /** * Servlet implementation class getdata */ public class getshow extends HttpServlet { private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public getshow() { super(); // TODO Auto-generated constructor stub } /** * @see HttpServlet#doGet(HttpServletRequest request HttpServletResponse response) */ protected void doGet(HttpServletRequest request HttpServletResponse response) `` throws ServletException IOException { // TODO Auto-generated method stub } /**` * @see HttpServlet#doPost(HttpServletRequest request HttpServletResponse ``response) */ protected void doPost(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { // TODO Auto-generated method stub try{ String url=null; String s1=request.getParameter(""name""); String s2=request.getParameter(""address""); request.setAttribute(""name""s1); request.setAttribute(""address""s2); url=""show.jsp""; RequestDispatcher view=request.getRequestDispatcher(url); view.forward(request response); } catch (Exception e) { // TODO Auto-generated catch block e.printStackTrace(); } } } The jsp file is(show.jsp) given below <%@ page language=""java"" contentType=""text/html; charset=UTF-8"" pageEncoding=""UTF-8""%> <!DOCTYPE html PUBLIC ""-//W3C//DTD HTML 4.01 Transitional//EN"" ""http://www.w3.org/TR/html4/loose.dtd""> <html> <head>` <meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8""> <title>show.jsp</title> </head> <body> <%String aid=(String)request.getAttribute(""name""); %> <%String sid=(String)request.getAttribute(""address""); %> <% Connection con=null; ResultSet rs=null; String records=null; StringBuffer appender=new StringBuffer(); java.sql.PreparedStatement st=null; try { Class.forName(""com.mysql.jdbc.Driver"").newInstance(); con=DriverManager.getConnection(""jdbc:mysql://localhost/ASHRAF?user=root&password=password""); st=con.prepareStatement(""select *from CASH where NAME like '"" + aid + ""%"" +""' and ADDRESS like '"" + sid + ""%"" +""'""); rs=st.executeQuery(); %> <center><TABLE cellpadding=""15"" border=""2""> <TR> <TH>NO</TH> <TH>NAME</TH> <TH>HOUSE NAME</TH> <TH>PET NAME</TH> <TH>PLACE</TH> <TH>TYPE OF OCCATION</TH> <TH>TYPE OF PAY</TH> <TH>AMOUNT</TH> </TR> <% while (rs.next()) { %> <TR> <TD><%=rs.getString(1)%></TD> <TD><%=rs.getString(2)%></TD> <TD><%=rs.getString(3)%></TD> <TD><%=rs.getString(4)%></TD> <TD><%=rs.getString(5)%></TD> <TD><%=rs.getString(6)%></TD> <TD><%=rs.getString(7)%></TD> <TD><%=rs.getString(8)%></TD> </TR> <% } %> </TABLE> </center> </div> <% } catch (Exception e) { // TODO Auto-generated catch block e.printStackTrace(); } finally { try { con.close(); } catch (SQLException e) { // TODO Auto-generated catch block e.printStackTrace(); } } %> </body> </html> now you can search either with the name nor with the address or with both. To make this useful at all you'll need to go back and do some major reformatting... as-is your 'answer' is unreadable."
295,A,"Connect to a secure database using JDBC How do you specify the username and password for a JDBC connection when acessing a secure database? The DriverManager.getConnection method has a signature which takes a username and password. In addition JDBC drivers tend to support specifying them on the URL  You should be able to specify them in DriverManager.getConnection() like Connection conn = DriverManager.getConnection(""jdbc:oracle:thin:@"" + dbname dbusername dbpassword);"
296,A,stored procedures in scala.dbc I wonder if scala.dbc supports stored procedures? The mysql jdbc backend I'm using supports it bonus points for a code illustration to show how it works. I don't think there's any work going on on Scala dbc anymore. You would have to wait for Scala dbc3 but I have no idea what the status of that is at the moment. You had better look at http://stackoverflow.com/questions/1362748/wanted-good-examples-of-scala-database-persistence for an excellent overview of alternatvie Scala SQL frameworks. I don't believe that any of the ones mentioned in the link support stored procedures out of the box however.
297,A,"Temporary in-memory database in SQLite Is it possible somehow to create in-memory database in SQLite and then destroy it just by some query? I need to do this for unit testing my db layer. So far I've only worked by creating normal SQLite db file and delete if after all tests but doing it all in memory would be much better. So is it possible to instanciate database only in memory without writing anything to disc? I can't use just transactions because I want to create whole new database. Create it with the filename "":memory:"": In-Memory Databases. It'll cease to exist as soon as the connection to it is closed. wow thx for superfast answer :) Is it posible to work with an in-memory database and then copy it to disk? (the idea is to *accelerate the blocking and time-expensive operations of writings*)  I'd suggest mounting a tmpfs filesystem somewhere (RAM only filesystem) and using that for your unit tests. Instantiate DB files as normal then blow them away using rm - yet nothing has gone to disk. (EDIT: Nice - somebody beat me to a correct answer ;) Leaving this here as another option regardless)"
298,A,What is a good strategy for caching prepared statements in Tomcat? I am looking for a way to cache prepared statements in a servlet environment (specifically Tomcat 5.5). This is meant to reduce the number of times that prepared statements are created i.e. the number of times that connection.prepareStatement(sql) is called. My initial idea was to store PreparedStatement objects in the session where the key (the attribute name) is the query itself. This can also be done lazily. However someone alerted me to the fact that depending on the JDBC driver implementation the same prepared statement may be accessed by 2 threads (or requests) simultaneously resulting for example in the wrong parameters being set. Therefore the access to these statement objects needs to be synchronized. What would be a good strategy to achieve this? Is there a method built in to tomcat for doing this? I have see this answer where it mentions the poolPreparedStatements DBCP parameter but it's not entirely clear from the documentation if it carries the same meaning as what I'm looking for. I'm not sure about other DBs but if you're using Oracle the JDBC client will cache the PreparedStatement. You might want to see if your DB does that.  PreparedStatement caching is usually provided by the connection pool you are using. In c3p0 you can activate it by setting the maxStatements and maxStatementsPerConnection settings In DBCP it is done by setting the poolPreparedStatements and maxOpenPreparedStatements parameters Notice that in the way connection pool works one thread acquires a connection use it for some sql queries and return it to the pool. Only then the connection is available to another thread. Unless there is a bug in in the connection pool connections are not shared among threads concurrently. BTW - my recommendation is to use c3p0 and not DBCP. I had a lot of issues with DBCP that were solved once I moved to c3p0.
299,A,"Java:how to pass value from class/bean to servlet i am new to java i'm having problem passing value from a class/bean (which are stored in arraylist) to servlet. any idea how can i achieve that? below is my code. package myarraylist; public class fypjdbClass { String timezone; String location; public String getTimezone() { return timezone; } public void setTimezone(String timezone) { this.timezone = timezone; } public String getLocation() { return location; } public void setLocation(String location) { this.location = location; } public fypjdbClass() { super(); ArrayList<fypjdbClass> fypjdbList = new ArrayList<fypjdbClass>(); this.timezone = timezone; this.location = location; } public static void main(String[] args) { //Establish connection to MySQL database String connectionURL = ""jdbc:mysql://localhost/fypjdb""; Connection connection=null; ResultSet rs; try { // Load the database driver Class.forName(""com.mysql.jdbc.Driver""); // Get a Connection to the database connection = DriverManager.getConnection(connectionURL ""root"" """"); ArrayList<fypjdbClass> fypjdbList = new ArrayList<fypjdbClass>(); //Select the data from the database String sql = ""SELECT locationtimezone FROM userclient""; Statement s = connection.createStatement(); //Create a PreparedStatement PreparedStatement stm = connection.prepareStatement(sql); rs = stm.executeQuery(); //rs = s.getResultSet(); while(rs.next()){ fypjdbClass f = new fypjdbClass(); f.setTimezone(rs.getString(""timezone"")); f.setLocation(rs.getString(""location"")); fypjdbList.add( f); } for (int j = 0; j < fypjdbList.size(); j++) { System.out.println(fypjdbList.get(j)); } //To display the number of record in arraylist System.out.println(""ArrayList contains "" + fypjdbList.size() + "" key value pair.""); rs.close (); s.close (); }catch(Exception e){ System.out.println(""Exception is ;""+e); } } } And this is the Servlet package myarraylist; public class arraylistforfypjServlet extends HttpServlet { private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public arraylistforfypjServlet() { super(); } public static ArrayList<fypjdbClass> fypjdbList = new ArrayList<fypjdbClass>(); /** * @see HttpServlet#doGet(HttpServletRequest request HttpServletResponse response) */ protected void doGet(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { //processRequest(request response); RequestDispatcher rd = request.getRequestDispatcher(""/DataPage.jsp""); //You could give a relative URL I'm just using absolute for a clear example. ArrayList<fypjdbClass> fypjdbList = new ArrayList<fypjdbClass>();// You can use any type of object you like here Strings Custom objects in fact any object. request.setAttribute(""fypjdbList"" fypjdbList); rd.forward(request response); } protected void doPost(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { //processRequest(request response); doGet(requestresponse); } } i dont know if my code is right pls advise me. thanks lot ^^ you're storing your array in a request after the method is executed in a servlet `doGet()` or `doPost()` the request is cleared. Why not save it in Session? (`request.getSession().setAttribute(....)`. It looks like you are trying to load data from a database into the fypjdbList ArrayList in your servlet. It isn't working because your servlet is not calling the database code. Your database code is in the main method of fypjdbClass; the main method is generally used by Java console or desktop applications but not in a Java servlet application. A better way to retrieve data from the database is to create a Data Access Object (DAO). This is a Java class that contains only code to access the database. The DAO retrieves data for you but does not store data itself (it would not contain timezone or location). The concept of a DAO is explained at http://java.sun.com/blueprints/corej2eepatterns/Patterns/DataAccessObject.html Google will find you a number of tutorial on DAOs (I can't post the links here because as a new member of Stack Overflow I can only post one link!) Writing servlets is useful when learning Java but if you want to build a full website you will probably find it easier to use a framework like the Spring MVC (part of the Spring Framework). Spring MVC has a comprehensive step-by-step tutorial available which is very useful if you're new to Java web development.  Why to confuse a newbie with different patterns! @OP - Change your main() method to return data instead of void and create an instance for that class in the servlet.  You don't pass something into a servlet. You just let the servlet access something. You should get rid of that main() method and move the database interaction code into a DAO class. I'd also give the model class (with timezone and location) a more sensitive name starting with an uppercase. So all with all you should update the code so that it look something like the following: Model class the Area (name it whatever you want as long as it makes sense) it should just represent a single entity: public class Area { private String location; private String timezone; public String getLocation() { return location; } public String getTimezone() { return timezone; } public void setLocation(String location) { this.location = location; } public void setTimezone(String timezone) { this.timezone = timezone; } } Basic connection manager class the Database here you load the driver just once and provide a getter for the connection: public class Database { private String url; private String username; private String password; public Database(String driver String url String username String password) { try { Class.forName(driver); } catch (ClassNotFoundException e) { throw new RuntimeException(""Driver class is missing in classpath"" e); } this.url = url; this.username = username; this.password = password; } public Connection getConnection() { return DriverManager.getConnection(url username password); } } DAO class the AreaDAO here you put all DB interaction methods: public class AreaDAO { private Database database; public AreaDAO(Database database) { this.database = database; } public List<Area> list() throws SQLException { Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; List<Area> areas = new ArrayList<Area>(); try { connection = database.getConnection(); statement = connection.prepareStatement(""SELECT location timezone FROM userclient""); resultSet = statement.executeQuery(); while (resultSet.next()) { Area area = new Area(); area.setLocation(resultSet.getString(""location"")); area.setTimezone(resultSet.getString(""timezone"")); areas.add(area); } } finally { if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } return areas; } } Finally in the servlet initialize the DAO once and obtain the list in the HTTP method: public class AreaServlet extends HttpServlet { private AreaDAO areaDAO; public void init() throws ServletException { String driver = ""com.mysql.jdbc.Driver""; String url = ""jdbc:mysql://localhost:3306/dbname""; String username = ""user""; String password = ""pass""; Database database = new Database(driver url username password); this.areaDAO = new AreaDAO(database); } protected void doGet(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { try { List<Area> areas = areaDAO.list(); request.setAttribute(""areas"" areas); request.getRequestDispatcher(""/WEB-INF/areas.jsp"").forward(request response); } catch (SQLException e) { throw new ServletException(""Cannot retrieve areas"" e); } } } Map this servlet on an url-pattern of /areas in web.xml so that you can invoke it by http://example.com/contextname/areas The /WEB-INF/areas.jsp can look like something this assuming that you want to display the areas in a table: <table> <c:forEach items=""${areas}"" var=""area""> <tr> <td>${area.location}</td> <td>${area.timezone}</td> </tr> </c:forEach> </table> See also: Beginning and intermediate JSP/Servlet tutorials Advanced JSP/Servlet tutorials DAO tutorial (contains more advanced/flexible DAO examples) Hidden features of JSP/Servlet Great answer! Your code clearly reveals MVC pattern. Thanks for posting such an excellent answer for a beginner to start with"
300,A,"Cannot create schema from Hibernate I'm trying to propagate the schema from the Hibernate configuration to the RDBMS. The code runs without any error message but the database doesn't get updated. Any hints ? Thank you ! Update That is hibernate-core only with a HSQL database. Update 2 Yes i should use SchemaExport (i'm away from hibernate a while )but it don't flush to the database. It is a HSQL in-process database (jdbc:hsqldb:file:config/config). Update 3 Something does not work with HSQL trying now with MySQL and all works fine !  public static void exportSchema() { new SchemaExport(hbConfig).create(true true); } public static void exportSchemaXXX() { // sessionFactory and hbConfig defined in the class Session sess = sessionFactory.openSession(); sess.doWork(new Work() { public void execute(java.sql.Connection conn) throws SQLException { System.err.println(""work""); try { Class dialect = Class.forName(hbConfig.getProperty(""hibernate.dialect"")); String[] lines = hbConfig.generateSchemaCreationScript((Dialect) dialect.newInstance()); for (String s : lines) { System.err.println(s); Statement stm = conn.createStatement(); stm.execute(s); } } catch (Exception ex) { System.err.println(""Error: "" + ex); } } }); sess.flush(); sess.close(); } Are you using hibernate on its own? Or are you using spring with it? Does the code in your for loop get hit? You can try forcing a commit when your done but with out knowing the database your using I'm not sure if this is the problem. Assuming your using pojo's to represent your database schema why are you executing the statements one by one through a JDBC connection instead of using Hibernates built in schema class similar to the following? config=new AnnotationConfiguration() config.addAnnotatedClass(Badge.class) config.addAnnotatedClass(Vote.class) config.configure() new SchemaExport(config).create(truetrue)//create the database tables For more info on this see this link  Ensure that your transaction gets committed. Some databases will actually roll back schema changes if the transaction gets rolled back.  Have this now. Seems that HSQLDB beginning with version 1.7 needs shutdown for in-memory to flush all changes."
301,A,"Why does autoReconnect=true not seem to work? I am using JDBC to connect to a MySQL server (no connection pooling I think). In the connection URL I have autoReconnect=true But my connection still times out. I've even checked conn.isClosed() and its false. But when I try to use the connection I get the following exception.  com.mysql.jdbc.CommunicationsException: Communications link failure due to underlying exception: ** BEGIN NESTED EXCEPTION ** java.net.SocketException MESSAGE: Software caused connection abort: socket write error STACKTRACE: java.net.SocketException: Software caused connection abort: socket write error ... I know in Java 1.6 you can use conn.isValid(0) to check the connection but I am using Java 1.5 Is there a way to either ensure it doesn't time out? Or am I going to have to upgrade to Java 1.6? autoReconnect still throws the exception so you can choose to do something about the situation if you like. If you catch it you should find that the connection is there again afterward. (There's some more complexity if you're in a transaction -- your current transaction is pretty much dead.)  I had the same issue and it was absolutely maddening. Here's what the docs say on the MySQL website (emphasis mine) *Should the driver try to re-establish stale and/or dead connections? If enabled the driver will throw an exception for a queries issued on a stale or dead connection which belong to the current transaction but will attempt reconnect before the next query issued on the connection in a new transaction. The use of this feature is not recommended because it has side effects related to session state and data consistency when applications do not handle SQLExceptions properly and is only designed to be used when you are unable to configure your application to handle SQLExceptions resulting from dead and stale connections properly. Alternatively investigate setting the MySQL server variable ""wait_timeout"" to some high value rather than the default of 8 hours.* In my experience it doesn't seem like the ""reconnect on the next query"" functionality worked either but I was using MySQL 4.0 which may have been the reason for that. I ended up writing a mini-framework that catches the exceptions checks for that specific error and attempts to reconnect and retry the query if possible. ETA: This link provides a bit more information and indicates that autoReconnect will probably be removed in the future anyways. The advice not to use autoReconnect because it will be removed in the future is 8-10 years old. And yet I'm still seeing MySQL 5.x provide guidance that setting the Connector/J autoReconnect property is an option to solve this problem... From the linked doc: ""There is no 100% safe way that a JDBC driver can re-connect automatically if a TCP/IP connection dies without risking corruption of the database 'state' (even _with_ transactional semantics) which is why this feature will eventually be removed."""
302,A,Oracle JDBC connection pooling with database link I'm building a J2EE web apps with Oracle database. The app server uses JDBC connection pooling to Oracle database A (e.g. 20 connections max) and some of the queries performed use tables in remote Oracle database B via database link. If the App Server creates 20 connections to database A and all queries are looking up data in database B will database A create 20 connections to database B? Or all queries are through the same connection tunnel? There's a one-to-one relationship between the local and remote database sessions. There has to be for the following situations: Session A1 on the local DB runs INSERT INTO table@B VALUES ('A1'); That insert is part of Session A1's transaction. Session A2 comes along and does a SELECT * FROM table@B. Because Session A1 hasn't committed yet session A2 shouldn't see the row. Therefore it needs a remote session that is distinct from that belonging to A1. Equally you could have all 20 sessions on database A running queries concurrently on database B. There is a DBMS_SESSION.CLOSE_DATABASE_LINK procedure which will disconnect the remote connection. I had some problems with that (9i database) when it refused to close them claiming 'outstanding transactions' even immediately after a commit. It seemed to relate to cached PL/SQL cursors. It may no longer be an issue.
303,A,Using PHP can I use a JDBC or ODBC connection? I have a PHP application that I want to switch from MySQL to Cache DB. I was wondering if I could somehow use a JDBC or ODBC connection since Cache doesn't come with a PHP connection? Thanks http://www.google.com/search?q=php+JDBC+&ie=utf-8&oe=utf-8&aq=t&rls=org.mozilla:de:official&client=firefox-a Sorry: -1 for a Google only link (and it tells you use firefox?). So you see any other answer than a reference to a quick google result?  PHP can use ODBC connections either directly or through PDO (recommended) using PDO_ODBC. PDO is recommended because it's easier to switch between databases if you use it... it's similar in concept to JDBC that way.  Probably not the most efficient method but take a look at the PHP-Java Bridge http://php-java-bridge.sourceforge.net/pjb/ or http://php.net/manual/en/book.java.php
304,A,"Building resultset using collection object I had an issue in building the resultset using java. Here it goes... I am storing a collection object which is organized as row wise taken from a resultset object and putting the collection object(which is stored as vector/array list) in cache and trying to retrieve the same collection object. Here i need to build back the resultset again using the collection object. Now my doubt is building the resultset in this way possible or not? Please let me know asap. Thanks in advance Bhaskar ohh I am not aware of that.. Thanks Wolfman I see that you are new here so you need to take time to look at the tagging system in place here. Many of us only look at certain Tags. I only found your question after it had been retagged with a Java Tag. Correctly tagging your questions will get you much better responses. The best idea if you are using a collection in place of a cache is to use a CachedRowSet instead of a ResultSet. CachedRowSet is a Subinterface of ResultSet but the data is already cached. This is far simpler than to write all the data into an ArrayList. CachedRowSets can also be queried themselves. CachedRowSet rs; ....................... ....................... Integer id; String name; while (rs.next()) { if (rs.getInt(""id"") == 13) { id = rs.getInt(""id""); name = rs.getString(""name"")); } } So you just call the CachedRowSet whenever you need the info. It's almost as good as sliced bread. :) EDIT: There are no set methods for ResultSet while there are Update methods. The problem with using the Update method's for the purpose of rebuilding a ResultSet is that it requires selecting a Row to update. Once the ResultSet has freed itself all rows are set to null. A null reference cannot be called. A List of Lists mimics a ResultSet itself or more correctly an array of arrays mimic a ResultSet. While Vectors are thread safe there is a huge overhead attached to them. Use the ArrayList instead. As each nested List is created and placed into the outer nest List insert it in this manner. nest.add(Collections.unmodifiableList(nested)); After all of the nested Lists are inserted return the nest List as an umodifiableList as well. This will give you a thread-safe collection without the overhead of the vectors. I don't think I understand why you would want to rebuild a ResultSet. If you rebuild the ResultSet you get right back to having this huge object on one node. The thing about the ""huge overhead"" of Vector is nonsense; in fact if you actually need the basic synchronization it provides it is faster than using Collections.unmodifiableList(). It is all according to haw many threads are calling it at one time. If many threads start calling it at once watch your system crawl to a stop with a vector. Using Vectors limit the use of the code. There are uses for it still but in all it is outdated. Collections.unmodifiableList() are not synchronized just thread safe. That is why it is faster for multiple threads. The trade off is that it is unmodifiable. As long as it is read only as in the case of this question there is no reason to use vectors. Oops - I was thinking of Collections.synchronizedList() - though I still doubt very much the performance hit is as big as you make it sound - very few apps actually have a large number of concurrently working threads accessing shared data. Yes Wolfman what you said is a good option. But here there is a problem.. when we use cachedRowSetImpl we are trying to put single object in cache. This will create problem when the size of the query result is huge. Instead if we use a array list/vector object we can put this on multiple nodes using clustering right. So is there any api or method using which I can build a resultset after getting the data from cache?  Another option you should consider is just to refactor your code to accept a Collection instead of a ResultSet. I'm assuming you pass that ResultSet to a method that iterates over it. You might as well change the method to iterate over an ArrayList...  I will advise you to use CachedRowSet. Refer http://www.onjava.com/pub/a/onjava/2004/06/23/cachedrowset.html this article to know more about CachedRowSet. Once you create this CachedRowSet you can disconnect from the database make some changes to the cached data and letter can even open the DB connection and commit the changes back to the Database.  From what I could get your code may be like this: List collection = new ArrayList(); collection.add("" A collection in some order""); List cache = new ArrayList(); cache.add(collection); ... Now when you retrieve I think you'll get your collection in order since you have used List. If this is not what you were expecting do comment. Yes I am able to get the collection back from the cache. After this I need to build the resultset again. Is that possible? I think you have in the collection that you are getting back. COde snippet may help. Basically I need to build a resultset object with all the functions that a resultset can do and the data should be that retrieved from the collection object. But is creating a resultset object possible (taking for granted that the db connection still exists)?  Take a look at this page. Try to see if the SimpleResultSet class is fine for your needs. If you combine http://h2database%5C.googlecode%5C.com"">its source into a standalone set of classes it should do the trick."
305,A,"Check if a column is auto incremented in Sybase with JDBC To check if a column is auto incremented i can do the following Connection con = ... DatabaseMetaData meta = con.getMetaData(); ResultSet metaCols = meta.getColumns(catalog schema table ""%""); while ( metaCols.next() ) String value = rs.getString(""IS_AUTOINCREMENT"") ... works fine except with Sybase databases. I've tried it with the jTDS and JConnect drivers but with both drivers I get the this exception: java.sql.SQLException: Invalid column name IS_AUTOINCREMENT. Is there another the get find out whether a column in Sybase is auto incremented or not? I thought ""IS_AUTOINCREMENT"" is a feature with JDBC4 and jTDS is a JDBC4 compatible driver. sp_help delivers all the information I need. This SP returns several ResultSets. The third ResultSet contains the information I need. Statement stmt = con.createStatement(); stmt.executeQuery(""sp_help "" + table); stmt.getMoreResults(); stmt.getMoreResults(); ResultSet rs = stmt.getResultSet(); //... while( rs.next() ) boolean identity = rs.getBoolean(""Identity"");  Sybase uses 'identity' columns rather than 'default autoincrement' which is why I believe you are getting this message. Try checking if TYPE_NAME column contains keyword ""identity"". The behaviour of identity columns is a little different also but that is an aside. the columns identity or IDENTITY does not exist. But thanks for the advice. See my answer I found after your hint.  Sorry I misunderstood as you have found below using sp_help if the identity column contains a 1 then the column is an identity. There are also other methods available. I was concentrating on Java methods when I could have given you the answer in seconds had I known you would be happy with SQL commands such as sp_help sp_columns and selecting from systemtables. Best of luck.  This is the easiest way to get the identity information  ResultSet tableInfo = tableInfoQuery.executeQuery(""SELECT * FROM "" + tableName + "" WHERE 1=2""); ResultSetMetaData rsMetaData = tableInfo.getMetaData(); for (int i = 1; i < = rsMetaData.getColumnCount(); i++) {rsMetaData.isAutoIncrement(i);}  What version of JConnect are you using? Try using 6. It should work using: DatabaseMetaData.getTypeInfo() PS. Sorry new to the site not enough points to comment on your post :( DatabaseMetaData.getTypeInfo() returns only the data type supported by the database. But this information is not helpful to find an identity column."
306,A,using Spring JdbcTemplate if i create a new instance of JdbcTemplate like so; JdbcTemplate jdbcTemplate = new JdbcTemplate(getDataSource()); by passing the datasource as a param (the datasource retrieves a connection from server connection pool) am i required to close the connection when im finished with it? In other words if i have a pool of connections will the previous code cause my application to create a new connection each time a request executes the code No. That's the whole deal. Use the JdbcTemplate and it will manage the ressources (Connection PreparedStatement ResultSet). It is an implementation of the template method design pattern. Javadoc: It simplifies the use of JDBC and helps to avoid common errors. It executes core JDBC workflow leaving application code to provide SQL and extract results. thanks Thomas my problem is somewhere else then.  What I did was to extend the JdbcTemplate and override the execute method to use the connection pool (a particular case). In my case the connections are pooled per user I don't know the details of your particular case but in general [`JdbcTemplate` will be injected with a `DataSource`](http://static.springsource.org/spring/docs/3.1.x/spring-framework-reference/html/jdbc.html#jdbc-JdbcTemplate-idioms) which is an instance of the class `org.apache.commons.dbcp.BasicDataSource` and thus already implements connection pooling.
307,A,"java - POST vs JDBC OK so here's the code: import java.io.BufferedReader; import java.io.InputStreamReader; import java.net.URL; public class Main { public static void main(String[] args) { try { URL my_url = new URL(""http://www.viralpatel.net/blogs/""); BufferedReader br = new BufferedReader(new InputStreamReader(my_url.openStream())); String strTemp = """"; while(null != (strTemp = br.readLine())){ System.out.println(strTemp); } } catch (Exception ex) { ex.printStackTrace(); } } } Using this method I can use POST and GET methods using PHP scripts. I can then use the PHP scripts to the MySQL database which in turn outputs back to the java applet. Is this possible? (and safer?) Thanks. You have to have an intermediary between the applet and database. If you're already writing Java I'd put a servlet in between. It can handle GET and POST requests but there are other benefits as well: You can have some measure of security because the servlet can ask for credentials and only allow authenticated users to access the database. You can even add role based security to allow authorized users to do certain things (e.g. only admins write to the database). You can bind and validate request parameters before passing them back to the database. Combine this with prepared statements and your database will be safer from SQL injection attacks. The servlet container maintains a thread pool and assigns one thread per incoming request. Your app will be able to accomodate more users than a simple client/server app which is bound by # of connections. The servlet container can maintain a pool of database connections. This will help to make your app more responsive because it spreads the cost of connection creation across all requests. Why can't I just have the PHP page do the mysql work and the java applet the display?  It is definitely possible to connect to an intermediate script. You can use apache http components for that purpose. You shouldn't use JDBC from an applet to connect to remote database because someone will read the credentials and ""hack"" your database. If you want a better approach with a similar idea - make a REST API. I would rather use POST and GET requests to connect to my MYSQL database... that's good right? You can't connect to MySQL via HTTP."
308,A,accessing Object[] values in Java Regarding to this image: link text I have an object 'rezultat' which has getters and setters. I wanna set for 'cli' attribute ( rezultat.setCli(String .....) ) and as string parameter it should be that m_objArray[0] so 'ADSL22675....' from that image. Expanding m_objArray there are 19 attributes i need to set for the 'rezultat' object attributes. But i don't know how to access them. Array o = ocs.getArray(1); Object[] obj = (Object[])o.getArray(); rezultat = new ListOfMdfTab(); for (int i = 0; i < obj.length; i++) { rezultat.setCli ((String)obj[0].<what>?); //i need here that m_objArray[0]. } 'ocs' is an OracleCallableStatament object type so i need Array o = ocs.getArray(1); because that 1 index is the out parameter which is a complx type. Please help. Thanks! This statement will return a String or will throw a clasCastException if the Object is not a string: (String)obj[0] If you're not sure if it is a String you could use obj[0].toString() OR String.valueOf(obj[0]) Which will handle nulls more elegantly From the picture OP linked `obj[0]` is a `STRUCT` (whatever that means). Within it there's a `Object[] m_objArray` which contains `String`. At least that's how I'm reading it. I tried with obj[0].toString() and it returned oracle.sql.STRUCT. So the type. I need the values from m_objArray that node contains 19 elements whose values i need (see that image). Yes true: rom the picture OP linked obj[0] is a STRUCT (whatever that means). Within it there's a Object[] m_objArray which contains String. At least that's how I'm reading it. And how can access m_objArray's values?  STRUCT is an oracle class that implements the java.sql.Struct interface. This interface offers a getAttributes() method. It's worth a try calling this method and hoping for the best that the array that is returned is equal to the internal m_objArray. In Java code: rezultat.setCli(((java.sql.Struct)obj[0]).getAttributes()[0].toString()); @Roger: you should then mark this answer accepted. Also see http://stackoverflow.com/faq Worked thanks!
309,A,"Jython CLASSPATH sys.path and JDBC drivers How can I add JDBC drivers at runtime to Jython? Using CLASSPATH works but using sys.path doesn't work with zxJDBC even though the class is imported fine and can be manipulated from the Jython interpreter prompt. Why does this work: $ CLASSPATH=/tmp/jtds\-1.2.5.jar ./jython *sys-package-mgr*: processing new jar '/private/tmp/jtds-1.2.5.jar' Jython 2.5.1 (Release_2_5_1:6813 Sep 26 2009 13:47:54) [Java HotSpot(TM) 64-Bit Server VM (Apple Inc.)] on java1.6.0_20 Type ""help"" ""copyright"" ""credits"" or ""license"" for more information. >>> from java.lang import Class >>> Class.forName('net.sourceforge.jtds.jdbc.Driver') <type 'net.sourceforge.jtds.jdbc.Driver'> But this doesn't? $ ./jython Jython 2.5.1 (Release_2_5_1:6813 Sep 26 2009 13:47:54) [Java HotSpot(TM) 64-Bit Server VM (Apple Inc.)] on java1.6.0_20 Type ""help"" ""copyright"" ""credits"" or ""license"" for more information. >>> import sys >>> sys.path.extend(['/tmp/jtds-1.2.5.jar']) >>> from java.lang import Class >>> Class.forName('net.sourceforge.jtds.jdbc.Driver') Traceback (most recent call last): File ""<stdin>"" line 1 in <module> at java.net.URLClassLoader$1.run(URLClassLoader.java:202) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:190) at java.lang.ClassLoader.loadClass(ClassLoader.java:307) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301) at java.lang.ClassLoader.loadClass(ClassLoader.java:248) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:169) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) java.lang.ClassNotFoundException: java.lang.ClassNotFoundException: net.sourceforge.jtds.jdbc.Driver >>> sys.path ['' '/home/me/pkg/jython2.5.1/Lib/site-packages/distribute-0.6.13-py2.5.egg' '/home/me/pkg/jython2.5.1/Lib' '__classpath__' '__pyclasspath__/' '/home/me/pkg/jython2.5.1/Lib/site-packages' '/home/me/pkg/jython2.5.1/Lib/site-packages/setuptools-0.6c11-py2.5.egg-info' '/tmp/jtds-1.2.5.jar'] >>> import net.sourceforge.jtds.jdbc.Driver as Driver >>> drv = Driver() >>> drv jTDS 1.2.5 Does it have something to do with the classloader? The solution is tricky but everything is explained here. It seems that the reason is because the JDBC DriverManager only uses drivers loaded using the system classloader even though what is registered is a driver instance not a class. Thanks for your link. For any others reading http://stackoverflow.com/questions/288828/how-to-use-a-jdbc-driver-from-an-arbitrary-location and http://www.kfu.com/~nsayer/Java/dyn-jdbc.html may be helpful. The link works fine. -1 Dead link so the solution is now lost. Link is dead. I _think_ this is the correct link: http://www.jython.org/jythonbook/en/1.0/appendixB.html#working-with-classpath Link is dead. Solution is lost. Can this question be removed?  Looks like even the updated link does not work anymore (at least with jython-2.5.3b3). Here's a working version: def importJar(jarFile): ''' import a jar at runtime (needed for JDBC [Class.forName]) adapted from http://forum.java.sun.com/thread.jspa?threadID=300557 Author: SG Langer Jan 2007 translated the above Java to Jython Author: seansummers@gmail.com simplified and updated for jython-2.5.3b3 >>> importJar('jars/jtds-1.2.5.jar') >>> import java.lang.Class >>> java.lang.Class.forName('net.sourceforge.jtds.jdbc.Driver') <type 'net.sourceforge.jtds.jdbc.Driver'> ''' from java.net import URL URLClassLoader from java.lang import ClassLoader from java.io import File m = URLClassLoader.getDeclaredMethod(""addURL"" [URL]) m.accessible = 1 m.invoke(ClassLoader.getSystemClassLoader() [File(jarFile).toURL()]) if __name__ == '__main__': import doctest doctest.testmod() The code from the updated link above didn't work but this did! (had to take out the comments) The code in the Jython 1.0 book didn't work for me either on Jython 2.5.2 but importJar did. Thanks !"
310,A,"How to query for Double with Spring JDBC template query How do one query for a double with the Spring JDBC temple? For example: public double getAverageScore() { return jdbctemplate.queryFor???(""select avg(score) from test""); } There are queryForInt and queryForLong but no queryForDouble public Double avgByCampo(Long param) { return simpleJdbcTemplate.queryForObject(""SELECT avg(t.campo) FROM table t where t.id_campo = ?"" Double.class param); }  public double getAverageScore() { return jdbctemplate.queryForObject(""select avg(score) from test"" Double.class); } Out of topic just interesting why Spring have no convenience method for Double and Long when there is one for Int and Long  I haven't tested this but queryForObject with Double.class as the last parameter might work. public double getAverageScore() { return jdbctemplate.queryForObject(""select avg(score) from test"" Double.class); }"
311,A,"What type of data structure should I use to hold table rows? I'm new to Java and just getting into querying databases. So far I have my results in a ResultSetMetaData. I'm think that for each row in the dataset I should add it to some form of collection? Can anyone tell me the best practice for this? Thanks Jonesy Your results are likely in a ResultSet rather than a ResultSetMetaData. I usually follow the same pattern as Andreas_D describes. The object used to contain each row of data (in this case the Customer class) is referred to as Data Transfer Object (TO). The code that gets the database connection queries the db populates the TOs and returns them (typically in a List) is referred to as a Data Access Object (DAO). You can read more about this design pattern here  Usually we have a class with fields that correspond to a table. Then whenever we have a (full) row in a result set we create an instance of this class. Example: Consider a table created like this: CREATE TABLE customer (First_Name char(50) Last_Name char(50) Address char(50) City char(50) Country char(25) Birth_Date date); A model class would be like this: public class Customer { private String firstName; private String lastName; private String address; private String city; private String country; private Date date; public String getFirstName() { return firstName; } // getters for all fields public void setFirstName(String firstName) { this.firstName = firstName; } // setters for all fields public String toString() { return String.format(""[%s %s %s %s %s %s]"" firstName lastName address city country date); } } Now if you read data and have a ResultSet you would create a new customer object and set the fields: List<Customer> customers = new ArrayList<Customer>(); ResultSet rs = stmt.executeQuery(""SELECT * from CUSTOMER;""); while (rs.next()) { Customer customer = new Customer(); customer.setFirstName(rs.get(""First_Name"")); // ... and so on customers.add(customer); } No but I would design it that way unless the application is that large that separating query and creation of model instances. The list can be created elsewhere just added it there to show a brief and quite complete snippet. you can present the data on a view (form table ...) or create an editor to modify existing db table rows (via the model object) or create new table entries. thanks last question i swear! I loop through each row creating the object then adding it to a an ArrayList. I then close the database connection. I know wanna access my objects through the ArrayList. how do i do this? I can only seem to print out the objects location Implement `toString` if you want `System.out.println(model)` to give a useful result. I've edited my code for a basic to show a simple implementation. thanks so how would i loop through each object and display say the firstname only. then again with the first and last? Just call the six getter methods (I've already added an implementation for the firstName field the rest is the same pattern). We usually do not loop through the model fields we call the getters. (last answer here - please open new questions on SO :-) ) thanks for your help Andreas! ok thanks another question if you don't mind. Once I have created an object of each record. what sort of things can I do with that object? typically that is.. in this situation does the query have to be within the same class as the object creation code?  First the ResultSetMetaData class holds ""information about the types and properties of the columns in a ResultSet object."" So the results from your query are in the ResultSet not in the ResultSetMetaData object. You can see the Retrieving Values from Result Sets Java tutorial for information on how to extract your data from a ResultSet. You should be able to just loop through the ResultSet as shown and put your records in a List or Map depending on how you want to access the data later.  Create an object to hold the data. Loop through the resultset creating an object for each one and store them in an ArrayList or HashMap depending on how you want to use the data. This allows you to close the database and it gives you good objects on which you can build methods to manipulate the data. It also allows you to write code that uses the object that doesn't need to rely on the database. If you ever want to pull out the database later and switch to text files or whatever it's easy to do and you can still use the same objects and methods. thanks Erick. I have a table of users. I've made a class called DisplayUsers with a constructor to retrieve the users. for each user returned should I create a new object of class User for example? Yeah something that has the same properties as the fields in the database table makes sense. Also typically the object has a name very similar to the name of the database table. I use a separate database class which implements source interfaces for the data types I want to pull. But I use the database very heavily for lots of different modules and I want to be source-agnostic.  A List seems quite logical. If you are not going to be having duplicates and you are not bothered about the order of the results then perhaps a Set. A relevant implementation of List: ArrayList: This is backed by an array so lookups on particular indices should be quick Relevant implementations of Set: HashSet: Backed by a HashMap so O(1) insertion time TreeSet: Respects the ordering of the data (using the compareTo method) - so iterating over the data will be in order - the trade off is O(log n) insertion time  You can create class which represents real world entities. Later if you wish to choose ORM technology/tool like hibernate you can use same classes."
312,A,"JDBC & MySQL read performance I really seem to have a big problem here. I'm using MySQL to store part-of-speech tagged sentences in a table. The Table looks like this: +------------+------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +------------+------------------+------+-----+---------+-------+ | idTitle | varchar(25) | NO | PRI | NULL | | | idReview | int(10) unsigned | NO | PRI | NULL | | | idSentence | int(10) unsigned | NO | PRI | NULL | | | content | text | NO | | NULL | | | POSInfo | text | YES | | NULL | | +------------+------------------+------+-----+---------+-------+ These are the indexes on the table: +-----------------+------------+-----------------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | +-----------------+------------+-----------------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+ | reviewsentences | 0 | PRIMARY | 1 | idSentence | A | 23 | NULL | NULL | | BTREE | | | reviewsentences | 0 | PRIMARY | 2 | idTitle | A | 32087 | NULL | NULL | | BTREE | | | reviewsentences | 0 | PRIMARY | 3 | idReview | A | 2470720 | NULL | NULL | | BTREE | | | reviewsentences | 1 | fk_ReviewSentences_Reviews1 | 1 | idTitle | A | 983 | NULL | NULL | | BTREE | | | reviewsentences | 1 | fk_ReviewSentences_Reviews1 | 2 | idReview | A | 494144 | NULL | NULL | | BTREE | | +-----------------+------------+-----------------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+ I'm trying to read the reviewsentences that blong to a certain review an add them to the a review object. I'm accessing the Database via JDBC and the reads take forever!! I'm talking 2 minutes for 26 rows! This is the java code I'm using to query the database: public List<Review> fillupReviews(List<Review> reviews boolean tagged){ try { Statement stmt = dbConnection.createStatement() ; for (Review review : reviews) { ResultSet rs=null; if(tagged==true){ rs = stmt.executeQuery(""SELECT idSentence POSInfo FROM reviewsentences WHERE idTitle=""+review.getMovieID()+"" and idReview=""+review.getReviewID()+"";"") ; }else{ rs = stmt.executeQuery(""SELECT idSentence content FROM reviewsentences WHERE idTitle=""+review.getMovieID()+"" and idReview=""+review.getReviewID()+"";"") ; } while(rs.next()){ review.addTaggedSentence(rs.getInt(1)rs.getString(2)); } } } catch (SQLException e) { e.printStackTrace(); } return reviews; } If I access the same table with the same query via the MySQL Workbench it takes 0.296 seconds?? So my guess is there has to be something seriously wrong! But I really can not see what goes wrong or what to change to speed this darn thing up. Please can someone give me a hint? It's me again I finally found the solution! Is called Prepared Statement!! <-- who would have guessed!? Here is the code: public List<Review> fillupReviews(List<Review> reviews boolean tagged){ try { PreparedStatement selectReview=null; if(tagged==true){ selectReview = dbConnection.prepareStatement(""SELECT idSentence POSInfo FROM reviewsentences WHERE idTitle= ? AND idReview= ?;""); }else{ selectReview = dbConnection.prepareStatement(""SELECT idSentence Content FROM reviewsentences WHERE idTitle= ? AND idReview= ?;""); } for (Review review : reviews) { selectReview.setString(1 review.getMovieID()); selectReview.setInt(2 review.getReviewID()); ResultSet rs = selectReview.executeQuery(); while(rs.next()){ review.addTaggedSentence(rs.getInt(1)rs.getString(2)); } rs.close(); } } catch (SQLException e) { e.printStackTrace(); } return reviews; } Now this hole thing runs like hell (nearly as fast as MySQL Workbench does[0.3 sec]). What i do not exactly get is why a normal statement is so slow? Has someone an explanation for that? It appears you have 2470720 reviews. Compared to running locally in Mysql Workbench running remotely (in your code) will certainly take longer to query return and transfer that many values. Mysql workbench likely fetches the count of the results and paginates what it gives you -- only returning the results as necessary; also your workbench could be enabling compression on the connection while JDBC is not thus creating an even faster connection.  Comment out review.addTaggedSentence(rs.getInt(1)rs.getString(2)); Does it still take that much time ? You are not closing the ResultSet you need to do rs.close() after your while(rs.next()) is done. Print out the actual SQL you're running in Java - are you 100% sure it's the same query you run in in the MySQL workbench ? You're also running the query in a for (Review review : reviews) so how many queries does that run ? You're not telling us what takes 2.36 min. so - profile or do some simple System.out.println()s in your java app so you're really certain what SQL you're actually running and how many of them gets run. 1. If commented out review.addTaggedSentence(rs.getInt(1)rs.getString(2)); it doesn't help :( 2. Added rs.close() still the same. 3. Checked and Yes 100% sure! 4. exactly 159598! But it takes 2min for every single one! So the problem is not the number of 159598 but that each query takes 2min :( 5. It takes 2min for the rs = stmt.executeQuery(... to return an even get to the part that assigns the values to the review. Are you sure you really get 159598 rows back when you do this in MySQL workbench ? run the `mysqladmin pr` status on the machine with mysql on and see what it's doing while your java code is executing  First of all. Can you give specific detail on which part of your code that takes 2m++. Is it in statement stmt.executeQuery(String) or another part? I myself happen to face this problem with a big major DBMS. But my data was larger than 150K. Unfortunately i don't have a ready-baked solution for your problem. But there are some footprints of what i did. I tried to switch from driver to driver. Please keep in mind that some driver may runs faster but it asks you to sacrifice portability. I tried to switch from hard-coded connection to connection pool. Unfortunately it wasn't really helpful. I tried not to use ""WHERE"" clause on VARCHAR field. I tried to index some field which i frequently ""WHERE""d I tried to use Prepared Statement just to make sure that the DBMS doesn't re-hash same query. There are other things but i think they are DMBS-specific. Yeah its the stmt.executeQuery() part that takes that long. Thanks for your answer!  First are you timing just this method call? Where do you get the db connection are you timing just the time to execute the query or the time to get the connection also? Are you using connection pooling? Maybe there is an issue there try getting a new connection first to narrow it down. Regardless it shouldn't take this long something is wrong I suspect with your connection setup maybe the way java is finding mysql (is it local are you using dns etc). Also I would use prepared statements they are more secure and better performing. Also what driver are you using? Just a WAG but is there enough memory on your box are you swapping like crazy? Is it possible the JVM is using up your memory that normally mysql would make use of? Wheres the love see my suggestion for prepared statement.... I get the db connection in the constructor of my class like this this.dbConnection = MySQLConnectionFactory.getConnection(""moviereviews"");. Im timing just the time till the rs = stmt.executeQuery(... returns. No i don't use connection pooling. The database runs one the same machine where the java code runs so i don't you any dns. This is the driver I'm using http://www.mysql.com/downloads/connector/j/  If it's local MySQL server then I would try to comment MySQL fetch and replace with dummy code to check performance of your code (don't forget to use yout GetMovieId() etc things)."
313,A,"Java Driver.getConnection() yields ""Connection Refused"" from mysql on live system not dev Pretty straightforward stuff here -- I'm just not good enough with mysql to understand what it wants from me. I've got a short java test-case that opens a connection on mysql on my dev system but when I try to put it to my server it fails. Any help in tracking this down would be most appreciated. Thanks! Test Code import java.util.*; import java.sql.*; public class mysqltest { static public void getDBConnection() { System.out.println (""Start of getDBConnection.""); Connection conn = null; String url = ""jdbc:mysql://localhost:3306/""; String dbName = ""magnets_development""; String driver = ""com.mysql.jdbc.Driver""; String userName = ""*****""; // blanked for publication String password = ""*****""; try { Class.forName (driver).newInstance(); System.out.println (""driver.newInstance gotten.""); conn = DriverManager.getConnection (url+dbName userName password); System.out.println (""Connection gotten: "" + conn + "".""); Statement sql = conn.createStatement (); ResultSet results = sql.executeQuery (""use "" + dbName + "";""); } catch (Exception ex) { System.out.println (""*** Got exception.""); ex.printStackTrace(); } } public static void main(String args[]) { System.out.println (""Main started.""); mysqltest.getDBConnection(); } } Dev System Output (Expected/correct response) olie$ java mysqltest Main started. Start of getDBConnection. Properties set. driver.newInstance gotten. Connection gotten: com.mysql.jdbc.Connection@c980c9. olie$ Server Output (Error I'm trying to track-down) (Some blank lines removed.) mini$ java mysqltest Main started. Start of getDBConnection. Properties set. driver.newInstance gotten. *** Got exception. com.mysql.jdbc.CommunicationsException: Communications link failure due to underlying exception: ** BEGIN NESTED EXCEPTION ** java.net.ConnectException MESSAGE: Connection refused STACKTRACE: java.net.ConnectException: Connection refused at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333) at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195) at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:432) at java.net.Socket.connect(Socket.java:520) at java.net.Socket.connect(Socket.java:470) at java.net.Socket.<init>(Socket.java:367) at java.net.Socket.<init>(Socket.java:209) at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:256) at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:271) at com.mysql.jdbc.Connection.createNewIO(Connection.java:2771) at com.mysql.jdbc.Connection.<init>(Connection.java:1555) at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:285) at java.sql.DriverManager.getConnection(DriverManager.java:525) at java.sql.DriverManager.getConnection(DriverManager.java:140) at mysqltest.getDBConnection(mysqltest.java:34) at mysqltest.main(mysqltest.java:49) ** END NESTED EXCEPTION ** Last packet sent to the server was 3 ms ago. at com.mysql.jdbc.Connection.createNewIO(Connection.java:2847) at com.mysql.jdbc.Connection.<init>(Connection.java:1555) at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:285) at java.sql.DriverManager.getConnection(DriverManager.java:525) at java.sql.DriverManager.getConnection(DriverManager.java:140) at mysqltest.getDBConnection(mysqltest.java:34) at mysqltest.main(mysqltest.java:49) mini$ Also make sure that your MySQL server's user account for the database user allows connections from other addresses but localhost. For security reasons in smaller servers it is possible (and possibly default?) to limit connections to localhost so that only the local web application can access the database using the magic-numbered user/password combination.  Here is my code that works on mysql on os X public SQL(String host String port String database String userid String password) { queryType = QUERYTYPE.Single; String driver = ""org.gjt.mm.mysql.Driver""; String url = ""jdbc:mysql://"" + host; if (port != null) { url += "":"" + port; } else { url += "":"" + defaultPort; } url += ""/"" + database; try { Class.forName(driver); connection = DriverManager.getConnection(url userid password); } catch (Exception e) { e.printStackTrace(); } }  Your URL has localhost in it. Are you trying to connect to this server on the network? Your URL may be incorrect.  Have you verified that you can connect to the database on the server with the name and password. Also if you are connecting via a url you should not need the following line. properties.setProperty(""socket"" ""/Applications/MAMP/tmp/mysql/mysql.sock""); The above property seems specific to Os X. Are you running the server on os X? Yes I can connect to mysql from the command line with said username & password. Yes the server is on OS-X (as is my dev system -- all same versions of java OSX mysql.) And you are correct that the set-property ""socket"" has no effect on whether the app runs or not.  /* answer date is Expire but my answer is for Future */ I have the same problem. How can i solve it? Answer: Open your Xammp or other server and just run MYSQL... . If SQL is not running that Exception will throw.  Just a helpful note on this subject. I spent at least 30 minutes trying to debug the same error and this was my mistake. In my MySQL conf file I happened to set the BIND ADDR to the IP of the machine. I did not set it to 127.0.0.1 or 0.0.0.0. So MySQL would accept JDBC connections from outside but not internally. I was getting Connection Refused only when connecting from the local machine. Changing that address to 0.0.0.0 allowed it to listen for requests to any IP. This allowed for both internal and external IPs. Hopefully this helps somebody who made the same dumb mistake I did. Check it with the above comment about netstat -an | grep 3306. Thank you! I could get remote connections but not localhost. 0.0.0.0 solved my own problem. Thank you for adding this ""helpful note."" Thank you thank you thank you! As a Linux/MySQL n00b this both saved and educated me!  There's only one reason for ""connection refused"" message never mind if it's mysql or any other service. The server isn't listening. Try ""netstat -an"" and grep for port 3306 to validate it. Ok netstat -an | grep 3306 returns nothing -- so that's a step in the right direction. Uh... mysql is clearly running. And I can log-in from command line. I take it there's some configure thing to turn on 3306-listening...? Are you logging in from the command line on the same machine or a different machine?  Bah! My apologies -- I just had ""local connections only"" set up. I was confused by the fact that the java app was running locally (so seemed a ""local connection"" but because it is connecting via TCP it's a ""remote"" connection even though it originates on localhost. I will eventually learn how to administer these things. In the mean time I hope someone else can learn from my mistakes. Thank you to all who put time into trying to help me. I have since allowed ""remote"" connections but all of my user-accounts are 'username'@'localhost"" only (i.e. there is no 'username'@'%' which would allow any machine to connect.) Hopefully I got that part right at least. Thanks again! And thanks to uzhin (honorable mention to Uri) for the hints I needed to eventually figure this out. + votes to both of you. No prob. I fell for that thing a long time ago. I was using DB2 and switched to MySQL"
314,A,"Scala: Exposing a JDBC ResultSet through a generator (iterable) I've got a set of rows in a database and I'd like to provide an interface to spin through them like this: def findAll: Iterable[MyObject] Where we don't require having all the instances in memory at once. In C# you can easily create generators like this using yield the compiler takes care of converting code that loops through the recordset into an iterator (sort of inverting it). My current code looks like this: def findAll: List[MyObject] = { val rs = getRs val values = new ListBuffer[MyObject] while ( rs.next() ) values += new valueFromResultSet(rs) values.toList } Is there a way I could convert this to not store the entire set in memory? Perhaps I could use a for comprehension? I came across the same problem and based on the ideas above I created the following solution by simply writing an adapter class: class RsIterator(rs: ResultSet) extends Iterator[ResultSet] { def hasNext: Boolean = rs.next() def next(): ResultSet = rs } With this you can e.g. perform map operations on the result set - which was my personal intention: val x = new RsIterator(resultSet).map(x => { (x.getString(""column1"") x.getInt(""column2"")) }) Append a .toList in order to force evaluation. This is useful if the database connection is closed before you use the values. Otherwise you will get an error saying that you cannot access the ResultSet after the connection was closed. I used this solution. Thank you muchly! I did have to call toList to use the results. val externalKeys = resultSet.map { x => x.getString(""external_key"") }.toList  Try extending Iterator instead. I haven't tested it but something like this: def findAll: Iterator[MyObject] = new Iterator[MyObject] { val rs = getRs override def hasNext = rs.hasNext override def next = new valueFromResultSet(rs.next) } This should store rs when it's called and otherwise just be a light wrapper to calls to rs. If you want to save the values that you traverse check out Stream. If ""isLast"" means that you can't get another one I'd think hasNext = !rs.isLast would be the thing to do. Maybe just a typo? @Rex oops yeah I meant hasNext = !rs.isLast I'll give that a shot thx Rex I just assumed that rs actually has a ""hasNext"" method. If not you should cache the next result with a (probably private) var inside the iterator and have hasNext say whether that cached result exists. Yeah that works I used hasNext = rs.isLast. One trouble is though I don't have any mechanism to close the rs and connection. In my current code I have wrapped the (above) code in a ""using"" method which closes things for me. `hasNext = rs.isLast` doesn't seem correct."
315,A,"java 1.4 -sql server2000:is it safe to append text to String in java of size in gbs i am dynamically creating sql query for inserting multiple records in one hit.Suppose no of record to be inserted is 1000.in that case sql query will be generated as below in code  String insertBatchSqlQuery=""""; for(int currentRecordIndex=0;currentRecordIndex<totalNoOfRecords;currentRecordIndex++) { insertBatchSqlQuery+=getSQL(""InsertFileUploadData"");//note SQL query retrieved from SQL repository must end with semi colon for(int currentFieldIndex=0;currentFieldIndex<countOfProperties;currentFieldIndex++) { insertBatchSqlQuery+=getSQL(""InsertFileUploadRecordFieldData""); } } In this case in case no of record is 1000 and noOfproperties is 80.then 80000 insert statements will be appended to String variable.Is it safe to use String in this case.Is there any issue while executing this query. after implementing executebatch as suggested by my frnd below i got exception com.microsoft.jdbc.base.BaseBatchUpdateException on execute update with message""operation was cancelled at user request"".batch contains 500 queries approximately.what can be cause? You should have a look at batch updates instead of joining everything to one big string. getting exception com.microsoft.jdbc.base.BaseBatchUpdateException on execute update with message""operation was cancelled at user request"".batch contains 500 queries approximately.what can be cause?  Agreed with Tangens I would never run 500 individual update statements like that. Maybe you can consider building a query like this instead of having each INSERT on its own: INSERT dbo.table(column1 column2) SELECT 'foo1' 'bar1' UNION ALL SELECT 'foo2' 'bar2' UNION ALL SELECT 'foo3' 'bar3' UNION ALL ..."
316,A,Should JDBC drivers be included in a WAR? We have a commercial software product under development. It supports Oracle MySQL and SQL*Server backends (we also use H2 for testing). We do our integration testing against those different database using JDBC drivers of a specific version. Maven handles all this beautifully. When packaging the application as a WAR is it ok if we include the JDBC drivers? What is the standard practice? Since we don't know which database could be used ahead of time we'd have to include them all. The targeted servlet containers are Tomcat and Jetty but some customers will also want to run within WebSphere and JBoss. So the servlet contains and application servers come with their own JDBC drivers? Will ours conflict? Another concern is that we have developed and tested with one version of the driver and if a customer uses another version we may have problems. Currently we use Spring data source beans but are in the process of moving to JNDI lookup for the datasource. Other then the technical merits of including the driver in the war file You should also check up the licensing for the driver and make sure that it is distributable by a third party.  In most of the applications JDBC drivers aren't shipped as part of the application. If you do ship JDBC drivers that means that you have to give drivers for all the database you want to support. It add a lot of unnecessary libraries. Just don't add any driver and tell the user to put the relevant JAR file in the server libraries if needed.  So the servlet contains and application servers come with their own JDBC drivers? Some do (e.g. WebLogic). Will ours conflict? They shouldn't. Not sure yours will be picked when creating an standalone connection pool at the application level though (it all depends on the classloader delegation mode). Another concern is that we have developed and tested with one version of the driver and if a customer uses another version we may have problems. Have a list of supported versions. Currently we use Spring data source beans but are in the process of moving to JNDI lookup for the datasource. If by this you mean using the connection pool provided by an application server drivers must be installed at the container level not at the application level. And this somehow ends the discussion. @Pascal Thivent: (relevant to the paragraph about the connection pool) could you add some links or explain a little? I would agree with your point (and I did it as you describe several times because it's the most intuitive way) but I was told that it's a bad practice (because same libraries in app-server and in deployed app can cause conflicts) and all libraries should be packed in application's war-file. This is more actual for cases when more then 1 app is deployed on the same server (tomcat in my case). To expand on the last sentence: a JNDI datasource is container managed and *implicitly requires* the driver to be present in container's library. The container won't scan the WAR libraries for drivers. This indeed ends the discussion :) @Roman Sure see the [Apache Tomcat 6.0 Class Loader HOW-TO](http://tomcat.apache.org/tomcat-6.0-doc/class-loader-howto.html). If you want to use Tomcat's **built-in** connection pool the driver must be available in $CATALINA_HOME/lib or Tomcat won't be able to load it. This is a better resource: [JNDI HOW-TO - JDBC Data Sources](http://tomcat.apache.org/tomcat-6.0-doc/jndi-resources-howto.html#JDBC_Data_Sources). Note that it explicitly recommends to place the driver in `tomcat/lib`. @BalusC Yes this is a good one. Thanks. @Pascal BalusC: thanx I've never used built-in tomcats connection pool but would know if ever need to do that.
317,A,"Accessing NexusDB from Java I am trying to get info from an embedded db called NexusDB using java. Alternative 1: I've read in NexusDB website that there is an ODBC driver so I might use it with unixODBC. Then I need to do a JDBC-ODBC Bridge as stated here. Alternative 2: Get some sort of application to migrate NexusDB db to another db. Would like to know one. I would like to know if anyone ever this this what's the best solution? Thanks for reading. Alternative 1: Not possible. unixODBC needs linux drivers and there aren't for nexusDB. Alternative 2: Didn't find any. Solution so far Writting a small webservice with delphi or get odbc and use that in a small proxy. In other words instead of connecting to the nexusdb server you connect to a dedicated application or webservice pass on the information and that app does connect to nexusd and writes the data. Do you need to use this db outside of java? You might consider moving to a non-embedded db engine which has proper jdbc support. Information I need to query comes from an output of an application which is a zipFile containing nexusdb embbeded db. I can't move to a non-embedded db. All the same nexusdb isn't only embedded it's just this particular case.  Since it is embedded (and you probably have full access to the machine) what about copying database files to a Windows system setting up NexusDB and its ODBC driver then using an ODBC-JDBC bridge on that machine? Once the bridge is running you can set up a new JDBC-compatible DBMS of your choice connect and use a little code to SELECT from NexusDB and insert to your new database. If you're looking to migrate to another embedded DBMS I'm using H2 Database for Java and I've got to say it's really sweet. Both embedded and client/server modes cross-platform and really fast for anything under 1M rows. Supports pretty much any feature you'd have in an embedded DBMS and then some.  If you connect to Nexus via .NET maybe you can use IKVM to run your Java app and connect through the .NET api? Otherwise I think your own ""solution so far"" sounds ok. Best Anders  I've had some success running nexusDB under wine. I was able to set up a WINEPREFIX follow the instructions here to get at wine's odbc management panel (by default it pipes into unixODBC and as Macarse noted that's a dead end) set up a DSN there and test that it could access the data. The next thing I tried was installing win32 PHP and writing a quick and dirty test using odbc_connect. After wasting a good chunk of time accidently using the linux php binary and wondering why it couldn't use the (inbuilt on win32 ONLY) function odbc_connect I did get it working. HINT: To save yourself feeling like banging your head against a brick wall remember that any attempts to run php scripts in this environment MUST look like this WINEPREFIX=/home/you/yourprefix wine php c:\phptest.php NOT WINEPREFIX=/home/you/yourprefix php c:\phptest.php The second version will use the linux php binary. Feeling pretty stupid after running the second version a good dozen times AND googling the error some before realising what was wrong - I think I need to get up later if I want to be able to still make things work at 4am :( (the c:\ path in the above examples can be passed as /home/you/yourprefix/drive_c/whatever if you prefer - relative paths are also fine) And yes I know this is a necro post but it's a pretty niche situation there isn't a lot of information out there making nexusdb and odbc play nice on linux and if this information was available to me a few months back when I was googling around and came across this thread it could have saved me a good chunk of time. Hope someone else finds it helpful."
318,A,PreparedStatement setNull(..) Java PreparedStatement provides a possibility to explicitely set a Null value. This possibility is: prepStmt.setNull(<n> Types.VARCHAR) Are the semantics of this call the same as when using a setType with a null value? prepStmt.setString(null) ? This guide says: 6.1.5 Sending JDBC NULL as an IN parameter The setNull method allows a programmer to send a JDBC NULL (a generic SQL NULL) value to the database as an IN parameter. Note however that one must still specify the JDBC type of the parameter. A JDBC NULL will also be sent to the database when a Java null value is passed to a setXXX method (if it takes Java objects as arguments). The method setObject however can take a null value only if the JDBC type is specified. +1: Interesting. I assumed that's how setXXX worked with nulls but I'd never actually tested it or read the docs for it. @ardave yes that's what I mean by my final paragraph I don't suppose there is something like myPreparedStatement.setInteger(myIntegerObject) (although I see that exact method name does not exist) in the case I'm wanting use a potentially null integer? Otherwise I'm going to have to use an if/else statement calling .setInt() one way and .setNull() the other way which seems a bit tedious.  but watch out for this.... Long nullLong = null; preparedStatement.setLong( nullLong ); -thows null pointer exception- because the protype is setLong( long ) NOT setLong( Long ) nice one to catch you out eh. +1 for that - it's had me scratching my head for about 30 minutes  Finally I did a small test and while I was programming it it came to my mind that without the setNull(..) method there would be no way to set null values for the Java primitives. For Objects both ways setNull(..) and set<ClassName>(.. null)) behave the same way.
319,A,"How does one convert from a Java resultset to ColdFusion query in Railo? The following works fine in CFMX 7 and CF8 and I'd assume CF9 as well: <!--- 'conn' is a JDBC connection ---> <cfset stat = conn.createStatement() /> <cfset rs = stat.executeQuery(trim(arguments.sql)) /> <!--- convert this Java resultset to a CF query recordset ---> <cfset queryTable = CreateObject(""java"" ""coldfusion.sql.QueryTable"")> <cfset queryTable.init(rs) > <cfset query = queryTable.FirstTable() /> This creates a statement using a JDBC driver executes a query against it putting it into a java resultset and then coldfusion.sql.QueryTable is instantiated passed the Java resulset object and then queryTable.FirstTable() is called which returns an actual coldfusion resultset (for cfloop and the like). The problem comes with a difference in Railo's implementation. Running this code in Railo returns the following error: No matching Constructor for coldfusion.sql.QueryTable(org.sqlite.RS) found. I've dumped the Railo java object and don't see init() among the methods. Am I missing something simple? I'd love to get this working in Railo as well. Please note: I am doing a DSN-less connection to a SQLite db. I understand how to set up a CF datasource. My only hiccup at this point is doing the translation from a Java result set to a Railo query. This may be a dumb question - but why don't you use a regular ColdFusion data source and `` to create a query result? See: http://www.coldfusionjedi.com/index.cfm/2009/9/24/Hooking-up-ColdFusion-and-SQLite That is probably because QueryTable is an interface in Railo. So you cannot instantiate it. (It is a concrete class in Adobe CF). I am not sure what concrete class Railo uses for queries or if it is similar to QueryTable in Adobe CF. But as mentioned is there is a reason you cannot use a regular query? I already know how to set up a ColdFusion datasource. I know how to load the sqlitejdbc.jar in the classes folder and make it an available 'Other' datasource in ColdFusion and I know how to set up the connection string to connect to it. I am the developer of the SqliteCFC project http://sqlitecfc.riaforge.org/ and I'm doing DSN-less creation of SQLite dbs. I find that everything works in CF or Railo except the actual running of queries. So that explains why I'm not using a CF datasource. What I need to know is how Railo constructs a query from a Java resultset. The railo devs are pretty active over here http://groups.google.com/group/railo - it may be a better question for them @Shawn - Makes sense. (Not everyone has a good reason for using them though ;) But glad you found the ""Railo"" version of the concrete class. Good to know. Looking at the Railo source code I see that railo.runtime.type.QueryImpl might fit your needs. It implements railo.runtime.type.Query and accepts a ResultSet in its constructor but it does not seem to implement QueryTable. If that's the right class you'll want to pass in a ResultSet and a string for the query name as it doesn't have a constructor that only takes a ResultSet. Thats the beauty of open source. I have looked at the Railo source code to also see how they generate PDFs using the cfdocument tag (it turns out Railo uses pdf4ml). That did it. The resulting CFML for Railo is:"
320,A,"Difference between JDBC Driver type numbers I am very new to Java when i was going through the JDBC section i noticed that JDBC has different Drivers like Type 1 Driver Type 2 Driver etc.. to Type 4 Why did they get the name like Type 1 Type 2 etc.. Is there any logic? I believe it goes back to Sun's original (1997) intro to JDBC: The JDBC drivers that we are aware of at this time generally fit into one of four categories: JDBC-ODBC bridge plus ODBC driver: The JavaSoft bridge product provides JDBC access via ODBC drivers. Note that ODBC binary code and in many cases database client code must be loaded on each client machine that uses this driver. As a result this kind of driver is most appropriate on a corporate network where client installations are not a major problem or for application server code written in Java in a three-tier architecture. Native-API partly-Java driver: This kind of driver converts JDBC calls into calls on the client API for Oracle Sybase Informix DB2 or other DBMS. Note that like the bridge driver this style of driver requires that some binary code be loaded on each client machine. JDBC-Net pure Java driver: This driver translates JDBC calls into a DBMS-independent net protocol which is then translated to a DBMS protocol by a server. This net server middleware is able to connect its pure Java clients to many different databases. The specific protocol used depends on the vendor. In general this is the most flexible JDBC alternative. It is likely that all vendors of this solution will provide products suitable for intranet use. In order for these products to also support Internet access they must handle the additional requirements for security access through firewalls and so forth that the Web imposes. Native-protocol pure Java driver: This kind of driver converts JDBC calls into the network protocol used by DBMSs directly. This allows a direct call from the client machine to the DBMS server and is an excellent solution for intranet access. Since many of these protocols are proprietary the database vendors themselves will be the primary source. Several database vendors have these in progress. The expectation is that eventually driver categories 3 and 4 will be the preferred way to access databases from JDBC. Driver categories 1 and 2 are interim solutions where direct pure Java drivers are not yet available. There are possible variations on categories 1 and 2 (not shown in the table below) that require a connector but these are generally less desirable solutions. Categories 3 and 4 offer all the advantages of Java including automatic installation (for example downloading the JDBC driver with an applet that uses it). Note that they didn't actually name them Type 1 2 3 and 4 but rather JDBC-ODBC bridge plus ODBC driver Native-API partly-Java driver JDBC-Net pure Java driver and Native-protocol pure Java driver. Each name was a mouthful so people immediately started referring to them by their number instead.  The types tells something about how the driver actually communicates with the database. Communicates through ODBC API. Communicates through DB vendor specific API (i.e. using JNI calls on e.g. a DLL file at Windows). Communicates through generic network protocol (i.e. using sockets using e.g. TCP/IP protocol). Communicates through DB vendor specific network protocol (still with sockets). In general (just by coincidence) how higher the type number how better the JDBC driver performs.  The numbers aren't very informative. I find it more useful to think of it along the lines of: Local API (12) vs network protocol (3 4) Database-independent (odd numbers) vs database-specific (even numbers) I could never remember the numbers but when someone said ""we use a type-4 driver here"" I could ask two yes-no questions to know what they were talking about. Nice mnemonic .  In short each Type uses a different strategy and works better for different types of implementations. I don't think it was laziness. I think it was to be able to more easily and clearly pick out which Type is best for your particular situation.  http://en.wikipedia.org/wiki/JDBC_driver Does not seem to be any logic just plain laziness I guess! UPDATE: The question was whether there was some logic to calling it type 1 type 2 etc instead of calling type apple type orange :). I understand that the driver types are different and work/not work based on circumstances but why the name ""Type 1"" instead of ""Type JDBC-ODBC"" or ""Type JO"" has no reason AFAIK. There is some logic to it - Knowing the driver type helps you understand under what circumstances the driver will work. For instance a driver using native code wouldn't work if you can't deploy native code (say in an applet).  This page explains the different driver types pretty well. Good link dude"
321,A,A great tutorial of mysql to jump right in? I will use mysql as a database choice with my java. What is the best way to learn it quickly and become productive super fast... well I am jsut trying to learn it as I am working on the project involving it. I my goal is to be able to create/administer/design tables for Mysql database program in Java against it (with tomcat) Thanks Well it sounds like you're asking for two types of information here: 1. how to perform basic operations on a MySQL database and 2. how to interact with a MySQL database programmatically from within Java. For the first question these are MySQL basics -- there's tons and tons of resources for getting started with MySQL and learning how to do the stuff you're describing. As to the second (interfacing with Java) I'd look into JDBC. Try here or here. Edit: Here's a dynamic content generation tutorial that talks about getting Tomcat to work with MySQL.  As well as the standard method of using Google you can also find quite a few decent tutorials popping up on YouTube nowadays. As for web recommendations here's a couple that go a little beyond the immediate beginner - not strictly tutorials but they should help a lot (the second is mine I have to confess but it does have a lot of useful links too) Mysql common queries Blog on using Mysql To start with here's a very useful cheat sheet on Mysql cheat sheet These tutorials ARE GREAT. thanks a lot  Check out this site: http://dev.mysql.com/tech-resources/articles/mysql%5Fintro.html Also I suggest you download a front end for MySQL Grab one here: http://dev.mysql.com/downloads/gui-tools/5.0.html Are you that set on Java or have you considered using .net? If you know any .net you can run your stuff on Linux or Mac using Mono. Not great but it can run .net v2 code. In my experience Java is more difficult to learn and master than C#.  Mysqls own web site is very good. Even their command reference is filled with good examples and user comments such as gotchas under each page (every site should have that IMHO). For example check out the insert command documentation. Here's a good beginner tutorial also on that site. Finally for Java connectivity use this as a reference. I've been using HeidiSQL to view and edit my tables in testing but it's also cool to get good with the command line initially.  Here are two.  You should take a look into Hibernate here is a quick start tutorial http://docs.jboss.org/hibernate/stable/core/reference/en/html/tutorial.html Then you'll be able to jump into any INSERT_DBSOFTWARE_HERE which have a jdbc driver by only knowing HQL language. If you use http://dev.mysql.com/workbench/ you can model your database with a cool software and only export a table creation file. So to create/administer/design : MySQL workbench To program in Java : Hibernate Good luck While I agree with this a solid understanding of native SQL is VERY handy before learning hibernate.
322,A,"Java/Oracle: executing a prepared statement fails on a second iteration of a loop (not all variables bound). Why? I'm debugging a Java App which connects to Oracle DB via a thin client. The code looks as follows: (i'm trying to simplify the use case here so pardon me if t does not actually comile) Connection conn = myEnv.getDbConnection(); CallableStatement call = conn.prepareCall( ""{ ? = call SomePackage.SomeFunction (?)}""); call.registerOutParameter(1 OracleTypes.CURSOR); for (int runCount = 0; runCount <= 1; runCount++) { currency = getCurrency(runCount); // NOTE: [0]=CAD [1]=USD call.setString(2 currency); try { call.execute(); } catch { // BREAKS HERE! } ResultSet rset = (ResultSet)call.getObject(1); ... more code that I think is irrelevant as it does not use/affect ""call"" } When I run this code the following happens: First iteration of the loop currency is set to ""CAN"". Entire code of the loop runs perfectly fine. Second iteration of the loopcurrency is set to ""USD"". The ""execute()"" call throws SQLException as follows: ORA-01008: not all variables bound Why? My initial suspicion was that it somehow related to registerOutParameter call before the loop that doesn't get called on 2d iteration. But moving that call inside the loop does not fix the problem. It seems that execute() call un-binds something but having both bindings inside the loop does not help. What am I missing? If it's something obvious please be gendle - I know very little about Oracle and thin client and Googling witrh miriad of fancy queries returned no love. One additional clue: this design seemed to have worked before when the app was on Oracle 9 with OCI drivers. The reason I'm debuggin it is someone ""upgraded"" it to Oracle 10.2 thi client and it broke. My next step should probably be bringing in entire CallableStatement into the loop but that kind of defeats the whole idea of why I though prepared statements are used in the first place no? Does it help if you put the registerOutputParameter() into the loop with the setString()? Sadly as I said in the Q it does not :( Are you using the latest driver? http://www.oracle.com/technology/software/tech/java/sqlj_jdbc/htdocs/jdbc_10201.html oracle client version is 10.2.0 from what I can see in directory path The explanation obtained via Oracle Support call was that this version of Java (1.3) was not compatible with new Oracle. Java 1.4 fixed the issue.  Have you tried adding call.clearParameters() into the loop? Perhaps it would reset some internal state on the object that it needs to execute again. Negative no effect sorry"
323,A,"Java : Insert query-Exception I have a doubt regarding database operation.I have one insert query that should run for 10 times. the loop starts and inserted 4 or 5 val while inserting 6th the db connection got failed for a while and again connected. then what will happen whether it skips that particular val or throws exception or roll back th entire operation? EDIT : Sample Code try { String sql_ji_inser=""insert into job_input values (??)""; PreparedStatement pst_ji_inser=OPConnect.prepareStatement(sql_ji_inser); for(int i=0;i<v_new_data.size();i++) { Vector row=new Vector(); row=(Vector)v_new_data.get(i); job_id=Integer.parseInt(row.get(0).toString()); item_no=Integer.parseInt(row.get(1).toString()); pst_ji_inser.setInt(1job_id); pst_ji_inser.setInt(2item_no); pst_ji_inser.addBatch(); } System.out.println(""No of rows inserted""+pst_ji_inser.executeBatch().length); } catch(Exception ex) { System.out.println(""********Insert Exception*********************""); ex.printStackTrace(); return false; } Is this the right way try { int count=0;// for checking no of inserting values OPConnect.setAutoCommit(false); String sql_ji_inser=""insert into job_input values (??)""; PreparedStatement pst_ji_inser=OPConnect.prepareStatement(sql_ji_inser); for(int i=0;i<v_new_data.size();i++) { job_id=Integer.parseInt(row.get(0).toString()); item_no=Integer.parseInt(row.get(1).toString()); pst_ji_inser.setInt(1job_id); pst_ji_inser.setInt(2item_no); pst_ji_inser.addBatch(); count++; } int norowinserted=pst_ji_inser.executeBatch().length; if(count==norowinserted) { OPConnect.commit(); } } catch(Exception ex) { System.out.println(""********Insert Exception*********************""); OPConnect.rollback(); ex.printStackTrace(); return false; } That depends on how you're inserting the rows. If you're inserting them in a single transaction on a connection which has auto-commit turned off by connection.setAutoCommit(false) and you're commiting the connection after completing the insert queries using connection.commit() and you're explicitly calling connection.rollback() inside the catch block then the entire transaction will be rolled back. Otherwise you're dependent on environmental factors you have no control over. See also: When to call rollback? Update: here's a rewrite of your code. Note that the connection and statement should be declared before the try acquired in the try and closed in the finally. This is to prevent resource leaking in case of exceptions. String sql = ""insert into job_input values (? ?)""; Connection connection = null; PreparedStatement statement = null; try { connection = database.getConnection(); connection.setAutoCommit(false); statement = connection.prepareStatement(sql); for (List row : data) { statement.setInt(1 Integer.parseInt(row.get(0).toString())); statement.setInt(2 Integer.parseInt(row.get(1).toString())); statement.addBatch(); } statement.executeBatch(); connection.commit(); return true; } catch (SQLException e) { if (connection != null) try { connection.rollback(); } catch (SQLException logOrIgnore) {} e.printStackTrace(); return false; } finally { if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } I am by the way not a fan of returning a boolean here. I'd just make the method void let the catch throw e and put the calling code in a try-catch. @ BalusC : Thank you I didnt use any autocommit() and rollback().in try block i used the insert query and using addbatch() for all values and finally executed using executeBatch() Then fix it accordingly. By the way `Vector` is really a legacy class. Is this a 15 year old codebase which you have to maintain? Since Java 1.2 the `ArrayList` was introduced as superior replacement to `Vector`. @ BalusC : Kindly note the Edited post"
324,A,"JDBC connection to very busy SQL 2000: selectMethod=cursor vs selectMethod=direct? In the process of trying to help out an app dev team with performance issues on a SQL 2000 server (from a bunch of Java applications on separate app servers) I ran a SQL trace and discovered that all calls to the database are full of API Server Cursor statements (sp_cursorprepexec sp_cursorfetch sp_cursorclose). Looks like they're specifying some connection string properties that force the use of server-side cursors retrieving only 128 rows of data at a time: (From http://msdn.microsoft.com/en-us/library/Aa172588) When the API cursor attributes or properties are set to anything other than their defaults the OLE DB provider for SQL Server and the SQL Server ODBC driver use API server cursors instead of default result sets. Each call to an API function that fetches rows generates a roundtrip to the server to fetch the rows from the API server cursor. UPDATE: The connection string at issue is a JDBC connection string parameter selectMethod=cursor (which enables the server-side cursors we discussed above) vs the alternative selectMethod=direct. They have been using selectMethod=cursor as their standard connection string from all apps. From my DBA perspective that's just annoying (it clutters the trace up with useless junk) and (I would speculate) is resulting in many extra app-to-SQL server round trips reducing overall performance. They apparently did test changing (just one of about 60 different app connections) to selectMethod=direct but experienced some issues (of which I have no details) and are concerned about the application breaking. So my questions are: Can using selectMethod=cursor lower application performance as I have tried to argue? (by increasing the number of round trips necessary on a SQL server that already has a very high queries/sec) Is selectMethod= an application-transparent setting on a JDBC connection? Could this break their app if we change it? More generally when should you use cursor vs direct? Also cross-posted to SF. EDIT: Received actual technical details that warrant a significant edit to title question and tags. EDIT: Added bounty. Also added bounty to the SF question (this question is focused on application behavior the SF question is focused on SQL performance.) Thanks!! IIRC you're right. This does seem like a ServerFault question as much as a SO one though. You'd probably be smart to ask at http://www.sqlservercentral.com/ too. My best guess would be that they should try it. Maybe they've got UnitTests which they can fire against the database with the changed connection string (or a little test application). I've mentioned it on the #sqlhelp tag on twitter. No bites there either. I think its considered bad form to cross-post a question across multiple SO sites right? I don't see why it would be and Q's get cross-posted all the time -- especially when they are ""moderated"" from one site to another 2 copies remain. If you get good answers on one site just be sure to link back to the other (to help future searchers). Briefly selectMethod=cursor theoretically requires more server-side resources than selectMethod=direct only loads at most batch-size records into client memory at once resulting in a more predictable client memory footprint selectMethod=direct theoretically requires less server-side resources than selectMethod=cursor will read the entire result set into client memory (unless the driver natively supports asynchronous result set retrieval) before the client application can iterate over it; this can reduce performance in two ways: reduced performance with large result sets if the client application is written in such a way as to stop processing after traversing only a fraction of the result set (with direct it has already paid the cost of retrieving data it will essentially throw away; with cursor the waste is limited to at most batch-size - 1 rows -- the early termination condition should probably be recoded in SQL anyway e.g. as SELECT TOP or window functions) reduced performance with large result sets because of potential garbage collection and/or out-of-memory issues associated with an increased memory footprint In summary Can using selectMethod=cursor lower application performance? -- either method can lower performance for different reasons. Past a certain resultset size cursor may still be preferable. See below for when to use one or the other Is selectMethod= an application-transparent setting on a JDBC connection? -- it is transparent but it can still break their app if memory usage grows significantly enough to hog their client system (and correspondingly your server) or crash the client altogether More generally when should you use cursor vs direct? -- I personally use cursor when dealing with potentially large or otherwise unbounded result sets. The roundtrip overhead is then amortized given a large enough batch size and my client memory footprint is predictable. I use direct when the size of the result set I expect is known to be inferior to whatever batch size I use with cursor or bound in some way or when memory is not an issue. Thanks vladr. Sounds like its a setting that would take some testing. I know the app server is pretty busy so perhaps it was a memory issue that caused some of the problems when they turned this off.  Using selectMethod=cursor prevents SQL Server from using Parallel Query Processing which can have a big performance impact for example when: - you have many CPU cores (and who doesn't?) - you have optimized your database by partitioning tables - you are running lots of aggregate queries (sum() count() etc.) Finally Microsoft states the following: (selectMethod=direct) provides the fastest performance when the application is processing all rows. You should definitely try and see if setting selectMethod=direct makes a difference for you."
325,A,What JDBC tools do you use for synchronization of data sources? I'm hoping to find out what tools folks use to synchronize data between databases. I'm looking for a JDBC solution that can be used as a command-line tool. There used to be a tool called Sync4J that used the SyncML framework but this seems to have fallen by the wayside. I'm primarily using Oracle at the moment and the most full-featured route I've come across is Red Gate's Data Compare: http://www.red-gate.com/products/oracle-development/data-compare-for-oracle/ This old blog gives a good summary of the solution routes available: http://www.novell.com/coolsolutions/feature/17995.html The JDBC-specific offerings I've come across have been very basic. The solution mentioned by Aidos seems the most feature complete if you want to go down the publish-subscribe route: http://symmetricds.codehaus.org/ Hope this helps.  I have heard that the Data Replication Service provided by Db4O is really good. It allows you to use Hibernate to back onto a RDBMS - I don't think it supports JDBC tho (http://www.db4o.com/about/productinformation/drs/Default.aspx?AspxAutoDetectCookieSupport=1) There is an open source project called Daffodil but I haven't investigated it at all. (https://daffodilreplicator.dev.java.net/) The one I am currently considering using is called SymmetricDS (http://symmetricds.sourceforge.net/) There are others they each do it slightly differently. Some use triggers some poll some use intercepting JDBC drivers. You need to decide what technical limitations you are under to determine which one you really want to use. Wikipedia provides a nice overview of different techniques (http://en.wikipedia.org/wiki/Multi-master_replication) and also provides a link to another alternative DBReplicator (http://dbreplicator.org/).  If you have a model and DAO layer that exists already for your codebase you can just create your own sync framework it isn't hard. Copy data is as simple as: read an object from database A remove database metadata (uuid etc) insert into database B Syncing has some level of knowledge about what has been synced already. You can either do it at runtime by getting a list of uuids from TableInA and TableInB and working out which entries are new or you can have a table of items that need to be synced (populate with a trigger upon insert/update in TableInA) and run from that. Your tool can be a TimerTask so databases are kept synced at the time granularity that you desire. However there is probably some tool out there that does it all without any of this implementation faff and each implementation would be different based on business needs anyway. In addition at the database level there will be replication tools. Thanks for the thoughtful answer. I have a roll-your-own syncing strategy at the moment and I'm looking to replace it with something more generic.  True synchronization requires some data that I hope your database schema has (you can read the SyncML doc to see how they proceed). Sync4J won't help you much it's really high-level and XML oriented. If you don't foresee any conflicts (which means: really easy synchronisation) you could try with a lightweight ETL like Enhydra Octopus.
326,A,"getBytes vs getBinaryStream vs getBlob for getting data out of a BLOB column There are 3 different ways to get data out of a Blob column: getBytes getBinaryStream getBlob Also the Blob object returned by getBlob also has a getBytes and getBinaryStream on it. Are there any particular reasons (performance memory database specific problems) that I should pick one over the other? The Blob object also has a free() call that has been introduced since JDBC 4.0. Does that make a difference? Generally you want to pick the stream-based methods (i.e. getBlob().getBinaryStream() or getBinaryStream()) rather than the byte-array method. Performance. The driver has a chance to incrementally pull bytes from the database. Memory. You don't have to load all bytes at once and in one contiguous block. Worst-case is the database (or JDBC driver) doesn't truly support streaming binary data but then there's still no appreciable penalty for using the streaming methods.  If you're going to be pulling a lot of data (i.e. enough data to cause memory problems) then getBinaryStream will give you most flexibility to process and discard the data as you read it in. On the other hand this could be quite slow depending on your JDBC driver since each read from the stream could entail a lot of network chatter with the database. If you call getBytes then the driver knows to fetch the whole lot in one go which is likely to be more efficient. getBlob() returns a ""pointer"" to the data which you can manipulate using the methods on the Blob interface. If you need to modify or otherwise get fancy with the data in-situ then this might be best for you."
327,A,"Oracle Blobs - store size or calculate? I am writing a generic Http resource hosting service and am storing larger objects as BLOBs in an Oracle database. I want to be able to set the 'Content-Length' header when returning a stored object which means I need to know the size of the BLOB before I start writing it to the client (I know I could use chunked-encoding and am in some cases). Does anyone have any experience with the performance impact calling dbms_lob.getlength() will have on every read or should I calculate the BLOB size on INSERT and store it in the table? On average I'd expect write rates to be higher then read rates. I'm writing a benchmark right now to try and see what the impact is but it seems like such a common question I thought someone might have already figured this out. Also using JDBC/Spring 3 how would I even calculate the BLOB size on write? (and I can't use triggers or stored procedures) Thanks. Measure measure measure. Guesses are just guesses. As always but with something like Oracle (used by thousands) this seemed like a pretty frequent paradigm and one that many DBAs have already tackled. If there were any ""gotchas"" about it I would like to know. I did a quick check selecting a BLOB from a table and then a LENGTH(BLOB) and DBMS_LOB.GETLENGTH(BLOB). When selecting the BLOB itself I got 44 consistent gets. When I selected the length (by either method) I got 7 consistent gets. Based on that when I get the length it does not retrieve the entire blob and calculate the length. It is sensible to assume that the length it stored at the start of the BLOB (like they length of a VARCHAR2 value is stored) and this is used directly. As such there shouldn't be a great overhead in deriving the length rather than storing it. It also reduces the chance of an inconsistency. There's a LOB INDEX which is a separate segment so if your LOB can't be stored in line it can find quickly how many blocks need to be used. In short the OP should when fetching a single LOB fetch DBMS_LOB.GETLENGTH() at the same time rather than storing a value which is potentially incorrect. Also with 11g you can use a virtual column to provide the length of the blob.  Since I don't see any answers yet.. I have not personally measured anything but our DBA recommended storing their size (I know it's just that HE told me so). He is pretty good though so I personally believe storing the size is the way to go -- at least if it's performance critical (we would have had to call .length() A LOT). Some DBAs will say any old thing. A good DBA will be able to knock up a code example to justify their assertions.  Because our BLOBS compress well in general we have taken this approach:- store the BLOB compressed. The compression is done on the java side as we stream into the BLOB record the uncompressed size in bytes in another column in the same table uncompress via a stream as we send the BLOB out again knowing what the content size will be You could consider this approach if your BLOBs are compressable."
328,A,"Where to close a JDBC Connection while I want to return the ResultSet It seems that the ResultSet will be automatically closed when I close the Connection. But I want to return the ResultSet and use it in another method then I don't know where to close Connection and PreparedStatement. public ResultSet executeQuery(String sql String[] getValue) { Connection conn = null; PreparedStatement pstmt = null; ResultSet rs = null; try { conn = getConn(); pstmt = conn.prepareStatement(sql); if (getValue != null) { for (int i = 0; i < getValue.length; i++) { pstmt.setString(i + 1 getValue[i]); } } rs = pstmt.executeQuery(); } catch (Exception e) { e.printStackTrace(); closeAll(conn pstmt rs); } return rs; } I've moved closeAll(conn pstmt null); into catch block because I found that if I put it in finally block I'll lost my rs immediately just before it returns. Now when I want to close the rs I can't close the conn and pstmt. Is there any solution? are you attempting to stream the resultSet i.e. avoid simply reading all of the results into some sort of collection and returning that? Off topic why is every one using that brace style?!!! This is Java not C# Thank you all you warmhearteds!It's nearly morning at China but I'm too touched by you and your brilliant answers to sleep.This is my first question at Stackoverflow.com .I really appreciate your help. I will be a frequenter here! @Oscar This must be Jon Skeet's fault. I hate him for that :) You can call ResultSet.getStatement to retrieve the Statement and Statement.getConnection to retrieve the Connection. From these you can write a closeResultSet utility method that will close all 3 for you given nothing but the ResultSet.  One clean way of coding this is to pass in an object that has a callback method that takes a result set. Your other method creates the object with the callback method with it's resultSet handling code and passes that to the method that executes the SQL. That way your SQL & DB code stays where it belongs your result set handling logic is closer to where you use the data and your SQL code cleans up when it should.  interface ResultSetCallBack{ void handleResultSet(ResultSet r); } void executeQuery(... ResultSetCallBack cb){ //get resultSet r ... cb.handleResultSet(r); //close connection } void printReport(){ executeQuery(... new ResultSetCallBack(){ public void handleResultSet(ResultSet r) { //do stuff with r here } }); }  Use CachedRowSet for holding info after disconnecting Connection con = ... ResultSet rs = ... CachedRowSet rowset = new CachedRowSetImpl(); rowset.populate(rs); con.close() After reading the API of CachedRowSetI found this seems to be the easiest way.I think I'll take this answer.  Where to close a JDBC Connection while I want to return the ResultSet Actually you've almost answered that question yourself. As you experimented closing the Connection will release the JDBC resources associated to it (at least this is how things should work). So if you want to return a ResultSet (I'll come back on this later) you need to close the connection ""later"". One way to do this would be obviously to pass a connection to your method something like this: public ResultSet executeQuery(Connection conn String sql String[] getValue); The problem is that I don't really know what is your final goal and why you need so low level stuff so I'm not sure this is a good advice. Unless if you are writing a low level JDBC framework (and please don't tell me you are not doing this) I would actually not recommend returning a ResultSet. For example if you want to feed some business class return some JDBC-independent object or a collection of them as other have advised instead of a ResultSet. Also bear in mind that a RowSet is a ResultSet so if you should not use a ResultSet then you should not use a RowSet. Personally I think you should use some helper class instead of reinventing the wheel. While Spring may be overkill and has a bit of learning curve (too much if you don't know it at all) Spring is not the only way to go and I strongly suggest to look at Commons DbUtils. More specifically look at QueryRunner and especially this query() method: public <T> T query(String sql ResultSetHandler<T> rsh Object... params) throws SQLException As you can see this method allows to pass a ResultSetHandler which exposes a callback method to convert ResultSets into other objects as described in z5h's answer and DbUtils provides several implementations just pick up the one that will suit your needs. Also have a look at the utility methods of the DbUtils class for example the various DbUnit.close() that you may find handy to close JDBC resources. Really unless you have very good reasons to do so (and I'd be curious to know them) don't write yet another JDBC framework use an existing solution it will save you some pain and more important some bugs and you'll benefit from proven good design. Even for low level stuff there are existing (and simple) solutions as we saw. At least check it out.  I'd recommend that you do something more like this: public List<Map> executeQuery(Connection connection String sql) throws SQLException { List<Map> rows = new ArrayList<Map>(); PreparedStatement stmt = null; ResultSet rs = null; try { pstmt = conn.prepareStatement(sql); rs = stmt.execute(); int numColumns = rs.getMetaData().getColumnCount(); while (rs.next()) { Map<String Object> row = new LinkedHashMap<String Object>(); for (int i = 0; i < numColumns; ++i) { String column = rs.getColumnName(i+1); Object value = rs.getObject(i+1); row.put(column value); } rows.add(row); } } finally { close(rs); close(stmt); } return rows; } public static void close(Statement s) { try { if (s != null) { s.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void close(ResultSet rs) { try { if (rs != null) { rs.close(); } } catch (SQLException e) { e.printStackTrace(); } }  You should never pass ResultSet (or Statement or Connection) into the public outside the method block where they are to be acquired and closed to avoid resource leaks. A common practice is just to map the ResultSet to a List<Data> where Data is just a javabean object representing the data of interest. Here's a basic example: public class Data { private Long id; private String name; private Integer value; // Add/generate public getters + setters. } and here's a basic example of how to handle it correctly: public List<Data> list() throws SQLException { Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; List<Data> list = new ArrayList<Data>(); try { connection = database.getConnection(); statement = connection.prepareStatement(""SELECT id name value FROM data""); resultSet = statement.executeQuery(); while (resultSet.next()) { Data data = new Data(); data.setId(resultSet.getLong(""id"")); data.setName(resultSet.getString(""name"")); data.setValue(resultSet.getInt(""value"")); list.add(data); } } finally { if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } return list; } you can use it as follows: List<Data> list = dataDAO.list(); To learn more about the best practices with JDBC you may find this basic kickoff article useful as well.  The way you have it right now the connection would never close which would cause problems later (if not immediately) for your program and the RDBMS. It would be better to create a Java class to hold the fields from the ResultSet and return that. The ResultSet is linked to the connection so returning it and closing the connection is not possible.  You really shouldn't handle with JDBC at the lower level. Use a framework like spring instead it will handle all required close() operations for you. This is a very good point. Using a framework like Spring keeps you from having to reinvent the wheel all the time and focus on building the car. Unfortunately setting up Spring on a new project without any prior experience is pretty much doomed to fail. You don't have to ""set up spring"". For using it's JDBC layer it's simply an additional jar. No extra config is needed. indeed. JDBC isn't always bad. I'm learning JDBC right now is it possible to just skip this part and study into Spring? @tangens It looks like you have to do quite a bit to set up Spring. Here is an example I saw for working with one table's data - http://www.byteslounge.com/tutorials/spring-jdbc-transactions-example  The cleaner way is to use CachedRowSetImpl. But on MySQL 5.x+ there are some bugs with selecting columns by name or label. For use with MySQL use this version: http://stackoverflow.com/a/17399059/1978096  You can't use ResultSet after you've closed Connection and/or PreparedStatement. So you need to pass an object on which to make a callback into this method. All cleanup should be done in finally blocks. Rewrite it like this public ResultSet executeQuery( String sql String[] getValue CallbackObj cbObj ) throws SQLException { final Connection conn = getConn( ); try { final PreparedStatement pstmt = conn.prepareStatement(sql); try { if (getValue != null) { for (int i = 0; i < getValue.length; i++) { pstmt.setString(i + 1 getValue[i]); } } final ResultSet rs = pstmt.executeQuery(); try { cbObj.processResultSet( rs ); } finally { // You may want to handle SQLException // declared by close rs.close( ); } } finally { // You may want to handle SQLException // declared by close pstmt.close( ); } } finally { // You may want to handle SQLException // declared by close conn.close( ); } }"
329,A,"Connection drop problem with Hibernate-mysql-c3p0 This is an issue which I have seen all across the web. I will bring it up again as till now I don't have a fix for the same.  I am using hibernate 3. mysql 5 and latest c3p0 jar. I am getting a broken pipe exception. Following is my hibernate.cfg file. com.mysql.jdbc.Driver org.hibernate.dialect.MySQLDialect  <property name=""hibernate.show_sql"">true</property> <property name=""hibernate.use_sql_comments"">true</property> <property name=""hibernate.current_session_context_class"">thread</property> <property name=""connection.autoReconnect"">true</property> <property name=""connection.autoReconnectForPools"">true</property> <property name=""connection.is-connection-validation-required"">true</property> <!--<property name=""c3p0.min_size"">5</property> <property name=""c3p0.max_size"">20</property> <property name=""c3p0.timeout"">1800</property> <property name=""c3p0.max_statements"">50</property> --><property name=""hibernate.connection.provider_class"">org.hibernate.connection.C3P0ConnectionProvider </property> <property name=""hibernate.c3p0.acquireRetryAttempts"">30</property> <property name=""hibernate.c3p0.acquireIncrement"">5</property> <property name=""hibernate.c3p0.automaticTestTable"">C3P0TestTable</property> <property name=""hibernate.c3p0.idleConnectionTestPeriod"">36000</property> <property name=""hibernate.c3p0.initialPoolSize"">20</property> <property name=""hibernate.c3p0.maxPoolSize"">100</property> <property name=""hibernate.c3p0.maxIdleTime"">1200</property> <property name=""hibernate.c3p0.maxStatements"">50</property> <property name=""hibernate.c3p0.minPoolSize"">10</property>--> My connection pooling is occurring fine. During the day it is fine  but once i keep it idle over the night next day I find it giving me broken connection error. public class HibernateUtil { private static Logger log = Logger.getLogger(HibernateUtil.class); //private static Log log = LogFactory.getLog(HibernateUtil.class); private static Configuration configuration; private static SessionFactory sessionFactory; static { // Create the initial SessionFactory from the default configuration files try { log.debug(""Initializing Hibernate""); // Read hibernate.properties if present configuration = new Configuration(); // Use annotations: configuration = new AnnotationConfiguration(); // Read hibernate.cfg.xml (has to be present) configuration.configure(); // Build and store (either in JNDI or static variable) rebuildSessionFactory(configuration); log.debug(""Hibernate initialized call HibernateUtil.getSessionFactory()""); } catch (Throwable ex) { // We have to catch Throwable otherwise we will miss // NoClassDefFoundError and other subclasses of Error log.error(""Building SessionFactory failed."" ex); throw new ExceptionInInitializerError(ex); } } /** * Returns the Hibernate configuration that was used to build the SessionFactory. * * @return Configuration */ public static Configuration getConfiguration() { return configuration; } /** * Returns the global SessionFactory either from a static variable or a JNDI lookup. * * @return SessionFactory */ public static SessionFactory getSessionFactory() { String sfName = configuration.getProperty(Environment.SESSION_FACTORY_NAME); System.out.println(""Current s name is ""+sfName); if ( sfName != null) { System.out.println(""Looking up SessionFactory in JNDI""); log.debug(""Looking up SessionFactory in JNDI""); try { System.out.println(""Returning new sssion factory""); return (SessionFactory) new InitialContext().lookup(sfName); } catch (NamingException ex) { throw new RuntimeException(ex); } } else if (sessionFactory == null) { System.out.println(""calling rebuild session factory now""); rebuildSessionFactory(); } return sessionFactory; } /** * Closes the current SessionFactory and releases all resources. * <p> * The only other method that can be called on HibernateUtil * after this one is rebuildSessionFactory(Configuration). */ public static void shutdown() { log.debug(""Shutting down Hibernate""); // Close caches and connection pools getSessionFactory().close(); // Clear static variables sessionFactory = null; } /** * Rebuild the SessionFactory with the static Configuration. * <p> * Note that this method should only be used with static SessionFactory * management not with JNDI or any other external registry. This method also closes * the old static variable SessionFactory before if it is still open. */ public static void rebuildSessionFactory() { log.debug(""Using current Configuration to rebuild SessionFactory""); rebuildSessionFactory(configuration); } /** * Rebuild the SessionFactory with the given Hibernate Configuration. * <p> * HibernateUtil does not configure() the given Configuration object * it directly calls buildSessionFactory(). This method also closes * the old static variable SessionFactory before if it is still open. * * @param cfg */ public static void rebuildSessionFactory(Configuration cfg) { log.debug(""Rebuilding the SessionFactory from given Configuration""); if (sessionFactory != null && !sessionFactory.isClosed()) sessionFactory.close(); if (cfg.getProperty(Environment.SESSION_FACTORY_NAME) != null) { log.debug(""Managing SessionFactory in JNDI""); cfg.buildSessionFactory(); } else { log.debug(""Holding SessionFactory in static variable""); sessionFactory = cfg.buildSessionFactory(); } configuration = cfg; } } Above is my code for the session factory. And I have only select operations . And below is the method which is used most often to execute my select queries. One tricky thing which I am not understanding is in my findById method i am using this line of code getSession().beginTransaction(); without which it gives me an error saying that this cannot happpen without a transaction. But nowhere I am closing this transaction. And thers no method to close a transaction apart from commit or rollback (as far as i know) which are not applicable for select statements. public T findById(ID id boolean lock) throws HibernateException DAOException { log.debug(""findNyId invoked with ID =""+id+""and lock =""+lock); T entity; getSession().beginTransaction();  if (lock) entity = (T) getSession().load(getPersistentClass() id LockMode.UPGRADE); else entity = (T) getSession().load(getPersistentClass() id); return entity; } Can anyone please suggest what can I do ? I have tried out almost every solution available via googling on stackoverlow or on hibernate forums with no avail. (And increasing wait_timeout on mysql is not a valid option in my case). I understand that MySQL can invalidate connections after 'n' hours of no use (see here) for a reference. So can you configure C3P0 to validate a connection before giving it to you (the client) ? Or configure C3P0 to time out connections after a certain time ? See this link for more info."
330,A,Java / MySQL - How to access connection from another class? I'm just getting my head around java (and OOP for that matter) the only thing I am familiar with is MySQL. I need to keep the DB connection open throughout the duration of the application as well as a server socket. I'm not even sure if they both need separate classes but here's what I have so far: http://pastebin.com/qzMFFTrY (it wouldn't all go in a code tag) The variable I need is con for line 86. Why not instantiate DoComms with the connection you've got earlier ? e.g. line 44 would be: DoComms conn_c = new DoComms(server con); and DoComms would hold a reference to that connection and then use it at line 86. Note that you get the connection and then close it in the finally block before you instantiate your DoComms objects (line 28). So you should close your connection once you've finished processing everything. Briefly: try { // get connection // do stuff in threads } catch { // handle } finally { con.close(); } If your application is long-lived then I would use connection-pooling (e.g. C3P0 or Apache DBCP) and open/close connections as required. However your approach may well be suitable for your requirements and I wouldn't worry about that for the moment.  I need to keep the DB connection open throughout the duration of the application You shouldn't do that. The connection has a limited lifetime whose length is out of control from your application. When the DB decides that the connection is been open for too long it will close the connection and you'll get connection reset or connection timed out exceptions. This is usually around 30 minutes but can also be less. The normal JDBC practice is to acquire and close Connection Statement and ResultSet in the shortest possible scope i.e. in the very same method block as you execute the query. If the reason for keeping the connection that long open is due to performance then you should consider connection pooling for example c3p0 (usage guide here). Using a temporary table can also require a connection to stay alive for a while. You could do _that_ with pinging once in a while though personally I'd go looking for an alternative solution is such a case.
331,A,"No Row inserted when using hibernate example I trying to use Hibernate 3.5.3 with Postgresql 8.4 and PostGreSQL-8.4.701.jdbc4.jar and after transaction completed no actually data inserted into table. this is the table:  CREATE TABLE doolloop2.dluser ( id bigint NOT NULL firstname character varying(255) lastname character varying(255) email character varying(255) CONSTRAINT users_pkey PRIMARY KEY (id) ) WITH ( OIDS=FALSE ); ALTER TABLE doolloop2.dluser OWNER TO doolloop2; I'm trying to map the following class into this table public class DlUser { private long Id; private String firstname; private String lastname; private String email; public DlUser() { } public void setId(long id) { this.Id = id; } public long getId() { return this.Id; } public void setEmail(String email) { this.email = email; } public void setFirstName(String name) { this.firstname = name; } public void setLastName(String name) { this.lastname = name; } public String getEmail() { return this.email; } public String getFirstName() { return this.firstname; } public String getLastName() { return this.lastname; } } Then I have my hibernate.cfg.xml which looks like this: <?xml version='1.0' encoding='utf-8'?> <!DOCTYPE hibernate-configuration PUBLIC ""-//Hibernate/Hibernate Configuration DTD//EN"" ""http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd""> <hibernate-configuration> <session-factory> <property name=""hibernate.connection.driver_class""> org.postgresql.Driver</property> <property name=""hibernate.connection.url""> jdbc:postgresql://127.0.0.1:5432/doolloop2</property> <property name=""hibernate.connection.username"">doolloop2</property> <property name=""hibernate.connection.password"">doolloop</property> <property name=""hibernate.connection.pool_size"">10</property> <property name=""show_sql"">true</property> <property name=""dialect"">org.hibernate.dialect.PostgreSQLDialect</property> <property name=""hibernate.hbm2ddl.auto"">update</property> <!-- Mapping files --> <mapping resource=""DlUser.hbm.xml""/> </session-factory> </hibernate-configuration> My DlUser.hbm.xml file looks like this: <?xml version=""1.0""?> <!DOCTYPE hibernate-mapping PUBLIC ""-//Hibernate/Hibernate Mapping DTD 3.0//EN"" ""http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd""> <hibernate-mapping> <class name=""com.doolloop.DlDataServices.Session.DlUser"" table=""DlUser""> <id name=""Id"" column=""id"" > <generator class=""assigned""></generator> </id> <property name=""firstName""> <column name=""firstname"" /> </property> <property name=""lastName""> <column name=""lastname""/> </property> <property name=""email""> <column name=""email""/> </property> </class> </hibernate-mapping> The main code looks like this: public static void main(String[] args) { Session session = null; try{ // This step will read hibernate.cfg.xml and prepare hibernate for use SessionFactory sessionFactory = new Configuration().configure().buildSessionFactory(); session =sessionFactory.openSession(); //Create new instance of Contact and set values in it by reading them from form object System.out.println(""Inserting Record""); DlUser user = new DlUser(); user.setFirstName(""Test""); user.setLastName(""Test""); user.setEmail(""Test@yahoo.com""); session.save(user); System.out.println(""Done""); // Actual contact insertion will happen at this step session.flush(); session.close(); } catch(HibernateException ex) { System.out.println(ex.getMessage()); } } and Console output is the following: Sep 25 2010 2:45:09 AM org.hibernate.cfg.Environment <clinit> INFO: Hibernate 3.5.3-Final Sep 25 2010 2:45:09 AM org.hibernate.cfg.Environment <clinit> INFO: hibernate.properties not found Sep 25 2010 2:45:09 AM org.hibernate.cfg.Environment buildBytecodeProvider INFO: Bytecode provider name : javassist Sep 25 2010 2:45:09 AM org.hibernate.cfg.Environment <clinit> INFO: using JDK 1.4 java.sql.Timestamp handling Sep 25 2010 2:45:09 AM org.hibernate.cfg.Configuration configure INFO: configuring from resource: /hibernate.cfg.xml Sep 25 2010 2:45:09 AM org.hibernate.cfg.Configuration getConfigurationInputStream INFO: Configuration resource: /hibernate.cfg.xml Sep 25 2010 2:45:09 AM org.hibernate.cfg.Configuration addResource INFO: Reading mappings from resource : DlUser.hbm.xml Sep 25 2010 2:45:10 AM org.hibernate.cfg.HbmBinder bindRootPersistentClassCommonValues INFO: Mapping class: com.doolloop.DlDataServices.Session.DlUser -> DlUser Sep 25 2010 2:45:10 AM org.hibernate.cfg.Configuration doConfigure INFO: Configured SessionFactory: null Sep 25 2010 2:45:10 AM org.hibernate.connection.DriverManagerConnectionProvider configure INFO: Using Hibernate built-in connection pool (not for production use!) Sep 25 2010 2:45:10 AM org.hibernate.connection.DriverManagerConnectionProvider configure INFO: Hibernate connection pool size: 10 Sep 25 2010 2:45:10 AM org.hibernate.connection.DriverManagerConnectionProvider configure INFO: autocommit mode: false Sep 25 2010 2:45:10 AM org.hibernate.connection.DriverManagerConnectionProvider configure INFO: using driver: org.postgresql.Driver at URL: jdbc:postgresql://127.0.0.1:5432/doolloop2 Sep 25 2010 2:45:10 AM org.hibernate.connection.DriverManagerConnectionProvider configure INFO: connection properties: {user=doolloop2 password=****} Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: RDBMS: PostgreSQL version: 8.4.4 Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: JDBC driver: PostgreSQL Native Driver version: PostgreSQL 8.4 JDBC4 (build 701) Sep 25 2010 2:45:10 AM org.hibernate.dialect.Dialect <init> INFO: Using dialect: org.hibernate.dialect.PostgreSQLDialect Sep 25 2010 2:45:10 AM org.hibernate.engine.jdbc.JdbcSupportLoader useContextualLobCreation INFO: Disabling contextual LOB creation as createClob() method threw error : java.lang.reflect.InvocationTargetException Sep 25 2010 2:45:10 AM org.hibernate.transaction.TransactionFactoryFactory buildTransactionFactory INFO: Using default transaction strategy (direct JDBC transactions) Sep 25 2010 2:45:10 AM org.hibernate.transaction.TransactionManagerLookupFactory getTransactionManagerLookup INFO: No TransactionManagerLookup configured (in JTA environment use of read-write or transactional second-level cache is not recommended) Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Automatic flush during beforeCompletion(): disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Automatic session close at end of transaction: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: JDBC batch size: 15 Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: JDBC batch updates for versioned data: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Scrollable result sets: enabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: JDBC3 getGeneratedKeys(): enabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Connection release mode: auto Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Default batch fetch size: 1 Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Generate SQL with comments: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Order SQL updates by primary key: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Order SQL inserts for batching: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory createQueryTranslatorFactory INFO: Query translator: org.hibernate.hql.ast.ASTQueryTranslatorFactory Sep 25 2010 2:45:10 AM org.hibernate.hql.ast.ASTQueryTranslatorFactory <init> INFO: Using ASTQueryTranslatorFactory Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Query language substitutions: {} Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: JPA-QL strict compliance: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Second-level cache: enabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Query cache: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory createRegionFactory INFO: Cache region factory : org.hibernate.cache.impl.NoCachingRegionFactory Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Optimize cache for minimal puts: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Structured second-level cache entries: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Echoing all SQL to stdout Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Statistics: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Deleted entity synthetic identifier rollback: disabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Default entity-mode: pojo Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Named query checking : enabled Sep 25 2010 2:45:10 AM org.hibernate.cfg.SettingsFactory buildSettings INFO: Check Nullability in Core (should be disabled when Bean Validation is on): enabled Sep 25 2010 2:45:10 AM org.hibernate.impl.SessionFactoryImpl <init> INFO: building session factory Sep 25 2010 2:45:10 AM org.hibernate.impl.SessionFactoryObjectFactory addInstance INFO: Not binding factory to JNDI no JNDI name configured Sep 25 2010 2:45:10 AM org.hibernate.tool.hbm2ddl.SchemaUpdate execute INFO: Running hbm2ddl schema update Sep 25 2010 2:45:10 AM org.hibernate.tool.hbm2ddl.SchemaUpdate execute INFO: fetching database metadata Sep 25 2010 2:45:10 AM org.hibernate.tool.hbm2ddl.SchemaUpdate execute INFO: updating schema Sep 25 2010 2:45:10 AM org.hibernate.tool.hbm2ddl.TableMetadata <init> INFO: table found: doolloop2.dluser Sep 25 2010 2:45:10 AM org.hibernate.tool.hbm2ddl.TableMetadata <init> INFO: columns: [id email lastname firstname] Sep 25 2010 2:45:10 AM org.hibernate.tool.hbm2ddl.TableMetadata <init> INFO: foreign keys: [] Sep 25 2010 2:45:10 AM org.hibernate.tool.hbm2ddl.TableMetadata <init> INFO: indexes: [users_pkey] Sep 25 2010 2:45:10 AM org.hibernate.tool.hbm2ddl.SchemaUpdate execute INFO: schema update complete Inserting Record Done Hibernate: insert into DlUser (firstname lastname email id) values (? ? ? ?) Then when I'm selecting from this table it's empty. I googled for a long time but haven't found any wise explanation what is happening here. Could anybody just help? Thank you in advance Danny. Are you using Logger ? Try to put it into debug mode for hibernate and JDBC libraries. Maybe it'll help You need to define clear transaction boundaries by beginning and committing transactions and to run your persistent code inside these boundaries. As mentioned in the Javadoc of the Session a typical transaction should use the following idiom: Session sess = factory.openSession(); Transaction tx; try { tx = sess.beginTransaction(); //do some work ... tx.commit(); } catch (Exception e) { if (tx!=null) tx.rollback(); throw e; } finally { sess.close(); } See also Sessions and transactions I use this skeleton in my servlets' base class. @Tony This was more intended to be a comment to your answer but didn't fit well in the comment box :) Up to your answer.  Commit your transaction. The log file says autocommit is off. Thank you you're absolutely right Transaction ts = session.beginTransaction(); ts.commit(); solved the problem."
332,A,"Logging PreparedStatements in Java One thing that always been a pain is to log SQL (JDBC) errors when you have a PreparedStatement instead of the query itself. You always end up with messages like: 2008-10-20 09:19:48114 ERROR LoggingQueueConsumer-52 [Logger.error:168] Error executing SQL: [INSERT INTO private_rooms_bans (room_id name user_id msisdn nickname) VALUES (? ? ? ? ?) ON DUPLICATE KEY UPDATE room_id = ? name = ? user_id = ? msisdn = ? nickname = ?] Of course I could write a helper method for retrieving the values and parsing/substitute the question marks with real values (and probably will go down that path if I don't get an outcome of this question) but I just wanted to know if this problem was resolved before by someone else and/or if is there any generic logging helper that would do that automagically for me. Edited after a few answers: The libraries provided so far seems to be suitable to logging the statements for debugging which no doubt is useful. However I am looking to a way of taking a PreparedStatement itself (not some subclass) and logging its SQL statement whenever an error occur. I wouldn't like to deploy a production app with an alternate implementation of PreparedStatement. I guess what I am looking for an utility class not a PreparedStatement specialization. Thanks! AFAIK p6spy does not involve using an alternate implementation of PreparedStatement. I think the way it works is that it acts as a proxy to the JDBC driver and logs all the SQL before forwarding it to the driver What DB are you using? I have found that the MySQL driver has the toString implemented on the Prepared statement that has the statement with the values set. This looks good: [http://www.ibm.com/developerworks/java/library/j-loggable.html](http://www.ibm.com/developerworks/java/library/j-loggable.html) ... however that applies to debug logging right? When you already executed a PreparedStatement and you want just to log after an exception I don't think that would apply right? You would need to have that enabled by default which I don't think is a good thing... we use p6spy to log prepared statements http://www.p6spy.com/ Just as an FYI their website is giving a PHP Error so I had to go to their SF.net download page: http://sourceforge.net/project/showfiles.php?group_id=49288 http://www.p6spy.com/download.html If you are using MySQL MySQL Connector's PreparedStatement.toString() does include the bound parameters. Though third-party connection pools may break this. Sub-class PreparedStatement to build up the query string as parameters are added. There's no way to extract the SQL from a PreparedStatement as it uses a compiled binary form. LoggedPreparedStatement looks promising though I haven't tried it. One advantage of these over a proxy driver that logs all queries is that you can modify the query string before logging it. For example in a PCI environment you might want to mask card numbers.  I tried log4jdbc and it did the job for me. SECURITY NOTE: As of today August 2011 the logged results of a log4jdbc prepared statement are NOT SAFE to execute. They can be used for analysis but should NEVER be fed back into a DBMS. Example of log generated by logjdbc: 2010/08/12 16:30:56 jdbc.sqlonly org.apache.commons.dbcp.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:105) 8. INSERT INTO A_TABLE (ID_FILECODE1ID_GID_SEQUENCEREFNAMEBARDRINK_IDAMOUNTDESCRIPTIONSTATUSCODE2REJECT_DESCRID_CUST_REJ) VALUES (2'123'1'2''aa''awe'null'0123'4317.95'Rccc''0'nullnullnull) The library is very easy to setup: My configuration with HSQLDB : jdbc.url=jdbc:log4jdbc:hsqldb:mem:sample With Oracle : jdbc.url=jdbc:log4jdbc:oracle:thin:@mybdd:1521:smt jdbc.driverClass=net.sf.log4jdbc.DriverSpy logback.xml : <logger name=""jdbc.sqlonly"" level=""DEBUG""/> Too bad it wasn't on a maven repository but still useful. From what I tried if you set You will only get the statements in error however I don't know if this library has an impact on performance. s/Exemple/Example/g  This is very database-dependent. For example I understand that some JDBC drivers (e.g. sybase maybe ms-sql) handle prepared statements by create a temporary stored procedure on the server and then invoking that procedure with the supplied arguments. So the complete SQL is never actually passed from the client. As a result the JDBC API does not expose the information you are after. You may be able to cast your statement objects the internal driver implementation but probably not - your appserver may well wrap the statements in its own implementation. I think you may just have to bite the bullet and write your own class which interpolates the arguments into the placeholder SQL. This will be awkward because you can't ask PreparedStatement for the parameters that have been set so you'll have to remember them in a helper object before passing them to the statement. It seems to me that one of the utility libraries which wrap your driver's implementation objects is the most practical way of doing what you're trying to achieve but it's going to be unpleasant either way."
333,A,"how to store the data in a object array which collected from data base? Here i have coded to get data from DB. I want to store the data in Object Array(POJO). How to do it? This code can also insert Data into DB but omit it. import java.*; import java.io.BufferedReader; import java.io.InputStreamReader; import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.Statement; public class Jdbc { static int id[] = new int[10]; static String name[] = new String[10]; static int salary[] = new int[10]; public static void main(String arg[]) { try { Statement stmt; ResultSet rs; Class.forName(""com.mysql.jdbc.Driver""); String url =""jdbc:mysql://localhost:3306/dwr""; Connection con = DriverManager.getConnection(url""root"" ""1234""); System.out.println(""URL: "" + url); System.out.println(""Connection: "" + con); stmt = con.createStatement(); System.out.println(""Enter EmpId:""); BufferedReader br=new BufferedReader(new InputStreamReader(System.in)); int empId=Integer.parseInt(br.readLine()); System.out.println(""Enter Name:""); BufferedReader br1=new BufferedReader(new InputStreamReader(System.in)); String name1=br1.readLine(); System.out.println(""Enter Salary:""); BufferedReader br2=new BufferedReader(new InputStreamReader(System.in)); int salary1=Integer.parseInt(br2.readLine()); stmt.executeUpdate(""INSERT INTO employee set EmpId='""+empId+""' Name='""+name1+""' salary='""+salary1+""';""); stmt = con.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVEResultSet.CONCUR_READ_ONLY); rs = stmt.executeQuery(""SELECT * "" + ""from employee ORDER BY EmpId""); System.out.println(""Display all results:""); int i = 0; while(rs.next()){ id[i]= rs.getInt(""Empid""); name[i]= rs.getString(""Name""); salary[i]= rs.getInt(""Salary""); System.out.println(""\n EmpId "" + id[i]+ ""\n name "" + name[i] + ""\n salary "" + salary[i]); } }catch( Exception e ) { e.printStackTrace(); } Jdbc pojo = new Jdbc(); } } Think of a database table as *the array* What how to do it. I am newbie. You can either use the get methods provided to populate the fields of the object one at a time so if you have an object named employee that takes in 3 arguments (id name and salary) you can have something like this: List<Employee> employee = new ArrayList<Employee>(); while(rs.next()) { employee.add(new Employee(rs.getInt(""Empid"") rs.getString(""Name"")rs.getInt(""Salary"")); } Or else you can use an ORM Tools like Hibernate and use it to retrieve objects as shown here P.S. The Java code I have provided is more like Pseudo code. I have not tested it."
334,A,Application to query a database and send results as file via HTTPS I've currently got a tool which allows me to configure a database connection (using JDBC) and specify a set of queries to run against the database. This is scheduled to run at a specific time of day (using cron or windows scheduler currently). The tool then exports the results to a file (xml) and sends this file to my server via HTTPS. This tool is installed on customers computers so that I can get some data feeds from them for later processing. I'd like to write a front-end to this that will make it easy for customers to set up the data extraction themselves. However I'm not really familiar with Rich Client front-end development (being a integration software developer) and was wondering whether there was an existing tool that would do all this or if it was worth learning a bit of Swing say so I could knock up a front-end. Do any of you know of a suitable tool? (I'm looking for a one function kind of thing rather than a full data extraction and transformation suite which may scare off some customers) If your tool already exists and is working I think the best approach would be to just read a bit about GUI events programming (it's fairly easy once you get the grasp of it and have a nice GUI Builder) and wrap up a small GUI using a GUI Builder. For Java I can recommend the Netbeans IDE and its GUI Builder. The easiest path then would be for the GUI to just pass the received arguments to the existing tool via Runtime.exec() or a similar approach.  In my opinion it's quite easy and fast to make a decent UI via Swing. The Swing tutorial may be a good start.
335,A,"Eclipse and Classpath I swear I'm going insane. JDeveloper runs my project with not a single complaint. If I do ""java -cp /usr/share/java/mysql.jar:. MAIN.java"" it works like a charm. But Eclipse says ""[censored] you"" and ignores my classpath settings. I open the Run > Run... menu and add the mysql jar in the classpath tab but time and time again I keep getting ""No suitable driver found"". Now I shouldn't have to add the jar to the build path ---otherwise what's the point of using JDBC if I'm gonna rebuild if I wanna change the engine---. Nor should I have to do ""Class.forName()"" which I don't need in the other ways to run it. A hand in this insanity? Try to add the jar as command line argument in Run dialog.  That is not how I normally add jars to an eclipse project. Try following the steps in this Wiki. The build path is also used as the runtime classpath. You can alternatively add it in a launcher definition (and save that definition with the project if you want to share it -- see the ""common"" tab of the launcher config) Why whould I add it to the build path if I'm not building MySQL into my app?  Sure just set your JRE to the proper Java6 one instead of relying on Eclipse's autoconfig. Yes I'm talking to myself."
336,A,"is there a standard way to define a JDBC Datasource for Java EE containers? I know that for JBoss you need a [name]-ds.xml file in the /deploy subdirectory of the appropriate instance. i dont have any experience with other Java EE containers but im trying to stick to standards as much as possible. is there a standard way to define a JDBC datasource and deploy it ? if possible i'd like to include my datasource inside the *.ear file (for instance an embedded in-memory HSQLDB datasource for demo purposes) ? if there is no standard way will other containers at least accept the jboss way ? (/deploy/*-ds.xml) Is there a standard way to define a JDBC datasource and deploy it ? No this is container specific. As Application Component Provider you're supposed to document the resources you need and the Application deployer and Administrator will configure them. If there is no standard way will other containers at least accept the JBoss way? No because this is the JBoss way and thus JBoss specific. With Tomcat you would have to use the context.xml file. With Jetty jetty-env.xml. With WebSphere you can create a so called WebSphere Enhanced EAR. With WebLogic you can package a JDBC Module in your application. With GlassFish you can use the command asadmin add-resources my.xml to add a datasource described in a XML file (example here). Etc etc. Note that there are some projects trying to achieve this goal in a universal way like jndi-resources or Cargo. There are also more complex solution like ControlTier or Chef. Now in your case (as I understood you want to use an embedded database that will be bundled with your application) I don't think you should configure a datasource at the application server level. You should just package the jar of your database in your application with a standalone connection pool like c3p0 or DBCP. >this is container specific. - No it's not necessarily container specific. There is a standard way as well using the `` element in e.g. web.xml (see my answer below).  Is there a standard way to define a JDBC datasource and deploy it? Yes there is. It's done via the <data-source> element which you can put in web.xml ejb-jar.xml and application.xml. If you don't like XML you can also use an annotation for this instead: @DataSourceDefinition Example of a web.xml entry <data-source> <name>java:app/myDS</name> <class-name>org.postgresql.xa.PGXADataSource</class-name> <server-name>pg.myserver.com/server-name> <database-name>my_db</database-name> <user>foo</user> <password>bla</password> <transactional>true</transactional> <isolation-level>TRANSACTION_READ_COMMITTED</isolation-level> <initial-pool-size>2</initial-pool-size> <max-pool-size>10</max-pool-size> <min-pool-size>5</min-pool-size> <max-statements>0</max-statements> </data-source> Further reading: Introducing the DataSourceDefinition Annotation The state of @DataSourceDefinition in Java EE Example application use standard data source p.s. I'm surprised all other answers say this doesn't exist while it clearly does even at the time this question was originally asked. The question was about container-specific config I believe? Like http://docs.jboss.org/jbossas/docs/Server_Configuration_Guide/4/html/Connectors_on_JBoss-Configuring_JDBC_DataSources.html This isn't the equivalent of that if I understand the question correctly. But yeah you're right this is the right answer for 90% of cases -- it was a few months old at the time this was asked and I sure didn't know about it! @SeanOwen >`The question was about container-specific config I believe` - I think Op asked for a standard way for something that could otherwise be done via container-specific config. I agree that at the time this mechanism was only a few months old and the various vendors didn't really make a lot of noise about it. yup OP was definitely looking for something like this :-) thank you very much Arjan. it does mean i need to go with exploded deployment to make the config easily accessible to scripts/tools but its a very valid option. if you look at the date though i was looking at ~2010 so j2ee6 wasnt really an option. @radai you're welcome! Note that I issued https://java.net/jira/browse/JAVAEE_SPEC-19 to address the configurability concern for among others the datasource in web.xml. If you or anyone else cares for this please give it a vote ;)  Sun's Java EE philosophy defines several roles in the design development and deployment of an enterprise application. Java EE design accommodates and reflects these separations of concerns. In particular Sun wants to separate the developer from the administrator of an application which is a good idea. The developer writes enterprise components in a container-agnostic way. In web.xml for example you do declare your DataSources in a standard way: <resource-ref> <res-ref-name>jdbc/myDB</res-ref-name> <res-type>javax.sql.DataSource</res-type> <res-auth>Container</res-auth> </resource-ref> This says ""this database thing the application needs make it available to me whatever database is and whatever container you're running it in via standard JNDI at 'jdbc/myDB' "". This is as much as the developer can do -- the rest is necessarily container specific and therefore not standardized. And then how ""myDB"" is actually configured is up to a different role the administrator of the container. So I'm repeating the correct answer above: no. But the reason is otherwise you'd be coding your app to a specific type of database on a specific host and port and the point is that you shouldn't be able to do that so there's no standard support for that on purpose. while youre right for the general case in my case i plan on using an in-jvm in-memory DB with hibernate on top (think of it as an Object cache) - something i was hoping could be done in a portable fashion > which is a good idea - it's a good idea for some use cases but not for all use cases. Java EE 6 started to provide alternatives (e.g. you can define a data source from within your app) and Java EE 7 has continued this trend (things like JMS destinations and mail sessions can be defined from the app as well). >you shouldn't be able to do that - The spec shouldn't mandate a one-and-only-one way of working. This explanation completely fails to take into account the existence of local private (possibly in-memory) databases AND it doesn't scale down to the simplest of apps. Interfaces and separate modules for business logic might have been a best practice for some use cases but enforcing it made EJB feel heavyweight. From Java EE 6 onwards the choice is up to the developer (Interfaces and a separate EJB module are optional now). Other reasons for embedded datasources: agile teams devops cloud deployments unit and integration tests tutorials and demos ... The list is endless... I was more just describing the Sun rationale here which does feel somewhat antiquated now. Separation of concerns remains a good idea and doesn't prevent you from packaging separate concerns at a higher level. As to whether it's worth the trouble -- still probably yes for a big app probably not for small libraries and small dependencies. JavaEE hardly scales down yes. The spec has to mandate a coherent architecture and way of working I don't agree that it shouldn't but it sure may not be suitable for all use cases."
337,A,"Best way to validate user input JDBC? Is there a built-in way to escape user input in java using the JDBC? Something similar to the php version mysql_real_escape() function. What's the best way to validate input? If you mean how do you make sure user input can't be used in SQL injection attacks the way to do this (and the way all SQL should be written in JDBC) is using Prepared Statements. JDBC will automatically handle any necessary escaping. http://java.sun.com/docs/books/tutorial/jdbc/basics/prepared.html +1: Always Use Bind Variables! ""Escaping"" the input is to assemble dynamic SQL statements is dumb for many reasons. The poor chap seems to have been tainted by PHP....  Just to add to the suggestion by @skaffman PreparedStatements solve the issue for the majority of applications. However there are some applications where (parts of) SQL statements (as opposed to just parameter values) are taken from user input (for example a URL parameter containing the ORDER BY clause). Just make sure you sanitize those as well or better yet avoid such designs if possible. This example isn't particularly compelling. if you want to have a user-injectable order-by clause then have a fixed set of parameter which the application recognises and then has a look up table of column names for each permitted value."
338,A,"Using JNDI for Database connections This might sound like a noob question but this is the first time I'm treading into Database territory. From here I got the info that The most efficient way to implement communication between the server and database is to set up a database connection pool. Creating a new connection for each client request can be very time-consuming especially for applications that continuously receive a large number of requests. and the tutorial uses a JNDI datasource. My application is also similar(but I won't be using Tomcat just sockets) and my server will be getting requests from multiple clients but I don't understand why should I use a JNDI datasource why can't the server maintain one open connection with the Database and when a client request arrives it will process the request and feed the data to the client. In the worst case If I should need a JNDI how can I implement it with my server app? JNDI for database connections solves the situation where the application developers are not the ones who manage the connections to the database. So an application developer may specify how many simultaneous connections their application needs. Then the server administrator would define the pool of database connections. The application looks up the pool. Neither the application nor the application developer would need to know the credentials necessary to connect to the database. Also the server administrator could define the connection pool to be different sizes depending upon the deployment environment and the application is insulated from knowing about such differences. Since your application is the server itself the application is therefore responsible for defining and managing the connection(s) to the database. For connection count one option is to just guess and then do a load test at the expected maximum production volume and monitor the connection usage. Use about 110% of the maximum you observed in your load test. Or you can examine your application's usage of connections and try to come up with an educated guess based upon how the DB is accessed how many simultaneous clients there are etc. The credentials are stored in the application server's configuration. Servers do it differently but they expose the connection pool in a standard way JNDI. How does an app developer judge the number of simultaneous connections. If the app and the app developer doesn't know the security parameters(credentials) where are these specified? Are these loaded in a configuration file?  Thus it is a client application? The application and the database usually talks with each other using a connection obtained by DriverManager#getConnection()? If so then you don't necessarily need JNDI to get connection pooling to work. Alone the connection pooling framework in question would already suffice. For example C3P0 or Apache Commons DBCP (I would recommend C3P0; DBCP is singlethreaded). Just replace the DriverManager#getConnection() by it. Edit: reply on your comments: The server would be talking to the database and the clients connect to the server so I won't know whether to call this a client application. I actually mean a plain vanilla Java application which doesn't run inside a Java EE container. Pascal has worded it better. Actually I'm a bit confused about how connection pooling works does each connection run in its own thread? is there any document/book to help me get a better understanding of these concepts vis-a-vis a non pooled connection? To start the connection pool opens a connection and holds it open as long as up to the configured timeout. The connection pool wraps/decorates the connection with its own implementation. The connection pool can open and hold a configured amount of connections simultaneously. When you call getConnection() it will immediately give you an already opened connection. When you call close() on the connection it will put the connection back in the pool for future requests. This thus means that you still have to write the JDBC code the usual way: acquire and close the Connection Statement and ResultSet in the shortest possible scope. Close them all in the finally block. If your JDBC code is already well written in fact only the DriverManager#getConnection() needs to be replaced. As you ought to open and close the Connection in the very same method block it will normally run in the same thread. The connection pooling will worry about that the Connection is not acquired by another threads in the meanwhile until your code calls close() on the Connection. You can find here a nice article to get the idea how connection pooling works under the hood (take care: don't use it for production and don't homegrow it further it is just to get the whole idea). For real work use an existing thoroughly developed and robust connection pooling framework. Thanks for the clear concise explanation I had made some sample code using DriverManager but I was keeping the connection open. My clients are using sockets to connect to the server and are going to remain connected. Each client is running in its own read/write thread so if the server wants to pass on data it would just ask data from the database(from the already open connection) and pass it on to the said client. Is this the right way to go about or should I close the connection asap? The normal practice is that you should close the connection in the finally block to avoid resource leaks and/or potential application crashes in the case that you have more than one connection open and/or that the DB times out the connection. To improve connection performance the best way is to use a connection pool. Just ensure that you don't configure the connection pool's timeout (i.e. how long to keep the connection open) longer than the DB's own connection timeout. The server would be talking to the database and the clients connect to the server so I won't know whether to call this a client application. And yes the server part of the code is using DriverManager.getConnection() Thanks for the C3P0 link.  My application is also similar(but I won't be using Tomcat just sockets) and my server will be getting requests from multiple clients but I don't understand why should I use a JNDI datasource why can't the server maintain one open connection with the Database and when a client request arrives it will process the request and feed the data to the client. Well you could. But what if you have multiple clients and if you have to serve concurrent requests? Of course you could maintain one connection open per client but this doesn't scale really well (which might not be a problem in your context). Still the traditional way to solve this is to use a connection pool (and to benefit from extra services e.g. connection validation connection renewal) and to use it to obtain a connection ""on demand"". If you are not in a J2EE container context use a standalone connection pool implementation something like c3p0 (prefer c3p0 over DBCP which is considered as out of date and less robust under load) and forget JNDI (which is just the standard way to get a handle on a connection pool when you are running inside a J2EE container). Have a look at c3p0's documentation for more details and code samples it's pretty clear. I didn't know JNDI was used only in the context of a J2EE container thanks for bringing that into notice and also for the c3p0 and DBCP links. Actually I'm a bit confused about how connection pooling works does each connection run in its own thread? is there any document/book to help me get a better understanding of these concepts vis-a-vis a non pooled connection?  Throwing out another link to another connection pool: BoneCP (http://jolbox.com). Benchmarks indicate that it's faster than C3P0/DBCP. P.S. Haven't seen DBCP lock up either in my multi-threaded tests."
339,A,"jdbc driver for Microsoft SQL Server CE(Compact Edition) 3.5 I want to be able to explore the contents of a DB for this version of the DB. I was thinking of using the Squirrel DB client (which needs a JDBC driver). Therefore I'm looking for a JDBC type 4 driver for SQL SERVER 3.5. Can somone point me to a FREE OR open source or trial ware ? If no JDBC driver how do MS developers explore a given .SDF file ? Thank you BR ~A JDBC driver uses TCP/IP connection. The compact edition most likely cannot listen on TCP/IP port 1433. Compact Edition is meant to be accessed by an application which has loaded the .dlls necessary to talk to it. It's meant for Visual Studio projects. You need to uninstall compact edition and install SQL Express 2005/2008 instead. After installation enable the ""sa"" account give it a password enable SQL+NT authentication and then enable the TCP/IP listener to listen on port 1433 (the default port). Then finally you can connect with JDBC. Jtds is a JDBC3.0 driver and therefore requires JDK1.6+ . I prefer using the Microsoft 2005 JDBC2.0 driver.  There is a free program called SQLCeEditor that does it. I'd still like a JDBC driver though since that would make it easy to use with Eclipse and Java.  If you're into linq syntax you can also use LinqPad. There's a free version that allows exploring the data and editing it. You would pay for autocompletion but you can live without it. I hope this helps.  1- There isn't a JDBC driver and at time of writing MS has no plans to create one. 2- There isn't a ODBC driver so the next obvious answer (JDBC to ODBC bridge) won't help you. 3- Some JDBC vendors claim to be able to connect to 'any oledb' data source so that is yoru most likely best bet-- link but it won't necessarily be free.  Have you tried SQL Server Management Studio Express? You can access SQL Server Compact 3.5 databases stored on a smart device or on the desktop computer by using SQL Server Management Studio in SQL Server or SQL Server Management Studio Express (SSMSE). http://technet.microsoft.com/en-us/library/ms172037.aspx As for the JDBC Driver you could take a look at this one provided by Microsoft. I don't know if it works with the Compact Edition or if you already tried it but I thought it was worth mentioning.  Use SDF Viewer to explore your .SDF database file can also import/export data script and work with tables indexes and foreign keys.  Try jTDS it's a free software JDBC driver for SQL Server and Sybase. http://jtds.sourceforge.net/ Its too bad jtds doesnt support a sqlce database. I guess that would be some complex jni stuff though... so it makes sense it wouldn't."
340,A,"How to define Spring datasource in controller? Is it possible to define a datasource connector in a Spring controller ? I'm working on a tool : synchronize a source table to a target table. I would define source and target in my controller (to synchronize different databases - in my view I can select different source and target databases). Actually I define my datasource in file call : datasource.xml My code : <?xml version=""1.0"" encoding=""UTF-8""?> <beans xmlns=""http://www.springframework.org/schema/beans"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns:context=""http://www.springframework.org/schema/context"" xsi:schemaLocation=""http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd""> <context:annotation-config /> <bean id=""sourceDataSource"" class=""org.springframework.jdbc.datasource.DriverManagerDataSource""> <property name=""driverClassName"" value=""com.mysql.jdbc.Driver""/> <property name=""url"" value=""jdbc:mysql://localhost/source""/> <!--<property name=""url"" value=""jdbc:mysql://linkSource""/>--> <property name=""username"" value=""username""/> <property name=""password"" value=""password""/> </bean> <bean id=""targetDataSource"" class=""org.springframework.jdbc.datasource.DriverManagerDataSource""> <property name=""driverClassName"" value=""com.mysql.jdbc.Driver""/> <property name=""url"" value=""jdbc:mysql://localhost/target""/> <!--<property name=""url"" value=""jdbc:mysql://linkTarget""/>--> <property name=""username"" value=""username""/> <property name=""password"" value=""password""/> </bean> </beans> Thank you for your help ! Thank you for your help ! But I think I put my question badly. Actually I have in my sync-servelt.xml (just part) :  <!--sync query beans--> <bean id=""sourceDatasetQueryBean"" class=""ds.sync.db.SyncDatasetQuery"" name=""sourceDatasetsQuery""> <property name=""dataSource"" ref=""sourceDataSource""/> </bean> <bean id=""targetDatasetQueryBean"" class=""ds.sync.db.SyncDatasetQuery"" name=""targetDatasetsQuery""> <property name=""dataSource"" ref=""targetDataSource""/> </bean> <bean id=""sourceDatasetDescriptionQueryBean"" class=""ds.sync.db.SyncDatasetDescriptionQuery"" name=""sourceDatasetsDescriptionQuery""> <property name=""dataSource"" ref=""sourceDataSource""/> </bean> <bean id=""targetDatasetDescriptionQueryBean"" class=""ds.sync.db.SyncDatasetDescriptionQuery"" name=""targetDatasetsDescriptionQuery""> <property name=""dataSource"" ref=""targetDataSource""/> </bean> ...more... And in my controller I'm using :  @Autowired @Qualifier(""sourceDatasetQueryBean"") protected SyncDatasetQuery m_datasetQuerySource; @Autowired @Qualifier(""targetDatasetQueryBean"") protected SyncDatasetQuery m_datasetQueryTarget; @Autowired @Qualifier(""sourceDatasetDescriptionQueryBean"") protected SyncDatasetDescriptionQuery m_datasetDescriptionQuerySource; @Autowired @Qualifier(""targetDatasetDescriptionQueryBean"") protected SyncDatasetDescriptionQuery m_datasetDescriptionQueryTarget; ...more... I have 11 tables to sync between source and target... Is there a way to group my query beans ? My synchronizations must be performed on several databases. For example I have 3 sites in different places 1 site is SOURCE (A) 2 sites are TARGET (B & C) ; with a form (made with YUI) I should be able to sync A->B and A->C. To sum up : 1- with my form I select a SOURCE and a TARGET (serveral databases) 2- my form send (in Ajax) the selected SOURCE and selected TARGET to my controller 3- my controller points to the good database. What is the best way to do this ? Using a Factory ? Using setDataSource ? Thank you for help. Finally by using DriverManagerDataSource and using setter I can redefine my dataSource selected (target and source) dynamically in my controller. I just need to use : setDriverManagerDataSource(m_sourceDataSource); and m_datasetQuerySource.setDataSource(dataSource); (SOURCE) Same play with target and all tables. I see also other way to do that : http://blog.springsource.com/2007/01/23/dynamic-datasource-routing/ http://grails.org/Spring+Bean+Builder  If you don't want to be messing with spring xml files and relay in properties or any other GUI to define those datasources at runtime you might use: applicationContext.getBean(beanobject[]) Be aware that is not a good practise with spring (even that it is quite handy sometimes). This way you define your beans expecting constructor arguments and supply those arguments as part of the array. This way you create as many datasources you need at runtime getting those from wherever you want to store the information.  You should be able to use the following syntax to achieve what you want (see Spring 2.x docs): @Autowired @Qualifier(""targetDataSource"") DataSource targetDataSource; @Autowired @Qualifier(""sourceDataSource"") DataSource sourceDataSource;  So assuming your data sources are defined correctly it's only a matter of injecting them into your Controller: <bean id=""myController"" class=""...""> <property name=""sourceDS"" ref=""sourceDataSource"" /> <property name=""targetDS"" ref=""targetDataSource"" /> .... </bean> If I have more than one target (could be 5 targets) what is the best to select the good target in my controller ? A factory is it a good idea ?"
341,A,JDBC Wrapper tutorial - is it still relevant? This article from IBM about a JDBC wrapper seems good and I'm tempted to use it: http://www.ibm.com/developerworks/java/library/j-jdbcwrap/index.html but it its dated 2001 - is it still relevant to today's best practices or has this been superseded by something else better? Your opinions are much appreciated. If you don't mind adding third party libraries - take a look at Spring. They have some very nice wrappers and abstractions around JDBC - they can significantly reduce code clutter. You will end up adding an XML config file but this isn't necessarily a bad thing. Spring can use pooling libraries to help with connection management - important in an enterprise environment.  Also have a look at the Java Persistence API (JPA). It's another abstraction layer which can help you avoid any SQL or DAO's completely. You might still want to use SQL for doing relational type things.  After a short glance at the source code of Table I’d strongly advise against it as it does nothing to prevent SQL injections. You’re a lot better of using “normal JDBC” especially PreparedStatement.  Spring with Hibernate is what you need.
342,A,"How to manage a large dataset using Spring MySQL and RowCallbackHandler I'm trying to go over each row of a table in MySQL using Spring and a JdbcTemplate. If I'm not mistaken this should be as simple as: JdbcTemplate template = new JdbcTemplate(datasource); template.setFetchSize(1); // template.setFetchSize(Integer.MIN_VALUE) does not work either template.query(""SELECT * FROM cdr"" new RowCallbackHandler() { public void processRow(ResultSet rs) throws SQLException { System.out.println(rs.getString(""src"")); } }); I get an OutOfMemoryError because it is trying to read the whole thing. Any ideas? If you suspect you are getting the OutOfMemory error due to the entire table read why dont you try splitting your query. Use filters LIMIT clause etc. That would cause the logic of the process to be much more complex. I'm now testing a way to actually do the streaming via the Spring JdbcTeamplate. Will let you know if it works...  Here's a Spring solution based on the answer provided by BalusC. class StreamingStatementCreator implements PreparedStatementCreator { private final String sql; public StreamingStatementCreator(String sql) { this.sql = sql; } @Override public PreparedStatement createPreparedStatement(Connection connection) throws SQLException { final PreparedStatement statement = connection.prepareStatement(sql ResultSet.TYPE_FORWARD_ONLY ResultSet.CONCUR_READ_ONLY); statement.setFetchSize(Integer.MIN_VALUE); return statement; } } Somewhere in your code: DataSource dataSource = ...; RowCallbackHandler rowHandler = ...; JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource); jdbcTemplate.query(new StreamingStatementCreator(""SELECT * FROM huge_table"") rowHandler);  The Statement#setFetchSize() javadoc already states: Gives the JDBC driver a hint as to the number of rows that should be fetched from the database The driver is actually free to apply or ignore the hint. Some drivers ignore it some drivers applies it directly some drivers needs more parameters. The MySQL JDBC driver falls in the last category. If you check the MySQL JDBC driver documentation you'll see the following information (scroll about 2/3 down until header ResultSet): To enable this functionality you need to create a Statement instance in the following manner: stmt = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY); stmt.setFetchSize(Integer.MIN_VALUE); Please read the entire section of the document it describes the caveats of this approach as well. To get it to work in Spring you'll however need to extend/override the JdbcTemplate with a custom implementation. As I don't do Spring I can't go in detail about this but now you at least know where to look. Good luck. I've added a Spring-based solution here: http://stackoverflow.com/questions/2095490/how-to-manage-a-large-dataset-using-spring-mysql-and-rowcallbackhandler/2834590#2834590"
343,A,"Java: Trouble connecting to MySQL I'm writing a desktop java app on that I want to connect to a MySQL database on a server. Here is the code to do that: import java.io.IOException; import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; private static Connection getDBConnection() throws SQLException InstantiationException IllegalAccessException ClassNotFoundException { String username = ""myUserName""; String password = ""myPassWord""; String url = ""jdbc:mysql://www.domainName.com:3306/databaseName""; Class.forName(""com.mysql.jdbc.Driver""); System.out.println(""Connecting to database...""); //hangs here Connection conn = DriverManager.getConnection(url username password); return conn; } When I run this it hangs on the DriverManager.getConnection() call. Why does this happen? Is my URL malformed? (I'm not getting any error messages but the program doesn't respond as if in an infinite loop. I haven't waited longer than 90 seconds to see if the connection will ever be established.) Also what is the purpose of the Class.forName() call? How does it work? I am almost entirely certain that the username and password are correct. (I just used userName and passWord as placeholders above.) UPDATE: I fixed the port number and now I get this error: Cannot connect to database: java.sql.SQLException: Access denied for user 'userName'@'r236059121.resnet.mySchool.edu' (using password: YES) Does this mean I need to configure settings on the database? Or does it mean that I've got the credentials wrong? (They work for PHP scripts deployed on the server that contains the database.) SOLUTION: Added the host above to the Access Host list on cPanel. Added place above. The domain is the domain name of the site which is backed by the database in question and which works fine using the credentials I supplied above. I don't know how to access the database from the command line. :( Not sure about the hanging but your URL is properly formatted so that's not the issue. Does the mysql client work on your computer? I guess this maybe firewall/configuration issues. Rosarch check my updated answer regarding the user/password issue. The credentials are correct. Could this still be a firewall/configuration issue? What is the exact domain in your url and what is the exact 'place' bit in the error message? Can you connect using these credentials on the command line? if so what does `SELECT USER() CURRENT_USER()` give? I think the line should just be Class.forName(""com.mysql.jdbc.Driver""); (close the .newInstance() bit) That causes the driver to register itself with the driver manager and allows the driver manager to pick a driver for the database url. I think the hang is caused by a DNS problem or some other reason why your db cannot be reached. By default the MySQL JDBC driver does not time out for a connection. See http://dev.mysql.com/doc/refman/5.0/en/connector-j-reference-configuration-properties.html and look for connectTimeout. In your code you have  String url = ""jdbc:mysql://www.domainName.com:portNumber/databaseName""; I take it that you used a real port there? By default it should be 3306. You can test with the test database which is present in virtually all mysql instances:  String url = ""jdbc:mysql://www.domainName.com:3306/test""; You also wrote:  String username = ""myUserName""; String password = ""myPassWord""; Obviously you should use real credentials here too. Ask your dba what they are. If you're the DBA then...well you should probably read up on MySQl administration :) Seriously when you installed MySQL you were probably promted for a password for the root user. Use those (in the obvious way) In real code you should probably not hang when the db is not there. So I advise adding a connectTimeout option like so:  String url = ""jdbc:mysql://www.domainName.com:3306/test?connectTimeout=3000""; (connectTimeout is in milliseconds so this would time out after 3 seconds) Yes I had the wrong port number but now I have another issue. (see above).  Seems to me like your database is not reachable and you will probably get an error when the call runs into a timeout. Are you sure the hostname and port are right and reachable from your machine? You don't need the newInstance() at the end of Class.forName(). Class.forName() triggers the classloader to load that class which in turn triggers some internal registration code in the driver which makes the driver available.  Rosarch - You are not able to connect to your DB since its unreachable. It'll timeout after a while. Try telnetting - telnet <IP-OF-domainName.com> <PortNumber> You'll mostly see that it shows timeout. Solutions - 1.) If you are behind a firewall you need to punch a hole to allow access 2.) If you are behind a proxy need to configure it to allow access"
344,A,"Spring JDBC DAO Im learning Spring (2 and 3) and i got this method in a ClientDao  public Client getClient(int id) { List<Client> clients= getSimpleJdbcTemplate().query( CLIENT_GET new RowMapper<Client>() { public Client mapRow(ResultSet rs int rowNum) throws SQLException { Client client = new ClientImpl(); // !! this (1) client.setAccounts(new HashSet<Account>()); // !! this (2) client.setId(rs.getInt(1)); client.setName(rs.getString(2)); return client; } }id ); return clients.get(0); } and the following Spring wiring: <bean id=""account"" class=""client.AccountRON"" scope=""prototype""> <property name=""currency"" value = ""RON"" /> <property name=""ammount"" value=""0"" /> </bean> <bean id=""client"" class=""client.ClientImpl"" scope=""prototype""> <property name=""name"" value=""--client--"" /> <property name=""accounts""> <set> </set> </property> </bean> The things is that i dont like the commented lines of java code (1) and (2). I'm going to start with (2) which i think is the easy one: is there a way i can wire the bean in the .xml file to tell spring to instantiate a set implementation for the 'accounts' set in ClientImpl? so i can get rid of (2) Now moving on to (1): what happens if the implementation changes ? do i really need to write another DAO for a different implementation? or do i have to construct a BeanFactory ? or is there another more beautiful solution ? Thanks! I'm a bit confused here - why have you defined a ClientImpl bean in your XML but not using it in your Java? Your already have most of the solution you just need to fetch a new ClientImpl from Spring each iterations through the loop: private @Autowired BeanFactory beanFactory; public Client getClient(int id) { List<Client> clients= getSimpleJdbcTemplate().query( CLIENT_GET new RowMapper<Client>() { public Client mapRow(ResultSet rs int rowNum) throws SQLException { Client client = beanFactory.getBean(Client.class); client.setId(rs.getInt(1)); client.setName(rs.getString(2)); return client; } }id ); return clients.get(0); } With this approach the actual construction and initialization of ClientImpl is done by Spring not your code. Thanks. I dont know why i though that having a Factory in the DAO was bad. Now it seems ok. I must be tired."
345,A,"SQL Deletion Cascading Help (Specific Question) I have two tables (renamed/refactored for illustrative purposes) with a Many-To-Many relationship in an HSQL database. I want everything to be wiped out when I delete from one side of a Many-to-Many relationship (without querying the table; this is performance critical) Here are my main tables: CREATE TABLE PERSON ( PERSON_ID INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY NAME VARCHAR(50) ) CREATE TABLE JOB ( JOB_ID INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY NAME VARCHAR(50) ) Here is my join table: CREATE TABLE JOB_PERSON ( PERSON_ID INTEGER JOB_ID INTEGER ) Here are my constraints: ALTER TABLE JOB_PERSON ADD CONSTRAINT FK_PERSON_JOB FOREIGN KEY(PERSON_ID) REFERENCES PERSON ON DELETE CASCADE ON UPDATE CASCADE ALTER TABLE JOB_PERSON ADD CONSTRAINT FK_JOB_PERSON FOREIGN KEY(JOB_ID) REFERENCES JOB ON DELETE CASCADE ON UPDATE CASCADE I basically want to do this: ""delete from person where person_id=0"" and have it delete everything from PERSON JOB_PERSON and JOB if the JOB entity will be orphaned (no longer referenced in the many to many table) Is this possible without querying the database? When I delete it only deletes from PERSON and JOB_PERSON. As you can probably tell my sql skills are lacking. Here is the dummy data I have been playing around with: insert into person values(null'Arthur'); insert into person values(null'James'); insert into job values(null 'Programmer') insert into job values(null 'Manager') insert into job_person values(00); insert into job_person values(01); insert into job_person values(11); So if I enter both of these statements: delete from person where person_id=0 delete from person where person_id=1 I would like to have everything in all 3 tables deleted. Possible? Create a Store Procedure where you pass the ID then simply DELETE the proper row in the order you need to. This way your app isn't tied to the exact order which might change in the future with DB redesigns. You also gain the added bonus that Stored Procs are faster then sending a bunch of queries. Although if you absolutely wanted a way to delete the dependent tables when you try to delete that entry you have to use triggers but the rule for triggers are avoid them whenever possible if another solution exists use it. So ultimately using a Stored Proc is the best solution."
346,A,Can I use multiple statements in a JDBC prepared query? I'd like to execute something like this on my MySQL server: SET @id=(SELECT id FROM lookupTable WHERE field=?); (SELECT * FROM table2 WHERE id=@id) UNION (SELECT * FROM table3 WHERE id=@id) UNION (SELECT * FROM table4 WHERE id=@id); This works fine from the console but not from my Java PreparedStatement. It throws an exception with a syntax error at the ';' separating the statements. I like the variable because I don't have to repeat the lookup clause but I could rewrite it if necessary. The equivalent JOIN is a little awkward with the UNION clauses too. Thanks Joshua As @ddimitrov says this doesn't seem possible directly. I didn't try `PreparedStatement.addBatch()`. A stored procedure would likely work for this too. If you're interested in other vendors then CUBRID Database supports this feature. See this forum post http://www.cubrid.org/forum/534638. JDBC has never supported parsing delimited queries. Each invocation is one trip to the database. Perhaps you can achieve what you meant to doing PreparedStatement.addBatch() for each separate query then executing and retrieving the two resultsets ?  Just running this as two separate queries (within one connection) should give you same results. I was hoping to avoid the network time twice but it seems unavoidable here. Maybe this is a security feature to avoid SQL injection. @Joshua you can batch queries to the server and avoid the multiple network trips.
347,A,"Overhead with Microsoft JDBC driver when executing a stored procedure I am using Microsoft JDBC Driver 2.0 with SQL Server 2005. To explain my question better let me start with a sample code to call a stored procedure. public static void executeSproc(Connection con) { CallableStatement cstmt = con.prepareCall(""{call dbo.getEmployeeManagers(?)}""); cstmt.setInt(1 50); ResultSet rs = cstmt.executeQuery(); while (rs.next()) { // print results in the result set } rs.close(); cstmt.close(); } Using SQL Profiler I see that the JDBC driver generates the following sql statements to make the call - declare @P1 int set @P1=1 exec sp_prepexec @P1 output N'@P0 int' N'EXEC getEmployeeManagers @P0' 50 select @P1 So this means when I execute a stored procedure using a CallableStatement the sp_prepexec statement is called. And later when I close the statement the sp_unprepare is called. This seems to be the default behavior of the JDBC driver. The problem is the overhead to generate a prepared statement and then close it has performance impact. Is there a way for the driver to execute the stored procedure directly? Why can't the driver just do this - exec getEmployeeManagers @P0=50 Try using the jTDS driver for SQLServer. I use it at work and it seems to be a lot better than the driver provided by MS. Thanks! I tried jTDS and it works beautifully."
348,A,"Execute SQL on CSV files via JDBC I need to apply an SQL query to CSV files (comma-separated text files). My SQL is predefined from another tool and is not eligible to change. It may contain embedded selects and table aliases in the FROM part. For my task I have found two open-source (this is a project requirement) libraries that provide JDBC drivers: CsvJdbc XlSQL JBoss Teiid Create an Apache Derby DB load all CSVs as tables and execute the query. These are the problems I encountered: it does not accept the syntax of the SQL (it uses internal selects and table aliases). Furthermore it has not been maintained since 2004. I could not get it to work as it has as dependency a SAX Parser that causes exception when parsing other documents. Similarly no change since 2004. Have not checked if it supports the syntax but seems like an overhead. It needs several entities defines (Virtual Databases Bindings). From the mailing list they told me that last release supports runtime creation of required objects. Has anyone used it for such simple task (normally it can connect to several types of data like CSV XML or other DBS and create a virtual unified one)? Can this even be done easily? From the 4 things I considered/tried only 3 and 4 seem to me viable. Any advice on these or any other way in which I can query my CSV files? Cheers If your SQL is predefined and cannot be changed your best option is to load your CSV into a database and run queries against it. Apache Derby is a viable option so are MySQL which even has a CSV storage engine or PostgreSQL. Does your SQL use any proprietary functions / extensions? If so that may limit your choices. Yes it uses substring and concatenations.  maybe a bit late sorry for that. I've been developing the csvjdbc for over a year now and since a few weeks I've got ""administrator"" rights on that project so I've been able to release the most recent version I had produced. it does all ""we"" need (we: me and my current my colleagues) need and I'm adding things as bugs are filed. have a look at it now and decide again. (the web documentation still needs reviewing for better insight check the test cases which are very extensive). embedded selects? table aliases? no not yet available there. but then again feel free to file a bug report with a non working query and who knows...  There is a Groovy script gcsvsql that lets you treat csv files as database tables including joins. With gcsvsql you can do things like: gcsvsql ""select * from people.csv where age > 40"" gcsvsql ""select people.namechildren.child from people.csvchildren.csv where people.name=children.name"" gcsvsql ""select avg(score) from people.csv where age < 40"" You can find this script which is based on the h2 database engine at Google code here: http://code.google.com/p/gcsvsql/  I'd say embedded db. I'd suggest either Javadb (Derby built into the Java API) or H2 if you don't care about pulling the extra dependency.  I would load the data into HSQL (HypersonicSQL). Pure Java correct SQL well-proven. Pretty much anything else has a bigger footprint. In fact HSQLDB is the only suggested solution that can open an existing CSV file as an SQL table. It allows both performing SQL queries directly on the CSV file and updating the records. http://hsqldb.org/doc/guide/ch06.html contains further details Hi @Vladimir what if csv file I want to process is very large in terms of 5 to 10 GB?? I did not try files that big with HSQL but the documentation says the largest one is 8 TB (T not G). You need to use CREATE CACHED TABLE to not keep the data in memory. http://hsqldb.org/web/hsqlFAQ.html#FAQ  If you are wanting to treat csv files as databases from within a Java program you should look at the h2 database engine. It has really nice support for reading/writing CSV files and working with in-memory databases. It's a successor to hsql faster and with added features. You can read about the csv support in the h2 tutorial. You can read how easy this is to do using h2 in a Groovy script in this blog post: http://bayesianconspiracy.blogspot.com/2010/02/executing-arbitrary-sql-on-csv-files.html"
349,A,"How to get all table names from a database? I'd like to retrieve all table names from a database schema and if possible get all table starting with a specified prefix. I tried using JDBC's connection.getMetaData().getTables() but it didn't work at all. Connection jdbcConnection = DriverManager.getConnection("""" """" """"); DatabaseMetaData m = jdbcConnection.getMetaData(); ResultSet tables = m.getTables(jdbcConnection.getCatalog() null ""TAB_%"" null); for (int i = 0; i < tables.getMetaData().getColumnCount(); i++) { System.out.println(""table = "" + tables.getMetaData().getTableName(i)); } Could someone help me on this?  public void getDatabaseMetaData() { try { DatabaseMetaData dbmd = conn.getMetaData(); String[] types = {""TABLE""}; ResultSet rs = dbmd.getTables(null null ""%"" types); while (rs.next()) { System.out.println(rs.getString(""TABLE_NAME"")); } } catch (SQLException e) { e.printStackTrace(); } }  If you want to use a high-level API that hides a lot of the JDBC complexity around database schema metadata take a look at this article: http://www.devx.com/Java/Article/32443/1954  In your example problem is passed table name pattern in getTables function of DatabaseMetaData. Some database supports Uppercase identifier some support lower case identifiers. For example oracle fetches the table name in upper case while postgreSQL fetch it in lower case. DatabaseMetaDeta provides a method to determine how the database stores identifiers can be mixed case uppercase lowercase see:http://docs.oracle.com/javase/7/docs/api/java/sql/DatabaseMetaData.html#storesMixedCaseIdentifiers() From below example you can get all tables and view of providing table name pattern if you want only tables then remove ""VIEW"" from TYPES array. public class DBUtility { private static final String[] TYPES = {""TABLE"" ""VIEW""}; public static void getTableMetadata(Connection jdbcConnection String tableNamePattern String schema String catalog boolean isQuoted) throws HibernateException { try { DatabaseMetaData meta = jdbcConnection.getMetaData(); ResultSet rs = null; try { if ( (isQuoted && meta.storesMixedCaseQuotedIdentifiers())) { rs = meta.getTables(catalog schema tableNamePattern TYPES); } else if ( (isQuoted && meta.storesUpperCaseQuotedIdentifiers()) || (!isQuoted && meta.storesUpperCaseIdentifiers() )) { rs = meta.getTables( StringHelper.toUpperCase(catalog) StringHelper.toUpperCase(schema) StringHelper.toUpperCase(tableNamePattern) TYPES ); } else if ( (isQuoted && meta.storesLowerCaseQuotedIdentifiers()) || (!isQuoted && meta.storesLowerCaseIdentifiers() )) { rs = meta.getTables( StringHelper.toLowerCase( catalog ) StringHelper.toLowerCase(schema) StringHelper.toLowerCase(tableNamePattern) TYPES ); } else { rs = meta.getTables(catalog schema tableNamePattern TYPES); } while ( rs.next() ) { String tableName = rs.getString(""TABLE_NAME""); System.out.println(""table = "" + tableName); } } finally { if (rs!=null) rs.close(); } } catch (SQLException sqlException) { // TODO sqlException.printStackTrace(); } } public static void main(String[] args) { Connection jdbcConnection; try { jdbcConnection = DriverManager.getConnection("""" """" """"); getTableMetadata(jdbcConnection ""tbl%"" null null false); } catch (SQLException e) { // TODO Auto-generated catch block e.printStackTrace(); } } }  You need to iterate over your ResultSet calling next(). This is an example from java2s.com: DatabaseMetaData md = conn.getMetaData(); ResultSet rs = md.getTables(null null ""%"" null); while (rs.next()) { System.out.println(rs.getString(3)); } Column 3 is the TABLE_NAME (see documentation of getTables). Thanks ! you made my day :) If this fails for you (like it did me) you need to make sure the database user can actually show tables on the database.  I believe using sp_tables for mssql will work http://msdn.microsoft.com/en-us/library/ms186250.aspx or show tables; for mysql http://dev.mysql.com/doc/refman/5.0/en/show-tables.html If I misundrerstand the question please tell me and I will delete post."
350,A,"Java sql transactions. What am I doing wrong? I have written the small test with sole purpose to better understand transactions in jdbc. And though I did all according to the documentation the test does not wish to work normally. Here is table structure: CREATE TABLE `default_values` ( `id` INT UNSIGNED NOT auto_increment `is_default` BOOL DEFAULT false PRIMARY KEY(`id`) ); Test contains 3 classes: public class DefaultDeleter implements Runnable { public synchronized void deleteDefault() throws SQLException { Connection conn = null; Statement deleteStmt = null; Statement selectStmt = null; PreparedStatement updateStmt = null; ResultSet selectSet = null; try { conn = DriverManager.getConnection(""jdbc:mysql://localhost/xtest"" ""root"" """"); conn.setAutoCommit(false); conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE); // Deleting current default entry deleteStmt = conn.createStatement(); deleteStmt.executeUpdate(""DELETE FROM `default_values` WHERE `is_default` = true""); // Selecting first non default entry selectStmt = conn.createStatement(); selectSet = selectStmt.executeQuery(""SELECT `id` FROM `default_values` ORDER BY `id` LIMIT 1""); if (selectSet.next()) { int id = selectSet.getInt(""id""); // Updating found entry to set it default updateStmt = conn.prepareStatement(""UPDATE `default_values` SET `is_default` = true WHERE `id` = ?""); updateStmt.setInt(1 id); if (updateStmt.executeUpdate() == 0) { System.err.println(""Failed to set new default value.""); System.exit(-1); } } else { System.err.println(""Ooops! I've deleted them all.""); System.exit(-1); } conn.commit(); conn.setAutoCommit(true); } catch (SQLException e) { try { conn.rollback(); } catch (SQLException ex) { ex.printStackTrace(); } throw e; } finally { try { selectSet.close(); } catch (Exception e) {} try { deleteStmt.close(); } catch (Exception e) {} try { selectStmt.close(); } catch (Exception e) {} try { updateStmt.close(); } catch (Exception e) {} try { conn.close(); } catch (Exception e) {} } } public void run() { while (true) { try { deleteDefault(); } catch (SQLException e) { e.printStackTrace(); System.exit(-1); } try { Thread.sleep(20); } catch (InterruptedException e) {} } } } public class DefaultReader implements Runnable { public synchronized void readDefault() throws SQLException { Connection conn = null; Statement stmt = null; ResultSet rset = null; try { conn = DriverManager.getConnection(""jdbc:mysql://localhost/xtest"" ""root"" """"); conn.setAutoCommit(false); conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE); stmt = conn.createStatement(); rset = stmt.executeQuery(""SELECT * FROM `default_values` WHERE `is_default` = true""); int count = 0; while (rset.next()) { count++; } if (count == 0) { System.err.println(""Default entry not found. Fail.""); System.exit(-1); } else if (count > 1) { System.err.println(""Count is "" + count + ""! Wtf?!""); } conn.commit(); conn.setAutoCommit(true); } catch (SQLException e) { try { conn.rollback(); } catch (Exception ex) { ex.printStackTrace(); } throw e; } finally { try { rset.close(); } catch (Exception e) {} try { stmt.close(); } catch (Exception e) {} try { conn.close(); } catch (Exception e) {} } } public void run() { while (true) { try { readDefault(); } catch (SQLException e) { e.printStackTrace(); System.exit(-1); } try { Thread.sleep(20); } catch (InterruptedException e) {} } } } public class Main { public static void main(String[] args) { try { Driver driver = (Driver) Class.forName(""com.mysql.jdbc.Driver"") .newInstance(); DriverManager.registerDriver(driver); Connection conn = null; try { conn = DriverManager.getConnection(""jdbc:mysql://localhost/xtest"" ""root"" """"); System.out.println(""Is transaction isolation supported by driver? "" + (conn.getMetaData() .supportsTransactionIsolationLevel( Connection.TRANSACTION_SERIALIZABLE) ? ""yes"" : ""no"")); } finally { try { conn.close(); } catch (Exception e) {} } (new Thread(new DefaultReader())).start(); (new Thread(new DefaultDeleter())).start(); System.in.read(); System.exit(0); } catch (Exception e) { e.printStackTrace(); } } } I have written script which fills table with 100k records (where one of them is default) for each run. But every time I run this test output is: Is transaction isolation supported by driver? yes Default entry not found. Fail. What's wrong with this code? I see some of the answers are starting to talk about declarative transactions and using Spring (I do like Spring) but they will just confuse the situation. This problem is solvable and you'll get a better understanding working with raw JDBC something that will be obscured if you start wrapping it in higher-level frameworks (such as JEE or Spring). I would suggest in the long term NOT doing raw JDBC unless you are in a really constrained environment. It's error-prone and a PITA. Why do you assume the DefaultReader should succeed ? Just because the thread is started before the deleter doesn't mean it will actually run before the deletion occurs? Keep in mind that MyISAM tables does not support transactions InnoDB tables does. SERIALIZABLE isolation level might fail it's common for dbs to fail transactions if there's 2 concurrent SERIALIZABLE transactions going on. If you allow the container to manage transactions you can do something like: @Resource private UserTransaction utx; and then just use it in your code: utx.begin(); // atomic operation in here utx.commit(); Then you don't need to worry about the intricacies of transaction management. Edit: @Gris: Yes you're correct on that. I had assumed you were developing a web app. as pjp said spring is a nice alternative in this case. Or -- depending on the size and complexity of the application -- you could get by with managing your own transactions. But if I correctly understand it's only usable if application runs inside j2ee container. But my goal is standalone j2se application not a webapp. As an alternative to fully blown j2ee you could use Spring which implements a DataSource TransactionManager. 2 pjp: You may be right. I'll look documentation but I do not sure that using such framework will be acceptable from other points.  There's a couple of points worth mentioning: Does your script to populate the database before the test really work? Try doing a select count(*) ... on the table from inside Java code to check (this might sound dumb but I've made this mistake before). Don't do System.exit() all over the place as it will make the code hard to test - it might be interesting to see what the deleter does even though it appears you have no default==true record.  The answer is simple: You create two threads. They run completely independent of each other. Since you don't synchronize them in any way there is no way to tell which one gets to the database first. If the reader is the first one the deleter won't have begun yet and there won't be an item with is_default == true since the deleter didn't get that far yet. Next you have completely isolated the two transactions (Connection.TRANSACTION_SERIALIZABLE). This means that even if the deleter has a chance to update the database the reader will only see it after it has closed its connection and opened a new one. And if that wasn't the case the deleter is slower than the reader so the chances that a record would have be updated with is_default == true at the time when the reader looks for it are slim. [EDIT] Now you say that there should be a single item with is_default == true when the tests starts. Please add a test to make sure that this is really the case before you start the two threads. Otherwise you might be hunting the wrong bug. About threads - this is one of the requirements. Test works as solid application but final app may consist of the several processes working completely independent. About transactions - as I understand completely isolated transaction should provide atomicity of enclosed operations so all operations inside processed as one solid operation (DELETE SELECT UPDATE in my case). Am I wrong? I using script which clears and fills table before each run. I've checked start conditions manually as well.  I suggest that you add some breakpoints and step through each of your database operations to check that they are doing what you expect. You can open a session onto your database server and set the transaction isolation level so that you can read uncommitted data. Also check that the use of 'true' is valid in MySql over the numeric value 1 for the boolean type. All operations by itself goes right. Using of 'true' is fine too (it's used not as text (in brackets) but as a built-in constant). I've checked all queries by myself from MySQL console first.  Please make sure you're creating InnoDB tables MyISAM (the default) doesn't support transactions. You can change your db create to this: CREATE TABLE `default_values` ( `id` INT UNSIGNED NOT auto_increment `is_default` BOOL DEFAULT false PRIMARY KEY(`id`) ) Engine=InnoDB; another example: http://stackoverflow.com/questions/292706/mysql-transaction-with-accounting-application I appreciate all the comments above are helping you - but I'd suggest you start with ensuring you're using a table which is transaction compliant - then Aaron Digulla's point comes up: which thread is hitting the db first. Once you're using transactional tables you can put a sleep in the writer thread (write 100 rows at a time type thing) then ensure the delete kicks off mid transaction of the writer thread. You should see transactions doing what they do at that point. Good point. I'll check this. It's seems that I've realy did such a noobish mistake. After changing engine to InnoDB application seems work well. Thank you."
351,A,"PreparedStatement is executed on prepareStatement on SQL Server We have a Java code similar to the following: PreparedStatement stmt = connection.prepareStatement(""drop login tmp""); int result = stmt.executeUpdate(); When running through a debugger it seems that our SQL statement is executed after the first line is executed and even before the second line is executed. When the second line is executed the drop SQL is executed again and is causing an error as the username tmp no longer exist. This only happens against SQL Server but not against Oracle and Postgres with similar drop SQL queries. Is this a known problem? Is there a common workaround other than moving to Statement instead of PreparedStatement? Well your statement doesn't include any variables so there really isn't anything to ""prepare."" Have you tried using just a Statement? I agree that drop is not a good candidate for prepared statement and indeed we switched to statement and the problem is solved. However this is a library code and we might need to use it for different queries so I wanted to find the root of the problem. I think your best bet is to run SQL Server Profiler against a test database and see what's really hitting the server when this code runs. With C# prepared statements you see something like declare @p1 int set @p1=-1 exec sp_prepexec @p1 output N'@param varchar(100)' ... select @p1 Java or your SQL client library might use a different technique. Having said that prepared statements are only designed to cache and parameterize repeated similar statements that are parameterizable. The idea is to save recompiling the SQL statement. If you aren't issuing many repeated similar statements then prepared statements aren't working in your favor and caching the SQL isn't useful. Personally I can't imagine using 'drop login' so much that caching would be helpful. On top of that I don't think the DROP LOGIN statement can take a parameter in T-SQL. I agree that drop is not a good candidate for prepared statement and indeed we switched to statement and the problem is solved. However this is a library code and we might need to use it for different queries so I wanted to find the root of the problem.  When you create a PreparedStatement the query is sent to the server to precompile it (Source). At a guess SQLServer sees that there are no placeholders and just executes the query instead. Judging from the comments you already know that the fix is to create a Statement instead."
352,A,"What is Type 4 XA driver? In our application when we create the Datasource we select the Database Name DB2 Driver: BEA Type 4 XA DB2 But what i know is there are only 4 types of Driver. Then what is Type 4 XA driver? Type 4: All Native Java XA: stands for Extensible Architecture which is refered mostly for a 2-phase-commit protocol - see wikipedia. Short: A standard protocol for a global transaction between one transaction coordinator and several transaction managers. Sometimes they are also called transaction monitors. It's pretty slow so should avoid it if you don't really need it. But well at our customer we mostly need it :(  Major advantage of XA is that it can access multiple databases in one connection/transaction.  From this blog entry. An XA transaction in the most general terms is a ""global transaction"" that may span multiple resources. That is a transaction running across (say) 2 databases. So for example insertions can be managed across those 2 databases and committed/rolled back atomically. The ""type 4"" refers to a native Java JDBC driver converting directly into the database protocol. See here for more details Thanks :) +1 and accepted Good explanation on theserverside.com: http://www.theserverside.com/discussions/thread.tss?thread_id=21385#95346"
353,A,"Java: ResultSet exception - before start of result set I'm having trouble getting data from a ResultSet object. Here is my code:  String sql = ""SELECT type FROM node WHERE nid = ?""; PreparedStatement prep = conn.prepareStatement(sql); int meetNID = Integer.parseInt(node.get(BoutField.field_meet_nid)); prep.setInt(1 meetNID); ResultSet result = prep.executeQuery(); result.beforeFirst(); String foundType = result.getString(1); if (! foundType.equals(""meet"")) { throw new IllegalArgumentException(String.format(""Node %d must be of type 'meet' but was %s"" meetNID foundType)); } The error trace: Exception in thread ""main"" java.sql.SQLException: Before start of result set at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1072) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:986) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:981) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:926) at com.mysql.jdbc.ResultSetImpl.checkRowPos(ResultSetImpl.java:841) at com.mysql.jdbc.ResultSetImpl.getStringInternal(ResultSetImpl.java:5656) at com.mysql.jdbc.ResultSetImpl.getString(ResultSetImpl.java:5576) at nth.cumf3.nodeImport.Validator.validate(Validator.java:43) at nth.cumf3.nodeImport.Main.main(Main.java:38) What am I doing wrong here? You have to call next() before you can start reading values from the first row. beforeFirst puts the cursor before the first row so there's no data to read.  You have to do a result.next() before you can access the result. It's a very common idiom to do ResultSet rs = stmt.executeQuery(); while (rs.next()) { int foo = rs.getInt(1); ... }  You need to move the pointer to the first row before asking for data: result.beforeFirst(); result.next(); String foundType = result.getString(1);  It's better if you create a class that has all the query methods inclusively in a different package so instead of typing all the process in every class you just call the method from that class.  Every answer uses .next() or uses .beforeFirst() and then .next(). But why not this: result.first(); So You just set the pointer to the first record and go from there. It's available since java 1.2 and I just wanted to mention this for anyone whose ResultSet exists of one specific record.  Basically you are positioning the cursor before the first row and then requesting data. You need to move the cursor to the first row.  result.next(); String foundType = result.getString(1); It is common to do this in an if statement or loop. if(result.next()){ foundType = result.getString(1); } Good answer! I lose daily limit for +1 sorry..."
354,A,"Is MySQL Connector/JDBC thread safe? Is the standard MySQL JDBC driver thread-safe? Specifically I want to use a single connection across all threads but each statement will only be used in a single thread. Are there certain scenarios that are safe and others that aren't? What's your experience here? ""..While you _can_ share a connection across threads (especially if each thread has its own Statement) it's usually not a good idea. The JDBC API is not really designed to be used in a thread-safe way and most JDBC connections (including MySQL's) can only process a single query at a time.."" http://forums.mysql.com/read.php?39171022171195#msg-171195 @Tim Yes I saw the post earlier. It doesn't go into details about any possible problems though so I felt that it would be interesting to hear about other peoples experiences. Also I felt that it's a valid question that belonged in the stack overflow question database. Feel free to post that link as an answer. :) Consider using a connection pool instead. If autocommit = 1 then it is very feasible to have multiple threads share the same connection provided the access to the connection is synchronized. If autocommit = 0 you will have to control access to the connection via some sort of mutex until the commit happens. Unless you absolutely are limited in the amount of connections your application can have a connection pool may be a more viable alternative.  I think the JDBC spec explains it perfectly. It's a two year old posting. Let me Google that for you....wait it worked for me. You're doing something wrong. wtf! works in chrome but not in firefox 7.0.1! oracle is doing something wrong :) http://img829.imageshack.us/img829/710/notfound.jpg thanks anyway broken link....  Transactions are started / committed per connection. Unless you're doing some very specific stuff (I can't really think of an example where that would be justified to be honest) you're better off with a connection pool and connection per thread. I wonder if there may be a possible use case where you wanted to do some kind of fork/join algorithm (c.f. http://www.ibm.com/developerworks/java/library/j-jtp11137.html) but entirely within one transaction so you might open a connection and start a transaction in the originating thread pass this to all the task executors and then commit in the originating thread after all joining has finished? Example: streaming data insertion using `load data local infile` into more than one table where the data has mutual relations and cannot be cheaply iterated over twice."
355,A,"JDBC built in functions and prepared statements Is there a way to execute a query(containing built in DB function) using PreparedStatement? Example: insert into foo (location) values (pointfromtext('12.56666 13.67777'4130)) Here pointfromtext is a built in function. The question marks are not being evaluated correctly because they are between simple quotes. Remove them and it should work  The scope of a PreparedStatement object is exactly to execute queries. If the query contains built in DB function is ok and everything should work if the same query works outside the PreparedStatement. As Thilo said test your query form SQL command line or with the SQL graphical tool that you usually use.  By what I've seen the first parameter on pointfromtext function is a string and the second a number. So try the following: PreparedStatement preparedStatement = getConnection().prepareStatement(""insert into map_address (location) values(pointfromtext('POINT(' || ? || ' ' || ? || ')'4130))""); preparedStatement.setString(1 ""12.56565665""); preparedStatement.setString(2 ""12.57565757""); preparedStatement.executeUpdate(); Is String concatenation the only way out? Is there no way I can tell JDBC to escape the quotes and let it know that ? is to be substituted with a parameter? You can also bind a single string ""POINT(12.5612.57)"" into it. And maybe there is an alternative to pointfromtext something like pointfrom_xy which can take two numbers directly.  Did you put connection.commit() after this code? The code should be:  PreparedStatement bar = connection.prepareStatement(""insert into foo (location) values (pointfromtext('? ?'4130)))""); bar.setDouble(1 13.67777); bar.setDouble(2 13.67777); bar.executeUpdate(); connection.commit();  Did you try to don't set doubles in the preparaedStatement? Just for testing you should try to insert this parameters directly in the String something like: String sql = ""insert into map_address (location) values(pointfromtext('POINT("" + ""12.56565665"" + "" "" + ""12.57565757"" + "")'4130))"" PreparedStatement preparedStatement = getConnection().prepareStatement(sql); and then try to execute the update.  Sure that should work. If not what is your database system and can you run the exact same command from the SQL command line?  Perhaps you've found a problem with the Postgresql JDBC driver rather than with JDBC per se. In general what you want to achieve works with JDBC."
356,A,"JDBC MySql Connection Pooling practices I have a Java-JSF Web Application on GlassFish in which I want to use connection pooling. Therefore I created an application scoped bean that serves with Connection instances for other beans: import java.sql.Connection; import java.sql.SQLException; import javax.sql.DataSource; import javax.naming.Context; import javax.naming.InitialContext; import javax.naming.NamingException; public class DatabaseBean { private DataSource myDataSource; public DatabaseBean() { try { Context ctx = new InitialContext(); ecwinsDataSource = (DataSource) ctx.lookup(""jdbc/myDataSource""); } catch (NamingException ex) { ex.printStackTrace(); } } public Connection getConnection() throws ClassNotFoundException SQLException InstantiationException IllegalAccessException { Connection connection = myDataSource.getConnection(); System.out.println(""Succesfully connected: "" + connection); //Sample: Succesfully connected: com.sun.gjc.spi.jdbc40.ConnectionHolder40@7fb213a5 return connection; } } This way the connection pool gets filled very fast; after a few navigation through 'db-related' views the application stops with the following:  RAR5117 : Failed to obtain/create connection from connection pool [ mysql_testPool ]. Reason : In-use connections equal max-pool-size and expired max-wait-time. Cannot allocate more connections. RAR5114 : Error allocating connection : [Error in allocating a connection. Cause: In-use connections equal max-pool-size and expired max-wait-time. Cannot allocate more connections.] java.sql.SQLException: Error in allocating a connection. Cause: In-use connections equal max-pool-size and expired max-wait-time. Cannot allocate more connections. at com.sun.gjc.spi.base.DataSource.getConnection(DataSource.java:115) at beans.DatabaseBean.getConnection(DatabaseBean.java:24) I'm closing connections and other resources in every method. The application runs all OK with standalone connections. What am I doing wrong? Any tips or advice would be appreciated. EDIT I looked into the way I am closing resources and it came out I wasn't very thorough. Now I'm closing them this way: private void close(Connection connection ResultSet rs Statement stmt) { try { if (rs != null) { rs.close(); } } catch (Exception ex) { } finally { try { if (stmt != null) { stmt.close(); } } catch (Exception ex) { } finally { try { if (connection != null) { connection.close(); } } catch (Exception ex) { } } } } I don't get the error anymore! YAY thanks!:) The exception indicates a typical case of application code which leaks database connections. You need to ensure that you acquire and close all of them (Connection Statement and ResultSet) in a try/finally block in the very same method block according the normal JDBC idiom: public void create(Entity entity) throws SQLException { Connection connection = null; PreparedStatement statement = null; try { connection = database.getConnection(); statement = connection.prepareStatement(SQL_CREATE); statement.setSomeObject(1 entity.getSomeProperty()); // ... statement.executeUpdate(); } finally { if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } } Yes you still need to close connections yourself even when using connection pooling. It's a common mistake among starters that they think that it will then automatically handle the close. This is not true. The connection pool namely returns a wrapped connection which does something like the following in the close(): public void close() throws SQLException { if (this.connection is still eligible for reuse) { do not close this.connection but just return it to pool for reuse; } else { actually invoke this.connection.close(); } } Not closing them would cause the connection not being released back to the pool for reuse and thus it will acquire a new one again and again until the DB runs out of connections which will cause your application to crash. Also see this basic JDBC/DAO tutorial for more hints how to get started with JDBC (in webapplications) the proper way. Update: you don't necessarly need to nest them that deep in their own finally blocks. The following is also just fine: public static void closeQuietly(Connection connection Statement statement ResultSet resultSet) { if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } which can be used as } finally { closeQuietly(connection statement resultSet); } Thank you for your thorough answer it was really helpful! I edited my comment with the app-modifications. Thanks for the great info again!  If you need JDBC connection pooling why don't you rely on what's available already? AFAIK JDBC connection pooling is considered more or less a standard feature in these java application servers and IMO you should not want to build this yourself if you're just interested in creating an application. Here's a link that should get you started: http://weblogs.java.net/blog/2007/09/12/totd-9-using-jdbc-connection-pooljndi-name-glassfish-rails-application What you probably should be doing is find out how to let your application grab a connection from the pool using jndi. He's already doing that? He has already configured a connection pooled datasource in the appserver. He's only not closing resources properly as per the exception. oh crap you're right. thanks BalusC."
357,A,statements in jdbc does statement object contain the session id the database returns for the current session? What does a resultset contain? Can you clarify what you mean by a session in the context of JDBC? To the best of my knowledge no Statements do not have session IDs. It seems like the Java API specifications for the Statement class backs that up. Basically Statements are used to execute SQL statements by specifying a SQL query through the execute method. A ResultSet is used to retrieve results which are returned by executing a query via a Statement or PreparedStatement. The JDBC(TM) Database Access trail of The Java Tutorials contains some information on these topics. The following sections may be of interest: Lesson: JDBC Basics Updating Tables Retrieving Values from Result Sets
358,A,"Java - retrieving large amounts of data from a DB using iBatis I need to extract data from a DB2 table run some processing on each returned row and output to a flat file. I'm using iBatis but found that using the queryForList I started getting out of memory errors I'll be looking at 100k+ rows of data increasing. I've looked at using queryWithRowHandler instead but the iBatis RowHandler interface doesn't throw an exception from its handleRow function so if it gets an error I can't properly report it back and stop iterating the rest of the data. It looks like I can throw a RuntimeException but that doesn't strike me as a neat way of doing things. I'd like to be able to stop processing while throwing a meaningful Exception indicating whether the error occurred on the data manipulation the file access or whatever. Has anyone had experience with this approach or have an alternative solution using iBatis. I know I could look to do this without iBatis just using JDBC but as iBatis is used for all other DB access in my app I'd like to avail of this architecture if possible. 1) Create your own RowHandler interface with checked Exceptions in signature: public interface MySpecialRowHandler { public void handleRow(Object row) throws DataException FileException WhateverException; } 2) Inherit (or even better delegate ) from SqlMapDaoTemplate to add a new method that will manage your own handler with the same Exceptions in signature: public class MySpecialTemplate extends SqlMapDaoTemplate { ... public void queryWithRowHandler(String id final MySpecialRowHandler myRowHandler ) throws DataException FileException WhateverException { // ""holder"" will hold the exception thrown by your special rowHandler // both ""holder"" and ""myRowHandler"" need to be declared as ""final"" final Set<Exception> holder = new HashSet<Exception>(); this.queryWithRowHandler(idnew RowHandler() { public void handleRow(Object row) { try { // your own row handler is executed in IBatis row handler myRowHandler.handleRow(row); } catch (Exception e) { holder.add(e); } } }); // if an exception was thrown rethrow it. if (!holder.isEmpty()) { Exception e = holder.iterator().next(); if (e instanceof DataException) throw (DataException)e; if (e instanceof FileException) throw (FileException)e; if (e instanceof WhateverException) throw (WhateverException)e; // You'll need this in case none of the above works throw (RuntimeException)e; } } } 3) Your business code will look like this: // create your rowHandler public class Db2RowHandler implements MySpecialRowHandler { void handleRow(Object row) throws DataException FileException WhateverException { // what you would have done in ibatis RowHandler with your own exceptions } } // use it. MySpecialTemplate template = new MySpecialTemplate(daoManager); try { template.queryWithRowHandler(""selectAllDb2"" new Db2RowHandler()); } catch (DataException e) { // ... } catch (FileException e) { ..."
359,A,"How to store the data in a object array which is collected from the Database Possible Duplicate: how to store the data in a object array which collected from data base? The Below code will retrieve data from the database. i want to store the data in a pojo object. It will be appreciative if anyone demonstrate with the code or dont hesitate to edit my code. I want to know about the creation and implementation of POJO objects. Actually what is meant by POJO object. Jdbc object=new Jdbc(); is this a pojo object. If so means how to declare a object array and how to use it to store array variables. import java.*; import java.io.BufferedReader; import java.io.InputStreamReader; import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.Statement; public class Jdbc { static int id[] = new int[10]; static String name[] = new String[10]; static int salary[] = new int[10]; public static void main(String arg[]) { try { Statement stmt; ResultSet rs; Class.forName(""com.mysql.jdbc.Driver""); String url =""jdbc:mysql://localhost:3306/dwr""; Connection con = DriverManager.getConnection(url""root"" ""1234""); System.out.println(""URL: "" + url); System.out.println(""Connection: "" + con); stmt = con.createStatement(); System.out.println(""Enter EmpId:""); BufferedReader br=new BufferedReader(new InputStreamReader(System.in)); int empId=Integer.parseInt(br.readLine()); System.out.println(""Enter Name:""); BufferedReader br1=new BufferedReader(new InputStreamReader(System.in)); String name1=br1.readLine(); System.out.println(""Enter Salary:""); BufferedReader br2=new BufferedReader(new InputStreamReader(System.in)); int salary1=Integer.parseInt(br2.readLine()); stmt.executeUpdate(""INSERT INTO employee set EmpId='""+empId+""' Name='""+name1+""' salary='""+salary1+""';""); stmt = con.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVEResultSet.CONCUR_READ_ONLY); rs = stmt.executeQuery(""SELECT * "" + ""from employee ORDER BY EmpId""); System.out.println(""Display all results:""); int i = 0; while(rs.next()){ id[i]= rs.getInt(""Empid""); name[i]= rs.getString(""Name""); salary[i]= rs.getInt(""Salary""); System.out.println(""\n EmpId "" + id[i]+ ""\n name "" + name[i] + ""\n salary "" + salary[i]); } }catch( Exception e ) { e.printStackTrace(); } Jdbc pojo = new Jdbc(); } } @McDowell Yes we didnt get the exact solution. Can u Solve it @Gladiator @Tamil Vendhan: You should clarify your original question accordingly. Is this homework or so? Gladiator has an identical question. Lol... We are friends man... Ah yes that's funny :) @BalusC: your answer is deleted man. why they are doing this. I thought i was an very valuable answer. I did it myself. @BalusC Why what happened. That was a good answer. I can able to learn more than searching around about it. @BalusC: Hey sorry for the comment ""This is not a good manner"". I dont know that you did it. Whats going on here. Why.... @BalusC: +1 for deleting your answer yourself. How can u able to delete a perfect explanation. @BalusC: Another +1 for editing your comment. @BalusC: One day i will become Super Professional in JAVA. Then i ll start to answer in stackoverflow. I wont expect formal replies. I wont delete my answers for this type of cheap problems. I swear. @BalusC: One last and final comment. ""Lol... We are friends man..."" The ""we"" is not u & me... Its me and Gladiator. Can you belive this A guy deleted his well documented answer jus for a ""LOL"".... What a GREAT LOL... You Rocks man... POJO is Plain Old Java Object. It is a term that was coined when EJBs came into the picture to differentiate between the two (EJBs implemented javax.ejb.*). Here is the wiki link for more on POJO. I think this is what you are wanting to do. First Declare a class called Employee. public class Employee{ private Integer empId; private Integer salary; private String name; //add getters and setters for these 3 members. } Then modify your record retrieval in the following way: if(rs!=null{ List<Employee> empList = new ArrayList<Employee>(); while(rs.next()){ Employee emp = new Employee(); emp.setEmpId(rs.getInt(""Empid"")); emp.setSalary(rs.getInt(""Salary"")); emp.setName(rs.getString(""Name"")); empList.add(emp); } } At the end of the traversal empList will contain all the records that you retrieved and each entry in the list will be of type Employee. Then you can use the getter for them to get each individual element (like salary name id). Hope this helps. Thakns man... After BalusC you gave me a good structural view to understand the structure of getters & setters and i also learned ""how to use getters & setters or how they will be used.... @Hope this helps: Ya you helped me to finish my project. It is web app which displays data from DB add delete & update entries into DB AND this all things happens without page reloading using DWR. Thanks again man...( If you came across the controversy of this question and you felt bad means Forgive me...)"
360,A,"JDBC get/setObject vs. get/setSpecificType JDBC ResultSet offers getObject getInt getString etc. methods and PreparedStatement has analogous setters. Apart from type compile-time type safety do the type specific getters/setters have any (dis)advantages or is it OK to use getObject/setObject everywhere? There are no real technical (dis)advantages. They may only be functionally disadvantageous if you're doing typechecking/casting yourself afterwards. I myself use ResultSet#getObject() only when the returned value is a primitive which is DB-defaulted to NULL and the declared value is a wrapper for the primitive. E.g. Integer age: user.setAge(resultSet.getObject(""age"") != null ? resultSet.getInt(""age"") : null); And I use PreparedStatement#setObject() practically all the time in an utility method: public static void setValues(PreparedStatement preparedStatement Object... values) throws SQLException { for (int i = 0; i < values.length; i++) { preparedStatement.setObject(i + 1 values[i]); } }"
361,A,"How to get hibernate3-maven-plugin hbm2ddl to find JDBC driver? I have a Java project I am building with Maven. I am now trying to get the hibernate3-maven-plugin to run the hbm2ddl tool to generate a schema.sql file I can use to create the database schema from my annotated domain classes. This is a JPA application that uses Hibernate as the provider. In my persistence.xml file I call out the mysql driver: <property name=""hibernate.dialect"" value=""org.hibernate.dialect.MySQLDialect""/> <property name=""hibernate.connection.driver_class"" value=""com.mysql.jdbc.Driver""/> When I run Maven I see it processing all my classes but when it goes to output the schema I get the following error: ERROR org.hibernate.connection.DriverManagerConnectionProvider - JDBC Driver class not found: com.mysql.jdbc.Driver java.lang.ClassNotFoundException: com.mysql.jdbc.Driver I have the MySQL driver as a dependency of this module. However it seems like the hbm2ddl tool cannot find it. I would have guessed that the Maven plugin would have known to search the local Maven file repository for this driver. What gives? The relevant part of my pom.xml is this: <plugin> <groupId>org.codehaus.mojo</groupId> <artifactId>hibernate3-maven-plugin</artifactId> <executions> <execution> <phase>process-classes</phase> <goals> <goal>hbm2ddl</goal> </goals> </execution> </executions> <configuration> <components> <component> <name>hbm2ddl</name> <implementation>jpaconfiguration</implementation> </component> </components> <componentProperties> <persistenceunit>my-unit</persistenceunit> </componentProperties> </configuration> </plugin> I figured it out. You have to add the corresponding JDBC driver as a dependency of the PLUGIN. Adding it as a dependency of the module does nothing. This seems surprising to me and kind of lame actually.  <dependencies> <dependency> <groupId>mysql</groupId> <artifactId>mysql-connector-java</artifactId> <type>jar</type> <version>5.0.8</version> </dependency> </dependencies> A plugin class path is isolated from the project class path and that's not lame at all. It would be **very** annoying if it wasn't (""no you can't use this dependency in your project because it brakes this plugin""). So it makes sense to have to declare them inside the plugin. You are correct of course. Just venting after 4 lost hours of work."
362,A,"Accessing data from servlet I have got a requirement that mysql database can only be accessed from localhost. I have to implement a servlet that would access the database allowing other servers in this system to access data (servlet would work as a proxy). However this system consists of a remote server which downloads large portions of data executing a statement like: select * from database limit 100; Can somebody suggest me how to write a servlet that would stream such data in a efficient way (I am new to databases)? First of all I don't recommend to use a servlet for this. See the answers of aioobe and mdma for the right approach. But if there is really no other option then continue reading: Just write the data to the response immediately as the data comes in. Don't store everything in Java's memory. So basically: writer.write(resultSet.getString(""col"")). Further the MySQL JDBC driver will by default cache everything in Java's memory before giving anything to ResultSet#next(). You'd like to let it give the data immediately row-by-row by setting the Statement#setFetchSize() as per the MySQL JDBC driver documentation. Here's a kickoff example assuming you'd like to output the data in CSV format: protected void doGet(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { response.setContentType(""text/csv""); Connection connection = null; Statement statement = null; ResultSet resultSet = null; PrintWriter writer = response.getWriter(); try { connection = database.getConnection(); statement = connection.createStatement(ResultSet.TYPE_FORWARD_ONLY ResultSet.CONCUR_READ_ONLY); statement.setFetchSize(Integer.MIN_VALUE); resultSet = statement.executeQuery(""SELECT col1 col2 col3 FROM tbl""); while (resultSet.next()) { writer.append(resultSet.getString(""col1"")).append(''); writer.append(resultSet.getString(""col2"")).append(''); writer.append(resultSet.getString(""col3"")).println(); // PS: don't forget to sanitize quotes/commas as per RFC4130. } } catch (SQLException e) { throw new ServletException(""Query failed!"" e); } finally { if (resultSet != null) try { resultSet.close; } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close; } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close; } catch (SQLException logOrIgnore) {} } }  A JDBC proxy would give you what you are looking for out of the box such as Virtual JDBC.  Well if your goal is to completely open up the sql-server for queries by external hosts but for some reason don't want to reconfigure it to accept external connections I would suggest that you simply set up a tunnel for the port which the server listens on. The remote host would connect to your application (running on localhost) which in turn simply connects to the sql-server and relays the stream of data back and forth. This is the simplest solution; using the database's native communication method is likely orders of time faster than running everything through a servlet / http response"
363,A,"JDBC JNDI Problem with tomcat 6.0.26 Greetings I am developing a webapp that requires setting up a DataSource with JNDI using Enterprise JDBC Classes.I am using the Netbeans 6.9 bundled tomcat (6.0.26 app) server with mysql 5.xx.The issue really is that I can still see the database values from a relation being displayed in my jsp page whereas during the tomcat initialization it says something like this: . . SEVERE: Servlet.service() for servlet jsp threw exception java.lang.ClassCastException: org.apache.tomcat.dbcp.dbcp.BasicDataSource cannot be cast to javax.naming.Context at org.apache.jsp.Hello_jsp._jspService(Hello_jsp.java:141) at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:70) at javax.servlet.http.HttpServlet.service(HttpServlet.java:717) at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:374) at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:313) at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:260) at javax.servlet.http.HttpServlet.service(HttpServlet.java:717) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.netbeans.modules.web.monitor.server.MonitorFilter.doFilter(MonitorFilter.java:393) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:298) at org.apache.coyote.http11.Http11AprProcessor.process(Http11AprProcessor.java:859) at org.apache.coyote.http11.Http11AprProtocol$Http11ConnectionHandler.process(Http11AprProtocol.java:579) at org.apache.tomcat.util.net.AprEndpoint$Worker.run(AprEndpoint.java:1555) at java.lang.Thread.run(Thread.java:619) Jul 25 2010 1:28:25 AM org.apache.catalina.core.ApplicationContext log INFO: SessionListener: contextDestroyed() Jul 25 2010 1:28:25 AM org.apache.catalina.core.ApplicationContext log INFO: ContextListener: contextDestroyed() Jul 25 2010 1:28:32 AM org.apache.catalina.core.ApplicationContext log INFO: ContextListener: contextInitialized() Jul 25 2010 1:28:32 AM org.apache.catalina.core.ApplicationContext log INFO: SessionListener: contextInitialized() Jul 25 2010 1:28:40 AM org.apache.catalina.core.StandardWrapperValve invoke SEVERE: Servlet.service() for servlet jsp threw exception javax.naming.NameNotFoundException: Name nexusirm is not bound in this Context at org.apache.naming.NamingContext.lookup(NamingContext.java:770) at org.apache.naming.NamingContext.lookup(NamingContext.java:140) at org.apache.naming.NamingContext.lookup(NamingContext.java:781) at org.apache.naming.NamingContext.lookup(NamingContext.java:140) at org.apache.naming.NamingContext.lookup(NamingContext.java:781) at org.apache.naming.NamingContext.lookup(NamingContext.java:140) at org.apache.naming.NamingContext.lookup(NamingContext.java:781) at org.apache.naming.NamingContext.lookup(NamingContext.java:153) at org.apache.naming.SelectorContext.lookup(SelectorContext.java:152) at javax.naming.InitialContext.lookup(InitialContext.java:392) at org.apache.jsp.Hello_jsp._jspService(Hello_jsp.java:141) at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:70) at javax.servlet.http.HttpServlet.service(HttpServlet.java:717) at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:374) at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:313) at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:260) at javax.servlet.http.HttpServlet.service(HttpServlet.java:717) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.netbeans.modules.web.monitor.server.MonitorFilter.doFilter(MonitorFilter.java:393) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:298) at org.apache.coyote.http11.Http11AprProcessor.process(Http11AprProcessor.java:859) at org.apache.coyote.http11.Http11AprProtocol$Http11ConnectionHandler.process(Http11AprProtocol.java:579) at org.apache.tomcat.util.net.AprEndpoint$Worker.run(AprEndpoint.java:1555) at java.lang.Thread.run(Thread.java:619) Jul 25 2010 1:29:50 AM org.apache.catalina.core.StandardWrapperValve invoke SEVERE: Servlet.service() for servlet jsp threw exception javax.naming.NameNotFoundException: Name jdbc is not bound in this Context at org.apache.naming.NamingContext.lookup(NamingContext.java:770) at org.apache.naming.NamingContext.lookup(NamingContext.java:153) at org.apache.naming.SelectorContext.lookup(SelectorContext.java:152) at javax.naming.InitialContext.lookup(InitialContext.java:392) at org.apache.jsp.Hello_jsp._jspService(Hello_jsp.java:143) at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:70) at javax.servlet.http.HttpServlet.service(HttpServlet.java:717) at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:374) at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:313) at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:260) at javax.servlet.http.HttpServlet.service(HttpServlet.java:717) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.netbeans.modules.web.monitor.server.MonitorFilter.doFilter(MonitorFilter.java:393) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:298) at org.apache.coyote.http11.Http11AprProcessor.process(Http11AprProcessor.java:859) at org.apache.coyote.http11.Http11AprProtocol$Http11ConnectionHandler.process(Http11AprProtocol.java:579) at org.apache.tomcat.util.net.AprEndpoint$Worker.run(AprEndpoint.java:1555) at java.lang.Thread.run(Thread.java:619) Jul 25 2010 1:30:10 AM org.apache.catalina.core.ApplicationContext log . . I have the following inside my /WEB-INF/web.xml <resource-ref> <res-ref-name>jdbc/NexusIRM</res-ref-name> <res-type>javax.sql.DataSource</res-type> <res-auth>Container</res-auth> <res-sharing-scope>Shareable</res-sharing-scope> </resource-ref> And the following in my /META-INF/context.xml  <Resource name=""jdbc/NexusIRM"" auth=""Container"" type=""javax.sql.DataSource"" driverClassName=""com.mysql.jdbc.Driver"" url=""jdbc:mysql://localhost:3306/nexusirm"" username=""root"" password="""" maxActive=""20"" maxIdle=""30"" maxWait=""-1"" /> My Application code looks like:  <% try{ Context initCtx = new InitialContext(); DataSource ds = (DataSource) initCtx.lookup(""java:comp/env/jdbc/NexusIRM""); Connection conn=ds.getConnection(); Statement stmt=conn.createStatement(); ResultSet rs=stmt.executeQuery(""SELECT * FROM irm_gtresult""); if(rs.next()) { for(int i=1;i<9;i++){ out.write(rs.getString(i)); } } conn.close(); }catch(SQLException e) {out.write(e.getMessage()); e.printStackTrace();} %> I am just curious to why these exceptions are being thrown while the application is being executed perfectly! Try this ... Connection conn; try { // Obtain our environment naming context Context initCtx = new InitialContext(); Context envCtx = (Context) initCtx.lookup(""java:comp/env""); // Look up our data source DataSource ds = (DataSource) envCtx.lookup(""jdbc/NexusIRM""); // Allocate and use a connection from the pool Connection conn = ds.getConnection(); ... use this connection to access the database ... } finally { if(conn != null) conn.close(); } NOTE: Make sure you put your close in a finally !!! thanks for the response but I have already tried this. It makes no difference. ""NOTE: Make sure you put your close in a finally !!!"" You can see that I am quite naively testing my code right now but I'll try to stick to the ""good"" practices during this phase in future."
364,A,"Oracle merge constants into single table In Oracle given a simple data table: create table data ( id VARCHAR2(255) key VARCHAR2(255) value VARCHAR2(511)); suppose I want to ""insert or update"" a value. I have something like: merge into data using dual on (id='someid' and key='testKey') when matched then update set value = 'someValue' when not matched then insert (id key value) values ('someid' 'testKey' 'someValue'); Is there a better way than this? This command seems to have the following drawbacks: Every literal needs to be typed twice (or added twice via parameter setting) The ""using dual"" syntax seems hacky If this is the best way is there any way around having to set each parameter twice in JDBC? If you're using 10g ""DUAL"" is even less of a hack. prior to that it was a real table in 10g it's not. I would hide the MERGE inside a PL/SQL API and then call that via JDBC: data_pkg.merge_data ('someid' 'testKey' 'someValue'); As an alternative to MERGE the API could do: begin insert into data (...) values (...); exception when dup_val_on_index then update data set ... where ...; end;  I prefer to try the update before the insert to save having to check for an exception. update data set ...=... where ...=...; if sql%notfound then insert into data (...) values (...); end if; Even now we have the merge statement I still tend to do single-row updates this way - just seems more a more natural syntax. Of course merge really comes into its own when dealing with larger data sets. I think you're right that it seems a more natural syntax but I prefer the single-transaction approach of the merge myself -- no chance of anything untoward happening between update and insert. Nothing untoward can happen between the update and the insert - this is an Oracle consistent transaction view. Does this syntax work in oracle9i? Yes this syntax works in Oracle 9i. I know this is quite an old thread but I've recently used this method and it is NOT safe to use with concurrent transactions. It is possible for two sessions to try the update the same row at the same time find there is nothing there then both try to insert. Safer to do the insert first then catch the exception. I accept that this is unlikely but can happen. I was using DBMS_JOB to set off two parallel processes at the same time.  I don't consider using dual to be a hack. To get rid of binding/typing twice I would do something like: merge into data using ( select 'someid' id 'testKey' key 'someValue' value from dual ) val on ( data.id=val.id and data.key=val.key ) when matched then update set data.value = val.value when not matched then insert (id key value) values (val.id val.key val.value);  Use a stored procedure  When your source and target table are sameyou need to use DUAL."
365,A,"OracleDataSource vs. Oracle UCP PoolDataSource I was researching some JDBC Oracle Connection Pooling items and came across a new(er) Oracle Pool implementation called Universal Connection Pool (UCP). Now this uses a new class PoolDataSource for connection pooling rather then the OracleDataSource [with the cache option enabled]. I am debating whether to switch to this new implementation but can't find any good documentation of what (if any) fixes/upgrades this would buy me. Anyone have an experience with both? Pluses/Minuses? Thanks. I did an extensive evaluation of UCP and decided to NOT use UCP - please have a look at this post for details.  I tested the UCP and deployed it to production in a Spring 3.0.5 Hibernate app using Spring JMS listener containers and Spring-managed sessions and transactions using the @Transactional annotation. The data sometimes causes SQL constraint errors due to separate listener threads trying to update the same record. When that happens the exception is thrown by one method annotated by @Transactional and the error is logged into the database using another method annotated by @Transactional. For whatever reason this process seems to result in a cursor leak that eventually adds up and triggers the ORA-01000 open cursor limit exceeded error causing the thread to cease processing anything. OracleDataSource running in the same code doesn't seem to leak cursors so it doesn't cause this problem. This is a pretty weird scenario but it indicates to me that it's a little too early to be using the UCP in an application with this kind of structure.  I too am testing UCP and am finding myself that I am having performance issues in a Thread Pool based application. Initially I tried OracleDataSource but am having trouble configuring it for batch processing. I keep getting NullPointerExceptions in the connections leading me to believe I have some sort connection leak but only with some application there are other applications we manage that are not batch process oriented that OracleDataSource works well. Based on this post and a few others I found researching this subject I tried UCP. I found that with enough tweaking I could get rid of closed connections/NullPointerExceptions on connections style errors but Garbage Collection was taking a beating. Long-Term GC fills up fast and does not ever seem to free up until the application finishes running. This can sometimes take as long as a day or more if the load is really heavy. I also notice that it takes progressive longer to process data as well. I compare that to the now depreciated OracleCacheImpl class (that we currently use in production because it still ""just works"") where it used a third of the GC memory that UCP does and processes files much faster. In all other applications UCP seems to work just fine and handles just about everything I throw at it but the Thread Pool Application is a major app and I could not risk GC Exceptions in production.  PDS is 'universal' as it provides the same level of pooling functionality you get in ODS for non-Oracle databases e.g. MySQL. See UCP Dev Guide an article on Oracle website and UCP Transition Guide I don't see any immediate benefit of moving to UCP (PDS) from ODS but perhaps in the future Oracle will deprecate some of the functionality in ODS. I used ODS for a while and I'm quite happy with it for the time being but if I started fresh I'd go with PDS.  Latest Oracle jdbc driver (11.2.0.1.0) explicit states that Oracle Implicit Connection cache (which is that one that use OracleDataSource) it's deprecated : Oracle JDBC Drivers release 11.2.0.1.0 production Readme.txt What Is New In This Release ? Universal Connection Pool In this release the Oracle Implicit Connection Cache feature is deprecated. Users are strongly encouraged to use the new Universal Connection Pool instead. The UCP has all of the features of the ICC plus much more. The UCP is available in a separate jar file ucp.jar. So I think it's better to start using UCP but the documentation it's not that good. For example I didn't foud a way to use UCP with spring... UPDATE: I've found the correct spring configuration: OK I'think I've found the right configuration: <bean id=""dataSource"" class=""oracle.ucp.jdbc.PoolDataSourceFactory"" factory-method=""getPoolDataSource""> <property name=""URL"" value=""jdbc:oracle:thin:@myserver:1521:mysid"" /> <property name=""user"" value=""myuser"" /> <property name=""password"" value=""mypassword"" /> <property name=""connectionFactoryClassName"" value=""oracle.jdbc.pool.OracleDataSource"" /> <property name=""connectionPoolName"" value=""ANAG_POOL"" /> <property name=""minPoolSize"" value=""5"" /> <property name=""maxPoolSize"" value=""10"" /> <property name=""initialPoolSize"" value=""5"" /> <property name=""inactiveConnectionTimeout"" value=""120"" /> <property name=""validateConnectionOnBorrow"" value=""true"" /> <property name=""maxStatements"" value=""10"" /> </bean> The key is to specify the right factory class and the right factory method Thanks I had not seen that. To use it in Spring is just like using the OracleDataStore just now you set the specific bean properties (like AbandonConnectionTimeout) rather then passing in a Map of cache properties. See also http://stackoverflow.com/questions/2423490/how-good-is-oracle-universal-connection-pool-ucp/ @user174630 I used this configuration but I got `java.lang.ClassNotFoundException: oracle.jdbc.pooling.Factory` although I have the jars ucp.jar  commons-dbcp.jar and ojdbc6.jar at the classpath  I tried ucp and the performance is better... May be the key is using this oracle.ucp.jdbc.PoolDataSource ds = (oracle.ucp.jdbc.PoolDataSource)envContext.lookup(url_r); MyConnectionLabelingCallback callback = new MyConnectionLabelingCallback(); ds.registerConnectionLabelingCallback( callback ); Properties label = new Properties(); label.setProperty(pname KEY); conn = ds.getConnection(label); This helps to borrow the connection and never closing it.. so the performance is great The code for the callback class is public class MyConnectionLabelingCallback implements ConnectionLabelingCallback {  public MyConnectionLabelingCallback() { } public int cost(Properties reqLabels Properties currentLabels) { // Case 1: exact match if (reqLabels.equals(currentLabels)) { System.out.println(""## Exact match found!! ##""); return 0; } // Case 2: some labels match with no unmatched labels String iso1 = (String) reqLabels.get(""TRANSACTION_ISOLATION""); String iso2 = (String) currentLabels.get(""TRANSACTION_ISOLATION""); boolean match = (iso1 != null && iso2 != null && iso1.equalsIgnoreCase(iso2)); Set rKeys = reqLabels.keySet(); Set cKeys = currentLabels.keySet(); if (match && rKeys.containsAll(cKeys)) { System.out.println(""## Partial match found!! ##""); return 10; } // No label matches to application's preference. // Do not choose this connection. System.out.println(""## No match found!! ##""); return Integer.MAX_VALUE; } public boolean configure(Properties reqLabels Object conn) { System.out.println(""Configure################""); try { String isoStr = (String) reqLabels.get(""TRANSACTION_ISOLATION""); ((Connection)conn).setTransactionIsolation(Integer.valueOf(isoStr)); LabelableConnection lconn = (LabelableConnection) conn; // Find the unmatched labels on this connection Properties unmatchedLabels = lconn.getUnmatchedConnectionLabels(reqLabels); // Apply each label <keyvalue> in unmatchedLabels to conn for (Map.Entry<Object Object> label : unmatchedLabels.entrySet()) { String key = (String) label.getKey(); String value = (String) label.getValue(); lconn.applyConnectionLabel(key value); } } catch (Exception exc) { return false; } return true; } }"
366,A,"Problems with globalization when using Oracle collections with thin JDBC To summarise the issue: Retrieving strings in Java 1.5 (JDBC) works fine when the DB encoding is Western ISO 8859-2 When switching to an Eastern European ISO (e.g. ISO 8859-5) all the normal JDBC string conversions work except the ones involving Oracle collections e.g. nested tables of objects. Instead of proper strings even simple ones such as ""1"" I get ""???"" (three question marks) instead. I tried the following 10.2.0.4 JDBC Jar files but to no avail: ojdbc14.jar orai18n.jar I also tried both CHAR and VARCHAR2 and both behave the same. Joel Spolsky has an interesting article on globalization  You might want to try using the type NVARCHAR2. That type is better suited for non-English characters. This is a good workaround I've just thought of it a short while ago myself. Nevertheless orai18n.jar should work but I'm getting some strange errors. BTW the characters in some of the strings which show up as ""???"" are just simple ASCII ones!"
367,A,"How do I test with DBUnit with plain JDBC and HSQLDB without facing a NoSuchTableException? I am trying to use DBUnit with plain JDBC and HSQLDB and can't quite get it to work -- even though I've used DBUnit with Hibernate earlier with great success. Here's the code: import java.sql.PreparedStatement; import org.dbunit.IDatabaseTester; import org.dbunit.JdbcDatabaseTester; import org.dbunit.dataset.IDataSet; import org.dbunit.dataset.xml.XmlDataSet; import org.junit.Test; public class DummyTest { @Test public void testDBUnit() throws Exception { IDatabaseTester databaseTester = new JdbcDatabaseTester(""org.hsqldb.jdbcDriver"" ""jdbc:hsqldb:mem"" ""sa"" """"); IDataSet dataSet = new XmlDataSet(getClass().getResourceAsStream(""dataset.xml"")); databaseTester.setDataSet(dataSet); databaseTester.onSetup(); PreparedStatement pst = databaseTester.getConnection().getConnection().prepareStatement(""select * from mytable""); } } And this is the dataset.xml in question: <dataset> <table name=""mytable""> <column>itemnumber</column> <column>something</column> <column>other</column> <row> <value>1234abcd</value> <value>something1</value> <value>else1</value> </row> </table> </dataset> This test gives me a NoSuchTableException: org.dbunit.dataset.NoSuchTableException: mytable at org.dbunit.database.DatabaseDataSet.getTableMetaData(DatabaseDataSet.java:282) at org.dbunit.operation.DeleteAllOperation.execute(DeleteAllOperation.java:109) at org.dbunit.operation.CompositeOperation.execute(CompositeOperation.java:79) at org.dbunit.AbstractDatabaseTester.executeOperation(AbstractDatabaseTester.java:190) at org.dbunit.AbstractDatabaseTester.onSetup(AbstractDatabaseTester.java:103) at DummyTest.testDBUnit(DummyTest.java:18) If I remove the databaseTester.onSetup() line I get an SQLException instead: java.sql.SQLException: Table not found in statement [select * from mytable] at org.hsqldb.jdbc.Util.throwError(Unknown Source) at org.hsqldb.jdbc.jdbcPreparedStatement.<init>(Unknown Source) at org.hsqldb.jdbc.jdbcConnection.prepareStatement(Unknown Source) at DummyTest.testDBUnit(DummyTest.java:19) The dataset in itself is working since I can access it like it should: ITable table = dataSet.getTable(""mytable""); String firstCol = table.getTableMetaData().getColumns()[0]; String tName = table.getTableMetaData().getTableName(); What am I missing here? EDIT: As @mlk points out DBUnit doesn't create tables. If I insert the following before adding the dataset everything goes smoothly: PreparedStatement pp = databaseTester.getConnection().getConnection().prepareStatement( ""create table mytable ( itemnumber varchar(255) NOT NULL primary key "" + "" something varchar(255) other varchar(255) )""); pp.executeUpdate(); I posted a followup question as Is there any way for DBUnit to automatically create tables from a dataset or dtd? dbUnit does not create tables. Nor could it with the limited information given in the XML file. Hibernate I believe can create the tables. This is one of the reasons I stopped using in-memory databases and instead got the DBA to give each developer their own database. Every developer then keeps the database up to date using the same scripts which are later ran on live. This adds a small overhead (all developers need to keep their databases up to date) but means you don't need to mess about building the database for each run and you can be sure that the queries ran in test work in live. The second reason was speed. I found creating the in memory-database took a lot longer than simply connecting to an existing database. The third reason was the tear down is none-destructive (start up wipes the database). This means I can run the SQL under test on the database to help work out why a test is failing. I have now switched to a local Oracle XE instance running in a VM. The reason for this is that we can continue developing when not connected to the internal network. With an in-memory database I can run unit tests anywhere without having to switch up any configuration and without having to start up a DB server. Primarily they run on various dev boxes and on the CI server. That's a huge advantage in my book. Yes it is. I personally found it to be significantly slower however this may have changed now. The time taken to start a local VM'ed Oracle XE instance is a short once-per-day thing.  In case you do create your tables upfront like suggested here and still get a NoSuchTableException then there is something wrong with the schema. Before you now turn crazy fiddling with it in all sorts of weird and wonderful ways try setting the schema parameter to PUBLIC when you create the IDatabaseConnection like so: IDatabaseConnection databaseConnection = new HsqldbConnection(sqlConnection ""PUBLIC""); It took me some stepping through the DbUnit code with the debugger but this seems to do the trick."
368,A,"Getting a ResultSet/RefCursor over a database link From the answers to http://stackoverflow.com/questions/1122175/calling-a-stored-proc-over-a-dblink it seems that it is not possible to call a stored procedure and get the ResultSet/RefCursor back if you are making the SP call across a remote DB link. We are also using Oracle 10g. We can successfully get single value results across the link and can successfully call the SP and get the results locally but we get the same 'ORA-24338: statement handle not executed' error when reading the ResultSet from the remote DB. My question - is there any workaround to using the stored procedure? Is a shared view a better solution? Piped rows? Sample Stored Procedure: CREATE OR REPLACE PACKAGE BODY example_SP IS PROCEDURE get_terminals(p_CD_community IN community.CD_community%TYPE p_cursor OUT SYS_REFCURSOR) IS BEGIN OPEN p_cursor FOR SELECT cd_terminal FROM terminal t community c WHERE c.cd_community = p_CD_community AND t.id_community = c.id_community; END; END example_SP; / Sample Java code that works locally but not remotely:  Connection conn = DBConnectionManagerFactory.getDBConnectionManager().getConnection(); CallableStatement cstmt = null; ResultSet rs = null; String community = ""EXAMPLE""; try { cstmt = conn.prepareCall(""{call example_SP.get_terminals@remote_address(??)}""); cstmt.setString(1 community); cstmt.registerOutParameter(2 OracleTypes.CURSOR); cstmt.execute(); rs = (ResultSet)cstmt.getObject(2); while (rs.next()) { LogUtil.getLog().logInfo(""Terminal code="" + rs.getString( ""cd_terminal"" )); } } Option 1. Go for a direct connection from Java to the remote database rather than going through the local database. Simpler but it is up to the application to co-ordinate the two separate transactions. If one database is just used for reads and not writes I'd go this route. You can use with a straight query or a stored procedure and ref cursor. I'd generally go with the former unless there is a good reason to add in a stored procedure layer. Option 2. Go for a direct query in the local database using the database link. Option 3. As (2) but hide the query in a view (or synonym) stored on the local database. Option 4. If the result set is small enough you could have a procedure on the local database call a procedure on the remote database. The remote procedure would return the result as XML or a structured CLOB (eg JSON) which could be 'decoded' by either the local procedure or the java layer. Thanks for your suggestions - we are leaning towards Option 3 at the moment."
369,A,"MySQL + JAVA Exception: Before start of result set try { PreparedStatement s = (PreparedStatement) conn.prepareStatement(""SELECT voters.Checkcount(*) FROM voting.voters where FirstName=""+first+""and LastName=""+last+"" and SSN=""+voter_ID); //java.sql.Statement k = conn.createStatement(); rs=s.executeQuery(); //s.executeQuery(""SELECT voters.Checkcount(*) FROM voting.voters where FirstName=""+first+""and LastName=""+last+"" and SSN=""+voter_ID); System.out.println(rs.first()); c=rs.getInt(1); d=rs.getInt(2); System.out.println(c); System.out.println(d); if(c==1 && d==1) { s.executeUpdate(""update cand set total=total+1 where ssn=""+can_ID); System.out.println(""Succeful vote""); System.out.println(""after vote""); s.executeUpdate(""update voters set voters.Check=1 where ssn=""+voter_ID); toclient=1; PreparedStatement qw = (PreparedStatement) conn.prepareStatement(""select FirstName from cand where ssn=""+can_ID); // rs=k.executeQuery(""select FirstName from cand where ssn=""+can_ID); rs1 = qw.executeQuery();//Error Here Plz help me String name1= (String) rs1.getString(1); System.out.println(name1); s.executeUpdate(""update voters set VTO=""+name1+""where ssn=""+voter_ID); System.out.println(rs.getString(1)); } else { if(c != -1) toclient =2; if( d ==0) toclient =3; if( d>1) toclient =4; } System.out.println(""out-----------""); rs.close(); s.close(); } catch (SQLException e) { // TODO Auto-generated catch block e.printStackTrace(); } Error IS : java.sql.SQLException: Before start of result set at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1072) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:986) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:981) IMHO posting blocks of code and some exceptions without any attempt at an explanation isn't great :/ I prefer this to ""I have a problem please help"" and no code whatsoever ;). And this one is quite easy so not that bothered. I see what you mean I can't see the harm of *a little* explanation though. I guess there is a compromise. Not taking benefit of preparedstatement powers (hardcoding values in query) not taking benefit of SQL powers (all unnecessary `SELECT` queries) poor SQL (that `count(*)` makes no sense) resource leaking (no closing in `finally`) poor code style (it isn't entirely clear what you're trying to achieve) poor datamodel (unclear columnnames and apparently no FK relations (using FirstName instead of ID)). I would like to help you out of this all but I don't know where to start. While rs1.first() may work to avoid exception I would like to avoid it and use rs1.next() instead. See javadoc of ResultSet.first(): SQLException - if a database access error occurs; this method is called on a closed result set or the result set type is TYPE_FORWARD_ONLY SQLFeatureNotSupportedException - if the JDBC driver does not support this method while next doesn't have this limitation Code: if (rs1.next()) { String name1 = rs1.getString(1); } Tips: avoid useless type casting (your code is full of them) his isn't a `FORWARD_ONLY` I think yup... but best practices are always good to be used It's a best practice to call the method you actually need ;) and to lose JDBC strength (DBMSs inter-compability) ? in this case you are losing nothing. The method wouldn't be there if it didn't have usage. first() is intended to be used when you go back-and-forth in the ResultSet. If that's your intention you'll break the inter-compability for performance and you clearly aware of this problem. For this very simple problem not using the best practice means you teach the reader of the code a practice that would cause them problem in the future. So I keep my mind use `next()` for inter-compability and avoid to use `first()` except you know that it improves performance significantly (after profiling of course).  Call rs1.first() before using the ResultSet. Moves the cursor to the first row in this ResultSet object. Initially the cursor position of the ResultSet is before the start of the set. The first() method returns true if there is data in the set. So preferably: if (rs1.first()) { String name1 = (String) rs1.getString(1); }  So to be sure the proper use of PreparedStatment here is your original example adjusted for best practices (note the cast is redundant): PreparedStatement s = conn.prepareStatement( ""SELECT voters.Checkcount(*) "" + ""FROM voting.voters "" + ""where FirstName=? and LastName=? and SSN=?""); s.setString(1first); s.setString(2last); s.setString(3voter_ID); ResultSet rs = s.executeQuery(); while( rs.next() ) { c = rs.getInt(1); d = rs.getInt(2); } Hope this helps... :)  The common practice is to use rs.next() method with while cycle: PreparedStatement st = conn.prepareStatement(""select 1 from mytable""); ResultSet rs = st.executeQuery(); while (rs.next()) { // do something with result set } rs.close(); st.close(); I've omitted try/catch/finally clauses for clarity. Note that you should invoke each close() method in separate finally block. he expects only 1 row (the query includes an `id`) so - `first()` is better. Nope. Look at `rs1 = qw.executeQuery();//Error Here Plz help me` line and the declaration of `qw` above — I think the author _should_ expect more than one record in result set (but I may be wrong of course — it is not so obvious without some explanations). he's making the query by the (apparent) ID which is unique. Personally I'm always doing either `while (rs.next())` for multiple results or `if (rs.next())` for single result.  When you get a resultset the cursor is placed before the first row. Trying to get anything before moving your cursor to the first row will cause the error you received. You need to move the cursor to the first row using this line: rs1.first(); before calling String name1 = (String) rs1.getString(1); Of course make sure the resultset contains entries before calling rs1.getString(1).  In your code snippet you create PreparedStatements but you do not use them correctly. Prepared statements are meant to be used as a kind of 'statement template' which is bound to values before it executes. To quote the javadoc:  PreparedStatement pstmt = con.prepareStatement( ""UPDATE EMPLOYEES SET SALARY = ? WHERE ID = ?""); pstmt.setBigDecimal(1 153833.00) pstmt.setInt(2 110592) This has two big advantages over your current usage of PreparedStatement: one PreparedStatement can be used for multiple executes it prevents a possible SQL injection attack The second one here is the biggie if for instance your variables first and last are collected in a user interface and not reformatted you run the risk of parts of SQL being input for those values which then end up in your statements! Using bound parameters they will just be used as values not part of the SQL statement."
370,A,Spring JDBC: How to create the tables? I am using Spring JdbcTemplate with the DAO pattern to access a database. Instead of creating the database tables manually I am looking for a way to generate the tables in the DAO layer. I understand that I can use the jdbcTemplate to execute statements I am only looking for the right place to do it. Is there a best practice for that? Creating tables programmatically is a smell. In real world (and with good datamodels) you normally just have to create tables only once and use them forever. Are you **sure** you need to do so? If not please post a new question how to change the datamodel so that you don't need to create new table for every hiccup. +1 for BalusC. If you want a reproducible automated way of creating tables create a DDL or some other script that can be executed when your environment is being set up. In other words this should not be handled in code. @BalusC a logical place to execute a DDL setup could be an install operation which might be distributed as part of your code -- why add something other than the current DAO to deal with this often necessary step? I agree that it's dangerous for production but I find that creating the tables in the code saves a ton of time for prototyping and quickly setting up local development environments. I like to create a maven profile to ensure I don't accidentally run the table drop/create code against production configs. For example it's sometimes super convenient to hand the code to another developer and tell them to simply run something like: `mvn -Pprototype jetty:run`. You can use the execute(String) method: public void execute(String sql) throws DataAccessException Issue a single SQL execute typically a DDL statement. Specified by: execute in interface JdbcOperations Parameters: sql - static SQL to execute Throws: DataAccessException - if there is any problem However as beny23 mentions I would be suspicious of an actual need to do this programatically in a live application.  Use .update() methods available in the (Simple)JdbcOperations the number they return is the number of affected rows. They're supposed to be specifically used for both INSERT and UPDATE statements. He's asking about how to create a table not how to update one `.update()` is meant for those too. basically all the other methods are for SELECTs `.update()` is for everything else.  Slightly offtopic: Is it absolutely necessary that you need to execute the DDL commands from within your code? In fact I do think it is a good idea to have separation between db admin and db usage. Our Oracle database security setup here is actually set up so that the tables are set up using a different database user (DB_OWNER) than the one running the SELECTs INSERTs DELETEs are run by DB_USER. This prevents accidentially deleting tables or modifying the schema and also allows the DB_USER to be setup such that only the privileges that are absolutely necessary are granted which adds a layer of security. I suppose it depends on the nature of your service/application but think about the benefit of creating the tables inside the code (and whether a possible bug in the DDL code could accidentially destroy production data). Thank you for this good advice! yes agree on that we used to have DB_USER which can only SELECT and CALL PROCEDURE so if happen that hackers somehow steal usernam/pass (used by application exposed on web for instance) they can only select from database with it... or they can call stored procedure which will handle checks before and insert something which will leave database in consistent state so the damage would be smaller Suppose you're doing a fresh installation do you distribute another application to run your DDL or do you bundle the DDL and have installation logic in your application? I guess that would depend on the type of application using the database. In a lot of production environment having a separate DDL script is absolutely necessary to hand over to the DBA team which will then approve the changes before running the script and the code developers wouldn't have any access to the production database and having the app modify the DB would be a definite no-no. Having said that AFAIK Hibernate can automatically generate the tables for you though personally I wouldn't use it as the index and constraint names be unreadable which makes DB maintenance more complicated.
371,A,Should I need to release my application if I include MySQL Connector/J (GPL) as part of my package? I am using MySQL Connector/J (GPL licence) and bundle the jar as part of my distribution. So should I need to release my application under GPL also? Yes you had to. But not because you are shiping mysql-connector with you application but because you are linking against it. (If you really do) For explanations and solution see this note link text  This has always a matter of some controversy and much confusion. This has not helped by the attitude of MySQL AB who would typically advise you to purchase a commercial license whatever you were doing (exempting you from the requirements of the GPL) rather than explaining their intrepretation of which circumstances it is where the GPL allows you to operate without one. (Well they're unlikely to want to spend much time arguing themselves out of a sale I suppose.) The crunch point as I understand it is that while the GPL is well-defined and widely-understood in the scenario of ‘linking’ in the traditional C model (eg) it is less-so for interpreted languages like Java where communication and choice between components is a fluid run-time matter. Could one argue that dropping a .jar into your distribution folder is “mere aggregation” on a medium as opposed to a “collective work” under the terms of GPLv2 section 2? hnnnnmm... well maybe. Fancy making that argument in court? Doubtful. Disregarding the issue of interpreting the letter of the GPL (as I Am Not A Lawyer) the spirit of the GPL's intent could be summed up with the question: Is Connector/J a dependency you're including in your package or is it a separate component that an end-user may choose to install and then connect to your package themselves? If you don't want to license your package as GPL or pony up for a commercial licence to support MySQL then make sure the latter really is the case: don't bundle MySQL or the Connector with your package any more tightly than simply having separate installers on the same disc. Don't make an installer that runs both. Best: ensure your software can operate with multiple different database backends allowing the user to choose which they'll be using it with. This is a Good Thing to do anyway; database-specific code sucks. Plus if you do want to provide a one-click installer that includes the database and sets them up together you can always use one with a license that permits it such as PostgreSQL or SQLite. [I am assuming here you're talking about a commercial package rather than an open-source program that you merely want to make available under a different licence than GPL. In that case see the EXCEPTIONS-CONNECTOR-J file for licences you're also allowed to use as FOSS exceptions.]
372,A,OracleDataSource connection caching - restarting connections? Is it possible to set the Oracle connection cache to restart cached connections after a period of time? Please explain in more detail what it is that you want to do. You can use the new Universal Connection Pool. The class oracle.ucp.jdbc.PoolDataSource has apropriate methods. e.g. void setTimeToLiveConnectionTimeout(int timeToLiveConnectionTimeout) throws java.sql.SQLException see javadoc at: http://download.oracle.com/docs/cd/B28359_01/java.111/e11990/oracle/ucp/jdbc/PoolDataSource.html This is exactly what I needed thanks a ton.
373,A,Need help on learning java frameworks quickly I wrote a piece of java code using threads JDBC Java Mail API etc. without using any of the frameworks (read Spring). I am frankly not too comfortable learning them first (lots of terminologies to remember!) and use them. So please suggest me some ways to refine my existing code incorporating few of these framework concepts applicable to the aforementioned things without having to learn a lot about them. Is there any quick way to learn some vital framework concepts and use it.. sounds certainly foolish but still looking for somebody's experiences :) If you aren't interested in frameworks your code should at least use interfaces and layering that's appropriate. Your app will be well-layered if you have interfaces for services and repositories whether you use a framework or not. You should have a front controller servlet that accepts all requests. You should bind and validate all requests prior to processing in the service tier. The services should be completely separate from your web tier. If you can't unbolt the web UI and have the rest of the stuff work you're doing it wrong. Thanks Duffymo!  for your simple stuff i dont really see a value add of using framework. u could replace the thread handling with the Java 5 Executors though. And if you want IoC/dependency injection then look into Google Guice Guice is just for dependency injection and extremely lightweight. Spring on the other hand is (after years of development) a monster. Guice is just as much a framework as Spring is. I don't see what makes it more acceptable. Thank you Pangea..  I am not one of those people that can read a book and understand (although I certainly wish I was that type). I have to learn by doing so I suggest installing an IDE that supports the framework you want to learn and do the tutorials or build something that you can use personally. Couple that with some books/internet for reference and guidance. Good luck! Thank you northpole
374,A,Hibernate's setFirstResult() issue with Oracle jdbc driver I'm trying to do pagination with Hibernate using setFirstResult() and setMaxResults() but I'm not getting the expected results when setting the first result to 0. When doing the following: Query query = session.createQuery(queryString); query.setFirstResult(0); query.setMaxResults(30); List list = query.list(); //list.size() returns 10 but if I set the first result to 1 (or anything different than 0 for that matter): query.setFirstResult(1); query.setMaxResults(30); List list = query.list(); //list.size() returns 30 I read this is a known bug in the jdbc driver but I searched for a solution and I can't seem to find it. Has anyone run across anything similar and found a fix for it? Apparently adding setFetchSize() does the trick. So something like this now works perfectly: query.setFirstResult(0); query.setMaxResults(30); query.setFetchSize(30); List list = query.list(); //list.size() now returns... wait for it... 30 You wonderful man! I just had this exact problem and `setFetchSize()` fixed it immediately.  Another Solution is to implement your own Oracle Dialect: public class Oracle10gDialectLimitBugfix extends Oracle10gDialect { @Override public boolean forceLimitUsage() { return true; } } See https://forum.hibernate.org/viewtopic.php?p=2379096 UPDATE: It seems to be fixed in Oracle 11.2.0.1.0
375,A,"JdbcTemplate — logging the dataSource connection url is there a way to log the JdbcTemplate's DataSource connection URL in Java? The field exists in the DataSource but there ain't a getter to access it. Of course I could read the DataSource properties from the application context xml but I'd like to do it the other way. What DataSource implementation are you using? Something like c3p0? If the field exists would you consider using reflection to access it? The approach may not be future-proof but may be sufficient for your needs.  I know you said you didn't want to have to get it from the context xml but I can't see an easy and non-fragile way around it. In Spring 2.0 and greater you can use the <util:property-path /> element to reference a property of another bean. Let's say your DataSource is declared like so (note: I'm going to use the p-namespace throughout for brevity): <bean id=""dataSource"" class=""com.example.SimpleDataSource"" p:user=""db_user"" p:password=""letmein"" p:driverClass=""com.example.CabDriver"" p:jdbcUrl=""jdbc:example:@localhost:1729:magicdb"" /> I'm assuming that your JdbcTemplate is being used by some data access object. Let's say it looks like this: public class SimpleDao implements ExampleDao { private JdbcTemplate jdbcTemplate; public void setDataSource(DataSource dataSource) { this.jdbcTemplate = new JdbcTemplate(dataSource); } } So the Spring config to construct this DAO is like so: <bean id=""dao"" class=""com.example.SimpleDao"" p:dataSource-ref=""dataSource"" /> Now to our problem: how to get the JdbcUrl property into our DAO? Let's add a setter: public class SimpleDao implements ExampleDao { private String jdbcUrl; // ... public void setJdbcUrl(String jdbcUrl) { this.jdbcUrl = jdbcUrl; } // ... And finally we inject this using the aforementioned <util:property-path /> element: <bean id=""dao"" class=""com.example.SimpleDao"" p:dataSource-ref=""dataSource""> <property name=""jdbcUrl> <util:property-path path=""dataSource.jdbcUrl"" /> </property> </bean> The URL is available from the bean named dataSource using getJdbcUrl (note that this is on the concrete DataSource not the interface) so the property-path element tells Spring to get the value from there and use it as the value for the DAO's property. This isn't too much code (it's one setter and one extra property) and you're guaranteed to always have the same value injected into both beans."
376,A,"How to avoid this very heavy query that slows down the application? We have a web application running in a production enviroment and at some point the client complained about how slow the application got. When we checked what was going on with the application and the database we discover this ""precious"" query that was being executed by several users at the same time (thus inflicting an extremely high load on the database server): SELECT NULL AS table_cat o.owner AS table_schem o.object_name AS table_name o.object_type AS table_type NULL AS remarks FROM all_objects o WHERE o.owner LIKE :1 ESCAPE :""SYS_B_0"" AND o.object_name LIKE :2 ESCAPE :""SYS_B_1"" AND o.object_type IN(:""SYS_B_2"" :""SYS_B_3"") ORDER BY table_type table_schem table_name Our application does not execute this query I believe it is an Hibernate internal query. I've found little information on why Hibernate does this extremely heavy query so any help in how to avoid it very much appreciated! The production enviroment information: Red Hat Enterprise Linux 5.3 (Tikanga) JDK 1.5 web container OC4J (whitin Oracle Application Server) Oracle Database 10.1.0.4 JDBC Driver for JDK 1.2 and 1.3 Hibernate version 3.2.6.ga connection pool library C3P0 version 0.9.1. UPDATE: Thanks to @BalusC for claryfing that indeed it is Hibernate that executes the query now I have a better idea about what's going on. I'll explain the way we handle the hibernate session (it's very rudimentary yes if you have suggestions about how to handle it better they are more than welcome!) We have a filter (implements javax.servlet.Filter) that when it's starts (init method) it constructs the session factory (supossedly this happens only once). Then every HttpRequest that goes to the application goes through the filter and obtains a new session and it starts a transaction. When the process it's over it comes back through the filter makes the commit of the transaction kills the hibernate session then continue to the forward page (we don't store the hibernate session in the Http session because it never worked well in our tests). Now here comes the part where I think the problem is. In our development enviroment we deploy our apps in Tomcat 5.5 and when we start the service all filters start inmediately and only once. In the production enviroment with OC4J doesn't seem to work that way. We deploy the application and only when the first request arrives OC4J instantiates the filters. This leads me to think that OC4J instantiates the filters on every request (or at least multiple times which is still wrong) thus creating a session factory on every request wich executes that %&%#%$# query which leads to my problem! Now is that correct? It's there a way for me to configure the OC4J for it to instantiate filters only once? Thanks very much to all of you for taking the time to respond this! Also are you using the correct Hibernate dialect and the correct JDBC Oracle drivers? Did you guys consider modifying the app such that the result of this query is cached? result of this seems to be static data unless you are building a DB management tool. I'm sure we're using the correct dialect not so much on the driver (but it never gave problems before). And the query is not part of the application it must be a hibernate c3p0 or driver query we're not sure who executes it. My first thought it's the driver so yes we're installing the latest. All right after months of looking at the thing it turns out that the problem wasn't my web application. The problem was the other Oracle Forms applications that use the same instance (different user) of the database. What was happening was that the Oracle Forms applications were locking records on the database therefore making pretty much all of the work of the database extremely slow (including my beloved Hibernate query). The reason of the locks was that none of the foreign keys of the Oracle Forms apps were indexed. So as my boss explained it to me (he discovered the reason) when a user is editing the master record of a master-detail relationship in a Oracle Form application the database locks the entire detail table if there is no index for its foreign key. That is because the way the Oracle Forms works that it updates all af the fields of the master record including the ones of the primary key wich are the fields that the foreign key references. In short please NEVER leave your foreign keys without indexes. We suffered a lot with this. Thanks to all of you who took the time to help. you're referring to the foreign key field referenced being indexed right?  Specifically what happens is that folks who write software that support different databases package their software in a database neutral way. ie. when an override isn't present what they do is use jdbc db metadata getTables call to check if the connection is still valid. Typically you override with select * from dual etc but when that's not done or you don't specifically say what kind of database you are using the software is written to run something that will work with any JDBC driver. jdbc db metadatabase getTables will do that.  Is the sys schema in your 10g database analyze with updated stats? Have you collected stats on the fixed tables in the sys schema. Queries on all_objects shouldn't be that taxing to a system. If you run the query via autotrace/tkprof what/where is the major of the resources be spent at. We do have A LOT of objects in the database on purpouse (there is another application developed in PL/SQL) so that's why that query takes a lot of time to execute (and in addition by the time we discovered it there was 17 users executing it at the same time). And again that query is NOT part of our web application must be an Hibernate/C3P0/oracle jdbc driver thing we haven't figured it out yet.  It's indeed coming from Hibernate and specifically org.hibernate.tool.hbm2ddl.TableMetadata. It's under each been used to validate the schema (table and column mapping). Apparently it's unnecessarily been executed on every spawned request or session instead of only once during application's startup. Are you for example not unnecessarily calling the Hibernate Configurator on every request or session? Actually this class is part of Hibernate Core. Yes? OK revised. Yes the packaging may be misleading but it is part of `hibernate-core.jar`. Upvoted too then :)  I just wanted to put in the workaround I used to get around this problem. We typically have lots of schemas in our databases and this would take hours to finish in the application we were trying to use which used hibernate because of the large number of objects that it ended up checking (the query itself would execute fast but it just did so many of them). What I did is overrode the ALL_OBJECTS view in the schema being connected to so that it only brought back it's own objects and not all objects in the db. e.g. CREATE OR REPLACE VIEW ALL_OBJECTS AS SELECT USER OWNER O.* FROM USER_OBJECTS O; It's not the greatest solution but for this application there is nothing else that would be using the ALL_OBJECTS view so it works fine and starts up substantially faster. Thanks! It's clearly a workaround that is best to avoid in production but it's working perfectly in our testing environment. Thanks! That was it - my query time changed from minutes to seconds!  Had the same problem the cause was exactly the one described by Bob Breitling C3P0 uses by default JDBC API for connection testing : java.sql.DatabaseMetaData#getTables(....) In order to change this behavior the preferredTestQuery must be set or if C3P0 is used through hibernate - hibernate.c3p0.preferredTestQuery  As pointed out by @BalusC this query is performed during schema validation. But validation is usually done once for all when creating the SessionFactory (if activated). Do you call the following method explicitely: Configuration#validateSchema(Dialect DatabaseMetadata)? Now is that correct? It's there a way for me to configure the OC4J for it to instantiate filters only once? Your implementation of the Open Session In View looks fine (and is very close to the one suggested in this page). And according to the Servlet specification only one instance per <filter> declaration in the deployment descriptor is instantiated per Java Virtual Machine (JVMTM) of the container. Since it is very unlikely that this isn't the case with OC4J I'm tempted to say that there must something else. Can you put some logging in the filter? What about making the SessionFactory static (in a good old HibernateUtil class)? Sorry I saw your answer *after* I updated my answer with a thought about the Hibernate Configuration but this is indeed the first direction where the OP should look for the cause and the solution :) (+1)  I believe this query is coming from the Oracle JDBC driver to implement a Hibernate request to retrieve database object info through DatabaseMetaData. This query shouldn't be too expensive or at least isn't on a system I have handy. What's your count of all_objects and more importantly what do you see in the rows/bytes total for the explain plan? This can impossibly be coming from the JDBC driver as it knows *nothing* about Hibernate. ...not a Java programmer but what I was trying to say that Hibernate was calling some method of the DatabaseMetaData class that is part of the driver with the purpose of retrieving table/view info - I'm now seeing more knowledgeable Hibernate-related answers since my original post Depends on the bind variables. A wildcard for the owner and object name could be bringing back a lot of data.  This is coming from the default C3PO test query. Supply a simpler query in your configuration. Something like select 'X' from dual."
377,A,"Best Practice: How to check for a specific java.util.Calendar/Date in SQL.DATE by JDBC? This is something I struggle with since yesterday. I have appointments to save in a database. They consist of a date and a time like: 01.02.1970 14:00 (german format in american I think it would be something like 02/01/1970 2:00pm). First idea: Save it as a SQL.DATE! So i created a table: CREATE TABLE appointments (id NUMBER(10) NOT NULL datum DATE NOT NULL PRIMARY KEY id) So far so good. Now I wrote a DAO saving my appointment entered via web form. Afterwards I wanted to write a unit test to check if the appointment is saved properly. The relevant test part is as follows: JdbcDao myDao = new JdbcDao(); myDao.setDataSource(jdbcTemplate.getDataSource()); myDao.saveAppointment(appointmentModel); // Not needed but I saw the appointment is saved in the database setComplete(); // And now for the (sorry for the harsh words) pain in the *** part String sql = ""SELECT id datum FROM appointments WHERE datum ... // <-- <--: This is just the part where I don't know what to enter to see if on a specific day a date already is in the database. I tried: datum = ? the the following call of jdbcTemplate.query(sql args rowMapper); had a java.util.Date a java.util.Calendar or a java.lang.String ('dd.MM.yyyy') in the args-array which holds the arguments replacing the ? in the prepared statement. Sure this was a bad idea because the database has something like DD.MM.YYYY HH:MI in the table row (DD=day MM=month YY=year HH=hour MI=minute). So I found the BETWEEN sql command refactoring (and trying all kind of formats inputs strings object to pass in the args-array) the SELECT-command to: String sql = ""SELECT id datum FROM appointments WHERE datum BETWEEN to_date( ? 'DD.MM.YYYY HH24:MI:SS') AND to_date( ? 'DD.MM.YYYY HH24:MI:SS') which works like many other tries if I enter it via a sql-tool directly e.g. SELECT * FROM appointments WHERE datum BETWEEN to_date('01.02.1970 00:00:00' 'DD.MM.YYYY HH24:MI:SS') AND to_date('01.02.1970 23:59:59' 'DD.MM.YYYY HH24:MI:SS') outputs for example: ID DATUM ---------------------- ------------------- 70 01.02.1970 11:11:11 but my jdbc-call in java always results in an empty resultset. Long story short question: What is the best practice to query a database if a date represented by a java-object exists in a sql.DATE column in a database independet from the given time? Something like this: PreparedStatement ps = conn.prepareCall(""SELECT * FROM table WHERE someDate = ?""); ps.setDate(1 javaDate) (From memory so the syntax might not quite be right) You do have to convert java.util.Date objects to java.sql.Date objects though. This is fairly simple: java.sql.Date myDate = new java.sql.Date(oldDate.getTime()); Where oldDate is a java.util.Date object. I was so into ""pattern matching the sql-string and the java-object"" that I never tried to pass a plain Date-Object without costumizing... that works."
378,A,"Netbeans with Oracle connection java.lang.ClassNotFoundException I use NetBeans 6.5. When I try to run the following code: package com.afrikbrain.numeroteur16; import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; import java.util.logging.Level; import java.util.logging.Logger; /** * * @author */ public class NumeroteurTest { public NumeroteurTest() { } public void doIt() throws ClassNotFoundException{ try { Class.forName(""oracle.jdbc.OracleDriver""); Connection connection = DriverManager.getConnection(""jdbc:oracle:thin:@localhost:1521:XE""""user""""pwd""); String newNUMERO = new Numeroteur16(""MATCLI"" connection).numeroter(); System.out.println(""NUMERO GENERE : ""+newNUMERO.toString()); } catch (SQLException ex) { Logger.getLogger(NumeroteurTest.class.getName()).log(Level.SEVERE null ex); ex.printStackTrace(); } catch (NumException ex) { System.out.println(ex.getMessage()); ex.printStackTrace(); } } public static void main(String[] args){ try { new NumeroteurTest().doIt(); } catch (ClassNotFoundException ex) { Logger.getLogger(NumeroteurTest.class.getName()).log(Level.SEVERE null ex); System.out.println(""Driver not found.""); } } } I get this error: java.lang.ClassNotFoundException: oracle.jdbc.OracleDriver at java.net.URLClassLoader$1.run(URLClassLoader.java:200) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:188) at java.lang.ClassLoader.loadClass(ClassLoader.java:307) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301) at java.lang.ClassLoader.loadClass(ClassLoader.java:252) at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:320) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:169) at com.afrikbrain.numeroteur16.NumeroteurTest.doIt(NumeroteurTest.java:27) at com.afrikbrain.numeroteur16.NumeroteurTest.main(NumeroteurTest.java:45) Driver not found. How do I solve this problem? Add ojdbc6.jar to the project libraries. First create a new library (NetBeans): NetBeans -> Tools -> Libraries -> New library (Use a descriptive name eg: OracleJDBC6.) Click OK then Add JAR/Folder. Type %ORACLE_HOME%\jdbc\lib\ojdbc6.jar then confirm. On my computer ORACLE_HOME=c:\app\admin\product\11.2.0\dbhome_1. Finally add the library to the project: Right-click on Libraries  select Add library and select the library previously added.  The problem: Java can't find the JDBC Driver Class. Solution: Add the Oracle JDBC Driver to your classpath. You can get it at http://www.oracle.com/technology/software/tech/java/sqlj%5Fjdbc/index.html Start java with java -classpath ojdbc14.jar ... to include the downloaded jar in your classpath. here is it http://download.oracle.com/otn/utilities_drivers/jdbc/11202/ojdbc6.jar  Make sure that the Oracle driver is in the classpath. The thin driver is in ojdbc14.jar."
379,A,Oracle Thin Driver and Transparent Failover of RAC DB I know the oci driver can perform transparent failover of the database but does the thin driver have the same capability? The Thin driver does not support TAF like the OCI driver does as is described in the FAQ. When using the Thin driver the built-in RAC capability of Fast Connection Failover is available: http://download.oracle.com/docs/cd/B28359_01/java.111/b31224/fstconfo.htm
380,A,"How to connect to database from Jython I cannot connect to database from my Jython program. Pure Java programs can connect and I can connect to db from Jython but only using JDBC-ODBC bridge: ""sun.jdbc.odbc.JdbcOdbcDriver"". If I use native JDBC driver my program fails with ""driver not found"" exception. Code: import sys from com.ziclix.python.sql import zxJDBC connection1 = zxJDBC.connect('jdbc:odbc:test_odbc' 'postgres' 'postgres' 'sun.jdbc.odbc.JdbcOdbcDriver') print ""JDBC:ODBC connection set"" connection2 = zxJDBC.connect('jdbc:postgresql://127.0.0.1/test?stringtype=unspecified' 'postgres' 'postgres' 'org.postgresql.Driver') print ""JDBC native connection set"" Output: C:\tools\pyscripts\scripts\db_examples>jython --version Jython 2.5b1 (trunk:5903:5905 Jan 9 2009 16:01:29) [Java HotSpot(TM) Client VM (Sun Microsystems Inc.)] on java1.6.0_11 C:\tools\pyscripts\scripts\db_examples>jython pg_test.py JDBC:ODBC connection set Traceback (most recent call last): File ""pg_test.py"" line 6 in <module> connection2 = zxJDBC.connect('jdbc:postgresql://127.0.0.1/test?stringtype=un specified' 'postgres' 'postgres' 'org.postgresql.Driver') zxJDBC.DatabaseError: driver [org.postgresql.Driver] not found I think that my CLASSPATH is set properly while native Java programs can connect to this database using native driver. I have found that all JDBC drivers have .pkc files in cachedir\packages. What should I set to get database connection? After struggling with this for a day I finally found a solution. Don't bother with zxJDBC Class.forName DriverManager etc - simply instantiate the driver directly: import os import sys from java.util import Properties # add the jar to your classpath then import it sys.path.append('/tmp/postgresql-8.4-701.jdbc4.jar') import org.postgresql.Driver as Driver props = Properties() props.put('user' 'u') props.put('password' 'p') conn = Driver().connect('jdbc:postgresql://127.0.0.1' props)  I will answer myself: There was bug in Jython 2.5b1: Jython has problems to dynamically loading classes when installed on the boot classpath I was able to run my program if I invoked it with --verify flag. Bug disappeared in Jython 2.5b3 One Up for learning !  I had the same problem and could not use the --verify flag (jython complained about unknown switch). The problem disappeared magically as soon as I configured my OS X Leopard Java to use the 1.6 virtual machine instead of 1.5."
381,A,"Use NamedParameterJdbcTemplate to update array field I have a double precision array field dblArrayFld in a table myTable and I'd like to update it using Spring's NamedParameterJdbcTemplate (I'm using Postgres). I'm running code like this: SqlParameterSource params = (new MapSqlParameterSource()) .addValue(""myarray"" myDblArrayListVar) .addValue(""myid"" 123); namedJdbcTemplate.update(""UPDATE myTable SET dblArrayFld = :myarray WHERE idFld = :myid"" params); This returns an error that reads syntax error at or near ""$2"" I'm assuming my syntax on :myarray is at fault here. I've also tried encasing :myarray in the following ways: dblArrayFld={:myarray} dblArrayFld={ :myarray } dblArrayFld=[:myarray] dblArrayFld=ARRAY[:myarray] dblArrayFld=(:myarray) What's the correct syntax here? What type is myDblArrayListVar? Sorry missed that one: myDblArrayListVar is an ArrayList I was expecting this answer but wanted to get confirmation Wehn you try to bind Collection or array as named parameter NamedParameterJdbcTemplate explodes the appropriate named parameter in your statement into a number of positional parameters matching the length of your array / collection. This is useful for WHERE column IN (:param) statements but is not going to work in this case. In order to set an actual Postgres array you have to supply your parameter as java.sql.Array. You can create its instance using Connection.createArrayOf() method. Thanks -- this is great. I think JDBC might define createArrayOf as standard but Postgres JDBC4 doesn't seem to support it. Any good alternatives? The latest JDBC does. Actually it did for a while: http://jdbc.postgresql.org/changes.html#version_8.3-dev602"
382,A,"Externalizing tomcat jdbc connection pool information for different environments Greetings I'm looking for a good solution for externalizing the JNDI connection pool information in context.xml of a war so that as the application moves from dev to QA to prod the war file won't need to be recompiled. Ideally the url driver username and password would be variablized and then populated by means of a properties file that would customized for each environment. If this isn't possible are there other suggestions on how to handle moving a war across environments without recompiling for a target environment? Maven provides profiles this requires a build targeted at a specific environment. Thanks in advance. Why don't you just configure this at the Tomcat level instead of embedding a context.xml? To me this makes particularly sense since Dev QA Prod can use different pool settings. And by this I mean the configuration/sizing of the pool not only not only the url username and password. By at ""the Tomcat level"" do you mean in GlobalNamingResources? In `$CATALINA_BASE/conf/context.xml` or `$CATALINA_BASE/conf/[enginename]/[hostname]/context.xml.default` or in an individual file in `$CATALINA_BASE/conf/[enginename]/[hostname]/` as documented in http://tomcat.apache.org/tomcat-6.0-doc/config/context.html.  You can have a context.xml that lives outside the WAR files in the common ""conf"" directory. See the docs."
383,A,Is it expensive to hold on to PreparedStatements? (Java & JDBC) I'm trying to figure out if it's efficient for me to cache all of my statements when I create my database connection or if I should only create those that are most used and create the others if/when they're needed.. It seems foolish to create all of the statements in all of the client threads. Any feedback would be greatly appreciated. A bit decent database will already cache them. Just fire Connection#prepareStatement() at the moment you actually need to execute the query. You actually also have no other choice since connection statement and resultset ought to be acquired and closed in the shortest possible scope i.e. in a try-finally block in the very same method as you execute the query. Opening and closing the connection on every query in turn may indeed be expensive. A common solution to that is using a connection pool for example c3p0.  This sounds to me like the kind of premature optimization that I wouldn't worry about until I have some information telling me that it mattered. If your database access is inefficient I'd suspect your schema or access of values before I'd think of caching prepared statements.  I think you're worrying too much prepared statements already benefit from several level of caching: At the database level: a decent database will reuse the access plan for a given prepared statement. At the connection pool level: a decent connection pool will cache PreparedStatement objects for each database connection in the pool (and return a cached PreparedStatement on subsequent calls to preparedStatement on a connection). So actually I would even say that you might be looking in the wrong direction. The best practice if you want to design a scalable solution is to use a connection pool and to not held a connection longer than needed and to release it (to release database resources) when you're done with it.
384,A,java.sql.Connection extension for SSH I have a MySQL database behind a firewall which can only be accessed via an SSH connection. Does anyone know of an implementation of java.sql.Connection which would allow me to make an SSH connection to this database? You can use SSH's port forwarding to do this. While not a pure java.sql.Connection it will allow you to tunnel the connection through ssh. ssh -L 3306:localhost:3306 remote.mysql.host.com This will forward port 3306 on your local machine to port 3306 on remote.mysql.host.com. This will allow you to connect to port 3306 on your local machine and it will be tunnelled to remote.mysql.host.com. If you're looking to do it all in Java create the ssh connection with JSch. How can I establish the connection with MySQL on remote server with Java?
385,A,"How to create a table in mysql for containing 3 columns? I want to create a table containing three string columns: The JSP page Part of JSP page (like footer header text) Actual value text How do I do that: from the command prompt from a Java application (Create if it doesn't exist -- how common is that?) Thanks It is not likely you would want to create a table dynamically especially if you need to save data and get it during other sessions. It's best to use mysql command prompt or a graphical tool like SQL Yog to create a table that you will later access at JSP page. The command to create table will look like this CREATE TABLE `pages` ( `id` int(11) NOT NULL auto_increment `part_of_page` varchar(30) NOT NULL `actual_text` varchar(300) NOT NULL PRIMARY KEY (`id`) ) CHARACTER SET `utf8`; Why is ID primary key? please don't say `NOT NULL default ''` but instead just say `NOT NULL`. This way the database will give an error if you try to insert empty data.  As PHP Thinker says you rarely want to create a table dynamically within a program. But if you have a legitimate reason you just submit the ""create"" statement like an update query: try { Statement st=conn.createStatement(); st.executeUpdate(""create table mytable ... whatever ...""); st.close(); } catch (SQLException oops) { ... query had syntax errors or something ... } This is an update and not a query so there is no ResultSet returned. The return value is the number of records updated which for a ""create table"" is always zero so no point bothering with it. If there's an error in +! How about create if it doesn't exist? The only trick is to check whether it already exists. I don't know of any generic SQL way to ask if a table exists but a generic Java way would be to use Connection.getMetaData() to get a DatabaseMetaData object for your database then do getTables(null null ""mytablename"" null) and if you get anything back the table exist. (Use non-null values for the other parameters if necessary to avoid ambiguity -- see the JavaDocs.) Most SQL engines now support the ""information_schema"" so you could query against that. But I think the DatabaseMetaData method is cleaner."
386,A,"How to find out if a Java ResultSet obtained is empty? Class.forName(""org.sqlite.JDBC""); Connection conn = DriverManager.getConnection(""jdbc:sqlite:userdata.db""); Statement stat = conn.createStatement(); ResultSet rs = stat.executeQuery(""SELECT * from table WHERE is_query_processed = 0;""); int rowcount = rs.getRow(); System.out.println(""Row count = ""+rowcount); // output 1 rs.first(); // This statement generates an exception Why is it so? I just noticed that you said an exception was thrown when you called `first()`. Which exception is thrown? It may be throwing one because you're already used `getRow()` or it may be throwing one because your driver doesn't support this method in which case Colin's solution is more likely to work for you. @jasonmp: You are right my driver does not support call to first(). I used Collin's solution and it is working for me. Why is execution not entering the while loop? If your ResultSet is empty the rs.next() method returns false and the body of the while loop isn't entered regardless to the rownumber (not count) rs.getRow() returns. Colins example works. but my SQL query returns 1 row. I have run the same query on db directly. rs.next() without anything other called before works for me (including only 1 row in RS) see also section 5.1.4 at http://java.sun.com/j2se/1.5.0/docs/guide/jdbc/getstart/resultset.html  Did you try Google first? http://www.google.com/search?hl=en&source=hp&q=jdbc+resultset+number+of+rows&aq=1&aqi=g10&aql=&oq=jdbc+resul&gs_rfai=CnX4s4mgCTOO3K4TIhgSyhKzICAAAAKoEBU_QWw9D Yes and it took me here. @Hamish Did you try reading the user guide lines of Stackoverflow? -1  Try with this: ResultSet MyResult = null; MyResult = Conexion.createStatement().executeQuery(""Your Query Here!!!""); MyResult.last(); int NumResut = MyResult.getRow();MyResult.beforeFirst(); //Follow with your other operations.... This manner you'll be able work normally.  CLOSE_CURSORS_AT_COMMIT public static final int CLOSE_CURSORS_AT_COMMIT The constant indicating that ResultSet objects should be closed when the method Connection.commit is called.  Shifting the cursor forth and back to determine the amount of rows is not the normal JDBC practice. The normal JDBC practice is to map the ResultSet to a List of value objects each representing a table row entity and then just use the List methods to determine if there are any rows. For example: List<User> users = userDAO.list(); if (users.isEmpty()) { // It is empty! if (users.size() == 1) { // It has only one row! } else { // It has more than one row! } where the list() method look like as follows: public List<User> list() throws SQLException { Connection connection = null; Statement statement = null; ResultSet resultSet = null; List<User> users = new ArrayList<User>(); try { connection = database.getConnection(); statement = connection.createStatement(); resultSet = statement.executeQuery(SQL_LIST); while (resultSet.next()) { User user = new User(); user.setId(resultSet.getLong(""id"")); user.setName(resultSet.getString(""name"")); // ... users.add(user); } } finally { if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } return users; } Also see this answer for other JDBC examples.   while (results.next()) is used to iterate over a result set.so results.next() will return false if its empty.  Here's a simple method to do it: public static boolean isResultSetEmpty(ResultSet resultSet) { return !resultSet.first(); } Caveats This moves the cursor to the beginning. But if you just want to test whether it's empty you probably haven't done anything with it yet anyways. Alternatively Use the first() method immediately before doing any processing. ResultSet rs = stat.executeQuery(""SELECT * from table WHERE is_query_processed = 0;""); if(rs.first()) { // there's stuff to do } else { // rs was empty } References ResultSet (Java Platform SE 6)  The pattern I normally use is as follows: boolean empty = true; while( rs.next() ) { // ResultSet processing here empty = false; } if( empty ) { // Empty result set } this moves the cursor forward right ? so for further processing  the first record might be missed. You would miss the first record if you are processing records after this code. However I usually process the records inside the same while loop. (Where the ""//ResultSet processing here comment"" is.) This works as expected and includes all rows. The downside it that you cannot just stick the check into a method.  You can do this too: rs.last(); int numberOfRows = rs.getRow(); if(numberOfRows) { rs.beforeFirst(); while(rs.next()) { ... } }"
387,A,Extracting time zone from Oracle JDBC TIMEZONETZ object Is there a way to extract timezone information directly from an oracle.sql.TIMESTAMPTZ object (selected from a TIMESTAMP WITH TIME ZONE column)? Ideally I'd like to be able to pull the time zone information directly out of the object without jumping through potentially expensive or fragile hoops (like converting things into strings and parsing those). You would think that there is an easy way to do this but I have yet to find one. Oracle's documentation is not very helpful. It claims the last two bytes returned by TIMESTAMPTZ#toBytes() encode the timezone information but there is no description of our to actually decode this information. Anyone out there have any experience dealing with this stuff? Oracle has specific date format elements for these: TZD TZH TZM and TZR. An example: SQL> create table t (col timestamp with time zone) 2 / Tabel is aangemaakt. SQL> insert into t values (sysdate) 2 / 1 rij is aangemaakt. SQL> select col 2  to_char(col'TZD') time_zone_daylight_info 3  to_char(col'TZH') time_zone_hour 4  to_char(col'TZM') time_zone_minute 5  to_char(col'TZR') time_zone_region 6 from t 7 / COL TIME_Z TIM TI TIME_ZONE_REGION ------------------------------- ------ --- -- -------------------------------- 22-05-09 09:12:33000000 +02:00 +02 00 +02:00 1 rij is geselecteerd. Or using the EXTRACT function: SQL> select col 2  extract(timezone_abbr from col) time_zone_abbr 3  extract(timezone_hour from col) time_zone_hour 4  extract(timezone_minute from col) time_zone_minute 5  extract(timezone_region from col) time_zone_region 6 from t 7 / COL TIME_ZONE_ TIME_ZONE_HOUR TIME_ZONE_MINUTE ------------------------------- ---------- -------------------------------------- -------------------------------------- TIME_ZONE_REGION ---------------------------------------------------------------- 22-05-09 09:15:24000000 +02:00 UNK 2 0 UNKNOWN 1 rij is geselecteerd. Regards Rob. Thanks. I don't suppose there is a way to do this without using format elements or the extract function (i.e. I have an existing application I'd like to make timezone-aware and it would be nice if I could do this without changing all the existing SQL statements)? Not that I'm aware of. This post seems to suggest the same: http://stackoverflow.com/questions/223096?sort=oldest. You can of course apply the Chinese method: setting to all possible time zone information and watch the last two bytes ...
388,A,"Not recognizing Date Type in Java MySQL DB Call I have the following calls in one of my classes @Override public Integer save(NewsItem item){ ConnectionPool pool = new ConnectionPool(); Connection connection = pool.getConnection(); PreparedStatement ps = null; try{ String query = ""INSERT INTO newsItem (typetitlecontentlinklayoutimageUritimestamp)"" + ""VALUES (???????)""; ps = connection.prepareStatement(query); ps.setInt(1item.getType()); ps.setString(2item.getTitle()); ps.setString(3item.getContent()); ps.setString(4item.getLink()); ps.setInt(5item.getLayout()); ps.setString(6item.getImageUri()); ps.setDate(7item.getTimestamp()); return ps.executeUpdate(); } catch(SQLException e){ e.printStackTrace(); return 0; } finally{ ConnectionUtility utility = new ConnectionUtility(); utility.closePreparedStatement(ps); pool.freeConnection(connection); } } The NewsItem POJO has the following properties  private Integer id; private Integer type; private String title; private String content; private String link; private Integer layout; private String imageUri; private Date timestamp; Everything works and has been tested except for the timestamp call which is ps.setDate(7item.getTimeStamp()) I am able to set the Date on the NewsItem object by calling item.setTimestamp(new Date()); but I get the error from my IDE (Eclipse) that tells me the following message The method setDate(intDate) in the type NewsItemDAO is not applicable for the arguments setDate(intDate) This has been a plague for me throughout the life of this application I have been working on because I have had to result to storing the timestamps as string for the time being. If the column in my MySQL database is of type DATETIME is there a different way I should be saving that timestamp? Or is there something wrong with the call? The setDate() expects java.sql.Date not java.util.Date. ps.setDate(7 new java.sql.Date(item.getTimestamp().getTime())); But the java.sql.Date contains only the date part of datetime not the time part. You'd like to use java.sql.Timestamp instead. ps.setTimestamp(7 new Timestamp(item.getTimestamp().getTime())); Does this method work well with MySQL and can I still use java.sql.Timestamp the way Java.util.Date is used? Should the MySQL datatype for this be TIMESTAMP or DATETIME? You should not use `java.sql.Timestamp` in your model object (POJO as you call it). Use it only during persisting in DB. On retrieving you can just upcast `ResultSet#getTimestamp()` to `java.util.Date`. As to the types you can use both. The difference is only that `TIMESTAMP` is implicitly converted to UTC timezone and thus more recommended to avoid timezone headaches and unportability. excellent! I made the changes. Everything looks great as long as I can go back and forth with the Date type on my POJO and the value when I pull it out of the Database. You're welcome.  Check your imports - My guess is that you are using java.util.Date instead of java.sql.Date. If possible it's a good idea to use java.sql.Timestamp which extends java.util.Date to avoid this confusion and enhance the readability of your code. The problem is in this particular case not in the imports. The `Timestamp` recommendation is however seconded but not only due to readability."
389,A,"How to search and insert a value using java code?  String link = ""http://hosted.ap.org""; I want to find whether the given url is already existing in the SQL DB under the table name ""urls"". If the given url is not found in that table i need to insert it in to that table. As I am a beginner in Java I cannot really reach the exact code. Please advise on this regard on how to search the url in the table. I am done with the SQL Connection using the java code. Please advise me on the searching and inserting part alone as explained above. For what database? And the table - it's called `URLS` but what are the columns in it? What have you tried so far because we aren't here to provide you end-to-end solutions. LNADWEEK is the database name. I am done with the SQL Connection part. There is only one column in it named URL which has a list of 20000 URLs. @BalusC could u please pitch in for this??? Some suggestions here  PreparedStatement insert = connectin.preparedStateme(""insert into urls(url) vlaues(?)""); PreparedStatement search = connectin.preparedStateme(""select * from urls where url = ?""); search.setString(1 <your url value to search>); ResultSet rs = search.executeQuery(); if (!rs.hasNext()) { insert.setString(1 <your url value to insert>); insert.executeUpdate(); } //finally close your statements and connection ... i assumed that you only have one field your table and field name is url. if you have more fields you need to add them in insert query.  You need to distinguish between two completely separate things: SQL (Structured Query Language) is the language which you use to communicate with the DB. JDBC (Java DataBase Connectivity) is a Java API which enables you to execute SQL language using Java code. To get data from DB you usually use the SQL SELECT statement. To insert data in a DB you usually use the SQL INSERT INTO statement To prepare a SQL statement in Java you usually use Connection#prepareStatement(). To execute a SQL SELECT statement in Java you should use PreparedStatement#executeQuery(). It returns a ResultSet with the query results. To execute a SQL INSERT statement in Java you should use PreparedStatement#executeUpdate(). See also: SQL tutorial JDBC tutorial thanks for the differentiation Balus You're welcome."
390,A,"Using JDBC driver to connect with Sql Server 2008 I'm using following code to connect with Sql Server 2008: Connection con = null; CallableStatement stmt = null; ResultSet rs = null; try { SQLServerDataSource ds = new SQLServerDataSource(); ds.setIntegratedSecurity(false); ds.setServerName(""localhost""); ds.setInstanceName(""MSSQLSERVER2008""); ds.setPortNumber(1433); ds.setUser(""televic-edu3-dev""); ds.setPassword(""internal""); ds.setDatabaseName(""televic-edu3-dev""); con = ds.getConnection(); ... It gives me following error: Login failed for user 'televic-edu3-dev'. The user is not associated with a trusted SQL Server connection. Mixed mode is enabled on my SqlServer instance. I already tried connecting to my SqlServer instance with the same credentials which works. In .NET it does work with a connectionString which has the same credentials... So what am I doing wrong? This is the connectionString from .NET: TLV-EDU-LIC\MSSQLSERVER2008;Password=internal;Persist Security Info=True;User ID=televic-edu3-dev;Initial Catalog=televic-edu3-dev I also tried this by the way which gives me the same error (which is logical): Connection con = null; Statement stmt = null; ResultSet rs = null; try { String connectionUrl = ""jdbc:sqlserver://localhost:1433;"" + ""instanceName=MSSQLSERVER2008;databaseName=televic-edu3-dev; userName=televic-edu3-dev;password=internal;""; Class.forName(""com.microsoft.sqlserver.jdbc.SQLServerDriver""); con = DriverManager.getConnection(connectionUrl); You're using domain (Windows username) authentication rather than DB authentication. Ensure that the JVM is running with the same Windows username and thus not as a system service. If that's not an option use DB authentication instead. Didn't see that. I was just translating the error message into easy-to-understand words :) Odd that omitting the portnumber changes things a lot. ds.setIntegratedSecurity(false);  Well omitting the ds.setPortNumber(1433); makes it work. Don't know why... my sqlserver instance is running on port 1433."
391,A,"How do I know Connection Pooling and Prepared Statements are working? I have been developing a web application for almost a year which I had started in college. After finishing I made some changes to the database code that I had written during college. I used simple JDBC when I was in college without the use of connection pooling and prepared statements. In the past month I have realized the potential and need to use connection pooling and prepared statements because of the increase in data being queried and used. I have implemented the connection pooling but have not really noticed an increase in performance. If there was an increase in performance then my question would be answered but how can I validate that connection pooling and prepared statements are being used properly? Just benchmark (stresstest) it. Use [JMeter](http://jakarta.apache.org/jmeter/). You won't see a performance improvement if opening and closing connections wasn't rate-limiting. Try looking at your database's profiling tools for a list of open connections. If you see open connections from your process when you have ostensibly closed them the interface layer is doing connection pooling. See also this other SO question on forcing a pooled connection to drop. (Caveat:I use ADO and ADO.NET; JDBC might behave differently.)  I think prepared statement is more important from a security than a performance standpoint. If you are using them cool you really should be. As long as 100% of your SQL is a prepared statement you are ""using them right""... Connection pooling is something you won't notice under light load. 1 or 2 or 10 users you will likely see 0 or near 0 difference. You would need to create some kind of load testing test to simulate 100s of simultaneous users then compare performance with and without pooling. Noted should be that using `PreparedStatement` certainly gives a performance advantage since they are prepared compiled and cached once in DB and reused forever. However like as with connection pooling the performance difference is completely negligible if you're the only one who is using the webapp :) @BalusC That depends on the DB and on the DB driver. Some won't compile them at all some will after the same PreparedStatement instance has been used X number of times. Some will even make more roundtrips to the DB 1 packet for the SQL one for sending the actual parameters. @nos Which DB's might those be? Of course I don't mean a comprehensive list but I've dealt with most of the ""big"" db's and I include even HSQLDB in that and all of them are significantly faster with prepared statements. TIA @nos: Yes it depends on the DB. In practice fortunately there are a lot of decent DB's.  You ask the connection pool for statistics to see if it works. If the connection pool library does not provide statistics find a better library."
392,A,"How to sort the MySql Database? I have stored various records in the MySql database ""orkut"". Now I want to sort that database through a java program. I have connected to the database through the jdbc driver. Now I want to sort that database in decreasing order of the field ""number"" of type ""int"" but don't know the commands. I have ""con"" reference variable which denotes the connection to the MySql database. One more thing there is a field ""sr_no"" that denotes the serial no. of the record and it is not the primary key. I want that this field won't change after sorting the database as the serial no. should not change on changing the order of the records. I want this sorting permanently stored on the same database. I don't want sorted ResultSet. I want sorted database. BTW what you call 'database' is actual called table. Database is set of tables. Do you work with DBase III DBF's before? :) as eric told you can't have a permanently sorted database. But if you want to execute this query on a large dataset very frequently then you can do indexing supported by various database. It will speedup your searching and sorting for a particular key. Yes I need to perform this for a very large dataset. It contains millions of records. Can you please explain me how to do this with using the indexing of MySQL. I am using MySQL. I am upvoting you for this. just you need to create index for table and while sorting use select number sr_no from tbl order by number desc  Don't try to sort this through Java--you'll kill yourself trying. SQL has an order by clause that does exactly this. Here's the SQL: select number sr_no from tbl order by number desc Also note that you cannot have a permanently sorted database. The way that the data is stored does not lend itself to being stored in whatever order you choose. You should never count on the order of a database to be the same unless you use an order by in your query. +1 - another nice answer. +1 ""you'll kill yourself trying"" - listen to this person."
393,A,"how to do hibernate mapping for table or view without a primary key Possible Duplicate: Hibernate and no PK Anyone knows how to do hibernate mapping for table or view without a primary key? see http://stackoverflow.com/questions/767277/hibernate-and-no-pk I would do this only when you are reading data (not writing it). When you have a DB like oracle you can have statements like select DOKUMENT.* ROWID from DOKUMENT → and thus you can add this statement into the Hibernate mapping: <id column=""ROWID"" type=""string"" /> subsequently you define all other columns as <property... When you use the reverse engineering Wizard you can remove the composite-key tag search and replace key-property for property and insert above line  Don't think Hibernate allows mapping a table without a primary key...think about how Hibernate would perform updates without a column that can uniquely identify a row. I guess a work-around would be to use a composite key with all columns but you are much better off adding a primary key. I think you are correct here. Also the composite key (of all columns) would still need to be primary so your better off making a more reasonable composite key or choosing a uniquely identifying column as the primary key. I don't know that it matters too much in a read-only situation (wrt udpates). sowhen I select from a view without a primary key and dont want t oupdate view what should I do?"
394,A,Database agnostic jdbc table import/export to files? Is it at all possible to do database-agnostic table dumps/hydrates? I don't have any complicated constraints. I would also settle for db-specific ways but the more pure jdbc it is the better (I don't want to resort to impdp/expdp). DBUnit looks good however you probably are not going to beat the vendor tools for import/export. If you are going to be importing or exporting 100000+ rows it's probably best to use impdp/expdp. I've also done strange things like building an insert statement from a sql query and then using sqlplus to process. [select 'insert into table values ( ...'||column||' ...) ] But i was being lazy and didn't want to create a sqlldr or jdbc insert program. I've used perl the same way for when i needed larger imports.  Have a look at DBUnit. DBUnit support exporting to a xml file and importing from a xml file. Their faq has some advice on how to make the export / imports fast be sure to check that out.  If it's a small volume of data some programs (like Aqua Data Studio) can export data as a sequence of SQL 'INSERT' statements.
395,A,Multiple conditions within WHERE clause This query is working fine: SELECT * FROM tablename where Date >'20091109' and id='11'; But below this query does not return anything. SELECT * FROM tablename WHERE Date BETWEEN ('20091109' AND '20081010') AND id='11'; You need to put the 20081010 _before_ the 20091109. between ('20091109' and '20081010') This is anything after 9th Nov 2008 and before 10th Oct 2008. Of course if show nothing. Do you mean this which is 10 Oct 2008 to 8th Nov 2009 inclusive Date >= '20081010' AND Date < '20091109' or this which is 10 Oct 2008 to 9th Nov 2009 inclusive Date >= '20081010' AND Date < '20091110' Edit: Removed SQL Server references   SELECT * FROM tablename where Date between '20081010' and '20091109' and id='11';
396,A,"Reading Unicode data from an Access database using JDBC I have an MS-Access database which I am connecting to in Java using the JDBC (I think the JDBC-ODBC bridge). My access database has some values which are in hebrew. When I try to read these values using String str = rs.getString(1) (rs is a RowSet) the string I get is just a string of question marks. I have other strings in hebrew which I set in the Java code using string literals and they work fine. So I'm pretty sure the problem is specifically with reading from the db. I'm very new to this whole thing so I could easily be missing something stupid... I searched Google for a while and didn't come up with anything except some people saying that there's a chance this kind of thing is not supported (say somewhere that the JDBC-ODBC bridge has a bug with regards to Unicode but it was from 2005 so who knows?). I'd appreciate any help thanks. Have you tried to set the charSet prior to calling the query? Refer to: http://java.sun.com/j2se/1.4.2/docs/guide/jdbc/bridge.html Nope just isn't working. When I switch from windows-hebrew to UTF8 I get strings of ???? again. To make sure I understand the only thing I need to do is pass JDBC an extra parameter - (charSet ""UTF8"") and that's it? Then the string I get back should be ok? Well that is if your data is UTF8 of course! In your case though if all data is hebrew and windows-1255/windows-hebrew encoding is working you should not worry about UTF8 then. Sorry I missed the fact that all data may be hebrew. My previous comment seems to have been deleted? Not sure why. I tried setting the charSet to various things (including utf-8 and utf-16). They either didn't work or gave me a IllegalArgumentException. However using your link I tried another encoding which seems to have done the trick (windows-hebrew). Is this the correct way to work? It seems to me like I'd prefer unicode over flat-out specifying that it's in hebrew. ummm... UTF8 should work! I use utf8 for Farsi Chars. Please visit the supported encodings for more details: http://java.sun.com/j2se/1.4.2/docs/guide/intl/encoding.doc.html"
397,A,"PreparedStatement with list of parameters in a IN clause How to set value for in clause in a preparedStatement in JDBC while executing a query. Example: connection.prepareStatement(""Select * from test where field in (?)""); If this in-clause can hold multiple values how can I do it. Sometimes I know the list of parameters beforehand or sometimes I don't know beforehand. How to handle this case? Lot of dupes: http://stackoverflow.com/questions/2861230/what-is-the-best-approach-using-jdbc-for-parameterizing-an-in-clause http://stackoverflow.com/questions/2510083/preparedstatement-question-in-java-against-oracle and http://stackoverflow.com/questions/178479/alternatives-for-java-sql-preparedstatement-in-clause-issue What I do is to add a ""?"" for each possible value. For instace: List possibleValues = ... String builder = new StringBuilder(); for( int i = 0 ; i < possibleValue.size(); i++ ) { builder.append(""?""); } String stmt = ""select * from test where field in "" + builder.deleteCharAt( builder.length() -1 ).toString(); PreparedStatement pstmt = ... And then happily set the params int index = 1; for( Object o : possibleValue ) { pstmt.setObject( index++ o ); // or whatever it applies } Depending on the maximum length of the list this can lead to a huge number of prepared statements possibly impacting database performance.  What you can do is dynamically build the select string (the 'IN (?)' part) by a simple for loop as soon as you know how many values you need to put inside the IN clause. You can then instantiate the PreparedStatement.  You might want to check this link: http://www.javaranch.com/journal/200510/Journal200510.jsp#a2 It explains the pros and cons of different methods of creating PreparedStatement with in clause. EDIT: An obvious approach is to dynamically generate the '?' part at runtime but I don't want to merely suggest just this approach because depending on the way you use it it might be inefficient (since the PreparedStatement will need to be 'compiled' every time it gets used)  public class Test1 { /** * @param args */ public static void main(String[] args) { // TODO Auto-generated method stub System.out.println(""helow""); String where=(new StringBuilder()).append(""where task in "").toString(); where=(new StringBuilder()).append(where).append(""("").toString(); // where=(new StringBuilder()).append(where).append(""'task1'"").toString(); int num[]={1234}; for (int i=0;i<num.length+1;i++) { if(i==1){ where =(new StringBuilder()).append(where).append(""'"").append(i).append(""'"").toString(); } if(i>1 && i<num.length) where=(new StringBuilder()).append(where).append("""").append(""'"").append(i).append(""'"").toString(); if(i==num.length){ System.out.println(""This is last number""+i); where=(new StringBuilder()).append(where).append("""").append(""'"").append(i).append(""'"").append("")"").toString(); } } System.out.println(where); } }  Many DBs have a concept of a temporary table even assuming you don't have a temporary table you can always generate one with a unique name and drop it when you are done. While the overhead of creating and dropping a table is large this may be reasonable for very large operations or in cases where you are using the database as a local file or in memory (SQLite). An example from something I am in the middle of (using Java/SqlLite): String tmptable = ""tmp"" + UUID.randomUUID(); sql = ""create table "" + tmptable + ""(pagelist text not null)""; cnn.createStatement().execute(sql); cnn.setAutoCommit(false); stmt = cnn.prepareStatement(""insert into ""+tmptable+"" values(?);""); for(Object o : rmList){ Path path = (Path)o; stmt.setString(1 path.toString()); stmt.execute(); } cnn.commit(); cnn.setAutoCommit(true); stmt = cnn.prepareStatement(sql); stmt.execute(""delete from filelist where path + page in (select * from ""+tmptable+"");""); stmt.execute(""drop table ""+tmptable+"");""); This would be even more efficient if you are able toreuse the table.  You can't replace ? in your query with an arbitrary number of values. Each ? is a placeholder for a single value only. To support an arbitrary number of values you'll have to dynamically build a string containing ? ? ? ...  ? with the number of question marks being the same as the number of values you want in your in clause."
398,A,"How to quote/escape identifiers such as column names with JDBC? Different database servers use different ways to quote and escape identifiers. E.g. ""foo bar"" vs `foo bar` vs [foo bar] or ""10"""""" vs ""10\"""" or identifiers such as FooBar or array need to be quoted for some databases but not for others. Is there any API method that performs the quoting/escaping correctly for a given database connection? Or any alternative solution? I think the answer to your question is that if you are writing a database neutral application using JDBC then you need to use database neutral names and not things that require special escaping per database vendor. There is nothing I know of in the JDBC which supports that. A ORM product will deal with such things. Edit: If you are writing an ORM then I would think need a seperate SQL generation class for each supported database just to handle the various syntax involved so you would have to write that. You can certainly look at the source code of the various open source ORM's out there and see how they handle it. Good point about database-neutral names but surprises can still appear (e.g. a certain identifier may not be acceptable in another database). Also what if I'm.. actually writing an ORM? Would it require a separate hand-coded quote/escape implementation for each supported database? Stick to the rules for identifier naming in the SQL standard. Those will work anywhere. @CraigRinger I amend my previous comment to ""Stick to the standard AND LOSE THE BAD HABITS YOU PICKED UP FROM USING MySQL - It's an abomination and it's not SQL"". I've never had to quote an identifier in 20+ years of doing SQL on Oracle Sybase Postgres even SQLlite. @PaulTomblin Heh dedicated PostgreSQL user here. There's the odd time it's been necessary for me in contexts where Pg's parser struggles to differentiate between an unreserved keyword and a user identifier but in general it's not overly problematic. I'm just irritated that the JDBC spec makes it harder than it should be for applications to defensively quote identifiers and for the JDBC driver to expose its knowledge of correct quoting. (Which unless you're MySQL or MS SQL Server is ANSI SQL quoting anyway) @PaulTomblin Heh yeah the ""standard"". There's a whole lot of flexibility in the spec - and vendors add their own keywords and reserved words which must be quoted if the application is to use them. I agree that trying to stick to the spec is the least painful option but it *sucks* that JDBC doesn't expose a `java.sql.Connection.quoteIdentifier(...)` or `DatabaseMetaData.quoteIdentifier(...)` method and backing SPI as it means you're always doing the reserved-word dance. `getIdentifierQuoteString` doesn't do the job it doesn't express the quoting rules.  Have a look at DatabaseMetaData.getIdentifierQuoteString() I never used it but it sounds good :-) getExtraNameCharacters() could also be of some help Not a complete solution but definitely useful!  Don't escape identifiers. Don't quote column values either - use bound queries with PreparedStatement. It's a lot safer from SQL injection attacks. What if the database I'm accessing uses identifiers that actually require quoting? PreparedStatement is great for passing values but what about identifiers? You shouldn't be using names that need quoting. Yishai's answer is pretty on the mark. That's good when I can choose the names myself but it's not always the case. There are legacy databases and many other situations plus I may be writing some generic code that doesn't know the actual names (e.g. they're passed as parameters)."
399,A,"How to get a value from the last inserted row? Is there some way to get a value from the last inserted row? I am inserting a row where the PK will automatically increase and I would like to get this PK. Only the PK is guaranteed to be unique in the table. I am using Java with a JDBC and PostgreSQL. I am using JDBC 4 so the Statement.RETURN_GENERATED_KEYS did not work. I've got this error message: ""org.postgresql.util.PSQLException: Returning autogenerated keys is not supported."" But the PostgresSQL - RETURNING did work. Since PostgreSQL JDBC driver version 8.4-701 the PreparedStatement#getGeneratedKeys() is finally fully functional. We use it here almost one year in production to our full satisfaction. In ""plain JDBC"" the PreparedStatement needs to be created as follows to make it to return the keys: statement = connection.prepareStatement(SQL Statement.RETURN_GENERATED_KEYS); You can download the current JDBC driver version here (which is at the moment still 8.4-701).  Use that simple code: // Do your insert code myDataBase.execSQL(""INSERT INTO TABLE_NAME (FIELD_NAME1FIELD_NAME2...)VALUES (VALUE1VALUE2...)""); // Use the sqlite function ""last_insert_rowid"" Cursor last_id_inserted = yourBD.rawQuery(""SELECT last_insert_rowid()"" null); // Retrieve data from cursor. last_id_inserted.moveToFirst(); // Don't forget that! ultimo_id = last_id_inserted.getLong(0); // For Java the result is returned on Long type (64)  PreparedStatement stmt = getConnection(PROJECTDB + 2) .prepareStatement(""INSERT INTO fonts (font_size) VALUES(?) RETURNING fonts.*""); stmt.setString(1 ""986""); ResultSet res = stmt.executeQuery(); while (res.next()) { System.out.println(""Generated key: "" + res.getLong(1)); System.out.println(""Generated key: "" + res.getInt(2)); System.out.println(""Generated key: "" + res.getInt(3)); } stmt.close();  See the API docs for java.sql.Statement. Basically when you call executeUpdate() or executeQuery() use the Statement.RETURN_GENERATED_KEYS constant. You can then call getGeneratedKeys to get the auto-generated keys of all rows created by that execution. (Assuming your JDBC driver provides it.) It goes something along the lines of this: Statement stmt = conn.createStatement(); stmt.execute(sql Statement.RETURN_GENERATED_KEYS); ResultSet keyset = stmt.getGeneratedKeys(); Nicely database agnostic. Oh if it were that easy. Unfortunately this doesn't work unless you have the correct Postgres driver version and even then the ResultSet has *all* of the fields and not just the generated id ones. Aye does not work for PostgreSQL As far as I know getGeneratedKeys() works only for the JDBC drivers that implement it. The correct thing would be IMHO to run `dmd = conn.getMetadata()` and then run `dmd.supportsGetGeneratedKeys()` to see whether this capability is supported or not.  Use sequences in postgres for id columns: INSERT mytable(myid) VALUES (nextval('MySequence')); SELECT currval('MySequence'); currval will return the current value of the sequence in the same session. (In MS SQL you would use @@identity or SCOPE_IDENTITY())  If you are using Statement go for the following //MY_NUMBER is the column name in the database String generatedColumns[] = {""MY_NUMBER""}; Statement stmt = conn.createStatement(); //String sql holds the insert query stmt.executeUpdate(sql generatedColumns); ResultSet rs = stmt.getGeneratedKeys(); // The generated id if(rs.next()) long key = rs.getLong(1); If you are using PreparedStatement go for the following String generatedColumns[] = {""MY_NUMBER""}; PreparedStatement pstmt = conn.prepareStatement(sqlgeneratedColumns); pstmt.setString(1 ""qwerty""); pstmt.execute(); ResultSet rs = pstmt.getGeneratedKeys(); if(rs.next()) long key = rs.getLong(1);  The sequences in postgresql are transaction safe. So you can use the currval(sequence) Quote: currval Return the value most recently obtained by nextval for this sequence in the current session. (An error is reported if nextval has never been called for this sequence in this session.) Notice that because this is returning a session-local value it gives a predictable answer even if other sessions are executing nextval meanwhile. Isn't it possible that another transaction could change the value of the sequence between his INSERT and his SELECT currval() ? I'm assuming that each of those operations would take place in separate transactions. No. that exactly what the currval function is for.  PostgresSQL - RETURNING INSERT INTO mytable( field_1 field_2... ) VALUES ( value_1 value_2 ) RETURNING anyfield It will return the value of ""anyfield"". ""anyfield"" may be a sequence or not. Hope it helps Use RETURNING ""ID"" assuming the name of your PK is ID. This is certainly the right SQL method but the question asked how to do this with JDBC and the other half of the problem is how to execute the statement. As mentioned in other answers you either need to use `executeQuery()` (returns a ResultSet) instead of `executeUpdate()` (returns number of rows updated) OR use the `RETURN_GENERATED_KEYS` option to activate the ability to call `getGeneratedKeys()` method after calling `executeUpdate()`.  Here is how I solved it based on the answers here: Connection conn = ConnectToDB(); //ConnectToDB establishes a connection to the database. String sql = ""INSERT INTO \""TableName\"""" + ""(\""Column1\"" \""Column2\""\""Column3\""\""Column4\"")"" + ""VALUES ('value1'value2 'value3' 'value4') RETURNING \""TableName\"".\""TableId\""""; PreparedStatement prpState = conn.prepareStatement(sql); ResultSet rs = prpState.executeQuery(); if(rs.next()){ System.out.println(rs.getInt(1)); }  For MyBatis 3.0.4 with Annotations and Postgresql driver 9.0-801.jdbc4 you define an interface method in your Mapper like public interface ObjectiveMapper { @Select(""insert into objectives"" + "" (codetitledescription) values"" + "" (#{code} #{title} #{description}) returning id"") int insert(Objective anObjective); Note that @Select is used instead of @Insert.  If you are in a transaction you can use SELECT lastval() after an insert to get the last generated id.  Don't use SELECT currval('MySequence') - the value gets incremented on inserts that fail. So what? He just asked for unique values not contiguous values (which is an impossible goal in a system with parallel abortable transactions). The original question: ""Is there some way to get a value from the last inserted row?"" Code that uses currval(seq) to form a SELECT statement for obtaining the last inserted row may fail to produce expected results.  for example:  Connection conn = null; PreparedStatement sth = null; ResultSet rs =null; try { conn = delegate.getConnection(); sth = conn.prepareStatement(INSERT_SQL); sth.setString(1 pais.getNombre()); sth.executeUpdate(); rs=sth.getGeneratedKeys(); if(rs.next()){ Integer id = (Integer) rs.getInt(1); pais.setId(id); } } with Statement.RETURN_GENERATED_KEYS);"" no found.  If you're using JDBC 3.0 then you can get the value of the PK as soon as you inserted it. Here's an article that talks about how : https://www.ibm.com/developerworks/java/library/j-jdbcnew/ Statement stmt = conn.createStatement(); // Obtain the generated key that results from the query. stmt.executeUpdate(""INSERT INTO authors "" + ""(first_name last_name) "" + ""VALUES ('George' 'Orwell')"" Statement.RETURN_GENERATED_KEYS); ResultSet rs = stmt.getGeneratedKeys(); if ( rs.next() ) { // Retrieve the auto generated key(s). int key = rs.getInt(1); } Note that this won't work for Oracle (I'm using 10g) http://stackoverflow.com/questions/1976625/value-from-last-inserted-row-in-db work nice with postgresql-9.2-1002.jdbc4.jar Thank you for the link"
400,A,"Find Oracle JDBC driver in Maven repository I want to add the oracle jdbc driver to my project as dependency (runtime scope) - ojdbc14. In MVNrepository site the dependency to put in the POM is: <dependency> <groupId>com.oracle</groupId> <artifactId>ojdbc14</artifactId> <version>10.2.0.3.0</version> </dependency> of course this does't work as it is not in the central repository used by maven. 2 questions: How do I find a repository (if any) that contains this artifact? How do I add it so that Maven will use it? http://maven-repository.com/artifact/com.oracle/ojdbc14/ ojdbc6 in public maven repository: http://stackoverflow.com/questions/9898499/oracle-jdbc-ojdbc6-jar-as-a-maven-dependency There is one repo that provides the jar. In SBT add a resolver similar to this: ""oracle driver repo"" at ""http://dist.codehaus.org/mule/dependencies/maven2"" and a dependency: ""oracle"" % ""ojdbc14"" % ""10.2.0.2"" You can do the same with maven. pom.xml and jar are available (http://dist.codehaus.org/mule/dependencies/maven2/oracle/ojdbc14/10.2.0.2/). Be careful because this pom [http://dist.codehaus.org/mule/dependencies/maven2/oracle/ojdbc14/10.2.0.2/ojdbc14-10.2.0.2.pom](http://dist.codehaus.org/mule/dependencies/maven2/oracle/ojdbc14/10.2.0.2/ojdbc14-10.2.0.2.pom) has no license definition so I don't think it was uploaded by the artifact owner. This answer makes things work but unfortunately expose you to trouble due to [this license term violation](http://stackoverflow.com/questions/1074869/find-oracle-jdbc-driver-in-maven-repository/23723203#23723203).  SOLVED Please do following settings to resolve the error This repository needs to be enable for finding Oracle 10.0.3.0 dependecies (this setting needs to be done in Buildconfig.groovy grails.project.dependency.resolver = ""ivy"" // or ivy Also use following setting for compile time Oracle driver download runtime ""com.oracle:ojdbc:10.2.0.3.0"" This should solve your issue for not finding the Oracle driver for grails application  You can use Nexus to manage 3rd party dependencies as well as dependencies in standard maven repositories. How would nexus help in this case? Where will it download the artifact from? The answer is incomplete but I *think* @Michael Munsey is saying to create an internal/corporate repository to download from. Yes. Set up Nexus then manually download the jars and put them into Nexus so that successive maven builds can pull it from your Nexus instance. @MichaelMunsey Generally speaking suggesting a repository manager like [Artifactory](http://www.jfrog.com/home/v_artifactory_opensource_overview) or [Nexus](http://www.sonatype.org/nexus/) would be a good answer but in the specific case of Oracle JDBC database drivers it isn't a good one because even if it makes things work it unfortunately expose you to trouble due to [this license term violation](http://stackoverflow.com/questions/1074869/find-oracle-jdbc-driver-in-maven-repository/23723203#23723203).  Download the jar and place it in your project src/lib. Now you can use the maven installer plugin. <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-install-plugin</artifactId> <version>2.3.1</version> <executions> <execution> <id>install-oracle-jdbc</id> <goals> <goal>install-file</goal> </goals> <phase>clean</phase> <configuration> <groupId>com.oracle</groupId> <artifactId>ojdbc6</artifactId> <version>11.2.0</version> <packaging>jar</packaging> <generatePom>true</generatePom> <createChecksum>true</createChecksum> <file>${project.basedir}/src/lib/ojdbc6.jar</file> </configuration> </execution> </executions> </plugin> Now you only have to execute mvn clean once and the oracle lib is installed in your local maven repository. Question already answered and accepted very useful alternative !  Some Oracle Products support publishing maven artifacts to a local repository. The products have a plugin/maven directory which contains descriptions where to find those artifacts and where to store them. There is a Plugin from Oracle which will actually do the upload. See: http://docs.oracle.com/middleware/1212/core/MAVEN/config_maven.htm One of the products which may ship OJDBC in this way is the WLS it uses however quite strange coordinates: <groupId>com.oracle.weblogic</groupId> <artifactId>ojdbc6</artifactId> <version>12.1.2-0-0</version>  How do I find a repository (if any) that contains this artifact? Unfortunately due the binary license there is no public repository with the Oracle Driver JAR. This happens with many dependencies but is not Maven's fault. If you happen to find a public repository containing the JAR you can be sure that is illegal. How do I add it so that Maven will use it? Some JARs that can't be added due to license reasons have a pom entry in the Maven Central repo. Just check it out it contains the vendor's preferred Maven info: <groupId>com.oracle</groupId> <artifactId>ojdbc14</artifactId> <version>10.2.0.3.0</version> ...and the URL to download the file which in this case is http://www.oracle.com/technology/software/tech/java/sqlj_jdbc/index.html. Once you've downloaded the JAR just add it to your computer repository with (note I pulled the groupId artifactId and version from the POM): mvn install:install-file -DgroupId=com.oracle -DartifactId=ojdbc14 \ -Dversion=10.2.0.3.0 -Dpackaging=jar -Dfile=ojdbc.jar -DgeneratePom=true The last parameter for generating a POM will save you from pom.xml warnings If your team has a local Maven repository this guide might be helpful to upload the JAR there. It would have been nice if oracle could host a maven repo with their jars... Those are not lines in settings.xml but a command once you have the JAR that command will add it to your local repository @Victor - where do I locate these lines? in settings.xml? @AmanicA it's hard to use ""Oracle"" and ""nice"" in the same sentence... For OJDBC6: 1. mvn install:install-file -DgroupId=com.oracle -DartifactId=ojdbc6 -Dversion=11.2.0.3 -Dpackaging=jar -Dfile=ojdbc6.jar -DgeneratePom=true 2. Add this to pom.xml: com.oracle ojdbc6 11.2.0.3 I wander why Oracle is so ugly that it doesn't care of all public judgements it has. It is bad even in these small things like public availability of their own FREE libraries. Is there any chances to find source code for ojdbc14?  1. How do I find a repository (if any) that contains this artifact? All Oracle Database JDBC Drivers are distribuited under the OTN License Agreement. If you read the OTN License Agreement you find this license term: You may not: ... - distribute the programs unless accompanied with your applications; ... so that's why you can't find the driver's jar in any public Maven Repository because it would be distributed alone and if it happened it would be a license violation. Adding the dependency: <dependency> <groupId>com.oracle</groupId> <artifactId>ojdbc14</artifactId> <version>10.2.0.3.0</version> </dependency> (or any later version) make Maven downloads the ojdbc14-10.2.0.3.0.pom only and in that pom you can read: ... <licenses> <license> <name>Oracle Technology Network Development and Distribution License Terms</name> <url>http://www.oracle.com/technology/software/htdocs/distlic.html</url> </license> </licenses> ... which informs you about the OTN License. 2. How do I add it so that Maven will use it? In order to make the above dependency works I agree with victor hugo who were suggesting you here to manually install the jar into your local Maven repository (the .m2 directory) by running: mvn install:install-file -Dfile={Path_to_your_ojdbc.jar} -DgroupId=com.oracle -DartifactId=ojdbc -Dversion=10.2.0.3.0 -Dpackaging=jar but I want to add that the license term above doesn't limit only where you can't find the JDBC jar but it limits where you install it too! In fact your local Maven repository must be private and not shared because if it was shared it would be a kind of distribution in which the jar is distributed alone even if to a little group of people into your local area network and this represent a OTN License Agreement violation. Moreover I think you should avoid installing the JDBC jar in your corporation repository manager (such as Artifactory or Nexus) as a single artifact because if it was installed it would be still distributed alone even if to people in your organization only and this represents a OTN License Agreement violation.  Up to now its not possible to use maven repositories. I'm using ivy as dependency management tool but also use maven2' s ibiblio repositories. And this is working for ivy: <dependency org=""oracle"" name=""ojdbc14"" rev=""10.2.0.2"" conf=""*->default""/> Maven2' s dependency could be something like that: <dependency> <groupId>oracle</groupId> <artifactId>ojdbc14</artifactId> <version>10.2.0.2</version> </dependency> Notice that i define http://download.java.net/maven/2/ and http://mirrors.ibiblio.org/pub/mirrors/maven/mule/dependencies/maven2/[organisation]/[module]/[revision]/[artifact]-[revision].[ext] as external maven2 repos on my ivy settings. This is a great answer - you can just add the repo: http://mirrors.ibiblio.org/pub/mirrors/maven/mule/dependencies/maven2 to your pom.xml for this to work. It might work but is it legal? As explained in one of the other answers here Oracle doesn't allow the driver to be distributed by anybody but them and they don't supply a Maven repository. If you use this solution sometime the driver may be removed from the repository when you least expect it. @Grouchal This answer makes things work but unfortunately expose you to trouble due to [this license term violation](http://stackoverflow.com/questions/1074869/find-oracle-jdbc-driver-in-maven-repository/23723203#23723203).  For whatever reason I could not get any of the above solutions to work. (Still can't.) What I did instead was to include the jar in my project (blech) and then create a ""system"" dependency for it that indicates the path to the jar. It's probably not the RIGHT way to do it but it does work. And it eliminates the need for the other developers on the team (or the guy setting up the build server) to put the jar in their local repositories. UPDATE: This solution works for me when I run Hibernate Tools. It does NOT appear to work for building the WAR file however. It doesn't include the ojdbc6.jar file in the target WAR file. 1) Create a directory called ""lib"" in the root of your project. 2) Copy the ojdbc6.jar file there (whatever the jar is called.) 3) Create a dependency that looks something like this: <dependency> <groupId>com.oracle</groupId> <artifactId>ojdbc</artifactId> <version>14</version> <scope>system</scope> <systemPath>${basedir}/lib/ojdbc6.jar</systemPath> <!-- must match file name --> </dependency> Ugly but works for me. To include the files in the war file add the following to your pom <build> <finalName>MyAppName</finalName> <plugins> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-war-plugin</artifactId> <configuration> <webResources> <resource> <directory>${basedir}/src/main/java</directory> <targetPath>WEB-INF/classes</targetPath> <includes> <include>**/*.properties</include> <include>**/*.xml</include> <include>**/*.css</include> <include>**/*.html</include> </includes> </resource> <resource> <directory>${basedir}/lib</directory> <targetPath>WEB-INF/lib</targetPath> <includes> <include>**/*.jar</include> </includes> </resource> </webResources> </configuration> </plugin> <plugin> <artifactId>maven-compiler-plugin</artifactId> <configuration> <source>1.6</source> <target>1.6</target> </configuration> </plugin> </plugins> </build> I actually like this solution because it does not require setting up nexus there are typically only 1 or 2 jars like this in a project and it simplifies other developers setup on the project because they don't have to update their local .m2 env. (oracle being the prime candidate for this). Also if you update your source repo with a new oracle jar all developers get it on next pull. added info on how to add the jar files to the WAR file"
401,A,"Array not showing in Jlist but filled in console Hey there. been a busy debugger today. ill give ths short version. ive made an array list that takes names from a database. then i put the contents of the arraylist into an array of strings. now i want too display the arrays contents in a JList. the weird thing is it was working earlier. and ive two methods. ones just a little practice too make sure i was adding to the Jlist correctly. so heres the key codes. this is the layout of my code. variables constructor methods in my variables i have these 3 defined String[] contactListNames = new String[5]; ArrayList<String> rowNames = new ArrayList<String>(); JList contactList = new JList(contactListNames); simple enough. in my constructor i have them again. contactListNames = new String[5]; contactList = new JList(contactListNames); //i dont have the array list defined though. printSqlDetails(); // the prinSqldetails was too make sure that the connectionw as alright. and its working fine. fillContactList(); // this is the one thats causing me grief. its where all the work happens. // fillContactListTest(); // this was the tester that makes sure its adding to the list alright. heres the code for fillContactListTest()  public void fillContactListTest() { for(int i = 0;i<3;i++) { try { String contact; System.out.println("" please fill the list at index ""+ i); Scanner in = new Scanner(System.in); contact = in.next(); contactListNames[i] = contact; in.nextLine(); } catch(Exception e) { e.printStackTrace(); } } } heres the main one thats supposed too work. public void fillContactList() { int i =0; createConnection(); ArrayList<String> rowNames = new ArrayList<String>(); try { Statement stmt = conn.createStatement(); ResultSet namesList = stmt.executeQuery(""SELECT name FROM Users""); try { while (namesList.next()) { rowNames.add(namesList.getString(1)); contactListNames =(String[])rowNames.toArray(new String[rowNames.size()]); // this used to print out contents of array list // System.out.println("""" + rowNames); while(i<contactListNames.length) { System.out.println("" "" + contactListNames[i]); i++; } } } catch(SQLException q) { q.printStackTrace(); } conn.commit(); stmt.close(); conn.close(); } catch(SQLException e) { e.printStackTrace(); } } i really need help here. im at my wits end. i just cant see why the first method would add to the JList no problem. but the second one wont. both the contactListNames array and array list can print fine and have the names in them. but i must be transfering them too the jlist wrong. please help p.s im aware this is long. but trust me its the short version. nb i get the same problem when i put the arrayList straight into the JList. still doesnt show You need to call contactList = new JList(contactListNames); after fillContactList(); Because inside the fillContactList() you're replacing the contactListNames reference instead of filling it. That said and unrelated to the described problem there are more odds in the code but you'll find them out sooner or later I think :) (the code is leaking JDBC connections the code flow is inefficient the code is not arranged in an intuitive OO way etc.. but again this has all nothing to do with the described problem). didnt change anything. sorry Then the problem lies somewhere else than in the as far provided information. Try to [ask your question the smart way](http://catb.org/esr/faqs/smart-questions.html) and provide an [SSCCE](http://sscce.org) (so that we can just copy'n'paste the code **unchanged** compile and exectute it to see the same problem). Please also work on your attitude I am not sure if it is the language barrier but you sound *very* rude in your last sentence. Certainly I am eager to help but you have first to help us to help you. I apologize. reading back on it now it was quite a bad comment for me to make. it wasnt meant too come across as rude but regardless it was a BIG mistake on my part. Im a beginner with java but not with manners. i really do appreaciate the help and hope you accept my sincere apologies. I'm eager to learn and in no way want to seem disrespectfull. p.s SSCCE is a hard topic to research and i want even aware of it until now. ill research ti some more. thanks you. No problem. With regard to the SSCCE: just create a class with a `main()` method which demonstrates/reproduces exactly the same problem in a single run and copypaste the entire source."
402,A,Detect Database Currently in Use with Java Is there a way to detect the ODBC database currently being connected to with Java? For example I would like to know whether an application is currently connected to Oracle 10g or SQL Server 2005. Thanks in advance. Who is making the connection to the database? Isn't it your application making the connection? So wouldn't you know if you loaded the Oracle or MSSQL configuration? If you have java.sql.Connection class getMetaData method will return database information. From DatabaseMetaData object you can retrieve all kinds of stuff like driver name or connection url to determine your kind of server. edit There's also getDatabaseProductName method there.  Why not extract it from the driver that is in use? IE if your currently using com.mysql.jdbc.Driver then you know that your using MySQL. You are passing the driver class name to something right? Often you use frameworks to access Connection object (e.g. application servers manage transactions and connection pools for you you do not create Connection object yourself there). Not sure what's the case here though.
403,A,"JDBC ResultSet getDate losing precision I am losing precision in my ResultSet.getDate(x) calls. Basically: rs = ps.executeQuery(); rs.getDate(""MODIFIED""); is returning dates truncated to the day where MODIFIED is an Oracle TIMESTAMP field of default precision. I think there may be some JDBC tweak I'm missing; usually TIMESTAMP is compatible with DATE but I'm hoping I don't have to redefine the entire table. You should use java.sql.Timestamp instead of java.sql.Date. You can use it as a java.util.Date object afterward if necessary. rs = ps.executeQuery(); Timestamp timestamp = rs.getTimestamp(""MODIFIED""); Hope this helps. Constructing `new Date` is unnecessary since `Timestamp extends Date`.  ResultSet.getDate() returns a java.sql.Date not a java.util.Date. It is defined to be a timeless date. If you want a timestamp use ResultSet.getTimestamp()! Note to self - rtfm. I thought this was working in other places. ""java.sql.Date is defined to be a timeless date"". That statement has saved my life. Thank you!  Using Timestap is the correct way. Please take not that with Timestamp you will not be able to set the columns to nullable if you were to use Liquibase. A problem I came across as well."
404,A,"mysql: find rows which have a field that is a substring of ""string"" is there a way to write an sql query that finds all rows where the field value is a substring of a given string. Example: table names Name | Nickname rohit iamrohitbanga banga rohitnick sinan unur query should be something like select * from names where Name is a substring of ""who is rohit""; // to get first row select * from names where Nickname is a substring of ""who is rohitnick""; // to get second row select * from names where Name is a substring of ""who is unur and banga"" or Nickname is substring of ""who is unur and banga""; // to get second and third row How is it possible? If it is not possible then i'll have to achieve that behaviour in java. i am using jdbc:mysql driver to connect to the database. Update your solutions work now a bit of a twist. if we want to check if a substring of the field occurs as a substring of the string that we specify. select * from names where Name is a substring of ""who is sina""; // to get third row It's disrespectful to those who provided answers to change the criteria afterwards. @iamrohitbanga: I agree with `OMG Ponies`. Posters do not get notified that you changed your question so most will not update their answers. If your initial problem is solved accept an answer and feel free to add another question. Also I do not see the difference between your new query (`Name is substring of something`) and the original queries (`Name is substring of something`) agreed! you are right the difference in the second one is that as shown in the example sina is not a value of any cell but it is a substring of sinan. so it must be matched. i'll try to solve this on my own. if i have trouble i'll post a separate question. and thanks for not voting me down for this :) One problem with all these approaches is your indexes go right out the window. You'll have to do a table scan for each and every row which means your performance will only get worse and worse as the table size grows. I'd rethink this approach if your table is going to be large. Maybe you need a indexed searcher like Lucene. i have lucene in mind. but right now for the prototype i want something simple. a doubt that i do have is that my fields are typically small. so is it worth creating a Lucene `Document` for each row. Lucene would match documents based on tf/idf which measures the frequency. so both my documents would be small. is lucene a good option.  SELECT * FROM names WHERE INSTR(NicknameName) > 0; or equivalently: SELECT * FROM names WHERE LOCATE(NameNickname) > 0; no. fireeyedboy seems to have done it correctly. i'll test that. anyhow you pointed out the same function. I'm sorry I don't understand the question then. :) But ok.  If one of Name or Nickname has to be found within the text use SELECT * FROM names WHERE instr(""who is Rohit"" Name) > 0 OR instr(""who is Rohit"" Nickname) > 0 No index can be used for that so it might take long for large tables.  You can also reverse the LIKE condition. select * from names where ""who is rohit"" LIKE CONCAT('%' Name '%'); Note this probably isn't any faster than instr(""who is Rohit"" Name) but it may be."
405,A,"JDBC query to Oracle We are planning to migrate our DB to Oracle.We need to manually check each of the embedded SQL is working in Oracle as few may follow different SQL rules.Now my need is very simple. I need to browse through a file which may contain queries like this. String sql = ""select * from test where name=""+test+""and age=""+age; There are nearly 1000 files and each file has different kind of queries like this where I have to pluck the query alone which I have done through an unix script.But I need to convert these Java based queries to Oracle compatible queries. ie. select * from test where name=""name"" and age=""age"" Basically I need to check the syntax of the queries by this.I have seen something like this in TOAD but I have more than 1000 files and can't manually change each one.Is there a way? I will explain more i the question is not clear Does your current application execute SQL through a common class? Could you add some logging to print out the raw SQL in this common class? From that output you could write a small script to run each statement against Oracle.  For performance and security reasons you should use PreparedStatement.bind(...) rather than string concatenation to build your SQL strings. I don't know of a way to tackle this problem other than fixing the code that needs to be fixed. If you can find common patterns then you can automate some of the editing using find/replace or sed or some other tool as long as you diff the result before checking it in. If there are thousands of files I guess that there is a reasonable sized team that built the code this way. It seems fair to share the workload out amongst the people that built the system rather than dump it all on one person. Otherwise you will end up as the ""SQL fixing guy"" and nobody else on the team will have any incentive to write SQL code in a more portable way."
406,A,"Why is retreiving a ResultSet from Oracle stored procedure soooo slow? I have to improve some code where an Oracle stored procedure is called from a Java program. Currently the code is really really slow : up to about 8 seconds on my dev machine. On the same machine if I call directly a SQL query that does about the same treatment and returns the same data it takes under 100 ms... The code creates a CallableStatement registers one of the output parameters to be an Oracle cursor and then retreives the cursor using the getObject method of the statement and parse it to ResultSet : cstmt = conn.prepareCall(""{ call PKG_ESPECEW.P_ListEspece( ? ? ? ? ? ? ) }""); cstmt.registerOutParameter(4 oracle.jdbc.OracleTypes.CURSOR); [...] cstmt.executeQuery(); rs = (ResultSet)cstmt.getObject(4); rs.setFetchSize(1000); //supposed to help ? options = new HashMap<String String>(1000); rs.next() //added that to measure exactly the length of the first call while(rs.next()) { [...] } I put some timestamps in the code to know which part is taking so long. The result : the first call to rs.next() is taking up to various seconds. The result sets are average from 10 to a couple thousands rows. As I said before handling similar result sets coming from a regular PreparedStatement takes 10-100 ms depending the size. Is anything wrong with the code ? How to improve it ? I'll do direct SQL qhere critical if I haen't any other solution but I'd prefer a solution tha allows me to not rewrite all the procedures ! Edit : here is the definition of the stored procedure : PROCEDURE P_ListEspece(P_CLT_ID IN ESPECE.ESP_CLT_ID%TYPE -- Langue de l'utilisateur P_ESP_GROUP_CODE IN ESPECE.ESP_CODE%TYPE-- Code du groupe ou NULL P_Filter IN VARCHAR2 -- Filtre de la requête P_Cursor OUT L_CURSOR_TYPE -- Curseur P_RecordCount OUT NUMBER -- Nombre d'enregistrement retourne P_ReturnStatus OUT NUMBER); -- Code d'erreur Is there a reason you don't use `OracleCallableStatement.getCursor` instead of `getObject`? I would have to cast the CallableStatement to OracleCallableStatement but I am using DBCP and the CallableStatement is actually a ""proxy"" provided by DBCP so I would get an Exception (I tried it). How long does it take to execute the procedure outside of java ? Check with a script like this in SQL*Plus: var ref refcursor var cnt number var status number exec p_listespece (xx yy zz :ref :cnt :status);--replace with actual values print :ref If it takes more than 10-100 ms your problem may come from the stored procedure Actually I don't have SQLPlus or the oracle client installed on my dev machine. I do most thnigs with SQLDevelopper and ask the DBA for the rest. I'll check with him tomorrow. Or you know if I can execute plsql directly from SQLDev ? I installed the oracle client and sql plus and tried this. The display of the result in the command line took forever but it was probably slowed down by the command line printing in windows command line. Anyway the problem is with the SP itself.  ""I thought the procedure was executed then it's result stored in oracle server's memory and finally transmitted back to the client (the java app) through the cursor and result set and JDBC"" That's incorrect. What oracle returns as a cursor is basically a pointer to a query (all ready with any bind variables). It has not materialized the result set in memory. It could be a massive result set of millions/billions of rows. So it could well be a slow query that takes a long time to deliver results. I talked with the DB guy that takes care of the DB and it seems the query execute inside the SP was actually the problem becaus it was calling a function that was opening another cursor for each record found. He removed this call and the execution time went down to less than 1 second. It is still quite slow but already more acceptable. I guess the query itself can still be improved and the problem is actually with the query and not the transmission of the data.  Apparently the stored procedure is doing some data conversion/massaging forth and back (e.g. int <--> varchar). This is known to take a lot of time in case of large tables. Ensure that you've declared the right datatypes in the SP arguments and are setting the right datatypes in CallableStatement. I chaked all the mapping of the parameters : they were all correct except the second one. It is of type NUMBER but I was applying the setInt method on the statement. I corrected this but unfortunately it didn't fix the slow response time... I think that the conversion of this parameter would be done only once by Oracle so not much influence... Actually it's not reading or setting the SP arguments that takes time it is reading from the ResultSet that is itself an argument of the SP. I'll update the question with th SP definition. So you think that type conversion could be an issue in this case ? You told that it's faster with `PreparedStatement` so the problem is likely with the SP. If any column value needs to be (implicitly) converted then it will take time especially when used in SP's `WHERE` clause. But it is not the cstmt.executeQuery(); that is slow it's the result set browsing. I thought the procedure was executed then it's result stored in oracle server's memory and finally transmitted back to the client (the java app) through the cursor and result set and JDBC. But maybe I am wrong ? I am an Oracle/PLSQL ignorant. Would the procedure be executed ""step by step"" when the result set is read ?"
407,A,Is there a way to force a jdbc connection to use TCP? In a normal SQL Server 2005 connection string it's possible to specify the desired protocol in the following format: Data Source=tcp:myServerAddress; Initial Catalog=myDataBase; Integrated Security=SSPI; Is there a way to do something similar in a JDBC connection string to SQL Server? Edit: My JDBC Connection String looks like this: JdbcDrivers=com.microsoft.sqlserver.jdbc.SQLServerDriver; Provider=Mondrian;Jdbc= 'jdbc:sqlserver://myServerAddress; instanceName=SQLEXPRESS; databaseName=myDataBase;integratedSecurity=true;'; Substituting the actual IP address for the server name seems to do the trick.
408,A,"Spring Jdbc Template + MySQL = TransientDataAccessResourceException : Invalid Argument Value : Java.io.notSerializationException I was using spring jdbc template to insert some data into the database and I was getting this error. Here is my code : JdbcTemplate insert = new JdbcTemplate(dataSource); for(ResultType result : response.getResultSet().getResult()) { Object[] args = new Object[] {result.getAddress() result.getCity() result.getState() result.getPhone() result.getLatitude() result.getLongitude()result.getRating().getAverageRating() result.getRating().getAverageRating() result.getRating().getTotalRatings() result.getRating().getTotalReviews() result.getRating().getLastReviewDate() result.getRating().getLastReviewIntro() result.getDistance() result.getUrl() result.getClickUrl() result.getBusinessUrl() result.getBusinessClickUrl()}; insert.update(""INSERT INTO data.carwashes ( address city state phone lat lng rating average_rating total_ratings total reviews last_review_date last_review_intro distance url click_url business_url business_click_url category_id zipcode_id) VALUES (? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?9692572478701)"" args); } Quite lengthy code.. but basically it gets the value from a object and sticks it to a array and passed that array to insert method of jdbc template. Any help will be appreciated. http://forum.springsource.org/showthread.php?t=53267 My guess is that one of the items in your arg array is of a type not recognised by JdbcTemplate (i.e. it's not a String a Date and so on) and so it's calling setObject() on the statement. The driver will then try to serialize the argument into a binary discovers it's not serializable and throws the exception. Make sure the arguments in the array are all what you think they should be e.g. they shouldn't be instances of your own classes but should be standard Java types. Thanks Espen. I'll do that. This was more like a test run to see whether all pieces fit together. I'll try these solutions and see. +1: I also believe this. Btw: To insert data in a for loop isn't very efficient. You should consider `JdbcTemplate`s `batchUpdate(sql pss)` method."
409,A,"architecture mismatch between the Driver and Application? I am using JDBC to connect to my microsoft access database. I get the following exception when I try to connect to the database: java.sql.SQLException: [Microsoft][ODBC Driver Manager] The specified DSN contains an architecture mismatch between the Driver and Application I am using 64bit windows7 and I am using eclipse which is also a 64bit version My database is a microsoft access database and it seems that the driver is a 32bit driver which is causing the problem. Any help on how to solve this problem would be greatly appreciated. I don't have enough reputation yet to vote Yoda up but I have to say that his solution is the most elegant I've come across. You could have also used a 32-bit JVM but that is kind of silly. (If you encounter this on IIS you can make the application pool 32-bit which is sort of the same thing.)  Check out the access 2010 redist Microsoft Access Database Engine 2010 Redistributable This download will install a set of components that can be used by non-Microsoft Office applications to read data from and write data to Office 2010 system files such as Microsoft Access 2010 (mdb and accdb) files and Microsoft Excel 2010 (xls xlsx and xlsb) files. Connectivity to text files is also supported. ODBC and OLEDB drivers are installed for application developers to use in developing their applications with connectivity to Office file formats. This should suit your needs. Good luck! Thank you for your response. I am using Microdoft Office 2006 does this matter? It says in the instructions on the download page that:(If you are application developer using ODBC to connect to Microsoft Office Access data set the Connection String to “Driver={Microsoft Access Driver (*.mdb *.accdb)};DBQ=path to mdb/accdb file”) my code currently connects in the following way: Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver"");connection = DriverManager.getConnection(""jdbc:odbc:users""); Im not sure as to where to put the connection string which is mentioned in the instructions?thanks again Change the parameters of DriverManager.getConnection to the connection string use the following example as a reference it includes your connection string: http://www.rgagnon.com/javadetails/java-0107.html If that works out for you an upvote and accepted answer would be nice ;) and if not give me a shout. And I'm fairly sure the drivers will be backwards compatible so shouldn't be an issue. There is no such thing as ""Microsoft Access 2006""."
410,A,"Is there a way to display PRINT results with SQL server JDBC driver? If my stored procedure has a print statement inside it: print 'message' Is there a way to fetch the output in java program that connects to SQL Server 2008 through JDBC? Also is there a danger that print messages left for debugging would shutdown connection when called from JDBC application? Yes there is: http://dba.stackexchange.com/a/44373/5457 Statement stmt = ...; stmt.execute(""some sql""); SQLWarning warning = stmt.getWarnings(); while (warn != null) { System.out.println(warning.getMessage()); warning = warning.getNextWarning(); }  this article shows how to do that in VB.NET I am sure you can do the same in your java code. All you need to do is attach a handler function to SqlInfoMessageEvent VB.NET code specified in the above article does not work properly some how on my studio 2005 environment. So I re wrote it as below Imports System.Data.SqlClient Module Module1 Public Sub Main() 'change your database name in following line. Dim conn As New SqlConnection(""server=(local);Integrated Security=SSPI;database=Test"") AddHandler conn.InfoMessage New SqlInfoMessageEventHandler(AddressOf OnInfoMessage) conn.Open() Dim cmd As New SqlCommand() cmd.Connection = conn cmd.CommandType = CommandType.StoredProcedure cmd.CommandText = ""[SPWithPrint]"" cmd.ExecuteNonQuery() conn.Close() ' Dts.TaskResult = Dts.Results.Success End Sub Private Sub OnInfoMessage(ByVal sender As Object ByVal args As System.Data.SqlClient.SqlInfoMessageEventArgs) Dim err As SqlError For Each err In args.Errors Console.WriteLine(""The {0} has received a severity {1} state {2} error number {3}\n"" & _ ""on line {4} of procedure {5} on server {6}:\n{7}"" _ err.Source err.Class err.State err.Number err.LineNumber _ err.Procedure err.Server err.Message) Next End Sub End Module Other usefull links are as below. http://msdn.microsoft.com/en-us/library/system.data.sqlclient.sqlconnection.infomessage.aspx http://msdn.microsoft.com/en-us/library/a0hee08w.aspx  You can't do it. Your options are to use an output parameter from your stored procedure or to do SELECT 'message' which will give you a ResultSet you can read in the Java."
411,A,"How to connect XAMPP MySQL local DB using JDBC? I have this Tetris game written in Java which uses DB to record high scores. It worked ok as long as I was using remote MySQL DB but now I'm trying to set up localhost DB using XAMPP MySQL and it keeps going like ""SQLException: Communications link failure"" at command: con = java.sql.DriverManager.getConnection(""jdbc:mysql://localhost/score"" user psw); I guess it's either wrong URL or DB configuration but I really don't know what to check. Any ideas? EDIT: My friend has fixed my problem by replacing ""localhost"" in URL by ""127.0.0.1"" (which was quite embarrassing as you can surely imagine :P ). So question is: Why is XAMPP not able to translate ""localhost"" into IP address and how to fix it? Can you browse to the MySQL database with the Query Browser? I remember running into a similar issue with a Java app that refused to recognize naming in the connection string to MySQL. Dont forget this important step on this link - http://ferdidolot.wordpress.com/2009/06/14/java-mysql-jdbc-tutorial-using-netbeans-part-1/ [This post](http://forums.netbeans.org/ntopic4896.html) claims to have fixed it. Check it out. Mentioned skip-networking variable is commented in my XAMPP by default so I afraid this is not the problem.. Why is XAMPP not able to translate ""localhost"" into IP address and how to fix it? This is not a XAMPP problem nor a programming problem. This is more a DNS problem. To start do you have a %SystemRoot%/system32/drivers/etc/hosts file with the following line as first line? (thus after all comments but before any other host declarations) 127.0.0.1 localhost Update: as per the comments I've Googled a bit and it look like that the MySQL JDBC driver doesn't eat IPv6 addresses at all. In other words you'll need to change ::1 to 127.0.0.1. But I also found this topic which mentions that you can use the following JVM argument to fix this problem: java -Djava.net.preferIPv4Stack=true What about ""::1 localhost""? That should do just the same shouldn't it? That makes sense thank you for you research ;)  I tried and got a successful connection. First create a database in phpmyadmin - eg. 'mydb' and then in code put connection.url with this value 'jdbc:mysql://localhost:3306/mydb' If you don't create a database first it wont connect  In MySql you have to allow access for your user from localhost explicitly. Here is an example (taken from here): mysql> grant usage on *.* to amarokuser@localhost identified by 'amarokpasswd'; mysql> grant all privileges on amarokdb.* to amarokuser@localhost ; I'm using root but I've also tried to create user and give him access and all privileges just to be sure... not working :/"
412,A,"Delete all tables in Derby DB How do i delete all the tables in the schema on Apache Derby DB using JDBC? I think most db providers don't allow DROP TABLE * (or similar). I think the best way would be to SHOW TABLES and then go through each deleting in a loop via a resultset. HTH.  you must generate schema and table name from Derby DB system catalog. Order all tables by relation. Generate java statement for drop all tables Use autoCommit() method and set this method to false. for manual commit or rollback transactions when got errors. Run you java process. Good Luck.  Do a little method in java in which you execute a ""DROP TABLE [tablename]"" tablename is passed by parameter. And another method in which you loop over a recordset formed by the query ""SELECT tablename FROM SYSTABLES"" calling the first method. Derby latest documentation There should be some order of deletion.  If you're working from the command prompt rather than through JDBC this should get you started. SELECT 'DROP TABLE ' || schemaname ||'.' || tablename || ';' FROM SYS.SYSTABLES INNER JOIN SYS.SYSSCHEMAS ON SYS.SYSTABLES.SCHEMAID = SYS.SYSSCHEMAS.SCHEMAID ;  For actual code that does this check CleanDatabaseTestSetup.java in the Derby test suite section of the Derby distribution: http://svn.apache.org/viewvc/db/derby/code/trunk/java/testing/org/apache/derbyTesting/junit/CleanDatabaseTestSetup.java?view=markup You are probably looking for http://svn.apache.org/viewvc/db/derby/code/trunk/java/testing/org/apache/derbyTesting/junit/JDBC.java?revision=990292&view=markup -- this is contains the actual dropSchema() method that deletes a single database (instead of all the user databases in the given connection).  JDBC allows you to solve your task in a database agnostic way: Open the connection Grab the DatabaseMetaData Use it to list all tables in your database JavaDoc Iterate over the resultset and fire the DROP TABLE for each table  Download Squirrel SQL from http://squirrel-sql.sourceforge.net/ Connect to the database. Expand the TABLE node. Select the tables that you want to drop. Right click and select -> Scripts -> Drop table scripts Run the generated queries You can even select delete records to empty the selected tables.  A simpler solution is to use JDBC to run ""drop database foo"" then ""create database foo"". However this will cause all objects in the DB to be deleted (i.e. not just tables).  A simple solution is to do right click -> disconnect then delete the folder containing your database and reconnect it.  Thanks are due to the blog: Step 1: Run the SQL statement but don't forget to replace the schema name 'APP' with your your schema name in the 2 occurrences below: SELECT 'ALTER TABLE '||S.SCHEMANAME||'.'||T.TABLENAME||' DROP CONSTRAINT '||C.CONSTRAINTNAME||';' FROM SYS.SYSCONSTRAINTS C SYS.SYSSCHEMAS S SYS.SYSTABLES T WHERE C.SCHEMAID = S.SCHEMAID AND C.TABLEID = T.TABLEID AND S.SCHEMANAME = 'APP' UNION SELECT 'DROP TABLE ' || schemaname ||'.' || tablename || ';' FROM SYS.SYSTABLES INNER JOIN SYS.SYSSCHEMAS ON SYS.SYSTABLES.SCHEMAID = SYS.SYSSCHEMAS.SCHEMAID where schemaname='APP'; Step 2: The result of the above execution is a set of SQL statements copy them to the SQL editor execute them then the constraints and the tables are dropped."
413,A,"When are two columns that look the same not the same in oracle? I am work on a project in oracle 9i. I was having a problem with toplink 10.1.3 loading a particular row in a table. It turns out the jdbc driver that toplink is relying on is acting very funny. Perhaps someone here can help... I have a table named: crazytable. It has a column: ""ver_num number(19) not null default 0"". This column was added to the table as part of the original insert some years ago. When I select any record (see below for jdbc connection code) from crazytable and attempt to do an rs.getLong(colIndex) everything works fine. However if I do a rs.getObject(colIndex) I get a stacktrace: java.lang.ArrayIndexOutOfBoundsException: 1 at oracle.sql.NUMBER.toBigDecimal(NUMBER.java:651) at oracle.jdbc.dbaccess.DBConversion.NumberBytesToBigDecimal(DBConversion.java:2805) at oracle.jdbc.driver.OracleStatement.getBigDecimalValue(OracleStatement.java:4539) at oracle.jdbc.driver.OracleStatement.getObjectValue(OracleStatement.java:5666) at oracle.jdbc.driver.OracleStatement.getObjectValue(OracleStatement.java:5622) at oracle.jdbc.driver.OracleResultSetImpl.getObject(OracleResultSetImpl.java:739) at oracle.jdbc.driver.OracleResultSet.getObject(OracleResultSet.java:1470) stacktrace truncated to protect my poor code... I can take another table lets call it: sanetable and run this same query against a column with the same name and type ""ver_num number(19) not null default 0"". And rs.getLong(colIndex) and rs.getObject(colIndex) work just fine. Neither column is involved in a constraint or index. I have tried oracle driver 9.2.0.8 9.2.0.5 9.2.0.1 even 10.* (which won't work). Does anyone know anything about what I can do here? This is my basic connection code. The only difference between the successful calls is the particular table in question:  Class.forName(oracle.jdbc.OracleDriver.class.getName()); String url = ""jdbc:oracle:thin:@IPADDRESS:PORT:INSTANCE""; Connection conn = null; ResultSet rs = null; try { conn = DriverManager.getConnection(url ""user""""pass""); PreparedStatement prepareStatement = conn.prepareStatement( ""select distinct ver_num "" + ""FROM [crazytable|sanetable] "" ); rs = prepareStatement.executeQuery(); assertNotNull(rs); while (rs.next()) { ResultSetMetaData md = rs.getMetaData(); for (int i = 1; i <= md.getColumnCount(); i++) { String key = md.getColumnLabel(i); Object value = rs.getLong(key); System.out.println(key+"" : ""+value +"" was null: ""+rs.wasNull() +"" type: ""+ rs.getType() +"" class: ""+ md.getColumnClassName(i)); } } } finally { if (rs != null) { rs.close(); } if (conn != null) { conn.close(); } } edit: The driver can be found on this page: http://www.oracle.com/technology/software/tech/java/sqlj_jdbc/htdocs/jdbc9201.html Could you please mention the drivers jar file name? Okay I think I figured this out. I was looking through some other questions and noticed there are other oracle type 4 drivers. One of which is DataDirect (http://datadirect.com). I used a trial version of their driver and it was able to return the rs.getObject(intIndex). The value was: -1.6777120E-27. So rs.getLong() was rounding down to zero but the BigDecimal was seeing a decimal part and throwing an exception. Perhaps this is due to oracle's driver being compiled with jdbc1.4 vs something newer for datadirect."
414,A,"Importing a (mysql) database dump programmatically through Java How can I import a mysql database dump file (contains insert and create table statements) programmatically through a java program. I need this as the setup phase of a unit test. Unfortunately this doesn't work: Connection conn = dbConnectionSource.getConnection(); Statement stmt = conn.createStatement(); stmt.execute(FileUtils.readFileToString(new File(""./some-sql-file""))); conn.close(); Thanks -A PS - In Rails I used fixtures for filling a test database. I made rails rails create the underlying tables through setting the environment to test anything similar in Java. ""pragmatically"" should be ""programmatically"" Personally I would disrecommend loading a regular SQL dump in this way because you would need non-trivial code to parse or at least tokenize SQL. I would recommend using CSV data dumps you can load these with a the LOAD DATA INFILE syntax. See: http://dev.mysql.com/doc/refman/5.1/en/load-data.html Of course you would still need to ensure the target tables exist but if you know you only have to parse table creation DDL stattemnts that will drastically simplify your java code. Note that you can use mysqldump to extract CSV data from your database see: http://dev.mysql.com/doc/refman/5.1/en/mysqldump.html#option_mysqldump_tab  You could start a new process from java and execute this command if you have access to the mysql executable wherever you are running the import. Something like this: Runtime rt = Runtime.getRuntime(); Process pr = rt.exec(""mysql -p -h ServerName DbName < dump.sql""); This is the *right* way to do this. Any other way may fail to work in subtle edge-cases. Mysql dumps are written to be imported with the mysql client not any other tool. Just a fix we cant use redirection like that in java: Process pr = rt.exec(new String[]{""/bin/bash""""-c""""mysql -p -h ServerName DbName < dump.sql""}); Thanks for the answer :) any ideas on how to do this in Windows?  Effective solution can be found here: http://stackoverflow.com/a/1044837 This explains how to run any sql script over jdbc.  Backup: /******************************************************/ //Database Properties /******************************************************/ String dbName = “dbName”; String dbUser = “dbUser”; String dbPass = “dbPass”; /***********************************************************/ // Execute Shell Command /***********************************************************/ String executeCmd = “”; executeCmd = “mysqldump -u “+dbUser+” -p”+dbPass+” “+dbName+” -r backup.sql”; } Process runtimeProcess =Runtime.getRuntime().exec(executeCmd); int processComplete = runtimeProcess.waitFor(); if(processComplete == 0){ out.println(“Backup taken successfully”); } else { out.println(“Could not take mysql backup”); } Restore: /******************************************************/ //Database Properties /******************************************************/ String dbName = “dbName”; String dbUser = “dbUser”; String dbPass = “dbPass”; /***********************************************************/ // Execute Shell Command /***********************************************************/ String executeCmd = “”; executeCmd = new String[]{“/bin/sh” “-c” “mysql -u” + dbUser+ ” -p”+dbPass+” ” + dbName+ ” < backup.sql” }; } Process runtimeProcess =Runtime.getRuntime().exec(executeCmd); int processComplete = runtimeProcess.waitFor(); if(processComplete == 0){ out.println(“success”); } else { out.println(“restore failure”); }"
415,A,"Editing JTable from RestulSet Table Continuing this question. My problem is that I can not edit my JTable. I get an exception and the Object value instead of what I should be seeing. I am using the ResultSet Table code with a MS-Access database and with a few modifications. My code can be found here. I run into an error when I rs.updateRow() is called. java.sql.SQLException: [Microsoft][ODBC Microsoft Access Driver]Error in row. I did a google search on this error with updateRow() and not much came up. The only real answer I saw was to use a prepared statement but I am not a pro with SQL commands. Also a plus if you could tell me the best approach in making this become a GlazedList so I can filter easily. Unless you can provide me something that filters regular JTables easily. Okay. I can easily display the database but editing it without using SQL commands is near impossible. What SQL commands would I need to edit? @twodayslate: `UPDATE tableName(columnName1columnName2etc) SET columname2 = column2value WHERE columnName1=row_value` -- assuming columnName1 is a primary key column. I think the issue is still that your JDBC driver doesn't support updatable ResultSets. How do I get a supported driver? Before I saw your answer I made a new TableModle that supported editing of the table. It however does not reflect the changes to the database. Yet. Does the resultSet method put the changes to the table without SQL commands? It appears I have gotten this to work using SQL. Just need the table to display true/false as checkboxes but that should be easy :) @twodayslate: actually now I think the issue with original code may be the way the Statement is configured to generate ResultSets and the options specified. But to actually modify the data you have to use updateRow/insertRow/deleteRow on an updatable ResultSet OR use SQL. Even if you use SQL the ResultSet may not actually reflect the change itself. It's surprisingly complex to get tables that reflect DB changes and can modify the DB as I also discovered. This is just an epic Swing/AWT/Java fail. The idea of ResultSets seems perfect but I guess they don't work in practice... :( Was really hard to pick a best answer... picked Bob cause he has helped me before and his answer was the most on topic and he gave me the SQL I am using the ResultSet Table code Search the web for a better example of a ResultSetTableModel. I'm sure you will find one that already implements the setValueAt(...) method. Or another approach is to just copy the data from the ResultSet to a DefaultTableModel and then you can edit it no problem. Unless you can provide me something that sorts regular JTables easily. Have you read the JTable API and followed the link to the Swing tutorial on ""How to Use Tables"" which contains a working example of sorting since sorting is a default part of the JDK. Whoops. I meant filtering multiple values. Would the DefaultTableModel method keep the database up to date? I still get the error with the google searched setValueAt The tutorial shows how to do filtering. No the DefaultTableModel doesn't automatically update the database (but neither does your current model) . Just add a TableModelListener to the model and you can update the database yourself. Otherwise I think you will need to get a 3rd party package to support this. Do you know of any 3rd party packages that can accomplish all of this?  Trying to offer more help since the initial solution didn't work 100%. Try the info here: Updatable ResultSets to see how to make your ResultSet updatable by specifying arguments when creating a Statement object from your Connection. I realized this option may not have been set by default for you. If you driver supports this mode it should allow the code to work. EDIT: It's not necessarily the driver (though you will need a JAR if you wish to change that). You need to enable ResultSet.TYPE_SCROLL_SENSITIVE when creating the table -- the driver may still support this mode. There are ways to probe what the JDBC driver supports but they're kind of a pain to use unless you use a GUI like SquirrelSQL Client to get a full list of capabilities. I was using the H2 DBMS driver... wouldn't touch Access with a 3 meter pole. To get my version to work you'll absolutely have to find a JDBC driver (yes JAR) for Access that supports more of the JDBC features. It sounds like your Access driver is pretty bare-bones. Thank you for the continued help! How would I change drivers? I am currently using `sun.jdbc.odbc.JdbcOdbcDriver`. I tried to use `com.pointbase.jdbc.jdbcDriver` but it doesn't work. I need a jar? In the link you gave - my program threw an error at `ResultSet.TYPE_FORWARD_ONLY` so it must be the driver that is making the issue? @twodayslate: see edit. I still get the Error in Row when I change it to SENSITIVE. When you had your code working... what driver did you use? In the example they used com.pointbase.jdbc.jdbcDriver but I could not find a jar for MS-Access."
416,A,"Connecting to MS SQL Server 2005 via Hibernate I have JRE 1.6 and am using the following hibernate.cfg.xml file. I am always getting ""Cannot open connection"" and ""The port number 1433/DB is not valid."" <hibernate-configuration> <session-factory> <property name=""hibernate.connection.driver_class"">com.microsoft.sqlserver.jdbc.SQLServerDriver</property> <property name=""hibernate.connection.url"">jdbc:sqlserver://IP/DB</property> <property name=""hibernate.connection.username""></property> <property name=""hibernate.connection.password""></property> <property name=""hibernate.connection.pool_size"">10</property> <property name=""show_sql"">true</property> <property name=""dialect"">org.hibernate.dialect.SQLServerDialect</property> <property name=""hibernate.hbm2ddl.auto"">update</property> </session-factory> </hibernate-configuration> From the official documentation: Building the Connection URL The general form of the connection URL is jdbc:sqlserver://[serverName[\instanceName][:portNumber]][;property=value[;property=value]] where: jdbc:sqlserver:// (Required) is known as the sub-protocol and is constant. serverName (Optional) is the address of the server to connect to. This could be a DNS or IP address or it could be localhost or 127.0.0.1 for the local computer. If not specified in the connection URL the server name must be specified in the properties collection. instanceName (Optional) is the instance to connect to on serverName. If not specified a connection to the default instance is made. portNumber (Optional) is the port to connect to on serverName. The default is 1433. If you are using the default you do not have to specify the port nor its preceding ':' in the URL. property (Optional) is one or more option connection properties. For more information see Setting the Connection Properties. Any property from the list can be specified. Properties can only be delimited by using the semicolon (';') and they cannot be duplicated. So use the following instead: jdbc:sqlserver://IP;databaseName=DB  You are connecting to host/instance. It should be a backslash: host\instance. Are you mixing up the concepts of instance and databases? host\instance;databaseName=DB"
417,A,"Informix JDBC timestamp string format I have Informix database with timestamp field defined as YEAR TO SECOND. When I show this field using JDBC rs.getString(column) it uses format with miliseconds so this field looks like: 2008-12-18 13:58:14.0 I would like it to use only YEAR TO SECOND fields. I set environment variable: GL_DATETIME=%Y-%m-%D %H:%M:%S but even then I got miliseconds. Programs using ODBC do not show milisecond. How can I receive TIMESTAMP string ""YEAR TO SECOND"" only? In my program I can check metadata if field is TIMESTAMP and then cut "".0"" but I think there should be simplier way. Server version: IBM Informix Dynamic Server Version 11.50.TC2DE Client version: IBM Informix JDBC Driver for IBM Informix Dynamic Server 3.50.JC3DE EDIT It looks that all other JDBC drivers I tested (Oracle and PostgreSQL) shows Timestamp columns with miliseconds if I use getString(). So I used solution proposed by Todd. I check metatdata and if column is Timestamp then I use getTimestamp() and format it. Thanks for including the good version information. It helps! If you are using JDBC you can use the rs.getDate(column) or rs.getTimestamp(column) methods which return Date and Timestamp objects respectively. Then you have an object representing time rather than a String expressing it directly. With Date or Timestamp you can use a date formatter to format it to whatever String representation of that time you choose. Update (after reading comments below): If you use getDate() it will still work for Timestamp columns. It will just reduce the precision down to the second. That way you don't have to check the metadata you just have to know that the column is some kind of timestamp or date. OK. But my program do reports and users can choose any table and field so this solution needs checking ResultSet metadata if returned column is of Date/Timestamp type. I thought about more general solution."
418,A,"MySQL jdbc driver and Eclipse: ClassNotFoundexception com.mysql.jdbc.Driver There is a VERY similar question to mine but in my case I don't have any duplicate jars in my build path so the solution does not work for me. I've searched google for a couple of hours now but none of the solutions I've found there actually resolve my issue. I'm creating a web site with some database connectivity for a homework. I'm using a MySQL database developing in Eclipse and running on Windows. I keep getting java.lang.ClassNotFoundException: com.mysql.jdbc.Driver with the following code: import java.sql.*; //... public void someMethodInMyServlet(PrintWriter out) { Connection connection = null; PreparedStatement query = null; try { out.println(""Create the driver instance.<br>""); Class.forName(""com.mysql.jdbc.Driver"").newInstance(); out.println(""Get the connection.<br>""); connection = DriverManager.getConnection(""jdbc:mysql://localhost:3306/test"" ""root"" ""secret""); query = connection.prepareStatement( ""SELECT * FROM customers""); //... } catch (Exception e) { out.println(e.toString()+""<br>""); } } //... When I run the above code I get the following output: Create the driver instance. java.lang.ClassNotFoundException: com.mysql.jdbc.Driver It doesn't get past the Class.forName... line and I can't figure out why! Here is what I did: Download mysql-connector. Put it in my MySQL folder C:\Program Files\MySQL\mysql-connector-java-5.1.12\mysql-connector-java-5.1.12-bin.jar. Opened the project properties in Eclipse. Add External Jar to my Build Path and I selected mysql-connector-java-5.1.12-bin.jar. Every time I attempt to use the servlet I get the same error regardless if I have the jar in there or if I don't. Could you help me figure this out? What happens with a non-servlet test program on the command line? `java -cp C:\Program Files\MySQL\mysql-connector-java-5.1.12-bin.jar;...` @trashgod I just made a dummy test project with an empty Main class: `..\Test\src>java -cp ""C:\Program Files\MySQL\mysql-con nector-java-5.1.12\mysql-connector-java-5.1.12-bin.jar""; Main.java Exception in thread ""main"" java.lang.NoClassDefFoundError: Main/java` The others are right about making the driver JAR available to your servlet container. My comment was meant to suggest that you verify from the command line whether the driver itself is intact. Rather than an empty main() try something like this adapted from the included documentation: public class LoadDriver { public static void main(String[] args) throws Exception { Class.forName(""com.mysql.jdbc.Driver""); } } On my platform I'd do this:  $ ls mysql-connector-java-5.1.12-bin.jar mysql-connector-java-5.1.12-bin.jar $ javac LoadDriver.java $ java -cp mysql-connector-java-5.1.12-bin.jar:. LoadDriver On your platform you need to use ; as the path separator as discussed here and here.  Just follow these steps: 1) Install eclipse 2) Import Apache to eclipse 3) Install mysql 4) Download mysqlconnector/J 5) Unzip the zipped file navigate through it until you get the bin file in it. Then place all files that are present in the folder containing bin to C:\Program Files\mysql\mysql server5.1/ then give the same path as the address while defining the driver in eclipse. That's all very easy guys.  Since you are running it in servlet you need to have the jar accessible by the servlet container. You either include the connector as part of your application war or put it as part of the servlet container's extended library and datasource management stuff if it has one. The second part is totally depend on the container that you have. I'm running a Tomcat server through Eclipse... can you be more specific given that information? Where do I have to put the jar? Place mysql-connector-java-5.1.6-bin.jar to the \Apache Tomcat 6.0.18\lib folder Thanks satya your trick works for me  As for every ""3rd-party"" library in flavor of a JAR file which is to be used by the webapp just copy/drop it in webapp's /WEB-INF/lib. It will then be available in webapp's default classpath. Also Eclipse is smart enough to notice that. No need to hassle with buildpath. However make sure to remove all unnecessary references you added before else it might collide. Thanks. I had the same problem and your solution worked. But what is the difference between adding a JAR file in webapp's '/WEB-INF/lib' and adding the same JAR file in buildpath? If every 3rd party library should be added in '/WEB-INF/lib' then why does buildpath have option for adding External JAR files? @Hiral: that section in the project's *Build Path* is for compiletime classpath. To have the JAR to end up in runtime classpath as well add it in project's *Deployment Assembly* list as well. Note that this ultimately ends up as a JAR in `/WEB-INF/lib` when the WAR is been built/exported. So why not just drop it right there in first place? THANK YOU so much.. i couldn't figure out why the same code was working in a java application but not in the servlet..Your answer works great :) For anyone else new to Eclipse you can add the jar into your project's Deployment Assembly by going to Properties > 'Deployment Assembly' > 'Add...' > 'Java Build Path Entries' and selecting your jar. :)  Place mysql-connector-java-5.1.6-bin.jar to the \Apache Tomcat 6.0.18\lib folder. Your problem will be solved. Only when the OP is using a container-managed `DataSource` not when the OP is fiddling with `DriverManager` manually. For that placing JAR in webapp's `/WEB-INF/lib` as in my answer is more than sufficient. I tried all the other more elegant approaches - and failed. Brute force - placing it in the lib did - worked. Thanks  for this error: java.lang.ClassNotFoundException: com.mysql.jdbc.Driver you need to: Import java.sql.*; Import com.mysql.jdbc.Driver; even if its not used till app running.  assuming your project is maven based add it to your POM:  <dependency> <groupId>mysql</groupId> <artifactId>mysql-connector-java</artifactId> <version>5.1.26</version> </dependency> Save > Build > and test connection again. It works! Your actual mysql java connector version may vary.  Many times I have been facing this problem I have experienced ClassNotFoundException. if jar is not at physical location. So make sure .jar file(mysql connector) in the physical location of WEB-INF lib folder. and make sure restarting Tomcat by using shutdown command in cmd. it should work.  The only solution worked for me is putting the .jar file under WEB-INF/lib . Hope this will help.  If the problem still persists Put the- mysql-connector-java-5.0.8-bin jar in a place inside your Tomcat->lib->folder (No matter where you've installed your Tomcat). And change your environmental variable (Done by clicking Properties of Mycomputer -Advanced system settings- Environmental variables-And set a new variable name & variable values as the place where your lib file resides.Dont forget to enter a ; at the end of the path) If still problem persists Try downloading commons-collections-2.0.jar (http://www.docjar.com/jar_detail/commons-collections-2.0.jar.html) and paste the jar in the same place where your mysql jar resides (ie) inside Tomcat-lib. Clean your project-Stop your server- Finally try to run."
419,A,"Execute sql statement via JDBC with CLOB binding I have the following query (column log is of type CLOB): UPDATE table SET log=? where id=? The query above works fine when using the setAsciiStream method to put a value longer than 4000 characters into the log column. But instead of replacing the value I want to append it hence my query looks like this: UPDATE table SET log=log||?||chr(10) where id=? The above query DOES NOT work any more and I get the following error: java.sql.SQLException: ORA-01461: can bind a LONG value only for insert into a LONG column BLOBs are not mutable from SQL (well besides setting them to NULL) so to append you would have to download the blob first concatenate locally and upload the result again. The usual solution is to write several records to the database with a common key and a sequence which tells the DB how to order the rows.  It looks to me like you have to use a PL/SQL block to do what you want. The following works for me assuming there's an entry with id 1: import oracle.jdbc.OracleDriver; import java.sql.*; import java.io.ByteArrayInputStream; public class JDBCTest { // How much test data to generate. public static final int SIZE = 8192; public static void main(String[] args) throws Exception { // Generate some test data. byte[] data = new byte[SIZE]; for (int i = 0; i < SIZE; ++i) { data[i] = (byte) (64 + (i % 32)); } ByteArrayInputStream stream = new ByteArrayInputStream(data); DriverManager.registerDriver(new OracleDriver()); Connection c = DriverManager.getConnection( ""jdbc:oracle:thin:@some_database"" ""user"" ""password""); String sql = ""DECLARE\n"" + "" l_line CLOB;\n"" + ""BEGIN\n"" + "" l_line := ?;\n"" + "" UPDATE table SET log = log || l_line || CHR(10) WHERE id = ?;\n"" + ""END;\n""; PreparedStatement stmt = c.prepareStatement(sql); stmt.setAsciiStream(1 stream SIZE); stmt.setInt(2 1); stmt.execute(); stmt.close(); c.commit(); c.close(); } }"
420,A,"jdbc transaction management : when releasing resources and distributed transactions hello i'm a beginner java developer and this is one question in a list i'm posting since i've started porting a very old web service . I'm trying to improve the access to db and i'm finding a lot of code i believe migth be dangerous but being not so experienced with java i cannot be sure . Actually i've a class which manages the db connection and holds static references to a connection and a statement objects : it exposes an ""openDb"" method which initializes the sql connection class member variable. Problem number 1 : the class member variables are static what is going to happen if the openDb is called multiple time and the first (for example) instance of the class is still executing a query? the above class expose a method name ""closeDb"" which releases all resources (connection and statement both static members! ) and a ""closeStatement"" method which release only the statement member and is used externally. Problem number 2 : stements and resultset must be closed after a transaction committ/rollback or can be closed immediatly? Still the same class handles the commit/rollback exposing some methods (to set autocommit to false to commit or rollback ) . An instance of this class is passed to other classes instance (for example the usual employee department classes ) which execute their own queries on the db and finally the commit/rollback is called by the connection manager class . Is this ""architecture"" correct or do you see any danger in it ? thank you in advance This is a very bad design and the observations you make concerning the static variables are correct. If one thread calls openDb and another thread does the same things will go wrong. Maybe this happens not all the time which makes this hard to debug. Concerning problem nr. 2: you should close things once you're done with them. This way you don't keep resources occupied unnecesary. So when you have read all (necessary) data from a result set close it. It's also not a good idea to have statements and result sets escape the transaction boundary. So instead of: begin transaction open result set commit transaction read from result set you should have: begin transaction open result set read from result set commit transaction To make the picture complete you should always have the following pattern when using transactions: begin transaction open connection read/modify data close connection commit transaction The open connection/close connection combination may occur multiple times within one transaction. EDIT: To complete the picture even more: in the usual scenario your application has several layers (e.g. UI business data). Transactions are usually started and committed inside the business layer. From the business layer you call one or more data layer methods that become a part of the transaction: // Inside business layer: public void businessMethod(...) { try { // Begin transaction. dataMethod1(...); dataMethod2(...); ... // Commit transaction. } catch (...) { } } // Inside data layer. public void dataMethod1(...) { // Open connection. try { // Get data from database. // Manipulate data. } finally { // Close connection. } } Some additional notes: The transaction commit is the final statement inside the try/catch (if you want to return data from your method it can be followed by a return statement). This ensures that the transaction only commits when everything is ok (i.e. no exception thrown). The connection close is inside the finally part of the try statement. This ensures that it is always closed no matter what happens inside your data method. ok  thak you anyway you have been very helpful the final two questions : when you say ""will run inside the same transaction"" do you mean the 2nd connection is part of the 1st connection transaction or the 2nd connection will work indipendently from 1st ? And what's the better strategy for jdbc connections provided by a datasource : open and close connection continuosly or try to use the less number of them (the first option i suppose : not to keep resources occupied ) This depends on your application design and what makes more sense. If you're inside a single method and you need to go to the database multiple times inside this method I would use one connection. If your transaction spans multiple method calls you should open a connection inside each method. I'll add some more info to my answer to illustrate this scenario. thank you very much for your fast and clear answer one more thing : you say open/close connection may happen multiple times but i suppose it's always the same connection. What about opening different connection inside the same transaction ? will the second conection causes an exception or will the transaction affect only the connection it's associated to ? Hm not absolutely sure. I thought you were using the Java Transaction API. I think both helper methods will enlist in the same transactions.. sorry to bother you so much i meant the following case : conn1.setAutocommit(false); stmt1 = conn1.createstatement(); ... accessing db one or more time .. localhelperMethod1(); localhelpermethod2(); ... conn1.commit(); if the class local helper methods access db only to retrieve data  their inner connections will be enlisted into conn1 transaction or will be indipendent ? and should i pass them conn1 or can i get their own connection from datasource. thank again for your answers The second connection will not cause an exception. It will only run inside the same transaction. You shouldn't worry about reusing the same connection but simply open a new connection when you need one. JDBC uses a connection pool so creating a new connection has hardly any performance impact."
421,A,"Switching users on a JDBC Connection I am writing a Java JDBC database application that connects to an Oracle 11g database and am using a c3p0 connection pool. For the purposes of an example I have 3 database users DEFAULT TOM and BILL. c3p0 opens all of the pooled Connections with the DEFAULT database user. I would like to retrieve one of the pooled Connections from c3p0 and change the user for the Connection to be BILL instead of DEFAULT. Is it possible to do this in JDBC without establishing a new connection with the database? I have already tried doing the following: connect BILL/password; But this does not work. I get an error saying java.sql.SQLException: ORA-00900: invalid SQL statement Are there any other options? Is there something having to do with context set or switching that can facilitate what I'm trying to do? Thanks! Sorry...web application. @jtbradle Can you clarify your use case? Is this for a client/server application? Yes this is for a client/server application. It is for a web app where the users of the web app each have an individual database account. This web app formerly operated using single sign-on but we are moving away from this and going to a multiple sign-on solution for security reasons. Thus this is where my connection pooling problem arises. Hmm... I'm confused. C/S or web application? If these users do not login interactively to the database via your application is it unreasonable to just have three separate pools one for each user? Then use some connection manager to retrieve the appropriate connection? I thought about this but in my case it wouldn't be that beneficial. The 3 users in this case are just for the purposes of an example. However in production I'll expect a large pool of users. Thanks!  You can use DataSource.getConnection(String user String password). c3p0 internally maintains a separate pool for each user.  c3p0 creates physical connections with the credential you told him to use and you can't change the credentials of a connection obtained from a pool after the facts. If you want to use connections with different database users you need to create and use different pools.  After researching yesterday I found that the solution is to use Oracle Proxy Authentication. This solution is outside of the JDBC specification. However Oracle provides a hook to implement such a solution. Opening a proxy connection would look like as follows: import oracle.jdbc.OracleConnection; //Declare variables String url = ""...""; String username = ""...""; String password = ""...""; //Create the Connection Connection conn = DriverManager.getConnection(url username password); //Set the proxy properties java.util.Properties prop = new java.util.Properties(); prop.put(OracleConnection.PROXY_USER_NAME ""BILL""); prop.put(OracleConnection.PROXY_USER_PASSWORD ""password""); //Cast the Connection to an OracleConnection and create the proxy session ((OracleConnection)conn).openProxySession(OracleConnection.PROXYTYPE_USER_NAME prop); /* The Connection credentials have now been changed */ I wouldn't be surprised if there are other nuances associated with this but this is a good start. Thanks for your help everyone!  Check JDBC Extension for Oracle VPD Setting OracleConnection.clientIdentifier looks more standard / suitable to me Sorry to post on old thread just thought of updating. Nice idea but I guess it doesn't help to change the current user. V$SESSION.Client_Identifier is changed but not V$SESSION.UserName  Have you tried issuing this statement via jbdc: alter session set current_schema=BILL. If I remember correctly the oracle structure the username with which you connect is the same as the schema you are working on. I did use the above statement successfully in the past with Oracle 10 via jdbc. My user was the root/admin user it had permissions to various database schemas and I had a need to switch between them in the same connection. Notice that I didn't need to supply a password again. This doesn't sound like a very security-conscious model so I don't know if it is suitable for your use-case. Thanks Yoni. Unfortunately I think your latter assumption is correct. This won't be suitable for my use-case. the set current_schema call changes the default schema...however all operations are run under the original user's privileges."
422,A,"SimpleJdbcTestUtils.executeScript and multilines script I want to load SQL script files for my unit tests. As I am using Spring 2.5.2 I decided to use the SimpleJdbcTestUtils.executeScript() method to load my script file using the following code: DriverManagerDataSource dataSource = ... // getting my DataSource defined in my Spring context SimpleJdbcTemplate template = new SimpleJdbcTemplate(dataSource); Resource resource = new ClassPathResource(""/create-table.sql""); SimpleJdbcTestUtils.executeSqlScript(template resource true); If I write each SQL statement in one line in the create-table.sql file then everything is ok. But if I write a statement on multiple lines then I get an error even if the statement is finished by a ;. Working script : CREATE TABLE T_FOO (ID NUMERIC PRIMARY KEY DATEID TIMESTAMP IS_ACTIVE INTEGER DEFAULT 0 NOT NULL); CREATE TABLE T_BAR (ID NUMERIC PRIMARY KEY DATEID TIMESTAMP IS_ACTIVE INTEGER DEFAULT 0 NOT NULL); Not working script: CREATE TABLE T_FOO ( ID NUMERIC PRIMARY KEY DATEID TIMESTAMP IS_ACTIVE INTEGER DEFAULT 0 NOT NULL); CREATE TABLE T_BAR ( ID NUMERIC PRIMARY KEY DATEID TIMESTAMP IS_ACTIVE INTEGER DEFAULT 0 NOT NULL); Error on second file: org.springframework.jdbc.BadSqlGrammarException: StatementCallback; bad SQL grammar [CREATE TABLE T_FOO (]; nested exception is java.sql.SQLException: Unexpected token: in statement [CREATE TABLE T_FOO (] at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.translate(SQLStateSQLExceptionTranslator.java:111) at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.translate(SQLErrorCodeSQLExceptionTranslator.java:322) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:404) at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:519) at org.springframework.jdbc.core.simple.SimpleJdbcTemplate.update(SimpleJdbcTemplate.java:237) at org.springframework.test.jdbc.SimpleJdbcTestUtils.executeSqlScript(SimpleJdbcTestUtils.java:150) at org.springframework.test.jdbc.SimpleJdbcTestUtils.executeSqlScript(SimpleJdbcTestUtils.java:113) at foo.bar.HsqldbUtils.run(HsqldbUtils.java:95) at foo.bar.SomeUnitTest.executeTests(SomeUnitTest.java:63) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.junit.internal.runners.TestMethodRunner.executeMethodBody(TestMethodRunner.java:99) at org.junit.internal.runners.TestMethodRunner.runUnprotected(TestMethodRunner.java:81) at org.junit.internal.runners.BeforeAndAfterRunner.runProtected(BeforeAndAfterRunner.java:34) at org.junit.internal.runners.TestMethodRunner.runMethod(TestMethodRunner.java:75) at org.junit.internal.runners.TestMethodRunner.run(TestMethodRunner.java:45) at org.junit.internal.runners.TestClassMethodsRunner.invokeTestMethod(TestClassMethodsRunner.java:71) at org.junit.internal.runners.TestClassMethodsRunner.run(TestClassMethodsRunner.java:35) at org.junit.internal.runners.TestClassRunner$1.runUnprotected(TestClassRunner.java:42) at org.junit.internal.runners.BeforeAndAfterRunner.runProtected(BeforeAndAfterRunner.java:34) at org.junit.internal.runners.TestClassRunner.run(TestClassRunner.java:52) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:45) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196) Caused by: java.sql.SQLException: Unexpected token: in statement [CREATE TABLE T_FOO (] at org.hsqldb.jdbc.Util.sqlException(Unknown Source) at org.hsqldb.jdbc.jdbcStatement.fetchResult(Unknown Source) at org.hsqldb.jdbc.jdbcStatement.executeUpdate(Unknown Source) at org.springframework.jdbc.core.JdbcTemplate$1UpdateStatementCallback.doInStatement(JdbcTemplate.java:509) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:393) As I am willing to create more complex tables I prefer to write the SQL instruction in a more readable way so using several lines. Is there a way to do that? WTF: http://efreedom.com/Question/1-2296468/SimpleJdbcTestUtilsexecuteScript-Multilines-Script ? @Boris This site seems to have a copy of the SO question... Need some investigations about that. Thanks. @Boris Look at this: http://meta.stackexchange.com/questions/58369 It seems OK then... You're using Spring 2.5.2 but referring to the 2.5.6 documentation. If you look at the javadoc for 2.5.2 (see here) you'll note that it doesn't support multi-line scripts. This was apparently resolved in 2.5.4 (issue here). You should upgrade to 2.5.6 or better yet 3.0.x. You are totally right! I must update my bookmark or my Spring version indeed ;) Spring updated to 2.5.6 the problem is solved. Thanks!"
423,A,"Index on date type column in oracle not used when query is run from java i have a table containing 15+ million records in oracle. its sort of a log table which has a created_ts column of type ""date"" . i have a simple ""non-unique"" type index on created_ts column. i have a simple range query : select * from table1 where created_ts >= ? and created_ts <= ?; when i run this query from SQLPlus or SQL Developer etc like this : select * from table1 where created_ts >= TO_DATE( '2009-11-10 00:00:00' 'YYYY-MM-DD HH24:MI:SS') and created_ts <= TO_DATE( '2009-11-10 23:59:59' 'YYYY-MM-DD HH24:MI:SS'); the query returns within 1-2 second max. but when I run the exact same query in java over JDBC and set the corresponding ""?"" params using java.sql.Timestamp object . the query takes long time . Analyzing the oracle process it goes for full table scan and doesnt use the index. the jdbc driver i am using is ojdbc5 11.1.0.7.0 Can any one please help .. how to create the index correctly so that it uses the index. My problem was resolved when i used ""oracle.sql.DATE"" objects to set the bind variables instead of ""java.sql.timestamp"" . The query used the index and executed almost within 1-2 seconds. Thanks to all who replied and helped. But its problematic for me as this solution is DB dependent and my app receives DB connection and query as param and load and process data in a generic way. The DB connection can be of any RDBMS like oracle mysql etc. Are you sure that the time issue is with the query and not the driver sending the data over to java? You should try a hint of the form /*+ USE_INDEX(table_name index_name) */ My guess is that the optimizer is choosing a full table scan because it sees that as the best option in absence of knowing the bind values. Wrong syntax: /*+ INDEX(table index) */ or better still use the newer index specification clause with /*+ INDEX(table (column)) */ or /*+ INDEX(table (table.column)) */  The difference may because of bind variables vs. literal values. You are not comparing the same things. Try this in SQL*Plus:- explain plan for select * from table1 where created_ts >= :1 and created_ts <= :2; set markup html preformat on set linesize 100 set pagesize 0 select plan_table_output from table(dbms_xplan.display('plan_table'null'serial')); This will show you the plan Oracle will pick when using bind variables. In this scenario Oracle has to make up a plan before you have provided values for your date range. It does not know if you are selecting only a small fraction of the data or all of it. If this has the same plan (full scan?) as your plan from java at least you konw what is happening. Then you could consider:- Enabling bind peeking (but only after testing this does not cause anything else to go bad) Carefully binding literal values from java in a way that does not allow SQL injection Putting a hint in the statement to indicate it should use the index you want it to. No: http://www.akadia.com/services/ora_bind_variables.html Too much to say for a comment but see this: http://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:492078000346228806 No -> Not usually. Maybe it only runs once a day with certain values and there will only be one hard parse every day? Maybe it's better to live with the hard-parse and allow the CBO to come up with a better plan based on the query? Hi I checked the execution plan for bind vars it was using index. But here i guess the problem was that the object passed in java for bind variable was not handled/cast properly into ""Date"" type value for Oracle DB so it was not using index. see my reply to APC @WW: If the issue is still there after the datatypes aren't being implicitly converted - See my & APCs answers. I've never seen such an issue relating to bind variables solely myself.  This is classic behaviour for an implicit datatype conversion. Because the database is having to convert the datatype of the column it cannot use any index on that column. In your case I suspect this is due to your use of java.sql.Timestamp. Would it be possible to use the equivalent type from the Oracle datatypes package oracle.sql.Timestamp? Obviously that may have some knock-on effects but I think you should at least test it to see whether that solves your problem. +1 - I've seen this in the past with Java queries against Oracle date types. If you're licensed to use the dbms_sqltune package and run it against the sql_id (shared pool or AWR repository) you'll see the datatype conversion in the resulting analysis Hi 1st of all thanks everyone. but the thing suggested by APC was my guess too. I used oracle.sql.DATE object to set the bind variable values and it worked .. query returned almost instantaneously and when i revert back to java.sql.Timestamp its the same problem that the query goes for full scan and takes too long. But this makes my work tough as the app is generic in sense that it can receive connectionquery pairs for loading data where connection can be of any DB like oracle mysqletc. Is it some problem in ojdbc driver that it doesnt correctly translates the object type ""Timestamp"" for oracle ? any suggestion on how to fix and keep the process DB-independent will be appreciated Thanks"
424,A,"Oracle SQL DATE conversion problem using iBATIS via Java JDBC I'm currently wrestling with an Oracle SQL DATE conversion problem using iBATIS from Java. Am using the Oracle JDBC thin driver ojdbc14 version 10.2.0.4.0. iBATIS version 2.3.2. Java 1.6.0_10-rc2-b32. The problem revolves around a column of DATE type that is being returned by this snippet of SQL: SELECT * FROM TABLE(pk_invoice_qry.get_contract_rate(??????????)) order by from_date The package procedure call returns a ref cursor that is being wrapped in a TABLE to where is then easy to read the result set as though were a select query against a table. In PL/SQL Developer one of the columns returned FROM_DATE of SQL DATE type has precision to time of day: Tue Dec 16 23:59:00 PST 2008 But when I access this via iBATIS and JDBC the value only retains precision to day: Tue Dec 16 12:00:00 AM PST 2008 This is clearer when displayed like so: Should have been: 1229500740000 milliseconds since epoch Tuesday December 16 2008 11:59:00 PM PST But getting this instead: 1229414400000 milliseconds since epoch Tuesday December 16 2008 12:00:00 AM PST (as instance of class java.sql.Date) No matter what I try I am unable to expose the full precision of this DATE column to be returned via Java JDBC and iBATIS. What iBATIS is mapping from is this: FROM_DATE : 2008-12-03 : class java.sql.Date The current iBATIS mapping is this: <result property=""from_date"" jdbcType=""DATE"" javaType=""java.sql.Date""/> I've also tried: <result property=""from_date"" jdbcType=""DATETIME"" javaType=""java.sql.Date""/> or <result property=""from_date"" jdbcType=""TIMESTAMP"" javaType=""java.sql.Timestamp""/> But all attempted mappings yield the same truncated Date value. It's as though JDBC has already done the damage of losing data precision before iBATIS even touches it. Clearly I'm losing some of my data precision by going through JDBC and iBATIS that is not happening when I stay in PL/SQL Developer running the same SQL snippet as a test script. Not acceptable at all very frustrating and ultimately very scary. I have solved my problem using jdbcType=""TIMESTAMP"" instead of jdbcType=""DATE"" • PROBLEM: •SOLVED: Regards. Pedro Turns out the success of your results with TIMESTAMP are dependent upon which version of the Oracle JDBC driver you're dealing with. They kept changing their policy as to how to translate the full millisecond precision of the PL/SQL DATE type to java.util.Date type. It worked for MyBatis 3.0.5 with ojdbc14 10.2.0.4.0 (probably because of new type handlers)  Yes I see - the plain SQL DATE standard must be to only store to day resolution. Indeed here is a snippet on Oracle's DATE type: Oracle supports both date and time albeit differently from the SQL2 standard. Rather than using two separate entities date and time Oracle only uses one DATE. The DATE type is stored in a special internal format that includes not just the month day and year but also the hour minute and second. Which makes the point that Oracle's DATE exceeds standard SQL DATE. Hmm Oracle PL/SQL folks use DATE extensively to hold values where they depend on the resolution being to the second. Looks like iBATIS needs something like the Hibernate sql dialect concept where instead of interpreting DATE via java.sql.Date could override and instead interpret via java.util.Date which Javadocs defines as permitting millisecond resolution. Unfortunately when I've changed the mapping to something like: <result property=""from_date"" jdbcType=""DATE"" javaType=""java.util.Date""/> or <result property=""from_date"" jdbcType=""DATETIME"" javaType=""java.util.Date""/> It's still seemingly first translated the SQL DATE to a java.sql.Date and lost the time of day precision.  The problem is the use of java.sql.Date. According to the Javadoc the millisecond values wrapped by a java.sql.Date instance must be 'normalized' by setting the hours minutes seconds and milliseconds to zero in the particular time zone with which the instance is associated to conform with the definition of SQL DATE.  I found out how to solve this problem. iBATIS permits custom type handlers to be registered. So in my sqlmap-config.xml file I added this: <typeAlias alias=""OracleDateHandler"" type=""com.tideworks.ms.CustomDateHandler""/> <typeHandler callback=""OracleDateHandler"" jdbcType=""DATETIME"" javaType=""date""/> And then added this class which implements the iBATIS TypeHandlerCallback interface: // corrected getResult()/setParameter() to correctly deal with when value is null public class CustomDateHandler implements TypeHandlerCallback { @Override public Object getResult(ResultGetter getter) throws SQLException { final Object obj = getter.getTimestamp(); return obj != null ? (Date) obj : null; } @Override public void setParameter(ParameterSetter setterObject value) throws SQLException { setter.setTimestamp(value != null ? new Timestamp(((Date)value).getTime()) : null); } @Override public Object valueOf(String datetime) { return Timestamp.valueOf(datetime); } } Whennever I need to map an Oracle DATE I now describe it like so: <result property=""from_date"" jdbcType=""DATETIME"" javaType=""date""/> nice one I wasn't sure exactly how to overcome the issue but I'm glad I could point you in the right direction  The problem is with the Oracle Driver. The best solution I found was to change all jdbcType=""DATE"" to jdbcType=""TIMESTAMP"" and all #column_name:DATE# to #column_name:TIMESTAMP# So change: <result property=""from_date"" jdbcType=""DATE"" javaType=""java.sql.Date""/> to <result property=""from_date"" jdbcType=""TIMESTAMP"" javaType=""java.sql.Date""/>  The full info (and it's more complex than described here and might depend upon which particular version of the Oracle drivers are in use) is in Richard Yee's answer here - http://www.nabble.com/Re%3A-Oracle-SQL-DATE-conversion-problem-using-iBATIS-via-Java-JDBC-p21112960.html Quick grab before it expires from nabble... Roger See: http://www.oracle.com/technology/tech/java/sqlj_jdbc/htdocs/jdbc_faq.html#08_01 Specifically: Simple Data Types What is going on with DATE and TIMESTAMP? This section is on simple data types. :-) Prior to 9.2 the Oracle JDBC drivers mapped the DATE SQL type to java.sql.Timestamp. This made a certain amount of sense because the Oracle DATE SQL type contains both date and time information as does java.sql.Timestamp. The more obvious mapping to java.sql.Date was somewhat problematic as java.sql.Date does not include time information. It was also the case that the RDBMS did not support the TIMESTAMP SQL type so there was no problem with mapping DATE to Timestamp. In 9.2 TIMESTAMP support was added to the RDBMS. The difference between DATE and TIMESTAMP is that TIMESTAMP includes nanoseconds and DATE does not. So beginning in 9.2 DATE is mapped to Date and TIMESTAMP is mapped to Timestamp. Unfortunately if you were relying on DATE values to contain time information there is a problem. There are several ways to address this problem: Alter your tables to use TIMESTAMP instead of DATE. This is probably rarely possible but it is the best solution when it is. Alter your application to use defineColumnType to define the columns as TIMESTAMP rather than DATE. There are problems with this because you really don't want to use defineColumnType unless you have to (see What is defineColumnType and when should I use it?). Alter you application to use getTimestamp rather than getObject. This is a good solution when possible however many applications contain generic code that relies on getObject so it isn't always possible. Set the V8Compatible connection property. This tells the JDBC drivers to use the old mapping rather than the new one. You can set this flag either as a connection property or a system property. You set the connection property by adding it to the java.util.Properties object passed to DriverManager.getConnection or to OracleDataSource.setConnectionProperties. You set the system property by including a -D option in your java command line. java -Doracle.jdbc.V8Compatible=""true"" MyApp Oracle JDBC 11.1 fixes this problem. Beginning with this release the driver maps SQL DATE columns to java.sql.Timestamp by default. There is no need to set V8Compatible to get the correct mapping. V8Compatible is strongly deprecated. You should not use it at all. If you do set it to true it won't hurt anything but you should stop using it. Although it was rarely used that way V8Compatible existed not to fix the DATE to Date issue but to support compatibility with 8i databases. 8i (and older) databases did not support the TIMESTAMP type. Setting V8Compatible not only caused SQL DATE to be mapped to Timestamp when read from the database it also caused all Timestamps to be converted to SQL DATE when written to the database. Since 8i is desupported the 11.1 JDBC drivers do not support this compatibility mode. For this reason V8Compatible is desupported. As mentioned above the 11.1 drivers by default convert SQL DATE to Timestamp when reading from the database. This always was the right thing to do and the change in 9i was a mistake. The 11.1 drivers have reverted to the correct behavior. Even if you didn't set V8Compatible in your application you shouldn't see any difference in behavior in most cases. You may notice a difference if you use getObject to read a DATE column. The result will be a Timestamp rather than a Date. Since Timestamp is a subclass of Date this generally isn't a problem. Where you might notice a difference is if you relied on the conversion from DATE to Date to truncate the time component or if you do toString on the value. Otherwise the change should be transparent. If for some reason your app is very sensitive to this change and you simply must have the 9i-10g behavior there is a connection property you can set. Set mapDateToTimestamp to false and the driver will revert to the default 9i-10g behavior and map DATE to Date. If possible you should change your column type to TIMESTAMP instead of DATE. -Richard Roger Voss wrote: I posted following question/problem on stackoverflow so if anyone knows a resolution would be good to see it answered there: Oracle SQL DATE conversion problem using iBATIS via Java JDBC Here's the problem description: I'm currently wrestling with an Oracle sql DATE conversion problem using iBATIS from Java. Am using the Oracle JDBC thin driver ojdbc14 version 10.2.0.4.0. iBATIS version 2.3.2. Java 1.6.0_10-rc2-b32. The problem revolves around a column of DATE type that is being returned by this snippet of SQL: SELECT * FROM TABLE(pk_invoice_qry.get_contract_rate(??????????)) order by from_date The package procedure call returns a ref cursor that is being wrapped in a TABLE to where is then easy to read the result set as though were a select query against a table. In PL/SQL Developer one of the columns returned FROM_DATE of SQL DATE type has precision to time of day: Tue Dec 16 23:59:00 PST 2008 But when I access this via iBATIS and JDBC the value only retains precision to day: Tue Dec 16 12:00:00 AM PST 2008 This is clearer when displayed like so: Should have been: 1229500740000 milliseconds since epoch Tuesday December 16 2008 11:59:00 PM PST But getting this instead: 1229414400000 milliseconds since epoch Tuesday December 16 2008 12:00:00 AM PST (as instance of class java.sql.Date) No matter what I try I am unable to expose the full precision of this DATE column to be returned via Java JDBC and iBATIS. What iBATIS is mapping from is this: FROM_DATE : 2008-12-03 : class java.sql.Date The current iBATIS mapping is this: I've also tried: or But all attempted mappings yield the same truncated Date value. It's as though JDBC has already done the damage of loosing data precision before iBATIS even touches it. Clearly I'm loosing some of my data precision by going through JDBC and iBATIS that is not happening when I stay in PL/SQL Developer running the same SQL snippet as a test script. Not acceptable at all very frustrating and ultimately very scary. link not working anymore ;( Found a copy and added it here...  Richard Yee mentions that Oracle's latest drivers fix the problem. I can confirm that. Had the same problem here with 10.2 drivers upgraded today to ojdbc5.jar (11.2.0.1.0) and the problem is gone now."
425,A,"Migrate from JavaDB to PostgreSQL and cant access database any longer Hi all I have an application on Glassfish v2 ( on Mac OS 10.5.8 and Java 1.6 ) that uses JavaDB and Toplinks that comes with the Glassfish bundle. Everything works fine. I have installed PostgreSQL 8.4 and the JDBC v4 driver. Both Glassfish and Postgres server run on localhost. From Netbeans I create a connection to a database on the Postgres server and it works fine I can manually create and delete tables. I create a connection pool resource and persistence unit for this connection to the Posgres server. When I deploy I have the following error : ADM1041:Sent the event to instance: [ResourceDeployEvent -- reference-added jdbc/jdbc/MyDatasource] CORE5004: Resource Deployed: [jdbc:jdbc/MyDatasource]. TopLink version: Oracle TopLink Essentials - 2.1 (Build b60e-fcs (12/23/2008)) Server: unknown RAR5038:Unexpected exception while creating resource for pool MyConnectionPool. Exception : Connection could not be allocated because: FATAL: database ""null"" does not exist I read that with Postgres 8.4 localhost request are accepted by default so I haven't changed anything in postgres.conf. I am missing something but I cant see what. Thanks in advance for any hint. Tart I don't know the stack but it sounds like you haven't specified the database name in the connection. See http://jdbc.postgresql.org/documentation/84/connect.html for a list of parameters you can/should set on the connection. I think the connection is ok as I can manually access the database using it. It is define this way :  First ensure that MacOSX/GlassFish really uses the specified Java version (test with: java -version). Then try the following: asadmin create-jdbc-connection-pool --datasourceclassname org.postgresql.ds.PGSimpleDataSource --restype javax.sql.DataSource --property portNumber=5432:password=secret:user=postgres:serverName=localhost:databaseName=postgres test-pool and asadmin create-jdbc-resource --connectionpoolid test-pool jdbc/Postgres remember to change the username password server port and database to reflect your setup. Then test the datasource using: asadmin ping-connection-pool test-pool if this does not work then you have miss-configured your data source. The first phrase makes no sense. JDBC4 requires Java SE 6 not Java EE 6. Java EE 5 can run perfectly on top of Java SE 6. This is not the problem. Thanks. The driver was actually correct but creating the ConnectionPool directly in the JavaEE server instead of doing via Netbeans worked. I am not sure what I did wrong setting the ConnectionPool via the wizard in Netbeans though but at least the problem is solved :o) fixed the the JDBC driver version part as correctly pointed out by BalusC."
426,A,"Oracle and Jdbc and OraclePreparedStatement#setPlsqlIndexTable and java.util.Date I´m a little bit frustrated with my Java environment that didn´t allow me to call the method OraclePreparedStatement#setPlsqlIndexTable ... but i think i should write the code before... String plSqlBody = ""some pl/sql procedure call"" /* * The PL/SQL procedure parameter is here of type * TYPE t_date_table IS TABLE OF DATE INDEX BY PLS_INTEGER; */ OracleCallableStatement ocs = (OracleCallableStatement) conn.prepareCall(plSqlBody); java.util.Date[] date = new java.util.Date[10]; // Initialise the array... and then... ocs.setPlsqlIndexTable(index date 20 20 OracleTypes.DATE 20); And here i get my exception: java.sql.SQLException: Ungültiger PL/SQL-Indextabellen-Elementtyp at oracle.jdbc.driver.SQLStateMapping.newSQLException(SQLStateMapping.java:70) I didn´t find a solution for the problem. I changed the Java type from java.util.Date to java.sql.Date / oracle.sql.DATE and OracleTypes.DATE to OracleTypes.TIME / OracleTypes.TIMESTAMP but nothing solved the problem. I find somewhere the hint that these types are not allowed here but i can´t believe it. Do you know the right way here? `java.util.Date date = new java.util.Date[10]` doesn't compile. Please modify your question with code that compiles otherwise it's hard to see what's wrong. It is modified. From the Oracle docs (JDBC Developer's Guide JDBC OCI Extensions chapter): Oracle JDBC does not support RAW DATE and PL/SQL RECORD as element types. Maybe you could pass the dates in as strings/numbers instead? It seems so. +1 That would by an uncomfortable solution. I don´t know the reason why Oracle´s JDBC driver does not support DATE here. I saw the same problem at a C# project. The Oracle .NET driver there seems to allow to pass an array of TIMESTAMP objects to the procedure. But i´m not an .NET expert."
427,A,"Impact of java.sql.Connection.close() on java.sql.Statement objects and the like Does closing a java.sql.Connection also close all the statements prepared statements etc. obtained from that connection? Or is there going to be memory leak if I close the connection but leave the statements etc. unclosed? Does closing a java.sql.Connection also close all the statements prepared statements etc. obtained from that connection? Or is there going to be memory leak if I close the connection but leave the statements etc. unclosed? You should not depend on it. The spec reads as follows: An application calls the method Statement.close to indicate that it has finished processing a statement. All Statement objects will be closed when the connection that created them is closed. However it is good coding practice for applications to close statements as soon as they have finished processing them. This allows any external resources that the statement is using to be released immediately. The best practice is to close ALL ResultSets Statements and Connections in a finally block each enclosed in their own try/catch in reverse order of acquisition. Write a class like this: public class DatabaseUtils { public static void close(Statement s) { try { if (s != null) { s.close(); } } catch (SQLException e) { // log or report in someway e.printStackTrace(); } } // similar for ResultSet and Connection } Call like this: Statement s; try { // JDBC stuff here } finally { DatabaseUtils.close(s); } @duffymo: Is there an official doc available where I can find more info on this? Maybe the JDBC spec but if the vendor implementing yours decides not to follow the recommendation you'll have issues. What does it matter what official documents say in that case? Just curious - why is this answer not authoritative enough for you? Well here's what the spec says: 13.1.4 Closing Statement Objects --- An application calls the method Statement.close to indicate that it has finished processing a statement. All Statement objects will be closed when the connection that created them is closed. However it is good coding practice for applications to close statements as soon as they have finished processing them. This allows any external resources that the statement is using to be released immediately. Could you please update your answer and add the text in section 13.1.4 so I can mark it as the answer? Thanks. Yuck. Use the Execute Around idiom to abstract the resource and exception handling nonsense as other assorted potential code duplications. Playing about with `null`s is nasty. Certainly there's a lot that can be done to reduce boilerplate here. But there's no indication that the OP is at that spot yet. If you have to ask whether or not resources need to be closed you're probably not ready for ""execute around"" idiom. 'If the vendor implementing yours decides not to follow the recommendation'. The vendor doesn't have that choice and it's not a 'recommendation' it's a specification. Vendors must comply. Actually I most often use Spring and let Spring manage my connections. But the last time I had read a JDBC book was ages ago and I thought I had read somewhere that closing connections close Statements Resultsets etc. as well. However for some reason recently I had started to doubt that and I was wondering if somebody else can reassure me about this. Turns out that all I needed was to look at the JDBC spec to find out. Which duffymo kinda pushed me to do so :) Spring is indeed doing all that for you. That's the best feature of the Spring JDBC design: eliminating boilerplate. Rod Johnson hated writing it on his consulting engagements as much or more than you do so he figured out a good way to do it once. My experience is that people have trouble with Oracle JDBC drivers if they don't close resources like this. I haven't read the source code to see if ""must"" applies here. It's easier to follow this idiom than rail about something that's not under my control."
428,A,"Failed to obtain JDBC Driver for MySQL under Tomcat environment I've been trying to obtain the Driver class for JDBC connection to MySQL. The workstation is running on Linux Fedora 10. I have manually set up the classpath variable for Java by CLI like this: bash-3.2$ echo $CLASSPATH /home/cmao/public_html/jsp/mysql-connector-java-5.1.12-bin.jar This shows that I've added the lastest mysql connection jar archive to my CLASSPATH variable. I've created a test JSP page which can be found here And source code for this page is: <%@page language=""java""%> <%@page import=""java.sql.*""%> <%@page import=""java.util.*""%> <html> <head> <title>UTS JDBC MySQL connection test page</title> </head> <body> <% Connection con = null; out.print(""Java version is : "" + System.getProperty(""java.version"") + ""<br />""); out.print(""Tomcat version is : "" + application.getServerInfo() + ""<br />""); out.print(""Servlet version is: "" + application.getMajorVersion() + ""<br />""); out.print(""JSP version is : "" + JspFactory.getDefaultFactory().getEngineInfo().getSpecificationVersion() +""<br />""); //out.print(""Java classpath is : "" + System.getProperty(""java.class.path"")+ ""<br />""); //out.print(""JSP classpath is : "" + appliaction.getAttribute(""org.apache.catalina.jsp_classpath"") + ""<br />""); //out.print(""Tomcat classpath is : "" + System.getProperty(""org.apache.tomcat.common.classpath"") + ""<br />""); try { Class c = Class.forName(""com.mysql.jdbc.Driver""); } catch(Exception e) { out.println(""Error! Failed to obtain JDBC driver for MySQL... Missing class \""com.mysql.jdbc.Driver\""<br />""); } %> </body> </html> None of those commented out line would work various Jsper Expetions would be thrown. You can check those Error pages from the following links: classpath Error page catalina Error page tomcat Error page It seems from my limited knowledge of JSP and Servlet the Tomcat environment ""ignores"" my Java CLASSPATH? In which case I cannot configure the MySQL JDBC package to let my Servlets(a JSP is but a Servlet anyway) work. I am not sure how to fix this issue. would it be better if I use an IDE like Eclipse or NetBeans and create a real Java ""web app"" so that everything can be ""self-configured"" by the usage of a web.config XML configuration file? So that I can certainly bypass this Tomcat environment restriction? Many thanks for the suggestions in advance. Too bad. It's important to know that JSPs are compiled into servlets so you're writing them whether you know it or not. Hans Bengston's JSP book from O'Reilly is the best because it teaches JSTL right from the word go. Related: http://stackoverflow.com/questions/2591505/java-lang-classnotfoundexception-com-mysql-jdbc-driver Duffymo got it right. When you consider to drop the JAR in `/WEB-INF/lib` then Eclipse/Netbeans will automatically take it in the buildpath. You don't need to manage it manually. That said I know that this is just a test but in real you shouldn't be writing raw Java code in JSP files using *scriptlets* (those `<% %>` things). That code belongs in real Java classes ;) BalusC has it exactly right as well: no scriptlets in JSPs. If you're not using JSTL you're doing it wrong. @duffymo : I bet you guys would be shocked to see how students do their JSP assignments - everything is written directly into JSP. The only thing ""taught"" in lectures is a bit of JSP not even Servlets... JSTL...Well I don't think the lecturer understands the common tags himself :) We are just doing the ""opposite way"" in this uni class :) You may want to learn how to package up a war file as that would be the simplest way to install the web application if you are going to have several files. Your jar files would go in the lib directory and would be found easily by tomcat. Agreed. This is just a test page to see if I am so lucky to have a working JDBC Driver for MySQL installed ""by default"". I am sure they installed the Driver for Oracle9i but not for MySQL unfortunately...  This shows that I've added the lastest mysql connection jar archive to my CLASSPATH variable. Too bad for you that Tomcat (and all other Java EE app servers) ignore any system CLASSPATH environment variable. You are supposed to add JDBC driver JARs in either one of two places: WEB-INF/lib for your web context which means it's available ONLY to your app (might not be a bad thing) In the Tomcat server/lib if you're using version 5.x or /lib if you're using version 6.x. I believe that Tomcat 6.x requires that you put JDBC driver JARs in /lib. Oh...I see so they did this on purpose... Now that the workstation is a shared environment (all students use the same environment I believe) I reckon I must create my own web app and configure the JDBC Driver myself. I cannot access the lib folder of Tomcat for security reasons I believe. Thanks for your clarifiaction. I will start working on NetBeans now:) Exactly. You can't count on CLASSPATH being set and it needs to be different for each app and app server. Best to try keeping it in your own WAR file. You have a self-contained package that way. yaaay for right answers."
429,A,"Scala dbc update statement Where can I see example of scala.dbc update statement? I have found select statement example only... select fields ( (""url"" of characterVarying(32)) and (""name"" of characterVarying(32)) and (""last_update"" of integer)) from (""feeds"") A search turned up this old wiki page I haven't tested it though. As other people have mentioned in the past there are possibly more up to date / actively maintained database persistence options for scala. Thanks. I have made task using jdbc."
430,A,"Do Tomcat JDBC Connection pools get shared between instances? We have a web application right now that we deploy a copy for each client. Our current deployment strategy is to create a uniquely named jdbc connection pool for each instance. so say jdbc/client. They are specified like this... < Context path=""/"" reloadable=""true"" docBase=""\home\client\ROOT"" debug=""5"" > < Resource name=""jdbc/client"" auth=""Container"" type=""javax.sql.DataSource"" maxActive=""100"" maxIdle=""30"" validationQuery=""SELECT 1"" testWhileIdle=""true"" timeBetweenEvictionRunsMillis=""300000"" numTestsPerEvictionRun=""6"" minEvictableIdleTimeMillis=""1800000"" maxWait=""10000"" username=""user"" password=""pass"" driverClassName=""com.mysql.jdbc.Driver"" url=""jdbc:mysql://databaseserver:3306/client ?zeroDateTimeBehavior=convertToNull&amp;jdbcCompliantTruncation=false""/> < /Context> The question is if I were to standardize it so that instead of unique names the connection pool is called jdbc/database on all deployed instances is there a chance of database crossing ie one customer in another customer's database or are these localized to a specific deployed instance? Thoughts? Thanks Scott There is only 1 copy of tomcat running in memory but multiple deployed war files on it No there is no chance of database crossing becoz the scope of the data source name is one Tomcat instance and you can have multiple data source in single tomcat instance .... so as long as data source is different there is no chance of database crossing.....  If you're defining the JNDI DataSource resource within the Context for a deployment of the application I believe you could even have multiple copies of the same application running in the same Tomcat instance and using the same JNDI name to access different databases. If each application instance is running in a different instance of Tomcat completely there is certainly no way that one instance would be referring to the database specified for another instance. I have 2 apps using same JNDI name but each one with a datasource resource poiting to different db schema and unfortunately only one resource is used for both... can you help me?  This depends on how you deploy application for each client If each client gets their own Tomcat installation (they have different CATALINA_HOME) there is no chance for it to cross. If they all use the same installation but run as different host in Tomcat you need to make sure you don't define the datasource in conf/context.xml which is shared by all hosts. If all clients share the same Tomcat instances and they are simply different web apps more attention is required. You need to define the datasource either in META-INF/context.xml or WEB-INF/web.xml. For further isolation you should copy dbcp.jar to WEB-INF/lib of each application so they use their own DBCP instance.  No. The scope of the data source name is one Tomcat instance. If you are starting a separate Tomcat process for each customer all that matters is how the data source is configured not what Tomcat calls it. As long as each data source is configured to use a different database there won't be any cross talk."
431,A,"What's the right way in Java to connect to a Microsoft Access 2007 database? I'm trying to create a simple connection using the jdbc-odbc bridge: public static Connection getConnection() { Connection con =null; try { Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver""); String conStr = ""jdbc:odbc:Driver={Microsoft Access Driver (*.mdb *.accdb)};DBQ="" + ""c:\\myfolder\\accesdbfile.accdb""; con = DriverManager.getConnection(conStr); } catch(Exception e) { e.printStackTrace();} return con; } But then I get this exception: java.sql.SQLException: [Microsoft][ODBC Microsoft Access Driver]General error Unable to open registry key Temporary (volatile) Ace DSN for process 0xa4 Thread 0xec0 DBC 0x2f8574c Jet'. Any ideas? Update 24/Mar/2009: Now it's working. Created a User Data Source and for some reason the exception went away. As a general question What would be the best way to handle database connections in Java? Go to control panel -- > Administrative tool --> ODBC Data Source Administrator Add database --> Select ""Microsoft Driver(*.mdb *.accdb)"" Dobule click on new database --> Under ""Database"" click on ""select"" --> Select your *.accdb file which you hv created as MS access database. Say OK and go to your java code Use: Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver""); con = DriverManager.getConnection(""jdbc:odbc:filename""); It will surely resolve all your problem.  To answer your general question I would say the best way to handle database connections in Java is to avoid the JDBC-ODBC bridge. Its OK for testing or learning about JDBC but not for real production use. Also if you have a data source that does not have its own JDBC driver but it has an ODBC driver then you may not have a choice. The main reason why I suggest that you stay away from it though is that it makes it difficult to deploy your application. You have to set up the Data Source on the machine that you are running your application from. If you have access to the machine no problem but suppose you are sending the application off to the client? The pure Java JDBC driver works better for this because it is included as part of your application so once your application is installed it is ready to connect to the data source. Of course depending on your requirements there are two other types of drivers but thats another discussion. Also Oracle has stated that the JDBC-ODBC Bridge ""will be removed in JDK 8"" (ref: [here](http://docs.oracle.com/javase/7/docs/technotes/guides/jdbc/bridge.html)).  In general the best way to work with an RDBMS in Java is by using a JDBC driver that is designed to connect directly to the database. Using the JDBC-ODBC bridge tends to be sloww. If you are trying to do basic read/write manipulations with an Access database I would also recommend taking a look at the Jackcess library."
432,A,"Creating JDBC Connection with Oracle 10g using jsp I am able to connect to Oracle 10g (using ojdbc14.jar driver) with java. But when I use the same code in a servlet or file with .jsp extension I am getting class not found exception. I am not able to understand why this is happening. Do we have different connection strings for JDBC in java and jsp? This is what I use to connect to oracle iwith both java and jsp: Class.forName(""oracle.jdbc.OracleDriver""); String url = ""jdbc:oracle:thin:@localhost:1521:xe""; //Xe being the database name String usr = ""username""; String pwd = ""pwd""; Works fine with java but gives error with jsp. When I use oracle.jdbc.OracleDriver it gives me class not found exception. You forgot to tell about the error. There are zillion kinds of errors each telling on its own way about the cause of the problem. Not telling anything about the error will make the cause underterminable and the problem hard to solve. I know the post is pretty old but still thought of to write the error that I can see in your code. You can use oracle.jdbc.driver.OracleDriver instead and try. ok I see. I encountered some similar problem yesterday. Despite adding the classes.jar and ojdbc14.jar under system classpath I have to also manually add them under the WEB_INF/lib folder of my application. It worked. @somnathchakrabarti: That wasn't the issue. The issue was that the server was not able to find the jar. And after following instructions from wds things started working fine. i found the solution to this... it's very easy... i would be specific to oracle database and apache tomcat server. download ojdbc6.jar from oracle or any source place it in your tomcat/lib/ (no matter if you use xampp or any amp bundle it is there) RESTART YOUR SERVER its a must otherwise you would be wondering only lolz. try this code it works..!! <%@ page import=""java.sql.*"" %> <HTML> <HEAD> <TITLE>Simple JSP to Oracle connection Example</TITLE> </HEAD> <BODY> <% Connection conn = null; try { Class.forName(""oracle.jdbc.driver.OracleDriver""); conn = DriverManager.getConnection(""jdbc:oracle:thin:@localhost:1521:orcl"" ""scott"" ""tiger""); out.println(""connected....!!""); } catch(Exception e) { out.println(""Exception : "" + e.getMessage() + """"); } %> </BODY> </HTML>  If you're using a CLASSPATH environment variable your app server ignores it. That's probably why it ""works"" with Java but not with JSPs. I'd advise you to not rely on CLASSPATH that way. Learn how to set it properly for every situation. I'd also advise against putting scriptlet code in JSPs. This will grow to be a maintenance nightmare in a short time. If you must put database calls in a JSP learn how to use JSTL and its <sql> tags.  <%@page import=""java.sql.*""%> <%@page import=""oracle.jdbc.driver.*"" %> <%@page import=""oracle.sql.*;"" %> <%@page contentType=""text/html"" pageEncoding=""UTF-8""%> <!DOCTYPE html> <html> <head> <meta http-equiv=""Content-Type"" content=""text/html; charset=UTF-8""> <title>JSP Page</title> </head> <body> <form id=""form1"" name=""form1"" method=""get"" action=""but1.jsp""> <label> Sr No:<input type=""text"" name=""txt"" /></br> Name: <input type=""text"" name=""txt1"" /> </label> <p>&nbsp;</p> <p> <input type=""submit"" name=""but1"" id=""but1"" value=""Submit""> </input> <% String s=request.getParameter(""txt""); System.out.print(s); String s1=request.getParameter(""txt1""); Connection con; Statement st; ResultSet rs; try{ System.out.println(""hi""); Class.forName(""oracle.jdbc.OracleDriver""); System.out.println(""1""); con=DriverManager.getConnection(""jdbc:oracle:thin:@localhost:1521:XE""""oracle-uname""""oracle-password""); System.out.println(""2""); st=con.createStatement(); System.out.println(""3""); String query=""insert into table1(srno name) values (""+s+""'""+s1+""')""; System.out.println(""4""); int rRs=st.executeUpdate(query); System.out.println(""5""); String q=""Select * from table1 where srno=""+s+""""; System.out.println(""cats""); rs=st.executeQuery(q); System.out.println(""catty""); while(rs.next()) { System.out.println(""6""); out.println(""number is: ""+rs.getString(1));%> </br> <%out.print(""name is: ""+rs.getString(2)); } } catch(Exception ee) { System.out.println(ee.getMessage()); } %> </body> </html> ""jdbc:oracle:thin:@localhost:1521:XE""=path to set path.. services > databases > drivers > oracle thin > connect using > add jar ojdbc6.jar > next > jdbc url (at the bottom) > set uname to system and password to oracle password > test connection the jdbc url forms the path ie ""jdbc:oracle:thin:@localhost:1521:XE"" all the best so what is the point in your answer? I don't get what you mean specifically  There should be no real difference between the two. Is the driver jar in your WEB-INF/lib/ subdirectory? A class not found exception typically means your jar wasn't found on the classpath. I have imported the jar in project and am not using system classpath. @wds: yes the jar is in the Web-Inf/lib/folder @Logan: just to make sure that's WEB-INF upper case. It sometimes matters. Run `jar tf` on the war you made and check whether it really does include everything correctly. The drivers jar is included in the class path. If I am creating a java file in same project it works fine. Problem is with jsp only. Which server are you using? And what path within the server folder have you placed the ojdbc14.jar ? @Logan - that's not what he asked you. Is the JAR in WEB-INF/lib? If you're using a system CLASSPATH you need to know that your app server ignores it. @Logan: are you running the application server by launching from your IDE somehow? Perhaps it is a configuration problem. @Arslan the first hit for oracle jdbc drivers: http://www.oracle.com/technetwork/database/features/jdbc/index-091264.html hi Thanks. That's what I was searching. But What I am missing is the .jar file. Can you please send me the .jar file requires for this? or link form where I can download that?"
433,A,"Upgrading to Oracle JDBC thin driver results in SQLException: Unexpected exception while enlisting XAConnection In Upgrading to Oracle JDBC thin driver results in SQLException: Unexpected exception while enlisting XAConnection (WebLogic Server 10.0 oracle version ) we are getting the error listed below. We did follow Oracle's advice to change the global timeout in weblogic i.e. For the JDBC Connection Pools set the XASetTransactionTimeout to true and XATransactionTimeout to zero When this parameter is set to zero the XAResource Session Timeout will be set to the global transaction timeout. Hence the time out on the WLS needs to be modified If the issue still remains it can be avoided by setting KeepXAConnTillTxComplete=""true"". Database Product Version : Oracle9i Enterprise Edition Release 9.2.0.5.0 - Production With the Partitioning OLAP and Oracle Data Mining options JServer Release 9.2.0.5.0 - Production JDBC Driver Name : Oracle JDBC driver JDBC Driver Version : 11.1.0.7.0-Production We know one option is not to use an XA connection but in our case that is not a possibility. We defenitly need to use XA connections. java.sql.SQLException: Unexpected exception while enlisting XAConnection java.sql.SQLException: XA error: XAResource.XAER_PROTO start() failed on resource 'serviceDataSource': XAER_PROTO : Routine was invoked in an inproper context oracle.jdbc.xa.OracleXAException at oracle.jdbc.xa.OracleXAResource.checkError(OracleXAResource.java:1101) at oracle.jdbc.xa.client.OracleXAResource.start(OracleXAResource.java:237) at weblogic.jdbc.wrapper.VendorXAResource.start(VendorXAResource.java:50) at weblogic.jdbc.jta.DataSource.start(DataSource.java:696) at weblogic.transaction.internal.XAServerResourceInfo.start(XAServerResourceInfo.java:1183) at weblogic.transaction.internal.XAServerResourceInfo.xaStart(XAServerResourceInfo.java:1116) at weblogic.transaction.internal.XAServerResourceInfo.enlist(XAServerResourceInfo.java:275) at weblogic.transaction.internal.ServerTransactionImpl.enlistResource(ServerTransactionImpl.java:508) at weblogic.transaction.internal.ServerTransactionImpl.enlistResource(ServerTransactionImpl.java:435) at weblogic.jdbc.jta.DataSource.enlist(DataSource.java:1407) at weblogic.jdbc.jta.DataSource.refreshXAConnAndEnlist(DataSource.java:1331) at weblogic.jdbc.jta.DataSource.getConnection(DataSource.java:426) at weblogic.jdbc.jta.DataSource.connect(DataSource.java:383) at weblogic.jdbc.common.internal.RmiDataSource.getConnection(RmiDataSource.java:339) Just checking but you're sure you need XA connections? They're a lot more complex than normal JDBC don't use them unless you really need to. Yes we defenitly need to use XA connections. After so consultation from Oracle we decided to upgrade the driver to the latest driver available. This seems to have solved the issue."
434,A,"export mysql data to csv file I am trying to do 2 output data from mysql to a csv file. My code is as follows: public void exportData(Connection connString filename) { Statement stmt; String query; try { stmt = conn.createStatement(); //For comma separated file query = ""SELECT * into OUTFILE '/tmp/input.csv' FIELDS TERMINATED BY '' FROM router ""; stmt.executeQuery(query); } catch(Exception e) { e.printStackTrace(); stmt = null; } } }; I get the following error at the line where stmt.executequery is called. java.sql.SQLException: Access denied for user 'nxy'@'%' (using password: YES) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1075) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3566) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3498) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1959) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2113) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2562) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2512) at com.mysql.jdbc.StatementImpl.executeQuery(StatementImpl.java:1476) at DBase.exportData(automateExport.java:50) at automateExport.main(automateExport.java:18) I am able to connect to the database properly and even execute basic queries but unable to export data to a .csv file. Please help. Thank you You need to have the FILE privilege for your user account to allow for the file to be created at the server host via a SELECT .. INTO OUTFILE command. Well if you are able to connect to the MySQL database via JDBC from a Java application you should be able to perform a select on the table to extract the data and then write it to a CSV file in a location of your choice. Given your circumstances I do not think that you will be able to write onto the database server host at all so JDBC access appears to be the best bet. Hi is there any way I could use mysqldump and dump all contents of the database to my machine and then export required info to a csv file ? It's possible to have mysqldump produce a csv file containing the table dump. You need to specify the database name and the table name to the mysqldump client. Addendum: Use the fields-terminated-by switch of mysqldump with comma as a parameter. Thanks for the quick response. Is there anyway I can enable it ? You need to run GRANT FILE on ""*.*"" to @ (remove quotes around star-dot-star as Stackoverflow is eating them up) to grant it to a user (replace the user and host tags with appropriate values for your case). Since GRANT FILE is an administrative privilege you need to connect as root to execute it. thank you so much :) Thanks. But I do not understand why I should create file at server host??? I just want to create a file on my machine and export the data here. Could you please explain?? Is there no way to do it without using Grant File ?? As I do not have any kind of administrative access and unable to connect as root. :( Well in that case you'll need to write code (perhaps in Java itself) that will obtain all the rows of the table which you can save as a CSV file (if you format the results correctly). This link might help you in assessing other options: http://support.modwest.com/content/6/135/en/how-can-i-export-data-in-csv-or-tab-delimited-format.html Hi thanks again. I was able to get an account created for on the particular host. But my user account remains the same for mysql with same read access. In what way could I create the csv file now. I am not able to connect to that machine remotely either."
435,A,appfuse: should I configure jdbc credentials twice? New to appfuse - I like the concept. I configured the username/password to the database in jdbc.properties. It didn't work. So I also configured my credentials in pom.xml Why is it so? Am I doing something wrong? You should leave the jdbc.properties file alone with its ${xxx} value placeholders. Maven will take the properties in your pom.xml and at compile time replace the ${xxx} in your jdbc.properties resource file with the proper values. This action of injecting property values into resource files is configured by setting filtering to true via  <build> <resources> <resource> <directory>src/main/resources</directory> <filtering>true</filtering> </resource> </resources> A general rule of thumb is to never have the same properties (or code or data) in two different places. This duplication is almost always unnecessary and makes applications harder to maintain.
436,A,Few questions from a Java programmer regarding porting preexisting database which is stored in .txt file to mySQL? I've been writing a Library management Java app lately and up until now the main Library database is stored in a .txt file which was later converted to ArrayList in Java for creating and editing the database and saving the alterations back to the .txt file again. A very primitive method indeed. Hence having heard on SQL later on I'm considering to port my preexisting .txt database to mySQL. Since I've absolutely no idea how SQL and specifically mySQL works except for the fact that it can interact with Java code. Can you suggest me any books/websites to visit/buy? Will the book Head First with SQL ever help? especially when using Java code to interact with the SQL database? It should be mentioned that I'm already comfortable with using 3rd Party APIs. Java: Use JDBC to connect to a MySQL db: http://stackoverflow.com/questions/1640910/connecting-to-a-mysql-database Your main hurdle to overcome will be SQL - data modelling and querying. Excellent intro to SQL JOINs: http://www.codinghorror.com/blog/archives/000976.html View from 30000 feet: First you'll need to figure out how to represent the text file data using the appropriate SQL tables and fields. Here is a good overview of the different SQL data types. If your data represents a single Library record then you'll only need to create 1 table. This is definitely the simplest way to do it as conversion will be able to work line-by-line. If the records contain a LOT of data duplication the most appropriate approach is to create multiple tables so that your database doesn't duplicate data. You would then link these tables together using IDs. When you've decided how to split up the data you create a MySQL database and within that database you create the tables (a database is just something that holds multiple tables). Connecting to your MySQL server with the console and creating a database and tables is described in this MySQL tutorial. Once you've got the database created you'll need to write the code to access the database. The link from OMG Ponies shows how to use JDBC in the simplest way to connect to your database. You then use that connection to create Statement object execute a query to insert update select or delete data. If you're selecting data you get a ResultSet back and can view the data. Here's a tutorial for using JDBC to select and use data from a ResultSet. Your first code should probably be a Java utility that reads the text file and inserts all the data into the database. Once you have the data in place you'll be able to update the main program to read from the database instead of the file.  Know that the connection between a program and a SQL database is through a 'connection program'. You write an instruction in an SQL statement say  Select * from Customer order by name; and then set up to retrieve data one record at a time. Or in the other direction you write Insert into Customer (name addr ...) values (x y ...); and either replace x y ... with actual values or bind them to the connection according to the interface. With this understanding you should be able to read pretty much any book or JDBC API description and get started.
437,A,"Java JDBC driver and TYPE_FORWARD_ONLY How I could determine if JDBC driver is TYPE_FORWARD_ONLY? In my program the user configures connection parameters to database and he could use any JDBC driver in the class path. I want to know if the driver is TYPE_FORWARD_ONLY before executing any statements. Is this possible? By querying the type of result set. For example: Statement stmt = con.createStatement( ResultSet.TYPE_FORWARD_ONLY ResultSet.CONCUR_UPDATABLE ); ResultSet rs = stmt.executeQuery(""SELECT a b FROM TABLE2""); System.out.println( ""Is Type Forward Only: "" + (rs.getType() == ResultSet.TYPE_FORWARD_ONLY) ); Would this not throw a SQLFeatureNotSupportedException if the ResultSet did not support TYPE_FORWARD_ONLY?  There are Drivers that don't support scrolling? Could you give an example? What does such a driver return when you try to create a Statement/ResultSet that is SCROLL_SENSITIVE and then ask for the Type? Like this: Connection con = ...; Statement statement = con.createStatement(ResultSet.TYPE_SCROLL_SENSITIVE ...); System.out.println(statement.getResultSetType()); here's a discussion of one that I came across : http://osdir.com/ml/db.sqlite.jdbc/2008-05/msg00048.html  DatabaseMetaData has a method supportsResultSetType(int type) that you could use to check if the ResultSet supports TYPE_FORWARD_ONLY.  You can get DriverPropertyInfo from the driver although I can't find a specific jdbc specification that describes what the driver must return. This reference may have more."
438,A,"Mysql syntax exception from jdbc I'm trying to move the data from one table to another based on names which end with ""@localhost"" but while moving the data I'm getting an exception: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '@localhost' at line 1 The JDBC code which I've used to connect with MySQL is: / /package foo; import javax.sql.*; import java.sql.*; public class TablesUpdate { public static String MoveMessage(String s) { int count=0; try{ String query=""insert into deadletter(message_namerepository_namemessage_stateerror_messagesenderrecipientsremote_hostremote_addrmessage_bodymessage_attributeslast_updated) select message_namerepository_namemessage_stateerror_messagesenderrecipientsremote_hostremote_addrmessage_bodymessage_attributeslast_updated from inbox where sender=""+s+""@localhost;""; Connection con=databaseConnection(); Statement stmt=con.createStatement(); count=stmt.executeUpdate(query); } catch(Exception e) { e.printStackTrace(); } if(count>0) return ""Data has been moved""; else return ""There is no data""; } public static void main(String[] args) { TablesUpdate.MoveMessage(args[0]); } public static Connection databaseConnection() throws Exception { Class.forName(""com.mysql.jdbc.Driver"").newInstance(); return DriverManager.getConnection(""jdbc:mysql://localhost:3306/mail""""root""""""); } } I tried the value of query variable of above code in MySQL and it worked correctly. But why not here? MySQL driver I'm using: mysql-connector-java-5.1.5-bin.jar. You need to quote the string literal: where sender='""+s+""@localhost'; You also need to escape the string s to prevent SQL injection attacks (or preferably you should use prepared statements)."
439,A,Is there any JDBC Type 4 driver for DB2 v6? Does DB2 UDB v6 supports JDBC Type 4 drivers? Where can I get that JDBC Type 4 driver? I think yes but not very sure. As V6 is out of support most likely you would not be able to get it from IBM. You may want to check internally to see if they have any copies of the drivers. Check the below link for some useful information http://publib.boulder.ibm.com/infocenter/db2luw/v8/index.jsp
440,A,"Tomcat connection pooling install jdbc driver for web-app I am making a web-app with Tomcat 6 as the container and I'm trying to use connection pooling. The jdbc driver I am using is jtds-1.2.2. The pool works fine when the driver jar is placed under ${Catalina_Home}/lib but my hosting provider would not let me do so. I get a CNF-Exception when the driver is placed in the WEB-INF/lib. Could someone please provide a solution where I won't have to access the tomcat installation? and the Resource entry in server.xml? Does it crib for net.sourceforge.jtds.jdbc.Driver or some other class? yes actually. The exception says that Class net.sourceforge.jtds.jdbc.Driver was not found. I wanted to accept both Pascal's and BalusC's answers as both answered appropriately. no can't use server.xml for the same reason I can't place anything under tomcat's /lib. The Resource entry is in /META-INF/context.xml To use Tomcat's connection pool you must copy the JDBC Driver's jar into $CATALINA_HOME/lib (as documented) so that the driver class is visible through the Common class loader or DBCP won't be able to find it hence the ClassNotFoundException. Tomcat's class loaders hierarchy is illustrated below:  Bootstrap | System | Common / \ Webapp1 Webapp2 ... And libraries from WEB-INF/lib are not visible from the Common class loader (which is a good thing). If you can't copy your driver into $CATALINA_HOME/lib you won't be able to use Tomcat's connection pool. In that case you'll have to use a standalone connection pool (and to bundle it along your driver in WEB-INF/lib). And I second BalusC here I would use C3P0. Got it! Thank you :)  If you don't have control over the server then you're lost. Just create the connection pool yourself instead of letting the container do it. I suggest to use c3p0 for this (which is far better than Tomcat's builtin DBCP since it's locked to a single thread). Put the c3p0 libraries in the /WEB-INF/lib and create it as per its documentation: ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setDriverClass(""org.postgresql.Driver""); dataSource.setJdbcUrl(""jdbc:postgresql://localhost/testdb""); dataSource.setUser(""dbuser""); dataSource.setPassword(""dbpassword""); // ... Connection connection = null; // ... try { connection = dataSource.getConnection(); // ... } finally { // ... if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} // Always close resources in finally! } Good then I should go for c3p0 :). Thank you!"
441,A,"Code runs in Eclipse but gives compilation errors ""Cannot resolve symbol"" in CMD Here is my class: import java.sql.Connection; import java.sql.Statement; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.ResultSetMetaData; import java.sql.SQLException; public class DisplayAuthors { static final String JDBC_DRIVER = ""com.mysql.jdbc.driver""; static final String DATABASE_URL = ""jdbc:mysql://localhost/myfirstdb""; public static void main(String[] args) { Connection connection = null; Statement statement = null; try { Class.forName(JDBC_DRIVER); connection = DriverManager.getConnection(DATABASE_URL ""root"" ""1234""); statement = connection.createStatement(); ResultSet resultset = statement.executeQuery(""SELECT S_ID S_NAME AGE CLASS FROM MYOWN""); ResultSetMetaData metaData = resultset.getMetaData(); int numberOfColumns = metaData.getColumnCount(); System.out.println(""Table Content""); for(int i = 1; i<+numberOfColumns; i++) System.out.printf(""%-8s\t"" metaData.getColumnName(i)); System.out.println(); ResultSet resultSet; while (resultSet.next()) { for (int i = 1; i<+numberOfColumns; i++) System.out.printf(""%-8s\t"" resultSet.getObject(i)); System.out.println(); } } catch ( SQLException sqlException) { sqlException.printStackTrace(); System.exit(1); } catch ( ClassNotFoundException classNotFound) { classNotFound.printStackTrace(); System.exit(1); } finally { try { statement.close(); connection.close(); } catch ( Exception exception ) { exception.printStackTrace(); System.exit(1); } } } } This runs fine in Eclipse and outputs as follows: testing oracle-character-set-1 against <abc> PASSED LOSSY testing oracle-character-set-1 against <ab?c> PASSED LOSSY testing oracle-character-set-1 against <XY I also tried to compile and run in CMD but it gives the following compilation errors:  C:\My Java>javac DisplayAuthors.java DisplayAuthors.java:43: cannot resolve symbol symbol : method printf (java.lang.Stringjava.lang.String) location: class java.io.PrintStream System.out.printf( ""%-8s\t"" metaData.getColumnName( i ) ); ^ DisplayAuthors.java:49: cannot resolve symbol symbol : method printf (java.lang.Stringjava.lang.Object) location: class java.io.PrintStream System.out.printf( ""%-8s\t"" resultSet.getObject( i ) ); ^ 2 errors How can I fix this? In the future please post the **actual** code not a changed/untested version. There are too much red herrings in your code. Updated your code with Couple of changes. It should atleast compile now :). import java.sql.Connection; import java.sql.Statement; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.ResultSetMetaData; import java.sql.SQLException; public class DisplayAuthors { static final String JDBC_DRIVER = ""com.mysql.jdbc.Driver""; static final String DATABASE_URL = ""jdbc:mysql://localhost/myfirstdb""; public static void main(String[] args) { Connection connection = null; Statement statement = null; try { Class.forName(JDBC_DRIVER); connection = DriverManager.getConnection(DATABASE_URL ""root"" ""1234""); statement = connection.createStatement(); ResultSet resultset = statement .executeQuery(""SELECT S_ID S_NAME AGE CLASS FROM MYOWN""); ResultSetMetaData metaData = resultset.getMetaData(); int numberOfColumns = metaData.getColumnCount(); System.out.println(""Table Content""); for (int i = 1; i < +numberOfColumns; i++) System.out.printf(""%-8s\t"" metaData.getColumnName(i)); System.out.println(); // ResultSet resultSet; while (resultset.next()) { for (int i = 1; i < +numberOfColumns; i++) System.out.printf(""%-8s\t"" resultset.getObject(i)); System.out.println(); } } catch (SQLException sqlException) { sqlException.printStackTrace(); System.exit(1); } catch (ClassNotFoundException classNotFound) { classNotFound.printStackTrace(); System.exit(1); } finally { try { statement.close(); connection.close(); } catch (Exception exception) { exception.printStackTrace(); System.exit(1); } } } }  You have 2 variables: resultset and resultSet. The second is not used and should be deleted. And in your while block replace resultSet with resultset. Also replace the line static final String JDBC_DRIVER = ""com.mysql.jdbc.driver""; with static final String JDBC_DRIVER = ""com.mysql.jdbc.Driver"";  Those compilation errors means that the method PrintStream#printf() cannot be found. As per the linked javadoc it was introduced in Java 1.5. Since:  1.5 This means that you're using Java 1.4 or older in CMD. Check your PATH and JAVA_HOME environment variables it should point to Java 1.5 or newer. That said there are at least three other major problems in your JDBC code: You should never call System#exit(); in a catch block with a finally because this way the finally will never be invoked. Here you're thus still leaking the connection and statement. Put the System#exit() at end of the code instead. You forgot to close() the ResultSet in finally as well. Closing of connection statement and resultset should each happen in its own try-catch block because closing can throw an exception. Imagine that closing the statement throws an exception then the connection will never be closed. So do this instead: } finally { if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} }  Your code path is not buildtry creating a new project and add the external libraries.Npw copy paste the source code in a new class. TRY IT!!IT WORKS FOR ME"
442,A,"JDBC PoolingDataSource vs PoolingDriver With reference to apache commons dbcp what is the difference between PoolingDataSource and PoolingDriver? The source code states ""Note that this example is very similiar to the PoolingDriver example. In fact you could use the same pool in both a PoolingDriver and a PoolingDataSource"" However it does not explicit state the differences PoolingDriver implements the Driver interface so you could use that wherever you need a java.sql.Driver. And similarly  PoolingDataSource implements the DataSource interface. (e.g. some frameworks need you to pass a reference to a Driver or DataSource  if you want them pooled you use one of PoolingDataSource or PoolingDriver -)"
443,A,"AbstractMethodError when invoking createArrayOf with postgresql 8.4 jdbc4 and JBoss 5.1GA when using this method public List<Field> getFieldWithoutId(List<Integer> idSections) throws Exception { try { Connection conn = this.getConnection(); Array arraySections = conn.createArrayOf(""int4"" idSections.toArray()); this.log.info(""Recupero field""); List<Field> fields = this.getJdbcTemplate().query(getFieldWithoutIdQuery new Object[] {arraySections}ParameterizedBeanPropertyRowMapper.newInstance(Field.class)); /*if (!conn.isClosed()) conn.close(); */ releaseConnection(conn); return fields; } catch (Exception e) { e.printStackTrace(); throw new Exception(""Errore.""); } } I have an exception at conn.createArrayOf(""int4"" idSections.toArray());. The exception is: javax.ejb.EJBException : Unexpected Error java.lang.AbstractMethodError: org.jboss.resource.adapter.jdbc.jdk5.WrappedConnectionJDK5.createArrayOf(Ljava/lang/String;[Ljava/lang/Object;)Ljava/sql/Array; postgresql-8.4-701.jdbc4.jar is in jboss/server/all/lib dir. Application is spring based with ejb3. When working locally with the same setup everything is fine. This only happens on a preproduction environment. Only difference is locally I have jboss run in default mode in the other case there are 2 jbosses in all configuration. I can't track down the cause of this error. Could someone help me please? java.lang.AbstractMethodError This means that an abstract method which is declared in some API in the current runtime classpath is missing in the concrete implementation in the current runtime classpath. org.jboss.resource.adapter.jdbc.jdk5.WrappedConnectionJDK5.createArrayOf(Ljava/lang/String;[Ljava/lang/Object;)Ljava/sql/Array; Given the fact that it works fine in local environment but not in preproduction environment it would mean that the environments are using a different JBoss server version and/or that the deployed webapplication unnecessarily contains JBoss-specific libraries in the /WEB-INF/lib. At least the classpath is messed up. Cleanup it. JBoss version is the same and EAR content is this : 1) lib folder with ejbclient.jar with no libraries 2) META-INF folder with Manifest 3) backend.jar that contains : 1) META-INF folder with manifest and spring config files 4) one webapp currently almost empty with no libraries anyway Could you point me to the right way of cleaning classpath? Just go through all paths covered by the webapp's classpath check if you don't see version collisions in JAR files with same classes. Maybe those libraries are in the `/JRE/lib` or `/JRE/lib/ext`. I'll check this out thanks!  I suspect you just hit this: https://bugzilla.redhat.com/show_bug.cgi?id=730588"
444,A,"Can someone help me with some beginners JDBC? As a C# developer new to Java i thought it might be easiest if i simply show a bit of C# code so i can see what the equivalent Java JDBC calls are: String myConnectionString = ""...""; String mySql = ""select name from people where id = @myId""; int myId = 123456; List<Field> fields = new List<Field>(); using (SqlConnection conn = new SqlConnection(myConnectionString) { conn.Open(); using (SqlCommand cmd = new SqlCommand(mySqlconn)) { cmd.Parameters.AddWithValue(""@myId"" myId); using(SqlDataReader rdr = cmd.ExecuteReader()) { while (rdr.Read()) { String name = rdr.GetString(0); fields.Add(name); } } } } Now i know that the using statements above will safely close the database if anything goes wrong whereas with java it's a bit more complicated (try..finally or something). And in java i'm not sure what exactly needs to be disposed or closed (or whatever) - the connection only? Or the statement as well? If you could give me a leg up that'd be great. Thanks a lot edit: I really like the code here: (http://stackoverflow.com/questions/1909662/java-exception-handling-style) Connection conn = MyDatabaseLayer.getConnection(); try { ... use conn ... } finally { conn.close(); } However do i need to do any further exception handling to ensure the statement and reader and all that other stuff gets closed? Or is closing the connection enough? you get a connection statement result set in that order. It helps to think of them as nested - if you close the connection it closes the statement. If you close the statement it closes the result set. All of this is in the javadoc. You indeed need a try-finally block here. The Java equivalent of the using keyword will be introduced in the upcoming Java 7. A Java port of your code would look like: // Prepare. String url = ""...""; String sql = ""SELECT name FROM people WHERE id = ?""; int id = 123456; List<String> names = new ArrayList<String>(); // Declare before try. Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; try { // Acquire inside try. connection = DriverManager.getConnection(url); statement = connection.prepareStatement(sql); statement.setInt(1 id); resultSet = statement.executeQuery(); // Process results. while (resultSet.next()) { names.add(resultSet.getString(""name"")); } } finally { // Close in reversed order in finally. if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } When not using connection pooling closing the Connection alone would in most cases also close the Statement and ResultSet. Although not strictly specified in the JDBC API the average JDBC driver would implicitly do that. But this is not the normal JDBC idiom. You should really close all the resources explicitly. This makes your code safely reusable for the case that you'd like to introduce connection pooling. See also: Equivalent of ""using"" keyword in Java JDBC tutorial JDBC connection pooling practices JDBC connectivity with MySQL Thanks: Wow didn't realise how much syntactic sugar 'using' was... Do i really need to close the resultset and the statement in the finally block? Can i get away with not worrying about those and simply close them in the try block? Is an un-closed resultset going to cause a leak? It's not the normal idiom. You could however create a ""helper"" method for that like `close(connection statement resultSet);` so that you can hide the verbosity away in the depths. To get a step further you can go for [JPA](http://download.oracle.com/javaee/6/tutorial/doc/bnbpy.html) (or [Hibernate](http://hibernate.org)) to have an extra abstraction layer over JDBC. If you do not want to go all the way to JPA/JDO/Hibernate have a look at Apache Commons DbUtils which is a think wrapper over JDBC that takes care of resource cleanup. Thanks for the tips guys. I'll stick with raw jdbc for this i'd like to understand JDBC. That's a really ugly way of doing it. `acquire(); try { use(); } finally { release(); }` for every resource. The Execute Around idiom may help. @Tom: That was subjective. Know what post a **full rewrite** of the above code in a new answer here and let the community decide.  Here's a rough explanation of the steps as liberally copied from some random page: first you load the driver. This will be a class in your driver jar file. In many environments you get this actually from a datasource this is sort of old fashioned but probably better to see the nuts and bolts. Class.forName(""com.imaginary.sql.msql.MsqlDriver""); then you get a connection:  Connection conn = DriverManager.getConnection(""jdbc:msql://www.myserver.com:1114/...."" ""user1"" ""password""); The url string tends to be different for different db vendors. Luckily we don't swap databases too often so you only need to look it up once. Now you can finally use the damned thing. PreparedStatement ps = conn.prepareStatement(""SELECT * FROM FOO WHERE A=?"" 1); A prepared statement gets cached so you can use it with inseted parameters. It will work with a plain SQL statement but for that you can just use a statement. You can also just call conn.executeQuery(...) to get a resultSet which is what you want.  ResultSet rs = ps.executeQuery(); Now you can loop through the rs and get whatever: while (rs.next()) { .. } ResultSets also have ResultSetmetadata which gives you things like the column names # of columns (but not the total # of results which would be too easy). As for try catch you need to close your statement/result set after you use them. Every time. Otherwise bad things will happen. Like leaving open resources on your db. Since your db connect method can throw errors you rap the whole thing in a try catch and close your statement (and connection if you've made it here) in a finally block. This is why people use ORM frameworks in java. Thanks. Your last line made my day: ""This is why people use ORM frameworks in java"" If you do not want to go all the way to ORM/JPA/JDO/Hibernate have a look at Apache Commons DbUtils which is a think wrapper over JDBC that takes care of resource cleanup."
445,A,Importing Data from a Microsoft Access File on a Mac I have an MS-Access mdb file that I need to import data from into my mysql instance. I am on a mac is there any free/OSS tools that allow me to do that? If not is there a free/OSS JDBC driver that I can use to extract the data I need? Thanks. Have a look at Jackcess. Note that this doesn't support Access 97 databases however only 2000+. For Access 97 the only thing I'm aware of is mdbtools but that's a C library so you'll have to write some JNI glue code if you want to use it from Java; also it's not maintained anymore to the best of my knowledge. Jackcess worked after some memory tweaking thanks!  You could export the MDB file using something like this. This won't help you if you need to do it from within your app but if you are ok exporting the data then using it then this should help.  Is your Access MDB on mac? Does the mac Access have the option of using linked tables? If so you can create a Linked Table from Access MDB to mySQL. Then you could treat mysql tables as if it were part of MS-Access. EDIT: See if this helps. I only have the mdb file I don't have Microsoft Access Application. What I want is the other way round importing from that file into my mysql database. I dont want to have to buy Microsoft Access to do that. You don’t need to install ms-access on a win computer to pull data out. You can even use windows scripting to pull data out as text. All recent versions of windows (even going back to win 2000) have the ability to pull data out of an mdb file without having to install ms-access. So no additional software need be installed on a windows box to pull out data from a mdb table. Your problem here is not purchasing ms-access. Purchasing ms-access will not help you unless you have a place to install ms-access (which as I mentioned you don’t need anyway). Do you have boot camp? Hmm I don't have a windows license and I don't want to buy one. Neither do I want to buy Office for Mac. Even if I run boot camp I still need a windows license. My problem is solved however by Jackcess as suggested above thanks everyone for the replies. Access does not and has never run on Macs.
446,A,"Query does not work with a parameter marker with preparedStatement Excerpt from code PreparedStatement preparedStatement = connection.prepareStatement(""SELECT * FROM sch.tab1 where col1 like lower ( 'ABZ' ) ""); preparedStatement.executeQuery(); The above code executes successfully. But when i try to execute this PreparedStatement preparedStatement = connection.prepareStatement(""SELECT * FROM sch.tab1 where col1 like lower ( ? ) ""); preparedStatement.setString ( myValue ); preparedStatement.executeQuery(); It throws an exception.""STRING TO BE PREPARED CONTAINS INVALID USE OF PARAMETER MARKERS"" What could be the problem here? Answer found see the comments i found the answer. thanks to Paul Chernoch. -- SELECT * FROM sch.tab1 where col1 like lower ( '' || ? ) -- This is potentially jdbc-driver-dependent. What's your database? Given the tags I'd assume db2. @skaffman i am using DB2 For reference: I ran into the same problem while using the NORMALIZE_STRING function: SELECT NORMALIZE_STRING(? NFKD) FROM sysibm.sysdummy1 Error message: THE DATA TYPE LENGTH OR VALUE OF ARGUMENT 1 OF NORMALIZE_STRING IS INVALID. SQLCODE=-171 SQLSTATE=42815 DRIVER=4.13.111 Using the following statement solved the problem (CONCAT). Thanks to Paul Chernoch! SELECT search_normalize(NORMALIZE_STRING(? CONCAT G'' NFKD)) FROM sysibm.sysdummy1 Note the ""G"" prefix for Unicode compatibility.  I think Carlos is on to something. Try SELECT * FROM sch.tab1 where col1 like lower ( '' + ? ) or whatever passes for string concatenation operator in your version of SQL. Forcing a string context might get you past the error. May require extra parentheses. ** '' + ? **  i never knew you can use + operator for string in SQL. atleast in DB2 you can not use. Accepting as `SELECT * FROM sch.tab1 where col1 like lower ( '' || ? )` will work  I suspect the problem is that you can't apply functions directly to parameters. Is there any particular reason why you want the lower casing to be performed at the database rather than in your code? (I can think of some potential reasons admittedly.) Unless you really need to do this I'd just change the SQL to: SELECT * FROM sch.tab1 where col1 like ? and call toLower() in Java preferably specifying the appropriate locale in which to perform the lower-casing. Currently i am doing ""preparedStatement.setString ( 1 myValue.toLower() ); "" as a work around but why it is not possible to do by using markers? I don't know - it could be a DB2 restriction or possibly one in their JDBC driver. An alternative would be to create a stored proc which did the lower-casing for you... maybe because the driver would not be able to determine the correct data type for the argument..."
447,A,JDBC Video Tutorials I am trying to learn how to connect my Java code to an MySQL database. I am looking for some good video tutorials (if none exists I'd be interested in non-video tutorials). Thanks in advance this will really help me! I ever wrote a [little JDBC+MySQL tutorial](http://stackoverflow.com/questions/2839321/java-connectivity-with-mysql/2840358#2840358) here you may find it useful as well. +1. Me too. I'm learning java after doing .NET for years and I'm amazed at how hard it is to find training resources for such a popular platform. I am betting I just don't know where to look yet. Thank you for asking this for me as well. java2s will help you  Start with sun tutorial. IMHO its the best. Sun has been taken over by Oracle :) +1. Nice. Do you know where I would find missing information such as how to connect to a SQL server or DB2 where to find and how to install appropriate JDBC drivers etc? I am having a bear of a time just getting my first connection to a SQL server to work and all of the tutorials like this one seem to completely ignore such info. The connection strings are specific to database and sometimes to driver. You have to check individual driver documentation for those details. This is the one for mysql with examples and details http://dev.mysql.com/doc/refman/5.1/en/connector-j.html Perfect. Thank you. I found the SQL Server connector and finally got it to work via the tutorial on MSDN.  Take a look at this. Nice tutorial. http://www.herongyang.com/JDBC/ \m/
448,A,"Caching a resultset My app will retrieve a countylist from MySql using a datasource bean. Since all pages will potentially use the same recordset every time I could store the countrylist as a List in some global bean safe in this case. I could manage to refresh the list any time I want... but when things become more complex what is the best strategy for it the more scalable solution? Use a in memory database? A 3rd part cached resultset? didnt found one probably because I'm to new to the subject. What do you mean with ""more complex""? What do you mean with ""refresh anytime""? Is the data changed everytime *externally*? Use CachedRowSet. It can be treated like a ResultSet but it doesn't need to maintain a connection to the database.  ResultSet is tied to the database connection it's a fairly ephemeral construct and not suitable for caching. I recommend using EhCache to cache your results. It's an in-memory cache mechanism (with options to overflow to disk and options to distribute across a cluster). It integrates very nicely with Spring (via EhCacheManagerFactoryBean and EhCacheFactoryBean). not much time to test but I will give a try! just saw a little article explaining its basics but the basic need a bit of preparation. anyway its said to be scalable and like you said goes well with spring. thanks!  If the country list is updated almost never fill a FastMap on application startup with the map keys being the two letter country abbreviations and the values being other info you want to store for each country. Otherwise use an in-memory DB cache such as EhCache and Memcached."
449,A,"jdbc query - date ranges as parameters I'd like to write a single JDBC statement that can handle the equivalent of any number of NOT BETWEEN date1 AND date2 where clauses. By single query i mean that the same SQL string will be used to create the JDBC statements and then have different parameters supplied. This is so that the underlying frameworks can efficiently cache the query (i've been stung by that before). Essentially I'd like to find a query that is the equivalent of SELECT * FROM table WHERE mydate NOT BETWEEN ? AND ? AND mydate NOT BETWEEN ? AND ? AND mydate NOT BETWEEN ? AND ? AND mydate NOT BETWEEN ? AND ? and at the same time could be used with fewer parameters: SELECT * FROM table WHERE mydate NOT BETWEEN ? AND ? or more parameters SELECT * FROM table WHERE mydate NOT BETWEEN ? AND ? AND mydate NOT BETWEEN ? AND ? AND mydate NOT BETWEEN ? AND ? AND mydate NOT BETWEEN ? AND ? AND mydate NOT BETWEEN ? AND ? AND mydate NOT BETWEEN ? AND ? I will consider using a temporary table if that will be simpler and more efficient. thanks for the help! A prepared statement has a fixed amount of parameters. In some cases (like IN() ) you can work with array's to overcome this issue but in your case that's not going to work. A temporary table will do the job just join ON (mydate BETWEEN startdate AND enddate) when you temp table has the columns ""startdate"" and ""enddate"". Inserting and deleting rows from from your temp table changes the amount of parameters. Arrays don't work in `IN`. You still need to autogenerate placeholders yourself. Array's work great but you have to transform the IN into = ANY(?). Send the string '{123}' as parameter and it works fine.  You just need to generate the SQL string on the fly. E.g. public List<Data> find(List<BetweenDate> betweenDates) throws SQLException { StringBuilder sql = new StringBuilder(""SELECT * FROM table WHERE ""); for (int i = 0; i < betweenDates.size();) { sql.append(""mydate NOT BETWEEN ? AND ?""); if (++i < betweenDates.size()) sql.append("" AND ""); } Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; List<Data> result = new ArrayList<Data>(); try { connection = database.getConnection(); statement = connection.prepareStatement(sql.toString()); for (int i = 0; i < betweenDates.size(); i++) { preparedStatement.setObject((i * 2) + 1 betweenDates.get(i).getStartDate()); preparedStatement.setObject((i * 2) + 2 betweenDates.get(i).getEndDate()); } resultSet = statement.executeQuery(); // ..."
450,A,Java - MySQL - Temporary Tables I periodically receive data that I use to update my database with. The external structure differs from my internal structure so what I end up doing is running the import and then running alter table commands. I do this manually. After I format it to my liking I export the data and then import it into my existing schema. My questions are: 1. How can I isolate the external SQL so that it does not adversely affect my database? Ideally I would like to run it as another user in another database / workspace. Should I create a database temporarily and then drop it once this operation is complete? Should I connect directly using JDBC to run all these queries since there will be a large sum of data? I am using Hibernate along with C3P0 to manage the primary connection. Lastly is there an API to automate/simplify exporting to SQL? If I go the JDBC route I can iterate through each row and create the insert statements from that. Any ideas? Thanks Walter IMO its better to do that outside of Hibernate using simple JDBC. Just create a connection for this thing and execute all SQL statements. In the end close the connection. This way its handy to make a connection to another temporary database if you choose this route. You will not need to configure all that into your Hibernate configuration. Other way is to go with Hibernate and let it create the schema for you using entity objects and their mappings. This way you don't need to manually come up with the database structure required it will be automatically created by Hibernate. I am using Hibernate to create the structure. Basically I am importing data from another website and changing its structure into mine which names columns differently as well as store only the pertinent information. There is some duplication with the data so I normalize it by simply using foreign keys where the imported data was not. I guess it makes the most sense to do these operations in another database / connection. JDBC seems like the best route and will be good practice to use something I haven't used directly for 3 years. Walter
451,A,"ant sql task throws ""no ResultSet available"" with org.sqlite.JDBC driver I'm trying to use org.sqlite.JDBC to create and update a sqlite database in ant. The sqlitejdbc-v056.jar comes from http://www.zentus.com/sqlitejdbc/ and is the latest version (056) This is my build.xml: <?xml version=""1.0"" encoding=""utf-8""?> <project name=""My Project"" default=""mytarget"" basedir="".""> <path id=""antclasspath""> <fileset dir=""_ant""> <include name=""*.jar""/> </fileset> </path> <target name=""mytarget""> <property name=""antclasspathar"" refid=""antclasspath"" /> <echo message=""Classpath is ${antclasspathar}""/> <sql driver=""org.sqlite.JDBC"" url=""jdbc:sqlite:C:/Projects/dummy/test.db"" userid="""" password="""" classpathref=""antclasspath"" > DROP TABLE IF EXISTS people; CREATE TABLE people (name occupation); </sql> </target> </project> This is the output I get: C:\Projects\dummy>ant -v Apache Ant version 1.7.1 compiled on June 27 2008 Buildfile: build.xml Detected Java version: 1.6 in: C:\Program Files (x86)\Java\jdk1.6.0_10\jre Detected OS: Windows Vista parsing buildfile C:\Projects\dummy\build.xml with URI = file:/C:/Projects/dummy/build.xml Project base dir set to: C:\Projects\dummy [antlib:org.apache.tools.ant] Could not load definitions from resource org/apache/tools/ant/antlib.xml. It could not be found. Build sequence for target(s) `mytarget' is [mytarget] Complete build sequence is [mytarget ] mytarget: [echo] Classpath is C:\Projects\dummy\_ant\sqlitejdbc-v056.jar [sql] connecting to jdbc:sqlite:C:/Projects/dummy/test.db [sql] Loading org.sqlite.JDBC using AntClassLoader with classpath C:\Projects\dummy\_ant\sqlitejdbc-v056.jar [sql] Executing commands [sql] SQL: DROP TABLE IF EXISTS people [sql] Failed to execute: DROP TABLE IF EXISTS people BUILD FAILED java.sql.SQLException: no ResultSet available at org.sqlite.Stmt.getResultSet(Stmt.java:111) at org.apache.tools.ant.taskdefs.SQLExec.execSQL(SQLExec.java:567) at org.apache.tools.ant.taskdefs.SQLExec.runStatements(SQLExec.java:535) at org.apache.tools.ant.taskdefs.SQLExec$Transaction.runTransaction(SQLExec.java:764) at org.apache.tools.ant.taskdefs.SQLExec$Transaction.access$000(SQLExec.java:706) at org.apache.tools.ant.taskdefs.SQLExec.execute(SQLExec.java:449) at org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:288) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:106) at org.apache.tools.ant.Task.perform(Task.java:348) at org.apache.tools.ant.Target.execute(Target.java:357) at org.apache.tools.ant.Target.performTasks(Target.java:385) at org.apache.tools.ant.Project.executeSortedTargets(Project.java:1337) at org.apache.tools.ant.Project.executeTarget(Project.java:1306) at org.apache.tools.ant.helper.DefaultExecutor.executeTargets(DefaultExecutor.java:41) at org.apache.tools.ant.Project.executeTargets(Project.java:1189) at org.apache.tools.ant.Main.runBuild(Main.java:758) at org.apache.tools.ant.Main.startAnt(Main.java:217) at org.apache.tools.ant.launch.Launcher.run(Launcher.java:257) at org.apache.tools.ant.launch.Launcher.main(Launcher.java:104) Total time: 0 seconds DDL (Data Definition Language e.g. CREATE DROP etc) statements does not return a ResultSet while your Ant script is apparently expecting it. At least the SQLException is basically telling that you. I don't do Ant extensively so I can't go in detail but you at least need to change the script so so that no return value is expected. I'm going to accept this answer even though it states ""this doesn't work"". I fear it is the only correct answer. This would mean that I can't use the sql ant task with DDL statements. Not the answer I was hoping for. :-("
452,A,"How to execute IN() SQL queries with Spring's JDBCTemplate effectivly? I was wondering if there is a more elegant way to do IN() queries with Spring's JDBCTemplate. Currently I do something like that: StringBuilder jobTypeInClauseBuilder = new StringBuilder(); for(int i = 0; i < jobTypes.length; i++) { Type jobType = jobTypes[i]; if(i != 0) { jobTypeInClauseBuilder.append(''); } jobTypeInClauseBuilder.append(jobType.convert()); } Which is quite painful since if I have nine lines just for building the clause for the IN() query. I would like to have something like the parameter substution of prepared statements. I cannot imagine I am the only person who is annoyed by this fact and I'm asking here to get a solution. Thanks a lot in advance! lutz: A bit redundant comment are you sure you know the full context of this question? The answer above by yawn sounds perfect but no such version of the query(...) method seems to exist in spring 2.5.6. Was it removed? Or is there some other silly reason I can't find it? Whats the exact signature of the method I should be looking for? You want the ones with 'named parameter support' http://static.springsource.org/spring/docs/2.5.x/api/org/springframework/jdbc/core/simple/SimpleJdbcTemplate.html#query(java.lang.String%2C%20org.springframework.jdbc.core.simple.ParameterizedRowMapper%2C%20java.util.Map%29  I do the ""in clause"" query with spring jdbc like this: List l = Arrays.asList(new Integer[]{12496124971249812499}); Map<String List> param = Collections.singletonMap(""goodsid""l); NamedParameterJdbcTemplate namedParameterJdbcTemplate = new NamedParameterJdbcTemplate(getJdbcTemplate().getDataSource()); String sql = ""SELECT bg.goodsid FROM beiker_goods bg WHERE bg.goodsid in(:goodsid)""; List<Long> list = namedParameterJdbcTemplate.queryForList(sql param2 Long.class); You just posted an answer to a almost three year old question with the same solution as the accepted answer had. Is there any good reason behind this? :-) Maybe i show more details for the question.  You want a parameter source: Set<Integer> ids = ...; MapSqlParameterSource parameters = new MapSqlParameterSource(); parameters.addValue(""ids"" ids); List<Foo> foo = getJdbcTemplate().query(""SELECT * FROM foo WHERE a IN (:ids)"" getRowMapper() parameters); Part of Spring since 2.0 btw Perfect the NamedParameterJdbcTemplate was exactly what i was looking for. Additionally i like named parameters more than those question marks all over the place. Thanks a lot! You're welcome! This works for small lists but attempting to use it on a large list results in a query where :ids is replaced with ""?????......"" and with enough list items it overflows. Is there a solution that works for large lists? You should probably insert the values into a temporary table and build the condition using `WHERE NOT EXISTS (SELECT ...)`. To comlete answer: [Spring 3.1 Reference — Passing in lists of values for IN clause](http://static.springsource.org/spring/docs/3.1.0.RELEASE/reference/html/jdbc.html#jdbc-in-clause). But in Reference was nothing said about: [it is possible to pass any Collection](http://grepcode.com/file/repository.springsource.com/org.springframework/org.springframework.jdbc/3.0.6/org/springframework/jdbc/core/namedparam/NamedParameterUtils.java/#206). thanksIt's a new way to do ""in clause"" with spring jdbc. strange i get ""error code [17004]; Invalid column type"" when I try this. @yawn Is it possible to return a `Map>` for `List` as in your answer . my [Question here](http://stackoverflow.com/questions/25405095/using-a-query-inside-rowmapper)  I don't think there is unfortunately. To concatenate your fields into an IN() clause you should look at Apache Commons and StringUtils.join(). I know that's not quite the answer you're looking for but it does simply the the above. EDIT: yawn (above) has identified the existing method. Not quite what im looking for but may help to ease the pain. Thanks! Yes. Unfortunately I think that's your only option. I've been there before :-(  If you get an exception for : Invalid column type Please use getNamedParameterJdbcTemplate() instead of getJdbcTemplate() This doesn't seem to be an answer to this question. Should it be a comment on another answer?"
453,A,"Chinese characters cannot be shown after saving and retrieving from Oracle Database Up to this moment I still have no luck to resolve this Chinese characters issue. I am using OC4J 9.0.4.1 with Oracle 10g Database (that is created with UTF-8). The situation is that my JSP page is set with pageencoding = UTF-8 already. I save some Chinese characters from web page to database (varchar2 column) via Thin Driver. In iSQLPlus those Chinese characters cannot be shown. Then the content is retrieved by using ResultSet.getString. When the content is placed back to JSP Page it shwos monster characters. Anyone can help ? The background information of the settings: NLS_LANGUAGE AMERICAN NLS_TERRITORY AMERICA NLS_CHARACTERSET AL32UTF8 NLS_LENGTH_SEMANTICS BYTE NLS_NCHAR_CHARACTERSET AL16UTF16 NLS_RDBMS_VERSION 10.2.0.1.0 System.getProperty(""file_encoding"") = MS950 Anyone can help ? I save some Chinese characters from web page to database (varchar2 column) via Thin Driver. In iSQLPlus those Chinese characters cannot be shown You need to set the request body encoding to the same encoding as the pageEncoding of the JSP before obtaining the parameters. request.setCharacterEncoding(""UTF-8""); Note that the above applies on POST requests only (I expect you're using POST here) for GET request parameters you need to configure it in the servletcontainer level. See also: Unicode how to get the characters right? But ... they are JSP pages that directly get String from Oracle Database via thin driver and shown on browser. Those parameters are not from request. You told that you **saved** some characters from web page to database and that they cannot be shown in iSQLPlus. So something went wrong during saving. Yes I need to do soemthing special during saving ? I use: sqlStr = ""UPDATE blah blah blah"" stmt = dbConn.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE ResultSet.CONCUR_UPDATABLE); intResult = stmt.executeUpdate(sqlStr); No. You need to ensure that the submitted data is been processed as UTF-8 everywhere. See my answer and if necessary also the link in it. Thanks for you help. Your answer solved my problem. You're welcome."
454,A,"Spring's JdbcTemplate read only connection exception I've a function updating a database table using Spring's JdbcTemplate and for some reason there was exception about the fact that the connection is read only and can't update any database related changes. How to resolve this problem? Check the transaction property. Is it Read-Only? http://static.springsource.org/spring/docs/2.0.x/reference/transaction.html Try adding this to the datasource defination  <property name=""defaultReadOnly""> <value>false</value> </property> This would rather solve the problem... Thank you for reply.. But actually i had given a property to Transaction advice like this and it was causing the problem.... As u can see i had now commented the code of line which are making my all methods connection read only... Again Thanks for the reply."
455,A,"JDBC connect string for SQL Server cluster I need to setup a JDBC connection string to SQL Server. This question is similar to the the C# ADO.Net connection question. This one is specific to JDBC connection strings. The usual format for the JDBC string is ""jdbc:sqlserver://{host}:{port}"". Now for a SQL server cluster I have a cluster name vvv\iii ({virtual server}{instance name}). There's no problem setting up an ODBC connection through the ""New Data Source to SQL Server"" wizard when using the vvv\iii string as the server name. However it seems the JDBC connection string requires a specific host and port. Is there a way to make a JDBC connect string to a SQL Server cluster? The cluster resource has a host name and a listening port. Use jdbc:sqlserver://{virtualserver}:1433 (or the appropriate listening port if not listening on the default one).  When using a SQL Server named instance in a cluster or stand alone environment each SQL Server instance is dynamically assigned a port number on startup. The SQL Server Browser server handles requests to each instance because each server restart could change the port number used by each instance. The first instance to start on a server reboot gets assigned 1433 but there is no guarantee if you have 2 instances that one of them will always get 1433. There are several veriables that affect the startup and recovery time it takes for an instance to start. This can change each time. That being sad... when connecting to a named instance the jdbc connection string should look like this: jdbc:sqlserver://server_name/db_name;instance=instance_name rather than this jdbc:sqlserver://server_name:1433/db_name;instance=instance_name note that the default database ""/db_name"" is optional. If exclued the connection will use the default database assigned to the SQL Server login.  I'd comment Mark Stewart's remark but the reputation is lacking. My source doesn't mention /db_name and I can't get it to work either. Maybe another case of confused instance names?  Make sure you leave the port definition off as the cluster determine this for you. So my datasource definition looks like: jdbc:sqlserver://sqlcluster_hostname\instancename;DATABASENAME=databasename;sendStringParametersAsUnicode=false;SelectMethod=direct I ran into this issue while trying to setup a Railo datasource to connect to MSSQL cluster. Slightly off topic ... The standard Railo datasource MSSQL driver option sets the port to ""-1"" if you leave the port field empty however if you set it to ""0"" then it removes the port definition altogether and then everything works. But the best way is to choose 'Other - JDBC Driver' to define the JDBC connection string in full as above.  it turns out that you can use the ""instanceName"" property within the JDBC string as documented on the Microsoft Technet page in section ""Named and Multiple SQL Server Instances"". What worked in my case was the following string for virtual server vvv and database instance name iii: ""jdbc:sqlserver://vvv;instanceName=iii"" I dislike to accept my own answer but it's the best one so far ;-)"
456,A,"How to correctly use ResultSet with h:dataTable The problem is that after displaying the ResultSet with <h:dataTable> the connection is left open. If I close it it closes the ResultSet too. I'm thinking about copying the ResultSet data into some HashMap/ArrayList combo. Is there a good way to deal with this problem? Indeed you should always acquire and close the Connection Statement and ResultSet in the shortest possible scope (preferably already inside the very same method block) and you should never pass any of them outside the DAO class. You need to map the ResultSet to a List<Data> wherein Data represents each row of the table. Here's a basic example how to map a resultset: List<Data> items = new ArrayList<Data>(); ... while (resultSet.next()) { Data item = new Data(); item.setColumn1(resultSet.getString(""column1"")); item.setColumn2(resultSet.getString(""column2"")); items.add(item); } ... return items; Then you can just use it in the h:dataTable's value attribute. For more examples and insights you may find one or both of the following articles useful: http://balusc.blogspot.com/2006/06/using-datatables.html http://balusc.blogspot.com/2008/07/dao-tutorial-data-layer.html Good luck. Thanks works really well!  Are you using ResultDataSetModel? If yes note that in javadoc stays Note that the specified ResultSet MUST be scrollable. Statement stmt=connection.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE ResultSet.CONCUR_READ_ONLY); Here is a complete example of ResultDataSetModel usecase.  Please check the following link: http://www.coderanch.com/t/478265/JSF/java/Displaying-array-data-tables#2585794 I am sure helps you to resolve your problem"
457,A,"iBatis 3 - JNDI configuration example The iBatis framework has been significantly tweaked between versions 2 & 3 so much that even the config file (now often referred to as MapperConfig.xml) is different. That being said there are lots of examples online on how to create a JDBC connection pool with iBatis but I couldn't find one example on how to do it with JNDI. There is an updated user guide at: http://svn.apache.org/repos/asf/ibatis/java/ibatis-3/trunk/doc/en/iBATIS-3-User-Guide.pdf which does refer to the JNDI settings on page 19 but I still couldn't it get it correctly communicate with the database. A working example of a JDNI (container managed connection pool) in iBatis 3 would be greatly appreciated!! Assuming you've already got a JNDI database resource set up the following environment for iBatis 3's configuration XML file works for me (running on Tomcat): <environment id=""development""> <transactionManager type=""JDBC""/> <dataSource type=""JNDI""> <property name=""data_source"" value=""java:comp/env/jdbc/webDb""/> </dataSource> </environment> that's exactly what I did too but with no success. What I eventually found out is there there's some specific ""weblogic'ness"" that needs to be done above this to make it work. It appears to have to do with the classpath. Basically you have to set weblogic to load your webapps librairies (jars) before weblogic's own.  This is what I have in my config file works well in Glassfish and WebSphere: <dataSource type=""JNDI""> <property name =""data_source"" value=""jdbc/cpswebmon""/> </dataSource> ""jdbc/cpswebmon"" is the JNDI resource name on my application server"
458,A,"what is best way to paging big Resultset -Java i am looking for best aproach from perfomance point of view  to show Resultset on webpage partially  lets say by 10 item per page and if user want to see more result he pressing ""next"" btn . i think (probablly wrong) it should be new request to the Server when ""Next"" button is pressed ?? currentlly i trying to learn JavaGWT thank You! PS: sorry for my English. If you can't use a cache-based approach due to memory limitations use a query-based approach. Adjust the WHERE clause on your search query to explicitly select data based on which page the user has requested. This approach requires that you pass additional context information back and forth on your page requests. One approach is to fetch pages using logical Row IDs (or primary keys) that delimit the page and identify each row in the result set. Say you have a very simple table with a numerical sequence of row ids. If you are showing 100 rows per page and the user has requested page two you would adjust the WHERE clause as follows: select col col2 from my_table where row_id > 100 and row_id <= 200 order by rownum asc  You usually only get a ""page"" from the database. Let's say a query select * from mytable where column1=""a""; would give 1000 records. Then getting a page would be like (mysql): select * from mytable where column1=""a"" limit 0 10; for page 1 (0 to 10) and page 2 would be retrieved like: select * from mytable where column1=""a"" limit 10 20; and so forth. If the data is large (1000 records) but not huge ( 1000 000 records) you can also give the entire dataset at once and use javascript to page. That has the added advantage that sorting can be done client-side. LIMIT isn't available in all dialects of SQL and depending on query structure it may be very inefficient -- the engine will have to execute the full query then apply the limit (although MySQL does have optimizations). If you use MySQL with a suitably large query cache it's not that expensive and it deals fairly well with a large number of clients (at the expense of CPU if the cache is full). Based on the given information I can't really think of anything better except maybe a separate dynamically created table which would require a lot of fault tolerant cleanup code.  Since you have ""GWT"" in your tags I'll assume your server app is running on Google App Engine (GAE). One approach is to have your first query obtain all results store them in a DB show the first 20 and then let the next/prev links pull subsets of the stored data out of the DB. You must remember to delete those results from the DB when your user's session times out! Another approach is to obtain all results on each page view but skip through the results until you've hit the desired subset of 20 and output only those. I think that with GAE underneath the 2nd approach will work better unless your query is likely to return more than 1000 results which GAE won't let you retrieve in one transaction. The best approach if your data and keys lend themselves to it would be to pull out the correct 20 data items already at query time. But unless your data has continuously ascending integer keys this may be hard to do. +1 for app engine comments ... I assumed that GWT was simply being used as a front-end for a normal app-server  you can cache/retrieve the records in web layer backend layer(for example ejb) or the database layer(as last ""limit"" or row_id statement). which approach you should use depends on your requirement(as said by kdgregory). most popular one is to cache them at the web layer using the session.  The answer would depend on your users' behavior: how often will the look at page 2 or page 10 or page 100. If they rarely look at page 2 and never look at page 10 or page 100 then resubmitting the request may be fine. If they usually look at page 2 often look at page 10 and occasionally look at page 100 then a partial cache will be useful: cache the first 100 (or 200 or 300) results and only resubmit the query when they go past those results. I would probably store the cache in the user's session although you have to give that some thought if your application server is clustered. And if they always page through every result? Partial caches are still the answer because you don't want to store large chunks of data in-memory.  If you are using JPA (which works quite well on GAE) you can paginate a result set using Query#setFirstResult(int startPosition) Query#setMaxResults(int maxResult) This article might be helpful: Paging large data sets with a LazyList"
459,A,Does Google app engine supports JDBC? I have heard the Google App Engine[java] do not support JDBC and Hibernate. Is it true? If yes then how do we access the database in Google App Engine. Also is there any [basic] sample application which can help me understand how to perform CRUD operations in GAE. AppEngine doesn't use a relational database. You should really read the docs about how AppEngine works starting with this Java-oriented overview of AppEngine. AppEngine delivers on its scalability promise by leveraging Google-style infrastructure. If you're looking to use a more traditional stack you'll probably be better off with Amazon EC2.  There is an early-stage 3rd party project to build a JDBC driver for the App Engine nonrel datastore: http://www.jiql.org/xwiki/bin/view/Main/ Looks like that project has been abandoned.  Yes that's true. JDBC drivers won't work there as long as GAE datastore is not based on RDBMS (it's rather some kind of NoSQL big-table storage). If you want to work with GAE storage via ActiveRecord ORM (Hibernate-like) you may be interested in JPA or JDO - the both are supported. Alternatively you can directly use low-level API. For more information you may refer to Datastore Java API Overview.  JDBC and Hibernate are not supported: http://groups.google.com/group/google-appengine-java/web/will-it-play-in-app-engine I'm currently learning app engine too. Here's some resources and projects that have been helpful: http://code.google.com/appengine/docs/java/overview.html http://groups.google.com/group/google-appengine-java Springsource Tool Suite is shipped with the Google Plugin for Eclipse (GPE): http://www.springsource.com/products/sts A non-trivial web app example (spring mvc/gwt/jsf + JDO + spring IOC service layer DAOs DTOs test suite): http://code.google.com/p/swagswap/  Google uses their own type of Datastore for GAE apps. Here is there documentation for how it works: http://code.google.com/appengine/docs/java/datastore/overview.html. That page has examples of how it works.  Storing data in a scalable web application can be tricky. You have to use their datastore API. http://code.google.com/appengine/docs/java/gettingstarted/usingdatastore.html
460,A,How do I track orphaned JDBC connections that are not closed? We've found a bug in old code where connections aren't being closed. It's an easy fix but I'm wondering how we go about proving that it's fixed. There is a choice of using a connection pool or not. For the pooling use it would be easy to add monitoring for the pool but when connections pooling is not used how do we track those unclosed orphaned connections? Is it just like any other memory leak? The bug looks like basically a cut and paste error. We have a few classes that manage the DB connection so it looks roughly like this: OurDBConn conn1 = ConnectionManager.getConnection(); try { // business logic } catch () { // } finally { ConnectionManager.returnConnection(conn1); } /// and then later in the same method OurDBConn conn2 = ConnectionManager.getConnection(); try { // business logic } catch () { // } finally { ConnectionManager.returnConnection(conn1); // NOTE Error: conn1 should be conn2 } I don't know why the earlier coders didn't just reuse the original connection but that's what it is (begin edit/append) Yes the connection code is ours as well and so I can use the answers given. However I don't think I asked the right question although the answers below answer the question I asked. I'm not sure what the right stackoverflow thing to do is; ask another question or edit this one? One of the question I should have asked is: how would these orphaned un-closed connections manifest themselves in system performance? Also since these connection objects exist only within the scope of a certain method wouldn't the connections be eligible for garbage collection? And then if they are gc'ed what is the effect of open connections being gc'ed? (end edit) I'll be watching this one closely we have a very similar problem in several of our projects. For the record I'd need to have a really good reason NOT to move this to a mature connection pool implementation such as DBCP or C3PO - if you have the opportunity - perhaps you should consider doing so? You can implement custom mini-framework or use exisitng one as a thin wrapper on JDBC operations. For example there is a spring-jdbc module (mavenized) that covers all of the boilerplate error-prone code from developer. You can check its usage examples and see that there is no initialization/cleanup at the client code at all! It uses 'template method' pattern i.e. you just write essential data processing and don't bother with connections/statements/resultsets creation and closing. So it becomes not possible to introduce the problem you talked at first.  Assuming the connection manager is also your own code you could store the initialised connections (along with a stacktrace) in a map within the connection manager and then remove them when they are returned. Thus at any point the keyset of the map is the set of unreturned connections and you can look up that value in the map in order to find the guilty bit of code that created them and never released them. (If the connection isn't a suitable map key you can probably use some kind of unique ID or connection number or whatever - the actual value doesn't matter so much as its presence). Then just add some appropriate way to access this map on demand and you're good. Depending on your environment adding a shutdown hook that dump the contents of the map to a file and/or adding a JConsole interface to lookup the set of unclosed connections in running code could both be good options. If the connection manager isn't your code you could still probably achieve the same thing using aspects. +1 for the AOP approach The connection pool that we use does something very like this; I believe it wraps the connections that it returns and keeps track of when they are used. If a connection is unused for longer than a certain amount of time that we specified in the configuration the connection will be terminated automatically and the stack trace which was recorded on connection open is printed to the log.
461,A,"When accessing ResultSets in JDBC is there an elegant way to distinguish between nulls and actual zero values? When using JDBC and accessing primitive types via a result set is there a more elegant way to deal with the null/0 than the following: int myInt = rs.getInt(columnNumber) if(rs.wasNull())? { // Treat as null } else { // Treat as 0 } I personally cringe whenever I see this sort of code. I fail to see why ResultSet was not defined to return the boxed integer types (except perhaps performance) or at least provide both. Bonus points if anyone can convince me that the current API design is great :) My personal solution was to write a wrapper that returns an Integer (I care more about elegance of client code than performance) but I'm wondering if I'm missing a better way to do this. Just to clarify what bothers me about this code is not the length but the fact that a it creates a state dependency between subsequent calls and what appears like a simple getter actually has a side effect within the same row. Clearly the people responsible for replacing a > b with a.compare(b) > 0 couldn't imagine a world where you wouldn't want to use getBigDecimal in place of any of the other options! Not an answer but a hint. This ""dilemma"" is handled in http://www.jooq.org where all numeric types are treated as object and this JDBC ""fact"" is abstracted... So with jOOQ there's no need to write your own wrapper for JDBC shortcomings The JDBC API was designed for performance. Remember that it dates back to Java 1.1 when a large turnover of objects was a JVM killer (it wasn't until the Hotspot JVMs in Java 1.2+ that you could relax this kind of limitation). Using boxed types would have ruined the performance of high volume applications at the time. Now it can't be changed because of backwards compatibility. So no it's not ideal any more but it's a pretty minor thing to workaround. If you want to avoid the type of code you mentioned you can always use getObject() instead of getInt() which will return an object of one of the subtypes of java.lang.Number probably Integer or BigInteger depending on the specific SQL type. It's a pity getObject() hasn't been generified like Spring's RowMapper JdbcTemplate and the like. It's only syntactic sugar but makes the code look much nicer without the casts. @mdma: That would be a good idea. But these things are hard to get through the JSR process..."
462,A,Where should I setup a Database connection in Struts 2 app? I am developing a small web application using struts 2. I want to setup a database connection when the web application starts. After that I want that database connection object to be used in the the entire web application to update records in the database server. Where should I include the database connection setup code in my struts2 web application ? You shouldn't setup a database connection on webapp startup. The DB will timeout the connection when it is been released for a too long time and that is truly shorter (~30 mins) than the time an average webapplication lives (days months years). Rather setup the datasource / DAO factory at that point. Connections are to be acquired and closed in the shortest possible scope. The normal JDBC idiom is the following: public void create(Entity entity) throws SQLException { Connection connection = null; PreparedStatement statement = null; try { connection = database.getConnection(); statement = connection.prepareStatement(SQL_CREATE); statement.setSomeObject(1 entity.getSomeProperty()); // ... statement.executeUpdate(); } finally { if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } } Note the closing in finally. It prevents leaking resources (i.e. not closing them) when an exception occurs. To improve connecting performance you normally want to use a connection pool. Any decent appserver provides this facility in flavor of a JNDI datasource. In for example Tomcat you can find in the JNDI Resources HOW-TO how to create one. This by the way does not mean that you don't need to close them you still need to close them according the usual JDBC idiom. The connection pool namely returns a wrapped connection which does something like the following in the close(): public void close() throws SQLException { if (this.connection is still eligible for reuse) { do not close this.connection but just return it to pool for reuse; } else { actually invoke this.connection.close(); } } As to setting up the datasource (or DAO factory) on webapp startup there are several ways. One is using a ServletContextListener which does the task in the contextInitialized() method another way is using a Struts2-managed application scoped bean which does the task in the constructor. Also see this basic JDBC/DAO tutorial for more hints how to get started with JDBC (in webapplications) the proper way.
463,A,"The big last_insert_id() problem again Note - this follows my question here: http://stackoverflow.com/questions/2983685/jdbc-does-the-connection-break-if-i-lose-reference-to-the-connection-object Now i have a created a class so i can deal with JDBC easily for the rest of my code - public class Functions { private String DB_SERVER = """"; private String DB_NAME = ""test""; private String DB_USERNAME = ""root""; private String DB_PASSWORD = ""password""; public Connection con; public PreparedStatement ps; public ResultSet rs; public ResultSetMetaData rsmd; public void connect() throws java.io.FileNotFoundException java.io.IOException SQLException Exception { String[] dbParms = Parameters.load(); DB_SERVER = dbParms[0]; DB_NAME = dbParms[1]; DB_USERNAME = dbParms[2]; DB_PASSWORD = dbParms[3]; // Connect. Class.forName(""com.mysql.jdbc.Driver"").newInstance(); con = DriverManager.getConnection(""jdbc:mysql://"" + DB_SERVER + ""/"" + DB_NAME DB_USERNAME DB_PASSWORD); } public void disconnect() throws SQLException { // Close. con.close(); } } As seen Parameters.load() refreshes the connection parameters from a file every-time so that any changes to the same may be applied on the next immediate connection. An example of this class in action - public static void add(String NAME) throws java.io.FileNotFoundException java.io.IOException SQLException Exception { Functions dbf = new Functions(); dbf.connect(); String query = ""INSERT INTO "" + TABLE_NAME + ""("" + ""NAME"" + "") VALUES(?)""; PreparedStatement ps = dbf.con.prepareStatement(query); ps.setString(1 NAME); ps.executeUpdate(); dbf.disconnect(); } Now here is the problem - for adding a record to the table above the add() method will open a connection add the record - and then call disconnect() . What if i want to get the ID of the inserted record after i call add() -like this : Department.add(""new dept""); int ID = getlastID(); Isn't it possible that another add() was called between those two statements? It doesn't matter if another add is performed between the statements as long as you keep your connection open. The last_insert_id function gets the last id created in the same database session i.e. using the same connection. So you have to change your code so that you con't close and reopen the connection between adding the record and getting the id.  It's possible .. you might want to consider refactoring your code. Baby steps retrieve and store the id in a variable inside your add method before closing the connection change the signature and return the id. that's what i was just thinking too. :)"
464,A,"JDBC Connection Pooling: Connection Reuse? As per my understanding JDBC Connection Pooling (at a basic level) works this way: create connections during app initialization and put in a cache provide these cached connections on demand to the app a separate thread maintains the Connection Pool performing activities like: discard connections that have been used (closed) create new connections and add to the cache to maintain a specific count of connections But whenever I hear the term ""connection reuse"" in a JDBC Connection Pooling discussion I get confused. When does the connection reuse occurs? Does it means that Connection Pool provides the same connection for two different database interactions (without closing it)? Or is there a way to continue using a connection even after it gets closed after a DB call? just curious but which connection pooling libraries launch separate threads for managing the pool? I don't think commons-dbcp does this - at least not the BasicDataSource. Rather I think the connection checking is done when the connection is checked out from the pool My understanding is the same as stated above and thanks to a bug I have evidence that it's correct. In the application I work with there was a bug an SQL command with an invalid column name. On execution an exception is thrown. If the connection is closed then the next time a connection is gotten and used with correct SQL this time an exception is thrown again and the error message is the same as the first time though the incorrect column name doesn't even appear in the second SQL. So the connection is obviously being reused. If the connection is not closed after the first exception is thrown (because of the bad column name) then the next time a connection is used everything works just fine. Presumably this is because the first connection hasn't been returned to the pool for reuse. (This bug is occurring with Jave 1.6_30 and a connection to a MySQL database.) Please avoid walls of text formatting is highly recommended on SO. Besides formatting consider to add what SQL command you issued as long as the error you got in order to enrich your answer  The connection pool does not provide you with the actual Connection instance from the driver but returns a wrapper. When you call 'close()' on a Connection instance from the pool it will not close the driver's Connection but instead just return the open connection to the pool so that it can be re-used (see skaffman's answer). That depends on the specific type of connection pool you're using e.g. `DataSource` or Commons DBCP-style. Lightweight pools can just return the raw `Connection` and rely on the application code not calling `close()`. So does this means that the JDBC connections in a pool necessarily rely on either Connection.commit() or Connection.setAutoCommit(true) - probably these calls are made in the over-ridden close() of the Connection wrapper.  Connection pooling reuses connections. Here is how apache dbcp works underline. Connection poolableConnection= apacheDbcpDataSource.getConnection(); Apache DBCP implementation returns connection wrapper which is of type PoolableConnection. poolableConnection.close(); PoolableConnection.close() inspects if actual underlying connection is closed or not if not then it returns this PoolableConnection instance into connection pool (GenericObjectPool in this case). if (!isUnderlyingConectionClosed) { // Normal close: underlying connection is still open so we // simply need to return this proxy to the pool try { genericObjectPool.returnObject(this); //this is PoolableConnection instance in this case .... }  Connection pooling works by re-using connections. Applications ""borrow"" a connection from the pool then ""return"" it when finished. The connection is then handed out again to another part of the application or even a different application. This is perfectly safe as long as the same connection is not is use by two threads at the same time. The key point with connection pooling is to avoid creating new connections where possible since it's usually an expensive operation. Reusing connections is critical for performance."
465,A,"Spring JDBCTemplate Table Locking with MySQL I just migrating one of our applications from pure JDBC to Spring's JDBCTemplate. I was wondering how to create a write lock for a table. Do i just execute a ""LOCK TABLE foo"" Query or is there a generalisized way for doing this in JDBCTemplate? Thanks! JdbcTemplate uses a DataSource so it's not guaranteed that you will use the same connection for the LOCK TABLE statement and whatever you're going to do in the next call to JdbcTemplate. So it's important that you do this in a transaction. Set up a PlatformTransactionManager either a DataSourceTransactionManager on the JdbcTemplate's DataSource or a JtaTransactionManager if the JdbcTemplate is using a container-provided JNDI DataSource. You can annotate your method as @Transactional or create a transaction programmatically using the PlatformTransactionManager."
466,A,"How can I use the MS JDBC driver with MS SQL Server 2008 Express? My configuration: windows XP SP3 JDBC 2005 MS SQL Server 2008 Express exposed via tcp/ip on port 1433 sqljdbc.jar in class path I tried: try { Class.forName(""com.microsoft.sqlserver.jdbc.SQLServerDriver"").newInstance(); con = DriverManager.getConnection(""jdbc:microsoft:sqlserver://localhost:1433/SQLEXPRESS2008;databaseName=Test;selectMethod=cursor"" ""sa"" """"); } catch (Exception e) { e.printStackTrace(); } But it always throws an exception: java.sql.SQLException: No suitable driver I also tried the following urls: localhost:1433/SQLEXPRESS2008 localhost/SQLEXPRESS2008 localhost Same results. Any help? You have the wrong URL. I don't know what you mean by ""JDBC 2005"". When I looked on the microsoft site I found something called the Microsoft SQL Server JDBC Driver 2.0. You're going to want that one - it includes lots of fixes and some perf improvements. [edit: you're probably going to want the latest driver. As of March 2012 the latest JDBC driver from Microsoft is JDBC 4.0] Check the release notes. For this driver you want: URL: jdbc:sqlserver://server:port;DatabaseName=dbname Class name: com.microsoft.sqlserver.jdbc.SQLServerDriver It seems you have the class name correct but the URL wrong. Microsoft changed the class name and the URL after its initial release of a JDBC driver. The URL you are using goes with the original JDBC driver from Microsoft the one MS calls the ""SQL Server 2000 version"". But that driver uses a different classname. For all subsequent drivers the URL changed to the form I have here. This is in the release notes for the JDBC driver. Looks like there is a v3.0 driver available now (which is JDBC 4.0 compliant) http://msdn.microsoft.com/en-us/sqlserver/aa937724 Yes the information in this answer is now out of date. I'd advise developers to go to the MS website and get the latest driver. Also read the release notes to verify the classname and URL. At this time they are unchanged but it makes sense to check. As of March 2012 the latest JDBC driver published by Microsoft is v4.0: http://www.microsoft.com/en-us/download/details.aspx?id=11774  If your databaseName value is correct then use this: DriverManger.getconnection(""jdbc:microsoft:sqlserver://ServerIp:1433;user=myuser;password=mypassword;databaseName=databaseName;"")  You can try the following. Works fine in my case: Download the current jTDS JDBC Driver Put jtds-x.x.x.jar in your classpath. Copy ntlmauth.dll to windows/system32. Choose the dll based on your hardware x86x64... The connection url is: 'jdbc:jtds:sqlserver://localhost:1433/YourDB'  you don't have to provide username and password. Hope that helps. They're asking how to use the MS driver not the JTDS driver. Sorry (-1)  The latest JDBC MSSQL connectivity driver can be found on JDBC 4.0 The class file should be in the classpath. If you are using eclipse you can easily do the same by doing the following --> Right Click Project Name --> Properties --> Java Build Path --> Libraries --> Add External Jars Also as already been pointed out by @Cheeso the correct way to access is jdbc:sqlserver://server:port;DatabaseName=dbname Meanwhile please find a sample class for accessing MSSQL DB (2008 in my case). import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.Statement; public class ConnectMSSQLServer { public void dbConnect(String db_connect_string String db_userid String db_password) { try { Class.forName(""com.microsoft.sqlserver.jdbc.SQLServerDriver""); Connection conn = DriverManager.getConnection(db_connect_string db_userid db_password); System.out.println(""connected""); Statement statement = conn.createStatement(); String queryString = ""select * from SampleTable""; ResultSet rs = statement.executeQuery(queryString); while (rs.next()) { System.out.println(rs.getString(1)); } conn.close(); } catch (Exception e) { e.printStackTrace(); } } public static void main(String[] args) { ConnectMSSQLServer connServer = new ConnectMSSQLServer(); connServer.dbConnect(""jdbc:sqlserver://xx.xx.xx.xxxx:1433;databaseName=MyDBName"" ""DB_USER""""DB_PASSWORD""); } } Hope this helps.  Download the latest JDBC Driver (i.e. sqljdbc4.0) from Microsoft's web site Write the program as follows: import java.sql.*; class testmssql { public static void main(String args[]) throws Exception { Class.forName(""com.microsoft.sqlserver.jdbc.SQLServerDriver""); Connection con=DriverManager.getConnection(""jdbc:sqlserver://localhost:1433; databaseName=chapter16""""sa""""123"");//repalce your databse name and user name Statement st=con.createStatement(); ResultSet rs=st.executeQuery(""Select * from login"");//replace your table name while(rs.next()) { String s1=rs.getString(1); String s2=rs.getString(2); System.out.println(""UserID:""+s1+""Password:""+s2); } con.close(); } } Compile the program and set the jar classpath viz: set classpath=C:\jdbc\sqljdbc4.jar;.; If you have saved your jar file in C:\jdbc after downloading and extracting. Run the program and make sure your TCP/IP service is enabled. If not enabled then follow these steps: Go to Start -> All Programs -> Microsoft SQL Server 2008 -> Configuration tools -> SQL Server Configuration Manager Expand Sql Server Network Configuration: choose your MS SQL Server Instance viz. MSQSLSERVER and enable TCP/IP. Restart your MS SQL Server Instance. This can be done also from the right click menu of Microsoft SQL Server Management Studio at the root level of your MS SQL server instance"
467,A,"Java DataBase Connectivity Problem with MS SQL Server 2005 from a Remote Server I am writing a java code to connect with MS SQL Server 2005. MS SQL Server is on Remote server windows server 2003. I am trying the following code but i am unable to establish a connection: import java.*; public class Connect { private java.sql.Connection con = null; private final String url = ""jdbc:sqlserver://""; private final String serverName=""xxx.xxx.xxx.xxx""; private final String portNumber = ""1433""; private final String databaseName=""myDb""; private final String userName =""user1""; private final String password = ""xxxx""; private final String selectMethod = ""cursor""; // Constructor public Connect() {} private String getConnectionUrl() { return url+serverName+"":""+portNumber+"";databaseName=""+databaseName+"";selectMethod=""+selectMethod+"";""; } private java.sql.Connection getConnection() { try { Class.forName(""com.microsoft.sqlserver.jdbc.SQLServerDriver""); con = java.sql.DriverManager.getConnection(getConnectionUrl()userNamepassword); if(con!=null) System.out.println(""Connection Successful!""); } catch(Exception e) { e.printStackTrace(); System.out.println(""Error Trace in getConnection() : "" + e.getMessage()); } return con; } /* Display the driver properties database details */ public void displayDbProperties() { System.out.println(""Perform Operations ""); } private void closeConnection() { try{ if(con!=null) con.close(); con=null; }catch(Exception e){ e.printStackTrace(); } } public static void main(String[] args) throws Exception { Connect myDbTest = new Connect(); // myDbTest.displayDbProperties(); } } But I am getting following exceptions:  com.microsoft.sqlserver.jdbc.SQLServerException: The TCP/IP connection to the host has failed. java.net.ConnectException: Connection refused: connect at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDriverError(Unknown Source) Error Trace in getConnection() : The TCP/IP connection to the host has failed. java.net.ConnectException: Connection refused: connect Error: No active Connection I am not getting where is the problem in the above code or do i need to do some setting to connect to remote server. Please give me your valuable suggestion which can help me to overcome with this problem. ALLOW THE CONNECTION FIRST IN WHICH PC YOUR SQL SERVER IS RUNNING... GO TO CONTROL PANEL-->ADMIN. TOOLS--->Windows Firewall with Advanced Security-->Inbounded rules-->new rule-->select port radio button -->next-->enter port 3306-->click next -->finally give the rule name like conn any...click finish  IMHO ""Connection refused"" means your database server is not visible from your application server. Check IP address and port. Check database connectivity directly from your database server (to avoid firewalls). Check database connectivity from your application server. Hope this will help you  Make sure that your SQL Server is configured to use TCP/IP. Enable it from SQL Server's Network Utility app. Also check there that the SQL Server is using port 1433 (IP Addresses - IPAll - TCP Port). Try to use ""telnet <server_host> 1433"". If it doesn't connect you will not be able to establish a connection."
468,A,"Deconstruct an SQL Statement in Java I have some legacy SQL and I want to split it up into it's constituent parts & then add more criteria an order by clause etc. Are there any existing Java libraries out there that interpret SQL like this? So I want to do something like deconstructedSQL.getCriteria().add(""price > 100""); or deconstructedSQL.getOrderBy().add(""price""); or String select = deconstructedSQL.getSelect(); if (""*"".equals(select)) { deconstructedSQL.setSelect(""my_table.*""); } I can use Dialects from Hibernate to add info specific to my database for paging (setFirstResult & setMaxResult) but I'd like to take it a step further. I would use a sql parser (javacc jparsec antlr) to break up the string into an AST. Once you have it in this kind of structure you can play with it as you describe and emit the modified version as a string in the end. ""SQL Parser"" was the phrase that eluded me when googling this. Having a look at Zql now - http://www.gibello.com/code/zql/  The Zsql framework matches exactly with your description (not tested).  You may want to checkout the SQL Builder library. It is a builder pattern based library for building SQL statements. I'm not positive if it has a deconstruction piece to it where you can give it a SQL statement and have it break it down into parts though. That's great. Between Zql & SQL Builder I should have my solution!  This is a demo that illustrate how to Deconstruct Modify Rebuild an SQL statement with the help of a SQL Parser. original SQL: SELECT * FROM TABLE_X where f > 0 Java code: assertTrue(parser.parse() == 0); TSelectSqlStatement select = (TSelectSqlStatement)parser.sqlstatements.get(0); select.addWhereClause(""c>1""); what you get is: SELECT * FROM TABLE_X where f > 0 and c>1 select list group by order clause can also be modified easily."
469,A,"Spring Like clause I am trying to use a MapSqlParameterSource to create a query using a Like clause. The code is something like this. The function containing it receives nameParam: String namecount = ""SELECT count(*) FROM People WHERE LOWER(NAME) LIKE :pname ""; String finalName= ""'%"" +nameParam.toLowerCase().trim() + ""%'""; MapSqlParameterSource namedParams= new MapSqlParameterSource(); namedParams.addValue(""pname"" finalName); int count= this.namedParamJdbcTemplate.queryForInt(namecount namedParams); This does not work correctly giving me somewhere between 0-10 results when I should be receiving thousands. I essentially want the final query to look like: SELECT count(*) FROM People WHERE LOWER(NAME) LIKE '%name%' but this is evidently not happening. Any help would be appreciated. Edit: I have also tried putting the '%'s in the SQL like  String finalName= nameParam.toLowerCase().trim(); String namecount = ""SELECT count(*) FROM People WHERE LOWER(NAME) LIKE '%:pname%' "" ; but this does not work either. You don't want the quotes around your finalName string. with the named parameters you don't need to specify them. This should work: String namecount = ""SELECT count(*) FROM People WHERE LOWER(NAME) LIKE :pname ""; String finalName= ""%"" + nameParam.toLowerCase().trim() + ""%""; MapSqlParameterSource namedParams= new MapSqlParameterSource(); namedParams.addValue(""pname"" finalName); int count= this.namedParamJdbcTemplate.queryForInt(namecount namedParams); You are my hero. Thanks a lot. I've been working on this for an embarassingly long period of time. how about some accepted answer love?  We can use simple JdbcTemplate instead of NamedParamJdbcTemplate String namecount = ""SELECT count(*) FROM People WHERE LOWER(NAME) LIKE ? ""; String finalName= ""%"" +nameParam.toLowerCase().trim() + ""%""; //Notes: no quote getJdbcTemplate().queryForInt(namecount new Object[] {finalName}); Hope it helpful for someone using JdbcTemplate  Have you tried placing the % wild cards in your sql string (not the bind variable value itself): String finalName= nameParam.toLowerCase().trim(); String namecount = ""SELECT count(*) FROM People WHERE LOWER(NAME) LIKE '%:finalName%'""; Thank you I see that my edit was unclear but I meant to reflect that I had essentially tried what you are suggesting but it still does not work. Do you have any other suggestions? Can you suggest a way to modify the existing code so that I can use the '?' placeholder? I don't believe you can use it with a MapSqlParameterSource. Thanks is `LIKE %:pname%` valid? I've tried that. It gave me similar (possibly same) results. I think there must be something with the single quotes or the '%' signs that interfere with the query. You can't leave the variable with % though so you now need: String finalName= nameParam.toLowerCase().trim(); The wild cards are not removed from the finalName variable. Updated my answer."
470,A,"getResultSet from Spring-JDBC I'm using Spring's support for JDBC. I'd like to use JdbcTemplate (or SimpleJdbcTemplate) to execute a query and obtain the result as an instance of ResultSet. The only way that I can see of achieving this is using: String sql = ""select * from....""; SqlRowSet results = jdbcTemplate.queryForRowSet(sql); ((ResultSetWrappingSqlRowSet) results).getResultSet(); An obvious shortcoming of this approach is that it requires me to make an assumption (by casting) about the implementation type of SqlRowSet but is there a better way? Background info... The reason I want to obtain the results as a ResultSet rather than a collection of beans is because the results will be passed straight to a Jasper report for display. In other words the Java bean would be used for nothing other than temporarily storing each row in the ResultSet and I'd like to avoid creating such a bean for every Jasper report if possible. Cheers Don You can either invoke Jasper inside a JdbcTemplate callback (like a ResultSetExtractor) or use straight JDBC to pass the ResultSet to Jasper. Either way when you call Jasper your connection to the database is still active until your report is finished.  If you want to just perform a query and get the results why don't you use plain jdbc and grab the resultset? Notice that you don't need spring to do just this.  Connection c = ... c.prepareCall(""select ..."").getResultSet(); Besides you get an advantage by using an object as a DTO. You don't need to change your DTO class even if your data acess or your report tool changes (let's say you start using xquery instead of jdbc or you use apache-poi instead of jasper."
471,A,"Store date object in sqlite database I'm using a database in my Java project and I want to store date in it the 5th and the 6th parameter are Date Object. I used the solution below but I have errors in the indicated lines: PreparedStatement creerFilm = connecteur.getConnexion().prepareStatement( ""INSERT INTO FILM (ID REF NOM DISTRIBUTEUR DATEDEBUT DATEFIN) ""+ ""VALUES (? ? ? ? ? ?)""); creerFilm.setInt(1 getId()); creerFilm.setString(2 getReference()); creerFilm.setString(3 getNomFilm()); creerFilm.setString(4 getDistributeur()); // These next two lines creerFilm.setDate(5 new Date (getDateDebut().getDate())); creerFilm.setDate(6 new Date (getDateFin().getDate())); // The above two lines creerFilm.executeUpdate(); creerFilm.close(); Can you help me to fix that please ? Thank you I can't really tell from your code but you have to use java.sql.Date not java.util.Date. Here's how you convert from a utility date instance to an SQL date instance: java.sql.Date date = new java.sql.Date(utilDate.getTime()); java.sql.Date has no String constructor. The java.util.Date String constructor is depreciated. java.text.DateFormat has a parse method that works with String dates in the format Jan 12 1952 or January 12 1952. If you have a java.text.SimpleDateFormat you have to parse it to get a java.util.Date. Then you can use the conversion in my answer to get a java.sql.Date. Thank you for your answer. I used the solution you told me and I have no errors now. However I don't know which date format I should use to store it correctly in the database. Currently I'm using a String in the constructor taht should have this format ""dd-MM-yyyy"" after that I use a function to convert it to SimpleDateFormat. When I use toString() everything works well but when I store it in the database I get something like that in the field ""1287525600000"" Can you tell me please where is the problem exactly?  I think detailed answer you can read here: How to insert date in sqlite through java In a short you can insert Date as setString (or setInt or setLong (see the above link) but not setDate): PreparedStatement ps = connection.prepareStatement(<your sql>); DateFormat df = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss""); ps.setString(1 df.format(<your date>));"
472,A,"How do I return a nested table from an oracle function using Java? I have the following type declaration and Oracle function: CREATE OR REPLACE TYPE var_outcomes_results IS TABLE OF VARCHAR2(80); CREATE OR REPLACE FUNCTION getValuesAbove(in_nodeID IN table1.KEY_SL%TYPE in_variable IN VARCHAR2) RETURN var_outcomes_results IS currentID table1.KEY_SL%TYPE; results var_outcomes_results; currentIndex integer := 0; BEGIN currentID := in_nodeID; WHILE currentID != null LOOP FOR outcomeRecord IN (select distinct a.PARENT b.NAME c.OUTCOME from table1 a left outer join table2 b on a.KEY_SL = b.KEY_SL left outer join table3 c on b.VAR_ID = c.VAR_ID where a.KEY_SL = currentID) LOOP currentID := outcomeRecord.PARENT; IF lower(outcomeRecord.NAME) = lower(in_variable) AND outcomeRecord.OUTCOME != null THEN currentIndex := currentIndex + 1; results(currentIndex) := outcomeRecord.OUTCOME; END IF; END LOOP; END LOOP; RETURN results; END; I have the following Java function: public List<Object> getAboveValues(String variable Integer nodeID) { Connection connection = null; CallableStatement callableStatement = null; try { connection = dataSource.getConnection(); callableStatement = connection.prepareCall(""begin ? := getValuesAbove(??); end;""); callableStatement.registerOutParameter(1 OracleTypes.ARRAY); callableStatement.setInt(2 nodeID); callableStatement.setString(3 variable); callableStatement.execute(); System.out.println(callableStatement.getObject(1)); } catch( SQLException e ) { logger.error(""An Exception was thrown in getAboveValues: "" + e); } finally { closeDataResources(callableStatement connection); } } However when I execute the function I get the following error message: ""ORA-03115: unsupported network datatype or representation"" What am I doing wrong? Any ideas/suggestions would be appreciated. Thanks B.J. I don't think a table of varchars is equivalent to OracleTypes.ARRAY. I've seen people do this using a REF CURSOR which then maps to OracleTypes.CURSOR Try this. There are 3 collection types in PL/SQL: associative array nested table and varray. You can transfer the data in the nested table into varray data type. Then you can follow the procedures in this link: Fetch pl/sql array return values in java Comment me if you found a direct solution so I can also use it. :)  If you want to return TABLE OF VARCHAR2 you should use Oracle-specific code: OracleCallableStatement.registerIndexTableOutParameter instead of CallableStatement.registerOutParameter. Since this requires OCI driver instead of the Thin driver I cannot test this code.  I can't check this right now but I think you could do this with a preparedStatement and resultSet using ... = connection.prepareStatement(""select * from table(getValuesAbove(??))""); This should work with the thin driver as far as I can remember - all the hard work is being done on the database so it looks like any other select from JDBC. Thank you this works well."
473,A,"Oracle: OALL8 is in an inconsistent state As part of upgrading JRun we are moving from a 1.4 JVM to a 1.6 JVM. Now I am getting a really strange oracle db error: ""OALL8 is in an inconsistent state"". I have pinned down the problem to insert queries that do not use bind variables at all - all inline parameters. If I run the query without any bind variables I get the above error. As soon as I replace one of the hard coded values with a bind variable - everything works without error. The other strange bit is that after executing the query it is in fact committed to the database. I can connect from another session and see the inserted row. I have tried wrapping the query in a transaction and it seems to succeed as the behavior is unchanged from the query without an explicit transaction. Here are the relevant details: Java Version: 1.6.0_12-b04 Virtual Machine Version: 11.2-b01 (HotSpot Server) Oracle Server: 10.2.0.4 Oracle Client: 11.1.0.7.0 through ojdbc6.jar Update: I am using cfqueryparam - they are called bind variables in the oracle world. While that does solve the immediate problem we have a rather large legacy code base that we can't realistically go through all of to update the queries as part of upgrading from CF7 to CF8. Even though I have pinned down one specific situation that fails (and encapsulated it in an mxunit test) - that doesn't mean there aren't other areas where this may be an issue. I would really like to have a solution in place that removes the OALL8 error rather than coding around it. Update 2: After checking with our DBA he had set a parameter called CURSOR_SHARING to SIMILAR. The Oracle default is EXACT. What is happening is when ColdFusion hands the query off to be executed Oracle is turning all the literal values to bind variables and that appears to be confusing ColdFusion. Turning the setting back to EXACT allows the literal queries to work just fine. Update 3: Oracle finally issued us an out-of-band patch for JDBC. It was identified as a JDBC error. The latest drivers should include it when they are finally updated. If you have support you can also request the patch through their TAR system. So... use bind variables? You should be using them (via cfqueryparam) for security anyway and if it solves the problem that's even more reason to do so. If you're interested in what the actual error means Google has plenty of results suggesting that it's an error with the JDBC driver and even suggests a patch is available. But I don't see an actual question in your post...? Ironically this page is one of top 10 google result.  i found this http://asanga-pradeep.blogspot.com/2008/06/oall8-is-in-inconsistent-state-with.html Oracle Patch 4390875  If you application run in weblogic you should copy ojdbc.jar to install directory ""weblogic81\server\lib""  cover the same name file."
474,A,What MS SQL Server types map to Types.VARCHAR I'm working on a statement scanner for our updater (looking for statements that will cause problems with synchronized data) and I need to know which TSQL data types get resolved as Types.VARCHAR and which ones resolve to Types.LONGVARCHAR when you invoke DatabaseMetaData.getColumns()? check out: Understanding the JDBC Driver Data Types in BOL: Using basic data types Using advanced data types So basically: LONGVARCHAR: text ntext varchar(max) nvarchar(max) xml VARCHAR: varchar nvarchar
475,A,"Can I set the JDBC isolation level from a Tomcat Context? I have a web application running in Tomcat 6 and I've managed to configure it to use the built-in DBCP connection pooling and all is working very well however I suspect it is running in the wrong isolation level on the database. I'd like it to run in read uncommitted but I think it's running in read committed and don't know how to set it. Here is my context's XML file: <?xml version=""1.0"" encoding=""UTF-8""?> <Context antiResourceLocking=""false"" privileged=""true""> <Resource name=""jdbc/Connection"" auth=""Container"" type=""javax.sql.DataSource"" maxActive=""100"" maxIdle=""30"" maxWait=""10000"" driverClassName=""net.sourceforge.jtds.jdbc.Driver"" url=""jdbc:jtds:sqlserver://...etc..."" /> </Context> And this is the Java method used to get a database connection. public Connection getDatabaseConnection() throws ServletException { try { InitialContext cxt = new InitialContext(); if ( cxt == null ) { throw new ServletException( ""ServletContext unavailable."" ); } DataSource ds = (DataSource)cxt.lookup( ""java:/comp/env/jdbc/Connection"" ); if ( ds == null ) { throw new ServletException( ""Data source not found!"" ); } Connection conn = ds.getConnection(); return conn; } etc... Having obtained the connection in getDatabaseConnection() I realise I could manually set the isolation level with conn.setIsolationLevel( Connection.TRANSACTION_READ_UNCOMMITTED ) but that feels wrong as it either involves hard-coding the isolation level into the Java or performing a look-up to the servlet context every time a new connection is required. Can I define this in the context XML somehow or is there a better approach I'm not aware of? Yes you can set that with defaultTransactionIsolation attribute in the Resource element. <Context antiResourceLocking=""false"" privileged=""true""> <Resource defaultTransactionIsolation=""READ_UNCOMMITTED"" name=""jdbc/Connection"" auth=""Container"" type=""javax.sql.DataSource"" maxActive=""100"" maxIdle=""30"" maxWait=""10000"" driverClassName=""net.sourceforge.jtds.jdbc.Driver"" url=""jdbc:jtds:sqlserver://...etc..."" /> From the docs: defaultTransactionIsolation¨ TransactionIsolation state of connections created by this pool. One of the following: (see javadoc ) NONE READ_COMMITTED READ_UNCOMMITTED REPEATABLE_READ SERIALIZABLE"
476,A,"Java Heap Memory error I am getting this error: Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space at com.mysql.jdbc.MysqlIO.nextRowFast(MysqlIO.java:1585) at com.mysql.jdbc.MysqlIO.nextRow(MysqlIO.java:1409) at com.mysql.jdbc.MysqlIO.readSingleRowSet(MysqlIO.java:2886) at com.mysql.jdbc.MysqlIO.getResultSet(MysqlIO.java:476) at com.mysql.jdbc.MysqlIO.readResultsForQueryOrUpdate(MysqlIO.java:2581) at com.mysql.jdbc.MysqlIO.readAllResults(MysqlIO.java:1757) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2171) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2562) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2512) at com.mysql.jdbc.StatementImpl.executeQuery(StatementImpl.java:1476) at DBase.connect(automateExport.java:31) at automateExport.main(automateExport.java:10) I tried to increase the heap memmory space by opening eclipse.ini file and then changing -Xms 256m and -Xmx 512m But that did not help. I tried 512m and 1024m but that ended up giving error: Failed to start JVM and eclipse did not open up. I tried doing the same on cmd line: java -Xms 256m and -Xmx 512m and also eclipse -vmargs -Xms 256m and -Xmx 512m But still no help. I am basically creating a JDBC connection to query the database for very large set of records. Please help me. How many records? What kind of app is this can you be more specific on what you want to do with all this data once you get it ? Do you want to show it to the user ? make calculations ? Must the whole result from the query be in memory? If yes then you should buy more RAM. If not then partitionning the problem will be the proper solution. You can even let the database consolidate the data for you in many cases. If your solution to a given problem doesn't scale well with the amount of data present you will return to this problem even by extending your RAM. So the really good solution is to avoid the situation at all.  You don't need to worry about -Xms too much - that's the initial Heap size on startup. -Xmx is the max Heap size. Try increasing it until either you don't get the OutOfMemory exception anymore or until you run out of memory. If you run out of memory you can't load the entire ResultSet at once and you'll need to apply the approaches that others have mentioned.  I discovered that the MySql driver has a memory leak. I use it with tomcat in a connection pool setup. Loads of JDBCResultSet and StatementImpl objects are in the heap. Setting the maxAge in the datasource configuration (context.xml) in tomcat helped.  Try splitting your data into a number of result sets. Think about what you want to do with the data once you got it back from the database. The result set is too large to fit in heap space.  Is Lazy Load applicable? Can you use an upper limit to bound the results of a piece-wise query?  When you query returns very large sets the mysql driver will by default load the entire result set in memory before giving you control back. It sounds like you're just running out of memory so increase the memory furter e.g. -Xmx1024M The other alternative might be to enable streaming results on your MySQL queries- this prevents the entire ResultSet to be loaded into memory all at once. This can be done by doing stmt = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY);//These are defaults thoughI believe stmt.setFetchSize(Integer.MIN_VALUE); (Note that anything else but Integer.MIN_VALUE has no effect on the MySQL driver) Thanks guys for all the information. stmt = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY);//These are defaults thoughI believe stmt.setFetchSize(Integer.MIN_VALUE); This worked !!! So relieved! :) Sadly this solution brought a ""Operation not supported for streaming result sets"" exception with Spring (2 mio records). Luckily increasing Xms did help."
477,A,"Do a DB2 insert with a select and parameters I want to do something like this: INSERT INTO TABLEA ( COLUMN1 COLUMN2 COLUMN 3 ) SELECT FOOBAR DOOBAR ? FROM TABLEB And then send this to JDBC via Spring JDBC to update... simpleJdbcTemplate.update( mySqlFromAbove someVariableToReplaceQuestionMark ); Is this even possible? It would work fine if I replace the question mark with the hardcoded value when building my SQL query but I don't want to open myself to SQL injection... Edit - I get nested exception is com.ibm.db2.jcc.c.SqlException: DB2 SQL error: SQLCODE: -418 SQLSTATE: 42610 SQLERRMC: null Which seems to indicate Invalid use of a parameter marker ? It should work fine. And +1 for the ""no SQL injection"". Share and enjoy. It doesn't work per the edit  Here's the DB2 SQL Message Reference. Here's an extract of relevance for the SQLCODE and SQLSTATE you retrieved: SQL0418N A statement contains a use of a parameter marker that is not valid. Explanation: Untyped parameter markers cannot be used: in a SELECT list as the sole argument of a datetime arithmetic operation in some cases as the sole argument of a scalar function as a sort key in an ORDER BY clause Parameter markers can never be used: in a statement that is not a prepared statement in the fullselect of a CREATE VIEW statement in the triggered action of a CREATE TRIGGER statement in a query captured by DB2 Query Patroller The statement cannot be processed. User Response: Correct the syntax of the statement. If untyped parameter markers are not allowed use the CAST specification to give the parameter marker a data type. sqlcode: -418 sqlstate: 42610 Unfortunately this doesn't answer your problem since your SQL seem to look fine. After Googling a bit more it look more like that the DB2 JDBC driver simply doesn't eat INSERT INTO ... SELECT ... statements in a PreparedStatement. It's unclear if that is missing in the SQL Message Reference or a bug in the JDBC driver.  You need to type-cast your parameter marker so DB2 knows what to expect. For example: INSERT INTO TABLEA ( COLUMN1 COLUMN2 COLUMN 3 ) SELECT FOOBAR DOOBAR cast(? as int) FROM TABLEB Obviously cast to the appropriate type -- int is just an example. Solved 1 problem made new problem Worked if I did a specific cast.. like cast(? as char(8)).. just as char wasn't enough"
478,A,Failed to execute stored procedure from the JDBC code using mysql connection I have one database. I executed a stored procedure on it. I wrote some JDBC code to connect to this database. When I am calling this stored procedure from my JDBC code it is throwing SQLException. One interesting thing I found is that I have one user other than root user. This user has all the privileges to this database where the stored procedure is present. When I use the root user I am able to call the stored procedure successfully. But with the other user I am getting SQLexception. I am not able to find why it happens like this. For sure I want this user(other than root) has to call this stored procedure successfully. Thanks in advance. I'd recommend adding JDBC to your tags I recall having trouble calling sprocs from my JDBC code before too that's all i remember though Are you sure the user has execute proceure rights? If not try GRANT EXECUTE ON PROCEDURE mydb.myproc TO 'someuser'@'somehost'; I think you should provide the whole exception stacktrace and the stored procedur. The user should have SELECT permissions to the mysql.proc and mysql.procs_priv. I don't know if there exists any other solution.
479,A,"Using info from a database as variable values I am working on a java project and I need to pull some values out of a database and turn them into variables the program will then use to make a billing statement. I can get the program to connect to the database just fine and the mySQL statement to call the data I need is easy enough. I just can't seem to figure out how to then have it put each field returned in the resultset into a separate variable. Shamelessly lifted from the jdbc tutorial Statement stmt = con.createStatement(ResultSet.TYPE_SCROLL_SENSITIVE ResultSet.CONCUR_READ_ONLY); ResultSet srs = stmt.executeQuery( ""SELECT COF_NAME PRICE FROM COFFEES""); while (srs.next()) { String name = srs.getString(""COF_NAME""); float price = srs.getFloat(""PRICE""); System.out.println(name + "" "" + price); }  You should review the JDBC tutorial and this section answers your question."
480,A,Are there any in-memory JDBC databases that support XA distributed transactions? I want to use an in-memory database to test my application but it needs to support XA distributed transactions. My first idea for an in-memory database was HSQLDB but it appears not to support XA. Are there any? Looks like H2 supports this. Yes H2 supports the XA API. Please note that H2 doesn't support all XA features but for most applications it should be OK. Awesome that's exactly what I'm looking for. Thanks!
481,A,"How to get JDBC connections obtained from a JNDI datasource to participate in a UserTransaction using Weblogic 10.3? I am currently retrieving both a UserTransaction and a DataSource from a Weblogic 10.3 server using JNDI. I have set the Datasource up to 'Support Global Transactions' and to use 'Logging Last Resource' My hope was that by beginning a UserTranscation and then retrieving a JDBC connection from the Datasource the connection would participate in the Transaction. This does not appear to be the case and my insert statements are being commited straight away and rolling back the transaction does not have any effect. Are my above assumptions correct? Can anyone point me in the direction of some documentation or samples on how to achieve this? Many thanks in advance UPDATE: As requested here is a skeleton outline of the code I am using: private void doSomething() { Connection conn = null; try { Hashtable env = new java.util.Hashtable(); env.put(javax.naming.Context.INITIAL_CONTEXT_FACTORY""weblogic.jndi.WLInitialContextFactory""); env.put(javax.naming.Context.PROVIDER_URL""t3://localhost:8080""); InitialContext ctx = InitialContext(env)); UserTransaction transaction = null; transaction = (UserTransaction) ctx.lookup(""java:comp/UserTransaction""); DataSource dataSource = (DataSource) context.lookup(""jdbc/xxxxx/DataSource""); conn = dataSource.getConnection(); transaction.begin(); // JDBC code goes here transaction.commit(); } catch(Exception e) { // TODO if (transaction != null) { try { transaction.rollback(); } catch (Exception ex) { // TODO } } finally { if (con != null) { conn.close } } } UPDATE 2: In order to resolve this issue I had to do 2 things: Change the order of the code to firstly begin the user transaction and then get a connection from the Datastore (as pointed out by Pascal Thivent). Change the Datasource referenced by '""jdbc/xxxxx/DataSource""' to an XADatasource. This is because I was calling code inside the user transaction that used another Datasource that was already configured to support LLR and as pointed out by Pascal Thivent below you can only have one LLR Datasource participate in a transcation. I have accepted Pascal Thivent's answer below because it explained both of these issues. Yes your assumptions are correct and according to Create LLR-enabled JDBC data sources your data source seems properly configured. Do you get the connection after starting the user transaction? Can you show your code or pseudo code? UPDATE: As mentioned in Programming Considerations and Limitations for LLR Data Sources: When programming with an LLR data source you must start the global transaction before calling getConnection on the LLR data source. If you call getConnection before starting the global transaction all operations on the connection will be made outside of the global transaction. So could you try this: transaction.begin(); //start the global tx before calling getConnection() conn = dataSource.getConnection(); ... transaction.commit(); UPDATE2: Not sure to understand from where the 2nd connection is comming (your pseudo code isn't showing this). However according to the same Programming Considerations and Limitations for LLR Data Sources: Only instances of a single LLR data source may participate in a particular transaction. A single LLR data source may have instances on multiple WebLogic servers and two data sources are considered to be the same if they have the same configured name. If more than one LLR data source instance is detected and they are not instances of the same data source the transaction manager will roll back the transaction. Actually without a fully representative example I feel a bit like walking in the dark :) Thanks for your help so far. I've added the skeleton outline of my code as requested. I tried your suggestion. It resulted in the following error: Connection has already been created in this tx context for pool named ABI_DS. Illegal attempt to create connection from another pool: AMS_DS Where ABI_DS is the datasource I am using and AMS_DS is another datasource configured for the same deployment"
482,A,"Which OJDBC Driver for Java 6? We're currently using ojdbc14.jar should we be using ojdbc6.jar ? Update: Oracle 10g being used Check this question on ""Server Fault"": http://serverfault.com/questions/10477/differences-between-classes12-jar-ojdbc14-jar-ojdbc5-jar-and-ojdbc6-jar Ok so even though we're on 10g with should use the latest ojdbc driver - thanks Short answer - yes you should. Long answer - look at compatibility tables in Oracle JDBC FAQ: Which JDBC drivers support which versions of Oracle Database? Which JDBC drivers support which versions of Javasoft's JDK? For JDK 1.6 and Oracle 10g best option is o  If you're working with java6 you can (and should) use ojdbc6.jar if it is compatible with your database. Resources : oracle.com - JDBC drivers We're using 10g release 2 - ojdbc6 is not listed for 10g or am I missing something here? @JamesC either upgrade your oracle version to 11g or use the ojdbc14 version then. Even if it works (most of the time) it's not officially supported. Seems the best advise is to always used the latest driver no matter the DB version according to http://serverfault.com/questions/10477/differences-between-classes12-jar-ojdbc14-jar-ojdbc5-jar-and-ojdbc6-jar @JamesC As I said it works most of the time but it's isn't officially supported. Understood. Will bare that in mind. ""bear"" that in mind."
483,A,"When should we call connection.rollback() method? Please let me know when do we require to call the method connection.rollback(); try{ connection = getConnection(); connection.setAutoCommit(false); pstmt1 = connection.preparedstatement ( ... ); ... pstt1.executeUpdate(); pstmt2 = connection.preparedstatement ( ... ); ... pstt2.executeUpdate(); connection.commit(); }catch ( Exception sqe ) { sqe.printStacktrace(); }finally { closeQuitely ( pstmt1 ); closeQuitely ( pstmt2 ); closeQuitely ( connection ); } In above code we are not using connection.rollback() but if some exception occurs even then everything will work fine [ i guess ] cos connection is already set in autoCommit = false mode. So what could be the possible situation when we need to use this method. Please post the example as well. Simple answer: the programmer should never manually call rollback() or commit(). Besides learning JDBC writing a library/framework or doing something performance critical I wouldn't recommend doing raw JDBC - use Spring JPA or some other framework to automatically handle transactions and connections. It's too easy to screw up the interactions and there's the huge amount of boilerplate code. In the exception case your transaction is unresolved. Eventually it will timeout and as you say it will rollback. But until then (which may be several minutes) all the locks taken by your transaction will be held. The connection has no way to realise that you may not just about to commit(). Holding locks for an extended period like that is very back for concurrency. Add the rollback to your exception case. It may appear that closing your connection will also terminate the transction. When using simple JDBC however in the presence of connection pooling as implemented in application servers closing the connection has the semantic of ""return to pool"" and the connection pool will retain the connection's association with your current transaction. If later in your code still in the scope of the same transaction you ask for a connection the pool will return you the same connection. This is very handy indeed for writing moular applications but has the penalty that you cannot assume closing a connection resolves the transaction. begin tran // call a method get connection work close connection // call another method get connection // you get the **same** connection still associated with the tran work close connection commit +1 for good answer will it timeout? i think the quiet closes in finally will discard the transaction Yes it will in the presenece of connetion pooling. I've expanded the answer to try to make this clear  If you close a connection without committing then it will transaction will be rolled back. if you are using a connection pool it is probably doing that for you. An explicit rollback is probably more appropriate when you encounter a condition that is not causing an exception but you still don't want to commit.  When you close your connection your transaction will be terminated. Most DBMS's will rollback your transaction because they don't know under what circumstances the connection was terminated (maybe your program was killed?). So if you've already committed the rollback will do nothing. On the other hand if you're using Connection-Pooling when you close the connection the Pool Manager intercepts it and will probably (hopefully) rollback the connection and leave the connection open. It's good practice to rollback inside the catch clause or even in the finally clause. It generally doesn't hurt to do an unnecessary rollback after a commit. As an aside if you're using Postgres it's a good idea to rollback before you start to ensure that your transaction start-time is reset. That's because Postgres holds the current_timestamp value to the time the transaction started and if you're using pooled Connections this could have been a long time ago! In the presence of connection pooling in certain app servers closing the connection will **not** rollback the transaction. This is a deliberate performance optimisation it means a second open of a connection will actually give the **same** connection still associated with the trasnaction."
484,A,"oracle sql converter CharacterConverter12Byte problem in jdbc I was working on a simple GUI script yesterday using jdbc in eclipse. When I went to run the program I got a pop up screen asking me about character conversion in jdbc. I had no idea what this was and neither did my professor (no surprise there). Now every time I run a program even one that doesn't use SQL I get the same error. 0 - 2127527632 189000 -1875869392 -2127527632 258 Exception in thread ""main"" java.lang.NullPointerException at oracle.sql.converter.CharacterConverter12Byte.toOracleCharacterWithReplacement(CharacterConverter12Byte.java:253) at oracle.sql.converter.CharacterConverterGB18030.main(CharacterConverterGB18030.java:1119) That's the output I get from it. It may as well be reading binary because I have no idea what it means. Can anyone explain what's wrong? Since there are no answers yet here's how I fixed the problem. I tried accessing the drivers of Oracle and finding anything to do with charconverters. Since I couldn't find any I fixed the problem by changing the workspace in Eclipse. So it must have been something to do with the location on the disc."
485,A,Hibernate Cache and JdbcTemplate Will the Hibernate caching(1st 2nd or Query) work when I use JdbcTemplate? I got to know that the caching is one of the advantage in using ORM instead of traditional JDBC. So If I got to use Hibernate's JdbcTemplate still can I enjoy the benefits of hibernate caching? There is no Hibernate's JdbcTemplate. You either use the JdbcTemplate for direct JDBC code (in which case you totally bypass Hibernate's API and thus Hibernate's services) or the HibernateTemplate for Hibernate code. There is something unclear in your question please clarify. Since you're bypassing your hibernate altogether you have to implement/configure those things yourself.  No if you use JdbcTemplate you will be bypassing the cache entirely and will thus need to invalidate it. HibernateTransactionManager to maintain the cache? Can you clarify? @Pascal: I must have mis-read something. Having re-read the HibernateTranscationManager javadoc it does nothing of the sort. Removed that part from my answer.
486,A,"Calling an Oracle PL/SQL procedure with Custom Object return types from 0jdbc6 JDBCthin drivers I'm writing some JDBC code which calls a Oracle 11g PL/SQL procdedure which has a Custom Object return type. Whenever I try an register my return types I get either ORA-03115 or PLS-00306 as an error when the statement is executed depending on the type I set. An example is below: PLSQL Code: Procedure GetDataSummary (p_my_key IN KEYS.MY_KEY%TYPE p_recordset OUT data_summary_tab p_status OUT VARCHAR2); More PLSQL Code (Custom Object Details): CREATE OR REPLACE TYPE data_summary_obj AS OBJECT (data_key NUMBER data_category VARCHAR2 (100) sensitive_flag VARCHAR2 (1) date_created DATE date_rep_received DATE date_first_offering DATE agency_data_ref VARCHAR2 (13) change_code VARCHAR2 (120) data_ref VARCHAR2 (50) data_status VARCHAR2 (100) data_count NUMBER) / CREATE OR REPLACE TYPE data_summary_tab AS TABLE OF data_summary_obj / Java Code: String query = ""begin manageroleviewdata.getdatasummary(? ? ?); end;""); CallableStatement stmt = conn.prepareCall(query); stmt.setInt(1 83); stmt.registerOutParameter(2 OracleTypes.CURSOR); // Causes error: PLS-00306 stmt.registerOutParameter(3 OracleTypes.VARCHAR); stmt.execute(stmt); // Error mentioned above thrown here. Can anyone provide me with an example showing how I can do this? I guess it's possible. However I can't see a rowset OracleType. CURSOR REF DATALINK and more fail. Apologies if this is a dumb question. I'm not a PL/SQL expert and may have used the wrong terminology in some areas of my question. (If so please edit me). Thanks in advance. Regs Andrew You two different and perhaps contradictory error messages there. PLS-00306: wrong number or types of arguments in call to 'string' What is the dexcription of user defined type data_summary_tab? OracleTypes.CURSOR expects a REF CURSOR which is equivalent to a JDBC ResultSet. Whereas data_summary_tab sounds like it might be a varray or nested table. ORA-03115: unsupported network datatype or representation This suggests you are using an older version of the client than the database server (say 10g or even 9i). Normally we can get away with it but sometime it can cause bugs where we're doing uncommon things. I'm not sure whether calling user-defined types over JDBC ought to count as an ""uncommon thing"" but I suspect it may. Hi @APC. Thanks for this. The last error was a typo. I've edited my question to rectify this. I think the tips on PLS-00306 are the right track (I'm pretty certain we're using the correct JDBC driver). I'll take a look and report back.  I finally (with a little help from others) found out the answer to this. It came in three parts: The first was that I needed to use an: OracleCallableStatement stmt = (OracleCallableStatement) conn.prepareCall(query); rather than the simple JDBC CallableStatement I had been trying to use. The second part was that I had to register my ""out"" parameter as follows: stmt.registerOutParameter(2 OracleTypes.STRUCT ""DATA_SUMMARY_TAB""); The third part and it is implicit in part 2 above was that ""DATA_SUMMARY_TAB"" had to be in UPPER CASE. If you put it in lower case then you get a cryptic error message as follows: java.sql.SQLException: invalid name pattern: MYTEST.data_summary_tab at oracle.jdbc.oracore.OracleTypeADT.initMetadata(OracleTypeADT.java:553) at oracle.jdbc.oracore.OracleTypeADT.init(OracleTypeADT.java:469) at oracle.sql.StructDescriptor.initPickler(StructDescriptor.java:390) at oracle.sql.StructDescriptor.(StructDescriptor.java:320) That's it. Also please note our custom object type was not in any packages. If it is you might need to hack the third parameter around a little. And how to hack around if parameters is in package? Got me with the capitalization"
487,A,JPA/ORM vs JDBC for performance limited machines We are creating a small application that will be deployed to very limited machines. They have only 256mb of RAM. I would like to use JPA as it simplifies the code and removes the need for JDBC ResultSet code. However will the overhead of JPA on such small machines be a factor? I am thinking of using Toplink at the moment which comes in a 2.5mb JAR file. We only have a limited number of tables so the JDBC code won't be too much trouble. But JPA makes the code so nice. Cheers. Depending on the OS and what else you are running 256MB of RAM is not as small as you would think. It may be entirely feasible to use an ORM solution but the best way is to test and see for yourself. It should be relatively simple to test this out and see if its going to work in your environment. Create a simple project or modification to your project that uses ORM and a single entity to do some test transactions. Then watch how it performs and what the memory usage is like. Depending on what you need to do it may be fine. You can also cap the JVM memory to a certain level too which will cause more garbage collections but it should prevent a crash unless you hit the limit.  JPA/ORM performance at runtime will always be greater than or equal to JDBC since they're both based on JDBC. As you've noted the big lift you get from JPA/ORM is at development time. I would like to use JPA as it simplifies the code and removes the need for JDBC ResultSet code. I'm not sure that I understand this statement. JPA will be using a ResultSet behind the scenes; you just won't be writing it. The mapping from ResultSet to objects is encapsulated in XML or annotations. If you're truly memory bound you might have to pass on JPA and hand code the JDBC. You might look at Spring JDBC in that case because it's got a very nice design for JDBC support that makes it pretty simple. 256MB of RAM? You'll have a hard time using any 3rd party libraries. 'I would like to use JPA as it simplifies the code and removes the need for JDBC ResultSet code.' - That's what I meant that we won't need to write it. JPA is awesome in that it can just return the collections. As much as I dislike it I think we'll have to go with JDBC. Thanks.
488,A,"Full text search with InnoDB tables I need to use full text search but the tables that I am using in my web application use the INNODB engine from what I read JDBC does not have support for Mysql triggers and I am supposed to deploy the project on the course server so installing tools such as sphinxs is not possible could someone please suggest a method to perform a full-text search? thanks Edit: the requirement in the project is to have a consistent database the table on which I want to perform search contains the list of instruments that exist in the lab for which I am building the web application it is possible to insert new instruments to it but let's assume that the insert accesses are few and that mostly the table will be used for read access in this case is using MyIsam justifiable and would it conform with the consistency requirements (Myisam doesn't support transactions)? You can create a second table using MyISAM that contains only the primary key of the main table and the text content you wish to FULLTEXT search over. Then when you want to do a fulltext search you do a JOIN between the proper InnoDB table and the search-bait MyISAM table with a MATCH condition against the MyISAM table. This also allows you to store different search-bait text in the MyISAM table to the ‘real’ text in the InnoDB table which allows you implement features like stemming or special apostrophe/hyphen handling that MySQL's FULLTEXT engine can't manage. The problem here of course is keeping the MyISAM data consistent with the InnoDB data. You can either run a job every so often to do it or make the app write to both tables any time there is a text update. Either way hopefully you can get away with inconsistency in fulltext searching where it would be unacceptable for the ‘canonical’ table data. Another approach is just to fall back to LIKE/RLIKE (regexp) matching when the fulltext solution you want isn't available. Will be unindexable so not fast but at least it'll always work and it's fine for smaller databases. Edit: the table on which I want to perform search contains the list of instruments that exist in the lab for which I am building the web application OK does that really have to be FULLTEXT searchable? Wouldn't it be better to model such a list as one entity per type of equipment and a join table between labs and equipments (or whatever it is)? so if 2 inserts happen at the same time? MyISAM won't let two INSERTs claim the same primary key. But this isn't enough to guarantee ‘consistency’ in the general case. Whilst it sounds like you could get away with it from a practical point of view if there is a explicit requirement for ‘consistency’ that's probably exactly what they don't want you to do. yes they suggested we use FULLTEXT search because each instrument has a description field as well and that's where we need to perform the search. I think I will follow this suggestion ""You can create a second table using MyISAM that contains only the primary key of the main table and the text content you wish to FULLTEXT search over. Then when you want to do a fulltext search you do a JOIN between the proper InnoDB table and the search-bait MyISAM table with a MATCH condition against the MyISAM table."" I think it's not a big deal if i returned a type for an instrument that doesn't exist in the labsince thats what we are supposed to return on a search term. How many instruments are there in all? `RLIKE` and the resultant full table scan probably aren't the end of the world unless you have a lot of well-stocked labs! it's not a real lab it's just for the purpose of describing the project application."
489,A,jdbc returns mySQL syntax error exception for a valid query I user the java.sql.Statement.excecuteUpdate method to create a table and insert some values into the database through JDBC. However it gives me MySQL syntax exceptions for no reason. I copied and pasted the same code into command prompt. it worked. I'm wondering why it's doing that?? Can you provide the query and code you're using? Guessing You cannot do a query like: insert ...; insert ... ; only one query per method call is there an easy way to do a bunch of insert? using java.sql.Statement with the following methods: addBatch executeBatch clearBatch
490,A,"SimpleJdbcTemplate and null parameters I'm using SimpleJdbcTemplate and MapSqlParameterSource in the folowing way: MapSqlParameterSource parameterSource = new MapSqlParameterSource(); parameterSource.addValue(""typeId"" typeId Types.BIGINT); List<Long> ids = _jdbcTemplate.query(_selectIdByParameters new EntityIdRowMapper() parameterSource); When typeId ( which is a Long ) is null then the query looks in the following way: SELECT id FROM XXX WHERE typeId = null whereas I would expect it to generate SELECT id FROM XXX WHERE typeId IS NULL I've reported this issue and the response was that You will have to provide the appropriate SQL statement based on your query parameters. and as a consequence my code is littered with null checks. Is there a more elegant way of handling null parameters sent to the SimpleJdbcTemplate? They have a point - JdbcTemplate isn't a SQL interpreter it just replaces your placeholders. I suggest you construct your clause with a utility method and concat it to the query string: String createNullCheckedClause(String column Object value) { String operator = (value == null ? ""is"" : ""=""); return String.format(""(%s %s ?)"" column operator); } ... String query = ""select * from table where "" + createNullCheckedClause(""col"" x); Not very pretty. Alternatively perhaps you can configure MySQL to allow ""= NULL"" but I don't think that's an option."
491,A,"Accessing the JDBC ResultSet concurrently in Spring I am processing a large amount of data in a Spring JDBC DAO. The DAO directly returns an Iterator over the objects which operates on a bounded BlockingQueue using take() while the retrieval operation is happening in a separate thread (using an ExecutorService). Inside this thread I see the following behaviour: the retrieval works but certain calls to the ResultSet are causing the call to hang. These calls are isClosed() and isLast() but not isAfterLast() or isBeforeFirst() or isFirst() Obviously I need to know what the last element is (in order to insert a special element into the blocking queue that yields false in the iterators hasNext() method). I could work around it by finding out the number of rows in the ResultSet before putting objects into the BlockingQueue but this feels a bit clumsy. Is there a thread-safe way to work with ResultSets? Switching to a multi-threaded datasource (I tested C3POs ComboPooledDataSource) does not seem to help. Note: this issue was first (incorrectly) identified by me here I don't think that java.sql.ResultSet is thread-safe although admittedly this is not actually mentioned in the javadoc. I wouldn't be at all surprised if calling methods on a ResultSet from different threads causes those method calls to hang. As an alternative I suggest having your retrieval thread as the only user of the ResultSet pulling the rows off and then dumping the data itself on to your BlockingQueue. It then becomes trivial to detect the end of the result set and put your EOF marker on the queue. The generally preferred mechanism in JDBC for iterating over very large result sets is to use the fetchSize property of java.sql.Statement although this is highly dependent on the database and JDBC driver. I know that the Oracle driver honours this setting but not sure about others. If the driver decides that it needs to fetch the whole result set into memory before giving you the first row then no matter what you do you won't be able to process the first rows while fetching the next ones. I am currently using a fetch size. It's the (relativly) lower processing speed of the data consumers that require the use of blocking queues. AFAIK the DAO in question currently IS the only user of the ResultSet. With the explicit row counting workaround I might as well leave things be as they are and document the ResultSet behaviour accordingly. Yes but is the DAO being accessed from multiple threads all of which are operating on the same ResultSet? No the ResultSet should be accessed only by one Thread. I will have to investigate this further.  The correct solution is to set an appropriate ResultSet type. The default *""TYPE_FORWARD_ONLY""* is not supported by isLast(). The type of ResultSet can be set by using a PreparedStatementCreator instead of an SQL string for e.g. query() calls to a JdbcTemplate. Such instances are acquired through a PreparedStatementCreatorFactory. On such a factory the type of the ResultSet (e.g. *""TYPE_SCROLL_INSENSITIVE""*) can be set. hmm obscure....."
492,A,"Prepared Statement Failing I'm using a prepared statment that should (using SQL & JDBC) insert data into a dataTable. I am using one that deletes data that works fine but the insert one is not inserting any data into the data table and does not produce an error or warning. What could cause a prepared statement to fail in this way? Could inserting a null value into the prepared statement cause this? Could you post some sample code? ChssPly76 got it exactly right What do you mean by ""failing but does not produce an error""? How do you know it's failing then - is data not actually being inserted? Perhaps you're not committing a transaction? edited question to eliminate confusion. Yes data is not actually being inserted. Well did you check whether transaction is being committed? Can you post your code here? yeah I forgot to call 'insert.executeUpdate();' Still not working but at least I have an error now Thanks.  Two ways to solve your problem. 1st way:  Connection con = DriverManager.getConnection(DB_host DB_UserName DB_UserPassword); con.setAutoCommit(true); String sql = ""INSERT INTO Users (fName lastName userName password) VALUES (? ? ? ?)""; PreparedStatement stmt = con.prepareStatement(sql); stmt.setString(1 ""fName"" ); stmt.setString(2 ""lastName"" ); stmt.setString(3 ""userName"" ); stmt.setString(4 ""password"" ); stmt.executeUpdate(); 2nd way: Connection con = DriverManager.getConnection(DB_host DB_UserName DB_UserPassword); String sql = ""INSERT INTO Users (fName lastName userName password) VALUES (? ? ? ?)""; PreparedStatement stmt = con.prepareStatement(sql); stmt.setString(1 ""fName"" ); stmt.setString(2 ""lastName"" ); stmt.setString(3 ""userName"" ); stmt.setString(4 ""password"" ); stmt.executeUpdate(); con.commit(); That is while creating connection object itself enable autocommit true for it. So tat it ll make the changes immediately reflect into ur database. Else after ur transaction make the connection as commit to ensure your transaction to be saved in database"
493,A,"What is difference between autoReconnect & autoReconnectForPools in MySql connector/J? In the configuration reference for MySql's connector J driver a caveat emptor is issued on the use of the autoReconnect property. I followed the instructions and increased my server's *wait_timeout*. Since I am using DBCP (I am considering moving to c3po after reading several posts on Stackoverflow shooting down DBCP ) is it ok to use the autoReconnectForPools property ? What does it actually do when enabled under DBCP or any connection pool for that matter ? Are you sure you're using DBCP properly? According to the short configuration notes it's supposed to handle timeouts pretty well thanks to the default value of testOnBorrow=true (tests the connection before used and if it fails it is dropped from the pool and we try to get a new one instead). The only thing you need to do is to make sure you configure the validationQuery property to a non-null String e.g. ""SELECT 0"" for MySQL database (here is a post about different validationQuery values per DB used).  autoReconnect will throw an SQLException to the client but will try to re-establish the connection. autoReconnectForPools will try to ping the server before each SQL execution. I had a lot of issues with dbcp in the past especially disconnections. Most were solved by moving to c3p0. Notice that the mysql driver has connection tester for c3p0 (com.mysql.jdbc.integration.c3p0.MysqlConnectionTester). Also you may want to check this out: http://stackoverflow.com/questions/520585/connection-pooling-options-with-jdbc-dbcp-vs-c3p0 Thanks for your thoughts."
494,A,"Understanding MySQL Connector/J's FOSS exception I have to create an application which transfers data from a local workstation into a remote MySQL database. Unfortunately my boss doesn't want to pay for a commercial license because it's not a critical application and we wouldn't make any money of it but still he doesn't want to put the full source under GPL. (Please don't comment on this attitude I don't share it) On the other hand I'd really like to do this project for my personal experience so please forgive me if this question makes me look like a freeloader. Here's my question: Would creating an additional layer with a liberal open source license like MPL or LGPL fulfill the conditions of the FOSS exception? Example: Closed-source Java application -- uses --> MPL JDBC connector -- uses --> GPL'ed MySQL Connector/J (I guess this would pretty much defy the spirit of the FOSS exception it would be a legal application of the facade pattern :) Please keep in mind that answers concerning legal matters on SO can only be ""legal opinions"". If you need legal advice you should consult a lawyer. Yes I understand that. But it would even help me if someone would give me a ballpark estimate. The question is whether you distribute your application (or sell it) or just use it in house. AFAIK if you distribute it as closed source you need to purchase a license. It seems that if you are using it in house there's no need to do so as you are no distributing it. Notice that I'm not a lawyer... AFAIK it should be ok (again I'm not a lawyer). The accepted answer here also agrees with me - http://stackoverflow.com/questions/620696/mysql-licensing-and-gpl Would providing some kind of commercial web-based service also count as internal use?"
495,A,"Java: Help constructing a fillTextFields() method I have a Java project where I am to connect to a database and create buttons (next new save delete previous) to navigate through the database content where there are appropriate text fields and labels for the specific information. I'll use the code below as an example (each button is set up very similar)... I have it as follows: JButton jbtnNext = new JButton(""Next ->""); jbtnNext.addActionListener(this); if (e.getSource() == jbtnNext) jbtnNext_Click(); private void jbtnNext_Click() { JOptionPane.showMessageDialog(null ""Next"" ""Button Pressed"" JOptionPane.INFORMATION_MESSAGE); try { if (rset.next()) { fillTextFields(true); }else{ //Display result in a dialog box JOptionPane.showMessageDialog(null ""Not found""); } } catch (SQLException ex) { ex.printStackTrace(); } } The professor gave the following outline of logic to construct the fillTextFields() method: Construct the method to provide reusable code that would fill the JTextFields on the GUI with appropriate values from current record from the database (when ""Previous or ""Next"" buttons are pressed) or blank values (when the new Button is pressed). To determine when the current record was to provide values (next and previous) or the value would be blank (new button) pass a boolean argument into the method. If data from the current record was to be used as fill values pass true for both previous and next button code after moving the record pointer. If the new button was pressed and want to fill with blank values pass false to the method. Inside the method use a conditional expression to evaluate the boolean variable. If true The appropriate get----() resultset method is used to fill the JTextFields. If false fill them with """". The .setText() method of the JTextField is used to fill each JTextField. Make sure the fillTextFields method throws the appropriate exception. I understand and have the previous and next button methods passing true while the new button method is passing false but I don't quite understand how to set up the fillTextFields() method correctly or how to ""throw the appropriate exception""... Any help would really be appreciated thank you! I don't quite understand how to set up the fillTextFields() method correctly or how to ""throw the appropriate exception"".. JDBC methods can throw SQLException when the DB interaction fails. The fillTextFields() should not catch it but just let it pass through. It will be handled in the catch (SQLException e) you already have there in the posted code. You need to add a throws clause with this exception to the fillTextFields() method. E.g. public void fillTextFields(boolean blank) throws SQLException { Connection connection = null; // ... try { connection = DriverManager.getConnection(url username password); // ... } finally { if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} // ... } } See also the Sun tutorial on Exceptions and the Sun JDBC tutorial.  The fillTextFields method should as the name suggest fills textfields with data you get from the database. I presume that the rset is a global variable so you should be able to access it from other methods within the same class. You can check out this tutorial so that you can get an idea of how to use the textfields in Java. In the fillTextFields method you first check if the boolean that has been passed is true or false if it is true you extract the data from the result set and use the .setText(textToPrint) to show the data you have retrieved from the database. To retrieve data you can do as follows: rset.getString(1) The above returns the value stored in the 1st column of the database as a String. You can read through the JavaDoc to see how to return different types. With regards to the exception to be thrown you can check the link to the JavaDoc provided to see which methods throw what exceptions."
496,A,dictionary data insert or select (oracle java) I have an table (in ORADB) containing two columns: VARCHAR unique key and NUMBER unique key generated from an sequence. I need my Java code to constantly (and in parallel) add records to this column whenever a new VARCHAR key it gets returning the newly generated NUMBER key. Or returns the existing NUMBER key when it gets an existing VARCHAR (it doesn't insert it then that would throw an exception of course due to the uniq key violation). Such procedure would be executed from many (Java) clients working in parallel. Hope my English is understandable :) What is the best (maybe using PL/SQL block instead of Java code...) way to do it? And what do you thing about trying to INSERT the new record first and than doing SELECT whenever an exception was thrown before on not? Depends on which case you think is more frequent. I assumed that you would be retrieving existing words more often than adding now ones. If you mostly add new ones then yes try the INSERT first. I do not think you can do better than SELECT the_number FROM the_table where the_key = :key if found return it if not found INSERT INTO the_table SELECT :key the_seq.NEXT_VAL RETURNING the_number INTO :number and COMMIT this could raise a ORA-00001(duplicate primary key insert) if the timing is unlucky. In this case SELECT again. Not sure if JDBC supports RETURNING so you might need to wrap it into a stored procedure (also saves database roundtrips). You can use an index-organized table (with the_key as primary key) makes the lookup faster.
497,A,"Converting between oracle.sql.TIMESTAMPTZ and standard JDBC classes for DbUnit I'm running Oracle 10g and have columns with Type_Name TIMESTAMP(6) WITH TIME ZONE When inflated into java classes they come out as oracle.sql.TIMESTAMPTZ But DbUnit can't handle converting Oracle specific classes to Strings for writing to XML. I'm wondering if there's any easy way for me to convert (say in my SELECT statement somehow) from these Oracle specific timestamps to something in java.sql. I haven't had to deal with this problem exactly but I presume that having it come through as a string from the SELECT query would be fine. You could use the to_char function. To convert it to a string. e.g: SQL> select to_char(systimestamp 'IYYY-MM-DD HH24:MI:SS.FF TZD') as d from dual; D ---------------------------------- 2008-10-21 17:00:43.501591 This would then be seen by your program as a string. TZD includes timezone information (of which there is none in this example) Later this could then be parsed by Java using the SimpleDateFormat class. Alternatively the oracle.sql.TIMESTAMPTZ class has a method called dateValue that returns a java.sql.Date class.  I would like to remark that using IYYY as format for the year might not be a good idea unless you really want to get the ISO year. You should use YYYY instead of IYYY. Try to run your SQL for 31.12.2012 using select to_char(timestamp'2012-12-31 00:00:00 +00:00' 'IYYY-MM-DD HH24:MI:SS.FF TZD') as d from dual; returns ""2013-12-31 00:00:00.000000000"" which is not the year you would expect."
498,A,"ResultSet loses first value Code seems to work fine but I noticed whenever I queried a string with only one result it returned nothing. Somehow I am skipping the first result I think but have no idea why.  else{ Conn con = null; try { con = new Conn(); } catch (Exception e) { e.printStackTrace(); } String sql = ""SELECT productname quantityperunit unitprice FROM products pr categories ca WHERE pr.categoryID = ca.categoryID AND ProductName LIKE '%"" + searchTerm + ""%'""; System.out.println(""last try""); try { searchResults = con.query(sql); if (searchResults.next()){ session.setAttribute(""searchResults"" searchResults); } } catch (Exception e) { e.printStackTrace(); } } and this is the display code:  java.sql.ResultSet resultSet = (java.sql.ResultSet) session.getAttribute(""searchResults""); if(resultSet == null){ out.println(""Nullified""); } if(resultSet!=null){ out.println(""<table border='1'>""); out.println(""<tr><th>Product Name</th><th>Quantity per Item</th><th>Price</th><th>Quantity</th><th><Add to Cart</th></tr>""); while(resultSet.next()){ out.println(""<tr><td>""+resultSet.getString(""ProductName"")+""</td></tr>""); } out.println(""</table>""); } any help would be appreciated. sorry about the formatting I can't seem to get it to work right... To format code indent it with 4 spaces. You can do it by selecting the piece and pressing `010101` button in editor toolbar or the `Ctrl+K` key. I've done it for you. Khorkrak already nailed it down. I just want to add that this is **really not** the way to code it. JDBC code is leaking resources. Model view and controller logic is mingled. Exception handling is bogus. Session scope is been abused. I've posted several answers with examples before how to do it the right way have a look: [this](http://stackoverflow.com/questions/2219238#2219238) [this](http://stackoverflow.com/questions/1832524#1832524) and [this](http://stackoverflow.com/questions/2428468#2428468). Thanks for the help BalusC excuse the noobiness but his is the first I've heard of JSTL. Change this: while(resultSet.next()) { out.println(""""+resultSet.getString(""ProductName"")+""""); } out.println(""""); } To this: do { out.println(""""+resultSet.getString(""ProductName"")+""""); } out.println(""""); } while(resultSet.next()); just tested this and it works great will fall back to it if my JSTL attempts fail. Thx man!  I'd imagine that resultSet.next() moves the cursor to the next result thus it immediately would skip the first result on the first iteration of the while loop. huh. is there another way to check if my resultset is empty? Yes map it to `List` and just test it by `List#isEmpty()` or `List#size()`. Also see [this answer](http://stackoverflow.com/questions/2591732/how-to-check-if-resultset-has-only-one-row-or-more/2592141#2592141)."
499,A,How to set fetch size in Hibernate against an Oracle database? When programming directly in JDBC against an Oracle database you can call stmt.setFetchSize(fetchSize) on the statement to determine the max number of records to fetch in one round trip from the small default value. I'd like to do this from withing Hibernate 3.2. Can someone tell me where this would be set? Use Query.setFetchSize(). Thanks for such a fast answer!
500,A,How to find out where a COMMIT might be happening? I'm refactoring some code converting a number of related updates into a single transaction. This is using JDBC MySQL InnoDB. I believe there is an unwanted COMMIT still happening somewhere in the (rather large and undocumented) library or application code. What's the easiest way to find out where this is happening? There must be some sort of implicit commit because I'm not finding any COMMIT statements. I am not an expert with mysql but there should be a possibility to log all executed statements to a file and/or console. This will probably help. If you can debug through code set breakpoints right before the commits you know and then have a look to the logged statements. Thus you'll probably see if or if not there is a unwanted commit.  Check out this page in the MySQL docs for statements that cause an implicit commit. Also since you're using JDBC make sure autocommit is false as in connection.setAutoCommit(false); Looking at the list actually helped after I found the my.cnf query-log settings.
501,A,"Spring commits when it should not ? (related to Oracle autocommit) I have an interface like below public interface FooDAO { public void callA(String x); } and an implementation as below deliberately making readonly true and not supported public class FooDAOImpl implements FooDAO { //for testing @Transactional(readOnly = true propagation = Propagation.NOT_SUPPORTED) public void callA(String x) { //sql update method } } In my spring context I declared the Datasource transaction manager and the tx:annotation-driven. I wrote a Junit4 test that looks like @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(...) @TransactionConfiguration(transactionManager=""txManager"" defaultRollback=true) public class MyTest { @Resource FooDAO fooDAO; @Test public void testRegisterWorker() { fooDAO.callA("""") } } I would have expected the record to not be inserted into the database at all. However I see that the row has infact been inserted into the DB. I do use the Oracle database so I think the autocommit is set to true by default (I think). But shouldn't the spring transactional tags override them? Can someone tell me what is going wrong here? In order to use @TransactionConfiguration you should annotate either your test class or test method @Transactional. Also your DAO method probably runs without transaction due to propagation = Propagation.NOT_SUPPORTED.  Autocommit probably is on by default. With DataSourceTransactionManager autocommit is only changed if a transaction is actually started. Neither NOT_SUPPORTED or SUPPORTS start a transaction so whatever default state the Connection is in will remain. Consider setting autocommit off by default in your Spring xml file. If it is enabled Spring will have to change it before each tx and restore it afterwards which may be expensive in Oracle (not sure). This also prevents you from accidentally committing outside of a transaction. For the details see org.springframework.jdbc.datasource.DataSourceTransactionManager.doBegin() which manages the autocomit and isolation level of the Connection. doBegin() is only called by AbstractPlatformTransactionManager.getTransaction() and handleExistingTransaction() if the propagation is REQUIRED REQUIRES_NEW or PROPAGATION_NESTED. You probably want to take a look at org.springframework.test.context.junit4.AbstractTransactionalJUnit4SpringContextTests. This is a Spring aware base class you can use for your test classes. It will rollback any transactions at the end of each test case. This way there is no need to change the annotations just for test. You can set your @Transactional the way they should be in prod and rely on the rollbacks to make sure nothing is actually changed in the db during the test.  Autocommit is a ""feature"" of JDBC not Oracle (in Oracle all DML statements are part of a transaction and thus are only commited when the application issues a commit). Most drivers make autocommit the default when creating a connection to a database. You can change the behaviour of your connection by calling the setAutoCommit method."
502,A,Can/should JPA be used to return values rather than entities? I'm using JPA for a project and in most cases want to get entities but there are a few cases (reporting being one of them but there are others) where I do not want or need to get entities but rather want a selection of values. Does JPA support this? If so does it make sense to use it or does it make sense to use straight JDBC in these cases? Q1: Yes it does. It's so called scalar queries e.g.: select u.name from User u as opposed to select u from User u Q2: When it comes to sense of using it: Such queries have sense - you just simply need a single property not the whole object. But if you plan to make all your queries only fetching separate values then the question 'why?' seems valid. The whole idea of O/R mappers is to allow you operate on objects not (related) tables and ids. So fetching ids using JPA usually doesn't make sense. Once you have objects mapped to database it should be easier for you to operate on the data. I'm looking to get multiple values. Is there a way to get u.name u.age from User u? This is a simplified example and I'm not pulling multiple values from an entity. And I am mostly using JPA for entities just wondering whether it makes sense to introduce something like JDBC for the those cases where I'm doing something different. I guess it is a threshold question. Obviously as per the JPA spec. As you wrote it  SQLResultsetMappingWithAlias at java2s.com seems to provide an example of what you are looking for.
503,A,"Add description to columns using Java code I can create a table and its columns in Java by using the statement: CREATE TABLE table_name(column1 int column2 double etc...) What I would like to do is to add descriptions to each of these columns with an appropriate statement I found a stored procedure sp_addextendedproperty that looks like it can be used to accomplish this I just have no idea how to use it in java with jdbc. Why would you want to do this from Java? Are you executing ""create table"" statements from java as well? If not presumably you'd want to keep things bundled together in your DDL script yes I am creating the data table from Java Are you creating the table dynamically at runtime (e.g. as part of your application) - perhaps that's even user-driven? If that's the case you already have that ""documentation"" (column comments) somewhere and I doubt the utility of adding them to SQL Server. But if you're just trying to automate your build take a look at LiquiBase. It's a pretty decent DB change management system that uses XML as backbone. It's written in java and integrates well with Hibernate (useful if you ever decide to use ORM instead of straight JDBC). Update: If you do decide to go forward with calling stored procedure via JDBC I would strongly recommend using CallableStatement to invoke it. Dynamically building SQL queries in the application should be avoided if possible.  There are a number of ways to call a stored procedure (essentially preparing the statement and binding the variables or sending a string of SQL) but the simplest is to just send rhe SQL statement exec sp_addextendedproperty list of arguments the sp needs; Skipping your try/finally boilerplate and assuming connection is a java.sql.Connection that's: connection .createStatement() .execute( ""exec sp_addextendedproperty arguments;""); But ChssPly76 has a good point: doing this from Java isn't a good idea (unless you're developing some database manager in Java)."
504,A,"How to get superior terror checking of MySQL queries I just started using MySQL and I just can see myself woking with strings! I mean the compiler can't catch errors like this and it's just a mess! Is there a wrapper or some kind of class I can add that does something as simple as making a function that adds a table and asks for args? I'm sure there is a tool like that but I can't find it or know its name. Yes working with SQL queries **is** working with the strings. Very handy. What'd wrong for you in this? Give JDBC prepared statements a try. ""Dummies"" in question title and spelling suggests just that. looks a lil simplistic  You're basically looking for an Object Relational Mapper. Hibernate is one of the pioniers in this area. JPA is a new and well-established Java EE standard in this area formed by the guy behind Hibernate. Hibernate and EclipseLink offers JPA implementations. There exist IDE tools to autogenerate Java classes based on database models and vice versa such as Hibernate Tools for ""good old"" Hibernate and Eclipse Dali for JPA. If you don't want to use an ORM and/or don't want to autogenerate model objects then you just have to make sure that you design the right model objects for the database model. I.e. use a Long property for a BIGINT field a BigDecimal property for a DECIMAL field etcetera. You can find an overview of the default mappings in this page. In ""plain vanilla"" JDBC you should at least use PreparedStatement methods to compose the SQL query rather than concatenating as String. There are a lot of setXXX() methods for the specific datatype such as setLong() setBigDecimal() etcetera. The PreparedStatement not only eases setting fullworthy Java objects like Date and InputStream in a SQL query but it also prevents the code from SQL injection attacks. You can learn more about PreparedStatement in the Sun JDBC tutorial and you can find a basic kickoff DAO tutorial in this article. tnx ill start looking at all this  You can use an object-relational mapper like Hibernate. See also What Java ORM do you prefer and why?."
505,A,"Is there any way to prepare a sql statement in Java without using a Connection object? I'm pretty new to JDBC so this is probably a very straightforward question. I have to run several SQL statements so I'm trying to write a generic ""runSQLResultSet"" method that takes a String sql statement and returns a ResultSet. I want it to take care of opening the database connection executing the statement storing the ResultSet in a CachedRowSetImpl object (so that it will persist after the connection is closed) and closing the connection. I created a method that does this and it works. My problem now is that I want to be able to use it for dynamic statements that are built with variables. I looked around and it seems that I should really change my method to take a PreparedStatement instead of just a plain String. Then I can build the PreparedStatement on the other side and pass it to the method. The problem is that I can't seem to create a PreparedStatement without a Connection object. I can open the connection before preparing the statement but that defeats my purpose of factoring out the database processing into the runSQLResultSet method. I need a way to build a SQL statement with dynamic components without a connection object and pass it to a method that will then execute it. Is there any way to do this with a PreparedStatement? Is there any other statement object I can use instead? Otherwise - is there any better way to do this? be forewarned the building ""dynamic"" sql statements without using PreparedStatement or something similar opens the door to SQL Injection attacks. @fuzzy lollipop - that's why I asked this question instead of just building the sql statement with string concatenation and passing it in as a string which would be convenient but dangerous If I understand you correctly you want to use the same query with different variables inserted into the query. You can have your method return the ResultSet like it currently does and pass the variables in as parameters to the method. then you can put the parameters into the query inside of the method. public ResultSet getResult(String param1 String param2){ statement = conn.prepareStatement(yourQuery);// conn must be an open connection statement.setString(1param1); statement.setString(2param2); ResultSet rs = statement.execusteQuery(); return rs; } That's a basic example of how you might do something like that if I understood your question correctly. As I posted in a comment for BalusC's answer - then the method is not really generic anymore. I want to be able to pass any sql statement with any number of dynamic variables (and possible different data types) incorporated.  You cannot create one without a DB connection. A PreparedStatement will be precompiled in the DB and thus really needs an open connection. You can instead also just consider to dynamically build the SQL string instead. Generating the PreparedStatement placeholders (the ? things) in a loop and and using String#format() to put them in the SQL string. u can also consider to just pass the variables to your runSQLResultSet method and build there instead. As per the comments here's an example: try { connection = database.getConnection(); statement = connection.prepareStatement(SQL); setValues(statement values); // ... . public static void setValues(PreparedStatement preparedStatement Object... values) throws SQLException { for (int i = 0; i < values.length; i++) { preparedStatement.setObject(i + 1 values[i]); } } If I have to pass the variables it won't really be generic anymore. I want to be able to pass any sql statement with any number of dynamic variables incorporated. Just pass them as a `Object[]` or as `Map`. But then how do I process them...? How do I know if it's a String int etc....? Doesn't matter. Just use `PreparedStatement#setObject()`. An example (and more hints) can be found here: http://balusc.blogspot.com/2008/07/dao-tutorial-data-layer.html Check the `DAOUtil` class example. I can't read the blog as my office blocks all blogs... but thanks for the suggestion! It worked! (Although I used a variable length array - Object ... - instead of an array - Object[]) The `DAOUtil` class example uses exactly this. I've updated the answer with some relevant copypastes.  what you are missing is the concept of Database connection pooling you should never be instantiaing connections directly the pool controls the database connections under the covers. You can look at my open source project SQL Construction Kit for some inspiration on one light weight way to deal with JDBC and how to build dynamic SQL statements using Factory and Builder patterns.  public ResultSet excuteStatement(String statement Object... params){ statement = conn.prepareStatement(statement); int i = 1; for (Object o:params){ statement.setObject(i++o); } ResultSet rs = statement.executeQuery(); return rs; } @BalusC - I agree that i did not give the finer details. But there are many ways to do this... eg. pass through the preparedStatement instead of a string etc. Bad example. This way you can't close the statement anymore. If you close it then the resultset will be closed. @BalusC - I used the same basic structure but cached the resultset in a CachedRowSetImpl. I also stored the result of conn.prepareStatement in a PreparedStatement not a String. But this was the general idea I used PS. Remember to close your ResultSet and preparedstatment. Thanks! This is basically what I implemented as suggested by BalusC in his post and comments"
506,A,How to use Java JDBC connection pool? I want to use a JDBC connection pool. The most important factor is that it's easy-to-use and bug-free. What is suitable for me? Also have a look at BoneCP; there are some samples on the site.  2 years later... Just migrated to jdbc-pool (standard on Tomcat 7 now) it was very easy to implement it standalone in a web app or for the the whole server. Per specifications and my experience it out-performs c3p0. Per specs it is also alot cleaner than dbcp or c3p0.  I suggest c3p0 (over DBCP which has some really serious issues): it works great is actively maintained and easy to use. Maybe have a look at this previous question for more inputs on this. Update: I admit I didn't check the status when I wrote this answer (I'm using c3p0 for many years and was happy with it) and it appears that c3p0 development is in stand by. Funnily the previous question mentioned as reference has been updated the 2010-03-12 to mention that DBCP development is alive again. My original post may thus be out of date. Is c3p0 really actively maintained? The latest version is 0.9.1.2 from 2007-05-21. @Arne Damn you're right. And DBCP has been resurrected. I've updated my answer... funnily...lol nice word  I got Tomcat jdbc-pool going as a standalone. See example at http://dvdsdirect.us/notesjdbcpool.jsp  Another fine alternative is the Apache Database Connection Pool. Instead of getting a connection using DriverManager you'll use a JNDI naming service to get your connection out of the pool. Be sure to close your resources - Connection Statement and ResultSet. If you don't your pool will be quickly exhausted.  I've used this MiniConnectionPoolManager with H2 and Derby.
507,A,"Deployed NetBeans web app that uses JDBC gives ""java.sql.SQLException: No suitable driver found"" I have a Java web app using JDBC created in NetBeans deployed to Tomcat that gives a ""java.sql.SQLException: No suitable driver found for ..."" error. The same app works fine when I run it as a non-web Java app. I have the jar of the JDBC driver I'm using added to the libraries of the web app. The solution was (in the case of SQL Server) to call DriverManager.registerDriver(new com.microsoft.sqlserver.jdbc.SQLServerDriver()). Make sure to call this before doing any JDBC stuff. You have to call this method with the appropriate JDBC driver. To not hardcode a driver you can use Class.forName(""full.driver.name"").newInstance(). This is probably not a NetBeans specific issue but a Tomcat/JDBC issue. Note that this seems more like a workaround than a true solution because why would this be required in a web app and not in a non-web app? Although I marked this as the answer BalusC's answer has useful details. His answer is more like a reply to my answer.  java.sql.SQLException: No suitable driver found To be clear this exception can have two causes: The driver is not loaded. The (wrong) URL didn't return true for Driver#acceptsURL() for any of the loaded drivers. Now back to your ""workaround"" which is actually the solution: Note that this seems more like a workaround than a true solution because why would this be required in a web app and not in a non-web app? JDBC4 has a new feature: the DriverManager will auto-load any drivers which are in the classpath and definied in service loaders of JAR files. This will only work in Java6 environments. Maybe your problem is that the webserver is using a Java5 JVM. I would however not always rely on it and just stick with using Class#forName(). In a well designed DAO layer you need to do this only once. Or even better just let the webcontainer manage a datasource for it so that you can take benefit from connection pooling and thus a major improvement in connecting performance. Further on I would clear out one misconception: Class.forName(""full.driver.name"").newInstance() The newInstance() call is actually not required for properly designed JDBC drivers. A decent JDBC driver will register itself as follows: static { DriverManager.registerDriver(new ThisDriver()); } But poorly designed JDBC drivers (of which there should actually be none nowadays this has only occurred in one of the oldest versions of the MySQL JDBC driver if I am correct) did the following: private ThisDriver() { DriverManager.registerDriver(this); } which thus really needed the newInstance() call to get itself registered. This became a myth because everyone was since then recommended to do so. That's not needed. Just leave it away and you'll save an unnecessary instantiation. Hope this helps.  Tomcat might need to find that JAR in the server/lib for Tomcat 5.x or /lib for 6.x. There's a hierarchy of class loaders: bootstrap app server WAR. If the Tomcat app server is looking for the JDBC driver JAR it won't find it in the WAR. But not finding the driver class would get you a ClassNotFoundException. ""java.sql.SQLException: No suitable driver found for ..."" usually means that the connection URL has a syntax error. I'd check that first. Don't be fooled by ""it works fine as a non-web app."" That tells me that your web app is different. If you've set up a JNDI connection pool which is a recommended best practice perhaps your URL isn't exactly the same. I tried putting the jar in the Tomcat's lib directory but that didn't help. The issue was not a connection URL issue. See BalusC's post for more details."
508,A,"SQL Server/T-SQL via JSP: ""The multi-part identifier XX.YY could not be bound"" I'm getting the error:  the multi-part identifier ""IC.industry"" could not be bound when making this SQL query from a JSP page via JDBC: select C.company C.shname C.fullname count(d_to_c.designer) from companies C left join ind_to_c IC on C.company = IC.company left join d_to_c on C.company= d_to_c.company where IC.industry = ? group by C.company C.shname C.fullname order by C.shname and I'm trying to run it as a prepared statement where I'm setting the parameter via (for example) stmt.setObject(1 7) prior to running stmt.executeQuery(). Now what's weird is: If I execute this with the ? and set the parameter as I just mentioned I get the ""could not be bound"" error. If however I just change the query and hardcode the number 7 into the text of the query it works! So it has something to do with binding that parameter. But I can't seem to figure out what. Anybody? UPDATE: Per request the table definition for ind_to_c:  industry - int(11) company - int(11) (it's just a table that defines the m2m relationship between industries and companies) UPDATE 2: Also per request the full JSP code. I had to pull this out of a call to an abstraction of the database connection (which we use to store prepared statements etc. // conn has been initialized as the db connection object. int parent_id = 7; PreparedStatement ps = conn.prepareStatement(""select C.company C.shname C.fullname count(d_to_c.designer) from companies C left join ind_to_c IC on C.company = IC.company left join d_to_c on C.company = d_to_c.company where IC.industry = ? group by C.company C.shname C.fullname order by C.shname""); ps.setObject(1 parent_id); ResultSet rs = null; rs = ps.executeQuery(); Have you tried passing a named parameter (i.e: @industry) instead of a question mark? No -- how does one do that in the context of JSP/JDBC? I tried just replacing the question mark placeholder with ""@industry"" and it appeared to not recognize it as a placeholder at all.  I see from your comments that you can only use SetObject. But why do you pass an object array instead of a single object? (if I read Java correctly) I don't that was a typo... I'm pulling all of this code out of an object structure we use to store prepared stmts and do some other high-level stuff... and the way we pass params to that framework is via an object array. Accidentally left it as an array instead of a single object. Oops! (that is to say the code you see now in the question is the correct code and it does still have the same problem.)  I upgraded to the newer v. 2.0 of the MS-SQL JDBC driver and magically it worked.  Maybe I am just thinking to simple here because i do not know JSP to well but would dit not just work: int parent_id = 7; PreparedStatement ps = conn.prepareStatement(""select C.company C.shname C.fullname count(d_to_c.designer) from companies C left join ind_to_c IC on C.company = IC.company left join d_to_c on C.company = d_to_c.company where IC.industry = ? group by C.company C.shname C.fullname order by C.shname""); ps.setInt(1 parent_id ); ResultSet rs = null; rs = ps.executeQuery();  What's the data type for industry? Does it make a difference if you use the type specific bind methods like stmt.setInt(17) instead? edit: also not related to the question but you should probably remove C.cid from the SELECT. Some variants of T-SQL will infer that you want to group by that column since it is not the subject of an aggregation function even though you don't specifiy it in the GROUP BY clause. Back on topic can you post the table definition for ind_2_c? The nature of the error would seem to indicate that it has no column called industry. aah that makes more sense also rather than tidying up the code for our benefit can you just copy and paste the code for creating the prepared statement? actually I can't test that -- have to operate through a framework (looong story) that only gives me access to setObject. Yes I realize that's silly. Anyway though I need to use setObject. (Industry is an int(11) by the way) C.cid was a typo as was ind_2_c (should have read ind_to_c). I renamed some of the columns/tables for purposes of this post hence the typos. Also posted the table def."
509,A,"No server-side prepared statements using MySQL Connector/J From what I understand MySQL 5.1 supports server-side prepared statements. Therefore the following code should prepare the statement once and execute it 10 times:  Connection conn = ds.getConnection(); PreparedStatement stmt = conn.prepareStatement(""SELECT COUNT(*) FROM users WHERE user_id=?""); for (int i=0; i<10; i++) { stmt.setString(1 ""FOO""+i); ResultSet res = stmt.executeQuery(); res.close(); } stmt.close(); conn.close(); What I see instead in the mysqld log is the query being executed directly:  SELECT @@session.tx_isolation SELECT USER() SELECT COUNT(*) FROM users WHERE user_id='FOO0' SELECT COUNT(*) FROM users WHERE user_id='FOO1' SELECT COUNT(*) FROM users WHERE user_id='FOO2' ... I see the query sent in the full each time in the protocol logs too (using tcpdump). Using Connector/J 5.1.12 and MySQL 5.1.44. No funny JDBC options in the JDBC URL. Going straight to the driver for this test no pool. Why aren't the statements being prepared? The Connector/J driver handles prepared statements locally unless you turn on real server side statements using the connection parameter useServerPrepStmts=true. http://dev.mysql.com/doc/refman/5.0/en/connector-j-reference-configuration-properties.html I'm not sure if this has been fixed since then (reading changelogs isn't my idea of a good time) but there were a bunch of problems with server-side prepared statements and so they were disabled by default in Connector/J (http://dev.mysql.com/doc/relnotes/connector-j/en/news-5-0-5.html)."
510,A,"Streaming ResultSet Error I am trying to run multiple MySQL queries which build up on each other: i.e field value of one element in each row is used as input for another query. I end up getting the following error: java.sql.SQLException: Streaming result set com.mysql.jdbc.RowDataDynamic@174cc1f is still active. No statements may be issued when any streaming result sets are open and in use on a given connection. Ensure that you have called .close() on any active streaming result sets before attempting more queries. at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:914) at com.mysql.jdbc.MysqlIO.checkForOutstandingStreamingData(MysqlIO.java:2074) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1484) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:1665) at com.mysql.jdbc.Connection.execSQL(Connection.java:3170) at com.mysql.jdbc.Connection.execSQL(Connection.java:3099) at com.mysql.jdbc.Statement.executeQuery(Statement.java:1169) at Stats.readInterfaces(Stats.java:105) at Stats.connect(Stats.java:63) at automateExport.main(automateExport.java:15) I have called .close() after every ResultSet and Statement of the query. I guess we cannot have multiple resultsets open at one time. Is there any way to get around this problem? Here is the relevant code: public class Stats { public static int UTC = 0; public String interfaceId = ""no value""; public String rId = ""no value""; public String NL = System.getProperty(""line.separator""); public String CSV = """"; public static String startTimeendTimeperformanceTable =null; public static int outputType = 1; public String pTable = ""('2010-7-13 00:00')""; public String start = ""('2010-7-13 09:00')""; public String end = ""('2010-7-13 17:00')""; Connection conn; Statement stmtRouter stmtInterface stmtTime stmtD; String query; ResultSet rsRouter rsInterface rsD rsTime; public Connection connect(String db_connect_strString db_userid String db_password) { String routerNamerouterId = null routerNetwork = null; // inputfile - csv try { // to bifurcate heap memory error Class.forName(""com.mysql.jdbc.Driver"").newInstance(); conn = DriverManager.getConnection(db_connect_strdb_userid db_password); stmtRouter = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY); stmtRouter.setFetchSize(Integer.MIN_VALUE); query = ""Select r.namer.ridr.network FROM router AS r Where r.network = 'ITPN'""; String append = null; // writing to file performanceTable = readTime(pTable); startTime = readTime(start); endTime = readTime(end); rsRouter = stmtRouter.executeQuery(query); while (rsRouter.next()) { routerName = rsRouter.getString(1); System.out.println(routerName); // routerId = rsRouter.getString(""rid""); // routerNetwork = rsRouter.getString(""network""); append = routerName+CSV+routerId+CSV+routerNetwork; readInterfaces(routerIdstartTimeendTimeperformanceTable append); } stmtRouter.close() ; rsRouter.close(); // output(2input); // output(outputType  input); } catch(Exception e) { e.printStackTrace(); conn = null; } return conn; } private String readTime(String time) throws SQLException { stmtTime = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY); stmtTime.setFetchSize(Integer.MIN_VALUE); query = ""Select unix_timestamp""+time; rsTime = stmtTime.executeQuery(query); String unixTime = null; while(rsTime.next()){ unixTime = rsTime.getString(1); System.out.println(unixTime); } rsTime.close(); stmtTime.close(); return unixTime; } private void readInterfaces(String routerId String startTime String endTime String performanceTable String append) throws SQLException IOException { String interfaceId iDescp iStatus = null; String dtime ingress egress = null; stmtInterface = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY); stmtInterface.setFetchSize(Integer.MIN_VALUE); stmtD = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY); stmtD.setFetchSize(Integer.MIN_VALUE); query = "" Select i.idi.description i.status from interface as i Where i.rid = "" + routerId +"" And i.status = 'active'""; rsInterface = stmtInterface.executeQuery(query); String input = ""inputData.txt""; BufferedWriter fw = new BufferedWriter(new FileWriter(input)); stmtInterface.close(); while(rsInterface.next()){ interfaceId = rsInterface.getString(""id""); iDescp = rsInterface.getString(""description""); iStatus = rsInterface.getString(""status""); if(!iStatus.equals(""active"")){ /* performance table query*/ query = "" Select d.dtimed.ifInOctets d.ifOutOctets from ""+performanceTable+""_1_60"" +"" AS d Where d.id = "" + interfaceId + ""AND dtime BETWEEN "" +startTime+ "" AND ""+ endTime + "" Order By d.id""; rsD = stmtD.executeQuery(query); while(rsD.next()){ dtime = rsD.getString(""dtime""); ingress = rsD.getString(""ifInOctets""); egress = rsD.getString(""ifOutOctets""); fw.write(append + CSV + interfaceId+CSV+iDescp+CSV+dtime+CSV+ingress+CSV+egress+NL); }// end of while rsD.close(); stmtD.close(); } } fw.close(); // rsInterface.close() ; // stmtInterface.close(); } } It'd help to see the java code SQL statement & parameters... added full code You cannot have more than one result set being open per connection. I believe here is the reason for the failure: You call readInterfaces(routerIdstartTimeendTimeperformanceTable append) (where you open new resultset) before you close Router resultset:  readInterfaces(routerIdstartTimeendTimeperformanceTable append); } stmtRouter.close() ; rsRouter.close(); I would move close statements before the call to readInterfaces(...). I would also close the result set and statement in opposite order (resultset first). but i need the router resultset open for processing all the data. how can i close it before itself? it will not work then I can propose 2 solutions: 1. Open separate connection inside readInterfaces to conform to the 1resultset-per-connection restriction. 2. Grab the data from rsRouter to a collection close the resultset and then call readInterfaces with the results from the collection. hi  thanks. is there any way to optimize the query execution. even after breaking it into 3 queries I end up getting a very bad working time of 20 mins:P ( the file i generate is like a 200 + MB text file. Still 20 mins is like way too much!  You definitely shouldn't close Statement object before you end working with ResultSet (function readInterfaces). rsInterface = stmtInterface.executeQuery(query); String input = ""inputData.txt""; BufferedWriter fw = new BufferedWriter(new FileWriter(input)); stmtInterface.close(); // Don't do this!!! It should be when you are done with rsInterface) while(rsInterface.next()){ tried this. same error :(  Connection object should not hold multiple ResultSet object at a time. After creation of ResultSet and Statement objects each has to closed explicitly like resultSet.close() statement.close() What does your answer three years later add to the existing - more thorough - answers?  Exactly as the error says you cannot issue additional queries over the same connection when you have a streaming result set open. Relevant documentation is here. So the obvious solution would be not to use a streaming result set for the driving query. The downside of this is that it will use more memory. The rather obscure comment at the top of your code implies that maybe someone tried this already and had memory issues. Anyway there is a better solution. This is a classic example of over-proceduralization. You are doing work in your code that could be better handled by the database engine. Instead of executing single-table queries that drive each other you can combine those into one query using a join: Select r.namer.ridr.networki.idi.description i.status FROM router AS r JOIN interface as i ON i.rid = r.rid Where r.network = 'ITPN' AND i.status='active' Then you have a third ""nested"" query which you can incorporate with an additional join. I think it would be: Select r.namer.ridr.networki.idi.description i.statusd.dtimed.ifInOctets d.ifOutOctets FROM router AS r JOIN interface as i ON i.rid = r.rid JOIN <performanceTable>_1_60 as d ON d.id = i.id Where r.network = 'ITPN' AND i.status='active' AND dtime BETWEEN <startTime> AND <endTime> Order By d.id You probably don't need all those columns in the final select list but I haven't pored through your code to see what is really being used. hi.. this is what i had done first. but resultset is super huge. so broke down the query to multiple queries. :)but that seems to have issues which i mentioned above :P If you use a streaming result set what problem is actually caused by a ""super huge"" result set? It seems to me you are processing the same amount of data either way and if you can stream it memory shouldn't be an issue."
511,A,"SQL connection lifetime I am working on an API to query a database server (Oracle in my case) to retrieve massive amount of data. (This is actually a layer on top of JDBC.) The API I created tries to limit as much as possible the loading of every queried information into memory. I mean that I prefer to iterate over the result set and process the returned row one by one instead of loading every rows in memory and process them later. But I am wondering if this is the best practice since it has some issues: The result set is kept during the whole processing if the processing is as long as retrieving the data it means that my result set will be open twice as long Doing another query inside my processing loop means opening another result set while I am already using one it may not be a good idea to start opening too much result sets simultaneously. On the other side it has some advantages: I never have more than one row of data in memory for a result set since my queries tend to return around 100k rows it may be worth it. Since my framework is heavily based on functionnal programming concepts I never rely on multiple rows being in memory at the same time. Starting the processing on the first rows returned while the database engine is still returning other rows is a great performance boost. In response to Gandalf I add some more information: I will always have to process the entire result set I am not doing any aggregation of rows I am integrating with a master data management application and retrieving data in order to either validate them or export them using many different formats (to the ERP to the web platform etc.) Tried to clarify sorry for the confusion What do you mean by ""SQL server (Oracle)""? To weigh the benefits we really need to know more about how you are using the results from the query. Will you always process the entire result set? Are you adding values from each result together or any other aggregation work that could be done on the databases end? There is no universal answer. I personally implemented both solutions dozens of times. This depends of what matters more for you: memory or network traffic. If you have a fast network connection (LAN) and a poor client machine then fetch data row by row from the server. If you work over the Internet then batch fetching will help you. You can set prefetch count or your database layer properties and find a golden mean. Rule of thumb is: fetch everything that you can keep without noticing it if you need more detailed analysis there are six factors involved: Row generation responce time / rate(how soon Oracle generates first row / last row) Row delivery response time / rate (how soon can you get first row / last row) Row processing response time / rate (how soon can you show first row / last row) One of them will be the bottleneck. As a rule rate and responce time are antagonists. With prefetching you can control the row delivery response time and row delivery rate: higher prefetch count will increase rate but decrease response time lower prefetch count will do the opposite. Choose which one is more important to you. You can also do the following: create separate threads for fetching and processing. Select just ehough rows to keep user amused in low prefetch mode (with high response time) then switch into high prefetch mode. It will fetch the rows in the background and you can process them in the background too while the user browses over the first rows. Based on your rule of thumb I understand that if I had unlimited amount of memory I should fetch every records at once. But my problem with this option is that fetching 100k records takes time and will delay the start of processing of these records. Fetching them one by one allow me to start the processing as records get fetched and limit CPU usage since my processing actually takes place between each record fetching. Thank you for suggesting the analysis. I will analyze those values and try to make the best decision. Thanks for the suggestions too but my application is not user-oriented bue data-oriented I need to export as much data as fast as possible."
512,A,How should I use UUID with JavaDB/Derby and JDBC? I currently use INT as type for primary key in JavaDB (Apache Derby) but since I'm implementing an distributed system I would like to change the type to java.util.UUID. A few questions about this: What datatype in JavaDB/Derby should I use for UUID? I have seen CHAR(16) FOR BIT DATA been mentioned but I don't know much about it. Is VARCHAR(16) an alternative? How should I use it with JDBC? E.g. in an PreparedStatement how should I set and get an UUID? If I later would likte to change database to SQL Server is there a compatible datatype to java.util.UUID? Simply How should I use UUID with JavaDB/Derby and JDBC? You could convert the UUID to a string and store it as VARCHAR. Most UUID string formats are similar to this one: 32 digits separated by hyphens: 00000000-0000-0000-0000-000000000000 so then you'd want a VARCHAR(36) or make it something like VARCHAR(64) if you please since it doesn't hurt to have extra 'space' available in your VARCHAR -- only the actual digits are stored. Once you've converted it to a string just call Statement.SetString to include it in your INSERT statement.  UUID is a 128 bit value. The CHAR(16) FOR BIT DATA type reflects that it is bit data stored in character form for conciseness. I don't think VARCHAR(16) would work because it doesn't have the bit flag. The database would have to be able to convert the binary data to character data which deals with encoding and is risky. More importantly it wouldn't buy you anything. Since a UUID is always 128 bits you don't get the space savings from using VARCHAR over CHAR. So you might as well use the intended CHAR(16) FOR BIT DATA. With JDBC I think you use the get/setBytes() method since it is dealing with small amounts of binary data. (Not positive would have to try this) And no idea about the SQL Server part.  If you still want to use the UUID object in your code you can use fromString to create UUID objects from the DB and toString to store them in the DB.
513,A,"Speed up multiple JDBC SQL querys? I'm working on a shortest path a* algorithm in java with a mysql db. I'm executing the following SQL Query approx 300 times in the program to find route connections from a database of 10000 bus connections. It takes approx 6-7 seconds to execute the query 300 times. Any suggestions on how I can speed this up or any ideas on a different method i can use ? Thanks private HashMap<CoordinateNode> closedNodes; private PriorityQueue<Node> openNodes; .. private List<Coordinate> calculatePath() { //While there are nodes in the open list while (!openNodes.isEmpty()) { //Get the node with the lowest gVal+hVal Node node = openNodes.poll(); //Add it to the closed list closedNodes.put(node); //If it is not the goal node if (!node.equals(goal)) { //Get all the neighbours and Create neighbour node List<Node> neighbours = helper.getNeighbours(node goal); //For each neighbour for (Node neighbourNode : neighbours) { //Check if the neighbour is in the list of open nodes boolean isInOpen = checkOpenNodes(neighbourNode); //If it is not in the open nodes and not in the closed nodes if ((!closedNodes.containsKey(neighbourNode))&& (!isInOpen)) { //Add it to the list of open nodes openNodes.add(neighbourNode); } } } else { // We found the path path = backTrackPath(node); break; } } return path; /** * Gets the list of valid Nodes that are possible to travel to from <b>Node</b> * @param stopNode Node to find neighbours for * @param goal End Node * @return list of neighbour Nodes */ public ArrayList<Node> getNeighbours(Node stopNode Node goal) { ArrayList<Node> neighbours = new ArrayList<Node>(); Node neighbourNode; //get neighbours connected to stop try { ResultSet rs = stmt.executeQuery(""select To_Station_id To_Station_routeID To_Station_stopID"" + ""To_Station_lat To_Station_lng Time from connections where Connections.From_Station_stopID ="" +stopNode.getCoord().getStopID()+"" ORDER BY Connections.Time""); rs = stmt.getResultSet(); while (rs.next()) { int id = rs.getInt(""To_Station_id""); String routeID = rs.getString(""To_Station_routeID""); String stopID = rs.getString(""To_Station_stopID""); String stopName = rs.getString(""To_Station_stopName""); Double lat = rs.getDouble(""To_Station_lat""); Double lng = rs.getDouble(""To_Station_lng""); int time = rs.getInt(""Time""); neighbourNode = new Node(id routeID stopID stopName lat lng); neighbourNode.prev = stopNode; neighbourNode.gVal = stopNode.gVal + time; neighbourNode.hVal = heuristic.calculateHeuristic(neighbourNode goal); neighbours.add(neighbourNode); } } catch (SQLException e) { e.printStackTrace(); } return neighbours; } Thanks for all your answers. Yes i have a graph with Stations as nodes. I've updated the question with full code of the methods i'm using. The getNeighbours() method is passed the Node with the lowest value of ((cost to reach node)+(distance to goal node)) by a means of a PriorityQueue. This is why i have to query the database for each time their is a new node on top of the priority queue. I cannot predict which node will be next to be first on the priority Queue untill I access it the nodes neighbours. I can't cache the Stop connection data as it contains 10000+ connections.Any suggestions? Don't use DB. Load all data to the 'graph' object in the main memory. In my project I have millions of nodes (and even more edges) in the graph and some sort of Dijkstra algorithm that runs on all this and I get running times much less then a second. This JDBC code is leaking resources. Fix it ASAP. For a start you should be using a PreparedStatement rather than a normal query and just do stmt.setInt(1 StopId) each time through. Also better to select the specific fields you are interested in rather than select *. Those are just general JDBC tips which will probably not have a huge impact on the runtime but are worth doing. After that I would try to investigate the table indexes to make sure that the query based on From_Station_stopID is indeed executing as fast as it can. If it is and the only overhead is the amount of separate calls to the database the next step might be to try to combine the queries perhaps by making it a select ... from connections where From_Station_stopID in (... ... ...). Depending on the size of the table you may simply want to load the whole thing in advance into memory (perhaps as a HashMap) and then you wouldn't need to go to the database on every iteration. In short it depends a lot on the different parameters of the problem and you will need to check to see which solution works best for you.  As I understand you have a graph with Stations as nodes and Connections as edges. Try to create some object which will represent that graph (it can be a matrix in the simplest case) and perform your search on that object. Then you will not need to do 300 calls to your database which are very costly from the performance point of view.  Make sure you have an index on connections.From_Station_stopID Instead of SELECT * only select the columns you need If only the constant in the WHERE clause for From_Station_stopID changes each time use a parameterized prepared query so that the database doesn't have to parse the query and build the execution path each time or combine the queries into one using WHERE From_Station_stopID IN (value1 value2 ...) If you're repeating the same queries often ensure that MySQL is using query caching If you showed us the rest of the code where it's looping to call the query 300 times we might be able to help further. In general I'd say that if you're computing the shortest path each time instead you should build a table that works like a grid with route distances precalculated for each stop or even entire routes precalculated from each stop.  You can use the IN clause in order to run the query only once - select * from connections where Connections.From_Station_stopID IN (value1 value2 ...).  In general if your query is slow and expensive try caching the results somewhere so on the next lookup it will be retrieved quickly from cache. So you would (expensively) compute connection between point A and B store the entire result set in other (temporary=cache) table in the database with a defined lifetime so for the next X hours/days (or until the routes change) you can retrieve route from A to B from this cache table. thanks i have cached the all the connection data in a hashTable this prevents me from continually connecting to the db"
514,A,"Can I have a mutex table in my database (Oracle) with just plain SQL? I would like to have a table in my Oracle database whose rows act as locks. The table would have one column a varchar and my clients (Java processes over JDBC) would run statements to acquire and release locks. The acquire statement should check existence of a row with a given value and insert if not there. The statement should somehow signal to the caller whether the row was free or not. The release statement should release the lock by deleting the row. The release statement is straightforward but what should my acquire statement look like? Why would you want to do this? It sounds like reinventing the wheel where you could also apply regular pessimistic or optimistic locking. I recommend you use DBMS_LOCK for this purpose. Under the hood it pretty much does what you're suggesting. DBMS_LOCK package Voted up. DBMS_LOCK is a much safer option. Doing it manually using a single row is easy until it gets hard - what happens if the client loses connection before deleting the row?? Is there any potential path where an uncaught exception could bypass the release? What happens if both processes do the test to check for a lock find no lock exists and then go on to create a lock (I've seen this happen in real life - a 1 in a million situation will occur every few days if there are tens of thousands of transactions a day). ""What happens if both processes do the test to check for a lock find no lock exists and then go on to create a lock"". You don't write it that way. Instead you try to create the lock and catch the exception if you can't.  You could define a primary key unique index on lockname. A client would try to: INSERT Locks (lockname) VALUES 'MyLock' If this generates a primary key violation the client did not succeed in acquiring the lock. A weakness here is what happens if the whatever cleans up (release statement) never runs because of some fault? Then you manually have to remove the lock entry. So you need to have some kind of cleanup or timeout solution for that."
515,A,"Clojure MySQL Syntax Error Exception (""[...] near '????????????????' [...]"") I'm having trouble doing anything with clojure.contrib.sql beyond establishing a connection. I have a mysqld running on localhost:3306 with a database called clj_db. The user 'clj_user'@'localhost' with password 'clj_pass' can access this database. When trying to ""select * from clj_table"" I get a ""com.mysql.jdbc.exceptions.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '????????????????' at line 1"". What am I doing wrong? clj_db.clj_table CREATE TABLE `clj_table` ( `col_one` int(11) NOT NULL `col_two` int(11) NOT NULL ) ENGINE=MyISAM DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci; mysql_test.clj (ns test.mysql (:use clojure.contrib.sql) ) (def db-settings {:classname ""com.mysql.jdbc.Driver"" :subprotocol ""mysql"" :subname ""//localhost:3306/clj_db"" :user ""clj_user"" :password ""clj_pass""}) (with-connection db-settings (with-query-results rs [""select * from clj_table""] (dorun (map #(println (:col_one :col_two %)) rs)) )) Output Exception in thread ""main"" com.mysql.jdbc.exceptions.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '????????????????' at line 1 (mysql_test.clj:0) at clojure.lang.Compiler.eval(Compiler.java:4658) at clojure.lang.Compiler.load(Compiler.java:4972) at clojure.lang.Compiler.loadFile(Compiler.java:4939) at clojure.main$load_script__7405.invoke(main.clj:213) at clojure.main$script_opt__7442.invoke(main.clj:265) at clojure.main$main__7466.doInvoke(main.clj:346) at clojure.lang.RestFn.invoke(RestFn.java:441) at clojure.lang.Var.invoke(Var.java:367) at clojure.lang.AFn.applyToHelper(AFn.java:179) at clojure.lang.Var.applyTo(Var.java:476) at clojure.main.main(main.java:37) Caused by: com.mysql.jdbc.exceptions.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '????????????????' at line 1 at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1048) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3563) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3495) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1959) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2113) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2687) at com.mysql.jdbc.ConnectionImpl.configureClientCharacterSet(ConnectionImpl.java:1859) at com.mysql.jdbc.ConnectionImpl.initializePropsFromServer(ConnectionImpl.java:3593) at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2199) at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:784) at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:350) at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:284) at java.sql.DriverManager.getConnection(libgcj.so.10) at clojure.contrib.sql.internal$get_connection__218.invoke(internal.clj:85) at clojure.contrib.sql.internal$with_connection_STAR___226.invoke(internal.clj:102) at test.mysql$eval__386.invoke(mysql_test.clj:12) at clojure.lang.Compiler.eval(Compiler.java:4642) ...10 more Additional Information: clojure-1.1.0 --- clojure-contrib-1.1.0 --- mysql-connector-java-5.1.11-bin --- java 1.5.0 --- mysql Ver 14.14 Distrib 5.1.41 for debian-linux-gnu (x86_64) using readline 6.1 Using gij-4.4 btw I was having the exact same problem only I was using Java. I found this post and the solution described there worked for me. The trick was to add ""useJvmCharsetConverters=true"" to the end of the connection-string.  I've switched to Sun's JDK6 instead of GIJ. I got ""com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure"". I found this thread which really helped me a lot. I've added the option ""-Djava.net.preferIPv4Stack=true"" and it now works fine. Thanks everybody!  the code looks very similar to the (presumably working) code in This Question perhaps its a problem with the version of clojure-contrib. when I macroexpand the code from these two question they come out the same so it seems likely that the problem is not with the contents of mysql_test.clj. Yup I had a look at that too. Just to be sure I've downloaded clojure and clojure-contrib releases again but I get the same output."
516,A,"Check to see if ResultSet is Null if not then get int I want to be able to get check to see if there is a result in my resultset. Todo this i would execute: if(rs.next()){ boolean = true; } However i want to check to see if the value is in the database if so retrieve it: while(rs.next()) id = rs.getInt(""id); How would i go about combining the two? I want -2 to be returned if the resultset is empty. Thanks in Advance Dean Just use an if-else: if (resultSet.next()) { return resultSet.getInt(""id""); } else { return -2; } Also see this answer for more hints how to handle existence zero/one zero/more results. Except you really should close the result set which pretty much requires you to save the result in either case then close the result set then return. @Jay: I don't know how you close your resources but I usually close them in `finally` and it will just work fine. Okay I'll buy that. Personally I usually close my connections in a finally block but close ResultSets and Statements in main-line code because I'm too lazy to declare them outside the try block and then populate them inside.  id = rs.next() ? rs.getInt(""id"") : -2; like that? Can you please explain this as i have never seen something written like this? @Dean: it's a ternary expression with the ternary operator `?:`. It does basically the same as `int id; if (rs.next()) id = rs.getInt(""id""); else id = -2;`. Also see http://java.sun.com/docs/books/tutorial/java/nutsandbolts/op2.html"
517,A,"Reusing a resultMap for different column names Is there a way of reusing the same resultMap multiple times in a single query. For example suppose I have a ""foo"" resultMap: <resultMap id=""foo"" class=""Foo""> <result property=""Bar"" column=""bar"" /> </resultMap> Is there a way to define another resultMap that reuses the above for different columns? Something like... <resultMap id=""fizz""class=""Fizz""> <result property=""Foo1"" column=""bar=bar1"" resultMapping=""foo"" /> <result property=""Foo2"" column=""bar=bar2"" resultMapping=""foo"" /> <result property=""Foo3"" column=""bar=bar3"" resultMapping=""foo"" /> </resultMap> you could use resultmaps which extend another resultmap e.g. <resultMap id=""document"" class=""Document""> <result property=""Id"" column=""Document_ID""/> <result property=""Title"" column=""Document_Title""/> <discriminator column=""Document_Type"" type=""string""/> <subMap value=""Book"" resultMapping=""book""/> <subMap value=""Newspaper"" resultMapping=""newspaper""/> </resultMap> <resultMap id=""book"" class=""Book"" extends=""document""> <property=""PageNumber"" column=""Document_PageNumber""/> </resultMap> more info: http://ibatis.apache.org/docs/dotnet/datamapper/ch03s05.html  Almost. If you select the ID of the Foo in your query you can have the Fizz result map execute a SELECT for that ID which will use the Foo result map. <result property=""Foo1"" column=""bar1Id"" select=""selectFoo""/> (Assuming you have a selectFoo query defined.) But that's extremely slow with large result sets since it does an additional SELECT for every row. iBATIS has a solution to this problem for the typical case where you have a composite object that contains various other objects. First you define a query that joins your tables then you can use fooMap to populate a Foo: <result property=""Foo1"" resultMap=""fooMap""/> But you can't use that result map twice for two different Foos because the result map specifies certain column names. You can use another technique though: <result property=""foo1.bar"" column=""foo1bar""/> <result property=""foo2.bar"" column=""foo2bar""/> More detail in page 35 of the iBatis Datamapper manual. That's unfortunate. In my case the resultMap I'd like to reuse is rather simple and I've only hit this in one query so I'll keep it simple and just *gasp* copy-paste for now."
518,A,"Is this error related to the OS or the database? I have a java programs that gives me an error after working fine for a few hours ... these programs used to work fine on our earlier server which had windows server 2003 now we have upgraded to windows server 2008 with a higher configuration and newly installed SQL Server .Is there any db setting that i'm missing or is there any OS setting that i've missed out ?? the EXCEPTION i receive is : Error:: org.apache.commons.dbcp.SQLNestedException:Cannot create PoolableConnectionFactory cause: Network error IOException: No buffer space available (maximum connections reached?): connect I have experienced a similar issue on Windows and had to make a registry change. It was related to the fact that sockets were being opened and closed at a high rate faster than they were cleanup by the OS. I can't remember the specific registry setting but it increase the number or socket connections available to user applications. If I remember correctly the OS defaults to 5000 connections. didn't get the exact solution yet but i too think that it is related to sockets ...the registry solution is too risky so cloud not try it yet..and didn't get the exact way of doing it too.  Use a different DB connection pooling package like c3p0. also check its compatibility with you JDBC driver.  I have a java programs that gives me an error after working fine for a few hours ... IOException: No buffer space available (maximum connections reached?) The JDBC code is likely not properly closing connections in the finally block of the try where the connection is been acquired. This way the connections will be kept open until the DB forcibly times-out and closes them. The timeout depends on the DB config used. Apparently the timeout was been relatively short in the previous machine and relatively long in the new machine. When the DB runs out of available connections because your application never closes them then you will get an exception like that. The following code examples illustrates the normal (basic) JDBC idiom for resource handling (note the code flow and the code comments): public List<Entity> list() throws SQLException { // Declare resources. Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; List<Entity> entities = new ArrayList<Entity>(); try { // Acquire resources. connection = database.getConnection(); statement = connection.prepareStatement(""SELECT id name value FROM entity""); resultSet = statement.executeQuery(); // Gather data. while (resultSet.next()) { Entity entity = new Entity(); entity.setId(resultSet.getLong(""id"")); entity.setName(resultSet.getString(""name"")); entity.setValue(resultSet.getInteger(""value"")); entities.add(entity); } } finally { // Close resources in reversed order. if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } // Return data. return entities; }"
519,A,"How to connect MySQL to Java program I ve installed MySQL (last update). I need to code that ll create & establish a connection with SQL DB & manage the DB(using SELECT INSERT CREATE). I did everything but I am not able to create connection. I've also installed the MySQL/J connector I just extracted the .zip pack in a folder & added the folder path in Variables). Can anyone tell me wat is meant by URL in the below line? Connection connection = DriverManager.getConnection(url username password); I ve tried this: String url = ""jdbc:odbc:sqlserver://localhost:3306/myfirstdb""; Connection con = DriverManager.getConnection(url ""root"" ""1234""); But it's not working. I am unable able to understand the term 'URL'. Can anyone explain the meaning of 'url' and wat should be done to connect to a SQL server from Java. Update: This is the Full code. It still cannot connect. import java.sql.*; public class TestDriver { public static void main(String[] args) { try { Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver"");//This s wat actually i did for connection System.out.println(""Driver Loaded Succesfully""); } catch (Exception e){ System.out.println(""Unable to Load Driver!!!""); } try { Class.forName(com.mysql.jdbc.Driver""); // initialise the driver String url =""jdbc:mysql://localhost:3306/myfirstdb""; Connection con = DriverManager.getConnection(url ""root"" ""1234""); System.out.println(""connection Established""); } catch(Exception e) { System.out.println(""Couldnt get connection""); } } } Can you tell me wat is the purpose of MySQL Connector/J? What error are you getting? MSSQL or MySql? @Zaki @Tamil Vendhan [has stated below](http://stackoverflow.com/questions/3377151/how-to-connect-a-sql-server-to-java-program/3377265#3377265) that MySql is being used. I have added the mysql tag to the question. possible duplicate of [Java connectivity with MySQL](http://stackoverflow.com/questions/2839321/java-connectivity-with-mysql) If its MS SQL Server String driver = ""com.microsoft.jdbc.sqlserver.SQLServerDriver""; Class.forName(driver); String url = ""jdbc:microsoft:sqlserver://host:1433/database""; Connection conn = DriverManager.getConnection(url ""username"" ""password""); For more info see this to get started with Microsoft JDBC. You can use any of the two JDBC drivers for MSSQL: Microsoft SQL Server JDBC Driver 2.0 jTDS For MS SQL Server driver 2.0 use URL: jdbc:sqlserver://server:port; DatabaseName=dbname Class name: com.microsoft.sqlserver.jdbc.SQLServerDriver For MySql & Java see this on SO.  In the question you seem to be using a MySQL jdbc driver with a SQL Server jdbc URL. This won't work. If you are using a MySQL database: Class.forName(""com.mysql.jdbc.Driver""); // initialise the driver String url =""jdbc:mysql://localhost:3306/myfirstdb""; If you are using a SQL Server database you are going to need a completely different jdbc driver. jTDS is open source and a good option. Include the jtds.jar file in your classpath and use something like: Class.forName(""net.sourceforge.jtds.jdbc.Driver""); // initialise the driver String url = ""jdbc:jtds:sqlserver://localhost:1433/myfirstdb"";  Here's an extract from your code: } catch (Exception e) { System.out.println(""Couldnt get connection""); } You should never suppress exceptions as long as you don't understand its cause. Replace it by at least: } catch (Exception e) { System.out.println(""Could not get connection""); e.printStackTrace(); } Or maybe } catch (Exception e) { throw new RuntimeException(""Could not get connection"" e); } Either way you should see the exception type message and trace. In your code snippet the possible exceptions are ClassNotFoundException and SQLException. The first one would mean that the driver is not properly placed in the classpath. The second one would mean that connection cannot be obtained. The exception message and/or trace should tell in detail about the underlying root cause of the problem. You should always observe exceptions. They tell something about the cause of the problem. You know once a cause is understood the solution is nothing more than obvious :) See also: Short MySQL/JDBC tutorial - Contains explanation about exception causes. Further Can anyone tell me wat is meant by URL in the below line? An URL is an Uniform Resource Locator. It's a common way to locate (identify) unique resources in computer systems and networks. The URL syntax for the MySQL database is explained in the documentation of the JDBC driver. Can you tell me wat is the purpose of MySQL Connector/J? It's the JDBC driver. The JDBC API exist of almost only interfaces. The DB vendors should provide their own concrete JDBC API implementation which is the JDBC driver. With a JDBC driver you'll be able to connect a specific database using JDBC API."
520,A,What is the Python equivalent to JDBC DatabaseMetaData? What is the Python equivalent to DatabaseMetaData There isn't an exact equivalent. What information are you trying to pull and what type of database is it? I need to be able to get tables columns (size scale type name) foreign keys primary keys from Oracle and also MySQL. If your willing to use ODBC for data access then you could use pyodbc http://code.google.com/p/pyodbc/wiki/Features. Pyodbc allows you to call functions like SQLTables which is equivalent to the JDBC getTables function. The JDBC and ODBC functions to get to metadata are extremely similar.  This is not a python-specific answer; in fact I don't know if Python data drivers have this sort of thing. But maybe this info will help. The ANSI SQL-92 and SQL-99 Standard requires the INFORMATION_SCHEMA schema which stores information regarding the tables in a catalog. The metadata you seek can be retrieved with a query on views in that schema. for example: select column_name is_nullable data_type character_maximum_length as maxlen from information_schema.columns where table_name = 'Products' Not all databases implement that part of the standard. Oracle for example does not. Fortunately there are also database-specific tables that store that kind of info. While Microsoft SQL Server supports the Information_Schema thing there are also SQL Server-specific tables that give more metadata information. These are [CatalogName].dbo.sysobjects and [CatalogName].dbo.sysolumns. Similar queries on these tables will give you the metadata you seek. Example: select * from [CatalogName].dbo.syscolumns where id = (Select id from [CatalogName].dbo.sysobjects where name = 'Products') In Oracle the ALL_TAB_COLUMNS table can give you the information: select column_name data_type data_length data_precision data_scale from ALL_TAB_COLUMNS where table_name = 'EMP'; Whether you query the standard views or the db-specific views you don't need ODBC to do these queries - you can use whatever db connection you have available for operational data subject to security approvals of course. Oracle of course does not seem to have this... It appears I will need to go the ODBC route to get a standard set of functionality between dbs. Hmm that's a surprise! With Oracle there is an alternative data table you can query. I'll update the answer to indicate that.
521,A,"How can I execute a stored procedure with JDBC / jTDS without using a transaction? We run a website written in Java that uses JDBC with jTDS to access an SQL Server database. Our database contains a complex stored procedure that typically takes 10 minutes to run. The stored procedure works fine if we execute it directly (say from SQL Server Management Studio) because it does not run in a transaction. But if we execute it using jTDS then it locks up the entire website for 10 minutes. This happens because jTDS runs it in a transaction and so all the website requests are on hold waiting for the transaction to finish. For example the following locks up the website due to the transaction: Connection connection = DriverManager.getConnection(""jdbc:jtds:sqlserver://example/example""); CallableStatement callableStatement = connection.prepareCall(""exec dbo.procTest""); callableStatement.execute(); Is there any way that we can run a stored procedure using JDBC / jTDS without it running in a transaction? Please note that calling this on the jTDS connection is not valid: connection.setTransactionIsolation(Connection.TRANSACTION_NONE); That throws an exception stating that the Connection.TRANSACTION_NONE parameter is not supported by jTDS. EDIT: I probably could have asked the question better: the core problem is not the transaction itself the problem is that the transaction causes database locks to be held for 10 minutes. Either I need to get rid of the transaction or I need locks released during the transaction. ""does not run in a transaction""? Are you sure? AFAIK every SQL statement runs in a transaction. The closest you can get to ""no transaction"" is probably auto-commit where every statement is executed in its own session. I can explain what I mean in practical terms: if I run ""EXEC dbo.procTest;"" using SQL Server Management Studio then the website doesn't lock up. But if I run ""BEGIN TRANSACTION; EXEC dbo.procTest; COMMIT;"" then the website locks up for the duration of the transaction — monitoring the database locks shows that website connections are all waiting on the thread executing that stored procedure. Maybe the transaction is not the key point here. Another way I could put it is ""I don't want the database to hold locks on updated objects for the duration of a transaction"". Have you tried `Connection.TRANSACTION_READ_UNCOMMITTED`? I ended up using the following ugly workaround. I'm still interested if anyone can explain how I might do this properly; but the workaround will do for the moment. The database is running on the same machine on the webserver so I am able to use the standard SQL Server command line tools to run the stored procedure. The Java code to trigger it is:  try { Process process = Runtime.getRuntime().exec(""sqlcmd -E -d \""example\"" -Q \""EXEC dbo.procTest;\""""); process.waitFor(); } catch (IOException e) { // Handler here } catch (InterruptedException e) { // Handler here } So exactly the same stored procedure is run — the difference is that the webserver doesn't lock up because sqlcmd isn't running it in a single transaction. Yes it's ugly... but it's the only option I know of that works!  Calling Connection#close() or Connection#commit() should submit and end the transaction. Do you close DB resources like Connection in the finally block? Yes Connection#close() and Connection#commit() do submit and end the transaction... which is not what I'm having a problem with. The problem is that before those lines are reached we have a 10-minute long transaction which locks up everything. So it's not a question of whether the transaction is being committed correctly it's a question of whether I can avoid running it in a transaction in the first place."
522,A,"Applying Oracle PL/SQL via JDBC Is it possible to create/replace PL/SQL via the Oracle JDBC driver i.e not via SQLPLus* ? Update 1: Driver: ojdbc14 (JDBC) Update 2: Change is being applied to oracle via Ant <SQL> task which is passed a sql script file. In this instance using SQLPlus in the Ant script is not possible (long story). What driver are you talking about? JDBC? ODBC? ODP.Net? It is almost certainly possible. But we'll need more information in order to provide any specifics. Currently using ojdbc14 but flexible here. Yes the standard Ant sql task will do this. These options are working for me: sql driver=""oracle.jdbc.driver.OracleDriver"" delimiter=""/"" delimitertype=""row"" keepformat=""yes"" caching=""true"" escapeprocessing=""no"" One thing I've found is that the processing is sensitive to the last line with the delimiter - if you have any whitespace after the ""/"" the execution will fail. +1 Thanks worked nicely."
523,A,"how to dynamically specify data type while creating the table in MS access using Java My application is extracting the data from excel sheet. I am storing the value and type of the data from the sheet into the ArrayList. ie. If my excel sheet consists of employee data i will retrive [ Employee name String] [ Employee id number] and so on.. So i have to create a table with these names and with their respective data types. So how could i dynamically specify the data types for the attributes in the table. I am using JDBCMS Access.. Could you explain what you do with jdbc in this context? I am retriving the data from the Excel sheet using java-JExcel API and i am creating the table with the column names which i had retrived it from the first cell columns from the excel sheet. ie. Employee nameEmployee id salary etc. Then i have to specify its type which i had acquired from the JExcel API. For each different data type use a different class. You can either use the default java classes like String or Integer or make your own depending on your further requirements. You can store all these classes in your ArrayList. When retrieving your data check which class is used and handle it appropriately. That is ok but i want to write a query to create a table with the dynamic data (Column name and type).  Well you read your data in a String and for every value do String.matches(regex) to find out the datatype. For example do value.matches(""\d"") if it mathces then instantiate an Integer like new Integer(value). Now you should be able to add this new integer object into your List. I hope you will be able to see how to go further. Check the instanceof or something while creating the table in the database."
524,A,"Database to GlazedList/Jtable and then edit the database through the GlazedList/JTable I am able to break this problem down into two questions: What is the best way to put the contents of a database (MS-Access) into a GlazedList/JTable? How do I make sure any changes made to the GlazedList/JTable are reflected on the database (MS-Access)? Here are the things I know: I know how to retrieve/manipulate the information from a database using the JDBC method. I know that GlazedList's require reflection so I would need to make a class that contains every column/field in the database. This is not very expandable... What is the best way to go about this problem? edit:// I have managed to create a class generator. It takes the column headings and creates an instance field. This should resolve the #2 http://pastebin.ca/1770996 - It creates the class but I do not think I used reflection correctly... edit2:// Edited my code from above so it works... http://pastebin.ca/1776722 I've provided one (simpler) answer that my initial implementation was based upon. It relies on some of the more advanced JDBC features though so it *may* not work for you. I'd forgotten I still had a link to the initial code. No worries and no need to rush. Take your time. Work is a little more important than this... It's going to be a few more days before I have a result for you -- doing a bit of contract work. `setValueAt` code: http://pastebin.ca/1803042 error: http://pastebin.ca/1803039 The column+2 didn't get the right column from the rs so I changed it to +1. I was googling this and the only answer I found was to not use a resultset and use a preparedstatement. That doesn't sound too good. Good news. I got ResultSetTable to display the table. I needed to add the [] to the table names. Now I just need to make it edit correctly. I get an `error in row` or `classcastexception`. ClassCast is easy to fix but idk about the error in row... It does not like your `setValueAt` method so I am having another look at that... To be even more specific it does not like `rs.updateRow();` which throws an `SQLException - if a database access error occurs or if this method is called when the cursor is on the insert row` It has to throw an SQLException if an error occurs... if you like you can collect and feed these errors to something or catch them in some fashion. For the insert row you need to call `rs.insertRow()` to add it. You cannot use `rs.updateRow()` there. Continued in another question. http://stackoverflow.com/questions/2308743/editing-jtable-from-restulset-table I had a very similar problem and I think my result was similar too except it didn't need reflection (static DB schema). You need to create row objects for each row (which may just include row number and references to a ResultSet and column info). Then write a ca.odell.glazedlists.gui.WritableTableFormat implementation to map these objects to table cells. To avoid problems with #2 you can create a flexible row class that fetches column info once from the ResultSet and caches it for reuse. Edit: I found an original and simpler implementation (fairly simple) that mine was based upon. You can view it here: ResultSet Table. It might be sufficient for your purposes. Then you add this to the AbstractTableModel implementation provided by the link. public void setValueAt(Object ob int row int column) throws SQLException { resultSet.absolute(r+1); if (ob == null) { resultSet.updateNull(column+2); } else { resultSet.updateObject(column+2ob); } rs.updateRow(); this.fireTableCellUpdated(rowcolumn); } public boolean isCellEditable(int row int col) { return true; } There are three catches though: your ResultSet needs to be updatable support scrolling both directions and be sensitive to updates to the DB. These are part of the JDBC spec but not all drivers support them and you need to make sure your ResultSet is created with them enabled. In that case you just do this.fireTableDataChanged() periodically to force a full update of the table data. It's not the fastest approach but it does work. Edit2: Another approach What about using one of the Object-relational mapper libraries and then do the ca.odell.glazedlists.gui.WritableTableFormat like I suggested above? Could you please explain this a little bit more? Code snippets would be great or more links. I will be using a MS-Access 2003 database on Windows XP so everything should be supported. The database is actually rather small compared to yours I would think. There are probably only 1000 elements total. So nothing huge by any means. @twodayslate: it is considerably simpler if the whole DB fits in memory. Ok I will be working on extending my existing implementation for your needs. Please give me a few days to get the code finished: bear in mind this can require significant coding especially as I will be avoiding reflection for performance reasons. Wow! Thank you for your time. That sounds like a huge task and I wish I could give you more for your time. I look forward to seeing how you do this cause the only thing I managed to come up with used reflection. Have all the time you want! So from my understanding it is better to accept the answer now so you get all the points right? Thank you for the wonderful linkage! I can see the resultsets but nothing else. I also get the following error `Error java.sql.SQLException: [Microsoft][ODBC Microsoft Access Driver] Syntax error in FROM clause.` Perhaps I do not meet the 3 catches? How do I ensure I meet them exactly? Also it didn't like `Class.forName(""com.pointbase.jdbc.jdbcDriver"");` so I changed it to the driver I had before. How do I set it up for this driver exactly? It said it couldn't find this one... If I knew how to do the Edit2 approach I would try it... :( @twodayslate: yeah I get more credit and I think you get a bit back too (to encourage people accepting answers). I wish I had a better answer for you. My initial approach runs into problems when you're only selecting part of the table or when the DB gets modified by another thread. I only have 53 rep points... I can't do anymore :\ Now THAT bounty makes it worth digging through source for my old code and combining it to create an implementation. Alright I accepted your answer. If you want to expand on the current answer later or post a new answer that would be great. ;) Err sorry: I'm not being sarcastic. It IS better than the 15 acceptance points especially when the question is kind of complex. Question: do you know what DBMS you will be using and can you guarantee that all the JDBC features will be supported? My previous implementation of an editable table ran to a couple thousand lines and relied on updatable resultsets and JDBC metadata. Not all drivers will support these features but doing it another way is... well really messy. How would you put glazedlist filters on this? You can't apply a filter to this unfortunately. To do that you need an entity-based approach with one object per row. I've been thinking on a way to do this without the full complexity of a object-relational mapper but it gets pretty complex pretty fast. I just decided to continue this in another question. This was getting rather long... http://stackoverflow.com/questions/2308743/editing-jtable-from-restulset-table"
525,A,"Extremely slow DB2 connectivity in Java I am trying to connect to an IBM DB2 9 database on a Linux server from my Java application. I am using db2jcc.jar (DB2 Universal JDBC Driver). Establishing a connection is taking a ridiculous amount of time. What could be wrong? I know there are a lot of factors that could cause this but I want to get down to the root cause. Okay I figured it out. This is exactly my problem - www-01.ibm.com/support/docview.wss?uid=swg21270934. I am getting in touch with my admin to get this resolved. Thank you everyone. Much appreciated. – GPX 0 secs ago Indeed use host name instead of direct address IP. Connection time was about 15s now it's immediate. So it was that the reverse hostname lookup was not working properly. TYpically this is a DNS configuration problem - now I've learned that it can be Windows Domain configuration problem too. First off I would try to up the log level on the driver to debug or even trace. This might give you an easy way of seeing where it is hanging in it's attempt to complete the connection. Are you using log4j? What is your JDBC connection string? jdbc:db2j:net://host-ip-address:port/DBSID I am not using log4j. But I guess I can use the JDBC trace. And by hanging if you mean it just freezes no - it doesn't. It does connect eventually. But every single time it takes 20 seconds (consistently!) to do that! What log level are you using? What log statement does it hang on? I just enabled the setLogWriter method for DriverManager. It takes time when it reaches the line with the method ""getHostAddressFromIpAddr""  Check if your DNS configuration is 100% correct. Can you please tell me how exactly?  Establish tracing on the client and on the server side. This should allow you to differentiate between the following possible issues: the driver implementation being slow (receives answer but takes a long time to reply) the network being slow (turnaround on both ends is fast but with large breaks in between) the database being slow to react (same as the first but on the server end) there is just a lot of stuff going back and forth Once you have found the issue you'll have to dig deeper in order to understand why this is the case.  This is happening because the driver does a reverse lookup of the IP to resolve a host name an easy fix is to add the server and hostname to your System32\drivers\etc\hosts (if you're on windows) file then use the hostname you just mapped. E.g. %WINDOWS%System32\drivers\etc\hosts 128.0.0.200 DB_SERVER then in your application: jdbc:db2://DB_SERVER:55701/SCHEMA_NAME"
526,A,"How do I bind an ArrayList to a PreparedStatement in Oracle? I was wondering if there was a way to bind an ArrayList (or any kind of List for that matter) to a PreparedStatement which will eventually be used to access an Oracle database. I found: http://stackoverflow.com/questions/178479/alternatives-for-java-sql-preparedstatement-in-clause-issue And that seems similar to my issue but this question is more specific: I'd like to bind an ArrayList to a PreparedStatement to be used in Oracle if it is possible how is this accomplished? In what capacity? What does your statement (with placeholders) look like? I doubt there's a general solution to this since 1) the length of List will vary and 2) the number of placeholders in your statement likely will not. Also not all Lists are ordered. Matt all objects that implement java.util.List provide a get(int) operation that retrieves the object at the specified index. It also provides an iterator. Both of these are non-optional: the order may be odd but an order exists. So all java.util.List implementations *are* ordered... ...and in Java List typically refers to the java.util.List interface contract. You can't bind it directly. There is a way to pass an array as a parameter. I have no idea what you want to do with it on the database side so this may not help you. Basically you have to create a nested table type in the database; build a Java object based on that type containing the data from your array; and pass that as the parameter. If you created these objects in the database: CREATE OR REPLACE TYPE my_nested_table IS TABLE OF VARCHAR2(20); CREATE TABLE my_table (a my_nested_table) NESTED TABLE a STORE AS my_table_a; Then you can write Java code like this: String[] insertvalues = { ""a"" ""b"" ""c"" }; PreparedStatement p = conn.prepareStatement(""INSERT INTO my_table VALUES( ? )""); ARRAY insertParameter = new ARRAY( a_desc conn insertvalues ); p.setArray( 1 insertParameter ); p.execute(); The results in Oracle look like this: dev> select * from my_table; A -------------------------------------------------------------------------------- MY_NESTED_TABLE('a' 'b' 'c')  Well judging by the answer to that one especially the comments to my wrong answer in that question you can't. See http://java.sun.com/j2se/1.3/docs/guide/jdbc/getstart/mapping.html#996857 That's a useful link but it wasn't what I was going for. Sorry.  You can't bind a List to a single parameter in a prepared statement. Generate SQL with the a parameter marker for each element in the list for example: SELECT NAME FROM ITEM WHERE ID IN (? ? ? ?) Even though you'll generate a new statement for each query I'd still recommend using a PreparedStatement. If your list contains String instances you'll get the necessary escaping to protect from SQL injection. But even if it's a safe type like Integer objects some drivers or middleware can cache PreparedStatements and return a cached instance if the same form is requested. Of course some testing would be necessary. If your lists vary widely in size you'll have many different statements and a poorly-implemented cache might not be prepared to handle so many. That's what I was afraid of but it seems like you do have to generate a ""question-mark string"" and append it to your general SQL statement. Oh well."
527,A,"spring jdbc and composite primary keys Is there a way in spring jdbc to return a composite primary key when a row is inserted. This composite primary key is made up of values from separate sequences Any help is greatly appreciated Regards Damien I would like some clarification on ""Spring JDBC""; do you mean with Hibernate mappings or some other JPA framework? I am not aware of any build in JDBC functionality that Spring offers. One other note: It is often a good idea to use ONE generated primary key column when your table's records are uniquely identified by a composite key. Especially if that composite key is just multiple generated columns. I would review your DB design to see if simplifying things will make using these frameworks easier. Here is a full example (tested on PostgreSQL 8.4): My table: CREATE TABLE test ( id serial NOT NULL otherid serial NOT NULL val text CONSTRAINT test_pkey PRIMARY KEY (id otherid) ) This is how you get keys back: public void doStuff() { KeyHolder keyHolder = new GeneratedKeyHolder(); jdbcTemplate.update( new PreparedStatementCreator() { public PreparedStatement createPreparedStatement(Connection connection) throws SQLException { PreparedStatement ps = connection.prepareStatement(""insert into test(val) values (?)"" Statement.RETURN_GENERATED_KEYS); ps.setInt(1 42); return ps; } } keyHolder); keyHolder.getKeys().get(""id""); keyHolder.getKeys().get(""otherid""); } Now if you want to get your composite key as an instance of some class directly from keyHolder it is not simple. JdbcTemplate uses ColumnMapRowMapper to map generated keys (generated keys are returned as result set at least on PostgreSQL. It actually returns the whole row as if you were executing select on the row you just inserted). Same ColumnMapRowMapper is used in number of other places in JdbcTemplate. The only possible point of extension here is KeyHolder itself. Here is what you can do: public void doStuff() { CompositeKeyHolder keyHolder = new CompositeKeyHolder(); ... same code here ... keyHolder.getCompositeKey(); } class CompositeKeyHolder extends GeneratedKeyHolder { private boolean converted; public CompositeKey getCompositeKey() { return new CompositeKey((Integer)this.getKeys().get(""id"") (Integer)this.getKeys().get(""otherid"")); } } class CompositeKey { private Integer id; private Integer otherId; CompositeKey(Integer id Integer otherId) { this.id = id; this.otherId = otherId; } public Integer getId() { return id; } public Integer getOtherId() { return otherId; } }  I think what you need is GeneratedKeyHolder.getKeys(). Code would look like this example except you will have to call keyHolder.getKeys() instead of keyHolder.getKey()  What database server are you using? MySQL only allows one auto_increment field per table and I'd imagine this is often the case but without knowing your setup it's hard to say. Assuming there is only one auto_generated field in your table your INSERT would have had to be aware of the value going into the second PK field. Robert's code should work for retrieving the generated key value and the cleanest solution would probably be to perform a SELECT after the fact using this generated key and the value which you had a hold of already. MySQL is not a good guide to other databases - it's crude and primitive. Composite keys are well supported by proper databases but Spring JDBC doesn't seem to have good support for this concept.  Here is the basic idea for a single key. The long id at the end is the key. If you have multiple sequences I would recommend just using two separate statements to get each generated key. JdbcTemplate template = getJdbcTemplate(); KeyHolder keyHolder = new GeneratedKeyHolder(); template.update( new PreparedStatementCreator() { public PreparedStatement createPreparedStatement(Connection connection) throws SQLException { PreparedStatement ps = connection.prepareStatement(...); return ps; } } keyHolder); long id = keyHolder.getKey().longValue(); Single keys are the easy case and don't really need explanation. Composite keys are the question and appear to have no easy/efficient solution. That is true but I wasn't sure if Damien knew the easy answer. The other part is that if you are inserting data into a table using 2 generated keys in one statement it sounds like a potential design flaw."
528,A,Display 100000 records on browser / multiple pages I would like to display 100000 records on browser / multiple pages with minimal impact on memory. ie Per page 100 records. I would like to move page back and forth. My doubts are 1. Can I maintain all the record inside the memory ? Is this good Idea ? 2) Can I make database connection/query for ever page ? If so how do write a query? Could anyone please help me.. In many SQL language you have a notion of LIMIT (mysql ...) or OFFSET (mssql). You can use this kind of thing to limit rows per page  As mentioned by others here it is not a good idea to store a large list of results in memory. Query for results for each page is certainly a much better approach. To do that you have two options. One is to use whatever the database specific features your DBMS provides for targeting a specific subsection of results from a query. The other approach is to use the generic methods provided by JDBC to achieve the same effect. This keeps your code from being tied to a specific database: // get a ResultSet from some query ResultSet results = ... if (count > 0) { results.setFetchSize(count + 1); results.setFetchDirection(ResultSet.FETCH_FORWARD); results.absolute(count * beginIndex); } for (int rowNumber = 0; results.next(); ++rowNumber) { if (count > 0 && rowNumber > count) { break; } // process the ResultSet below ... } Using a library like Spring JDBC or Hibernate can make this even easier.  1) No having all the records in memory kind of defeats the point of having a database. Look into having a scrollable result set that way you can get the functionality you want without having to play with the SQL. You can also adjust how many records are fetched at a time so that you don't load more records than you need. 2) Db connections are expensive to create and destroy but any serious system will pool the connections so the impact on performance won't be that great. If you want to get a bit more fancy you can do away with pages altogether and just load more records as the user scrolls through the list.  Depends on the data. 100k int's might not be too bad if you are caching that. T-SQL has SET @@ROWCOUNT = 100 to limit the amount of records returned. But to do it right and return the total # of pages you need a more advanced paging SPROC. It's a pretty hotly dedated topic and there are many ways to do it. Here's a sample of an old sproc I wrote CREATE PROCEDURE Objects_GetPaged ( @sort VARCHAR(255) @Page INT @RecsPerPage INT @Total INT OUTPUT ) AS SET NOCOUNT ON --Create a temporary table CREATE TABLE #TempItems ( id INT IDENTITY memberid int ) INSERT INTO #TempItems (memberid) SELECT Objects.id FROM Objects ORDER BY CASE @sort WHEN 'Alphabetical' THEN Objects.UserName ELSE NULL END ASC CASE @sort WHEN 'Created' THEN Objects.Created ELSE NULL END DESC CASE @sort WHEN 'LastLogin' THEN Objects.LastLogin ELSE NULL END DESC SELECT @Total=COUNT(*) FROM #TempItems -- Find out the first and last record we want DECLARE @FirstRec int @LastRec int SELECT @FirstRec = (@Page - 1) * @RecsPerPage SELECT @LastRec = (@Page * @RecsPerPage + 1) SELECT * FROM #TempItems INNER JOIN Objects ON(Objects.id = #TempItems.id) WHERE #TempItems.ID > @FirstRec AND #TempItems.ID < @LastRec ORDER BY #TempItems.Id  I would recommend that you choose using CachedRowSet . A CachedRowSet object is a container for rows of data that caches its rows in memory which makes it possible to operate without always being connected to its data source. A CachedRowSet object is a disconnected rowset which means that it makes use of a connection to its data source only briefly. It connects to its data source while it is reading data to populate itself with rows and again while it is propagating changes back to its underlying data source. Because a CachedRowSet object stores data in memory the amount of data that it can contain at any one time is determined by the amount of memory available. To get around this limitation a CachedRowSet object can retrieve data from a ResultSet object in chunks of data called pages. To take advantage of this mechanism an application sets the number of rows to be included in a page using the method setPageSize. In other words if the page size is set to five a chunk of five rows of data will be fetched from the data source at one time. An application can also optionally set the maximum number of rows that may be fetched at one time. If the maximum number of rows is set to zero or no maximum number of rows is set there is no limit to the number of rows that may be fetched at a time. After properties have been set the CachedRowSet object must be populated with data using either the method populate or the method execute. The following lines of code demonstrate using the method populate. Note that this version of the method takes two parameters a ResultSet handle and the row in the ResultSet object from which to start retrieving rows. CachedRowSet crs = new CachedRowSetImpl(); crs.setMaxRows(20); crs.setPageSize(4); crs.populate(rsHandle 10); When this code runs crs will be populated with four rows from rsHandle starting with the tenth row. On the similar path you could build upon a strategy to paginate your data on the JSP and so on and so forth.  I would not hold the data in memory (either in the browser or in the serving application). Instead I'd page through the results using SQL. How you do this can be database-specific. See here for one example in MySql. Mechanisms will exist for other databases.  It's generally not a good idea to maintain so much records in memory. If the application is accessed by several users at the same time the memory impact will be huge. I don't know what DBMS are you using but in MySQL and several others you can rely on the DB for pagination with a query such as: SELECT * FROM MyTable LIMIT 0 100 The first number after limit is the offset (how many records it will skip) and the second is the number of records it will fetch. Bear in mind that this is SQL does not have the same syntax on every DB (some don't even support it).  It would not be a good idea as you are making the browser executable hold all of that. When I had something like this to do used javascript to render the page and just made ajax calls to get the next page. There is a slight delay in displaying the next table as you fetch it but users are used to that. If you are showing 100 records/page use json to pass the data from the server as javascript can parse it quickly and then use innerHTML to put the html as the DOM is much slower in rendering tables. U made a DB connection for every page display? mySQL makes very fast connections but you can also have a pool of db connections if concerned about performance so yes a db connection for each page especially since you don't know how long before the next page is moved to.
529,A,"ClassNotFoundException: com.microsoft.sqlserver.jdbc When I ran my web application under Eclipse IDE everything worked fine. But when I exported my project into war-file and deployed in tomcat I've got following message: java.lang.ClassNotFoundException: com.microsoft.sqlserver.jdbc I've tried putting sqljdbc4.jar everywhere: catalina-home\lib dir WEB-INF\lib dir both of them What I'am missing? Environment: tomcat 6.0.20 sql server 2005 Your driver class name is wrong. The exception text points to a package not an actual driver class. And don't forget to restart Tomcat after changing the contents of various lib directories. Edit: Your IDE might use different configuration than your deployed war. Or fail with the same exception silently but the driver itself was already loaded by other means - then the actual connection just works. thnks for feedback What you mean by saying ""Your driver class is wrong"" - that driver works fine under IDE Regardless of what your IDE is doing ""com.microsoft.sqlserver.jdbc"" is not a driver class it's a package. I feel silly but what conclusions I should draw from >>>""com.microsoft.sqlserver.jdbc"" is not a driver class it's a package In general if you see these kind of error messages check your configuration for mistypes.  The driver class is ""com.microsoft.sqlserver.jdbc.SQLServerDriver"". You've just missed the class name off the end. I never remember the driver class names. These times I wish JDBC had automatic driver discovery. skaffman I specified driver class in context.xml as following: driverClassName=""com.microsoft.sqlserver.jdbc.SQLServerDriver"" please post the relevent part of your context.xml file. For that configuration to work in the deployed version of your web application the JAR containing com.microsoft.sqlserver.jdbc.SQLServerDriver has to be in $CATALINA_HOME/lib  blah... After reinstalling tomcat it worked just fine. As kd304 said - maybe it was configuration issue Thanks for your help"
530,A,"How do I convert a Joda Time DateTime object into a String in SQL Server format? I am using the Joda-Time library in Java and have a date and time stored as an org.joda.time.DateTime object. How can I reliably convert this DateTime object into a String that will be parsed correctly by SQL server (including timezone) such that I can use it in an INSERT SQL statement? Be careful to consider time zones. Using new Timestamp() may be tricky since it expects time in milliseconds in GMT.  DateTime dt = new DateTime(2010 1 1 14 30 59 1 DateTimeZone.forOffsetHoursMinutes(7 0)); Timestamp ts = new Timestamp(dt.getMillis()); System.out.println(dt); // prints 2010-01-01T14:30:59.001+07:00 System.out.println(ts); // prints 2010-01-01 08:30:59.001 DateTimeFormatter fmt = DateTimeFormat.forPattern(""yyyy-MM-dd HH:mm:ss""); String sqlTimeString = fmt.print(dt); System.out.println(sqlTimeString); // prints 2010-01-01 14:30:59  Use java.sql.Timestamp with PreparedStatement#setTimestamp(). ps.setTimestamp(1 new Timestamp(dateTime.getMillis())); Note that java.sql.Date stores only the date part not the time part.  Simply Function I use this simple function to get a SQL-friendly date format from a JodaTime DateTime object: // Converts a DateTime object into a SQL-format friendly string. // // Return format looks like this: 2014-01-22 10:05:34.546 // public static String toSql(DateTime dateTime) { return new Timestamp( dateTime.getMillis() ).toString(); }  you can try this simple code : DateTime dt = new DateTime(); DateTimeFormatter fmt = DateTimeFormat.forPattern(""yyyy-MM-dd HH:mm:ss""); String dtStr = fmt.print(dt);"
531,A,"How do I get the size of a java.sql.ResultSet? Shouldn't this be a pretty straightforward operation? However I see there's neither a size() nor length() method. Please stop writing tags in titles. I would love to know the reason for that omission. My understanding of the question was that you want to find the size of the ResultSet IN BYTES not the number of tuples...  String sql = ""select count(*) from message""; ps = cn.prepareStatement(sql); rs = ps.executeQuery(); int rowCount = 0; while(rs.next()) { rowCount = Integer.parseInt(rs.getString(""count(*)"")); System.out.println(Integer.parseInt(rs.getString(""count(*)""))); } System.out.println(""Count : "" + rowCount); }  The way of getting size of ResultSet No need of using ArrayList etc int size =0; if (rs != null) { rs.beforeFirst(); rs.last(); size = rs.getRow(); } Now You will get size And if you want print the ResultSet before printing use following line of code too rs.beforeFirst();  I got an exception when using rs.last(); if(rs.last()){ rowCount = rs.getRow(); rs.beforeFirst(); } : java.sql.SQLException: Invalid operation for forward only resultset it's due to by default it is ResultSet.TYPE_FORWARD_ONLY which means you can only use rs.next(); the solution is: stmt=conn.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE ResultSet.CONCUR_READ_ONLY); Switching from `ResultSet.TYPE_FORWARD_ONLY` to `ResultSet.TYPE_SCROLL_INSENSITIVE` usually incurs in a **huge** performance penalty.  theStatement=theConnection.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE ResultSet.CONCUR_READ_ONLY); ResultSet theResult=theStatement.executeQuery(query); //Get the size of the data returned theResult.last(); int size = theResult.getRow() * theResult.getMetaData().getColumnCount(); theResult.beforeFirst(); This deals with the number of _columns_ not the number of _rows_...  ResultSet.last() followed by ResultSet.getRow() will give you the row count but it may not be a good idea as it can mean reading the entire table over the network and throwing away the data. Do a SELECT COUNT(*) FROM ... query instead. last() and getRow() aren't static methods in the ResultSet class. For brevity's sake I always reference methods in this fashion when writing about them to others regardless of whether they are static or not. Actually creating an instance of the object and calling the method is implied. I write SomeClass.staticMethod() and SomeClass#instanceMethod() for less confusion. How does one fetch the value returned when executing a `select count`? @TK Kocheran same way you would get the result of any one-row/one-column query with `executeQuery()` `next()` and `getInt(1)` `ResultSet#last()` doesn't work on all types of `ResultSet` objects you need to make sure you use one that is either `ResultSet.TYPE_SCROLL_INSENSITIVE` or `ResultSet.TYPE_SCROLL_SENSITIVE` @Giodude the `SELECT COUNT(*)` would need to be performed inside the stored procedure or the stored procedure could return a temporary view and the caller could do `SELECT COUNT(*)` on that. What if you can't change the stored proc because it comes from somewhere else? What if the result set is returned from a stored procedure call? Is there no way to know its size beforehand? @Giodude it may not be possible to efficiently count the rows in that case. But if you must manually count the rows I would do it on the server side if possible (e.g. with a temporary procedure.) Does anyone know why getting the count for a resultset is so difficult? Why didn't they just include a `ResultSet#size()` method in the API? @ryvantage A bit late. They don't do that because the count is not known in advance only after materializing the entire result set does the database know how many rows it produced. This is inefficient as materializing all rows takes memory I/O and processing time. When reading a forward-only result set (and sometimes also scrollable result sets) a database will only read rows when asked to do so (and it might read a bit ahead). So a client might process some rows while the database is reading some more: efficient and less memory-intensive. So does that mean `select count(*) from table` is a O(n) operation? Also other answers have indicated using `ResultSet::last()` as a way to find the count. Would the `last()` method also be a O(n) operation then? @ryvantage: Yes. In MS SQL Server for example `ResultSet::last()` is O(N) with the (default) forward-only cursor. You can get O(1) `last` (from the client's point of view) with a scrollable+static cursor. But these cursor types require the *server* to store the whole keyset in memory. The server does not know in advance that you are going to throw away the results and use only the row count. It has to build the query plan with the assumption that you will consume all the data.  int i = 0; while(rs.next()) { i++; }  It is a simple way to do rows-count. ResultSet rs = job.getSearchedResult(stmt); int rsCount = 0; //but notice that you'll only get correct ResultSet size after end of the while loop while(rs.next()) { //do your other per row stuff rsCount = rsCount + 1; }//end while Yeah that works. But I think the OP struggles with knowing the number of rows _before_ actually processing them. Real life reasons I'd have to fight this issue so far: 1.) paging of record rows 2.) showing the rows processed in long-running tasks for progress monitoring purposes... Preallocating data structure size are another reason. I've seen plenty of libs return 10 element Lists when there is only a single value because the dev's had this same issue with ResultSet.  Well if you have a ResultSet of type ResultSet.TYPE_FORWARD_ONLY you want to keep it that way (and not to switch to a ResultSet.TYPE_SCROLL_INSENSITIVE or ResultSet.TYPE_SCROLL_INSENSITIVE in order to be able to use .last()). I suggest a very nice and efficient hack where you add a first bogus/phony row at the top containing the number of rows. Example Let's say your query is the following select MYBOOLMYINTMYCHARMYSMALLINTMYVARCHAR from MYTABLE where ...blahblah... and your output looks like true 65537 ""Hey"" -32768 ""The quick brown fox"" false 123456 ""Sup"" 300 ""The lazy dog"" false -123123 ""Yo"" 0 ""Go ahead and jump"" false 3 ""EVH"" 456 ""Might as well jump"" ... [1000 total rows] Simply refactor your code to something like this: Statement s=myConnection.createStatement(ResultSet.TYPE_FORWARD_ONLY ResultSet.CONCUR_READ_ONLY); String from_where=""FROM myTable WHERE ...blahblah... ""; //h4x ResultSet rs=s.executeQuery(""select count(*)as RECORDCOUNT"" + ""cast(null as boolean)as MYBOOL"" + ""cast(null as int)as MYINT"" + ""cast(null as char(1))as MYCHAR"" + ""cast(null as smallint)as MYSMALLINT"" + ""cast(null as varchar(1))as MYVARCHAR "" +from_where +""UNION ALL ""//the ""ALL"" part prevents internal re-sorting to prevent duplicates (and we do not want that) +""select cast(null as int)as RECORDCOUNT"" + ""MYBOOLMYINTMYCHARMYSMALLINTMYVARCHAR "" +from_where); Your query output will now be something like 1000 null null null null null null true 65537 ""Hey"" -32768 ""The quick brown fox"" null false 123456 ""Sup"" 300 ""The lazy dog"" null false -123123 ""Yo"" 0 ""Go ahead and jump"" null false 3 ""EVH"" 456 ""Might as well jump"" ... [1001 total rows] So you just have to if(rs.next()) System.out.println(""Recordcount: ""+rs.getInt(""RECORDCOUNT""));//hack: first record contains the record count while(rs.next()) //do your stuff  I checked the runtime value of the ResultSet interface and found out it was pretty much a ResultSetImpl all the time. ResultSetImpl has a method called getUpdateCount() which returns the value you are looking for. This code sample should suffice: ResultSet resultSet = executeQuery(sqlQuery); double rowCount = ((ResultSetImpl)resultSet).getUpdateCount() I realize that downcasting is generally an unsafe procedure but this method hasn't yet failed me. Not working with Tomcat/MySQL: `java.lang.ClassCastException: org.apache.tomcat.dbcp.dbcp.DelegatingResultSet cannot be cast to com.mysql.jdbc.ResultSetImpl`  ResultSet rs = ps.executeQuery(); int rowcount = 0; if (rs.last()) { rowcount = rs.getRow(); rs.beforeFirst(); // not rs.first() because the rs.next() below will move on missing the first element } while (rs.next()) { // do your standard per row stuff } Inside the if(rs.last()) code block wouldn't the correct method be rs.beforeFirst() instead of rs.first()? This way you are not skipping the first record in your result set for processing in the while loop. KG - Indeed that looks right at a brief look at the code!"
532,A,"JDBC + Java Query execution error I'm getting this exception java.sql.SQLException: Unknown column 'auyu' in 'where clause' My Query and method in my database facade class. db.save(""delete from users where name = auyu""); public static void save(String sql) throws Exception { new DBFacade().connect(); synchronized (c) { c.createStatement().executeUpdate(sql); } } Please indent code with four spaces so it gets formatted properly. +1 to Jon Skeet's answer. Expanding and perhaps going OT but it's best to parameterize these things and ensure escaping so that you aren't susceptible to SQL-injection attacks. E.g.: public static void deleteUser(userName) throws Exception { PreparedStatement ps; new DBFacade().connect(); // (Assuming 'c' is a connection that's in scope somehow) synchronized (c) { // (You'd want to cache the prepared statement in an appropriate // way related to how you're handling connections and pooling) ps = c.prepareStatement(""delete from users where name = ?""); ps.setString(1 userName); ps.executeUpdate(); } } Otherwise if a user provides a name like ""anyu'; drop table users;"" you could be for it.  You need single quotes around the auya ('auyu') and you'll need to escape them like so: ""delete from users where name = \'auyu\'""  I suspect you meant: delete from users where name = 'auyu' This is still a pretty odd SQL command to give to a ""save"" method. I'd also strongly suggest that you use parameterised SQL statements instead of embedding data directly into the SQL itself - particularly if the data has come from the user. Thanks what if I need to use a String like this: String s = ""auyu""; @Rocky: Use a preparedStatement (or string concatenation); see my answer for details on the PS option."
533,A,"Behaviour of ResultSet after connection got corrupted Suppose I am making jdbc call and I had fetched data from db to resultset. But due to some network issue I lost my connection with db. (Connection statement and resultset is not closed in DB). So can I still able to iterate resultset ? Even if you could you shouldn't unless you are coding against a very specific jdbc driver. In some cases the result set will not be constructed at all. In others (Oracle IIRC) you could configure it so that it only fetches a give number of rows out of the total. However in general if you lose the connection you have more things to worry about than wondering if you can iterate over a partially fetched resulst set object. In such cases the rule of thumb is to assume the worst; attempt to close the result set statement and connection; even if the physical connection is lost there might be resources like memory and file handles on the calling side that need to be disposed off; if possible attempt to get a new connection (either a new physical one or from a connection pool) and start over. Also as a rule of thumb you should not worry about partial failures when executing statements within a transaction. Discard and retry fresh. In some rare cases the DB can send you a vendor specific code (SQLException.getErrorCode()) that can tell you whether the operation can be retried. Oracle has some specific codes (don't remember them) for cases when you do an insert and a unique constrain has been violated. Sometimes such failed operations can be retried but that's vendor and business specific. In general just dump the mauled result set and start over.  It am pretty sure it depends entirely on your JDBC driver. It may have buffered all the results before the connection was lost. It may have only buffered the next 10 results before the connection was lost. Even if all results were buffered the driver itself may start throwing exceptions before you can finish iterating over the buffered results. Personally I would assume that any behavior after a network interruption is considered undefined.  Typically any kind of ""entire result set"" object will not be fully constructed until the full row set has been received successfully. If for example you have a property like NumberRecordsAffected on the object then it must have received all rows. However an enumerable object like GetFirstRow/GetNextRow typically will bring down a chunk of rows at a time so you wouldn't know the connection died until the current buffer was exhausted (if it buffers any rows) and it tries to fetch the next row from the db. In either case I would expect an exception to be thrown but IANAJDBCD (I am not a jdbc developer)."
534,A,"Running a .sql script using MySQL with JDBC I am starting to use MySQL with JDBC. Class.forName(""com.mysql.jdbc.Driver""); conn = DriverManager.getConnection(""jdbc:mysql:///x"" ""x"" ""x""); stmt = conn.createStatement(); stmt.execute( ""CREATE TABLE amigos"" + ""(""+ ""id int AUTO_INCREMENT not null""+ ""nombre char(20) not null""+ ""primary key(id)"" + "")""); I have 3-4 tables to create and this doesn't look good. Is there a way to run a .sql script from MySQL JDBC? any particular reason why you need to write java code to run these create table statements? Are they dynamic in some way? Spring Framework's ResourceDatabasePopulator may help. As you said you're using MySQL and JDBC let's assume you have a MySQL-backed DataSource instance ready. Further let's assume your MySQL script files are classpath-locatable. Let's assume you are using WAR layout and the script files are located in a directory src/main/webapp/resources/mysql-scripts/... or src/test/resources/mysql-scripts/.... Then you can use ResourceDatabasePopulator to execute SQL scripts like this: import org.springframework.jdbc.datasource.init.ResourceDatabasePopulator; import javax.sql.DataSource; DataSource dataSource = getYourMySQLDriverBackedDataSource(); ResourceDatabasePopulator rdp = new ResourceDatabasePopulator(); rdp.addScript(new ClassPathResource( ""mysql-scripts/firstScript.sql"")); rdp.addScript(new ClassPathResource( ""mysql-scripts/secondScript.sql"")); try { Connection connection = dataSource.getConnection(); rdp.populate(connection); // this starts the script execution in the order as added } catch (SQLException e) { e.printStackTrace(); } By far the best answer here. I get tired of seeing the answers that tell you to run the MySQL dump import from the command line. Doesn't work so well in an automated environment where the database is on a different server.  For Oracle PL/SQL the Oracle JDBC-driver indeed supports executing entire SQL-scripts including stored procedures and anonymous blocks (PL/SQL specific notation) see Can the JDBC Drivers access PL/SQL Stored Procedures? The Oracle JDBC driver FAQ has more info: Oracle JDBC drivers support execution of PL/SQL stored procedures and anonymous blocks. They support both SQL92 escape syntax and Oracle PL/SQL block syntax. The following PL/SQL calls would work with any Oracle JDBC driver: // SQL92 syntax CallableStatement cs1 = conn.prepareCall ( ""{call proc (??)}"" ) ; // stored proc CallableStatement cs2 = conn.prepareCall ( ""{? = call func (??)}"" ) ; // stored func // Oracle PL/SQL block syntax CallableStatement cs3 = conn.prepareCall ( ""begin proc (??); end;"" ) ; // stored proc CallableStatement cs4 = conn.prepareCall ( ""begin ? := func(??); end;"" ) ; // stored func It should be possible to read in a file and feed the content to the prepareCall()-method. The first link to the question is broken.  Ok. You can use this class here (posted on pastebin because of file length) in your project. But remember to keep the apache license info. JDBC ScriptRunner It's ripoff of the iBatis ScriptRunner with dependencies removed. You can use it like this Connection con = .... ScriptRunner runner = new ScriptRunner(con [booleanAutoCommit] [booleanStopOnerror]); runner.runScript(new BufferedReader(new FileReader(""test.sql""))); That's it! Very handful class. I must add that line 130 can cause headaches. I replaced it to ""String trimmedLine = line.trim().replaceAll("";$"" Matcher.quoteReplacement(""; \\""));"" because you might get http://stackoverflow.com/questions/3499483/error-unterminated-quoted-string-at-or-near Can this be used to return a `ResultSet` or it only works for update statements? I tried using it but cannot figure how to get it to return a `ResultSet`. I would go for `Spring` but it is easier to use a class than an entire library.  Maven SQL Plugin Use this plugin to execute SQL statements a file or list of files through sqlCommand srcFiles 3.fileset configurations  There isn't really a way to do this. You could either run the mysql command line client via Runtime.exec(String[]) and read this article when you decide for this option Or try using the ScriptRunner (com.ibatis.common.jdbc.ScriptRunner) from ibatis. But it's a bit stupid to include a whole library just to run a script. Yes it's true. Doesn't make sense to add a lib just to run a script :( I think it's quite strange that jdbc doesn't come with something like that.  I did a lot of research on this and found a good util from spring. I think using SimpleJdbcTestUtils.executeSqlScript(...) is actually the best solution as it is more maintained and tested. Edit: SimpleJdbcTestUtils is deprecated. You should use JdbcTestUtils. Updated the link. Thanks @Amir Raminfar your answer helped me out. Anyway just as an update spring deprecated `SimpleJdbcTestUtil` and advises to use `JdbcTestUtils` in future. This is the best answer the Spring framework team is active.  Regarding SQL script runner (which I'm also using) I noticed the following piece of code: for (int i = 0; i < cols; i++) { String value = rs.getString(i); print(value + ""\t""); } However in the API documentation for the method getString(int) it's mentioned that indexes start with 1 so this should become: for (int i = 1; i <= cols; i++) { String value = rs.getString(i); print(value + ""\t""); } Second this implementation of ScriptRunner does not provide support for DELIMITER statements in the SQL script which are important if you need to compile TRIGGERS or PROCEDURES. So I have created this modified version of ScriptRunner: http://pastebin.com/ZrUcDjSx which I hope you'll find useful. this is very helpful. Thank you very much.  For simple sql script splitted by ';' you can use this simple function. It remove comments and run statements one by one  static void executeScript(Connection conn InputStream in) throws SQLException { Scanner s = new Scanner(in); s.useDelimiter(""/\\*[\\s\\S]*?\\*/|--[^\\r\\n]*|;""); Statement st = null; try { st = conn.createStatement(); while (s.hasNext()) { String line = s.next().trim(); if (!line.isEmpty()) st.execute(line); } } finally { if (st != null) st.close(); } }  Write code to: Read in a file containing a number of SQL statements. Run each SQL statement. If I do it like that I should parse the .sql file. I was expecting there was a jdbc's fuction which I couldn't find.  @Pantelis Sopasakis Slightly modified version on GitHub: https://gist.github.com/831762/ Its easier to track modifications there."
535,A,"Named parameters in JDBC Are there named parameters in JDBC instead of positional ones like the @name @city in the ADO.NET query below? select * from customers where name=@name and city = @city possible duplicate of [Using a variable instead of a parameter index with a JDBC prepared statement](http://stackoverflow.com/questions/1097855/using-a-variable-instead-of-a-parameter-index-with-a-jdbc-prepared-statement) Plain vanilla JDBC DOES NOT support named parameters. If you are using DB2 then using DB2 classes directly: Using named parameter markers with PreparedStatement objects Using named parameter markers with CallableStatement objects `NamedParameterStatement` is not a class in the Java API. True. Here is link to it: http://www.javaworld.com/javaworld/jw-04-2007/jw-04-jdbc.html  You can't use named parameters in JDBC itself. You could try using Spring framework as it has some extensions that allow the use of named parameters in queries.  To avoid including a large framework I think a simple homemade class can do the trick. Example of class to handle named parameters: public class NamedParamStatement { public NamedParamStatement(Connection conn String sql) throws SQLException { int pos; while((pos = sql.indexOf("":"")) != -1) { int end = sql.substring(pos).indexOf("" ""); if (end == -1) end = sql.length(); else end += pos; fields.add(sql.substring(pos+1end)); sql = sql.substring(0 pos) + ""?"" + sql.substring(end); } prepStmt = conn.prepareStatement(sql); } public PreparedStatement getPreparedStatement() { return prepStmt; } public ResultSet executeQuery() throws SQLException { return prepStmt.executeQuery(); } public void close() throws SQLException { prepStmt.close(); } public void setInt(String name int value) throws SQLException { prepStmt.setInt(getIndex(name) value); } private int getIndex(String name) { return fields.indexOf(name)+1; } private PreparedStatement prepStmt; private List<String> fields = new ArrayList<String>(); } Example of calling the class: String sql; sql = ""SELECT id Name Age TS FROM TestTable WHERE Age < :age OR id = :id""; NamedParamStatement stmt = new NamedParamStatement(conn sql); stmt.setInt(""age"" 35); stmt.setInt(""id"" 2); ResultSet rs = stmt.executeQuery(); Please note that the above simple example does not handle using named parameter twice. Nor does it handle using the : sign inside quotes. I used yours with a few small modifications. ` Pattern findParametersPattern = Pattern.compile(""(?Vanilla JDBC only supports named parameters in a CallableStatement (e.g. setString(""name"" name)) and even then I suspect the underlying stored procedure implementation has to support it. An example of how to use named parameters: //uss Sybase ASE sysobjects table...adjust for your RDBMS stmt = conn.prepareCall(""create procedure p1 (@id int = null @name varchar(255) = null) as begin "" + ""if @id is not null "" + ""select * from sysobjects where id = @id "" + ""else if @name is not null "" + ""select * from sysobjects where name = @name "" + "" end""); stmt.execute(); //call the proc using one of the 2 optional params stmt = conn.prepareCall(""{call p1 ?}""); stmt.setInt(""@id"" 10); ResultSet rs = stmt.executeQuery(); while (rs.next()) { System.out.println(rs.getString(1)); } //use the other optional param stmt = conn.prepareCall(""{call p1 ?}""); stmt.setString(""@name"" ""sysprocedures""); rs = stmt.executeQuery(); while (rs.next()) { System.out.println(rs.getString(1)); } Yes it is right but not all db's support this feature. I tested on postgresql it does not work. Yes obviously the database has to support named parameters first...and it appears postgres does not. The question implies their DB does support this and wants to understand how to use the feature in JDBC.  I ended up just creating my own wrapper meothod. in which I first sanitized the value being bound (you can find examples on Google) Then just used Java's String.replace() method to do replace the placeHolders. The biggest downfall is that you have to ensure that the variable is indeed safe for binding. Edit: I now just use Spring's Hibernate much better  JDBC does not support named parameters. Unless you are bound to using plain JDBC (which causes pain let me tell you that) I would suggest to use Springs Excellent JDBCTemplate which can be used without the whole IoC Container. NamedParameterJDBCTemplate supports named parameters you can use them like that:  NamedParameterJdbcTemplate jdbcTemplate = new NamedParameterJdbcTemplate(dataSource); MapSqlParameterSource paramSource = new MapSqlParameterSource(); paramSource.addValue(""name"" name); paramSource.addValue(""city"" city); jdbcTemplate.queryForRowSet(""SELECT * FROM customers WHERE name = :name AND city = :city"" paramSource); Thanks - but I can't use springs because I can't make that much change to existing codebase :( the point that @Malax is making is that you can use the NamedParameterJdbcTemplate from spring standalone. You wouldn't have to change any other parts of the code base. But you have to include many Spring JARs into your project just to use a few classes related to the NamedParameterJdbcTemplate. It's pitty the org.springframework.jdbc.jar cannot be used standalone."
536,A,"JDBC Jtds can't establish a connection I want to make a access to my sql database than is placed in ASUS\MSSQLSERVER1 and database names ""Test"" with access to user teste with password teste in java code I coded this: @Test public void TesteTemp() throws SQLException InstantiationException IllegalAccessException ClassNotFoundException { Class.forName(""net.sourceforge.jtds.jdbc.Driver"").newInstance(); String connString = ""jdbc:jtds:sqlserver://ASUS/Test;instance=MSSQLSERVER1;user=teste;password=teste;""; Connection conn = null; try{ conn = DriverManager.getConnection(connString); }catch(SQLException ex){ ex.printStackTrace(); } conn.close(); } And I receive this error: Server ASUS has no instance named MSSQLSERVER1. It makes sense? I have the MSSQLSERVER1 service running. i resolved the problem.. the code is ok the problem was than protocols for tcp/ip and named pipes were disabled i just activated them now runs ok.. Sql Configuration Manager > Sql Server Network Configuration > Protocols for"
537,A,"What is the best database to use with a java program? I've been struggling to get a Java program to connect to MS SQL Server and I'm starting to wonder if MySQL would be a better choice for my (learning) project. Sun's tutorials refer to Java DB but I've never heard of that in any other context so it seems not the most useful database to learn about. I appreciate any insight into the most natural way to connect Java to a commonly used database. The simplest way to connect to an external relational database (as opposed to an in memory database like berkeley db) is via JDBC. You should get familiar with JDBC before you progress on to any other storage methods. For most projects you will be fine using either mysql or postgresql. Don't worry about deciding on one over the other for smaller projects the differences are not that relevant. As long as you are using jdbc you will be ble to switch between the two later if you really need to. To get started I would download mysql and follow the jdbc tutorial on the sun site http://java.sun.com/docs/books/tutorial/jdbc/index.html ). At a later date you may decide you need to use an object-relational-mapping tool like hibernate but I would not worry about that now either just get familiar with jdbc and either mysql or postgresql.  The kind or the name of Database won't affect your education process as you will work with JDBC. I think you can go with any. Just set up it in the proper way on your machine and connect with appropriate connection string.  Microsoft even has documentation on its website. Google keywords were ""jdbc sql server"". http://msdn.microsoft.com/en-us/data/aa937724.aspx  You could try either PostgreSQL or MySQL  I recommend MySQL or Oracle. From Oracle you can get free database as well however size of the database is limited. Reasoning for this is that those are most used databases and it's good to get some visibility for those. Use JDBC and it's similar interface but doing code on top of the database and there are other things you need to learn as well. Especially if you do any application which is bit more complex. Also getting hands dirty with basic operations with database is always good. Oracle is only free as long as you do not put it into production.  Perhaps you could describe the problems you've been having with connecting to MS SQL. Of course it's possible so it's likely something small that you have or have not done that's preventing the connection from working. There are many open source database servers with JDBC drivers. One that you might consider is HSQLDB which has a completely in-memory mode so you don't even have to think about setting up a server. This is probably a great way to learn the basics of SQL. Beside HSQLDB H2 (http://www.h2database.com/) may be also a good choice to learn database programming. Personally I prefer H2 to HSQLDB because of its good web gui and better transaction isolation.  Java DB is Apache Derby rebranded and included in the JDK. It is ok and it is much easier to install than natively running databases. It is very important to use a good driver to the database! That might solve all your connection problems. Also note that if you switch database you most likely also need to change your SQL unless you use a layer like Hibernate or JPA. Derby is probably not a great DBMS to learn with. It's painfully slow and lacks a lot in the SQL area. Last I'd used it (6 months ago) this included the ""MERGE""/""INSERT... ON DUPLICATE KEY"" DML statement and the LIMIT/OFFSET options on queries. Among many other missing features. I'd appreciate links to good pages describing the ""painfully slow"" part. LIMIT/OFFSET's are database dependent so it is probably called something else.  Pick one database that you can figure out how to install. Most are pretty easy and it will give you a good idea of what using a database is like. Once you have a working app try porting it to another database. I would recommend using JavaDB for the first one and then one of the other db - Oracle MySQL Postgres etc.  The biggest issue that I've had with using MSSql is when using the antiquated JDBC -> ODBC Bridge drivers; these do a half-assed Java wrapper around the ODBC calls which are flaky and fragile. If you are using JDBC ODBC Bridge replace them with the latest native JDBC drivers from microsoft- they work a million times better.  Anything with a JDBC driver should work fine. I don't think you will ever find a definitive answer to what is ""best"" it is a very subjective question. We use InterBase at my work and have no problems.  If you want to stay in Java one option is Berkeley DB Java Edition. It's the same BDB software that was from Sleepycat which had a sterling reputation in the embedded database market."
538,A,"Spring JDBC connection pool and InputStream results I am writing a webservice that allows users to post files and then retrieve them at a URL (basically think of it as the RESTful Amazon S3). The issue I came across was rather then return a byte[] from my Oracle query (Spring JDBC) I am returning an InputStream and then streaming the data back to the client in chunks. This (IMO) is a much better idea since I put no size restriction on the file and I don't want 2GB byte arrays in memory. At first it seemed to work fine but I ran into a case during heavy load that sometimes a Connection would get reused before the previous servlet could send the file. It seems after the JDBC call that returned the InputStream the Connection would be returned to the pool (Spring would call conn.close() but not clear the associated ResultSet). So if no other request was given that Connection then the InputStream would still be valid and could be read from but if the Connection was given to a new request then the InputStream would be null and the previous request would fail. My solution was to create a subclass of InputStream that also takes a Connection as a constructor arg and in the overridden public close() method also close the Connection. I had to ditch the Spring JDBC and just make a normal PreparedStatement call otherwise Spring would always return the connection to the pool. public class ConnectionInputStream extends InputStream { private Connection conn; private InputStream stream; public ConnectionInputStream(InputStream s Connection c) { conn = c; stream = s; } // all InputStream methods call the same method on the variable stream @Override public void close() throws IOException { try { stream.close(); } catch (IOException ioex) { //do something } finally { try { conn.close(); } catch (SQLException sqlex) { //ignore } } } } Does anyone have a more elegant solution or see any glaring problems with my solution? Also this code wasn't cut/paste from my actual code so if there is a typo just ignore it. You may want to also close the `PreparedStatement`. Unfortunately my imagination went wild when you asked this question. I don't know if this solution is considered more elegant. However these classes are simple and easily re-usable so you may find a use for them if they are not satisfactory. You will see everything coming together at the end... public class BinaryCloseable implements Closeable { private Closeable first; private Closeable last; public BinaryCloseable(Closeable first Closeable last) { this.first = first; this.last = last; } @Override public void close() throws IOException { try { first.close(); } finally { last.close(); } } } BinaryCloseable is used by CompositeCloseable: public class CompositeCloseable implements Closeable { private Closeable target; public CompositeCloseable(Closeable... closeables) { target = new Closeable() { public void close(){} }; for (Closeable closeable : closeables) { target = new BinaryCloseable(target closeable); } } @Override public void close() throws IOException { target.close(); } } The ResultSetCloser closes ResultSet objects: public class ResultSetCloser implements Closeable { private ResultSet resultSet; public ResultSetCloser(ResultSet resultSet) { this.resultSet = resultSet; } @Override public void close() throws IOException { try { resultSet.close(); } catch (SQLException e) { throw new IOException(""Exception encountered while closing result set"" e); } } } The PreparedStatementCloser closes PreparedStatement objects: public class PreparedStatementCloser implements Closeable { private PreparedStatement preparedStatement; public PreparedStatementCloser(PreparedStatement preparedStatement) { this.preparedStatement = preparedStatement; } @Override public void close() throws IOException { try { preparedStatement.close(); } catch (SQLException e) { throw new IOException(""Exception encountered while closing prepared statement"" e); } } } The ConnectionCloser closes Connection objects: public class ConnectionCloser implements Closeable { private Connection connection; public ConnectionCloser(Connection connection) { this.connection = connection; } @Override public void close() throws IOException { try { connection.close(); } catch (SQLException e) { throw new IOException(""Exception encountered while closing connection"" e); } } } We now refactor your original InputStream idea into: public class ClosingInputStream extends InputStream { private InputStream stream; private Closeable closer; public ClosingInputStream(InputStream stream Closeable closer) { this.stream = stream; this.closer = closer; } // The other InputStream methods... @Override public void close() throws IOException { closer.close(); } } Finally it all comes together as: new ClosingInputStream( stream new CompositeCloseable( stream new ResultSetCloser(resultSet) new PreparedStatementCloser(statement) new ConnectionCloser(connection) ) ); When this ClosingInputStream's close() method is called this is effectively what happens (with exception handling omitted for clarity's sake): public void close() { try { try { try { try { // This is empty due to the first line in `CompositeCloseable`'s constructor } finally { stream.close(); } } finally { resultSet.close(); } } finally { preparedStatement.close(); } } finally { connection.close(); } } You're now free to close as many Closeable objects as you like. It would probably be easier just to pass a list (stack array whatever) of Closeables and close them all rather then needing it to be specific to Preparestatement Connection etc. Also when you close a Connection it is supposed to close all underlying resources associated with that connection (such as Statements and ResultSets). I do appreciate the effort though your code has a similar fell to my minimal example. Going to accept this answer as in the end this is almost exactly the same way I solved this issue.  Why not read the entire InputStream/byte[]/whatever from the query before releasing the query yourself? It sounds like you are trying to return data from the query after your code has told Spring / the pool that you are done with the connection. Because the InputStream is being passed back to the controller from the DAO. Once Spring JDBC completes a call it immediately calls connection.close(). I'm not going to pass the ServletResponse all the way into the data access layer. What I meant was read the contents of the InputStream completely from the resultset/connection to some sort of intermediate datatype and then return a new InputStream wrapping that datatype. This way you read all of the contents of the file prior to closing the connection. In other words I don't think you can return a reference to an InputStream (which will read from an underlying connection) and then close the connection prior to reading the stream But that would completely invalidate the point of returning the Inputstream. If I read the entire contents of the InputStream then I have just [possibly] loaded 2GB of data into memory - exactly what I do not want to do. I want to write out 10K chunks of the file and have the client read them from the the Outputstream of the response."
539,A,"Can someone explain this JDBC Exception to me? I'm gettting the following exception when performing an insert to an Oracle Databse using JDBC. java.sql.SQLRecoverableException: Io exception: Unexpected packet What could cause this and how can I recover from it? The application I'm writing performs an aweful lot of updates the the databse in rapid succession. Judging from the exception I'd assume it's a network issue however the Database is on the same box as my Application. I don't have a stack trace and this is one of those irritating ""Works on my machine"" problems"" where it Borks when I put it on a client site. Unfortunately I've got to throw together something that will fix this/diagnose but the client site only throws data to my app between 5pm and 9 pm when I'm out of the office... I've got a few hours to work out my contingencies though... Any thoughts. Problem solved: It was a synchronization issue. I'm fairly sure I resolved this and it was because there were multiple threads using the same driver. Did you find a solution for your problem? Was it related to multithreading? Sounds like a driver problem is there an updated driver for the server version you're using? Also make sure you don't have older versions of the ojdbc jar in your classpath.  How many inserts in a batch? Under some conditions its advisable to have a commit-threshold in a transaction. If you're doing transactions you should keep aware of that. btw any stack traces?  Any unclosed cursors/resultssets? There are no result sets it's an insert only system. Another system recives the data... assuming it ever gets there... :( This does not provide an answer to the question. To critique or request clarification from an author leave a comment below their post.  Are you per any chance using multiple threads and forgot synchronization? yes probably. I'll see if that's the root cause."
540,A,"MS Access - Can't Open Any More Tables using JdbcOdbcDriver at work we have to deal with several MS Access mdb files so we use the default JdbcOdbcBridge Driver which comes with the Sun JVM and for most cases it works great. The problem is that when we have to deal with some larger files we face several times exceptions with the message ""Can't open any more tables"". How can we avoid that? We already close all our instances of PreparedStatements and RecordSets and even set their variables to null but even so this exception continues to happen. What should we do? How can we avoid these nasty exceptions? Does someone here knows how? Is there any additional configuration to the ODBC drivers on Windows that we can change to avoid this problem? Any code to share? There's an outside chance that you're simply running out of free network connections. We had this problem on a busy system at work. Something to note is that network connections though closed may not release the socket until garbage collection time. You could check this with NETSTAT /A /N /P TCP. If you have a lot of connections in the TIME_WAIT state you could try forcing a garbage collection on connection closes or perhaps regular intervals. Great tip! I'll check this out. Actually I always set my instances of Connection PreparedStatement and ResultSet while working with Access to null exactly because the JdbcOdbcDriver doesn't close them if they are not null. I checked this out with some experiments in our company. But what amazes me is the fact that untill now NO patch was made for this issue.  I had the same problem but none of the above was working. I eventualy locataed the issue. I was using this to read the value of a form to put back into a lookup list record source. LocationCode = [Forms]![Support].[LocationCode].Column(2) ContactCode = Forms(""Support"")(""TakenFrom"") Changed it to the below and it works. LocationCode = Forms(""Support"")(""LocationCode"") ContactCode = Forms(""Support"")(""TakenFrom"") I know I should have written it better but I hope this helps someone else in the same situation. Thanks Greg  You should also close your Connection object. Looking into an alternative for the jdbc odbc driver would also be a good idea. Don't have any experience with an alternative myself but this would be a good place to start: http://stackoverflow.com/questions/732264/is-there-an-alternative-to-using-sun-jdbc-odbc-jdbcodbcdriver I agree that the jdbcodbc driver is far from good. We face many many many problems with it daily. Unfortunetely we have some budget restraints that doesn´t allow us to buy any other alternative driver :( And actually we close all the connections. What pisses me off about it is that in this case we are doing everything exactly like all the books (we hope the goods :)) say!  ""Can't open any more tables"" is a better error message than the ""Can't open any more databases"" which is more commonly encountered in my experience. In fact that latter message is almost always masking the former. The Jet 4 database engine has a limit of 2048 table handles. It's not entirely clear to me whether this is simultaneous or cumulative within the life of a connection. I've always assumed it is cumulative since opening fewer recordsets at a time in practice seems to make it possible to avoid the problem. The issue is that ""table handles"" doesn't just refer to table handles but to something much more. Consider a saved QueryDef with this SQL:  SELECT tblInventory.* From tblInventory; Running that QueryDef uses TWO table handles. What? you might ask? It only uses one table! But Jet uses a table handle for the table and a table handle for the saved QueryDef. Thus if you have a QueryDef like this:  SELECT qryInventory.InventoryID qryAuthor.AuthorName FROM qryInventory JOIN qryAuthor ON qryInventory.AuthorID = qryAuthor.AuthorID ...if each of your source queries has two tables in it you're using these table handles one for each:  Table 1 in qryInventory Table 2 in qryInventory qryInventory Table 1 in qryAuthor Table 2 in qryAuthor qryAuthor the top-level QueryDef So you might think you have only four tables involved (because there are only four base tables) but you'll actually be using 7 table handles in order to use those 4 base tables. If in a recordset you then use the saved QueryDef that uses 7 table handles you've used up yet another table handle for a total of 8. Back in the Jet 3.5 days the original table handles limitation was 1024 and I bumped up against it on a deadline when I replicated the data file after designing a working app. The problem was that some of the replication tables are open at all times (perhaps for each recordset?) and that used up just enough more table handles to put the app over the top. In the original design of that app I was opening a bunch of heavyweight forms with lots of subforms and combo boxes and listboxes and at that time I used a lot of saved QueryDefs to preassemble standard recordsets that I'd use in many places (just like you would with views on any server database). What fixed the problem was: loading the subforms only when they were displayed. loading the rowsources of the combo boxes and listboxes only when they were onscreen. getting rid of all the saved QueryDefs and using SQL statements that joined the raw tables wherever possible. This allowed me to deploy that app in the London office only one week later than planned. When Jet SP2 came out it doubled the number of table handles which is what we still have in Jet 4 (and I presume the ACE). In terms of using Jet from Java via ODBC the key point would be I think: use a single connection throughout your app rather than opening and closing them as needed (which leaves you in danger of failing to close them). open recordsets only when you need them and clean up and release their resources when you are done. Now it could be that there are memory leaks somewhere in the JDBC=>ODBC=>Jet chain where you think you are releasing resources and they aren't getting released at all. I don't have any advice specific to JDBC (as I don't use it -- I'm an Access programmer after all) but in VBA we have to be careful about explicitly closing our objects and releasing their memory structures because VBA uses reference counting and sometimes it doesn't know that a reference to an object has been released so it doesn't release the memory for that object when it goes out of scope. So in VBA code any time you do this:  Dim db As DAO.Database Dim rs As DAO.Recordset Set db = DBEngine(0).OpenDatabase(""[database path/name]"") Set rs = db.OpenRecordset(""[SQL String]"") ...after you've done what you need to do you have to finish with this:  rs.Close ' closes the recordset Set rs = Nothing ' clears the pointer to the memory formerly used by it db.Close Set db = Nothing ...and that's even if your declared variables go out of scope immediately after that code (which should release all the memory used by them but doesn't do so 100% reliably). Now I'm not saying this is what you do in Java but I'm simply suggesting that if you're having problems and you think you're releasing all your resources perhaps you need to determine if you're depending on garbage collection to do so and instead need to do so explicitly. Forgive me if I'd said anything that's stupid in regard to Java and JDBC -- I'm just reporting some of the problems that Access developers have had in interacting with Jet (via DAO not ODBC) that report the same error message that you're getting in the hope that our experience and practice might suggest a solution for your particular programming environment. David this is an AWESOME explanation about this issue! Thanks you very much! Actually does Jet4 works with Access 97? Is it possible to configure the number of database handles I can use with Jet? If so how should I do that? A97 uses only Jet 3.5 but as long as you have the last service release of Jet 3.5 it has the same limit as Jet 4.0. This is not user configurable -- it's a hard top limit. +1 from me. This is incredibly thorough."
541,A,"Parameterized Oracle SQL query in Java? I've been trying to figure out why the following code is not generating any data in my ResultSet: String sql = ""SELECT STUDENT FROM SCHOOL WHERE SCHOOL = ? ""; PreparedStatement prepStmt = conn.prepareStatement(sql); prepStmt.setString(1 ""Waterloo""); ResultSet rs = prepStmt.executeQuery(); On the other hand the following runs properly: String sql = ""SELECT STUDENT FROM SCHOOL WHERE SCHOOL = 'Waterloo' ""; PreparedStatement prepStmt = conn.prepareStatement(sql); ResultSet rs = prepStmt.executeQuery(); The data type for SCHOOL is CHAR (9 Byte). Instead of setString I also tried: String sql = ""SELECT STUDENT FROM SCHOOL WHERE SCHOOL = ? ""; PreparedStatement prepStmt = conn.prepareStatement(sql); String school = ""Waterloo""; Reader reader = new CharArrayReader(school.toCharArray()); prepStmt.setCharacterStream(1 reader 9); prepStmt.setString(1 ""Waterloo""); ResultSet rs = prepStmt.executeQuery(); I'm completely stuck on what to investigate next; the Eclipse debugger says the SQL query doesn't change even after setString or setCharacterStream. I'm not sure if it's because setting parameters isn't working or if the debugger simply can't pick up changes in the PreparedStatement. Any help will be greatly appreciated thanks! I tried changing the field and table names to make it easier to understand so the actual column name is different than the table name. I guess that backfired! Need to construct better examples next time =) Two things to check: 1) Does it still happen if you don't use a table where one of the columns has the same name as the table? 2) Are you sure you're iterating over the result set properly - if you hard-code the query instead of using a parameter do you get results? For what it's worth your first example looks fine to me. Jon might be onto something with the `School` column in the `School` table - this *shouldn't* be a problem but then your code *shouldn't* fail... Just out of curiosity try the first example (the one with the `?`) but set the parameter to `""Waterloo ""` with a trailing space. MySQL is supposed to disregard trailing spaces but maybe the driver is doing something funky in this case. I think the problem is that your datatype is CHAR(9) and ""Waterloo"" has only 8 chars. I assume that this would return the expected results (LIKE and %). Or add the missing space. String sql = ""SELECT STUDENT FROM SCHOOL WHERE SCHOOL LIKE ? ""; PreparedStatement prepStmt = conn.prepareStatement(sql); prepStmt.setString(1 ""Waterloo%""); ResultSet rs = prepStmt.executeQuery(); The best way would by to use varchar instead of char if your Strings have a flexible length. Then the PreparedStatement would work as expected. A workaround would be to use the Oracle specific setFixedCHAR method (but it's better to change the datatype to varchar if possible). The following is from Oracle's PreparedStatement JavaDoc: CHAR data in the database is padded to the column width. This leads to a limitation in using the setCHAR() method to bind character data into the WHERE clause of a SELECT statement--the character data in the WHERE clause must also be padded to the column width to produce a match in the SELECT statement. This is especially troublesome if you do not know the column width. setFixedCHAR() remedies this. This method executes a non-padded comparison. Notes: Remember to cast your prepared statement object to OraclePreparedStatement to use the setFixedCHAR() method. There is no need to use setFixedCHAR() for an INSERT statement. The database always automatically pads the data to the column width as it inserts it. The following example demonstrates the difference between the setString() setCHAR() and setFixedCHAR() methods. // Schema is : create table my_table (col1 char(10)); // insert into my_table values ('JDBC'); PreparedStatement pstmt = conn.prepareStatement (""select count() from my_table where col1 = ?""); ResultSet rs; pstmt.setString (1 ""JDBC""); // Set the Bind Value rs = pstmt.executeQuery(); // This does not match any row // ... do something with rs CHAR ch = new CHAR(""JDBC "" null); ((OraclePreparedStatement)pstmt).setCHAR(1 ch); // Pad it to 10 bytes rs = pstmt.executeQuery(); // This matches one row // ... do something with rs ((OraclePreparedStatement)pstmt).setFixedCHAR(1 ""JDBC""); rs = pstmt.executeQuery(); // This matches one row // ... do something with rs Thanks! I really wish I could change the datatype but it's a protected database and I can only query it."
542,A,"Using Sybase ASE 12.5.4 with jTDS drivers with JRuby Problem I am trying to build a small ruby script - which will be run using jruby once a day - to connect to a Sybase ASE 12.5.4 database and perform a complex query. Ultimately I intend to do some processing on the data and insert the new data in a MySQL table for use within a rails application. Environment jruby v1.4.0 java v1.6.0_15 on Ubuntu Karmic JRuby Installed Gems activerecord-jdbc-adapter (0.9.1) activerecord-2.3.4 Jruby Lib Directory jtds-1.2.5 Query SET rowcount 10 SELECT * FROM TEST_TABLE Code Snippet require 'java' require 'jtds-1.2.5.jar' require 'rubygems' require 'active_record' config = { :username => 'railstest' :password => 'railstest' :adapter => 'jdbc' :dialect => 'sybase' :host => 'localhost' :database => 'railstest' :port => '5000' :driver => 'net.sourceforge.jtds.jdbc.Driver' :url => 'jdbc:jtds:sybase://localhost:5000/railstest' } ActiveRecord::Base.establish_connection(config).connection.execute(-- QUERY --) I can confirm this connects to the DB. Although I am having issues just selecting 10 rows from a database table. Produces For execute method: /usr/local/bin/jruby-1.4.0/lib/ruby/gems/1.8/gems/activerecord-2.3.5/lib/active_record/connection_adapters/abstract_adapter.rb:219:in `log': ActiveRecord::ActiveRecordError: The executeUpdate method must not return a result set.: SET rowcount 10 SELECT * FROM TEST_TABLE (ActiveRecord::StatementInvalid) from /usr/local/bin/jruby-1.4.0/lib/ruby/gems/1.8/gems/activerecord-jdbc-adapter-0.9.2/lib/active_record/connection_adapters/jdbc_adapter.rb:559:in `execute' from db-test.rb:21 For select_rows method: /usr/local/bin/jruby-1.4.0/lib/ruby/gems/1.8/gems/activerecord-2.3.5/lib/active_record/connection_adapters/abstract_adapter.rb:219:in `log': ActiveRecord::ActiveRecordError: The executeUpdate method must not return a result set.: SET rowcount 10 SELECT * FROM TEST_TABLE (ActiveRecord::StatementInvalid) from /usr/local/bin/jruby-1.4.0/lib/ruby/gems/1.8/gems/activerecord-jdbc-adapter-0.9.2/lib/active_record/connection_adapters/jdbc_adapter.rb:559:in `execute' from /usr/local/bin/jruby-1.4.0/lib/ruby/gems/1.8/gems/activerecord-jdbc-adapter-0.9.2/lib/active_record/connection_adapters/jdbc_adapter.rb:629:in `select' from /usr/local/bin/jruby-1.4.0/lib/ruby/gems/1.8/gems/activerecord-jdbc-adapter-0.9.2/lib/active_record/connection_adapters/jdbc_adapter.rb:550:in `select_rows' from db-test.rb:21 The error states that I should not return a results set but it doesn't matter which method I use execute select_rows etc nothing works. One more thing regarding queries. My original query is rather complex I decalre variables drop temporary tables and create temporary tables as well as populate and select from them. Using Squirrel SQL I can execute once and gain a result. Using DBI I was unable to do this in one execution does anyone know if I can just execute the whole thing once or will I have to split it up? Would anyone be able to give me any assistance please? Am I using jTDS properly? Many thanks in advance. Is the `SET rowcount 10` part of the query you are trying to execute? I had been using the Sybase drivers for sometime as suggested by @lollipopman which was helpful in getting going but as I built more complex queries I kept running into issues so I tried to revisit the original problem and with an hour or so I go it working. Find the open source jTDS drivers here require java require jtds-1.2.5.jar require rubygems require dbi dbh = DBI.connect('dbi:Jdbc:jtds:sybase://<host>:<port>/<db>' <username> <password> {'driver' => 'net.sourceforge.jtds.jdbc.Driver'} ) And that is all that is needed to connect to your Sybase Database with JRuby and DBI Hope this helps someone!  not entirely relevant but this is what is required when using jruby sybase jdbc and dbi: require 'java' require './jars/jTDS3.jar' require './jars/jconn3.jar' require ""rubygems"" require ""dbi"" dbh = DBI.connect('dbi:Jdbc:sybase:Tds:foobar:2460/testdb' 'sa' 'password' {'driver' => 'com.sybase.jdbc3.jdbc.SybDriver'} ) Glad to here you got it working I am not using ruby on rails so DBI is sufficient for my scripting needs. I tried this and I can connect to my Database - thanks lollipopman For anyone reading this you need to download the drivers from the Sybase website: http://www.sybase.com/products/allproductsa-z/softwaredeveloperkit/jconnect Register and download the archive - you need jTDS3.jar and jconn3.jar which can be found in the archive in the classes folder. I still would prefer to use ActiveRecord and will pursue how to get this resolved. @lollipopman why DBI drivers? Does this give you better performance? @lollipopman: Although i use rails this is for a cron process which will run once a day and populate a table which will be used by the rails app. I just wanted to use active record within the ruby script As I said I have something working now sow will continue with this path for now @lollipopman: have you had any issues getting column names using DBI drivers? I posted this issue here: http://stackoverflow.com/questions/1530329/jrruby-sybase-jdbc-and-dbi-fetching-column-name-with-the-as-clause-issue  Note : you are saying ""set rowcount"" and ""select"". These are two different statements - they both get results even if it's ""0 rows"" ... So you ARE getting a resultset. Try to execute those separately. Agreed this is part of the issue and have resolved. Can I ask your advice on which method to use to return a result set. I keep getting a FIXNUM object ie. a number of results. This is all very experimental for me"
543,A,"What is the best way/template to set up connection mysql and jdbc? What is the best way to set up connection with mysql's jdbc? And execute simple statement. How to do that? Thank you. The best way is dependent on your requirements so more information would help answer this. Are you intending to deploy to a servlet engine eg Tomcat? Standalone application - thick client. This is the twenty first century - use a JPA (ORM) implementation. But if you insist on going back to the metal (at the risk of down votes) - There are many ways of getting a JDBC connection from some driver. Using reflection with a hardwired class name is the commonest and perhaps most brain damaged. If you're going to hardwire a class name you might as well as get the benefits of normal code (compiler catches typos no extraneous exceptions to deal with easier to read explicit dependencies better tool support etc). Also get in to the habit of clearing up resources safely. So: public static void main(String[] args) throws SQLException { Driver driver = new com.mysql.jdbc.Driver(); Connection connection = driver.connect( ""jdbc:mysql://mydatabase"" new java.util.Properties() {{ put(""user"" ""fred""); }} ); try { PreparedStatement statement = connection.prepareStatement( ""SELECT insideLeg FROM user WHERE name=?"" ); try { statement.setString(1 ""jim""); ResultSet results = statement.executeQuery(); try { if (results.next() { System.out.println(""= ""+results.getLong(1)); } else { System.out.println(""Missing.""); } } finally { results.close(); } } finally { statement.close(); } } finally { connection.close(); } } What a mess! And it doesn't even use transactions yet. Yes use an ORM. They're very respectable these days. You wont need to do all that for every single statement. You don't want to go around creating instantiating drivers every time. In particular the execute around idiom is useful.  Her is a very small sample which illustrates it: http://web.njit.edu/all_topics/Servers/MySQL/Docs/mySample.java.html  The basic boilerplate for MySQL/JDBC goes something like this: Get the connection: Class.forName(""com.mysql.jdbc.Driver"").newInstance(); Connection conn = DriverManager.getConnection(""jdbc:mysql://databaseName""); Execute the statement: Statement stmt = conn.createStatement(); ResultSet rs = stmt.executeQuery(""SELECT * from tableName""); while (rs.next()) { System.out.println(rs.getString(1)); } Close the statement and connection: rs.close(); stmt.close(); conn.close(); You just need to make sure you have the driver installed and/or in your CLASSPATH. Class.forName is not required anymore  Here's the sun documentation for creating a JDBC connection. From there it's easy to get access to a Statement object and run some simple SQL. For production level systems you'll probably also want to create a connection pool.  Use Spring Framework's JDBC abstraction framework - all you need to do is create a context XML file and use the JDBC template class. Just a few lines of XML + Java code will get you going. The advantage is keeping your connection details out of compiled Java. See: http://www.springbyexample.org/examples/simple-spring-jdbc-template.html  It depends on your case. If you simply need to execute some queries from standalone application then you should use single connection like: Class.forName (""yourDriverName""); Connection cn = DriverManager.getConnection (""db url""); Statement st = cn.createStatement (); ResultSet rs = st.executeQuery (""select * from foo""); while (rs.next()) { doSmth (); } rs.close (); st.close (); cn.close (); But if you are developing real application (specially web-application) then use DataSource's. Read manual of your DB and Web-server how to configure datasource. DataSource allows you to use connection-pooling - it'll nessecary to increase performance. Configuring DataSource isn't difficult process."
544,A,Spring JDBC & MultiThreading Which datasource best supports multi-threading in Spring? JDBC Connections are not thread-safe. You have to manage that yourself. If you're using Spring in a web app it's usually one thread per request. If you pool your connections that will mean the thread gets its connection from the pool uses it and returns it to the pool. If you don't share it you're unlikely to have issues.  To support multi-threading you would need to use a data source that supports connection pooling so that each thread can use its own connection. The most common database connection pools are Commons DBCP and C3p0 and can be easily integrated with Spring. yes Mark ..using C3P0 resolved my issues greatly :)! DBCP is fairly outdated!
545,A,"Postgresql JDBC and streaming BLOBs I am trying to retrieve a blob from a postgres database using the jdbc drivers. It is too big to have in memory so I want to stream it as a download. I tried using the getBinaryStream method on ResultSet but it turns out that this method actually reads it all into memory so doesn't work for large file. Apparently one can use the getBlob method on the resultset and the presumeably get the inputstream from the blob and go from there but that is where I run into my problem. PreparedStatement ps = con.prepareStatement(""select data from file_data WHERE ID = ?""); ps.setLong(1file.fileData.id) ResultSet rs = ps.executeQuery() if(rs.next()){ rs.getBlob(""data"") That is the code I'm running. When it gets to that last line it throw out an error that I cannot make sense of... org.postgresql.util.PSQLException: Bad value for type long : xxxxxx ""xxxxxx"" then is the contents of the file. You can imagine that gets quite long but not really the point. I'm stuck here. Does anyone have any ideas on what is going on? Heck I'll even take alternative methods for streaming large blobs as a download. In my case it was `rs.getBlob(...)` instead of `rs.getBinaryStream(...)`. Never late to learn JDBC. Would the PostgreSQL docs for ""Storing Binary Data"" help? http://jdbc.postgresql.org/documentation/head/binary-data.html The section titled ""Retrieving the image from the Large Object"" its at the bottom of the page might help.  My guess is that you have mixed up OID and BYTEA style blobs. Large binary objects are stored indirecty with OID columns in Postgres. The actual file data is stored somewhere outside the database table by Postgres. The column just contains an object identifier that is associated internally with the blob. For instance: janko=# CREATE TABLE blobtest1 (name CHAR(30) image OID); CREATE TABLE janko=# INSERT INTO blobtest1 VALUES ('stackoverflow' lo_import('/tmp/stackoverflow-logo.png')); INSERT 0 1 janko=# SELECT * FROM blobtest1; name | image --------------------------------+------- stackoverflow | 16389 (1 row) If you use the ResultSet#getBlob(String) method than an OID style column is expected. getBlob reads the data from the column and converts it to a Long. Then it tries to read the associated binary data from its internal storage. On the other hand with BYTEA you can place small pieces of binary data directly in your DB. For instance: janko=# CREATE TABLE blobtest2 (name CHAR(30) image BYTEA); CREATE TABLE janko=# INSERT INTO blobtest2 VALUES ('somebinary' E'\\336\\255\\276\\357\\336\\255\\276\\357'); INSERT 0 1 janko=# SELECT * FROM blobtest2; name | image --------------------------------+---------------------------------- somebinary | \336\255\276\357\336\255\276\357 (1 row) Here the data column directly contains the binary data. If you try to use getBlob on such a column the data will still be interpreted as an OID but obviously it will not fit into a Long. Let's try this on the database we just created: groovy:000> import java.sql.* ===> [import java.sql.*] groovy:000> Class.forName(""org.postgresql.Driver""); ===> class org.postgresql.Driver groovy:000> db = DriverManager.getConnection(""jdbc:postgresql:janko"" ""janko"" ""qwertz""); ===> org.postgresql.jdbc4.Jdbc4Connection@3a0b2c64 groovy:000> ps = db.prepareStatement(""SELECT image FROM blobtest2 WHERE name = ?""); ===> SELECT image FROM blobtest2 WHERE name = ? groovy:000> ps.setString(1 ""somebinary"") ===> null groovy:000> rs = ps.executeQuery() ===> org.postgresql.jdbc4.Jdbc4ResultSet@66f9104a groovy:000> rs.next() ===> true groovy:000> rs.getBlob(""image"") ERROR org.postgresql.util.PSQLException: Bad value for type long : \336\255\276\357\336\255\276\357 at org.postgresql.jdbc2.AbstractJdbc2ResultSet.toLong (AbstractJdbc2ResultSet.java:2796) at org.postgresql.jdbc2.AbstractJdbc2ResultSet.getLong (AbstractJdbc2ResultSet.java:2019) at org.postgresql.jdbc4.Jdbc4ResultSet.getBlob (Jdbc4ResultSet.java:52) at org.postgresql.jdbc2.AbstractJdbc2ResultSet.getBlob (AbstractJdbc2ResultSet.java:335) at groovysh_evaluate.run (groovysh_evaluate:3) ..."
546,A,"How to handle parent key constraints in jdbc transactions? I have 2 tables named T1 and T2. Where T1 is parent and T2 is child. The scenario is I started a jdbc transaction and then insert a row in T1 and then try to insert a row in T2. Inserting row in T2 gies me ""Integrity Constraint-Parent key not found"" exception. How i handle this scenario ?  Connection con; try{ con = ConnectionPool.getConnection(); con.setAutoCommit(false); int T1Id = getNewId(""T1""); // from sequence; int T2Id = getNewId(""T2""); // from sequence; Insert in to table T1(t1IdtName) values (T1Id'A') Insert in to table T2(t2Id t1IdtName) values (T2IdT1Id'A')//Here Exception raises con.commit(); }catch(Exception e){ try {con.rollback();} catch (SQLException e) {} }finally{ try {con.setAutoCommit(true);} catch (SQLException e) {} ConnectionPool.returnConnection(con); } Using JDBC API struts1.2 Oracle10 G Database you should show your **actual** JDBC code. Not a pseudo-sql code. Not real Java code. I'll vote to close this. You are probably doing something wrong. If both inserts are within the same transaction what you've just mentioned can't happen. Please share some code and more information (DB server table structures) to see if we can help you. did you understand my question ? Yes I did. And I am telling you that it can't happen if you do both inserts within the same transaction. We still need more info to help you. My friend now here is the actual code  You need a three step process: INSERT row into parent SELECT the generated key from the parent Use the generated key and the child information to INSERT into the child It should be a single unit of work so make it transactional. It's impossible to tell from your pseudo code. It'd also be helpful to know whether or not you're using auto generated keys. I'm guessing that the primary key you're assuming for T1 doesn't actually appear. If T2 says the foreign key cannot be null or is required and it doesn't appear in T1 then the RDBMS system should complain and throw an exception. I am doing step 1 and 3. Skip step2 because i already have newly generated id got from sequence. All 3 steps are already in a transaction. ""m guessing that the primary key you're assuming for T1 doesn't actually appear. If T2 says the foreign key cannot be null or is required and it doesn't appear in T1 then the RDBMS system should complain and throw an exception."" Yes this is scenario primarykey for T1 doesn't appears becuase of transaction. You need to either generate a key that you can INSERT into both OR do the equivalent of a flush without committing. T1 is parent table and i have T1's primary key. Then i use this key int T2's table where T1's key as foreign key. Now when i execute T2's insert SQL then the ""Parent keynot found"" exception raises and transaction is rolled back. Yes so you've said three times now. There's no new information here. Can't help you if you just keep repeating the same story over and again. That's not Java code. Still pseudo code. I'll vote to close this."
547,A,"Oracle JDBC Euro character We have a problem with the Euro character when saving and retrieving it from a Oracle 10g using the Oracle 10.2.0.3 JDBC driver. The problem only occurs during a JUnit test running under Linux. The Euro characters returned from database after saving are total screwed up. Oracle has been configured to use character set ""WE8MSWIN1252"". Could it be that Linux cannot work with this character set? It's quite possible; code page 1252 is Microsoft's own extension of ISO-8859-1 (a.k.a. Latin-1) and it's rarely used on Linux which tends to use the latter. The euro symbol is not part of Latin-1 that may be why it can't be displayed properly on Linux. Can you not use UTF-8? It will work the same way on both sides.  It's not a Linux thing. It's a known Oracle bug in the retrieve code of the jdbc driver. There's a patch available but you'll need access to Oracle Metalink to download it. The other alternative suggested there is to use the OCI driver instead of the thin one. That may or may not be an option for you. EDIT: This bug which existed in the 10.2.0.3 driver is fixed in the 10.2.0.4 jdbc driver."
548,A,setting persistence context to read-only in jpa we are going to be working with an old database. so it is very crucial that we do not modify the database/table/schemas under any circumstances (from the reporting modules) and as such i want to setup a persistence-context with some persistence units as read-only (for reporting modules) and some as normal JTA enabled. we have already thought about creating two accounts for using in these persistence units one will be given read only access the other will have read-write access. I was wondering if there is something simpler that we can do with the persistence.xml file or may be at the JDBC driver level so that my connections to the DB are selectively read-only and read-write based on the persistence-unit active. or the database driver url being used... we are using SQL-Server as the DB Server...if that helps any bit. To my knowledge there is no support for that (beyond using a user with restricted rights for the database connection) in standard JPA. But your JPA provider might support: Read-only entities (e.g. with ElipseLink @ReadOnly or Hibernate @Immutable annotations) Read-only queries via hints (e.g. with eclipselink.read-only set to true for EclipseLink or org.hibernate.readOnly set to true for Hibernate). I checked the connection properties of the Microsoft JDBC driver but didn't spot anything that could help. PS: There is a pending enhancement request for EclipseLink ( Bug 282595 ) to provide support for a read-only EntityManager. You might want to vote for it.
549,A,"java ResultSet using MAX sql function Hello here is what I want I connect to a DB and retrieve the biggest element of the UniqueId column and assign it to an integer variable named maxID here is my approach: int maxID = 0; Statement s2 = con.createStatement(); s2.execute(""SELECT MAX(UniqueId) FROM MyTable""); ResultSet rs2 = s2.getResultSet(); // while ( rs2.next() ){ maxID = rs2.getInt(0); } What would be a decent way of solving this it feels like a very crude way by using ""rs2.next()"" while loop. Thanks Boris Pavlović was almost right. if (rs2.next()) { maxID = rs2.getInt(1); } The columns in a result set are 1-based. And the reason for using if instead of while is that the query you’re executing only returns a single row. I've just fixed mine answer and gave you +1  if (rs2.next()) { maxID = rs2.getInt(1); }  .next() is to reposition your cursor from 'nowhere' to a row if any. you can test it if you like it is recommendable though that you do so can't escape that while loop. Although if you're certain that the query will only return a single row you can do this if (rs.next()) { maxID = rs2.getInt(1); } seems like a good idea but when I change as above Eclipse is displaying this error: Description Resource Path Location Type Cannot invoke getInt(int) on the primitive type boolean Alertmail.java /alertmail/src line 33 Java Problem yes `next()` returns a boolean and therefore works in the `while()` loop. yes Is right you need to reposition the cursor before yo can fetch any data I rushed my answer. I shouldn't be looking at questions this time of the night. I'm going to edit my answer I should had leave as it was..."
550,A,"JDBC unwanted statement close I have a Java JDBC application that uses multiple threads to retrieve information from an Oracle data base. Each thread si supposed to periodically execute a statement that executes a select on a specific table (the table is different for each row). The threads are instances of a class that extends the Thread class. This class has a private variable that stores a connection to the data base. This thread also has a child thread that periodically deletes some info from the table trough a statement. When i run a single thread (get data from a single table) it works perfectly but when i run multiple threads (trying to get data from multiple tables) i get an error that says that my statement was closed before I printed the entire resultset generated by that statement. My questions are: Why is a different thread closing my statement? Why isn't the child thread closing the parent thread statement? What can i do to prevent this? I hope someone can help. Constantin I don't use connection pooling because the connection on eacht thread stays open permanently because i execute a select statement every 20 milliseconds and the cild thread (that has his own connection) executes a delete statement every 10 seconds. I cant store the data in an array because as sone as i retrieve it i have to send it ot an API for processing. I can't understand it. Every thread is a different instance (with different paramenter except those used for connecting aka user password) of the class (witch has nothing static in it) and yet close each other statements. Each thread has it's own connection object and it's own statement adn result set object. It should be thread safe Here is a code sample stmt = conn.createStatement(); rs = stmt.executeQuery(query); while (rs.next()) { //some processing } stmt.close(); The conn variable is a connection and is created in the thrad's constructor could this be the problem? New EDIT I have wrapped my connection object in a wraper class and extended it into tow different connection wrapper classes one that is used by the threads doing the select statements and one by the threads doing the delete statements. I dont close my connection after a statement because it would be inefficient but i do close the satement I dont have any shared objects between the threads because i dont need any. Each thread select data from a different table using a different statement object and a different resultset and passes it on to the API. To use connection pooling would meam rethinking my entire application but if no other solution apears than i'll have to do it. Thanks for the help and sorry if i sound stubern and sorry for not expressing myself more clearly from the start If you are running a query every 20 milliseconds then you should DEFINITELY be using a connection pool. The job of the connection pool is to keep connections open. It costs nothing to call getConnection() when you need a connection and conn.close() when you are done with it. Don't manage the connection yourself as you will have to run into the headaches of managing when connections are close as you are seeing now. If ""each thread has it's own connection object and it's own statement and result set object"" then perhaps what you think is going on is not really what is occuring. Isn't the connection object a static field in your thread by accident? There is no apparent reason for other threads to close your statement if they cannot see it. What is the scope of the stmt variable? I can only think that somehow another thread has access to that same variable (it is declared statically or is a member of a shared instance of some object). Also you should really put close() in a finally block otherwise you will likely leak cursors/connections on the database if an exception occurs. If I was really desperate I'd try the following to debug the problem: First I'd create a wrapper class for JDBC connection objects. Each wrapper method compares the current thread pointer with the thread pointer for the last operation. If they are the same it calls the wrapped connection. Otherwise it logs an error with a stacktrace to show exactly where the call was made. Next I'd find all places where JDBC connections are created and change them to wrap the connection with an instance of my wrapper class. Finally I'd run the application and set up something to watch the logs. Why not use the debugger with method breakpoints do catch the guy who closes the object?  If you make sure you do not share state between threads you won't need to worry about synchronisation. Use a connection pool. Before each database statement is executed retrieve a connection from the pool. Even if you are acquiring and releasing a connection 50 times a second the connection to the database will be kept open by the pool and new connections will only be needed when multiple threads require a DB connection at the same time. I recommend you take a look at DBCP which has a good implementation of a robust thread safe and flexible database connection pool. Use local variables to make sure the scope of the connection means it is only visible to the current thread. Always close connections (or release them back to the pool) when you have completed your database statement execution. Use a finally block around your JDBC code to do this. When creating statements again make sure they are local so that their scope is visible only to the current thread. Always close statements when you are done with them in a finally block. public Data getMyData() { Connection conn = null; Statement statement = null; try { conn = ConnectionPool.getConnection(); statement conn.prepareStatement(""select mydata from mytable""); //execute statement get results //return Data }finally{ if (statement != null) statement.close(); if (conn != null) conn.close(); //release the connection back to the pool } }  As long as your connection pool is thread safe this code should also be thread safe as you are never sharing connections or statements between threads. if statement.close() were to throw an Exception then you won't be closing that connection. A nested try{}finally{} will fix it."
551,A,"how do I make a select which always returns zero rows I want to determine if a column exists in a table for any jdbc driver. In order to know the columns in a table I have to make a query to the table and then get the ResultSetMetaData for the info but this is pretty expensive in like 99% of times. In mysql I have: SELECT * FROM tablename LIMIT 00 In Intersystems caché I have: SELECT TOP 0 * FROM tablename But for example in JavaDB I cannot apply any limit at all. Is there any generic query that would give me the same result and still be fair with the DB performance? Thanks in advance. SELECT * FROM tableName WHERE 'You' = 'Smart' I would have said WHERE ""Paula Bean"" = ""Brillant"" but this works too. this one made my day... thanks i use 1<>! but hey this works amazingly well. isn't it better to do: 'You' = 'Smart' ? Doing a select is unnecessary as you can query the database table metainfo without it.  select * from tablename where 1 != 1 On some databases 1 would refer to the *first column*. Even so this will work: not even NULL is not equal to NULL. won't work on many databases. SHould be 1 <> 1 <> and != are fairly mutually exclusive across DBMS platforms so I'd avoind inequality altogether.  ...or you could just use the DatabaseMetaData route. There's a ""getColumns"" method that does what you need without creating a resultset.  Unrelated but if you just need the columns in MySQL you can run SHOW FIELDS FROM tablename. This returns columns and the associated info.  SELECT * FROM table_name WHERE 1 = 2;"
552,A,"Any WorkAround For Java ResultSet Limitation I am doing a database migration work. I have to copy a database in MSSQL to MySql database. It was possible to come up with a small java utility to copy table stucture from MSSQL to MySql Database. Now i have to copy all data from MSSQL to MySql. I tried using resultset in java to obtain all data from a table but then it could only fetch a small part of data. Is there any alternate solution to get all data from table to resultset or to some other similar structure which i could possibly use to insert the same data into mysql Db. There are more than 2500000 records for a table. There is no such limitation in JDBC. The best way to achieve a database migration like you describe is to use and ETL Tool - there's a good overview of ETL here: http://en.wikipedia.org/wiki/Extract_transform_load There's no reason why you wouldn't be able to do this with JDBC and so if you are set on rolling your own please elaborate on 'could only fetch a small part of data': what is the query you are running? are you getting an exception? which JDBC driver are you using to connect to MS-SQL? hi Nick Thank you for your response. I know that ideally resultset should pick up all data from databasebut then its not working for me. * The query which I am trying to run is ""SELECT * FROM "" * I am not getting any exception while executing the query * the jdbc driver is microsoft jdbc SQL Server Driver Hi Richie - the MS JDBC driver isn't that good (some might say intentionally). Try using the TDS driver - http://jtds.sourceforge.net/index.html  A JDBC result set should in principle allow you to iterate the entirity of a large query result. However going via Java may not be the most efficient approach. Bulk export to a file and bulk import may be the way to go. It appears that MS has a bcp utility that may do the export. Thank you djna and Vinko s/may be/is/g . Thanx djna Bulk export to a file from mssql?? Can u elaborate a bit. Thanks in advance again :) Some database vendors have utlities for exporting and importing data. It appears that MS do. I don't know how readily that export can be imported to MYSQL but once you have a file to play with I'd expect any required transforms to be quite easy. the tool in mssql is called bcp"
553,A,Randomize database row results I've been finding some unit tests that assume that the results of database queries are in a particular order yet the query being run doesn't include an order by clause. I would like to find more of these unit tests so that I can examine whether the test is at fault in its assumptions or the code is at fault in its lack of specifying an order. I'm using java junit spring hibernate dbunit jdbc and postgresql. One idea I had was to intercept the test queries somewhere and if a query does not include an order by clause then capture all the results and return them in a random order. Where would be the easiest place to intercept and check the query? Are there other simple ways of identifying such tests? You could take a look at extending Hibernate's EmptyInterceptor and specifically the onPrepareStatement method. If the sql query passed as the argument doesn't contain an order by clause you could try adding order by random() to it. That looks like it might work. Is my implementation able to be injected in a sessionFactory bean? If you configure your sessionFactory with Spring's LocalSessionFactoryBean I'd try making a test-specific config that adds the interceptor there (entityInterceptor property). Thanks got that working. Now to deal with the errors (eg filtering out select distinct queries)
554,A,"PreparedStatement error I have two select statements and make 'union all' for these two statements. Then I use the PreparedStatement and when I setString to this preparedStatement it shows ""java.sql.SQLException: Missing IN or OUT parameter at index:: 2"". After I toured around google some people say that for each ""?"" in sql statment I should write setString. For my situation I have two select statments so I have two ""?"" but I ""union all"" so I'm not sure whether it is assumed that one ""?"" or two ""?"". But when I tried to write two setString like preparedStatement.setString(1ApplicationNo); preparedStatement.setString(2ApplicationNo);  it shows ""ORA-00918: column ambiguously defined"". I have no idea how to solve this problem. my union select statment is query.append(""select TO_CHAR(TRUNC(SYSDATE)'DD MONTHYYYY')a.appl_noa.assigned_tob.co_nameb.co_name2a.credit_acct_noa.credit_bank_noa.credit_branch_noa.service_id ""); query.append(""from newappl a newappl_hq b where b.appl_no = a.appl_no and a.appl_no=(select appl_no from newappl where appl_no=?) and rownum=1 and credit_status = 'CRPEND'""); query.append("" union all ""); query.append(""select TO_CHAR(TRUNC(SYSDATE)'DD MONTHYYYY')a.appl_noa.assigned_toc.trading_name co_name ' ' co_name2 d.bank_acct_no credit_acct_no d.bank_no credit_bank_no d.bank_branch_no credit_branch_noa.service_id ""); query.append(""from newappl anewappl_hq b newappl_ret c newappl_ret_bank d where b.appl_no = a.appl_no or a.appl_no = c.appl_no and c.ret_id= d.ret_id and a.appl_no=(select appl_no from newappl_ret where appl_no=?) and rownum=1 and credit_status = 'CRPEND'"");* setString is preparedStatement.setString(1ApplicationNo); When I searched for setString example there are two different parameters if there are two setString like preparedStatement.setString(1ApplicationNo); preparedStatement.setString(2LoginID); But I need ApplicationNo for both select statments. I re-wrote your query as: SELECT TO_CHAR(SYSDATE'DD MONTHYYYY') a.appl_no a.assigned_to b.co_name b.co_name2 a.credit_acct_no a.credit_bank_no a.credit_branch_no a.service_id FROM newappl a JOIN newappl_hq b ON b.appl_no = a.appl_no WHERE a.appl_no = ? AND rownum = 1 AND credit_status = 'CRPEND' UNION ALL SELECT TO_CHAR(SYSDATE'DD MONTHYYYY') a.appl_no a.assigned_to c.trading_name ' ' d.bank_acct_no d.bank_no d.bank_branch_no a.service_id FROM newappl a JOIN newappl_ret c ON c.appl_no = a.appl_no JOIN newappl_ret_bank d ON d.ret_id = c.ret_id WHERE c.appl_no = ? AND rownum = 1 AND credit_status = 'CRPEND' From what I can see the ORA-00918 is about the reference to the credit_status column. Of the tables involved is there a credit_status column in more than one of them? Because it's the only un-aliased column in either query. Couple other things to mention: don't need to TRUNC a date if you're going to TO_CHAR it for just the day/month/year info. don't need to alias columns in the latter part of UNION'd statements UNIONs only need the same number of columns in the SELECT clause and that their data types match don't subquery for what you don't need to always test the query in PLSQL Developer/etc before dumping it into a Prepared Statement. This looks like it could be a stored procedure with a single parameter (assuming the appl_no is identical for both sides) +1 - This is the superior answer.  I see no reason why you should be building this query up and gc-ing it away over and over. I'd make it a static final String once and be done with it. If you need it twice why can't you do this? ps.setString(1 applicationNumber); ps.setString(2 applicationNumber); I have tried and it shows ""ORA-00918: column ambiguously defined"" Can you run that query successfully in SQL*Plus leaving Java out of the equation? Could be a problem with the query itself. yes thx & it solved Personally I think the answer from OMGPonies is better than mine. I don't know if the SQL actually works but there's far more details."
555,A,"create object output stream from an object I want to create on ObjectOutputStream but I don't want to persist the object in a file so how to do that? All the tutorials(that I found) say only about the file way:  FileOutputStream fos = new FileOutputStream(""t.tmp""); ObjectOutputStream oos = new ObjectOutputStream(fos); oos.writeObject(new Date()); oos.close(); I want to store the object into a database so I need to specify a stream in method setBinaryStream() from class PreparedStatement. Thanks for answering... Store it in a byte array instead. You can use ByteArrayOutputStream for this. This way you can use PreparedStatement#setBytes(). ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(new Date()); oos.close(); // ... preparedStatement.setBytes(i baos.toByteArray()); That said this is pretty a good smell. Are you sure that you need to serialize Java objects into a database? This way they are unindexable and unsearchable. If you for example store each Person serialized in the DB you cannot do SELECT * FROM person WHERE name = 'John' anymore. The normal practice is to do a 1:1 mapping of the entity and the DB table. The Date for example can perfectly be stored in a DATETIME/TIMESTAMP column. I definitely know this is not a good practice which is in my opinion no justification for not knowing this way of programming :-) Okay let's assume that you know what you're doing :) You're welcome.  you specifically need to use an outputstream to write to a database? I would seriously consider looking at the persistence api before attempting to write an outputstream implementation.. since connection details etc might get tricky to manage. have a look at link text and remember it can be used in J2SE as well.  ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream os = new ObjectOutputStream(bos); os.writeObject(new Date()); os.close(); byte[] data = bos.toByteArray(); So now you have a byte array and do what you want with it."
556,A,"Returning a table type from a PL?SQL function called via JDBC? I've got the following function that I wish to call: CREATE OR REPLACE PACKAGE utils AS TYPE item_list IS TABLE of items.item_id%TYPE; FUNCTION getParentsForItem(p_item_id IN items.items_id%TYPE) RETURN item_list; END utils; But I'm unsure of how to bind a java Collection to the return type of getParentsForItem. After some Google searching I found this example. It makes use of methods exclusive to the Oracle JDBC driver namely: OracleCallableStatement.registerIndexTableOutParameter(int int int int) OracleCallableStatement.getPlsqlIndexTable(int) After suiting it to your situation perhaps this will work: Warning: I have not compiled this myself. int itemId = ...; // This feature is only supported by the OCI driver: Connection connection = DriverManager.getConnection(""jdbc:oracle:oci8:@[HOST]"" ""[USER]"" ""[PASSWORD]""); CallableStatement callableStatement = connection.prepareCall(""{? = utils.getParentsForItem(p_item_id => ?)}""); OracleCallableStatement oracleCallableStatement = (OracleCallableStatement) callableStatement; int maximumElementsInTable = 150; // the maximum possible number of elements. int elementSqlType = Types.INTEGER; // index table element SQL type (as defined in java.sql.Types or OracleTypes). int elementMaxLen = 100; // maximum length of the element. If not specified maximum length allowed for that type is used. oracleCallableStatement.registerIndexTableOutParameter( 1 maximumElementsInTable elementSqlType elementMaxLen ); oracleCallableStatement.setInt(2 itemId); oracleCallableStatement.execute(); int[] parentItemIds = oracleCallableStatement.getPlsqlIndexTable(1); According to [this page](http://docs.oracle.com/cd/B28359_01/java.111/b31224/oraint.htm#BABBGDFA) *Index-by tables of PL/SQL records are not supported.*... So accessing `TYPE T_X IS TABLE OF X%rowtype INDEX BY BINARY_INTEGER` won't work..."
557,A,how to set fetch size for jdbc odbc driver Im using sun.jdbc.odbc.JdbcOdbcDriver to connect to an oracle database.I know I would be probably be better off using the thin driver but I want the app to work without specifying the db server name and port no.My connection string is like jdbc:odbc:DSN. The queries that I execute in my application may return millons of rows.All the data is critical so I cannot limit them within the query.My concern is for my java app running into memory issues. When I check the fetch size of the statement it is set to 1.This seems extremely sub-optimal(A query retrieving 45K rows took abt 13 mins)to me and I would like to have a fetch size of atleast 500 so as to improve performance. My understanding is that when my query is executed(I'm using Statement) the statement object points to the results on the database which I iterate using a ResultSet. The resultSet will hit the database to fetch n no of rows (where n is fetch size) each time I do a resultSet.next(). Is this interpretation correct? If so does it mean that my app will never face any out of memory issues until my fetch size is so large that the JVM gets swamped? When I do a stmt.setFetchSize() after creating a statement I get an invalid fetch size sql exception.I am able to avoid this exception if I set the stmt.setMaxRows() to a larger value than the fetch size.But 1. I dont want my results to be limited to the MaxRows value. 2. Tried setting max rows to a huge value and tried with fetch size of 500 but saw no improvement in time taken. Please help me figure out how I can set a valid fetch size and get some improvement.Any other optimization suggestions for the same driver would be appreciated. Thanks Fell I haven't used a JDBC-ODBC bridge in quite a few years but I would expect that the ODBC driver's fetch size would be controlling. What ODBC driver are you using and what version of the ODBC driver are you using? What is the fetch size specified in the DSN? As a separate issue I would seriously question your decision to use a JDBC-ODBC bridge in this day and age. A JDBC driver can use a TNS alias rather than explicitly specifying a host and port which is no harder to configure than an ODBC DSN. And getting rid of the requirement to install configure and maintain an ODBC driver and DSN vastly improves performance an maintainability. The ODBC driver configuration is stored in the registry in Windows or config files in Unix. In either case it should be possible to write a small application that would extract that information. thanks again.My app is running fine now! thanks a lot! I didnt know about the thin driver using TNS aliases. This solved all my unix issues. Is there any way to extract the server/instance name specified in ODBC driver configuration?  Use JDBC. There is no advantage in using ODBC bridge. In PreparedStatement or CallableStatement you can call setFetchSize() to restrict the rowset size.  Are you sure the fetch size makes any difference in Sun's ODBC-JDBC driver? We tried it a few years ago with Java 5. The value is set even validated but never used. I suspect it's still the case.
558,A,easy transactions using spring jdbc? I am working on a java app that uses Spring IOC and JDBC Template classes. I have a DAO class that has 4 methods : m1() to m4(). m1 performs multiple inserts and updates on table t1 m2 on table t2 m3 on t3 etc. The dao methods are used as follows: while(true) { //process & generate data dao.m1(data1); dao.m2(data2); dao.m3(data3); dao.m4(data4); //sleep } I want the db operations under the 4 consecutive method calls to be atomic either all the 4 tables are updated successfully or none are. So if there is an error while performing operations in m3() i want to rollback all the changes(updates & inserts) performed in m2 & m1. So does spring let you do it the following way ? while(true) { //process & generate data transaction = TransactionManager.createNewTransaction(); transaction.start() try { dao.m1(data1); dao.m2(data2); dao.m3(data3); dao.m4(data4); } catch(DbUpdateException e) { transaction.rollBack(); } transaction.end(); // sleep } or are there better ways to do it ? Spring can handle this all for you by using @Transactional as explained or in XML if you'd prefer. The import thing to get right is the type of Transaction Propagation you want which all depends on your application. By default a transaction will be started if one doesn't exist and will re-use an existing transaction if one has already been started. This is the behavior you want if you want all 4 DAOs to be atomic. Put @Transactional on a class which will manage the DAO methods called (MyService) - anything below this layer will now take part in that transaction boundary. i.e: @Transactional public void m1(Data data) { ... } @Transactional public void m2(Data data) { ... } Doing this in code is completely unnecessary. See here for more info  For completeness the programmatic solution would be: private TransactionTemplate transactionTemplate; public setTransactionManager(PlatformTransactionManager transactionManager) { this.transactionTemplate = new TransactionTemplate(transactionManager); } ... while (true) { transactionTemplate.execute(new TransactionCallbackWithoutResult() { protected void doInTransactionWithoutResult(TransactionStatus status) { try { dao.m1(data1); dao.m2(data2); dao.m3(data3); dao.m4(data4); } catch(DbUpdateException e) { status.setRollbackOnly(); } } }); }  Yes Spring allows you to programatically control transactions. Personally I prefer declarative transactions using annotations which goes like this: public void runBatchJob() { while (true) { // generate work doWork(unitOfWork); } } @transactional private void doWork(UnitOfWork work) { dao.m1(data1); dao.m2(data2); dao.m3(data3); dao.m4(data4); } where the DAO functions are defined: @Transactional public void m1(Data data) { ... } This requires in your applicationContext.xml: <tx:annotation-driven/> Declarative transactions can be declared to require a transaction require a new transaction support transactions etc. Rollback will occur when a block annotated with @Transactional throws a RuntimeException. Does the @Transactional annotation do anything when applied to a private method? Yes private isn't as private as it used to be. :) I don't believe you need to annotate the m1m2etc as @Transactional. If any throws an exception everything already completed by doWork will be rolled back. You don't need to in this context no. But if they are doing updates you should annotate them as requiring transactions otherwise you may find yourself doing non-transactional updates if you call them outside the doWork() context.  Yes you can put those calls inside a method and specify your transactions declaratively. You don't need to add that code - Spring can do it for you.
559,A,SQL logging in Websphere 6.1 I am looking for a tool that Logs SQL statemetns fired in the application as I use the application. I found p6spy. But there is an issue with that. It doesnt seem to be compatible with XA Datasources. Is there a way to make p6spy work on Websphere 6.1 OR is there an alternative to p6spy ? Also if anyone has any AspectJ code that intercepts the PreparedStatment object and dumps the SQL that would also be great. It is not mandatory for the JDBC drivers to implement a feature to be able to extract / print out the SQL statements. To be honest I would do this in database. All reasonable database products can log in detail everything that comes in. Also you can at the same time get further information like execution plans and their impact on the server.  I seem to remember there being some parameter you can add to your jdbc url configuration and/or the connection. Can't remember the details.  It does depend on the way that you are accessing the database. If you are using Hibernate then you can make that spit out its SQL if you are accessing the datasource through WAS then you can use the trace service. Set the trace to something like: =info: com.ibm.websphere.rsadapter.=detail And see what you get out of it. thanks Micahel for the info.  You shold change trace level into jdbc driver. If you using DB2 then change custom properties for data source if you using Oracle then change driver on the ojbdc6_g.jar and change JVM properties
560,A,"Primary key from inserted row jdbc? Is there a cross database platform way to get the primary key of the record you have just inserted? I noted that this answer says that you can get it by Calling SELECT LAST_INSERT_ID() and I think that you can call SELECT @@IDENTITY AS 'Identity'; is there a common way to do this accross databases in jdbc? If not how would you suggest I implement this for a piece of code that could access any of SQL Server MySQL and Oracle? Thanks for asking this question it was exactly what I wanted to know myself! Thanks a lot! The answer for the question works perfectly for PostgreSQL! for oracle Hibernate uses NEXT_VALUE from a sequence if you have mapped a sequence for PKEY value generation. Not sure what it does for MySQL or MS SQL server  For databases that conform to SQL-99 you can use identity columns: CREATE TABLE sometable (id INTEGER GENERATED ALWAYS AS IDENTITY(START WITH 101) PRIMARY KEY ... Use getGeneratedKeys() to retrieve the key that was just inserted with executeUpdate(String sql int autoGeneratedKeys). Use Statement.RETURN_GENERATED_KEYS for 2nd parameter to executeUpdate()  Spring provides some useful support for this operation and the reference guide seems to answer your question: There is not a standard single way to create an appropriate PreparedStatement (which explains why the method signature is the way it is). An example that works on Oracle and may not work on other platforms is... I've tested this example on MySQL and it works there too but I can't speak for other platforms.  extraneon's answer although correct doesn't work for Oracle. The way you do this for Oracle is: String key[] = {""ID""}; //put the name of the primary key column ps = con.prepareStatement(insertQuery key); ps.executeUpdate(); rs = ps.getGeneratedKeys(); if (rs.next()) { generatedKey = rs.getLong(1); }  Copied from my code: pInsertOid = connection.prepareStatement(INSERT_OID_SQL Statement.RETURN_GENERATED_KEYS); where pInsertOid is a prepared statement. you can then obtain the key: // fill in the prepared statement and pInsertOid.executeUpdate(); ResultSet rs = pInsertOid.getGeneratedKeys(); if (rs.next()) { int newId = rs.getInt(1); oid.setId(newId); } Hope this gives you a good starting point.  Have you tried the Statement.executeUpdate() and Statement.getGeneratedKeys() methods? There is a developerWorks article that mentions the approach. Also in JDBC 4.0 Sun added the row_id feature that allows you to get a unique handle on a row. The feature is supported by Oracle and DB2. For sql server you will probably need a third party driver such as this one. Good luck!"
561,A,"Java - Storing SQL statements in an external file I am looking for a Java library/framework/technique of storing SQL statements in an external file. The support team (including DBAs) should be able to alter (slightly) the statement to keep them in sync in case database schema changes or for tuning purposes. Here are the requirements: The file must be readable from a Java application but also must be editable by the support team without the need of fancy editors Ideally the file should be in plain text format but XML is OK too Allow DML as well as DDL statements to be stored / retrieved New statements can be added at a later stage (the application is flexible enough to pick them up and execute them) Statements can be grouped (and executed as a group by the application) Statements should allow parameters Notes: Once retrieved the statements will executed using Spring’s JDBCTemplate Hibernate or Spring’s IOC container will not be used So far I managed to find the following Java libraries which use external files for storing SQL statements. However I am mainly interested in the storage rather than a library that hides all JDBC “complexities”. Axamol SQL Library Sample file content: <s:query name=""get_emp""> <s:param name=""name"" type=""string""/> <s:sql databases=""oracle""> select * from scott.emp join scott.dept on (emp.deptno = dept.deptno) where emp.ename = <s:bind param=""name""/> </s:sql> </s:query> iBATIS Sample file content: <sqlMap namespace=""Contact""""> <typeAlias alias=""contact"" type=""com.sample.contact.Contact""/""> <select id=""getContact"" parameterClass=""int"" resultClass=""contact""""> select CONTACTID as contactId FIRSTNAME as firstName LASTNAME as lastName from ADMINISTRATOR.CONTACT where CONTACTID = #id# </select> </sqlMap> <insert id=""insertContact"" parameterClass=""contact""> INSERT INTO ADMINISTRATOR.CONTACT( CONTACTIDFIRSTNAMELASTNAME) VALUES(#contactId##firstName##lastName#); </insert> <update id=""updateContact"" parameterClass=""contact""> update ADMINISTRATOR.CONTACT SET FIRSTNAME=#firstName#  LASTNAME=#lastName# where contactid=#contactId# </update> <delete id=""deleteContact"" parameterClass=""int""> DELETE FROM ADMINISTRATOR.CONTACT WHERE CONTACTID=#contactId# </delete> WEB4J -- This is a comment ADD_MESSAGE { INSERT INTO MyMessage -- another comment (LoginName Body CreationDate) -- another comment VALUES (???) } -- Example of referring to a constant defined above. FETCH_RECENT_MESSAGES { SELECT LoginName Body CreationDate FROM MyMessage ORDER BY Id DESC LIMIT ${num_messages_to_view} } Can anyone recommend a solution that is tried and tested? Are you sure you want to centralise all your SQL into a file that the support team can edit? How badly could they break things? Once deployed the application is unlikely to change unless major bugs are found. The support team will not have the expertise to tinker with a complex Java applications by they know how to tinker with SQL statements. Usually they will need to do DBA type changes rather than actual application changes WEB4J example is not properly formatted could somebody with edit privileges fix that? Thinking that the Java code won't change is an illusion. If you change your queries you'll likely have to change the code that is using the results. [SQLind](http://www.sqlind.net) provides a xml templated way to externalize SQL from java code. If you must do this you should look at the MyBatis project. I haven't used it but have heard it recommended a number of times. Separating SQL and Java isn't my favorite approach since SQL is actually code and is tightly coupled to the Java code that calls it. Maintaining and debugging the separated code can be challenging. Absolutely don't used stored procs for this. They should only be used to improve performance by reducing traffic between the DB and the application. I'm puzzled by your statement that the Java and SQL are tightly coupled. The only coupling should be the names of the columns in the query. iBATIS is one option I am considering; it is a bit complex but it ticks most of the boxes ""Separating SQL and Java isn't my favorite approach..."" I assume you do not agree with the statements in this article ""Keep SQL out of code"" http://www.javapractices.com/topic/TopicAction.do?Id=105 I would recommend iBatis as well; it usually takes new developer minutes to start using it. (Of course assuming you already are using it; introducing it to a new project usually takes a bit more work depending on project itself.) Adrian - The article you link to equates SQL code with metadata which is I believe a false characterization. My preferred approach is to isolate all SQL into a set of Java Data Access Object (DAO) classes which are responsible for translating between the database and the Java object model and are not allowed to contain any additional logic. Now you *still* have all of the SQL code in a well-defined location (a set of java files) with the added benefit of having all of the appropriate context of where the query is used. I could go on but I'm out of chars... I'm with John - separating queries this way makes it hard to figure out what fields you're setting/reading. You start with PreparedStatement p = new PreparedStatement(readSqlQuery(""getContact"")). Then what? What arguments should you pass it? What result columns are there? You have to go hunt down the right entry in the sql file. If it's in the code it is right there for you to look at.  Just create a simple Java Properties file with key-value pairs like this one: users.select.all = select * from user Declare a private field of type Properties in your DAO class and inject it using Spring configuration which will read the values from the file. UPDATE: if you want to support SQL statements in multiple lines use this notation: users.select.all.0 = select * users.select.all.1 = from user +1 for simple but effective and will work well with prepared statements (http://java.sun.com/docs/books/tutorial/jdbc/basics/prepared.html) A properties file is a good option I agree. It is easy to implement and easy to edit by the support team. However there are a few points I am not entirely happy the fact that ""One statement per line"" might mean long statements will make the file difficult to view/edit You should be able to use \ at the end of the line to allow the content to go over multiply lines. If your java is sufficiently up-to-date you could use an XML properties file instead of nvp. The project will use JDK6 and XML is an accepted format I have used properties stored in XML file for exactly this purpose. It has simple syntax (`properties` element as root `entry` elements with `key` attribute as children) can be loaded as simply as normal Properties (by using loadFromXML method instead of load method) and it works perfectly. Only one small issue was encoding of < > characters which must be written as entities in XML (< >) Be careful with properties files - the DBA's would likely rebel against having to append a '\' on every line in order to continue a statement. I have used a properties file before and it was very simple the \ to continue a newline is a little annoying but it's such a simple solution that we lived with it. @PeterŠtibraný You can put the entire entry in CDATA elements so you don't have to bother with XML entities @JohnB: I have since switched to a different file format but my XML properties file looked like this: https://gist.github.com/pstibrany/c01fa0643121f3ffa26b @PeterŠtibraný If the different file format is better could you tell me about that? @PeterŠtibraný Could you show an example of your xml file. Please @JohnB: I am simply using text file like this: https://gist.github.com/pstibrany/38aadfec22dfd72d52f2. Nothing interesting here `/*$* */` marks the beginning of the query `/*$ */` marks the end and everything between is a query itself. It's just simpler than XML. One of the reasons is also that once you parse Properties (e.g. from XML) you can't get them in the same order as they were in the file which is what we require to execute Database Upgrade queries in the right order. Thanks @PeterŠtibraný  You can also use the QueryLoader class in Apache Commons DbUtils which will read the sql from a properties file. However you will have to use DbUtils which sort of serves the same purpose as the JDBCTemplate.  It's simple and reliable to do using classes from Spring. Take your SQL files and save them in some location on your classpath. This can be in a JAR file that only contains SQL if you want. Then use Spring's ClassPathResource to load the file into a stream and use Apache IOUtils to convert it into a String. You can then execute the SQL using SimpleJdbcTemplate or DB code of your choice. I suggest you create a utility class that takes a simple Java class with public String fields that correspond to the SQL file names following a convention of your choosing. Then use reflection in conjunction with the ClassPathResource class to go find the SQL files conforming to your naming convention and assign them to the String fields. After that just refer to the class fields when you need the SQL. It's simple works great and achieves the goal you want. It also uses well worn classes and techniques. Nothing fancy. I did it couple years back. Works great. Too lazy to go get the code. You'll have no time figuring it out yourself.  You can use velocity to have ""scriptable"" sql templates that you can use to work with the files in a flexible way. You have primitive statements like conditionals and loops to build your sql commands. But I strongly suggest to use prepared statements and/or stored procedures. Building your SQL the way you're planning will make you vulnerable to SQL injection the DB server will not be able to cache the sql queries (which will lead to bad performance). BTW: You can store the definition of the prepared statements in files too. This is not the best solution but pretty close to it and you get the benefit of SQL-injection protection and performance. When your SQL schema is not build to work with prepared statements or stored procedures you might want to rethink your schema. Maybe it needs to be refactored. The application will be built on a legacy database so schema refactoring is out of the question. Also using stored procedure is not an accepted solution (arguably they can be a good idea). Caching (fortunately) is not a major issue every statement is executed once a day (it is a batch application) OK then I'd choose Velocity. IMHO it's flexible enough to ""script"" the scripts a little bit and not that flexible that it's a programming language on its own.  dynamic-query is a good open source framework for those want something between JDBC and ORM. 1 plain SQL. - It saves plain sql to external files. no redundant tags supports comments. /* It also supports comment. This code is in an external file 'sample.sql' Not inisde java code.*/ listUsers : select * from user_table where user_id= $$; /* $$ will automatically catch a parameter userId */ 2 expandable SQL. -It supports parameters including other files and sub query. listUsers: select id amount created @checkEmail{ email } from user_table where amount > $amt and balance < $amt @checkDate { and created = $$ } @checkEmail{ and email in ( select email from vip_list ) } ; /* Above query can be four queries like below. 1. listUsers 2. listUsers.checkDate 3. listUsers.checkEmail 4. listUsers.checkDate.checkEmail */ -- It can include other files like below & ../hr/additional hr.sql ; & ../fi/additional fi.sql ; Java example code using above. setting values to db. QueryUtil qu = qm.createQueryUtil(""selectAll""); try { qu.setConnection(conn); // with native jdbc qu.setString(""alpha""); qu.setDouble(10.1); qu.executeQuery(); // or with bean qu.executeQuery(new User(""alpha"" 10.1)); // or with map Map<String Object> map=new HashMap<String Object>(); map.put(""userName"" ""alpha""); map.put(""amt"" 10.1); qu.executeQuery(map); // or with array qu.executeQueryParameters(""alpha"" 10.1); Java example code using above. getting values from db.  while (qu.next()) // == qu.rs.next() { // native jdbc String usreName = qu.getString(""user_name""); double amt = qu.getDouble(""amt""); // or bean User user = new User(); qu.updateBean(user); // or array Object[] values = qu.populateArray(); } } catch (Exception e) { e.printStackTrace(); } finally { qu.closeJust(); }  You can use Spring and have your sql statements stored in your beans file that are injected when you get the class from your bean factory. That class can also to use an instance of SimpleJDBCTemplate that can be configured via the bean file to help simplify your code.  A simple solution we have implemented when faced with this was to externalize the SQL/DML into a file (mySql.properties) then use MessageFormat.format(String[] args) to inject dynamic properties into the SQL. For example: mySql.properties: select * from scott.emp join scott.dept on (emp.deptno = dept.deptno) where emp.ename = {0} Utility methods: public static String format(String template Object[] args) { String cleanedTemplate = replaceSingleQuotes(template); MessageFormat mf = new MessageFormat(cleanedTemplate); String output = mf.format(args); return output; } private static String replaceSingleQuotes(String template) { String cleaned = template.replace(""'"" ""''""); return cleaned; } Then use it like so: String sqlString = youStringReaderImpl(""/path/to/file""); String parsedSql = format(sqlString new String[] {""bob""}); We actually store a single properties file per sql/dml statement and use spring to inject a map of the files into the component responsible for loading the files. I presume you want to store more than one statement in the ""mySql.properties"" file. How do you indentify it? Also if you want to group several statements what method would you suggest?  The ElSql library provides this functionality (when working with Spring). ElSql consists of a small jar file (two public classes) that allows an external SQL file (elsql) to be loaded. The file uses a simple format to optionally provide slightly more behaviour than simply loading a file: -- an example comment @NAME(SelectBlogs) @PAGING(:paging_offset:paging_fetch) SELECT @INCLUDE(CommonFields) FROM blogs WHERE id = :id @AND(:date) date > :date @AND(:active) active = :active ORDER BY title author @NAME(CommonFields) title author content // Java code: bundle.getSql(""SelectBlogs"" searchArgs); The file is broken up into @NAME blocks which can be referred to from code. Each block is defined by signofocant whitespace indentation. @PAGING will insert the necessary code for paging such as FETCH/OFFSET. @AND will only be output if the specified variable exists (helping build dynamic searches). The DSL also handles LIKE vs = for wildcards in searches. The goal of the optional DSL tags is to provide the common basics that often hit when trying to build dynamic SQL in a database-neutral way. More info on the blog or user guide.  I would strongly encourage you to use Stored Procedures. This kind of thing is exactly what they're for. Yes I am aware of the Stored Procedure option. Normally it would be a path I would consider but for this project is not possible I cannot disagree more. Stored procedures make your business logic alienated from Java code. Stored procedures are written in plsql code closely coupled to the DB vendor without proper tools for refactoring more often no OOP support etc. Use Stored procedures only for performance optimizations. Useful stored procedures are only written in plsql if you're using Oracle. Generally useful stored procedures are written in SQL and can be easily port to another platform. +1 - Putting all our SQL into (Oracle) packages is great. It keeps all the queries in one nice place and allows the DB team play about without worrying about recompiling the application. This project will run agains an Ingres database; Ingres supports stored procedures so this is not a problem. But one of the requirements is not to use stored procedures. That's too bad. It's an odd restriction. That's absolutely not an odd restriction. With stored procedures all the business logic is running on the database machine (that won't scale easily because it's a single big machine). With SQL queries the business logic is coded in Java (and you can benefit from all the language features) and runs on the application server which scale better and for less money than a DB server. To me not using stored procedures is actually a good restriction. @Boris Pavlović - I cannot disagree more. :) Most enterprise applications never need to change the DB anyway especially because this would incur a heavy licence fee penalty for doubtful gains. And if you narrow yourself to a common subset of SQL that works on all RDBMS (or at least the few you are targeting) you will almost always have performance penalties sometimes severe. If you do wish to make your application multi-RDBMS compatible you should take the ORM way and build your application from the ground up keeping its strengths and limitations in mind.  You can use the localization facilities to do this. You then use the name of the database as the locale to get the ""oraclish"" version of ""insert-foo-in-bar"" instead of the English or French version. The translations are usually stored in property files and there are good tools for localizing applications by allowing editing these property files. Can you point me to an example of such file? Have a look at the Java Tutorial on this subject: http://java.sun.com/docs/books/tutorial/i18n/resbundle/propfile.html"
562,A,"How to check that a ResultSet contains a specifically named field? Having rs an instance of java.sql.ResultSet how to check that it contains a column named ""theColumn""? possible duplicate of [How can I determine if the column name exist in the ResultSet ?](http://stackoverflow.com/questions/3599861/how-can-i-determine-if-the-column-name-exist-in-the-resultset) You can use ResultSetMetaData to iterate through the ResultSet columns and see if the column name matches your specified column name. Example: ResultSetMetaData rsMetaData = rs.getMetaData(); int numberOfColumns = rsMetaData.getColumnCount(); // get the column names; column indexes start from 1 for (int i = 1; i < numberOfColumns + 1; i++) { String columnName = rsMetaData.getColumnName(i); // Get the name of the column's table name if (""theColumn"".equals(columnName)) { System.out.println(""Bingo!""); } } @Ivan be aware there are some complexities if you use an alias (SELECT col AS foo). http://bugs.mysql.com/bug.php?id=43684  Use the ResultSetMetaData object provided by the ResultSet object via rs.getMetaData()  You can do: rs.findColumn(""theColum"") and check for SQLException Yeah easiest way I would think is to just try to retrieve the column one way or another and catch the exception.  Try using the method ResultSet#findColumn(String) private boolean isThere(ResultSet rs String column) { try { rs.findColumn(column); return true; } catch (SQLException sqlex) { logger.debug(""column doesn't exist {}"" column); } return false; } It may be compared to a regular execution of Java. Bear in mind that usually bottleneck is not the Java code but the thins that are running on the other side -- the database. Most probably execution of the query and transport of data is few orders of magnitude slower than exception handling. Aren't exceptions slow? Tis method works well with aliases in mysql."
563,A,"Return ROWID Parameter from insert statement using JDBC connection to oracle I can't seem to get the right magic combination to make this work:  OracleDataSource ods = new oracle.jdbc.pool.OracleDataSource(); ods.setURL(""jdbc:oracle:thin:app_user/pass@server:1521:sid""); DefaultContext conn = ods.getConnection(); CallableStatement st = conn.prepareCall(""INSERT INTO tableA (some_id) VALUES (1) RETURNING ROWID INTO :rowid0""); st.registerReturnParameter(1 OracleTypes.ROWID); st.execute(); The error I get is ""Protocol Violation"". If I change to registerOutParameter() I get notified that I haven't registered all return variables. If I wrap the statement in a PL/SQL begin; end; block then I get the parameter just fine using a regular registerOutParameter() call. I would really prefer to avoid wrapping all my inserts statements in PL/SQL - so what is missing from above? Usually you don't want to make code database dependent. Instead of OraclePreparedStatement you should use CallableStatement. CallableStatement statement = connection.prepareCall(""{call INSERT INTO tableA (some_id) VALUES (1) RETURNING ROWID INTO ? }""); statement.registerOutParameter( 1 Types.VARCHAR ); int i = statement.executeUpdate(); if (i > 0) // Update count return statement.getString(1); This syntactic sugar was exactly what I needed - {call } Save my day thanks!!!  A few things you'll need to do Change CallableStatement to OracleCallableStatement Try and return into a NUMBER ie: OracleTypes.Number Sample code for returning info from a query: OraclePreparedStatement pstmt = (OraclePreparedStatement)conn.prepareStatement( ""delete from tab1 where age < ? returning name into ?""); pstmt.setInt(118); /** register returned parameter * in this case the maximum size of name is 100 chars */ pstmt.registerReturnParameter(2 OracleTypes.VARCHAR 100); // process the DML returning statement count = pstmt.executeUpdate(); if (count>0) { ResultSet rset = pstmt.getReturnResultSet(); //rest is not null and not empty while(rset.next()) { String name = rset.getString(1); ... } } More info on Oracle's JDBC extensions: http://download-uk.oracle.com/docs/cd/B19306_01/java.102/b14355/oraint.htm [@kaido has provided a preferable database-agnostic solution](http://stackoverflow.com/questions/682539/return-rowid-parameter-from-insert-statement-using-jdbc-connection-to-oracle/881414#881414).  Don't know if this applies or not since you don't specify what version you're using. From Oracle Metalink: Cause In the 10.1.0.x JDBC driver returning DML is not supported: Per the JDBC FAQ: ""10.1.0 (10g r1) Is DML Returning Supported ? Not in the current drivers. However we do have plans to support it in post 10.1.0 drivers. We really mean it this time."" As the application code is trying to use unsupported JDBC features errors are raised. Solution Upgrade the JDBC driver to 10.2.0.x because per the FAQ the 10.2.0.x JDBC drivers do support returning clause: ""10.2.0 (10g r2) Is DML Returning Supported ? YES! And it's about time. See the Developer's Guide for details. "" EDIT Just for grins you can check the version of JDBC Oracle thinks it's using with:  // Create Oracle DatabaseMetaData object DatabaseMetaData meta = conn.getMetaData(); // gets driver info: System.out.println(""JDBC driver version is "" + meta.getDriverVersion()); If that shows a JDBC driver 10.2.0.x or later then I'm out of ideas and perhaps a support request to oracle is in order... Thanks for the info here are the various versions I am using: Java Version: 1.6.0_12-b04 Virtual Machine Version: 11.2-b01 (HotSpot Server) Oracle Server: 10.2.0.4 Oracle Client: 11.1.0.7.0 through ojdbc6.jar  Try using ? instead of :rowid0 on your SQL string. I have had problems before with named parameters and Oracle.  PreparedStatement prepareStatement = connection.prepareStatement(""insert..."" new String[] { ""your_primary_key_column_name"" }); prepareStatement.executeUpdate(); ResultSet generatedKeys = prepareStatement.getGeneratedKeys(); if (null != generatedKeys && generatedKeys.next()) { Long primaryKey = generatedKeys.getLong(1); } I have found the answer this is perfectly works. I can insert from JAVA and its return with the key. Full version: CREATE TABLE STUDENTS ( STUDENT_ID NUMBER NOT NULL PRIMARY KEY NAME VARCHAR2 (50 BYTE) EMAIL VARCHAR2 (50 BYTE) BIRTH_DATE DATE ); CREATE SEQUENCE STUDENT_SEQ START WITH 0 MAXVALUE 9999999999999999999999999999 MINVALUE 0; And the Java code String QUERY = ""INSERT INTO students ""+ "" VALUES (student_seq.NEXTVAL""+ "" 'Harry' 'harry@hogwarts.edu' '31-July-1980')""; // load oracle driver Class.forName(""oracle.jdbc.driver.OracleDriver""); // get database connection from connection string Connection connection = DriverManager.getConnection( ""jdbc:oracle:thin:@localhost:1521:sample"" ""scott"" ""tiger""); // prepare statement to execute insert query // note the 2nd argument passed to prepareStatement() method // pass name of primary key column in this case student_id is // generated from sequence PreparedStatement ps = connection.prepareStatement(QUERY new String[] { ""student_id"" }); // local variable to hold auto generated student id Long studentId = null; // execute the insert statement if success get the primary key value if (ps.executeUpdate() > 0) { // getGeneratedKeys() returns result set of keys that were auto // generated // in our case student_id column ResultSet generatedKeys = ps.getGeneratedKeys(); // if resultset has data get the primary key value // of last inserted record if (null != generatedKeys && generatedKeys.next()) { // voila! we got student id which was generated from sequence studentId = generatedKeys.getLong(1); } } source : http://viralpatel.net/blogs/oracle-java-jdbc-get-primary-key-insert-sql/"
564,A,"Character encoding problem using ScrollableResults and MySql I'm doing private void doSomething(ScrollableResults scrollableResults) { while(scrollableResults.next()) { Object[] result = scrollableResults.get(); String columnValue = (String) result[0]; } } I tried this in two computers It works fine. It is a Windows 7. System.getProperty(""file.encoding"") returns Cp1252. When the word in the database has accents columnValue gets strange values. Is is a CentOS. System.getProperty(""file.encoding"") returns UTF-8. Both databases are MySql Charset: latin1 Collation: latin1_swedish_ci. What should I do to correct this? Can you show an example of the strange values? @Pekka Nível gets NÃvel. With a break line after Ã. I set file.encoding in the Windows and for Nível I get NÃ?VEL. It is different from what I get in Linux. My suggestion would be to use UTF-8 everywhere: at the database/tables level (the following ALTER will change the character set not only for the table itself but also for all existing textual columns) ALTER TABLE <some table> CONVERT TO CHARACTER SET utf8 in the connection string (which is required with MySQL's JDBC driver or it will use the client's encoding) jdbc:mysql://localhost:3306/db_name?useUnicode=yes&characterEncoding=UTF-8 References MySQL 5.0 Reference Manual 9.1.3.2. Database Character Set and Collation 9.1.3.3. Table Character Set and Collation Connector/J (JDBC) Reference 20.3.4.4. Using Character Sets and Unicode I'd try just the JDBC connection parameters first. You might be able to skip changing your table character encoding. was missing character set in the alter table."
565,A,"Streaming Data through Spring JDBC unknown length I currently have an application that inserts byte[] into our DB through the use of Spring JDBC [SqlLobValue]. The problem is this is not a scalable way to take in data as the server is buffering all the data in memory before writing to the database. I would like to stream the data from the HttpServletRequest Inputstream but all the constructors I can find for any classes that take an Inputstream as an argument also require the content length as an argument. I do not and will not require the user to know the content length when POSTing data to my application. Is there a way around this limitation? I can find no documentation about what happens if I pass -1 for content length but my guess is it will throw an Exception. I'm not sure why they couldn't just have the stream keep reading until the read(...) returns -1 the required behavior of an InputStream. I presume you meant ""InputStream"" rather than ""OutputStream"". I tried this out but I was having bigger problems with my JDBC driver so I am unsure if this actually works. InputStream inputStream = httpServletRequest.getInputStream(); int contentLength = -1; // fake will be ignored anyway SqlLobValue sqlLobValue = new SqlLobValue( inputStream contentLength new DefaultLobHandler() { public LobCreator getLobCreator() { return new DefaultLobHandler.DefaultLobCreator() { public void setBlobAsBinaryStream(PreparedStatement ps int paramIndex InputStream binaryStream int contentLength) throws SQLException { // The contentLength parameter should be the -1 we provided earlier. // You now have direct access to the PreparedStatement. // Simply avoid calling setBinaryStream(int InputStream int) // in favor of setBinaryStream(int InputStream). ps.setBinaryStream(paramIndex binaryStream); } }; } } ); jdbcTemplate.update( ""INSERT INTO foo (bar) VALUES (?)"" new Object[]{ sqlLobValue } ); Much appreciated - that seems to do the trick. I did have to upgrade my Oracle JAR to ojdbc6.jar seems the setBinaryStream(...) method w/o the length argument was added in Java 6. The older Oracle drivers would throw an AbstractMethodException."
566,A,"How to get the number of columns from a JDBC Resultset? I am using CsvJdbc (it is a JDBC-driver for csv-files) to access a csv-file. I don't know how many columns the csv-file contains. How can I get the number of columns? Is there any JDBC-function for this? I can not find any methods for this in java.sql.Resultset. For acessing the file I use code similar to the example on the CsvJdbc website. PreparedStatement ps=con.prepareStatement(""select * from stud""); ResultSet rs=ps.executeQuery(); ResultSetMetaData rsmd=rs.getMetaData(); System.out.println(""columns: ""+rsmd.getColumnCount()); System.out.println(""Column Name of 1st column: ""+rsmd.getColumnName(2)); System.out.println(""Column Type Name of 1st column: ""+rsmd.getColumnTypeName(2)); Plase explain your code  You can get columns number from ResultSetMetaData: Statement st = conn.createStatement(); ResultSet rs = st.executeQuery(query); ResultSetMetaData rsmd = rs.getMetaData(); int columnsNumber = rsmd.getColumnCount(); It would be interesting to understand how the CSV JDBC driver and it's `ResultSetMetaData` implementation handles variable length CSV records. e.g. If you specified `SELECT * FROM sample` and each row contained a different number of fields would the column count get re-evaluated for each row that were iterated over?"
567,A,"Tomcat-6.0.18 expanded directory structure datasource in context.xml Environment: Tomcat-6.0.18 Oracle-Db JDK-1.6.0_1 -1- context.xml i a war file - works fine my-application.war/META-INF/context.xml: <Resource auth=""Container"" driverClassName=""oracle.jdbc.OracleDriver"" maxActive=""5"" maxIdle=""1"" maxWait=""-1"" name=""jdbc/dataource-name"" password=""pwd"" type=""javax.sql.DataSource"" url=""jdbc:oracle:thin:@host-name:1521:xe"" username=""name""/> Important: context.xml is placed in a War-archive in this case. After deploying the application can access the database without problems -2- context.xml in an expanded directory structure (does not work): my-application/META-INF/context.xml (same content) Important: context.xml is placed in a expanded directory structure in this case. After deployment application con not access the database. Exception message is: javax.naming.NameNotFoundException: Name jdbc is not bound in this Context My question: How do i configure tomcat (or my application) in case 2? Please forget my posting... Case 2 works fine too!"
568,A,"How to sanitize log messages in Log4j to save them in database I'm trying to save log messages to a central database. In order to do this I configured the following Appender in log4j's xml configuration: <appender name=""DB"" class=""org.apache.log4j.jdbc.JDBCAppender""> <param name=""URL"" value=""jdbc:postgresql://localhost/logging_test"" /> <param name=""user"" value=""test_user"" /> <param name=""password"" value=""test_password"" /> <param name=""sql"" value=""INSERT INTO log_messages ( log_level message log_date ) VALUES ( '%p' '%m' '%d{yyyy-MM-dd HH:mm:ss}' )"" /> </appender> This works fine except some of the messages contain ' and then the appender fails. Is there an easy way to do this? I'd suggest creating a custom appender and overriding the flushBuffer and execute methods where you can escape your strings or use PreparedStatement : public class MyJDBCAppender extends JDBCAppender { } To explain why you need to override flushBuffer - the appender puts LogEvent objects into a buffer which is later flushed towards the target (database in this case). Here the flushBuffer method uses getLogStatement and (via execute) a normal Statement. You can replace that behaviour completely. Have a look a the current source code Then register your appender istead of JDBCAppender.  i solved the thing in the following way : Copied the source code of the JDBCAppender called ACMEJDBCAppender override the getLogStatement(LoggingEvent event) method cloning the old event and providing the new one with the escaped message. Not the cleanest solution from the oop point of view but it does the work. Hope it helps. protected String getLogStatement(LoggingEvent event) { LoggingEvent clone = new LoggingEvent( event.fqnOfCategoryClass LogManager.getLogger(event.getLoggerName()) event.getLevel() AidaUtils.sqlEscape(event.getMessage().toString()) event.getThrowableInformation()!=null ? event.getThrowableInformation().getThrowable() : null ); return getLayout().format(clone); }  Have a look at this non official Log4J JDBCAppender which fixes this issue and is distributed under the Apache 2.0 license. Quoting its features in comparision to org.apache.log4j.jdbc.JDBCAppender: Log to (relational) database Flexible connection handling (does not yet support DataSource) Flexible sql commands to execute actual logging Prepared Statements and Stored Procedures (J2SDK 1.4+) supported Enables logging of messages with special characters such as ' (single quote) and  (comma) Flexible table and column structure Flexible id generation Multiple PatternLayout applications allowed; in one or more columns Supports J2SDK 1.3 1.4 and 1.5 Supports Log4j 1.2.9 and current development Or and you should seriously consider this option switch from log4j to its successor logback (this is where things happen) which has a DBAppender that uses PreparedStatement (see the sources) that can use a JNDI datasource connection pooling (this is a big plus) etc. For more information about this appender refer to the online manual http://logback.qos.ch/manual/appenders.html#DBAppender I ended up using this one DBAppender worked fine. Thanks! An alternative library is one possible solution but doesn't answer the question of how to sanitize the data while using `org.apache.log4j.jdbc.JDBCAppender`  I'm not familiar with log4j or JDBC but I do know JDBC supports prepared statements. Perhaps there is a way to use that with the JDBCAppender You can extend the JDBCAdapter to work with prepared statements if it does not have an option to use them already. Extending it should be relatively simple  As per the Javadocs the offical JDBCAppender is quite limited and in particular has no good way of dealing with this issue. One way around it is to use an alternative appender such as this one which aims to be functionally compatible with the Log4J one except you know work.  To get around this problem logging to Oracle you can use Oracle's quote operator. Wrap the quote operator around %m (i.e. q#'%m'#) For example: INSERT INTO log_messages ( log_level message log_date ) VALUES ( '%p' q#'%m'# '%d{yyyy-MM-dd HH:mm:ss}' ) it doesn't run!  Joao sorry for being late but here it is: <appender name=""DB"" class=""org.apache.log4j.db.DBAppender""> <connectionSource class=""org.apache.log4j.db.DriverManagerConnectionSource""> <param name=""driverClass"" value=""org.postgresql.Driver"" /> <param name=""url"" value=""jdbc:postgresql://localhost/database"" /> <param name=""user"" value=""user"" /> <param name=""password"" value=""password"" /> </connectionSource> <layout class=""org.apache.log4j.PatternLayout""> <param name=""ConversionPattern"" value=""%d %-5p [%t] %c - %m%n"" /> </layout> </appender> Hope it helps!"
569,A,"JDBC with MySQL really slow don't know why I have a problem with a really slow connection between my Java code and a MySQL Database. I don't know where the bottle neck is. My program is more or less a chatbot. The user types something in my program splits the sentence into words and sends it word per word to the database. If it finds something there the user gets an output. The database is on an external Server but I also tried to connect to a pc next to me. Both is slow. I tried the connection once at another place then where I normally work and there it was fast most of the time. My SQL Code: SELECT info.INFORMATION FROM INFORMATION info INFO_SCHLUESSEL sch WHERE LCASE(sch.SCHLUESSELWORT) LIKE '"" + input + ""%' AND info.ID_INFO = sch.ID_INFO Order BY info.PRIORITAET DESC LIMIT 1; (just remembered if it helps to understand the sql code: schluessel = key Schluesselwort = key word prioritaet = priority) My Java Database Code is more or less standard stuff: String driver = ""com.mysql.jdbc.Driver""; String dbase = ""jdbc:mysql://bla""; String dbuser = ""bla""; String dbpw = ""bla""; Class.forName(driver); Connection con = DriverManager.getConnection(dbase dbuser dbpw); Statement stmt = con.createStatement(); ResultSet rs = stmt.executeQuery(query); while (rs.next()) { ergebnis = rs.getString(""info.INFORMATION""); } rs.close(); stmt.close(); con.close(); edit: I have tried this DBCP for a while now and I can't seem to get it to work. It seems to be as slow as the old connection. This is the example provided by the website that I use: GenericObjectPool connectionPool = new GenericObjectPool(null); ConnectionFactory connectionFactory = new DriverManagerConnectionFactory(""jdbc:mysql://bla"" ""bla"" ""bla""); PoolableConnectionFactory poolableConnectionFactory = new PoolableConnectionFactory(connectionFactoryconnectionPoolnullnullfalsetrue); PoolingDriver driver = new PoolingDriver(); driver.registerPool(""example""connectionPool); Connection conn = DriverManager.getConnection(""jdbc:apache:commons:dbcp:example""); Are you using a connection pool? No not yet. But I will look into it now. Well I think this warrants a discussion on the design.There are a few things which you can do in order to improve the performance. Since you are not persisting anything here its better to preload all the data in memory in some custom java object a map list or whatever and then do an in-memory lookup for the word and get the results. Another approach could be to use a batch statement so that you dont go ahead and create and release connections for each word. Oh and if using batch statements make sure you set the batch size to an appropriate number preferably a prime number Well then basically the design warrants a requirement as to why are you storing word based data in a relational database. If you are doing it for the sake of persistence i think the solution does not make sense. A better approach would be to let it be file based and use some IR library for indexing and search. Maybe it would be a better approch but I was happy to somehow do what was asked from me. Never thougt that a file based system was also a possebility. Maybe next time ... It's just a prototype. It somehow has to work it's no big deal if it isn't perfect. Preloading all the data? That may be possible with a small database but the bigger the database the more the user has to load over the internet. It may be faster for searching but until the computer has all the data it needs it has taken longer than my old approach.  I suspect that it's the connection setup that is causing the problem. It would be worth timing how long this takes: Connection con = DriverManager.getConnection(dbase dbuser dbpw); and if so check out Apache Commons DBCP which allows you to pool database connections. yeah it seems to be the problem... This alone takes about 2 seconds. I will read your link. Excellent (that you've found the problem). The pool will set up and maintain connections for you and hand them out on demand without the connection time overhead. I tried it but I can't seem to get it to work. Maybe you could look at the connection pool code I edited into my original post? Are you building the pool in advance and simply calling DriverManager.getConnection() when you require (ie. not setting up a whole pool for each iteration?) I wrote a test class that does nothing beside what I posted above (connection pool) and telling me how long it took. I just see that at my old code I started a new connection for every word ... maybe if I change that it's fast enough without this pooling stuff. It still has to make the connection. The point is that the pooling then keeps that connection for reuse. So a single test won't reveal any speed increase. You have to reuse the connection to make it worthwhile. I changed my old database code so that it has three methods: one that is only called once at the beginning of the chat and opens the connection. The second sends the querys and is called a lot. The third that's called just once at the end of the chat closes the connection. At the moment it seems to be fast enough. I will try the pooling code if I have speed problems again. Never knew that something like this existed. Thanks a lot!"
570,A,"Is there a way to determine that a Connection is managed? I have some legacy JDBC code that is used within an EJB in this code a call to setAutocommit() is made (which is not allowed for managed transactions for understandable reasons). I would like to skip this method call if the code is used within a managed transaction but let the call remain if used in an un-managed context. Is there a standardised way to detect if a JDBC Connection object is ""managed"" or not? A bit decent transaction manager does setAutoCommit(false) and setTransactionIsolation(Connection.TRANSACTION_XXX). Depending on the JDBC driver and the transaction manager used you may have some luck with getAutoCommit() and/or getTransactionIsolation(). Determine by testing which values are been used in both cases so that you can learn how to distinguish the one from other. Good advice! I eventually decided to just skip the setAutoCommit entirely though since I realized the code I had would really just be used within a container at the moment anyway and will hopefully be completely deprecated soon but your suggestions seems like a good solution would I need to do it."
571,A,"java database connection retrieval I am using the code below to display the records from my database in the swing form. However when I click on the button it only shows the first record of the database (table in database has 5 records) private void btnnextActionPerformed(java.awt.event.ActionEvent evt) { try { Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver""); Connection con=DriverManager.getConnection(""jdbc:odbc:StudentDetails""); Statement stm=con.createStatement(ResultSet.TYPE_SCROLL_SENSITIVEResultSet.CONCUR_UPDATABLE); ResultSet rs=stm.executeQuery(""Select * from NurseryStDetails""); if(rs.first()) { txtstID.setText(rs.getString(1)); txtname.setText(rs.getString(2)); txtaddress.setText(rs.getString(3)); // int i=rs.getInt(4); // String s=String.valueOf(i); // txtage.setText(rs.getString(s)); // int j=rs.getInt(5); // String t=String.valueOf(j); txtage.setText(rs.getString(4)); txttelephone.setText(rs.getString(5)); txtgNIC.setText(rs.getString(6)); txtgname.setText(rs.getString(7)); } } catch(Exception ex) { System.out.println(""Exception caught""+ex); } } if(rs.first()) That checks if you're on the first record in the resultset  Well you've indeed written the code that way. Here's a cite of the Javadoc of ResultSet#first(): Moves the cursor to the first row in this ResultSet object. Returns: true if the cursor is on a valid row; false if there are no rows in the result set. You see all it does it moving the cursor to the first row. Nothing more. You basically need to replace this by ResultSet#next() in a while loop. It will then iterate through all rows as long as there's a row. while (rs.next()) { // ... } But there's another problem. If you make only that change then the code would end up to display only the data of the last row since you're reusing the same text components for that everytime. You want to display each row separately in new fields in your UI. I don't do Swing so I can't give a detailed answer from top of my head but I at least know that you would like use to use JTable for this. See also: Swing JTable tutorial (basic) code example to display ResultSet in JTable That said there are other problems in your code. Calling Class#forName() everytime is unnecessary. Just once during application's startup is enough. Not calling close() on each of ResultSet Statement and Connection inside a finally block will cause a resource leak. If you continue running this for a long term the DB will run out of connections sooner or later and your application will not be able to connect it anymore and break. Fix it accordingly. Just printing the ex doesn't give worthy information. It'll only print the exception type and message which isn't very helpful during debugging. You'd like to do ex.printStackTrace() instead.  is it if(rs.first()) ?? try while (rs.next()) This will help u to iterate through the resultset. no then it is displayin only the last record of the table. previously it shwd the first record only You are updating the same field again and again... and hence it shows only the last value. May be you need to show array of textfields for your requirement. You can dynamically create textfields inside while loop or store the result values in array and pass it over to swing client where you have array of text fields  JDBC ResultSet object can be taken to be pointing to a location before the start of the result rows of the query being executed. the first rs.next() makes it point to the first row returned.subsequent calls to rs.next() moves it forwards in the resultant rows. Hence to display all the results use the concept while(rs.next()){ //use rs to get the details of the current row. } rs.next() returns true if the next row exists."
572,A,"Java SQL database independence I have been looking for an alternative to Hibernate for various reasons. I came across Liquibase and i like the idea so i am willing to try it. Liquibase will cater for database creation/modification in a SQL independent fashion. My main question is how does my code in my application execute SQL statements without being database dependent? Is there some other project that acts like Hibernates Dialect classes? Thanks Paul Later you talk about your application and executing SQL statements (not saying ""DDL only""). Plus comparing LB to Hib. That's where all the confusion grows. Excuse me but Liquibase seems to be a ""version control"" tool for database not DB access library. So your question sort of make no sense. IMHO. What part does not make sense? I am talking about a solution for database independence and Liquibase is for the creation/modification or ""version control"". My main question is how does my code in my application execute SQL statements without being database dependent? Well the only way to really achieve this is to use a higher level query language than SQL that would be translated into database specific SQL. And we have already a few (proprietary standard) DSLs for this: Toplink QL EJB-QL JDO QL HQL JPQL etc. My suggestion would be to pick your poison (but please don't roll your own solution).  One of the issues with using SQL is that it is vendor-dependent. I don't think there's any way of getting around that without using some third-party library or framework (like Hibernate!). But if you do go with SQL I'd strongly recommend you take a look at Ibatis. I have looked and used ibatis. I dont see how this helps with my problem. Am i missing something?  If you want to use liquibase's SQL generation classes outside of the normal liquibase process you can. Especially in 2.0 the sql generation classes have been improved and abstracted but depending on what you are wanting to run it may not meet your needs. Since liquibase is about database migrations most of the database-independent logic is around DDL statements (create table/add column etc.) and not as much around insert/update/delete statements. Not knowing what type of statements you will run I would assume you are more concerned about cross-database insert/update/delete statements in which case you will be better served by hibernate/ibatis/etc.  I doubt it - the dialects in hibernate are used for translating objects and HQL queries to proper native queries. If you want to use plain SQL queries then you should translate SQL queries to.. SQL queries. One way to achieve database independence is to use only ANSI SQL. But even that does not guarantee complete database independence. I'd suggest sticking with hibernate and HQL (JPA-QL) Sticking to ANSI SQL also means that you're quite limited in what you can do as there are many things that lie outside the scope of the standard. (Especially if only older versions of the spec are supported.)"
573,A,"jdbc + large postgresql query give out of memory I'm trying to execute a postgresql query which returns a large result: connection.setAutoCommit(false); st = connection.createStatement( ResultSet.CONCUR_READ_ONLY ResultSet.TYPE_FORWARD_ONLY ); st.setFetchSize(100); logMemory(); System.out.println(""start query ""); rs = st.executeQuery(queryString); System.out.println(""done query ""); logMemory(); but this uses a lot of memory: Free memory; 4094347680 (= 3905 mb). start query done query Free memory; 2051038576 (= 1956 mb). (printed with Runtime.getRuntime().freeMemory() ) So far it works but the database is going to be a lot bigger. I don't ever need the entire result in memory; I just need to proccess each row write the results to disk and go to the next row. I know 'setFetchSize' is only a hint but I would find it strange if postgresql/jdbc would ignore it as it's around for ages. Any way to get around this? My only idea so far is to make a batch script which streams the result of the query to disk and then parse the file from Java... Just curious what is the max heap size you are running with? Or are you using default? It's -Xmx4096M -Xms4096M it's a vista 8GB machine. Here are the guidelines for ensuring that the result set is actually retrieved with a cursor. You seem to hit on all of the known ones in your code but you haven't specified the statement so it may be several strung together with semicolons (unlikely by the looks of your code). You have to be using the V3 protocol (version 7.4 or later). Do all of these things apply to your case? Yeah I've tried switching on/off all the guidelines. The statement is simply Select hh.data hh.customer_ID from dataTable hh join customer PH on hh.customer_ID = PH.customer_ID ; and it's postgresql 8.3 and I'm using postgresql-8.3-603.jdbc4.jar . I'm stumped. I'd say the next best step is to post on groups that focus on Postgresql. There are probably some other non-obvious things that causes/can force the connection to use a cursor. I'd crack open the JDBC source code (that is the nice thing about open source) and see what is going on in your scenario. Thanks a lot for the answer. I was struggling this problem for the whole day until I've found a requirement for `conn.setAutoCommit(false)` on the page you cited.  Ouch this is one of the most nasty bugs using JDBC I've seen. You should change st = connection.createStatement( ResultSet.CONCUR_READ_ONLY ResultSet.TYPE_FORWARD_ONLY ); into st = connection.createStatement( ResultSet.TYPE_FORWARD_ONLY ResultSet.CONCUR_READ_ONLY ); Maybe simply st = connection.createStatement(); will work as well (as you've met the other criteria for a cursor)."
574,A,"Is Hibernate good for batch processing? What about memory usage? I have a daily batch process that involves selecting out a large number of records and formatting up a file to send to an external system. I also need to mark these records as sent so they are not transmitted again tomorrow. In my naive JDBC way I would prepare and execute a statement and then begin to loop through the recordset. As I only go forwards through the recordset there is no need for my application server to hold the whole result set in memory at one time. Groups of records can be feed across from the database server. Now lets say I'm using hibernate. Won't I endup with a bunch of objects representing the whole result set in memory at once? If there are possible performance issues then stick with the JDBC code. There are a number of well known pure SQL optimisations which which would be very difficult to do in Hibernate. Only select the columns you use! (No ""select *"" stuff ). Keep the SQl as simple as possible. e.g. Dont include small reference tables like currency codes in the join. Instead load the currency table into memory and resolve currency descriptions with a program lookup. Depending on the DBMS minor re-ordering of the SQL where predicates can have a major effect on performance. If you are updateing/inserting only commit every 100 to 1000 updates. i.e. Do not commit every unit of work but keep some counter so you commit less often. Take advantage of the aggregate functions of your database. If you want totals by DEPT code then do it in the SQL with "" SUM(amount) ... GROUP BY DEPT "". Changing the projection is dead easy in Hibernate you can get back List modeling a relational results grid or have Hibernate instantiate a specific object for you using native SQL or HQL. Aggregate functions and GROUP BY are also available in the Criteria API and in HQL.  In my opinion I would NOT use Hibernate since it makes your application a whole lot bigger and less maintainable and you do not really have a chance of optimizing the generated sql-scripts in a quick way. Furthermore you could use all the SQL functionality the JDBC-bridge supports and are not limited to the hibernate functionality. Another thing is that you have the limitations too that come along with each layer of legacy code. But in the end it is a philosophical question and you should do it the way it fits you're way of thinking best.  Hibernate does also iterate over the result set so only one row is kept in memory. This is the default. If it to load greedily you must tell it so. Reasons to use Hibernate: ""Someone"" was ""creative"" with the column names (PRXFC0315.XXFZZCC12) The DB design is still in flux and/or you want one place where column names are mapped to Java. You're using Hibernate anyway You have complex queries and you're not fluent in SQL Reasons not to use Hibernate: The rest of your app is pure JDBC You don't need any of the power of Hibernate You have complex queries and you're fluent in SQL You need a specific feature of your DB to make the SQL perform  Hibernate as any ORM framework is intended for developing and maintaining systems based on object oriented programming principal. But most of the databases are relational and not object oriented so in any case ORM is always a trade off between convenient OOP programming and optimized/most effective DB access. I wouldn't use ORM for specific isolated tasks but rather as an overall architectural choice for application persistence layer.  Hibernate offers some possibilities to keep the session small. You can use Query.scroll() Criteria.scroll() for JDBC-like scrolling. You can use Session.evict(Object entity) to remove entities from the session. You can use a StatelessSession to suppress dirty-checking. And there are some more performance optimizations see the Hibernate documentation."
575,A,"Getting the Return Value from JDBC MSSQL I'm connecting to SQL Server (2005) through Java using the Microsoft SQL Server JDBC Driver 2.0. How do I get the return value from a stored procedure? I'm doing something like: Connection connection = dataSource.getConnection() CallableStatement proc = connection.prepareCall(""{ call dbo.mySproc() }""); proc.execute(); Should I be using execute()? executeQuery()? executeUpdate()? None of these seem to return a return value by default but I'm not really sure how to get to it. EDIT 1: To be clear I know how to call stored procedures. This question is specifically about how to get the RETURN VALUE (as opposed to a Result Set). The Return Value is an integer that is usually generated when you execute a query with no Result Set or if you specifically state something like RETURN 0 in your SQL. EDIT 2: executeUpdate() returns an int but this int is not the same as the Return Value. Also an OUT parameter is not the same as a return value. Check the following links [http://www.exampledepot.com/egs/java.sql/CallProcedure.html](http://www.exampledepot.com/egs/java.sql/CallProcedure.html) [http://www.jguru.com/faq/view.jsp?EID=30731](http://www.jguru.com/faq/view.jsp?EID=30731) I'm looking specifically to get the Return Value I'm not looking for generic information about calling sprocs. For reference here is the official docs for the CallableStatement class: http://docs.oracle.com/javase/7/docs/api/index.html?java/sql/CallableStatement.html  c.prepareCall(""? = ..""); cs.execute(); String returnedValue = cs.getString(1); (or the method of the appropriate type. You can use getObject alternatively) From an old getting started tutorial the getXXX methods in CallableStatement retrieve values from the OUT parameters and/or return value of a stored procedure. (Btw the links that were provided by Umesh had this sort of information.) That returns an output parameter which is different from a return value. I think the stored procedure would have to have an output parameter defined in order for this to work. no it isn't in the context of CallableStatement (check my updated answer) +1 for getting me close to the right answer thanks for the help  Bozho's 2nd revised answer was close but not quite there. It did lead me to the answer though. Taking the code example I started with we end up with: CallableStatement proc = connection.prepareCall(""{ ? = call dbo.mySproc() }""); proc.registerOutParameter(1 Types.INTEGER); proc.execute(); int returnValue = proc.getInt(1); The key pieces here are the ""? ="" in front of the ""call"" in the prepareCall function which sets up a place for the return value and the registerOutputParameter. It has to be registered as an Integer as the return value is always an int (at least in SQL Server maybe it's different in other DBs). You therefore have to get it using getInt. I tested this method and it does work."
576,A,"How to manage db connections on server? I have a severe problem with my database connection in my web application. Since I use a single database connection for the whole application from singleton Database class if i try concurrent db operations (two users) the database rollsback the transactions. This is my static method used: All threads/servlets call static Database.doSomething(...) methods which in turn call the the below method. private static /* synchronized*/ Connection getConnection(final boolean autoCommit) throws SQLException { if (con == null) { con = new MyRegistrationBean().getConnection(); } con.setAutoCommit(true); //TODO return con; } What's the recommended way to manage this db connection/s I have so that I don't incurr in the same problem. Check the database query log or start making your own logs to see what is going wrong. No database will never do rollbacks because of two concurrent users you probably have errors in your queries or missings commits. I've not much experience with PostgreSql but all the web applications I've worked on have used a single connection per set of actions on a page closing it and disposing it when finished. This allows the server to pool connections and stops problems such as the one that you are experiencing. Yes but isn't a new servlet thread created for each client request? Then if I have a connection per servlet (closed at the end of it) I'll soon receive a: fatal error: too many connections already. Isn't it?  Keeping a Connection open forever is a very bad idea. It doesn't have an endless lifetime your application may crash whenever the DB times out the connection and closes it. Best practice is to acquire and close Connection Statement and ResultSet in the shortest possible scope to avoid resource leaks and potential application crashes caused by the leaks and timeouts. Since connecting the DB is an expensive task you should consider using a connection pool to improve connecting performance. A decent applicationserver/servletcontainer usually provides a connection pooling facility in flavor of a JNDI DataSource. Consult its documentation for details how to create it. In case of for example Tomcat you can find it here. Even when using a connection pool you still have to write proper JDBC code: acquire and close all the resources in the shortest possible scope. The connection pool will on its turn worry about actually closing the connection or just releasing it back to pool for further reuse. You may get some more insights out of this article how to do the JDBC basics the proper way. Hope this helps. for simplicity (now) I'm ok with the time it takes to open and close the connection. Actually I'm not even (yet) worried about the crash after the DB timeout. My question is about synchronizing the multiple requests of a connection to the db. My method above doesn't do any synchronization. I'm not sure what's happening but it seems like both threads share the same connection and that's detected as a problem in itself or the 2nd thread steels it from the 1st again being detected as an error. and btw I was already closing the connection at the end of each db method but that conflicts with this singleton connection because one thread could close it before another is done with it. Opening and closing connection in shortest possible scope (in the very same method block) should already fix the problem of connections being shared. how?! ""I was already closing the connection at the end of each db method but that conflicts with this singleton connection because one thread could close it before another is done with it."" Are you considering that my Database has only static methods and so thread A could be in method m (with the connection) while thread B comes and calls method m too! (or m' if u like) and when 2nd m requests the connection I get my problem. No opening the connection by `DriverManager#getConnection()` or `DataSource#getConnection()` not by `SomeBadSingleTon#getConnection()`. Follow the article link and carefully read it. I extract the relevant bits: Connection getConnection(){ return dataSource.getConnection(); } This is just what my new MyRegistrationBean().getConnection(); i.e. return DriverManager.getConnection(""jdbc:jdc:jdcpool""); new or an instance variable is the same thing since MyRegistrationBean includes:static { try { new MyConnectionDriver(className url username password); } So the only real difference btw my code and the one you suggest (in these bits) is not keeping a singleton connection and static. That didn't work. How could static db class be the problem? You told you were using a single connection for the whole application. That's the problem. You should create a physically new connection inside the very same method block where you're doing the query and close it in the `finally`. yes because doing that results in FATAL: sorry too many clients already authentication failed. For the nth trial I've changed the code so that the getConnection stated in the q returns new MyRegistrationBean().getConnection() instead of keeping a singleton con and return that. That's a new connection for each method isn't it? Then I do close it with code very similar to yours. That's correct. I still strongly recommend to read the last linked article in my answer to learn how to do this all nicely. I did read it. Indeed from it I've caught the nice idea of a close function and made the above observations. I'm willing to plugin all that DAO code though (maybe in some other new project) because it's beyond my purposes. Besides that wouldn't explain the problem of my problem. According to your claims I shouldn't be getting this FATAL error yet I'm. The only smelly thing left is static and that I get the connection from within db class not the servlet (possibly on another thread). The initial problem was that you're returning the **same** connection everytime. You create it only once and returns it everytime. That's just plain wrong. As to the *too many clients* error the detail/stacktrace is missing but this just sounds like as if that the opened connections are not closed properly. Fixing the code to make it close them all in finally and restarting the app and the DB should resolve it. okaylet me get it right. restart : sure. I'm indeed not doing finally everywhere because that would mean that my servlets don't call Database.m(..) but need to keep Connection and pass it along. Or add in between a middleman (no!) or use con as static variables in database -> will not work. So will try with passing Connection along from servlet to Database.m(..) and finally in servlet code. For that you actually need an extra *transaction* layer but you at least got the point now.  Singleton should be the JNDI pool connection itself; Database class with getConnection() query methods et al should NOT be singleton but can be static if you prefer. In this way the pool exists indefinitely available to all users while query blocks use dataSource.getConnection() to draw a connection from the pool; exec the query and then close statement result set and connection (to return it to the pool). Also JNDI lookup is quite expensive so it makes sense to use a singleton in this case."
577,A,"what is the harm of using executeQuery instead of executeUpdate for deleting rows In my code I am using String query= ""delete all from myTable""; stmt.executeQuery(query); Ideally for DML executeUpdate should be used instead. However executeQuery too works well. So was curious to know what could be the harm of using executeQuery instead of executeUpdate? It does not tell you how many rows were affected. It creates a ResultSet (or maybe not?) of questionable value. And are you sure that this works well with all databases? The Javadoc says that the driver can throw an SQLException if ""the given SQL statement produces anything other than a single ResultSet object"" for which DELETE probably qualifies. If you really do not know if you are about to run a query or DML you could use execute() which works for both and then lets you call getUpdateCount or getResultSet and even getMoreResults. i dont need all the databases to work with. just oracle db  First you don't get the number of updated row. Second depends on the JDBC driver your query may be failed. what if i dont need to know that? You can use the method if you insist to do that and there is no bad effect you can observe. But doing that means you also ready to modify the application if the JDBC driver get updated (and bahave differently)."
578,A,"In-memory database close() In an in-memory database is it necessary to close ResultSets Statements and Connections? My Java program uses HSQLDB to create a ""memory table"" and populate it with data which it later queries. There is no persistence. Everything is done in memory. The program is single-threaded and only has one database connection (i.e. no database connection pooling). It's always best to close your jdbc objects - otherwise you risk memory leaks. Read (at least) items 6 and 7 from Effective Java Chapter 2 - they are more or less related.  connections: definitely (as the DB may have a connection limit; in case you'd put it on a different server there's also network overhead) other objects: database may not care but your JVM keeps them in memory too (and won't GC them). Plus it's good practice to clean up after yourself so you have a better view of ""what I'm working with now""."
579,A,"JDBC Connection pool not reopening Connections in tomcat I have set up tomcat to use a connection pool yet after the mysql timeout on connections the connections previously open in the pool are not opened.Here is what my context.xml file looks like: <Resource name=""jdbc/hpsgDB"" auth=""Container"" type=""javax.sql.DataSource"" maxActive=""5"" maxIdle=""3"" maxWait=""10000"" username=""uname"" password=""password"" driverClassName=""com.mysql.jdbc.Driver"" url=""jdbc:mysql://localhost:3306/hpsgdb?autoReconnect=true""/> As you can see i have included autoReconnect as true yet it doesn't. I have checked the process on the database after 8 hours which is what the time out is set to. If anyone can help then please help me as this has been a problem for a few months yet has just cropped up as urgent due to my software going live soon. Thanks in Advance Dean Chester With your configuration it's not supposed to create another connection if it's idle. Try to add  minIdle=""3"" With this setting DBCP will maintain 3 connections all time. We see exactly the same behavior with one of lightly used servers. Due to the default connection timeout of 8 hours we see no connections when we come in the morning. That's what we expected. However sometimes we see stale connection and the first request will fail. To get around this issue you need add following attributes testWhileIdle=""true"" timeBetweenEvictionRunsMillis=""60000""  First get rid of the autoReconnect property. You don't need this with a connection pool and may cause problems. Second ensure that you close all resources (Connection Statement and ResultSet) in your JDBC code in the finally block. I am not sure if this applies in your case but a common misconception among starters is that they seem to think that you don't need to close those resources in case of a pooled connections. This is untrue. A pooled connection is a wrapper (decorator) around a connection which has a slightly changed close() method which roughly look like public void close() throws SQLException { if (this.connection is still active) { do not close this.connection but just return it to pool for reuse; } else { actually invoke this.connection.close(); } } With other words closing them frees up the pooled connection so that it can be put back in the pool for future reuse. If you acquire connections without closing them then the pool will run out of connections sooner or later.  Since this is urgent and for production I suggest you have look at a decent connection pool such as c3p0. It's more robust and reliable and can handle timeouts better.  Try adding a validation query attribute. This should have the effect of automatically closing and re-opening the connection after a timeout like this: validationQuery=""SELECT 1"" I got this solution on another forum aswell and already have done this. validationQuery is not enough. Please read: http://leakfromjavaheap.blogspot.com/2013/11/robust-db-connection-pool-configuration.html"
580,A,"Is there a 64bit driver for Microsoft Access? java.sql.SQLException: [Microsoft][ODBC Driver Manager] The specified DSN contains an architecture mismatch between the Driver and Application I get the following error when I try to connect to my Microsoft Access database from an eclipse project using jdbc. I am using 64bit windows and microsoft office 2007. any help on this matter would be great. Microsoft Office 2007 sorry. There is no such thing as Microsoft Office 2006 even on Mac. Access 2010 has 64 bit drivers and can be downloaded http://www.microsoft.com/downloads/details.aspx?FamilyID=C06B8369-60DD-4B64-A44B-84B371EDE16D&displaylang=en The instructions state: >If you are application developer using ODBC to connect to Microsoft Office Excel data set the Connection String to “Driver={Microsoft Excel Driver (*.xls *.xlsx *.xlsm *.xlsb)};DBQ=path to xls/xlsx/xlsm/xlsb file” where exactly would i put this connection string if using jdbc to connect to the access database? That is the Excel driver you may wish to look at this: http://stackoverflow.com/questions/1418807/accessing-access-over-jdbc-using-odbc The download citation gives connect string instructions for Access via OLEDB and ODBC.  64bit applications can't play with the 32bit Jet (Access) drivers. You need to fix this. Two ways: The hard crazy cat lady way is to route the queries through something that can go both ways such as installing the 32bit version of SQL Server Express writing stored procedures in it to query the Access database and then call the stored procedures from your 64bit application. The easy ""correct"" but potentially buggy for a short while way is to download and install the beta version of the Office 2010 Jet drivers (redistributable) which finally support 64bit mode. They can be downloaded from Microsoft here. It actually went gold several weeks ago. I downloaded the RTM from MSDN on April 26th for instance. The link is definitely no longer the beta. I see thank you very much. i downloaded the office 2010 drivers however I am unsure on how exactly to use them. The instructions state: >If you are application developer using ODBC to connect to Microsoft Office Excel data set the Connection String to “Driver={Microsoft Excel Driver (*.xls *.xlsx *.xlsm *.xlsb)};DBQ=path to xls/xlsx/xlsm/xlsb file” where exactly would i put this connection string if using jdbc to connect to the access database? I would think the 64-bit ACE is now out of beta since Office 2010 went gold in April and the RTM version was made available for download on MSDN on April 22nd. I have it installed on my Win7 test laptop in fact. So the beta should have been replaced with a production version (since it's shipping in Office 2010) or it will be very soon. I actually just saw an announcement of Office 2010 going gold (retail gold) a few hours after this on Google News. And looking at the link now - it's no longer pointing at a beta download but what appears to be the production one."
581,A,Check if edit is valid for database ms-access I want to be able to check if I can edit a cell in a database with a new object Example method declaration: something.isValid(Object newObject row column); Example cases: If the editing cell stores an Number and I give it a String the method will return false... If the editing cell has to be different than every other entry (unique) and the new object is the same as something else the method will also return false.... My main goal... I want to check a whole row and if everything is valid I will edit the whole row. Right now the only way I can find out if I can actually edit something is by actually editing it and seeing if I get an error. edit://Interface DatabaseMetaData is a good method. Is there a SQL command method? *edit://I feel like the resultsetmeta data is good enough. however where is the isUnique() Method? edit://isSigned() accomplishes this? edit://So I just check if !isSigned() and isWritable(). What about database column conditions? For example... X has to be more than 3 characters...* Don't use Object but just use the type which is associated with the datatype in question. You can find here more detailed information about which Java object types you should be using for certain DB datatypes with under each this table: Alternatively you can use DatabaseMetaData#getColumns() to figure the column information (column name datatype size maxlength nullable etc). There are lot of other methods which may be of use e.g. getIndexInfo() to figure all indexes the getPrimaryKeys() to figure the PK's the getExportedKeys() to figure the FK's etcetera. Just poke a bit round in the whole DatabaseMetaData API to find that you need. This was useful but I think ResultSetMetaData is easier. Thoughts? It contains the same information. You only have to create/prepare a `Statement` and query a `ResultSet` first before you can get it. This makes not much sense. With just the `Connection` you can already get the `DatabaseMetaData`. Oh I see. That is a big benefit. Changing my RSMD stuff to DMD stuff now... Getting `[Microsoft][ODBC Driver Manager] Driver does not support this function` for a lot of things... but oh well :\ The ODBC bridge driver is indeed a pain in the ass. You can either go for [HXTT JDBC driver](http://www.hxtt.com/access.html) (costs $$$ tho) or replace MSAccess by a real DB server which ships with decent (and free) JDBC drivers. Forced to use access :( I have everything but if it is required or unique. That is all I need left. I can just hard code it I guess...
582,A,"When I call PreparedStatement.cancel() in a JDBC application does it actually kill it in an Oracle database? I have Java JDBC application running against an Oracle 10g Database. I set up a PreparedStatement to execute a query and then call ps.executeQuery() to run it. Occasionally the query takes a long time and I need to kill it. I have another thread access that PreparedStatement object and call cancel() on it. My question is does this actually kill the query in the database? Or does it just sever it from the client and the query is still running somewhere in the bowels of Oracle? Thanks! It depends on the driver you are using both the driver and the database need to support the cancellation of a statement in order for it to work as you want. Oracle does support this feature but you'd need to know more about the specific driver you are using to know for sure. Alternatively you could run a simple test by looking at the database after initiating and canceling a long running query.  The answer is that it's a quality-of-implementation issue. If you look at the javadoc for Statement.cancel() it says it'll happen ""if both the DBMS and driver support aborting an SQL statement"". In my experience with various versions of Oracle JDBC drivers Statement.cancel() seems to do what you'd want. The query seems to stop executing promptly when cancelled.  Please note that what I say below is based on observations and inferences of Oracle in use and is not based on any deep understanding of Oracle's internals. None of it should be considered authoritative. What ninesided said in their first paragraph is correct. However beware the test suggested. Not all long-running oracle queries are the same. It seems that queries are evaluated over two phases first a phase that combines up sufficient data to know how to return the rows in the right order and second a phase that returns the rows filling in the gaps that it didn't compute in the first phase. The division of work between the two phases is also affected by the settings of the cost-based optimizer. e.g. First-rows vs All-rows. Now if the query is in phase 1 the cancel request seems at best to be queued up to be applied at the end of phase 1 which means that the query continues operating. In phase 2 rows are returned in bunches and after each bunch the cancel command can take effect so assuming the driver supports the command the cancel request will result in the query being killed. The specification for the JDBC cancel command does not seem to say what should happen if the query does not stop running and therefore the command may wait for confirmation of the kill or may timeout and return with the query still running."
583,A,"how to store BigInteger values in oracle database I have connected Java program to Oracle database using JDBC. I want to store BigInteger values(512 bits) in the database. What should be the type of the column? I m trying like this: I have taken a column of number type in the database. I converted BigInteger to BigDecimal like this: BigInteger b=new BigInteger(""5779857570957802579079""); Number n =b; BigDecimal d=(BigDecimal)n; PreparedStatement pstmt=con.prepareStatemant(""insert into database values(??)""); pstmt.setString(1""john""); pstmt.setBigDecimal(2d); I am getting the following exception:  javax.servlet.ServletException: java.lang.ClassCastException: java.math.BigInteger cannot be cast to java.math.BigDecimal root cause java.lang.ClassCastException: java.math.BigInteger cannot be cast to java.math.BigDecimal Is there anything wrong in this code snippet? If there is please suggest other methods. Please format your question with lists. Some pointers [here](http://stackoverflow.com/editing-help) can i store BigDecimal in a column of NUMBER type Both BigInteger and BigDecimal extend java.lang.Number however this does not mean that you can cast from BigInteger up to Number then down to BigDecimal. There is a constructor in BigDecimal that takes a BigInteger so try: BigDecimal d = new BigDecimal(b); i tried but i m getting another exception. javax.servlet.ServletException: java.sql.SQLException: [Oracle][ODBC]Invalid precision value. root cause java.sql.SQLException: [Oracle][ODBC]Invalid precision value Possible that the type of the column you are inserting into doesn't accept BigDecimal?  You can use a decimal/numeric value depending on your db limits.  I'm not answering directly your question but i only see one oracle datatype that can store a 512 bits number : varchar2(156) (156 = abs(log(2^512))+2) So i would rather convert the biginteger to a string rather than a bigdecimal. i used varchar2(4000) and it is working. a `RAW(64)` would work as well."
584,A,Is it possible to make a JDBC connection through SSIS? I've never used a JDBC connection before and am familiar with only ODBC connections. We have a vendor who will only support JDBC. They consider ODBC 'Open Source' and therefore do not support connections to their DB through an ODBC connection. Does anyone know if it is possible to create an SSIS connection via JDBC? I am not getting any hits on this from my initial research online. No SSIS does not have the java interface necessary to do this. You would have to use an ADO.Net or OLEDB driver or the OLEDB provider for ODBC to connect to a database. You could write a java program that extracted the data to a file and then read the data from that file. You can execute a process from SSIS which could be used to run the Java program. Any workarounds that you know of?
585,A,"Weblogic 10.3 JDBC Oracle SQL - Table or View does not exist I've got a really odd issue that I've not had any success googling for. It started happening with no changes to the DB connection settings code etc. Problem is when accessing a servlet one of the EJB's is doing a direct SQL call very simple ""select \n"" + "" value \n"" + "" other_value \n"" + "" from \n"" + "" some_table \n"" + "" where some_condition = ? "" That's obviously not the direct SQL but pretty close. For some reason this started returning an error stating ""ORA-00942: table or view does not exist"". The table exists and the kicker is if I hook in a debugger change a space or something minor (not changing the query itself) in the query and hot-deploy the change it works fine. This isn't the first time I've run across this. It only seems to happen in dev environments (haven't seen it in q/a sandbox or production yet) is not always replicable and driving me seriously insane. By not always replicable I mean that occasionally a clean build & redeploy will sometimes fix the problem but not always. It's not always the same table (although if the error occurs it continues with the same query). Just throwing a feeler out there to see if anybody has run into issues like this before and what they may have discovered to fix it. Two questions: 1) Which version of Oracle 2) Do the dev environments have multiple schemas that each contain a table of the that same name Oracle 11g (11.2.0.1.0) and no single schema well there went my idea - we had a problem in a 10g dev environment where multiple schemas would have a copy of the same table and we had an intermittent problem like yours. What was happening could be generically described as an Oracle bug where one schema would try to execute SQL against another schema's object of the same name when the SQL was found in the shared pool. An Oracle version upgrade (forget which) eventually fixed it but until then we were just flushing the shared pool periodically. I imagine this would work around your issue as well -try it the next time it happens. Cool thanks for the info. I'll give that a shot when it happens again. Sounds like maybe one connection in your JDBC pool has a problem which could explain the intermittent nature and that redeploy only sometimes fixes it as you could end up still using the same connection afterwards. You could try resetting the connection pool instead of redeploying perhaps. (java weblogic.Admin -url t3://<server_url> RESET_POOL <pool_name> I think) You've said there's only one schema but does that mean only one schema exists or that all the tables are under one schema? Is it possible that you're doing an ALTER SESSION SET CURRENT_SCHEMA somewhere and when whichever connection that's issued against is returned to the pool and then randomly used for the query later it can't see anything in the main schema any more? That could happen in a package or trigger as well as from the Java side and could be a 'temporary' change that doesn't get reverted after an exception. Sounds like something that might only exist in a dev environment too... Thanks I'll try the reset pool next time it happens & see if that solves the issue. I don't think there's any session altering happening but it's possible. The error when it occurs is normally seen almost immediately after starting the app so I don't think that's it but something else to investigate for sure."
586,A,jSecurity JDBCRealm SQL setup I am trying to use jSecurity for an enterprise java app but the documentation is...well...lacking. Has anyone out there in SO-land been able to get the JDBCRealm setup and if so did you find a SQL setup script or did you just derive it on your own? Either way can you provide the create SQL statements to make this work? I have posted to the mailing list here but I don't know if\when I will get a response\I don't have a long time to wait. Thanks in advance! So far as I can tell this is it (or will work well enough in most circumstances): CREATE TABLE [dbo].[users]( [username] [varchar](50) NOT NULL [password] [varchar](50) NOT NULL ) CREATE TABLE [dbo].[user_roles]( [username] [varchar](50) NOT NULL [role_name] [varchar](50) NOT NULL ) CREATE TABLE [dbo].[roles_permissions]( [role_name] [varchar](50) NOT NULL [permission] [varchar](50) NOT NULL ) [EDIT: If you are using Maven you will need ehcache and commons-logging in your POM as well]
587,A,"Java equivalent for PHP's mysql_real_escape_string() Is there a Java equivalent to PHP's mysql_real_escape_string() ? This is to escape SQL injection attempts before passing them to Statement.execute(). I know I can use PreparedStatement instead but let's assume these are one shot statements so preparing them will result in lower performance. I've already changed the code to use PreparedStatement but given the way the existing code was structured an escape() function would make the code changes much simpler to review and maintain; I prefer easy to maintain code unless there is a compelling reason for the extra complexity. Also PreparedStatements are handled differently by the database so this could expose us to bugs in the database that we haven't run into before requiring more testing before releasing to production. Apache StringEscapeUtils escapeSQL() only escapes single quotes. Postscript: There are a lot of subtleties in the environment I inherited that I deliberately avoided in my question. Two points to consider: 1) Prepared statements are not a panacea and do not provide 100% protection against SQL injection. Some database drivers instantiate parameterised queries using unsafe string concatenation rather than pre-compiling the query to a binary form. Also if your SQL relies on stored procedures you need to ensure the stored procedures do not themselves build queries in unsafe ways. 2) Most prepared statement implementation bind the statement to the database connection the statement was instantiated on. If you are using database connection pooling you need to be careful to use the prepared statement reference only with the connection it was prepared on. Some pooling mechanisms do implement this transparently. Otherwise you could pool the prepared statements as well or (simplest but more overhead) create a new prepared statement for every query. You prefer easy to maintain code and yet you'd rather use manual string escaping rather than PrearedStatement? Given the way the existing code (which I didn't write) is yes it would be easier to maintain. the lower performance may well be more attractive than the security risk. the security penalty can just be too high. Prepare your statements in the application initialisation code and the penalty may not be noticable (application-dependent of course). Do not assume that PreparedStatements are slower. Try it measure it and then judge. PreparedStatements should always be used in preference to Statement pretty much without exception especially when SQL injection attacks are what you're trying to avoid.  You can find a Java version of mysql_real_escape_string at the VNet Publishing wiki http://wiki.vnetpublishing.com/Java_Mysql_Real_Escape_String This is madness. I can't even imagine what that code does. @droope the code checks if there are any dangerous characters in a string. If not than the string is returned without processing. The code then checks if escaping the string normally removes any possibly dangerous characters. If so than the string is returned in the escaped form. Finally the escaped string is sent to MySQL to be escaped by the QUOTE function which is specifically meant to escape strings.  org.apache.commons.lang.StringEscapeUtils.class in commons-lang.jar could solve your problem! This was what I used.  The only sensible way to avoid SQL injection is to use prepared/parameterized statements. For example the PreparedStatement you are trying to avoid for some reason. If you do one-shot statements the time to prepare them should be negligible (""one-shot"" and ""performance-critical"" is a contradiction IMHO). If you do things in a loop prepared statements even cause performance to increase.  As far as I know there is no ""standard"" way to do it. I strongly suggest using prepared statements despite your current concerns. The performance impact is going to be negligible - we have a similar situation with several thousand statements per second - most of them one-shots as well. The security you gain should be weighed much higher than a performance problem you have not even seen yet. In my opinion this is a clear situation of ""Don't optimize prematurely"". In any case should you really find out later that you run into performance problems make sure that the prepared statements are really the cause by profiling carefully and then look for alternatives. Till then you should save yourself the hassle of trying to get the escaping right. This is even more important as I infer you are developing some sort of public facing site - internal apps seldom get enough traffic to be concerned about performance anyway. Thank you for starting by answering the question I asked! You're welcome :)"
588,A,"What really comes back when using a ResultSet in JDBC? The following pseudocode works which is probably no surprise to anyone who's done any JDBC work: ResultSet rs = foo.executeQuery(); boolean hasNext = rs.next(); while(hasNext) { bar(); boolean hasNext = rs.next(); } ResultSet (java.sql.ResultSet) is an interface so there should be no implementation for next() only a method declaration. So how does the code run successfully? The best answer I found online is that what comes back is an instance of a class that implements the ResultSet interface. That answer makes sense to me (it confirms what I assumed before I actually looked it up) but it only leads to another question: how do you know what kind of class you're getting back? Couldn't it in theory be something that overrides the interface's method in an unexpected or undesirable way? @BalusC +1 for a nice all-purpose trick even though I've long since forgotten the reason I originally asked this question. I bet it's just the beginner's confusion about the use of interfaces and polymorphism and not realizing that it's the returned instance which actually contains the concrete implementation. The interface just definies the methods which you could use on the concrete implementation. The advantage in the particular case of JDBC is that you can easily switch of DB and/or JDBC driver without affecting the JDBC code (expect of DB vendor-specific SQL statements/clauses/functions of course). `System.out.println(rs.getClass());` --> That prints the implementation class. If the JDBC driver is open source take a look. By the way this isn't related to your question but I believe the recommended usage of a result set is supposed to go like: ResultSet rs = conn.executeQuery(); while (rs.next()) { bar(); } This leads to cleaner/shorter code instead of having to use a temporary boolean variable. On a more related note you can generally trust interfaces to be implemented correctly if you use ""brand name"" implementors (in this case Oracle MySQL Microsoft etc.) because of verbose documentation large user communities etc. Just like in the grocery store only use generic products if you can confirm that what's happening inside is the same as what you expect from the brand names. Thanks. You're right of course. This is such an old question that I don't remember the reason I asked but I bet I generified some debug code. I tend to intentionally break things apart too much when I debug so that I can step through more precisely.  During Runtime your JVM knows what kind of class is returned. You can even access it yourself by using the java instanceof keyword. It is perfectly possible that you get something that overrides this method in an undesirable way. But the signature of the method is always the same and only during runtime class cast problems are going to appear. This is the whole point of inheritance in an OOP language like Java. More information here.  What you get back is a class that implements those interfaces and that are found in your database driver. For example if you connect to MySQL you might use drivers from here. The driver implements those interfaces. It does not implement the interfaces in an unexpected or undesirable way if you get them from the database providers (there are implementation variations between vendors of course but it should not be something major; e.g. I got burned today when using the DatabaseMetaData.getSQLStateType(). This should return 1 or 2 but my driver implementation decided to return 0 but with everything else I had no problems)."
589,A,"Java - JDBC alternatives this is just teorethical question. I use JDBC with my Java applications for using database (select insert update delete or whatever). I make ""manually"" Java classes which will contain data from DB tables (attribute = db column). Than I make querys (ResultSet) and fill those classes with data. I am not sure if this is the right way. But I've read lot of about JDO and another persistence solutions. Can you please recommend some? Which are modern? Will be used in the future? Some advantages of JDO over JDBC (in simple words). I've been able to google lot of this stuff but opinions from the ""first hand"" are always best. Ebean ORM is another alternative http://www.avaje.org Ebean uses JPA Annotations for Mapping but it is architected to be sessionless. This means that you don't have the attached/detached concepts and you don't persist/merge/flush - you just simply save() your beans. I'd expect Ebean to be much simplier to use than Hibernate JPA or JDO So if you are looking for a powerful alternative approach to JDO or JPA you could have a look at Ebean.  I can recommend Hibernate. It is widely used (and for good reasons) and the fact that the Java Persistence API specification was lead by the main designer of Hibernate guarantees that it will be around for the foreseeable future :-) If portability and vendor neutrality is important to you you may use it via JPA so in the future you can easily switch to another JPA implementation. Lacking personal experience with JDO I can't really compare the two. However the benefits of Hibernate (or ORM in general) at first sight seem to be pretty much the same as what is listed on the JDO page. To me the most important points are: DB neutrality: Hibernate supports several SQL dialects in the background switching between DBs is as easy as changing a single line in your configuration performance: lazy fetching by default and a lot more optimizations going on under the hood which you woulds need to handle manually with JDBC you can focus on your domain model and OO design instead of lower level DB issues (but you can of course fine-tune DML and DDL if you wish so) One potential drawback (of ORM tools in general) is that it is not that suitable for batch processing. If you need to update 1 million rows in your table ORM by default will never perform as well as a JDBC batch update or a stored procedure. Hibernate can incorporate stored procedures though and it supports batch processing to some extent (I am not familiar with that yet so I can't really say whether it is up to the task in this respect compared to JDBC - but judging from what I know so far probably yes). So if your app requires some batch processing but mostly deals with individual entities Hibernate can still work. If it is predominantly doing batch processing maybe JDBC is a better choice. +1 - you beat me to it. Hibernate is a great ORM to use with sufficient flexibility to allow you to complete pretty much any task that you would do in JDBC directly. Yep I heared lot of about Hibernate Do you recommend it to use in small projects? Like 50 classes 10-15 DB tables? Or stick to manual JDBC data management? @Mike Good question. Some say it is overkill for small projects. I have done a smaller project using Cayenne (http://cayenne.apache.org) a similar ORM tool and I was satisfied. So I would definitely give it a try. It _might_ feel like you need to do a lot of ""extra"" work at startup but IMHO it will pay back in the long run.  Hibernate requires that you have an object model to map your schema to. If you're still thinking only in terms of relational schemas and SQL perhaps Hibernate is not for you. You have to be willing to accept the SQL that Hibernate will generate for you. If you think you can do better with hand-coded SQL perhaps Hibernate is not for you. Another alternative is iBatis. If JDBC is raw SQL and Hibernate is ORM iBatis can be thought of as something between the two. It gives you more control over the SQL that's executed. +1 for **iBatis**. Often being overlooked but great for read-only complex queries using proprietary features of your DBMS.  Have a look at MyBatis. Often being overlooked but great for read-only complex queries using proprietary features of your DBMS. http://www.mybatis.org  There is also torque (http://db.apache.org/torque/) which I personally prefer because it's simpler and does exactly what I need. With torque I can define a database with mysql(Well I use Postgresql but Mysql is supported too) and Torque can then query the database and then generate java classes for each table in the database. With Torque you can then query the database and get back Java objects of the correct type. It supports where clauses (Either with a Criteria object or you can write the sql yourself) and joins. It also support foreign keys so if you got a User table and a House table where a user can own 0 or more houses there will be a getHouses() method on the user object which will give you the list of House objects the user own. To get a first look at the kind of code you can write take a look at http://db.apache.org/torque/releases/torque-3.3/tutorial/step5.html which contains examples which show how to load/save/query data with torque. (All the classes used in this example are auto-generated based on the database definition).  JPA/Hibernate is a popular choice for ORM. It can provide you with just about every ORM feature that you need. The learning curve can be steep for those with basic ORM needs. There are lots of alternatives to JPA that provide ORM with less complexity for developers with basic ORM requirements. Query sourceforge for example: http://sourceforge.net/directory/language:java/?q=ORM I am partial to my solution Sormula: http://sourceforge.net/projects/sormula/. Sormula was designed to minimize complexity while providing basic ORM.  Here is how it goes with java persistence. You have just learnt java now you want to persist some records you get to learn JDBC. You are happy that you can now save your data to a database. Then you decide to write a bit bigger application. You realize that it has become tedious to try catch  open connection close connection  transfer data from resultset to your bean .... So you think there must be an easier way. In java there is always an alternative. So you do some googling and in a short while you discover ORM and most likely hibernate. You are so exited that you now dont have to think about connections. Your tables are being created automatically. You are able to move very fast. Then you decide to undertake a really big project initially you move very fast and you have all the crud operations in place. The requirements keep comming then one day you are cornered. You try to save but its not cascading to the objects children. Somethings done work as explained in the books that you have read. You dont know what to do because you didnt write the hibernate libraries. You wish you had written the SQL yourself. Its now time to rethink again... As you mature  you realize that the best way to interact with the Database is through SQL. You also realize that some tools get you started very fast but they cant keep you going for long. This is my story. I am now a very happy ibatis/User.  I recommend to use the Hibernate its really fantastic way of connecting to the database earlier there were few issues but later it is more stable. It uses the ORM based mapping it reduces your time on writing the queries to an extent and it allows to change the databases at a minimum effort. If you require any video based tutorials please let me know I can uplaod in my server and send you the link.  All these different abstraction layers eventually use JDBC. The whole idea is to automate some of the tedious and error prone work much in the same way that compilers automate a lot of the tedious work in writing programs (resizing a data structure - no problem just recompile). Note however that in order for these to work there are assumptions that you will need to adhere to. These are usually reasonable and quite easy to work with especially if you start with the Java side as opposed to have to work with existing database tables. JDO is the convergence of the various projects in a single Sun standard and the one I would suggest you learn. For implementation choose the one your favorite IDE suggests in its various wizards.  Use hibernate as a stand alone JAR file then distribute it to your different web apps. This far is the best solution out there. You have to design your Classes Interfaces Enums to do an abstract DAO pattern. As long as you have correct entities and mappings. You will only need to work with Objects(Entities) and not HSQL. No facts to back up that this is ""the best solution out there"" @Woot4Moo - Everything about this question kinda sucks. You should focus on flagging subjective ""what is the best/recommend me"" questions for closing instead.  Here is how it goes with java persistence. You have just learnt java now you want to persist some records you get to learn JDBC. You are happy that you can now save your data to a database. Then you decide to write a bit bigger application. You realize that it has become tedious to try catch  open connection close connection  transfer data from resultset to your bean .... So you think there must be an easier way. In java there is always an alternative. So you do some googling and in a short while you discover ORM and most likely hibernate. You are so exited that you now dont have to think about connections. Your tables are being created automatically. You are able to move very fast. Then you decide to undertake a really big project initially you move very fast and you have all the crud operations in place.  The story of database persistence in Java is already long and full of twists and turns: JDBC is the low level API that everybody uses at the end to talk to a database. But without using a higher level API you have to do all the grunt work yourself (writing SQL queries mapping results to objects etc). EJB 1.0 CMP Entity Beans was a first try for a higher level API and has been successfully adopted by the big Java EE providers (BEA IBM) but not by users. Entity Beans were too complex and had too much overhead (understand poor performance). FAIL! EJB 2.0 CMP tried to reduce some of the complexity of Entity Beans with the introduction of local interfaces but the majority of the complexity remained. EJB 2.0 also lacked portability (because the object-relational mapping were not part of the spec and the deployment descriptor were thus proprietary). FAIL! Then came JDO which is a datastore agnostic standard for object persistence (can be used with RDBMS OODBMS XML Excel LDAP). But while there are several open-source implementations and while JDO has been adopted by small independent vendors (mostly OODBMS vendors hoping that JDO users would later switch from their RDBMS datastore to an OODBMS - but this obviously never happened) it failed at being adopted by big Java EE players and users (because of weaving which was a pain at development time and scaring some customers of a weird query API of being actually too abstract). So while the standard itself is not dead I consider it as a failure. FAIL! And indeed despite the existence of two standards proprietary APIs like Toplink an old player or Hibernate have been preferred by users over EJB CMP and JDO for object to relational database persistence (competition between standards unclear positioning of JDO earlier failure of CMP and bad marketing have a part of responsibility in this I believe) and Hibernate actually became the de facto standard in this field (it's a great open source framework). SUCCESS! Then Sun realized they had to simplify things (and more generally the whole Java EE) and they did it in Java EE 5 with JPA the Java Persistence API which is part of EJB 3.0 and is the new standard for object to relational database persistence. JPA unifies EJB 2 CMP JDO Hibernate and TopLink APIs / products and seems to succeed where EJB CMP and JDO failed (ease of use and adoption). SUCCESS! To summarize Java's standard for database persistence is JPA and should be preferred over others proprietary APIs (using Hibernate's implementation of JPA is fine but use JPA API) unless an ORM is not what you need. It provides a higher level API than JDBC and is meant to save you a lot of manual work (this is simplified but that's the idea). +1 for success/fail. Note that for completeness I would maybe distinguish JDBC RowSet and DataSet from plain JDBC (This somehow compares to ADO.NET DataSet). Never used them and never heard of anybody using them though. brilliant THIS IS what I exaclty wanted help most appreciated! BTW : Do you know what does NetBeans IDE use byt default? F.e. when I drag&drop DB table to JTable NetBeans generates class with some management ... uses Entity Manager  Query Result etc. @Mike Thanks. Regarding NetBeans recent versions have support for JPA by default (as Sun's standard that makes sense). And indeed `EntityManager` is part of JPA. great I'll give a try to JPA I guess:) Very nice and true. @BalusC Thanks! Would you please update your answer to include a comparison of MyBatis too?  A new and exciting alternative is GORM which is the ORM implementation from Grails. Can now be used stand alone. Under the hood it uses Hibernate but gives you a nice layer on top with cool dynamic finders etc. ""Under the hood it uses Hibernate"" - and Spring.  JDO builds off JDBC technology. Similarly Hibernate still requires JDBC as well. JDBC is Java's fundamental specification on database connectivity. This means JDBC will give you greater control but it requires more plumbing code. JDO provide higher abstractions and less plumbing code because a lot of the complexity is hidden. If you are asking this question I am guessing you are not familiar with JDBC. I think a basic understanding of JDBC is required in order to use JDO effectively or Hibernate or any other higher abstraction tool. Otherwise you may encounter scenario where ORM tools exhibit behavior you may not understand. Sun's Java tutorial on their website provide a decent introductory material which walks you through JDBC. http://java.sun.com/docs/books/tutorial/jdbc/. Thank you I'll keep that in mind  If you want to write SQL yourself and don't want an ORM you can still benefit from some frameworks which hides all the tedious connection handling (try-catch-finally). Eventually you will forget to close a connection... One such framework that is quite easy to use is Spring JdbcTemplate.  Hibernate surely. It's popular there is even a .NET version. Also hibernate can be easily integrated with Spring framework. And it will mostly fit any developer needs."
590,A,"URL string format for connecting to Oracle database with JDBC I'm a newbie to Java-related web development and I can't seem to get a simple program with JDBC working. I'm using off-the-shelf Oracle 10g XE and the Eclipse EE IDE. From the books and web pages I've checked so far I've narrowed the problem down to either an incorrectly written database URL or a missing JAR file. I'm getting the following error: java.sql.SQLException: No suitable driver found for jdbc:oracle://127.0.0.1:8080 with the following code: import java.sql.*; public class DatabaseTestOne { public static void main(String[] args) { String url = ""jdbc:oracle://127.0.0.1:8080""; String username = ""HR""; String password = ""samplepass""; String sql = ""SELECT EMPLOYEE_ID FROM EMPLOYEES WHERE LAST_NAME='King'""; Connection connection; try { connection = DriverManager.getConnection(url username password); Statement statement = connection.createStatement(); System.out.println(statement.execute(sql)); connection.close(); } catch (SQLException e) { System.err.println(e); } } } What is the proper format for a database URL anyways? They're mentioned a lot but I haven't been able to find a description. EDIT (the resolution): Based on duffymo's answer I got ojdbc14.jar from Oracle's download site and dropped it in the Eclipse project's Referenced Libraries. Then I changed the start of the code to ... // jdbc:oracle:thin:@<hostname>:<port>:<sid> String url = ""jdbc:oracle:thin:@GalacticAC:1521:xe""; ... and it worked. DriverManager.registerDriver(new oracle.jdbc.driver.OracleDriver()); connection = DriverManager.getConnection(""jdbc:oracle:thin:@machinename:portnum:schemaname""""userid""""password"");  There are two ways to set this up. If you have an SID use this (older) format: jdbc:oracle:thin:@[HOST][:PORT]:SID If you have an Oracle service name use this (newer) format: jdbc:oracle:thin:@//[HOST][:PORT]/SERVICE Source: this OraFAQ page The call to getConnection() is correct. Also as duffymo said make sure the actual driver code is present by including ojdbc6.jar in the classpath where the number corresponds to the Java version you're using.  Look here. Your URL is quite incorrect. Should look like this: url=""jdbc:oracle:thin:@localhost:1521:orcl"" You don't register a driver class either. You want to download the thin driver JAR put it in your CLASSPATH and make your code look more like this. UPDATE: The ""14"" in ""ojdbc14.jar"" stands for JDK 1.4. You should match your driver version with the JDK you're running. I'm betting that means JDK 5 or 6. Just wanted to update that the documentation seems to have moved here: http://docs.oracle.com/cd/E11882_01/appdev.112/e13995/oracle/jdbc/OracleDriver.html The link provided in the top voted answer now redirects to a 404 page. Connection strings using SIDs are getting quite old-fashioned. Using service names gives the DBA much more flexibility (eg multiple services hosted on one database instance (consolidation) or using multiple instances for one service (RAC)). See @Pops answer. Seeing that the question is almost five years old I'd say that it's no surprise.  I'm not a Java developer so unfortunatly I can't comment on your code directly however I found this in an Oracle FAQ regarding the form of a connection string jdbc:oracle:<drivertype>:<username/password>@<database> From the Oracle JDBC FAQ http://www.oracle.com/technology/tech/java/sqlj_jdbc/htdocs/jdbc_faq.html#05_03 Hope that helps  The correct format for url can be one of the following formats: jdbc:oracle:thin:@<hostName>:<portNumber>:<sid>; (if you have sid) jdbc:oracle:thin:@//<hostName>:<portNumber>/serviceName; (if you have oracle service name) And don't put any space there. Try to use 1521 as port number. sid (database name) must be the same as the one which is in environment variables (if you are using windows).  if you are using oracle 10g expree Edition then: 1. for loading class use DriverManager.registerDriver (new oracle.jdbc.OracleDriver()); 2. for connecting to database use Connection conn = DriverManager.getConnection(""jdbc:oracle:thin:username/password@localhost:1521:xe"");"
591,A,"ojdbc14.jar vs. ojdbc6.jar I noticed the following difference but did not see it documented anywhere. I'm wondering if others have noticed the same thing or can point me to some documentations that proves the same. Env:- Oracle 11g JDK 1.6 iBatis PL/SQL Scenario:- ojdbc14.jar: if pl/sql returns a variable of type DATE and I try to put that in a java.sql.Date variable then everything works fine. Example: Date annualDate = (Date) map.get(""exam_date""); ojdbc6.jar: if pl/sql returns a variable of type DATE and I try to put that in a java.sql.Date variable then I get an exception: java.lang.ClassCastException: java.sql.Timestamp cannot be cast to java.sql.Date Can't you call getDate('exam_date') on the result_set and get a proper date and not a timestamp? Actually ojdbc14.jar doesn't really say anything about the real version of the driver (see JDBC Driver Downloads) except that it predates Oracle 11g. In such situation you should provide the exact version. Anyway I think you'll find some explanation in What is going on with DATE and TIMESTAMP? In short they changed the behavior in 9.2 drivers and then again in 11.1 drivers. This might explain the differences you're experiencing (and I suggest using the most recent version i.e. the 11.2 drivers).  I have same problem! Found following in oracle site link text As mentioned above the 11.1 drivers by default convert SQL DATE to Timestamp when reading from the database. This always was the right thing to do and the change in 9i was a mistake. The 11.1 drivers have reverted to the correct behavior. Even if you didn't set V8Compatible in your application you shouldn't see any difference in behavior in most cases. You may notice a difference if you use getObject to read a DATE column. The result will be a Timestamp rather than a Date. Since Timestamp is a subclass of Date this generally isn't a problem. Where you might notice a difference is if you relied on the conversion from DATE to Date to truncate the time component or if you do toString on the value. Otherwise the change should be transparent. If for some reason your app is very sensitive to this change and you simply must have the 9i-10g behavior there is a connection property you can set. Set mapDateToTimestamp to false and the driver will revert to the default 9i-10g behavior and map DATE to Date.  The ""14"" and ""6"" in those driver names refer to the JVM they were written for. If you're still using JDK 1.4 I'd say you have a serious problem and need to upgrade. JDK 1.4 is long past its useful support life. It didn't even have generics! JDK 6 u21 is the current production standard from Oracle/Sun. I'd recommend switching to it if you haven't already. I am using jdk 1.6 JDK 6 has reached the end of its support life as well. The current standard is JDK 7. Right I added new information three years later. It's not a correction; it's an update. @duffymo He said that 4 years before at the time he had right (I say that in the begin of the java8 era )."
592,A,"SQL java get value assigned to auto increment primary key I have a primary key auto increment attribute in my table. I want to know the value assigned to it for a row that is inserted using statement.executeUpdate(). How to achieve this in the best possible manner? For what database? You could use the RETURNING clause for Oracle/DB2 (and possibly Postgres); LAST_INSERT_ID for MySQL; @SCOPE_IDENTITY for SQL Server... @OMGPonies: JDBC abstracts the way databases implement this (when supported by the database). Use Statement#getGeneratedKeys() and Statement#executeUpdate(String int) (this is a JDBC 3.0 feature your database has to support JDBC 3.0). Here's an example that returns a ResultSet with values for auto-generated columns in TABLE1: Statement stmt = conn.createStatement(); int rows = stmt.executeUpdate(""INSERT INTO TABLE1 (C11 C12) VALUES (11)"" Statement.RETURN_GENERATED_KEYS); ResultSet rs = stmt.getGeneratedKeys(); @Pascal any idea i get an error saying column id not found when i call rs.getInt(""id""); what could be the reason? something related. http://bugs.mysql.com/bug.php?id=18409 but even this does not solve the problem my column has a datatype of int(11). i am using mysql @iamrohitbanga Did you try to retrieve the column by index `rs.getInt(1);`? yes i did. i still get an exception. i have posted a new question here. http://stackoverflow.com/questions/2854774/sql-jdbc-getgeneratedkeys-returns-column-id-not-found-column-type-unknown i have put up the stack trace as well as the datatypes of the columns in the table. see the link above."
593,A,"Java ResultSet how to getTimeStamp in UTC The database has data in UTC and when I try to get data java.util.Calendar cal = Calendar.getInstance(); cal.setTimeZone(TimeZone.getTimeZone(""UTC"")); java.sql.Timestamp ts = resultSet.getTimestamp(PUBLISH_TIME); cal.setTime(ts); Is there anything wrong with this? You tell us you're the one asking the question. Have you actually tried it? Does it not give results that you were expecting? If yes then what were you expecting and what were the results that it gave? And what does the database tell you when you use its own query tool? Yes I tried it yes it is not giving the results that I am expecting. The database has UTC value and this code further add +8 to the already existing value in DB. I mean +8 Hours What is the DB? Have you tried with other DB? do you know resultSet.getTimestamp(PUBLISH_TIMECalendar.getInstance()); possible? java.util.Calendar cal = Calendar.getInstance(); cal.setTimeZone(TimeZone.getTimeZone(""UTC"")); java.sql.Timestamp ts = resultSet.getTimestamp(PUBLISH_TIME cal); This should do the trick! this should be marked as the correct answer ;) Note that as per the documenation at http://docs.oracle.com/javase/6/docs/api/java/sql/ResultSet.html#getTimestamp%28int%20java.util.Calendar%29 this will work only if the underlying database does not store timestamp information @arahant if the underlying db stores timezone (not timestamp) information then there's no problem as the timestamp will be in the correct timezone. The problem is when the timestamp is stored in UTC without timezone information as Java will use the local machine's timezone to construct the timestamp object.  Your DateFormat instance is most likely displaying the value in local time. When displaying your value give this a try: java.util.Calendar cal = Calendar.getInstance(); cal.setTimeZone(TimeZone.getTimeZone(""UTC"")); java.sql.Timestamp ts = resultSet.getTimestamp(PUBLISH_TIME); cal.setTime(ts); SimpleDateFormat sdf = new SimpleDateFormat(""HH:mm:ss z""); sdf.setTimeZone(TimeZone.getTimeZone(""UTC"")); System.out.println(cal.getTime()); EDIT: to your comment: What if I use GMT would that be an issue in SimpleDateFormat SimpleDateFormat can use general timezones (GMT +/- n) RFC822 and text (""if they have names"" as the JavaDoc states - see this post for info on the names). What if I use GMT would that be an issue in SimpleDateFormat see my edits in the post."
594,A,"what are the various other programs using which i can connect to odbc database besides ms-access what are the various other programs using which i can connect to odbc database besides ms-access. i'm talking about programs in which i can run sql queries. i dont want to use ms-access because the size of the access file has become 1.5 gb . why my database is 1.5 gb ? i am using access to connect to odbc - mysql database . which is quite huge. in my access database i have several queries that create tables in the access database using odbc - mysql database thats why the size is huge . but 1.5 gb is still a bit too much for me to understand cause the sql dump of the whole database should not be more than 200 mb. maybe acess files are large in size compared to other databases. now i dont want to use access anymore . but i want to use the existing sql queries in the ms-access database to operate the odbc-mysql database. also i want the queries that create table be modified so that that they create the database in mysql itself and not in ( access ) . so i am looking for this alternate program. Stop importing the MySQL data into your Access database and your problem will permanently disappear. I don't understand your question: Are you using Access as a *frontend* to access some ODBC *backend*? (If this is the case why is your frontend 1.5gb large?) Or are you using Access *as an* ODBC database for your application and want another ODBC-accessible database system as a replacement? Are you looking for an alternative database engine or software to interact with ODBC-available databases? In the later case you'd probably better look for software dedicated to the specific DBMS vendor for the database you'll be using... Only 1.5Gb? I've had tables that require more than that. About the size of your Access frontend: If you haven't done so already try compacting the Access database file. Maybe the huge size is just a ""leftover"" from the temporary tables that were created and removed from the DB. About alternatives: You can keep using Access as the frontend and just create your tables in mysql instead (use so-called ""pass-through queries"" to enter SQL statements (CREATE TABLE INSERT INTO ...) that are executed directly on the remote ODBC data source. If you want other programs the answer depends on whether you want to do ""database administration"" (manually enter SQL statements and move around data) or ""software development"". In the latter case you can use almost any development platform available on Windows at the moment; it won't be easy finding one without ODBC client support. In the former case you might want to ask on http://serverfault.com. you answered everything and all of it works .. thanks a lot  Along the lines of GUI tools you can use to write SQL queries on top of MySQL data try looking into either the MySQL Query Browser which is part of the MySQL GUI Tools or SQLyog from Webyog. Either of these tools will allow you to right SQL queries and review the results in a data-grid. You haven't mentioned what you are doing with all this data so it's tough to decipher if you are using the access DB as only a front-end client to view the data from MySQL or if you have some application logic built into Access. However in either case you really want to look into using a tool that uses MySQL's C api directly rather than ODBC. The C api which both of the tools I mentioned above will improve the performance of the queries you're running over ODBC while at the same time reduce network and server load by not requiring the server to go through ODBC translation routines. Since this post was tagged as Java you might want to look into rolling the queries you have saved into a Java application and using JDBC to connect to your MySQL data. JDBC may not use ODBC as it's connection protocol but it will let you get to the data you have saved in your database. Of course the downside to this approach is that you'll have to roll your own application to look at the data you already have in MySQL but the trade-off is you'll have the most control over what you can do with that data programmatically.  SQL Server is one potential candidate. A linked server configuration enables SQL Server to execute commands against OLE DB data sources on remote servers e.g. use the OLE DB provider for ODBC.  Click Start->Programs->Administrative Tools->Data Sources (ODBC) Click Add. The list shows which apps you can connect to using ODBC. There's hundreds of those... If you want to connect to a MySQL server to test some queries - install the mysql GUI tools (though they connect directly not via ODBC). actually im looking for only those programs in which i can write sql queries  If you want to view a MySQL database I suggest you connect MySQL's own protocol rather than ODBC. I can suggest SQLyog as a good easy to use tool for viewing a MySQL database. Can Access/Jet/ACE use this data source? I'm afraid not."
595,A,"Hibernate+PostgreSQL throws JDBCConnectionException: Cannot open connection I write an Test Java APP and it works right BUt this Web app throws an exception like that with to same cfg.xml file <property name=""hibernate.bytecode.use_reflection_optimizer"">false</property> <property name=""hibernate.connection.autocommit"">true</property> <property name=""hibernate.connection.release_mode"">auto</property> <property name=""hibernate.current_session_context_class"">thread</property> <property name=""hibernate.connection.driver_class"">org.postgresql.Driver</property> <property name=""hibernate.connection.password"">1234</property> <property name=""hibernate.connection.url"">jdbc:postgresql://localhost/postgres</property> <property name=""hibernate.connection.username"">postgres</property> <property name=""hibernate.default_schema"">public</property> <property name=""hibernate.dialect"">org.hibernate.dialect.PostgreSQLDialect</property> <property name=""hibernate.ejb.discard_pc_on_close"">false</property> <property name=""hibernate.query.jpaql_strict_compliance"">true</property> <property name=""hibernate.transaction.factory_class"">org.hibernate.transaction.JDBCTransactionFactory</property> <property name=""hibernate.transaction.flush_before_completion"">false</property> <property name=""hibernate.show_sql"">false</property> <property name=""hibernate.generate_statistics"">false</property> <property name=""hibernate.use_sql_comments"">false</property> <property name=""hibernate.connection.pool_size"">100</property> When I press ""Save"" button I get the following exception: javax.servlet.ServletException: org.hibernate.exception.JDBCConnectionException: Cannot open connection javax.faces.webapp.FacesServlet.service(FacesServlet.java:325) root cause javax.faces.el.EvaluationException: org.hibernate.exception.JDBCConnectionException: Cannot open connection javax.faces.component.MethodBindingMethodExpressionAdapter.invoke(MethodBindingMethodExpressionAdapter.java:102) com.sun.faces.application.ActionListenerImpl.processAction(ActionListenerImpl.java:102) javax.faces.component.UICommand.broadcast(UICommand.java:315) javax.faces.component.UIViewRoot.broadcastEvents(UIViewRoot.java:775) javax.faces.component.UIViewRoot.processApplication(UIViewRoot.java:1267) com.sun.faces.lifecycle.InvokeApplicationPhase.execute(InvokeApplicationPhase.java:82) com.sun.faces.lifecycle.Phase.doPhase(Phase.java:101) com.sun.faces.lifecycle.LifecycleImpl.execute(LifecycleImpl.java:118) javax.faces.webapp.FacesServlet.service(FacesServlet.java:312) root cause org.hibernate.exception.JDBCConnectionException: Cannot open connection org.hibernate.exception.SQLStateConverter.convert(SQLStateConverter.java:98) org.hibernate.exception.JDBCExceptionHelper.convert(JDBCExceptionHelper.java:66) org.hibernate.exception.JDBCExceptionHelper.convert(JDBCExceptionHelper.java:52) org.hibernate.jdbc.ConnectionManager.openConnection(ConnectionManager.java:449) org.hibernate.jdbc.ConnectionManager.getConnection(ConnectionManager.java:167) org.hibernate.jdbc.JDBCContext.connection(JDBCContext.java:142) org.hibernate.transaction.JDBCTransaction.begin(JDBCTransaction.java:85) org.hibernate.impl.SessionImpl.beginTransaction(SessionImpl.java:1463) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) java.lang.reflect.Method.invoke(Unknown Source) org.hibernate.context.ThreadLocalSessionContext$TransactionProtectionWrapper.invoke(ThreadLocalSessionContext.java:344) $Proxy108.beginTransaction(Unknown Source) com.yemex.beans.CompanyBean.saveOrUpdate(CompanyBean.java:52) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) java.lang.reflect.Method.invoke(Unknown Source) org.apache.el.parser.AstValue.invoke(AstValue.java:196) org.apache.el.MethodExpressionImpl.invoke(MethodExpressionImpl.java:276) com.sun.faces.facelets.el.TagMethodExpression.invoke(TagMethodExpression.java:98) javax.faces.component.MethodBindingMethodExpressionAdapter.invoke(MethodBindingMethodExpressionAdapter.java:88) com.sun.faces.application.ActionListenerImpl.processAction(ActionListenerImpl.java:102) javax.faces.component.UICommand.broadcast(UICommand.java:315) javax.faces.component.UIViewRoot.broadcastEvents(UIViewRoot.java:775) javax.faces.component.UIViewRoot.processApplication(UIViewRoot.java:1267) com.sun.faces.lifecycle.InvokeApplicationPhase.execute(InvokeApplicationPhase.java:82) com.sun.faces.lifecycle.Phase.doPhase(Phase.java:101) com.sun.faces.lifecycle.LifecycleImpl.execute(LifecycleImpl.java:118) javax.faces.webapp.FacesServlet.service(FacesServlet.java:312) root cause java.sql.SQLException: No suitable driver found for jdbc:postgresql://localhost/postgres java.sql.DriverManager.getConnection(Unknown Source) java.sql.DriverManager.getConnection(Unknown Source) org.hibernate.connection.DriverManagerConnectionProvider.getConnection(DriverManagerConnectionProvider.java:133) org.hibernate.jdbc.ConnectionManager.openConnection(ConnectionManager.java:446) org.hibernate.jdbc.ConnectionManager.getConnection(ConnectionManager.java:167) org.hibernate.jdbc.JDBCContext.connection(JDBCContext.java:142) org.hibernate.transaction.JDBCTransaction.begin(JDBCTransaction.java:85) org.hibernate.impl.SessionImpl.beginTransaction(SessionImpl.java:1463) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) java.lang.reflect.Method.invoke(Unknown Source) org.hibernate.context.ThreadLocalSessionContext$TransactionProtectionWrapper.invoke(ThreadLocalSessionContext.java:344) $Proxy108.beginTransaction(Unknown Source) com.yemex.beans.CompanyBean.saveOrUpdate(CompanyBean.java:52) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) java.lang.reflect.Method.invoke(Unknown Source) org.apache.el.parser.AstValue.invoke(AstValue.java:196) org.apache.el.MethodExpressionImpl.invoke(MethodExpressionImpl.java:276) com.sun.faces.facelets.el.TagMethodExpression.invoke(TagMethodExpression.java:98) javax.faces.component.MethodBindingMethodExpressionAdapter.invoke(MethodBindingMethodExpressionAdapter.java:88) com.sun.faces.application.ActionListenerImpl.processAction(ActionListenerImpl.java:102) javax.faces.component.UICommand.broadcast(UICommand.java:315) javax.faces.component.UIViewRoot.broadcastEvents(UIViewRoot.java:775) javax.faces.component.UIViewRoot.processApplication(UIViewRoot.java:1267) com.sun.faces.lifecycle.InvokeApplicationPhase.execute(InvokeApplicationPhase.java:82) com.sun.faces.lifecycle.Phase.doPhase(Phase.java:101) com.sun.faces.lifecycle.LifecycleImpl.execute(LifecycleImpl.java:118) javax.faces.webapp.FacesServlet.service(FacesServlet.java:312) Blockquote I didn't look at your config file but I'm assuming it configured at least reasonably well since the stack trace indicates that it is trying to connect to a postgres database at a localhost JDBC url. It looks like the big problem is that it can't find the postgres JDBC driver: root cause java.sql.SQLException: No suitable driver found for jdbc:postgresql://localhost/postgres java.sql.DriverManager.getConnection(Unknown Source) java.sql.DriverManager.getConnection(Unknown Source) org.hibernate.connection.DriverManagerConnectionProvider.getConnection(DriverManagerConnectionProvider.java:133) Make sure the JAR file is in your classpath. You can download it here if you don't already have it: http://jdbc.postgresql.org/ I write a test Java app and it works right but I think that this Web application have a problem. And I control JDBC driver and it is right  Verify that you have the jar for your database driver in classpath. Verify if the driver class name is correct. Verify if the connection.url is correct. I got the same error. Only difference being I am using Oracle 11g. I had ojdbc14.jar in classpath  driver class name was correct but connection.url property was wrong. The correct format in case of Oracle 11g is jdbc:oracle:thin:@localhost:1521:global_dsn_name  What's the question here? The exception is pretty explicit: org.hibernate.exception.JDBCConnectionException: Cannot open connection Make sure you can connect to the database you are connected to that the configuration is correct that you do not have network issues preventing the connection etc. Ok and do you have a postgres database running on localhost at the default port and does it have a database named postgres and does it have a user named postgres with a password named postgres? Yes There is a database which is name postgres and is used default port This db have a user which is name postgres and its pass = '1234' But I configure hibernate cfg.xml llike that; org.postgresql.Driver 1234 jdbc:postgresql://localhost/postgres postgres public org.hibernate.dialect.PostgreSQLDialect A bit rude this answer no?  When encountering an exception it's worth to check the bottommost root cause in the stacktrace. In this case it's the following: java.sql.SQLException: No suitable driver found for jdbc:postgresql://localhost/postgres This just means that either the URL is wrong or that the desired driver is not present in the current runtime classpath. Since the URL looks fine as per the PostgreSQL JDBC documentation it'll be that the driver is missing in the current runtime classpath. So to fix this problem you need put the JDBC driver JAR file in the webapp's runtime classpath. The /WEB-INF/lib is one of the folders which is covered by the webapp's default runtime classpath. Just drop the PostgreSQL JDBC driver JAR file in there and redeploy. The Driver path is already /WEB-INF/lib but same problem continues Apparently a different classloader is been used. Try putting in `Tomcat/lib` or adding JAR file's root path to `shared.loader` in `Tomcat/conf/catalina.properties`."
596,A,"Connection timeout for DriverManager getConnection I am trying to connect to DB using the standard JDBC way connection = DriverManager.getConnection(url username password); Is there a maximum value of timeout on the connection how long does a connection live can I increase the value. I want in cases the connection to be open forever  is it a good idea. You can use ExecutorService interface from Java. Below is a sample of what you need to do. Future future = executor.submit(YOUR_METHOD); future.get(TIMEOUT_YOU_NEED TimeUnit.SECONDS);  The value is usually DB-controlled. You have no control over it using code. It depends on the DB server used. It is usually around 30 minutes up to one hour. On the other hand keeping a Connection open forever is a very bad idea. Best practice is to acquire and close Connection Statement and ResultSet in the shortest possible scope to avoid resource leaks and potential application crashes caused by the leaks and timeouts. True connecting the DB is an expensive task. If your application is supposed to run a relatively long time and to connect the DB fairly often then consider using a connection pool to improve connecting performance. If your application is a webapplication then take a look in the appserver's documentation it usually provides a connection pooling facility in flavor of a DataSource. If it is a client application then look for 3rd party connection pooling libraries which have proven their robustness with years such as Apache Commons DBCP (commonly used used in lot appservers) C3P0 (known from Hibernate) and Proxool (if you want XA connections). Keep in mind when using a connection pool you still have to write proper JDBC code i.o.w. acquire and close all the resources in the shortest possible scope. The connection pool will on its turn worry about actually closing the connection or just releasing it back to pool for further reuse. You may get some more insights out of this article how to do the JDBC basics the proper way. Hope this helps and happy coding. DBCP is a horrible *horrible* connection pool. Never use it. Interesting. I've never had serious problems with it when used in flavor of a Tomcat 6.0 managed datasource. Care to elaborate? Well you want to use a pool when resources are ""expensive"" (take some time to create). DBCP (or really the underlying pool) holds a lock on the entire pool while new objects are being produced. This prevents threads that have finished with a resource and are merely trying to return it to block. Meanwhile other threads are blocked trying to get those resources. Because these lock acquisitions aren't using the concurrent package they aren't interruptible. This hurts performance under normal conditions. If something is actually wonky with the DB it gets *really* ugly really fast. Yes good point. For Tomcat better replace by `org.apache.tomcat.jdbc.pool.DataSourceFactory`. Thanks for heads up +1.  You can set the Timeout on the DriverManager like this:  DriverManager.setLoginTimeout(10); Connection c = DriverManager.getConnection(url username password); Which would imply that if the connection cannot open within the given time that it times out. In terms of keeping a connection open forever it is possible if you do not close the connection but it may not be a good idea. Connections should be closed as soon as you are finished with them. If you want to optimise the opening and closing of connections then you can use a connection pool. Hmm IIRC this only sets the timeout how long the DriverManager has to wait before the DB returned a connection. It does not set the connection's timeout. Also see: http://java.sun.com/javase/6/docs/api/java/sql/DriverManager.html#setLoginTimeout%28int%29 Thats right @BalusC. As I mentioned that timeout is only how long the DriverManager waits for a connection not how long the connection stays open. I must however admit (and you probably also) that this is the correct answer on the question as literally phrased in topic's subject. But the actual question in the topic message turned out to be something different. `DriverManger.setLoginTimeout(10)` doesn't work for me with the MySQL driver. I think the only way to do it is with [threads](http://stackoverflow.com/questions/4850957/how-to-force-time-out-the-drivermanager-getconnection-method-call). LoL @ your threads - you can do it quite simply by creating a Properties object `prop` then `prop.put(""connectTimeout"" ""2000"")` (where the ""2000"" is the timeout in ms) and then pass your `prop` object to the `DriverManager.getConnection()` method along with your url  Here is how to do it with Connector/J MYSQL driver: String qqq = ""jdbc:mysql://localhost/Test?connectTimeout=TIME_IN_MILLIS""; conn = DriverManager.getConnection(qqq db_user db_pass); It worked for me after setLoginTimeout() did nothing."
597,A,"Connect to an oracle db in jdbc over an SSH tunnel Currently we have to tunnel over SSH to access our Oracle database. In order to do this we have to make sure than putty or an equivalent program/script is running on the server doing this tunelling before the application is deployed to Tomcat/Glassfish/etc. Has anybody found a way to have java handle this tunneling transparently? Perhaps a jdbc driver than itself wraps another jdbc drive handling the tunnelling for you right in Java? My solution was to use Jsch from JCraft http://www.jcraft.com/jsch/ to open a tunnel when my application server starts up. I close the tunnel when the application server shuts down. I do this via a servlet context listener. int findUnusedPort() { final int startingPort = 1025; final int endingPort = 1200; for (int port = 1025; port < 1200; port++) { ServerSocket serverSocket = null; try { serverSocket = new ServerSocket(port); return port; } catch (IOException e) { System.out.println(""Port "" + port + ""is currently in use retrying port "" + port + 1); } finally { // Clean up if (serverSocket != null) try { serverSocket.close(); } catch (IOException e) { throw new RuntimeException(""Unable to close socket on port"" + port e); } } } throw new RuntimeException(""Unable to find open port between "" + startingPort + "" and "" + endingPort); } private Session doSshTunnel(int tunnelPort) { // SSH Tunnel try { final JSch jsch = new JSch(); sshSession = jsch.getSession(""username"" ""sshhost"" 22); final Hashtable<String String> config = new Hashtable<String String>(); config.put(""StrictHostKeyChecking"" ""no""); sshSession.setConfig(config); sshSession.setPassword(""password""); sshSession.connect(); int assigned_port = sshSession.setPortForwardingL(tunnelPort remoteHost remotePort); return sshSession; } catch (Exception e) { throw new RuntimeException(""Unable to open SSH tunnel"" e); } }  I have used Apache MINA SSHD for a project a while back and I remember that there was support ofr opening tunnels. You can check out http://mina.apache.org/sshd/ for more info. Other options are discussed on this quesiton : http://stackoverflow.com/questions/995944/ssh-library-for-java"
598,A,"Prepared Statements and JDBC Drivers I have the below questions on Prepared Statements in Java. Is it beneficial to use Prepared Statements when the SQL Query does not have any Where clause ? Assume a simple query Select * from tablename; It is said that the Prepared Statement is compiled once and only the values are substituted the second time. Hence it is faster as the Query validation and compilation step can be skipped. Where is the compiled form stored ? What is the life time of this compiled form ? Good Detail about Pre-compilation : [http://stackoverflow.com/questions/5497297/what-does-pre-compiling-a-jdbc-preparedstatement-do][1] [1]: http://stackoverflow.com/questions/5497297/what-does-pre-compiling-a-jdbc-preparedstatement-do A PreparedStatement is beneficial when there are parameters to be passed and when the query is to be executed repeatedly. If there is a simple query to be fired once a Statement will prove faster. The caching takes place on DB server. The DB server has APIs that help caching compiled queries. Hence for repeated execution of queries the same compiled query will run again and boost performance. Even a simple ""select * from tablename"" has to be compiled and an execution plan calculated. The gain might not be tremendous tho. The compiled form should never be re-calculated but the execution plan can depending on changes on the implied tables or indexes. The item #2 is not entirely true. Apps server may provides its own PreparedStatement cache Weblogic is one of them.  Use PreparedStatement everytime there's an input or more from the user. It will help you escape the needed characters to prevent SQL Injection and errors in queries."
599,A,"Getting the count of rows in a Java resultset Does anyone know a better way of getting the number of rows in a Java resultset returned from a MySQL database? The resultset returned is not going to be the total number of rows read from the database so I don't think I can use SQL's COUNT aggregate function. public static int getResultSetRowCount(ResultSet resultSet) { int size = 0; try { resultSet.last(); size = resultSet.getRow(); resultSet.beforeFirst(); } catch(Exception ex) { return 0; } return size; } Calling resultSet.last() will cause the result set to actually iterate over all the records - so it is clearly inefficient. Also it will force all the data to be cached to memory even if you don't need it yet. Any reason why you said ""he resultset returned is not going to be the total number of rows read from the database"" ? @RonK: Why do you think it will be iterating all over? I couldn't find anything like this in docs. @Ronk: The data read from the database table will be a subset of the table's data only rather than all the data in the table. I am curious about the 'iterating all over' though. @Adeel Ansari: I'm not 100% certain of it I decompiled Oracle's result sets and found out that in the flow of invoking the 'last()' method the 'cacheAllRows()' method is invoked and that method starts with 'while(resultSet.next())'. I assume that the MySQL driver won't have something better to do. @Mr Morgan: As some of the answers below stated - if you have an SQL that gets the data you can have the same one to return COUNT() - I don't see a reason why it cannot work. That catch clause looks a bit suspicious. I would propagate exceptions but at least i would return -1 in that catch. You can always use SELECT COUNT() with the same exact conditions before making the actual SELECT. It still imposes a database read though. @Mr Morgan: Thats perfactly fine for me. Actually we do similar thing to achieve pagination. However we ask specific number of rows in the 2nd query though. But here in your case `duffymo` is very much right. When you already queried the database why not load that into a List or something. I'm currently looking at a 2 dimensional arraylist as per duffymo's idea. Before I needed the resultset number of rows to work out the size of a 2 dimensional String array. Or as I'm trying to access table metadata from the system schema I can use a class with two fields column name column type and then create an array list of this class. The main point here is to avoid iterating through a result set and this class in a collection should suffice.  If you are using Java 6 you can use the JDBC4ResultSet class which has the getUpdateCount method that returns the number of the lines affected by a SQL Statement even for a Select Statement. See below the example code: PreparedStatement ps = con.prepareStatement(""select * from any_table ...""); JDBC4ResultSet rs = (JDBC4ResultSet)ps.executeQuery(); int rowNumber = rs.getUpdateCount(); I hope that this help! This doesn't really work with MySQL. All I get is -1 even when there is a row.  .In DB I have 2 rows. with this query using above code when I print Row get only one row: select D.DEALER_CODE FROM SCOTT.T_DEALERSHIP DSCOTT.T_DEALER_BILLING DB WHERE D.DEALER_CODE = DB.DEALER_CODE AND DEALER_NAME LIKE 'XTIME%' AND (RNR_CUST_NUM = '546' OR RNR_CUST_NUM = '43356'OR RNR_CUST_NUM = '7637055'OR RNR_CUST_NUM ='7637055' OR RNR_CUST_NUM IS NULL) AND (RCI_STORE_NUMBER IS NULL OR RCI_STORE_NUMBER = '05') AND (RCI_AREA_NUMBER = '01'OR RCI_AREA_NUMBER IS NULL) AND (RCI_DEALER_NUMBER IS NULL AND DEALER_Address1 LIKE UPPER('1500 ORACLE%') AND DEALER_CITY =UPPER('BAKERSFIELD') AND DEALER_ZIP LIKE'6%')  You can also use the following way to get the total records in the resultSet: statement = connect.createStatement(); resultSet = statement.executeQuery(sqlStatement); resultSet.last(); int count = resultSet.getRow(); System.out.println(count); count is the total returned rows for your result set. ;) It only works if the resultset is scrollable and it will iterate over all the record so not very efficient.  A better answer is to forget about the number of rows until you've successfully loaded the ResultSet into an object or collection. You can keep the count of the number of rows with either of those options. It's important to close ResultSets (and all SQL resources like Connection and Statement) in the narrowest method scope possible. That means not passing ResultSet out of the persistence layer. Better to get the number of rows using a Collection size() call. Stop thinking about databases and start thinking in terms of objects. Java's an object-oriented language. (+1) Of course you are right. `count()` is perfectly fine for me but not in this case. We normally do that to achieve pagination thingie. I find myself wanting to know the rowcount so I can make an appropriately sized `ArrayList`. I mean the amortized cost is negligible but if I can get it right the first time why not right? :-)  You can execute SELECT FOUND_ROWS() immediately after executing your SELECT statement to find the row count.  Here is my solution to this question (since I mostly want the number of records returned to build an array or something similar): Use a collection such as Vector<T> instead. public Vector<T> getRecords(){ Vector<T> records = new Vector<T>(); init_conn_and_stmt_and_rs(); try { rs = stmt.executeQuery(""SELECT * FROM `table` WHERE `something` = 0""); while(rs.next()){ // Load the Vector here. } } catch (SQLException e) { e.printStackTrace(); }finally{ close_rs_and_stmt_and_conn(); } return records; } Clean and simple no? Works for any size record set returned (no need to know the size before hand) and makes all the List methods available. This has served me well for a time now but if someone sees a flaw in this please let me know. Always want to make my practices better ya know."
600,A,"mysql query for timezone conversion is there a way to convert from unix timestamp to GMT in mysql while running the query itself?? My query is as follows: SELECT r.name  r.network  r.namestring  i.name  i.description  r.rid  i.id  d.unixtime // this is the unix time i am asking to print  d.ifInOctets FROM range AS r INNER JOIN intranet AS i ON r.rid = i.rid INNER JOIN 1279080000_1_60 AS d ON i.id = d.id AND unixtime BETWEEN 1279113600 AND 1279115400 // range of unix time WHERE r.network = ""ITPN"" AND i.status = ""active"" GROUP BY i.id AND d.unixtime I was working with it in jdbc and tried numerous ways suggested in this forum to do the conversion but it does not seem to help. Can I convert it directly and print out while running the query itself? I want to display the date in hour:minutes. eg: 9:20. Please help or if there is any link I can follow that would be great too. Thank you Using FROM_UNIXTIME converts a UNIX timestamp to a MySQL DATETIME: FROM_UNIXTIME(r.unixtime) Then you can use CONVERT_TZ to get the DATETIME in a different timezone: CONVERT_TZ(FROM_UNIXTIME(r.unixtime) ? 'GMT') Problem is you need to know the original timezone is - you have to update the ? with the correct timezone... hi the from_unixtime worked like a charm. but is it possible to just get it in hours and minutes rather than the whole datehourmin second ?? thanks a lot :) that does not work. I get 'null' as the field content then. :( @jillika iyer: See update - the example I gave will return the value in h24:mm CONVERT_TZ(FROM_UNIXTIME(d.unixtime '%h:%i') 'GMT' 'EST') http://dev.mysql.com/doc/refman/5.1/en/date-and-time-functions.html#function_from-unixtime"
601,A,"Clean up repetitive setup and cleanup Java(JDBC) code I've too many methods that repeatedly do something like Statement stmt = null; ResultSet rstmt = null; try { stmt = conn.createStatement(); rstmt = stmt.executeQuery(...); while (rstmt.next()) { //handle rows } } catch (SQLException e) { //handle errors } finally { try {rstmt.close();} catch (SQLException ex) {} try {stmt.close();} catch (SQLException ex) {} } This setup/teardown/cleanup of statements and resultsets is repetive and hides the interesting pieces of code. Is there any pattern or idiom for handling this(without introducing any external framework) ? One of the real values of abstracting this sort of rubbish out your code is that you'll make sure your close statement don't NPE (hopefully using the `acquire; try { use; } finally { release; }` idiom. Duplicate: http://stackoverflow.com/questions/1072925/remove-boilerplate-from-db-code/1072949#1072949 You want the Execute Around idiom. You may want to ask 'What is the ""Execute Around"" idiom?'. (And if you like ASCII diagrams: my weblog on 'Factoring out exception handling')  Although it does not eliminate the set-up and tear-down logic I often prefer this style for making JDBC interactions more pleasant: Statement statement = connection.createStatement(); try { ResultSet results = statement.executeQuery(...); try { while (results.next()) { //handle rows } } finally { results.close(); } } finally { statement.close(); } By nesting the try blocks you automatically ensure that both results and statement will have their close() methods called without resorting to the try/catch statements in your finally block. As well by starting the try blocks immediately after acquiring your objects you don't need to worry about checking for null values (unless of course connection.createStatement() or statement.executeQuery(...) return null - In that case you have bigger issues). Doesn't this code strike you as well ... ugly? I suppose beauty is in the eye of the beholder. I personally find this form more ""appealing"" than the form presented in the question.  you can create a method that receives the SQL query and an object to handle the ResultSet. for example: private void executeSql(String sql ResultSetHandler handler) { Statement stmt = null; ResultSet rstmt = null; try { stmt = conn.createStatement(); rstmt = stmt.executeQuery(sql); while (rstmt.next()) { handler.handle(rstmt); } } catch (SQLException e) { //handle errors } finally { try {rstmt.close();} catch (SQLException ex) {} try {stmt.close();} catch (SQLException ex) {} } } with ResultSetHandler being an interface: public interface ResultSetHandler { void handle(ResultSet rs) throws SQLException; } and you can create an object of an anonymous class implementing that interface so it won't clutter too much. Probably want to make that interface method throw at least SQLException. good idea Tom.  You should reconsider using Java persistence managers like iBatis and Hibernate. These automate a lot of the boilerplate away. I've been using iBatis where the SQL statements are all neatly packaged and named in XML files and the code volume has to be about 25% of a raw JDBC approach. You could gradually refactor your system to use iBatis.  Have a look at SimpleJDBCTemplate in Spring Framework. This does exactly what you want. If you don't want to introduce an external framework then just use it for some inspiration to implement your own. absolutely agree +1 from me. This is exactly the right thing to do. Either using Spring as inspiration or incorporating it into your project will be beneficial. In addition to hiding this messy setup\teardown code Spring will improve the exception handling in 2 ways: 1) it will handle the SQLException and 'regurgitate' it as something more meaningful 2) the exception that is 'regurgitated' will be unchecked so you don't have to catch or throw anything. +1. LOVE the way jdbc is handled with spring."
602,A,how do i get the current schema on DB2 if i have a JDBC conneciton? If I have an instance of a JDBC DB2 connection how do I get the current schema? Either a SQL statement would work or just a JDBC method call. Take a look at Java API Makes Database Metadata as Easily Accessible as POJOs for an easy way to obtain schema information.  select current_schema from sysibm.sysdummy1 ; I tried that on iSeries DB2 v6r1 but got: [SQL5016] Qualified object name SYSDUMMY1 not valid.
603,A,combine 2 resultset is there a way to add the results of 2 different queries to a resultset? something like that: ResultSet rs ; i=0; while(i<=l) ResultSet rs1 = select * from tablei; rs = rs + rs1; i++; } I know that I can do it with union but I have a lot queries and if I use UNION the query is too slow. Any idea? are you sure the UNION query takes more time than the multiple database hits in the while loop ? Agreed. If it's too slow it must be some or all of the individual queries. The UNION itself shouldn't be slow. The UNION is probably slowing it down because it forces a DISTINCT operation. Try UNION ALL. Depending on which data access library you use ResultSet has a method called MoveNextRecordSet() and SqlDataReader provides NextResult(). Create a stored procedure to return several result sets (i.e. several SELECT statements in one sp) and navigate through the result sets using these methods.  I'd be surprised if you found a method that has better performance than UNION in the database. Union is doing what you want and the database server will have optimised this as best as they can. You'd essentially be re-inventing the wheel. If your UNION is too slow then try looking into whether your database could do with better indexing. You should also do some timing analysis on the individual queries compared with the UNION option. I'd expect one or the other queries is the slow bit rather than the UNION.  IF that Union takes too much time to complete maybe you should consider changing your indexes on the tables that you use. Did you check your index fragmentation? See if you add the right indexes if you can speed up the query that way. I do not think that a while being used like that will be quicker than a union all.  I don't believe there is any way to add a ResultSet to another. They have no method in the class that does such a thing or updates the ResultSet from the code. ResultSets are designed to receive data from the database and not from developer manipulation user input or the like. My suggestion would be to extract the data to an array or something similar and manipulate the data in the code or do the UNION in the query.  Are you doing a UNION or a UNION ALL? The latter shouldn't be much different from doing it yourself (although I'd expect doing it yourself to be slower). I'm using union. Each query takes 5948 mseg without union (2 queries 13000 mseg). But if I use union with 2 queries takes 56125 mseg. I have to do a lot of queries... So use UNION ALL. UNION implicitly adds a DISTINCT operation which both slows things down and changes your results. UNION ALL is a simple concatenation of results.
604,A,"Is MySQL JDBC driver compliant with the JDBC spec? I am using Connector/J 5.1.10 as the JDBC driver for my Database application (which uses MySQL). I have found that although the default ResultSet returned by a Statement is of type TYPE_FORWARD_ONLY I am still able to safely call the previous() method on the ResultSet. I also looked at the source code (com.mysql.jdbc.ResultSetImpl) and found out that it too does not do any checks for the type of the ResultSet. Is Connector/J not fully compliant with the JDBC spec ? Thanks. According to the release notes the driver is compliant with all of the tests that Sun makes publicly available. Some parts of the spec are vague mysql specifically says so in the release notes. Perhaps the spec doesn't say what the vendor should do if you traverse back on a forward_only cursor ... the vendor has a choice whether to throw an exception at you or not. The public tests can't test the parts of the spec where a decision is left to the vendor's discretion. But the spec definitely mentions what should happen if we attempt to call previous() on a result set that can be scrolled only forwards; the javadoc says that an SQLException should be thrown.  The API documentation says that ResultSet#previous() should throw an SQLException ""if ... the result set type is TYPE_FORWARD_ONLY"" so I guess it's safe to assume that J/Connector violates the specification here."
605,A,Java JDBC Oracle 9i upgrade to 10g issues We have just upgrade from oracle 9i to 10g and a database query I have works with the 9i client but not the 10g. Nothing in the query has changed. I get the following error: java.sql.SQLException: ORA-01036: illegal variable name/number Not really sure what is going on. Why wouldn't it run anymore. It's just a select statement which joins about 3 or 4 tables. I am making sure that I am passing in the variable using setInt (it's a number that I'm using). While diff'ing the tables being joined the only thing I find different is that on one table a column I'm joining is set to be a Number on one table and Number(12) on the other. Does this make a difference? The query still runs in TOAD and SQL Navigator... NUMBER vs NUMBER(12) isn't the issue; NUMBER(12) just defines the precision after the decimal point. Can't remember what the precision is for NUMBER by default. Yea I kinda guessed at that I just threw this out there because this really isn't my area and noone around here has a clue or even an idea of where to begin. thanks. Seeing the function might help. 2 thoughts spring to mind: make sure you're using the correct version of the jdbc driver. Since you've said the query works in TOAD etc this is very likely to be your problem. make sure you're not using any ORACLE key-words in your query as column-aliases etc Also from experience if your database is big/busy you've got a fair way to go before your 10g environment is stable. My recommendations: learn as much as you can about stats Read the survival guides (there's lots on the net) watch out for built-in jobs that re-compute status. We got hammered 12 days after go-live because stats changes broke key query performance. Our testing hadn't allowed a 12 day stability test. be aware of bind-variable-peeking if you aren't already  The problem was with the following method call on the prepared statement: ps.setEscapeProcessing(false); Removed that and now it works fine. Don't think that was compatable with oracle 10g driver. Thanks everyone for the help.
606,A,"Possible memory leak due to not using StringBuffer? Can the following code cause a memory leak? Would using a StringBuffer actually improve memory usage? A little background: A coworker has been pushing his theories on memory leaks and this is code he has identified as being problem code (without doing any sort of profiling) which he claims can cause a memory leak. I disagree with this so I thought I'd put it to some other developers to get a third party opinion.  List partCollection = new ArrayList() String partKeyID = null; String sPartNbr = null; String partDescription = null; while(rsPartRes.next()) { partKeyID = rsPartRes.getString(""PART_KEY_ID""); sPartNbr = rsPartRes.getString(""PART_NBR""); partDescription = rsPartRes.getString(""PART_DESC""); SomeValueObject someValueObject = new SomeValueObject(); someValueObject.setPartKeyID(partKeyID); someValueObject.setSPartNbr(sPartNbr); someValueObject.setPartDescription(partDescription); partCollection.add(someValueObject); } Assume that rsPartRes is a ResultSet in this code which could contain 100+ records. Basically his concern is that because we are looping through this result set and not using a StringBuffer (which in this case I'm not even sure HOW you would use one) that it could be causing memory leaks. Is there ANY case that anyone sees here where this could possibly cause memory leaks or performance issues...? No this is a fairly standard JDBC object extraction from DB block of code. Assuming that there is an rsPartRes.close() and a psPartRes.close() (the PreparedStatement you used) afterwards of course. Can you post the SomeValueObject code that's the only place left to look for a memory leak? The SomeValueObject is a hypothetical object but it would be purely a Bean. No that won't cause a memory leak. However it would be cleaner to declare the variables inside the loop:  List partCollection = new ArrayList(); while(rsPartRes.next()) { String partKeyID = rsPartRes.getString(""PART_KEY_ID""); String sPartNbr = rsPartRes.getString(""PART_NBR""); String partDescription = rsPartRes.getString(""PART_DESC""); SomeValueObject someValueObject = new SomeValueObject(); someValueObject.setPartKeyID(partKeyID); someValueObject.setSPartNbr(sPartNbr); someValueObject.setPartDescription(partDescription); partCollection.add(someValueObject); } It's not even obvious why you need those variables at all:  while(rsPartRes.next()) { SomeValueObject someValueObject = new SomeValueObject(); someValueObject.setPartKeyID(rsPartRes.getString(""PART_KEY_ID"")); someValueObject.setSPartNbr(rsPartRes.getString(""PART_NBR"")); someValueObject.setPartDescription(rsPartRes.getString(""PART_DESC"")); partCollection.add(someValueObject); } (It would also be nicer to use generics but that's a different matter...) How was your colleague planning to use StringBuffer? There's no string manipulation going on here... Jon agreed on your coding suggestions. I'm not totally sure what the StringBuffer suggestion was. But I think my point would be exactly as you stated ... ""There's no string manipulation going on here...""  As far as I can tell there is no need to use a StringBuffer here. The only reason to use a StringBuffer to increase performance would be when you are concatenating Strings over and over. String result = """"; while (condition) { result += somethingElse; } or (StringBuilder is a better replacement for StringBuffer these days) StringBuilder result = new StringBuilder(); while (condition) { result.append(somethingElse); } The second piece of code performs much better. I imagine that somewhere else in their codebase there is some code that usese this List and does the StringBuffer / StringBuilder work probably to a webpage table. Of course this should be done in a JSP... I'm marking this as the accepted answer. I think the answer I looking for is the fact that unless there is no concatentation or serious String manipulation going on then there would be no need for StringBuffer. Exactly !  What does he think is leaking? Not sure how StringBuilder helps here since you don't appear to be building up (concatenating) any strings. Unless there is something going on inside SomeValueObject()"
607,A,"Copying Java ResultSet I have a java.sql.ResultSet object that I need to update. However the result set is not updatable. Unfortunately this is a constraint on the particular framework I'm using. What I'm trying to achieve here is taking data from a database then manipulating a small amount of the data and finally the data is being written to a CSV file. At this stage I think my best option is to create a new result set object and copy the contents of the original result set into the new one manipulating the data as I do so. However I've hunted high and low on Google and don't seem to be able to determine how to do this or whether it's even possible at all. I'm new to everything Java so any assistance would be gratefully received. Answer taken from - http://www.coderanch.com/t/294658/JDBC/databases/clone-ResultSet Strictly a class which implements ResultSet doesn't hold any data. Drivers are free to go back to the database for each ""next()"". This is why a ResultSet is usually neither serializable nor cloneable. What almost everyone does is read the results into some other data structure (a 2d array a Vector of arrays an ArrayList of Maps whatever.) You can make that data structure serializable or cloneable if you wish. Thanks for the responses. In the end I found CachedRowSet which is exactly what I needed. With this I was able to disconnect the ResultSet object and update it. What's more because CachedRowSet implements the ResultSet interface I was still able to pass it to my file generation method which requires an object that implements ResultSet. Thanks! looking for just that  The normal practice would be to map the ResultSet to a List<Entity> where Entity is your own class which contains information about the data represented by a single database row. E.g. User Person Address Product Order etcetera depending on what the table actually contains. List<Entity> entities = new ArrayList<Entity>(); // ... while (resultSet.next()) { Entity entity = new Entity(); entity.setId(resultSet.getLong(""id"")); entity.setName(resultSet.getString(""name"")); entity.setValue(resultSet.getInt(""value"")); // ... entities.add(entity); } // ... return entities; Then you can access traverse and modify it the usual Java way. Finally when persisting it back in the DB use a PreparedStatement to update them in batches in a single go. String sql = ""UPDATE entity SET name = ? value = ? WHERE id = ?""; // ... statement = connection.prepareStatement(sql); for (Entity entity : entities) { statement.setString(1 entity.getName()); statement.setInt(2 entity.getValue()); statement.setLong(3 entity.getId()); // ... statement.addBatch(); } statement.executeBatch(); // ... Note that some DB's have a limit on the batch size. Oracle's JDBC driver has a limit on around 1000 items. You may want to call executeBatch() every 1000 items then. It should be simple using a counter inside the loop. See also: Collections tutorial PreparedStatement tutorial Hi - thanks for the great response. In this situation - the data is being pull from the db there will be a small amount of manipulation and then the data is being written to a CSV file. If the manipulation is row-based then just do it inside the `while` loop and write it immediately as a new line of CSV file. By the way the average DB ships with CSV export facilities which can do it more efficient than you can ever do in Java. It's unclear which one you're using so here's just a MySQL based example: `LOAD DATA INFILE`. @BalusC - wouldn't it be better to use an ETL tool for such jobs if you have access to one ?"
608,A,"Is rollback needed if java.sql.Connection#commit() throws exception? According to JAVA documentation Connection#commit() can throw SQLException. My question is whether or not a rollback should still be issued in this scenario. For example: Connection con = null; try { // assume this method returns an opened connection with setAutoCommit(false) con = createConnection(); // do DB stuff con.commit(); } catch (SQLException e) { if (con != null) { // what if con.commit() failed is this still necessary // will it hurt anything? con.rollback(); } } finally { if (con != null) { con.close(); } } I actually wrapped the con.rollback() call into another method which ignores any exceptions thrown by it so I think I'm ok here. I just wondered if this was the best way of handling things. Related: http://stackoverflow.com/questions/3160756/in-jdbc-when-autocommit-is-false-and-no-explicit-savepoints-have-been-set-is-it Rollback is important even if commit failed according to the Java 1.6 JDBC docs: It is strongly recommended that an application explicitly commits or rolls back an active transaction prior to calling the close method. If the close method is called and there is an active transaction the results are implementation-defined. This means that if you do not explicitly invoke rollback some JDBC implementation might invoke commit before closing the connection. Another good reason to rollback is as Xepoch suggested and when using a connection pool it is even more important. When getting a connection from a connection pool most implementations will execute connection.setAutoCommit(defaultAutoCommit) before giving you the connection and according to the JavaDocs: If this method is called during a transaction and the auto-commit mode is changed the transaction is committed If the connection.rollback() throws an exception - then it is a tricky one... This should be the accepted answer. Proof by specification is king.  I would do explicit rollback just for clean-up purposes. Although changes won't be persisted in db either way it seems nice to explicitly let database know that you're done here. Just like the way you close connection explicitly without waiting for Connection object to be garbage-collected. This is obviously not a technical answer and I would also be interested to learn whether there's a practical point in doing so. Plus in case of a pooled connection it will give a clean connection back in the next lease instead of a dirty one.  The usual way I do this is: boolean bSuccess = false; Connection con = null; try { // assume this method returns an opened connection with setAutoCommit(false) con = createConnection(); // do DB stuff bSuccess = true; } catch (SQLException e) { } finally { try { if (con != null) { if(bSuccess) con.commit() else con.rollback(); con.close(); } } catch(SQLException sqle) { log(""Log the error here""); // do nothing we tried } } That being said I have never seen a commit or a rollback fail if the queries worked. If you have pending transactions then most databases have tools to free them. Most app servers will keep retrying the commits and rollbacks until they can connect. You might want to look at this post: http://stackoverflow.com/questions/2751129/is-it-necessary-to-write-rollback-if-queries-fail  ""Returns an open connection?"" If that connection is shared in a pool (and could be in the future) you don't want another transaction committing your earlier work. I've seen MANY customer/solution cases of plugging in pooled connection driver that comply with JDBC interfaces and Connection.close() can also be used to just return the Connection back to a pool. Also better try{}catch{} your rollback() (edit just read your whole post but I always like to log an exception on rollback)"
609,A,"Connecting Java Applet to MySQL DB - Communications link failure I am trying to connect my Java Applet to a MySQL Database. I know that it works because I can connect to it on localhost and it retreives a list of records just fine. But when I put it on the internet it doesn't work. Here is my applet: http://mystikrpg.com/play It's signed but I keep getting the following exception: SQLException Get Cause: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. How can this happen and what can I do to fix this problem? Here's the applet source code: http://sodan.pastebin.com/jWKTgBSU To start the following exception com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure can have the following causes: IP address or hostname in JDBC URL is wrong. Hostname in JDBC URL is not recognized by local DNS server. Port number is missing or wrong in JDBC URL. DB server is down. DB server doesn't accept TCP/IP connections. DB server has run out of connections. Something in between Java and DB is blocking connections e.g. a firewall or proxy. Further do you realize that an Java Applet physically runs at the client machine? I.e. the machine where the webbrowser runs. The client basically downloads the applet from the webserver and it get executed at client (local) machine. The JDBC connection string jdbc:mysql://localhost:3306 would try to connect to a MySQL database running at the very same machine as where the applet runs. You can't reasonably expect that every client on the world will run a MySQL DB let alone with your database/table. If all you want is to access the MySQL server hosted at the server machine (there where the webserver runs) and you want to let the applet communicate with it then you really have to create and run a webservice at the webserver. Since you tagged this question with [PHP] as well I guess that you're using PHP at the server side in that case just create a PHP script which executes the MySQL action accordingly based on the request parameters or pathinfo and returns the MySQL results as for example a JSON or XML string. In the Applet you can use the Java SE builtin java.net.URLConnection or the more convenienced Apache HttpComponents Client to communicate with the webserver. E.g. URLconnection connection = new URL(getCodeBase() ""script.php?action=getdetails&productid=1"").openConnection(); InputStream response = connection.getInputStream(); // ... In Java you could process any JSON response using Google Gson any XML response using JAXP. That said (and unrelated to the current problem) the JDBC driver name you're using is the deprecated org.gjt.mm.mysql.Driver. I strongly recommend to use the correct driver name which was introduced over a decade ago to replace the old driver name: com.mysql.jdbc.Driver. Further the Class#newInstance() call after Class#forName() is also not needed. It was to workaround a bug in the old driver. Also see this explanation. @Dan: did you spot that the part `java.net.URLConnection` in my answer is blue and clickable? Anyway here's the link again hope that helps more: http://stackoverflow.com/questions/2793150/how-to-use-java-net-urlconnection-to-fire-and-handle-http-requests thanks this is what I needed to do too  Applets did not have the sufficient privilege to access a file or DB when it's remotely been accessed. That's the way JVM employs security via Sandboxing... This is what I know about applet's privilege... Maybe it's this line: con = DriverManager.getConnection(""jdbc:mysql://localhost:3306/jgame"" props); Of course yes bro.. It tries to establish connection with the localhost which will be denied by the JVM sandbox. If it were a security issue then you would rather have gotten an `AccessControlException` *before* the code can even attempt to connect the DB. In this particular case the attempt to connect has already taken place but the DB simply cannot be located."
610,A,"JDBC character encoding I have a Java Web application running on GlassFish 3 and JPA (EclipseLink) on MySQL. The problem I'm facing is that if I'm saving entities to the database with the update() method String fields lose integrity; '?' is shown instead of some characters. The server pages and database are configured to use UTF-8. After I post form data the next page shows the data correctly. Furthermore it ""seems"" in NetBeans debug that the String property of the current entity stores the correct value too. Dunno if NetBeans debug can be trusted; might be that it decodes correctly however it's incorrect. What is the database and what connection string are you using? I'm using MySQL and the connection string is: `jdbc:mysql://localhost:3306/administer` I solved it with the following: I used the GlassFish admin interface to add this property to my connection pool's settings: characterEncoding = UTF-8  It's JDBC not JPA that determines the encoding: jdbc:mysql://localhost:3306/administer?characterEncoding=utf8 +1 Thank you very helpful :) Just a sidenote for those who come across the same problem: if you want to chain parameters in the JDBC url in your `persistence.xml` you have to rewrite `&` as `&`. Example: `jdbc:mysql://localhost:3306/administer?rewriteBatchedStatements=true&characterEncoding=UTF-8`"
611,A,"Where to create a prepared statement with JDBC? Consider to following method that read data from some data-structure (InteractionNetwork) and writes them to a table in an SQLite database using an SQLite-JDBC dirver: private void loadAnnotations(InteractionNetwork network) throws SQLException { PreparedStatement insertAnnotationsQuery = connection.prepareStatement( ""INSERT INTO Annotations(GOId ProteinId OnthologyId) VALUES(? ? ?)""); PreparedStatement getProteinIdQuery = connection.prepareStatement( ""SELECT Id FROM Proteins WHERE PrimaryUniProtKBAccessionNumber = ?""); connection.setAutoCommit(false); for(common.Protein protein : network.get_protein_vector()) { /* Get ProteinId for the current protein from another table and insert the value into the prepared statement. */ getProteinIdQuery.setString(1 protein.get_primary_id()); ResultSet result = getProteinIdQuery.executeQuery(); result.next(); insertAnnotationsQuery.setLong(2 result.getLong(1)); /* Extract all the other data and add all the tuples to the batch. */ } insertAnnotationsQuery.executeBatch(); connection.commit(); connection.setAutoCommit(true); } This code works fine the program runs in about 30 seconds and takes an average of 80m heap space. Because the code looks ugly I want to refactor it. The first thing I did was moving the declaration of getProteinIdQuery into the loop: private void loadAnnotations(InteractionNetwork network) throws SQLException { PreparedStatement insertAnnotationsQuery = connection.prepareStatement( ""INSERT INTO Annotations(GOId ProteinId OnthologyId) VALUES(? ? ?)""); connection.setAutoCommit(false); for(common.Protein protein : network.get_protein_vector()) { /* Get ProteinId for the current protein from another table and insert the value into the prepared statement. */ PreparedStatement getProteinIdQuery = // <--- moved declaration of statement here connection.prepareStatement( ""SELECT Id FROM Proteins WHERE PrimaryUniProtKBAccessionNumber = ?""); getProteinIdQuery.setString(1 protein.get_primary_id()); ResultSet result = getProteinIdQuery.executeQuery(); result.next(); insertAnnotationsQuery.setLong(2 result.getLong(1)); /* Extract all the other data and add all the tuples to the batch. */ } insertAnnotationsQuery.executeBatch(); connection.commit(); connection.setAutoCommit(true); } What happens when I run the code now is that it takes about 130m heap space and takes an eternity to run. Can anyone explain this strange behavior? I guess it is a matter of taste if the first fragment looks ugly ;-)... However the reason why the second code fragment takes longer (IMHO) is that now for every iteration of the for loop a new instance of PreparedStatement (getProteinIdQuery) gets created whereas in the first fragment you reused the prepared statement using it the way it was meant to be: Instantiated and then supplied with proper values. At least that's my opinion... Jan  Preparing a statement takes time as you've found out. Whether the code is ugly or not that decrease in speed is very ugly too so you need to use the faster form. But what you could do is use an inner class to hold the details and provide a nicer interface: private class DatabaseInterface { private PreparedStatement insertAnnotation getProteinId; public DatabaseInterface() { // This is an inner class; 'connection' is variable in outer class insertAnnotation = connection.prepareStatement( ""INSERT INTO Annotations(GOId ProteinId OnthologyId) VALUES(? ? ?)""); getProteinId = connection.prepareStatement( ""SELECT Id FROM Proteins WHERE PrimaryUniProtKBAccessionNumber = ?""); } public long getId(Protein protein) { // Exceptions omitted... getProteinId.setString(1 protein.get_primary_id()); ResultSet result = getProteinId.executeQuery(); try { result.next(); return result.getLong(1); } finally { result.close(); } } public void insertAnnotation(int GOId long proteinId String ontologyId) { insertAnnotation.setInt(1 GOId); // type may be wrong insertAnnotation.setLong(2 proteinId); insertAnnotation.setString(3 ontologyId); // type may be wrong insertAnnotation.executeUpdate(); } } private void loadAnnotations(InteractionNetwork network) throws SQLException { connection.setAutoCommit(false); DatabaseInterface dbi = new DatabaseInterface(); for(common.Protein protein : network.get_protein_vector()) { dbi.insertAnnotation(... dbi.getId(protein) ...); } connection.commit(); connection.setAutoCommit(true); } The aim is that you have one piece of code that knows about mangling things into SQL (and which is easy to adapt if you go to a different database) and another piece of code that knows about how to coordinate these things together. Note also that you could think in terms of sharing the glue class more widely; it's tied to a connection and not a particular operation. Thank you very much it works very well."
612,A,"ResultSet not closed when connection closed? I ve been doing code review (mostly using tools like FindBug) of one of our pet projects and FindBug marked following code as errorneus (pseudocode): Connection conn = dataSource.getConnection(); try{ PreparedStatement stmt = conn.prepareStatement(); //initialize the statement stmt.execute(); ResultSet rs = stmt.getResultSet(); //get data }finally{ conn.close(); } The error was that that this code could might not release resources. I figured out that the ResultSet and Statement were not closed so I closed them in finally. finally{ try{ rs.close() }catch(SqlException se){ //log it } try{ stmt.close(); }catch(SqlException se){ //log it } conn.close(); } But I encountered the above pattern in many projects (from quite a few companies) and noone was closing ResultSets or Statements. Did you have troubles with ResultSets and Statements not being closed when Connection is closed? I found only this and it refers to Oracle having problems with closing ResultSets when closing Connections (we use Oracle db hence my corrections). java.sql.api says nothing in Connection.close() javadoc. I highly recommend using Apache commons-dbutils (http://commons.apache.org/dbutils/) It's a lightweight JDBC library that really cleans up a lot of boilerplate JDBC code. This is the kind of errors one gets when they don't close the relevant objects - ""ORA-01000: maximum open cursors exceeded"" - http://stackoverflow.com/questions/12192592/java-sql-sqlexception-ora-01000-maximum-open-cursors-exceeded database cursor - http://stackoverflow.com/questions/3861558/what-are-the-benefits-of-using-database-cursor A cursor is a tool that allows you to iterate the records in a set. It has concepts of order and current record. You should always close all JDBC resources explicitly. As Aaron and John already said closing a connection will often only return it to a pool and not all JDBC drivers are implemented exact the same way. Here is a utility method that can be used from a finally block: public static void closeEverything(ResultSet rs Statement stmt Connection con) { if (rs != null) { try { rs.close(); } catch (SQLException e) { } } if (stmt != null) { try { stmt.close(); } catch (SQLException e) { } } if (con != null) { try { con.close(); } catch (SQLException e) { } } } Man maybe we need a Closable interface huh? ResultSet are closed automatically when you close the Statement. (See JavaDoc http://download.oracle.com/javase/1.4.2/docs/api/java/sql/Statement.html) Thanks for posting. I like this idea. From this post's http://stackoverflow.com/questions/11160557/java-jdbc-best-design-pattern-to-close-database-connection-when-exception-occ#11160807 response from Brunoss (see Miserable Variable comment) you may want to reverse the order of closing rs and stmt (close stmt before rs). Connection Stamement and ResultSet all implement AutoCloseable since Java 7.  In Java Statements (not Resultsets) correlate to Cursors in Oracle. It is best to close the resources that you open as unexpected behavior can occur in regards to the JVM and system resources. Additionally some JDBC pooling frameworks pool Statements and Connections so not closing them might not mark those objects as free in the pool and cause performance issues in the framework. In general if there is a close() or destroy() method on an object there's a reason to call it and to ignore it is done so at your own peril.  I work in a large J2EE web environment. We have several databases that may be connected to in a single request. We began getting logical deadlocks in some of our applications. The issue was that as follows: User would request page Server connects to DB 1 Server Selects on DB 1 Server ""closes"" connection to DB 1 Server connects to DB 2 Deadlocked! This occurred for 2 reasons we were experiencing far higher volume of traffic than normal and the J2EE Spec by default does not actually close your connection until the thread finishes execution. So in the above example step 4 never actually closed the connection even though they were closed properly in finally . To fix this you you have to use resource references in the web.xml for your Database Connections and you have to set the res-sharing-scope to unsharable. Example: <resource-ref> <description>My Database</description> <res-ref-name>jdbc/jndi/pathtodatasource</res-ref-name> <res-type>javax.sql.DataSource</res-type> <res-auth>Container</res-auth> <res-sharing-scope>Unshareable</res-sharing-scope> </resource-ref>  I've definitely seen problems with unclosed ResultSets and what can it hurt to close them all the time right? The unreliability of needing to remembering to do this is one of the best reasons to move to frameworks that manage these details for you. It might not be feasible in your development environment but I've had great luck using Spring to manage JPA transactions. The messy details of opening connections statements result sets and writing over-complicated try/catch/finally blocks (with try/catch blocks in the finally block!) to close them again just disappears leaving you to actually get some work done. I'd highly recommend migrating to that kind of a solution. Its one point in this app. We use EJB and this part was sort of plugin - our client would deploy a datasource on serwer and then is able to query it through this plugin.  One problem with ONLY closing the connection and not the result set is that if your connection management code is using connection pooling the connection.close() would just put the connection back in the pool. Additionally some database have a cursor resource on the server that will not be freed properly unless it is explicitly closed. The javadocs for Connection#close method says that ""releases this Connection object's database and JDBC resources immediately"". I think the problem is that some bad implementations don't do the right job. When pools don't close related resources are they doing the wrong thing? Most major vendor's JDBC drivers correspond to spec. However most (if not all) application servers maintain a pool of connections. They wrap the native connection and reimplement methods like close() so that the connections can be 'pooled'. This means that if you work in these environments you MUST close resources like Statements and ResultSets yourself. @Ryan Fernandes: Well some pool just give you a connectionProxy object that saves all opened statements on it. When it gets returned in the pool it closes all opened statements.  I've had problems with unclosed ResultSets in Oracle even though the connection was closed. The error I got was ""ORA-01000: maximum open cursors exceeded"" So: Always close your ResultSet! +1 - for mentioning the consequences of not closing resources.  Oracle will give you errors about open cursors in this case. According to: http://java.sun.com/javase/6/docs/api/java/sql/Statement.html it looks like reusing a statement will close any open resultsets and closing a statement will close any resultsets but i don't see anything about closing a connection will close any of the resources it created. All of those details are left to the JDBC driver provider. Its always safest to close everything explicitly. We wrote a util class that wraps everything with try{ xxx } catch (Throwable {} so that you can just call Utils.close(rs) and Utils.close(stmt) etc without having to worry about exceptions that close scan supposedly throw. _but i don't see anything about closing a connection will close any of the resources it created._ http://docs.oracle.com/javase/6/docs/api/java/sql/Connection.html#close() _releases this Connection object's database **and JDBC resources** immediately_ But yeah always better to close everything.  The ODBC Bridge can produce a memory leak with some ODBC drivers. If you use a good JDBC driver then you should does not have any problems with closing the connection. But there are 2 problems: Does you know if you have a good driver? Will you use other JDBC drivers in the future? That the best practice is to close it all."
613,A,JDBC URL for Oracle XA client Using the JDBC driver oracle.jdbc.xa.client.OracleXADataSource what is the correct format of the JDBC URL? The thin format of jdbc:oracle:thin:@host:port:sid does not work. WebSphere is reporting that the given url (which is otherwise correct) is invalid. The test connection operation failed for data source Oracle MyDB (XA) on server nodeagent at node MY_node with the following exception: java.sql.SQLException: Invalid Oracle URL specifiedDSRA0010E: SQL State = 99999 Error Code = 17067. View JVM logs for further details. There is nothing in the JVM logs. For me the issue resolved by adding alias name username and password in JAAS - J2C authentication data. And also selecting this entry as Component-managed authentication alias.  Had the same issue. Dont know about simple deployments but on a two nodes cluster I restarted the first node and the connection started working on it (not on the second). Restarted the second node and the connection started working there too. So just restart the nodes (I also restarted the nodeAgents but i don't know if it's necessary).  In my case the problem went away when I change the authentication property of the jdbc resource reference from Authentication=Application to Authentication=Container  Whether you use a XA Driver or not the JDBC connection string is the same (and the format of your question is correct). I thought so but the error message was saying otherwise. That there was no JVM logging at all was the thing that made me think WAS was in a bad state...  In case this happens to anyone else. The problem went away after restarting websphere.
614,A,"Parse SQL via Oracle's JDBC driver I'd like to test whether given SQL statement is syntactically and semantically valid (ie. no syntax errors and no field misspellings). For most databases Connection.prepareStatement and PreparedStatement.getMetaData would do the trick (no exception == good query). Unfortunately Oracle's newest driver only parses like this only SELECT queries but not other kind of queries. Older drivers don't do even that. Is there some other facility provided by Oracle for parsing SQL statements? You can use the Oracle DBMS_SQL package to parse a statement held in a string. For example: SQL> declare 2 c integer; 3 l_statement varchar2(4000) := 'insert into mytable (col) values (12)'; 4 begin 5 c := dbms_sql.open_cursor; 6 dbms_sql.parse(cl_statementdbms_sql.native); 7 dbms_sql.close_cursor(c); 8 end; 9 / declare * ERROR at line 1: ORA-00913: too many values ORA-06512: at ""SYS.DBMS_SYS_SQL"" line 824 ORA-06512: at ""SYS.DBMS_SQL"" line 32 ORA-06512: at line 6 You could wrap that up into a stored function that just returned e.g. 1 if the statement was valid 0 if invalid like this: function sql_is_valid ( p_statement varchar2 ) return integer is c integer; begin c := dbms_sql.open_cursor; dbms_sql.parse(cp_statementdbms_sql.native); dbms_sql.close_cursor(c); return 1; exception when others then return 0; end; You could then use it something like this PL/SQL example: :n := sql_is_valid('insert into mytable (col) values (12)'); Wohooo! Looks nice gonna try it tomorrow :) Thanks! It really works!! thanks again :)"
615,A,"stored procedures error #1312 CLIENT_MULTI_RESULTS flag i am writing stored procedures in MySQL that return values; CREATE PROCEDURE getCustomerById (id int) BEGIN SELECT * FROM customer WHERE customer.id = id; END; and i get the error that the results cannot be shown in the given context. after some googling i think that i need to set the flag ""CLIENT_MULTI_RESULTS"" - i am connecting the database from JDBC using a java app but cant find where to set it! any suggestions? try this delimiter ; drop procedure if exists getCustomerById; delimiter # create procedure getCustomerById ( in p_id int unsigned ) begin select c.* from customer c where c.id = p_id; end # delimiter ;"
616,A,"Fastest way to iterate through large table using JDBC I'm trying to create a java program to cleanup and merge rows in my table. The table is large about 500k rows and my current solution is running very slowly. The first thing I want to do is simply get an in-memory array of objects representing all the rows of my table. Here is what I'm doing: pick an increment of say 1000 rows at a time use JDBC to fetch a resultset on the following SQL query SELECT * FROM TABLE WHERE ID > 0 AND ID < 1000 add the resulting data to an in-memory array continue querying all the way up to 500000 in increments of 1000 each time adding results. This is taking way to long. In fact its not even getting past the second increment from 1000 to 2000. The query takes forever to finish (although when I run the same thing directly through a MySQL browser its decently fast). Its been a while since I've used JDBC directly. Is there a faster alternative? First of all are you sure you need the whole table in memory? Maybe you should consider (if possible) selecting rows that you want to update/merge/etc. If you really have to have the whole table you could consider using a scrollable ResultSet. You can create it like this. Statement stmt = con.createStatement( ResultSet.TYPE_SCROLL_INSENSITIVE ResultSet.CONCUR_READ_ONLY); ResultSet srs = stmt.executeQuery(""select * from ...""); It enables you to move to any row you want by using 'absolute' and 'relative' methods. Awesome. that did the trick. To answer your point about selectively getting data. Unfortunately I don't know which rows to merge and fix ahead of time -- I have to go through all the rows and inspect build appropriate in-memory hashmaps and then go back and clean the table based on certain qualities. This method is rather fragile. If you have millions of rows and some processing to do you might hit a network lag or a timeout which will make it difficult to resume the action in certain cases. Unfortunately this works very slow on large tables because MySQL JDBC driver doesn't support cursors and driver tries to load all data into the memory  One thing that helped me was Statement.setFetchSize(Integer.MIN_VALUE). I got this idea from Jason's blog. This cut down execution time by more than half. Memory consumed went down dramatically (as only one row is read at a time.) This trick doesn't work for PreparedStatement though.  Although it's probably not optimum your solution seems like it ought to be fine for a one-off database cleanup routine. It shouldn't take that long to run a query like that and get the results (I'm assuming that since it's a one off a couple of seconds would be fine). Possible problems - is your network (or at least your connection to mysql ) very slow? You could try running the process locally on the mysql box if so or something better connected. is there something in the table structure that's causing it? pulling down 10k of data for every row? 200 fields? calculating the id values to get based on a non-indexed row? You could try finding a more db-friendly way of pulling the data (e.g. just the columns you need have the db aggregate values etc.etc) If you're not getting through the second increment something is really wrong - efficient or not you shouldn't have any problem dumping 2000 or 20000 rows into memory on a running JVM. Maybe you're storing the data redundantly or extremely inefficiently? Thanks for the suggestions. I believe the main problem was I wasn't using the JDBC API in an optimal way. I am able to fetch my data relatively quickly right now in 10k-20k increments. Good suggestion though on only pulling the necessary columns instead of doing a SELECT *."
617,A,"How to load Java Stored Procedure through JDBC into Oracle 10g? I'm trying to load some java stored procedures into an Oracle 10g database through JDBC. The statement I'm executing is - CREATE OR REPLACE JAVA SOURCE NAMED ""test.Test"" AS package test; public class Test { public static String myMethod(String a) { return a; } }; Running this through TOAD works just fine but when running through my JDBC client gives the following error - Exception in thread ""Thread-3"" java.lang.NullPointerException at oracle.jdbc.driver.T4C8Oall.getNumRows(T4C8Oall.java:728) at oracle.jdbc.driver.T4CStatement.execute_for_rows(T4CStatement.java:478) at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1028) at oracle.jdbc.driver.OracleStatement.executeUpdate(OracleStatement.java:1451) at ejsdal.CreateDBJavaSQL.executeScript(CreateDBJavaSQL.java:23) at ejsdal.OperationController.run(OperationController.java:182) I'm using the java.sql.Statement's ""executeUpdate"" passing the string in the first code block. It is possible to load java source through JDBC? Figured it out - need to set the statement.setEscapeProcessing(false); before executing the update. This is because the Java source file's { and } characters are misinterpreted as procedure call syntax by the JDBC driver."
618,A,"What are likely causes of StringBuilder and ResultSet performance issues I'm looping through a ResultSet in Java; which for testing purposes is returning about 30 rows with 17 Columns (all String data) per row. I'm manually building an XML String out of the results using StringBuilder and its literally taking about 36 seconds for the loop to finish these iterations. Note: I realize this isn't the best way to go about getting XML out of a Database or even the best way to get XML out of a ResultSet - but this has me curious of the slow performance regardless. Update: As per responses so far I have to address the following: The time to run the Query is less than a second and I did a System.currentTimeMillis() before and after every section of my code to narrow this down. The 36 seconds is entirely within the code below. ResultSetMetaData rsmeta = rset.getMetaData(); StringBuilder resultBuilder = new StringBuilder(); resultBuilder.append(""<?xml version=\""1.0\"" ?><ROWSET>""); if(numColumns != 0){ while (rset.next()) { resultBuilder.append(""<ROW>""); for (int i = 0; i <= numColumns -1;i++) { columnName = rsmeta.getColumnName(i+1); resultBuilder.append(""<""); resultBuilder.append(columnName); resultBuilder.append("">""); resultBuilder.append(rset.getString(i+1)); resultBuilder.append(""</""); resultBuilder.append(columnName); resultBuilder.append("">""); } resultBuilder.append(""</ROW>""); numRows += 1; } } else { stmt.close(); wsConn.close(); return ""No Results""; } Update: Given the suggestions I received - this code takes roughly the same amount of time give or take half a second. StringBuilder resultBuilder = new StringBuilder(); resultBuilder.append(""<?xml version=\""1.0\"" ?><ROWSET>""); if(numColumns != 0){ while (rset.next()) { resultBuilder.append(""<ROW>""); for (int i = 0; i <= numColumns -1;i++) { //columnName = rsmeta.getColumnName(i+1); resultBuilder.append(""<""); resultBuilder.append(""TestColumnName""); resultBuilder.append("">""); //resultBuilder.append(rset.getString(i+1)); resultBuilder.append(""TestData""); resultBuilder.append(""</""); resultBuilder.append(""TestColumnName""); resultBuilder.append("">""); } resultBuilder.append(""</ROW>""); numRows += 1; } } else { stmt.close(); wsConn.close(); return ""No Results""; } The last test I did having eliminated everything else was to replace the while test with a realistic number of iterations (160 the max rows returned from the small tests I've done previously). The question now is what could it be about this result set that causes such a slow down. while (numRows <= 160) { // same as above } Update: As suggested I'll be closing this question as the title doesn't reflect the direction the problem took. **Question for more experienced SO users:** When you say ""close"" do you mean select an answer or delete the question as it became more about ResultSet/Database performance than StringBuilder. Thanks I'm pretty sure that your problem here is not the `StringBuilder`. Try removing everything mentioning `StringBuilder` and keep only the loops and the `getColumnName()` and `getString()` calls. you are doing a performance test against a database connection. How can you be sure the bottleneck is not the database? At the update: the query is just the first part of the database operation. a result set often is a facade to a database cursor. Thats interesting Arne I wasn't aware of that. Hmm... Can you put the System.currentTimeMillis() before and after the line ResultSetMetaData rsmeta = rset.getMetaData(); then another after the code block. I suspect its the construction of the result set that is causing the delay. Why don't you try putting column names and data in some data structure and trying the same code pulling String values from a list of that instead of the database? I think you'll find it's quite fast. (Aside: currentTimeMillis() is for wall clock time nanoTime() is for timing things). After your last update your preoccupation is not aligned with your initial question and its title and answers. **I suggest closing this question and asking another one for your new preoccupation.** I agree that the StringBuilder may not be the real time sink here. However the StringBuffer may be slightly constrained because it ends up having to allocate additional space as the buffer grows (and exceeds it's default size). This suggestion addresses your question but again I doubt they'll address your problem. Good Luck The solution to that is to preallocate sufficient space or close to sufficient space using `new StringBuilder()`.  The problem is that the ResultSet has a persistent link to the database and gets more info when its called. May I suggest that you look into a CachedRowSet (javadoc here). It will pull down all the data immediately and acts exactly like a ResultSet otherwise. You can then close your database connection and then start parsing your data. I would suggest trying that and see if it speeds up your process. This is great to know; in practice the performance stayed just about the same as either way - it needs to bring down the results and I strongly believe the bottleneck is nearly 100% on the Database at this point. Great I'll give this a shot thanks!  I strongly doubt that StringBuilder is your bottleneck in comparison to the time taken to access and retrieve data from the database. The fact that optimizing simple String concatenation did not significantly change run time confirms this. You need to look to optimizing how you access the database -- faster connection to the DB compressed connection etc. However I can offer one micro-optimization to your code: instead of appending single-character strings like ""<"" append a character like '<'. This however should not make much of any difference.  Try replacing various calls with canned data. For example someone has suggested that accessing the metadata is the culprit. Try replacing: columnName = rsmeta.getColumnName(i+1); with: columnName = ""Column"" + i; where i is an int you set to 0 before the loop and increment through the loop.  I think your note2 speak by itself. The time is not lost in the StringBuilder but somewhere else... columnName = rsmeta.getColumnName(i+1); Reading the meta-data could be very slow depending on the implementation. You could read them only once for all resultSets and reuse them in the loop. UPDATE From your last update the StringBuilder is out of concern and the problem is with the ResultSet. I feel that the question title and all answers given are not in synch with your current preoccupation. I suggest closing this question and opening a new one for the new preoccupation :-) I didn't mean that I had replaced StringBuilder altogether only combined some of the appends (I removed that note and provided an update). I'll look into the meta calls though.  Check how you're getting the result set back. There are methods in statement which allow you to change how the ResultSet pulls in data. In particular look at Statement#setFetchSize Statement#setFetchDirection Thanks this is useful!  I had similar problem yesterday: Querying a Microsoft SQL server 10 for about 1.7 million records and reading the values took about 50 minutes. After change; about 80 seconds... My problem was the jdbc driver used: The only change was going from com.microsoft.sqlserver.jdbc version 1.2 driver to net.sourceforge.jtds version 1.2.2 driver...  Actually reading info from a result set with getColumnName() next() and getValue() often takes much more time than fetching the result in the first place. This is especially true for non-scrollable result sets. StringBuilder allocates memory exponentially (newSize = FACTOR*oldSize) so the more you do the less it needs to reallocate. To really test this simply replace rset and rsmeta with a dummy object that has the same methods: let next() return true for a realistic number of rows and have the other methods return realistic-length strings. Actually `next()` and `getXXXXX()` all have to do with *fetch*; perhaps you mean *execute*. That is the fetch step (these methods) may take more time than preparing and executing the query. None-the-less `StringBuilder` is not the problem here as you say.  I very much doubt that StringBuilder is the culprit here. Java uses it extensively I have used it extensively I have rewritten it for my own sort-of-JVM and basically it is always able to eat characters by the hundreds of millions per second. I think your trouble comes from the database access itself. When you run a query and get a ResultSet it does not necessarily mean that all the data has been obtained and internally transformed into an easy-to-manage memory representation. Depending on the database implementation (and its JDBC driver) the ResultSet may be a promise of a number of results which are dynamically fetched when the ResultSet.next() and ResultSet.getString() methods are called. Try simply exploring the results calling all your next() and getString() but without storing the obtained data in your StringBuilder. If it still takes 36 seconds then StringBuilder is innocent (which I strongly believe it is). I selected this as the answer because it effectively describes the problem found in ResultSet.next() which actually describes the bottleneck being in my Query/Stored procedure."
619,A,XA vs. Non-XA JDBC Driver Performance? We are using an XA JDBC driver in a case where it is not required (read-only work that doesn't participate in a distributed transaction). Just wondering if there are any known performance gains to be had to switch to the Non-XA JDBC driver - if not it's probably not worth switching? FWIW we are using MySQL 5.1 Measuring is knowing. Do some benches. Replace the driver. Repeat the benches. Compare the results. You have the environment we not. Indeed - we will - but I was wondering if there is any inherent reason one might be faster than another (e.g. XA has to check if certain conditions occur - what those conditions are and if they are expensive to calculate). Is this question specific to *read-only* transactions? If so please add it to the title. As with all things performance related the answer is: it depends. Specifically it depends on exactly how you are using the driver. The cost of interacting transactionally with a database is divided roughly into: code complexity overhead communication overhead sql processing and disk I/O. Communication overhead differs somewhat between the XA and non-XA cases. All else being equal an XA transaction carries a little more cost here as it requires more round trips to the db. For a non-XA transaction in manual commit mode the cost is at least two calls: the sql operation(s) and the commit. In the XA case it's start sql operation(s) end prepare and commit. For your specific use case that will automatically optimize to start sql operation(s) end prepare. Not all the calls are of equal cost: the data moved in the result set will usually dominate. On a LAN the cost of the additional round trips is not usually significant. Note however that there are some interesting gotchas lurking in wait for the unwary. For example some drivers don't support prepared statement caching in XA mode which means that XA usage carries the added overhead of re-parsing the SQL on every call or requires you to use a separate statement pool on top of the driver. Whilst on the topic of pools correctly pooling XA connections is a little more complex than pooling non-XA ones so depending on the connection pool implementation you may see a slight hit there too. Some ORM frameworks are particularly vulnerable to connection pooling overhead if they use aggressive connection release and reacquire within transaction scope. If possible configure to grab and hold a connection for the lifetime of the tx instead of hitting the pool multiple times. With the caveat mentioned previously regarding the caching of prepared statements there is no material difference in the cost of the sql handling between XA and non-XA tx. There is however a small difference to resource usage on the db server: in some cases it may be possible for the server to release resources sooner in the non-XA case. However transactions are normally short enough that this is not a significant consideration. Now we consider disk I/O overhead. Here we are concerned with I/O occasioned by the XA protocol rather than the SQL used for the business logic as the latter is unchanged in either case. For read-only transactions the situation is simple: a sensible db and tx manager won't do any log writes so there is no overhead. For write cases the same is true where the db is the only resource involved due to XA's one phase commit optimization. For the 2PC case each db server or other resource manager needs two disk writes instead of the one used in non-XA cases and the tx manager likewise needs two. Thanks to the slowness of disk storage this is the dominant source of performance overhead in XA vs. non-XA. Several paragraphs back I mentioned code complexity. XA requires slightly more code execution than non-XA. In most cases the complexity is buried in the transaction manager although you can of course drive XA directly if you prefer. The cost is mostly trivial subject to the caveats already mentioned. Unless you are using a particularly poor transaction manager in which case you may have a problem. The read-only case is particularly interesting - transaction manager providers usually put their optimization effort into the disk I/O code whereas lock contention is a more significant issue for read-only use cases particularly on highly concurrent systems. Note also that code complexity in the tx manager is something of a red-herring in architectures featuring an app server or other standard transaction manager provider as these usually use much the same code for XA and non-XA transaction coordination. In non-XA cases to miss out the tx manager entirely you typically have to tell the app server / framework to treat the connection as non-transactional and then drive the commit directly using JDBC. So the summary is: The cost of your sql queries is going to dominate the read-only transaction time regardless of the XA/non-XA choice unless you mess up something in the configuration or do particularly trivial sql operations in each tx the latter being a sign your business logic could probably use some restructuring to change the ratio of tx management overhead to business logic in each tx. For read-only cases the usual transaction protocol agnostic advise therefore applies: consider a transaction aware level second level cache in an ORM solution rather than hitting the DB each time. Failing that tune the sql then increase the db's buffer cache until you see a 90%+ hit rate or you max out the server's RAM slots whichever comes first. Only worry about XA vs. non-XA once you've done that and found things are still too slow. In the end we abandoned XA data sources for MySQL because we were told by MySQL support that the XA data sources were not fully supported and could cause MySQL DBs to crash - so in the end this was all null and void
620,A,"java.lang.OutOfMemoryError: Java heap space i get this error when calling a mysql Prepared Statement every 30 seconds this is the code which is been called: public static int getUserConnectedatId(Connection conn int i) throws SQLException { pstmt = conn.prepareStatement(""SELECT UserId from connection where ConnectionId ='"" + i + ""'""); ResultSet rs = pstmt.executeQuery(); int id = -1; if (rs.next()) { id = rs.getInt(1); } pstmt = null; rs = null; return id; } not sure what the problem is :s thanks in advanced. check your memory. linux command: free Why not make the query parameterized and simply change the connection ID? That's how prepared statements were intended to be used. That way you only compile the statement once and re-use the compiled query plan (or whatever your DB compiles your query into).  Because you are running out of memory as your ResultSet is occupyng more memory compared to default memory. Solution: At the time of starting the application use this argument java or javaw -Xms 25M -Xmx 1024M This is completely ridiculous advice. How do you know the process isn't already started with -Xmx2g? How do you know that -Xms25m is not going to cause the process to thrash when it starts? How do you know -Xmx1024m is going to be enough to solve the problem?  I will add some lines to my previous answer Force yor Garbage collection by making the main thread sleep for 2s. More ridiculous advice. Sleeping does not force garbage collection. Garbage collection happens when it needs to. If you get an OOM the garbage collector has already tried and failed to free up memory.  You need to close all the resources you create - prepared statement resultset etc. ahh of course! when you look at something for so long you dont see the obvious! :p"
621,A,"receiving xml with value null when it's actually null I'm executing a stored procedure on sql server 2005 from livecycle es 8.2 the result return something like <Table> <Row> <ID>1</ID> <EN_Cd>EN</EN_Cd> <FR_Cd>null</FR_Cd> <EN_Nm>English</EN_Nm> <FR_Nm>Anglais</FR_Nm> <EN_Shrt_Dscrptn>null</EN_Shrt_Dscrptn> <FR_Shrt_Dscrptn>null</FR_Shrt_Dscrptn> </Row> </Table> I'm trying to figure out why the word ""null"" is put in the result. Even with type xs:int it return the word ""null"" is there something in the jdbc or livecycle that can fix this? the stored procedure is a simple  select id en_cd fr_cd en_nm fr_nm en_shrt_dscrptn fr_shrt_dscrptn from language fr_nm en_shrt_dscrptn fr_shrt_dscrptn are null in the database they do not contain the value ""null"". Please edit your post and add the query that produced this result. @Jim Garrison I updated my question What is converting the query results to XML? livecycle does it Had the same question but posted on Adobe forums. Here's the link http://forums.adobe.com/thread/721645?tstart=0. Never really got a good answer other than speculation that the behaviour might change with JDBC/Datastore combo. Basically the XML just returns the value in the field period. I'd say the best bet is to XSLT the nulls into the correct XML xsi:nil=""true"" before it returns out of the workflow. @Jim Garrison - LC has 'foundation' components that you configure through the IDE. One of the 'foundation' components is a JDBC one that contains what is called a 'Query Multiple Rows as XML'. It calls the datastore and then formats the results into an XML result. A good example of how it works with a solution for transforming the results is here http://www.adobe.com/devnet/livecycle/articles/transforming_jdbc.html. Try using the coalesce() function to convert nulls to empty strings like this: select id coalesce(en_cd'') coalesce(fr_cd'') coalesce(en_nm'') coalesce(fr_nm'') coalesce(en_shrt_dscrptn'') coalesce(fr_shrt_dscrptn'') from language Alternatively you could investigate how the conversion to XML is happening and see if there's a way to specify null-handling options there. Yea unfortunately you have to wrap the columns with either coalesce or isnull in SQL. In Livecycle 9 if a column is null and you are using the Select single row component it will actually throw a SQL Exception.  you can use a XSLT transformation for removing the NULL from the nodes content. check my questions for a further explanation on that"
622,A,java.sql.SQLException: Exhausted Resultset I get the error java.sql.SQLException: Exhausted ResultSet to run a query against an Oracle database. The connection is via a connection pool defined in Websphere. The code executed is as follows:  if (rs! = null) ( while (rs.next ()) ( count = rs.getInt (1); ) ) I note that the resultset contains data (rs.next ()) Thanks Has the statement or connection be closed while reading the result set? @Arne: that would rather have thrown a `SQLException: ResultSet is closed`. In the future add the stacktrace and point the line. Seeing the accepted answer the line where it was thrown was **absolutely not** in the code which you posted in your question. You should practice more with interpreting stacktraces. I deleted my answer. Yup was absolutely not in the code because I figured it :-) Always i've seen this error was caused for same issue. I've seen this error while trying to access a column value after processing the resultset. if (rs! = null) { while (rs.next()) { count = rs.getInt(1); } count = rs.getInt(1); //this will throw Exhausted resultset } Hope this will help you :)  Try this: if (rs != null && rs.first()) { do { count = rs.getInt(1); } while (rs.next()); } This will fail if the resultset is forward only...  Please make sur that res.getInt(1) is not null. If it can be null use Integer count = null; and not int count =0; Integer count = null; if (rs! = null) ( while (rs.next ()) ( count = rs.getInt (1); ) )  This occurs typically when the stmt is reused butexpecting a different ResultSet try creting a new stmt and executeQuery. It fixed it for me!  If you reset the result set to the top using rs.absolute(1) you won't get exhaused result set. while (rs.next) { System.out.println(rs.getString(1)); } rs.absolute(1); System.out.println(rs.getString(1)); You can also use rs.first() instead of rs.absolute(1) it does the same.
623,A,What happens if I don't include a db driver when using JDBC? I'm new to java development and was happy to see how much easier the database implementation was when it comes to supporting several platforms compared to the php environment I'm used to. There is however one thing I'm confused about - I read everywhere I have to do a runtime-include of the database driver I want to use ie: Class.forName(com.example.jdbc.Driver).newInstance(); However omitting this seems to work fine too - so my question is does jdbc find the driver given the server url automagically? And if so why is this line included in all the tutorials i read on the subject? Also - if anyone's got any good tips for online java learning resources (enterprise development in particular) please share! Yes this has improved in JDK 6. See this O'Reilly article for JDBC 4.0 improvements. In particular: In JDBC 4.0 we no longer need to explicitly load JDBC drivers using Class.forName(). When the method getConnection is called the DriverManager will attempt to locate a suitable driver from among the JDBC drivers that were loaded at initialization and those loaded explicitly using the same class loader as the current application. See also the JavaDoc for DriverManager in JDK 6.  Didn't this change in JDK 6? That would make a lot of sense - and would support my theory that I need to find better places to get info from :)
624,A,"Auto generate key on JDBC insert in SQL Server Is there a general cross RDMS way I can have a key auto generated on a JDBC insert? For example if I have a table with a primary key id and an int value: create table test ( id int not null myNum int null ) and do an insert PreparedStatement statement = connection.prepareStatement(""insert into test(myNum) values(?)"" Statement.RETURN_GENERATED_KEYS); statement.setInt(1 555); statement.executeUpdate(); statement.close(); I get an java.sql.SQLException: Cannot insert the value NULL into column 'id'. I have a feeling this is entirely RDMS dependent. We are using using SQL Server 2005 and I have set CONSTRAINT [PK_test] PRIMARY KEY CLUSTERED ( [id] ASC )WITH (PAD_INDEX = OFF STATISTICS_NORECOMPUTE = OFF IGNORE_DUP_KEY = OFF ALLOW_ROW_LOCKS = ON ALLOW_PAGE_LOCKS = ON FILLFACTOR = 1) ON [PRIMARY] in the table with no luck. This is database dependant. Oracle requires a SEQUENCE to be created and on MySQL you just set the column as auto increment. You could always use Hibernate. To explain it a bit more - using Hibernate you could generate the DDL or even let Hibernate create all mapped tables on startup. You would just have to tell Hibernate the target database using the appropriate ""dialect"".  This is completely database dependent. There are two main options: 1 - DBMSs that allow an auto-increment keyword next to the primary key definition and 2 - DBMSs that provide sequence generators (that you then can use to generate the new values for the PK for instance by writing a ""before insert"" trigger that automatically inserts the new value in the column before completing the insertion ). As far as I know: Firebird uses sequences DB2 allows to define a column as ""GENERATED BY DEFAULT AS IDENTITY""; Interbase uses sequences (called generators) MySQL has the ""AUTO_INCREMENT"" clause Oracle uses sequences PostgreSQL uses sequences SQLServer has the ""IDENTITY(11)"" clause For DB2 you can choose between an identity column and a sequence. I could image this counts for other rdbms' too. Thanks for the clarification. However this does not count for other rdbms. At least not for Oracle.  As far as I know it's database dependent. Likewise with inserting timestamps; some will insert the current time when you insert a null.  You need to set the id column in the test table to autocreate an identity. In the case of SQL Server you need to set the IDENTITY() property on the ID column."
625,A,"OracleCallableStatement registerOutParameter doesn't like named binding this code gives ""Incorrectly set or registered parameter"" SQLException. Can anyone help please? OracleConnection conn = getAppConnection(); String q = ""BEGIN INSERT INTO tb (id) values (claim_seq.nextval) returning id into :newId; end;"" ; CallableStatement cs = (OracleCallableStatement) conn.prepareCall(q); cs.registerOutParameter(""newId"" OracleTypes.NUMBER); cs.execute(); int newId = cs.getInt(""newId""); `newId` isn't an OUT parameter which IIRC requires you to use a stored procedure JDBC does not support named binding so it stops here. Either live with indexed placeholders ? or add an extra abstraction layer on top of JDBC which supports named parameters e.g. Hibernate and/or JPA. See also: JDBC tutorial Hibernate manual chapter 10.4.1.4 - Bind Parameters"
626,A,"c3p0 ResultSet.unwrap throws an AbstractMethodError I have a ResultSet object that I need to turn into an OracleResultSet so that I can call the getOPAQUE(String) method on it. I'm using c3p0 as my connection pool. The problem is that c3p0 wraps ResultSets in NewProxyResultSet objects. This shouldn't be a problem because I should just be able to call unwrap on the ResultSet like this: rs.unwrap(OracleResultSet.class) However that doesn't work. It actually throws an AbstractMethodError: java.lang.AbstractMethodError: com.mchange.v2.c3p0.impl.NewProxyResultSet.unwrap(Ljava/lang/Class;)Ljava/lang/Object; It includes a stack trace but it's not helpful because the top line of the stack trace just points to the exact line on which I call the unwrap method. That seems to indicate that NewProxyResultSet itself does not have unwrap implemented. What's up with this? How can I take a NewProxyResultSet and get an OracleResultSet from it? I figured out a way to get the inner value! It's a hack but it works. If anyone knows a more portable way of getting the inner value (like making the unwrap method work) then I'd love to do that instead. But it turns out that the ""inner"" variable of the NewProxyResultSet is declared protected. So I just make a class in the same package as NewProxyResultSet and use it to get the inner value like so: package com.mchange.v2.c3p0.impl; import java.sql.ResultSet; /** * This is a sneaky way to get at the inner ResultSet of NewProxyResultSet. It marks the variable as protected * so here I just make a class in the same package and get the value out. * */ public class C3P0ResultSetPeeker { public static ResultSet getInnerFrom(NewProxyResultSet rs) { return rs.inner; } } BTW I had problems with c3p0 as well. It didn't do transactions properly. See http://stackoverflow.com/questions/1977366/spring-transactional-cpool-which-one-do-i-use/2002505#2002505 for full instructions on how I did it."
627,A,"Spring Jdbc query execution Does anyone know how what Spring Jdbc template method I could use to execute this 'upsert' or an alternative approach that would also perform the operations in one database call? UPDATE jasper_report SET Uri = 'update' WHERE ReportId = 99; IF @@ROWCOUNT = 0 AND Exists(Select 1 FROM report Where Id = 99) BEGIN INSERT INTO jasper_report (ReportId Uri) VALUES (99 'insert') END; EXACT duplicate - http://stackoverflow.com/questions/2104211/spring-jdbc-template-query-execution Accidentally posted twice dup has been removed Shouldn't that be Not Exists? At any rate I think it would work fine without the Not Exists since @@ROWCOUNT is already giving you that info: UPDATE jasper_report SET Uri = 'update' WHERE ReportId = 99; IF @@ROWCOUNT = 0 BEGIN INSERT INTO jasper_report (ReportId Uri) VALUES (99 'insert') END; No the exists is on a different table essentially it is checking that the foreign key constraint exists on the primary table thus avoiding a foreign key violation if the id is not in the 'report' table. Oh missed that it was a different table!  Turns out I was close but forget a step. I had to change the query itself to: BEGIN UPDATE jasper_report SET Uri = ? WHERE ReportId = ? IF @@ROWCOUNT = 0 AND EXISTS(SELECT 1 FROM report WHERE Id = ?) BEGIN INSERT INTO jasper_report (ReportId Uri) VALUES (? ?) END END Then in my Dao only needed to use Spring's JdbcTemplate update method. It looks something like this: @Repository(""jasperReportsDao"") public class JasperReportsDaoImpl extends JdbcTemplate implements JasperReportsDao { @Override public void saveJasperReport(JasperReport report) { // If a record already exists do an update otherwise do an insert int rowsAffected = this.update(UPSERT_JASPER_REPORT new Object[] { report.getUri() report.getId() report.getId() report.getId() report.getUri()} ); if(log.isDebugEnabled()) { log.debug(""Rows affected: "" + rowsAffected); } } }"
628,A,Insert a lot of data into database in very small inserts So i have a database where there is a lot of data being inserted from a java application. Usualy i insert into table1 get the last id then again insert into table2 and get the last id from there and finally insert into table3 and get that id as well and work with it within the application. And i insert around 1000-2000 rows of data every 10-15 minutes. And using a lot of small inserts and selects on a production webserver is not really good because it sometimes bogs down the server. My question is: is there a way how to insert multiple data into table1 table2 table3 without using such a huge amount of selects and inserts? Is there a sql-fu technique i'm missing? Since you're probably relying on auto_increment primary keys you have to do the inserts one at a time at least for table1 and table2. Because MySQL won't give you more than the very last key generated. You should never have to select. You can get the last inserted id from the Statement using the getGeneratedKeys() method. See an example showing this in the MySQL manual for the Connector/J: http://dev.mysql.com/doc/refman/5.1/en/connector-j-usagenotes-basic.html#connector-j-examples-autoincrement-getgeneratedkeys Other recommendations: Use multi-row INSERT syntax for table3. Use ALTER TABLE DISABLE KEYS while you're importing and re-enable them when you're finished. Use explicit transactions. I.e. begin a transaction before your data-loading routine and commit at the end. I'd probably also commit after every 1000 rows of table1. Use prepared statements. Unfortunately you can't use the fastest method for bulk load of data LOAD DATA INFILE because that doesn't allow you to get the generated id values per row.  There's a lot to talk about here: It's likely that network latency is killing you if each of those INSERTs is another network roundtrip. Try batching your requests so they only require a single roundtrip for the entire transaction. Speaking of transactions you don't mention them. If all three of those INSERTs need to be a single unit of work you'd better be handling transactions properly. If you don't know how better research them. Try caching requests if they're reused a lot. The fastest roundtrip is the one you don't make.  You could redesign your database such that the primary key was not a database-generated auto-incremented value but rather a client generated UUID. Then you could generated all the keys for every record upfront and batch the inserts however you like. good idea but there is a but... the time to redesign the database would be too time consuming. There is a planned database redesign but not now.
629,A,"How to use Oracle jdbc driver fixedString property? Oracle pads values in char columns so if I insert ""a"" in a CHAR(2) column then I cannot get that record by comparing that column to ""a"" I should get it by comparing it to ""a "". Right? To solve this problem the Oracle jdbc driver has the property fixedString but I cannot make it work. (look for fixedString here) I'm using ojdbc14.jar driver for Oracle 10gR2 and accessing an Oracle 10gR2 database. This is my code:  try { Properties props = new Properties(); props.put(""user"" ""****""); props.put(""password"" ""****""); props.put(""fixedString"" true); Class.forName(""oracle.jdbc.driver.OracleDriver""); String jdbcUrl = ""jdbc:oracle:thin:@<host>:<port>:<sid>""; Connection connection = DriverManager.getConnection(jdbcUrl props); PreparedStatement ps = connection.prepareStatement( ""SELECT * FROM MY_TABLE WHERE MY_TABLE_ID = ?""); ps.setObject(1 ""abc""); // (*) // MY_TABLE_ID is CHAR(15) ResultSet rs = ps.executeQuery(); while (rs.next()) { System.out.print(""data: ""); System.out.println(rs.getString(""MY_TABLE_ID"")); } rs.close(); ps.close(); connection.close(); } catch (SQLException ex) { ex.printStackTrace(); } catch (ClassNotFoundException ex) { ex.printStackTrace(); } The above code executes fine (no exceptions thrown) but the ResultSet is empty after executeQuery(). If I change the line (*) for ps.setObject(1 ""abc ""); Then I get the column I wanted. So it seems the driver is ignoring the fixedString option. I've also tried changing the line (*) for ps.setObject(1 ""abc"" java.sql.Types.CHAR); But the ResultSet I get is empty again. What am I missing? Thanks in advance The oracle docs are infuriating really. I'd never heard of this before your question (one of the things I like about this site). looked into this and found a few refs that mention that it'll use ""FIXED CHAR"" semantics but nothing that describes how they work or what your expected return values will be only behavior regarding matching and equality. Can you do your query using ""Like""? (much slower of course) Turn off fixed char semantics for that query? Insert trimmed values only into the db? references herehere here. I've just added a reference for the fixedString property.  Try using it as props.put(""fixedString"" ""true""); Oracle documentation says fixedString as String (containing boolean value) The property only works with setObject(...). The property has no effect when calling setString(...).  You should only use CHAR for strings that will be the same length for every entry in the database. Use VARCHAR for variable length strings. The question was about the fixedString property specifically. That was not the question. I cannot change the column definition it is not up to me. You answered your own question while asking the question. CHAR is fixed length. Oracle pads your string to match the fixed length. You must give it a string that also has the pads. VARCHAR would stop the padding."
630,A,What is required for building Java Windows Application to access Online MySQL Database Can anyone list the requirements (i.e. any books tutorials libraries etc) to build an application in Java which could communicate with my MySQL Database which is running on web. I am running an online webstore built in PHP and MySQL. I would like to build a Java Application through which I can (CRUD) Products Categories Orders etc. My Database is already built in MySQL and all the data is present in my online site. So i only need to work on a GUI App which can access my Store's data. Here is an example application built in Delphi which acts as a Front End (Store Manager) for oscommerce shopping cart. What technologies do I need for creating Windows GUI in java and Database Application to communicate with my Online Store's Database. ? I have found some tutorials: hXXp://www.netbeans.org/kb/docs/java/gui-db.html hXXp://www.netbeans.org/kb/docs/java/gui-db-custom.html hXXp://www.netbeans.org/kb/articles/mysql-client.html hXXp://www.netbeans.org/kb/docs/java/gui-db.html Are the above tutorials enough ? UPDATE: How about the following books : 1). JDBC Practical Guide for Java Programmers 2). JDBC API Tutorial and Reference 3rd Edition Would these be enough for a beginner ? Why don't you just use the MySQL tools directly or any Javabased database viewer? If it is only for you you will save quite a bit of time. DBvisualizer has worked well for me. http://www.minq.se/products/dbvis/ I did not understand your post. Can you elaborate please. How would DBVisualizer help me in building a Windows Application interacting with my Online MySQL Database. I was suggesting that if you were the only person working with your database and the database is small  it might be much easier and faster to do the work in a database interaction program than to hand code an application. If not Netbeans has a tutorial on creating a CRUD application against MySQL - http://platform.netbeans.org/tutorials/nbm-crud.html  also Java Swing tutorial or check out SWT if you prefer faster and more native looking UI  For the database communication you're going to need a JDBC driver for MySql. Check out the official Sun JDBC tutorial for details on how to use this to access your database. Can you recommend any good book on this topic ? I'd look at the tutorial (I've just edited my original answer). Otherwise I think there's an OReilly book on this Just read the following at the first link you posted: ------ Although JDBC is useful by itself we would hope that if you are not familiar with JDBC that after reading the first few sections of this manual that you would avoid using naked JDBC for all but the most trivial problems and consider using one of the popular persistence frameworks such as Hibernate Spring's JDBC templates or Ibatis SQL Maps to do the majority of repetitive work and heavier lifting that is sometimes required with JDBC. -------- Do I need to learn Hibernate or Spring as well ? or would JDBC suffice ? What GUI technology should I use ? Swing or SWT with JDBC I don't think so for this. If you have an existing db schema and are familiar with it and presumably you have stored procs/queries etc. already fashioned for your existing application then translating those into JDBC is relatively straightforward. Depending on the complexity of the objects you want to retrieve you may want some automated solution to perform that mapping but I would suggest trying it first getting something working (with JDBC) and then see how much effort it is Shouldn't make a difference. That decision should be orthogonal to the database work For starters JDBC works find. Remember to have anything SQL related outside the GUI code.
631,A,JDBC and Connection Pools in Glassfish App Server I want to set up a connection pool and JDBC connection on EAR deployment so I do not have to set it up on each App Server I deploy to manually. What do I need to do? Is there an .xml file I can put this information into? Sorry to be so terse but this may be what you are looking for http://docs.sun.com/app/docs/doc/820-4502/beaqi?a=view  If you are using a single GlassFish administration console to manage multiple application servers throughout your environment those application servers can share a common configuration. If each deployed application server has its own administration console you can write a script to call the CLI (asadmin) to create and configure the connection pools. Actually you can use the CLI to configure a distributed deployment in the 1st use case but you'll have to specify which configuration you are modifying. The CLI is good for automation. Hopefully the following resources help: http://docs.sun.com/app/docs/doc/820-4341/abdjl?a=view http://wiki.glassfish.java.net/Wiki.jsp?page=GlassFishV2Architecture http://docs.sun.com/app/docs/doc/820-4332/6nfq988or?a=expand (for asadmin CLI reference) http://docs.sun.com/app/docs/doc/820-4332/create-jdbc-connection-pool-1?a=view (see --target to specify the target in a multi-host deployment) John Clingan GlassFish Group Product Manager
632,A,"JDBC: What is the correct JDBC URL to connect to a RAC database We were connecting to Oracle from our code with a simple (custom) JDBC connector class. This class reads the connection properties from a resource file and tries to make a connection to Oracle (thin connection). However recently the database have moved to a RAC and now the application is unable to connect to the DB. Here is the TNSPING output: Used LDAP adapter to resolve the alias Attempting to contact (DESCRIPTION=(ADDRESS_LIST=(LOAD_BALANCE=OFF)(FAILOVER=ON) (ADDRESS=(PROTOCOL=TCP)(HOST=tst-db1.myco.com)(PORT=1604)) (ADDRESS=(PROTOCOL=TCP)(HOST=tst-db2.myco.com)(PORT=1604)))(CONNECT_DATA= SERVICE_NAME=mydb1.myco.com)(SERVER=DEDICATED))) OK (80 msec) What would be the correct URL to specify in this case. Regards Ashish The point of a tnsnames file the older Oracle Names server and the newer recommended LDAP directory server method of resolving database names is to avoid having to hardcode hostnames addresses ports etc. into your connection string. The DBAs should be able to move the database to a new host or port without breaking anything. The best way to set your thin connect URL is with the following syntax: jdbc:oracle:thin:@ldap://<OID server name>:<OID port>/<DB SID or Service Name>cn=OracleContextdc=<yourdomain> So in your case if ""oid"" were the DNS-resolvable name of the OID server at your company and it used port 5000 it would be: jdbc:oracle:thin:@ldap://oid:5000/mydb1cn=OracleContextdc=mycodc=com If your DBAs have not yet set up OID they are woefully behind. Time to get new DBAs. -squish  You may want to look at the OCI drivers. I believe they are supposed to be better performing and handle RAC better. from http://download.oracle.com/docs/cd/B10500%5F01/appdev.920/a96590/adg01dev.htm#429762 OCI provides significant advantages over other methods of accessing an Oracle database: * More fine-grained control over all aspects of the application design. * High degree of control over program execution. * Use of familiar 3GL programming techniques and application development tools such as browsers and debuggers. * Support of dynamic SQLmethod 4. * Availability on the broadest range of platforms of all the Oracle programmatic interfaces. * Dynamic bind and define using callbacks. * Describe functionality to expose layers of server metadata. * Asynchronous event notification for registered client applications. * Enhanced array data manipulation language (DML) capability for array INSERTs UPDATEs and DELETEs. * Ability to associate a commit request with an execute to reduce round-trips. * Optimization for queries using transparent prefetch buffers to reduce round-trips. * Thread safety so you do not have to use mutual exclusive locks (mutex) on OCI handles. * The server connection in nonblocking mode means that control returns to the OCI code when a call is still executing or could not complete. Agreed - but the enterprise policy (sigh) recommends using thin clients over their 'thick' counterparts. Wow... that's just ignorant.  The URL should look like the following: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS_LIST=(LOAD_BALANCE=OFF)(FAILOVER=ON) (ADDRESS=(PROTOCOL=TCP)(HOST=tst-db1.myco.com)(PORT=1604)) (ADDRESS=(PROTOCOL=TCP)(HOST=tst-db2.myco.com)(PORT=1604))) (CONNECT_DATA=SERVICE_NAME=mydb1.myco.com)(SERVER=DEDICATED))) Actually just copy the tnsentries from your tnsnames.ora. That. Is. Awesome. I had no idea you can directly copy from `tnsnames.ora`. I just waded thru some JDBC connection string hell earlier. Your post really helped.  also you can use scan ip in oracle 11g r2 instead of your nodes ip:  testi=(DESCRIPTION = (ADDRESS_LIST= (ADDRESS= (PROTOCOL = TCP)(HOST = scan-ip-or-name)(PORT = 1521)) (FAILOVER = on) (LOAD_BALANCE = on) ) (CONNECT_DATA= (SERVICE_NAME = testi) ) )"
633,A,Does the setting time_out in mysql affect JDBC connection pool? It's usually set to 60 seconds. But I think con pool will hold the connection so is there any conflict? Thank you. Here is the answer from Glassfish Wiki: idle-timeout-in-seconds maximum time in seconds that a connection can remain idle in the pool. After this time the pool implementation can close this connection. ====>Note that this does not control connection timeouts enforced at the database server side<====. Adminsitrators are advised to keep this timeout shorter than the EIS connection timeout (if such timeouts are configured on the specific EIS) to prevent accumulation of unusable connection in Application Server.
634,A,"Type 5 JDBC Driver Is anybody has tried JDBC type 5 driver. Is it faster than JDBC 4 driver? I thought this was just a hypothetical idea rather than actual software? It's not at all clear to me that ""type 5"" is really an official term rather than just something invented by DataDirect. Every article about them that I can find seems to be written by or about DataDirect. So you could ask whether DataDirect's ""type 5"" driver is faster than the DataDirect type 4 driver for any particular database... but beyond that the question doesn't currently make much sense. I can hardly make out any actual features between the ""faster simpler"" marketing gibberish on their website. Are they selling a JDBC driver that can connect to multiple RDBMS vendors? Based on the description you'd think Type 5 drivers should be able to bring world peace and solve the financial crisis as well...  I thought types I through IV for JDBC drivers referred to the amount of native code used. Type IV was always ""100% pure Java"". What's Type V supposed to mean? How much more pure can you be? ""...an album so black - it can't get much blacker..."" - Spinal Tap ""This one goes to eleven - It's one louder"""
635,A,How can I set up a JDBC connection to an OpenOffice Database odb file? For instructional purposes I want to set up a database in a Linux environment then conenct to it using JDBC. OpenOffice looks a lot simpler thatn MySQL but I'm not sure how to get the connection to it set up. The .odb files are zipped HSQL files. Here's a guide on how to handle them via Java.
636,A,Performing static SQL queries against DB2 without PureQuery I'd like to use JPA over JDBC for a new application. I'm strictly using Named queries and basic CRUD methods of JPA Entity manager which allows me (with the help of Hibernate or any other JPA implementation) to extract all SQL native queries that will be performed on the database. With this list of static queries I understand that I can build a DB2 package that is all execution plans of my requests. So my question is: Does performing those queries through JDBC against DB2 will take advantage of those execution plans or not ? I understand that the PureQuery product can capture the list of sql orders. Does it still through JDBC and not through PureQuery specific API provide more ? such a specific DB2 static bind feature ? or it is equivalent to JDBC? Thank you for any piece of answer. Question has been answered anyway feel free to add other comments related to this subject ! JDBC applications execute dynamic SQL only (i.e. DB2 does not use static packages). There are only 2 ways to get static SQL (where the queries are stored in a package in the database): Write your application using SQLJ (which eliminates JPA/Hibernate) or use pureQuery (which sits between JDBC and the database). Keep in mind that even with dynamic SQL DB2 does cache the execution plans for queries so if they are executed frequently enough (i.e. they remain in the cache) then you won't see the overhead from query compilation. The cache is only useful if the queries are an exact byte-for-byte match so select * from t1 where c1 = 1 is not the same as select * from t1 where c1 = 2 nor is select * from t1 where C1 = 1 (which gives the same result but the query differs). Using parameter markers (select * from t1 where c1 = ?) is key. Your DBA can tune the size of the catalog cache to help maximize the hit ratio on this cache. Although caching helps avoid repeatedly compiling a query it does not offer the plan stability that static SQL does so YMMV. Thank you for this valuable answer :)
637,A,"tool for detecting non-parametrized sql in java jdbc code I'm looking to inspect SQL statements in Java/jdbc code to ensure that the SQL to be executed is of acceptable quality. Neither PMD not Findbugs appears to have JDBC or sql rules. I could use p6spy to log the SQL and look at that way but this is manual. I'm wondering if the strategy of of using PMD/Findbugs/etc to create a rule that any string passed to PreparedStatement where there is an ""="" or ""in"" has only parametrized vars on the compare side. Has anyone done this? Or done this by other means? This is a tricky problem. Comparison operators like = and IN() are some cases but there's also: != <> < <= > >= LIKE. How do you spot cases of interpolating application variables as literals in expressions? String sql = ""SELECT * "" + someJavaVar + "" AS constant_column FROM mytable""; You could search for SQL containing string delimiters but SQL injection doesn't come only from interpolating string literals. How would you spot cases of interpolating application variables as things other than data values? String sql = ""SELECT * FROM mytable ORDER BY "" + columnname; I don't know any automatic way to detect SQL injection flaws. Code review is a more effective way to spot them. In every SQL statement that contains interpolated application variables you have to confirm that the application variables are ""safe"" and that your app has explicitly validated them or transformed them so they don't contain dangerous payload. Hm. I didn't understand your comment. I guess all SQL statements in your Java app are stored in Strings with variable names beginning with 'sql'? If so then yes you need to do a code review for all these cases. I don't know it this can be done. I would view interpolating application variables as a problem as this is for refactoring prior to migrating to a new rdbms rather than just looking for sql injection problems. I'm leaning toward searching for all vars starting with sql and progressing from there.  Do you have the ability to completely test the application with a debugger connected to it? Set a breakpoint in your JDBC driver's implementation of Connection.createStatement() and run the app... (or if using a driver for which you don't have source code write a fake driver that just delegates calls to the real one and log all instances of createStatement()) I did end up using p6spy to log all SQL and then trace them all back to the src."
638,A,"JDBC fundamental concepts Pooling and Threading I was always using JDBC in JavaSE on single-threaded environment. But now I need to use a connection pool and let many threads to have interaction with the database (MSSQL and Oracle) and I am having a hard time trying to make it as it seems that I am lacking some fundamental undestanding of the api. AFAIK after connect and logging a Connection represents a phisical tcp/ip connection to the database. It creates Statement(s) that can be seen as SQL interaction(s) with the database over the Connection. Where does the transaction and rollback comes in ? Is it at the Connection or Statement level. Is it safe that 'one' Connection create N statements and give it to diferent threads so to let each one own the use of that Statement ? If not and after configuring the pool something like this: OracleDataSource ods = new OracleDataSource(); ods.setURL(""jdbc:oracle:thin:@tnsentryname""); ods.setUser(""u""); ods.setPassword(""p""); BTW where do I set the connection pool size ? Is this what I would be doing in each thread in order to correctly use the connection ? //thead run method Connection conn = ods.getConnection(); Statement stmt = conn.createStatement(); ResultSet rs = stmt.executeQuery(""the sql""); // do what I need to do with rs rs.close(); int updateStatus = stmt.executeUpdate(""the update""); stmt.close(); conn.close(); // end of thread run method If any physical Connection of the Pool somehow crashes or disconects will the pool automaticaly try to reconnect and inject the new connection in the pool so that subsequent pool.getConnection() will just get a health connection ? Thanks a lot and forgive my bad english please. Extra bits: Application server tend to provide connection pooling and it can get quite clever. If you are using an app server investigate carefully what you get out of the box before adding anything of your own. Transactions: if you have Begin transaction get connnection work close connection // meaning return to pool get connection (with same isolation level etc.) // you will get SAME connection the pool reserves it for your transaction work // happens in same transacction close connection Commit transaction // commits all the work connections and errors Pool implementations can be clever. If any one connection from the pool experiences certain errors which indicate that the DB server has bounced then the pool can choose to to discard all pool members.  Transactions happen at the connection level. No. Usually the JDBC driver will make sure that you can't execute a second statement over the same connection while another one is active. If you need connection pooling try the DBCP framework. It offers pretty decent failure handling (like noticing stale connections and connections that haven't been returned by client code). As for your code: Always wrap the code in try{...}finally{...}: Connection conn = null; Statement stmt = null; ResultSet rs = null; try { conn = ds.getConnection (); stmt = ... rs = ... } finally { rs = close (rs); stmt = close (stmt); conn = close (conn); } public static Connection close (Connection conn) { if (conn != null) { try { conn.close (); } catch (SQLException e) { e.printStackTrace(); // Log don't rethrow!! } } return null; } This code will make sure that all connections etc are always correctly closed and that any exception during close won't hide a previous error. oh boy I love java everithing has a framework :D Thanks Aaron for the answer. But well about what the framework does with stale connections isn't it something that any pool implementation (oracle or mssql driver) should do it by default ? ""should"" != ""does"" != ""does well"". You can set a timeout in DBCP which says ""If the connection wasn't returned after an hour there's a bug in the client so let's reuse it"". As for ""stale"" you need to supply custom SQL to check whether a connection is dead. It would be nice if JDBC would define that but it doesn't and most DB vendors don't even bother to support a lot of the JDBC spec. For example in Oracle TIMESTAMP is not a java.sql.Timestamp.  Connection pools decorate Connection and Statement instances with their own wrapper implementations. When you call close on a connection you are actually just releasing it back to the pool. When you call close on a prepared statement you are actually just releasing it back to the connection's statement cache. When you prepare a statement you might just be fetching a cached statement instance from the connection. All this is hidden from view so that you don't have to worry about it. When a connection is given to a client it is no longer available for any other client to use until the connection is released back to the pool. You generally just fetch connections when you need them and then return them as soon as you are finished with them. Because the connections are being held open in the pool there is little overhead in fetching and releasing connections. You should use a connection from the pool just as you would a single JBDC connection and follow best-practices regarding the closing of resources so that you do not leak any connections or statements. See the try/catch/finally examples in some of the other answers. Pools can manage the connection resources and test them before handing them out to clients to ensure that they aren't stale. Also a pool will create and destroy connections as needed. wow ! thanks teabot one more thing once you have a connection. Why the api split the operations to be made in the database in a Statement object instead of just using the connection object ? I undertand this for prepared statements. But for normal statements is it just to let the developer have lets say N operations that migth get executed or not or may be executed many times it is just for this ? Just guessing but: As you apparently realize PreparedStatements have to be separate from Connections because there could be more than one PreparedStatement per Connection. So I suppose the Java people made Statements separate to keep them parallel with PreparedStatements. Otherwise you'd have a whole bunch of ""statement functions"" in Connection and then another whole bunch in PreparedStatement. That would mess up the inheritance tree of Statement and PreparedStatement. As I say just speculating. If anyone has an authoritative source on this I'd be amused to hear it.  I think you should start with the Sun tutorial on connection pooling. Besides this there are many implementations of connection pooling some open source including one from Apache. You should really start there rather than reinvent the wheel here. Em sorry I didn't meant to re-invent something. The tutorial suggest a connection wrapper JDCConnectionManager. But the drivers I use have already their pooled datasource implementation. ojdbc14.jar and jtds-1.2.2.jar. Why would I try apache's pool implementation if the driver already provides it ? What drivers are you using? Also did you look at Apache's implementation? If you need more than the basic JDBC that may solve your problem for you. Well right there you have two different databases you are connecting to which the Apache implementations (or potentially others) will give you the ability to have one pool that interacts with either. But I'm no longer clear on your question. At first you seemed to be writing your own pool implementation (like the Sun Tutorial). Now you seem to want to use an existing one. I don't know what Oracle has but jTDS just gives you a connection appropriate for a pool it doesn't give you the actual pool implementation.  If you've mastered JDBC with single-threading going to multi-threading and connection pools shouldn't be a big deal. All you need to do differently is: 1. When you need a connection get it from the pool instead of directly. 2. Each thread should get its own connections. To clarify point 2: If you get a connection and then pass it to multiple threads you could have two threads trying to execute queries against the same connection at the same time. Java will throw exceptions on this. You can only have one active Statement per Connection and one active query (i.e. ResultSet) per Statement. If two threads are both holding the same Connection object they are likely to promptly violate this rule. One other caveat: With Connection pooling be very very careful to always close your connections when you're done. The pool manager has no definitive way to know when you're done with a connection so if you fail to close one it's going to sit out there dangling for a long time possibly forever depending on the pool manager. I always always always follow every ""getConnection"" with a try block and close the connection in the finally block. Then I KNOW that I've closed it before the function exits. Besides that everything should be the same as what you're used to. +1 For the Caveat  Take a gander at this (+:  You can only keep one Statement open on any given Connection. Creating more than one Connection using a connection pool isn't that difficult although the way to go is to use one of the greater used ones out there. Also if you're going to go the way of standard JDBC I recommend using PreparedStatement over Statement. I've been using iBatis and out of the box is pretty nice. Brings a few other things to the table as well."
639,A,"Programatically setting the db url/user/password in Hibernate I need to centralize all settings for our Java web application in one .properties file. I can still have hibernate.cfg.xml for adding mappings to entity classes but I need to keep all of our settings for the database and custom paths in one .properties file. Originally I kept my configs in hibernate.cfg.xml as follows.... <?xml version='1.0' encoding='utf-8'?> <!DOCTYPE hibernate-configuration PUBLIC ""-//Hibernate/Hibernate Configuration DTD//EN"" ""http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd""> <hibernate-configuration> <session-factory> <property name=""connection.url"">my jdbc connection</property> <property name=""connection.driver_class"">oracle.jdbc.OracleDriver</property> <property name=""connection.username"">user</property> <property name=""connection.password"">password</property> <property name=""hibernate.dialect"">org.hibernate.dialect.Oracle10gDialect</property> <property name=""hibernate.current_session_context_class"">managed</property> <mapping class=""myEntityClass""/> </session-factory> </hibernate-configuration> Now I want to move""connection.url"" ""connection.username"" and ""connection.password"" to my own .properties file. The code for creating my hibernate configuration class went from. new AnnotationConfiguration().configure(); to new AnnotationConfiguration() .setProperty(""connection.url"" databaseUrl) .setProperty(""connection.username"" databaseUser) .setProperty(""connection.password"" databasePassword) .configure(); Which seemed conceptually simple. Unfortunately I get the following error when I try to use my Hibernate Session that worked with the previous config. The user must supply a JDBC connection Any ideas? It seems to me that when Hibernate sees these properties missing in the hibernate.cfg.xml file it assumes all settings will be manually added and ignore the xml altogether. From the Hibernate Reference Documentation: 3.3. JDBC connections [...] The following is an example hibernate.properties file for c3p0: hibernate.connection.driver_class = org.postgresql.Driver hibernate.connection.url = jdbc:postgresql://localhost/mydatabase hibernate.connection.username = myuser hibernate.connection.password = secret hibernate.c3p0.min_size=5 hibernate.c3p0.max_size=20 hibernate.c3p0.timeout=1800 hibernate.c3p0.max_statements=50 hibernate.dialect = org.hibernate.dialect.PostgreSQLDialect Adapt it to suit your needs and put the hibernate.properties in the root of the class path (and remove the equivalent entries from the hibernate.cfg.xml as the XML configuration file overrides properties). So there is actually no need to change the following line: new AnnotationConfiguration().configure(); Unless you really want a programmatic configuration of course. But from the body of your question moving to a .properties file is something else and you can rely on Hibernate: move the relevant properties from hibernate.cfg.xml to hibernate.properties. @Benju I think the properties specified in XML work with or without the `hibernate.` prefix. See [org.hibernate.cfg.Configuration.addProperties(Element)](http://viewvc.jboss.org/cgi-bin/viewvc.cgi/hibernate/core/tags/hibernate-3.5.3-Final/core/src/main/java/org/hibernate/cfg/Configuration.java?revision=19754&view=markup) method. Why does ""connection.url"" work in the hibernate.cfg.xml file? Does it assume you meant hibernate.connection.url? This is intriguing. @Benju: Well as you can see in `org.hibernate.cfg.Environment` properties are prefixed by `hibernate.`. Maybe Hibernate developers are doing some magic with the XML configuration I didn't check the sources. Anyway the documentation is pretty clear. Thanks this worked perfectly.  Try setting following properties properties.put(""hibernate.connection.driver_class"" ""net.sourceforge.jtds.jdbc.Driver""); properties.put(""hibernate.connection.url"" ""jdbc:jtds:sqlserver://test/dbname;SSL=REQUEST""); properties.put(""hibernate.cconnection.username"" ""user""); properties.put(""hibernate.connection.password"" ""password""); properties.put(""hibernate.dialect"" ""org.hibernate.dialect.SQLServerDialect""); of course this is for SQL Server so you would need to change driver to 'org.gjt.mm.mysql.Driver""' and change dialect as well 'org.hibernate.dialect.MySQLInnoDBDialect'"
640,A,"grouping data in java hi is there someway we can group similar data in java? i want to group all the data with same id and print it out. i am querying for the data using jdbc and was searching for a library i could use for this. any idea? thanks I'm confused. Do you want to do a SQL group in the query or do you have objects from a query that you want to group in memory? Ideally you should use a where clause in your SQL query to limit the returned data to the id in question: select * from table where id = 'xxxxxx' Of course if you will be printing out the data for all id's this may be a bad choice as then your app will perform multiple sql queries which usually will result in a performance hit. As for grouping data in Java take a look at java.util.HashMap (or any of the container classes that implement the Map interface). HashMap is a container of key-value pairs. In your case the 'key' can be a String (or whichever data type applies) representing your id and the 'value' can be an object to contain the data associated to the id key (i.e.: ArrayList of Strings or a new class you define to help you manage the data)  Are you looking for the SQL ORDER BY clause? SELECT columns WHERE criteria ORDER BY id ASC; That will give you all the data in your criteria and will order it by the id column which naturally means that all the rows with the same id will appear consecutively.  Use a Map<GroupID List<Data>>. Map<Long List<Data>> groups = new HashMap<Long List<Data>>(); while (resultSet.next()) { Long groupId = resultSet.getLong(""groupId""); String col1 = resultSet.getString(""col1""); String col2 = resultSet.getString(""col2""); // ... List<Data> group = groups.get(groupId); if (group == null) { group = new ArrayList<Data>(); groups.put(groupId group); } group.add(new Data(groupId col1 col2 /* ... */)); } You could also just make it a property of another (parent) bean. See also: Collections and Maps tutorial this is like too time consuming as I have a lot of data and arraylist is not a good option :( @jillika then surely you can use a different `List` implementation? @jillika: isn't hauling the data from DB itself more time consuming? If you are already complaining like that it look like you're trying to haul at least a million of records in or so. Did you consider letting DB do the work of returning the data in the right format so that you don't need to remassage it in Java afterwards? Or if aplpicable have you considered pagination?"
641,A,"How do I unit test jdbc code in java? I'd like to write some unit tests for some code that connects to a database runs one or more queries and then processes the results. (Without actually using a database) Another developer here wrote our own DataSource Connection Statement PreparedStatement and ResultSet implementation that will return the corresponding objects based on an xml configuration file. (we could use the bogus datasource and just run tests against the result sets it returns). Are we reinventing the wheel here? Does something like this exist already for unit testing? Are there other / better ways to test jdbc code? Use any of the Mock frameworks for such a task. (jMock etc.) Some examples  There is DBUnit. It won't allow you to test your jdbc code without a database but it seems like you could introduce a different set of buys by emulating a database.  While the way to mock jdbc in your application is of course dependant on how you've implemented your actual jdbc transactions. If you're using jdbc as is I'd assume you have written yourself an utility class of sorts to do some tasks in the line of DBUtils.getMetadataFor(String tablename). What this would mean is that you'd have to create a mock of that class and that could be all you need. This would be rather easy solution for you since you apparently already have a series of jdbc related mock objects available. Note that I'm assuming your jdbc code isn't exploded all around the application - if it is refactor!!! If you're however using any framework for database handling (like Spring Framework's JDBC Template classes) you can and should mock the interface class using EasyMock or some other equivalent. That way you can have all the power in the world required for easy mocking of the connection. And last if nothing else works you can do what others have said already and use DBUnit and/or derby.  Acolyte driver can be used to mock up a JDBC connection managing it during tests and returning data as result set (with its typesafe row list API): https://github.com/cchantep/acolyte  You could use DBUnit together with a HSQLDB which can read its initial data from CSV files for example.  We use Mockrunner. http://mockrunner.sourceforge.net/ It has mock connections and datasources built in so there is no need to implement them your selves.  I like to use a combination of: DBUnit HSQLDB Unitils (specifically the database testing and maintenance modules) You can get pretty far with just DBUnit and HSQLDB. Unitils provides the last mile of code to manage and reset database state. It also provides a nice way of managing database schema changes and makes it easy to use specific RBDMS (Oracle DB2 SQL Server etc). Finally Unitils provides some nice wrappers around DBUnit which modernizes the API and makes DBUnit much more pleasant to work with. If you haven't checked out Unitils yet you definitely should. Unitils is often overlooked and under-appreciated. This is the stack I tend to use as well. DBUnit/H2/Unitils  If you want to do unit tests not an integration tests than you can use a very basic and simple approach using Mockito only like this: public class JDBCLowLevelTest { private TestedClass tested; private Connection connection; private static Driver driver; @BeforeClass public static void setUpClass() throws Exception { // (Optional) Print DriverManager logs to system out DriverManager.setLogWriter(new PrintWriter((System.out))); // (Optional) Sometimes you need to get rid of a driver (e.g JDBC-ODBC Bridge) Driver configuredDriver = DriverManager.getDriver(""jdbc:odbc:url""); System.out.println(""De-registering the configured driver: "" + configuredDriver); DriverManager.deregisterDriver(configuredDriver); // Register the mocked driver driver = mock(Driver.class); System.out.println(""Registering the mock driver: "" + driver); DriverManager.registerDriver(driver); } @AfterClass public static void tearDown() throws Exception { // Let's cleanup the global state System.out.println(""De-registering the mock driver: "" + driver); DriverManager.deregisterDriver(driver); } @Before public void setUp() throws Exception { // given tested = new TestedClass(); connection = mock(Connection.class); given(driver.acceptsURL(anyString())).willReturn(true); given(driver.connect(anyString() Matchers.<Properties>any())) .willReturn(connection); given(connection.prepareCall(anyString())).willReturn(statement); } } Than you can test various scenarios like in any other Mockito test e.g. @Test public void shouldHandleDoubleException() throws Exception { // given SomeData someData = new SomeData(); given(connection.prepareCall(anyString())) .willThrow(new SQLException(""Prepare call"")); willThrow(new SQLException(""Close exception"")).given(connection).close(); // when SomeResponse response = testClass.someMethod(someData); // then assertThat(response is(SOME_ERROR)); }  You have several options: Mock the database with a Mock library e.g. JMock. The huge drawback of this that your queries and the data will most likely be not tested at all. Use a light weight database for the tests such as HSQLDB. If your queries are simple this is probably the easiest way to go. Dedicate a database for the tests. DBUnit is a good option or if you are using Maven you can also use the sql-maven-plugin to set up and tear down the database properly (be careful of dependencies between tests). I recommend this option as it will give you the biggest confidence that the queries work properly with your db vendor. Sometimes it is necessary and useful to make these tests configurable so that these tests are only executed if the database is available. This can be done with e.g. build properties. Thanks I like the idea of using maven to setup / tear down the database. We're using maven now for builds so this would be pretty easy for us to use.  I prefer using EasyMock for testing a not-so-easy-to-test code.  That's why you have derby (now called JavaDB) or sqlite -- they are small simple databases that you can create load test against and destroy relatively quickly and simply. But any code that depends on vendor-specific SQL that isn't supported by the lightweight db will not be testable. @Asaph: ""vendor-specific SQL"" is often a mistake. However when you go to test vendor-specific SQL you're not doing unit testing so that's not really a unit test issue is it? It's more of an integration test than a unit test at that point. But connecting to MySQL in a JUnit test is arguably not fundamentally different from connecting to sqlite from a JUnit test. I see both scenarios as integration tests. What would truly make it a _unit_ test would be having mocks or fakes at all the database seams ie. no database server (lightweight or heavyweight) at all. Having said that I'm not fanatic about adhering to this principle _all_ the time. As long as the tests run fast and don't require lots of manual setup it's okay with me. @Asaph: Mocking the database -- while technically possible -- is usually silly. You don't write it therefore you must *trust* it. If you don't trust it stop considering it and find something you do trust. Since you trust it use it for testing. You trust your test framework. (You don't test it do you?) You trust your compilers and libraries. It's okay to trust a JDBC service too.  I would say that HSQL is the way to go during your unit tests. The point of your test is to test your jdbc code and make sure it works. Adding custom classes or mocking the jdbc calls can easily hide bugs. I mostly use mysql and when the tests run the driver class and url is changed to org.hsqldb.jdbcDriver and jdbc:hsqldb:mem:test."
642,A,"How do I place large (or at least nontrivial) BLOBs into Oracle with JDBC? I'm working on an application to do some batch processing and want to store the input and output data as files in BLOB fields in an Oracle database. The Oracle version is 10g r2. Using the PreparedStatement.setBinaryStream() method as below will insert a small text file into the database but I'm not having any luck with a larger image file. Am I doing something wrong? Is this possible to do with JDBC? Will I need to bother the DBA? Thanks for your help. EDIT: The issue has been resolved. I've updated this code to a working sample: import java.io.File; import java.io.FileInputStream; import java.io.OutputStream; import java.sql.Blob; import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.Statement; public class WriteBlobDriver { public static void main(String[] args) { Connection con = null; try { Class.forName(""oracle.jdbc.driver.OracleDriver""); con = DriverManager.getConnection( ""blahblah"" ""blahblah"" ""blahblah""); con.setAutoCommit(false); Statement statement = con.createStatement(); //statement.executeUpdate(""UPDATE BATCH_GC_JOBS SET INPUT_BATCH_FILE = EMPTY_BLOB() WHERE JOB_ID = 'a'""); //Get blob and associated output stream ResultSet resultSet = statement.executeQuery(""SELECT INPUT_BATCH_FILE FROM BATCH_GC_JOBS WHERE JOB_ID = 'a' FOR UPDATE""); resultSet.next(); Blob blob = resultSet.getBlob(1); OutputStream outputStream = ((oracle.sql.BLOB)blob).getBinaryOutputStream(); // Buffer to hold chunks of data to being written to the Blob. byte[] buffer = new byte[10* 1024]; int nread = 0; //Write file to output stream File file = new File(""C:\\TEMP\\Javanese_cat.jpg""); FileInputStream fileInputStream = new FileInputStream(file); while ((nread = fileInputStream.read(buffer)) != -1) { outputStream.write(buffer 0 nread); } //Cleanup fileInputStream.close(); outputStream.close(); statement.close(); con.commit(); con.close(); System.out.println(""done!""); } catch (Exception e){ e.printStackTrace(); } } } I don't think you can update or insert into a BLOB/CLOB with JDBC in a single step (for data > 4k). From this example from Oracle it seems you need to: Insert an empty LOB with the SQL function empty_clob() Select for update the LOB you've inserted get the LOB in java with ResultSet.getBlob() then get the output stream with blob.setBinaryStream (since oracle.sql.BLOB.getBinaryOutputStream() is deprecated) write to this output stream close the output stream when you are finished You would do something similar in Pl/SQL (SELECT FOR UPDATE a LOB then write to it). Vincent thanks for your well-thought-out answer linking to official Oracle documentation. Unfortunately once I tried to follow their example I started getting ORA-01002 errors as soon as I issued the query FOR UPDATE. @Phil: the ORA-01002 doesn't seem BLOB-related. Did you disable autocommit first ? (you would need a transaction for this to work => disable autocommit) Thanks that worked! That link has gone dead. I think [this one](http://docs.oracle.com/cd/B28359_01/java.111/b31224/oralob.htm#CHDFHHHG) could be used instead. @Mat: thanks updated  Just remember getBinaryOutputStream has been deprecated. You should be using setBinaryStream if you are using oracle.sql.BLOB instead."
643,A,"ResultSet and Select * Performance I am refactoring some Spring JDBC code in which some of the costlier queries do ""SELECT * FROM..."" - and was about to start checking which columns were actually needed and just SELECT x  y FROM.. them. But reading through the ResultSet class is seemed that most data is lazily loaded. When you do a ResultSet.next() it moves the cursor in the database (Oracle 10g in this application) and when you do a ResultSet.getXX() it retrieves that column. So my thought was that if you do a ""SELECT * "" but only retrieve the columns you want you are not really taking a performance hit. Am I thinking about this correctly? The only place I can think of where this hurts you is inside the database because it is storing the query results in memory and has to use more memory then it would if only a few rows are selected but if it's actually only storing pointers to the columns that hit the query then even this wouldn't be the case. Thoughts? NOTE : this only applies to standard ResultSet I know CachedResultSet acts differently. I would be surprised if going from ""SELECT *"" to ""SELECT ABC"" gave you any meaningful performance improvement unless you had a huge number of columns that you didn't need. This is all very dependent on your database your driver and your application and most generalisations are going to be pretty meaningless. The only reliable answer you're going to get from this is by benchmarking it - try ""SELECT *"" try ""SELECT ABC"" and see if there's improvement worth chasing. Wow i always thought we sould not use select * You shouldn't as a rule. But the question wasn't about whether we should use it or not but what its performance is like.  I do know that in an application I was involved with at large data volumes (and large table sizes) changing from select * to select x y did buy us a small performance gain. However I would strongly recommend as did skaffman that you use a profiling tool such as Oracle's built in profiler or an external profiler and do large data sets to normalize out noise (like network traffic hard drive spin up sun spots etc) I've seen better behavior with `SELECT ABC` than `SELECT *` when a `BLOB` column wasn't included.  I'm with @skaffman and others on this - minor gains at best. If you think about how Oracle retrieves data and remember it's block I/O then regardless of the columns you ask for in your client the database is going to fetch the entire block the record is found in anyway. If your client always retrieves the entire record (e.g. doing the SELECT * in SQL*Plus) there could be a performance gain but in your situation where the data is only transmitted if you ask for it then probably not much. ""SELECT *"" can be evil for apps that are compiled. If the table changes your code could break. That's why I wouldn't use it. EDIT: Mulling over all the excellent responses here: Justin makes great points about certain situations where significant performance improvements can arise. Codemonkey makes the good point about self-documenting code. Aperkins and skaffman make one of the best suggestions of all: try it out measure and see for your own situation what the effects are. +1's all around... What I don't see is anyone falling over themselves recommending using ""SELECT *"" at all. If it's easy to specify the exact columns you need I'd fix the code to do so.  I have never noticed any performance gains between one and the other when switching statements around - I'm fairly certain Oracle grabs an entire row's contents first anyway regardless of wild card or column specification. There are much larger factors on performance to be checked into before this (indexes hard drive speed etc.). As a coding practice I'd avoid ""SELECT *"". Specifying the specific columns does make the intent of each query a bit more obvious. It makes for good self-documenting code. Writing out the column names also helps me to wrap my head around what exactly I plan to do with a query as I'm writing it.  Depending on the table structure the Oracle version and the indexes involved it is entirely possible that changing the set of columns you are selecting would substantially improve performance by changing query plans for the better. For most queries the performance benefits may well be minimal but overall it is generally good practice to name columns explicitly. The simplest case where performance will be improved will occur when you have a ""covered index"" that the optimizer could use. If all the columns you are selecting and all the columns you are filtering by are part of a single index that index is a covered index for the query. In that case Oracle can avoid ever reading the data from the table and can just read the index. There are other cases where performance will be improved as well. The optimizer may be able to perform table elimination if you have queries there are interim joins that don't affect the eventual output. If you are selecting all the columns that optimization isn't possible. If you have tables with chained rows eliminating columns can also eliminate the need to fetch the additional blocks where the eliminated columns reside. If there are LONG and LOB columns in the table not selecting those columns would also result in large improvements. Finally eliminating columns will generally reduce the amount of space Oracle will require to sort and hash results before shipping them over the wire. And even though the ResultSet may lazily load data in the application server's RAM it is probably not able to lazily fetch columns over the network. If you select all the columns from the table the JDBC driver likely has to fetch at least 1 complete row at a time (more likely it is fetching 10 or 100 rows per network round-trip). And since the driver doesn't know when the data is fetched what columns are going to be requested you'll have to ship all the data over the network. I don't think that the columns you SELECT by have anything to do with the query tuning/plan - that is only effected by what comes after the WHERE statement. @Gandalf - no Justin is correct when all of the columns referenced in the SELECT are available from the index structure (in certain cases). Oracle doesn't have to read the table to obtain the column values Thanks for the clarification I can see how Oracle could get all it needed from just the index. Unfortunately that's not the case for these queries but something I can definitely try to take advantage of in the future.  In the environments that I've worked in as a rule SELECT * is simply never used. I believe skaffman & aperkins are probably correct about performance gain being small. This is one of those things where as a database developer I have a strong opinion that you should always name the columns you're retrieving but I guess there may be no real basis for this. Hmmm... I guess from a maintainability perspective one could argue that naming the columns you're retrieving serves to self-document your code a bit. SELECT * doesn't give another developer as much information to work with down the line. Whether or not that & the small performance benefit justifies the extra typing I'm not sure. +1 for the second paragraph."
644,A,"Launch Oracle stored-procedure in Java code I wrote a stored-procedure in Oracle and now I want to launch it in Java code. I will describe a problem. I have a object type: TYPE PERSON_TYPE AS OBJECT (ID NUMBER(38) NAME VARCHAR2(20)); And table type: TYPE PERSON_TYPE_TABLE AS TABLE OF PERSON_TYPE; My procedure looks like this: PROCEDURE EVALUATE_PERSON_PROC(P_PERSON_ID IN NUMBER return_data OUT NOCOPY PERSON_TYPE_TABLE) AS --Some code BEGIN --Some code END; How to launch this procedure in Java code? Which classes are the best to do it? Why not use Spring's DAO abstraction (a very useful and reasonably lightweight library around raw JDBC which eliminates the need for boilerplate code) you can subclass the StoredProcedure class. class MySproc extends StoredProcedure { public MySproc(DataSource ds) { super("" { exec MY_SPROC ? ? }"" ds); declare(new SqlParameter(""p1"" Types.VARCHAR)); declare(new SqlParameter(""p2"" Types.INT)); } public void execute(String p1 int p2) { Map m = new HashMap(); m.put(""p1"" p1); m.put(""p2"" p2); super.execute(m); } } Then this is executed very simply as follows: new MySproc(ds).execute(""Hello"" 12); With no database Connections CallableStatements anywhere to be seen. Lovely! Oh yes and it also provides annotation-based Transactions. If your sproc returns a table this is incredibly easy using Spring. Simply declare:  declare(new SqlReturnResultSet(""rs"" mapper)); Where mapper is an instance that converts a line of a ResultSet into the desired object. Then modify your line:  Map out = super.execute(m); return (Collection) out.get(""rs""); The returned Collection will contain instances of objects created by your mapper implementation. top stuff...... probably for statement like this introducing spring libraries into project is nonsense. There is also scenario where this author could decide to deploy code directly to Oracle DBMS where spring would make a lot of pain.  You need to use the CallableStatement class: String sql = ""{call EVALUATE_PERSON_PROC(? ?)}""; CallableStatement statement = connection.prepareCall(sql); ... statement.execute(); +1. I also suspect the author will need some documentation on returning table types: http://stackoverflow.com/questions/1031420/returning-a-table-type-from-a-plsql-function-called-via-jdbc Yes I know it. But what doing with my type which I created in PL/SQL? How to configure CallableStatement that return collection of my type?"
645,A,Can I build a resultset from a file in Java? I don't have much experience working with resultsets but as ResultSet is an interface I guess I could implement it to work with a file as a backend. Is this nonsense? Is there any solution already given for my problem? Have you looked for existing text-to-resultset adapters? Interesting question.. why are you trying to do this? @Marcus: Sometimes the datasource is a large generated file and sometimes it's a table and the code needs to be flexible enough to handle both. Usually this scenario happens in testing (rarely in the final product). You may want that sort of detail hidden from the code that actually processes the data so all it cares about is a ResultSet... or at least that's how I've seen it happen before. He may have different reasons ;) It's actually a performance test. I have to do some queries that are really slow when done on a db but fast when done by a script on a text file. It sounds crazy but I want to be sure before discarding the text file option. HSQL also provides support for interpreting csv files as ResultSets.  It seems like there already is a Csv2JDBC project that may contain at least an example implementation of ResultSet.
646,A,"JDBC Connection Issue I have create a getDBConnection method in my Java application. This returns a connection object and hence I haven't closed this connection in this method itself. Now I am invoking this method from various methods in my application at regular intervals and closing them inside a try - finally block. I thought this should free up the connection after use. However I am seeing a large number of connections opened (about 50) in the MySQL Administrator's Server Connections tab. //Defining a method to retrieve a database connection // PropDemo is a properties class that retrieves Database related values from a file public Connection getDBConnection() { //Instantiating the Properties object PropDemo prop = new PropDemo(); Connection con = null; // Retrieving values from the parameters.properties file String JdbcDriver = prop.getMessage(""JdbcDriver""); String JdbcUrlPrefix = prop.getMessage(""JdbcUrlPrefix""); String DBIP = prop.getMessage(""DBIP""); String DBName = prop.getMessage(""DBName""); String DBUser = prop.getMessage(""DBUser""); String DBPassword = prop.getMessage(""DBPassword""); try { // Loading and instantiating the JDBC MySQL connector driver class Class.forName(JdbcDriver).newInstance(); con = DriverManager.getConnection(JdbcUrlPrefix + DBIP + ""/"" + DBName DBUser DBPassword); if (con.isClosed()) Logger.log(""Connection cannot be established"" ""vm""); } catch (Exception e) { Logger.log(""Exception: "" + e ""vm""); Logger.log(Logger.stack2string(e) ""vm""); } return con; } I am also closing the associated ResultSet and Statement Objects. What could be missing here? I am planning to replace all the Statements with PreparedStatements for efficiency and security reasons. Will that help significantly? What else can be done? EDIT: This is just a core java application that is repeatedly quering for changes in some fields in a MySQL database through MySQL-JDBC connector. I am not using any framework like Spring or Hibernate. could you post your code? More info is needed. What is your environment is it an standalone application a framework a JavaEE container? Do you use a connection pool? Are you closing the connection object when you application closes as well? Yes. I have taken care of that.  Are you using your JDBC connection within a J2EE application server or with Hibernate? Both of these tend to start out with a fairly high connection pool to begin with so you would see a large number. Check out the details on connection pooling.  You could take a Singleton approach to the problem and only create a new Connection object if the current one is null: If (connectionObject != null){ return connectionObject; }else { //create new connection object } This will make sure that you only have one non-null connection at any time.  Your code looks sane. That's how you're creating a new connection. Probably the error is where you close it. You should close it in a finally block. Some additional questions. 1) Are you sure those 50 conections come from this program ? Maybe there are some others comming from your same office. To confirm this you would need to stop the program and look again in your connection monitor. 2) Does your application uses many connection simultaneously? Probably its a peak when you're using 50 at the same time. If you can post the code where you close the connection. Chances are the problem is there. Additionally I would suggest you to use a connection pool. You can build one your self or you can see the results from this page: http://stackoverflow.com/questions/471745/how-many-jdbc-connections-in-java  One thing to start out with is to check to see if the Connection object has a session object within it (I check this through stepping through a debugger). If there is a session object in the Connection then check to see if it changes during a close(). The database that I use sets the session object to be null. Another thing: what Driver class are you creating the connection object with. If you are using the PooledConnection class the connection would not be closed automatically. I am using the JDBC-MYSQL connector jar file."
647,A,"SQL Server Windows Authentication using a Service I am running a Java Application as a Service in Windows that's using JDBC to connect to SQL Server. This application is started as a different user than the one logged into the Machine. My question is will the JDBC Driver use the user assigned to start the service to authenticate against or the logged in user (which there might not be one)? Thanks Why didn't you try it and find out? I am researching using Windows Authentication for our next release and I have nothing setup yet to try it. Otherwise I would have. Thanks for you answer. You can change logged in users all you want the service will keep running in the background under the account that it was initially started. If the connection is set to using Integrated Security then the account that the service is started under will be the one that is used.  Your service application is configured to always run as a particular user for example ""Service_User"". Even if user ""Bob"" logs in to start the service - all connections/files made by that service will appear to be from user ""Service_User"". In your service application you make a JDBC connection to a database. If you specify Integrated Security in the connection string it will log in to the database as ""Service_User"". If you specify a Database username / password in your connection string it will log into the database as that user. That will happen regardless of the interactive login used to start it on the system. I reworded it to try and make it clearer .. :-) My service is started by a different user than the one that logs in. I was wondering about that situation  The service will connect using whatever user the service is running under (as visible in the service control manager)."
648,A,"Get query from java.sql.PreparedStatement In my code I am using java.sql.PreparedStatement. I then execute the setString() method to populate the wildcards of the prepared statement. Is there a way for me to retrieve (and print out) the final query before the executeQuery() method is called and the query is executed? I Just want this for debugging purposes. Thanks. You can add log4jdbc to your project. This adds logging of sql commands as they execute + a lot of other information. http://code.google.com/p/log4jdbc/wiki/FAQ Here is a great tutorial how to use log4j http://www.cubrid.org/store_java_logs_to_databdase_using_log4j.  I would assume it's possible to place a proxy between the DB and your app then observe the communication. I'm not familiar with what software you would use to do this.  This is nowhere definied in the JDBC API contract but if you're lucky the JDBC driver in question may return the complete SQL by just calling PreparedStatement#toString(). I.e. System.out.println(preparedStatement); To my experience the ones which do so are at least the PostgreSQL 8.x and MySQL 5.x JDBC drivers. For the case your JDBC driver doesn't support it your best bet is using a statement wrapper which logs all setXxx() methods and finally populates a SQL string on toString() based on the logged information. For example Log4jdbc or the old and well known P6Spy. This does not work for example on the Cassandra CQL driver. I wonder who is the genius who left this functionality out of jdbc? @Jus12: use Log4jdbc then. In the meanwhile post an enhancement request to Cassandra development team and hope that they'll implement it as well. Doesn't seem to work with SQLite. Any workarounds? @Jason: use Log4jdbc then. In the meanwhile post an enhancement request to SQLite development team and hope that they'll implement it as well. What I love about these two comments as they are `/s/Cassandra/SQLite`. :-) I usually use this for MySQL but it does not work for Oracle :S @melanke: use Log4jdbc then. In the meanwhile post an enhancement request to Oracle development team and hope that they'll implement it as well. Why on earth isn't a method that does this part of the JDBC api forcing vendors to implement it... If you're looking for a solution for Oracle: http://stackoverflow.com/a/24734294/965176  For those of you looking for a solution for Oracle I made a method from the code of Log4Jdbc. You will need to provide the query and the parameters passed to the preparedStatement since retrieving them from it is a bit of a pain: private String generateActualSql(String sqlQuery Object... parameters) { String[] parts = sqlQuery.split(""\\?""); StringBuilder sb = new StringBuilder(); // This might be wrong if some '?' are used as litteral '?' for (int i = 0; i < parts.length; i++) { String part = parts[i]; sb.append(part); if (i < parameters.length) { sb.append(formatParameter(parameters[i])); } } return sb.toString(); } private String formatParameter(Object parameter) { if (parameter == null) { return ""NULL""; } else { if (parameter instanceof String) { return ""'"" + ((String) parameter).replace(""'"" ""''"") + ""'""; } else if (parameter instanceof Timestamp) { return ""to_timestamp('"" + new SimpleDateFormat(""MM/dd/yyyy HH:mm:ss.SSS""). format(parameter) + ""' 'mm/dd/yyyy hh24:mi:ss.ff3')""; } else if (parameter instanceof Date) { return ""to_date('"" + new SimpleDateFormat(""MM/dd/yyyy HH:mm:ss""). format(parameter) + ""' 'mm/dd/yyyy hh24:mi:ss')""; } else if (parameter instanceof Boolean) { return ((Boolean) parameter).booleanValue() ? ""1"" : ""0""; } else { return parameter.toString(); } } }  A bit of a hack but it works fine for me: Integer id = 2; String query = ""SELECT * FROM table WHERE id = ?""; PreparedStatement statement = m_connection.prepareStatement( query ); statement.setObject( 1 value ); String statementText = statement.toString(); query = statementText.substring( statementText.indexOf( "": "" ) + 2 );  You could try calling toString() on the prepared statement after you've set the bind values. PreparedStatement query = connection.prepareStatement(aSQLStatement); System.out.println(""Before : "" + query.toString()); query.setString(1 ""Hello""); query.setString(2 ""World""); System.out.println(""After : "" + query.toString()); This works when you use the JDBC MySQL driver but I'm not sure if it will in other cases. You may have to keep track of all the bindings you make and then print those out. Sample output from above code. Before : com.mysql.jdbc.JDBC4PreparedStatement@fa9cf: SELECT * FROM test WHERE blah1=** NOT SPECIFIED ** and blah2=** NOT SPECIFIED ** After : com.mysql.jdbc.JDBC4PreparedStatement@fa9cf: SELECT * FROM test WHERE blah1='Hello' and blah2='World' Doesn't work with Oracle sadly :( Don't work with Sqlite as well!"
649,A,"Is DBCP (Apache Commons Database Connection Pooling) still relevant? The JDBC 3.0 spec talks about Connection (and Prepared Statement) pooling. We have several standalone Java programs (i.e. we are not using an application server) that have been using DBCP to provide connection pooling. Should we continue to use DBCP or can we take advantage of the JDBC-provided pooling and get rid of DBCP? We are using MySQL (Connector/J) and will eventually be adding SQL Server support (jTDS); it's unlikely that we'll support any other databases. EDIT: See comment below about my attempt to eliminate the connection pooling library. It appears that DBCP is still relevant (note that some commenters recommended C3P0 over DBCP). People still use DBCP I think it even comes as a default with Hibernate. Is DBCP not meeting your current needs? I'm not a big believer in replacing infrastructure unless there's already a performance or functionality gap that it can't fill even if there are newer or fancier alternatives around. DBCP works but if I can get the same features from the JDBC driver I'd just as soon simplify things. I also wouldn't mind removing some of the code we've added to ""fix"" DBCP exception handling. c3p0 comes with Hibernate.  I prefer using dbcp or c3p0 because they are vendor neutral. I found out at least with mysql or oracle that whenever I try to do something with the jdbc client that is not standard sql I have to introduce compile-time dependency on the vendor's classes. See for example a very annoying example here. I am not sure about mysql but oracle uses their specific non-standard classes for connection pooling. The thread - you provided - is not relevant I am afraid. I know. I referred to it to illustrate what I meant regarding compile dependencies.  Based on the encouragement of other posters I attempted to eliminate DBCP and use the MySQL JDBC driver directly (Connector/J 5.0.4). I was unable to do so. It appears that while the driver does provide a foundation for pooling it does not provide the most important thing: an actual pool (the source code came in handy for this). It is left up to the application server to provide this part. I took another look at the JDBC 3.0 documentation (I have a printed copy of something labeled ""Chapter 11 Connection Pooling"" not sure exactly where it came from) and I can see that the MySQL driver is following the JDBC doc. When I look at DBCP this decision starts to make sense. Good pool management provides many options. For example when do you purge unused connection? which connections do you purge? is there a hard or soft limit on the max number of connections in the pool? should you test a connection for ""liveness"" before giving it to a caller? etc. Summary: if you're doing a standalone Java application you need to use a connection pooling library. Connection pooling libraries are still relevant.  DBCP has serious flaws. I don't think it's appropriate for a production application especially when so many drivers support pooling in their DataSource natively. The straw that broke the camel's back in my case was when I found that the entire pool was locked the whole time a new connection attempt is made to the database. So if something happens to your database that results in slow connections or timeouts other threads are blocked when they try to return a connection to the pool—even though they are done using a database. Pools are meant to improve performance not degrade it. DBCP is naive complicated and outdated. How big an effort is it to switch from DBCP to JDBC pooling? It depends on the driver. With Oracle and PostgresQL it was a simple configuration change--the code was already working with a (DBCP) DataSource. I don't have experience with MySQL drivers. We've been using DBCP together with Spring for about 4 years with no issues - maybe we've been lucky! I would agree that DBCP is broken. We switched to C3PO and it worked like a dream Same question would apply to C3PO - is it still relevant?"
650,A,"Incorrect Use of JDBC Connection Pool I am running a Spring MVC application backed by a MySQL database which I am accessing using JDBC. I have been using the same code for a while and have never really taken a look as to whether or not I was using it correctly (using connection pools properlyetc). I am aware that there is the JDBCTemplate out there and I have considered using it but if the only advantage is that I would just have to not write the boilerplate code for then I am not quite convinced I should be using it. In fact I prefer the readability of my code over the JDBCTemplate code. Below is the code in my DAO for some reason I feel like I am not using ConnectionPooling correctly. public Agent get(Integer id){ ConnectionPool pool = new ConnectionPool(); Connection connection = pool.getConnection(); PreparedStatement ps = null; try{ String query = ""SELECT * FROM agent where id= ?""; ps = connection.prepareStatement(query); ps.setInt(1id); ResultSet rs = ps.executeQuery(); Agent agent = null; if(rs.next()){ agent = new Agent(); agent.setFirstName(rs.getString(1)); agent.setLastName(rs.getString(2)); agent.setStreet(rs.getString(3)); agent.setCity(rs.getString(4)); agent.setZip(rs.getString(5)); agent.setState(rs.getString(6)); agent.setUsername(rs.getString(7)); agent.setPassword(rs.getString(8)); agent.setId(rs.getInt(9)); agent.setEmail(rs.getString(10)); } return agent; } catch(SQLException e) { e.printStackTrace(); return null; } finally{ ConnectionUtility utility = new ConnectionUtility(); utility.closePreparedStatement(ps); pool.freeConnection(connection); } } The code above is what I am worried about the most being incorrect but I have a few utility classes that may also be contributing to bad practice/improper code. Below is my ConnectionUtility class. public class ConnectionUtility{ public static void closeStatement(Statement s){ try{ if(s != null){ s.close(); } } catch(SQLException e){ e.printStackTrace(); } } public void closePreparedStatement(Statement ps){ try{ if(ps != null){ ps.close(); } } catch(SQLException e){ e.printStackTrace(); } } public static void closeResultSet(ResultSet rs){ try{ if(rs != null){ rs.close(); } } catch(SQLException e){ } } } Here is my ConnectionPool class public class ConnectionPool { private static ConnectionPool pool = null; public ConnectionPool(){ } public static ConnectionPool getInstance(){ if(pool == null){ pool = new ConnectionPool(); } return pool; } @SuppressWarnings(""static-access"") public Connection getConnection(){ try{ return ConnectionFactory.getInstance().getConnection(); } catch(SQLException e){ e.printStackTrace(); return null; } } public void freeConnection(Connection c){ try{ c.close(); } catch(SQLException e){ e.printStackTrace(); } } } Again I feel like I am really using all of these classes incorrectly even though everything is working fine but nothing has been put to the test in production. I prefer staying with JDBC so please no advice on making the switch to another. Jeez settle down. The question was about how to improve his code. Your comment is not helpful. I am improving his code. Using Spring will be a huge improvement over this. It's more helpful than you know. Suggesting Spring is helpful. Telling him his code is horrible you would never work with him and that he should not have received his degree is not. It seems a bit harsh to downvote the question just because the question-asker doesn't have a firm grasp on some of the concepts he/she is asking about. The author is clear that he/she might be misunderstanding some concepts and is here to ask us to help clarify them. thank you for the help those that are willing to help again nowhere in my code does it say that I was the greatest programmer...there is a reason why I was asking for help. @duffymo I apologize if I am not an experienced programmer I made it clear in the first line of question that I am using Spring but feared I was not using it correctly. Everybody had to start somewhere... There are two problems with your code: 1) You are creating a new ConnectionPool object for each call to get(). Your ConnectionPool class is designed to be a singleton so enforce it by making the constructor private and change your client code to ConnectionPool pool = ConnectionPool.getInstance(). 2) Basically the same issue with ConnectionUtility. You have static methods but you're using them in a non-static way. Replace ConnectionUtility utility = new ConnectionUtility(); utility.closePreparedStatement(ps); with ConnectionUtility.closePreparedStatement(ps); and make the ConnectionUtility constructor private and the class final. Singletons and utility classes can be tricky to get right so I'd recommend you use static analysis tools like Findbugs to pick up these kinds of problems. It will warn you when you have a class that looks like it should be a singleton or utility class but is not being used in that way.  One of the core principles of Spring is dependency injection. Spring is based around a belief that injecting the components that a class uses into that class leads to easier-to-read easier-to-test and easier-to-maintain code over having classes/code (such as your get() method) responsible for finding their own dependencies. As an example of what this means in more concrete terms: your get() method depends on at least two other classes: 1) the ""connection pool"" and 2) the connection itself. The get() method has intimate knowledge of how it needs to obtain these instances. As an alternative to your style of coding here with the DI approach the class that owns your get() method would have the Connection (or Datasource) injected into it (via a setter or constructor injection). Now why does this simple change make code easier and better? Because the get() method no longer needs to be concerned with details which are not it's core responsibility. The core responsibility of the get() method is to know how to get an Agent given an Integer id. Why does this method also need to know 1) where to get connections from and 2) that you want to pool connections? What happens when you want to change this connection logic? You need to touch the code of each and every data access method in your application. This would be a far far harder change than it needs to be. This is the power of dependency injection: it allows you to change the details (such as where a JDBC connection comes from) without having to also change the code that happens to use these details. As for your actual connection pool code it seems like you are misunderstanding two concepts: 1) Your ConnectionPool claims to want to be a Singleton but you expose a public constructor allowing collaborators to completely default the purpose of having a single instance of ConnectionPool. 2) Your connection pool is not actually a pool of connections! The idea of a connection pool is to open up N connections to a database and then hand out each of these N connections to code that needs a connection on-demand. The core idea here is that you can recycle connections and avoid the expensive costs of opening a new connection for each request. In a connection pool when the code using a connection is done with it's connection the physical connection is not actually terminated - instead the connection handle is simply returned to the pool to be used again by another request/thread/method. Most importantly in applications that use a connection pool the code responsible for data access typically doesn't even know it's connections are being pooled - instead the DAO simply has a reference to a DataSource interface and the DAO has no idea what actually happens when it asks the DataSource for a connection or what happens when the connection is released. Thus you can abstract away the details of ""how do I connect"" from the code responsible for higher-order logic such as ""how do I get an Agent from this integer?"". This abstraction is what allows you to change one layer of your application without rewriting all of the other layers - you've decoupled the layers and each is only concerned with what it is actually responsible for. I would strongly strongly suggest you do some more reading on not just the idea of a connection pool but also Dependency Injection. Why in the world would you use Spring without the DI components? As for connection pools why spend time re-inventing the wheel by writing your own instead of using a number of already-existing and popular libraries like commons-dbcp or c3p0? Instead of re-inventing the wheel use an existing library (which is less likely to have bugs than your home-brewed solution) and focus on building your actual application."
651,A,"Inserting multiple rows using JdbcTemplate How can I execute the following SQL in a scalable way using JdbcTemplate running on mySQL. In this case scalable means: Only one SQL statement is executed on the server it works for any number of rows. Here's the statement: INSERT INTO myTable (foo bar) VALUES (""asdf"" ""asdf"") (""qwer"" ""qwer"") Assume that I have a list of POJO's with foo and bar fields. I realize that I could just iterate over the list and execute: jdbcTemplate.update(""INSERT INTO myTable(foo bar) VALUES (? ?)"" paramMap) but that doesn't doesn't accomplish the first criterion. I believe I could also execute: jdbcTemplate.batchUpdate(""INSERT INTO myTable(foo bar) VALUES (? ?)"" paramMapArray) but from what I can tell that will just compile the SQL once and execute it multiple times failing the first criterion again. The final possibility which seems to pass both criteria would be to simply build the SQL myself with a StringBuffer but I'd like to avoid that. @Pace: That seems to be a good explanation and nobody else is posting an answer. If you rewrite it as an answer I'll accept it. Can we do the same using just JDBC?? This has nothing to do with JdbcTemplate or even JDBC. You can't do this in SQL period (or standard SQL anyway) so you certainly can't do it in JdbcTemplate. @skaffman: I've updated my question to say that I'm using mySQL. Maybe it's an mySQL-only feature but it's described at http://dev.mysql.com/doc/refman/5.1/en/insert.html about a quarter of the way down: ""INSERT statements that use VALUES syntax can insert multiple rows. To do this include multiple lists of column values each enclosed within parentheses and separated by commas. Example: "" @Teja: Yes it would be possible to do in pure JDBC but that's not the question. I've updated the question with a third possibility which would be to build the SQL all by hand. If you're using InnoDB then a batchUpdate *should* only update the index table after the last insert. The only efficiency gain you'd get from using a single statement is that you'd have to send less data to the MySQL server. I doubt you'll be able to do the multiple inserts with a standard JdbcTemplate but you could always extend JdbcTemplate and roll your own batch insert method which built the insert string by hand. you can also try with jdbcInsert.executeBatch(sqlParamSourceArray)  // define parameters jdbcInsert = new SimpleJdbcInsert(jdbcTemplate); jdbcInsert.withTableName(""TABlE_NAME""); SqlParameterSource[] sqlParamSourceArray = new SqlParameterSource[apiConsumer .getApiRoleIds().size()]; for (int i = 0; i < myCollection.size(); i++) { sqlParamSourceArray[i] = new MapSqlParameterSource().addValue(""COL1""); ...................... } // execute insert int[] keys = jdbcInsert.executeBatch(sqlParamSourceArray);  Multirow inserts (using ""row value constructors"") are in fact part of the SQL-92 standard. See http://en.wikipedia.org/wiki/Insert_(SQL)#Multirow_inserts. Some databases do not support this syntax but many do. In my experience Derby/Cloudscape DB2 Postgresql and the newer Hypersonic 2.*+ releases do support this. Your concern about getting this to work as a PreparedStatement is understandable but I've seen similar cases where Spring JDBC does automatically handle a Collection of items for certain queries (like where in (?)) but I cannot vouch for this case. I did find some possibly helpful information at (can't add second link to this post) which might be of some help. I can tell you that its probably not possible for your second requirement (works for any number of arguments) to be met in the most strict sense: every database I've used does impose query length limitations that would come into play. that URL that SO did not allow my to post above was: http://fusesource.com/docs/router/2.2/transactions/DataAccess-JDBC.html  You can't do this in JDBC period. In MySQL it's just syntactic sugar but the effect of the statement will be the same as issuing several INSERT statements. So you can use batchUpdate and it will have the same effect. Incorrect. MySQL's ""extended insert"" (as presented in the Question) is faster than a batch insert (where you prepare in advance but insert one row at a time). It is NOT a syntactic sugar in MySQL.  You can use BatchPreparedStatementSetter like below. public void insertListOfPojos(final List<MyPojo> myPojoList) { String sql = ""INSERT INTO "" + ""MY_TABLE "" + ""(FIELD_1FIELD_2FIELD_3) "" + ""VALUES "" + ""(???)""; getJdbcTemplate().batchUpdate(sql new BatchPreparedStatementSetter() { @Override public void setValues(PreparedStatement ps int i) throws SQLException { MyPojo myPojo = myPojoList.get(i); ps.setString(1 myPojo.getField1()); ps.setString(2 myPojo.getField2()); ps.setString(3 myPojo.getField3()); } @Override public int getBatchSize() { return myPojoList.size(); } }); }"
652,A,"Updating ResultSets with SQL Array types in JDBC / PostgreSQL I'm trying to use a SQL Array type with PostgreSQL 8.4 and the JDBC4 driver. My column is defined as follows: nicknames CHARACTER VARYING(255)[] NOT NULL and I'm trying to update it thusly: row.updateArray(""nicknames"" connection.createArrayOf(""CHARACTER VARYING"" p.getNicknames().toArray())); (p.getNicknames() returns a List<String>) but I'm seeing: org.postgresql.util.PSQLException: Unable to find server array type for provided name CHARACTER VARYING. at org.postgresql.jdbc4.AbstractJdbc4Connection.createArrayOf(AbstractJdbc4Connection.java:67) at org.postgresql.jdbc4.Jdbc4Connection.createArrayOf(Jdbc4Connection.java:21) Unfortunately the Array types don't seem to be well documented - I've not found mention of exactly how to do this for PostgreSQL anywhere :( Any ideas? Change ""CHARACTER VARYING"" to ""varchar"". The command-line psql client accepts the type name ""CHARACTER VARYING"" but the JDBC driver does not. The source for org.postgresql.jdbc2.TypeInfoCache contains a list of accepted type names. Consider part of the ambiguously-worded contract for createArrayOf(): The typeName is a database-specific name which may be the name of a built-in type a user-defined type or a standard SQL type supported by this database. I always assumed driver implementors interpret the phrases ""database-specific name"" and ""supported by this database"" to mean ""accept whatever you want"". But maybe you could file this as a bug against the Postgres JDBC driver. Good luck. Ach you're right. I assumed ""database-specific"" meant ""whatever the DB uses"" which as you point out is wrong. Also worth noting that it *seems* to be case sensitive unlike just about everything else. Thanks!"
653,A,"Accessing output parameters before processing result set in SQL Server via jdbc I am calling an 2005 MS SQL Server stored procedure using the MS JDBC Driver and want to access the output parameters before processing the result set as follows:  proc = ""{call mySproc(???)}""; conn = ds.getConnection(); callableStmt = conn.prepareCall(proc); callableStmt.setString(1inputParam); callableStmt.registerOutParameter(2Types.INTEGER); callableStmt.registerOutParameter(3Types.INTEGER); callableStmt.execute(); rs = (ResultSet)callableStmt.getResultSet(); output[0] = callableStmt.getInt(2); //@rc output[1] = callableStmt.getInt(3); //@rs if(output[0] != 0){ //do some stuff } else { // process result set } Problem is that accessing the output parameters before processing the result set causes the result set to be closed. Is there a way I can achive this without altering the stored procedure? It's possible to do this via JDBC for other databases. However from researching I found the JDBC Spec states: For maximum portability a call's ResultSet objects and update counts should be processed prior to getting the values of output parameters. Is it the case that the MS JDBC Driver has been implemented to the letter of the law and other JDBC drivers have provided more flexible implementations? Hoping someone can clear up my understanding on this issue. The output parameters come on the wire after all result set. Any client regardless of the platform or technology has to first parse all results before they can even see the output parameters values. If there are clients that offer the value of output parameters before consuming the result sets it means they cache the result sets in memory. Very bad considering result sets can grow quote large."
654,A,"handling DATETIME values 0000-00-00 00:00:00 in JDBC I get an exception (see below) if I try to do resultset.getString(""add_date""); for a JDBC connection to a MySQL database containing a DATETIME value of 0000-00-00 00:00:00 (the quasi-null value for DATETIME) even though I'm just trying to get the value as string not as an object. I got around this by doing SELECT CAST(add_date AS CHAR) as add_date which works but seems silly... is there a better way to do this? My point is that I just want the raw DATETIME string so I can parse it myself as is. note: here's where the 0000 comes in: (from http://dev.mysql.com/doc/refman/5.0/en/datetime.html) Illegal DATETIME DATE or TIMESTAMP values are converted to the “zero” value of the appropriate type ('0000-00-00 00:00:00' or '0000-00-00'). The specific exception is this one: SQLException: Cannot convert value '0000-00-00 00:00:00' from column 5 to TIMESTAMP. SQLState: S1009 VendorError: 0 java.sql.SQLException: Cannot convert value '0000-00-00 00:00:00' from column 5 to TIMESTAMP. at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1055) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:926) at com.mysql.jdbc.ResultSetImpl.getTimestampFromString(ResultSetImpl.java:6343) at com.mysql.jdbc.ResultSetImpl.getStringInternal(ResultSetImpl.java:5670) at com.mysql.jdbc.ResultSetImpl.getString(ResultSetImpl.java:5491) at com.mysql.jdbc.ResultSetImpl.getString(ResultSetImpl.java:5531) this is already-answered question is one of the best sources you come up after a google search. So i want to place my advice for avoiding this trouble. 0000-00-00 00:00:00 is the value that mySql places when you choose None as default value for your DATETIME column . So  if you avoid choosing this value while creating or altering your table  there's no way you can have this value in that column afterwards.  I wrestled with this problem and implemented the 'convertToNull' solutions discussed above. It worked in my local MySql instance. But when I deployed my Play/Scala app to Heroku it no longer would work. Heroku also concatenates several args to the DB URL that they provide users and this solution because of Heroku's use concatenation of ""?"" before their own set of args will not work. However I found a different solution which seems to work equally well. SET sql_mode = 'NO_ZERO_DATE'; I put this in my table descriptions and it solved the problem of '0000-00-00 00:00:00' can not be represented as java.sql.Timestamp  I suggest you use null to represent a null value. What is the exception you get? BTW: There is no year called 0 or 0000. (Though some dates allow this year) And there is no 0 month of the year or 0 day of the month. (Which may be the cause of your problem) ever heard of legacy systems yes but there is still no year called 0 even retrospectively. The year before 1 AD/CE was 1 BC/BCE That's the whole reason MySQL uses 0000 as an invalid date because it doesn't conflict with existing dates. Also dates like 1999-00-00 is sometimes used (not by me!) to represent the year 1999 rather than a specific day.  My point is that I just want the raw DATETIME string so I can parse it myself as is. That makes me think that your ""workaround"" is not a workaround but in fact the only way to get the value from the database into your code: SELECT CAST(add_date AS CHAR) as add_date By the way some more notes from the MySQL documentation: MySQL Constraints on Invalid Data: Before MySQL 5.0.2 MySQL is forgiving of illegal or improper data values and coerces them to legal values for data entry. In MySQL 5.0.2 and up that remains the default behavior but you can change the server SQL mode to select more traditional treatment of bad values such that the server rejects them and aborts the statement in which they occur. [..] If you try to store NULL into a column that doesn't take NULL values an error occurs for single-row INSERT statements. For multiple-row INSERT statements or for INSERT INTO ... SELECT statements MySQL Server stores the implicit default value for the column data type. MySQL 5.x Date and Time Types: MySQL also allows you to store '0000-00-00' as a “dummy date” (if you are not using the NO_ZERO_DATE SQL mode). This is in some cases more convenient (and uses less data and index space) than using NULL values. [..] By default when MySQL encounters a value for a date or time type that is out of range or otherwise illegal for the type (as described at the beginning of this section) it converts the value to the “zero” value for that type. Awesome thanks.  DATE_FORMAT(column name '%Y-%m-%d %T') as dtime Use this to avoid the error. It return the date in string format and then you can get it as a string. resultset.getString(""dtime""); This actually does NOT work. Even though you call getString. Internally mysql still tries to convert it to date first. at com.mysql.jdbc.ResultSetImpl.getDateFromString(ResultSetImpl.java:2270) ~[mysql-connector-java-5.1.15.jar:na] at com.mysql.jdbc.ResultSetImpl.getStringInternal(ResultSetImpl.java:5743) ~[mysql-connector-java-5.1.15.jar:na] at com.mysql.jdbc.ResultSetImpl.getString(ResultSetImpl.java:5576) ~[mysql-connector-java-5.1.15.jar:na] That's kinda the same as my CAST(add_date AS CHAR) solution but +1 since this lets you format it explicitly the way you want.  Alternative answer you can use this JDBC URL directly in your datasource configuration: jdbc:mysql://yourserver:3306/yourdatabase?zeroDateTimeBehavior=convertToNull Edit: Source: MySQL Manual Datetimes with all-zero components (0000-00-00 ...) — These values can not be represented reliably in Java. Connector/J 3.0.x always converted them to NULL when being read from a ResultSet. Connector/J 3.1 throws an exception by default when these values are encountered as this is the most correct behavior according to the JDBC and SQL standards. This behavior can be modified using the zeroDateTimeBehavior configuration property. The allowable values are: exception (the default) which throws an SQLException with an SQLState of S1009. convertToNull which returns NULL instead of the date. round which rounds the date to the nearest closest value which is 0001-01-01. Update: Alexander reported a bug affecting mysql-connector-5.1.15 on that feature. See CHANGELOGS on the official website. interesting. where'd you find this info? just updated my answer! But @sarumont 's URL may fit better in this case (it lists all connector properties). Awesome! Thanks. Wow! Thanks for the info. I guess you had a hard time figuring that out :-( version 5.1.16 of the jdbc software contains this bugfix: - Fix for BUG#57808 - wasNull not set for DATE field with value 0000-00-00 in getDate() although zeroDateTimeBehavior is convertToNull. thank you very much this saved me :) The URL.. Life. Saved!  If after adding lines: <property name=""hibernate.connection.zeroDateTimeBehavior"">convertToNull</property> hibernate.connection.zeroDateTimeBehavior=convertToNull <connection-property name=""zeroDateTimeBehavior"">convertToNull</connection-property> continues to be an error: Illegal DATETIME DATE or TIMESTAMP values are converted to the “zero” value of the appropriate type ('0000-00-00 00:00:00' or '0000-00-00'). find lines: 1) resultSet.getTime(""time""); // time = 00:00:00 2) resultSet.getTimestamp(""timestamp""); // timestamp = 00000000000000 3) resultSet.getDate(""date""); // date = 0000-00-00 00:00:00 replace with the following lines respectively: 1) Time.valueOf(resultSet.getString(""time"")); 2) Timestamp.valueOf(resultSet.getString(""timestamp"")); 3) Date.valueOf(resultSet.getString(""date""));  I stumbled across this attempting to solve the same issue. The installation I am working with uses JBOSS and Hibernate so I had to do this a different way. For the basic case you should be able to add zeroDateTimeBehavior=convertToNull to your connection URI as per this configuration properties page. I found other suggestions across the land referring to putting that parameter in your hibernate config: In hibernate.cfg.xml: <property name=""hibernate.connection.zeroDateTimeBehavior"">convertToNull</property> In hibernate.properties: hibernate.connection.zeroDateTimeBehavior=convertToNull But I had to put it in my mysql-ds.xml file for JBOSS as: <connection-property name=""zeroDateTimeBehavior"">convertToNull</connection-property> Hope this helps someone. :)  I solved the problem considerating '00-00-....' isn't a valid date then I changed my SQL column definition adding ""NULL"" expresion to permit null values: SELECT ""-- Tabla item_pedido""; CREATE TABLE item_pedido ( id INTEGER AUTO_INCREMENT PRIMARY KEY id_pedido INTEGER id_item_carta INTEGER observacion VARCHAR(64) fecha_estimada TIMESTAMP fecha_entrega TIMESTAMP NULL // HERE IS!!.. NULL = DELIVERY DATE NOT SET YET CONSTRAINT fk_item_pedido_id_pedido FOREIGN KEY (id_pedido) REFERENCES pedido(id)... Then I've to be able to insert NULL values that means ""I didnt register that timestamp yet""... SELECT ""++ INSERT item_pedido""; INSERT INTO item_pedido VALUES (01 01 01 'Ninguna' ADDDATE(@HOY INTERVAL 5 MINUTE) NULL) (02 01 02 'Ninguna' ADDDATE(@HOY INTERVAL 3 MINUTE) NULL)... The table look that: mysql> select * from item_pedido; +----+-----------+---------------+-------------+---------------------+---------------------+ | id | id_pedido | id_item_carta | observacion | fecha_estimada | fecha_entrega | +----+-----------+---------------+-------------+---------------------+---------------------+ | 1 | 1 | 1 | Ninguna | 2013-05-19 15:09:48 | NULL | | 2 | 1 | 2 | Ninguna | 2013-05-19 15:07:48 | NULL | | 3 | 1 | 3 | Ninguna | 2013-05-19 15:24:48 | NULL | | 4 | 1 | 6 | Ninguna | 2013-05-19 15:06:48 | NULL | | 5 | 2 | 4 | Suave | 2013-05-19 15:07:48 | 2013-05-19 15:09:48 | | 6 | 2 | 5 | Seco | 2013-05-19 15:07:48 | 2013-05-19 15:12:48 | | 7 | 3 | 5 | Con Mayo | 2013-05-19 14:54:48 | NULL | | 8 | 3 | 6 | Bilz | 2013-05-19 14:57:48 | NULL | +----+-----------+---------------+-------------+---------------------+---------------------+ 8 rows in set (0.00 sec) Finally: JPA in action: @Stateless @LocalBean public class PedidosServices { @PersistenceContext(unitName=""vagonpubPU"") private EntityManager em; private Logger log = Logger.getLogger(PedidosServices.class.getName()); @SuppressWarnings(""unchecked"") public List<ItemPedido> obtenerPedidosRetrasados() { log.info(""Obteniendo listado de pedidos retrasados""); Query qry = em.createQuery(""SELECT ip FROM ItemPedido ip Pedido p WHERE"" + "" ip.fechaEntrega=NULL"" + "" AND ip.idPedido=p.id"" + "" AND ip.fechaEstimada < :arg3"" + "" AND (p.idTipoEstado=:arg0 OR p.idTipoEstado=:arg1 OR p.idTipoEstado=:arg2)""); qry.setParameter(""arg0"" Tipo.ESTADO_BOUCHER_ESPERA_PAGO); qry.setParameter(""arg1"" Tipo.ESTADO_BOUCHER_EN_SERVICIO); qry.setParameter(""arg2"" Tipo.ESTADO_BOUCHER_RECIBIDO); qry.setParameter(""arg3"" new Date()); return qry.getResultList(); } At last all its work. I hope that help you. I don't think this addresses the problem of converting a MySQL DATETIME of all zeros into a valid date. It just shows how to enter null into a DATETIME field which is not really going to help much."
655,A,Passing DataSource object from a servlet to a JavaBean I like the ease of using @Resource annotation to get a DataSource but as far as I know it's not possible to use it in a regular JavaBean. Would it be considered a bad practice if I pass the DataSource object from a servlet to a bean along with the other data to avoid having that lookup code in the bean? It is certainly a bad practice to pass the data source to bean calls. You better use one of the dependency inversion frameworks such as Spring or Guice. The former has utilities to inject required DataSources to configured beans among to many other useful things. Спасибо Евгений.
656,A,"Call PL/SQL Web Toolkit procedures from Java I need to call some PL/SQL procedures from my Java application. I can do it with JDBC. But the problem is that procedures are using the ""PL/SQL Web Toolkit"" and its packages (htp owa _ util owa _ cookie ...). When I call them I get some exceptions as this: Exception in thread ""main"" java.sql.SQLException: ORA-06502: PL/SQL: numeric or value error ORA-06512: at ""SYS.OWA_UTIL"" line 323 ORA-06512: at ""SYS.HTP"" line 859 ORA-06512: at ""SYS.HTP"" line 974 ... Is possible to call these procedures using a Java package or any other way? I can't modify these procedures but I can't create some. Thanks for your help. Are you calling the procedures via Statement's executeQuery() method? Well not at all. I use CallableStatement's execute() method. This class is an Statement's subinterface. here's the sample code how you can do it ---  CallableStatement stmt = conn.prepareCall(""? = call test(?)""); stmt.registerOutParameter(1 OracleTypes.INTEGER); stmt.setString(2 ""callIndex""); stmt.execute(); Integer outputValue = stmt.getInt(1); here test is a stored function which is been called via java ""callable statement"".Also if you need to pass variables to stored procedure or a function in oracle you have to OracleTypes to pass the correct variable up over there.  That error message means that you are passing an argument of the wrong datatype or assigning the result to a variable of the wrong datatype. You need to re-check your code and in particular its assignments. Alterntively you can post your code here: I'm sure one of the SO Brains will be able to spot the problem. Incidentally which method in OWA_UTIL are you calling? Thanks for your answer. I'm sure the procedure arguments are correct. The problem seems to be that some system objects are not created/initialized. The call stack is: MyMethod --> SYS.PRINT('Hello world!') --> SYS.PRN('Hello World') --> OWA_UTIL.GET_CGI_ENV('GATEWAY_IVERSION')  htf and htp assume that some things are going to be set up in advance. This is done automatically when the call goes through a PL/SQL gateway like mod_plsql. But it can also be done manually. There's a good explanation on the Ask Toad wiki To successfully use htp & htf you'll need to define a couple variables and then initialize the cgi environment. It seems the perfect solution! I'll work on this now. Thank you very much!"
657,A,"does android support JDBC I know that on android there is android.database.sqlite package that provides helpfull classes to manage the internal android database. The question is - can i use the standard java.sql package to manipulate android's database without using anything from android.database.sqlite.* I try to open connection using sqlite JDBC driver but when i added the library as e reference to the project eclipse crashes with ""java heap out of memory ... couldn't convert to dalvik VM"". You cannot import a JAR implementing java.* classes easily. And JDBC would need to be ported to Android since it probably relies upon classes in JavaSE that Android lacks. And you would need to write your own JDBC driver for SQLite anyway wrapping the API Android already supplies since I suspect the existing JDBC driver uses JNI. And when all of that is done you will have an application that adds a lot of bloat making it less likely people will download and retain your application. In short I wouldn't go this route.  the JDBC driver is undocumented and unsupported. please do not use this code. avoid java.sql and use android.database.sqlite instead.  There is an (undocumented?) JDBC driver for Android's SQLite database. Try this: (from http://groups.google.com/group/android-developers/browse%5Fthread/thread/cf3dea94d2f6243c)  try { String db = ""jdbc:sqlite:"" + getFilesDir() + ""/test.db""; Class.forName(""SQLite.JDBCDriver""); Connection conn = DriverManager.getConnection(db); Statement stat = conn.createStatement(); stat.executeUpdate(""create table primes (number int);""); stat.executeUpdate(""insert into primes values (2);""); stat.executeUpdate(""insert into primes values (3);""); stat.executeUpdate(""insert into primes values (5);""); stat.executeUpdate(""insert into primes values (7);""); ResultSet rs = stat.executeQuery(""select * from primes""); boolean b = rs.first(); while (b) { Log.d(""JDBC"" ""Prime="" + rs.getInt(1)); b = rs.next(); } conn.close(); } catch (Exception e) { Log.e(""JDBC"" ""Error"" e); } http://code.google.com/p/sqldroid/"
658,A,"Using Spring JDBC for Oracle Stored Procedure I get a ORA-02055 when SP throws ORA-20118 ORA-20118 is a custom exception from the stored procedure. The stored procedure runs just fine from PL-SQL developer so the problem is in Spring. What I need to do is to get Spring to rollback the SP when it gets the ORA-20118 exception back from the SP. How do I do that? or maybe just get spring to correctly handle the 20118 code coming back. That would work too. There is no transaction management being done. Da code: @Repository public class ProgramMaintenance extends StoredProcedure { //bunch of static final param names go here @Autowired(required = true) public ProgramMaintenance(@Qualifier(""osirisDataSource"") final DataSource ds) { super(ds SQL); OracleStoredProcedureExceptionHandler exceptionHandler = new OracleStoredProcedureExceptionHandler(); exceptionHandler.setDataSource(ds); this.getJdbcTemplate().setExceptionTranslator(exceptionHandler); addParameters(); this.setFunction(false); compile(); } public void execute( //parameters ) { //Put the input map together here execute(inputMap); } So here is the exception handler along with notes of what's going on: public class OracleStoredProcedureExceptionHandler extends SQLErrorCodeSQLExceptionTranslator { protected DataAccessException customTranslate(String task String sql SQLException sqlex) { if (logger.isDebugEnabled()) { logger.debug(""customTranslate(String String SQLException) - start""); //$NON-NLS-1$ } //The error code at this point is ORA-02055 with the cause as ORA-20118 //So the case statement drops straight through. switch (sqlex.getErrorCode()) { case 20113 : return new ProgramNotAtCampusException(task + "" "" +sql sqlex); case 20118 : return new ProgramNotApprovedForStateOfResidence(task + "" "" +sql sqlex); default: return null; } } And the stack trace: org.springframework.jdbc.BadSqlGrammarException: CallableStatementCallback; bad SQL grammar [{call isis.program_maintenance.program_maintenance(? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)}]; nested exception is java.sql.SQLException: ORA-02055: distributed update operation failed; rollback required ORA-20118: VALIDATION ERROR:This program is not approved for the state this student resides in. ORA-06512: at ""ISIS.APPLY_WEB_INTEGRATION"" line 372 ORA-06512: at ""ISIS.APPLY_WEB_INTEGRATION"" line 1332 ORA-06512: at ""ISIS.APPLY_WEB_INTEGRATION"" line 2842 ORA-06512: at ""ISIS.PROGRAM_MAINTENANCE"" line 66 ORA-06512: at line 1 at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:97) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:80) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:80) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:952) at org.springframework.jdbc.core.JdbcTemplate.call(JdbcTemplate.java:985) at org.springframework.jdbc.object.StoredProcedure.execute(StoredProcedure.java:117) at com.apollo.aw.dao.storedProcedures.programMaintenance.ProgramMaintenance.execute(ProgramMaintenance.java:125) at test.eval.dao.storedprocedures.programMaintenance.TestProgramMaintenance.testExecuteForORA20118(TestProgramMaintenance.java:64) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at junit.framework.TestCase.runTest(TestCase.java:168) at junit.framework.TestCase.runBare(TestCase.java:134) at org.springframework.test.ConditionalTestCase.runBare(ConditionalTestCase.java:76) at junit.framework.TestResult$1.protect(TestResult.java:110) at junit.framework.TestResult.runProtected(TestResult.java:128) at junit.framework.TestResult.run(TestResult.java:113) at junit.framework.TestCase.run(TestCase.java:124) at junit.framework.TestSuite.runTest(TestSuite.java:232) at junit.framework.TestSuite.run(TestSuite.java:227) at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:45) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196) I'm looking for that answer now but would that explain why the SP works via PL-SQL Developer but not via JDBC? Exact same data. Don't worry be happy. If Oracle raises an exception any uncommitted changes made by that call will be automatically rolled back. It doesn't matter if that call is an insertupdatedeletemerge or stored proedure call the statement has failed and the atomic nature of the call requires that the database state is restored to the point before the calls started. > create table test (id number); Table created. > create or replace procedure ins_test is 08:42:46 2 begin 08:42:48 3 insert into test values (10); 08:42:55 4 raise too_many_rows; 08:43:00 5 end; 08:43:01 6 / Procedure created. > exec ins_test; BEGIN ins_test; END; * ERROR at line 1: ORA-01422: exact fetch returns more than requested number of rows ORA-06512: at ""GARY.INS_TEST"" line 4 ORA-06512: at line 1 > select * from test; no rows selected  On the surface it looks like everything is functioning exactly the way it should. Can you post the spring-config.xml entries for the transaction Manager for this datasource? By default RuntimeException instances cause a rollback in Spring. There are several programmatic ways to rollback (but the transaction manager can have the most common attributes set to avoid this kind of code: TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); You should read the Spring docs on Transaction Management for thorough overview. Are there savepoints in the SP? Are there any db links being used in the SP? There might be I'll look. Would they work differently in PL-SQL developer vs JDBC? No there aren't. And the DBA's confirmed it. There isn't any Transaction Management being explicitly called for this SP. Also the problem is that it's apparently not rolling back the transaction even though Oracle thinks it needs to.  What I need to do is to get Spring to rollback the SP when it gets the ORA-20118 exception back from the SP. For declarative transactions you can refer to this section about rollback rules. But in short just throw an exception that will not get caught in a try/catch block. This is happening before the custom SQLErrorCodeSQLExceptionTranslator is being called. So I can't just throw another exception. Spring is intercepting the custom exception (2011* being returned by the SP and then doing something to get the (2055) which indicates that a rollback needs to happen. There is no transaction management being declared.  And the right answer is.... the test itself was in error and Spring was doing the right thing.. SIGH This:  @Test(expected=ProgramNotAtCampusException.class) was not working correctly however wrapping it in a try catch block and ignoring the error works just fine.. SIGH."
659,A,"hibernate mapping for postgresql ""timestamp without time zone""? I'm trying to map java.util.Date to postgresql timestamp without time zone type. I'm using a custom sql-insert statement (because the table is partitioned and postgresql won't return number of rows updated on a normal insert) and I keep getting an error saying the function does not exist. I suspect this is due to a problem mapping these Date fields. From the hibernate mapping: <?xml version=""1.0""?> <!DOCTYPE hibernate-mapping PUBLIC ""-//Hibernate/Hibernate Mapping DTD 3.0//EN"" ""http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd""> <hibernate-mapping default-lazy=""false""> <class ...snip... <property name=""dateCreated"" type=""timestamp""> <column name=""DATE_CREATED""/> </property> <property name=""dateUpdated"" type=""timestamp""> <column name=""DATE_UPDATED""/> </property> ...snip... <sql-insert callable=""true"">{call insert_wal (? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)}</sql-insert> </class> </hibernate-mapping> From the application log: Hibernate: {call insert_wal (? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?)} 12/06/09 17:22:15.409 WARN hibernate.util.JDBCExceptionReporter - SQL Error: 0 SQLState: null 12/06/09 17:22:15.425 ERROR hibernate.util.JDBCExceptionReporter - Batch entry 0 select * from insert_wal (foo 439 ...snip... 2009-06-12 17:22:15.315000 -07:00:00 2009-06-12 17:22:15.378000 -07:00:00 ...snip...) as result was aborted. Call getNextException to see the cause. 12/06/09 17:22:15.425 WARN hibernate.util.JDBCExceptionReporter - SQL Error: 0 SQLState: 42883 12/06/09 17:22:15.425 ERROR hibernate.util.JDBCExceptionReporter - ERROR: function insert_wal(character varying integer ...snip... unknown unknown ...snip...) does not exist 12/06/09 17:22:15.425 ERROR event.def.AbstractFlushingEventListener - Could not synchronize database state with session (The Exception returned from getNextException referenced in the first ERROR line simply repeats the second ERROR line with a stack trace.) As you can see for some reason the function signature JDBC is looking for has ""unknown"" as the data types where the timestamps go. I've tried every combination of property type and column sql-type I can think of but it shows up as ""unknown"" every time. Here's the signature of the function definition in the DB: CREATE OR REPLACE FUNCTION insert_wal(p_action character varying p_partner_id numeric ...snip... p_date_created timestamp without time zone p_date_updated timestamp without time zone ...snip... The only other differences are that where there's a ""numeric"" in the function definition the ERROR line shows various types like ""integer"" ""double precision"" and ""bigint""; and one parameter in the function definition is type ""text"" where the error shows ""character varying"". I can produce a similar error by calling the function in pgAdminIII except that it's the string values (e.g. 'foo' with quotes) that are ""unknown"" while the date values (I just used now()) are treated as ""timestamp with time zone"". So: am I doing something wrong in my hibernate mapping? Is it a problem with the function? I don't know Hibernate enough to comment on that part but you could perhaps work around the error by overriding the datatypes in the INSERT statement: <sql-insert callable=""true"">{call insert_wal (?::text ?::numeric <snip>?::timestamp )::timestamp <snip>)}</sql-insert> You probably don't need to override all the fields of course just those causing problems. I ended up overriding all the fields (maybe I only needed to override the numeric fields but I got tired of trial-and-error) and it worked. Thanks!"
660,A,Transaction Control across multiple JVMs I have what seems to be a standard java problem: multiple database transactions in Oracle that need to all be committed or none. This is complicated by the fact that each process is in a seperate JVM. The modules are connected by JMS queues in a pipeline configuration. The idea is that a series of messages can be passed through the pipeline and when all the processing has finished a message can be sent from a coordinating module to cause all the transactions to commit. Is it possible with any sensible level of robustness to synchronise commits across the multiple JVMs? You might be interested in reading A brief history of Consensus 2PC and Transaction Commit.  When there are multiple participants in a transaction you need some two-phase commit protocol like XA. When using JMS you have an option to use JMS transactions. And here is a comparison of the two options.
661,A,"Getting a connection from a Sybase datasource in WAS 6.1 fails with message ""User name property missing in DriverManager.getConnection"" I have a standalone application that needs to connect to a Sybase database via a datasource I'm trying to connect using getConnection() and get the connection from this Sybase datasource which is hosted in WAS 6.1 sadly I'm getting an error JZ004 -> Sybase(R) jConnect for JDBC(TM) Programmer's Reference: SQL Exception and Warning Messages JZ004 error message is: User name property missing in DriverManager.getConnection(... Properties) Action: Provide the required user property. As you can see this is not a connectivity (so we can discard JNDI or lookup problems) but rather a configuration problem. For my Sybase datasource in WAS 6.1 I have set up the proper authentication alias (Component-managed Authentication Alias) and I know the credentials are alright ""Test Connection"" is successful for this datasource. Somebody had a similar problem and was because of the authentication alias-> http://forum.springsource.org/showthread.php?t=39915 Next I tried calling getConnection() but now I provided the credentials like getConnection(user password)... and this time it worked!!! So I suspect that somehow WAS 6.1 is not picking or taking the authentication info I set in the datasource as mentioned before. If you think that maybe getConnection(user password) should be OK for my case well that's not the case since I have a requirement to keep the credentials in the server the standalone application only needs to know the JNDI information to lookup the datasource. Please let me know if have faced a similar problem or what would you suggest me to do. Thanks. In order to use the configured resource you need to look it up rather than using DriverManager directly: new InitialContext().lookup(""myDS""); That's what I'm doing but i get the problem mentioned before. The DriverManager exception appears in the actual stack trace. I added a new question for this case: http://stackoverflow.com/questions/2677079/call-to-datasource-getconnection-not-returning-the-expected-connection  In another thread -> Call to DataSource.getConnection not returning the expected connection I got an answer that also solved this issue basically the answer is that an authentication alias won't work for external clients according to the J2C documentation. The workaround is to provide the user and password as custom properties instead of being provided as an authentication alias."
662,A,"Why am I getting SQLSyntaxErrorException - encountered """"? This method keeps throwing the exception in the title and I cannot find a reason I have created other tables through the connection and all the referenced tables have been created. I'm using embedded JavaDB. private void createEvidenceTable() throws SQLException { Statement evidenceTable = CONNECTION.createStatement(); evidenceTable.execute(""CREATE TABLE evidence(""+ ""evidence_id INTEGER NOT NULL PRIMARY KEY""+ ""date_added VARCHAR(6) NOT NULL""+ ""evidence_dated VARCHAR(6) NOT NULL""+ ""evidence_file varchar(20)""+ ""evidence_text VARCHAR(10)""+ ""source_location_id INTEGER""+ ""source_person_id INTEGER""+ ""evidence_type VARCHAR(20)""+ ""CONSTRAINT evidence__location_source FOREIGN KEY(source_location_id) REFERENCES location_source""+ ""CONSTRAINT evidence_person_source FOREIGN KEY(source_person_id) REFERENCES person_source""+ ""CONSTARINT evidence_evidence_type FOREIGN KEY(evidence_type) REFERENCES evidence_types)""); } What database are you trying to create the table in? JavaDB embedded sorry just did an edit. One definite problem is that the third constraint clause is misspelled (CONSTARINT iso CONSTRAINT) Thanks for the help that was it.  This worked in MySQL client: CREATE TABLE evidence ( evidence_id INTEGER NOT NULL date_added VARCHAR(6) NOT NULL evidence_dated VARCHAR(6) NOT NULL evidence_file varchar(20) evidence_text VARCHAR(10) source_location_id INTEGER source_person_id INTEGER evidence_type VARCHAR(20) PRIMARY KEY(evidence_id) FOREIGN KEY(source_location_id) REFERENCES location_source(source_location_id) FOREIGN KEY(source_person_id) REFERENCES person_source(source_person_id) FOREIGN KEY(evidence_type) REFERENCES evidence_types(evidence_type) ); Why would you use VARCHAR(6) instead of DATE? Makes little sense to me."
663,A,"IS ResultSet thread safe Is ResultSet Thread safe? My question arises because in my program i have used different statement for each query i have declared a ResultSet as an local variable but it gives me a error of Operation not allowed after ResultSet is closed. But my statements are working as i'm using the statements in insert and delete query.I have commented the ResultSet part and have not got the error !! The real problem is that you are sharing Statement objects between multiple threads. Each time you ""execute"" a Statement the previously returned ResultSet is automatically closed. In this case the ResultSet objects ""belong"" to a different thread which may not yet have finished using it. Hence the exception ... You should not share Connection Statement / PreparedStatement or ResultSet objects between multiple threads. Each thread should acquire and release its own resources. but wouldnt making a connection for each thead led to many connection and closing it evrytime lead to overheads Not if you use a connection pool. Besides an inefficient solution is better than a ""solution"" that breaks due to concurrency bugs. how do u rate proxool for connection pooling? is there any better tool that can be used?? Read the answers to http://stackoverflow.com/questions/520585/connection-pooling-options-with-jdbc-dbcp-vs-c3p0  No ResultSet should not be exposed to more than one thread. A ResultSet should never have a scope larger than a single method: execute the query map the ResultSet into an object or collection and close the ResultSet in the same scope in which it was created. The correct way to close a ResultSet is in a finally block in its own try/catch. Looked at the code in your other question. It needs a serious complete refactoring. It's not surprising that you're having problems with it. Here are a few suggestions: Follow the Sun Java coding conventions. It might seem trivial but anything that makes your code harder to read is a bad idea. Your ""doComms"" and ""savetodatabase"" classes break the ""class names start with a capital letter"" convention. Naming matters. ""doComms"" is not my idea of a good abstraction. Magic numbers/constants are everywhere. They'll make your code harder to change later. Java's an object-oriented language; you're writing in another style altogether. When I see ""insert studentinfo"" it makes me wonder where the Student class is. Your JDBC code doesn't handle resources properly at all. Just curious - are you trying to learn how to write a server? Is there a reason why you wouldn't use a servlet engine as the basis for this app? Sockets are a very low level place to start to solve a problem like this. yes i'm trying to write a server ...thanks for the reply. @user335990 - but **why** are you trying to do it?  The few times I've written hand-coded JDBC it's been both ugly and error prone. Of course that could just be me but you may have much better results with using the Spring JDBC data access classes. You don't have to use the whole spring container just a DataSource and a spring's JdbcTemplate class. It enforces a usage pattern to JDBC that is both thread-safe and resource-safe. Agree with this. You are reinventing the wheel badly. I am all for teaching people how not to shoot themselves in the foot but can only do so much at once."
664,A,Glassfish/Toplink and sqljdbc.jar retrying forever on broken db-connection I'm using Glassfish and Toplink together with an MS-SQL-Server thus sqljdbc4.jar is used for connecting to the database. When the database is not available (DB server is down) the CPU usage rises to 100% and Glassfish keeps on trying to connect forever. My log fills up rapidly with the following messages: FINE: TDSChannel (ConnectionID:7) read failed:Connection reset FINE: *** SQLException:ConnectionID:7 com.microsoft.sqlserver.jdbc.SQLServerException: Connection reset Connection reset FINE: com.microsoft.sqlserver.jdbc.SQLServerConnection.terminate(SQLServerConnection.java:1368)com.microsoft.sqlserver.jdbc.SQLServerConnection.terminate(SQLServerConnection.java:1355)com.microsoft.sqlserver.jdbc.TDSChannel.read(IOBuffer.java:1532)com.microsoft.sqlserver.jdbc.TDSReader.readPacket(IOBuffer.java:3274)com.microsoft.sqlserver.jdbc.TDSReader.nextPacket(IOBuffer.java:3227)com.microsoft.sqlserver.jdbc.TDSReader.ensurePayload(IOBuffer.java:3203)com.microsoft.sqlserver.jdbc.TDSReader.peekTokenType(IOBuffer.java:3420)com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:50)com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:39)com.microsoft.sqlserver.jdbc.SQLServerStatement.processExecuteResults(SQLServerStatement.java:1064)com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement$PrepStmtExecCmd.processResponse(SQLServerPreparedStatement.java:345)com.microsoft.sqlserver.jdbc.TDSCommand.close(IOBuffer.java:4111)com.microsoft.sqlserver.jdbc.SQLServerStatement.discardLastExecutionResults(SQLServerStatement.java:99)com.microsoft.sqlserver.jdbc.SQLServerStatement.closeInternal(SQLServerStatement.java:592)com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement.closeInternal(SQLServerPreparedStatement.java:170)com.microsoft.sqlserver.jdbc.SQLServerStatement.close(SQLServerStatement.java:604)com.sun.gjc.spi.ManagedConnectionFactory.isValidByTableQuery(ManagedConnectionFactory.java:397)com.sun.gjc.spi.ManagedConnectionFactory.isValid(ManagedConnectionFactory.java:297)com.sun.gjc.spi.ManagedConnectionFactory.getInvalidConnections(ManagedConnectionFactory.java:246)com.sun.enterprise.resource.AbstractConnectorAllocator.getInvalidConnections(AbstractConnectorAllocator.java:99)com.sun.enterprise.resource.AbstractResourcePool.removeInvalidResources(AbstractResourcePool.java:1535)com.sun.enterprise.resource.AbstractResourcePool.removeInvalidAndIdleResources(AbstractResourcePool.java:1515)com.sun.enterprise.resource.AbstractResourcePool.resizePool(AbstractResourcePool.java:1448)com.sun.enterprise.resource.AbstractResourcePool$Resizer.run(AbstractResourcePool.java:1610)java.util.TimerThread.mainLoop(Timer.java:512)java.util.TimerThread.run(Timer.java:462) Is there a way to set a retry-limit for connections to the database or a pause timeout between the connection retries? How can I make Glassfish throw an exception instead trying to connect forever? THe HADB edition of GlassFish delivers free a DataDirect JDBC driver for MS SQL that can handle connection resets and closes  We tracked that down this seems to be a bug in sqljdbc4.jar by Microsoft: https://connect.microsoft.com/SQLServer/feedback/ViewFeedback.aspx?FeedbackID=483322
665,A,"JDBC always tests the last row of MySQL table? I have a Manager class that saves data in the SQL table and also get result from SQL table and test these data.when I run my programone frame will be shown that gets ID and password and if they are correct the other frame will be shown.BUT I don't know that why it just test the last row of SQL table?? i mean if I set those text fields with the other IDs and passwords except from last row.it will show the data are wrong(I have set it before for wrong data) Manager class:  public static boolean Test(String userName String password) { boolean bool = false; Statement stmt = null; try { stmt = conn.createStatement(); ResultSet rst = null; rst = stmt.executeQuery(""SELECT yahooId  password FROM clienttable""); while (rst.next()) { if (rst.getString(1).equalsIgnoreCase(userName) && rst.getString(2).equalsIgnoreCase(password)) { bool = true; } else { bool = false; } } } catch (SQLException ex) { Logger.getLogger(Manager.class.getName()).log(Level.SEVERE null ex); } return bool; } my button's perform action in the frame which get the ID and password and test it:  private void jButton1ActionPerformed(java.awt.event.ActionEvent evt) { try { submit(); } catch (ConnectException ex) { JOptionPane.showMessageDialog(this ""You coudn't connect to the server successfullytry it again"" ""Sign_In Problem"" JOptionPane.OK_OPTION); } clear(); } private void submit() throws ConnectException { String id = idField.getText(); char[] pass1 = passField.getPassword(); String pass = new String(pass1); if (id.equals("""") || pass.equals("""")) { Toolkit.getDefaultToolkit().beep(); JOptionPane.showMessageDialog(this ""You should enter an ID and password"" ""Sign_In Problem"" JOptionPane.OK_OPTION); return; } else { boolean b = Manager.Test(id pass); client.setCurrentName(id); if (b == true) { this.setVisible(false); ListFrame frame = new ListFrame(client); frame.setVisible(true); } else { JOptionPane.showMessageDialog(this ""You have entered wrong datastry it again"" ""Sign_In Problem"" JOptionPane.OK_OPTION); return; } } } EDIT: I have edited my manager class(test method) but still it works like past!!  public static boolean Test(String userName String password) { boolean bool = false; PreparedStatement stmt = null; ResultSet resultSet = null; try { stmt = conn.prepareStatement(""SELECT id FROM clienttable WHERE yahooId = ? AND password = ?""); stmt.setString(1 userName); stmt.setString(2 password); resultSet = stmt.executeQuery(); bool = resultSet.next(); } catch (SQLException ex) { Logger.getLogger(Manager.class.getName()).log(Level.SEVERE null ex); } finally { try { resultSet.close(); stmt.close(); conn.close(); } catch (SQLException ex) { Logger.getLogger(Manager.class.getName()).log(Level.SEVERE null ex); } } return bool; } The simple answer is that your while loop should terminate when you find a match so it should read:  while (rst.next() && bool == false) { if (rst.getString(1).equalsIgnoreCase(userName) && rst.getString(2).equalsIgnoreCase(password)) { bool = true; } } Note that it would be more efficient to select only rows that match your user id & password something along the lines of the following: (note that error handling is left as an exercise for the reader) PreparedStatement stmt; stmt = conn.prepareStatement(""SELECT yahooId  password FROM clienttable WHERE yahooId = ?""); stmt.setString(1 ""userName""); ResultSet rst = null; rst = stmt.executeQuery(); if (rs != null && rs.getString(""password"").equals(password)) { bool = true; }  Because you're hauling the entire database table down into Java's memory and testing every row in a while loop. You don't break the loop if a match is found so that it continues overwriting the boolean outcome until with the last row. That said you really don't want to do the comparison in Java. Just make use of the SQL WHERE clause. That's much more efficient and really the task a DB is supposed to do. Don't try to take over the DB's work in Java it's only going to be inefficient. public boolean exists(String username String password) throws SQLException { Connection connection = null; PreparedStatement preparedStatement = null; ResultSet resultSet = null; boolean exists = false; try { connection = database.getConnection(); preparedStatement = connection.prepareStatement(""SELECT id FROM client WHERE username = ? AND password = ?""); preparedStatement.setString(1 username); preparedStatement.setString(2 password); resultSet = preparedStatement.executeQuery(); exists = resultSet.next(); } finally { close(resultSet); close(preparedStatement); close(connection); } return exists; } You see that I made a few enhancements: Use preparedstatement. Do not use equalsignorecase. A password of ""FooBar"" should NOT be the same as ""foobar"". Gently acquire and close resources in same scope to avoid leaking. Have it in an independent and reuseable non-static DAO method. To learn more about using JDBC the proper way you may find this basic tutorial useful. +1 from me - a typically well written response. think we might need a bit more information than it doesn't work correctly... @BalusC's answer is about as good as it's going to get with the information you have provided @Johanna: Then the problem lies somewhere else. Debug it. If you mean that `false` is been returned then it simply means that there's no match in the DB :) By the way your edited code is in JDBC perspective still wrong. You're still leaking the `Connection` and not closing the resources each in its own try-catch (and worse the whole method is still `static`). Your app might break sooner or later when used extensively in production. @Johanna: if you want more assistance you really *really* need to learn to ask questions the smart way. Plain saying ""it doesn't work!"" gives us really **nothing** to work with. Elaborate in detail what exactly happens and also elaborate in detail what exactly happens **not** (i.e. your expectations). With in detail I mean at code (developer) level and not at end-user level. nice answerthanks a lot (sorry for late thanks!)"
666,A,"Alternative way to load DB driver in Java Is there any other way to load DB driver than class.forName? Removed ""oracle"" tag because the question applies to JDBC in general. You can also add the driver class to the system property jdbc.drivers which is a list of colon-separated driver classnames that the DriverManager class loads. Example: java -Djdbc.drivers=oracle.jdbc.driver.OracleDriver MyApp Source: The DriverManager javadocs.  Modern Drivers don't need to be registered because they have a META-INF/services/java.sql.Driver file that declares the existence of the driver by containing the name of the Driver class. Just use DriverManager.getConnection(...) and it discovers the driver itself. EDIT @Thilo: I just tested it with PostgreSQL and it works: import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; public class JdbcDriverLoadTest { public static void main(String[] args) throws SQLException { Connection c = DriverManager.getConnection(""jdbc:postgresql://localhost:5434/IKOffice_Core"" ""ik"" ""ik0000""); System.out.println(c.getMetaData().getDatabaseProductName()); } } However your application needs to be properly documented that the enduser should be providing a full JDBC 4 compatible driver utilizing this [`java.util.ServiceLoader`](http://download.oracle.com/javase/6/docs/api/java/util/ServiceLoader.html) feature else the application may not work. As far now not all major JDBC driver vendors have implemented this. I would still rely on `Class#forName()` and reevaluate the JDBC driver world after one year or two before entirely killing the `Class#forName()`.  Modern JDBC drivers are supposed to provide enough metadata in their jar file manifest so you may not need to do anything. The main point of Class#forName is to remove the compile-time dependency on the particular JDBC driver (and make it configurable at run-time). If you are using Oracle driver code in your program anyway (to use their non-standard JDBC extensions) and have no compulsions to hardcode the driver class name you can also just create a regular instance of the driver class.  new oracle.jdbc.driver.OracleDriver(); Damn i was just about to write that :) but it is not the manifest file where they are registered. @Daniel: I've never seen that work though. Thilo I didn't see that working too before. But I believe this is fixed in Java 1.6 because I just checked and it works. +1 nonetheless.  Often you can just create an instance of it but that results in a hard dependency on a particular driver. The reason what Class.forName is used is because you can make it configurable. The reason it works is because it triggers the class's static initializers to run which allow it to register with jdbc. In short as far as I'm aware you have two options: Class.forName - allows configurable driver - nice direct instantiation - creates solid class dependency - not nice"
667,A,"Why date is inserted as 02/10/0010 instead of 02/10/2010 I am inserting a record to orcle db through java application. The date value inserted as 02/10/0010 instead of 02/10/2010 HH:MM:SS AM/PM? I am using oracle jdbc connection. Does it problem with JDBC driver ? Any input on this. Can you post your code please? Is it because the date you're passing in is `02/10/0010`? If you're using Oracle and JDBC don't store Date in your table as a String. Make it a real Date and you'll spare yourself all this pain.  I'm guessing that the value you're passing in is ""02/10/10"". Date functions are pretty inconsistent about what they do with 2 digit years. If you are trying to enter dates for your ""timeline of ancient history"" having the computer assume that 2-digit dates must be shorthand for the 21st century would be very annoying. We really are better off with a WYSIWYG date interpretation.  Agree. If you use a Java Date format (dunno its class just now) then JDBC driver performs all what is needed to store it in a Date column. If you use String in java and/or varchar2 in Oracle table you are doing it wrong. This will lead to implicit conversions NLS settings and all that pain... if you are in this bad shape then you need explicit conversions and format masks on each date usage. Use proper types.  Check your date source. Is it two digit year or four? Also there are Oracle date mask formats which might cause that. Check the default for the installation."
668,A,How does the SQL Server JDBC Trusted Connection Authentication work? How does the SQL Server JDBC Trusted Connection Authentication work? (ie how does the trusted connection authenticate the logged in AD user in such a transparent and elegant fashion and how can I implement a similar authentication solution for my client-server applications in Java without a database connection or any use of the existing SQL Server solution.) Assumptions * Working within a Windows 2003 domain * You have access to the Windows API via JNI/JNA It depends on the client. For example if you have a Web Browser it can use the NTLM Authentication to pass the domain authentication of your current client to the server. In this case the browser like IE or FF supports this and you web server needs the support for NTLM. For example here for Tomcat: http://jcifs.samba.org/src/docs/ntlmhttpauth.html There is also the SPNEGO protcol in combination with Kerberos as explained here: http://java.sun.com/javase/6/docs/technotes/guides/security/jgss/lab/index.html If you have your own client it depends on the client's framework if it is able to use the local user's security context and is able to pass it on. The page above describes this at least for a kerberos scenario. Greetings Bernd PS: I am not sure if you can pass the authentication context established with the jcifs/ntmlm solution to a backend component like SQL Server. It should work with Kerberos tickets (if configured). This PS comment is what the question was about. I want to pass the authentication context established with jcifs to a backend component like SQL Server. Any suggestions?  jTDS and Microsoft JDBC Driver both offer native Windows Authentication.  Have you looked at this question? The situation seems to be similar to yours (connecting to a SQL Server database using Windows authentication).
669,A,"Hiberate problems jdbc IDENTITY_INSERT is set to OFF I am getting JDBC error when I attempt a commit through hibernate to SQL Server Cannot insert explicit value for identity column in table 'Report' when IDENTITY_INSERT is set to OFF I am using mappings generated by netbeans that contain <class name=""orm.generated.Report"" table=""Report"" schema=""dbo"" catalog=""DatabaseName""> <id name=""id"" type=""int""> <column name=""ID"" /> <generator class=""assigned"" /> </id> Which looks to me like it should be doing the identity insert properly. Any idea on how to fix this? EDIT: Some links to documentation for posterity http://www.hibernate.org/hib_docs/v3/reference/en-US/html/mapping.html#mapping-declaration-id-generator http://www.roseindia.net/hibernate/hibernateidgeneratorelement.shtml I had the same problem only using annotations - this helped me solve it :) Awesome it's nice to know that my questions are helping other people. Here's something that worked for me. Adapt as needed. @SuppressWarnings(""deprecation"") public static void saveWithOverwrittenId(Session session Object entity) { String tableName = entity.getClass().getSimpleName(); boolean identityInsertSetToOn = false; try { session.connection().createStatement().execute(""SET IDENTITY_INSERT ""+tableName+"" ON""); identityInsertSetToOn = true; session.beginTransaction(); session.saveOrUpdate(entity); session.getTransaction().commit(); } catch (SQLException e) { session.getTransaction().rollback(); throw new RuntimeException(e); } finally { if (identityInsertSetToOn) { try { session.connection().createStatement().execute(""SET IDENTITY_INSERT ""+tableName+"" OFF""); } catch (SQLException e) { throw new RuntimeException(e); } } } } In my case the SQL Server table had the same name as the Entity class. For you this is probably not true. One solution then would be to ask the table name as a parameter.  You cannot insert into an identity column in SQL Server unless ""IDENTITY_INSERT"" is set to ""ON"". Since your generator class is ""assigned"" Hibernate is assuming that you are setting an explicit value for ""id"" in Java before saving the object and that Hibernate can directly insert the value into the database. You need to either: Pick a different generator class such as ""native"" Set IDENTITY_INSERT to ""ON"" This works leads me into another error but it works Thank you. Just to clarify I meant by fixing this problem I uncovered another one. Thanks I will give this a try when I get back to work on Tuesday.  It would be best to use wrapper classes like Integer instead of primitive int. It is a good practice on SO to add as much relevant details as you can in your post. Thus here you could add code sample for example. That would make your answer way more valuable ;)  Change the type of the generator class BEFORE <id name=""id"" type=""long""> <column name=""Id"" /> <generator class=""assigned"" /> </id> AFTER <id name=""id"" type=""long""> <column name=""Id"" /> <generator class=""native"" /> </id> Now this will work!  try to change the type of the generator class from 'assigned' to 'identity' it worked for me This does not provide an answer to the question. To critique or request clarification from an author leave a comment below their post - you can always comment on your own posts and once you have sufficient [reputation](http://stackoverflow.com/help/whats-reputation) you will be able to [comment on any post](http://stackoverflow.com/help/privileges/comment)."
670,A,suggest a link with such concepts implemented - java and mysql i need to write a program in java that will connect to a mysql database and execute some sql queries and display the result. suggest me a link with similar implementation / discussion of such concepts for guidance. NetBeans is not my favourite IDE but I must admit they have really nice tutorials and screencasts especially for beginners. So you could maybe start with Connecting to a MySQL Database. Then have a look at Creating a Simple Web Application Using a MySQL Database. If you are more into Swing maybe you'll prefer NetBeans Platform CRUD Application Tutorial. Without more details on the technologies you want to use and the type of application you want to build it's actually hard to provide more guidance.  Investigate object-relational mapping (ORM) libraries such as Hibernate. They encapsulate the JDBC API in a way that simplifies coding. While I think ORM is great in many instances it may be overkill for what the user is looking for especially if they are asking about guidance on connecting to a database. I think jdbc is the place to start and then if needed move onto other concepts such as ORM.  I would look here: http://dev.mysql.com/usingmysql/java/ you will need the connector jar from mysql. And then a basic jdbc tutorial from sun here: http://java.sun.com/docs/books/tutorial/jdbc/index.html  Probably the easiest would be to use the predefined Desktop Database Template included with NetBeans. It's based on the Swing Application Framework. Benefits: drag and drop GUI all the pre-wiring is done. I mean... it would be hard to make more simple. There's a complete tutorial here. And another one there.  First start with the JDBC tutorial to learn the generic JDBC concepts. You can consult the MySQL JDBC documentation for more MySQL-specific details such as how to create a connection string and more JDBC code examples. As next step you can learn the DAO pattern how to manage your JDBC code nicely. If you want to go more further then you can take a look for JPA.
671,A,"How to make Java work with SQL Server? I know this is a basic question but I can't seem to find an answer and I apologize if this question is way too stupid but here we go: I am supposed to work with SQL Server (no problem so far) and with Java (love java so no problem here either) but now: What am I supposed to do to make the combination work? I got: JRE 1.6 and the sqljdbc4.jar ... Before I put sqljdbc4.jar into my classpath I had sqljdbc.jar in it and with a test-program I got this exception: 21.08.2009 09:26:59 com.microsoft.sqlserver.jdbc.SQLServerConnection <init> SCHWERWIEGEND: Die Java-Laufzeitumgebung (Java Runtime Environment JRE) Version 1.6 wird von diesem Treiber nicht unterstützt. Verwenden Sie die Klassenbibliothek 'sqljdbc4.jar' die Unterstützung für JDBC 4.0 bietet. java.lang.UnsupportedOperationException: Die Java-Laufzeitumgebung (Java Runtime Environment JRE) Version 1.6 wird von diesem Treiber nicht unterstützt. Verwenden Sie die Klassenbibliothek 'sqljdbc4.jar' die Unterstützung für JDBC 4.0 bietet. at com.microsoft.sqlserver.jdbc.SQLServerConnection.<init>(SQLServerConnection.java:223) at com.microsoft.sqlserver.jdbc.SQLServerDriver.connect(SQLServerDriver.java:840) at java.sql.DriverManager.getConnection(Unknown Source) at java.sql.DriverManager.getConnection(Unknown Source) at msSqlTest.DB.dbConnect(DB.java:13) at msSqlTest.TestConnection.main(TestConnection.java:7) Sorry for the German ... It basically means that I should use sqljdbc4.jar b/c the JRE I am using is not supported by the driver. So I put sqljdbc4.jar into my classpath but it didn't work so I am kinda lost what I could do. Maybe someone could tell be in an idiot-proof way what I should do :( Oh yeah here is the test appI use: import java.sql.*; public class TestConnection{ public static void main(String[] args){ // Neue DB und los geht's :) DB db = new DB(); db.dbConnect(""jdbc:sqlserver://localhost:1433/muff"" ""user"" ""pw"" ); } } class DB{ public void dbConnect( String db_connect_string String db_userid String db_password){ try{ Class.forName( ""com.microsoft.sqlserver.jdbc.SQLServerDriver"" ); Connection conn = DriverManager.getConnection( db_connect_string db_userid db_password); System.out.println( ""connected"" ); } catch( Exception e ){ e.printStackTrace(); } } }; The driver you are using is the MS SQL server 2008 driver (sqljdbc4.jar). As stated in the MSDN page it requires Java 6+ to work. http://msdn.microsoft.com/en-us/library/ms378526.aspx sqljdbc4.jar class library requires a Java Runtime Environment (JRE) of version 6.0 or later. I'd suggest using the 2005 driver which I beleive is in (sqljdbc.jar) or as Oxbow_Lakes says try the jTDS driver (http://jtds.sourceforge.net/). thnx for the hint with the jtds ... I tried it and it worked :)  Have you tried the jtds driver for SQLServer? +1 - that's the one to use not yet but something tells me I should ;) So I downloaded ... and now what happened? IT WORKS!!! What I've learned: listen to your inner-voice (or stackoverflow ;) ...) Do you use jTDS oxbow? Haha - yes it's the recommended SQL Server driver to use with Atlassian's Confluence and JIRA which we have installed here Ridiculous; our enterprise is specifically moving to the MS driver *away* from jtds because of it's bugs. And it supports XA. Just make sure you're using the latest JRE >= 1.6.30  For anyone still googling this go to \blackboard\config\tomcat\conf and in wrapper.conf put an extra line in wrapper.java.classpath pointing to the sqljdbc4.jar and then update the wrapper.conf.bb as well Then restart the blackboard services and tomcat and it should work It won't work by simply setting your java classpath you have to set it up in the blackboard config files to point to your jar file with the jdbc library  Do not put both the old sqljdbc.jar and the new sqljdbc4.jar in your classpath - this will make it (more or less) unpredictable which classes are being used if both of those JARs contain classes with the same qualified names. You said you put sqljdbc4.jar in your classpath - did you remove the old sqljdbc.jar from the classpath? You said ""it didn't work"" what does that mean exactly? Are you sure you don't still have the old JAR in your classpath somewhere (maybe not explicitly)? I think you'll find that whichever jar is in the classpath first will be favored (with the Sun JVM) although agreed it's best to only include the jar you actually want to use. thnx for the reply. I didn't make it clear sorry but yes I did remove the sqljdbc.jar from the classpath and put the sqljdbc4.jar into the classpath but I still get the same exception. How can I see if it is still ""not explicitly"" in the classpath? With ""not explicitly"" I meant that maybe you are running code in a server (Tomcat for example) and you have the JAR in a lib directory of the server or maybe it's even in your lib/ext directory of the JRE (JAR files in there are automatically put in the classpath).  Indeed. The thing is that the 2008 R2 version is very tricky. The JTDs driver seems to work on some cases. In a certain server the jTDS worked fine for an 2008 R2 instance. In another server though I had to use Microsoft's JBDC driver sqljdbc4.jar. But then it would only work after setting the JRE environment to 1.6(or higher). I used 1.5 for the other server so I waisted a lot of time on this. Tricky issue.  Maybe a little late but using different drivers altogether is overkill for a case of user error: db.dbConnect(""jdbc:sqlserver://localhost:1433/muff"" ""user"" ""pw"" ); should be either one of these: db.dbConnect(""jdbc:sqlserver://localhost\muff"" ""user"" ""pw"" ); (using named pipe) or: db.dbConnect(""jdbc:sqlserver://localhost:1433"" ""user"" ""pw"" ); using port number directly; you can leave out 1433 because it's the default port leaving: db.dbConnect(""jdbc:sqlserver://localhost"" ""user"" ""pw"" );  What about the official JDBC 4.0 compatible JDBC driver from Microsoft? Don't go near it intentionally or not it's pretty poor or was the last time I used it - the conspiracy theorist in me might say that's intentional but I suspect they simple didn't devote enough resources to it... that's the one I am using :(  If you are use sqljdbc4.jar use the following code ResultSet objResultSet = objPreparedStatement.getResultSet(); if (objResultSet == null) { boolean bResult = false; while (!bResult){ if (objPreparedStatement.getMoreResults()){ objResultSet = objPreparedStatement.getResultSet(); bResult = true; } } } objCachedRowSet = new CachedRowSetImpl(); objCachedRowSet.populate(objResultSet); if (CommonUtility.isValidObject(objResultSet)) objResultSet.close(); objResultSet = null;  I had the same problem with a client of my company the problem was that the driver sqljdbc4.jar tries a convertion of character between the database and the driver. Each time that it did a request to the database now you can imagine 650 connections concurrently this did my sistem very very slow for avoid this situation i add at the String of connection the following parameter:  SendStringParametersAsUnicode=false then te connection must be something like url=""jdbc:sqlserver://IP:PORT;DatabaseName=DBNAME;SendStringParametersAsUnicode=false"" After that the system is very very fast as the users are very happy with the change i hope my input be of same. i'm using sqljdbc4.jar jre1.6_29"
672,A,"JDBC postgres statement_timeout Suppose I have: untimedStatement = connection.createStatement() ; timedStatement = connection.createStatement(); And then run timedStatement.execute(""SET statement_timeout TO "" + timeout); Will the SET statement_timeout command also affect untimedStatement? I was hoping it would not but some of the behaviour I'm observing suggests that SET statement_timeout has a ""universal"" effect (at least for the life of the program) Yes as long as they are executed on the same connection. You can use SET LOCAL statement_timeout to make it affect only the current transaction. Details."
673,A,"java.sql.SQLData - Oracle object mapping problem I am using java.sql.SQLData interface to map my java objects to Oracle database types. For example I have an object type Person in Oracle DB defined as: CREATE OR REPLACE TYPE PERSON AS OBJECT ( PERSON_ID NUMBER PERSON_NAME VARCHAR2(100) ); Corresponding Java type is: public class Person implements SQLData { private String sql_type = ""PERSON""; private int personId; private String personName; public int getPersonId() { return personId; } public void setPersonId(int personId) { this.personId = personId; } public String getPersonName() { return personName; } public void setPersonName(String personName) { this.personName = personName; } public void readSQL(SQLInput stream String typeName) throws SQLException { this.sql_type=typeName; this.personId = stream.readLong(); this.personName = stream.readString(); } public void writeSQL(SQLOutput stream) throws SQLException { stream.writeLong(this.personId); stream.writeString(this.personName); } } This works fine currently and populates Person Objects from database type. Now I have a another type and it's corresponding collection as follows: CREATE OR REPLACE TYPE SUBJECT AS OBJECT ( SUBJECT_ID NUMBER SUBJECT_NAME VARCHAR2(100) ); -- Corresponding List CREATE OR REPLACE TYPE SUBJECT_LIST IS TABLE OF SUBJECT; I have to create a new entry in type PERSON with this collection as follows: CREATE OR REPLACE TYPE PERSON AS OBJECT ( PERSON_ID NUMBER PERSON_NAME VARCHAR2(100) SUBJECT_LIST TYPE SUBJECT_LIST ); To make this change I have to change my java Person class. I tried adding java.sql.Array parameter but it is not working. Can you please help here to map the new PERSON Object type to Java type? Thanks in advance. --Siddharth Please someone help.. Hey I did not access this so sorry I could not reply. What I did was to have a java.sql.Array defined in my class. This maps to the the nested type in Oracle database. So in this case my Person class will have an instance variable : java.sql.Array subjectList; To set the value you will need to do the following: Subject[] subjectListArray=null; Person p = new Person(); p.setSubjectList(new oracle.sql.ARRAY(getOracleArray(typeName connection subjectListArray))); The getOracleArray method will be something like this: public static oracle.sql.ArrayDescriptor getOracleArray(final String typeName)throws SQLException { if(typeName==null)return null; final oracle.sql.ArrayDescriptor arrayDescriptor = new oracle.sql.ArrayDescriptor( typeName con); return arrayDescriptor; }  The documentation of SQLInput (link below) has this on the first line... ""This interface [ie SQLInput] ... is used by the driver behind the scenes and a programmer never directly invokes SQLInput methods."" Are you sure you should be using SQLInput directly? Is there an example you're following? Ref: http://java.sun.com/j2se/1.4.2/docs/api/java/sql/SQLInput.html#readObject%28%29 It freaking worked! Thanks cogcowboy!!!! The example above is the one I am using right now. I am not using SQLInput directly. I am simply implementing the SQLData interface and the methods readSQL and writeSQL. The methods are called internally by SQLInput and SQLOutput. I am sorry if I haven't described the problem statement correctly. I need to have an Oracle collection type within an Oracle object type. I want to know how I can create the corresponding Java class. Do I need a java.sql.Array instance for the Collection type? Thanks. Yes I think you'll need a java.sql.Array class although we actually use oracle.sql.ARRAY since it already implements a lot of the methods for us. So should I have an instance of java.sql.Array in person class something like this: private java.sql.Array subjectList; In readSql... this.subjectList=stream.readArray(); In writeSQL... stream.writeArray(subjectList); Is this wat you mean?"
674,A,"Restrict access to connection pool in Weblogic? In short how can I restrict access to connection pool X based on application name or JAR name? A simple use case might help... A business web-app (call it WEB_APP_A) uses pool Y to do basic look-up SQL. Some users of this web-app have access to also update some sensitive data in the database. This code is provided by a JAR file (call it HR_JAR) that can be dropped in where needed. This JAR uses pool X for all of it's connections. We don't want developers of WEB_APP_A using pool X. We only want HR_JAR using pool X. This is to keep devs of WEB_APP_A from accidentally or intentionally abusing the access pool X provides. Some considerations: This is legacy code so HR_JAR is here to stay We are running on Weblogic 9.2 We can not keep passwords in any from in the source code We have researched weblogic user level authn/authz for JDBC resources but then this begs the question; how do we secure the user creds we use to become a user per app/jar? Ideas? Thoughts? I can elaborate more on what I have tried but I wanted fresh ideas. There is no good way to do this as far as I can tell. There are some clever tricks with AspectJ but in the end it's more trouble than it's worth.  Haven't ever tried this and don't have access to an instance to play right now but in your JDBC config you could try adding a <scope> element for the application against pool X inside the <jdbc-data-source-params> I think... Though that assumes you have a separate application defined for HR.jar which I'm not sure is the case from your description. I don't know if you can restrict an individual JAR within an application though. @Andrew I'm not sure to understand how this JBoss stuff would solve your problem. Well in JBoss I could do the following right? grant codeBase ""jar:file:${catalina.home}/webapps/WEB_APP_A/WEB-INF/lib/HR.jar!/-"" { org.apache.naming.JndiPermission ""jndi://localhost/poolX; }; @Andrew Ah yes indeed. After a second read it appears that you're right. HR JAR is shipped with WEB_APP_A. In JBoss the answer seems trivial (see http://www.jboss.org/file-access/default/members/jbossweb/freezone/docs/latest/security-manager-howto.html section ""JBoss Web Custom Permissions""). I can't seem to find the equivalent in Weblogic."
675,A,"jdbcTemplate hangs on long update I recently switched to Spring Framework instead of manually handling JDBC and it is mostly a good transition. One program started having strange problems though: if the database is slow when calling getJdbcTemplate().update( ... ) it sometimes never returns. After researching a little bit I switched from Apache DBCP to C3PO but the problem still came back. Here's the code I'm using: public class MyDao extends SimpleJdbcDaoSupport { private static Logger logger = Logger.getLogger(MyDao.class); public MyDao(Config config) { super(); ComboPooledDataSource cpds = new ComboPooledDataSource(); try { cpds.setDriverClass(""com.mysql.jdbc.Driver""); } catch (PropertyVetoException e) { throw new RuntimeException(e); } cpds.setUser(""username""); cpds.setPassword(""password""); cpds.setJdbcUrl(""jdbc:mysql://localhost/schema"" + ""?useUnicode=true&characterEncoding=UTF-8""); cpds.setMaxStatements( 180 ); cpds.setPreferredTestQuery(""SELECT 1""); cpds.setTestConnectionOnCheckout(true); this.setDataSource(cpds); } public void addToWorkQueue(String item) { long[] ids = Utils.getItemIds(item); try { logger.debug(""About to insert to work table""); getJdbcTemplate().update( ""INSERT IGNORE INTO work "" + ""SELECT * FROM queue WHERE id_1 = ? AND id_2 = ?"" new Object[] { ids[0] ids[1] } ); } finally { logger.debug(""Updated work table""); } } } Here's what it looks like in the log file: 2009-07-29 17:37:13.570 com.mycomp.MyDao About to insert into work table 2009-07-29 17:37:13.570 com.mchange.v2.c3p0.impl.C3P0PooledConnectionPool Testing PooledConnection [com.mchange.v2.c3p0.impl.NewPooledConnection@170984c] on CHECKOUT. 2009-07-29 17:37:13.571 com.mchange.v2.c3p0.stmt.GooGooStatementCache checkinAll(): com.mchange.v2.c3p0.stmt.GlobalMaxOnlyStatementCache stats -- total size: 1; checked out: 0; num connections: 1; num keys: 1 2009-07-29 17:37:13.571 com.mchange.v2.c3p0.impl.C3P0PooledConnectionPool Test of PooledConnection [com.mchange.v2.c3p0.impl.NewPooledConnection@170984c] on CHECKOUT has SUCCEEDED. 2009-07-29 17:37:13.571 com.mchange.v2.resourcepool.BasicResourcePool trace com.mchange.v2.resourcepool.BasicResourcePool@d402dd [managed: 3 unused: 2 excluded: 0] (e.g. com.mchange.v2.c3p0.impl.NewPooledConnection@170984c) 2009-07-29 17:37:13.571 com.mchange.v2.c3p0.stmt.GooGooStatementCache com.mchange.v2.c3p0.stmt.GlobalMaxOnlyStatementCache ----> CACHE HIT 2009-07-29 17:37:13.571 com.mchange.v2.c3p0.stmt.GooGooStatementCache checkoutStatement: com.mchange.v2.c3p0.stmt.GlobalMaxOnlyStatementCache stats -- total size: 1; checked out: 1; num connections: 1; num keys: 1 This is where the code hangs. Usually it just goes on like this: 2009-07-29 17:37:13.762 com.mchange.v2.c3p0.stmt.GooGooStatementCache checkinStatement(): com.mchange.v2.c3p0.stmt.GlobalMaxOnlyStatementCache stats -- total size: 1; checked out: 0; num connections: 1; num keys: 1 2009-07-29 17:37:13.763 com.mchange.v2.c3p0.stmt.GooGooStatementCache checkinAll(): com.mchange.v2.c3p0.stmt.GlobalMaxOnlyStatementCache stats -- total size: 1; checked out: 0; num connections: 1; num keys: 1 2009-07-29 17:37:13.763 com.mchange.v2.resourcepool.BasicResourcePool trace com.mchange.v2.resourcepool.BasicResourcePool@d402dd [managed: 3 unused: 2 excluded: 0] (e.g. com.mchange.v2.c3p0.impl.NewPooledConnection@170984c) 2009-07-29 17:37:13.763 com.mycomp.MyDao Updated work table I don't know why I'm not getting any log message from Spring Framework itself. I added these lines in my main code: Logger springLogger = Logger.getLogger(""org.springframework""); springLogger.setLevel(Level.TRACE); springLogger.debug(""testing spring logger""); The test message shows but nothing else. Sorry for diverging. I did notice a slowdown before the hang. The last time the query ran successfully it took a minute and a half to finish instead of the usual 200ms. The next time I let it run for 25 minutes before killing the process. I know I have some problems with my database (InnoDB) which I'm working on but this seems like after a timeout Spring Framework just ""gives up"" and hangs. Any advice would be appreciated. I doubt this has anything to do with Spring it's a pretty thin layer. it could be something to do with transactions though...? I agree is it possible you are not closing transactions? Is it possible another query locks the table? If you are using InnoDB Run ""show innodb status"" Eventually the problem was avoided by fixing the underlying DB issue. I was using an InnoDB table as a work queue which meant I added and removed a whole lot of items to it. The table never had too many rows at a given time but apparently InnoDB can't handle this sort of work or as my DBA friend put it ""deleting rows from a table doesn't do anything for performance"". After switching to a much crazier db strategy which involved creating and dropping tables all the time the performance was much improved and the hangs went away. So I guess what I'm saying is skaffman's comment was probably right. This didn't have anything to do with Spring. maybe you should close the question or remove the spring tag?"
676,A,"Connection to Oracle without a username or password Oracle has this concept of allowing database users to be identified by the operating system user who is running the program that is connecting to Oracle. See here. This allows you to do as that user on a unix machine for example a command such as: sqlplus / I am attempting to write a Java program for Oracle 10.2 which connects without a username or password. The obvious choice of url: jdbc:oracle:thin:/@localhost:1521:MYDBSID doesn't work giving an error (Sorry I don't have the error available right now). I have attempted many other forms of doing this as well but with no luck. Does anyone have any suggestions on how I can connect a Java program to Oracle using the OS identification method? If you're accessing Oracle from a J2EE appserver you could achieve a similar end by using JNDI to acquire a datasource.  The jdbc thin driver is a 100% Java implementation that cannot collect the needed info from the operating system. The jdbc oci driver however can do this use ""jdbc:oracle:oci8:/@MYDBSID"" it will require that the oracle driver be installed on the machine not a problem if this is a server (and is faster to boot and supports many more features than the thin driver). This is true for older versions of Oracle JDBC Drivers but not true for the newer versions (ojdbc5.jar and ojdbc6.jar). You still have to give the connection the user but it should work according to the documentation here: http://download.oracle.com/docs/cd/B28359_01/java.111/b31224/clntsec.htm#CIHCBCBC  The 11g thin driver can connect using Kerberos authentication. See Connect to an Oracle database using Kerberos  try following jdbc:oracle:thin:username/password@localhost:1521:MYDBSID you need to specify the account information sqlplus / as sysdba on a unix machine which go through the operation system autentication  Thanks to those that answered. We've gone with the OCI driver. I did find documentation to suggest that Oracle 11g does support OS user authentication via the thin driver though: http://www.orindasoft.com/public/Oracle_JDBC_JavaDoc/javadoc1110/oracle/jdbc/OracleConnection.html#CONNECTION_PROPERTY_THIN_VSESSION_OSUSER I don't have an 11g setup to test this on so I can't be certain this works. Just for your information: using the Oracle 11g JDBC thin driver on an Oracle 10g database works with the OS user authentication (I've tested it). But be aware that it is not really secure as one can programmatically change the property mentioned above. Even if remote OS authentication is not allowed running a program on the same machine from an unauthorized user is still a high risk in this case.  The jdbc driver that oracle ships does NOT have the capability of gathering the OS username and password from the URL that you provide it. Suppose there are 3rd party JDBC driver providers for ORACLE one of them might provide the functionality that you're asking for. you should google around."
677,A,Pattern for working with different database dialects via JDBC I'm creating an application that has to work with different databases (Oracle MSSQL MySQL...) through JDBC. I have to work via JDBC because my application calls stored procedures in these databases. What is the best aproach for building such applications? Are there any frameworks for this? Important: The solution must nicely deal with Spring Framework. I am thinking about Hibernate since it is robust ORM solution and it has a buildin support for stored procedures: http://docs.jboss.org/hibernate/stable/core/reference/en/html_single/#sp_query Please provide me with your oppinions about my current choise. Best regards Max I would give myBatis a good look. It handles all the pain associated with JDBC and transactions and mapping resultsets to Java objects or hashes. It also plays nice with SQL and stored procedure by separating them from the Java code and configuring them in XML configuration files. This works in practice a lot better because it is easier to copy queries from XML to an interactive SQL browser and vice versa. To connect to multiple datasets you need to create an SqlSessionFactory for each datasource. Hi Peter thank you very much for reminding me about *BATIS. I was using iBATIS some years ago and I liked it a lot. I just checked iBATIS website and saw that it is retired. After I checked myBATIS and saw that it is not very good with Spring. So it seems not the best choise for me. I saw that the Spring support was broken with iBatis 3. However myBatis.org also supports iBatis 2.3.5 which presumably has still Spring support.  Hibernate is usually the standard option (and the one I'd choose). I prefer using JPA over Hibernate but that's not an option if you need Stored Procedures. But regarding the comment about iBatis: While I have no experience with iBatis myself it seems the Spring Support for iBatis is not bad: From the Spring Reference chapter 13.6: iBATIS SQL Maps: The iBATIS support in the Spring Framework much resembles the JDBC support in that it supports the same template style programming and as with JDBC and other ORM technologies the iBATIS support works with Spring's exception hierarchy and lets you enjoy Spring's IoC features. Transaction management can be handled through Spring's standard facilities. No special transaction strategies are necessary for iBATIS because no special transactional resource involved other than a JDBC Connection. Hence Spring's standard JDBC DataSourceTransactionManager or JtaTransactionManager are perfectly sufficient.
678,A,"How to overcome OutOfMemoryError during huge file write I am writing a full database extract program in java. Database is Oracle and it is huge. Some tables have ~260 million records. The program should create one file per table in a specific format so using Oracle datapump etc is not an option. Also some company security policies do not allow to write a PL/SQL procedure to create files on DB server for this requirement. I have to go with Java and JDBC. The issue I am facing is that Since files for some of the table is huge (~30GB) I am running out of memory almost every time even with a 20GB Java Heap. During the creation of file when the file size exceeds the heap size even with one of the most aggressive GC policy the process seems to hang-up. For example if the file size is > 20GB and heap size is 20GB once heap utilization hits max heap size its slows down writing 2MB per minute or so and at this speed it will take months to get full extract. I am looking for some way to overcome this issue. Any help would be greatly appreciated. Here are some details of the system configuration I have: Java - JDK1.6.0_14 System config - RH Enterprise Linux (2.6.18) running on 4 X Intel Xeon E7450 (6 cores) @2.39GH RAM - 32GB Database Oracle 11g file wirting part of the code goes below: private void runQuery(Connection conn String query String filePath String fileName) throws SQLException Exception { PreparedStatement stmt = null; ResultSet rs = null; try { stmt = conn.prepareStatement(query ResultSet.TYPE_SCROLL_INSENSITIVE ResultSet.CONCUR_READ_ONLY); stmt.setFetchSize(maxRecBeforWrite); rs = stmt.executeQuery(); // Write query result to file writeDataToFile(rs filePath + ""/"" + fileName getRecordCount( query conn)); } catch (SQLException sqle) { sqle.printStackTrace(); } finally { try { rs.close(); stmt.close(); } catch (SQLException ex) { throw ex; } } } private void writeDataToFile(ResultSet rs String tempFile String cnt) throws SQLException Exception { FileOutputStream fileOut = null; int maxLength = 0; try { fileOut = new FileOutputStream(tempFile true); FileChannel fcOut = fileOut.getChannel(); List<TableMetaData> metaList = getMetaData(rs); maxLength = getMaxRecordLength(metaList); // Write Header writeHeaderRec(fileOut maxLength); while (rs.next()) { // Now iterate on metaList and fetch all the column values. writeData(rs metaList fcOut); } // Write trailer writeTrailerRec(fileOut cnt maxLength); } catch (FileNotFoundException fnfe) { fnfe.printStackTrace(); } catch (IOException ioe) { ioe.printStackTrace(); } finally { try { fileOut.close(); } catch (IOException ioe) { fileOut = null; throw new Exception(ioe.getMessage()); } } } private void writeData(ResultSet rs List<TableMetaData> metaList FileChannel fcOut) throws SQLException IOException { StringBuilder rec = new StringBuilder(); String lf = ""\n""; for (TableMetaData tabMeta : metaList) { rec.append(getFormattedString(rs tabMeta)); } rec.append(lf); ByteBuffer byteBuf = ByteBuffer.wrap(rec.toString() .getBytes(""US-ASCII"")); fcOut.write(byteBuf); } private String getFormattedString(ResultSet rs TableMetaData tabMeta) throws SQLException IOException { String colValue = null; // check if it is a CLOB column if (tabMeta.isCLOB()) { // Column is a CLOB so fetch it and retrieve first clobLimit chars. colValue = String.format(""%-"" + tabMeta.getColumnSize() + ""s"" getCLOBString(rs tabMeta)); } else { colValue = String.format(""%-"" + tabMeta.getColumnSize() + ""s"" rs .getString(tabMeta.getColumnName())); } return colValue; } You haven't provided any code which makes it hard to say exactly what you're doing wrong... if you are streaming the records to a file you should not have a problem there is no reason to keep an entire 2GB table in memory prior to writing it to a file. Also check how your are using Strings in your code. Without any code it is difficult to suggest any solutions. Yes we need some code to review. Pseudocode if necessary. @Sam Saffron - I am not keeping the large table in the memory. I am fetching only 100 records per cycle and I am writing the file per record so to avoid memory usage in buffering the records. @Amit I would probably isolate the offending code try iterating through your table without writing to a file are you still running out of memory? @Sam Saffron - I liked this idea and tested as you said and to my astonishment it failed even without writing the file. I was using 2GB heap which I thought would be enough for this operation. Now I am getting the feeling that using ""ResultSet.TYPE_SCROLL_INSENSITIVE"" is causing the issue. right now I am testing with ""conn.prepareStatement(query)"" and will get back to you guys when I am done with testing. @Sam Saffron and all - I tested the code without ""ResultSet.TYPE_SCROLL_INSENSITIVE"" and this time it ran successfully. Though I didn't create the file this time only ran throught the ResultSet but I am preety sure I have found the issue. It seems that ResultSet.TYPE_SCROLL_INSENSITIVE flag causes the Resultset object to hold up the memory. I wonder why this is not documented prominently. Well it *is* documented here: http://download.oracle.com/docs/cd/E11882_01/java.112/e16548/resltset.htm#BABBCECI Its probably due to the way you call prepareStatement see this question for a similar problem. You don't need scrollability and a ResultSet will be read-only be default so just call stmt = conn.prepareStatement(query); I am testing what you suggested. Will get back once done.  I believe this must be possible on default 32 MB java heap. Just fetch each row save the data to file stream flash and close once done. Are you sure the file size would not effect the heap size usage. I am doing exactly what you are saying. I am writing record by record.  Edit: Map your database tables to Class usig JPA. Now load collection of Objects from DB using Hibernate in the Batch of some tolerable size and serialize it to FILE . Can you be a bit clearer on this?  Is your algorithm like the following? This is assuming a direct mapping between DB rows and lines in the file: // open file for writing with buffered writer. // execute JDBC statement // iterate through result set // convert rs to file format // write to file // close file // close statement/rs/connection etc Try using Spring JDBC Template to simplify the JDBC portion. How would Spring JDBC help in decreasing the memory usage which is actually being caused by a huge file write process? Using `SimpleJdbcTemplate` would fix the problem because it would give you a correctly instantiated `ResultSet` to iterate over. My personal opinion is that you should *always* use Spring for no other reason than the `DataAccessException` hierarchy @Jon Freedman - I agree that Spring helps but I preferred not to use it here since it was preety small functionality out side the actual application.  What value are you using for maxRecBeforWrite? Perhaps the query of the max record length is defeating your setFetchSize by forcing JDBC to scan the entire result for record length? Maybe you could delay writing your header and note the max record size on the fly. maxRecBeforWrite=100"
679,A,How to measure time to execute a query when using SimpleJdbcTemplate The only solution I can come up with is to write a decorator class that decorates each and every method of SimpleJdbcTemplate and logs the time taken. Do you have any thing better?? You can use Spring AOP. Check here for a tutorial on how to achieve this. +1. Write a simple aspect. We wrote an aspect to log every SQL that is being done would be very similar to time them.
680,A,"What's the problem in the next sequence of Java/SQL code? I made an update to a table in access via Java code and it doesn't work. But when I print to the console the result of executeUpdate() it shows me 1 but in the database no change. Can you tell me where's the problem please? System.out.println(""here""); PreparedStatement st = conn.prepareStatement( ""UPDATE StocProduseCuFactura SET cantitate = "" + ""cantitate - ? WHERE nume = ? and um = 'buc'""); st.setInt(1 cant); st.setString(2 p.getNume()); System.out.println(st.executeUpdate()); st.close(); I forgot to say if i run that SQL code in access it's working. are values of `cant` and `p.getNume()` correct? Also you have `= cantitate - ?`. Is that minus intentional ? Are you using transactions manually? Do you commit the transaction properly? yes they are correct. cantitate - ? is the quantity from the database minus quantity to be decreased from it before that code I just simply get the connection via drivermanager and after that i'm closing it. It's working in other cases like insert select delete but in this case - UPDATE - it prints the number of updates done but there is no difference in the database when i check it Have you ensured the transaction is commited? I don't use Transaction I use just a Connection and a PreparedStatement with executeUpdate(). But in other cases it's working and in this case too it shows me the number of updates done but in the database no difference. Trying calling the commit() method on the Connection object after you close the statement. So instead of just st.close() do: st.close(); conn.commit(); I will at further problems thank you  As others have told transaction is the area you might need to focus upon. Try setting the autoCommit to true and false explicitly and try the update query. conn.setAutoCommit(true); Moreover check for locks on the database. Some other connection might have acquired a lock and waiting for it to be committed but then in that case your update query would have not gotten fired at all. But just try restarting the database. PRoblem resolved thank you but it was my stupid mistake.  Johnny Keys is probably on the right trail. Most likely your connection isn't set to commit the transaction automatically so when you close it the transaction is rolled back and your change is removed. You might try putting conn.setAutocommit(true); at the top to see if it makes a difference. The other possibility is ""cant"" is always zero. In that case you will be setting cantitate = cantitate (i.e. no change) but update will still report every row the ""where"" clause was satisfied.  people sorry for bothering you but I realized it was my stupid mistake. There is another method after this sequence of code that made that table right as it was before the update that why I didn't see any changes. Thank you very much."
681,A,"Java connectivity with MySQL Can anyone explain me how to connect Java with MySQL? DriverManager is a fairly old way of doing things. The better way is to get a DataSource either by looking one up that your app server container already configured for you: Context context = new InitialContext(); DataSource dataSource = (DataSource) context.lookup(""java:comp/env/jdbc/myDB""); or instantiating and configuring one from your database driver directly: MysqlDataSource dataSource = new MysqlDataSource(); dataSource.setUser(""scott""); dataSource.setPassword(""tiger""); dataSource.setServerName(""myDBHost.example.org""); and then obtain connections from it same as above: Connection conn = dataSource.getConnection(); Statement stmt = conn.createStatement(); ResultSet rs = stmt.executeQuery(""SELECT ID FROM USERS""); ... rs.close(); stmt.close(); conn.close(); I think this is the old-style Driver class that works with the old-style driver mechanism. `MysqlDataSource` implements `javax.sql.DataSource` which is the newer mechanism. how come the other examples use `com.mysql.jdbc.Driver`? is this method better?  You can see all steps to connect MySQL database from JAVA application here. For other database you just need to change the driver in first step only. Please make sure that you provide right path to database and correct username and password. Visit http://apekshit.com/t/51/Steps-to-connect-Database-using-JAVA  Here's the very minimum you need to get data out of a MySQL database: Class.forName(""com.mysql.jdbc.Driver"").newInstance(); Connection conn = DriverManager.getConnection (""jdbc:mysql://localhost:3306/foo"" ""root"" ""password""); Statement stmt = conn.createStatement(); stmt.execute(""SELECT * FROM `FOO.BAR`""); stmt.close(); conn.close(); Add exception handling configuration etc. to taste.  you need to have mysql connector jar in your classpath. in Java JDBC API makes everything with databases. using JDBC we can write Java applications to 1. Send queries or update SQL to DB(any relational Database) 2. Retrieve and process the results from DB with below three steps we can able to retrieve data from any Database Connection con = DriverManager.getConnection( ""jdbc:myDriver:DatabaseName"" dBuserName dBuserPassword); Statement stmt = con.createStatement(); ResultSet rs = stmt.executeQuery(""SELECT a b c FROM Table""); while (rs.next()) { int x = rs.getInt(""a""); String s = rs.getString(""b""); float f = rs.getFloat(""c""); }  Here's a step by step explanation how to install MySQL and JDBC and how to use it: Download and install the MySQL server. Just do it the usual way. Remember the port number whenever you've changed it. It's by default 3306. Download the JDBC driver and put in classpath extract the ZIP file and put the containing JAR file in the classpath. The vendor-specific JDBC driver is a concrete implementation of the JDBC API (tutorial here). If you're using an IDE like Eclipse or Netbeans then you can add it to the classpath by adding the JAR file as Library to the Build Path in project's properties. If you're doing it ""plain vanilla"" in the command console then you need to specify the path to the JAR file in the -cp or -classpath argument when executing your Java application. java -cp .;/path/to/mysql-connector.jar com.example.YourClass The . is just there to add the current directory to the classpath as well so that it can locate com.example.YourClass and the ; is the classpath separator as it is in Windows. In Unix and clones : should be used. Create a database in MySQL. Let's create a database javabase. CREATE DATABASE javabase DEFAULT CHARACTER SET utf8 COLLATE utf8_unicode_ci; Create an user for Java and grant it access. Simply because using root is a bad practice. CREATE USER 'java'@'localhost' IDENTIFIED BY 'd$7hF_r!9Y'; GRANT ALL ON javabase.* TO 'java'@'localhost' IDENTIFIED BY 'd$7hF_r!9Y'; Yes java is the username and d$7hF_r!9Y is the password here. Determine the JDBC URL. To connect the MySQL database using Java you need an JDBC URL in the following syntax: jdbc:mysql://hostname:port/databasename hostname: The hostname where MySQL server is installed. If it's installed at the same machine where you run the Java code then you can just use localhost. It can also be an IP address like 127.0.0.1. If you encounter connectivity problems and using 127.0.0.1 instead of localhost solved it then you've a problem in your network/DNS/hosts config. port: The TCP/IP port where MySQL server listens on. This is by default 3306. databasename: The name of the database you'd like to connect to. That's javabase. So the final URL should look like: jdbc:mysql://localhost:3306/javabase Test the connection to MySQL using Java. Create a simple Java class with a main() method to test the connection. I. First we need to load the JDBC driver: try { System.out.println(""Loading driver...""); Class.forName(""com.mysql.jdbc.Driver""); System.out.println(""Driver loaded!""); } catch (ClassNotFoundException e) { throw new RuntimeException(""Cannot find the driver in the classpath!"" e); } Note that the newInstance() call is not needed here. It's just to fix the old and buggy org.gjt.mm.mysql.Driver. Explanation here. If this line throws ClassNotFoundException then the JAR file containing the JDBC driver class is simply not been placed in the classpath. Note that you don't need to load the driver everytime before connecting. Just only once during application startup is enough. II. Then we can get a connection: String url = ""jdbc:mysql://localhost:3306/javabase""; String username = ""java""; String password = ""d$7hF_r!9Y"" Connection connection = null; try { System.out.println(""Connecting database...""); connection = DriverManager.getConnection(url username password); System.out.println(""Database connected!""); } catch (SQLException e) { throw new RuntimeException(""Cannot connect the database!"" e); } finally { System.out.println(""Closing the connection.""); if (connection != null) try { connection.close(); } catch (SQLException ignore) {} } If you get a SQLException: No suitable driver then it means that either the JDBC driver wasn't loaded at all or that the JDBC URL is wrong (i.e. it wasn't recognized by any of the loaded drivers). If you get a SQLException: Connection refused or Connection timed out or a MySQL specific CommunicationsException: Communications link failure then it means that the DB isn't reachable at all. This can have one or more of the following causes: IP address or hostname in JDBC URL is wrong. Hostname in JDBC URL is not recognized by local DNS server. Port number is missing or wrong in JDBC URL. DB server is down. DB server doesn't accept TCP/IP connections. DB server has run out of connections. Something in between Java and DB is blocking connections e.g. a firewall or proxy. To solve the one or the other follow the following advices: Verify and test them with ping. Refresh DNS or use IP address in JDBC URL instead. Verify it based on my.cnf of MySQL DB. Start the DB. Verify if mysqld is started without the --skip-networking option. Restart the DB and fix your code accordingly that it closes connections in finally. Disable firewall and/or configure firewall/proxy to allow/forward the port. Note that closing the Connection is extremely important. If you don't close connections and keep getting a lot of them in a short time then the database may run out of connections and your application may break. Always acquire and close the Connection in the shortest possible scope in a try-catch-finally block. Closing in finally is just to ensure that it get closed as well in case of an exception. This also applies to Statement PreparedStatement and ResultSet. That was it as far the connectivity concerns. You can find here a more advanced tutorial how to load and store fullworthy Java model objects in a database with help of a basic DAO class. Can't we use Singleton pattern for creating connections? @Pankaj: please don't spread nonsense. Using a singleton for DB connection absolutely isn't a ""very good approach"". Using Singleton Pattern for using DB Connection resource is very good approach you can read about different ways of singleton patten at http://www.journaldev.com/1377/java-singleton-design-pattern-best-practices-with-examples @BalusC why is that? Rather than creating new connection everytime we can reuse the already created connection through Singleton pattern. What is the harm in that? @Pankaj: an on long term instable application which no one would recommend any other. See also among others http://stackoverflow.com/q/9428573/. This is #1 starters mistake. This coming from someone who pretends in his profile to have 7+ years Java/J2EE experience is just sad. @BalusC YES for web application it's good idea to go for connection pooling but for Standalone application where multi-threading is not present and we are doing some DB operations such as loading data into DB creating reports from DB etc we can reuse the connection.  String url = ""jdbc:mysql://127.0.0.1:3306/yourdatabase""; String user = ""username""; String password = ""password""; // Load the Connector/J driver Class.forName(""com.mysql.jdbc.Driver"").newInstance(); // Establish connection to MySQL Connection conn = DriverManager.getConnection(url user password); what is yourdatabase in here? database name? I will answer my own question: It is ""yourdatabase"""
682,A,"Java: ResultSet closing strategy apart from closing it in finally I am facing ORA-01000: maximum open cursors exceeded although I am closing the resultsets in finally block. But I suspect there is some trouble with my legacy code below is my pseudo-code while (someCondition) { rs1=executePreparedStatementNew(query1param1""""); //do something with rs1 rs1=executePreparedStatementNew(query2param2""""); } If the loops runs 5 times how many cursor will be opened by this code ? If I close rs1 in finally how many cursors will be closed some people say that rs1 instance for query1 will not be closed as it is masked by query2 instance. Does resultsets really gets masked this way  if so how to ensure that all the instances are closed. Appreciate any help. You haven't said where your finally block is but if it's outside the while loop then yes you will have unclosed result sets. The rs1 variable will refer to the ""latest"" result set fetched - so that's the only one which will be closed. There's nothing magical going on here - it's just the normal behaviour of variables. I would suggest that you separate each ""fetch result set and use it"" case into its own method and close the result set in a try/finally block within that method. That will make it fairly clear what's going on. @Stephen -Thanks for clearing my doubt +1 for ""nothing magical going on here"". :-) Yes my finally block is outside the while loop. I will change my code to use separate resultset but just out of curiosity is there anyway to close all the result in the above code? Will it help if I close rs1 before using it for query2 ? @Ravi - yes an explicit `rs1.close()` after you've finished with the first ResultSet would do the trick. (Calling `close()` on a closed ResultSet is defined to be a no-op so you don't have to worry about double closes in the outer `finally` block.)"
683,A,"Is there a Java API for comparing Database Schemas I'd like to compare if tables columns including datatypes and length/precision. indexes and their columns constraints in two database schemas are identical. Is there anything like this available? Maybe from one of the database migration managing tools? JDBC is the only Java API that deals with databases. You'd have to connect to both get their respective DatabaseMetaData and compare the two.  LiquiBase has database diff. But I don't know if there is an API or just the tool.  I don't know a high level API for schema comparison I used DatabaseMetaData it's not to hard to find differences i.g to retieve all tables you can do something like this: DatabaseMetaData meta = con.getMetaData(); ResultSet res = meta.getTables(null null null new String[] {""TABLE""}); System.out.println(""List of tables: ""); while (res.next()) { System.out.println( "" ""+res.getString(""TABLE_CAT"") + "" ""+res.getString(""TABLE_SCHEM"") + "" ""+res.getString(""TABLE_NAME"") + "" ""+res.getString(""TABLE_TYPE"") + "" ""+res.getString(""REMARKS"")); } res.close(); The following methods are also important for your intention: getColumns(String catalog String schemaPattern String tableNamePattern String columnNamePattern) getExportedKeys(String catalog String schema String table) getIndexInfo(String catalog String schema String table boolean unique boolean approximate) getPrimaryKeys(String catalog String schema String table)  SchemaCrawler provides a Java API that presents database metadata as plain-old Java objects. While there is no API to compare the database metadata objects but SchemaCrawler produces text (text JSON CSV HTML) output that is designed to be diff-ed using standard diff tools. Sualeh Fatehi SchemaCrawler"
684,A,Is using a JDBC scrolling strategy for paging of tabular data going to result detrimental performance? We currently have a system that displays a page tabular data on the screen without any paging support in the user interface. It is running on Java 1.5 / Spring JDBC / T-SQL stored procs / SQLServer 2000 stack. In the absence of the ability to skip rows in the result set (limitation of SQLServer 2K without using dynamic SQL); I am exploring the option of having the data layer select all rows and have the DAO layer scroll through the skipped pages of rows and then only read off a page worth of rows. My question is this: How much of a performance gain (in terms of DB CPU and I/O) is this change going to be compared with the current state where all rows are returned? I know that there will be only a page worth of data going over the wire between the DB and the Application but I am interested to know what will happen inside the DBMS. Assuming the query plan is already cached is the DBMS going to skip the processing of the first 40 pages of results if i only want page 41? I guess I'm looking to know if we incur much of a cost even though the cursor is going to skip the first x pages of the result set. Why not use a unit test to get some numbers. So you start with your current setup and have 5 tests skip 0 2 4 6 8 pages and see if there is a difference between skipping 8 and 2 pages. Then once you have a baseline why not use dynamic SQL and return just the rows that are of interest. Write another test and see what happens. Then have a stored procedure that selects everything but just returns the rows of interest and have another test for that. for your Then try the test with the idea of the DAO doing the filtering. It is difficult to give any real idea as to the performance hit the last one will have as there are many factors that we don't have but I expect that the more work you can have the stored procedure do the faster you will go overall. I tend to find unit tests useful to see what is the best option as you can then compare it under load look at what happens to the CPU and memory. You can measure whatever is important to determine which option will be best for your design. Thanks James a valid approach for sure. I guess I'm looking for a more theoretical rather than empirical answer. I want to know if the is the DBMS going to actually read data off the rows even if the cursor scrolls past it. @bart - I think it is because of my engineering background but before I make a decision I like numbers but you may want to modify your answer adding your comment here as that sounds like the real question the rest was just filler IMO.  If you have a BTree (index clustered or non-clustered) then the only way to go to page X is to know a key on the page and seek straight to it. Every other mean to 'skip' first X-1 pages will have to go trough the all the pages from 1 to X and skip each record individually. A narrow index on the 'paged' field can help to count as high density slots (hence the narrow index) reduce the number of pages that have to be scanned to find the row that starts the page X. Thanks Remus I recognize that the cursor that drives the data access is going to have to skip to the row that corresponds to the first row of page x. When we use JDBC to scroll to row (x * pagesize ) does this mean that the SQLServer is going to read from the disk all of the blocks for rows from page 0 to page x-1? If you want to skip 1000 rows SQL has to count 1000 rows on 'disk' so it can locate the row you're interested. I say 'disk' because is not necessarily disk access it can be cached in the buffer pool. Thanks Remus - I've got it now.
685,A,"c3p0 acronym origin - jdbc connection pool name Can anyone share the origin and meaning of the jdbc connection pool named c3p0. Was it inspired from star wars?. Quoting Steve Waldman (C3P0 Developer) in the Hibernate forums: re: why c3p0? mostly because it began as an attempt to see how hard it would be to implement connection pooling as defined by the JDBC 3.0 specification. Connection Pooling 3.0 --> cp30 --> c3p0. Also I was working on a (never completed and now obseleted) project for easy-to-use access to berkeley db from java and that was called bdbd. A robot in an old television show (Buck Rogers) always said ""bdbd"" and c3p0 was a robot too. The pairing of names was a private little joke."
686,A,"Why do I keep on getting an exception-illegal operation on ResultSet? Why do I keep on getting an exception-illegal operation on ResultSet? Here is the code: /* * To change this template choose Tools | Templates * and open the template in the editor. */ /* * SearchParts.java * * Created on 08-Mar-2010 12:14:31 */ package garits; import java.sql.*; import javax.swing.*; /** * * @author Deniz */ public class SearchParts extends javax.swing.JFrame { /** Creates new form SearchParts */ public SearchParts() { initComponents(); } /** This method is called from within the constructor to * initialize the form. * WARNING: Do NOT modify this code. The content of this method is * always regenerated by the Form Editor. */ @SuppressWarnings(""unchecked"") private void jButton1ActionPerformed(java.awt.event.ActionEvent evt) { if (!jTextField1.getText().equals("""")) { String result = """"; int Partnumber = Integer.parseInt(jTextField1.getText()); DB db = new DB(); try { db.connect(); String query = ""Select * from Stock Where Part_no ="" + ""'"" + jTextField1.getText() + ""'""; ResultSet rs = db.execSQL(query); if (rs.equals(null)) { PartNotFound nf = new PartNotFound(); nf.setVisible(true); } else { ResultSetMetaData rsmd = rs.getMetaData(); int numberOfColumns = rsmd.getColumnCount(); int RowCount = 0; for (int i = 1; i < numberOfColumns; i++) { rs.getString(i); result += i + ""/n""; } if (!result.equals("""")) { Receptionist_FranchiseePartFound part = new Receptionist_FranchiseePartFound(); part.setVisible(true); while (rs.next()) { RowCount++; } part.getTable().addRowSelectionInterval(0 RowCount); } else { PartNotFound nf = new PartNotFound(); } } } catch (Exception e) { e.printStackTrace(); JOptionPane.showMessageDialog(jButton1 ""More information needed for search"" ""Error Message"" JOptionPane.ERROR_MESSAGE); } } else if (!jTextField2.getText().equals("""")) { String result = """"; DB db = new DB(); try { db.connect(); String query = ""Select * from Stock Where Part_name ="" + ""'"" + jTextField2.getText() + ""'""; ResultSet rs = db.execSQL(query); if (rs.equals(null)) { PartNotFound nf = new PartNotFound(); nf.setVisible(true); } else { ResultSetMetaData rsmd = rs.getMetaData(); int numberOfColumns = rsmd.getColumnCount(); int RowCount = 0; for (int i = 1; i < numberOfColumns; i++) { rs.getString(i); result += i + ""/n""; } // Receptionist_FranchiseePartFound part = new Receptionist_FranchiseePartFound(); // part.setVisible(true); if (!result.equals("""")) { Receptionist_FranchiseePartFound part = new Receptionist_FranchiseePartFound(); part.setVisible(true); while (rs.next()) { RowCount++; } part.getTable().addRowSelectionInterval(0 RowCount); } else { PartNotFound nf = new PartNotFound(); nf.setVisible(true); } } } catch (Exception e) { e.printStackTrace(); JOptionPane.showMessageDialog(jButton1 ""More information needed for search"" ""Error Message"" JOptionPane.ERROR_MESSAGE); } } else if (jTextField1.getText().equals("""") && jTextField2.getText().equals("""")) { String result = """"; DB db = new DB(); try { db.connect(); String query = ""Select * from Stock Where Manufacturer ="" + ""'"" + jTextField3.getText() + ""'AND Vehicle_type ='"" + jTextField4.getText() + ""'""; ResultSet rs = db.execSQL(query); if (rs.equals(null)) { PartNotFound nf = new PartNotFound(); nf.setVisible(true); } else{ ResultSetMetaData rsmd = rs.getMetaData(); int numberOfColumns = rsmd.getColumnCount(); int RowCount = 0; for (int i = 1; i < numberOfColumns; i++) { rs.getString(i); result += i + ""/n""; } // Receptionist_FranchiseePartFound part = new Receptionist_FranchiseePartFound(); // part.setVisible(true); if (!result.equals("""")) { Receptionist_FranchiseePartFound part = new Receptionist_FranchiseePartFound(); part.setVisible(true); while (rs.next()) { RowCount++; } part.getTable().addRowSelectionInterval(0 RowCount); } else { PartNotFound nf = new PartNotFound(); nf.setVisible(true); } } } catch (Exception e) { e.printStackTrace(); JOptionPane.showMessageDialog(jButton1 ""More information needed for search"" ""Error Message"" JOptionPane.ERROR_MESSAGE); } } else if (jTextField3.getText().equals("""") || jTextField4.getText().equals("""")) { JOptionPane.showMessageDialog(jButton1 ""More information needed for search"" ""Error Message"" JOptionPane.ERROR_MESSAGE); } } /** * @param args the command line arguments */ // Variables declaration - do not modify private javax.swing.JButton jButton1; private javax.swing.JButton jButton2; private javax.swing.JLabel jLabel1; private javax.swing.JLabel jLabel2; private javax.swing.JLabel jLabel3; private javax.swing.JLabel jLabel4; private javax.swing.JLabel jLabel5; private javax.swing.JLabel jLabel6; private javax.swing.JLabel jLabel7; private javax.swing.JLabel jLabel8; private javax.swing.JTextField jTextField1; private javax.swing.JTextField jTextField2; private javax.swing.JTextField jTextField3; private javax.swing.JTextField jTextField4; // End of variables declaration } sorry for the typos at the beginning. it would help if you could take out the swing code and trim down your error to a few lines There's an `edit` link at bottom of the question. Make use of it. And the error is probably in the DB class as its sql related. You need to at least provide a stack trace and the line on which the exception is occuring. Remove the following line it serves no purpose. Its trying to the the column value from the ResultSet but you haven't scrolled to the first row yet  rs.getString(i); I think the intent is `result += rs.getString(i) + ""\n""`.  You always need to call next() on the ResultSet before accessing it. If not the pointer points to the row before the first. You do this with while-loops in your code but some places you dont which generates an error: for (int i = 1; i < numberOfColumns; i++) { rs.getString(i); result += i + ""/n""; } Ohh and as another poster mentions you dont assign the result to a variable so the rs.getString(i) call has no effect. But this is probably your source of error.  if rs is null then rs.equals(null) will throw a NullPointerException instead of returning false. Nevertheless if that is not the exception you are getting then the problem lies somewhere else. In this case `rs` would never be `null`. I suspected so but given that the call is behind a custom class I couldn't be certain.  Also take a look into the javadoc/code for the DB class' execSQL(query) method. Typically a ResultSet is never null e.g. like when you use PreparedStatement.executeQuery. However check into the that execSQL method to verify whether or not it will ever return a null ResultSet. THANKS EVERYONE  I see a few things First rs is never null. If there are no rows then rs.next() will return false ResultSet starts position BEFORE the first row. You need to call rs.next() to move to the first row which as above will return false if there are no rows. The typical pattern for ResultSet use is... while (rs.next()) { rs.getXXX(); } ResultSet should ALWAYS be close()d when you are done otherwise you may leak database resources. This also applies to Connection Statement PreparedStatement so check your DB code in other classes. When looping over the column metadata you need to do.. for (int i = 1; i <= numberOfColumns; i++) { } Note the <= rather than <. As you have correctly found that JDBC column indexes start at 1. It would be worth considering using a library that hides all the JDBC noise. Consider spring which has a basic JDBC abstraction while retaining all the power or all the way up to hibernate which is very powerful but has quite a learning curve. In your case I'd recommend just use the spring stuff. See: Spring docs Also it would be good to note that when checking an object reference for `null` to use normal `==` instead of `equals()` (i.e. `rs == null` instead of `rs.equals(null)`). In fact using the equals form here should also be `false` because of the contract on equals or throw an exception if `rs` really was `null`.  Several have pointed out some of your problems in the code. The reason for your exception is because you have not advanced to the first row using rs.next(). If you expect that your SQL statement will only retrieve a single row then you probably should change your rs.equals(null) statement to: if (!rs.next()) { ...code here to set not found... } else { ...code here to retrieve the columns... } Here are some other tips. In the code to retrieve the columns your use of rs.getString(i) doesn't do anything the result variable is just accumulating the column numbers with ""/n"" (not new-line; probably that should be ""\n""). So the loop inside that section should probably become: for (int i = 1; i <= numberOfColumns; i++) { result += rs.getString(i) + ""\n""; } But concatenating to a immutable String is not good and can result in slow execution for large numbers of concatenations. Use a StringBuilder instead and initialize it to a reasonable size something like this: StringBuilder sb = new StringBuilder(256); for (int i = 1; i <= numberOfColumns; i++) { sb.append(rs.getString(i)).append(""\n""); } result = sb.toString(); Later you loop through the results set so in the loop through the columns are you trying to get column names from the meta data? In that case: StringBuilder sb = new StringBuilder(256); for (int i = 1; i <= numberOfColumns; i++) { sb.append(rsmd.getColumnName(i)).append(""\n""); } result = sb.toString(); But since you need to check for the first row the next loop will not count the number of rows correctly so you will need to adjust for that perhaps (and there is no need to check result at that point since it is guaranteed to no longer be an empty string since there must be at least one column in the table): do { RowCount++; // recommend using rowCount. } while (rs.next()); In the end what are you using result for? It seems that this is just used to determine if there were some columns in the result. If that is all then you can eliminate most of this code. For what you actually have (I don't know if this is your intent) this could be reduced to (in the else if where you do the DB interaction): DB db = new DB(); try { db.connect(); String query = ""select count(1) from Stock where Part_name ="" + ...; ResultSet rs = db.execSQL(query); if (!rs.next()) { PartNotFound nf = ...; nf.setVisible(true); } else { Receptionist_FranchiseePartFound part = new Receptionist_FranchiseePartFound(); part.setVisible(true); rowCount = rs.getInt(1); part.getTable().addRowSelectionInterval(0 rowCount); } } catch (Exception e) { ...error handling with stack trace/JOptionPane... } Note that if you are just after the count of rows then it is best to let the database engine do that for you - looping through the result rows just to count them also means that all that data must be sent to your application. Instead if you just use the aggregate function then the database only needs to send a single row and column to your application."
687,A,How can I see the generated SQL from my Spring StoredProcedure? I have an org.springframework.jdbc.object.StoredProcedure which I am using to call a DB function. I want to be able to see the generated SQL. I am calling org.springframework.jdbc.object.SqlCall.getCallString() on my StoredProcedure object but this returns a String with ? characters in place of the parameters. How can I get the complete SQL with the parameters included? You can't that's not how stored procedures work. The application sends the arguments separately from the call string. What you can do however is turn your logging up to DEBUG you should see Spring logging the individual arguments as it sets them.
688,A,java.sql.SQLWarning: [Microsoft][SQLServer 2000 Driver for JDBC]Database changed to X I'm using Hibernate 3.2.1 and database SQLServer2000 while I'm try to insert some data using my dao some warning occurred like this: java.sql.SQLWarning: [Microsoft][SQLServer 2000 Driver for JDBC]Database changed to BTN_SPP_DB at com.microsoft.jdbc.base.BaseWarnings.createSQLWarning(Unknown Source) at com.microsoft.jdbc.base.BaseWarnings.get(Unknown Source) at com.microsoft.jdbc.base.BaseConnection.getWarnings(Unknown Source) at org.hibernate.util.JDBCExceptionReporter.logAndClearWarnings(JDBCExceptionReporter.java:22) at org.hibernate.jdbc.ConnectionManager.closeConnection(ConnectionManager.java:443) at org.hibernate.jdbc.ConnectionManager.aggressiveRelease(ConnectionManager.java:400) at org.hibernate.jdbc.ConnectionManager.afterTransaction(ConnectionManager.java:287) at org.hibernate.jdbc.JDBCContext.afterTransactionCompletion(JDBCContext.java:221) at org.hibernate.transaction.JDBCTransaction.commit(JDBCTransaction.java:119) at co.id.hanoman.btnmw.spp.dao.TagihanDao.save(TagihanDao.java:43) at co.id.hanoman.btnmw.spp.dao.TagihanDao.save(TagihanDao.java:1) at co.id.hanoman.btnmw.spp.dao.test.TagihanDaoTest.testSave(TagihanDaoTest.java:81) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.junit.internal.runners.TestMethodRunner.executeMethodBody(TestMethodRunner.java:99) at org.junit.internal.runners.TestMethodRunner.runUnprotected(TestMethodRunner.java:81) at org.junit.internal.runners.BeforeAndAfterRunner.runProtected(BeforeAndAfterRunner.java:34) at org.junit.internal.runners.TestMethodRunner.runMethod(TestMethodRunner.java:75) at org.junit.internal.runners.TestMethodRunner.run(TestMethodRunner.java:45) at org.junit.internal.runners.TestClassMethodsRunner.invokeTestMethod(TestClassMethodsRunner.java:66) at org.junit.internal.runners.TestClassMethodsRunner.run(TestClassMethodsRunner.java:35) at org.junit.internal.runners.TestClassRunner$1.runUnprotected(TestClassRunner.java:42) at org.junit.internal.runners.BeforeAndAfterRunner.runProtected(BeforeAndAfterRunner.java:34) at org.junit.internal.runners.TestClassRunner.run(TestClassRunner.java:52) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:45) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196) my hibernate initialization log is: 2010-04-26 22:54:05203 INFO [Version] Hibernate Annotations 3.3.0.GA 2010-04-26 22:54:05234 INFO [Environment] Hibernate 3.2.1 2010-04-26 22:54:05234 INFO [Environment] hibernate.properties not found 2010-04-26 22:54:05234 INFO [Environment] Bytecode provider name : cglib 2010-04-26 22:54:05234 INFO [Environment] using JDK 1.4 java.sql.Timestamp handling 2010-04-26 22:54:05343 INFO [Configuration] configuring from resource: /hibernate.cfg.xml 2010-04-26 22:54:05343 INFO [Configuration] Configuration resource: /hibernate.cfg.xml 2010-04-26 22:54:05406 DEBUG [DTDEntityResolver] trying to resolve system-id [http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd] 2010-04-26 22:54:05406 DEBUG [DTDEntityResolver] recognized hibernate namespace; attempting to resolve on classpath under org/hibernate/ 2010-04-26 22:54:05406 DEBUG [DTDEntityResolver] located [http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd] in classpath 2010-04-26 22:54:05453 DEBUG [Configuration] hibernate.dialect=org.hibernate.dialect.SQLServerDialect 2010-04-26 22:54:05453 DEBUG [Configuration] hibernate.connection.driver_class=com.microsoft.jdbc.sqlserver.SQLServerDriver 2010-04-26 22:54:05453 DEBUG [Configuration] hibernate.connection.url=jdbc:microsoft:sqlserver://12.56.11.65:1433;databaseName=BTN_SPP_DB 2010-04-26 22:54:05453 DEBUG [Configuration] hibernate.connection.username=spp 2010-04-26 22:54:05453 DEBUG [Configuration] hibernate.connection.password=spp This says: This is a normal message from the MS jdbc driver when the database that you are using for JM isn''t the default database for the sql server account you are using to access the database. Pretty much ignore it - it''s completely harmless.
689,A,"Populate JSP dropdown with database info I'm trying to populate a JSP dropdown from a database table. Here's the code that will create the array and fill it with the database info: // this will create my array public static ArrayList<DropDownBrands> getBrandsMakes() { ArrayList<DropDownBrands> arrayBrandsMake = new ArrayList<DropDownBrands>(); while (rs.next()) { arrayBrandsMake.add(loadOB(rs)); } return arrayBrandsMake; } // this will load my array object private static DropDownBrands loadOB(ResultSet rs) throws SQLException { DropDownBrands OB = new DropDownBrands(); OB.setBrands(""BRAN""); return OB; } How do I call that class from my JSP and populate the dropdown? I would suggest trying to stay away from mixing the display and model code. Keep all of your html in the jsp page and create model backing objects that provide the information you need. For example let's say you have a simple Java class that has a list of objects: package com.example; import java.util.ArrayList; import java.util.List; public class ListBean { public List<String> getItems() { List<String> list = new ArrayList<String>(); list.add(""Thing1""); list.add(""Thing2""); list.add(""Thing3""); return list; } } It doesn't matter how the getItems method constructs the list that it is returning. To display these items in the JSP Page using JSTL you would do the following: <%@ page language=""java"" contentType=""text/html; charset=ISO-8859-1"" pageEncoding=""ISO-8859-1""%> <%@taglib uri=""http://java.sun.com/jsp/jstl/core"" prefix=""c""%> <!DOCTYPE html PUBLIC ""-//W3C//DTD HTML 4.01 Transitional//EN"" ""http://www.w3.org/TR/html4/loose.dtd""> <html> <head> <meta http-equiv=""Content-Type"" content=""text/html; charset=ISO-8859-1""> <title>Insert title here</title> </head> <body> <jsp:useBean id=""obj"" class=""com.example.ListBean"" scope=""page""/> <select> <c:forEach var=""item"" items=""${obj.items}""> <option>${item}</option> </c:forEach> </select> </body> </html> Instead of using useBean the items collection used in the forEach loop could also come from the session or a request object. This link also has good advice: http://java.sun.com/developer/technicalArticles/javaserverpages/servlets_jsp/ Just compare with the current item inside the loop and print `selected` accordingly? This is what i do when the dropdown option are hard coded how it will be with the database option ${item} >Additional i try something like this but give an error that cannot convert a string to bolean >${item} and how i can show the value choosen by the user when the form is load lets said that the user choose option 2 and i search for a record how when it load i make to display the option selected by the user i know how to do this when the value hard coded in the drop down value. I am assuming that auto.getCustomerData2() is returning a string? It doesn't know how to evaluate that to True or False. You should take a look at the JSTL string functions (http://java.sun.com/products/jsp/jstl/1.1/docs/tlddocs/fn/tld-summary.html). You could than do something like fn:length(auto.getCustomerData2()) > 0 ? ""selected"" : """". Or add another method to your class that returns a boolean like auto.hasCustomerData2() ?  First in your JSP import the class you are trying to use: <%@ page import=""com.mypackage.MyClass"" %> Then you can use that class as you would normally do: <% MyClass c = new MyClass(); c.getSomeProperty(); %> To fill the control you iterate your array and set the value argument of the option tag: <select> <%while (myList.next()){%> <option><%out.print(c.getName());%></option> <%}%> </select> As you can see there's mixed Java code and HTML. First it outputs the select tag then on Java code there's a while loop iterating a list of objects. This could be your ResultSet an array or some other collection. For each iteration it creates an option tag with some value this would be the value you want the user to see. This is the basic approach using only JSP. But there are many tag libraries for example JSTL that provide things like iteration so you can write things like: <select name=""mySelect""> <foreach collection=""<%= myCollection %>"" var=""mybean""> <%= mybean.getOptionTag() %> </foreach> </select>"
690,A,PostgreSQL query for current minute My web application needs to get the results of all the items which have their time value for this minute. My table has a time attributes id message time ... where time is of type timestamp with timezone. I need to get a list of all entries where the time is the current minute. Comparing the entire value does not match because the timestamp has microsecond resolution. Currently I am using the following query to return this list and it works but I think there should be a more efficient way of doing this. SELECT * FROM notification WHERE date_part('year' time) = date_part('year' current_date) AND date_part('month' time) = date_part('month' current_date) AND date_part('day' time) = date_part('day' current_date) AND date_part('hour' time) = date_part('hour' current_time) AND date_part('minute' time) = date_part('minute' current_time); I'd also like to know how to get the results for the this and the previous minute or the last 'n' minutes. Database is PostgreSQL 8.4.3 Thanks What about simply comparing the truncated timestamps? SELECT * FROM notification n WHERE date_trunc('minute' n.time) = date_trunc('minute' current_timestamp); I doubt that the optimizer is clever enough to make use of an index on the time column using this approach though. If you have such an index then you should probably use Lukáš Lalinský's suggestion if you want better performance. Depends how much data you have really.  I'd try something like this: WHERE time >= date_trunc('minute' now()) AND time < date_trunc('minute' now()) + INTERVAL '1 minute'; This will define the boundaries and search for times within that range which means it still can use the index you have (or should have) on the time column. This is exactly what I was looking for. I am able to check for the last n minutes just by changing the interval amount. Thanks... One question relating to this is Postgres smart enough to figure if the hour wraps around? Let's say there's an entry at 11:59 will a query at 12:00 for t he past 2 minutes return that result? Or does it just use the minute field for comparison? Any operation that is done using the `INTERVAL` type will be smart enough to time/calendar calculations like that correctly.
691,A,"Handling large records in a Java EE application There is a table phonenumbers with two columns: id and number. There are about half a million entries in the table. Database is MySQL. The requirement is to develop a simple Java EE application connected to that database that allows a user to download all numbervalues in comma separated style by following a specific URL. If we get all the values in a huge String array and then concatenate them (with comma in between all the values) in a String and then send it down to the user does it sound a proper solution? The application is not public and will be used by a limited no. of people. Having half a million comma separated list of values does not sound good to me. May be newline separated is okay so that user can easily open this file in text editor if required. But this depends on how users wants to use this list of values. Can you please elaborate on user requirements? CSV is a user requirement because it is supported by MS Excel. I am not sure how they are going to use it probably they would use it for reporting purpose. CSV's map to columns in excel. If you have half a million CSV entries then how is going to open correctly in excel? Excel does not have half a million columns. You need to as users how are they going to use it. Most of the time users are not sure of their requirements. If using Mysql 5.1+ I would simply use the proprietary syntax to dump the file somewhere and stream it in a Servlet response. SELECT aba+b INTO OUTFILE '/tmp/result.txt' FIELDS TERMINATED BY '' OPTIONALLY ENCLOSED BY '""' LINES TERMINATED BY '\n' FROM test_table; http://dev.mysql.com/doc/refman/5.1/en/select.html For so many records if you still want to use JDBC you may try the following: fetch the number of records fetch few records( using a query limit ) and write them if you reach the number of records in a chunk you fetch another one until you reach the maximum number of records Assuming the web server shares a file system with the DB. In many deployment scenarios it does not. True indeed Eric J. In my case as well DB and application are running on different machines. I believe my JDBC suggestion is among the same lines as the fetch size suggestion for the query to avoid caching the all thing in memory and avoid the filesystem sharing issue.  Your best bet is to not store the data in Java's memory in any way but just write the obtained data to the response immediately as the data comes in. You also need to configure the MySQL JDBC driver to serve the resultset row-by-row by Statement#setFetchSize() as per the MySQL JDBC driver documentation otherwise it will cache the whole thing in memory. Assuming you're familiar with Servlets here's a kickoff example which takes that all into account: protected void doGet(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { response.setContentType(""text/plain""); response.setHeader(""Content-Disposition"" ""attachment;filename=numbers.txt""); // Force download popup. Connection connection = null; Statement statement = null; ResultSet resultSet = null; Writer writer = response.getWriter(); try { connection = database.getConnection(); statement = connection.createStatement(ResultSet.TYPE_FORWARD_ONLY ResultSet.CONCUR_READ_ONLY); statement.setFetchSize(Integer.MIN_VALUE); resultSet = statement.executeQuery(""SELECT number FROM phonenumbers""); while (resultSet.next()) { writer.write(resultSet.getString(""number"")); if (!resultSet.isLast()) { writer.write(""""); } } } catch (SQLException e) { throw new ServletException(""Query failed!"" e); } finally { if (resultSet != null) try { resultSet.close; } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close; } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close; } catch (SQLException logOrIgnore) {} } } I agree on ""write the obtained data to the response immediately as the data comes in"" Thank you BalusC. This is exactly what I wanted!  There's a bit more to properly formatting CSV output. It would be easiest to use an existing library such as this one to generate the output file. You can generate output to a file on disk (on the web server) and then redirect the browser to that file (with a cron job or whatever to clean up old data) or just stream the result directly back to the user. If you are streaming directly be sure and set the MIME type to something that will trigger a download in the user's browser (e.g. text/csv or text/comma-separated-values) I agree but just want to add http://supercsv.sourceforge.net/ as a free alternative CSV reader/writer library I never worked with CSV before. Can you please elaborate why do we need a full library for this purpose as apparently it only seems to be writing values separated by commas with a Writer (as can be seen in BalusC's example)? In the general case your data can contain commas which throw off the field order if not properly handled since fields are separated by commas. To handle that you quote your fields that might contain commas. Then again your data might contain quote characters which throws off the quoting if not properly handled. You have to escape the quotes. Rather than do this by hand I find it easier to use a pre-existing library. If you are 100% confident your data will never contain a quote or comma (including typos) you can just write your fields separated by commas."
692,A,"unable to update CLOB using DBCP connection Am trying to do update a clob column using a connection object that is retrieved using Apache DBCP connection pooling. Earlier I've implemented connection pooling using this and it was working fine i.e am able to update CLOB. I switched to DBCP because I was getting java.sql.SQLException: ORA-01000: maximum open cursors exceeded. I've checked connection resultSet preparedStatement objects in all the DAOs. All the finally blocks have these cursors closed. Still am facing this error and so decided to switch to DBCP. But when I try to update CLOB with this DBCP connection the application just hangs at pstmt.executeUpdate(). Connection conn = null; PreparedStatement pstmt = null; CLOB clob = null; String q = ""UPDATE REPORT_TABLE SET RPT_FILE = ? WHERE RPT_SEQ_NUM = ?""; ... conn = DBConnection.getConnection(); pstmt = conn.prepareStatement(q); clob = getCLOB(xmlReport conn); pstmt.setObject(1 clob); pstmt.setString(2 reportSeqNo); if (pstmt.executeUpdate() == 1) { logger.logError(""Report has been successfully UPDATED""); } ... where getCLOB() method is: private CLOB getCLOB(String xmlData Connection conn) throws SQLException{ CLOB tempClob = null; try{ // If the temporary CLOB has not yet been created create new tempClob = CLOB.createTemporary(conn true CLOB.DURATION_SESSION); // Open the temporary CLOB in readwrite mode to enable writing tempClob.open(CLOB.MODE_READWRITE); // Get the output stream to write Writer tempClobWriter = tempClob.getCharacterOutputStream(); // Write the data into the temporary CLOB tempClobWriter.write(xmlData); // Flush and close the stream tempClobWriter.flush(); tempClobWriter.close(); // Close the temporary CLOB tempClob.close(); } catch(SQLException sqlexp){ tempClob.freeTemporary(); sqlexp.printStackTrace(); } catch(Exception exp){ exp.printStackTrace(); tempClob.freeTemporary(); exp.printStackTrace(); } return tempClob; } I've also tried by passing the ((DelegatingConnection) conn).getInnermostDelegate() connection but no use. Also I tried what Shiny has suggested here. This time its hanging while I'm selecting the data. Am using Oracle 9i and the JDBC Oracle Driver version is above 10(Sorry couldn't remember exact version now). Could you show your getCLOB method (and what datatype is ""xmlReport""?)? have you tried using the PreparedStatement.setClob method instead of setObject ?  OTN has some documentation on clob handling in Oracle JDBC that may be helpful.  With the Oracle JDBC driver you can't use setClob(). It won't throw an error but it also won't work. The reason behind this is that the JDBC driver will try to read your Clob stream inside the executeUpdate(). So you must open the stream before the update run the update and then close the stream afterwards. Therefore I always use select RPT_FILE ... for update and then:  ResultSet rs = null; try { rs = stmt.executeQuery (); rs.next (); Clob clob = rs.getClob (1); clob.truncate (0); clob.setString (1 data); } finally { rs = DBUtil.close (rs); } You can replace setString() with the methods to read/write the CLOB as a stream. That always works and doesn't leak cursors (because of bugs in Oracle's JDBC driver). But the key is always the same: You must get a CLOB object from Oracle. Never try to create one of them yourself."
693,A,Using Db2Mon is there a way to distinguish between clients connecting using type 2 and type 4 driver? Well The question explains all Using DB2mon tool Is there a way to tell which client is connecting using which type of connection (type 2 jdbc or type 4 jdbc connection)? All of the connections are showing as db2jcc process which is the common driver for both type 2 and type 4. Also if there is a way to find out whether is connection is UDP or TCP/IP it can be helpful too as the type 2 is UDP based. It is not possible to find out which type of driver the user is using from db2mon. You can see only the username with which the user loggedin
694,A,Choosing betwen JDBC or ADO.NET performance studies on Oracle We are starting a new project wich talks to an Oracle database with millions of data. The system is mission critical and should be highly performant. We are now choosing the technologies that will be involved in the system and we are doubting between JDBC or ADO.NET for data access. Wich technlogy is most performant? Are there any studies that test both technologies with Oracle database? Thanks I feel like the bulk of your time in a query is going to be spent waiting on Oracle I have a hard time believing your API of choice is going to be the bottleneck you will care about in the long haul. Besides isn't this a function of your development environment way more than it is of performance?  Either JDBC or ADO.NET works just fine. Oracle's JDBC drivers are really good; so are the ADO.NET drivers. Do your best to obtain the latest driver versions that are compatible with your server. Your choice (JDBC/ADO.NET) should be dictated by the implementation technology of the rest of your client software. If you're building a dot Net (in a Visual Studio environment) app use ADO.NET. If you're building a Java client (e.g. in Eclipse) use JDBC. Where you will run into performance trouble is if you try to build a heterogeneous client trying to use software gaffer tape to attach JDBC to a C++ program or ADO.NET to a Java program. That will be slower and more unstable. For example Crystal Reports claims to be able to use JDBC data connectors but they have an inefficient adapter between their native code and Java. I totally agree however the client is requesting us performances test to complete our reasoning even if those documents say that both are equal in perfomance terms. I haven't found anything that compares performance between ado.net and jdbc
695,A,"How to find the offending insertion from a BatchUpdateException? When I have a BatchUpdateException as the result of a unique constraint violation is there a way for me to determine which record in the batch insert is in violation? For example let's say I'm performing a batch insert by calling PreparedStatement.executeBatch() and I catch the BatchUpdateException which has as it's cause ""ORA-00001: unique constraint (ABC.SYS_123) violated"". When debugging using Eclipse this is about as much info as I can coax from this exception but I'd like to find out which actual insert is causing the violation of the unique constraint. Is there a way I can find this information? My code currently looks (more or less) like this: public void batchInsert(final Collection<MyObject> objectCollection) { try { if (connection == null) { connection = getJdbcTemplate().getDataSource().getConnection(); } // get the last entity ID value so we can know where to begin Long entityId = getJdbcTemplate().queryForLong(""SELECT MAX("" + MyObject.ID_COLUMN_NAME + "") FROM "" + MyObject.TABLE_NAME); entityId++; // get a date to use for the created and updated dates Date now = new Date(new java.util.Date().getTime()); // set auto commit to false so we can batch save without committing each individual insert connection.setAutoCommit(false); // create the prepared statement String insertSql = ""INSERT INTO "" + MyObject.TABLE_NAME + "" ("" + MyObject.ID_COLUMN_NAME + "" VALUE_1 VALUE_2) "" + ""VALUES (? ? ?)""; PreparedStatement preparedStatement = connection.prepareStatement(insertSql); // add a batch entry for each of the SurfaceMetObservations objects for (MyObject object : objectCollection) { preparedStatement.setLong(1 entityId); preparedStatement.setBigDecimal(2 object.getValue1()); preparedStatement.setBigDecimal(3 object.getValue2()); preparedStatement.addBatch(); entityId++; } int updateCounts[] = preparedStatement.executeBatch(); preparedStatement.close(); if (confirmUpdateCounts(updateCounts)) { connection.commit(); } else { connection.rollback(); throw new RuntimeException(""One or more inserts failed to execute.""); } } catch (SQLException ex) { throw new RuntimeException(ex); } } I am using Spring's JdbcTemplate and an Oracle 11G database in case that is relevant. Thanks in advance for any advice. --James From the Java API documentation of BatchUpdateException: After a command in a batch update fails to execute properly and a BatchUpdateException is thrown the driver may or may not continue to process the remaining commands in the batch. If the driver continues processing after a failure the array returned by the method BatchUpdateException.getUpdateCounts will have an element for every command in the batch rather than only elements for the commands that executed successfully before the error. In the case where the driver continues processing commands the array element for any command that failed is Statement.EXECUTE_FAILED. Now I'm unsure about the behavior of the Oracle JDBC driver that you are using but it is apparent that either of the techniques mentioned should work - if there are N elements in the array returned by the call to BatchUpdateException.getUpdateCounts then N elements in the batch have been processed. Or if the array returned has the same size as the number of batched statements then all the array elements whose value is Statement.EXECUTE_FAILED would have failed execution in the batch. Glad to be of help :) Thanks Vineet for bringing this very helpful information to my attention. Very much appreciated!"
696,A,"Is there a set of stubs/mocks for JDBC available anywhere? For the past few years I've continuously struggled with unit testing database code and all the pain that comes with it. I found this existing thread which I found very enlightening: What's the best strategy for unit testing databases? The author of the accepted answer suggests that it might be useful to mock the entire database layer in order to validate the generated SQL. I didn't think much of it when I first read the answer a few months ago but recently I have observed several bugs caused by incorrectly generated SQL wrongly assigned fields and so on. I do realize that JDBC is rather bloated and error prone to use but it isn't an option to switch to something different at this point. The application in question is a batch processor of data feeds and uses JDBC directly rather than an ORM. All JDBC code is separated into distinct DAO objects where each object has its own interface and stub besides the actual implementations. This has allowed me to achieve good test coverage of the business layer but the testing of the database layer is virtually non-existant. Is there an existing stub implementation of the JDBC (java.sql) interfaces that can be injected into DAO classes and used to validate the generated SQL and possibly send back some preprogrammed results? You could test the database directly with dbunit.  I see no purpose for mocking the java.sql interfaces in DAOs. After all when you're unit testing those you really do want them to connect to the database and bring something back. I can see using HSQL or Derby or an in-memory database as Skaffman suggests but I see no point at all for mocking ResultSet or Connection. Once you've unit tested the DAO I can see where you'd mock the whole thing for your service test. Using mocking for an interface in java.sql seems wrong to me.  I don't know if you have seen it or not but there's MockRunner. It provides many classes that implement the interfaces of JDBC (as well as other J2EEclasses). Here's the JDBC mock objects. There are also quite a few examples. A nice find thanks. You're welcome. Have fun. Seems really interesting. I'll take a closer look and see if it's what I'm looking for.  It sounds like you're having issues in the DAO code itself? Otherwise the DAO layer is the obvious place to do your mocking but if you're trying to test the DAO then you'll need to mock that which comes beneath. Personally I tend to stay away from mocking large complex libraries; if you really need to test the DAO layer directly and the DAO works directly with JDBC you've got three obvious choices: Run an integrated test that includes the DAO and JDBC along with a Database Add a layer above JDBC with a thinner interface better suited for mocking. Use JDBC mocks either of your own writing or some of the items listed above. I would almost always choose #1 or #2. Because there's a host of possibilities of errors in malformed SQL syntax and the like I tend to lean towards #1. I realize however that that's not what you're asking for. ;) Sometimes I unit test my DAOs using a throwaway in-memory HypersonsonicDB datasource. The obvious flaw in that idea is that it's no use with database-proprietary SQL but it's useful for testing Hibernate configurations. As I said in the question: I already have mocks for the DAO layer that I use when testing the business layer. I'll consider your advice though. Thanks for your time. :)  If you want to test persistence layer (ORM DAO ...) is acting as expected according various JDBC cases (e.g. when it gets such result set/update count then it should do this and that) then Acolyte framework must be considered. It allow to build JDBC connection you manage throught handler so you choose what is returned for each query/update: https://github.com/cchantep/acolyte  While I'm a huge fan of unit testing in general I've found it to be of limited value with DAOs. What I've seen is while it is entirely possible to write the tests (using any of the mocking APIs - JMock EasyMock etc) they typically work straight-off (the logic is so basic how couldn't they) only breaking when you change the code (adding a value for example) and that just makes them a burden on the code base. I think this is because my DAOs typically follow the form: get connection. create statement. set values. read values (for load operations). clean-up. You then make assumptions about how the JDBC driver will/is work(ing) and you get a test that's really doing nothing more than testing some simple code gets called in the order it is declared. Errors originating from DAOs typically occur within the database (key violations bugs in stored procs etc) and unless you are running the system as a whole you aren't going to see these errors. These days I tend to let the higher levels of testing - integration and the like - exercise the DAO code hitting the actual database in doing so and hopefully catching the sort of errors I mentioned sooner rather than later.  jOOQ ships with a MockConnection that can be provided with a MockDataProvider which is much easier to implement than the complete JDBC API. This blog post shows how to use the MockConnection: http://blog.jooq.org/2013/02/20/easy-mocking-of-your-database/ An example: MockDataProvider provider = new MockDataProvider() { // Your contract is to return execution results given a context // object which contains SQL statement(s) bind values and some // other context values @Override public MockResult[] execute(MockExecuteContext context) throws SQLException { // Use ordinary jOOQ API to create an org.jooq.Result object. // You can also use ordinary jOOQ API to load CSV files or // other formats here! DSLContext create = DSL.using(...); Result<MyTableRecord> result = create.newResult(MY_TABLE); result.add(create.newRecord(MY_TABLE)); // Now return 1-many results depending on whether this is // a batch/multi-result context return new MockResult[] { new MockResult(1 result) }; } }; // Put your provider into a MockConnection and use that connection // in your application. In this case with a jOOQ DSLContext: Connection connection = new MockConnection(provider); DSLContext create = DSL.using(connection dialect); // Done! just use regular jOOQ API. It will return the values // that you've specified in your MockDataProvider assertEquals(1 create.selectOne().fetch().size()); There is also the MockFileDatabase which helps you matching dummy results with SQL strings by writing a text file like this: # This is a sample test database for MockFileDatabase # Its syntax is inspired from H2's test script files # When this query is executed... select 'A' from dual; # ... then return the following result > A > - > A @ rows: 1 # Just list all possible query / result combinations select 'A' 'B' from dual; > A B > - - > A B @ rows: 1 select ""TABLE1"".""ID1"" ""TABLE1"".""NAME1"" from ""TABLE1""; > ID1 NAME1 > --- ----- > 1 X > 2 Y @ rows: 2"
697,A,"iSeries JDBC Sql statement with ""é"" in column name throws java.sql.SQLException: [SQL0104] I am having trouble using the character ""é"" in a returned column name from an SQL query. Running this query SELECT PRCAT as Categorie PRYEA as Année PRDSC as Designation from DEMO.PRODUCT using the IBM Toolbox JDBC driver connecting to an iSeries produces this exception:  java.sql.SQLException: [SQL0104] Token é was not valid. Valid tokens:  FROM INTO. Cause . . . . . : A syntax error was detected at token é. Token é is not a valid token. A partial list of valid tokens is  FROM INTO. This list assumes that the statement is correct up to the token. The error may be earlier in the statement but the syntax of the statement appears to be valid up to this point. Recovery . . . : Do one or more of the following and try the request again: -- Verify the SQL statement in the area of the token é. Correct the statement. The error could be a missing comma or quotation mark it could be a misspelled word or it could be related to the order of clauses. -- If the error token is <END-OF-STATEMENT> correct the SQL statement because it does not end with a valid clause. at com.ibm.as400.access.JDError.throwSQLException(JDError.java:650) at com.ibm.as400.access.JDError.throwSQLException(JDError.java:621) at com.ibm.as400.access.AS400JDBCStatement.commonPrepare(AS400JDBCStatement.java:1481) at com.ibm.as400.access.AS400JDBCPreparedStatement.<init>(AS400JDBCPreparedStatement.java:185) at com.ibm.as400.access.AS400JDBCConnection.prepareStatement(AS400JDBCConnection.java:1903) at com.ibm.as400.access.AS400JDBCConnection.prepareStatement(AS400JDBCConnection.java:1726) ... Is this an issue of improper jdbc driver setup or is there some built in limitation to what characters can be used (and where can I find this? I find IBM doco impossibly labyrinthine...). My jdbc connection code looks like this: Class.forName(""com.ibm.as400.access.AS400JDBCDriver"").newInstance(); Connection cnnobj=DriverManager.getConnection(""jdbc:as400://""+ipAddress+"";errors=full;date format=iso;time format=iso;"" user pass); Its actually automatically generated... ish. long long story! Why would you use an é in année but not in catégorie and désignation? Great question... I am not a French speaker. These came to me from elsewhere and possibly got literally ""lost in translation""... But presumably the same problem would result for those fields too. Why don't you change this SQL query? I feel sorry for you to have to maintain this but I can't think of any reason to keep that ... not to mention any reason to write that in the first place. What happens if you quote the alias name? SELECT PRCAT as Categorie PRYEA as ""Année"" PRDSC as Designation from DEMO.PRODUCT by golly that works!"
698,A,Printing SQL Query In PreparedStatement in oracle.jdbc.driver.OraclePreparedStatement I need to see the query being sent to Oracle from a Java program. In the PostgreSQL JDBC driver toString() does the job but the same does not apply to prepared statements from Oracle JDBC implementation. Any ideas how to achieve that? I think the getOriginalSql() method returns the String being sent to Oracle. In JDBC I wouldn't rely on vendorspecific methods. Thanks it returns the string in the prepared statement but without the set columns (question marks show up in the output). @BalusC can you elaborate on that statement?  Check out Log4Jdbc. This sits between your JDBC driver and the application logging all DB traffic that goes back and forth. It's driver-agnostic so need for driver-specific logging code. Extremely handy and would be even handier if it supported DataSources but sadly it doesn't. It was very helpful I could not follow the installation instructions on the site but I managed to get the debugging information I needed through it. Thanks.
699,A,"How do you LOAD TABLE in Sybase IQ from a client using Java? Is it possible to load a file from a client computer into a table in Sybase IQ using the LOAD TABLE ... USING CLIENT FILE statement? The data does not come from a database but rather an external source. Can this be done using a JDBC driver in Java and having the file only on the client computer? If so how? Try this : http://stackoverflow.com/questions/2112395/sybase-jconnect-enable-bulk-load-usage Also you may want to try bcp. I have already seen that answer but that is for Sybase ASE. I want to use Sybase IQ and the fastest way to get data into IQ as I understand it is ""LOAD TABLE...""  After doing some research and a ""proof-of-concept"" this is the answer I have come up with: Use the iAnywhere JDBC Driver which is part of the SQL Anywhere Studio suite of software from SyBase. It is not limited to the TDS protocol which the standard jConnect JDBC driver from SyBase is. http://www.sybase.com/detail?id=1037304 Note: This is not a Type 4 driver and is not pure Java. Nicolai I ran into the same issue. After reading your post I switched over to the iAnywhere JDBC Driver. I am on Windows so I configured an ODBC Data Source for DBODBC11.dll. In my java project I am using jodbc.jar from SQL Anywhere 11. My connection string is pretty simple. ""jdbc:ianywhere:DSN=dw"". I can get a connection but I now get the following error: [Sybase][ODBC Driver][Sybase IQ]Syntax error near 'LOAD'. Any Ideas? What exactly did you have to do in order to get this to work? Thanks! I am sorry but I haven't really touched this stuff since last year. I don't really remember what we did and the code was a throw away ""proof of concept"" so I am afraid I can't help you."
700,A,"How to use SQL Server Compact Edition (CE) from Java? I want to access Microsoft SQL Server Compact Edition databases from Java. How can I do that? I searched for JDBC driver for SQLCE but I didn't find any. Search for the SqlJDBC4 library. I know a coworker uses it. From reading the MS site it seems that it does not support SQL CE.  Good tutorial sqljdbc-tut Latest driver (in tech preview) is sqljdbc-jars  According to MSDN there isn't one and there aren't any plans neither.  While I'm not familiar with SQL Server CE I presume that MS provides an ODBC driver for it. Although it is not recommended for production use you can use the JDBC-ODBC bridge to make your connection. Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver""); Connection con = DriverManager.getConnection(""jdbc:odbc:<yourODBC_DSN>""); To reiterate the JDBC-ODBC Bridge driver provided with JDBC is recommended only for development and testing or when no other alternative is available. No there is no ODBC driver for SQL Server CE and there are apparently no plans for one.  According to a newsgroup post sent this Tuesday (2008-12-09) by Jimmy Wu@Mircrosoft: The Microsoft SQL Server JDBC Driver does not support connecting to SQL Server Compact. At this time there isn't a scheduled JDBC support for SQL Server Compact edition. Thank-you for your continuing support of SQL Server. Sincerely Jimmy Wu"
701,A,MySQL - Connection using Singleton pattern or a ConnectionPool? The topic has already been on the table in some previous questions. New elements come with new problems. I am seeking here for the best way to handle database connection(s) concerning aspects of : maintainability performance security and implementation. I must mention that i am not interested in abstractions like Hibernate Spring etc at this time. Here are the facts : Scenario 1 - Singleton pattern The main ideas here are : verify connection details instantiate the connection write a static getter for her and use it as long as needed. Code sample :  static Connection connection; private Statement stmt = null; connection = createConnection(...) stmt = connection.createStatement(); Queries will be executed using :  stmt.execute(); Now this may not sound too fancy but..it works. I have total control over my connection closing it instantiating it closing resultSet(must be done by every caller) etc. Scenario 2 - Singleton pattern with PreparedStatement As some people suggested here i've introduced the PreparedStatement for executing the queries and basically i've dropped the stmt variable and instead i use the expression : PreparedStatement pStmt= getConnection().prepareStatement(query); pStmt.execute(); Using PMD code analyzer i've noticed that pSmt may fail to close which is true because i cannot close it here and i cannot instruct the caller to close it either. This approach leads to the next scenario. Scenario 3 - Singleton pattern with static PreparedStatement All set i've declared : private static PreparedStatement preparedStmt = null; My executeQuery() method adapts itself to : setPreparedStmt(getConnection().prepareStatement(query)); getPreparedStmt().execute(); where the setter and getter are simply .. setters and getters with public visibility and static attribute. This approach is easy to understand and the callers will have to close the PreparedStatement themselfs (no problem but closing PreparedStatement will also close the ResultSet if the case?). However somehow i feel that re-using this pre-compiled statement is not all that safe with transactional aspect of the database. Are there any dangers here? Scenario 4 - Using a Connection Pool This aspect needs further research but i get the main idea. I cannot go into details about this practice but there are few questions here also : 4.1 I know that one can set the number of connections the max size of the pool. What that number would be for a single user for instance resulting that i will multiply that number with the user count. 4.2 Using a pool of connections should i use the Statement or the PreparedStatement when getting one connection from the pool and use it to execute some query? 4.3 It is my understanding that using this strategy i have to close the connection after his task is finished. But what if for some reasons the connection fail to close? If that will for some reason repeat for a number of times equal to connection pool size..we are doomed. OK i will stop here perhaps some updates will follow depend on the answers to come. Manny thanks. In just about every case imaginable I would use a connection pool. The aspects of maintainability performance and implementation have been taken care of for you. Most servers provide a built-in data source for you that can be accessed through JNDI and there are standalone connection pools as well. As for security use prepared statements for any query that requires user input for a parameter. That way user input can never allow a SQL injection attack. And about your questions: 4.1: Ideally each page request will use 1 connection. So in order to figure out how many total pooled connections you need you've got to do the math on how many requests you'll be getting per average query time (say requests per second). Unless that number is high then the default number of connections provided by most connection pools will suffice (usually 20 from what I've seen). 4.2: You can use either a Statement or PreparedStatement from the Connection you get from the pool. In most cases (including any in which user input is used in the query) you should use PreparedStatements. 4.3: If you put your connection closing code in the finally block of a try statement and remember to do this every time you access the database then you should never run into the problem of running out of connections. Thanks for the reply. Regarding connection pools there are 3 questions unanswered there :D. LOL there you go answered them. +1 for the speed of reaction! Cheers.
702,A,"How to limit number of rows returned from Oracle at the JDBC data source level? Is there a way to limit the rows returned at the Oracle datasource level in a Tomcat application? It seems maxRows is only available if you set it on the datasource in the Java code. Putting maxRows=""2"" on the datasource doesn't apply. Is there any other way limit the rows returned? Without a code change? If you know you will be dealing with only one table then define a view with rownum in the where statement to limit the number of rows. In this way the number of rows is controlled at the DB and does not need to be specified as part of any query from a client application. If you want to change the number of rows returned then redefine the view prior to executing query. A more dynamic method would be to develop a procedure and pass in a number of rows and have the procedure return a ref_cursor to your client. This would have the advantage of avoiding hard parsing on the DB and increase performance.  Take a look at this page with a description of limiting how much is sucked into the Java App at a time. As another post points out the DB will still pull all of the data this is more for controlling network use and memory on the Java side.  *Beware: the code below is provided as pure example. It has not been tested * It thus may harm yourself or your computer or even punch you in the face. If you want to avoid modifying your SQL queries but still want to have clean code (which means that your code stay maintainable) you may design the solution using wrappers. That is by using a small set of classes wrapping existing ones you may achieve what you want seamlessly for the rest of the application which will still think it is working with real DataSource Connection and Statement. 1 - implement a StatementWrapper or PreparedStatementWrapper class depending what your application already uses. Those classes are wrappers around normal Statement or PreparedStatement instances. They are implemented simply as using the inner statement as a delegate which does all the work except when this is a QUERY statement (Statement.executeQuery() method). Only in that precise situation the wrapper surrounds the query by the two following strings : ""SELECT * FROM ("" and "") WHERE ROWNUM < ""+maxRowLimit. For basic code wrapper code see how it looks for the DataSourceWrapper below. 2 - write one more wrapper : ConnectionWrapper which wraps a Connection which returns StatementWrapper in createStatement() and PreparedStatementWrapper in prepareStatement(). Those are the previously coded classes taking ConnectionWrapper's delegateConnection.createStatement()/prepareStatement() as construction arguments. 3 - repeat the step with a DataSourceWrapper. Here is a simple code example. public class DataSourceWrapper implements DataSource { private DataSource mDelegate; public DataSourceWrapper( DataSource delegate ) { if( delegate == null ) { throw new NullPointerException( ""Delegate cannot be null"" ); mDelegate = delegate; } public Connection getConnection(String username String password) { return new ConnectionWrapper( mDelegate.getConnection( username password ) ); } public Connection getConnection() { ... <same as getConnection(String String)> ... } } 4 - Finally use that DataSourceWrapper as your application's DataSource. If you're using JNDI (NamingContext) this change should be trivial. Coding all this is quick and very straightforward especially if you're using smart IDE like Eclipse or IntelliJ which will implement the delegating methods automagically.  Ok a code change it'll have to be then. The scenario is limiting an adhoc reporting tool so that the end user doesnt pull back too many records and generate a report which is unusable. We already use oracle cost based resource management.  The question is why do you want to limit the number of rows returned. There could be many reasons to do this. The first would be to just limit the data returned by the database. In my opinion this makes no sense in most cases as if I would like to get certain data only then I would use a different statement or add a filter condition or something. E.g. if you use rownum of Oracle you don't exactly know which data is in the rows you get and which data is not included as you just tell the database that you want row x to y. The second approach is to limit memory usage and increase performance so that the ResultSet you get from the JDBC driver will not include all data. You can limit the number of rows hold by the ResultSet using Statement.setFetchSize(). If you move the cursor in the ResultSet beyond the number of rows fetched the JDBC driver will fetch the missing data from the database. (In case of Oracle the database will store the data in a ref cursor which is directly accessed by the JDBC driver).  It isn't something that is available at the configuration level. You may want to double check that it does what you want it to do anyway: see the javadoc for setMaxRows. With Oracle it is still going to fetch every row back for the query and then just drop the ones outside the range. You would really need to use rownum to make it work well with Oracle and you can't do that either in the configuration."
703,A,Database Connection Always disconnect when Developing on same PC as DB I am developing a JSP application and I used Oracle Express 10g as database. I notice when I try to develop in the same PC I would only be able to make several page request and transition and I immediately get IO exceptions. But I download the same code in a different PC and connect to the said database PC. It does not kick me out immediately. Any Idea if there is any other settings that needs to be set here? Im using Apache Tomcat 5.5 and Eclipse as IDE. [ 2009/10/05 17:59:02 The error occurred by XXXClass. ] java.sql.SQLException: I/O Exception。: Connection reset by peer: socket write error at oracle.jdbc.driver.SQLStateMapping.newSQLException(SQLStateMapping.java:133) at oracle.jdbc.driver.DatabaseError.newSQLException(DatabaseError.java:115) at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:221) at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:293) at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:646) at oracle.jdbc.driver.T4CPreparedStatement.executeForDescribe(T4CPreparedStatement.java:1057) at oracle.jdbc.driver.T4CPreparedStatement.executeMaybeDescribe(T4CPreparedStatement.java:1139) at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1471) at oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:3874) at oracle.jdbc.driver.OraclePreparedStatement.executeQuery(OraclePreparedStatement.java:3944) at oracle.jdbc.driver.OraclePreparedStatementWrapper.executeQuery(OraclePreparedStatementWrapper.java:3613) at org.apache.tomcat.dbcp.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:93) Your PC with the database isn't by any chance configured to get it's IP via DHCP is it? If so you need to install the Microsoft Loopback Adapter. Yes my PC is configured to get IP via DHCP. I followed the instructions on adding the Microsoft Loopback Adapter and it worked. Thanks.
704,A,"How to combine two ResultSets in Java? I have two result sets (rs1 and rs2) having same fields. Now how to combine those two result sets into one so that duplicate rows are shown once. You can: Create a class that has properties corresponding to the columns implement the equals() and hashCode() methods using the fields by which you define ""duplicate"" (let your IDE help you with the generation of these) createa a Set (HashSet): Set combinedDataSet = new HashSet(); Iterate each resultSet and construct objects: while (rs1.next) { YourClass obj = new YourClass(); obj.setSomeProperty(rs.getString(1)); obj.setAnotherProperty(rs.getString(2)); // etc.. cominbedDataSet.add(obj); } The same iteration goes for rs2 Do this only in case you can't get the desired result via an SQL query! +1 ... .......... :) @Bozho I want to communicate with you. I don't have any programming problems which I can post here. You have answered various questions of mine and thus I know that you are the right person to have advice from you for my career. I checked your blog too but didn't find any way to communicate with you. I don't want to use SO to communicate with you as it would be wrong. I would be very grateful to you if you give me some time from your precious time and tell me how can I chat with you. Thanks. @Yatendra Goel if you have particular questions ask them at SO. If you have less-particular questions check my blog (linked in my profile here) and drop me a comment.  if the two ResultSets are from the same database then why not combine them during the retrieval by using union; e.g. select A B from C union select A B from D However if this is not an option then I suggest defining a Row class to represent a Row extracted from your ResultSet and implementing equals / hashCode to allow the Row to be compared for equality. Then simply add each Row to a Set (e.g. HashSet) in order to remove duplicates. @Adam: The OP already stated he wanted duplicate rows to only be shown once hence why I mentioned UNION rather than UNION ALL. +1 ... great answer ... very precise and to the point... I would upvote you 10 times if I had the rights. UNION removes duplicates forcing a sort. UNION ALL functionally concatenates result sets. If dups are acceptable or you know the two result sets have no overlap use UNION ALL."
705,A,"What is the best way to iterate over a large result set in JDBC/iBatis 3? We're trying to iterate over a large number of rows from the database and convert those into objects. Behavior will be as follows: Result will be sorted by sequence id a new object will be created when sequence id changes. The object created will be sent to an external service and will sometimes have to wait before sending another one (which means the next set of data will not be immediately used) We already have invested code in iBatis 3 so an iBatis solution will be the best approach for us (we've tried using RowBounds but haven't seen how it does the iteration under the hood). We'd like to balance minimizing memory usage and reducing number of DB trips. We're also open to pure JDBC approach but we'd like the solution to work on different databases. UPDATE 1: We need to make as few calls to DB as possible (1 call would be the ideal scenario) while also preventing the application to use too much memory. Are there any other solutions out there for this type of problem may it be pure JDBC or any other technology? UPDATE 2 Query will be backend driven and will only have 1 instance executing at a given time. Thanks and hope to hear your insights on this. It seems you need some sort of pagination. iBatis does that through the standard LIMIT/OFFSET parameters in the query (and RowBounds in iBatis 3 ). But it seems (if I get it right) that you also are using the GROUP BY feature of iBatis so that a select returning N records with N1 distint ""idx"" fields result in the creation of N1 ""parent"" objects each one having several children objects (with a total of N children objects created). Or something like that. Unfortunately (and understandably) both things do not mix well. I dont' see any silver bullet here one can think of many approaches each has its shortcomings - hard to evaluate without more information. If the main objects are ""big"" (many records) and each one will be processed individually (with a trip to a remote server) you might even want to do an ad-hoc pagination with a object per page remembering internally the previosuly read id (something like SELECT ... FROM ... WHERE id = (SELECT MIN(id) FROM .... WHERE id > #lastid# ) ) I you insist on doing that in one DB query take a look at RowHandler or ResultHandler - (or more exotically return a ResultSet/Cursor - or revert to plain JDBC). But this is only reasonable if the action to be done remotely for each ""object"" is supposed to give a response (quickly - non dependent on some human interaction) and you can trust that the loop will be completed. The ResultSet/Cursor approach is I believe what my boss is looking for. I just saw a tutorial for PostgreSQL to setFetchSize use ResultSet.TYPE_FORWARD_ONLY and setAutocommit(false) to enable this behavior. Unfortunately I'm trying this now with MySQL and it doesn't look like it's supported. Would you have an idea which DBs have this? Thanks. PostgreSQL beats Mysql in almost every respect specially for non trivial db-backed apps. Go for it -if you can. Beware that using cursors in this scenario feel rather dirty to me (I have very little experience with them - do your boss really know what he is doing?) and they might introduce leaks. Your application must have full control about closing them properly always. Alright I added the ?useCursorFetch=true to the driver URL for MySQL and memory usage dropped from 364651264 to 4160608. I'll try to check whether setFetchSize is supported in DB2 and Oracle next. Thanks. 1. I had a feeling iBatis was using the LIMIT/OFFSET I guess that means it needs to hit the database for every page right? 2. We are doing the grouping on the Java side so no need to use group by keyword in the query we just need to have the results sorted by id so we can finish creating one object with children of the same id before processing the next objects. 3. Your adhoc pagination sounds like a good alternative to the RowBounds approach. This way we're guaranteed that only the next object will be retrieved. I'll give that a try and check performance. Thanks for the help leonbloy! I added a new requirement which is to make as few DB roundtrips as possible. Hope you can comment also on the updates. Thanks!  We need to make as few calls to DB as possible (1 call would be the ideal scenario) while also preventing the application to use too much memory. Are there any other solutions out there for this type of problem may it be pure JDBC or any other technology? You should really not worry about the amount of DB calls. Just query exactly the data the enduser needs to see at once. It can't be done more efficiently. Google also doesn't query the entire database to show only the first 10. No it queries exactly those 10 for display nothing less or more. This is much much faster and more efficient than hauling/duplicating the entire database into application's memory and working on that. Take benefit of the powers of the RDBMS. That's what it was invented/intended for. +1 BalusC is right generally speaking (and I suspect particualarly speaking also) @paul: Well if the boss says it... :/ Talk with him. Convince him more. Thanks BalusC. Sorry but I forgot to mention that this will not be a user driven query but one which is triggered by the backend. Not sure why the boss wants a single DB call I mentioned that it might be hard to balance memory usage with that approach but he suggested to keep trying which is why I'm still looking for other alternatives."
706,A,"Error while connecting to Oracle DSN using Java I need to develop an application that connects to various DSN's using the Microsoft ODBC drivers. I have developed the application in Eclipse and it seems to work properly. The connection succeeds and I am able to view table data. However when I export the project to a runnable jar file (using Eclipse) the functionality fails for Oracle. It is unable to establish connectivity with the Oracle connection string. It still works for SQL server but fails in case of Oracle. I'm unable to figure out the cause as the same ODBC drivers are being used for both Oracle and SQL-Server. More mystifying is that it runs properly on Eclipse. Since im using the ODBC drivers I don't believe the problem is because of an external jar file. The driver is sun.jdbc.odbc.JdbcOdbcDriver and connection string is like jdbc:odbc:oratest;user=fell;password=pass. I'm getting the following exception java.sql.SQLException: [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified at sun.jdbc.odbc.JdbcOdbc.createSQLException(JdbcOdbc.java:6958) Can you please help me figure what the problem might be? Thanks in advance Fell Is `oratest` a ""System DSN"" or a ""User DSN""? its a system DSN.. Check the classpath in the eclipse project  Create a System DSN. java.sql.Connection cn; Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver""); cn=java.sql.DriverManager.getConnection(""jdbc:odbc:dsn_name""""user""""pass""); cool..thanks a lot... works just fine now !"
707,A,"How to get only the first row from a java.sql.ResultSet? I have a ResultSet object containing all the rows returned from an sql query. I want to be able to (in the java code NOT force it in the SQL) to be able to take a ResultSet and transform it so that it only contains 1 (the first) row. What would be the way to acheive this? Also is there another appropriate class (somewhere in java.sql or elsewhere) for storing just a single row rather than trimming my ResultSet? Thanks! Why not in SQL? See Statement.setMaxRows This looks like what I need - could you please show me an example of how I would use this to take an existing ResultSet (possibly containing many rows) and modify it (or create a new ResultSet) containing only the first row? I am just confused about how I would use this given that the ResultSet object is already created. Thanks @llm Why would you want to do this on an existing ResultSet rather than before the statement is executed? You lose the possibility of the driver optimizing the query to return only the data you need.  For the purpose of just limiting the number of rows in a result set you can do the following: String yourQuery = ""select * from some_table""; PreparedStatement statement = connection.prepareStatement(yourQuery); statement.setMaxRows(1); rs = statement.executeQuery(); As for a specific class that can hold only one row this really depends on what you want to do with the data. You could for example just extract the contents of the result set and store them in an array or if you need names as well as values a map. You could also just read the data into a POJO if you would rather work with a specific object rather than a generic data structure.  You reference the need to store a single row of data in which case I'd say that using a ResultSet is probably a bad idea as it will be typically consume database resources until closed (e.g. the underlying java.sql.Connection). Instead I'd recommend reading the first row of your ResultSet into a POJO perhaps using Spring's JDBC utility classes (e.g. RowMapper) to achieve this concisely. Immediately after this close the ResultSet and associated Statement and Connection (or allow Spring to do it for you)."
708,A,"MySQL timestamp to Java date conversion How can I convert time in unix timestamp to normal time? Your question is vague and ambiguous. Don't you just mean ""How to convert a timestamp in (milli)seconds to a human readable time format of HH:mm:ss""? [UTC](http://en.wikipedia.org/wiki/Coordinated_Universal_Time) is namely a timezone as is [GMT](http://en.wikipedia.org/wiki/Greenwich_Mean_Time). @BalusC that is incorrect GMT is GMT all the time the British daylight savings time is BST which is GMT+1 GMT doesn't vary from UTC by anything more than negligible fractions of a second which aren't relevant in day to day use. @MrXexxed: I edited the DST part away for the sake that. @BalusC thanks looks better now! But your point is valid the questions title *is* misleading as for the purposes of this UTC and GMT are the same thing. Unix timestamp is seconds since ""epoch"". Java's currentTimeMillis are milliseconds since ""epoch"". You can get a Java Date object with a simple multiplication like this:  Date dateFromUnixTime = new Date( 1000l * unixTime) ; From there you can format it using the normal date formatting tools in Java. thank you so much!!! :)  Your question is vague and ambiguous. I'll leave the timezone ambiguity away. How can I convert time in unix timestamp to normal time? I suspect that you're somehow obtaining a long or maybe a String value from the DB instead of a Date. In JDBC you would normally like to use the appropriate methods to obtain the DB-specific datatypes. The MySQL TIMESTAMP datatype can be obtained by ResultSet#getTimestamp() which gives you a java.sql.Timestamp which in turn is a subclass of java.util.Date. In a nut the following should do: Date date = resultSet.getTimestamp(""columnname""); To format it further in a human readable format whenever you're going to present it to the enduser use SimpleDateFormat. Click the link it contains an overview of all patterns. Here's an example: String dateString = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss"").format(date); To do all the other way round use respectively SimpleDateFormat#parse() and PreparedStatement#setTimestamp()."
709,A,"Java Oracle connection pooling - Closed Connection exception This post is intended to be less of a question and more a confirmation that I'm doing things correctly. I've seen many similar posts but I'm not sure I fully understand everything that's been said. The problem is that after a certain amount of time I get an exception when trying to establish a connection to my oracle database. (I'm using Tomcat 6.0 and Spring) Previously I had the following configuration: private PoolDataSource poolDataSource = null; public MainDAOImpl(String url String username String password) throws Exception { poolDataSource = PoolDataSourceFactory.getPoolDataSource(); try { poolDataSource.setConnectionFactoryClassName(""oracle.jdbc.pool.OracleDataSource""); poolDataSource.setURL(url); poolDataSource.setUser(username); poolDataSource.setPassword(password); } catch( SQLException e ) { ... } } public List<Object> getValues(String query) { Connection connection = null; PreparedStatement preparedStatement = null; try { connection = poolDataSource.getConnection(); preparedStatement = connection.prepareStatement(query); ... } catch( SQLException e ) { ... } finally { //close connections } } However sometimes the preparedStatement = connection.prepareStatement(query); threw an SQLException with a ""Closed Exception"" message. It's important to note that the MainDAOImpl's constructor gets called only once per server restart (it's dependency injected via Spring). I've recently changed my setup like so: private DataSource dataSource = null; public MainDAOImpl() throws Exception { try { Context initContext = new InitialContext(); Context envContext = (Context)initContext.lookup(""java:/comp/env""); dataSource = (DataSource)envContext.lookup(""jdbc/myOracleConn""); } catch( NamingException e ) { ... } } and poolDataSource.getConnection() to dataSource.getConnection(). I've also added the following Resource to my Context in Tomcat: <Resource name=""jdbc/myOracleConn"" auth=""Container"" type=""javax.sql.DataSource"" driverClassName=""oracle.jdbc.OracleDriver"" url=""<myURL>"" username=""<myUsername>"" password=""<myPassword>"" maxActive=""20"" maxIdle=""10"" maxWaith=""-1"" /> This basically follows http://tomcat.apache.org/tomcat-6.0-doc/jndi-datasource-examples-howto.html word-for-word. Everything seems to be working. My question is will these changes solve my closed connection problem or is there something different I need to do? Thanks B.J. First of all if you are using Spring for dependency injection I would recommend that you also use DI to inject the DAO's dependencies into it. In other words your DAO should have a DataSource injected into it rather than the DAO implementation knowing either 1) what type of DataSource to construct or 2) how and where to look it up in JNDI. Spring can handle JNDI lookups for you. I'd also recommend using Spring's JdbcTemplate as it makes for a great wrapper over raw JDBC calls yourself. Finally the actual exception you are getting may just be because the database server is closing long-open connections. Not sure which connection pool implementation you are using but in commons-dbcp there is an option for a ""validationQuery"" which the pool will execute before returning a connection to verify the connection is still valid. I'm sure most other pools supply similar features which I would recommend here - this way your DAO is never receiving stale connections from the pool."
710,A,"Oracle Driver Installation I am having Oracle 10g installed on my laptop and have downloaded ojdbc14.jar driver for the same. The problem is my operating system is Windows 7 and I'm not having option to create a Data Source for Oracle since I m not having oracles driver installed. I m having option to create a Data Source for SQL server 6 but I want to get connected to Oracle. Please Help. I have figured out the solution for my problem. All that I needed to do is put ojdbc14.jar file in my class path and then I was able to use it. Though by doing so I needed to make some change in the code. I was no more able to use Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver"") instead I needed to use Class.forName(""oracle.jdbc.OracleDriver"") also instead of using my data source as ""jdbc:odbc:somename"" I needed to use jdbc:oracle:thin:@localhost:1521:xe.  By 'Data Sources' I'm guessing that you mean Data Sources (ODBC) under Control Panel > Administrative Tools. Is this correct? I've set up ODBC Data Sources that connect to Oracle databases before but to do that I've needed the Oracle client to be installed. However if you're having the full database installed on your laptop (as your question suggests) you won't need the client - that's only used to connect to databases running on other machines. I believe the full database contains everything in the client so you should be able to set up an ODBC Data Source pointing to the database on your laptop once the database has been installed. The ojdbc14.jar just contains the JDBC classes to talk to an Oracle database and only programs written in Java (and other languages that run on the JVM such as Scala Groovy or Clojure) can use it. This jar on its own not enough to be able to set up an ODBC data source.  Oracle currently has 1 version that is certified for windows 7. That version is 11.2. They have indicated that they plan to certify 10.2.0.5 if this happens there will likely be a patch that will be needed. This is probably why the Data Source does not work either ODBC or OLEDB. Another possibility is that you have installed the 32bit version of Oracle and your OS is 64bit then you would need to use the 32bit Data Source administrative tools."
711,A,DDLUtils and autoincrement values When trying to use DDLUtils it always seems to take over the id values for the columns that are set to autoincrement. How can I prevent this? For example I have a Dogs table with a column called ownerID. The column ownerID is set to autoincrement. However my list of owners is not continuous there are gaps (for example ownerID's 2 4 5 6 7 10 exist but not 1 3 8 9 because they've since been deleted). The problem is that on DdlToDatabase restoring the owner ids are reset to 1 2 3 4 and so on. This means that the links in my Dogs table through ownerID are now all incorrect. How can I get the DDlUtils to correctly import the values for autoincrementing fields? Why do you use autoincrement for a column with a FK constraint? It's an easy to guarantee that owners.id is unique. Ok. But isn't that the cause of all your troubles? BTW am I not allowed to have 2 dogs? :D You can have as many dogs as you want. Each row of dog just points to an owner's id. Yes I agree having autoincrements is causing the issue but there should be a working solution. I can't imagine a powerful framework such as this one not having some kind of support for autoincrements. I don't know much about DDLUtils but for this sort of ETL (export transform load) operation you have to do a bit more work. I know two ways that are common Insert the new Dog record. Keep a map of the old ID to the new ID. When inserting into another table that has an FK to ownerID use the map to choose the new ID.  Original Dogs New Dogs [ID] [Name] [ID] [Name] 2 Henry 1 Henry 5 Oliver 2 Oliver When you insert both records you end up with an old to new map of [ 2 => 1 5 => 2 ]. Then when you insert any record that uses an ID of 2 you instead use 1. Another way is to disable the auto increment nature of the table when loading your data. This is DB specific. For instance in SQL Server you can use set identity_insert Dogs on In MySQL you can simple insert records and specify the ID you want.  It's some time ago - but i had the same problem The Solution: First of all your choosen Platform must support identityOverrideAllowed. Platform mySqlPlatform = PlatformFactory.createNewPlatformInstance(mysqlDataSource); mySqlPlatform.getPlatformInfo().setIdentityOverrideAllowed(true); You also have to set isIdentityOverrideOn An example how to set it at you can find in the sourcecode.DDLUtils org.apache.ddlutils.platform.mssql.MsSqlPlatform... /** * Determines whether we need to use identity override mode for the given table. * * @param table The table * @return <code>true</code> if identity override mode is needed */ private boolean useIdentityOverrideFor(Table table) { return isIdentityOverrideOn() && getPlatformInfo().isIdentityOverrideAllowed() && (table.getAutoIncrementColumns().length > 0); } /** * {@inheritDoc} */ protected void beforeInsert(Connection connection Table table) throws SQLException { if (useIdentityOverrideFor(table)) { MSSqlBuilder builder = (MSSqlBuilder)getSqlBuilder(); connection.createStatement().execute(builder.getEnableIdentityOverrideSql(table)); } } /** * {@inheritDoc} */ protected void afterInsert(Connection connection Table table) throws SQLException { if (useIdentityOverrideFor(table)) { MSSqlBuilder builder = (MSSqlBuilder)getSqlBuilder(); connection.createStatement().execute(builder.getDisableIdentityOverrideSql(table)); } }  It looks like you can't import the values from the auto-increment rows which means if they are referenced in other tables you're in trouble. Instead what you should do is use UUID's if you wish to go this route.
712,A,"identity from sql insert via jdbctemplate Is it possible to get the @@identity from the SQL insert on a Spring jdbc template call? If so how? How about SimpleJdbcInsert.executeAndReturnKey? Wow I didn't really know about that class - kinda neat. Thanks. +1  Adding detailed notes/sample code to todd.pierzina answer jdbcInsert = new SimpleJdbcInsert(jdbcTemplate); jdbcInsert.withTableName(""TABLE_NAME"").usingGeneratedKeyColumns( ""Primary_key""); Map<String Object> parameters = new HashMap<String Object>(); parameters.put(""Column_NAME1"" bean.getval1()); parameters.put(""Column_NAME2"" bean.getval2()); // execute insert Number key = jdbcInsert.executeAndReturnKey(new MapSqlParameterSource( parameters)); // convert Number to Int using ((Number) key).intValue() return ((Number) key).intValue();  The JDBCTemplate.update method is overloaded to take an object called a GeneratedKeyHolder which you can use to retrieve the autogenerated key. For example (code taken from here): final String INSERT_SQL = ""insert into my_test (name) values(?)""; final String name = ""Rob""; KeyHolder keyHolder = new GeneratedKeyHolder(); jdbcTemplate.update( new PreparedStatementCreator() { public PreparedStatement createPreparedStatement(Connection connection) throws SQLException { PreparedStatement ps = connection.prepareStatement(INSERT_SQL new String[] {""id""}); ps.setString(1 name); return ps; } } keyHolder); // keyHolder.getKey() now contains the generated key That would be the ""one liner"" I am looking for here. Nice. Sad thing is I saw the link but glossed past it due to this: ""part of the JDBC 3.0 standard"". (I don't think we use JDBC 3.0 but I also don't think this is relevant).  I don't know if there is a ""one-liner"" but this seems to do the trick (for MSSQL at least): // -- call this after the insert query... this._jdbcTemplate.queryForInt( ""select @@identity"" ); Decent article here."
713,A,"Large ResultSet on postgresql query I'm running a query against a table in a postgresql database. The database is on a remote machine. The table has around 30 sub-tables using postgresql partitioning capability. The query will return a large result set something around 1.8 million rows. In my code I use spring jdbc support method JdbcTemplate.query but my RowCallbackHandler is not being called. My best guess is that the postgresql jdbc driver (I use version 8.3-603.jdbc4) is accumulating the result in memory before calling my code. I thought the fetchSize configuration could control this but I tried it and nothing changes. I did this as postgresql manual recomended. This query worked fine when I used Oracle XE. But I'm trying to migrate to postgresql because of the partitioning feature which is not available in Oracle XE. My environment: Postgresql 8.3 Windows Server 2008 Enterprise 64-bit JRE 1.6 64-bit Spring 2.5.6 Postgresql JDBC Driver 8.3-603 Is your call returning? If not have you tried ctrl-\ (ctrl-break for Windows) jstack jconsole visualvm or similar to find where the thread has stopped? It's processing the query inside the driver. I'm betting that there's not a single client of your app that needs 1.8M rows all at the same time. You should think of a sensible way to chunk the results into smaller pieces and give users the chance to iterate through them. That's what Google does. When you do a search there might be millions of hits but they return 25 pages at a time with the idea that you'll find what you want in the first page. If it's not a client and the results are being massaged in some way I'd recommend letting the database crunch all those rows and simply return the result. It makes no sense to return 1.8M rows just to do a calculation on the middle tier. If neither of those apply you've got a real problem. Time to rethink it. After reading the later responses it sounds to me like this is more of a reporting solution that ought to be crunched in batch or calculated in real time and stored in tables that are not part of your transactional system. There's no way that bringing 1.8M rows to the middle tier for calculating moving averages can scale. I'd recommend reorienting yourself - start thinking about it as a reporting solution. The database loading is done once on system startup to massage the data and ""convert"" it to a more suitable format for client use. There is nothing to configure in the RowCallbackHandler itself. But a lot of configuration on the connection datasource driver or database design. It's a little hard to debug this on production server where the mass data is. Logging is all I have.  In order to use a cursor to retrieve data you have to set the ResultSet type of ResultSet.TYPE_FORWARD_ONLY and autocommit to false in addition to setting a fetch size. That is referenced in the doc you linked to but you didn't explicitly mention that you did those steps. Be careful with PostgreSQL's partitioning scheme. It really does very horrible things with the optimizer and can cause massive performance issues where there should not be (depending on specifics of your data). In any case is your row only 1.8M rows? There is no reason that it would need to be partitioned based on size alone given that it is appropriately indexed. Yes I did all the steps described at the docs (TYPE_FORWARD_ONLY and autocommit false). 1.8M is my current sample. The data is partitioned by day one day in each partition. Each day has around 400k rows. Afraid I can't be of help then. I haven't had any issue with the pg JDBC driver and fetch size for multi-gigabyte analysis queries but I have no experience with the spring library. Just as a test I'd try it without partitioning. How large to you expect the data set to grow to? At 400k rows per day I don't expect your current algorithm to last all that long. Without exactly knowing your use case I'd suggest you start looking at data warehousing techniques like star schemas and data dimensions. Thanks for the help Trey. I'm storing historical market data. I'll use 30 days of data. It'll be like a 30 days sliding window from today to 30 days ago. Every day the inheritance will be modified to link new partitions and unlink old partitions. The data will be there for an year or so but only 30 subtables (days) will be linked at a given time. Partition is being used to make this maintenance more feasible.  The fetchSize property worked as described at postgres manual. My mistake was that I was setting auto commit = false to a connection from a connection pool that was not the connection being used by the prepared statement. Thanks for all the feedback."
714,A,"In a JDBC ResultSet what should happen when getLong() or getShort() is called on an int result column? Say that I have a JDBC ResultSet and I call the getLong() or getshort() method. For which of the following SQL types {SMALLINT INT BIGINT} should I get long and for which types should I get an error? In other words if I have an INT and I want a SMALLINT (A short) would I get it or would I get an error? Similarly if I have an INT and want a BIGINT (a long) would I get it or would I get an error? The Javadocs (listed below) say nothing. public long getLong(int columnIndex) throws SQLException Retrieves the value of the designated column in the current row of this ResultSet object as a long in the Java programming language. Parameters: columnIndex - the first column is 1 the second is 2 ... Returns: the column value; if the value is SQL NULL the value returned is 0 Throws: SQLException - if a database access error occurs It'll cast it to a long and it should be fine. You'll get an error if you're trying to get a long from a string containing ""Bob"" or some other field that can't be easily converted to a long. That's what I'm wondering about and whether this is implementation dependent. I feel like the documentation is ambiguous about this. In the case that it is a null I know I will get a 0. But it seems like I won't even get a runtime warning in this case. It most likely is very implementation dependent. That just means you'll need to test it against several DBs. But the cold truth is that many apps even using ""portable"" SQL are DB specific so it's not usually a big problem. Obviously ""it depends"".  From the Retrieving Values from Result Sets section of the Java tutorials: JDBC allows a lot of latitude as far as which getXXX methods you can use to retrieve the different SQL types. For example the method getInt can be used to retrieve any of the numeric or character types. The data it retrieves will be converted to an int; that is if the SQL type is VARCHAR  JDBC will attempt to parse an integer out of the VARCHAR. The method getInt is recommended for retrieving only SQL INTEGER types however and it cannot be used for the SQL types BINARY VARBINARY LONGVARBINARY DATE  TIME or TIMESTAMP. I'm interpreting that to mean that the data will be coerced. It should work just fine if it's an upcast but I'd expect potential loss of precision (naturally) if for example you're reading a LONG value using getInt(). I'd expect an Exception to be thrown if you try to read text using getInt(). Wonderful... I'm writing a wrapper for JDBC's ResultSet and was hoping there was an unambiguous interpretation of the int types that is not implementation dependent. Thank you for finding this! You can call DataBaseMetaData.supportsConvert(int fromType int toType) to see if a given implementation supports a given conversion.  This is implementation dependent. The spec says that the ResultSet implemenation may support such a conversion and you can check by calling DataBaseMetaData.supportsConvert(int fromType int toType) (Section 15.2.3.1 of the 4.0 implementer spec). Best is to not rely on the behavior but rather check the ResultSetMetaData for the correct type.  The spec doesn't say anything about this behavior. This will totally depend on the implementation of the drivers. With the MySQL Connector you can almost get anything looking like a number as long as it's in valid numeric format and it's in the range of long. Null/False are also returned as 0."
715,A,"JDBC: in set condition: can I pass a set as single param? In JDBC I can use question marks for query parameters like this: ""SELECT * FROM users WHERE login = ?"" and then ps.setString(1 ""vasya""); But how can I query for list of logins: ""SELECT * FROM users WHERE login IN ?"" suppose I have List<String> logins = ... What should I type there: ps.setWhat(1 what); I could rewrite query as: ""SELECT * FROM users WHERE login = ? OR login = ? OR login = ?"" and then call setString in loop but I'd like to know if it is possible to pass a set of elements as single param in query. Maybe there are vendor-specific extensions? //--- String query = ""SELECT * FROM users WHERE login = ?""; List<Login> list = new ArrayList<Login>(); Login login = null; for(String param : conditions){ pStmt.setString(1param); rSet = pStmt.executeQuery(); if(rSet.next()){ login = new Login(); login.setName(rSet.getString(1)); list.add(login); } } return list; //--- conditions will be the list of item on basis of which you want to retrieve fields. Edited my answer might help you. It is not what I asked. That's simply sending queries in a loop. It should be very inefficient compared to using a generated query (if the collection is reasonably large).  There are vendor specific ways to do that therefore it would be good to know what database you use. I know solutions for PostgreSQL and H2. I implemented this feature in the H2 database so that's what I know best: H2 Database PreparedStatement prep = conn.prepareStatement( ""SELECT * FROM users WHERE login IN (?)""); prep.setObject(1 new Object[] { ""1"" ""2"" }); ResultSet rs = prep.executeQuery(); PostgreSQL WHERE login = ANY(?) Then set the parameter to an array of values using PreparedStatement.setArray(..) (not setObject as for H2).  Look here for an overview of available options. As far as I can tell you everyone is dynamically generating the necessary number of placeholder characters (with some optimizations). There's a setArray method in PreparedStatement but sometimes using it is not feasible. You might give it a try though. If Spring's JDBCTemplate is an option you could use automatic collection expansion as described here. There is no reason that you cannot use Spring for this and you should as you get a real exception hierarchy for free."
716,A,"creating sybase stored procedure that returns jdbc statement.getWarning I am creating a sybase stored prodedure that is being called through JDBC. Under certain error conditions i want my stored procedure to return a warning to the JDBC caller. What do i need to add to the stored procedure so Statement.getWarnings() returns a SqlWarning that contains an error message of my choice? Unless I'm mistaken you can remap SQL exceptions to SQL warnings using error message handlers. More information can be found in the jConnect 6 Programmer's Reference. Information is available on how to create a custom message handler is available in Chapter 2 in the section on handling error messages. This of course means that you will still have to raise errors via raiserror in the stored procedure with the only benefit that you can remap certain errors to warnings. The complexity of the message handler will be proportional to the number of user errors raised by your stored procedure. The reason why SQLExceptions will be raised instead of SQLWarnings when you raise an error from the stored procedure is because Sybase automatically sets the severity of user errors to 16 - termed as ""Miscellaneous User Error"". Errors of severity level 16 are automatically converted to SQLExceptions."
717,A,DB2 jdbc performance doing profiling on an java application running websphere 7 and DB2 we can see that we spend most of our time in the com.ibm.ws.rsadapter.jdbc package handling connections to and from the database. How can we tune our jdbc performance? What other strategies exist when database performance is a bottleneck? Thanks In my experience what you are seeing is pretty common. The question to ask is what exactly is the DB2 connection doing... The first thing to do is to try and isolate the performance issue down to a section of the website - i.e. is there one part of the application that see poor performance when you find that you can increase the trace logging to see if you can see the query causing issues. Additionally if you chat to your DBA's they may be able to run some analysis on the database to tell you what queries are taking the time to return values this may also help in your troubleshooting. Good luck! I think its time to talk to the DBA.  Connection pooling Caching DBAs  You should check your websphere manual for how you configure a connection pool. Here is an introduction inculding code samples Thanks for the links we have a connection pool but I am not sure how to measure on the DB2 side.  One cause of slow connect times is a deactivated database which does not open its files and allocate its memory buffers and heaps until the first application attempts to connect to it. Ask your DBA to confirm that the database is active before running your tests. The LIST ACTIVE DATABASES command (run from the local DB2 server or over a remote attachment) should show your database in its output. If the database is not activated have your DBA activate it explicitly with ACTIVATE DATABASE yourDBname. That will ensure that the database files and memory structures remain available even when the last user disconnects from the database. Use GET MONITOR SWITCHES to ensure all your monitor switches are enabled for your database otherwise you'll miss out on some potentially revealing performance details. The additional overhead of tracking the data associated with those monitor switches is minimal while the value of the performance data is significant. If the database is always active and things still seem slow there are detailed DB2 traces called event monitors that log everything they encounter to a file pipe or DB2 table. The statement event monitor is one I turn to fairly often to analyze SQL statement efficiency and UOW hygiene. I also prefer taking the extra hit to log the event monitor records to a table rather than a file so I can use SQL to search the data for all sorts of patterns. The db2evtbl utility makes it fairly easy to define the event monitor you want and create the tables to store its output. The SET EVENT MONITOR STATE command is how you start and stop the event monitor you've created. Thanks are these applicable on iseries DB2 as well?
718,A,"JDBC- postgres connection refused This is my first time using java to access databases so I probably have a simple mistake here but when I go to retrieve my connection from a remote database I have access to I get a connection refused. Here's the code in question: String url = ""jdbc:postgresql:url.isformatted.like.this/database""; try { conn = DriverManager.getConnection(url ""username"" ""password""); } catch (SQLException e) { e.printStackTrace(); System.exit(1); } (user/pass and database url removed for privacy sake) The problem couldn't be credentials or the URL itself as I use it to manually log in from the same box successfully using psql. I'm thinking it's probably the formatting of the URL but I couldn't find any examples of psql being used on a remote address (they were all local host kinda things) I would agree with @Jonathan about having the PostgreSQL JDBC jar library on you classpath: here is what I used: private static final String TABLE_NAME = ""tablenamegoeshere""; private static final String DRIVER = ""org.postgresql.Driver""; private static final String URL = ""jdbc:postgresql://url.for.database/DatabaseName""; private static final String USERNAME = ""yourusername""; private static final String PASSWORD = ""yourpassword""; private static Connection getConnection() throws Exception { Class.forName(DRIVER); Connection conn = DriverManager.getConnection(URL USERNAME PASSWORD); return conn; }  I just looked ad my code which connects to a PostgreSQL database and it looks like this: DriverManager.getConnection(String.format(""jdbc:postgresql://%s/%s"" server dbName) userName password); Also make sure you're loading the PostgreSQL database driver before trying to connect: Class.forName(""org.postgresql.Driver""); and that the PostgreSQL JDBC Jar library is on your classpath.  According to http://www.petefreitag.com/articles/jdbc%5Furls/ valid urls are  jdbc:postgresql:database jdbc:postgresql://host/database jdbc:postgresql://host:port/database jdbc:postgresql://host:port/database?user=userName&password=pass jdbc:postgresql://host:port/database?charSet=LATIN1&compatible=7.2 Do you have the // before the host? nope I didnt! (I saw the // in the localhost kinda examples but I thought it applied only to local databases) THANKYOU!"
719,A,"Jython zxJDBC cursor.tables() always returns None I am using Jython 2.2.1 and MySQL Connector/J 5.1 to access a MySQL database. I would like to use zxJDBC's cursor.tables() method to retrieve a list of tables in that database. However this method always returns None. According to the zxJDBC documentation cursor.tables() is the same as Java's DatabaseMetaData.getTables(). When I call this Java method from Jython it works as expected but using the zxJDBC package doesn't work for me. Here's what I have tried: import java.sql.*; public class TableTest { public static void tables(String url) { try { Class.forName(""com.mysql.jdbc.Driver""); Connection conn = DriverManager.getConnection(url ""root"" null); DatabaseMetaData meta = conn.getMetaData(); ResultSet rs = meta.getTables(null null ""%"" new String[] {""TABLE""}); while (rs.next()) { System.out.println(rs.getString(""TABLE_NAME"")); } } catch (Exception e) { e.printStackTrace(); } } } When I call this from Jython it is all fine. from com.ziclix.python.sql import zxJDBC import TableTest url = 'jdbc:mysql://localhost/jythontest' print 'Java:' TableTest.tables(url); print 'Python:' conn = zxJDBC.connect(url 'root' None 'com.mysql.jdbc.Driver') cursor = conn.cursor() print cursor.tables(None None '%' ('TABLE')) There are two tables in my test database called 'table_a' and 'table_b'. The output is: Java: table_a table_b Python: None I have tried this on Linux and on MacOS with the same result. Before I try to figure out what's wrong with zxJDBC I wanted to know whether there is anything wrong in the way I am using this package. Thank you. Try a print cursor.fetchall() after your cursor.tables() from com.ziclix.python.sql import zxJDBC import TableTest url = 'jdbc:mysql://localhost/jythontest' print 'Java:' TableTest.tables(url); print 'Python:' conn = zxJDBC.connect(url 'root' None 'com.mysql.jdbc.Driver') cursor = conn.cursor() print cursor.tables(None None '%' ('TABLE')) print cursor.fetchall() (tested with Informix and jython 2.5 beta) i assume: cursor.tables() excutes the query in python cursor.fetchall() returns the results"
720,A,"Setting session timezone with spring jdbc oracle I have a spring/jdbc/oracle 10g application. The Oracle server database timezone is set to GMT + 2 JVM timezone is GMT + 2 (even though it doesn't matter in my case). I have a stored procedure that performs some date operations. The problem is that session timezone is different(GMT) than database timezone even though I do not set session timezone explicit in my code/configuration. As far as I know the session timezone is by default equal to database timezone. Any idea why is the session timezone different than database timezone or how can I configure it in spring configuration (org.apache.commons.dbcp.BasicDataSource) ? Thank you. Which session do you mean? Oracle connection session or HTTP session? The former I assume? This solve your problem? I need to do the same on MySQL and I'm still looking for how to do it! I have questions/posts that stay in this DEAD mode!! No answers no confirmations no speculations!! I solved this problem by upgrading Oracle's JDBC drivers from v10.2.0.1.0 to v11.2.0.3. No changes to my java code were required. Source: Spring forums.  The correct way is to use DelegatingDataSource retrieve OracleConnection object from the original data source and call OracleConnection.setSessionTimeZone() with the appropriate parameter. C3P0 code looks like: private Object[] timeZoneArgs = new Object[] { ""Europe/Berlin"" }; @Override public Connection getConnection() throws SQLException { Connection conn = super.getConnection(); try { final Method setSessionTimeZoneMethod = OracleConnection.class.getMethod(""setSessionTimeZone"" String.class); final C3P0ProxyConnection castCon = (C3P0ProxyConnection) conn; castCon.rawConnectionOperation(setSessionTimeZoneMethod C3P0ProxyConnection.RAW_CONNECTION timeZoneArgs); return conn; } catch (Exception e) { log.error(""setSessionTimeZone failed "" + e.getMessage()); return conn; } }"
721,A,"Java ResultSet getString weirdness? This one has me stumped. I've got a java.sql.ResultSet and I'm pulling string values out of it like so: address.setAddressLine1(rs.getString(""AddressLine1"")); address.setAddressLine2(rs.getString(""AddressLine2"")); When I debug and inspect rs.getString(""AddressLine1"") the debugger says I've got a 30 character string: ""ATTN: ACCOUNTS PAYABLE"" (trailing spaces removed). However when I inspect my address object immediately after this line it's reporting that addressLine1 is a 30 character string of spaces or some other whitespace. When I debug and inspect rs.getString(""AddressLine2"") the debugger says that I've got a 23 character string: ""10 Something Street"" (trailing spaces removed). When I inspect my address object immediately after this line it's reporting addressLine2 is null. What's really driving me nuts is that this isn't happening with every value only a few. My address class is storing plain old strings with totally dumb getters and setters. Really I promise! This is cut & paste with other dumb properties removed: public class Address implements java.io.Serializable { private static final long serialVersionUID = 1L; private String addressLine1; private String addressLine2; public String getAddressLine1() { return addressLine1; } public void setAddressLine1(String addressLine1) { this.addressLine1 = addressLine1; } public String getAddressLine2() { return addressLine2; } public void setAddressLine2(String addressLine2) { this.addressLine2 = addressLine2; } } What in the heck is going on here? Is it some kind of weird scoping problem? Is it some kind of character encoding thing? P.S. - I'm using spring's SimpleJdbcTemplate and the ""pseudo database"" I'm talking to is ProvideX which I'm accessing via ODBC (sun.jdbc.odbc.JdbcOdbcDriver). Note what the javadocs say about ResultSet: ""For maximum portability result set columns within each row should be read in left-to-right order and each column should be read only once."" So when you're reading the column by using the debugger that's one read then your code reads it a second time when setAddressLine1 is called. How does it behave when you only look at addressLine1 and don't fiddle with the ResultSet? I just noticed that you're going through ODBC; you probably want to strive for maximum portability in that case as compared to a regular jdbc driver. The same. When I don't debug and just look at the output my addressLine1 value is 30 character string of whitespace and addressLine2 is null. If I create a temp String like this: String tmp = rs.getString(""AddressLine1""); and debug the value of tmp is correct. I'm really at a loss here. Uh why can't you do `String tmp = rs.getString(""AddressLine1""); address.setAddressLine1(tmp);`? Is it now just a matter of getting to the bottom of it? Actually I just tried that... same result. The way it behaves in the debugger is not terribly predictable. Ok I found a goof in my code where I checked a column twice. Fixing this and making things nice per lumpynose's suggestions (e.g. left-to-right reading order) got everything working. Thanks!"
722,A,"I want to create a login page using servlets I want to create a login page using Servlet & JSP. I ve created a page which gets Username & password. I made a database with a table which contains Username & password. <form action=""LoginPage"" method=""POST""> User name: <input type=""text"" name=""userName"" size=""20""><br> Password: <input type=""password"" name=""password"" size=""20""> <br><br> <input type=""submit"" value=""Submit""> </form> I entered the below code in doPost()  response.setContentType(""text/html;charset=UTF-8""); PrintWriter out = response.getWriter(); String userName = request.getParameter(""userName"").toString(); String passWord = request.getParameter(""password"").toString(); Connection con = null; String url = ""jdbc:mysql://localhost:3306/""; String dbName = ""userdb""; String driver = ""com.mysql.jdbc.Driver""; String user = ""root""; String password = ""1234""; try { Class.forName(driver).newInstance(); Connection conn = DriverManager.getConnection(url+dbName user password); PreparedStatement pstmt; String sql = ""SELECT USR_NAME FROM LOGIN WHERE USR_NAME='userName'""; pstmt = conn.prepareStatement(sql); ResultSet rs=pstmt.executeQuery(); String usr = null; String pass = null; while(rs.next()) { pass = rs.getString(3); } if(pass != null && pass.equals(passWord)) { out.println(""<html>""); out.println(""<head>""); out.println(""<title>Login Sucessfull</title>""); out.println(""</head>""); out.println(""<body>""); out.println(""<h1>Login Sucessfull "" + request.getContextPath () + ""</h1>""); out.println(""<p>Welcome</p> "" + userName); out.println(""</body>""); out.println(""</html>""); out.close(); } } catch (Exception e) { out.println(""<html>""); out.println(""<head>""); out.println(""<title>Login is not Sucessfull</title>""); out.println(""</head>""); out.println(""<body>""); out.println(""<h1>Login is not Sucessfull "" + request.getContextPath () + ""</h1>""); out.println(""<p>Wrong Username Or Password</p> ""); out.println(""</body>""); out.println(""</html>""); out.close(); And I dont know how to make it work. Any Quick Fix Available For me? Its not a big project i jus want a Login page which gets username & password then the servlet will search the username in DB then checks for password. I have made the changes you guys told. But the output looks like something wrong in try block Because I get the Login not successful page. I put the code ""Login not successful Page"" in Catch block. you should use SELECT PASSWORD from Login in the sql query here PASSWORD is the column name which contains password in your database table LOGIN  I am seeing problems with the lines:  String sql = ""SELECT USR_NAME FROM LOGIN WHERE USR_NAME='userName'""; pstmt = conn.prepareStatement(sql); ResultSet rs=pstmt.executeQuery(); String usr = null; String pass = null; It should be: String sql = ""SELECT * from LOGIN WHERE USR_NAME=""+ userName+"";""; Also check the table name for the login information as you have it as LOGIN sure it isn't login? Also i would avoid writing HTML in the servlet and just let it forward to another JSP. It could just be something simple for now. Saying Logged in. Dean  toString() for request.getParameter is not required. You can modify your query to String sql = ""SELECT <PASSWORD_CLM> FROM LOGIN WHERE USR_NAME=""+userName; while(rs.next()) { //read the password in pass. } if(pass !=null && pass.equals(passWord)) { // Code } You do need to put the semi colon at the end of the SQL statement even with Prepared statements though. @Dean: this is not true. This is only required when you want to pass multiple statements in one query. The semicolon is then the statement separator. Also note that whether it is accepted is DB dependent.  It's unclear what you mean with ""How to make it work"". What happens? What happens not? At least I can spot several problems in your code: You are emitting HTML inside a servlet. You should use JSP for this. You are leaking JDBC resources. You need to close them in finally. You are not setting the entered username (and password) in the SQL string. You are not letting the DB do the task of comparing the password. Add it to the WHERE. You are swallowing the exception. All detailed info about the problem cause get lost. You should either rethrow it as ServletException or at least log the exception type message and cause. This information is important since it tells something about the root cause of the problem. You know once the root cause is understood the solution is obvious. Further it's also bad user experience if you change the page to a page where the user can do absolutely nothing else than facing an error message. The user has to take extra handling to go back to the login page to re-enter the details. Rather redisplay the same page with the error message inlined. Rewrite your doPost() method as follows: String userName = request.getParameter(""userName""); String passWord = request.getParameter(""password""); String driver = ""com.mysql.jdbc.Driver""; String url = ""jdbc:mysql://localhost:3306/""; String dbName = ""userdb""; String user = ""root""; String password = ""1234""; String sql = ""SELECT * FROM LOGIN WHERE USR_NAME = ? AND USR_PASS = ?""; // Not sure how the password column is named you need to check/update it. You should leave those ? there! Those are preparedstatement placeholders. Connection connection = null; PreparedStatement statement = null; ResultSet resultSet = null; boolean login = false; try { Class.forName(driver); // You don't need to call it EVERYTIME btw. Once during application's startup is more than enough. connection = DriverManager.getConnection(url + dbName user password); statement = connection.prepareStatement(sql); statement.setString(1 userName); statement.setString(2 password); resultSet = statement.executeQuery(); login = resultSet.next(); } catch (Exception e) { throw new ServletException(""Login failed"" e); } finally { if (resultSet != null) try { resultSet.close(); } catch (SQLException ignore) {} if (statement != null) try { statement.close(); } catch (SQLException ignore) {} if (connection != null) try { connection.close(); } catch (SQLException ignore) {} } if (login) { request.getSession().setAttribute(""username"" userName); // I'd prefer the User object which you get from DAO but ala. response.sendRedirect(""home.jsp""); // Redirect to home page. } else { request.setAttribute(""message"" ""Unknown username/password try again""); // This sets the ${message} request.getRequestDispatcher(""login.jsp"").forward(request response); // Redisplay JSP. } And add ${message} to your JSP: <form action=""LoginPage"" method=""POST""> User name: <input type=""text"" name=""userName"" size=""20""><br> Password: <input type=""password"" name=""password"" size=""20""> <br><br> <input type=""submit"" value=""Submit""> ${message} </form> Here are some links to learn how to do JSP/Servlet/JDBC properly. Beginning and Intermediate JSP/Servlet tutorials Advanced JSP/Servlet tutorials (with JDBC) DAO tutorial - How to create a proper data layer DAO tutorial - Using in JSP/Servlet"
723,A,"What is the best practice to deploy database config (username/password) with Java web-app (web.xml)? I have a Java web-app using standard web.xml and servlets. At the moment I'm using the <context-param> tags in web.xml to define the database configuration (JDBC url username password etc.). These are picked up by a servlet in its init() method. But I'd like to not include database username/password in my source repository. For testing I'm using jetty-maven-plugin. With that I specify an option overrideDescriptor with a supplementary web.xml that is applied after the primary web.xml. I put my testing database configuration in this supplementary file and everything works great. For deployment my host is using Tomcat. I'm not sure how to apply a database config here. Is there a similar way to specify a supplementary web.xml file? If not what is the best practice to do this? Read the configuration from a separate properties file (or similar) included as a resource? You could always store the configuration in an external .properties file change your servlet to read from this instead (perhaps having web.xml point at the path to the file) and thus keep the file only on the server and out of source control.  You should be using connection pools and JNDI. You keep the credentials on the server that way. Users only need the JNDI lookup name (e.g. ""jdbc/FooDataSource"") to access the connection pool. Thanks this seems to be the ""correct"" way to do it. I've found some [Tomcat examples](http://tomcat.apache.org/tomcat-4.1-doc/jndi-datasource-examples-howto.html) on how to set this up. And for completeness [Jetty examples](http://docs.codehaus.org/display/JETTY/DataSource+Examples). You can use the `` configuration to set up the environment when using the [jetty-maven-plugin](http://wiki.eclipse.org/Jetty/Feature/Jetty_Maven_Plugin#Running_an_Unassembled_webapp_with_mvn_jetty:run) for testing. The connection pool should be in the container not the web application.  ""Read the configuration from a separate properties file (or similar) included as a resource?"" Yes. There are lots of ways to do THAT too. My current project uses Spring's PropertyPlaceholderConfigurer to read the appropriate properties files and allow any of the values to be used in a context file using the usual ${whatever} notation. Addition: Incidentally we use a custom subclass of PropertyPlaceholderConfigurer to set the locations of the files. We use a ""global"" properties file that applies to all environments (dev test uat prod) and then one file for each environment that overrides the global settings. The files themselves are deployed in a jar but we don't need the flexibility of changing the values on the fly.  In your application-context.xml  you can use the place holders and point the location of the placeholder's parameters to external properties file. <bean id=""propertyConfigurer"" class=""org.springframework.beans.factory.config.PropertyPlaceholderConfigurer""> <property name=""location""> <value>/WEB-INF/database-config.properties</value> </property> </bean> <bean id=""dataSource"" class=""org.apache.commons.dbcp.BasicDataSource"" destroy-method=""close""> <property name=""driverClassName"" value=""${jdbc.driver}""/> <property name=""url"" value=""${jdbc.url}""/> <property name=""username"" value=""${jdbc.user}""/> <property name=""password"" value=""${jdbc.password}""/> </bean> In your database-config.properties file. You can provide the placeholder's parameters. In this case database settings. jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/school?useUnicode=true&characterEncoding=UTF-8 jdbc.user=root jdbc.password=root"
724,A,"How do I manually configure a DataSource in Java? I'm trying to follow Sun's JDBC tutorial at http://java.sun.com/docs/books/tutorial/jdbc/basics/connecting.html It gives the following example code: DataSource ds = (DataSource) org.apache.derby.jdbc.ClientDataSource() ds.setPort(1527); ds.setHost(""localhost""); ds.setUser(""APP"") ds.setPassword(""APP""); Connection con = ds.getConnection(); This code doesn't compile because the DataSource interface has none of these methods except for the getConnection() method invoked last. (Here's the javadoc: http://java.sun.com/javase/6/docs/api/javax/sql/DataSource.html) What am I missing? Edit: I'm actually trying to connect to MySQL (com.mysql.jdbc) and I can't find the javadoc for that. I'll accept an answer that points me to either: 1) documentation for com.mysql.jdbc regarding a DataSource that I can understand or 2) gives an example to follow for what the tutorial's code should be for any database. DataSource is vendor-specific for MySql you could use MysqlDataSource which is provided in the MySql Java connector jar:  MysqlDataSource dataSource = new MysqlDataSource(); dataSource.setDatabaseName(""xyz""); dataSource.setUser(""xyz""); dataSource.setPassword(""xyz""); dataSource.setServerName(""xyz.yourdomain.com""); If you are going to answer a question asked 4.5 years ago it would be good to indicate why the current answers are insufficient.  One thing you might want to look at is the Commons DBCP project. It provides a BasicDataSource that is configured fairly similarly to your example. To use that you need the database vendor's JDBC JAR in your classpath and you have to specify the vendor's driver class name and the database URL in the proper format. Edit: If you want to configure a BasicDataSource for MySQL you would do something like this: BasicDataSource dataSource = new BasicDataSource(); dataSource.setDriverClassName(""com.mysql.jdbc.Driver""); dataSource.setUsername(""username""); dataSource.setPassword(""password""); dataSource.setUrl(""jdbc:mysql://<host>:<port>/<database>""); dataSource.setMaxActive(10); dataSource.setMaxIdle(5); dataSource.setInitialSize(5); dataSource.setValidationQuery(""SELECT 1""); Code that needs a DataSource can then use that. This answer deserves more up-votes. I used this post to create unit tests Thanx heaps.... xml was doing my head in....  Basically in JDBC most of these properties are not configurable in the API like that rather they depend on implementation. The way JDBC handles this is by allowing the connection URL to be different per vendor. So what you do is register the driver so that the JDBC system can know what to do with the URL:  DriverManager.registerDriver((Driver) Class.forName(""com.mysql.jdbc.Driver"").newInstance()); Then you form the URL:  String url = ""jdbc:mysql://[host][failoverhost...][:port]/[database][?propertyName1][=propertyValue1][&propertyName2][=propertyValue2]"" And finally use it to get a connection:  Connection c = DriverManager.getConnection(url); In more sophisticated JDBC you get involved with connection pools and the like and application servers often have their own way of registering drivers in JNDI and you look up a DataSource from there and call getConnection on it. In terms of what properties MySQL supports see here. EDIT: One more thought technically just having a line of code which does Class.forName(""com.mysql.jdbc.Driver"") should be enough as the class should have its own static initializer which registers a version but sometimes a JDBC driver doesn't so if you aren't sure there is little harm in registering a second one it just creates a duplicate object in memeory. @Yishai: Thanks for that clarification. And yes this tutorial overall is not up to Sun's usual standards. Well that works. I wanted the DataSource as the tutorial said it was preferred but I'll take it. DataSource is really for application servers and other containers that supply a JNDI service. Without a JNDI service they don't make much sense and the tutorial is honestly not really well written on that point. You could create your own class to implement the DataSource interface using the code above for the getConnection methods. Beyond that you only need to implement getters and setters for loginTimeout and LogWriter. One important advantage of Datasource is to be able to rely on a connection pool  I think the example is wrong - javax.sql.DataSource doesn't have these properties either. Your DataSource needs to be of the type org.apache.derby.jdbc.ClientDataSource which should have those properties.  The javadoc for DataSource you refer to is of the wrong package. You should look at javax.sql.DataSource. As you can see this is an interface. The host and port name configuration depends on the implementation i.e. the JDBC driver you are using. I have not checked the Derby javadocs but I suppose the code should compile like this: ClientDataSource ds = org.apache.derby.jdbc.ClientDataSource() ds.setHost etc...."
725,A,"How to connect to Oracle using JRuby & JDBC First approach: bare metal require 'java' require 'rubygems' require ""c:/ruby/jruby-1.2.0/lib/ojdbc14.jar"" # should be redundant but tried it anyway odriver = Java::JavaClass.for_name(""oracle.jdbc.driver.OracleDriver"") puts odriver.java_class url = ""jdbc:oracle:thin:@myhost:1521:mydb"" puts ""About to connect..."" con = java.sql.DriverManager.getConnection(url ""myuser"" ""mypassword""); if con puts "" connection good"" else puts "" connection failed"" end The result of the above is: sqltest.rb:4: cannot load Java class oracle.jdbc.driver.OracleDriver (NameError) Second approach: Active Record require 'rubygems' gem 'ActiveRecord-JDBC' require 'jdbc_adapter' require 'active_record' require 'active_record/version' require ""c:/ruby/jruby-1.2.0/lib/ojdbc14.jar"" # should be redundant... ActiveRecord::Base.establish_connection( :adapter => 'jdbc' :driver => 'oracle.jdbc.driver.OracleDriver' :url => 'jdbc:oracle:thin:@myhost:1521:mydb' :username=>'myuser' :password=>'mypassword' ) ActiveRecord::Base.connection.execute(""SELECT * FROM mytable"") The result of this is: C:/ruby/jruby-1.2.0/lib/ruby/gems/1.8/gems/activerecord-jdbc-adapter-0.9.1/lib/active_recordconnection_adapters/jdbc_adapter.rb:330:in `initialize': The driver encountered an error: cannot load Java class oracle.jdbc.driver.OracleDriver (RuntimeError) Essentially the same error no matter how I go about it. I'm using JRuby 1.2.0 and I have ojdbc14.jar in my JRuby lib directory Gems: ActiveRecord-JDBC (0.5) activerecord-jdbc-adapter (0.9.1) activerecord (2.2.2) What am I missing? Thanks Originally posted to Nabble http://www.nabble.com/Having-problems-accessing-Oracle-td23070394.html I guess they get propigated to Ruby Forum somehow... I'll be interested to see if SO can beat the ruby forum (http://www.ruby-forum.com/topic/184414) Have you got the Oracle client installed? you probably need at least the jdbc driver files from the client Yes but I did not think it would be required with this ""thin"" connection type. yeah the jar is typically enough.   require 'java' # This require doesn't load the jdbc driver jar into the system class path require ""c:/ruby/jruby-1.2.0/lib/ojdbc14.jar"" # 2 ways you can load the class (There are probably more) # 1 ruby syntax for java class name Java::OracleJdbcDriver::OracleDriver # 2 Use the thread context class loader java.lang.Class.forName(""oracle.jdbc.driver.OracleDriver"" true java.lang.Thread.currentThread.getContextClassLoader) url = ""jdbc:oracle:thin:@myhost:1521:mydb"" puts ""About to connect..."" con = java.sql.DriverManager.getConnection(url ""myuser"" ""mypassword""); if con puts "" connection good"" else puts "" connection failed"" end  It turns out that my ojdbc14.jar file was corrupt. Further the jar file MUST be in the jruby/lib directory. Simply having it on the classpath does not work. appears these days having it in the (jruby specific) CLASSPATH environment variable is also enough but just doing a require 'ojdbc14.jar' is not. also appears that these days you just need to require the jar it doesn't have to be in the lib dir anymore (1.6.0RC2)  Ummm I'm a little confused. Tried this myself today with JRuby 1.5.3 and Oracle ojdbc6.jar JVM(IBM Java 6) and I'm getting NativeException: java.sql.SQLException: No suitable driver from java/sql/DriverManager.java:320:in 'getConnection' from java/sql/DriverManager.java:348:in 'getConnection' However I've set everything up just as OP listed in his post and I'm getting nothing. I was confused about Brian Castillo's answer although I tried that as well. Anyone shed some light on this question again even though its a bit old? I'm not working at an Oracle site any more (hooray!) but I would suggest trying the activerecord-jdbc-adapter gem - it's quite actively developed. http://github.com/nicksieger/activerecord-jdbc-adapter this is not the place to hijack old questions make a new one for yourself.  and then to use it after creation:  b = con.create_statement rs=b.execute_query(“select BANNER from SYS.V_$VERSION”) while(rs.next()) p rs.getObject(1) # get first column end rs.close and how to deal with oracle timestamps (if column 3 is a timestamp for example): >> rs.getObject(3).timestamp_value.to_string => “1970-01-01 00:00:01.0″ >> Date.parse(rs.getObject(3).timestamp_value.to_string) # or you can use time like >> as_ruby_time= Date.parse(rs.getObject(3).timestamp_value.to_string).to_time # 1.9 has this method # or >> as_ruby_time = Time.at(0) + rs.getObject(3).timestamp_value.get_time"
726,A,"How to disable Postgresql messages translation Is there a way to disable the Postgresql translation of messages? I´m running my appl and Postgresql on a pt_BR Windows machine and when a exception is thrown the error message is translated to Portuguese like: Caused by: org.postgresql.util.PSQLException: ERRO: relação ""unidade_federacao"" não existe Posição: 25 I would like the messages to appear in English. I´m using the driver postgresql-8.4-701.jdbc3.jar on a Java (with Hibernate) app. thanks in advance Fabrício Lemos You could change lc_messages in postgresql.conf or just per database: ALTER DATABASE dbname SET lc_messages=en_us; See also the manual. Thank you Frank. I edited postgresql.conf changing lc_messages = 'Portuguese_Brazil.1252' to lc_messages=en_us. Now it works fine!"
727,A,JDBC Licensing - Packaging jdbc in jar I'm packaging my open-source non-commercial java application in a .jar and I'd like to package the JDBC mysql-connector with it as it is a dependency. The issue that I am having is that I'm uncertain whether or not this is frowned upon or even illegal due to the JDBC license. I've also got the jdbc mysql-connector jar in my code repository. -- Has anyone been in the same situation? Thanks in advance. What is your code's license? What version of Connector/J? I haven't thought about my code's license as it's a small project so I'm pretty much open to all suggestions and frankly it's not that important to me. I just want to get it right with JDBC and all. The Connector/J version is 5.1.12 Expanding on @matt b's answer and your comment above: given that MySQL Connector/J may be redistributed under the terms of the GPL and you haven't yet chosen a license one simple expedient would be to license your own code the same way. Fine print: I am not a lawyer.  This email looks a little old but according to http://forums.mysql.com/read.php?393679936827 mysql-connector-j is licensed under GPL. I'm having a hard time understanding these 20 page long license texts. If the connector is under GPL does this mean I am not allowed to package the connector inside of my jar? @John yes but you must follow the terms of the GPL. This is a pretty good exploration of what that means: http://articles.sitepoint.com/article/public-license-explained Thanks Matt. Now that's an explanation I can wrap my head around :-)
728,A,"Is JDBC capable of handling huge database? I am working on a project which is having huge database. [ around 32gb data in one week ]. We are using DB2 and spring-framework + jdbc. I just wanted to know is JDBC capable of handling this much of data? Or should i use something else? Or if JDBC is capable of doing this then should i use some specific technique for this thing. It all depends on the processing you would be doing on the database. How many tables will you be accessing at any time and also will it be more writes or reads from the database. Based on that you can design it. You can also look at using an ORM solution like hibernate which integrates well with spring. This will provide you some options like caching to avoid direct db access every time. Also you should setup some connection pooling to reuse connections. ""How many tables will you be accessing at any time"" we are not having more than 20 tables. At any point of time we are fetching from at max 6-7 tables.  Although your SQL API and database abstraction layer are important the biggest impact on the performance and maintainability of your database will be the indexing clustering and partitioning scheme your DBA will use for managing the significant amounts of data being inserted every week. The most powerful features in these areas are available in the enterprise version of the DB2 data engine for Linux UNIX and Windows. I would recommend looking at a combination of multi-dimensional clustering (MDC) range table partitioning and deep compression to manage the table as it grows facilitate easy roll-in/roll-out and most importantly to quickly zero in on the data requested with a minimum of scanning. You may also benefit from materialized query tables (MQTs). Version 9.7 of DB2 which IBM released very recently offers noteworthy enhancements to several of those features most notably an aggressive compression scheme for indexes. Thanks Fred actually Database optimization is not on my hand. But yes i will let tht mate know about these things  JDBC is just the interface between the database and the java program. It's up to the database to handle that amount of data. In the java world there is hardly an alternative to using JDBC when it comes to database connectivity.  JDBC is just the connection - it doesn't care how much data is in the database. I'd expect it to be more of an issue at the database side if anywhere. If you've got indexes which are expensive to create etc you're more likely to have issues - but to be honest 32GB in a week isn't really that big. I'd expect any ""real"" server-side database to handle it fairly easily. I suggest you try it before committing yourself too far down any particular path. Chuck data at it as quickly as you can. I'd be slightly worried if you couldn't create 32GB of data in a few hours. so chuck Oops i mean Jon :D according to you it is just the DBA who will have to care about this not me. Almost certainly. JDBC just represents the pipe through which you're pumping the data. Obviously it incurs *some* overhead to process the data but that's unlikely to be significant."
729,A,"To prevent a memory leak the JDBC Driver has been forcibly unregistered I am getting this message when I run my web application. It runs fine but I get this message during shutdown. SEVERE: A web application registered the JBDC driver [oracle.jdbc.driver.OracleDriver] but failed to unregister it when the web application was stopped. To prevent a memory leak the JDBC Driver has been forcibly unregistered. Any help appreciated. Could be duplicate of http://stackoverflow.com/questions/2604630/tomcat-fails-to-start-because-of-jdbc-driver-loading Removing the app (tomcat6) solves it. The conf files are preserved. It breaks itself somehow. I am not really sure how it does it. Does it answer the question? Shouldn't it be a comment?  I did not check these solutions! For this I just simply change my tomcat with a new fresh tomcat and configs and everything got happy !  I see this issue come up a lot. Yes Tomcat 7 does automatically deregister it but it that REALLY taking control of your code and a good coding practice? Surely YOU want to know that you have all the correct code in place to close all your objects shut down database connection pool threads and get rid of all warnings. I certainly do. This is how I do it. Step 1: Register a Listener web.xml <listener> <listener-class>com.mysite.MySpecialListener</listener-class> </listener> Step 2: Implement the Listener com.mysite.MySpecialListener.java public class MySpecialListener extends ApplicationContextListener { @Override public void contextInitialized(ServletContextEvent sce) { // On Application Startup please… // Usually I'll make a singleton in here set up my pool etc. } @Override public void contextDestroyed(ServletContextEvent sce) { // On Application Shutdown please… // 1. Go fetch that DataSource Context initContext = new InitialContext(); Context envContext = (Context)initContext.lookup(""java:/comp/env""); DataSource datasource = (DataSource)envContext.lookup(""jdbc/database""); // 2. Deregister Driver try { java.sql.Driver mySqlDriver = DriverManager.getDriver(""jdbc:mysql://localhost:3306/""); DriverManager.deregisterDriver(mySqlDriver); } catch (SQLException ex) { logger.info(""Could not deregister driver:"".concat(ex.getMessage())); } // 3. For added safety remove the reference to dataSource for GC to enjoy. dataSource = null; } } Please feel free to comment and/or add... It looks so lovely when your application ends and your logs just say: [INFO]Shutting down application. [INFO]Closing connection pool. [INFO]Deregistering MySQLDriver. [INFO]Closing Log FileHandler. But `DataSource` does NOT have a `close` method Yes there is no method close() for DataSource. Funnily enough it was there in the version I was using :) Removed it as it's no longer there. The dataSource = null will do the trick instead. [BasicDataSource](http://commons.apache.org/dbcp/api-1.2.2/org/apache/commons/dbcp/BasicDataSource.html) has a close() should it be implements javax.servlet.ServletContextListener not extends ApplicationContextListener? Is there a reason for the order of those operations in the method `contextDestroyed`? Why do you do step 1. before doing step 2. where `initContext` `envContext` and `datasource` are not referenced at all? I'm asking because I don't understand step 3. @matthaeus I think Step 1. is not necessary `lookup` seems to just gets some objects you don't need. Step 3. is completly useless. It certainly doesn't add any safety and looks like something beginners would do who don't understand how GC works. I would just go with http://stackoverflow.com/a/5315467/897024 and remove all drivers. @kapep Removing all drivers is dangerous as some might be shared across the container. See [my answer](http://stackoverflow.com/a/23912257/889583) for an approach which only removes the drivers loaded by your webapp's ClassLoader.  This is purely driver registration/deregistration issue in mysql`s driver or tomcats webapp-classloader. Copy mysql driver into tomcats lib folder (so its loaded by jvm directly not by tomcat) and message will be gone. That makes mysql jdbc driver to be unloaded only at JVM shutdown and noone cares about memory leaks then. that don't works... I tried to copy the jdbc driver has you say: TOMCAT_HOME/lib/postgresql-9.0-801.jdbc4.jar - Tomcat 7.0\lib\postgresql-9.0-801.jdbc4.jar with no results... @Florito - you have to remove it from your web-apps WEB-INF/lib as well  Although Tomcat does forcibly deregister the JDBC driver for you it is nonetheless good practice to clean up all resources created by your webapp on context destruction in case you move to another servlet container which doesn't do the memory leak prevention checks that Tomcat does. However the methodology of blanket driver deregistration is dangerous. Some drivers returned by the DriverManager.getDrivers() method may have been loaded by the parent ClassLoader (i.e. the servlet container's classloader) not the webapp context's ClassLoader (e.g. they may be in the container's lib folder not the webapp's and therefore shared across the whole container). Deregistering these will affect any other webapps which may be using them (or even the container itself). Therefore one should check that the ClassLoader for each driver is the webapp's ClassLoader before deregistering it. So in your ContextListener's contextDestroyed() method: public final void contextDestroyed(ServletContextEvent sce) { // ... First close any background tasks which may be using the DB ... // ... Then close any DB connection pools ... // Now deregister JDBC drivers in this context's ClassLoader: // Get the webapp's ClassLoader ClassLoader cl = Thread.currentThread().getContextClassLoader(); // Loop through all drivers Enumeration<Driver> drivers = DriverManager.getDrivers(); while (drivers.hasMoreElements()) { Driver driver = drivers.nextElement(); if (driver.getClass().getClassLoader() == cl) { // This driver was registered by the webapp's ClassLoader so deregister it: try { log.info(""Deregistering JDBC driver {}"" driver); DriverManager.deregisterDriver(driver); } catch (SQLException ex) { log.error(""Error deregistering JDBC driver {}"" driver ex); } } else { // driver was not registered by the webapp's ClassLoader and may be in use elsewhere log.trace(""Not deregistering JDBC driver {} as it does not belong to this webapp's ClassLoader"" driver); } } } Shouldn't be `if (cl.equals(driver.getClass().getClassLoader())) {` ? @user11153 No we are checking if it is precisely the same ClassLoader instance not if it is two separate instances which are equal in value. Although the others seem to correctly handle the problem in question they cause problems when the war file is deleted and then replaced. In that case the drivers are de-registered and never return - only a Tomcat restart can get you out of that hole. This solution avoids that hell.  I found that implementing a simple destroy() method to de-register any JDBC drivers works nicely. /** * Destroys the servlet cleanly by unloading JDBC drivers. * * @see javax.servlet.GenericServlet#destroy() */ public void destroy() { String prefix = getClass().getSimpleName() +"" destroy() ""; ServletContext ctx = getServletContext(); try { Enumeration<Driver> drivers = DriverManager.getDrivers(); while(drivers.hasMoreElements()) { DriverManager.deregisterDriver(drivers.nextElement()); } } catch(Exception e) { ctx.log(prefix + ""Exception caught while deregistering JDBC drivers"" e); } ctx.log(prefix + ""complete""); } This is potentially unsafe in a shared environment as you might not want to deregister _all_ JDBC drivers that are available. See [my answer](http://stackoverflow.com/a/23912257/889583) for a safer approach. Also this really should be done in a ServletContextListener not on a per-servlet basis as your JDBC driver is shared across all of your servlets in your webapp.  In your servlet context listener contextDestroyed() method manually deregister the drivers:  // This manually deregisters JDBC driver which prevents Tomcat 7 from complaining about memory leaks wrto this class Enumeration<Driver> drivers = DriverManager.getDrivers(); while (drivers.hasMoreElements()) { Driver driver = drivers.nextElement(); try { DriverManager.deregisterDriver(driver); LOG.log(Level.INFO String.format(""deregistering jdbc driver: %s"" driver)); } catch (SQLException e) { LOG.log(Level.SEVERE String.format(""Error deregistering driver %s"" driver) e); } } that works great!! thank you!! Nice! Worked perfectly. It works! http://www.javabeat.net/servletcontextlistener-example/ may help to implement servlet context listener This is potentially unsafe in a shared environment as you might not want to deregister _all_ JDBC drivers that are available. See [my answer](http://stackoverflow.com/a/23912257/889583) for a safer approach.  I was having a similar problem but additionally I was getting a Java Heap Space error anytime I modified/saved JSP pages with Tomcat server running therefore the context were not fully recharged. My versions were Apache Tomcat 6.0.29 and JDK 6u12. Upgrading JDK to 6u21 as suggested in References section of URL http://wiki.apache.org/tomcat/MemoryLeakProtection solved the Java Heap Space problem (context now reloads OK) although JDBC Driver error still appears.  Solution for per-app deployments This is a listener I wrote to solve the problem: it autodetects if the driver has registered itself and acts accordingly.it Important: it is meant to be used ONLY when the driver jar is deployed in WEB-INF/lib not in the Tomcat /lib as many suggest so that each application can take care of its own driver and run on a untouched Tomcat. That is the way it should be IMHO. Just configure the listener in your web.xml before any other and enjoy. add near the top of web.xml: <listener> <listener-class>utils.db.OjdbcDriverRegistrationListener</listener-class> </listener> save as utils/db/OjdbcDriverRegistrationListener.java: package utils.db; import java.sql.Driver; import java.sql.DriverManager; import java.sql.SQLException; import java.util.Enumeration; import javax.servlet.ServletContextEvent; import javax.servlet.ServletContextListener; import oracle.jdbc.OracleDriver; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * Registers and unregisters the Oracle JDBC driver. * * Use only when the ojdbc jar is deployed inside the webapp (not as an * appserver lib) */ public class OjdbcDriverRegistrationListener implements ServletContextListener { private static final Logger LOG = LoggerFactory .getLogger(OjdbcDriverRegistrationListener.class); private Driver driver = null; /** * Registers the Oracle JDBC driver */ @Override public void contextInitialized(ServletContextEvent servletContextEvent) { this.driver = new OracleDriver(); // load and instantiate the class boolean skipRegistration = false; Enumeration<Driver> drivers = DriverManager.getDrivers(); while (drivers.hasMoreElements()) { Driver driver = drivers.nextElement(); if (driver instanceof OracleDriver) { OracleDriver alreadyRegistered = (OracleDriver) driver; if (alreadyRegistered.getClass() == this.driver.getClass()) { // same class in the VM already registered itself skipRegistration = true; this.driver = alreadyRegistered; break; } } } try { if (!skipRegistration) { DriverManager.registerDriver(driver); } else { LOG.debug(""driver was registered automatically""); } LOG.info(String.format(""registered jdbc driver: %s v%d.%d"" driver driver.getMajorVersion() driver.getMinorVersion())); } catch (SQLException e) { LOG.error( ""Error registering oracle driver: "" + ""database connectivity might be unavailable!"" e); throw new RuntimeException(e); } } /** * Deregisters JDBC driver * * Prevents Tomcat 7 from complaining about memory leaks. */ @Override public void contextDestroyed(ServletContextEvent servletContextEvent) { if (this.driver != null) { try { DriverManager.deregisterDriver(driver); LOG.info(String.format(""deregistering jdbc driver: %s"" driver)); } catch (SQLException e) { LOG.warn( String.format(""Error deregistering driver %s"" driver) e); } this.driver = null; } else { LOG.warn(""No driver to deregister""); } } }  I found the same issue with Tomcat version 6.026. I used the Mysql JDBC.jar in WebAPP Library as well as in TOMCAT Lib. To fix the above by removing the Jar from the TOMCAT lib folder. So what I understand is that TOMCAT is handling the JDBC memory leak properly. But if the MYSQL Jdbc jar is duplicated in WebApp and Tomcat Lib Tomcat will only be able to handle the jar present in the Tomcat Lib folder.  I will add to this something I found on the Spring forums. If you move your JDBC driver jar to the tomcat lib folder instead of deploying it with your webapp the warning seems to disappear. I can confirm that this worked for me http://forum.springsource.org/showthread.php?87335-Failure-to-unregister-the-MySQL-JDBC-Driver&p=334883#post334883  Since version 6.0.24 Tomcat ships with a memory leak detection feature which in turn can lead to this kind of warning messages when there's a JDBC 4.0 compatible driver in the webapp's /WEB-INF/lib which auto-registers itself during webapp's startup using the ServiceLoader API but which did not auto-deregister itself during webapp's shutdown. This message is purely informal Tomcat has already taken the memory leak prevention action accordingly. What can you do? Ignore those warnings. Tomcat is doing its job right. The actual bug is in someone else's code (the JDBC driver in question) not in yours. Be happy that Tomcat did its job properly and wait until the JDBC driver vendor get it fixed so that you can upgrade the driver. Downgrade to Tomcat 6.0.23 or older so that you will not be bothered with those warnings. But it will silently keep leaking memory. Not sure if that's good to know after all. Those kind of memory leaks are one of the major causes behind OutOfMemoryError issues during Tomcat hotdeployments. Move the JDBC driver to Tomcat's /lib folder and have a connection pooled datasource to manage the driver. Note that Tomcat's builtin DBCP does not deregister drivers properly on close. See also bug DBCP-322. The DBCP project is however currently stalling. I wouldn't expect quick updates. You would rather like to replace DBCP by another connection pool which is doing its job better then DBCP. For example BoneCP or Tomcat JDBC Pool maybe? This is good advice. It's not warning of a memory leak it's a warning that Tomcat took some forcible action to prevent a leak @BalusC we are not using Tomcat's connection pool do you think the message should still show up?? can we keep it this way or do you suggest to use the fix shown in DBCP-322 that you provided in the answer? I was wondering if we could just ignore those warnings! Thanks for your quick responses... I have the same issue as in mona's comment. We're using C3P0 in Spring but still get the issue. And I'm even running Tomcat 6.0.23 which is below 6.0.24. If option (1) is the way to go why does Tomcat log these as SEVERE though? SEVERE to me means ""page the admin"" not ""ignore"". Why not do it yourself - rather than expect Tomcat to do it. In my opinion it's not Tomcat's job to clean up our messy code. See my answer below. Just pointing out that this error can cause your session state to be invalid after reloading. I was having that problem until I used the solution mentioned by ae6rt to deregister the drivers. @sproketboy: Huh? Was you assigning JDBC artifacts as fields of a class which is in turn stored in the HTTP session?  If you are getting this message from a Maven built war change the scope of the JDBC driver to provided and put a copy of it in the lib directory. Like this: <dependency> <groupId>mysql</groupId> <artifactId>mysql-connector-java</artifactId> <version>5.1.18</version> <!-- put a copy in /usr/share/tomcat7/lib --> <scope>provided</scope> </dependency>"
730,A,"Consistent method of inserting TEXT column to Informix database using JDBC and ODBC I have problem when I try insert some data to Informix TEXT column via JDBC. In ODBC I can simply run SQL like this: INSERT INTO test_table (text_column) VALUES ('insert') but this do not work in JDBC and I got error: 617: A blob data type must be supplied within this context. I searched for such problem and found messages from 2003: http://groups.google.com/group/comp.databases.informix/browse_thread/thread/4dab38472e521269?ie=UTF-8&oe=utf-8&q=Informix+jdbc+%22A+blob+data+type+must+be+supplied+within+this%22 I changed my code to use PreparedStatement. Now it works with JDBC but in ODBC when I try using PreparedStatement I got error: Error: [Informix][Informix ODBC Driver][Informix] Illegal attempt to convert Text/Byte blob type. [SQLCode: -608] [SQLState: S1000] Test table was created with: CREATE TABLE _text_test (id serial PRIMARY KEY txt TEXT) Jython code to test both drivers: # for Jython 2.5 invoke with --verify # beacuse of bug: http://bugs.jython.org/issue1127 import traceback import sys from com.ziclix.python.sql import zxJDBC def test_text(driver db_url usr passwd): arr = db_url.split(':' 2) dbname = arr[1] if dbname == 'odbc': dbname = db_url print ""\n\n%s\n--------------"" % (dbname) try: connection = zxJDBC.connect(db_url usr passwd driver) except: ex = sys.exc_info() s = 'Exception: %s: %s\n%s' % (ex[0] ex[1] db_url) print s return Errors = [] try: cursor = connection.cursor() cursor.execute(""DELETE FROM _text_test"") try: cursor.execute(""INSERT INTO _text_test (txt) VALUES (?)"" ['prepared' ]) print ""prepared insert ok"" except: ex = sys.exc_info() s = 'Exception in prepared insert: %s: %s\n%s\n' % (ex[0] ex[1] traceback.format_exc()) Errors.append(s) try: cursor.execute(""INSERT INTO _text_test (txt) VALUES ('normal')"") print ""insert ok"" except: ex = sys.exc_info() s = 'Exception in insert: %s: %s\n%s' % (ex[0] ex[1] traceback.format_exc()) Errors.append(s) cursor.execute(""SELECT id txt FROM _text_test"") print ""\nData:"" for row in cursor.fetchall(): print '[%s]\t[%s]' % (row[0] row[1]) if Errors: print ""\nErrors:"" print ""\n"".join(Errors) finally: cursor.close() connection.commit() connection.close() #test_varchar(driver db_url usr passwd) test_text(""sun.jdbc.odbc.JdbcOdbcDriver"" 'jdbc:odbc:test_db' 'usr' 'passwd') test_text(""com.informix.jdbc.IfxDriver"" 'jdbc:informix-sqli://169.0.1.225:9088/test_db:informixserver=ol_225;DB_LOCALE=pl_PL.CP1250;CLIENT_LOCALE=pl_PL.CP1250;charSet=CP1250' 'usr' 'passwd') Is there any setting in JDBC or ODBC to have one version of code for both drivers? Version info: Server: IBM Informix Dynamic Server Version 11.50.TC2DE Client: ODBC driver 3.50.TC3DE IBM Informix JDBC Driver for IBM Informix Dynamic Server 3.50.JC3DE http://stackoverflow.com/questions/1074364/informix-7-3-isql-insert-statement-text-blob-clob-field-insert-error maybe this will shed some light on your situation as it did mine First off are you really sure you want to use an Informix TEXT type? The type is a nuisance to use in part because of the problems you are facing. It pre-dates anything in any SQL standard with respect to large objects (TEXT still isn't in SQL-2003 - though approximately equivalent structures CLOB and BLOB are). And the functionality of BYTE and TEXT blobs has not been changed since - oh let's say 1996 though I suspect there's a case for choosing an earlier date like 1991. In particular how much data are you planning to store in the TEXT columns? Your example shows the string 'insert'; that is I presume much much smaller than you would really use. You should be aware that a BYTE or TEXT columns uses a 56-byte descriptor in the table plus a separate page (or set of pages) to store the actual data. So for tiny strings like that it is a waste of space and bandwidth (because the data for the BYTE or TEXT objects will be shipped between client and server separately from the rest of the row). If your size won't get above about 32 KB then you should look at using LVARCHAR instead of TEXT. If you will be using data sizes above that then BYTE or TEXT or BLOB or CLOB are sensible alternatives but you should look at configuring either blob spaces (for BYTE or TEXT) or smart blob spaces (for BLOB or CLOB). You can and are using TEXT IN TABLE rather than in a blob space; be aware that doing so impacts your logical logs whereas using a blob space does not impact them anything like as much. One of the features I've been campaigning for a decade or so is the ability to pass string literals in SQL statements as TEXT literals (or BYTE literals). That is in part because of the experience of people like you. I haven't yet been successful in getting it prioritized ahead of other changes that need to be made. Of course you need to be aware that the maximum size of an SQL statement is 64 KB text so you could create too big an SQL statement if you aren't careful; placeholders (question marks) in the SQL normally prevent that being a problem - and increasing the size of an SQL statement is another feature request which I've been campaigning for but a little less ardently. OK assuming that you have sound reasons for using TEXT...what next. I'm not clear what Java (the JDBC driver) is doing behind the scenes - apart from too much - but it is a fair bet that it is noticing that a TEXT 'locator' structure is needed and is shipping the parameter in the correct format. It appears that the ODBC driver is not indulging you with similar shenanigans. In ESQL/C where I normally work then the code has to deal with BYTE and TEXT differently from everything else (and BLOB and CLOB have to be dealt with differently again). But you can create and populate a locator structure (loc_t or ifx_loc_t from locator.h - which may not be in the ODBC directory; it is in $INFORMIXDIR/incl/esql by default) and pass that to the ESQL/C code as the host variable for the relevant placeholder in the SQL statement. In principle there is probably a parallel method available for ODBC. You may have to look at the Informix ODBC driver manual to find it though. Thanks for your answer. TEXT column is used because project started when there was no LVARCHAR column on both server side (IDS7.2) and client side (SQLLinks from Delphi4). I think I will convert TEXT columns to LVARCHAR when client side upgrade to newer Delphi with dbExpress drivers."
731,A,"Proper usage of JDBC Connection Pool (Glassfish) I need a database connection in Java Web service implemented as a session bean and I'm not sure if I do it right. I created a class public final class SQLUtils { //..... private static DataSource m_ds=null; static { try { InitialContext ic = new InitialContext(); m_ds = (DataSource) ic.lookup(dbName); //Connection pool and jdbc resource previously created in Glassfish  dbName contains the proper JNDI resource name } catch (Exception e) { e.printStackTrace(); m_ds = null; } } public static Connection getSQLConnection() throws SQLException { return m_ds.getConnection(); } } Whenever I need a connection I do  Connection cn = null; try { cn = SQLUtils.getSQLConnection(); // use connection } finally { if (null != cn) { try { cn.close(); } catch (SQLException e) { } } } Is it ok to use it this way or I DataSource must be a member of the bean ?  @Stateless @WebService public class TestBean { private @Resource(name=dbName) DataSource m_ds; } I'm sorry if it is a nube question but I'm pretty new to Java. Thanks in advance. Apart from the C-style formatting a few unnecessary lines and a bit poor exception handling you can just do so. Here's how I'd do it: public final class SQLUtil { private static DataSource dataSource; // .. static { try { dataSource = (DataSource) new InitialContext().lookup(name); } catch (NamingException e) { throw new ExceptionInInitializerError(e); } } public static Connection getConnection() throws SQLException { return dataSource.getConnection(); } } I throw here ExceptionInInitializerError so that the application will immediately stop so that you don't need to face ""unexplainable"" NullPointerException when trying to obtain a connection. +1 for the ExceptionInInitializerError which I didn't know. I would however favor the injection in the bean itself because it's easier to mock and to test. Thanks a lot for your answer. As Pascal pointed out you actually don't need all that stuff. Just a `@Resource` is enough.  In the ancient J2EE world the traditional way to manage this was to use a ServiceLocator. Below a sample implementation (non optimized the DataSource could be cached): public class ServiceLocator { private Context initalContext; private static ServiceLocator ourInstance = new ServiceLocator(); public static ServiceLocator getInstance() { return ourInstance; } private ServiceLocator() { try { this.initalContext = new InitialContext(); } catch (NamingException ex) { throw new ServiceLocatorException(...); } } public DataSource getDataSource(String dataSourceName) { DataSource datasource = null; try { Context ctx = (Context) initalContext.lookup(""java:comp/env""); datasource = (DataSource) ctx.lookup(dataSourceName); } catch (NamingException ex) { throw new ServiceLocatorException(...); } return datasource; } } To use it simply call it like this: DataSource ds = ServiceLocator.getInstance().getDataSource(""jdbc/mydatabase""); But this was prior to the EJB3 and Dependency Injection era. Now when using EJB3 if you have setup your DataSource in your EJB container all you have to do to automatically inject the DataSource in your Stateless Bean is to write (where mydatabase is the name of the datasource): @Resource private DataSource mydatabase; Use the name attribute if you want to explicitly well set the name: @Resource(name=""jdbc/mydatabase"") private DataSource dataSource; EJB3 actually make the ServiceLocator pattern obsolete and you should really prefer injection when working with them. Ah drat I *knew* it. That's indeed **much** better than some helper class. +1.  Um isn't this an example to a JDBC DataSource not a Glassfish Connection Pool?"
732,A,"Snippet to create a file from the contents of a blob in Java I have some files stored in a database blob column in Oracle 9. I would like to have those files stored in the file system. This should be pretty easy but I don't find the right snipped. How can I do this in java?  PreparedStatement ptmst = ... ResutlSet rs = pstmt.executeQuery(); rs.getBlob(); // mistery FileOutputStream out = new FileOutputStream(); out.write(); // etc et c I know it should be something like that... what I don't know is what is commented as mistery Thanks EDIT I finally got this derived from David's question. This is my lazy implementation: PreparedStatement pstmt = connection.prepareStatement(""select BINARY from MYTABLE""); ResultSet rs = pstmt.executeQuery(); while( rs.next() ) { Blob blob = rs.getBlob(""BINARY""); System.out.println(""Read ""+ blob.length() + "" bytes ""); byte [] array = blob.getBytes( 1 ( int ) blob.length() ); File file = File.createTempFile(""something-"" "".binary"" new File(""."")); FileOutputStream out = new FileOutputStream( file ); out.write( array ); out.close(); } You'd want to get the blob as an inputstream and dump its contents to the outputstream. So 'misery' should be something like: Blob blob = rs.getBlob(column); InputStream in = blob.getBinaryStream(); OutputStream out = new FileOutputStream(someFile); byte[] buff = new byte[4096]; // how much of the blob to read/write at a time int len = 0; while ((len = in.read(buff)) != -1) { out.write(buff 0 len); } If you find yourself doing a lot of IO work like this you might look into using Apache Commons IO to take care of the details. Then everything after setting up the streams would just be: IOUtils.copy(in out); The brings back some good old memories using Oracle XML DB with Java.  There is another way of doing the same operation faster. Actually the answer above works fine but like IOUtils.copy(inout) it takes a lot of time for big documents. The reason is you are trying to write your blob by 4KB iteration. Simplier solution : Blob blob = rs.getBlob(column); InputStream in = blob.getBinaryStream(); OutputStream out = new FileOutputStream(someFile); byte[] buff = blob.getBytes(1(int)blob.getLength()); out.write(buff); out.close(); Your outputStream will write the blob in one shot. Edit Sorry didn't see the Edit section on the intial Post."
733,A,"simpleJDBCTemplate not replacing quoted parameter I am using simpleJDBCTemplate to insert a value to a postgre database. String sql ""insert into testTable values(:bla :blah functionThatTakesAText(':blu'))"" BeanPropertySqlParameterSource namedParameters = new BeanPropertySqlParameterSource(lighting); simpleJdbcTemplate.update(sql namedParameters); Now the blu parameter is actually a number(the actual sql takes 2 real's ) that is read from a file given by the client. As a result the database receives something like the following: insert into testTable values(? ? functionThatTakesAText(':blu')) and fails to replace the :blu parameter as expected. The current workaround that I'm using is replacing the blu parameter with its value using a regex but I'm unsure on how safe that is. How would you solve that? Spring will skip over anything inside quotes in the SQL (see the skipCommentsAndQuotes() method of NamedParameterUtils) on the basis that anything inside quotes shouldn't be touched. That makes sense in this context - you would want the prepared statement to say functionThatTakesAText(?) rather than functionThatTakesAText('?') Try removing the quotes there and the placeholder should be substituted correctly. ""see the skipCommentsAndQuotes() method of NamedParameterUtils"" I can't find it in the documentation* *- http://static.springsource.org/spring/docs/2.5.x/api/org/springframework/jdbc/core/namedparam/NamedParameterUtils.html @awregan: It's not in the documentation it's in the source code."
734,A,"Connecting to Progress database from Mac OSX Does anyone know how to connect to a Progress 9.1E database from a Mac (or even from Linux)? I can connect successfully from Windows but the JDBC driver requires that the Progress install directory and it's bin directory are in the path. It seems to be one product that is firmly under Google's radar. OpenLink has an OSX driver but it is a paid for product which is fine but as this is for development use only I'd rather find a free alternative. Thanks. If you upgrade your progress to Openedge (Progress v10) its jdbc driver doesn't require any progress related installation because it's 100% pure java (type 4 driver) so you can access Openedge DB from any OS that supports java.  You need Progress SQL92 Client Access Mac is unsupported RedHat SuSe and several flavours of Unix are. See Progress Version 9 product availability matrix look for ODBC and JDBC. As far as I know there are only two companies in the world that produce ODBC/JDBB connectivity drivers for Progress DB: OpenLink and DataDirect (now acquired by Progress). Another way is to connect using Progress AppServer then you'd be able to run Progress 4GL (or ABL - Advanced Business Language) queries/logic on AppServer and output resulting datasets to Java. The third way is to migrate the data (if this is an option). Other options include exposing DB via WebSpeed (web application server) or using sockets files getting OpenEdge and exposing the data through 4GL web services etc. This will really depend on your data access needs. However all of these methods are non-trivial and require Progress platform and 4GL expertise.  I did a development on MAC with ProgreSQL using OpenLink ODBC drivers about 4 years ago. Don't remember too many problems but it introduces commercial problems (costs!).... for deployment. http://developer.apple.com/internet/opensource/postgres.html Wait a minute!! that was PostgreSQL which isn't the same thing is it. I can't delete this answer because there is useful info in the comments below. The Progress database supports JDBC and uses Java triggers from the SQL-92 engine. I'm not sure what else you'd want for ""Java support"" directly from the db. Mac support is nonexistent. Mac is not a supported platform. 9.1E is also ancient obsolete and essentially unsupported (technically 9.1E04 is ""supported"" as in ""if you have a problem we'll listen and try to help you find a workaround but we won't patch anything""). The Progress environment is not just the db though -- it also includes thinks like app servers and Sonic. Or you could code up something using a socket interface. If it's a legacy application that you're dealing with you might find that they have already built interfaces of some sort that you would be better off using. Not my call. It is for a web app to view legacy data which is housed in Progress. Nope. PostgreSQL is an open-source database. And a good one. Whereas Progress is a proprietary database with poor Java support (from what I can see). Any Progress DBAs care to enlighten me? maybe you should be using PostgreSQL after all !!! @TomBascom You also have to agree (as with anyone NOT employed by Progress) that progress has always headed in the wrong direction always creating proprietary technologies looking for a ""lock-in"" strategy to its customers. No I do not have to agree with that. Sure they've done some ""wrong"" things at times most companies do. But on the whole I've found the product and the people to be very fruitful to work with."
735,A,Reading the same ResultSet from multiple threads In the database I have a definition table that is read from the application once upon starting. This definition table rarely changes so it makes sense to read it once and restart the application every time it changes. However after the table is read (put into a ResultSet) it will be read by multiple handlers running in their own threads. How do you suggest to accomplish this? My idea was to populate a CachedRowSet and then create a copy of this set (through the createCopy() method) for each handler every time a new request comes. Do you think this is wise? Does this offer a good performance? Thanks. If you are just reading you don't have to worry about data race issues. Yes that is correct. However more worried about performance. I may have 30-60 requests per second and each handler will create a copy of the definition table (which has 300 records at the moment but this may grow). It may be better for you to use the singleton pattern. This would allow you to create a single class that all of your threads could access to get the object that they needed. This could also allow you to not have to shut down your application whenever changes are made. One way to accomplish this is to have a class where you have get and set methods for the information you need. And another class that will give out references of that object. The class that gives out references could have a private constructor and a getInstance method that will return a reference to itself to ensure that only one exists. This would also give you some other options regarding what you can do when things change.  I think it is a pattern to read the configuration table into a static data structure (ConcurrentHashMap) and then let the threads to look it up. You can ensure that there is no write race at startup by populating the reference map from a Servlet.init() - it is guaranteed to execute once per servlet.  Ok if you control access to the resultSet and you don't care to update the result set until you restart the application then i would suggest wrapping the CachedRowSet in a custom class. One possible way to do this is to have a wrapper class that is a singleTon and provide it with getter methods so that other threads or classes for that matter can access it. That way you remove the need to make a copy and remove the dependency on CachedRowSet implementation. Creating a copy would cause unnessary overhead. Imagine in the way you described above if you had 1000 threads accessing your result set you would call createCopy() 1000 times thus creating a 1000 copies of the same resultSet.
736,A,"JDBC Timestamp & Date GMT issues I have a JDBC Date column which if a i use getDate is get the 'date' part only 02 Oct 2009 but if i use getTimestamp i get the full 'date' 02 Oct 2009 13:56:78:890. This is excatly what i want. However the 'date' returned by getTimestamp 'ignores' the GMT values suppose date; 02 Oct 2009 13:56:78:890 i end up getting 02 Oct 2009 15:56:78:890 My date was saved as a +2GMT date on the database but the application server is on GMT i.e 2hrs behind How can still get my date as is 02 Oct 2009 13:56:78:890 Edit I get the date +2 on the client side that is on GMT +2 From this post i have come to the conclusion that JDBC does retrieve the timezone for the Timestamp (I don't think MS SQL support this as well most Google results point to Oracle) When the JDBC getTimeStamp method is called it only gets the 'milliseconds' portion and create a Date object with the server TimeZone which is GMT. When this Date object is presented to my client which is +2 GMT it adds 2 hours which is the standard offset which leads to the extra hours. I have corrected this by removing the time offset from the date i retrieve i.e. convert to the true GMT Date.  private Date convertDate(Date date1) throws ParseException { SimpleDateFormat sdfFormatter = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss""); String dateStr = sdfFormatter.format(date1); SimpleDateFormat sdfParser = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss""); sdfParser.setTimeZone(TimeZone.getTimeZone(""GMT"")); return sdfParser.parse(dateStr); }  You should be aware that java.util.Date (and also java.sql.Date and java.sql.Timestamp which are subclasses of java.util.Date) don't know anything about timezones or rather they are always in UTC. java.util.Date and its subclasses are nothing more than a container for a ""number of milliseconds since 01-01-1970 12:00 AM UTC"" value. To display a date in a specific timezone convert it to a string by using a java.text.DateFormat object. Set the timezone on that object by calling the setTimeZone() method. For example: Date date = ...; // wherever you get this from DateFormat df = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss""); // Make the date format show the date in CET (central European time) df.setTimeZone(TimeZone.getTimeZone(""CET"")); String text = df.format(date);  I ran into a similar problem the other day where the time component was being truncated from some dates. We narrowed it down to a difference in Oracle Driver versions. On Oracle's FAQ there is a section about this: select sysdate from dual; ...while(rs.next()) Prior to 9201 this will return: getObject for sysdate : java.sql.Timestamp <<<< getDate for sysdate : java.sql.Date getTimetamp for sysdate : java.sql.Timestamp As of 9201 onward the following will be returned getObject for sysdate : java.sql.Date <<<<< getDate for sysdate :java.sql.Date >> no change getTimetamp for sysdate :java.sql.Timestamp >> no change Note: java.sql.Date has no time portion whereas java.sql.Timestamp does. With this change in Datatype mapping some application will fail and/or generate incorrect results when JDBC driver is upgraded from 8i/ 9iR1 to 920x JBDC driver. To maintain compatibility and keep applications working after upgrade a compatibility flag was Provided. Developers now have some options: Use oracle.jdbc.V8Compatible flag. JDBC Driver does not detect database version by default. To change the compatibility flag for handling TIMESTAMP datatypes connection property 'oracle.jdbc.V8Compatible' can be set to 'true' and the driver behaves as it behaved in 8i 901x 9 200 (with respect to TIMESTAMPs). By default the flag is set to 'false'. In OracleConnection constructor the driver obtains the server version and set the compatibility flag appropriately. java.util.Properties prop=newjava.util.Properties(); prop.put(""oracle.jdbc.V8Compatible""""true""); prop.put(""user""""scott""); prop.put(""password""""tiger""); String url=""jdbc:oracle:thin:@host:port:sid""; Connection conn = DriverManager.getConnection(urlprop); With JDBC 10.1.0.x instead of the connection property the following system property can be used: java -Doracle.jdbc.V8Compatible=true.....Note: This flag is a client only flag that governs the Timestamp and Date mapping. It does not affect any Database feature. '2. Use set/getDate and set/getTimestamp when dealing with Date and TimeStamp column data type accordingly. 9i server supports both Date and Timestamp column types DATE is mapped to java.sql.Date and TIMESTAMP is mapped to java.sql.Timestamp. So for my situation I had code like this: import java.util.Date; Date d = rs.getDate(1); With 9i I was getting a java.sql.Timestamp (which is a subclass of java.util.Date) so everything was groovy and I had my hours and minutes. But with 10g the same code now gets a java.sql.Date (also a subclass of java.util.Date so it still compiles) but the HH:MM is TRUNCATED!!. The 2nd solution was pretty easy for me - just replace the getDate with getTimestamp and you should be OK. I guess that was a bad habit. thanks for that one Jim most appreciated.  That's the difference between Timestamp and other temporal types in MySQL. Timestamp is saved as Unix time_t in UTC but other types store date/time literally without zone information. When you call getTimestamp() MySQL JDBC driver converts the time from GMT into default timezone if the type is timestamp. It performs no such conversion for other types. You can either change the column type or do the conversion yourself. I recommend former approach. keyword **converts** which is why i get the +2 hours I'm confused if conversion is working properly shouldn't he seeing a date that is 2 hours less instead of more? @wds - check my edit and response this was close enough and guided me to my final solution"
737,A,"MDE Access decrypt JDBC I want to perform JDBC SQL queries on a MDE Access file. I've set up the data source ODBC and everything worked well for a MDE file. Now I'm working with a newer version of the MDE file and here is the result: java.sql.SQLException: [Microsoft][Driver ODBC Microsoft Access] Cannont read record. Read authorization unavailable for ""tbl_mytable"". If I open the MDE with Access Runtime I am asked for a password and after leaving a blank password I can see all the data. Of course ""tbl_mytable"" does exist inside the database. Is this an application database? If not it shouldn't be an MDE as MDE's apply only to VBA code. If there's no code converting to an MDE does nothing at all. Your question confuses me as you seem to be asking about a data table but you talk about an MDE. Either you've left out information or there's something wrong with the setup. I'm using the MDE as a data source for my JDBC (Java) application. I'm not ""converting"" an MDE I'm only trying to read it. And I'm reading it by means of a SQL query but this query responds as written above. I assume that you did not make the MDE yourself. As David said there is no advantage to convert a MDB database to MDE if it is just going to be used as a database file and not an application. Anyway it looks like some group security was put in place on the new version of the MDE database you are using. You need to check with the person who created the original database if they set up security so they can give you the proper username and password needed to access it again. Once you get the username/password you can either change your ODBC data source settings or the connection string you are currently using usually by adding a ""UID=username;PWD=password;"" to it."
738,A,"Mutlithread-safe JDBC Save or Update We have an interesting problem: We have a JMS queue of job statuses and two identical processes pulling from the queue to persist the statuses via JDBC. When a job status is pulled from the queue the database is checked to see if there is already a row for the job. If so the existing row is updated with new status. If not a row is created for this initial status. What we are seeing is that a small percentage of new jobs are being added to the database twice. We are pretty sure this is because the job's initial status is quickly followed by a status update - one process gets one another process the other. Both processes check to see if the job is new and since it has not been recorded yet both create a record for it. So my question is how would you go about preventing this in a vendor-neutral way? Can it be done without locking the entire table? EDIT: For those saying the ""architecture"" is unsound - I agree but am not at liberty to change it. JDBC connections are not thread safe so there's nothing to be done about that. ""...two identical processes pulling from the queue to persist the statuses via JDBC..."" I don't understand this at all. Why two identical processes? Wouldn't it be better to have a pool of message queue listeners each of which would handle messages landing on the queue? Each listener would have its own thread; each one would be its own transaction. A Java EE app server allows you to configure the size of the message listener pool to match the load. I think a design that duplicates a process like this is asking for trouble. You could also change the isolation level on the JDBC connection. If you make it SERIALIZABLE you'll ensure ACID at the price of slower performance. Since it's an asynchronous process performance will only be an issue if you find that the listeners can't keep up with the messages landing on the queue. If that's the case you can try increasing the size of the listener pool until you have adequate capacity to process the incoming messages. I believe this is analagous to what we have but substitutes threads for processes yielding the same issues. Not true? (Not that we can change our design.) But you don't have to maintain two processes and you can control the size of the thread pool more easily because it's under the control of the app server. How will you increase capacity if two processes aren't enough? Add more processes? The designs are not equivalent even if the issues are the same for both. I think increased isolation is one part of the solution.  Create a unique constraint on JOB_ID and retry to persist the status in the event of a constraint violation exception. That being said I think your architecture is unsound: If two processes are pulling messages from the queue it is not guaranteed they will write them to the database in queue order: one consumer might be a bit slower a packet might be dropped ... causing the other consumer to persist the later messages first causing them to be overridden with the earlier state. One way to guard against that is to include sequence numbers in the messages update the row only if the sequence number is as expected and delay the update otherwise (this is vulnerable to lost messages though ...). Of course the easiest way would be to have only one consumer ... Yes we have examples where the second message is persisted after the first as you describe."
739,A,connection to dbase from jdbc on linux Can we connect to a dBAse/FoxPro .dbf file on Linux using JDBC? There appear to be vendors for cross-platform JDBC drivers such as these folks. It is also possible to use a proxy with a server running on Windows and JDBC driver on Linux. @Juan sounds like you have an issue using J-Stels in a particular scenario. That does not make this answer invalid. Why not start a new question to see whether there is a solution to your problem. Done. I have a related issue http://stackoverflow.com/questions/18326959/stelsdbf-java-lang-outofmemoryerror-java-heap-space
740,A,"How to enable GUI behaviors for sorting a JTable when SQL does the sorting? How do I enable JTable icons and behaviors for sorting table rows by a column without letting it use a comparison predicate to do the sorting? That is to say how do I tell the table headers to show the arrow for ascending/descending sort order in the column being used and get it to call appropriate methods when sort order/column change? I am trying to create an (editable filterable sortable) JTable backed by an SQL query or view. The rows may not fit in memory and may not map cleanly to java objects so I want to do all sorting/filtering within SQL. I have already written the code for changing a query to accommodate sorting by column filtering by values and visible columns. To use this I am planning to write a JTableModel based on a ResultSet with TYPE_SCROLL_SENSITIVE and CONCUR_UPDATABLE so changes to the DB get propagated to the ResultSet. I will periodically (several times a second) force a refresh of the visible JTable from the ResultSet so changes to the database become visible to the user. User changes to the table will be passed to the updateable ResultSet after validation. I've looked a little bit at how sorting is done normally but most implementations seems to rely on the JTable creating a javax.swing.RowSorter with a Comparator predicate or on maintaining a sorted list of rows that fires events when changed. So my questions: ORM frameworks are NOT an answer to this question because the data do not map well to entity objects. Also the DBMS I am using is H2. EDIT: Sortable JTable libraries based on applying Comparators or sorting predicates to row objects are also unsuitable unfortunately. I do not believe I will be able to hold all objects in memory in order to perform sorting. This problem prevents me from using the SwingX JXTables GlazedLists or similar libraries. I wish I could but I can't. Period. ** I will be dealing with many thousand rows potentially millions with numerous columns. Yes I really DO need to use SQL to do the sorting and filtering.** Questions: (in descending importance) How do I show indicators for which column is used to sort rows? How do I get the JTable to fire appropriate events when the column headers are LEFT-clicked to change sort order? Is there an easier way to force the JTable to update when the database changes? Is there a library that would make all this considerably easier (connecting DB queries or views and JTables)? Am I going to run into horrible horrible problems when I design the system like this? You should be able to subclass javax.swing.RowSorter in order to create a row sorter that does the sorting in the database. From the API docs: ""RowSorter implementations typically don't have a one-to-one mapping with the underlying model but they can. For example if a database does the sorting toggleSortOrder might call through to the database (on a background thread) and override the mapping methods to return the argument that is passed in."" http://docs.oracle.com/javase/6/docs/api/javax/swing/RowSorter.html  In answer to 1 and 2 check out SwingX which already includes a table class with built-in sorting (and filtering). You may be able to adapt this. Am I going to run into horrible horrible problems when I design the system like this? From experience yes. I worked on a project almost exactly the same as this where someone had designed a JTable that supposedly 'magically' bound to a database table. This coupled display logic and database access together in one big horrible mess which we replaced entirely with reflection-driven table models and separate record CRUD operations. You say that ORM is not the answer... If the format of the data doesn't change then it's worth considering anyway. Your 'entity' classes need not represent real-world entities. If (as I suspect) your entity format changes it might be worth considering: A flexible map-based Record class which stores records as key-value pairs; Dynamically-built table models for your display logic built by querying record keys plugged into SwingX tables to get sort and filter for free; A similarly-designed Repository class which encapsulates your database access separately from the table itself responsible for loading and saving Records. This acts as an adapter between your updateable ResultSet and the view (although I'd check whether using a ResultSet this way is going to require an open database connection whilst data is visible...). This separation into 'a table that displays and sorts records' and 'a repository that manages the data' means: You can reuse the table for non-database-bound data; You can display database-bound records in things other than tables; You won't go mad trying to build and test the thing :) Definitely start with SwingX which provides a flexible JXTable(sortingfiltering). I would stay away from a scrollable result set even if it has some advantages. The huge disadvantage is that it keeps a connection opened and having a few grids like that opened in several applications leads to ""no more connections available"" when you expect less(you cannot control how many grids will use an user most of the time).Myself I had to build something like this and I went on the path of retrieving pages in the table model instead of using a cursor. 1&2 = JXTable 3=table model should fire events. See posted question: both JXTable and the GlazedLists connections to it are awesome but not particularly feasible for my needs. To use them I either have to store primary key objects (longs in this case) and use ~1 query per key to get properties for comparison OR store all the objects in memory. The first is unworkably slow. The latter is more complex: it works fine for small simple rows but rapidly eats RAM up. If you store 100K rows with 15 columns you pay for java's objects. 8 bytes minimum per object 24 PER STRING. I've been here before: there's a reason we use DBs. When I say that ORM is utterly unsuitable due to structure I mean it reflection is too bloody slow. AFAIK SwingX is tied to sort predicates on row objects and is thus unsuitable. The table is describing resources with a set of tags which the user may modify. The user can also add new tags. Furthermore I *know* at this point that I will be adding additional data types for tags. There will be thousands or (potentially) millions of unique resources. Reflection will choke on performance and an ORM will generate too many queries or eat RAM like popcorn. @BobMcGee - cool then ditch the ORM and reflection. I still think that you should seriously consider separating the data access from the table though. I've written a JTable extension myself that had clickable column headers. I overrode the code that renders the header row to place JButtons there instead of labels then added event handlers to receive the click update the icon appropriately (up/down arrow) and create a custom Comparator to pass to a straight collection sort method on the backing data. All the sorting was wrapped in a SortableTableModel model extension class. Hmmm....not sure what do you mean by "" I do not believe I will be able to hold all objects in memory in order to perform sorting."" You don't have to keep all the objects in memory and you don't have to use the default sorting model. The main reason to use JXTable is because it provides support for sorted columns and takes care of all visual details but you can still do whatever you want in the table model. You can do the same thing with JTable but you will have to implement yourself a functionality already implemented in JXTable.  I have never used it myself but JIDE Data Grids provides a DatabaseTableModel that provides filtering and sorting support using SQL WHERE and ORDER BY. Not free but I should be able to dissect it for ideas at least. Best answer so far and it doesn't involve ""ignore your requirements"" or ""use reflection"" (snicker) so you get credit. Thanks!  Leaving aside the database stuff there's a class called SortableTable that's a part of JIDE Grids. It displays the sorting with a little ^ or v in the table header and supports sorting by more than 1 column (1v 2v etc.). Well its a JTable subclass and uses a TableModel just like any other JTable. It's possible you can if you write your own customised TableModel I don't need multiple sorting columns (yet). Is there a way I can use this to hook into external sorting (SQL) rather than operating on objects in memory?"
741,A,"How to Create a MySql Database using JDBC Can we create a new MySQL database( not a table I want a new database) from java code ? I have searched the internet and I get code only for connecting with existing mysql databases. Can i create a new database at run time using java code. please help Note that not all JDBC drivers supports all DDL statements and that it's generally considered bad practice to create db's and tables using JDBC unless you'd like to (re)invent a DB manager tool in Java. For normal apps creating the datamodel ought to be a separate task. Class.forName(""org.gjt.mm.mysql.Driver"").newInstance(); String url =""jdbc:mysql://localhost/myDB?user=soft&password=soft1234&useUnicode=true&characterEncoding=8859_1""; Connection conn = DriverManager.getConnection(url); Uhm I think you didn't understood the question nor the already accepted answer :)  In your connection string omit a database name and then execute Create database command. Connection String: jdbc:mysql://localhost Create Database Syntax : stm.executeUpdate(""CREATE DATABASE dbname"")"
742,A,"How to check if resultset has one row or more? How to check if resultset has one row or more with JDBC? This is indeed something that is missing in JDBC reason for this is that not all database system support getting the size of the resultset in advance (because results aren't prefetched). Unfortunately this means you can not easily use those features in databases that do support it such as MySQL. My no-brainer suggestion: Fetch the first result row and then try to fetch the next. If the attempt is successful you have more than one row. If there is more than one row and you want to process that data you'll need to either cache the stuff from the first row or use a scrollable result set so you can seek back to the top before going through the results. You can also ask SQL directly for this information by doing a SELECT COUNT(*) on the rest of your query; the result will be 0 1 or more depending on how many rows the rest of the query would return. That's pretty easy to implement but involves two queries to the DB assuming you're going to want to read and process the actual query next.  There are many options and since you don't provide more context the only thing left is to guess. My answers are sorted by complexity and performance ascending order. Just run select count(1) FROM ... and get the answer. You'd have to run another query that actually selects and returns the data. Iterate with rs.next() and count until you're happy. Then if you still need the actual data re-run same query. If your driver supports backwards iteration go for rs.next() couple of times and then rewind back with rs.previous(). If your driver doesn't support backwards iteration `first()` usually works to start over.  You don't need JDBC for this. The normal idiom is to collect all results in a collection and make use of the collection methods such as List#size(). List<Item> items = itemDAO.list(); if (items.isEmpty()) { // It is empty! if (items.size() == 1) { // It has only one row! } else { // It has more than one row! } where the list() method look like something: public List<Item> list() throws SQLException { Connection connection = null; Statement statement = null; ResultSet resultSet = null; List<Item> items = new ArrayList<Item>(); try { connection = database.getConnection(); statement = connection.createStatement(); resultSet = statement.executeQuery(SQL_LIST); while (resultSet.next()) { Item item = new Item(); item.setId(resultSet.getLong(""id"")); item.setName(resultSet.getString(""name"")); // ... items.add(item); } } finally { if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } return items; } This doesn't scale very well. What if the result set has millions of rows? @mindas: It would then already make no sense to `SELECT * FROM table` them. You need `SELECT COUNT(*) FROM table` then. JDBC is simply not the right tool for this particular purpose and that's exactly the reason a fictive `ResultSet#size()` method doesn't exist in JDBC. Original question have never said it is doing `SELECT * FROM table` neither I have suggested that. Original question hasn't got an assumption that all data is actually necessary too. @mindas: Either way there's still no reason to do this using JDBC. Either use SQL to select the rowcount or use collection methods to get the result size.  ResultSet rs = stmt.executeQuery(""SELECT a b c FROM Table1""); boolean isMoreThanOneRow = rs.first() && rs.next(); You didn't ask this one but you may need it: boolean isEmpty = ! rs.first(); Normally we don't need the row count because we use a WHILE loop to iterate through the result set instead of a FOR loop: ResultSet rs = stmt.executeQuery(""SELECT a b c FROM Table1""); while (rs.next()) { // retrieve and print the values for the current row int i = rs.getInt(""a""); String s = rs.getString(""b""); float f = rs.getFloat(""c""); System.out.println(""ROW = "" + i + "" "" + s + "" "" + f); } However in some cases you might want to window the results and you need the record count ahead of time to display to the user something like Row 1 to 10 of 100. You can do a separate query with SELECT COUNT(*) first to get the record count but note that the count is only approximate since rows can be added or removed between the time it takes to execute the two queries. Sample from ResultSet Overview  Get the Row Count using ResultSetMetaData class. From your code u can create ResultSetMetaData like : ResultSetMetaData rsmd = resultSet.getMetaData(); //get ResultSetMetaData rsmd.getColumnCount(); // get row count from resultsetmetadata -1 ResultSetMetaData has nothing to do with row count.. rsmd.getColumnCount() gives you the number of columns of your resultset"
743,A,MYSQL & Java Applet I am currently changing a java desktop application over to a java applet. Everything is working fine but as soon as the applet attempts to make a mysql database call it does not work. The code in the desktop application is fine but as soon as its called from the application its not working. Do any changes need to be made to the code because it is being called from an applet rather then a desktop application using JDBC? Thanks ~ Kyle G Can you clarify what you mean by 'doesn't work' ? Exceptions etc.? I suspect you're probably trying to talk to a server other than the one serving your applet ? See this for applet security restrictions. Thats it!. Just ran them from the same server and problem was solved. Thanks :) Good. It's probably worth providing more info re. the error in future since the above was a bit of an informed guess :-)  The JDBC in the applet can not connect to the other server port : security restrictions like they can not read file on your desktop
744,A,"JDBC postgres vacuum timeout I'm trying to vacuum my Postgres database by running the following SQL instruction within Java: vacuum verbose analyze Sometimes it just seems to ""hang"" is there any clean way to abort the process? I have tried SET statement_timeout TO XXXX But I get the error message ""VACCUM cannot run inside the transaction block"" This error can occur if postgres server is taking so much time to load data i.e if for a particular query their is so many results it will take time to load that and will throw this exception.  I've just tested and ""vacuum"" does honor ""statement_timeout"". Example program: import java.sql.*; class test { public static void main(String[] args) { try { Class.forName(""org.postgresql.Driver""); Connection connection = DriverManager.getConnection( ""jdbc:postgresql://hostname/dbname"" ""username"" ""password"" ); connection.createStatement().executeUpdate( ""set statement_timeout to 500"" ); connection.createStatement().executeUpdate( ""vacuum analyze"" ); } catch (Exception ex) { ex.printStackTrace(); } } } I get the following error: org.postgresql.util.PSQLException: ERROR: canceling statement due to statement timeout at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2062) at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:1795) at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:257) at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:479) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeWithFlags(AbstractJdbc2Statement.java:353) at org.postgresql.jdbc2.AbstractJdbc2Statement.executeUpdate(AbstractJdbc2Statement.java:299) at test.main(test.java:14) Maybe you have to (temporary) enable autocommit on your connection.  I don't think there's a good (i.e. safe) way to kill the process other than re-starting the database. I'm not aware of any transaction timeout option either. The best solution is to figure out what's causing the hang and fixing that problem. It's likely that vacuum is waiting for a transaction lock to be release. Use the pg_locks view to see if this is the case. If you can see what resource is being locked you can begin to address that issue."
745,A,Read a large result set in chunks from mysql I am trying to read a huge result set from mysql. Reading them in a straight-forward manner didn't work as mysql tries to return all results together which times out. I found the following piece of code which tells mysql to read the results back one at a time: stmt = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY); stmt.setFetchSize(Integer.MIN_VALUE); Can I read a chunk at a time instead of one by one? I've tried setting fetch size to a different value but it doesn't work. In your query use pagination by setting limit and offset.
746,A,Accessing infobright from Java Would someone advise me technology for accessing Infobright from java or some technics... things of that nature.. as far as I understand I should use plain jdbc connection and execute queries... not making use of high level thing like hibernate... Am I right? Thanks in advance! Also if you have any questions about connecting or using Infobright check out their community forums at http://www.infobright.org/Forums.  Accessing Infobright from Java would be the same approach as you would with MySQL. We support the JDBC drivers that are available from the MySQL website. Thanks! And what about hibernate here ?? @Andrew You can set up a JDBC connection in the Hibernate configuration the same way you would if it was MySQL. Keep in mind that 'UPDATE' performance is relatively poor in Infobright however.
747,A,"how to access multiple users' database via JDBC I have an account in oracle database. I can connect it via jdbc in my java code. When I access database from Oracle SQL Developer under ""Connections""->""Other Users"" I can access to their tables (I have been assigned privilege for reading others tables). My question is how to access / retrieve data from others tables via jdbc? You need to prefix the table name with the schema name which in Oracle is the same as the user name. select * from some_other_user.their_table; If having the user name hardcoded in the SQL statement is a problem you could make that configurable on the Java side somehow or install a table alias (synonym) into your own schema on the Oracle side. thanks it works."
748,A,"How best to modernize the 2002-era J2EE app? I have this friend.... I have this friend who works on a java ee application (j2ee) application started in the early 2000's. Currently they add a feature here and there but have a large codebase. Over the years the team has shrunk by 70%. [Yes the ""i have this friend is"". It's me attempting to humorously inject teenage high-school counselor shame into the mix] Java Vintage 2002 The application uses EJB 2.1 struts 1.x DAO's etc with straight jdbc calls (mixture of stored procedures and prepared statements). No ORM. For caching they use a mixture of OpenSymphony OSCache and a home-grown cache layer. Over the last few years they have spent effort to modernize the UI using ajax techniques and libraries. This largely involves javascript libaries (jquery yui etc). Client Side On the client side the lack of upgrade path from struts1 to struts2 discouraged them from migrating to struts2. Other web frameworks became popular (wicket spring  jsf). Struts2 was not the ""clear winner"". Migrating all the existing UI from Struts1 to Struts2/wicket/etc did not seem to present much marginal benefit at a very high cost. They did not want to have a patchwork of technologies-du-jour (subsystem X in Struts2 subsystem Y in Wicket etc.) so developer write new features using Struts 1. Server Side On the server side they looked into moving to ejb 3 but never had a big impetus. The developers are all comfortable with ejb-jar.xml EJBHome EJBRemote that ""ejb 2.1 as is"" represented the path of least resistance. One big complaint about the ejb environment: programmers still pretend ""ejb server runs in separate jvm than servlet engine"". No app server (jboss/weblogic) has ever enforced this separation. The team has never deployed the ejb server on a separate box then the app server. The ear file contains multiple copies of the same jar file; one for the 'web layer' (foo.war/WEB-INF/lib) and one for the server side (foo.ear/). The app server only loads one jar. The duplications makes for ambiguity. Caching As for caching they use several cache implementations: OpenSymphony cache and a homegrown cache. Jgroups provides clustering support Now What? The question: The team currently has spare cycles to to invest in modernizing the application? Where would the smart investor spend them? The main criteria: 1) productivity gains. Specifically reducing the time to develope new subsystems features and reduced maintenance. 2) performance/scalability. They do not care about fashion or techno-du-jour street cred. What do you all recommend? On the persistence side Switch everything (or new development only) to JPA/JPA2? Straight hibernate? Wait for Java EE 6? On the client/web-framework side: Migrate (some or all) to struts2? wicket? jsf/jsf2? As for caching: terracotta? ehcache? coherence? stick with what they have? how best to take advantage of the huge heap sizes that the 64-bit jvms offer? Thanks in advance. I understand your friend's pain :) However newer shinier frameworks won't necessarily make your end user's life better after all that's what you're paid for. Some issues have been around for a while caching data to speed things up auto wiring request parameters to a method call managing transactions seaming related components together ... Over the years people have developed 'good enough' implementations. My feeling is that the framework switch is only worth the cost if it brings a lot of improvements. For instance if switching to something else enables to AJAXify your application then it might be worth it. But you will have to let the end users feel the improvement. My advice would be to start decoupling your business model from anything else (DAO UI transaction management...) then it will be easier to introduce a new framework (ORM ?). Even if it doesn't work in the end you would probably have improved your codebase's quality by decoupling.  Okay here is the answer that doesn't demand a rewrite in a different language or learning spring and writing 2000 lines of XML. Advise your friend to try deploying the application in glassfish v3 the EJB 2.1 will work (and play nice with any new EE 6 code). Going forward they can now develop new code in EJB 3.1 and they can refactor old EJB 2.1 code at their leisure. They could continue to use Struts or slowly migrate new code to JSF / Wicket / ??? Same goes for JPA move to JPA 2 at their own pace although their domain model may require this occur in one big bang or many smaller bangs. Caching? EclipseLink (JPA 2 RI) has some pretty decent caching on board. Read more Most of all this pudding has proof. I just deployed a legacy EJB 3 + Struts 1.3 app in glassfish v3 at work not only was it dead simple (the bit of effort it took was I moved it out of a jdeveloper project and into a netbeans project) but its a great footing to begin refactoring to EE 6 which we intend to do as bugs or features are requested. Basically this comes down to ""If it ain't broke don't fix it."" why change working (albeit very old) code? Let it live on write new features in EE 6 and if a feature touches on old code consider refactoring it to EE 6 while you're there. Most of all the effort involved in this would be deploying into glassfish v3...  Honestly you could probably just redo the entire thing in grails and do it like 20x faster than how long it took to do it in 2002 ;) For projects that I absolutely have to use a real Java stack for I stick with Spring 3.0 and Hibernate 3.5. You can even use Roo to get the project started quickly and just turn it off if you don't want it anymore. Use an idea like IntelliJ to make coding quick. Unfortunately I gotta say this is not productive anymore. While it's great for raw Java... raw Java just sucks unless you absolutely need everything Java offers. Also Ajax is really bad with Spring. If you want to use database mapping in your MVC you have to code against custom Jackson deserializers... so you gotta parse raw JSON. This is terrible and the Spring people are already aware of the problem. Good luck seeing a high-level fix any time soon. I used to laugh at the Ruby on Rails people... but I gotta hand it to them they got it right. For small to medium projects it really works. And if you want the scalability of the Java stack Grails is a great solution. If you really really really don't want to go in that direction then just using a modernized Spring 3.0 with Hibernate 3.5 is the way the go. I've researched grails (worked through one of the books) and found it very impressive: it looked a great candidate for a new application but integrating with an existing app looked more difficult. Can you clarify about ""ajax being bad with spring""? i.e. Spring-in-general or a specific component/aspect of Spring. I'm not familiar with Spring details nor its problems with json. thanks  If I were you I'll start with measurements. Perhaps take a few typical operations preferably the ones that are annoying users at high load or something chop their path into some phases and measure how much time is consumed in each step. Once you find a step that is taking long you can narrow down until you have a likely culprit. If it's DB access maybe caching would help etc. You might find some plain old optimization but that's okay too right? If you are running on older version of app. server then I'd recommend upgrading it. It has generally better performance/scalability and in case of JBoss it makes even more sense because of the better support (can find information/human resource easier). As for EJB2.1 to EJB3 migration I tested EJB3 dependency injection vs. EJB2.1 JNDI look up and it was like much much faster. Maybe getting rid of EJBHome stuff made things faster too though I don't know for sure. Once you migrate fully to EJB3 you'll have JPA and it is very easy to get ehcache to work and I can tell you that ehcache is very efficient. (well I don't know how it compares to the one you are using now..)  I was a in a very similar position to yourself a few years ago with a complex monolithic application consisting of a mix of EJB 1.x and a home-grown MVC framework. Migrating the whole thing at once was never an option I needed a way of doing it a bit at a time without breaking anything and without requiring approval for a mega-budget project. The tool that let me do this was Spring (v1.2 as it was at the time). When you strip away all the buzzwords from Spring what you're left with is a simple framework for integrating disparate application components making it easier to swap these components out for alternatives modernising as you go. For example Spring gives you integration with Struts 1 making it easier to introduce Struts 1 components into the ""Spring way"". Your Struts apps should operate as before but now they've got the leverage to get themselves modernised from the bottom up. Next Spring's data access abstractions will allow you to plug in your existing JDBC DAOs and start introducing the DA abstractions to make them easier to modernise. If you choose to stick with JDBC that's fine Spring provides extensive JDBC support to make it feel less stone-age. If you want to tinker with JPA or Hibernate then those will integrate with the Spring-managed application just as easily as JDBC will. For EJB Spring can wrap the EJB access layer into something a bit less prehistoric making them easier to swallow. Once you've isolated the client layer from the specifics of EJB data access you could if you choose replace the EJBs (one at a time) with simpler Spring-managed components (with any of remoting transactions security or none of them) or you can retain EJB (using EJB3 perhaps) if you choose to. In summary let Spring take over the role of application ""backbone"" while starting off using the same legacy components you already have. You then have increased freedom to modernise at the pace and risk you dictate. It won't be easy but with some patience and perseverance you can get to where you want to go without too much disruption. Thanks for the response. The 'gradual transition to spring' provides some helpful insight. As a non-spring user I forget that Spring provides more than just a 'web framework'. I'm new to stackoverflow and not sure why I can't specify more than one answer for a question but it was a tossup between yours and the other answer. Thanks for weighing in.  It's really hard to justify re-engineering something that ""works"" as is. You spend a lot of work getting back to where you started. That said. The transition from EJB 2.1 Session Beans to EJB 3 is pretty trivial. For us when we made the transition most of our EJBs were deployed separately rather than in a combined EAR. But you don't have that problem. Even with EJB 3 you may very likely still have an ejb-jar.xml file (or files). But there's still benefit I think and the cost is very low. You can incrementally do it bean by bean vs ""all at once"" which is nice simply by moving the bulk of the information in the current ejb-jar.xml files in to the annotations within the application. If nothing else it brings visibility (like transaction requirements etc.) in to the code and not ""hidden away"" in the ejb-jar.xml files. There's no reason to deploy the ""app tier"" on to a separate jvm/server. Is the web tier calling Remote session beans? vs Local? You may or may not see a speed up by switching to local calls (many ""co-located"" deployments can be made similar to a local invocation on some servers if configured properly dunno if you are doing that already). The biggest risk of switching to local is that with a remote call your arguments are ""safe"" from being changed since they're serialized over the network. With local semantics if you change the value of an argument on purpose or not (i.e. say changing the value of a property in a bean) that change will be reflected in the caller. That may or may not be a problem. If they're already using the local call semantics even for a ""remote"" bean then they already have encountered this issue. As for JPA vs SQL I'd leave it as is. It's not worth redoing the entire data tier to swtich to JPA and if you really wanted the benefits of JPA runtime (vs development time) notably caching etc. then you'd have to convert the ENTIRE data layer (or at least large chunks of inter-related parts) all at once. Really risky and error prone. For the ""duplicate jars"" issue that's an artifact of packaging and build not deployment. To fix the ambiguity issue you need to work on your development environment to use a shared jar repository and be cognisant of the fact that if you upgrade the jar for one you'll upgrade it for all. People decry that that is an unreasonable demand forcing the entire application to upgrade if a jar changes. For enormous disparate apps sure. But for apps in a single JVM no it's not. As much as we'd like every little bit to be an isolated world in the teeming soup we call a Java classloader environment it's simply not true. And the more we can keep that simplified the better off we in terms of complexity and maintenance. For common jars you MIGHT consider bundling those jars in to the app server and out of the application. I'm not fond of that approach but it has it's uses if you can make it work for you. It certainly reduces the deployment size. Client side it's not that hard to convert from Struts 1 to Struts 2 as they both very similar at the high level (notably they're both action frameworks). The key here is that both frameworks can live side by side with each other allowing again incremental change. You can slowly migrate old code over or you can solely implement new code in the new framework. This is different from trying to mix and match an action framework and a component framework. That's literally a ""dogs and cats living together"" situation. If I were to go that route I'd simply deploy the component stuff in their own WAR and move on. The state management of component frameworks makes interoperating with them on the back end really troublesome. If you choose to implement via a new WAR make sure you spend a little time doing some kind of ""Single Sign On"" so folks are ""logged in"" to each module as appropriate. As long as the apps don't share any session state this is as far as the integration really needs to go. And once you've chosen to add a new subsystem via a new WAR you can use any tech you want for the client side. Caching is a different issue. The different caches solve different problems. It's one thing to cache and memoize some little bits within the system (like JSP renderings) or to use a distributed cache to transfer sessions across instance during failover or load balancing. It's quite another to have a cache based domain layer where the persistence and caching are very very tightly integrated. That's far more complex. Just keeping it all straight in your head is painful. The former you can pretty much sprinkle willy nilly across the application as you encounter a needs and those kinds of caches can be pretty much stand alone rather than part of a coordinated overarching caching framework. The latter is a different. There you need to pretty much redo your entire data model even for parts that you're not caching at all as you want to ensure that you have consistent access to the data and it's cache views. This is effectively what JPA does with its two levels of caching and why I mentioned earlier it's not something you can casually slip in to an application save for mostly stand alone chunks of your system. When you have distinct modules hitting the same backend resources cache coherence and consistency becomes a real issue and that's why you want those integrated on both systems. Mind it can be done. The trick is simply integrating the data access level and then you can start caching at that level. But if you have folks making direct SQL calls those have to go. Finally I think the term to use is evolution not revolution. Migrating to EJB 3 or 3.1 I don't think has to be painful as it pretty much Just Works with EJB 2.1 which is a boon. You CAN have a ""mixed"" environment. The most painful integration would have been if you used Entity beans but you didn't so that's good. And for all of the EJB naysayers this backward compatibility that spans across what almost 10 years of EJB is what lets you actually keep a bulk of your code yet still move forward. Yea Glassfish also has the ""one classloader per EAR"" model with the ""one per WAR"" model being an option. This was a real issue when I tried to bundle two WARs in the same EAR. The EJB spec does not define the behavior one way or the other so both models are ""compliant"" but I consider this a hole as the applications built under the two different environments aren't really interchangable even if both are coded ""to spec"". Thanks for the helpful response. Your and the ""wade into the spring"" post complemented each other and addressed our realms-of-concern. As for 'remote' vs. 'local' I was a bit unclear. In practice all calls are local --because Jboss treats ejb calls in the same vm as local. I do not foresee ever putting ejb's on separate vm's as the web tier. We'll look at our 'duplicate jar' issue and deployment. AFAIK and IIRC the earlier versions were vague on .war jars and .ear jars (Jboss had its 'flatclassloader' model which treated every jar in the ear/war as equals. But that's another topic) +1 since this answer has only received 1 other upvote at this time."
749,A,"UNIX socket implementation for Java? I realize that since UNIX sockets are platform-specific there has to be some non-Java code involved. Specifically we're interested in using JDBC to connect to a MySQL instance which only has UNIX domain sockets enabled. It doesn't look like this is supported but from what I've read it should be at least possible to write a SocketFactory for JDBC based on UNIX sockets if we can find a decent implementation of UNIX sockets for Java. Has anyone tried this? Does anyone know of such an implementation? Why not just use the JDBC driver for MySQL? Because it uses tcp/ip sockets instead of unix domain sockets? The better question is ""Why not enable TCP/IP and then use the JDBC driver for MySQL?"" but sometimes we don't get to make that call :) Some searching on the internet has uncovered the following useful-looking library: http://www.nfrese.net/software/gnu_net_local/overview.html Writing a socket factory should be easy enough. Once you've done so you can pass it to your driver THUSLY.  Check out the JNA library. It's a halfway house between pure Java and JNI native code https://github.com/twall/jna/ Thanks Dave. It looks like we could use JNA to write our own socket implementation then write a SocketFactory on top of it though I was hoping to find something already written. :) Have a dig in the Jruby source they use JNA to simulate a lot of pure ruby stuff including fork! There are also examples of a Posix class that should wrap most of the C level functions you need  Checkout the JUDS library. It is a Java Unix Domain Socket library... https://github.com/mcfunley/juds Thanks njsf this may be just what we need!  You could use junixsocket: http://code.google.com/p/junixsocket/ It already provides code for connecting to MySQL from Java (Connector/J) via Unix sockets. One big advantage compared to other implementations is that junixsocket uses the standard Java Socket API. This one's cool because it extends Java Sockets"
750,A,"How to parse a string into a java.sql.date Hi i am trying to parse a string into a java.sql.date Here is what i am doing private static SimpleDateFormat sdfout = new SimpleDateFormat(""yyyy.MM.dd.HH.mm""); try{ String date = ""2010.09.30.13.18""; task.setDueDate(new java.sql.Date(sdfout.parse(date).getTime())); } The problem is that i only get the date back. Not the time. Am i doing this correctly The code logic is fine you only need java.sql.Timestamp instead of java.sql.Date. The SQL timestamp represents both the date and time parts like date in Java. The SQL date represents only the date part. See also: Handling timestamps in MySQL using JDBC Noted should be that you should prefer java.util.Date over java.sql.Timestamp in the model objects and use the Timestamp only at the very moment when you're about to set it in a SQL query. This separates the model objects from the JDBC API and improves their portability and reusability.  The java.sql.Date (according to JavaDoc) A thin wrapper around a millisecond value that allows JDBC to identify this as an SQL DATE value. It returns to you a representation of a SQL DATE. The java.sql.Time (according to JavaDoc) A thin wrapper around the java.util.Date class that allows the JDBC API to identify this as an SQL TIME value. It returns to you a representation of a SQL TIME. If you want both date and time use the java.util.Date instead of java.sql.Date.:"
751,A,"ORM Technologies vs JDBC? My question is regarding ORM and JDBC technologies on what criteria would you decide to go for an ORM technology as compared to JDBC and other way round ? Thanks. Complexity. ORM If your application is domain driven and the relationships among objects is complex or you need to have this object defining what the app does. JDBC/SQL If your application is simple enough as to just present data directly from the database or the relationships between them is simple enough. The book ""Patterns of enterprise application architecture"" by Martin Fowler explains much better the differences between these two types: See: Domain Model and Transaction Script +1. My own way of putting it is that you have to have a sense of when the large constant cost of ORM ""pays for itself"". I've got to agree with this - but I'd also add that there are times when using both within a single application makes sense.  JDBC With JDBC developer has to write code to map an object model's data representation to a relational data model and its corresponding database schema. With JDBC the automatic mapping of Java objects with database tables and vice versa conversion is to be taken care of by the developer manually with lines of code. JDBC supports only native Structured Query Language (SQL). Developer has to find out the efficient way to access database i.e. to select effective query from a number of queries to perform same task. Application using JDBC to handle persistent data (database tables) having database specific code in large amount. The code written to map table data to application objects and vice versa is actually to map table fields to object properties. As table changed or database changed then it’s essential to change object structure as well as to change code written to map table-to-object/object-to-table. With JDBC it is developer’s responsibility to handle JDBC result set and convert it to Java objects through code to use this persistent data in application. So with JDBC mapping between Java objects and database tables is done manually. With JDBC caching is maintained by hand-coding. In JDBC there is no check that always every user has updated data. This check has to be added by the developer. HIBERNATE. Hibernate is flexible and powerful ORM solution to map Java classes to database tables. Hibernate itself takes care of this mapping using XML files so developer does not need to write code for this. Hibernate provides transparent persistence and developer does not need to write code explicitly to map database tables tuples to application objects during interaction with RDBMS. Hibernate provides a powerful query language Hibernate Query Language (independent from type of database) that is expressed in a familiar SQL like syntax and includes full support for polymorphic queries. Hibernate also supports native SQL statements. It also selects an effective way to perform a database manipulation task for an application. Hibernate provides this mapping itself. The actual mapping between tables and application objects is done in XML files. If there is change in Database or in any table then the only need to change XML file properties. Hibernate reduces lines of code by maintaining object-table mapping itself and returns result to application in form of Java objects. It relieves programmer from manual handling of persistent data hence reducing the development time and maintenance cost. Hibernate with Transparent Persistence cache is set to application work space. Relational tuples are moved to this cache as a result of query. It improves performance if client application reads same data many times for same write. Automatic Transparent Persistence allows the developer to concentrate more on business logic rather than this application code. Hibernate enables developer to define version type field to application due to this defined field Hibernate updates version field of database table every time relational tuple is updated in form of Java class object to that table. So if two users retrieve same tuple and then modify it and one user save this modified tuple to database version is automatically updated for this tuple by Hibernate. When other user tries to save updated tuple to database then it does not allow saving it because this user does not have updated data.  It also depends on the learning curve. Ebean ORM has a pretty low learning curve (simple API simple query language) if you are happy enough with JPA annotations for mapping (@Entity @Table @OneToMany etc)."
752,A,"java read JDBC connection from XML file Anyone have idea how can i write XMl file that i will have JDBC connection (username passwd driver connection) in it and then read that xml for connecting to db? What have you tried what did not work? I'm not clear what you are asking. Is it: a). How to structure the XML b). how to read the XML in Java c) how to use what you have parsed to make a JDBC connection? You should focus on one of those problems in this question. You could define your own XML schema bind it to a Java bean and parse it through JAXB. Then you just have to invoke the getters of your bean to build your connection.  Here's how you could compose the XML: <?xml version=""1.0"" encoding=""UTF-8""?> <config> <jdbc> <url>jdbc:mysql://localhost:3306/javabase</url> <driver>com.mysql.jdbc.Driver</driver> <username>java</username> <password>d$7hF_r!9Y</password> </jdbc> </config> Assuming that it's called config.xml and is been placed in the root of the classpath here's an example how you could load it with help of JAXP and Xpath: InputStream input = Thread.currentThread().getContextClassLoader().getResourceAsStream(""config.xml""); Document document = DocumentBuilderFactory.newInstance().newDocumentBuilder().parse(new InputSource(input)); XPath xpath = XPathFactory.newInstance().newXPath(); String url = (String) xpath.compile(""//config//jdbc//url"").evaluate(document XPathConstants.STRING); String driver = (String) xpath.compile(""//config//jdbc//driver"").evaluate(document XPathConstants.STRING); String username = (String) xpath.compile(""//config//jdbc//username"").evaluate(document XPathConstants.STRING); String password = (String) xpath.compile(""//config//jdbc//password"").evaluate(document XPathConstants.STRING); // ... It's only pretty verbose as opposed to properties files. Here's an example of such a properties file:  jdbc.url = jdbc:mysql://localhost:3306/javabase jdbc.driver = com.mysql.jdbc.Driver jdbc.username = java jdbc.password = d$7hF_r!9Y Assuming that it's named config.properties and is been placed in the root of the classpath (or its root path is been added to the classpath) here's how you could load it from the classpath: Properties properties = new Properties(); properties.load(Thread.currentThread().getContextClassLoader().getResourceAsStream(""config.properties"")); String url = properties.getProperty(""jdbc.url""); String driver = properties.getProperty(""jdbc.driver""); String username = properties.getProperty(""jdbc.username""); String password = properties.getProperty(""jdbc.password""); // ... uu thx for such a good howto  I often use the Spring Framework to externalize the configuration of a connection pool and setup of the jdbc URL.  Take a look at commons-configuration. You can read multiple configuration formats with it. That said for database connection properties the a simple key-value .properties file is better I think."
753,A,Can a BFILE locator point to a directory on a different filer? I have a java web application which needs to upload files and we want to store these files on the filesystem rather than in the database. The database will store the document metadata only. The question is whether to just store the path as a string in Oracle or as a BFILE locator? Can a BFILE locator point to a location which is on a different filesystem? If we have to store the file on the Oracle filer then we may as well just store it as a BLOB. The BFILE locator must be a directory that is visible from the Oracle server and which the Oracle OS user has read and write privileges on. So while it could theoretically be a remote server the admin of that approach would get rather gnarly rather quickly. In practical terms it makes more sense to have the BFILE directory on the database server. So might you just as well store it as a BLOB? Well if the file is only ever going to be accessed through the database then yes definitely. Using a BLOB datatype has the advantage of transactional support. And in a related point it makes backup and recovery simpler because the file contents are guaranteed to be in sync with the database. This is not necessarily true of BFILEs and almost certainly not true of BFILEs which reside on a different physical server.
754,A,"spring jdbc RowCallbackHandler nightmare I'm having trouble retrieving data from my database using Spring Jdbc. Here's my issue: I have a getData() method on my DAO which is supposed to return ONE row from the result of some select statement. When invoked again the getData() method should return the second row in a FIFO-like manner. I'm aiming for having only one result in memory at a time since my table will get potentially huge in the future and bringing everything to memory would be a disaster. If I were using regular jdbc code with a result set I could set its fetch size to 1 and everything would be fine. However I recently found out that Spring Jdbc operations via the JdbcTemplate object don't allow me to achieve such a behaviour (as far as I know... I'm not really knowledgeable about the Spring framework's features). I've heard of the RowCallbackHandler interface and this post in the java ranch said I could somehow expose the result set to be used later (though using this method it stores the result set as many times over as there are rows which is pretty dumb). I have been playing with implementing the RowCallbackHandler interface for a day now and I still can't find a way to get it to retrieve one row from my select at a time. If anyone could enlighten me in this matter i'd greatly appreciate it. You can take a different approach. Create a query which will return just IDs of rows that you want to read. Keep this collection of IDs in memory. You really need to have huge data set to consume a lot of memory. Iterate over it and load one by one row referenced by its ID.  JdbcTemplate.setFetchSize(int fetchSize): Set the fetch size for this JdbcTemplate. This is important for processing large result sets: Setting this higher than the default value will increase processing speed at the cost of memory consumption; setting this lower can avoid transferring row data that will never be read by the application. Default is 0 indicating to use the JDBC driver's default. No depending on your database it will use a clause appropriate for limiting the result set. (e.g. MySQL - limit Oracle - rownum etc.) Hmmm - I'm uncertain now. With Hibernate I know this is possible but pure Spring I'm uncertain. Wouldn't this still attempt to assemble a list with all the data in the result set? I still can't afford to have that in memory.  After a lot of searching and consulting with the rest of my team we have come to the conclusion that this is not the best implementation path for our project. As Boris suggested a different approach is the way to go. However I'm doing something different and using SimpleJdbcTemplate instead and splitting my query so it'll fit in memory better. A ""status"" field in my records table will be responsbile for telling if the record was successfully processed or read so i know what records to fetch next. The question if Spring Jdbc is capable of the behaviour i mentioned in my OP is however still in the air. If anyone has an answer for that question I'm sure it would help someone else out there. Cheers!"
755,A,Cannot issue data manipulation statements with executeQuery() In MySQL I have two tables tableA and tableB. I am trying to execute two queries: executeQuery(query1) executeQuery(query2) But I get the following error: can not issue data manipulation statements with executeQuery(). What does this mean? Do you have any access to MySQL other than via JDBC - MySQL Administrator? Or command line? i have the access to mysql admin. however the requiement is such that . the mysql database will be created modified  updated etc. using mysql admin but after that all operations are required to be done with java. Better to include the index creation in scripts to create the database than via JDBC likely after you could have already used them. That's what executeUpdate is for. Here's a very brief summary of the difference: http://www.coderanch.com/t/301594/JDBC/java/Difference-between-execute-executeQuery-executeUpdate  To manipulate data you actually need executeUpdate() rather than executeQuery(). Here's an extract from the executeUpdate() javadoc which is already an answer at its own: Executes the given SQL statement which may be an INSERT UPDATE or DELETE statement or an SQL statement that returns nothing such as an SQL DDL statement.  ExecuteQuery expects a result set. I'm not as familiar with Java/MySQL but to create indexes you probably want a ExecuteUpdate(). It does not expect a `ResultSet`. It instead **returns** a `ResultSet`. It expects a result set from the DB is what I mean.  Use executeUpdate() to issue data manipulation statements. executeQuery() is only meant for SELECT queries (i.e. queries that return a result set).
756,A,"Slow XML response in Java Servlet with MySQL connector I created a Java Servlet that get query result from mySQL database and print it in XML format. the problem is that it takes a very long time something about three minutes to print the xml result while in my PHP script it takes 5 seconds. My Servlet relevant function is: ( run a query and return the xml in a String variable then print it to the page ) public String QueryResult(String query) { String retStr; try { Class.forName(""com.mysql.jdbc.Driver""); Connection conn = DriverManager.getConnection (""jdbc:mysql://""+this.host+"":""+this.port+""/""+this.db this.user this.pass); Statement stmt = conn.createStatement(); ResultSet rset = stmt.executeQuery(query); ResultSetMetaData rsMetaData = rset.getMetaData(); retStr = ""<Result>\n""; while (rset.next()) { retStr += ""\t<Item>\n""; for (int i=1;i<=rsMetaData.getColumnCount();i++) { retStr += ""\t\t<""+rsMetaData.getColumnName(i)+"">""+ rset.getString(i) + ""</""+rsMetaData.getColumnName(i)+"">\n""; } retStr += ""\t</Item>\n""; } retStr += ""</Result>\n""; stmt.close(); conn.close(); } catch(Exception e) { return ""<Result><Error>""+e.toString()+""</Error></Result>""; } return retStr; } Do you know which part of this method is taking the time? Is it just the call to executeQuery() or is it the loop that's constructing the result? Also is this method being called once or many times? Strings in Java are immutable this means that your code creates and destroys a lot of string objects. An obvious optimisation would be to use a StringBuilder or StringBuffer to build your result. I would not expect this to result in minutes difference between this and your other implementation so something else might be the problem (a missing table index perhaps?) If you can add logging to your code so that you get an idea where all this time is spent we could give a more specific advice.  String Concatenation: First of all when speed matters you do not want to concatenate strings the way you do. Each time you concatenate a String you are creating a new one. Better use StringBuilder with a well planned capacity as the default one won't probably suit your need judging from the code snippet you show. Also See: http://stackoverflow.com/questions/2971315/string-stringbuffer-and-stringbuilder http://stackoverflow.com/questions/65668/why-to-use-stringbuffer-in-java-instead-of-the-string-concatenation-operator XML: XStream is a simple library to serialize objects to XML and back again. Might not be related to your performance issue but might come in handy: XStream ""Performance"" does figure in their features list.  Creating/opening/closing connection takes lots time. It is not good for servlet to create own connection - better use connection pooling. I'm newbie in Java can you reference me to connection pooling information? Please read this: http://www.javaranch.com/journal/200601/JDBCConnectionPooling.html and http://dev.mysql.com/tech-resources/articles/connection_pooling_with_connectorj.html  If there is a lot of data to concatenate maybe you would use StringBuffer instead of String.  You should try to use a StringBuilder to concatenate the XML data. This avoids continously copying of data collected so far. A minor improvement could also be to set the initial capacity (in StringBuilders constructor) to the expected size."
757,A,"How do I check to see if a column name exists in a CachedRowSet? I am querying data from views that are subject to change. I need to know if the column exists before I do a crs.get******().I have found that I can query the metadata like this to see if a column exist before I request the data from it. ResultSetMetaData meta = crs.getMetaData(); int numCol = meta.getColumnCount(); for (int i = 1; i < numCol+1; i++) if(meta.getColumnName(i).equals(""name"")) return true; Is there a simpler way of checking to see if a column exists? EDIT: It must be database agnostic. That is why I am referencing the CachedRowSet instead of the database. No there really isn't a better way. You may want to relook at the problem. If you can redefine the problem sometimes it makes the solution simpler because the problem has changed.  There's not a simpler way with the general JDBC API (at least not that I know of or can find...I've got exactly the same code in my home-grown toolset.) (Your code isn't complete): ResultSetMetaData meta = crs.getMetaData(); int numCol = meta.getColumnCount(); for (int i = 1; i < numCol+1; i++) { if(meta.getColumnName(i).equals(""name"")) {return true;} } return false; That being said if you use proprietary database-specific API's and/or SQL queries I'm sure you can find more elegant ways of doing the same thing...but you'd have to write custom code for each database you need to deal with. I'd stick with the JDBC APIs if I were you. Is there something about your proposed solution that makes you think it's incorrect? It seems simple enough to me... I'm new to cachedRowSet I just figured this out as I was writing my question. Asking the question in a coherent manner made me think it in different terms. Just making sure that I am staying on the right track. If you need to look for a lot of columns you can always have this return a `Set` populated by the `getColumnName(i)` method calls. In this way you can refer to `set.contains(myCol)` instead of iterating over it everything.  you could take the shorter approach of using the fact that findColumn() will throw an SQLException for InvalidColumName if the column isn't in the CachedRowSet. for example  try { int foundColIndex = results.findColumn(""nameOfColumn""); } catch { // do whatever else makes sense } Likely an abuse of Exception Handling (per EffectiveJava 2nd ed item 57) but it is an alternative to looping through all the columns from the meta data.  WARNING: following comment purely from memory without any supporting paperwork :) If I recall correctly there is a mysterious problem that rears its ever-so-ugly-head when the oracle cached rowset implementation is used with connection pooling. There appears to be a silent reference to the connection held within the cached rowset object (even though it's supposed to be disconnected) which closes another connection subsequently opened from pool on garbage collection. For this reason I eventually gave up and wrote my own data object layer (these days I'd hand that over to spring & hibernate).  Which Database? I think in Oracle there are tables where the columns are listed. I don't remember if it work for views also but I guess they do it was something like: select colum_name from all_views where view_name like 'myview' or select name from all_objects where object_name like 'myview' and object_type='view' I don't remember exactly the syntax. You should have spacial permissions though. Every RDBMS should have something similar. You can also perform the query select * from myView where 1 = 0 ; And from the metadata get the columns if what you want it to avoid fetching the data before to know if the columns are present. Then select * from myview where 1 = 0 should do. Working with RsMd though but it is pretty fast. It has to be database agnostic. I have never worked with Oracle but may be doing so very soon. +1 for some good info about Oracle views."
758,A,"How can I return the generated keys to JDBC from a DB2 stored procedure that does an insert? I've got a simple stored procedure that does an insert to a table with an identity primary key column. I need to get the key that was generated by the insert. I would prefer to use the standard JDBC getGeneratedKeys method but I'm not sure what the stored procedure needs to do/return to build that result set. My end goal is to do this from Hibernate. I also tried using the select identity generator but it always returns 0. I've never tried the identity val local() function; in my own stored procedures I just do a SELECT after the insert. But you can have a stored procedure return a result set: create procedure proc1( IN in_val ) language sql dynamic result sets 1 BEGIN -- do insert BEGIN DECLARE c_out CURSOR WITH RETURN TO CLIENT FOR select max(key) as inserted_key from table where val = in_val FOR READ ONLY; OPEN c_out; END; END; You can probably use identity val local replacing the select with ""select identity val local() from sysibm.sysdummy1"". I can't seem to get the underscores to work in markdown but hopefully this is clear. What method are you using to call the stored procedure? See http://publib.boulder.ibm.com/infocenter/db2luw/v8/index.jsp?topic=/com.ibm.db2.udb.doc/ad/tjvjdidn.htm That's my solution so far but it requires using a custom Hibernate identity generator. I was hoping there was a way to make it work with the default Hibernate options (getGeneratedKeys or a second select using identity_val_local()). This seems to be about as close as I can get. identity_val_local() doesn't maintain its value when the procedure exits.  The stored procedure can use identity val local to get the generated value and pass it as output parameter to Java program . Select after insert is not a good idea as other processes may have inserted new data to the table and would cause data integrity issues.  It is also possible to select from the insert: SELECT pkey FROM FINAL TABLE (INSERT INTO tab(a b c d) VALUES ... ) This seems a lot simpler than the accepted answer...  On DB2/400 it seems to be the IDENTITY_VAL_LOCAL() function that returns the most recently assigned value for an identity column. http://publib.boulder.ibm.com/infocenter/db2luw/v8/topic/com.ibm.db2.udb.doc/admin/r0004231.htm The key value could be placed in an out parameter for the stored procedure True but that doesn't work when the insert is in a stored procedure and you need to get the key after the procedure exits. True again but I was hoping there was a way to integrate cleanly into Hibernate which allows you to either use the JDBC getGeneratedKeys method or to define a query that will get the last key."
759,A,Where can I find a good jdbc-odbc bridge driver? I do data conversions and I am constantly connecting to a variety of different DBMS'. Certain DBMS' do not have JDBC drivers (MsAccess for example). Sun's JDBC-ODBC bridge driver was meant as a short term solution when JDBC drivers weren't widely available and because of that it is lacking functionality and is pretty buggy. I am told that there are good commercial solutions available I have yet to find any however. Does anyone know of any good bridge drivers? I know I've come late to this discussion but Easysoft offer a JDBC-ODBC bridge too you can also get a free trial of it from them.  use this form and select ODBC from the 'supported dbms'. that way you should be able to find one that also meets your other needs. The link is invalid. Got an updated one? probably because sun don't own java anymore.  Simba has an ODBC and JDBC SDK that contains a JDBC/ODBC bridge. Basically the SimbaEngine SDK is a toolkit that allows you to quickly build an ODBC driver. Many of our customers also want a JDBC driver. So we developed a JDBC/ODBC bridge as part of the SDK to fill this need. The way the driver is put together allows you to take the JDBC/ODBC bridge and use it to connect to any ODBC data source. If you want we have a free evaluation download. Go to http://www.simba.com/evaluate-odbc-sdk.htm. In the project overview explain that you want a JDBC/ODBC bridge and you are looking to use the Simba Client/Server component. Thanks I will check it out.
760,A,Is there a way to listen for changes in an MySQL database table using Java and JDBC? I have a number of users which are logged in at a time in my desktop application. They are working on the same table (create read update delete data) so I have to update their views to reflect changes every few seconds - currently I am thinking to use a different thread to do that. I am using the MySQL database engine. Is there a way using JDBC to listen for changes on a specific table in the database and triggering a Java method only when changes are made? No mysql does not support sending async notifications to a client nor does it have any ways of waiting for table changes. You'd have to build your own data access layer where you support this in your code - and all data access would have to go through that same code.
761,A,"Application using Pooled JDBC Connections I'm working with a legacy WebLogic application that contains a web-service application and a standalone command-line application. Both need access to a common database and I would like to try and get the command-line application use a pooled connection to the web-server's JDBC connection. (The standalone application can only be run when the server is active and both will be run on the same physical machine.) I've been trying to use a JNDI lookup to the JDBC driver as follows: try { Context ctx = null; Hashtable ht = new Hashtable(); ht.put(Context.INITIAL_CONTEXT_FACTORY ""weblogic.jndi.WLInitialContextFactory""); ht.put(Context.PROVIDER_URL ""t3://localhost:7001""); ctx = new InitialContext(ht); DataSource ds = (DataSource) ctx.lookup (""dbOracle""); Connection conn = null; conn = ds.getConnection(); // <-- Exception raised here // conn = ds.getConnection(username password); // (Also fails) // ... } catch (Exception e) { // Handle exception... } I've confirmed the JNDI name is correct. I am able to connect to the database with other web-applications but my standalone application continues to have difficulties. - I got the idea for this from a WebLogic app note. Any ideas on what I have overlooked? EDIT 1.1: I'm seeing a ""java.lang.ClassCastException: java.lang.Object"" exception. EDIT 2: When I perform the following: Object dsObj = ctx.lookup(""dbOracle""); System.out.println(""Obj was: "" + dsObj.getClass().getName()); In the standalone-application it reports: ""Obj was: weblogic.jdbc.common.internal._RemoteDataSource_Stub"" I attempted to test the same chunk of code (described in original question) in the web-application and was able to connect to the datasource (i.e. it seems to ""work""). This working test reports: ""Obj was: weblogic.jdbc.common.internal.RmiDataSource"" Also here's a stack-trace for when it's failing: ####<Apr 22 2009 10:38:21 AM EDT> <Warning> <RMI> <mlbdev16> <cgServer> <[ACTIVE] ExecuteThread: '0' for queue: 'weblogic.kernel.Default (self-tuning)'> <<WLS Kernel>> <> <> <1240411101452> <BEA-080003> <RuntimeException thrown by rmi server: weblogic.jdbc.common.internal.RmiDataSource.getConnection() java.lang.ClassCastException: java.lang.Object. java.lang.ClassCastException: java.lang.Object at weblogic.iiop.IIOPOutputStream.writeAny(IIOPOutputStream.java:1584) at weblogic.iiop.IIOPOutputStream.writeObject(IIOPOutputStream.java:2222) at weblogic.utils.io.ObjectStreamClass.writeFields(ObjectStreamClass.java:413) at weblogic.corba.utils.ValueHandlerImpl.writeValueData(ValueHandlerImpl.java:235) at weblogic.corba.utils.ValueHandlerImpl.writeValueData(ValueHandlerImpl.java:225) at weblogic.corba.utils.ValueHandlerImpl.writeValue(ValueHandlerImpl.java:182) at weblogic.iiop.IIOPOutputStream.write_value(IIOPOutputStream.java:1957) at weblogic.iiop.IIOPOutputStream.write_value(IIOPOutputStream.java:1992) at weblogic.iiop.IIOPOutputStream.writeObject(IIOPOutputStream.java:2253) at weblogic.jdbc.common.internal.RmiDataSource_WLSkel.invoke(Unknown Source) at weblogic.rmi.internal.BasicServerRef.invoke(BasicServerRef.java:589) at weblogic.rmi.cluster.ClusterableServerRef.invoke(ClusterableServerRef.java:224) at weblogic.rmi.internal.BasicServerRef$1.run(BasicServerRef.java:479) at weblogic.security.acl.internal.AuthenticatedSubject.doAs(AuthenticatedSubject.java:363) at weblogic.security.service.SecurityManager.runAs(Unknown Source) at weblogic.rmi.internal.BasicServerRef.handleRequest(BasicServerRef.java:475) at weblogic.rmi.internal.BasicServerRef.access$300(BasicServerRef.java:59) at weblogic.rmi.internal.BasicServerRef$BasicExecuteRequest.run(BasicServerRef.java:1016) at weblogic.work.ExecuteThread.execute(ExecuteThread.java:200) at weblogic.work.ExecuteThread.run(ExecuteThread.java:172) It would help if you'd tell us what the exception is. java.lang.Object is not an exception. Perhaps try: Object dsObj = ctx.lookup(""dbOracle""); System.out.println(""Obj was: "" + dsObj.getClass().getName()); to see if you are really getting what you think? I think a full stacktrace would be useful Can you tell us what additional libs did you included with your standalone application? What version of WebLogic are you using? It is possible that the JARs you have for Oracle driver in the client JVM are different than the ones in the server. make sure the same Oracle JDBC driver jar is in both classpaths of the command-line tool and the weblogic webapp good luck !  One possibility: you import incorrect ""DataSource"" class :-) Try replacing this line of code: DataSource ds = (DataSource) ctx.lookup (""dbOracle""); for this: javax.sql.DataSource ds = (javax.sql.DataSource) ctx.lookup (""dbOracle""); Just an idea hope this will help you  Hard to tell what is going on with such limited information. Did you set the application up as a thin client? When you are not operating within one of the Java EE containers the context and means of doing lookups does not work the same way (varies by vendor). You may want to research how to do lookups of resources with Weblogic from such a client as well as how to set it up correctly. I agree... we clearly need more data. I have just added additional information. I hope it'll be helpful.  This exception looks like it is generated on the server side. The first thing I would do is verify the version of WebLogic Server and check the classpath of the client application. You need to make sure your client app has the same version of the WebLogic client jar files as the WebLogic Server. You are including weblogic client jar files in the classpath of your client right? Since your are using WebLogic's RMI driver I don't believe you need any Oracle jar files in the classpath of the client. Your client is essentially speaking RMI to the WebLogic Server. The WebLogic Server connection pool you configured knows how to speak to Oracle. It shouldn't matter what JDBC driver you use in your connection pool. I was *not* including the WebLogic client jar files in the application's classpath. Thanks! Yup it isn't obvious by only looking at the import statements of your code that you need it. The compiler won't complain but casting the object looked up will barf.  I think this problem is resolved by executing bea or weblogic\user_projects\domains\base_domain\bin>setDomainEnv.cmd its nothing but setting CLASSPATH to required jar files....  Perhaps a classpath issue or even a jvm version thing?"
762,A,"simple jdbc wrapper To implement data access code in our application we need some framework to wrap around jdbc (ORM is not our choice because of scalability). The coolest framework I used to work with is Spring-Jdbc. However the policy of my company is to avoid external dependencies especially spring J2EE etc. So we are thinking about writing own handy-made jdbc framework with functionality similar Spring-jdbc: row mapping error handling supporting features of java5 but without transaction support. Does anyone have experience of writing such jdbc wrapper framework? If anyone has experience of using other jdbc wrapper frameworks please share your experience. Thanks in advance. ""the policy of my company is to avoid external dependencies especially spring J2EE etc."" wow this sounds like a nightmare. Sounds like an endless loop of re-inventing the wheel J2EE is an ""external dependency""?? If you're looking for simplistic SQL execution to object mapping mybatis is an option. I wouldn't call it an ORM in the sense that it doesn't do object graphs like hibernate would. It simply allows you to execute sql and pull in parameters from your input or map columns to output object(s). We wrote our own wrapper. This topic is worthy of a paper but I doubt I'll ever have time to write it so here are some key points: we embraced sql and made no attempt to hide it. the only tweak was to add support for named parameters. parameters are important because we do not encourage the use of on-the-fly sql (for security reasons) and we always use PreparedStatements. for connection management we used Apache DBCP. This was convenient at the time but it's unclear how much of this is needed with modern JDBC implementations (the docs on this stuff is lacking). DBCP also pools PreparedStatements. we didn't bother with row mapping. instead (for queries) we used something similar to the Apache dbutil's ResultSetHandler which allows you to ""feed"" the result set into a method which can then dump the information wherever you'd like it. This is more flexible and in fact it wouldn't be hard to implement a ResultSetHandler for row mapping. for inserts/updates we created a generic record class (basically a hashmap with some extra bells and whistles). the biggest problem with row mapping (for us) is that you're stuck as soon as you do an ""interesting"" query because you may have fields that map to different classes; because you may have a hierarchical class structure but a flat result set; or because the mapping is complex and data dependent. we built in error logging. for exception handling: on a query we trap and log but for an update we trap log and rethrow an unchecked exceptions. we provided transaction support using a wrapper approach. the caller provides the code that performs transaction and we make sure that the transaction is properly managed with no chance of forgetting to finish the transaction and with rollback and error handling built-in. later on we added a very simplistic relationship scheme that allows a single update/insert to apply to a record and all its dependencies. to keep things simple we did not use this on queries and we specifically decided not to support this with deletes because it is more reliable to use cascaded deletes. This wrapper has been successfully used in two projects to date. It is of course lightweight but these days everyone says their code is lightweight. More importantly it increases programmer productivity decreases the number of bugs (and makes problems easier to track down) and it's relatively easy to trace through if need be because we don't believe in adding lots of layers just to provide beautiful architecture.  The one I prefer: Dalesbred. It's MIT licensed. A simple example of getting all rows for a custom class (Department). List<Department> departments = db.findAll(Department.class ""select id name from department""); when the custom class is defined as: public final class Department { private final int id; private final String name; public Department(int id String name) { this.id = id; this.name = name; } } Use it as is or take a look how it works by checking out the code. Disclaimer: it's by company I work for.  Spring-JDBC is fantastic. Consider that for an open source project like Spring the down side of external dependency is minimized. You can adopt the most stable version of Spring that satisfies your JDBC abstraction requirements and you know that you'll always be able to modify the source code yourselves if you ever run into an issue -- without depending on an external party. You can also examine the implementation for any security concerns that your organization might have with code written by an external party.  Try JdbcSession from jcabi-jdbc. It's as simple as JDBC should be for example: String name = new JdbcSession(source) .sql(""SELECT name FROM foo WHERE id = ?"") .set(123) .select(new SingleOutcome<String>(String.class)); That's it.  This sounds like a very short sighted decision. Consider the cost of developing/maintaining such a framework especially when you can get it and it's source code for free. Not only do you not have to do the development yourself you can modify it at will if need be. That being said what you really need to duplicate is the notion of JdbcTemplate and it's callbacks (PreparedStatementCreator PreparedStatementCallback) as well and RowMapper/RowCallbackHandler. It shouldn't be overcomplicated to write something like this (especially considering you don't have to do transaction management). Howver as i've said why write it when you can get it for free and modify the source code as you see fit?"
763,A,How can I find out how many rows a MySQL query returns in Java? How can I find out how many rows a MySQL query returns in Java? This is not digg if you want people to spend time helping you you should spend time writing better questions. If you use a CachedRowSet you can know how many rows your statement returned and iterate then both ways forward and backwards with the drawback that the full rowset must be placed in memory instead of being fetched dynamically. here more info.  I don't think you can except maybe by calling ResultSet.last() and then ResultSet.getRow() - but I don't know if that will actually work. I've always just processed each row at a time and counted them afterwards.  From the jdbc faq: .18. There is a method getColumnCount in the JDBC API. Is there a similar method to find the number of rows in a result set? No but it is easy to find the number of rows. If you are using a scrollable result set rs you can call the methods rs.last and then rs.getRow to find out how many rows rs has. If the result is not scrollable you can either count the rows by iterating through the result set or get the number of rows by submitting a query with a COUNT column in the SELECT clause.
764,A,"How to use Java DB (named Derby) with hibernate Hi guys i can connect Derby via Eclipse Database Development but i cannot connect Derby with same url with Eclipse Database Development's through Hibernate. Error :""Caused by: java.sql.SQLException: Another instance of Derby may have already booted the database "" Answer: don't! Derby is a slow inflexible minimally-featured DBMS. Use H2 DBMS or HSQL... or basically anything else instead. It seems as if you are running Derby as an embedded DB and not a DB Server. The problem is both are running in different JVMs and a given database can only be accessed from one JVM. Eclipse will start another JVM when you start testing your program and not allow to conenect to the embedded DB in eclipse. I think the how to use Derby as a network DB Server can help you. An alternative would be to disconnect from the DB in the tooling prior to running the code - via the `Data Source Explorer` view.  Just finished a project that did this using Derby with Hibernate a couple of days ago. (With Derby running in the same JVM.) As I understand it when you use the Embedded driver it by default starts the database instance as part of the driver and as long as you hang onto the connection the database is running. But for Hibernate it likes to have a DataSource given to it which should really be a pooling data source. The above answer is correct it is really a good idea to start Derby as a Network DB Server even if your in the same JVM. You can still use the embedded JDBC driver which seems to know when the database your connecting to is in Network mode and adjusts accordingly. (This also allows using a third party tool to connect to the database and view and edit the data and schema while it is running very handy for debugging.) System.setProperty(""derby.system.home"" applicationHome); NetworkServerControl serverControl = new NetworkServerControl(InetAddress.getByName(m_address)port); serverControl.start(new PrintWriter(System.out true)); Once the database is running you then stick a DataSource instance in a JNDI registry. Then Hibernate can access this data source given it's name from the JNDI registry. EmbeddedConnectionPoolDataSource40 dataSource = new EmbeddedConnectionPoolDataSource40(); dataSource.setDatabaseName(databaseName); dataSource.setUser(username); dataSource.setPassword(password); The EmbeddedConnectionPoolDataSource40 is the DataSource implementation to use with a pooling DataSource wrapper so connections can be reused where possible. I used Apache Commons DBCP and modified one of the examples to create my own pooling DataSource using EmbeddedConnectionPoolDataSource40."
765,A,"How to do a backup from a Postgresql-DB via JDBC? In our application we've implemented an automatic DB migration triggered from within our code. Now we want to backup the existing DB before doing any migration. Can anyone explain how to do a full backup of a Postgresql-DB via JDBC from within Java code? Update: it doesn't work via JDBC. Here some working code to the response of Frank Heikens:  final List<String> baseCmds = new ArrayList<String>(); baseCmds.add(""/usr/bin/pg_dump""); baseCmds.add(""-h""); baseCmds.add(""hostname""); baseCmds.add(""-p""); baseCmds.add(""5432""); baseCmds.add(""-U""); baseCmds.add(""username""); baseCmds.add(""-b""); baseCmds.add(""-v""); baseCmds.add(""-f""); baseCmds.add(""/path/to/backup.sql""); baseCmds.add(""dbName""); final ProcessBuilder pb = new ProcessBuilder(baseCmds); // Set the password final Map<String String> env = pb.environment(); env.put(""PGPASSWORD"" ""password""); try { final Process process = pb.start(); final BufferedReader r = new BufferedReader( new InputStreamReader(process.getErrorStream())); String line = r.readLine(); while (line != null) { System.err.println(line); line = r.readLine(); } r.close(); final int dcertExitCode = process.waitFor(); } catch (IOException e) { e.printStackTrace(); } catch (InterruptedException ie) { ie.printStackTrace(); } I use DbUnit for backup of a database from within my java application: DbUnit has the ability to export and import your database data to and from XML datasets. Since version 2.0 DbUnit can also work with very large datasets when used in streaming mode. DbUnit doesn't dump SQL. But I didn't tell that in the original question.  The Postgresql JDBC library now supports the bulk COPY operations. See http://jdbc.postgresql.org/documentation/publicapi/index.html?org/postgresql/copy/CopyManager.html To back up a database you'll want to CopyOut from the db to a stream then reverse the process to restore using CopyIn.  Why don't you use pg_dump? Because when I use ProcessBuilder to start pg_dump pg_dump can't access file to write the dump into :( Then stream the output of pg_dump to another location. pg_dump is the only secure method to make a backup all others (except PITR) will fail. And they fail at the worst posible moment. That didn't work either. It ran into a blocking read. I solved the problem specifying the Filename without any "" or '."
766,A,"How can I get the SQL of a PreparedStatement? I have a general Java method with the following method signature: private static ResultSet runSQLResultSet(String sql Object... queryParams) It opens a connection builds a PreparedStatement using the sql statement and the parameters in the queryParams variable length array runs it caches the ResultSet (in a CachedRowSetImpl) closes the connection and returns the cached result set. I have exception handling in the method that logs errors. I log the sql statement as part of the log since it's very helpful for debugging. My problem is that logging the String variable sql logs the template statement with ?'s instead of actual values. I want to log the actual statement that was executed (or tried to execute). So... Is there any way to get the actual SQL statement that will be run by a PreparedStatement? (Without building it myself. If I can't find a way to access the PreparedStatement's SQL I'll probably end up building it myself in my catches.) If you're writing straight JDBC code I'd highly recommend looking at Apache commons-dbutils http://commons.apache.org/dbutils/. It simplifies JDBC code greatly. Dupe: http://stackoverflow.com/questions/218113/logging-preparedstatements-in-java Using prepared statements there is no ""SQL query"" : You have a statement containing placeholders it is sent to the DB server and prepared there which means the SQL statement is ""analysed"" parsed some data-structure representing it is prepared in memory And then you have bound variables which are sent to the server and the prepared statement is executed -- working on those data But there is no re-construction of an actual real SQL query -- neither on the JAVA side nor on the database side. So there is no way to get the prepared statement's SQL -- as there is no such SQL. For debugging purpose the solutions are either to : Ouput the code of the statement with the placeholders ; and the list of data Or to ""build"" some SQL query ""by hand"". Although this is functionally true there's nothing preventing utility code from reconstructing an equivalent unprepared statement. For example in log4jdbc: ""In the logged output for prepared statements the bind arguments are automatically inserted into the SQL output. This greatly Improves readability and debugging for many cases."" Very useful for debugging as long as you're aware that it's not how the statement is actually being executed by the DB server. This also depends on the implementation. In MySQL -- at least the version I was using a few years ago -- the JDBC driver actually built a conventional SQL query from the template and bind variables. I guess that version of MySQL didn't support prepared statements natively so they implemented them within the JDBC driver. @sidereal : that's what I meant by *""build the query by hand""* ; but you said it better than me ;;; @Jay : we have the same kind of mecanism in place in PHP *(real prepared statements when supported ; pseudo-prepared statements for database drivers that don't support them)*  here an example of how you can get the sql of the perperated statment http://www.avajava.com/tutorials/lessons/how-do-i-display-a-prepared-statement-with-bind-variables-using-mysql.html simply do prepStmt.toString()  If you're using MySQL you can log the queries using MySQL's query log. I don't know if other vendors provide this feature but chances are they do.  To do this you need a JDBC Connection and/or driver that supports logging the sql at a low level. Take a look at log4jdbc  It's nowhere definied in the JDBC API contract but if you're lucky the JDBC driver in question may return the complete SQL by just calling PreparedStatement#toString(). I.e. System.out.println(preparedStatement); Most JDBC drivers doesn't support it. If you have such one then your best bet is using P6Spy. Alternatively you can also write a generic function which takes a Connection a SQL string and the statement values and returns a PreparedStatement after logging the SQL string and the values. Kickoff example: public static PreparedStatement prepareStatement(Connection connection String sql Object... values) throws SQLException { PreparedStatement preparedStatement = connection.prepareStatement(sql); for (int i = 0; i < values.length; i++) { preparedStatement.setObject(i + 1 values[i]); } logger.debug(sql + "" "" + Arrays.asList(values)); return preparedStatement; } and use it as try { connection = database.getConnection(); preparedStatement = prepareStatement(connection SQL values); resultSet = preparedStatement.executeQuery(); // ... Another alternative is to implement a custom PreparedStatement which wraps (decorates) the real PreparedStatement on construction and overrides all the methods so that it calls the methods of the real PreparedStatement and collects the values in all the setXXX() methods and lazily constructs the ""actual"" SQL string whenever one of the executeXXX() methods is called (quite a work but most IDE's provides autogenerators for decorator methods Eclipse does). Finally just use it instead. That's also basically what P6Spy and consorts already do under the hoods. That's similar to the method I'm using (your prepareStatement method). My question isn't how to do it - my question is how to *log* the sql statement. I know that I can do `logger.debug(sql + "" "" + Arrays.asList(values))` - I'm looking for a way to log the sql statement with the parameters already integrated into it. Without looping myself and replacing the question marks. Then head to the last paragraph of my answer or look at P6Spy. They do the ""nasty"" looping and replacing work for you ;)"
767,A,"Easy way to fill up ResultSet with data I want to mock a ResultSet. Seriously. I'm refactoring one big complicated piece of code which is parsing data from ResultSet and I want my code to behave identically. So I need to write a unit test for the piece being refactored to be able to test this. After googling I came up with 2 ideas: Use EasyMock write looooong mocking sequence. VERY BAD solution: hard to add initial data hard to change data big test debugging promices. Use Apache Derby or HSQLDB to create in-memory DB fill it from file or String array query with some magical InMemoryDBUtils.query(sql). Then use that ResultSet. Unfortunately I did not find any magical InMemoryDBUtils to write the test fast :-). IBM article ""Isolated unit testing of persistence with Derby"" seems just fine about what I need though... Second approach looks somewhat easier and much more supportable. What would you advice for creating such a mock? (despite doctors of course :-)? Am I missing an eyebrow some silver bullet? Possibly DBUnit is the tool for this? Thank you all for your time and answers. WBR DiaWorD I have written something for this same case. You can mock the resultset using Mockito. You can as well loop over the mock rows of resultset by mocking the resultset.next() with this piece of code. // two dimensional array mocking the rows of database. String[][] result = { { ""column1"" ""column2"" } { ""column1"" ""column2"" } }; @InjectMocks @Spy private TestableClass testableClass; @Mock private Connection connection; @Mock private Statement statement; @Mock private ResultSet resultSet; @BeforeTest public void beforeTest() { MockitoAnnotations.initMocks(this); } @BeforeMethod public void beforeMethod() throws SQLException { doAnswer(new Answer<Connection>() { public Connection answer(InvocationOnMock invocation) throws Throwable { return connection; } }).when(testableClass).getConnection(); when(connection.createStatement()).thenReturn(statement); when(statement.executeQuery(anyString())).thenReturn(resultSet); final AtomicInteger idx = new AtomicInteger(0); final MockRow row = new MockRow(); doAnswer(new Answer<Boolean>() { @Override public Boolean answer(InvocationOnMock invocation) throws Throwable { int index = idx.getAndIncrement(); if (result.length > index) { String[] current = result[index]; row.setCurrentRowData(current); return true; } else return false; } ; }).when(resultSet).next(); doAnswer(new Answer<String>() { @Override public String answer(InvocationOnMock invocation) throws Throwable { Object[] args = invocation.getArguments(); int idx = ((Integer) args[0]).intValue(); return row.getColumn(idx); } ; }).when(resultSet).getString(anyInt()); } static class MockRow { String[] rowData; public void setCurrentRowData(String[] rowData) { this.rowData = rowData; } public String getColumn(int idx) { return rowData[idx - 1]; } }  I've had success with the MockResultSet class from here: http://mockrunner.sourceforge.net/. It allows you to create a class that implements the ResultSet interface and lets you set the values for each column and row. If your methods are working with ResultSets of reasonable size you should be able to create tests that return the values you need fairly easily. Here's a simple example: MockResultSet rs = new MockResultSet(""myMock""); rs.addColumn(""columnA"" new Integer[]{1}); rs.addColumn(""columnB"" new String[]{""Column B Value""}); rs.addColumn(""columnC"" new Double[]{2}); // make sure to move the cursor to the first row try { rs.next(); } catch (SQLException sqle) { fail(""unable to move resultSet""); } // process the result set MyObject obj = processor.processResultSet(rs); // run your tests using the ResultSet like you normally would assertEquals(1 obj.getColumnAValue()); assertEquals(""Column B Value"" obj.getColumnBValue()); assertEquals(2.0d obj.getColumnCValue()); Hello mjd79 And thank you for your answer. The trouble in my case is that I'll defenitely have about 100 records for each testcase and about 10 testcases :-) Each record has 10 fields including Dates Numbers and Strings. Because of that I'd prefer to store mock data in file preferably in INSERT INTO form which can be taken directly from almost every DB client. MockRunner looks quite nice but I'll keep it for some other case. Thanks again for your time. mockrunner was a great resource to mock out a simple result set for a batch job test. Thanks a bunch!  I was looking for the same thing a library to mock a ResultSet and I eventually found it. Mockrunner can load a csv or xml file and create a MockResultSet automatically. It also mocks Connection and Statement so all your JDBC stuff simply works without even adding a JDBC driver to your classpath. http://mockrunner.sourceforge.net  If applicable you could you take the result set you have now from your real data source serialize it and save the file. Then you could deserialize that result set for each of your unit tests and you should be good to go. Hello GWLlosa and thanks for your feedback too. I think DBUnit will help me with storing data in file.  DBUnit doesn't present a result set to my knowledge although it will well help you populate your in memory database. I would say that a mocking framework is the wrong approach at this point. Mocking is about testing behavior and interaction not just returning data so it will likely get in your way. I would instead either implement a result set interface or create a dynamic proxy of a result set interface to a class that implements the methods you care about without having to implement the whole result set. You will likely find maintaining a class as easy as maintaining an in memory database (provided that the dataset under test is consistent) and probably easier to debug. You could back up that class with DBUnit where you take a snapshot of your result set with dbunit and have dbunit read it back during the test from xml and have your dummy result set read the data from dbunit's classes. This would be a reasonable approach if the data was mildly complex. I would go for the in memory database if the classes were so coupled that they need to read data that was modified as part of the same test. Even then I would consider using a copy of the real database until you managed to pull that dependency apart. A simple proxy generation method: private static class SimpleInvocationHandler implements InvocationHandler { private Object invokee; public SimpleInvocationHandler(Object invokee) { this.invokee = invokee; } public Object invoke(Object proxy Method method Object[] args) throws Throwable { method = invokee.getClass().getMethod(method.getName() method.getParameterTypes()); if (!method.isAccessible()) { method.setAccessible(true); } try { return method.invoke(invokee args); } catch (InvocationTargetException e) { throw e.getTargetException(); } } } public static <T> T generateProxy(Object realObject Class... interfaces) { return (T) Proxy.newProxyInstance(realObject.getClass().getClassLoader() interfaces new SimpleInvocationHandler(realObject)); } You are welcome. I would say that if each of the 10 tests requires different data then yes this would be a reasonable approach. With DBUnit you can take a ResultSet and write it to XML so you just reference that in the test. Hello Yishai thanks for feedback. I'll be mocking about 100 records for each of 10 or more tests with record consisting of 10 fields. This AFAIU leaves me with DBUnit to store the data in file and custom ResultSet implementation. Thanks again for answering.  As long as you're not calling most of the ResultSet methods I would probably just load a delimited text file into a two-dimensional array and implement the methods I actually needed leaving the rest to throw an UnsupportedOperationException (which is the default implementation for stubbed-out methods in my IDE)."
768,A,"Handling MySQL datetimes and timestamps in Java In a java application what would a good compromise in terms of extracing and inputting date information with a MySQL database using a mix of datetimes and timestamps? The MySQL documentation has information on mapping MySQL types to Java types. In general for MySQL datetime and timestamps you should use java.sql.Timestamp. A few resources include: http://dev.mysql.com/doc/refman/5.1/en/datetime.html http://www.coderanch.com/t/304851/JDBC/java/Java-date-MySQL-date-conversion http://stackoverflow.com/questions/2400955/how-to-store-java-date-to-mysql-datetime http://www.velocityreviews.com/forums/t599436-the-best-practice-to-deal-with-datetime-in-mysql-using-jdbc.html EDIT: As others have indicated the suggestion of using strings may lead to issues. why would it better to convert the dates into strings? Don't massage it forth and back as string. It's recipe for portability and maintainability trouble. Agreed. I've modified my answer accordingly.  In Java side the date is usually represented by the (poorly designed but that aside) java.util.Date. It is basically backed by the Epoch time in flavor of a long also known as a timestamp. It contains information about both the date and time parts. In Java the precision is in milliseconds. In SQL side there are several standard date and time types DATE TIME and TIMESTAMP (at some DB's also called DATETIME) which are represented in JDBC as java.sql.Date java.sql.Time and java.sql.Timestamp all subclasses of java.util.Date. The precision is DB dependent often in milliseconds like Java but it can also be in seconds. In contrary to java.util.Date the java.sql.Date contains only information about the date part (year month day). The Time contains only information about the time part (hours minutes seconds) and the Timestamp contains information about the both parts like as java.util.Date does. The normal practice to store a timestamp in the DB (thus java.util.Date in Java side and java.sql.Timestamp in JDBC side) is to use PreparedStatement#setTimestamp(). java.util.Date date = getItSomehow(); Timestamp timestamp = new Timestamp(date.getTime()); preparedStatement = connection.prepareStatement(""SELECT * FROM tbl WHERE ts > ?""); preparedStatement.setTimestamp(1 timestamp); The normal practice to obtain a timestamp from the DB is to use ResultSet#getTimestamp(). Timestamp timestamp = resultSet.getTimestamp(""ts""); java.util.Date date = timestamp; // You can just upcast. do you think that using java.sql.Timestamp in the model (Java layer) is bad? @cherouvim: Yes. The model shouldn't be aware of any JDBC specifics. Only use it to set the timestamp. `preparedStatement.setTimestamp(new Timestamp(date.getTime()));`. Getting it is easy since it's already a subclass of `java.util.Date`."
769,A,"Displaying entity-attribute-value data in JTable? How can I use a JTable to display & edit attribute properties for entities retrieved from an entityattributevalue (EAV) store (a relational DBMS)? I know this is a question with a lot of possible answers so PLEASE look at the requirements I have below before answering. I promise to vote up answers that show you've read & understand the whole thing (as long as they aren't totally silly). The user needs to be able to: Filter/Search entities by their attributes Choose which attributes to show (as columns) Sort entities by chosen attributes Edit attribute values Do operations on selected entities (Optional) Ability to save view for later use. System Requirements: Number of entities: needs to scale up to 100K+ unique entities Attributes: user can add and define new attributes system should be able to handle this Underlying Storage: H2 Database (already designed) communicating by JDBC Memory: not everything will fit so somehow needs to pull from DBMS queries Performance: should minimize number of queries needed to DBMS (one query per attribute OK and I have a form with 1 query per table view but it sucks). Queries: ONE query should be required to generate list of entities matching a search/filter. Otherwise massive performance suck. Reusing data: shouldn't have to re-query or re-sort the entire list when column is added. Things I've looked at: Glazed Lists library Pros: Flexible about column handling Easy to implement sort/filter of entities Flexible about column display format & editing Cons: One object per entity (if objects are complex memory overhead becomes a serious memory problem!) Object responsible for all functionality... but objects should be simple for memory reasons How do I support user-selectable columns without a HashMap for EVERY entity object? Extending AbstractTableModel to map data from a JDBC ResultSet to rowscolumns Pros: Paging of results avoids memory problem Searching/Filtering is directly in SQL Memory-friendly doesn't have to make an object per-row Cons: Implementing custom columns & sorting is a pain (table header renderer managing sort columns and order etc)! Probably have to write custom JTableColumnModel too and this gets messy! Has to manipulate SQL a lot so if DB schema changes have to rewrite multiple pieces of code! Hard to maintain entity ID info ORM Pros: Designed to map DB rows to objects Provides object management Cons: WORST POSSIBLE solution for entity-attribute-value model Have to learn & write ORM code in addition to DBMS & Java code! Entities can have any number of attributes ORM is only good with static limited object attributes Lose flexibility/speed of custom SQL Is there a better option that I missed or some clever way to make Glazed Lists or custom Table Model easier? I've totally discarded ORM as an option already because of how badly matched it is to EAV storage. boy do I feel your pain. clearly you understand the problem of trying to link a JTable as a ""viewer""/""editor"" of an underlying database that should not exist all at once in memory. The worst part: I think all entity identifier keys (longs or ints) *could* fit in memory so it should be simpler. Except I'm pretty sure that the DefaultRowSorter implementation bundles them in like 1 billion layers of wrappers so what should take a couple MB of RAM will actually be >1 GB. It's like those babies you see where the mom has put so many layers of protection wrapped around that they can hardly breathe. I think your best option is to go with 'Extending AbstractTableModel with form map data from a JDBC ResultSet' because Java 6 JTable has built in sorting support so you don't really need to implement that. If you design your model carefully you could survive some schema changes. Code clearly to allow yourself to make changes easier if you need. You'll have to write back changes anyway. Use a 'Save' button and batch update might even help your performance. You can override TableCellEditor to supply combobox instead of the default text editor. Don't try to do all edit in one table. Have separated means for entry creation etc. You can add/remove columns to JTable at runtime. Just fireTableModelChanged() and the new column becomes visible Edit: One crazy thing I would do to create a custom component and do all rendering myself and perform the edit operations with well placed JTextField and JComboBox. Edit2: Based on your comment. Save the position of the selected item before you do the fire...() call. Btw I don't think the call resets the sorting or the selection - had no problem with that. If you add a column you could just fetch the key field and the values for the new column only. Display them in the column. Then do a hidden complete reload in the background and swap the model to that when it is finished. This is practically working from multiple ResultSets at the same time in one table. Removing is easy as you don't show the values for that column. Edit3: DefaultRowSorter isn't that deep. It maintains a reindexing table for your records. So when JTable asks for the 10th row the rowsorter checks its 10th entry of the index table and retrieves that indexth element from your actual model. Also if you have lots of identical strings in your model use a simple Map of String to String cache when you query the data from the database. This way the tons of redundant String objects can be GC-d right away. Edit4: I would query the new field into a Map of key to value and have my primary model contain a list of map of key to value. Then I would use a getValue() implementation which returns the value from either the primary data source of from these additional maps on demand. I would lookup the row's key from the primary model and use that to retrieve the actual value from the additional maps. (Btw. Reputation gained from accepted answers are not subject to the daily limit.) Heh fixed the typo there. Not a bad answer but the tricky part is how I then do column addition/removal. fireTableModelChanged() will totally reset selected items sorting and require the whole dataset to be re-fetched (IIRC). The issue I have is... how do I then do column show/hide? Make a new query and re-do everything from scratch in the model? Call ""fireColumnedAdded"" on the TableColumnModel? I really like the edit 2 answer but would like a little more detail to see if I follow. Could I get a little pseudo-code and additional detail (like how do I manage the mapping of rowcolumn to the additional ResultSet -- hidden hashmap between model column index and (ResultSetresultset column index)? If you post response as a new answer it may make things simpler and I can give you another up vote for being responsive. I would use some hash maps behind the scenes as you inferred. I can give you only some conceptional hints and approaches in my answers as your case is fairly complex to create reasonable code snipplets. Unfortunately I'm already at the daily 200 reputation limit but thanks. Glad that DefaultRowSorter isn't *terrible* like I thought and a cache was already planned in 1st set of memory optimizations. Could you explain a little more how (in your idea) I should handle column index to resultset & resultset column mappings? Are we talking one ResultSet per column here with entityIDattributeValue(s) columns for each resultset or a some sort of hashmap from column index to resultset & resultset column? In that case I will wait until tomorrow to accept the answer (unless someone posts a better one which I seriously doubt) so you get the full credit."
770,A,JDBC (mysql) saves queries in heap memory I am trying to run Hibernate Search on database on a table with 12500000 records. On startup Hibernate Search queries the database to obtain the schema information. The problem is that I get OutOfMemory: heap size exception. I read around and found out that JDBC connector of MySQL puts queries on JAVA heap memory and it's a bug. Is there a workarround for this bug? I am using 5.1 connector. Please see my post to Hibernate forum where they write that there is a bug in MySQL Hibernate Search Forum The question is how can I work arround it? Database metadata doesn't need to much memory. Start the application with a profiler and you will see right away how memory is used. I edited my question - added the link to Hibernate Forum  It isn't necessarily a bug if you run out of memory you might just not have enough memory allocated to Java. Heap space is where data in Objects is stored and the JDBC connection is an Object. If the code is correct and you just need more heap space increase the size of the heap. java -Xms<initial heap size> -Xmx<maximum heap size> If this doesn't solve it odds are the code has a deeper issue; something's eating memory that shouldn't be. Find the problem before continually adding more memory; otherwise you're just putting a temporary bandage on the issue and the bandage probably won't last long. I am running it with heap size 1200MB - the maximum Run a profiler tool against the code see where it's gobbling up that memory. Schema information shouldn't take anywhere near that amount of RAM. I edited my question - added the link to Hibernate Forum  I found the solution. In MySQL I had to add to connection string: &useServerPrepStmts=true&useCursorFetch=true This option enables streaming results by default.
771,A,Instantiating Oracle Driver results in InvocationTargetException I have a simple web service that uses an oracle database. When I test the service internally it works fine however calling the web service through my client (on the same machine but in a different WAR) throws an invocationtargetexception. I've finally discovered it's an issue with instantiating the OracleDriver. It doesn't throw any exception at all so I cannot find out what the error is. Googling has only provided a solution of using oracle.jdbc.driver.OracleDriver instead of oracle.jdbc.OracleDriver but that doesn't seem to fix anything. The jar I'm using is ojdbc14.jar and as far as I can tell it's included in the class path for the web service properly... since it works when I test the service with a simple main method. EDIT: The InvocationTargetException is generated by an AxisFault from the Axis server. The invocationtargetexception is a wrapper class and my attempts to try to extract the exception using .getCause() always return null. I am deploying the service using jboss and was including the driver JAR file in the library for the source but not for the server. Including the driver in /jboss/server/default/lib resolved it. can you post the full exception? In particular what is the exception that caused the exception. The question says that it doesn't throw an exception - but InvocationTargetException is an exception that clearly got instantiated. More details on the exception would definitely be useful - see my answer below for a total guess that's probably not well informed enough to actually help. Without more information it's hard to provide concrete suggestions; I have however had experience with an Oracle driver that attempts to connect via native OCI libraries fails to find those libraries installed on the system and throws an InvocationTargetException. This is all from very vague memory so your mileage will almost certainly vary. It's been a while but if memory serves me I had a case where the connection URL was incorrectly configured and OracleDriver (or one of its wrappers) iterated through a set of possible connection methods trying to find one that worked. In the case that the URL was correctly configured it never got to the OCI attempt (the thin connection method attempt came first) but if the connection URL was misconfigured the thin attempt would fail causing the OCI attempt which then also failed because the OCI client was not installed on the host (resulting in an InvocationTargetException.) So some things to check: Is the connection URL valid? If you're using the same connection URL in both places are you sure that both processes are binding to the same NIC? If they are binding to different NICs it might cause connection oddities even on the same host. Is the environment the same in both cases - if the OCI client is getting used in your development environment there are likely several environment variables it depends on. If those environment variables aren't set identically in the environment where the servlet container is running I'd expect different behavior.  2 WARs? I suppose your ojdbc.jar is located inside WEB-INF/lib of the web service's WAR. Maybe your WAR is inside an EAR so you should reference the driver in MANIFEST.MF. More info: http://java.sun.com/j2ee/verified/packaging.html Yea two different EAR's is what I meant. I'm writing the web service as well as the client. I'll have to look into the MANIFEST; I have looked at it but never really knew what it did.
772,A,sql delete lock I execute a query in JDBC  delete * from mytable where ... I got: java.sql.SQLException: The total number of locks exceeds the lock table size I have about 200k records in the table. how to fix this? I just Googled this up. Assuming you're using MySQL increase your innodb_buffer_pool_size if you have a default size set. http://www.mysqlperformanceblog.com/2007/11/03/choosing-innodb_buffer_pool_size/  this can happen when deleting a large # of rows in mysql/innodb the suggested workaround is to increase your innodb_buffer_pool_size until it works. http://bugs.mysql.com/bug.php?id=15667
773,A,How to log all sql going through JBoss datasource with log4j I've looked at log4jdbc (which does not support datasources) p6spy which seems to be what I am looking for but it has not been updated since 2003 which makes me nervous and lists only JBoss 3.x (we use JBoss 5) and JAMon which seems heavyweight for what I am trying to accomplish (a simple log of all SQL statements running through a JBoss application server). I was hoping that JBoss itself would have a switch to log all the sql (as Websphere does) but I cannot find any documentation for it so that functionality might not exist. FYI there's a much better answer if you're using Hibernate... Other persistence providers have similar options as well. Stick in your persistence.xml file: ... It looks like jdbcdslog might do what you're looking for. http://code.google.com/p/jdbcdslog/ On the wiki page for this project there are notes on connecting it to and Oracle DataSource in JBoss.
774,A,"How to set list of parameters on prepared statement? i have a list of names e.g.: List<String> names = ... names.add('charles'); ... and a statement: PreparedStatement stmt = conn.prepareStatement('select * from person where name in ( ? )'); how to do the following: stmt.setParameterList(1names); Is there a workaround? can someone explain why this method is missing? using: java postgresql jdbc3 There's no clean way to do this simply by setting a list on the PreparedStatement that I know of. Write code that constructs the SQL statement (or better replaces a single ? or similar token) with the appropriate number of questions marks (the same number as in your list) and then iterate over your list setting the parameter for each.  this method is missing due to type erasure the parameter type of the List is lost at runtime. Therefore the need to add several methods arires: setIntParameters setLongParameters setObjectParameters etc this is the point the Statement interface is already bloated even without counting list variants if there is a add method for every data type why isn't there a 'addList' method for every datatype too? (e.g. addStringList(...)) Type erasure is not a good reason there could be setArrayParameter(int pos Object[] params)  I was reviewing code this morning and one of my colleagues had a different approach just pass the parameter using setString(""name1''name2''name3""). Note: I skipped the single quote at the beginning and end because these are going to be added by the setString. For constant strings it might be acceptable. For user input it is a nice example of code vulnerable to SQL injection. This absolutely should not work. If it does there's a bug in your JDBC driver. `setString` deals with the apostrophes so that you actually get the `String` that you passed. Had your colleague tested their code?  Other method : public void setValues(PreparedStatement ps) throws SQLException { // first param inside IN clause with myList values ps.setObject(1  myList.toArray() 2003); // 2003=array in java.sql.Types } Please give some explanation to your code  For postgres 9 I have used this approach:  jdbcTemplate.query(getEmployeeReport() new PreparedStatementSetter() { @Override public void setValues(PreparedStatement ps) throws SQLException { ps.setTimestamp(1 new java.sql.Timestamp(from.getTime())); ps.setTimestamp(2 new java.sql.Timestamp(to.getTime())); StringBuilder ids = new StringBuilder(); for (int i = 0; i < branchIds.length; i++) { ids.append(branchIds[i]); if (i < branchIds.length - 1) { ids.append(""""); } } // third param is inside IN clause // Use Types.OTHER avoid type check while executing query ps.setObject(3 ids.toString() **Types.OTHER**); } } new PersonalReportMapper());  This question is very old but nobody has suggested using setArray This answer might help http://stackoverflow.com/a/10240302/573057"
775,A,configure oracle jdbc driver in jboss i'm new to jboss i wish to setup a development server on my local machine to be used with netbeans under windows xp; I need to install the oracle jdbc driver on it. I've searched the web and all the articles i found say to copy the jar in the server default folder. Will it be visible also to all and minimal folder ? there's another way to configure drivers without physically moving the jar to the folder ? thank you in advance No JBOSS has to have the Oracle JDBC driver JAR in the CLASSPATH so it has to be in the server /lib directory. It's visible to the app server and all deployed apps if the JAR is in that location. This is necessary but not sufficient for configuration connection pools. You still have to set them up in JBOSS.
776,A,"Java Spring JdbcTemplate What's the difference between a JdbcTemplate object and a SimpleJdbcTemplate? From the Javadoc SimpleJdbcTemplate is a Java-5-based convenience wrapper for the classic Spring JdbcTemplate taking advantage of varargs and autoboxing and exposing only the most commonly required operations in order to simplify JdbcTemplate usage. In other words SimpleJdbcTemplate just breaks the ""regular"" JdbcTemplate down to the most common/convenient parts — in other words it simplifies it. Thanks Torgamus. I'll use the SimpleJdbcTemplate.  As of Spring 3.1 SimpleJdbcTemplate has been deprecated and most of the features of SimpleJdbcTemplate have been integrated into JdbcTemplate except named parameter which is provided by NamedParameterJdbcTemplate. The bottom line is if you're using SimpleJdbcTemplate is perfectly fine and there is no rush to upgrade but for new developments you should use JdbcTemplate or NamedParameterJdbcTemplate. If anyone's interested I've posted an usage example of JdbcTemplate in my blog (starting form the project set up in the previous post) more interesting examples are in the official Spring documentation."
777,A,"PreparedStatement not returning ordered ResultSet I am having some problems and I'm sure it's something stupid. So I have a query like SELECT name id xyz FROM table ORDER BY ? then later down the road setting the ? doing a ps.setString(1 ""xyz""); I am outputting the query and the value of xyz in the console. When I loop through the ResultSet returned from the PreparedStatement the values are not in the correct order. They are in the returned order as if I had left the ORDER BY clause off. When I copy/paste the query and the value into TOAD it runs and comes back correctly. Any ideas to why the ResultSet is not coming back in the correct order? The database will see the query like this SELECT name id xyz FROM table ORDER BY 'xyz' I think you should add more variable like order_field and order_direction I assume you have a method like below and I give you an example to solve it pulbic List<Object> getAllTableWithOrder(String order_field String order_direction) { String sql = ""select * from table order by ? ?""; //add connection here PreparedStatement ps = (PreparedStatement) conn.prepareStatement(sql); ps.setString(1order_field); ps.setString(2order_direction); logger.info(String.valueOf(ps)); //returns something like: com.mysql.jdbc.JDBC4PreparedStatement@a0ff86: select * from table order by 'id' 'desc' String sqlb = String.valueOf(ps); String sqlc = sqlb.replace(""'""+order_field+""'"" order_field); String sqld = sqlc.replace(""'""+order_direction+""'"" order_direction); String[] normQuery = sqld.split("":""); ResultSet result = conn.createStatement().executeQuery(normQuery[1]); while(result.next()) { //iteration } }  The database will see the query as SELECT name id xyz FROM table ORDER BY 'xyz' That is to say order by a constant expression (the string 'xyz' in this case). Any order will satisfy that. +1 nice Tom. devil's in the details jeebus you think I would have thought of that. But that cleared it up. Thanks! You can only specify constants in prepared statements.  Why not run: ps.setInteger(1 3); Regards. EDIT: AFAIK Oracle 10g supports it.  ? is for parameters you can't use it to insert column names. The generated statements will look something like SELECT name id xyz FROM table ORDER BY 'xyz' so that your entries are sorted by the string 'xyz' not by the content of column xyz. It's so obvious now that I see it but I spent many hours trying to find why my results weren't sorted. This sums it up nicely.  PreparedStatement placeholders are not intend for tablenames nor columnnames. They are only intented for actual column values. You can however use String#format() for this that's also the way I often do. For example: private static final String SQL_SELECT_ORDER = ""SELECT name id xyz FROM table ORDER BY %s""; ... public List<Data> list(boolean ascending) { String order = ascending ? ""ASC"" : ""DESC""; String sql = String.format(SQL_SELECT_ORDER order); ... Another example: private static final String SQL_SELECT_IN = ""SELECT name id xyz FROM table WHERE id IN (%s)""; ... public List<Data> list(Set<Long> ids) { String placeHolders = generatePlaceHolders(ids.size()); // Should return ""???..."" String sql = String.format(SQL_SELECT_IN placeHolders); ... DAOUtil.setValues(preparedStatement ids.toArray()); ... Shouldn't that be `""SELECT name id xyz FROM table ORDER BY %s %s""` and then `String.format(SQL_SELECT_ORDER orderby order);`"
778,A,Retrieve an Image stored as BLOB on a MYSQL DB I'm trying to create a PDF based on the information that resides on a database. Know I need to retrieve a TIFF image that is stored as a BLOB on a mysql database from Java. And I don't know how to do it. The examples I've found shows how to retrieve it and save it as a File (but on disk) and I needed to reside on memory. Table name: IMAGENES_REGISTROS BLOB Field name: IMAGEN Any Ideas? are you using plain JDBC? Yes Bozho plain JDBC with the MySQL lib for java. see my updated answer - turned out there is an alternative way to do it :) On your ResultSet call: Blob imageBlob = resultSet.getBlob(yourBlobColumnIndex); InputStream binaryStream = imageBlob.getBinaryStream(0 imageBlob.length()); Alternatively you can call: byte[] imageBytes = imageBlob.getBytes(1 (int) imageBlob.length()); As BalusC noted in his comment you'd better use: InputStream binaryStream = resultSet.getBinaryStream(yourBlobColumnIndex); And then the code depends on how you are going to read and embed the image. Don't use `ResultSet#getBlob()` or `ResultSet#getBytes()`. Just use `ResultSet#getBinaryStream()`. is it just a convenient method or there is something more to it? Thanks just a comment. imageBlob returns a Long. And getBytes expect an Integer. I parse (Integer.ParseInt..) the Long and it works. I don't know if eventually that'll gonna bring problems. Is there any other way? thanks I guess because it is expected that the data is huge and you'll get an OutOfMemory exception why getBlob() and getBytes() method are not good ?
779,A,"SQL Server JDBC Exception When using ANT to build my Java application I keep getting this error. I have tried multiple times to use SQLJDBC.JAR and SQLJDBC4.JAR but continually receive this error message. I am completely stumpped why this error is received even after upgrading to sqljdbc4.jar.  [javadoc] java.lang.UnsupportedOperationException: Java Runtime Environment (JRE) version 1.6 is not supported by this driver. Use the sqljdbc4.jar class library which provides support for JDBC 4.0. Refer to this link: http://msdn.microsoft.com/en-us/library/ms378526.aspx ""sqljdbc4.jar class library requires a Java Runtime Environment (JRE) of version 6.0 or later."" So if you aren't using a JDK 1.6 or later when compiling you will get an error when using sqljdbc4.jar. If you are using JDK 1.5 or earlier then you need to be using the sqljdbc.jar which you can get from here. Also one tip with ANT is that you can use ""ant -verbose"" to help determine which libaries it's finding on the classpath to make sure it's using the sqljdbc JAR you expect. Also make sure to confirm which version of the JDK you are compiling with. You can set the JAVA_HOME environment variable to point to a different JDK to compile with. thanks..It directed me to solve this issue!!"
780,A,"How can I bind a DataSource to an InitialContext for JUnit testing? I'm trying to run JUnit tests on database ""worker"" classes that do a jndi lookup on an InitialContext to get a DataSource. The worker classes are usually running on a Glassfish v3 App Server which has the appropriate jdbc resources defined. The code runs just fine when deployed on the App Server but doesn't run from the JUnit testing environment because obviously it can't find the jndi resources. So I tried to setup an InitialContext in the test class that binds a datasource to the appropriate context but it doesn't work. Here is the code I have in the test @BeforeClass public static void setUpClass() throws Exception { try { // Create initial context System.setProperty(Context.INITIAL_CONTEXT_FACTORY ""org.apache.naming.java.javaURLContextFactory""); System.setProperty(Context.URL_PKG_PREFIXES ""org.apache.naming""); InitialContext ic = new InitialContext(); ic.createSubcontext(""java:""); ic.createSubcontext(""java:/comp""); ic.createSubcontext(""java:/comp/env""); ic.createSubcontext(""java:/comp/env/jdbc""); // Construct DataSource SQLServerConnectionPoolDataSource testDS = new SQLServerConnectionPoolDataSource(); testDS.setServerName(""sqlserveraddress""); testDS.setPortNumber(1433); testDS.setDatabaseName(""dbname""); testDS.setUser(""username""); testDS.setPassword(""password""); ic.bind(""java:/comp/env/jdbc/TestDS"" testDS); DataWorker dw = DataWorker.getInstance(); } catch (NamingException ex) { Logger.getLogger(TitleTest.class.getName()).log(Level.SEVERE null ex); } } Then the DataWorker class has a method with the following code more or less InitialContext ic = null; DataSource ds = null; Connection c = null; PreparedStatement ps = null; ResultSet rs = null; String sql = ""SELECT column FROM table""; try{ ic = new InitialContext(); ds = (DataSource) ic.lookup(""jdbc/TestDS""); c = ds.getConnection(); ps = c.prepareStatement(sql); // Setup the Prepared Statement rs = ps.executeQuery(); if(rs.next){ //Process Results } }catch(NamingException e){ throw new RuntimeException(e); }finally{ //Close the ResultSet PreparedStatement Connection InitialContext } If I change the ic.createSubContext(""java:/comp/env/jdbc""); ic.bind(""java:/comp/env/jdbc/TestDS""testDS); lines to ic.createSubContext(""jdbc""); ic.bind(""jdbc/TestDS""testDS); The worker class is able to find the DataSource but fails giving an error saying that ""username failed to login to the server"". If I pass the DataSource that I create in the JUnit method directly into the worker it can connect and run queries. So I would like to know how to bind a DataSource that can be looked up by the worker class without being in the Web Container. This might be a bit late. The link here is exactly what you need http://blogs.oracle.com/randystuph/entry/injecting_jndi_datasources_for_junit Whilst this may theoretically answer the question [it would be preferable](http://meta.stackexchange.com/q/8259) to include the essential parts of the answer here and provide the link for reference. This gives `java.lang.ClassNotFoundException: org.apache.naming.java.javaURLContextFactory` Better late than never... this is exactly what I needed as well!  When I last tried something like this a few years ago I finally gave up and refactored: at that point you could NOT create a DataSource outside of a container. Maybe you can now maybe someone's mocked something up. Still that smells... You shouldn't have ANY ""business logic"" code directly dependent on DataSources or JNDI lookups or such. That's all plumbing to be wired together outside your code. How flexible is your design? If your code under test is directly dependent on a DataSource (or even obtains its own Connection) refactor it. Injecting a Connection will let you can test all you like with plain old JDBC even using an in-memory implementation and save you from having to prop up a lot of unnecessary (for the test anyway) infrastructure to do it."
781,A,"Problems with Date preparedStatement JDBC and PostgreSQL I Have to get a movie from a PostgreSQL database that matches a given title and release date. title is a character(75) and releaseDate is a date. I Have this code: String query = ""SELECT * FROM \""Movie\"" WHERE title = ? AND \""releaseDate\"" = ?)""; Connection conn = connectionManager.getConnection(); PreparedStatement stmt = conn.prepareStatement(query); java.sql.Date date = new java.sql.Date(releaseDate.getTime()); stmt.setString(1 title); stmt.setDate(2 date); ResultSet result = stmt.executeQuery(); but it's not working because the releaseDate is not matching when it should. The query SELECT * FROM ""Movie"" WHERE title = A_MOVIE AND ""releaseDate"" = A_DATE works perfectly on a command shell using psql If `releaseDate` is a `java.sql.Date` why copy it to `date` before calling `setDate()`? is not java.sql.Date is java.util.Date What's the exact SQL column type of `releaseDate`? Is it really `date`? There is also `timestamp`. Which PostgreSQL DB version and JDBC driver version are you using? The problem was in the database because of time format was changed from dd/MM/YYYY to MM/dd/YYYY. Thanks Aha! http://www.postgresql.org/docs/current/static/datatype-datetime.html#DATATYPE-DATETIME-INPUT"
782,A,"Error getting JDBC Connection: Could not enlist in transaction on entering meta-aware object I am having a problem getting a JDBC connection in an EJB SessionBean. The error is: org.jboss.util.NestedSQLException: Could not enlist in transaction on entering meta-aware object!; - nested throwable: (javax.transaction.SystemException: java.lang.Throwable: Unabled to enlist resource see the previous warnings. I thought this happens because I already have an open connection from a different datasource so I configured an XA datasource to avoid transaction problems but it doesn't work at all so I don't know if I am doing something wrong in my code. Here it is:  try { Properties p = new Properties(); p.put(Context.INITIAL_CONTEXT_FACTORY""org.jnp.interfaces.NamingContextFactory""); p.put(Context.PROVIDER_URL""jnp://localhost:11099""); p.put(""java.naming.factory.url.pkgs"" ""org.jboss.naming""); InitialContext ic = new InitialContext(p); DataSource dataSource = (DataSource)ic.lookup(""java:/jdbc/etlreportservices""); return dataSource.getConnection(); } catch(Exception e) { e.printStackTrace(); } The exception is thrown while calling dataSource.getConnection(). Is your EJB anotated with any transaction Anotation? The transaction is container-managed Thanks tomás you gave me an idea i changed my transaction manager to be bean-managed and it works perfectly I have noticed this in cases where the tx times out. FWIW.  I changed my transaction manager to be bean-managed and it works perfectly.  Using JBoss 6.0.0 the error message is slightly different: Caused by: org.jboss.resource.JBossResourceException: Could not enlist in transaction on entering meta-aware object! As for the reason: A quote from here Within the same process two calls were being made to different non-XA data sources. This is not supported by default on JBoss. The same site shows a solution which was not applicable for JBoss 6.0.0. The general solution is to change all data sources involved in the same transaction into XA data sources. Then it works both with bean managed and container managed transactions. For example this solution is proposed in a CodeRanch and in a JBoss forum as well."
783,A,"How to stub/mock JDBC ResultSet to work both with Java 5 and 6? I'm testing some of my classes working with JDBC statements etc and now I got problem with JDBC ResultSet interface: The software should run both with Java 5 and Java 6 and hence the tests should also be run with both versions. Unfortunately Java 6 has introduced a bunch of new methods (which is still not a big deal) that return a bunch of new classes/interfaces which makes the things more difficult. (see Frank Carver’s Punch Barrel - Java 6 breaks JDBC for example) Before finding out these version differences I considered between stubbing and mocking and ended up with stubbing because the ResultSet has internal state (current row handled) that is more natural to me to work with stubs as : public class StubResultSet implements ResultSet { private Object[][] data; private int currentRow = -1; private boolean closed = false; public StubResultSet(Object[][] data) { this.data = data; } public Object getObject(int columnIndex) throws SQLException { checkClosed(); return data[currentRow][columnIndex]; } public String getString(int columnIndex) throws SQLException { checkClosed(); return (String) getObject(columnIndex); } // ... } But if I don't introduce the new methods as public NClob getNClob(int columnIndex) the class is broken under Java 6 - if I introduce them the class in broken under Java 5. I can work with mockito (for example) callbacks to have the state being reflected with the return values but does somebody have some other - maybe more nice - idea? I had the same problem and solved it using a Proxy implementation. It seems like it's working pretty good. public class TestResultSet implements InvocationHandler { public static ResultSet createProxy(HashMap<Object Object>[] rows) { return (ResultSet) Proxy.newProxyInstance(ResultSet.class.getClassLoader() new Class[] { ResultSet.class } new TestResultSet(rows)); } public Object invoke(Object proxy Method method Object[] args) throws Throwable { // Find the equivalent method in the proxy class. Method m = TestResultSet.class.getMethod(method.getName() method.getParameterTypes()); if(m == null) { throw new SQLException(""Unsupported method "" + method.getName()); } return m.invoke(this args); } // Method implementations follow here (only one supplied as an example) public boolean isFirst() throws SQLException { return index ==0; } }  Well after some thinking I ended up having the stub class as there and mocking it with Mockito as: public static ResultSet initMock(Object[][] data) throws SQLException { final StubResultSetContents contents = new StubResultSetContents(data); ResultSet rs = mock(ResultSet.class RETURNS_SMART_NULLS); when(rs.getObject(anyInt())).thenAnswer(new Answer<Object>() { public Object answer(InvocationOnMock invocation) throws Throwable { return contents.getObject(getIntArgument(invocation)); } }); // a bunch of similar when(...).thenAnswer(...) constructs... } (stub class in StubResultSetContents). If somebody has some other ideas feel free to answer =)"
784,A,JDBC & Deadlock avoidance question (Basic) I'm using JDBC (through Spring's JDBCTemplate) to access a small number of tables in a database. Although I haven't had anything happen yet I'm concerned about the possibility of deadlock. I was under the impression there was a way to specify a lock order for queries that access multiple tables for deadlock avoidance but I don't know if this is the type of thing that gets set up at the DB level when creating my tables or if I have to do something explicitly with my JDBC queries. i.e. is there a global setting or something for specifying lock order or if it has to be done on each query/update. Thanks. This is to be managed at transaction level. You usually only risk a deadlock when there's means of a chicken-egg issue. I.e. there are two simultaneous row-locking transactions with each multiple queries whose results depends on the other transaction. If the other transaction isn't finished while the query is been executed then the other transaction won't be able to finish its own query. I am not sure how JDBCTemplate manages the transactions but a JDBC connection is by default not transactional. Once you set the Connection#setAutoCommit() to false (or configure it to be by default) then the transaction will start and it will finish when you call Connection#commit(). To avoid deadlocks rule #1 is avoiding mixing SELECT with INSERT/UPDATE/DELETE statements in a single transaction. When mixing is -at first sight- mandatory then you should at least try to rewrite it into a single/nested statement. This is often just possible. This way you don't need to execute those queries in a transaction. Further some databases like PostgreSQL and Oracle can autodetect deadlocks and will automatically rollback one of the transactions usually the one which was initiated later. In the JDBC end you will receive a specific SQLException for that. So should I not be doing things like testing for existence then inserting or is it only dangerous if I'm doing a select that will look at multiple rows and then insert if the result isn't found? Very true :) Rather catch the unique constraint. Also see [this answer](http://stackoverflow.com/questions/3101820/how-to-check-for-duplicate-entries-in-database/3101957#3101957).
785,A,"Can PostgreSQL be used with an on-disk database? Currently I have an application that uses Firebird in embedded mode to connect to a relatively simple database stored as a file on my hard drive. I want to switch to using PostgreSQL to do the same thing (Yes I know it's overkill). I know that PostgreSQL cannot operate in embedded mode and that is fine - I can leave the server process running and that's OK with me. I'm trying to figure out a connection string that will achieve this but have been unsuccessful. I've tried variations on the following: jdbc:postgresql:C:\myDB.fdb jdbc:postgresql://C:\myDB.fdb jdbc:postgresql://localhost:[port]/C:\myDB.fdb but nothing seems to work. PostgreSQL's directions don't include an example for this case. Is this even possible? I was afraid of this. We were switching because of security concerns raised by end-users but we will have to find another option. @Chris : I think that no database is really secure when you can access the database file(s). So embedded mode is not secure. Postgres won't be able to store a database in one file. Depending on your operating system you can have a disk image inside of a single file. What is the issue with continuing to use Firebird or another embedded database? I like Postgres too - but if it doesn't fit your requirements... Postgres databases are not a single file. There will be one file for each table and each index in the data directory inside a directory for the database. All files will be named with the object ID (OID) of db / table / index. The JDBC urls point to the database name not any specific file: jdbc:postgresql:foodb (localhost is implied) If by ""disk that behaves like memory"" you mean that the db only exists for the lifetime of your program there's no reason why you can't create a db at program start and drop it at program exit. Note that this is just DDL to create the DB not creating the data dir via the init-db program. You could connect to the default 'postgres' db create your db then connect to it. I'd like to mark Steve K's answer as the solution but since it was a comment this is the next best thing.  Firebird 2.1 onwards supports global temporary tables which only exist for the duration of the database connection. Syntax goes something like CREATE GLOBAL TEMPORARY TABLE ... ON COMMIT PRESERVE ROWS  You can trick it. If you are running PostGRESQL on a UNIXlike system then you should be able to create a RAMDISK and use that for the database storage. Here's a pretty good step by step guide for RAMdisks on Linux. In general though I would suggest using SQLITE for an SQL db in RAM type of application. Thanks for the comment. However it would seem that a RAM disk is memory that behaves like a disk whereas I would need a disk that behaves like memory. The main behavioral difference between a disk and memory is that memory is very fast and every location is accessed equally fast. The only way to get a disk that behaves like memory is to use memory. In other words an SSD disk or flash memory. PostgreSQL can store its database on either of those two as well."
786,A,"EJB 3 with JDBC Is it possible to use EJB 3 with JDBC. I read somewhere that it's allowed. However I hear that EJB 3 implementation uses JTA by default. What does that mean for JDBC? Is it only for the transaction support? That means JTA is used for transaction when using JDBC code? Meaning that even local transactions are implemented as global transactions? Does it mean it's not a good idea to use JDBC with EJB 3? Many people point me to JPA but it's an ORM. I want to use SQL. any suggestions? Why do you want to use EJB3? Have you compared that to what you get from Spring Framework? Which version of J2EE will you be working on? Java EE5 implementation that comes with Websphere 7. Spring DAO - Simple JDBC templates seems to be good. In fact we are only working with one data source its all local transactions. The person who gave this architecture thinks Spring has zero value proposition outside of J2EE and non-Application servers like Tomcat. 1º That means JTA is used for transaction when using JDBC code ? And Meaning that even local transactions are implemented as global transactions ? The EJB container CAN MAKE USE of resource manager local transactions AS AN OPTIMIZATION TECHNIQUE for enterprise beans for which distributed transactions ARE NOT NEEDED. It is a good idea do the following when using a declarative or programmatic transaction demarcation: declare resources using the Resource annotation in the enterprise bean class or using the resource-ref element in the enterprise bean’s deployment descriptor Something like (setter method or member field) // mappedName points to a global mapping name @Resource(mappedName=""java:/DefaultDS"") private javax.sql.DataSource ds; And inside a business logic method If you are using a declarative transaction Connection conn = ds.getConnection(); If you are using a programmatic transaction Declare a setter or member field UserTransaction @Resource private UserTransaction ut; And ut.beginTransaction(); Connection conn = ds.getConnection(); ut.commit(); Take care of the following If you are using a Stateful session bean do the following in the PrePassivate callback method Close all JDBC connections in the PrePassivate method and assign the instance’s fields storing the connections to null regards good answer thank you. When you say ""The EJB container CAN MAKE USE of resource manager local transactions AS AN OPTIMIZATION TECHNIQUE for enterprise beans for which distributed transactions ARE NOT NEEDED"" does that mean this is done automatically by the EJB 3 container? Is that a JEE standard requirement or a feature offered by some vendors? If it's a feature then is it configurable or usually done this way by default? @Shaw Hi Although IS NOT a requirement JEE specification ALLOWS it when distributed transaction are not needed. Check your JEE implementation whether it makes use of resource manager local transaction when distributed transaction are are not needed. And Does that mean this is done automatically by the EJB 3 container ? EJB container can do it AUTOMATICALLY but again it is a good idea check out its documentation.  If you are using JPA2 you can use entityManager.unwrap(Connection.class) to get actual connection and use with your JDBC code. For example: Connection connection = entityManager.unwrap( Connection.class ); try (Statement stmt = connection.createStatement()) { stmt.executeUpdate( ""INSERT INTO MyTable( name ) VALUES ( 'my name' ) "" ); } Does it mean it's not a good idea to use JDBC with EJB 3? Many people point me to JPA but it's an ORM. I want to use SQL. Sometime it's necessary for performance or compatibility issues. I usually use this technique to execute PL/PSQL with array parameters complex Posgis SQL etc.  You can look at this page it does appear that you can combine EJB3 with JDBC. http://www.java2s.com/Tutorial/Java/0415__EJB3/UseJDBCInEJB.htm"
787,A,"WebSphere to Oracle - doesn't accept correct password In WebSphere 6.1 I have created a datasource to an Oracle 11g instance using the thin JDBC client. In Oracle I have two users one existing and another newly created. My websphere datasource is OK if I use the component-managed authentication alias of the existing user but fails with ""invalid user/password"" message if I use the alias of the new user. The error message is: The test connection operation failed for data source MyDB (Non-XA) on server nodeagent at node MY_node with the following exception: java.sql.SQLException: ORA-01017: invalid username/password; logon denied DSRA0010E: SQL State = 72000 Error Code = 1017. View JVM logs for further details. There is nothing in the JVM logs. I have grepped all websphere logs and they do not mention my connection at all. I can confirm that the username and password are correct by logging in via SQLPlus or (to prove the JDBC connection is OK) via SQuirreL. I have checked in Oracle that the new user has all the system privs that the existing user has. Any thoughts on what is going on or how I can debug this further? Oftentimes when people tell me they can't log into Oracle 11g with the correct password I know they've been caught out by passwords becoming case-sensitive between 10g and 11g. They weren't case sensitive before? **wow!** Nope! Remember that Oracle goes way back in the day when you couldn't even assume that your client would be capable of mixed case. Even in 11g it's optional.  If this happens to anyone else I restarted WebSphere and all my problems went away. It's a true hallmark of quality software. If you change the configuration in WAS (you are doing that as you are changing the credentials of a JAAS alias) you are likely to have a restart of the server for it to take effect.  I have point my data source to componenet-manage authentication as well as container-managed authentication.Its working fine now........  Try this : data source definition security use the j2c alias both autentication managed by component and autentication managed by container  Just FYI. I am guessing you are running WebSphere in ""Network Deployment"" mode. This behavior you're experiencing is actually by design. The reason for it is that the ""Test Connection"" button you see on the admin console invokes the JDBC connection test from within the address-space of the Node Agent. There is no way for the J2C Alias information to propagate to the Node Agent without restarting it; some configuration objects take effect in WebSphere as soon as you save the configuration to the master repository and some only take effect on a restart. J2C aliases take effect on restarts. In a Network Deployment topology you may have 10 server instances all controlled by the same Node Agent. You may restart your server instances many times but unless you restart the Node Agent itself the ""test connection"" button will never work. It's a known WebSphere limitation... Which also exists on version 7.0 so don't be surprised when you test it during your next migration. :-)"
788,A,which database to use in Scala (and examples needed) I am new to Scala. Which database connectivity is best supported in Scala? I am also looking for complete examples to access a database (authenticate connect query extract result) I have a table MyTable with two columns (Value1 Value2) in a database MyDB which I need to access. I have been thinking of postgresql so some examples using this would be nice. Thanks in advance. Click here and you will get all answers of your questions.
789,A,Can I ignore or suppress warnings in JDBC for MySQL? I have an INSERT INTO ... ON DUPLICATE KEY UPDATE ... statement that executes fine (but with warnings) in the mysql> prompt: mysql> INSERT INTO ... ON DUPLICATE KEY UPDATE ... ; Query OK 2 rows affected 2 warnings (0.00 sec) Warning (Code 1364): Field 'x' doesn't have a default value However when I try to execute the same statement via JDBC the warning shows up as an SQLException and no rows are updated: java.sql.SQLException: Field 'x' doesn't have a default value at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1055) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3536) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3468) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1957) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2107) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2648) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2086) at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1365) Is there a JDBC or mysql connector setting or command to ignore or suppress these warnings? I'm using MySQL Community Server 5.1.31 with MySQL connector 5.1.8 and Java 1.5.0_24. You can use INSERT IGNORE to suppress these completely. (: That works. Interesting I thought I had tried that.. Thanks!
790,A,"Cannot use a Like query in a JDBC prepared statement? OK first the query code and query: ps = conn.prepareStatement(""select instance_id ? from eam_measurement where resource_id in (select RESOURCE_ID from eam_res_grp_res_map where resource_group_id = ?) and DSN like '?' order by 2""); ps.setString(1""SUBSTR(DSN2716)""); ps.setInt(2defaultWasGroup); ps.setString(3""%Module=jvmRuntimeModule:freeMemory%""); rs = ps.executeQuery(); while (rs.next()) { bla blah blah blah ... Returns an empty resultSet. Through basic debugging I have found its the 3rd bind that is the problem i.e. DSN like '?' I have tried all kinds of variations the most sensible of which seemed to be using: DSN like concat('%'?'%') bit that doesn' work as I am missing the ' ' either side of the concatenated string so I try DSN like ' concat('%'Module=P_STAG_JDBC01:poolSize'%') ' order by 2 but I just can't seem to find a way to get them in that works. What am I missing? Writing Java code in a JSP file instead of in a real Java class (where you **should** have done it) and having problems with the particular Java code doesn't make it a JSP problem. You would face exactly the same problem when doing so in a real Java class. So I removed the `[jsp]` tag since that's irrelevant. True it is not JSP specific but then there is nothing *wrong* with using such code in a servlet according to most books I have read especially when it is a super simple report page of less than 40 lines of code where application architecture is a little bit overkill :) But I appreciate your point! You can try: String beforeAndAfter = ""%"" + yourVariable + ""%"";  There are two problems with your statement. You have to understand how bind variables work. The query is not processed by substituing the characters ? with your parameters. Instead the statement is compiled with placeholders and then during execution the actual values of the parameters are given to the DB. In other words you parse the following query: SELECT instance_id :p1 FROM eam_measurement WHERE resource_id IN (SELECT RESOURCE_ID FROM eam_res_grp_res_map WHERE resource_group_id = :p2) AND DSN LIKE '?' ORDER BY 2 I'm pretty sure the last parameter will be ignored because it is in a delimited character string. Even if it is not ignored it does not make sense to have ' characters around because Oracle won't bind a parameter in a string (I'm surprised it hasn't raised any error do you catch exceptions ?). Now if you replace your DNS LIKE '?' with DSN LIKE ? and bind ""%Module=jvmRuntimeModule:freeMemory%"" this will make sense and should return the correct rows. You still have the problem with your first parameter it won't do what you expect i-e the query that will be executed will be equivalent to the following query: SELECT instance_id 'SUBSTR(DSN2716)' FROM ... which is not at all the same as SELECT instance_id SUBSTR(DSN2716) FROM ... I would suggest parsing (=prepareStatement) the following query if you expect the SUBSTR to be dynamic: SELECT instance_id SUBSTR(DSN??) FROM eam_measurement WHERE resource_id IN (SELECT RESOURCE_ID FROM eam_res_grp_res_map WHERE resource_group_id = ?) AND DSN LIKE ? ORDER BY 2 Wonderful answer Vincent! I really did not appreciate the finer points in how it worked which you so eloquently described. I took on board what you say and it's working beautifully. Still learning every day thanks to guys like you :) @SeerUK: glad to help =)  Omit the ' around the ?. Without the ' ? is a placeholder for a parameter. With it it's an SQL string (i.e. the same as ""?"" in Java). Then you must concatenate the string on the Java side; you can't pass SQL functions as parameters to queries; only basic values (like string integer etc) because the JDBC driver will convert the parameter to the SQL type the database expects and it cannot execute SQL functions in this step. Without the '' around the ? I get an empty resultSet too. Not surprisingly I guess as then the sql would read: and DSN like %Module=P_STAG_JDBC01:poolSize% which oracle does not like and replies with: Missing IN or OUT parameter at index:: 1 (error code=17041) Thus I need to add the ''s to the bind when I set it via ps.setString? e.g. ps.setString(3""'Module=jvmRuntimeModule:freeMemory'""); But also gives an empty result set as does ps.setString(3""\'Module=jvmRuntimeModule:freeMemory\'""); Though java docs says it should not be necessary to escape an ' inside """"s @SeerUK: The error message comes from parameter 1 not from parameter 3!  First the PreparedStatement placeholders (those ? things) are for column values only not for table names column names SQL functions/clauses etcetera. Better use String#format() instead. Second you should not quote the placeholders like '?' it would only malform the final query. The PreparedStatement setters already do the quoting (and escaping) job for you. Here's the fixed SQL: private static final String SQL = ""select instance_id %s from eam_measurement"" + "" where resource_id in (select RESOURCE_ID from eam_res_grp_res_map where"" + "" resource_group_id = ?) and DSN like ? order by 2""); Here is how to use it: String sql = String.format(SQL ""SUBSTR(DSN2716)""); // This replaces the %s. preparedStatement = connection.prepareStatement(sql); preparedStatement.setInt(1 defaultWasGroup); preparedStatement.setString(2 ""%Module=jvmRuntimeModule:freeMemory%""); See also: Sun JDBC tutorial: Using Prepared Statements Format string syntax Again great answer and nice references! Thanks BalusC  If you want to use LIKE in prepared statement and also want to use % characters in LIKE; write prepared statement as normally "" .... LIKE ? ...."" and while assigning parameter value to question mark use ps.setString(1 ""%"" + ""your string value"" + ""%""); This will work :)"
791,A,"JDBC connection pooling issue I have I might say a quite a big issue. I'm working on Java web application which use springs BasicDataSource to setup DB connection. I was testing the application locally and it works just fine... but when application is online connection to DB in some point just stuck. I was than investigating regarding connection pooling and I figure it out that on each new HTTP request where I have some of the queries executed new pool is created. As I know pooling is introduced to be reusable and not created the each time when new DB access is involved. Or I'm wrong? Here is my spring datasource config: <bean id=""dataSource"" destroy-method=""close"" class=""org.apache.commons.dbcp.BasicDataSource""> <property name=""driverClassName"" value=""${jdbc.driverClassName}""/> <property name=""url"" value=""url""/> <property name=""username"" value=""username""/> <property name=""password"" value=""password""/> <property name=""defaultAutoCommit"" value=""true""/> <property name=""defaultTransactionIsolation"" value=""1""/> <property name=""initialSize"" value=""0""/> <property name=""maxActive"" value=""20""/> <property name=""minIdle"" value=""0""/> </bean> Than I have configured: <bean id=""EventDao"" class=""my.managament.database.class""> <property name=""dataSource"" ref=""dataSource""/> </bean> And mainPageController which handles all HTTP requests sent to application <bean id=""mainController"" class=""my.management.main.controller.class""> In the rest of application I use gedDatabase() to acquire DB connection and do select through JDBCTemplate. Where am I getting wrong? Thanks I'm not sure if you meant to state that a new connection is getting created instead of stating that a new connection pool is getting created on every request. If not this is indeed a big problem. May I suggest that you edit the question to include why you believe that the pool is getting recreated every request. Sorry I thought that I was clear... What I tried to do is to create only one connection with consideration that new pools are going to be created but also reused... not on each single request to create new one... in 1000 requests I have dozen thousands of pools invoked. If it is of any help I've implemented this much like described in tutorial here: http://www.vogella.de/articles/SpringJDBC/article.html I hope someone had the same problem and managed to fix it... or if someone have tutorials which show the right way to implement this. What is the life time of your EventDao ? You are injecting your DataSource into the dataSource property. I suspect that you are creating multiple EventDao beans and each time you create one you have a new DataSource. I think we would need to have further understanding of the code to be able to answer your question properly. My two cents: As far as I am concerned having code and wiring things through XML is a terrible anti-pattern.  You want to use dao and jdbcTemplate and dataSource through a connection pool. My guess the closest correct approach to your setup is having a dao which has JdbcTemplate field and a JdbcTemplate bean created with your dataSource bean. It would look like: public class MyDAO { private JdbcTemplate jdbcTemplate; // your dao methods using jdbcTemplate here } where jdbcTemplate comes from a bean like: <bean id=""jdbcTemplate"" class=""org.springframework.jdbc.core.JdbcTemplate""> <constructor-arg ref=""dataSource""> </bean> You should never need to obtain a connection from dataSource (which is apache dbcp based connection pool in your case) directly. JdbcTemplate will get a connection itself when needed. I'm not sure what ""gedDatabase"" is but it sounds like you tried to get connection yourself and possibly forgot to close it. This would result in pool quickly running out of connections. After handling 20 requests the subsequent requests would be stuck on attempt to get connection from the pool. Also I don't understand why and how you see multiple pools. You have a single connection pool which can hold up to 20 connections. All your beans are created as singletons which is the default spring scope. My main concern was what is getDatabase doing and how often do you call it. I just noticed that I haven't copied all the necessary config. and it is not gedDatabase it's getDatabase() :)... mainController uses setter dependency injection and sets dataSource previously initialized by EventDao. EventDao is instanced only once!"
792,A,"Connection reset SQLException with jetty I've switched my webserver from tomcat to jetty and encounter a ""java.sql.SQLException: Io exception: Connection reset"" when back from idle time (eg. i go out for a while) :( This issue doesn't appear when i use tomcat. Does it come from jetty or i've done something wrong ? Here is my datasource config <bean id=""dataSourceOracle"" class=""com.mchange.v2.c3p0.ComboPooledDataSource""> <property name=""driverClass"" value=""oracle.jdbc.driver.OracleDriver""></property> <property name=""jdbcUrl"" value=""jdbc:oracle:thin:@127.0.0.1:1521:ORCL""/> <property name=""user"" value=""admin""/> <property name=""password"" value=""123""/> <property name=""initialPoolSize"" value=""0""></property> <property name=""minPoolSize"" value=""0""></property> <property name=""maxPoolSize"" value=""100""/> </bean> <bean id=""hibernateSessionFactory2"" class=""org.springframework.orm.hibernate3.LocalSessionFactoryBean""> <property name=""dataSource"" ref=""dataSourceOracle""/> <property name=""mappingLocations""> <list> <value>classpath:hibernate/mapping/User.hbm.xml</value> <value>classpath:hibernate/mapping/Address.hbm.xml</value> <value>classpath:hibernate/mapping/Province.hbm.xml</value> <value>classpath:hibernate/mapping/Service.hbm.xml</value> <value>classpath:hibernate/mapping/AccessLog.hbm.xml</value> </list> </property> <property name=""hibernateProperties""> <value> hibernate.connection.shutdown=false hibernate.show_sql=true hibernate.dialect=org.hibernate.dialect.Oracle10gDialect </value> </property> </bean> Thank you! I've switch to bonecp and it's solved with the default bonecp config :)  Does it use different connection settings / pooling in datasource definition ? no i use the same datasource."
793,A,"Why am I getting a Null Pointer Exception from this Java code? I have a method ... where I can't find the error:  public String getUsernameforID(int id) { String statment = ""SELECT USERNAME FROM `BENUTZER` WHERE `ID` = ? ;""; String username = null; try { PreparedStatement ps = dbCommunicator.getStatment(statment); // HERE : NULL POINTER EXECTION ps.setInt(1 id); ResultSet rs = dbCommunicator.readFromDB(ps); if (rs.first()) { username = rs.getString(""USERNAME""); } } catch (SQLException ex) { Logger.getLogger(DBManager.class.getName()).log(Level.SEVERE null ex); } return username; I think it's the statement ... but how can I find this out? I get a Null Pointer Exeption. Edit : my getStatment-method:  public PreparedStatement getStatment(String st) { connect(); PreparedStatement ps = null; try { ps = (PreparedStatement) connection.prepareStatement(st); } catch (SQLException ex) { Logger.getLogger(DBCommunicator.class.getName()).log(Level.SEVERE null ex); } return ps; } The Exception: Exception in thread ""main"" java.lang.NullPointerException at test.DBCommunicator.getStatment(DBCommunicator.java:107) at test.database.DBManager.getUsernameforID(DBManager.java:359) at dbtestdrive.Main.main(Main.java:25) which db are you using? i am using mySQL NullPointerException.. where? also attach the original exception Voting to close as 'no longer relevant'. The NPE originates from the getStatement() possibly the connection is null. Something fails silently in conenct() perhaps? Although this question may have been solved here's a little bit on how to go about debugging given an stack trace. In this case the stack trace is the following: Exception in thread ""main"" java.lang.NullPointerException at test.DBCommunicator.getStatment(DBCommunicator.java:107) at test.database.DBManager.getUsernameforID(DBManager.java:359) at dbtestdrive.Main.main(Main.java:25) What this shows is that in the test.DBCommunicator.getStatment method a NullPointerException was thrown at the location of line 107 of DBCommunicator.java. Furthermore the getStatment method was called from line 358 of DBManager.java which is in the DBManager.getUsernameforID method. Therefore the first place that should be checked is what is going on at line 107 of DBCommunicator.java. Although there are no line numbers in the code snippet given one can presume that a NullPointerException occurred in the following line: ps = (PreparedStatement) connection.prepareStatement(st); There's one thing that is fairly common about NullPointerExceptions -- they generally arise when method calls are performed on an null reference. Invoking a method on an object that doesn't exist will throw a NullPointerException. In the above code one can expect that the connection variable is actually null rather than having a Connection. This should lead to trying to track down why the connection variable is null rather than having a valid connection to the database that is initialized.  //Ending "";"" inside the string is not neccessary. String statment = ""SELECT USERNAME FROM `BENUTZER` WHERE `ID` = ? ;""; Instead of: PreparedStatement ps = dbCommunicator.getStatment(statment); PreparedStatement ps = dbCommunicator.prepareStatement(statment); That's what I have using oracle.  It is probably because your query is failing try changing it to: String statment = ""SELECT USERNAME FROM `BENUTZER` WHERE `ID` = ?""; Your original query had a trailing semi-colon which is illegal. This could have caused a nullpointerexception to be thrown up at a later stage I would advise you to post the contents of your exception. EDIT: dbCommunicator.getStatment(statment); Should be: dbCommunicator.getStatement(statment); You're misspelling 'statement' as 'statment' which is fine for a variable name but not when referring to a method :) no .. that was not the problem :( So paste your exception or at least the line number that's throwing it See my edit please unfortunately its not the error :S"
794,A,"JRruby Sybase JDBC and DBI - fetching column name with the AS clause issue I have a ruby script which I run using the JRuby Interpreter. The script connects to a Sybase database using DBI and Sybase JDBC (jTDS3.jar and jconn3.jar) My problem is that I have a select query that alters the column names of table. For example: SELECT t.TRANSACTION as 'business_transaction' t.TRADE_CURRENCY as 'currency' t.CURRENCY as 'settlement_currency' ...etc... FROM TRADE t ...etc... My problem is when using the examples directly from the documentation sth = dbh.execute(stmt) printf ""Number of rows: %d\n"" rows.size printf ""Number of columns: %d\n"" sth.column_names.size sth.column_info.each_with_index do |info i| printf ""--- Column %d (%s) ---\n"" i info[""name""] end or simply sth = dbh.execute(stmt) rows = sth.fetch_all col_names = sth.column_names sth.finish DBI::Utils::TableFormatter.ascii(col_names rows) Not ALL the names come out as I set them using the 'as' clause in the query. Some are the original field names and some are the names I have specified. For example they will list like: --- Column 0 (TRANSACTION) --- --- Column 1 (TRADE_CURRENCY) --- --- Column 2 (settlement_currency) --- or TRANSACTION TRADE_CURRENCY settlement_currency When testing this in Squirrel SQL Client the columns are correctly named so is this a bug in DBI or the Sybase JDBC drivers? or am I doing something wrong? Any help would be greatly appreciated I would guess that it's a bug in DBI since the JDBC drivers have presumably been put through the mill for years. You may want to contact DBI folks to see if they have a suggestion. I would not bet on it :-) Glad to hear you found a fix. As long as it wasn't in JRuby I'm happy too :)  Sybase 6.0 JDBC drivers has some ""interesting"" behavior dealing with aliases. The resultSet.findColumn method will fail on a table column name lookup if an alias is defined. There are some properties you can set on the connect to change some of these behaviors or just use the JTDS drivers. BookTextView/1072;pt=1072;uf=0"">http://manuals.sybase.com/onlinebooks/group-jc/jcg0600e/prjdbc/@Generic_BookTextView/1072;pt=1072;uf=0  I can confirm it is the Sybase drivers. Using the jTDS (v1.2.5) from http://jtds.sourceforge.net/ I can get all the column names correctly defined in my query and can confirm that the original issue is NOT DBI If anyone who is following this wondered how I got jtds working with DBI under jRuby please take a look at one of my former questions - it did take some time - and DBI is a little funny when specifying the URL use dbi:Jdbc:jtds:sybase://<host>:<port>/<db> Please note the capital J for Jdbc I hope this saves someone a lot of time ;-)"
795,A,"Is it resource-safely to use prepared statements multiple times? My application uses some prepared statement in every iteration of infinity loop. Is it safely to create preparedStatement before the loop and to run only pstmt.execute in the loop? Also it is interesting about simple statement. That's the point of prepared statements - to prepare them once and use them multiple times.  Yes that's fine and moreover is one of the points of using PreparedStatements (the statement gets compiled once and then can be run multiple times). So long as you're not calling the same statement from multiple (different) threads this will work as you expect. Calling the same statement from multiple threads is likely to cause problems as these objects are not guaranteed to be threadsafe under these conditions.  ""infinity loop""? Sorry this sounds like a bad idea. People are correct when they say that calling a prepared statement multiple times in a loop is a good idea. But implicit in that is a loop with a definite beginning and end. I'm suspicious of your ""infinite loop"". It sounds more like a listener that you want to keep alive to respond to some database event. The answer ""it's fine"" is correct but it might be interesting to go into more detail about what you're doing. UPDATE after comment: I'd have an Atom RSS server that listened for events. When a request came in I'd have the RSS listener hand it off to a service that would get a connection out of the connection pool start a transaction create a prepared statement in method scope insert the message close the prepared statement in a finally block within method scope commit the transaction and return the connection to the pool. The JDBC driver or database will cache PreparedStatements so it won't be inefficient. No need to hang onto one. No infinite loop. No threading issues that way. +1 I missed that important point My programm is collecting data from rss channels and puts items to the database. I think it is not possible to build evented model for this task. But it is interesting: how is it possible to make evented model based on database events? Are there any libraries for this? If it is impoetant I am writing programm on scala language. Very interesting. I think in my project I will do this using Scala actors."
796,A,"problem using base64 encoder and InputStreamReader I have some CLOB columns in a database that I need to put Base64 encoded binary files in. These files can be large so I need to stream them I can't read the whole thing in at once. I'm using org.apache.commons.codec.binary.Base64InputStream to do the encoding and I'm running into a problem. My code is essentially this FileInputStream fis = new FileInputStream(file); Base64InputStream b64is = new Base64InputStream(fis true -1 null); BufferedReader reader = new BufferedReader(new InputStreamReader(b64is)); preparedStatement.setCharacterStream(1 reader); When I run the above code I get one of these during the execution of the update java.io.IOException: Underlying input stream returned zero bytes it is thrown deep in the InputStreamReader code. Why would this not work? It seems to me like the reader would attempt to read from the base 64 stream which would read from the file stream and everything should be happy. This appears to be a bug in Base64InputStream. You're calling it correctly. You should report this to the Apache commons codec project. Simple test case: import java.io.*; import org.apache.commons.codec.binary.Base64InputStream; class tmp { public static void main(String[] args) throws IOException { FileInputStream fis = new FileInputStream(args[0]); Base64InputStream b64is = new Base64InputStream(fis true -1 null); while (true) { byte[] c = new byte[1024]; int n = b64is.read(c); if (n < 0) break; if (n == 0) throw new IOException(""returned 0!""); for (int i = 0; i < n; i++) { System.out.print((char)c[i]); } } } } the read(byte[]) call of InputStream is not allowed to return 0. It does return 0 on any file which is a multiple of 3 bytes long. Wow thanks for confirming that I must say I'm surprised that I found such a bug (however inadvertently). Yes you're right. This is a bug in Base64InputStream. +1 for the testcase which confirms this. Reported btw: https://issues.apache.org/jira/browse/CODEC-101 That said I'm still wondering about the coincidence that my test file was indeed a multiple of 3 bytes long :o)  Interesting I did some tests here and it indeed throws that exception when you read the Base64InputStream using an InputStreamReader regardless the source of the stream but it works flawlessly when you read it as binary stream. As Trashgod mentioned Base64 encoding is framed. The InputStreamReader should in fact have invoked flush() on the Base64InputStream once more to see if it doesn't return any more data. I don't see other ways to fix this than implementing your own Base64InputStreamReader or Base64Reader. This is actually a bug see Keith's answer. As a workaround you can also just store it in a BLOB instead of a CLOB in the DB and use PreparedStatement#setBinaryStream() instead. It doesn't matter if it's stored as binary data or not. You don't want to have such large Base64 data to be indexable or searchable anyway. Update: since that's not an option and having the Apache Commons Codec guys to fix the Base64InputStream bug which I repored as CODEC-101 might take some time you may consider to use another 3rd party Base64 API. I've found one here (public domain so you can do whatever with it you want even place in your own package) I've tested it here and it works fine. InputStream base64 = new Base64.InputStream(input Base64.ENCODE); Update 2: the commons codec guy has fixed it pretty soon. Index: src/java/org/apache/commons/codec/binary/Base64InputStream.java =================================================================== --- src/java/org/apache/commons/codec/binary/Base64InputStream.java (revision 950817) +++ src/java/org/apache/commons/codec/binary/Base64InputStream.java (working copy) @@ -14521 +14541 @@ } else if (len == 0) { return 0; } else { - if (!base64.hasData()) { - byte[] buf = new byte[doEncode ? 4096 : 8192]; - int c = in.read(buf); - // A little optimization to avoid System.arraycopy() - // when possible. - if (c > 0 && b.length == len) { - base64.setInitialBuffer(b offset len); + int readLen = 0; + /* + Rationale for while-loop on (readLen == 0): + ----- + Base64.readResults() usually returns > 0 or EOF (-1). In the + rare case where it returns 0 we just keep trying. + + This is essentially an undocumented contract for InputStream + implementors that want their code to work properly with + java.io.InputStreamReader since the latter hates it when + InputStream.read(byte[]) returns a zero. Unfortunately our + readResults() call must return 0 if a large amount of the data + being decoded was non-base64 so this while-loop enables proper + interop with InputStreamReader for that scenario. + ----- + This is a fix for CODEC-101 + */ + while (readLen == 0) { + if (!base64.hasData()) { + byte[] buf = new byte[doEncode ? 4096 : 8192]; + int c = in.read(buf); + // A little optimization to avoid System.arraycopy() + // when possible. + if (c > 0 && b.length == len) { + base64.setInitialBuffer(b offset len); + } + if (doEncode) { + base64.encode(buf 0 c); + } else { + base64.decode(buf 0 c); + } } - if (doEncode) { - base64.encode(buf 0 c); - } else { - base64.decode(buf 0 c); - } + readLen = base64.readResults(b offset len); } - return base64.readResults(b offset len); + return readLen; } } I tried it here and it works fine. Unfortunately I cannot use BLOB because sometimes the data in there will be text +1 Thanks that class will work nicely. +1 Good workaround.  ""For top efficiency consider wrapping an InputStreamReader within a BufferedReader. For example:"" BufferedReader in = new BufferedReader(new InputStreamReader(b64is)); Addendum: As Base64 is padded to a multiple of 4 characters verify that the source isn't truncated. A flush() may be required. Perhaps it is more efficient but it doesn't solve the problem @Stephen C: ""an integer multiple of 4 characters""—Base64 http://en.wikipedia.org/wiki/Base64 Any chance your stream is truncated? IIRC `base64` is framed. Question updated. Can you elaborate on what you mean by ""base64 is framed"" ? The stream comes directly from the file. The encoded stream must be padded to ""an integer multiple of 4 characters"" in order to decode the last byte; this would be a problem if the stream were truncated. Reference cited above. @trashgod - *""Reference cited above.""*. WHERE?"
797,A,"When inserting a complex object into an SQL database when should the object be broken up into its respectful tables? Edit: In short what strategy should one use on insert and select scripts with complex objects (eg. two select calls one for each table; a single select call with unions)? We have a database insert (postgresql) that includes a list of objects that is serialized (in text xml) and put it into a cell in a row amongst normal strings and such. We would like to create a new table with those lists with references back to the key of the original item. Where should the object be split off? I don't think it is possible in the SQL query but if so that would be ideal. Our favorite spot currently is just before we set up our JDBCProcedures. string name int id List<sub-objects> and currently this is being stored in a DB schema like: name varchar(20) id int subObjs text [or other character type big enough to hold the serialized XML] Please provide a little more information about the structure of your objects and clarify your question. It's not entirely clear what you're asking here. That said let me try to take a stab: If you have objects in Java code with structure somewhat like this: string name int id object[] list_of_sub-objects and currently this is being stored in a DB schema like: name varchar(20) id int subObjs text [or other character type big enough to hold the serialized XML] Is that about right? And then your question is: We would like to create a new table with those lists with references back to the key of the original item. Where should the object be split off? I don't think it is possible in the SQL query but if so that would be ideal. When you say the list-attribute item is ""serialized"" in your existing system do you mean as XML? It looks like XML parsing in SQL itself is still in development for postgreSQL and in any case it's likely to be a lot of trouble to code something like that up if you do not already know how. But you already have application code which represents your objects in a non-serialized fashion. You could write a function in your application codebase which performs the migration. Load the records from the old database table into application objects according to your existing schema then write them back into your new pair of DB tables according to your new schema. This conceptually simplifies the problem down to something you can represent in pseudocode i.e. ""how do I map the structure of my object from the old database schema to the new one?"" I hope this helps! If you can clarify your structure a bit I might be able to contribute some more specific pseudocode for the solution I'm proposing here. Your structure was correct and I added it to the question. Moving the old data isn't important as we aren't yet in production. Specifically I was asking about the `insert` and `select` techniques I'll add more details to the question.  We ended up splitting the insert into two calls (one for main object one for sub-object) so that each table would have its own insert but created a single select so that we could use the advantages of foreign keys in the query."
798,A,"JDBC INSERT MULTIPLE records obtained from query into other table I need to insert multiple records into mysql database at once. What I am doing is SELECT on one table from my application with Prepared statement. What I must do is to insert those results into one other temporary table. String sqlquery = ""select * from table1 where arg1 = ?""; PreparedStatement statement; statement = con.prepareStatement(sql); ArrayList<String>termlist = index.getTermList(); for (int i = 0; i < termlist.size(); i++) { String search = termlist.get(i); statement.setString(1search); ResultSet rs1 = statement.executeQuery(); // } These sets might be big. What is the fastest way to insert this ResultSet somehow into my other table after each iteration? How to pass this resultsset to some stored procedure if there is way? You could get the database to do the work for you: INSERT INTO othertable SELECT col1 col2 FROM table1 WHERE arg1 = ? This way you don't have to send a copy of data to the database that already exists there. Thanx Mark. Gosh this seems simple didnt come to my mind. So i just make this as prepared statement??? If i do it in this way is it possible to in case I did not have match with searchstring somehow to keep reference to this searchstring? I mean if i do not do the ResultSet count???  You could perform a single query if you pass a comma separated list of parameter values into a stored procedure and use an IN (val1 val2 ...) clause. Not sure what MySQL's limit is for the length of an IN clause. Here's a split implementation."
799,A,Simulation of long-running Oracle DB query What is the simplest (preferably without any new table creation) way of running a database query which takes long time (at least several minutes) in Oracle DB? DBMS_LOCK.sleep (http://www.oracle-base.com/articles/9i/UsefulProceduresAndFunctions9i.php) Thanks but Veton was faster :).  Consider using DBMS_LOCK.SLEEP(300) where parameter - number of seconds to wait. Thanks that's what I really need :) +1 Very useful thanks for the tip!
800,A,how to get mysql query result as xml? I recall reading about XML support from MySql. Does anyone know how to get XML without writing code? My client-protocol expects XML and I have a data source that I can access from a web app (JSP using JDBC). I think you want to get the result of a query in xml format isn't it? Take a look here: Using XML in MySQL 5.1 and 6.0 That is exactly what I was looking for --- I don't know why I could not find it yesterday. (I am a bit under the weather so my head is foggy for certain.)
801,A,JDBC: best way to update a table? Let's say that I get a ResultSet which was queryed using joins from an sql database. Is it better to use an sql statement to update the tables or insert new tuples/rows? Or should i use the resultSet.update() function? I just want to know the drawbacks associated with each as well as the preferred method of updating tables. ResultSet will only be updatable if: You've created your statement with appropriate flag (ResultSet.CONCUR_UPDATABLE) The underlying database / driver supports updates over join results If both conditions are true updates are likely to be more efficient when done this way as you're already holding a cursor to the item. Otherwise you'll need to create a new statement - be sure to use a PreparedStatement for that. why use a prepared statement? Because prepared statements should pretty much always be used in place of regular ones - they can be cached / reused by the database resulting in better performance and they protect you from SQL injection attacks among other things. + 1 - Yeah baby. PreparedStatement is the only way to go. I'd be hard-pressed to think of a good reason NOT to use them.
802,A,"Spring Jdbc atomicity with alter table I'm trying to write an equivalent of Rails data model evolution/rollback mechanism using Spring Jdbc. Spring Jdbc transactionnal insert/replace works very well (DataSourceTransactionManager with PROPAGATION_REQUIRED under InnoDB mysql 5) : // Transaction begins getJdbcTemplate().execute(""replace into aTable ...""); getJdbcTemplate().execute(""wrong request""); getJdbcTemplate().execute(""replace into aTable ...""); // none are commited but alter doesn't : // Transaction begins getJdbcTemplate().execute(""alter table aTable add column `columnForTest` ...""); getJdbcTemplate().execute(""wrong request""); getJdbcTemplate().execute(""alter table aTable add column `columnForTest` ...""); // the first alter is commited Is there a way to achieve atomicity (all-or-none behavior) with alter ? Thanks in advance Adding DB columns during runtime is a *huge* datamodel design smell. Shouldn't you be using a link table? This way you just need to insert the ""column name"" and the desired associated data as a new row. ALTER TABLE (and other DDL operations) are usually non-transactional depending on the database. Spring and JDBC have no control over this. If a non-transactional operation is performed inside a transaction it will be performed non-transactionally. So it comes down to the database and how it is configured rather than being an issue with the client. Thanks I will look in this direction."
803,A,"ResultSet prematurely closing I'm compiling a list of Page variables (which has a list of books in it) from a running MYSQL Database. When attempting the second iteration in the while(rs.next()) loop I receive an SQL Exception saying that the ResultSet was already closed. I see nowhere that this code closes the rs object. try { stmt = con.createStatement(); ResultSet rs = stmt.executeQuery(""SELECT pageURL"" + ""pageName FROM pages GROUP BY pageName;""); ResultSet rs2; while(rs.next()) { // Where the error occurs on the second pass Page tempP = new Page(rs.getString(1)rs.getString(2)); rs2 = stmt.executeQuery(""SELECT `books`.`itemID`cost"" + ""titleauthorshortDlongD FROM "" + ""books INNER JOIN pages ON "" + ""books.itemID=pages.itemID WHERE "" + ""pageName='"" + rs.getString(2) + ""';""); while(rs2.next()) { tempP.addBook(new Book(rs2.getInt(1) rs2.getFloat(2)rs2.getString(3) rs2.getString(4)rs2.getString(5) rs2.getString(6))); } pages.addPage(tempP); } } catch(SQLException e) { System.err.print(""SQLException: ""); System.err.println(e.getMessage()); } Here is the contents of the pages table: |pageName |pageURL |itemID| ------------------------------- |Tech Books|./techbooks|1 | ------------------------------- |Tech Books|./techbooks|2 | ------------------------------- |Kids Books|./kidsbooks|3 | ------------------------------- |Kids Books|./kidsbooks|4 | ------------------------------- |Kids Books|./kidsbooks|5 | ------------------------------- EDIT: Okay it looks like that ResultSet becomes invalid when I use the Statement again. Does anyone have any suggestions to remedy this situation? Your second query has a possible SQL-injection threat. Even if you are sure that it is safe it is bad form to code this way and it will also hurt optimization of your queries in the database. I'm sure it is safe but what would you suggest to optimize this? @Kevin: use a PreparedStatement with bind variables (setString) See the documentation of ResultSet: A ResultSet object is automatically closed when the Statement object that generated it is closed re-executed or used to retrieve the next result from a sequence of multiple results.  To quote the javadocs for Statement: By default only one ResultSet object per Statement object can be open at the same time. Therefore if the reading of one ResultSet object is interleaved with the reading of another each must have been generated by different Statement objects. All execution methods in the Statement interface implicitly close a statment's current ResultSet object if an open one exists. Create two statements or better yet use PreparedStatements with bound variables. Thanks a bunch Paul!"
804,A,"Quering and writing to a file : errorcode 28 I am getting this error when I try to query the database and write results to a file. It never occured before. java.sql.SQLException: Error writing file '/tmp/MYwADPLw' (Errcode: 28) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:946) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:2870) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1573) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:1665) at com.mysql.jdbc.Connection.execSQL(Connection.java:3170) at com.mysql.jdbc.Connection.execSQL(Connection.java:3099) at com.mysql.jdbc.Statement.executeQuery(Statement.java:1169) at DBase.connect(DBase.java:58) // this is where i call executequery at automateExport.main(automateExport.java:11) Exception in thread ""main"" java.lang.NullPointerException at automateExport.main(automateExport.java:13) // main class with db connection The resultset I am expecting is very large. I never had this problem when I was querying for a smaller resultset. Could it be space issues? I have 117 gb on my disc. But I am expecting a max of 1gb text data. Any solutions??? My Code:  public Connection connect(String db_connect_strString db_userid String db_password) { Connection conn; Statement stmt; String query; // inputfile - csv String input = ""inputfile.txt""; try { // to bifurcate heap memory error Class.forName(""com.mysql.jdbc.Driver"").newInstance(); conn = DriverManager.getConnection(db_connect_strdb_userid db_password); stmt = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY); stmt.setFetchSize(Integer.MIN_VALUE); query = ""SELECT r.name r.network  r.namestring i.name i.description ""+ ""  r.rid  i.id d.dtime d.ifInOctets  d.ifOutOctets  FROM_UNIXTIME(d.dtime)""+ "" FROM router AS r INNER JOIN interface AS i ON r.rid = i.rid "" + ""INNER JOIN 1278993600_1_60 AS d ON i.id = d.id "" + ""AND dtime BETWEEN "" +startTime+ "" AND ""+ endTime +"" WHERE r.network = 'ITPN'"" + ""AND i.status = 'active' ORDER BY i.id d.dtime""; BufferedWriter fw = new BufferedWriter(new FileWriter(input)); ResultSet rs = stmt.executeQuery(query); String idescp = null; // writing to file while (rs.next()) { if(rs.getString(""description"").equals(null)){ System.out.println(""description"" +rs.getString(""description"") ); idescp = ""NA""; System.out.println(""idescp :"" +idescp + "":""); }else{ idescp = rs.getString(""description""); } fw.write(rs.getString(1)+""""+ rs.getString(""rid"")+""""+ rs.getString(""id"") + """" +idescp+"""" +rs.getString(""dtime"")+ """" +rs.getString(""ifInOctets"")+ """" + rs.getString(""ifOutOctets"") + """"+ rs.getString(11)+NL); } fw.close(); rs.close() ; stmt.close() ; } catch(Exception e) { e.printStackTrace(); conn = null; } return conn; } Please help. Thank you. Can you show us what your automateExport main method looks like? public class automateExport { public static void main(String[] args) throws SQLException{ DBase db = new DBase(); Connection conn = db.connect( ""jdbc:mysql://comm.comng..com/perf""""bread"" ""nm36""); conn.close(); } } works perfect for a smaller resultset of data. gives above error for a larger resultset. there is not result set in the sample of code you writed added code. sorry about that a 1gb+ resultset is huge and will comsume a bunch of server resources for a long time. can't you call a stored proc that select... into outfile server side and then transfer the data file and process it locally ?? Maybe the database runs out of temp space on the file. I would check if ot the path given the account the database is running on has the right and the space to write some data. but i am running it and writing it on my machine. file gets created in my workspace And the MySQL engine is started with your account? Is there enough free space on the drive mentioned in the error message? I have no idea which drive this could be: '/tmp/MYwADPLw' I am writing on my machine only. Just querying db for the data. could it be because of the complex query?? if i break the query down to 2 parts would that help??? @jillika So the database is running on a server different from your machine? Who is administering that server? Maybe you should contact her/him and have them do the space check. Thank you for your answer. My machine runs out of memory. Your answer helped me.  MySQL will write large resultsets to disk for streaming. The database server's /tmp folder is likely filling up as @Frank suggests."
805,A,"SQL Server connection management in Tomcat 6 We are having trouble with a Java web application running within Tomcat 6 that uses JDBC to connect to a SQL Server database. After a few requests the application server dies and the in the log files we find exceptions related to database connection failures. We are not using any connection pooling right now and we are using the standard JDBC/ODBC/ADO driver bridge to connect to SQL Server. Should we consider using connection pooling to eliminate the problem? Also should we change our driver to something like jTDS? It's hard to tell really because you've provided so little information on the actual failure: After a few requests the application server dies and the in the log files we find exceptions related to database connection failures. Can you tell us: exactly what the error is that you're seeing give us a small example of the code where you connect and service one of your requests is it after a consistent number of transactions that it fails or is it seemingly random I have written a lot of database related java code (pretty much all my code is database related) and used the MS driver the jdt driver and the one from jnetDirect. I'm sure if you provide us more details we can help you out.  I would definitely give jTDS a try. I've used it in the past with Tomcat 5.5 with no problems. It seems like a relatively quick low impact change to make as a debugging step. I think you'll find it faster and more stable. It also has the advantage of being open source. In the long term I think you'll want to look into connection pooling for performance reasons. When you do I recommend having a look at c3p0. I think it's more flexible than the built in pooling options for Tomcat and I generally prefer ""out of container"" solutions so that it's less painful to switch containers in the future. has anyone given jTDS a try? I'm runing Tomcat 5.5 with the sql server 2000 jdbc connector and I'm running into issues handling special characters. its a pretty painful problem.  That is the correct behavior if you are not closing your JDBC connections. You have to call the close() method of each JDBC resource when you are finished using it and the other JDBC resources you obtained with it. That goes for Connection Statement/PreparedStatement/CallableStatement ResultSet etc. If you fail to do that you are hoarding potentially huge and likely very limited resources on the SQL server for starters. Eventually connections will not be granted get queries to execute and return results will fail or hang. You could also notice your INSERT/UPDATE/DELETE statements hanging if you fail to commit() or rollback() at the conclusion of each transaction if you have not set autoCommit property to true. What I have seen is that if you apply the rigor mentioned above to your JDBC client code then JDBC and your SQL server will work wonderfully smoothly. If you write crap then everything will behave like crap. Many people write JDBC calls expecting ""something"" else to release each thing by calling close() because that is boring and the application and server do not immediately fail when they leave that out. That is true but those programmers have written their programs to play ""99 bottles of beer on the wall"" with their server(s). The resources will become exhausted and requests will tend to result in one or more of the following happening: connection requests fail immediately SQL statements fail immediately or hang forever or until some godawful lengthy transaction timeout timer expires etc. Therefore the quickest way to solve these types of SQL problems is not to blame the SQL server the application server the web container JDBC drivers or the disappointing lack of artificial intelligence embedded in the Java garbage collector. The quickest way to solve them is to shoot the guy who wrote the JDBC calls in your application that talk to your SQL server with a Nerf dart. When he says ""What did you do that for...?!"" Just point to this post and tell him to read it. (Remember not to shoot for the eyes things in his hands stuff that might be dangerous/fragile etc.) As for connection pooling solving your problems... no. Sorry connection pools simply speed up the call to get a connection in your application by handing it a pre-allocated perhaps recycled connection. The tooth fairy puts money under your pillow the Easter bunny puts eggs & candy under your bushes and Santa Clause puts gifts under your tree. But sorry to shatter your illusions - the SQL server and JDBC driver do not close everything because you ""forgot"" to close all the stuff you allocated yourself."
806,A,"Hibernate cannot open connection I'm having trouble with hibernate not able to open a connection. I have a DAO: public class MyDao extends HibernateDaoSupport { DataSource dataSource; public void setDataSource(DataSource dataSource) { this.dataSource = dataSource; } public MyPOJO findByQuery(int hour) { Query query = this.getSession().createSQLQuery( ""SELECT * FROM MyPOJO WHERE someDate >= DATE_SUB(now() INTERVAL ? HOUR)"") .addEntity(MyPOJO.class); List<MyPOJO> results = query.setInteger(0 hours).list(); return results; } } and then in a test case call findByQuery(1) 8 times it works but if I call a 9th time it fails with: org.hibernate.exception.GenericJDBCException: Cannot open connection at org.hibernate.exception.SQLStateConverter.handledNonSpecificException(SQLStateConverter.java:103) at org.hibernate.exception.SQLStateConverter.convert(SQLStateConverter.java:91) at org.hibernate.exception.JDBCExceptionHelper.convert(JDBCExceptionHelper.java:43) at org.hibernate.exception.JDBCExceptionHelper.convert(JDBCExceptionHelper.java:29) at org.hibernate.jdbc.ConnectionManager.openConnection(ConnectionManager.java:426) at org.hibernate.jdbc.ConnectionManager.getConnection(ConnectionManager.java:144) at org.hibernate.jdbc.AbstractBatcher.prepareQueryStatement(AbstractBatcher.java:139) at org.hibernate.loader.Loader.prepareQueryStatement(Loader.java:1547) at org.hibernate.loader.Loader.doQuery(Loader.java:673) at org.hibernate.loader.Loader.doQueryAndInitializeNonLazyCollections(Loader.java:236) at org.hibernate.loader.Loader.doList(Loader.java:2213) at org.hibernate.loader.Loader.listIgnoreQueryCache(Loader.java:2104) at org.hibernate.loader.Loader.list(Loader.java:2099) at org.hibernate.loader.custom.CustomLoader.list(CustomLoader.java:289) at org.hibernate.impl.SessionImpl.listCustomQuery(SessionImpl.java:1695) at org.hibernate.impl.AbstractSessionImpl.list(AbstractSessionImpl.java:142) at org.hibernate.impl.SQLQueryImpl.list(SQLQueryImpl.java:152) Caused by: org.apache.commons.dbcp.SQLNestedException: Could not retrieve connection info from pool at org.apache.commons.dbcp.datasources.SharedPoolDataSource.getPooledConnectionAndInfo(SharedPoolDataSource.java:169) at org.apache.commons.dbcp.datasources.InstanceKeyDataSource.getConnection(InstanceKeyDataSource.java:631) at org.apache.commons.dbcp.datasources.InstanceKeyDataSource.getConnection(InstanceKeyDataSource.java:615) at org.springframework.orm.hibernate3.LocalDataSourceConnectionProvider.getConnection(LocalDataSourceConnectionProvider.java:81) at org.hibernate.jdbc.ConnectionManager.openConnection(ConnectionManager.java:423) ... 35 more Caused by: java.util.NoSuchElementException: Timeout waiting for idle object at org.apache.commons.pool.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:827) at org.apache.commons.dbcp.datasources.SharedPoolDataSource.getPooledConnectionAndInfo(SharedPoolDataSource.java:165) ... 39 more This is what my hibernate properties look like: <property name=""hibernateProperties""> <props> <prop key=""hibernate.dialect""> org.hibernate.dialect.MySQL5Dialect </prop> <prop key=""hibernate.current_session_context_class""> thread </prop> <prop key=""hibernate.format_sql"">false</prop> <prop key=""hibernate.show_sql"">false</prop> <prop key=""hibernate.use_sql_comments"">false</prop> <prop key=""hibernate.jdbc.use_get_generated_keys"">true</prop> <prop key=""hibernate.cache.use_second_level_cache"">true</prop> <prop key=""hibernate.cache.provider_class""> org.hibernate.cache.EhCacheProvider </prop> <prop key=""hibernate.connection.release_mode"">auto</prop> </props> </property> If I change the release_mode to 'after_statement' (ala http://docs.jboss.org/hibernate/stable/core/reference/en/html_single/#transactions-connection-release) it will work but I don't understand that and feel like that is just a band-aid for something bigger that I am doing wrong. I've also tried to flush and close the this.getSession() with no luck either. I can see the close() gets called AFTER all of the calls to findByQuery(1) have completed. This is on Hibernate 3.2.6 Spring 3.0 and MySQL 5.1. Let me know what more information I can provide. isn't there a `Caused by` of the exception? yes thanks. See edit. Javadoc for HibernateDaoSupport.getSession() says: Note that this is not meant to be invoked from HibernateTemplate code but rather just in plain Hibernate code. Either rely on a thread-bound Session or use it in combination with releaseSession(org.hibernate.Session). So the session obtained via getSession() should be released via releaseSession(): public MyPOJO findByQuery(int hour) { Session s = null; try { s = this.getSession(); Query query = s.createSQLQuery( ""SELECT * FROM MyPOJO WHERE someDate >= DATE_SUB(now() INTERVAL ? HOUR)"") .addEntity(MyPOJO.class); List<MyPOJO> results = query.setInteger(0 hours).list(); return results; } finally { if (s != null) this.releaseSession(s); } } But the better way to deal with session is to use a HibernateCallback: public MyPOJO findByQuery(int hour) { return this.getHibernateTemplate().executeFind(new HibernateCallback<List<MyPOJO>>() { List<MyPOJO> doInHibernate(org.hibernate.Session session) { Query query = session.createSQLQuery( ""SELECT * FROM MyPOJO WHERE someDate >= DATE_SUB(now() INTERVAL ? HOUR)"") .addEntity(MyPOJO.class); return query.setInteger(0 hours).list(); } }); } Ahh! I looked for ever for a way to do it via getHibernateTemplate(). Thanks a lot axtavt. Thank you a lot! I would never have figured out why my application fails each 10 minutes when using `getSession()`.."
807,A,"Why is the Sybase JDBC driver ""eating"" the exceptions? I'm using the official Sybase JDBC driver to connect to a database and call a stored procedure by creating a CallableStatement binding the parameters to it and calling .execute() on it. However I found that no exception is thrown even if the stored procedure fails. I can verify that the failure is propagated back to me by sniffing the traffic to the database with Wireshark and observing the error messages coming back. Finally I found that using .executeUpdate() instead of .execute() does give me the exceptions however I still have two questions left: Why are .execute() and .executeUpdate() behaving differently? From the SUN documentation of the interface it seems that they should do (almost) the same thing... Is it always appropriate to replace .execute() with .executeUpdate() when calling a stored procedure? Must the stored procedure conform to some particular requirements to be callable with .executeUpdate()? (for example must it have an update/delete/insert statement as the last step?) Update: I've tried jTDS and it behaves correctly (as in: it throws the SQLException in both cases - with .execute() and with .executeUpdate()). However due to constraints beyond my control switching out the driver is not really possible. Also: I'm no interested in the result returned by this stored procedure it is an insert/update type procedure. I would only be inserted to see (and be able to catch / log) if it fails or not. An other thing I've tried is to get the warnings off the connection after .execute() but it didn't contain anything either. do other drivers behave the same? What about jTDS? http://jtds.sourceforge.net/ Because those Sybase people are crazy that's why it eats Exceptions! There's no reason to avoid using executeUpdate() for prepared/callable statements. If that's what you've got to use to get it working then go ahead and do so. But you ought to file a bug report with Sybase - there's no reason the driver should be doing that.  not sure whether the sybase people are ""crazy"". Maybe. On the other hand not synchronuously retrieving results when you don't actively check for the return code of a callable statement may make sense performance-wise. I have not yet tested it completely but there is a simple workaround to your problem (ASE 15.5 jconn 7): the exception will be triggered when you fetch an out param from the stored proc (at least when calling stored procedures):  // one may force the error check by retrieving the return code! cs = conn.prepareCall(""{ ? = call sp_nested_error @nNestLevels = 1 }""); cs.registerOutParameter(1 Types.INTEGER); cs.execute(); try { cs.getInt(1); fail(); } catch(SQLException e) { assertTrue(e.getMessage().indexOf(""some error"") > -1); } Another curiosity is that this behavior only shows up when errors are triggered in nested stored procedure calls and the workaround is not necessary when the top-most procedure raises the error.  don't know anything about Sybase but executeUpdate returns more infos than execute : the # of rows inserted/updated/deleted -> it is usable with UPDATE INSERT DELETE and DML operations according to the javadoc. executeQuery returns a ResultSet this is for SELECT statements."
808,A,"How effective is executeBatch on a Prepared Statement? Subject to this question asks it all:How effective is executeBatch method? Is there a performance benchmark that says.. 'if you have 1000 records to be inserted using a executeBatch instead of executeUpdate saves you x amount of database cycles?' Or Is this just a convention? EDIT: Here is what I am working with: a DB2 V 8.1 hosted on Z/OS a web app that would be inserting 80000 records at one go in it's worst case scenario execution. Rather than have everyone give you woolly numbers why not try it for yourself and measure it? Only you can know how much benefit you'll get from your set-up. @skaffman I don't want to do what is popularly called premature optimization. I would however like to understand how significantly faster it is. I understand that but you can't make an informed choice without a bit of benchmarking. Not sure what database you are using. When I ran a test on this using db2 this is what I saw: To write to the database: 1 insert it took 2500 microseconds. 10 inserts it took 6000 microseconds. (600 microseconds per write) 10000 inserts it took about 1 million microseconds. ( 100 microseconds per write) Performance maxed out there. All this means is that there is a huge overhead in sending messages and using a batch method minimizes this. Of course sending inserts/updates in huge batches runs the risk of losing them if the application crashes. Also of note: Exact numbers will vary depending on your DB and settings. So you will have to find your own ""sweet spot."" But this gives you an idea. @windfinder did you use executeBatch for all the above? And you said 'huge batches run risk of being lost in application crashes' - if I am using transaction management - I should be good in this scenario? Yes I used executeBatch. Transaction management will not completely eliminate this risk but it might reduce it. In the simplest of ways if I were to set autocommit to false and commit only when the executeBatch returns How am I at risk? @windfinder - how did you find and measure those times ?  JDBC specification Chapter 14 says that submitting multiple SQL statements instead of individually can greatly improve performance  I'm not sure what you're asking but for inserting many thousands of rows a batched statement is hugely faster. I can't give you numbers though. @skaffman that was my question - how hugely faster is it? Can you give me an approximation? I'd estimate somewhere between 10 and 20 times it would depend to a large extent on the database itself. A non-batched statement involves a lot more network traffic so a remove server would benefit more from batching than a local one for example. More than 10-20x in my experience (for my particular use case). (and environment)  In my experience it is significantly faster - even if you are inserting/updating just a few records at a time. If you are doing more than one update I would almost always recommend batching them if it makes sense. That said you'd have to do some actual testing to figure out the performance improvement for your particular situation."
809,A,CLASSPATH on Mac and how does Mac look for mysql-connector-java-bin.jar Is there a default classpath on Mac OS X 10.6? When I echo $CLASSPATH nothing would show up. In my .profile I only see PATH variable being set. My problem is that My servlet cant seem to find a suitable driver to connect to the mysql server. I use Eclipse with Glassfish v3 and MAMP for MYSQL server. I struggled a lot with this one. Try adding the appserv-rt.jar (located on Glassfish lib directory) to your project's build path. (I't will drag all it's dependancies if you want to avoid this first create a library with the jar and then add the library to your build path.  There are several methods of getting JARs to be seen by Java on Mac OS X: Place it in /Library/Java/Extensions Create/edit the CLASSPATH environment variable Specify the classpath explicitly with the -cp option. The CLASSPATH environment variable is not set by default however you can set it if you so choose. Be aware however that any environment variables that you set in ~/.profile will only take effect within your Terminal session and will not affect any GUI applications. If you want to set environment variables so that they affect your GUI applications you can create a file named ~/.MacOSX/environment.plist that includes your environment variables. Any changes made to that file will take effect when you next login. As has been observed placing JARs in the extensions folder or modifying the CLASSPATH environment variable are generally bad ideas since they can lead to dependency hell. A better way is to bundle your JARs with your artifact and to set the metadata appropriately so that they are on your artifact's classpath. If you use Apache Maven2 to build your artifact you can have it automatically download as well as bundle any thirdparty dependencies and set the classpath appropriately for your artifact. the first 2 suggestions are BAD suggestions and the third one is not really an option when working with a Servlet container you should include the .jar file in the lib directory of the .war you are deploying to your Servlet container. you should NOT need to have a CLASSPATH it makes your machine really brittle and rife with .jar conflicts. OK when I develop on Netbean I can see my War file but not on eclipse. Does eclipse create war file for deployment? If so where do I put the jar file? inside WEB-INF/lib? Aslo when setting the classpath i beleive you need to do so in the users environment.plist (/Users/username/.MacOSX/environment.plist) in addition to or instead of your .bash_profile. Could be worng about that but i seem having to do that with the svn-javahl and its dependencies. Sigh...very where I go in the java world I heard about maven. I looked at it before quite robust and complex. Is it very important to know maven? @Harry Maven is definitely worth it though I agree it is a bit hard to configure. just tell Eclipse to add the .jar file to the WEB-INF/lib dir you do not need to deal with Maven if you are building with Eclipse  Do not use the CLASSPATH environment variable. This is portability trouble. The whole environment variable is a mistake of the Sun guys. It's only useful for starters but certainly not in real world. This would only confuse the starters more afterwards. Besides appservers (and IDE's) completely ignores this environment variable. Do not put the libraries in the library of JRE or JDK. This is portability trouble as well. If you upgrade the JRE/JDK or run the application somewhere else it won't work anymore. In webapplications you normally just drop webapp-specific 3rd party libraries in Webapp/WEB-INF/lib. This folder is covered by the webapp's default classpath. If those libraries are rather appserver-specific (e.g. JDBC driver is required to create a JNDI datasource which is managed by the appserver) then you need to drop them in Appserver/lib. This folder is covered by the appserver's default classpath. In case of Glassfish you need to put it more specifically in the domain-specific /lib folder e.g. glassfish/domains/<domainname>/lib.
810,A,Multithreading in JDBC connectivity i am trying to upload a file into the server and storing the information of the file into an Access database is there any need to handle the threads while database connectivity for multiple user. If yes how to do it? Exactly. Each HTTP request is already a thread at its own. Keep in mind that the web container will create only one servlet instance during application's lifetime and that the servlet code is been shared among all requests. This implies that any class-level variables or static variables are going to be shared among all requests. If you have such one variable it is not threadsafe. You need to declare request-specific variables threadlocal at method-level. As to JDBC: just write solid code and everything should go well. Using a connection pool is only useful to improve connecting performance (which is really worth the effort believe me connecting the DB is a fairly expensive task which may account up to at least 200ms or even more while reusing a connection from the pool costs almost nothing). It only doesn't change anything to the threadsafety of the code you write it's still in your control/hands. To get a clear picture of how to do the basic JDBC coding the right way you may find this article useful.  Your webserver is inheritly multithreaded that saves you from implementing you own threads to handle the uploads. Do however make sure that multiple requests dont use same resources (dont write all uploaded file in the same tmp file....) To avoid problems saving the data to your db use a Connection Pool. So yes you need threads but if your design is good then all the threading will be handled by your frameworks
811,A,"Tomcat Postgres Connection I'm using a singleton class for a PostgresSQL connection inside a servelet. The problem is that once it is open it works for a while (I guess until some timeout) and then it starts throwing a I/O exception. Any idea what is happening to the singleton class inside Tomcat VM? Thanks Likely the exception tells you what's wrong so what does it say ? Same problem was posted recently: http://stackoverflow.com/questions/2979415/how-to-manage-db-connections-on-server I have no idea. Just do the right thing and do not reinvent the wheel. Use a DataSource either obtain it via JNDI (see http://tomcat.apache.org/tomcat-6.0-doc/jndi-datasource-examples-howto.html) or do it yourself (I like using Spring but if your web application is very simple it's probably overkill). Use a DataSource.  There's no singleton inside Tomcat; that's just the way connections work when you only have one and keep it open for a long time. It's called ""timeout"". This design cannot scale. A better solution is to keep connections open for as short a time as possible. Your code should open a connection use it and close it in transaction scope. You should also set up a connection pool in Tomcat.  and then it starts throwing a I/O exception Well what is the exception exactly? Also as a note it's safe to use the same Postgres JDBC connection from multiple threads but it is not recommended to do so."
812,A,"I want to give JDBC connection to mysql. I dont wish have the data values inside my class people()  import java.util.*; import org.directwebremoting.util.Logger; public class People { public People() { people = new HashSet(); random = new Random(); log.debug(""Generating a new set of random people""); for(int i = 0; i < 5; i++) people.add(getRandomPerson()); } public Set getAllPeople() { return people; } public void setPerson(Person person) { log.debug(""Adding person: "" + person); if(person.getId() == -1) person.setId(getNextId()); people.remove(person); people.add(person); } public void deletePerson(Person person) { log.debug(""Removing person: "" + person); people.remove(person); debug(); } private Person getRandomPerson() { Person person = new Person(); person.setId(getNextId()); String firstname = FIRSTNAMES[random.nextInt(FIRSTNAMES.length)]; String surname = SURNAMES[random.nextInt(SURNAMES.length)]; person.setName(firstname + "" "" + surname); String housenum = (random.nextInt(99) + 1) + "" ""; String road1 = ROADS1[random.nextInt(ROADS1.length)]; String road2 = ROADS2[random.nextInt(ROADS2.length)]; String town = TOWNS[random.nextInt(TOWNS.length)]; String address = housenum + road1 + "" "" + road2 + "" "" + town; person.setAddress(address); float salary = Math.round(10F + 90F * random.nextFloat()) * 1000; person.setSalary(salary); return person; } protected void debug() { Person person; for(Iterator it = people.iterator(); it.hasNext(); log.debug(person.toString())) person = (Person)it.next(); } private static synchronized int getNextId() { return nextId++; } static Class _mthclass$(String x0) { try { return Class.forName(x0); } catch(ClassNotFoundException x1) { throw new NoClassDefFoundError(x1.getMessage()); } } private Set people; private static int nextId = 1; private Random random; private static final String FIRSTNAMES[] = { ""Fred"" ""Jim"" ""Shiela"" ""Jack"" ""Betty"" ""Jacob"" ""Martha"" ""Kelly"" ""Luke"" ""Matt"" ""Gemma"" ""Joe"" ""Ben"" ""Jessie"" ""Leanne"" ""Becky"" }; private static final String SURNAMES[] = { ""Sutcliffe"" ""MacDonald"" ""Duckworth"" ""Smith"" ""Wisner"" ""Iversen"" ""Nield"" ""Turton"" ""Trelfer"" ""Wilson"" ""Johnson"" ""Cowan"" ""Daniels"" }; private static final String ROADS1[] = { ""Green"" ""Red"" ""Yellow"" ""Brown"" ""Blue"" ""Black"" ""White"" }; private static final String ROADS2[] = { ""Close"" ""Drive"" ""Street"" ""Avenue"" ""Crescent"" ""Road"" ""Place"" }; private static final String TOWNS[] = { ""Birmingham"" ""Kettering"" ""Paris"" ""San Francisco"" ""New York"" ""San Mateo"" ""Barcelona"" }; private static final Logger log; static { log = Logger.getLogger(People.class); } } I dont want these data values FIRSTNAMESTOWNSROADS2ROADS1SURNAMES inside the program rather i want to connect it to mysql table. How to do that anyone help me. I ever wrote a [little tutorial as answer](http://stackoverflow.com/questions/2839321/java-connectivity-with-mysql/2840358#2840358). You may find it useful. You can take a look at this introductory tutorial. There are tons of tutorials online as well regarding connecting Java applications and MySQL. On the other hand if you want to go that extra step forward you might want to take a look at ORM Tools like Hibernate. It basically allows your Java application to connect to a database (just like JDBC). The advantage of such framework tough is that it allows you to change the Database you are using without having to make drastic changes to your application. Not to mention that it automatically maps data stored inside the database to objects and the other way round."
813,A,Database Connection Problem with MS SQL Database: JDBC-ODBC Driver from JSP I'm using Netbeans 6.8 to develop application using JSP. I'm able to work with it properly in my project guides system. But i'm unable to get the connection to database from my system. It shows error unable to connect. I have not changed any of the codes. How can I fix this error? This can have one or more of the following causes: IP address or hostname in JDBC URL is wrong. Hostname in JDBC URL is not recognized by local DNS server. Port number is missing or wrong in JDBC URL. DB server is down. DB server doesn't accept TCP/IP connections. DB server has run out of connections. Something in between Java and DB is blocking connections e.g. a firewall or proxy. To solve the one or the other follow the following advices: Verify and test it using ping. Refresh DNS server or use IP address instead in JDBC URL. Verify it in the DB configuration. Start the DB. Verify it in the DB configuration. Restart the DB and fix your code accordingly that it closes connections in finally. Disable firewall and/or configure firewall/proxy to allow/forward the port. That said the JDBC-ODBC bridge driver is a poor choice for SQL Server. Rather use its own JDBC driver or the much more performant and robust jTDS driver. Thanks bro.let me try with TDS or so.
814,A,"JDBC + PL/SQL = Is it so simple or is there a catch? I am planning to execute Oracle PL\SQL blocks via JDBC (can't test it yet question of few days). Is there anything I should know? Does everything work as it used to with plain SQL? I mean: ResultSet rs = st.executeQuery(""DECLARE BEGIN NULL; END;""); Or will I need some custom classes? I'd like to keep it as much simple as possible (no ORM etc.). Thanks! Possible duplicate of http://stackoverflow.com/questions/5101529/execute-anonymous-pl-sql-block-and-get-resultset-in-java It is possible to call PL/SQL anonymous blocks using a standard CallableStatement (and Oracle JDBC drivers of course). See Returning data from anonymous PL/SQL block for some example code. See also Oracle® Database JDBC Developer's Guide and Reference Stored Procedure Calls in JDBC Programs"
815,A,"How is Oracle's JDBC query timeout implemented? I was curious as to how the Oralce JDBC thin client implement query timeout. This can be set by calling java.sql.Statement's setQueryTimeout(int seconds) method. Is this implemented in the driver itself on the client side? Is a new thread spawned and joined? Or does the JDBC driver simply send a parameter to Oracle and then it enforces the timeout? After the timeout is reached which resources on the client and database are released and which hang around? Does Oracle continue to run the query even though the client abandoned it or is it terminated? Is there still a cursor object on the client side? Thank you Tanel Poder wrote an article on how a Cancel works through the OCI (Oracle Call Interface). I guess something similar is done for JDBC. If you are using the thick driver through OCI you could try tracing the session (through settings sqlnet.ora) and see what gets recorded. Couldn't say whether it is a separate thread or just a loop saying ""Anything from the server...has it timed out...anything from the server...has it timed out...."" So does this mean that the JDBC driver spawns another tread for the query and wait for it to time out and then sends an OCICancel?  I do know that the query does not continue on the server side when the timeout is reached. There is some intention/signal option sent to the server either before or after the timeout is reached to indicate it the server should stop. I have verified this by looking on the server in various V$ tables to see if the query is running. (V$SESSION V$SQL etc)  According to Oracle JDBC FAQ Statement timeout thread. This thread is created if you execute any statement with a timeout. Only one thread is created no matter how many statements or connections. This thread lasts the lifetime of the VM.  When a query actually timesout when using the setTimeOut method a SQL exception with the Oracle error code ORA-01013 - user requested cancel of current operation is thrown from the oracle server. This would mean that the operation has been cancelled gracefully (as far as oracle is concerned/as much oracle can) - because it is oracle sending this message."
816,A,"How to migrate data from FoxPro to MySQL I am having a database in .dbf (FoxPro) format. How to retrieve data from FoxPro using Java? If the data can be migrated to MySQL How to do the conversion? Do you have a copy of FoxPro? You can save the database as an HTML file if you want. Then from HTML you can save to any format you want. I recently did this to save a FoxPro table as an Excel spreadsheet (not that I'd suggest using that for your Java code). If you plan on using Java once you have access to the data why not use one of Java's native storage types?  I suppose doing a CSV export of your FoxPro data and then writing a little Java programme that takes the CSV as input is your best bet. Writing a programme that both connects to FoxPro and MySQL in Java is needlessly complicated you are doing a one time migration. By the way PHP could do an excellent job at inserting the data into MySQL too. The main thing is that you get your data in the MySQL schema so you can use it with your new application (which I assume is in Java.)  I worked on the same project once long back where the project had be done with FoxPro and then we migrated that project to Java with MySQL. We had the data in Excel sheets or .txt files so we created tables as exact replica of the FoxPro data and transferred the data from the Excel/CSV /txt to MySQL using the Import data feature. Once we did this I think further you can take care from MySQL Data. But remember work will take some time and we need to be patient. will you please tell me to how to convert Foxpro data as CSV format ?  Taking the data to intermediate formats seems flawed as there are limitation with memo fields and CSV or Excel files. If you are interested in a more direct approach you could consider something like ""VFP2MySQL Data Upload program"" or ""Stru2MySQL_2"" both written by Visual FoxPro developers. Search for them on this download page: http://leafe.com/dls/vfp DB-Convert (http://dbconvert.com/convert-foxpro-to-mysql-sync.php) is a commercial product that you might find helpful. Rick Schummer VFP MVP  You can use XBaseJ to access (and even modify write) data from FoxPro databases directly from Java with simple API. This would allow you to have the two applications (the old FoxPro and the new Java one) side by side by constantly synchronizing the data until the new application is ready to replace the old one (e.g. many times the customers still hang on and trust more their old application for a while).  Two steps: DBF => CSV and the CSV => MySQL. To convert DBF(Foxpro tables) to CSV the below link helps a lot http://1stopit.blogspot.com/2009/06/dbf-to-mysql-conversion-on-windows.html CSV => MySQL MySQL itself supports CSV import option (or) to read csv file this link helps http://www.csvreader.com/java_csv.php I read the CSV file using Java CsvReader and inserted the records through program. For that i used PreparedSatement with Batch the below link gives samples for that http://www.codeweblog.com/switch-to-jdbc-oracle-many-data-insert/"
817,A,"oracle jdbc driver version madness Why the heck does Oracle offer a different(!) version of the JDBC driver e.g. ojdbc14.jar for every(!) database version? The files all have different sizes and thus probably different content. background: We get a random and seemingly irreproducible error saying ""invalid number"" when saving data (we guess it's the Timestamp). But it's not any particular statement. Most of the time it saves just fine. Just once a month a harmless looking statement will fail. So i had a closer look at Oracle's download site and noticed that none of the filesizes match despite files sharing the same name. Our product is run on databases maintained by our clients i.e. whatever version and patch the clients have running is what it is. So what driver do we use? The latest (Oracle 11g) - despite the fact that it's usually 9i and 10g databases? Why don't they just link all versions to the same ""one driver suits all"" file? Or are there minute differences leading to effects like our random errors? EDIT: i was mistaken about the 9i databases. The ""version"" in the driver's filename refers to the **Java version** they are intended for not to the driver's version. I made it a habit to save the jar file with the driver's version appended when downloading them e.g. `ojdbc6-11.2.0.3.0.jar`. Just go for the latest drivers. please see the compatibility matrix at http://www.oracle.com/technetwork/database/enterprise-edition/jdbc-faq-090281.html#02_02 Also take in mind that the timestamp datatype is only available since Oracle 10. These drivers ""can talk to"" just about any modern database version. So you're saying i just pick the newest release and keep my fingers crossed that it has all the bug fixes i need? ... and i was wrong about the 9i's. We retired them last year. well i doubt it is a bug in the jdbc driver. i would inspect the code for number casting bugs ""number to string"" ""string to date"" and so on. Are we talking about ORA-01722 invalid number? If so i would check the debugging logs and not care about driver version conflicts. Yes it's ORA-01722. We use PreparedStatements meaning the type conversions are all done by the driver. And the same statement works fine 99.9% of the time. We of course looked at our code first but there seems to be nothing out of the ordinary. Random `ORA-01722` errors are very often caused by relying on *implicit* data type casting. Don't do it. Pass the right values/objects and do never rely on implict casting. Even different NLS settings can cause this error (so it might work on System A but not on System B)  I have similar issue here http://stackoverflow.com/users/1017344/user1017344 It seems like invalid operation inside the JDBC driver itself  When we upgraded our Oracle database from 8.1.7 to 10.2.0 I was able to use the same Oracle jdbc driver (ojdbc14.jar). So their jdbc driver supports quite a few versions at the same time. Of course it's possible that some of the drivers are buggy but the plan is to support more versions at the same time."
818,A,"Connection pooling options with JDBC: DBCP vs C3P0 What is the best connection pooling library available for Java/JDBC? I'm considering the 2 main candidates (free / open-source): Apache DBCP - http://commons.apache.org/dbcp/ C3P0 - http://sourceforge.net/projects/c3p0 I've read a lot about them in blogs and other forums but could not reach a decision. Are there any relevant alternatives to these two? Just got done wasting a day and a half with DBCP. Even though I'm using the latest DBCP release I ran into exactly the same problems as j pimmel did. I would not recommend DBCP at all especially it's knack of throwing connections out of the pool when the DB goes away its inability to reconnect when the DB comes back and its inability to dynamically add connection objects back into the pool (it hangs forever on a post JDBCconnect I/O socket read) I'm switching over to C3P0 now. I've used that in previous projects and it worked and performed like a charm.  Dbcp is production ready if configured properly. It is for example used on a commerce Website of 350000 visitors/ day and with pools of 200 connections. It handles very well timeouts provided you configure it correctly. Version 2 is on progress and it has a background which makes it reliable since Many Production problems have been tackled. We use it for our batch server solution and it has been running hundreds of batches That work on millions of lines in database. Performance tests run by tomcat jdbc pool show it has better performance than cp30.  Have been using DBCP for a couple of years now in production. It is stable survives DB server reboot. Just configure it properly. It only requires a handful of parameters to be specified so don't be lazy. Here is a snippet from our system production code which lists parameters that we explicitly set to make it work: DriverAdapterCPDS driverAdapterCPDS = new DriverAdapterCPDS(); driverAdapterCPDS.setUrl(dataSourceProperties.getProperty(""url"")); driverAdapterCPDS.setUser(dataSourceProperties.getProperty(""username"")); driverAdapterCPDS.setPassword(dataSourceProperties.getProperty(""password"")); driverAdapterCPDS.setDriver(dataSourceProperties.getProperty(""driverClass"")); driverAdapterCPDS.setMaxActive(Integer.valueOf(dataSourceProperties.getProperty(""maxActive""))); driverAdapterCPDS.setMaxIdle(Integer.valueOf(dataSourceProperties.getProperty(""maxIdle""))); driverAdapterCPDS.setPoolPreparedStatements(Boolean.valueOf(dataSourceProperties.getProperty(""poolPreparedStatements""))); SharedPoolDataSource poolDataSource = new SharedPoolDataSource(); poolDataSource.setConnectionPoolDataSource(driverAdapterCPDS); poolDataSource.setMaxWait(Integer.valueOf(dataSourceProperties.getProperty(""maxWait""))); poolDataSource.setDefaultTransactionIsolation(Integer.valueOf(dataSourceProperties.getProperty(""defaultTransactionIsolation""))); poolDataSource.setDefaultReadOnly(Boolean.valueOf(dataSourceProperties.getProperty(""defaultReadOnly""))); poolDataSource.setTestOnBorrow(Boolean.valueOf(dataSourceProperties.getProperty(""testOnBorrow""))); poolDataSource.setValidationQuery(""SELECT 0"");  Another alternative Proxool is mentioned in this article. You might be able to find out why Hibernate bundles c3p0 for its default connection pool implementation?  Here are some articles that show that DBCP has significantly higher performance than C3P0 or Proxool. Also in my own experience c3p0 does have some nice features like prepared statement pooling and is more configurable than DBCP but DBCP is plainly faster in any environment I have used it in. Difference between dbcp and c3p0? Absolutely nothing! (A Sakai developers blog) http://blogs.nyu.edu/blogs/nrm216/sakaidelic/2007/12/difference_between_dbcp_and_c3.html See also the like to the JavaTech article ""Connection Pool Showdown"" in the comments on the blog post. faster in single threaded environments maybe buggy and un-stable and just plain broken anywhere else.  A good alternative which is easy to use is DBPool. ""A Java-based database connection pooling utility supporting time-based expiry statement caching connection validation and easy configuration using a pool manager."" http://www.snaq.net/java/DBPool/ I benchmarked DBPool vs BoneCP. DBPool makes getConnection() synchronized amongst other things and is far far slower than BoneCP (see: http://jolbox.com/forum/viewtopic.php?f=3&t=175).  c3p0 is good when we are using mutithreading projects. In our projects we used simultaneously multiple thread executions by using DBCP then we got connection timeout if we used more thread executions. So we went with c3p0 configuration.  Unfortunately they are all out of date. DBCP has been updated a bit recently the other two are 2-3 years old with many outstanding bugs. To be fair these are not big projects so you should expect fewer and fewer updates in C3P0/DBCP and time goes by. That is true - the last release of C3PO (a 0.9 pre-release) is from May 2007. The latest release of Proxool (a 0.9 pre-release) is from August 2008. The last release of DBCP is also from Apr 2007 but at least its a stable 1.2 release. Is there anything actually maintained out there?  I invite you to try out BoneCP -- it's free open source and faster than the available alternatives (see benchmark section). Disclaimer: I'm the author so you could say I'm biased :-) Wallace UPDATE: As of March 2010 still around 35% faster than the new rewritten Apache DBCP (""tomcat jdbc"") pool. See dynamic benchmark link in benchmark section. Update #2: (Dec '13) After 4 years at the top there's now a much faster competitor : https://github.com/brettwooldridge/HikariCP Would really love get a troubleshoot using BoneCP as a Tomcat Datasource. The main problem I had with this was that it required BoneCP Classes in tomcat's lib dir as well as the log4j and google classes. Doing this made the connection pools work - (it hadn't worked while in WAR) - however it conflicted with the log4j setting of Tomcat and prevented any log output at all from the application which was a dealbreaker... This sounds like a log4j issue more than anything else. Drop me a line on forum.jolbox.com and I'll help you track it down ASAP. 1up BoneCP is brilliant. Switched from C3P0. It even allowed me to remove my dependency on log4jdbc-remix because it allows statement logging out of the box! We faced serious issue while trying to use BoneCP in our spring+hibernate webapp. We were previously using DBCP however just wanted to give BoneCP a try (for performance reason). We have paginated grids (pagination done using jsp framework on full resultset in-memory). On refreshing the same page it seemed to (as per the view grid) fetch inconsistent number of records. With the same code and just the connection provider changed back to DBCP it worked as expected! Since I was rushing on a deadline couldn't dig deep on this however this was the first hand experience unfortunately :( Big thanks for your last update. I've been using BoneCP for 2 years now but now I discovered HikariCP and it's plain awesomeness! :) thanks for the heads up on [HikariCP](https://github.com/brettwooldridge/HikariCP) it's performance seems insane! +1 for updating about something you didn't write being faster! I am getting a lot of dead threads on the newest bonecp release in fedora using postgresql 9.3 as in the pool was returning closed threads. Any chance this will be fixed? It would be a great connection pool without the bug. @AndrewScottEvans Probably best to revert to v0.7.1  For the auto-reconnect issue with DBCP has any tried using the following 2 configuration parameters? validationQuery=""Some Query"" testOnBorrow=true As to [documentation](http://commons.apache.org/dbcp/configuration.html) `testOnBorrow` has default value `true` so if `validationQuery` is defined DBCP will test every connection before it is passed to application.  I was having trouble with DBCP when the connections times out so I trialled c3p0. I was going to release this to production but then started performance testing. I found that c3p0 performed terribly. I couldn't configure it to perform well at all. I found it twice as slow as DBCP. I then tried the Tomcat connection pooling. This was twice as fast as c3p0 and fixed other issues I was having with DBCP. I spent a lot of time investigating and testing the 3 pools. My advice if you are deploying to Tomcat is to use the new Tomcat JDBC pool.  DBCP is out of date and not production grade. Some time back we conducted an in-house analysis of the two creating a test fixture which generated load and concurrency against the two to assess their suitability under real life conditions. DBCP consistently generated exceptions into our test application and struggled to reach levels of performance which C3P0 was more than capable of handling without any exceptions. C3P0 also robustly handled DB disconnects and transparent reconnects on resume whereas DBCP never recovered connections if the link was taken out from beneath it. Worse still DBCP was returning Connection objects to the application for which the underlying transport had broken. Since then we have used C3P0 in 4 major heavy-load consumer web apps and have never looked back. UPDATE: It turns out that after many years of sitting on a shelf the Apache Commons folk have taken DBCP out of dormancy and it is now once again an actively developed project. Thus my original post may be out of date. That being said I haven't yet experienced this new upgraded library's performance nor heard of it being de-facto in any recent app framework yet. Thanks! How about the suggested Proxool alternative? The current version of Hibernate comes with both c3p0 and Proxool. We haven't tried Proxool but I'll be sure to check it out now :) c3p0 has some drawbacks. it sometimes fails to handle connection peaks. things have changed a lot since 4 years when you first posted this answer could you add an update sharing the current scenario if possible ? DBCP does not have regalular maintenance releases... e.g. memory leak fixed 2 years ago (https://issues.apache.org/jira/browse/DBCP-352) is still not in any stable release. This is very sad story which is common for other Apache projects (e.g. log4j). I highly recommend [HikariCP](http://brettwooldridge.github.io/HikariCP/) but then I helped write it."
819,A,"JDBC - Oracle ArrayIndexOutOfBoundsException I'm getting an Exception while trying to insert a row in oracle table. I'm using ojdbc5.jar for oracle 11 this is the sql i'm trying INSERT INTO rule_definitions(RULE_DEFINITION_SYSrule_definition_type rule_namerule_textrule_commentrule_messagerule_conditionrule_active rule_typecurrent_valuelast_modified_bylast_modified_dttm rule_category_sysrecheck_unitrecheck_periodtrackable) VALUES(RULE_DEFINITIONS_SEQ.NEXTVAL???????????????) and i get following Exception. Any help will be appreciated.  java.ljava.lang.ArrayIndexOutOfBoundsException: 15 at oracle.jdbc.driver.OracleSql.computeBasicInfo(OracleSql.java:950) at oracle.jdbc.driver.OracleSql.getSqlKind(OracleSql.java:623) at oracle.jdbc.driver.OraclePreparedStatement.(OraclePreparedStatement.java:1212) at oracle.jdbc.driver.T4CPreparedStatement.(T4CPreparedStatement.java:28) at oracle.jdbc.driver.T4CDriverExtension.allocatePreparedStatement(T4CDriverExtension.java:68) at oracle.jdbc.driver.PhysicalConnection.prepareStatement(PhysicalConnection.java:3059) at oracle.jdbc.driver.PhysicalConnection.prepareStatement(PhysicalConnection.java:2961) at oracle.jdbc.driver.PhysicalConnection.prepareStatement(PhysicalConnection.java:5874) at org.jboss.resource.adapter.jdbc.WrappedConnection.prepareStatement(WrappedConnection.java:232) at com.gehcit.platform.cds.common.util.db.DBWrapper.executeInsertOracleReturnPK(DBWrapper.java:605) I think you should paste the code you are executing this SQL with. In Oracle Metalink (Oracle's support site - Note ID 736273.1) I found that this is a bug in JDBC adapter (version 10.2.0.0.0 to 11.1.0.7.0) that when you call preparedStatement with more than 7 positional parameters then JDBC will throw this error. If you have access to Oracle Metalink then one option is to go there and download mentioned patch. The other solution is workaround - use named parameters instead of positional parameters: INSERT INTO rule_definitions(RULE_DEFINITION_SYSrule_definition_type rule_namerule_textrule_commentrule_messagerule_conditionrule_active rule_typecurrent_valuelast_modified_bylast_modified_dttm rule_category_sysrecheck_unitrecheck_periodtrackable) VALUES(RULE_DEFINITIONS_SEQ.NEXTVAL:rule_definition_type :rule_name:rule_text:rule_comment:rule_message:rule_condition:rule_active :rule_type:current_value:last_modified_by:last_modified_dttm :rule_category_sys:recheck_unit:recheck_period:trackable) and then use preparedStatement.setStringAtName(""rule_definition_type"" ...) etc. to set named bind variables for this query. It works fine unless generated keys are needed to be returned. At least I still get this error. I am using spring's template: KeyHolder keyHolder = new GeneratedKeyHolder(); SqlParameterSource paramSource = new BeanPropertySqlParameterSource(item); simpleJdbcTemplate.getNamedParameterJdbcOperations().update(sql paramSource keyHolder new String[] { ""id"" }); Any ideas? Metalink patch still does not fix the bug in some specific cases. For example this query does not work neither with patched ojdbc nor with most recent ojdbc version (11.2.0.1.0 ): select 1 from dual where 1 in (????????) and 1=:foo However this query works just fine: select 1 from dual where 1 in (???????) and 1=:foo Conclusion: don't mix positional and named parameters to avoid this particular problem.  When you don't have access to the oracle.jdbc.PreparedStatement class (and are forced to use java.sql.PreparedStatement which does not support the methods #setXXXAtName()) the proposed solution to use named parameters is not an option. I've used the PreparedStatement and GeneratedKeyHolder approach for the mandatory values to be passed (luckily less than 7) and used the generated primary key returned to issue a simple SQL update for the remaining values.  Without seeing the code the only thing I can think of is to check that each connection is being accessed in a thread safe manner. The Oracle drivers are usually pretty solid. The only time I've seen weird internal errors like that is when you've got more than one thread accessing the same connection instance and doing weird stuff with it. They aren't thread safe and should be kept to one per thread.  Looks like you're passing in the wrong number of parameters. You should be passing in 15 but you're either sending 16 or 14.  Yeah unless my mouse-cursor-counting is off you're trying to insert 16 values into 15 columns. Try the same thing SQLPlus* you should get ORA-00913: too many values The number of values and columns in the statement match up by my count.  You create a prepared statement with 15 placeholders if i understand correct. So you need to pass an array with 15 parameter values to the call. Maybe you missed one or added a surplus one? or perhaps an extra one... I think it is an extra one too."
820,A,"Data source rejected establishment of connection message from server: ""Too many connections"" I am trying to make connections to my database using connection pooling library: DBPool. Here's my source code. DBUtils.java package DB; import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; import javax.sql.ConnectionPoolDataSource; import snaq.db.ConnectionPool; import com.mysql.jdbc.Driver; /** * @author decorrea */ public class DBUtils { public static String jdbc_driver_name = ""com.mysql.jdbc.Driver""; private static String server_name ; private static String database; private static String username; private static String password; public String getServer_name() { return server_name; } public void setServer_name(String serverName) { server_name = serverName; } public String getDatabase() { return database; } public void setDatabase(String database) { this.database = database; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } /* * Creates a MySQL DB connection from a pool */ public Connection createConnection(ConnectionPool pool){ Connection connection = null; try { // Load the JDBC driver Class driver_class = Class.forName(jdbc_driver_name); Driver driver = (Driver)driver_class.newInstance(); DriverManager.registerDriver(driver); connection = pool.getConnection(); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } catch (InstantiationException e) { e.printStackTrace(); } return connection; } /* * Creates a MySQL DB connection */ public Connection createConnection(){ Connection connection = null; try { // Load the JDBC driver Class driver_class = Class.forName(jdbc_driver_name); Driver driver = (Driver)driver_class.newInstance(); DriverManager.registerDriver(driver); String url = ""jdbc:mysql://"" + server_name + ""/"" + database; connection = DriverManager.getConnection(url); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } catch (InstantiationException e) { e.printStackTrace(); } return connection; } } TwitterAPI.java /** * @author decorrea */ public class TwitterAPI { private static String server_name = ""127.0.0.1""; private static String twitter_databse = ""twitter""; private static String username = ""root""; private static String password = ""password""; public static Connection startDBConnection(String server_name String database String username String password) { //Set DB parameters DBUtils mysql_obj = setDBParams(server_name database username password); String url = ""jdbc:mysql://"" + server_name + ""/"" + database; ConnectionPool pool = new ConnectionPool(""local""1 1 1 180000 url username password); Connection connection = mysql_obj.createConnection(pool); return connection; } public static DBUtils setDBParams(String server_name String database String username String password){ DBUtils mysql_obj = new DBUtils(); mysql_obj.setServer_name(server_name); mysql_obj.setDatabase(database); mysql_obj.setUsername(username); mysql_obj.setPassword(password); return mysql_obj; } public static String getTweets(BigInteger id){ Connection connection = startDBConnection(server_nametwitter_databseusernamepassword); ResultSet resultSet = null; String tweet = new String(); try { Statement statement = connection.createStatement(); String query = SQL_queries.get_tweets_on_id + id.toString(); //Execute the query resultSet = statement.executeQuery(query); while(resultSet.next()){ tweet = resultSet.getString(""content""); } resultSet.close(); statement.close(); } catch (SQLException e) { e.printStackTrace(); } finally{ try { connection.close(); } catch (SQLException e) { // TODO Auto-generated catch block e.printStackTrace(); } } return tweet; } } I am new to the business of connection pooling and decided to do so only because I was receiving a ""Communications Link failure"" without it. Update 1: To add I also tried Apache DBCP and tried this example but still receive the same error. org.apache.commons.dbcp.SQLNestedException: Cannot create PoolableConnectionFactory (Data source rejected establishment of connection message from server: ""Too many connections"") at org.apache.commons.dbcp.BasicDataSource.createPoolableConnectionFactory(BasicDataSource.java:1549) at org.apache.commons.dbcp.BasicDataSource.createDataSource(BasicDataSource.java:1388) at org.apache.commons.dbcp.BasicDataSource.getConnection(BasicDataSource.java:1044) at Twitter.TwitterAPI.startDBConnection(TwitterAPI.java:55) at Twitter.TwitterAPI.getTweets(TwitterAPI.java:84) at Twitter.TwitterAPI.main(TwitterAPI.java:235) Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: Data source rejected establishment of connection message from server: ""Too many connections"" at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:45) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:528) at com.mysql.jdbc.Util.handleNewInstance(Util.java:409) at com.mysql.jdbc.Util.getInstance(Util.java:384) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1015) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:989) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:984) at com.mysql.jdbc.MysqlIO.doHandshake(MysqlIO.java:1105) at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2186) at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:787) at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:49) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:45) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:528) at com.mysql.jdbc.Util.handleNewInstance(Util.java:409) at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:357) at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:285) at org.apache.commons.dbcp.DriverConnectionFactory.createConnection(DriverConnectionFactory.java:38) at org.apache.commons.dbcp.PoolableConnectionFactory.makeObject(PoolableConnectionFactory.java:582) at org.apache.commons.dbcp.BasicDataSource.validateConnectionFactory(BasicDataSource.java:1556) at org.apache.commons.dbcp.BasicDataSource.createPoolableConnectionFactory(BasicDataSource.java:1545) ... 5 more Exception in thread ""main"" java.lang.NullPointerException at Twitter.TwitterAPI.getTweets(TwitterAPI.java:108) at Twitter.TwitterAPI.main(TwitterAPI.java:235) I also checked the max_connections variable in the my.ini file in MySQL. Here's it's value: The maximum amount of concurrent sessions the MySQL server will allow. One of these connections will be reserved for a user with SUPER privileges to allow the administrator to login even if the connection limit has been reached. max_connections=100 The show processlist command on the MySQL terminal shows 101 processes in sleep. Any kind of help/comments will be appreciated Update 2 -- Solution:: So I figured out the solution. I hadn't mentioned the port name in the url connection to the database. String url = ""jdbc:mysql://"" + server_name + ""/"" + database; Probably hence it led to many leaking connections. Once done I tried with the example given here. It now doesn't throw any error. Thanks to BalusC as I figured this out only due to his comment on changing the port number on MySQL. To add the way to change the MySQL port number is NOT by changing the my.ini file but by running the MySQL instance config wizard under Start -> Programs -> MySQL Server 5.1 -> MySQL Server Instance Config Wizard. It was also interesting to note the code didn't throw any error when the port number wasn't specified and the program ran smoothly. Probably JDBC connects to 3306 by default. If anyone has any particular idea about the same please share. For my complete source code see my answer below Any particular reason for the edit ? you used ` ` which caused nested scrollbars in code. Just indent with 4 spaces or select and then press `010101` button in message editor toolbar or `Ctrl+K` key to format code nicely. BalusC Thanks for the tip. Will keep in mind. So I figured out the solution. I hadn't mentioned the port name in the url connection to the database. String url = ""jdbc:mysql://"" + server_name + ""/"" + database;  Probably hence it led to many leaking connections. Once done I tried with the example given here. It now doesn't throw any error. Thanks to BalusC as I figured this out only due to his comment on changing the port number on MySQL. To add the way to change the MySQL port number is NOT by changing the my.ini file but by running the MySQL instance config wizard under Start -> Programs -> MySQL Server 5.1 -> MySQL Server Instance Config Wizard. It was also interesting to note the code didn't throw any error when the port number wasn't specified and the program ran smoothly. Probably JDBC connects to 3306 by default. If anyone has any particular idea about the same please share. For benefit of folks here's the source code: DBUtils.java package DB; import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; import javax.sql.DataSource; import org.apache.commons.dbcp.BasicDataSource; import com.mysql.jdbc.Driver; /** * @author decorrea * */ public class DBUtils { public static String jdbc_driver_name = ""com.mysql.jdbc.Driver""; private static String server_name ; private static String database; private static String username; private static String password; private static int maxActive = 20; private static int maxIdle = 2 ; public String getServer_name() { return server_name; } public void setServer_name(String serverName) { server_name = serverName; } public String getDatabase() { return database; } public void setDatabase(String database) { this.database = database; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } public static DataSource getDataSource(String server_name String database String username String password){ BasicDataSource datasource = new BasicDataSource(); datasource.setDriverClassName(jdbc_driver_name); String url = ""jdbc:mysql://"" + server_name + ""/"" + database; System.out.println(url); datasource.setUsername(username); datasource.setPassword(password); datasource.setUrl(url); datasource.setMaxActive(maxActive); datasource.setMaxIdle(maxIdle); return datasource; } }  TwitterAPI.java public class TwitterAPI { private static String server_name = ""localhost:7777""; private static String twitter_databse = ""twitter""; private static String username = ""root""; private static String password = ""password""; public static String twitter_unique_usernames_file = ""twitter_unique_usernames_file.txt""; public static String language_model_file = ""C:\\de\\JARS\\lingpipe-4.0.0\\demos\\models\\langid-leipzig.classifier""; public static DataSource dataSource = DBUtils.getDataSource(server_name twitter_databse username password); public static Connection startDBConnection(String server_name String database String username String password) { //Set DB parameters //DBUtils mysql_obj = setDBParams(server_name database username password); Connection connection = null; //connection = mysql_obj.createConnection(); try { connection = dataSource.getConnection(); } catch (SQLException e) { e.printStackTrace(); } return connection; } public static DBUtils setDBParams(String server_name String database String username String password){ DBUtils mysql_obj = new DBUtils(); mysql_obj.setServer_name(server_name); mysql_obj.setDatabase(database); mysql_obj.setUsername(username); mysql_obj.setPassword(password); return mysql_obj; } public static String getTweets(BigInteger id){ Connection connection = startDBConnection(server_nametwitter_databseusernamepassword); ResultSet resultSet = null; String tweet = new String(); try { Statement statement = connection.createStatement(); String query = SQL_queries.get_tweets_on_id + id.toString(); //Execute the query resultSet = statement.executeQuery(query); while(resultSet.next()){ tweet = resultSet.getString(""content""); } resultSet.close(); statement.close(); } catch (SQLException e) { e.printStackTrace(); } finally{ try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } return tweet; }  Hope this helps. Interesting I didn't expect that omitting the port number would lead to this behaviour... Does it also happen when you don't use a connection pool? BalusC With port number + connection pool : no issues. Without port number + connection pool : can't connect. Without port number + Without connection pool : Can run for a limited time but soon exceeds max_number_of_connections. With port number + without connection pool: haven't tried as yet. For whoever is still wondering where this port was set check the `server_name` field in `TwitterAPI`  org.apache.commons.dbcp.SQLNestedException: Cannot create PoolableConnectionFactory (Data source rejected establishment of connection message from server: ""Too many connections"")  This indicates that something is leaking connections. I.e. something keeps acquiring (opening) connections without ever closing them and/or returning to connection pool. Restarting the DB so that it can hard-close all opened connections should temporarily fix the issue. Fixing something so that it is properly closing the connection after use should permanently fix the issue. Although the posted JDBC code is not following the optimal idiom it doesn't look like to be the cause of leaking connections. Probably the DB is already running for hours/days and you've during earlier tests acquired too many connections without closing them so that the DB is running out of them. BalusC I do close the connections in the getTweets() function in the finally block. It's the only place where I am ""making"" a connection. What else could be leaking ? Restart DB and reobserve if the problem would occur again. I brought the last paragraph of my answer in during an edit which you might have missed. BalusC Yes I did miss it. 1. I have restarted my DB multiple times and it doesn't have any effect 2. The code isn't optimal agreed but I'm more curious on the problem 3. As told earlier I have checked the connections via MySQL but none of them seem to be an issue. Well it much look like that *something else* is using the DB. Try changing the DB port number (so that something else cannot connect it without being reconfigured) and retry in Java. BalusC I tried changing the port number and tried using Java to no success. :-( BalusC I figured out the solution. Updated in the question itself. Thanks for the help. Just curious to know if this is you : http://balusc.blogspot.com/ ? Cheers. Yes it's me. Also see my profile's homepage :)"
821,A,How commons dbcp (and other connection pools) manage open statements and resultsets? Specifically when I return a connection to the pool does dbcp (and other connection pools) close the statements and resultsets for me? Or should I be closing these myself? OK I see that statements are closed by dbcp in DelegatingConnection.passivate() and DelegatingStatement.close() closes the resultsets.
822,A,"How can I abort a running JDBC transaction? Is there a way to prematurely abort a transaction? Say I have sent a command to the database which runs five minutes and after four I want to abort it. Does JDBC define a way to send a ""stop whatever you are doing on this connection"" signal to the DB? I am guessing what you want to do is prevent your application blocking on long running queries / transactions. To this end JDBC supports the concept of a query time out. You can set the query timeout using this: java.sql.Statement.setQueryTimeout(seconds) And handle the SQLException thrown by the execute() method by rolling back the transaction (of course that would only work if you have autocommit set to false and your JDBC driver supports Statement.cancel()). I think this is a better and simpler approach since it allows the tread to ""clean itself"" versus having an outside thread do it (which always involves a new set of issues).  As mentioned by james Statement.cancel() will cancel the execution of a running Statement (select update etc). The JDBC docs specifically say that Statement.cancel() is safe to run from another thread and even suggests the usage of calling it in a timeout thread. After canceling the statement you're still stuck with the job of rolling back the transaction. That is not documented as being safe to run from another thread. The Connection.rollback() should happen in the main thread doing all the other JDBC calls. You can handle that after the canceled Statement.execute...() call completes with a JDBCException (due to the cancel).  Check out Statement.cancel().  No you can't abort it using standard JDBC. You might try to check if your particular RDBMS define some extension to suppot it. I've had vendors tell me this. If a particular JDBC driver doesn't implement Statement.cancel() that's a quality-of-implementation problem. It's there and documented for that use case."
823,A,"ClassNotFoundException com.mysql.jdbc.Driver This question might have asked here number of times . After doing some google search for the above error and doing some update I can't understand why I'm still getting that error. I've already put my driver-- mysql-connector-java-5.1.5-bin in the classpath: Java_Home\jre\lib\ Java_Home\jre\lib\ext\ Java_Home\lib and the code which I'm using to connect to mysql database is: try{ Class.forName(""com.mysql.jdbc.Driver""); Connection con=DriverManager.getConnection(""jdbc:mysql://localhost:3306/mail""""root""""""); Statement stmt = con.createStatement(); ResultSet rs = stmt.executeQuery(""select message_body from deadletter""); String dbtime; while (rs.next()) { dbtime = rs.getString(1); System.out.println(dbtime); } con.close(); } catch (SQLException e) { System.out.println(""Connection Failed! Check output console""); e.printStackTrace(); } } and the complete stacktrace of the above exception is: java.lang.ClassNotFoundException: com.mysql.jdbc:Driver at java.net.URLClassLoader$1.run(URLClassLoader.java:200) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:307) at java.lang.ClassLoader.loadClass(ClassLoader.java:307) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301) at java.lang.ClassLoader.loadClass(ClassLoader.java:252) at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:320) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:169) at mail.main(mail.java:114) Now what's wrong I'm doing here? So what exactly does your classpath look like? You must put the JAR file (mysql-connector-java-5.1.5-bin.jar) in the classpath. The exception message has a colon in the class name which I don't believe should happen. Ok..May be i can also contribute my solution.. Right click on project -properties -->Deployment assembly...there you need to add the mysql-connector-java.jar and apply it...which makes your prject configured with web-Libraries that has this sql connector...This worked for me.. I hope this works for you guys as well  I keep the mysql-connector jar with my project rather than in Javahome. As a result you can be sure it can be found by being sure its in the local classpath. A big upside is that you you can more the project to another machine and not have to worry about (or forget) to set this up again. I personally like including it in version control.  The most common cause is that you have some conflict in where your classes are loaded from. For example if you have 2 locations and one has JDBC drivers and the other one not then if your classloader loads from the 1st location and some class from the 1st location wants to use the driver - the driver is not there. So look for the duplicate JARs that are using your driver You're damn correct! Thankyou! Glad you've been able to solve it. Stuff like that can be very frustrating @Bostone I thought that the driver went with [Apache James itself](http://wiki.apache.org/james/V3ConfigTutorial).  Ok i find solution change the path of mysql-conector-java.jar to the follow path: ProjectName/WebContent/Web-inf/lib/mysql-conector-java.jar Of course the you add other time the conector to project and delete it early.  I too struggled with the same problem and finally got the solution for it. Just copy the MySql-Connector.jar in apache tomcat's lib folder and then remove the jar in project's lib folder and then run the project. ^+1 works for me thx.. +1 works for me too.. Is this bug?  What did you put exactly in lib jre/lib or jre/lib/ext? Was it the jar mysql-connector-java-5.1.5-bin.jar or something else (like a directory)? By the way I wouldn't put it in lib jre/lib or jre/lib/ext there are other ways to add a jar to the classpath. You can do that by adding it explicitly the CLASSPATH environment variable. Or you can use the -cp option of java. But this is another story. +1 for this - no code should ever be added to these directories. @duffymo Agreed even the endorsed mechanism is a mess.  I have the same problem but I found this after a long search: http://www.herongyang.com/JDBC/MySQL-JDBC-Driver-Load-Class.html But I made some change. I put the driver in the same folder as my ConTest.java file and compile it resulting in ConTest.class. So in this folder have ConTest.class mysql-connector-java-5.1.14-bin.jar and I write this java -cp .;mysql-connector-java-5.1.14-bin.jar ConTest This way if you not use any IDE just cmd in windows or shell in linux.  set the path to C:\Program Files\MySQL\MySQL Tools for 5.0\java\lib\mysql-connector-java-5.0.4-bin.jar"
824,A,"How do I write StoredProcedure sub-classes to call Oracle functions? I've written the following Spring JDBC API StoredProcedure sub-class: class GetLdapPropertiesStoredProcedure extends StoredProcedure { protected GetLdapPropertiesStoredProcedure(JdbcTemplate jdbcTemplate) { super(jdbcTemplate ""get_ldap_properties""); setFunction(true); declareParameter(new SqlReturnResultSet(""rs"" new ProductPropertiesMapper())); declareParameter(new SqlParameter(""in_ldap_code"" Types.VARCHAR)); compile(); } public Properties execute(String productCode) { HashMap input = new HashMap(); input.put(""in_ldap_code"" productCode); Map results = execute(input); Collection<Map.Entry<ObjectObject>> entries = (Collection<Map.Entry<ObjectObject>>) results.get(""rs""); Properties properties = new Properties(); properties.entrySet().addAll(entries); return properties; } } Which calls the following Oracle function: FUNCTION get_ldap_properties ( in_ldap_code IN VARCHAR2 ) RETURN rowset; However when I call the above I get the following Oracle exception: java.sql.SQLException: ORA-06550: line 1 column 13: PLS-00306: wrong number or types of arguments in call to 'GET_LDAP_PROPERTIES' ORA-06550: line 1 column 7: PL/SQL: Statement ignored Can anyone please see what I'm doing wrong? This is the statement you'll get for a function call (i.e. with setFunction(true)) : { ? = call get_ldap_properties(?) } So you need to add a first out parameter for the return value. Try this instead: setFunction(true); // The return value parameter must be the first parameter that you declare. declareParameter(new SqlOutParameter(""RETURN_VALUE"" OracleTypes.CURSOR new ProductPropertiesMapper())); Edit: Fixed the syntax to deal with the function's return value and the rowset when using Oracle according to Thomas Risberg's answer on Spring Community Forums. Thanks for the answer but that doesn't tell me how to fix the rowset stuff. This answers the question: http://forum.springframework.org/showthread.php?p=231407 There were 2 things here : adding a SqlOutParamater as **first** parameter and using the good Type. I don't know why I wrote Types.VARCHAR... I'll fix the answer. Thanks for that answer."
825,A,"Is it possible to create a jdbc connection without a password (using postgresql 'trust')? I am using jdbc to connect to a postgresql database in a java application (actually the app is written in Groovy). I have postgresql set up to use the 'trust' authentication method. Is it possible to open a jdbc connection without specifying a password? When I try to use the normal constructor with a blank password it fails with Exception in thread ""Thread-2"" org.postgresql.util.PSQLException: FATAL: password authentication failed for user ""myuser"" Even though from the command line this works fine psql -U myuser mydatabase Welcome to psql 8.3.5 the PostgreSQL interactive terminal. Type: \copyright for distribution terms \h for help with SQL commands \? for help with psql commands \g or terminate with semicolon to execute query \q to quit @Milen sorry misread First check the authentication with psql but from the same machine from which you're trying to connect with JDBC - I have the feeling the ""trust"" authentication is enabled only for local connections and you're trying to connect with JDBC from another machine. @Milen ""trust"" authentication (i.e. no password) can be used also for ip connections @leonbloy - please re-read what I've written. Already answered but: When you connect using the psql client program and don't specify a host (-h) the default is to use a local socket (at least in Linux). In JDBC instead you will use a TCP/IP socket. Then to check your connection problem you should invoke psql with the same settings you are using in JDBC host included. For example  psql -U myuser -h 127.0.0.1 mydatabase # uses TCP/IP Which is not the same as  psql -U myuser mydatabase # uses local socket (non TCP/IP)  GlassFish at least including version 3.1 has an issue with specifying empty JDBC passwords.  Yes you can. Note that Postres JDBC driver always uses IP sockets (host in pg_hba.conf) even if database is on the local machine then psql can use local sockets (local in pg_hba.conf). So if psql works with trust authentication and JDBC doesn't you probably should configure trust authentication for IP sockets see documentation. Thanks for the link. So can I use the normal jdbc constructor and just pass in a blank password? Yes you can. It works if Postgres is properly configured."
826,A,"Java JDBC Lazy-Loaded ResultSet Is there a way to get a ResultSet you obtain from running a JDBC query to be lazily-loaded? I want each row to be loaded as I request it and not beforehand. Without knowing more about the problem you're trying to solve I may be making a sweeping generalization but this sounds like quite a strange thing to do with potential performance issues if the driver implementation actually does do remote call for each row (which as pointed out in the answers below won't necessarily be the case). You will find this a LOT easier using hibernate. You will basically have to roll-your-own if you are using jdbc directly. The fetching strategies in hibernate are highly configurable and will most likely offer performance options you weren't even aware of. wow downvotes for this? I think the down votes are because it doesn't answer the question not because the advice is wrong per se.  Short answer: Use Statement.setFetchSize(1) before calling executeQuery(). Long answer: This depends very much on which JDBC driver you are using. You might want to take a look at this page which describes the behavior of MySQL Oracle SQL Server and DB2. Major take-aways: Each database (i.e. each JDBC driver) has its own default behavior. Some drivers will respect setFetchSize() without any caveats whereas others require some ""help"". MySQL is an especially strange case. See this article. It sounds like if you call setFetchSize(Integer.MIN_VALUE) then it will download the rows one at a time but it's not perfectly clear. Another example: here's the documentation for the PostgreSQL behavior. If auto-commit is turned on then the ResultSet will fetch all the rows at once but if it's off then you can use setFetchSize() as expected. One last thing to keep in mind: these JDBC driver settings only affect what happens on the client side. The server may still load the entire result set into memory but you can control how the client downloads the results. Hi Nick. Thanks for your comment. I tried to re-phrase the answer to explain that in theory setFetchSize() is the answer but again it depends on which database you're using. This *might* be the right answer if for example the OP is using Oracle. With the implication being that you can't rely on the one row retrieved per call to ResultSet.next() and therefore imho this probably isn't the solution to the problem you're trying to solve.  Could you not achieve this by setting the fetch size for your Statement to 1? If you only fetch 1 row at a time each row shouldn't be loaded until you called next() on the ResultSet. e.g. Statement statement = connection.createStatement(); statement.setFetchSize(1); ResultSet resultSet = statement.executeQuery(""SELECT .....""); while (resultSet.next()) { // process results. each call to next() should fetch the next row } Could you please describe how to do this? I added some sample code. This will only work for sequential iteration and will not allow fetching of data outside the initial statement scope. But its a good suggestion for use in trivial cases.  I think what you would want to do is defer the actually loading of the ResultSet itself. You would need to implement that manually."
827,A,"A very very strange error ClassCastException. PreparedStatement's setInt method Can anybody tell me why is this method not working? String strQuery = ""Insert Into cust_subs (CustomerIdSubscriptionId) Values (??)""; PreparedStatement objPreparedStatement = Utils.getPreparedStatement(objConnection strQuery); objPreparedStatement.setInt(2 currentSubscriptions.get(0) ); where currentSubscriptions is: List<Integer> currentSubscriptions; I get this error even though it is Integer list:- SEVERE: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer Assume that connection object already exists. And i am very sure that currentSubscriptions is not null else i wouldn't have got this error. If instead of using List i hardcode like this: objPreparedStatement.setInt(21); It works. I have even printed the values of List using System.out.println and it's perfectly fine. They are integers only. Don't know why is it treating them as Strings. I have even tried Integer.parseInt on list's item. Still it gives me the same error. This is one of the funniest errors I have ever faced. Thanks in advance :) EDIT :- Atleast this should work. But even this is not working :-  int intSubscriptionId = Integer.parseInt( currentSubscriptions.get(0).toString()); objPreparedStatement.setInt(2 intSubscriptionId ); EDIT 2: Posting whole code :- package beans; import entities.Customer; import entities.Subscription; import java.io.IOException; import java.io.Serializable; import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Savepoint; import java.util.ArrayList; import java.util.List; import javax.faces.bean.ManagedBean; import javax.faces.bean.ViewScoped; import javax.faces.context.FacesContext; import javax.servlet.http.HttpServletRequest; import misc.Utils; @ManagedBean @ViewScoped public class AddSubscriptionBean implements Serializable { private Customer customer; private List<Integer> currentSubscriptions; private List<Subscription> subscriptionList; public List<Subscription> getSubscriptionList() { return subscriptionList; } public void setSubscriptionList(List<Subscription> subscriptionList) { this.subscriptionList = subscriptionList; } public List<Integer> getCurrentSubscriptions() { return currentSubscriptions; } public void setCurrentSubscriptions(List<Integer> currentSubscriptions) { this.currentSubscriptions = currentSubscriptions; } public Customer getCustomer() { return customer; } public void setCustomer(Customer customer) { this.customer = customer; } /** Creates a new instance of AddSubscriptionBean */ public AddSubscriptionBean() throws IOException SQLException { Connection objConnection = null; try { HttpServletRequest objHttpServletRequest = (HttpServletRequest) FacesContext.getCurrentInstance().getExternalContext().getRequest(); int intCustomerId = Integer.parseInt(objHttpServletRequest.getParameter(""cid"")); String strQuery = ""Select * from customer Where CustomerID = "" + intCustomerId; ResultSet objResultSet = Utils.executeResultSet(objConnection strQuery); if (objResultSet.next()) { String strFirstName = objResultSet.getString(""FirstName""); String strLastName = objResultSet.getString(""LastName""); customer = new Customer(intCustomerId strFirstName strLastName); } currentSubscriptions = new ArrayList<Integer>(); for (Subscription objSubscription : customer.getSubscriptionList()) { currentSubscriptions.add(objSubscription.getSubscriptionId()); } subscriptionList = new ArrayList<Subscription>(); strQuery = ""Select * from subscription""; objResultSet = Utils.executeResultSet(objConnection strQuery); while (objResultSet.next()) { int intSubscriptionId = objResultSet.getInt(""SubscriptionId""); String strSubsriptionTitle = objResultSet.getString(""Title""); String strSubsriptionType = objResultSet.getString(""Type""); Subscription objSubscription = new Subscription(intSubscriptionId strSubsriptionTitle strSubsriptionType); subscriptionList.add(objSubscription); } } catch (Exception ex) { ex.printStackTrace(); FacesContext.getCurrentInstance().getExternalContext().redirect(""index.jsf""); } finally { if (objConnection != null) { objConnection.close(); } } } public void save() throws SQLException { Connection objConnection = null; Savepoint objSavepoint = null; try { objConnection = Utils.getConnection(); objConnection.setAutoCommit(false); objSavepoint = objConnection.setSavepoint(); String strQuery = ""Delete From cust_subs Where CustomerId = "" + customer.getCustomerId(); if (!Utils.executeQuery(objConnection strQuery)) { throw new Exception(); } strQuery = ""Insert Into cust_subs (CustomerIdSubscriptionId) Values (??)""; int intCustomerId = customer.getCustomerId(); PreparedStatement objPreparedStatement = Utils.getPreparedStatement(objConnection strQuery); for (int intIndex = 0; intIndex < currentSubscriptions.size(); intIndex++) { objPreparedStatement.setInt(1 intCustomerId); int intSubscriptionId = Integer.parseInt( currentSubscriptions.get(0).toString()); objPreparedStatement.setInt(2 intSubscriptionId ); objPreparedStatement.addBatch(); } objPreparedStatement.executeBatch(); objConnection.commit(); } catch (Exception ex) { ex.printStackTrace(); if (objConnection != null) { objConnection.rollback(objSavepoint); } } finally { if (objConnection != null) { objConnection.close(); } } } } This is my JSF page :- <?xml version='1.0' encoding='UTF-8' ?> <!DOCTYPE html PUBLIC ""-//W3C//DTD XHTML 1.0 Transitional//EN"" ""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd""> <html xmlns=""http://www.w3.org/1999/xhtml"" xmlns:h=""http://java.sun.com/jsf/html"" xmlns:f=""http://java.sun.com/jsf/core"" xmlns:msc=""http://mscit/jsf""> <h:head> <title>Facelet Title</title> </h:head> <h:body> <center> <h:form> <h1>Add Subscription</h1> <b> Customer Name :</b> <h:outputText value=""#{addSubscriptionBean.customer.firstName} #{addSubscriptionBean.customer.lastName}""/> <h:selectManyCheckbox value=""#{addSubscriptionBean.currentSubscriptions}""> <f:selectItems value=""#{addSubscriptionBean.subscriptionList}"" var=""row"" itemLabel=""#{row.title}"" itemValue=""#{row.subscriptionId}"" /> </h:selectManyCheckbox> <h:commandButton value=""Save"" actionListener=""#{addSubscriptionBean.save}""/> </h:form> </center> </h:body> </html> Please look at the h:selectManyCheckbox of JSF. JSF internally passes all the checkboxes that i have checked to my List. I think JSF is converting my integer list to string. Is `setInt` actually where your error is occurring? `PreparedStatement.setInt` has only one overload taking two integer arguments; your `List.get` should autounbox and it should work fine. But what about `Utils.getPreparedStatement`? Is that a custom method or in a custom library? Searching for that specific static method on Google only returns this page. What does `currentSubscriptions.get(0).getClass().getName()` return? @Paul `currentSubscriptions.get(0)` will cause a `ClassCastException`. He needs to assign to a `List` as I've shown in my answer. Hi Brian yes that is just my custom method. I found the problem but not the solution. Can you post the whole stacktrace? It's possible to put Strings into a List<Integer> if you use unsafe operations: List<Integer> intList = new ArrayList<Integer>(); List list = intList; list.add(""1""); intList and list hold references to the same list which now contains a string. As you've seen you get a ClassCastException upon trying to extract the element from intList. Java generics work using hidden casting and you can defeat the type-checking. To test this assign to a List then print the class of every element: List currentSubscriptionsUnsafe = currentSubscriptions; for(Object o : currentSubscriptionsUnsafe) { System.out.println(o.getClass()); } EDIT: I'm not familiar with JSF but I think your guess is correct. One solution is to make currentSubscriptions a List<String> everywhere (which JSF seems to expect). Then get(0) will return a String which you can parse into an Integer. There may be a cleaner method but this should work. Hi BalusC thanks for your valuable comments. Did you later on happen to give a thought on creating JSF composite components using JQuery? Netbeans 6.9 is out and it's fine. But i am not doing any such thing. How do i get rid of this? What changes do i need to make instead of list? @Nitesh print the class of every element using that code. That will tell you if this is the issue. Hi Matthew Yes indeed this is the problem. I get this :- `INFO: class java.lang.String`. How can i solve this? Why is it being oversmart? even though i pass integers in it? @Nitesh post more of your code (anything somehow connected to `currentSubscriptions`). You clearly have an unsafe reference somewhere and you are adding a String using that. Hi Matthew Flaschen please read my edited post. Atleast the `edited` code should work? But even that is not working. @Nitesh no. Because `currentSubscriptions` is a `List` reference `get(0)` has a hidden cast to `Integer`. So you're trying to cast a `String` to an `Integer` then call `toString`. But the cast is still not allowed. You need to prevent the `String` from being added in the first place. Please show more code specifically any code related to this list. Great! Works :). But i still didn't understand your above comment Integer.parseInt will return a primitive type value and it is always a int only. Don't know why just changing List from Integer to String works. He is refering to currentSubscriptions.get(0) not parseInt. The get method will try to convert the String's in your List to integers which it cannot do. So making the list List and calling get on the list will not try to convert to Integers. @BobTurbo i was talking about my edited code. Can you tell me how can this ever return anything other than int? `int intSubscriptionId = Integer.parseInt(currentSubscriptions.get(0).toString());`? I always thought Integer.parseInt will always return a primitive type `int`. No matter what the internal references are but Integer.parseInt should always return a primitive `int` type value. I must admit this is one of the most strange errors i have faced till today and not easy for me to digest. It will always return an int but int intSubscriptionId = Integer.parseInt(currentSubscriptions.get(0).toString()); is now where the error occurs (instead of the next line). As the error is in currentSubscription.get(0). So you have just shifted the error up a line. @Nitesh when `currentSubscriptions` was a `List` that line internally became: `int intSubscriptionId = Integer.parseInt(((Integer)(currentSubscriptions.get(0))).toString());`. You were still casting a `String` to an `Integer` which is an error. Thanks Matthew Flaschen. Got it! While technically correct the proposed solution is in JSF context not a real solution but more a workaround. I certainly wouldn't use it.  You need to instruct h:selectManyCheckbox to convert the values to Integer by specifying javax.faces.Integer as converter. Generic types are namely unknown in EL and it treats the parameters by default as String. <h:selectManyCheckbox converter=""javax.faces.Integer""> No need to use List<String> instead which would only lead to more weaktype clutter in the bean. Thanks exactly what i was looking for!"
828,A,"JDBC driver for Oracle 10G XE I have installed Oracle 10G XE. I want to connect to it using JDBC . Which driver should i use for it and from where can i download it ? Thank You. http://www.oracle.com/technology/software/tech/java/sqlj_jdbc/index.html You generally want the latest JDBC drivers they will work with older versions of the database as well. Or to be on the safe side match the JDBC version with your DB. In fact the correct version of the driver should be in the Oracle install tree somewhere after the install is completed.  On the machine you have installed the server Oracle JDBC drivers are in ORACLE_HOME/jdbc/lib. Just put ojdbc14.jar on your classpath (ojdbc14_g.jar is the same as ojdbc14.jar except that classes were compiled with ""javac -g"" and contain some tracing information). EDIT: According to Oracle Database 10g Release 2 (10.2.0.4) JDBC Drivers ojdbc14.jar contains classes for use with JDK 1.4 and 1.5 (and I don't see why it wouldn't work with a JDK 6 some features of JDBC 4.0 won't just be available). Some newer drivers are available at Oracle Database 11g Release 2 JDBC Drivers but I don't really see the difference between ojdbc14.jar and ojdbc15.jar (except that ojdbc15.jar requires a JDK 5+): they are both JDBC 3.0 driver so I think it's just a matter of end of life support for ojbdc14.jar. If you want JDBC 4.0 support you'll need ojdbc16.jar though. Have a look at the Oracle JDBC FAQ if you want more details.  According to this getting started guide you need the Oracle Express client which can be found here You do not need Oracle Express client if you want to use JDBC. There is a pure-Java JDBC driver.  You want to choose a JDBC driver that matches both your version of Oracle and the JDK you're using. ojdbc14.jar is for JDK 1.4; there are newer versions for at least JDK 5 that I know of. I'm not sure if there's a JDBC driver for JDK 6. Use the best match to your situation that Oracle makes available."
829,A,"When to shut down message processing in case of queue / database failure? This is more of a best practice question for the common case of an application receiving messages persisting them to a database and possibly sending messages as a result. Assume transactionality sorts out atomic commit; what is a good policy on when to shut the application down altogether? If the database fails the application could get flooded by messages which it will end up rejecting. Should it give up immediately? If the outbound messaging service fails the database will be flooded with rollbacks. Again is it best to give up immediately? More brownie points for any hints on how to best force a spring app to shut down in this case as the default listener contain will catch any runtime exception and keep running. From what I understand you're looking for following: Do not loose messages from inbound queue just because application cannot process them. When to stop processing if errors occur during processing. First of all it's important to analyze the infrastructure you're dealing with and the kind of situations you'll have to deal with. Typical down times and how often they occur in various tiers of the system. How reliable is the network is you db a rac server etc. JMS already provides for mechanisms of retry. If message processing fails send it back to queue until retires expire. This makes sense only if coupled with a delay so that flooding doesn't occur. If a small delay will not affect the transaction I would recommend using messages with a delay. depending on your JMS provider this is supported custom to container. Using a dead letter or exception queue when message from inbound queue cannot be processed can help with loss of messages. Again you can be the best judge of situation. You can define a property as how many many consecutive sends to dead letter queue constitute a shut down condition. You can tweak it during your system test to avoid false positives. Dead letter queue is very interesting to me and I would like to get more information about it. Cracked_all how are your approaches to tweak this setting? Can you please elaborate more you that? @cracked_all Thanks for the explaining the scenario. Though I was really interested in your methods or approaches to set the value of retry or delays? Do run some benchmarking analysis and tweak that accordingly? And my second question would be what your strategy is when your redirected Queue fails as well? Do you have some kind of backup plan? Thanks @xcut In the current production system I'm working on we have a MaxDeliveryCnt of 10 and a delay of 10 seconds. TO give a perspective this is a 24x7 system spread across the globe with 3-tier structure handling between 2K-3K unique transactions daily. @paradisonoir I'm not sure what is that you need. Depending on your app server the implementation details may vary widely. Currently I use another JMS queue to which the messages are redirected if they cannot be processed (after retry count is reached). How the values for retry counts and delay are reached is again dependent on your current system architecture both s/w and h/w. More details on what you're looking for will help? Thank you for answering! I'm not worried about point 1 - the insert into the DB and acknowledgement of the message are already transactional in my setup (and duplicate submission detection is there as well). I was really looking to gather opinions on how to handle point 2 i.e. what other people have done. @ paradisonoir: If retry queue fails it's the queue that should go down not the application. Which should alert queue support folks to look into why that queue is failing and resolve the issue. @cracked_all thanks that's useful; I guess I will have to make my own calculations and it will depend on scenarios. Some of them will involve thousands of messages per second in those cases I guess failing quickly might be the only option. @paradisonoir I don't have a comment on the question you ask about setting the retry values/delays (you can configure those in a queue specific way); what I can say is that the pattern discussed doesn't get around queue failure only database failure. The retry queue is a transparent JMS queue that is usually handled by the same broker. So if the main queue fails so will the retry queue. You could make your behaviour application specific an switch to a completely different queue I suppose. @xcut: To handle spikes you need to constantly monitor your application load and make sure by load testing that your application can handle 2-3 times more capacity than max load you have received in production. @paradisonoir No we didn't run any benchmarks but have based it on two factors: 1. Since the transactions are supposed to be instantaneous what is an acceptable delay for users before they notice a lag. 2. How many retries can generally ensure that message is not rejected due to spike in network/cpu/hdd usage. If processing messages from retry queue fails then we log them to a text file (and even if that's not available then the you have more serious problems than worry abt messages). @xcut I would agree if the volume per second is so high failing quickly may be the best option.However keep in mind that sudden network spikes may cause your queue to shutdown for no reason. You may want to take that into account before you decide on shutdown counter. On second thoughts inserting a deferred queue in between main and dead letter queue may give you a change to process transactions with a delay if they cannot be processed immediately.  As cracked_all also mentioned it is not recommended to give up immediately. I think the best way would be to have other databases ready to function as the primary fails. Upon receiving unsuccessful acknowledgment you can route them to the secondary one. Therefore you don't lose that much of data. For this case you can use ""Guaranteed Delivery"" feature in JMS. With Guaranteed Delivery the messaging system uses a built-in data store to persist messages. Each computer the messaging system is installed on has its own data store so that the messages can be stored locally. When the sender sends a message the send operation does not complete successfully until the message is safely stored in the sender’s data store. Subsequently the message is not deleted from one data store until it is successfully forwarded to and stored in the next data store. In this way once the sender successfully sends the message it is always stored on disk on at least one computer until is successfully delivered to and acknowledged by the receiver.1 In that case I think you're in pretty good shape. Thank you for the answer one vote up. I'm really interested in hearing about different policies people have used. I have no problem with persistent delivery etc (the messaging system in the question is already transaction and uses JTA for outbound messaging that also requires DB updated)."
830,A,If I use jRuby Ruby on Rails and JDBC can I still use an ORM? Can I use Hibernate for example? Active Record? I have to use jdbc for an older database so I have to use jRuby with Ruby on Rails. Thank you. Using ActiveRecord should be possible see instructions here. You can also use Hibernate directly by using JRuby's Java interface or maybe with some Ruby sugar.  I am using JDBC and Active Record on JRuby in parallel. In my Rails application I have done it like this: the activerecord-jdbc module to connect to the database. This is my default database.yml development: adapter: jdbc driver: url: username: user password: pass (test and production accordingly) some stuff is accessed via JDBC the connection is retrieved through this: ActiveRecord::Base.connection.instance_variable_get(:@connection) thank you..everyone.
831,A,"Even easier Java/SQL data transfer needed So I'm using jdbc to talk to a MySQL DB. For many a table and for many queries/views I have created one class which encapsulates one row of the table or the query/table result. Accesses to the DB return one object of such a class (when I know exactly that there's only one matching row) or a Vector of such objects. Each class features a factory method that builds an object from a row of a ResultSet. A lot of ResultSet.getXXX() methods are needed as is finicky bookkeeping about which value is in which column especially after changes to the table/query/view layout. Creating and maintaining these objects is a boring work-intensive and mind-numbing task. In other words the sort of task that is done by a tool. It should read SQL (the MySQL variant alas) and generate Java code. Or at least give me a representation (XML? DOM?) of the table/query/view allowing me to do the java code generation myself. Can you name this tool? If you are looking for a simple framework to help with the drudge work in writing sql I would recommend ibatis sql maps. This framework basically does exactly what you want. Hibernate is also a good option but it seems a bit oversized for a simple problem like yours. You might also have a look at the spring framework. This aims to create a simple environment for writing java application and has a very usable sql abstraction as well. But be careful with spring you might start to like the framework and spend too many happy hours with it 8) As to your concern with reflection. Java has no major problems anymore with performance overhead of reflection (at least since Version 1.4 and with O/R mapping tools). In my experience it is better to care about well written and easily understandable code than caring about some performance overhead this might perhaps cost that is only theoretical. In most cases performance problems will not show up where you expect them and can only be identified with measurement tools used on your code after it has been written. The most common problems with performance are I/O related or are based on some error in your own code (i.e. massively creating new instances of classes or loops with millions of runs that are not necessary...) and not in the jdk itself. Totally agree with you. The speed of an application is concerned more with the amount of that in the wire than the operations performed in RAM. So I guess that the mini framework of mine was not that bad after all. A short look at the Java tutorial of ibatis makes me think that that's what I'm looking for.  I created a mini-framework like that years ago but it was for prototyping and not for production. The idea follows and it is VERY very simple to do. The tradeoff is the cost of using reflection. Although Hibernate and others ORM tools pay this cost also. The idea is very simple. You have a Dao class where you execute the query. Read the ResultSet Metadata and there you can grab the table name fields types etc. Find in the class path a Class that matches the table name and / or have the same number/types of fields. Set the values using reflection. Return this object and cast it in the other side and you're done. It might seem absurd to find the class at runtime. And may look too risky too because the query may change or the table structure may change. But think about it. When that happens you have to update your mappings anyway to match the new structure. So instead you just update the matching class and live happy with that. I'm not aware on how does ORM tools work to reduce reflection call cost ( because the mapping the only thing it does is help you to find the matching class ) In my version the lookup among about 30000 classes ( I added jars from other places to test it ) took only .30 ms or something like that. I saved in cache that class and the second time I didn't have to make the lookup. If you're interested ( and still reading ) I'll try to find the library in my old PC. At the end my code was something like this:  Employee e = ( Employee ) MagicDataSource.find( ""select * from employee where id = 1 ""); or Employee[] emps = ( Employee[] ) MagicDataSource.findAll(""select * from employee ""); Inside it was like: Object[] findAll( String query ) { ResultSet rs = getConnection().prepareStatemet( query ).executeQuery(); ResultSetMetaData md = rs.getMetadata(); String tableName = md.getTableName(); String clazz = findClass( toCamelCase( tableName ) ); // search in a list where all the class names where loaded. Class.forName( clazz ); while( rs.next() ) { for each attribute etc. etc. setter... end result.append( object ); } return result.toArray(); } If anyone knows how ORM tools deal with reflection cost please let me know. The code I have read from open source projects don't event attempt to do anything about it. At the end it let me create quick small programs for system monitoring or stuff like that. I don't do that job anymore and that lib is now in oblivion. Well I *think* I already have code availlable that goes through the meta data of a ResultSet. I'll spare You the trouble of digging up your code and use my own for starters. Thanks for pointing me that way.  Apart from the ORMs... If you're using the rs.getString and rs.getInt routines then you can certainly ease your maintenance burden if you rely on named columns rather than numbered columns. Specifically rs.getInt(""id"") rather than rs.getInt(1) for example. It's been rare that I've had an actual column change data type so future SQL maintenance is little more than adding the new columns that were done to the table and those can be simply tacked on to the end of your monster bind list in each of you little DAO objects. Next you then take that idiom of using column names and you extend it to a plan of using consistent names and at the same time ""unique"" names. The intent there is that each column in your database has a unique name associated with it. In theory it can be as simple (albeit verbose) as tablename_columnname thus if you have a ""member"" table the column name is ""member_id"" for the id column. What does this buy you? It buys you being able to use your generic DAOs on any ""valid"" result set. A ""valid"" result set is a result set with the columns named using your unique naming spec. So you get ""select id member_id name member_name from member where id = 1"". Why would you want to do that? Why go to that bother? Because then your joins become trivial. PreparedStatement = con.prepareStatement(""select m.id member_id m.name member_name p.id post_id p.date post_date p.subject post_subject from member m post p where m.id = p.member_id and m.id = 123""); ResultSet rs = ps.executeQuery(); Member m = null; Post p = null; while(rs.next()) { if (m == null) { m = MemberDAO.createFromResultSet(rs); } p = PostDAO.createFromResultSet(rs); m.addPost(p); } See here the binding logic doesn't care about the result set contents since it's only interested in columns it cares about. In your DAOs you make them slightly clever about the ResultSet. Turns out if you do 'rs.getInt(""member_id"")' and member_id doesn't happen to actually BE in the result set you'll get a SQLException. But with a little work using ResultSetMetaData you can do a quick pre-check (by fetching all of the column names up front) then rather than calling ""rs.getInt"" you can call ""baseDAO.getInt"" which handles those details for you so as not to get the exception. The beauty here is that once you do that you can fetch incomplete DAOs easily. PreparedStatement = con.prepareStatement(""select m.id member_id from member m where m.id = 123""); ResultSet rs = ps.executeQuery(); Member m = null; if (rs.next()) { m = MemberDAO.createFromResultSet(rs); } Finally it's really (really) a trivial bit of scripting (using say AWK) that can take the properties of a bean and convert it into a proper blob of binding code for an initial DAO. A similar script can readily take a SQL table statement and convert it in to a Java Bean (at least the base members) that then your IDE converts in to a flurry of getters/setters. By centralizing the binding code in to the DAO maintenance is really hardly anything at all since it's changed in one place. Using partial binding you can abuse them mercilessly. PreparedStatement = con.prepareStatement(""select m.name member_name max(p.date) post_date from member m post p where post.member_id = m.id and m.id = 123""); ResultSet rs = ps.executeQuery(); Member m = null; Post p = null; if (rs.next()) { m = MemberDAO.createFromResultSet(rs); p = MemberDAO.craateFromResultSet(rs); } System.out.println(m.getName() + "" latest post was on "" + p.getDate()); Your burden moving forward is mostly writing the SQL but even that's not horrible. There's not much difference between writing SQL and EQL. Mind is does kind of suck having to write a select statement with a zillion columns in it since you can't (and shouldn't anyway) use ""select * from ..."" (select * always (ALWAYS) leads to trouble IME). But those are just the reality. I have foundthough that (unless you're doing reporting) that problem simply doesn't happen a lot. It happens at least once for most every table but it doesn't happen over and over and over. And naturally once you have it once you can either ""cut and paste"" your way to glory or refactor it (i.e. sql = ""select "" + MemberDAO.getAllColumns() + "" "" + PostDAO.getAllColumns() + "" from member m post p""). Now I like JPA and ORMs I find them useful but I also find them a PITA. There is a definite love/hate relationship going on there. And when things are going smooth boy is it smooth. But when it gets rocky -- hoo boy. Then it can get ugly. As a whole however I do recommend them. But if you're looking for a ""lightweight"" non-framework this technique is useful practical low overhead and gives you a lot of control over your queries. There's simply no black magic or dark matter between your queries and your DB and when things don't work it's not some arcane misunderstanding of the framework or edge case bug condition in someone elses 100K lines of code but rather odds are a bug in your SQL -- where it belongs.  Edit: Nevermind. While searching for a solution to my own problem I forgot to check the date on this thing. Sorry. You can ignore the following. @millermj - Are you doing that for fun or because there's a need? Just curious because that sounds exactly like what Java IDEs like Eclipse and NetBeans already provide (using the Java Persistence API) with New->JPA->Entity Classes from Tables functionality. I could be missing the point but if someone just needs classes that match their tables and are persistable the JPA plus some IDE ""magic"" might be just enough.  I'm a little confused about your questions. Why don't you use an Object-relational-mapping framework like Hibernate? I used to have the same problem having to read and write a lot of SQL directly. Eventually I started writing newer projects with Hibernate and haven't looked back. The system takes care for me of building the actual tables and running the SQL in the background and I can mostly work with the java objects. Well I don't want to give up control over how the tables are built. That's what irks me about Hibernate (or Linq for that matter): I need to be able to taylor the DB schema to the expected load characteristics at run time. Hibernate also have a place where you can drop SQL directly but it is not the right place to do it. Also with Hb you can control how the tables are created and you can run later a tool against existing schema and the have the object model created automatically. What do you need to do to your tables that hibernate doesn't let you do? I've found the configurable tweaks I can achieve with annotations to meet most of my needs (e.g. column naming). +1 for Hibernate. In short ORM respects your time. :-) You can do both forward engineering (generate DDL script from Hibernate entity classes - do this when starting from scratch) and reverse engineering (generate Hibernate entity classes from an existing DB - use this with legacy databases). I've never tried reverse engineering with hibernate; how does that work? How does it generate new interfaces? It's not Hibernate but a plugin ( eclipse I think ) you specify the database connection setting go through some wizards to select the tables and it generates the hibernate.hbm.cfg.xml ( or what ever name it is I don't remember ) the config for each class and from the contraints infer the relation Pretty useful when it comes to a legacy database. You run it in have some 50+ classes all of them linked and ready to use. :) Oh ok something does generate the classes for you. that's really cool. I love Hibernate. I hate all the time I spent hand coding my DB work especially before Java supported generics. OK if Hibernate can do this for me it's an option I'll consider."
832,A,Installer package for program that uses JDBC to connect to MySQL I have an installer wizard thing called 'install creator'. I want to include my mySQL database into the installer or find another way that the user upon installation can just use my database. Prob is-not everyone has MySQL installed on the computer and even then the user doesn't know the name of the database or my password. Somehow the database must be created automatically upon install and for my purposes some of the tables created. How can one do this. Thanks Oh I'm using JDBC to interact with the database.... If you are just using MySQL as a local storage engine as it seems to be what you are doing then you should consider using Sqlite with JDBC instead of MySQL. MySQL is really intended to be used on a server where information from multiple users is stored and where the database is accessed only indirectly through the programs that you create that run on the server. You could in theory package up MySQL and MySQL Connector/J which lets JDBC talk with MySQL; however MySQL is a pretty big beast and I don't think it's nice to do that to your users (also don't forget that they might already have MySQL installed and if you were to install MySQL for the first time you would effectively be forcing them to use your root password). Unlike MySQL sqlite is intended to provide the structure of SQL for use with lightweight local file storage.
833,A,"Why do I need a connection to create PreparedStatements? I would like to use prepared statements for many reasons. But I would like to create a method that looks like this: /* This opens a connection executes the query and closes the connection */ public static void executeNonQuery(String queryString); In other words I want my application logic to only have to formulate the queries and feed in parameters but not deal with connections & statements. However PreparedStatements are created from a connection object so I am currently forced into preparing the query string using String.format() - butt ugly and dangerous. Is there a way to do what I want without using String.format()? Your executeNonQuery method has one problem: getting a connection. If you create one every time this method is executed you will have performance problems executing over and over (creating and closing connections is expensive). If this is encapsulated on an object that creates a connection only on the first call you will have a problem: when to close it? Maybe based on time? If you use static fields to cache beware this will not be collected. Beware of concurrent calls when caching a connection though: without a lock mechanism (such as syncrhonized) you could create lots of connnections. Why do I need a connection to create PreparedStatements ? Because the statements are prepared on per-connection basis in most RDBMS's. Prepared statements are in fact cached execution plans that don't take you permissions encodings collation settings etc. into account. All this is done during query parsing. Is there a way to do what I want without using String.format() Don't see why you need String.format() here. You can implement your query as a class create a connection and prepare the query in the class constructor and then execute it in a method. A parametrized query typically looks like this: SELECT * FROM table WHERE col1 = ? AND col2 = ?  where the bound parameters will be substituted for ?'s during the query execution. If you want a static method: Create a static connection handle. Create a static hash table of prepared queries using the parametrized query text as a key and the handle to the prepared query as a value. Whenever you want to execute a query find its handle (or create it if it wasn't found) and use to to bind the parameters and execute the query.  I abstract out all of the JDBC stuff by having a class I call QueryRunner that has an execute method that takes the sql a List of objects that represent the parameters and an object that will process the ResultSet. If you use the setObject method from JDBC to set your parameters it will figure out the appropriate DB types to use based on the underlying object. Here is a portion of my code. I've got another method that wraps this one and get's the connection. public void executeNoCommit(Connection conn String sql List params ResultSetProcessor processor) throws SQLException { PreparedStatement stmt = null; ResultSet rs = null; int updateCount = 0; Iterator it; int paramIndex = 1; boolean query; try { stmt = conn.prepareStatement(sql); if (params != null) { it = params.iterator(); while (it.hasNext()) { stmt.setObject(paramIndex it.next()); paramIndex++; } } query = stmt.execute(); if (query) { rs = stmt.getResultSet(); } else { updateCount = stmt.getUpdateCount(); } processor.process(rs updateCount); } finally { if (rs != null) { try { rs.close(); } catch (SQLException e) { log.error(e); } } if (stmt != null) { try { stmt.close(); } catch (SQLException e) { log.error(e); } } } } Can you post code?  You probably want something like the DbUtils package in the Apache Commons libraries: [http://commons.apache.org/dbutils/index.html][1] The QueryRunner class lets you execute sql statements without having to manually create PreparedStatements or even have an open connection for that matter. From the examples page: QueryRunner run = new QueryRunner( dataSource ); try { // Create an object array to hold the values to insert Object[] insertParams = {""John Doe"" new Double( 1.82 )}; // Execute the SQL update statement and return the number of // inserts that were made int inserts = run.update( ""INSERT INTO Person (nameheight) VALUES (??)"" insertParams ); // Now it's time to rise to the occation... Object[] updateParams = {new Double( 2.05 ) ""John Doe""}; int updates = run.update( ""UPDATE Person SET height=? WHERE name=?"" updateParams ); } catch(SQLException sqle) { // Handle it } So it basically handles the creation of prepared statements transparently and the only thing you really need to know is a DataSource. This also works just as well for non-update/insert statements i.e. plain-vanilla select queries and the ability to create ResultSetHandlers gives you the power to convert a ResultSet into something like a fully-prepared bean or a Map with the keys being the column names and the values being the actual row values. Very useful for when you can't implement a whole ORM solution.  Why not have your ""application"" logic use a data layer which you create which can present that kind of interface method? Your data layer can then handle creating connections preparing statements etc. all within that executeNonQuery method. I think that if you are attempting to merge the parameters in your query/statement yourself into a String then you are shooting yourself in the foot and actually not using the parameter functionality of PreparedStatements. Not sure why you would want to do this. You might also want to look into using an API such as Spring which has a series of JdbcTemplate classes that can abstract all of the connection handling away from you but still allow you to work with parameters in a Map."
834,A,"We're using JDBC+XMLRPC+Tomcat+MySQL to execute potentially large MySQL queries. What is a better way? I'm working on a Java based project that has a client program which needs to connect to a MySQL database on a remote server. This was implemented is as follows: Use JDBC to write the SQL queries to be executed which are then hosted as a servlet using Apache Tomcat and made accessible via XML-RPC. The client code uses XML-RPC to remotely execute these JDBC based functions. This allows us to keep our MySQL database non-public restricts use to the pre-defined functions and allows Tomcat to manage the database transactions (which I've been told is better than letting MySQL do it alone but I really don't understand why). However this approach requires a lot of boiler-plate code and Tomcat is a huge memory hog on our server. I'm looking for a better way to do this. One way I'm considering is to make the MySQL database publicly accessible re-writing the JDBC based code as stored procedures and restricting public use to these procedures only. The problem I see with this are that translating all the JDBC code to stored procedures will be difficult and time consuming. I'm also not too familiar with MySQL's permissions. Can one grant access to a stored procedure which performs select statements on a table but also deny arbitrary select statements on that same table? Any other ideas are welcome as are thoughts and or sugguestions on the stored procedure solution. Thank you! I am sure you could implement your solution without much boiler-plate esp. using something like Spring's remoting. Also how much memory is Tomcat eating? I frankly believe that if it's just doing what you are describing it could work in less than 128mb (conservative guess). Your alternative is the ""correct by the book"" way of solving the problem. I say build a prototype and see how it works. The major problems you could have are: MySQL having some important gotcha in this regard MySQL's Stored Procedure support being too primitive and forcing you to do a lot of work Some other strange hiccup I'm probably one of those MySQL haters so the situation might be better than I think. Unfortunately there is more than one book. The REST and the Semantic Web devotees would disagree with you (they'd see it as a missed opportunity) but your DBA will wonder why you had a web tier at all. The guy who maintains the client will also wonder why you're changing what you have!  You can probably get the RAM upgraded in your server for less than the cost of even a few days development time so don't write any code if that's all you're getting from the exercise. Also just because the memory is used inside of tomcat it doesn't mean that tomcat itself is using it. The memory could be used up by data or by technical flaws in your code. If you've tried additional RAM and it is being eaten up then that smells like a coding issue so I'd suggest using a profiler or log data to try and work out what the root cause is before changing anything. If the cause is large data sets then using the database directly will only delay the inevitable instead you'd need to look at things like paging summarisation client side caching or redesigning clients to reduce the use of expensive queries. Using a profiler or simply reviewing the code base will also tell you if something is creating too many objects (especially strings or XML nodes) or leaking memory. Boiler plate code can be avoided by refactoring creatively and its good that you do avoid repetition. Its unclear how much structure you might already have but with a little work its easy to centralise boilerplate JDBCs calls. There is no fundamental reason JDBC code should be repeated perhaps you could tell us what code is being repeated? Finally I'll venture that there are many good reasons to put a web tier over your database. Flexibility (of deployment) compatibility control (over the SQL) and security are all good reasons to keep the web tier. Thanks for the accepted-answer endoresement. I recently used this tool: http://www.eclipse.org/mat/ to get an impression of memory usage. It has limitations but will certainly flag any big memory structures. Good luck.  MySQL 5.0.3+ does have an execute privilege that you can set (without setting select privileges) that should allow you to get the functionality you seek. However note this mysql bug report with JDBC (well and a lot of other drivers). When calling the [procedure] with JDBC I get ""java.sql.SQLException: Driver requires declaration of procedure to either contain a '\nbegin' or '\n' to follow argument declaration or SELECT privilege on mysql.proc to parse column types."" the workaround is: See ""noAccessToProcedureBodies"" in /J 5.0.3 for a somewhat hackish non-JDBC compliant workaround."
835,A,"How can I escape '""' when reading a csv-file with JDBC? I am reading a csv-file with JDBC using CsvJdbc. Some strings in the csv-file contains a ""-char how can I handle these situations? When I am reading the csv-file with: while (results.next()) { String name = results.getString(""Name""); ... } I get this SQLException on the line where I have while (results.next()) { java.sql.SQLException: Unexpected '""' in position 19. Line=Mats ""Matte"" Tyr;12;; How can I escape the ""-chars so I can read the String? Or can a Java String not contain an ""-char? Any other suggestions on how I can solve this problem? This is nothing to do with Java but the rules of CSV. A double quote needs to be escaped by doubling it to """" and enclosing the whole field value in double quotes. foobar""a """"quoted"""" string""bang"
836,A,"JDBC Change Default Schema I'm trying to connect to a sql server 2005 database via JDBC. I get the error: com.microsoft.sqlserver.jdbc.SQLServerException: The SELECT permission was denied on the object 'MyTable' database 'MyDatabase' schema 'dbo'. The schema I use to connect is ""MyUser"". How do I connect using MyUser as opposed to dbo? Thanks! i found that you have to specify your schema in your POJOS definitions. In my case I got the same trouble using JPA (Entities / Annotations) and I realized that specifing the schema property in the @Table annotation works. for example: @Table(name = ""address"" **schema=""*dbo*""** catalog = ""petcatalog"") I hope this helps you.  To clear things up: You connect to SQL Server using a user not a schema. You don't say what version of SQL Server you're connecting to but it used to be the case that the two were equivalent. As of 2005+ that is no longer true. dbo is the default schema (think of it as a namespace); what the error message is telling you is the user you are connecting with (If I understand correctly that's MyUser) does not have permission to SELECT from the MyTable table which is part of the dbo schema in the MyDatabase database. The first thing to do is confirm whether or not the user you're connecting with does or does not have SELECT permissions on that table. The second thing to do is if it doesn't either give MyUser that permission or use a different user to perform the SELECT statement."
837,A,"Easier storage into a JDBC driver I was going to try using JDBC and an sqlite driver to save information into a file. It seems to work fine but I was wondering if there was a more automated way to set it up. Maybe almost like a key-value pair. Anyway this is what I'm doing now... Connection conn = DriverManager.getConnection(""jdbc:sqlite:test.db""); Statement stat = conn.createStatement(); stat.executeUpdate(""drop table if exists people;""); stat.executeUpdate(""create table people (name text age int etc...);""); PreparedStatement prep = conn.prepareStatement( ""insert into people values (? ? etc... );""); for (int i = 0; i < persons.length; i++) { prep.setString(1 persons[i].name) prep.setString(2 persion[i].age) .... prep.addBatch() } conn.setAutoCommit(false); prep.executeBatch(); The (??) is kind of hacky when there are like ten fields I want to store from the class which may change later. Counting seems very old school. Ideally I'd just like to go through my class and annotate which fields I'd like to store (mostly primitives like ints) but if they're objects get the fields they annotate. Either that or something that just sits on JDBC and has a slightly faster cleaner syntax for building the table and adding objects. This doesn't have to be persistent. It's only for rare reads and writes. Well it sounds you're looking for JPA or Hibernate. These frameworks do exactly what you describe annotate your fields and persist them in a database. There is a learning curve involved though but it is well worth it. Here is more info about JPA. and here for hibernate. These frameworks will allow mapping to an existing database or create the tables for you for new developments. Note that these are not lightweight frameworks. Great thanks for the tip. I am going to look into this project this looks cool. If you like to do your own SQL you may also be interested in mybatis which is a very mature OR framework where you own the SQL. After looking into JPA I eventually found orbroker which I think meets my needs well. Thanks."
838,A,"Solr DataImportHandler with SQL Server I'm having a problem getting Solr to talk to Microsoft SQL Server via the Microsoft JDBC Driver. I have the handler registered in solrconfig.xml: <requestHandler name=""/dataimport"" class=""org.apache.solr.handler.dataimport.DataImportHandler""> <lst name=""defaults""> <str name=""config"">C:\Program Files\Apache Software Foundation\Tomcat 6.0\Solr\conf\data-config.xml</str> </lst> </requestHandler> In data-config.xml I have a data source and a document defined: <?xml version=""1.0"" encoding=""UTF-8"" ?> <dataConfig> <dataSource type=""JdbcDataSource"" name=""ds1"" driver=""com.microsoft.sqlserver.jdbc.SQLServerDriver"" url=""jdbc:sqlserver://localhost;databaseName=myDB;responseBuffering=adaptive;"" user=""xxxx"" password=""xxxx"" readOnly=""true"" /> <document name=""members""> <entity name=""member"" datasource=""ds1"" pk=""id"" query = ""select MemberID as id UserName as userName FirstName as firstName LastName as lastName Birthday as birthday PrimaryEmail as primaryEmail PersonalStatement as personalStatement from member"" transformer=""DateFormatTransformer""> <field column=""Birthday"" name=""birthday"" dateTimeFormat=""yyyy-MM-dd"" /> </entity> </document> </dataConfig> The columns are fairly irrelevant - I just wanted to start with a few items including a date column. The Solr schema.xml has some fields defined: <field name=""id"" type=""tlong"" indexed=""true"" stored=""true"" required=""true"" /> <field name=""userName"" type=""text"" indexed=""true"" stored=""true"" /> <field name=""firstName"" type=""text"" indexed=""true"" stored=""true"" /> <field name=""lastName"" type=""text"" indexed=""true"" stored=""true"" /> <field name=""birthday"" type=""tdate"" indexed=""true"" stored=""true"" /> <field name=""primaryEmail"" type=""text"" indexed=""true"" stored=""true"" /> <field name=""personalStatement"" type=""text"" indexed=""true"" stored=""true"" /> When I attempt an import the log shows an exception building the datasource: Jun 26 2010 10:24:48 PM org.apache.solr.handler.dataimport.DataImporter doFullImport INFO: Starting Full Import Jun 26 2010 10:24:48 PM org.apache.solr.core.SolrCore execute INFO: [] webapp=/solr path=/select params={clean=false&commit=true&command=full-import&qt=/dataimport} status=0 QTime=7 Jun 26 2010 10:24:48 PM org.apache.solr.handler.dataimport.SolrWriter readIndexerProperties WARNING: Unable to read: dataimport.properties Jun 26 2010 10:24:48 PM org.apache.solr.handler.dataimport.DataImporter doFullImport SEVERE: Full Import failed org.apache.solr.handler.dataimport.DataImportHandlerException: No dataSource :null available for entity :member Processing Document # 1 at org.apache.solr.handler.dataimport.DataImporter.getDataSourceInstance(DataImporter.java:279) at org.apache.solr.handler.dataimport.ContextImpl.getDataSource(ContextImpl.java:93) at org.apache.solr.handler.dataimport.SqlEntityProcessor.init(SqlEntityProcessor.java:52) at org.apache.solr.handler.dataimport.EntityProcessorWrapper.init(EntityProcessorWrapper.java:71) at org.apache.solr.handler.dataimport.DocBuilder.buildDocument(DocBuilder.java:319) at org.apache.solr.handler.dataimport.DocBuilder.doFullDump(DocBuilder.java:242) at org.apache.solr.handler.dataimport.DocBuilder.execute(DocBuilder.java:180) at org.apache.solr.handler.dataimport.DataImporter.doFullImport(DataImporter.java:331) at org.apache.solr.handler.dataimport.DataImporter.runCmd(DataImporter.java:389) at org.apache.solr.handler.dataimport.DataImporter$1.run(DataImporter.java:370) Jun 26 2010 10:24:48 PM org.apache.solr.update.DirectUpdateHandler2 rollback INFO: start rollback Jun 26 2010 10:24:48 PM org.apache.solr.update.DirectUpdateHandler2 rollback INFO: end_rollback Jun 26 2010 10:24:54 PM org.apache.solr.core.SolrCore execute INFO: [] webapp=/solr path=/select params={clean=false&commit=true&command=status&qt=/dataimport} status=0 QTime=0 I've read the FAQ and documentation looked at as many sources as I can find and I just can't get past this error. What am I doing wrong? The error ""Unable to read: dataimport.properties"" appears to be shown any time there is any issue with the configuration. I can't find my mistake. It seems that the datasource is not recognized in the entity declaration because the proper attribute to use is dataSource not datasource"
839,A,"Can I optimize this code? I am trying to retrieve the data from the table and convert each row into CSV format like s12 james 24 1232 Salaried The below code does the job but takes a long time with tables of rows exceeding 100000. Please advise on optimizing technique:  while(rset1.next()!=false) { sr=sr+""\n""; for(int j=1;j<=rsMetaData.getColumnCount();j++) { if(j< 5) { sr=sr+rset1.getString(j).toString()+""""; } else sr=sr+rset1.getString(j).toString(); } } /SR Why don't you export the csv directly from DB? @ruslik: couldn't agree more. You ain't ever going to do it faster in Java than a bit decent DB can do. PLEASE WRITE THE TITLE MORE DESCRIPTIVELY. Also look at http://stackoverflow.com/questions/101100/csv-api-for-java this will give you some more information how to write read csv in java StringBuilder sr = new StringBuilder(); int columnCount =rsMetaData.getColumnCount(); while (rset1.next()) { sr.append('\n'); for (int j = 1; j <= columnCount; j++) { sr.append(rset1.getString(j)); if (j < 5) { sr.append(''); } } } I think this is as good of a solution you will get although I'm not sure the changes will actually show a noticeable performance improvement. The only change I would make is changing the while to while(rset1.next()) @gregcase: Thanks! I didn't notice the '!= false' part. I have edited and fixed it. Also I imagine the 'j < 5' should be 'j < columnCount' but it's impossible to tell for sure.  I'm no Java expert but I think it's always bad practice to use something like getColumnCount() in a conditional check. This is because after each loop it runs that function to see what the column count is instead of just referencing a static number. Instead set a variable equal to that number and use the variable to compare against j. ok.. i will try and let you know. @user414977: A decent compiler should be able to inline .getColumnCount() and reference the variable behind the function call directly. Additionally the time needed to refer to the variable once per loop is far defeated by the time you wasted on copying string over and over instead of using StringBuilder. What he said. If I were you I'd accept the answer from Steven Schlansker. I'm not even a Java programmer.  Two approaches in order of preference: Stream the output PrintWriter csvOut = ... // Construct a write from an outputstream say to a file while (rs.next()) csvOut.println(...) // Write a single line (note that you should ensure that your Writer / OutputStream is buffered although many are by default) Use a StringBuilder StringBuilder sb = new StringBuilder(); while (rs.next()) sb.append(...) // Write a single line The idea here is that appending Strings in a loop is a bad idea. Imagine that you have a string. In Java Strings are immutable. That means that to append to a string you have to copy the entire string and then write more to the end. Since you are appending things a little bit at a time you will have many many copies of the string which aren't really useful. If you're writing to a File it's most efficient just to write directly out with a stream or a Writer. Otherwise you can use the StringBuilder which is tuned to be much more efficient for appending many small strings together. No file IO is SLOW buffering the writes would perform much faster. @arthurprs: unless you are using a raw OutputStream nearly all IO operations in Java are already buffered. If you fear this you can always use a BufferedOutputStream or a BufferedWriter. It's generally considered much faster to stream out data than build a huge intermediate value and then copy it out. It's possible the result String/StringBuilder is getting so large that the JVM is running out of heap space leading to overactive garbage collection. Maybe try java -Xms512m -Xmx512m @gregcase: if you're building a half-gig String object you **really** should try for a streaming approach instead. @Steven Schlansker: In this case you are right sorry I don't know much java. But you may want to edit your answer. @arthurprs: I already did a few minutes ago :) @Steven Schlansker I agree just providing some feedback that this might be a situation where the problem isn't unoptimized code but rather the limitations of the approach 3rd approach can be combinied: instruct JDBC to return result row-by-row. It by default hauls the entire resultset into Java's memory first before giving anything to `next()`. How to do that depends on JDBC driver used. @BalusC: that should really be a different answer. Agreed though not row-by-row but in row batches! :) +1 cuz this should have been the accepted answer.  You might want to use a StringBuilder to build the string that's much more efficient when you're doing a lot of concatenation. Also if you have that much data you might want to consider writing it directly to wherever you're going to put it instead of building it in memory at first if that's a file or a socket for example. Will try your option. The basic requirement is that its should not be written on to a file.  I don't believe minor code changes are going to make a substantive difference. I'd surely use a StringBuffer however. He's going to be reading a million rows over a wire assuming his database is on a separate machine. First if performance is unacceptable I'd run that code on the database server and clip the network out of the equation. If it's the sort of code that gets run once a week as a batch job that may be ok. Now what are you going to do with the StringBuffer or String once it is fully loaded from the database? We're looking at a String that could be 50 Mbyte long. This should be 1 iota faster since it removes the unneeded (i<5) check. StringBuilder sr = new StringBuilder(); int columnCount =rsMetaData.getColumnCount(); while (rset1.next()) { for (int j = 1; j < columnCount; j++) { sr.append(rset1.getString(j)).append(""""); } // I suspect the 'if (j<5)' really meant ""if we aren't on the last // column then tack on a comma."" So we always tack it on above and // write the last column and a newline now. sr.append(rset1.getString(columnCount)).append(""\n""); } } Another answer is to change the select so it returns a comma-sep string. Then we read the single-column result and append it to the StringBuffer. I forget the syntax now but something like: select column1 || """" || column2 || """" ... from table; Now we don't need to loop and comma concatenation business. StringBuilder sr = new StringBuilder(); while (rset1.next()) { sr.append(rset1.getString(1)).append(""\n""); } } I think you mean `select column1 || '' || column2 || '' ...` Yes thanks for the syntax assist. I don't have a DB running here at home to try it.  As the other answers say stop appending to a String. In Java String objects are immutable so each append must do a full copy of the string turning this into an O(n^2) operation. The other is big slowdown is fetch size. By default the driver is likely to fetch one row at a time. Even if this takes 1ms that limits you to a thousand rows per second. A remote database even on the same network will be much worse. Try calling setFetchSize(1000) on the Statement. Beware that setting the fetch size too big can cause out of memory errors with some database drivers. With some databases (at least Postgres JDBC) it defaults to retrieving the entire set not one row at a time. That said your suggestion is still very useful as for a lot of rows that can easily OOM.  As a completely different but undoubtely the most optimal alternative use the DB-provided export facilities. It's unclear which DB you're using but as per your question history you seem to be doing a lot with Oracle. In this case you can export a table into a CSV file using UTL_FILE. See also: Generating CSV files using Oracle Stored procedure example on Ask Tom I agree using the data export module is the best way because 1. it will handle any weird escaping 2. it will certainly execute quicker 3. you can dump the work on the DBAs :-D and move on to something else."
840,A,"What does ""java.sql.SQLException: No tables used"" mean? Jboss + Hibernate I am using JBoss 5.1 and I get the same error either with MySQL 5 or HSQLDB. Of course I already tried Google but it seems that I am the only one who gets such an exception. Does anyone know what it means? According to the MySQL reference this happens if the query has no FROM clause or has a FROM DUAL clause. Can you post the request on which you're having this error ? Use <property name=""show_sql"">true</property> to log generated SQL in Hibernate."
841,A,"org.postgresql.util.PSQLException: FATAL: sorry too many clients already I am trying to connect to a Postgresql database I am getting the following Error: Error:org.postgresql.util.PSQLException: FATAL: sorry too many clients already What does the error mean and how do I fix it? My server.properties file is following: serverPortData=9042 serverPortCommand=9078 trackConnectionURL=jdbc:postgresql://127.0.0.1:5432/vTrack?user=postgres password=postgres dst=1 DatabaseName=vTrack ServerName=127.0.0.1 User=postgres Password=admin MaxConnections=90 InitialConnections=80 PoolSize=100 MaxPoolSize=100 KeepAliveTime=100 TrackPoolSize=120 TrackMaxPoolSize=120 TrackKeepAliveTime=100 PortNumber=5432 Logging=1 We don't know what server.properties file is that we neither know what SimocoPoolSize means (do you?) Let's guess you are using some custom pool of database connections. Then I guess the problem is that your pool is configured to open 100 or 120 connections but you Postgresql server is configured to accept MaxConnections=90 . These seem conflictive settings. Try increasing MaxConnections=120. But you should first understand your db layer infrastructure know what pool are you using if you really need so many open connections in the pool. And specially if you are gracefully returning the opened connections to the pool  An explanation of the following error: org.postgresql.util.PSQLException: FATAL: sorry too many clients already. Summary: You opened up more than the allowed limit of connections to the database. You ran something like this: Connection conn = myconn.Open(); inside of a loop and forgot to run conn.close();. Just because your class is destroyed and garbage collected does not release the connection to the database. The quickest fix to this is to make sure you have the following code with whatever class that creates a connection: protected void finalize() throws Throwable { try { your_connection.close(); } catch (SQLException e) { e.printStackTrace(); } super.finalize(); } Place that code in any class where you create a Connection. Then when your class is garbage collected your connection will be released. Run this SQL to see postgresql max connections allowed: show max_connections The default is 100. PostgreSQL on good hardware can support a few hundred connections at a time. If you want to have thousands you should consider using connection pooling software to reduce the connection overhead. Take a look at exactly who/what/when/where is holding open your connections: SELECT * FROM pg_stat_activity; The number of connections currently used is: select count(*) from pg_stat_activity Debugging strategy You could give different usernames/passwords to the programs that might not be releasing the connections to find out which one it is and then look in pg_stat_activity to find out which one is not cleaning up after itself. Do a full exception stack trace when the connections could not be created and follow the code back up to where you create a new Connection make sure every code line where you create a connection ends with a connection.close(); How to set the max_connections higher: max_connections in the postgresql.conf sets the maximum number of concurrent connections to the database server. First find your postgresql.conf file If you don't know where it is query the database with the sql: SHOW config_file; Mine is in: /var/lib/pgsql/data/postgresql.conf Login as root and edit that file. Search for the string: ""max_connections"". You'll see a line that says max_connections=100. Set that number bigger check the limit for your postgresql version. Restart the postgresql database for the changes to take effect. What's the maximum max_connections? Use this query: select min_valmax_val from pg_settings where name='max_connections' I get the value 8388607 in theory that's the most you are allowed to have but then a runaway process can eat up thousands of connections and surprise your database is unresponsive until reboot. If you had a sensible max_connections like 100. The offending program would be denied a new connection. Some really good advice here  No need to increase the MaxConnections & InitialConnections. Just close your connections after after doing your work. For example if you are creating connection: try { connection = DriverManager.getConnection( ""jdbc:postgresql://127.0.0.1/""+dbnameuserpass); } catch (SQLException e) { e.printStackTrace(); return; } After doing your work close connection: try { connection.commit(); connection.close(); } catch (SQLException e) { e.printStackTrace(); }  The offending lines are the following: MaxConnections=90 InitialConnections=80 You can increase the values to allow more connections. And if you will be having more connections allowed adjust memory parameters as well to align with increased connections."
842,A,"Hibernate is rounding my double? I've got a double which I'm trying to save to a postgres numeric column. The value I'm trying to save is 151.33160591125488 and I've verified that this is in fact the argument being received by Hibernates internals pre-insert. However the value in the database post insert is 151.331605911255 ie it's been rounded to 12dp. I know my column is of the right scale as it's an unrestricted numeric column and the following... update tbl set col=151.33160591125488 ...has the desired effect. So the culprit has to be either Hibernate or the postgres-JDBC driver. Ideas? EDIT: org.hibernate.dialect.PostgreSQLDialect: registerColumnType( Types.DOUBLE ""float8"" ); and select cast (151.33160591125488 as float8); =151.331605911255 therefore the default behavior for double is incorrect as it doesn't always save the double supplied to it. Does anyone know how to get hibernate to use the column type ""numeric"" in postgres? You haven't really given enough details on the hibernate side. The mapping can specify precision and scale. for example: Thanks brian i'll try that however this would reduce the scalability of my app all because hibernate is misbehaving. java double doesn't restrict postgres doesn't restrict why should hibernate? i tried with precision=""30"" scale=""20"" which should have been plenty same result. so bad advice. FYI the ""postgres"" tag was recently replaced with ""postgresql"". See http://meta.stackexchange.com/questions/25279/retag-request-postgres-postgresql for more info. I took the liberty of re-tagging this question. just for your information precision=""12"" scale=""2"" has no effect on inserts/updates it is only used if hibernate also creates the database so that it knows how to create the column. Java double is not really appropriate for precise math operations. Use BigDecimal instead. Hibernate supports it as one of basic types: <property name=""amount"" type=""big_decimal"" /> show me one example of a double changing without arithmetic being performed. It doesn't matter whether you perform arithmetic or not. You **CANNOT** rely on `double` for **any** kind of precision. Besides you've asked how to map to ""NUMERIC"" type - that's what ""big_decimal"" is mapped to. thanks see my comment on n002213f's post.  Whenever precision matters use java.math.BigDecimal. This answer discusses this in great detail. how so? i have an exact double. i need it persisted. it doesn't change. if hibernate didn't cast it to float8 it would be persisted properly. in my experience you only have problems with IEEE 754 stuff when you do arithmetic on these numbers. prove me wrong. show an example. Testing with BigDecimal - it is not acceptable. it returns an invalid number. eg: System.out.println(new BigDecimal(-33.62112355233672)); = -33.62112355233671934229278122074902057647705078125. I am aware I can set the precision/scale but the whole point is that i want a true floating point number. i don't want fixed scale. so to use bigdecimal i would have to interrogate my double first figure out how may dp it uses and set that on the BigDecimal? also -33.62112355233672 is the equivalent of -33.62112355233672000000000000000000000000000000000 not -33.62112355233671934229278122074902057647705078125 using new BigDecimal(String.valueOf(-33.62112355233672))); returns desired result thanks i'm sure this would work (and i will test it) however since i don't perform any arithmetic on this number the IEEE pitfalls don't apply. therefore double is perfectly appropriate for my needs. it still doesn't make sense for hibernate to inadvertently alter a piece of information i ask it to persist. from the JLS (http://java.sun.com/docs/books/jls/third_edition/html/typesValues.html) **The floating-point types are float whose values include the 32-bit IEEE 754 floating-point numbers and double whose values include the 64-bit IEEE 754 floating-point numbers.** Therefore it does not matter whether you have done any calculations or not you still have the pitfalls."
843,A,Simple database web application with Eclipse and Glassfish I just started to learning Eclipse with Glassfish server. I was looking around how can I make simple database web application but can't figure out yet. I downloaded the Glassfish bundle for Eclipse. I need to create simple database ( perhaps one table ) and connect the database with simple web application. How to do that in Eclipse  can you give me some step by step link how can I do this Thank you If you decide to use Apache Derby as your database a version of it called JavaDB comes with jee6 + Glassfish bundle you can read this tutorial about how to connect to it and create tables from within Eclipse. You need to download the Apache Derby plugin. This has nothing to do with Glassfish however the example shows you how to connect to it from a normal Java desktop application using JDBC.  For the database you could do worse than use JavaDb which comes as standard with Java 6. Check out the JDBC tutorial for details on interfacing Java to a database.  This Tip Of The Day seems to have the info you are looking for....  At this point you have a webapp server and an IDE. Both of which are designed to be semi-agnostic when it comes to databases. The next choice is how you want to interact with the database. Then you should be able to find more information and examples on how to start constructing your webapp. I'd suggest going with spring and stripes (http://www.springsource.org/ and http://www.stripesframework.org/display/stripes/Home respectively) but that's a personal choice.
844,A,Oracle Jar causing warning in Maven packaging I have added my Oracle JDBC driver to my Maven repository and everything is working fine however I am still receiving warnings whenever I package my project. E.g.  [INFO] Unable to find resource 'com.oracle:ojdbc14:pom:10.2.0' in repository central (http://repo1.maven.org/maven2) How can I stop those warnings from showing up? Yes it does build alright. It just has warnings. Pascal cleared it up for me. Thank you for your help. Well does your package build all right? Maven is trying to get the .pom file of your Oracle driver because it can't find it in your local repository. A simple ojdbc14-10.2.0.pom with the following content would suffice: <project> <modelVersion>4.0.0</modelVersion> <groupId>com.oracle</groupId> <artifactId>ojdbc14</artifactId> <version>10.2.0</version> </project> You could create it manually or get it generated by Maven when invoking install:install-file (to install it in your local repository) or deploy:deploy-file (to install it in a remote repository) using the generatePom optional parameter: mvn install:install-file -Dfile=/path/to/ojdbc14.jar \ -DgroupId=com.oracle \ -DartifactId=ojdbc14 \ -Dversion=10.2.0 \ -Dpackaging=jar \ -DgeneratePom=true The deploy:deploy-file goal admits the same generatePom optional parameter. PS: My recommendation would be to use the Oracle Database 11g Release 2 (11.2.0.1.0) drivers. Thank you very much Pascal. That helped immensely. @Luke: You're welcome.
845,A,"Exception while calling stored procedure :Bigger type length than Maximum HI I am getting this exception when I am calling any stored procedure from my J2EE app. Exception while calling stored procedure :Bigger type length than Maximum I am having Oracle 9.1.0.7 JDK1.4 and using ojdbc14.jar running on Weblogic 8.1 Please advise what could be the root cause ? Below is the manifest of my ojdbc14.jar Manifest-Version: 1.0 Implementation-Version: ""Oracle JDBC Driver version - 10.1.0.2.0"" Specification-Title: ""Oracle JDBC driver classes for use with JDK1.4"" Specification-Version: ""Oracle JDBC Driver version - 10.1.0.2.0"" Implementation-Title: ""ojdbc14.jar"" Created-By: 1.2.2 (Sun Microsystems Inc.) Implementation-Time: ""Wed Jan 21 00:48:12 2004"" Implementation-Vendor: ""Oracle Corporation"" Specification-Vendor: ""Oracle Corporation"". It's a driver bug. Your version is already 6 years old. Download the latest and greatest from here.  See this post for a possible workaround. For possible causes see this thread: There are bugs in different versions of the drivers and different versions of the database; most of them are fixed in later versions. For example bugs produce the ""Bigger type length than maximum"" in Oracle database 8.1.7.2 or 9.0.1.1 for certain very specific operations using DB links; upgrading to 8.1.7.3 or 8.1.7.4 or 9.0.1.2 resolves those problems. For example bugs produce the ""Bigger type length than maximum"" in Oracle database 10.1.0.2 and 10.1.0.3 for certain very specific operations involving NLS characters; upgrading to 10.1.0.4 pr 10.2.0.1 resolves those problems. For example the 8.1.6 classes12.zip had such a bug on certain operation with databases in a UNICODE character set that was fixed in the 8.1.7.4 driver. If you have an Oracle support contract you can find out this information on the Oracle support site; metalink.oracle.com If not download the latest versions of the drivers and pray...  i downloaded the latest driver and now much better - now that all the referenced locations are updated"
846,A,"JDBC: How to read all rows from huge table? I have a problem to process all rows from database (PostgreSQL). I get error: ""org.postgresql.util.PSQLException: Ran out of memory retrieving query results."". I thing that i need to read all rows in small pieces but it doesn't work - it read only 100 rows (code below). How to do that ?  int i = 0; Statement s = connection.createStatement(); s.setMaxRows(100); // bacause of: org.postgresql.util.PSQLException: Ran out of memory retrieving query results. ResultSet rs = s.executeQuery(""select * from "" + tabName); for (;;) { while (rs.next()) { i++; // do something... } if ((s.getMoreResults() == false) && (s.getUpdateCount() == -1)) { break; } } The short version is call stmt.setFetchSize(50); and conn.setAutoCommitMode(false); to avoid reading the entire resultset into memory. Here's what the docs says: Getting results based on a cursor By default the driver collects all the results for the query at once. This can be inconvenient for large data sets so the JDBC driver provides a means of basing a ResultSet on a database cursor and only fetching a small number of rows. A small number of rows are cached on the client side of the connection and when exhausted the next block of rows is retrieved by repositioning the cursor. Note: Cursor based ResultSets cannot be used in all situations. There a number of restrictions which will make the driver silently fall back to fetching the whole ResultSet at once. The connection to the server must be using the V3 protocol. This is the default for (and is only supported by) server versions 7.4 and later.- The Connection must not be in autocommit mode. The backend closes cursors at the end of transactions so in autocommit mode the backend will have closed the cursor before anything can be fetched from it.- The Statement must be created with a ResultSet type of ResultSet.TYPE_FORWARD_ONLY. This is the default so no code will need to be rewritten to take advantage of this but it also means that you cannot scroll backwards or otherwise jump around in the ResultSet.- The query given must be a single statement not multiple statements strung together with semicolons. Example 5.2. Setting fetch size to turn cursors on and off. Changing code to cursor mode is as simple as setting the fetch size of the Statement to the appropriate size. Setting the fetch size back to 0 will cause all rows to be cached (the default behaviour). // make sure autocommit is off conn.setAutoCommit(false); Statement st = conn.createStatement(); // Turn use of the cursor on. st.setFetchSize(50); ResultSet rs = st.executeQuery(""SELECT * FROM mytable""); while (rs.next()) { System.out.print(""a row was returned.""); } rs.close(); // Turn the cursor off. st.setFetchSize(0); rs = st.executeQuery(""SELECT * FROM mytable""); while (rs.next()) { System.out.print(""many rows were returned.""); } rs.close(); // Close the statement. st.close();  At lest in my case the problem was on the client that tries to fetch the results. Wanted to get a .csv with ALL the results. I found the solution by using psql -U postgres -d dbname -c ""COPY (SELECT * FROM T) TO STDOUT WITH DELIMITER ''"" (where dbname the name of the db...) and redirecting to a file.  I did it like below. Not the best way i think but it works :)  Connection c = DriverManager.getConnection(""jdbc:postgresql://....""); PreparedStatement s = c.prepareStatement(""select * from "" + tabName + "" where id > ? order by id""); s.setMaxRows(100); int lastId = 0; for (;;) { s.setInt(1 lastId); ResultSet rs = s.executeQuery(); int lastIdBefore = lastId; while (rs.next()) { lastId = Integer.parseInt(rs.getObject(1).toString()); // ... } if (lastIdBefore == lastId) { break; } }  Use a CURSOR in PostgreSQL or let the JDBC-driver handle this for you. LIMIT and OFFSET will get slow when handling large datasets. Try this one: http://jdbc.postgresql.org//documentation/head/query.html#fetchsize-example The second link not working...  I think your question is similar to this thread: http://stackoverflow.com/questions/2771439/jdbc-pagination which contains solutions for your need. In particular for PostgreSQL you can use the LIMIT and OFFSET keywords in your request: http://www.petefreitag.com/item/451.cfm PS: In Java code I suggest you to use PreparedStatement instead of simple Statements: http://download.oracle.com/javase/tutorial/jdbc/basics/prepared.html Just use Spring practically no need to ever code against the JDK classes - http://static.springsource.org/spring/docs/3.0.x/spring-framework-reference/html/jdbc.html"
847,A,Named pipes versus TCP for JDBC-MySQL in Windows I've been having numerous connection problems between my Java (JPA+Hibernate+CommonsDBCP) app connecting to MySQL. I've done the research tweaked all the settings with validation queries timeouts tests before X etc. This path led me to another StackOverflow question comparing DBCP and C3PO. From the responses I've decided to definitely try out C3PO instead. Along the way however I've found another option: named pipes since both the app server and MySQL are running on the same machine. Trouble is I can't find many details about this method. So here's my question: what is going to be the most STABLE option: Named pipes or TCP w/C3PO? Any stories or knowledge would be most welcome as well as answers. Well it depends on your situation: Who is connecting to MySQL? Clients from a slow LAN or WAN link? Or localhost? TCP/IP has the benefit of connection backlogging where named pipes do not so for slow links or WAN I would go with TCP/IP; otherwise named pipes. Also local named pipes run in kernel mode so they're going to be pretty fast. Try looking at http://msdn.microsoft.com/en-us/library/aa178138(SQL.80).aspx Even though it speaks about MS SQL Server the Local named pipes running in kernel mode should still apply.
848,A,"How to make a thread try to reconnect to the Database x times using JDBCTemplate I have a single thread trying to connect to a database using JDBCTemplate as follows: JDBCTemplate jdbcTemplate = new JdbcTemplate(dataSource); try{ jdbcTemplate.execute(new CallableStatementCreator() { @Override public CallableStatement createCallableStatement(Connection con) throws SQLException { return con.prepareCall(query); } } new CallableStatementCallback() { @Override public Object doInCallableStatement(CallableStatement cs) throws SQLException { cs.setString(1 subscriberID); cs.execute(); return null; } }); } catch (DataAccessException dae) { throw new CougarFrameworkException( ""Problem removing subscriber from events queue: "" + subscriberID dae); } I want to make sure that if the above code throws DataAccessException or SQLException the thread waits a few seconds and tries to re-connect say 5 more times and then gives up. How can I achieve this? Also if during execution the database goes down and comes up again how can i ensure that my program recovers from this and continues running instead of throwing an exception and exiting? Thanks in advance. It might be worthwhile for you to look into Spring's Aspect support. What you're describing is retry with (constant) backoff and chances are you'll eventually need it somewhere else be it talking to a web service an email server or any other complicated system susceptible to transient failures. For instance this simple method invokes the underlying method up to maxAttempts times whenever an exception is thrown unless it is a subclass of a Throwable listed in noRetryFor. private Object doRetryWithExponentialBackoff(ProceedingJoinPoint pjp int maxAttempts Class<? extends Throwable>[] noRetryFor) throws Throwable { Throwable lastThrowable = null; for (int attempts = 0; attempts < maxAttempts; attempts++) { try { pauseExponentially(attempts lastThrowable); return pjp.proceed(); } catch (Throwable t) { lastThrowable = t; for (Class<? extends Throwable> noRetryThrowable : noRetryFor) { if (noRetryThrowable.isAssignableFrom(t.getClass())) { throw t; } } } } throw lastThrowable; } private void pauseExponentially(int attempts Throwable lastThrowable) { if (attempts == 0) return; long delay = (long) (Math.random() * (Math.pow(4 attempts) * 100L)); log.warn(""Retriable error detected will retry in "" + delay + ""ms attempts thus far: "" + attempts lastThrowable); try { Thread.sleep(delay); } catch (InterruptedException e) { // Nothing we need to do here } } This advice could be applied to any bean you wish using Spring's Aspect support. See http://static.springsource.org/spring/docs/2.5.x/reference/aop.html for more details. +1 - bye bye to boilerplate around every jdbcTemplate use.  How about writting an aspect (DBRetryAspect) over it;It will be more transparent.  something like this: private int retries; /** * Make this configurable. */ public void setRetries(final int retries) { Assert.isTrue(retries > 0); this.retries = retries; } public Object yourMethod() { final int tries = 0; Exception lastException = null; for (int i = 0; i < this.retries; i++) { try { return jdbcTemplate.execute ... (your code here); } catch (final SQLException e) { lastException = e; } catch (final DataAccessException e) { lastException = e; } } throw lastException; }  Try this. My considerations are : run a loop until the statements executed successfully. If there is a failure tolerate the failure for 5 times and each time it will wait for 2 seconds for the next execution. JDBCTemplate jdbcTemplate = new JdbcTemplate(dataSource); boolean successfullyExecuted = false; int failCount = 0; while (!successfullyExecuted){ try{ jdbcTemplate.execute(new CallableStatementCreator() { @Override public CallableStatement createCallableStatement(Connection con) throws SQLException { return con.prepareCall(query); } } new CallableStatementCallback() { @Override public Object doInCallableStatement(CallableStatement cs) throws SQLException { cs.setString(1 subscriberID); cs.execute(); return null; } }); successfullyExecuted = true; } catch (DataAccessException dae) { if (failedCount < 5){ failedCount ++; try{java.lang.Thread.sleep(2 * 1000L); // Wait for 2 seconds }catch(java.lang.Exception e){} }else{ throw new CougarFrameworkException( ""Problem removing subscriber from events queue: "" + subscriberID dae); } } catch (java.sql.SQLException sqle){ if (failedCount < 5){ failedCount ++; }else{ try{java.lang.Thread.sleep(2 * 1000L); // Wait for 2 seconds }catch(java.lang.Exception e){} throw new CougarFrameworkException( ""Problem removing subscriber from events queue: "" + subscriberID dae); } } }"
849,A,"Reading a BLOB using JDBC Spring without a result set I have an Oracle stored procedure that returns a BLOB in an output parameter: PROCEDURE GET_IMAGE_DATA(i_image_type IN NUMBER o_image_data OUT BLOB) IS BEGIN SELECT IMAGE_DATA INTO o_image_data FROM IMAGES WHERE IMAGE_TYPE = i_image_type; END GET_IMAGE_DATA; I want to use JDBC Spring to read this data. However DefaultLobHandler (and I think OracleLobHandler) getBlobAsBytes() requires a resultset. private static class QueryForBinaryCryptKey extends StoredProcedure { private static final String SQL = ""IMAGE_PKG.GET_IMAGE_DATA""; private DefaultLobHandler lobHandler; QueryForImageData(DataSource dataSource) { super(dataSource SQL); setFunction(false); lobHandler = new DefaultLobHandler(); declareParameter(new SqlParameter(KEY_TYPE OracleTypes.NUMBER)); declareParameter(new SqlOutParameter(KEY_BLOB OracleTypes.BLOB)); } public Map getImage(int keyType) { Map outParams = super.execute(inParams(keyType)); //how can I get the contents of the blob right here since //getBlobAsBytes requires a resultSet??? return outParams; } private Map inParams(int keyType) { Map params = new HashMap(); params.put(KEY_TYPE new Integer(keyType)); return params; } } How can I get the blob data when all I have is an out parameter and not a resultset? The JDBC Spring API (DefaultLobHandler and OracleLobHandler) require a ResultSet object for their BLOB related methods. You need to convert your GET_IMAGE_DATA procedure into a function: FUNCTION ATTACHMENT_BLOB_GET(IN_IMAGE_TYPE IN IMAGES.IMAGE_TYPE%TYPE) RETURN SYS_REFCURSOR AS results_cursor SYS_REFCURSOR; BEGIN OPEN results_cursor FOR SELECT t.image_data FROM IMAGES t WHERE t.image_type = IN_IMAGE_TYPE; RETURN results_cursor; END; OUT parameters are always good for some grief BLOBs especially.  It is indeed possible to read Blob as Stream/byte[] without a ResultSet. Check this one out."
850,A,"How do I make a prepared statement? How can I make an prepared statement of this one?  Statement stmt = con.createStatement(); long lastid = getLastId(stmt); // create a SQL query String strQuery = ""INSERT INTO studenten "" + "" (id naam adres postcode plaats geboren) "" + "" VALUES ("" + (lastid+1) + """" + ""'"" + contact.getNaam() + ""'"" + ""'"" + contact.getAdres() + ""'"" + ""'"" + contact.getPostcode() + ""'"" + ""'"" + contact.getPlaats() + ""'"" + ""{d '"" + contact.getGeboren() + ""'}"" + "") ""; stmt.executeUpdate(strQuery); stmt.close(); con.close(); What database system are you using? You need to substitute values with question marks ? as placeholders. String sql = ""INSERT INTO studenten (id naam adres postcode plaats geboren)"" + "" VALUES (? ? ? ? ? ?)""; Connection connection = null; PreparedStatement statement = null; try { connection = database.getConnection(); statement = connection.prepareStatement(sql); statement.setLong(lastId + 1); // Why don't you use an generated sequence? This is plain ugly and errorprone. statement.setString(contact.getNaam()); statement.setString(contact.getAdres()); statement.setString(contact.getPostcode()); statement.setString(contact.getPlaats()); statement.setDate(new java.sql.Date(contact.getGeboren().getTime())); // Assuming it returns java.util.Date statement.executeUpdate(); } finally { // Always close in finally to prevent resource leaks. if (statement != null) try { statement.close(); } catch (SQLException ignore) {} if (connection != null) try { connection.close(); } catch (SQLException ignore) {} } See also: JDBC tutorial - Using prepared statements thanks!the lastID thingy is just part of the source I needed to edit not sure why they use You're welcome."
851,A,How to save Map objects in Java to MySQL database I have Java Map (out of Strings and Ints) objects that I want to save to a database. Is there a standard way to go about this task? Is there a way to compress the Map to take less space on the harddrive? Have a look to http://stackoverflow.com/questions/369916/serializing-a-java-map-to-a-db As a java object or the data it contains? You actually ask two different questions: How to save a Map object to a database You need to create a database and an appropriate table. You can of source serialize the Map into a binary object and store that in the database as a BLOB. It will be better however to have a table entry for every object in the map. You need to use the JDBC API to communicate with the database. How to compress the Mao to take less space in the hard drive? You need to serialize the Map to a file. The map will be saved in a binary file which you can try to compress.
852,A,JDBC proxy to simulate a SQL view? I need to be able to execute (via JDBC) a straightforward SQL select query against a view (the view can be generated via a fairly complex source query). Here's the catch: I don't have write access to the database so I can't create the view there. Is anyone aware of a JDBC proxy that will let you define a view against the underlying database? The database happens to be MSSQL if that helps but bonus points for a db-agnostic proxy. Certainly I can implement my own as a brute-force solution but I would much prefer to avoid re-inventing the wheel if there's a solution out there already. For purposes of this question assume that read-only db access and querying the JDBC driver against the view schema (with no end-user knowledge of the underlying db schema) are non-negotiable. You can use what is called an inline view using a subselect: SELECT * FROM (SELECT * FROM ...) x In this example x is the table alias. What goes on within the brackets is the inline view - it can be whatever valid SQL statement to represent the view you need for your situation. It's not reuseable in the sense that a typical SQL view would be but it's less effort than whatever infrastructure you're proposing to create. To add the subselect/inline view is executed *first*
853,A,"Best Way to get XML from a JDBC resultset I'm looking for the best approach to getting an XML document from a JDBC resultset. The structure of the XML isn't awfully important but it should be fairly speedy. For clearification I would like the data from the resultset and only enough metadata to identify the data (field names essentially). I'm working with MySQL DB2 SQL Server at the moment but the solution needs to be database agnostic (for XML in SQL Server isn't a viable option). [Here](http://www.java2s.com/Code/Java/Database-SQL-JDBC/ConvertaResultSettoXML.htm) you can find a good solution. I agree with the first respondent that you can get very nice human+computer readable XML representation just be writing a little code. I took that same approach back in 2002 to create a middleware business object to XML/PDF/HTML/XHTML/XLS reporting tool. It only took a few hours to program the business object to XML converter. I took advantage of fact that the objects were not self-referential. Otherwiise I would have had to add reference(s) elements not just flatten the values out. There is also the WebRowSet technique if you use Java 5 or later. I cannot say its output looks super appealing for consuming directly by XSLT but it is still usable. Far more palatable than typical JAXB output. However now there is now a cooler approach if you are running Java 6 or later. If you are using JDBC 4 you can specify a Dataset with a generic type parameter identifying the class and JDBC will populate the fields of that class with the data. That's the first half of the trick. See JDBC Annotations for more details The second half of the trick is to use XStream to convert a collection of those into XML. XStream usually gives a good result the first time. You can make the XML generated really clean readable concise (i.e. ""tight"") by supplying XStream with some aliases to use. And if that does not work there are lots of other ways of Tweaking the Output.  By using WebRowSet once can convert the entire ResultSet into XML. The XML generated by WebRowSet is far clear and simple i am not sure about the speed since it also depends upon driver implementations. Here is a good article on WebRowSet using Oracle which will fulfill your needs i guess.  Are you looking to convert the ResultSet table into XML? I don't know of any thirdparty tool but tt is not very difficult to roll one of your own. Your two options are to either have a constant format: <ResultSet> <MetaData> <Column name=""...."" type=""...""/> .... <MetaData> <Data> <Row><Cell value=""valueConvertedToString""/><Cell null=""true""/></Row> .... </Data> </ResultSet> Or metadata specific: <ResultSet> <MetaData> <Column name=""id"" type=""int""/> <Column name=""color"" type=""string""/> .... <MetaData> <Data> <Row><id value=""45""/><color null=""true""/></Row> .... </Data> </ResultSet> In the second case you can't define schema statically."
854,A,"Reading greek text from jdbc / SQL Server 2005 and displaying it with a servlet Well the subject says it all but I will explain a little further. I have a database in MS SQL server 2005 that contains greek text. I have created a servlet that connects to that database using net.sourceforge.jtds.jdbc.Driver and receive some data with the following commands: Connection con = DriverManager.getConnection(connectionUrl); Statement sta = con.createStatement(); ResultSet res = sta.executeQuery(""SELECT * FROM data""); After that I want to use output.println to display the data to the page. The result is that greek characters are displayed as question marks (?). I tried changing the encoding charset of the browser but no luck so the problem must be to the page. I also tried displaying new String( res.getBytes(""text"") ""ISO-8859-7""); instead of res.getString(""text"") with different encodings (UTF-8 UTF-16) but still no luck ! What can I do to see the greek characters ??? TIA ! You need to set the response encoding to UTF-8. Since you normally use JSP for displaying data you can do this by placing the following line at the top of the JSP page: <%@ page pageEncoding=""UTF-8"" %> Also see this article for more background information and all the other aspects you'll need to take into account as well for a Java EE webapplication. I was using servlets instead of JSP however the article about unicode was great !  The problem may be at a number of locations. Check them all: the database encoding the connection encoding the response encoding (response.setCharacterEncoding(""utf-8"")) The problem was with the response encoding. Adding the line response.setContentType (""text/html;charset=utf-8""); solved the problem !"
855,A,"How to I retrieve an image from a URL and store it as a Blob in Java (google app engine) I understand how to fetch a URL text page and loop over the results URL url = new URL(this.url); BufferedReader reader = new BufferedReader(new InputStreamReader(url.openStream())); String line; while ((line = reader.readLine()) != null) { .... How would I do this to fetch an image and store it as a Blob? Well what I do to store binary data such as images is quite simplictic. In my case I deal with uploaded files which get posted to a servlet. Inside the servlet I get the InputStream on the posted body with request.getInputStream(). However this works with any kind of InputStreawm inlcuding one based on an URL. The sample code below shows how to convert that InputStream into google appeninge Blob which then you can for instance make persistant in the data store. ... import org.apache.commons.io.IOUtils; import com.google.appengine.api.datastore.Blob; ... public void InputStreamToBlob(InputStream i) throws IOException { ... Blob content = new Blob(IOUtils.toByteArray(i)); ...  Just get it straight as InputStream and use PreparedStatement#setBinaryStream() to store it. It's binary data not character data so a Reader would only messup things you don't want to have that. In a nutshell: InputStream input = imageUrl.openStream(); // ... statement = connection.prepareStatement(""INSERT INTO image (content) VALUES (?)""); statement.setBinaryStream(1 input); statement.executeUpdate(); A PreparedStatement is really useful. It not only saves you from SQL injections but it also eases setting fullworthy Java objects like InputStream in a SQL statement. You can learn more about PreparedStatement at the JDBC tutorial. Thanks I'm making more progress with the InputStream however since I am using Google App Engine I need to store the Blob to a property in an object. Could you clarify how I might convert the InputStream to a Blob? Why would you ? Just use `PreparedStatement#setBinaryStream()` to store `InputStream` into a DB blob field and use `ResultSet#getBinaryStream()` to retrieve `InputStream` from a DB blob field. No need to hassle with `java.sql.Blob` or something tight-coupled like that in Java code. Thanks for your help the little piece I was missing was to byte[] theBytes = new byte[input.available()]; input.read(theBytes); Trouble!! 1) Don't store it as `byte[]` it's memory hogging just stick to `InputStream`. 2) Don't use `input.available()` it's just returns the next amount bytes available for read without blocking the stream it doesn't denote the full content length (but which may **by coincidence** do so in case of smaller files). Thanks for the advice. I abandoned this train of thought soon afterwards but I will keep your tips handy for the next time. @BalusC I'm trying to follow your code but `setBinaryStream(1 input)` has one more int parameter for file size. How do you get around that? @mlevit: this parameter is optional. Do we need to close the inputStream or will it be closed once the update is executed?  For an image instead of reading the buffer line by line you'll load it in byte array and save this byte array as a blob. That's also possible it's only possibly more memory hogging than using `InputStream`."
856,A,"JDBC generation of SQL in PreparedStatement I had a really huge problem recently which took me a lot of time to debug. I have an update statement which updates 32 columns in table. I did that with PreparedStatement. Accidentaly I deleted one setParameter() call so update could not be finished successfully. I got exception from JDBC (Apache Derby) telling: ""At leas one parameter is not initialized"" and was not able to figure out which parameter is not set since driver would not tell you nothing about name or ordinal number of at least first parameter which is not set... I was googleing unsuccessfully for some utility which will produce plain old SQL out of (nearly-finished) prepared statement. It would help a lot in situations like this one since I will be able to see what is not set. Have anyone faced this problem? Got any solution? Since the parameters in a prepared statement are just a List or Map in the PreparedStatement Object you should be able to inspect the values. Also you could write a very simple Wrapper around you jdbc driver that creates wrapped PreparedStatements and logs all parameters and there settings before actually executing the statement.  Have a look at P6Spy. It can intercept all your JDBC calls and log them before forwarding them onto your database. Alternatively think about using Springs JDBCTemplate which can take out alot of your boilerplate JDBC coding and help avoid these kind of mistakes. You don't need the rest of the Spring framework to use this bit."
857,A,oracle 11g thin jdbc driver compatible with oracle 10g database? Currently I'm using the ojdbc14.jar Oracle 10g thin driver to access an Oracle 10g database. I would like to upgrade the driver to the thin ojdbc6.jar Oracle 11g driver ahead of the actual upgrade of the DB server occurs. Using an 11g driver against the 10g DB seems fine in testing so far but I'm wondering if anyone can confirm this OK. I looked through the Oracle docs and Readme files but didn't see anything. This question is similar to this one but that wasn't for Java and didn't seem to have a definitive answer. Yes the upwards and downwards compatibility is usually pretty good. I've successfully used such configuration several times in the past. Having said that I remember one occasion where we had a problem with calling a stored procedure that returned an open cursor to the Java application. Going back to an older version of the OJDBC driver solved it. At the time it was a Oracle 9i database. So with some testing you can become confident it works.
858,A,"How do I lookup a JNDI Datasource from outside a web container? I have the following environment set up: Java 1.5 Sun Application Server 8.2 Oracle 10 XE Struts 2 Hibernate I'm interested to know how I can write code for a Java client (i.e. outside of a web application) that can reference the JNDI datasource provided by the application server. The ports for the Sun Application Server are all at their defaults. There is a JNDI datasource named jdbc/xxxx in the server configuration but I noticed that the Hibernate configuration for the web application uses the name java:comp/env/jdbc/xxxx instead. Most of the examples I've seen so far involve code like Context ctx = new InitialContext(); ctx.lookup(""jdbc/xxxx""); But it seems I'm either using the wrong JNDI name or I need to configure a jndi.properties or other configuration file to correctly point to a listener? I have appserv-rt.jar from the Sun Application Server which has a jndi.properties inside of it but it does not seem to help. There's a similar question here but it doesn't give any code / refers to having iBatis obtain the JNDI Datasource automatically: http://stackoverflow.com/questions/39053/accessing-datasource-from-outside-a-web-container-through-jndi If you're talking some every day generic Java application running outside of the container then you're out of luck. Effectively you would need to configure your own JNDI implementation with it's own configure connection pool etc. However you can write Java EE ""standalone"" applications. These are applications that run within the Java EE application client. Basically it's an app that is deployed and packaged but then executed using a launcher that's provided by your Java EE container. When running within an application client environment all of the resources of the app server (connection pools EJBs queues etc.) are available to your app just like they would be if the code were deployed within the app server. Here is some tutorial documentation for Sun App Server 8.2 which is a J2EE 1.4 container. If it's possible I'd strongly suggest upgrading to Glassfish v2.1 just a more modern better all around server that should deploy your apps just fine as is since it's a descendant of 8.2. Thanks for the idea of writing a standalone JEE application. It's an interesting alternative but I was hoping for the possibility of using the app server as a direct JNDI provider to obtain the remote datasource directly. The choice of Sun App Server 8.2 is due to legacy reasons unfortunately so we can't shift to Glassfish which would definitely be better.  I got stuck on this exact same problem. I wrote a small tutorial. Basically you have to create your own implementation of the DataSource objects and add them to your own custom initial context. There are source examples here: http://penguindreams.org/blog/running-beans-that-use-application-server-datasources-locally/  What you want is an ""application client"" (see http://java.sun.com/developer/technicalArticles/J2EE/appclient/ for details). Alternatively you could establish a plain JDBC connection from your standalone client which might be easier to create - but you'll have to configure the connection details in the client and can not reuse the settings from your application server. Hi thanks for the response. The application client is interesting but it's a little too heavy for my needs. The intent was to reuse the connection defined in the web-server to maintain consistency as a single point to get a database connection.  This might be a bit late for you but I have used the Simple-JNDI library for many years for the exact purpose you mention. I'm not sure if it has all the options you may need but it sufficed for my command line utilities. The library can be found at: https://code.google.com/p/osjava/wiki/SimpleJNDI"
859,A,mysql propogate sql exception to java program i have a java program that is calling a Mysql stored procedure that is rolling back when it gets an SQLException. When i added the rollback (exit handler) to the store procedure the java program stopped getting the sql exception. i need for the java program to get a sql exception and the error message from mysql. does any one know how this is done? here is my store procedure: DELIMITER $$ DROP PROCEDURE IF EXISTS up_OMS_insertParticipantOmsOrderOwner $$ CREATE PROCEDURE up_OMS_insertParticipantOmsOrderOwner( IN PID int IN OwnerName varchar(50) IN DisplayName varchar(50) IN Enabled tinyint(1)) BEGIN declare exit handler for SQLException BEGIN rollback; END; start transaction; if (DisplayName<>'') then insert OmsOrderOwner (ParticipantID OmsOrderOwnerName DisplayName Enabled) value (PID OwnerNameDisplayName Enabled); else insert OmsOrderOwner(ParticipantID OmsOrderOwnerName DisplayName Enabled) value (PID OwnerNamenull Enabled); end if; set @OwnerID := @@identity; insert UserOmsOrderOwnerSubscription (UserID ParticipantID OmsOrderOwnerID Enabled) select userOrderSub.UserId PID @OwnerID 1 from Users u UserOmsOrderSubscription userOrderSub where userOrderSub.UserID = u.UserID and u.ParticipantID = PID; commit; END $$ DELIMITER ; Since you handled the error in STP it's not an exception anymore. It should be just a normal return status of your call. You should return something from the exit handler like declare exit handler for SQLException BEGIN rollback; select 1; END; start transaction; 1 or whatever will be error code for rollback. If you still think this is an exception you can use resignal in MySQL 6.0. In earlier version  you can just trigger an error by calling a non-existant function like this  call ROLLED_BACK_EXCEPTION(); Resignal works starting with 5.4 not 6.0. And creating a fake error (by calling non-existent function) instead of returning an actual one is less than ideal for many reasons.  Use RESIGNAL statement in your exit handler to rethrow the error. That said do you REALLY need to explicitly begin / commit / rollback transaction within your stored procedure? JDBC call will be (should be) done within its own transaction anyway can you instead rely on it to handle the error / rollback and save yourself some trouble perhaps? yeah we may move the commit and rollback in our java code. unfortunately we can't do that in the short term. Also unfortunate is that we are on version 5.0x of mysql so resignal doesn't work. I can write a signalFunct myself but i won't get the mysql error message.
860,A,Read rows from a mysql table via java I need sample code to read rows of data from a mysql table using java Standard tutorial from Oracle/Sun example with explanation  I wouldn't recommend using the JDBC API directly it's error prone (sooner or later you forget to close a conection) and too verbose. There are many nice layers to use on top of JDBC. If you want to write SQL I think Spring JDBCTemplate is nice. Or better Groovy's SQL support (if you are just bound to 'Java the platform' not 'Java the language'). Then there are object relational mappers (ORM) where you don't need to write SQL. Take a look at Hibernate and JPA You're forgetting that the company writing database drivers uses JDBC.....  A very simple tutorial: http://www.vogella.de/articles/MySQLJava/article.html Google is your friend.  Here is a tutorial with sample code: http://www.developer.com/java/data/article.php/3417381/Using-JDBC-with-MySQL-Getting-Started.htm
861,A,"How can I identify columns when SELECTing from multiple tables with JDBC? I have two tables that I join on the id-column they look like: +-------+ | users | +----+--+---+ | id | name | +----+------+ +-------+ | posts | +-------+------+---------+ | id | user_id | message | +----+---------+---------+ And now I want to select all posts and include the username with: SELECT * FROM posts users WHERE user_id = users.id And then I try to get the values with: ResultSet rs = // SQL if(rs.next()) { rs.getInt(""posts.id""); ... } But I get SQLException when executing rs.getInt(""posts.id"") : java.sql.SQLException: Column 'posts.id' not found. How can I get the values from the SQL-query above using JDBC and JavaDB/Derby as database? How can I distinguish between the id column in the users and posts table when retrieving values with ResultSet? Solution 1 : use alias select u.id as uid u.name p.id as post_id p.user_id p.message from users u inner join posts p on u.id=p.user_id Solution 2: remove the duplicate user.id since you already have it in the posts table select p.user_id u.name p.id as post_id p.message from users u inner join posts p on u.id=p.user_id  You're attempting to retrieve the id value but you're using ""posts.id"" to reference it. Don't All you need is the column name or alias not the table name as well: ResultSet rs = // SQL if(rs.next()) { rs.getInt(""id""); ... } It would've worked if your column name itself was ""posts.id"" but I recommend using underscore (_) instead of a period should you choose to update the table. But I have an id column in both tables how do i distinguish between them? You need to specify a column alias: SELECT p.id AS post_id p.name u.id AS users_id p.user_id --redundant due to relationship omit if possible u.message FROM POSTS p JOIN USERS u ON u.id = p.user_id ...and reference that column alias in the Java code: ResultSet rs = // SQL if(rs.next()) { rs.getInt(""post_id""); ... } But I have an `id` column in both tables how do i distinguish between them if I use only `rs.getInt(""id"")` instead of `rs.getInt(""posts.id"")` and `rs.getInt(""users.id"")` ? @Jonas: Updated  you can simplify these further by getting data as per the column index instead of getting it by column name..!! what ever data we retrieve from DB is stored in result set in the column order as per the select statement so instead of getting data as per the column name prefer fetching data as per the column index in result set.. ex: String query = "" select agenum from table_abc""; ResultSet rs= statement.executeQuery(query); while(rs.next){ int var1= rs.getInt(1); int var2= rs.getInt(2); } these will help you do away with complexity and confusion created due to similar column names in your database tables.. Hope these helps... All the best..!!  Alias the column names SELECT posts.id posts_id name name id id user_id message FROM posts INNER JOIN users ON posts.user_id = users.id depending on your sql flavour that alias may need to be posts.id as posts_id"
862,A,"How do you determine if a JDBC Connection was retrieved from a JTA enabled DataSource or straight JDBC? I'm using a vendor API to obtain a JDBC connection to the application's database. The API works when running in the application server or when running in a stand-alone mode. I want to run a series of SQL statements in a single transaction. I'm fine with them occurring in the context of the JTA transaction if it exists. However if it doesn't then I need to use the JDBC transaction demarcation methods. (Calling these methods on a JDBC connection that is participating in a JTA transaction causes a SQLException.) So I need to be able to determine whether the Connection came from the JTA enabled DataSource or if it's just a straight JDBC connection. Is there a straight forward way to make this determination? Thanks! What thilo says does make sense. Otherwise Not sure of a straight way BUT I will give you a ""hack"" way write a BAD SQL which you know will give a DB exception. That will result in a stack trace. From the stack trace you can find out if it is a JTA derived connection or NOT ?  You could try to check the Connection's autoCommit flag to see if it is in a transaction (regardless of where it came from). (Apparently see the accepted answer this does not work too well. I am not deleting this answer because the following still stands: ) But I think you should really modify your API to depend on external transactions exclusively. If you still want to support plain JDBC wrap it into a separate API that just starts the transaction. Update: Just re-read your question and saw that you are not providing an API but want to use a container-managed connection. But still can you just mandate (as part of your application's requirements) that JTA be in effect? If not you could provide a configuration option to fall back to manually managed transactions. For such a critical feature it seems reasonable to require the proper configuration (as opposed to try to guess what would be appropriate). Auto commit is a behaviour that says commit anyway it doesnt actually communicate whther something is XA or transacted etc.  Even if it's straight JDBC you can have a JTA transaction enabled. Checking the autoCommit flag will NOT help in this regard. You can be in a transaction distributed or otherwise with autoCommit set to false. autoCommit set to true would tell you you're not in a distributed transaction but a value of false just means you won't auto-commit... it could be in any kind of transaction. I think you're going to have to call UserTransaction.getStatus() and verify that it is not equal to Status.NoTransaction(). This would tell you if you're in a JTA transaction."
863,A,"Using Hibernate sequence generators manually Basically I want a way to access sequence values in a database-neutral way. The use case is that I have a field on an entity that I want to set based on an incrementing value (other than the id). For instance say I have a Shipment entity. At some point after the shipment gets created it gets shipped. Once it gets shipped a manifest number is generated for it and assigned. The manifest number looks something like M000009 (Where the stuff after the 'M' is a left-padded value from a sequence). Something similar was asked here at SO  but I'm not a fan of the solution since it requires another table to maintain and seems like a weird relationship to have. Does anyone know if it is possible to use something like hibernate's MultipleHiLoPerTableGenerator as something other than an ID generator? If that's not possible does anyone know of any libraries that handle this (either using hibernate or even just pure JDBC). I'd prefer not to have to write this myself (and have to deal with prefetching values locking and synchronization). Thanks. Here is a code samnple. I would like to caveat this with - I have not comiled this and it reuires spring code. Having said this it should still provide the bones of what you want to do. public Long getManifestNumber() { final Object result = getHibernateTemplate().execute(new HibernateCallback() { public Object doInHibernate(Session sess) throws HibernateException SQLException { SQLQuery sqlQuery = sess.createSQLQuery(""select MY_SEQUENCE.NEXTVAL from dual""); sqlQuery.uniqueResult(); } }); Long toReturn; if (result instanceof BigDecimal) { toReturn = ((BigDecimal)result).longValue(); } return toReturn; }  I think the complexity of your task depends on whether or not you manifest number needs to be sequential: If you don't need sequential manifest numbers then it's happy days and can use a sequence. If you do need sequential manifest numbers (or your database doesn't support sequences) then use an id table with the appropriate locking so that each transaction gets a unique sequential value. Then you've got 2 options that I can think of: write the necessary JDBC code on your client ensuring (if the manifest number is sequential) that the transaction being used is the same as that for the database update. use a trigger to create the manifest number when the appropriate update occurs. I think my preference would be the trigger because the transaction side of things would be taken care of although it would mean the object would need refreshing on the client.  I didn't read over the linked similar solution but sounds like something I wound up doing. I created a table just for sequences. I added a row to the table for each sequence type I needed. I then had a sequence generator class that would do the necessary sql query to fetch and update the sequence value for a particular named sequence. I used hibernate's Dialect class to do it in a db neutral way. I also would 'cache' the sequences. I would bump the stored sequence value by a large number and then dole those out those allocated sequences from my generator class. If the class was destroyed (ie. app shutdown) a new instance of the sequence generator would start up at the stored value. (having a gap in my sequence numbers did not matter)"
864,A,"Invalid Cursor State on every query JDBC Spring Derby. Configuration problem? I am just getting started with Spring (MVCWebflow etc etc) and I am trying to write my own small web application. As a database I am using Apache Derby which I set up though the Eclipse Database Developer plug-ins. Now my problem: Everytime I fire queries through the JDBCTemplate I get an ""Invalid cursor state"" exception at runtime. These are queries that work when they are manually tested (aka ask the database through the SQL Scrapbook. This is my simplest DAO method: public List<Player> getAllPlayers() { JdbcTemplate select = new JdbcTemplate(dataSource); List<Player> result = select.query( ""SELECT ID  Name  TeamID "" + ""FROM PLAYERS ""  new PlayerExtractor()); return result; } And this is the corresponging ResultSetExtractor: @Override public Object extractData(ResultSet rs) throws SQLException DataAccessException { Player player = new Player(); player.setId(Integer.valueOf(rs.getString(1))); player.setName(rs.getString(2)); TeamDAO t_dao = new TeamDAOImpl(); Team team = t_dao.getTeamByKey( Integer.valueOf(rs.getString(3)) ); player.setTeam(team); return player; } As soon as rs.getString(1) the ""invalid cursor state"". What is the problem? I have a feeling that it is a configuration problem.. Here is my JDBC configuration in my ApplicationContext: <bean id=""dataSource"" class=""org.springframework.jdbc.datasource.DriverManagerDataSource""> <property name=""driverClassName"" value=""org.apache.derby.jdbc.Driver169""/> <property name=""url"" value=""jdbc:derby:C:\Dokumente und Einstellungen\araptarc\MyDB""/> <property name=""username"" value=""APP""/> <property name=""password"" value=""test""/> Any ideas? Thanks! I see you specified value=""org.apache.derby.jdbc.Driver169"". Are you trying to run in a J2ME configuration? Can you set up a test where you run your application using an embedded Derby configuration with a full JDK and see if your program works correctly in that case?"
865,A,how to access a mySQL enum field with Java ResultSet and PreparedStatement Quick question what's the correct way to use ResultSet and PreparedStatement to access an ENUM field in MySQL? never did but I would use String see the documentation: 21.4.4.3. Java JDBC and MySQL Types
866,A,"Default Schema in Oracle Connection URL I'd like to set default database schema in Oracle Connection URL jdbc:oracle:thin:@<server>:<port1521>:<sid> My sample SQL statement: select monkey_name from animals.monkey I need to query database without schema prefix anymals. i.e. when I run this statement select monkey_name from monkey it will uses animals schema by default. What do I need to specify in connection URL above get such effect? Thanks You can't put anything in the connection URL. In Oracle each user has their own schema (even if doesn't contain any objects) and that is their default schema. Once logged in/connected they can change their default schema with an ALTER SESSION SET CURRENT_SCHEMA=animals So you'd need to do the extra statement after connecting. It is possible to have a logon trigger on the user and/or database that will run this when they log in. I'd personally prefer an explicit statement when an application connects. I can now see that this should be a solution. By having this logon trigger I don't have to modify my sql. So all generic statements are still portable. This looks like something I can work around it. Create logon trigger with this statement might be my possible solution. Thanks.  If you use C3PO you can make it do it when it checks the connection out. As properties: c3p0.preferredTestQuery=alter session set current_schema=animals c3p0.testConnectionOnCheckout=true As Java code: ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setPreferredTestQuery(""alter session set current_schema=animals""); dataSource.setTestConnectionOnCheckout(true); Downside is this will happen every time the connection is taken out of the pool. If you are using a JDBC connection yourself you could just do: Class.forName(""oracle.jdbc.driver.OracleDriver""); Connection connection = getConnection(""jdbc:oracle:thin:@//server:1521/instance"" ""username"" ""password""); connection.createStatement().execute(""alter session set current_schema=animals""));  What about the use of synonyms? create synonym monkey for animals.monkey; select monkey_name from monkey +This solution is quite commonly used and works well. It's a good idea. However I find it is not definite I am not sure if there are any side effects that could break things along the way. This is usually the much better choice over altering the session since it shifts the problem from a behavioural aspect to a structural which is much more robust."
867,A,Concurrent queries on a given JDBC connection? I'm seeing OraclePreparedStatement executeQuery() exhibit serialization. That is I have two queries that I want to run concurrently against an Oracle database using the same connection. However the OraclePreparedStatement seems to explicitly prohibit concurrent queries. My question is: Is this serialization a necessary artifact of running both queries on the same connection or is this configurable? I've tried setting readOnly to true for the duration of the two queries but they still serialize. I believe that Oracle's Connection class methods are synchronized. see this api description. This would then be an artifact of using the same connection and not a configurable property. If you need to get around this limitation you can either use 2 connections or look into connection pooling if you want a more flexible solution. Thanks. Both threads are using the same connection from the pool. It would take a little re-working to avoid the use of a temporary table so I was hoping for an easier solution before going down that road. if that is the case you may want to reconsider the design of the pool. the pool shouldn't give out connections that currently are in use. It's not. I'm reworking a long-running task that issues about 8 queries sequentially. A couple of them can be done concurrently so I was starting two threads to run two queries concurrently and handing the queries the same connection. Now the code grabs two connections so each thread has its own connection. Works like a champ.
868,A,"Are there any good CachedRowSet implementations other than the proprietary Sun one? I am investigating using javax.sql.rowset.CachedRowSet in part of my application however I can only find information on using the proprietary sun implementation com.sun.rowset.CachedRowSetImpl or Oracle specific implementations. The sun implementation is unsupported and subject to change. Using this could also cause problems if I want to deploy to non-Sun virtual machines in the future and finally it leaves unsuppressible warnings in our build logs which can mask other warnings. Is there an open source alternative implementation that we I can deploy with my application that will work well across multiple databases? At a minimum something that supports MySQL. Oracle Implementation Is Open-Source The question incorrectly states that the Oracle RowSet implementation is proprietary. It is not; it already is open-source. The source code is released as free software under the GNU General Public Library (GPL) version 2 license. Read the source code to see the license. So they cannot be withdrawn. You and others are free to maintain or modify these classes provided you follow the terms of the GPL. JDBC Driver Implementation Also some JDBC drivers provide an implementation of RowSet. I do not know if any are open-source but that would be one avenue to explore.  Here is my improved implementation of CachedRowSetImpl to support MySQL 5.x names and labels. Based on the implementation of thiy guy http://tech.groups.yahoo.com/group/Firebird-Java/message/10715 import java.math.BigDecimal; import java.sql.Array; import java.sql.Blob; import java.sql.Clob; import java.sql.Ref; import java.sql.SQLException; import java.util.Calendar; import java.util.Collection; import java.util.Hashtable; import javax.sql.rowset.RowSetMetaDataImpl; import com.sun.rowset.CachedRowSetImpl; public class FixedCachedRowSetImplMySql extends CachedRowSetImpl { private static final long serialVersionUID = -9067504047398250113L; private RowSetMetaDataImpl RowSetMD; public FixedCachedRowSetImpl() throws SQLException { super(); } public FixedCachedRowSetImpl(Hashtable env) throws SQLException { super(env); } private int getColIdxByName(String name) throws SQLException { RowSetMD = (RowSetMetaDataImpl) this.getMetaData(); int cols = RowSetMD.getColumnCount(); for (int i = 1; i <= cols; ++i) { String colLabel = RowSetMD.getColumnLabel(i); String colName = RowSetMD.getColumnName(i); if (colName != null) if (name.equalsIgnoreCase(colName) || name.equalsIgnoreCase(RowSetMD.getTableName(i) + ""."" + colName)) { return (i); } else if (colLabel != null) if (name.equalsIgnoreCase(colLabel)) { return (i); } else continue; } throw new SQLException(resBundle.handleGetObject(""cachedrowsetimpl.invalcolnm"").toString()); } @Override public Collection<?> toCollection(String column) throws SQLException { return toCollection(getColIdxByName(column)); } @Override public String getString(String columnName) throws SQLException { return getString(getColIdxByName(columnName)); } @Override public boolean getBoolean(String columnName) throws SQLException { return getBoolean(getColIdxByName(columnName)); } @Override public byte getByte(String columnName) throws SQLException { return getByte(getColIdxByName(columnName)); } @Override public short getShort(String columnName) throws SQLException { return getShort(getColIdxByName(columnName)); } @Override public int getInt(String columnName) throws SQLException { return getInt(getColIdxByName(columnName)); } @Override public long getLong(String columnName) throws SQLException { return getLong(getColIdxByName(columnName)); } @Override public float getFloat(String columnName) throws SQLException { return getFloat(getColIdxByName(columnName)); } @Override public double getDouble(String columnName) throws SQLException { return getDouble(getColIdxByName(columnName)); } @Override public BigDecimal getBigDecimal(String columnName int scale) throws SQLException { return getBigDecimal(getColIdxByName(columnName) scale); } @Override public byte[] getBytes(String columnName) throws SQLException { return getBytes(getColIdxByName(columnName)); } @Override public java.sql.Date getDate(String columnName) throws SQLException { return getDate(getColIdxByName(columnName)); } @Override public java.sql.Time getTime(String columnName) throws SQLException { return getTime(getColIdxByName(columnName)); } @Override public java.sql.Timestamp getTimestamp(String columnName) throws SQLException { return getTimestamp(getColIdxByName(columnName)); } @Override public java.io.InputStream getAsciiStream(String columnName) throws SQLException { return getAsciiStream(getColIdxByName(columnName)); } @Override public java.io.InputStream getUnicodeStream(String columnName) throws SQLException { return getUnicodeStream(getColIdxByName(columnName)); } @Override public java.io.InputStream getBinaryStream(String columnName) throws SQLException { return getBinaryStream(getColIdxByName(columnName)); } @Override public Object getObject(String columnName) throws SQLException { return getObject(getColIdxByName(columnName)); } @Override public int findColumn(String columnName) throws SQLException { return getColIdxByName(columnName); } @Override public java.io.Reader getCharacterStream(String columnName) throws SQLException { return getCharacterStream(getColIdxByName(columnName)); } @Override public BigDecimal getBigDecimal(String columnName) throws SQLException { return getBigDecimal(getColIdxByName(columnName)); } @Override public boolean columnUpdated(String columnName) throws SQLException { return columnUpdated(getColIdxByName(columnName)); } @Override public void updateNull(String columnName) throws SQLException { updateNull(getColIdxByName(columnName)); } @Override public void updateBoolean(String columnName boolean x) throws SQLException { updateBoolean(getColIdxByName(columnName) x); } @Override public void updateByte(String columnName byte x) throws SQLException { updateByte(getColIdxByName(columnName) x); } @Override public void updateShort(String columnName short x) throws SQLException { updateShort(getColIdxByName(columnName) x); } @Override public void updateInt(String columnName int x) throws SQLException { updateInt(getColIdxByName(columnName) x); } @Override public void updateLong(String columnName long x) throws SQLException { updateLong(getColIdxByName(columnName) x); } @Override public void updateFloat(String columnName float x) throws SQLException { updateFloat(getColIdxByName(columnName) x); } @Override public void updateDouble(String columnName double x) throws SQLException { updateDouble(getColIdxByName(columnName) x); } @Override public void updateBigDecimal(String columnName BigDecimal x) throws SQLException { updateBigDecimal(getColIdxByName(columnName) x); } @Override public void updateString(String columnName String x) throws SQLException { updateString(getColIdxByName(columnName) x); } @Override public void updateBytes(String columnName byte x[]) throws SQLException { updateBytes(getColIdxByName(columnName) x); } @Override public void updateDate(String columnName java.sql.Date x) throws SQLException { updateDate(getColIdxByName(columnName) x); } @Override public void updateTime(String columnName java.sql.Time x) throws SQLException { updateTime(getColIdxByName(columnName) x); } @Override public void updateTimestamp(String columnName java.sql.Timestamp x) throws SQLException { updateTimestamp(getColIdxByName(columnName) x); } @Override public void updateAsciiStream(String columnName java.io.InputStream x int length) throws SQLException { updateAsciiStream(getColIdxByName(columnName) x length); } @Override public void updateBinaryStream(String columnName java.io.InputStream x int length) throws SQLException { updateBinaryStream(getColIdxByName(columnName) x length); } @Override public void updateCharacterStream(String columnName java.io.Reader reader int length) throws SQLException { updateCharacterStream(getColIdxByName(columnName) reader length); } @Override public void updateObject(String columnName Object x int scale) throws SQLException { updateObject(getColIdxByName(columnName) x scale); } @Override public void updateObject(String columnName Object x) throws SQLException { updateObject(getColIdxByName(columnName) x); } @Override public Object getObject(String columnName java.util.Map<String Class<?>> map) throws SQLException { return getObject(getColIdxByName(columnName) map); } @Override public Ref getRef(String colName) throws SQLException { return getRef(getColIdxByName(colName)); } @Override public Blob getBlob(String colName) throws SQLException { return getBlob(getColIdxByName(colName)); } @Override public Clob getClob(String colName) throws SQLException { return getClob(getColIdxByName(colName)); } @Override public Array getArray(String colName) throws SQLException { return getArray(getColIdxByName(colName)); } @Override public java.sql.Date getDate(String columnName Calendar cal) throws SQLException { return getDate(getColIdxByName(columnName) cal); } @Override public java.sql.Time getTime(String columnName Calendar cal) throws SQLException { return getTime(getColIdxByName(columnName) cal); } @Override public java.sql.Timestamp getTimestamp(String columnName Calendar cal) throws SQLException { return getTimestamp(getColIdxByName(columnName) cal); } @Override public void updateRef(String columnName java.sql.Ref ref) throws SQLException { updateRef(getColIdxByName(columnName) ref); } @Override public void updateClob(String columnName Clob c) throws SQLException { updateClob(getColIdxByName(columnName) c); } @Override public void updateBlob(String columnName Blob b) throws SQLException { updateBlob(getColIdxByName(columnName) b); } @Override public void updateArray(String columnName Array a) throws SQLException { updateArray(getColIdxByName(columnName) a); } @Override public java.net.URL getURL(String columnName) throws SQLException { return getURL(getColIdxByName(columnName)); } }  You shouldn't be directly instantiating implementation of CachedRowSet -- use its Provider to obtain an instance: see http://docs.oracle.com/javase/7/docs/api/javax/sql/rowset/RowSetProvider.html (available since JDK7) In fact CachedRowSet's interface and related factory are standard/portable. Something like the following shoud do the trick: CachedRowSet crs = RowSetProvider.newFactory().createCachedRowSet(); crs.populate(myResultSet); This wasn't available when I asked the original question but it is good to know that this gap is addressed by Java now thanks."
869,A,"JDBC MySQL; is supplying the DB name & username/password enough? When setting up a JDBC connection in a J2EE application do you need to specify the schema name in addition to the database name? I have followed this tutorial and have setup a database and username/password but I'm coming up against this error when I startup my application. Is it possible that DBUnit is trying to insert the data before hibernate has initiated and created the schema? Caused by: org.dbunit.dataset.NoSuchTableException: Did not find table 'CLIENT' in schema 'null' My connection details are as follows :  <bean id=""dataSource"" class=""org.apache.commons.dbcp.BasicDataSource"" destroy-method=""close""> <property name=""driverClassName"" value=""com.mysql.jdbc.Driver""/> <property name=""url"" value=""jdbc:mysql://127.0.0.1:3306/salestracker""/> <property name=""username"" value=""salestracker""/> <property name=""password"" value=""salestracker""/> </bean> I have created the database : [james@nevada sales-tracker]$ mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 16 Server version: 5.1.42 Source distribution Type 'help;' or '\h' for help. Type '\c' to clear the current input statement. mysql> show DATABASES; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | salestracker | | test | +--------------------+ 4 rows in set (0.00 sec) Do I need to specify something in my hibernate persistence.xml that says to ""use"" a particular database? I was assuming this would be implied in the JDBC URL Inside of your `salestracker` database do you have a `CLIENT` table? the database is empty I have this in hibernate which I believe should create the database structure for me : ` ` sometimes hibernate has problems generating the schema which it aptly reports in the logs. Check if the table is there and then check the logs Connect to the database as root and run 'desc client' to see if the table is there (or 'show tables'). If it doesn't find it then Hibernate isn't auto-creating it. If it does find it try connecting as salestracker and doing the same thing to see if maybe that user doesn't have the correct permissions. If the table is really there the next step would be to write a simple Java program to connect and query the table i.e. remove Hibernate from the equation. Something like: Class.forName(""com.mysql.jdbc.Driver""); Connection conn = DriverManager.getConnection(""jdbc:mysql://127.0.0.1:3306/salestracker"" ""salestracker"" ""salestracker""); PreparedStatement s = conn.prepareStatement(""select count(*) from client""); ResultSet rs = s.executeQuery(); rs.next(); System.out.println(rs.getString(1));"
870,A,Reading Microsoft Access files in Java How to read (and write) MS Access files (.mdb) in Java? Is there any open-source jdbc driver for MS Access? Thanks I updated question. MDF is not a common Jet file extension. You can use the open source Jackcess library to read an Access database through Java (currently supporting Access versions 2000-2007). Jackcess is good but it only works for Access 2000 (JET4) files. @Yuval: Thanks I edited my answer to include that information. @Bill the Lizard can you update this entry? Jackcess now supports Access 2000 through 2007. @Nitrodist: Sure thanks for the heads up! @David: I don't have Access 2010 to test with but I imagine they'd claim support if it worked so probably not. Saying that it supports A2007 raises the question of whether it supports A2010. Very little of the data format changed but A2010 introduced table-level data macros (which can be used to implement triggers) and that's a significant change. jackcess now supports access 2010 (although it doesn't support macros).  If you'd like to use Access as a JDBC database check out the JDBC-ODBC Bridge driver.
871,A,"How to get descriptive error messages from DB2? When I call a SQL statement via JDBC on the DB2 and the statement fails I catch an SQLException with the following message text: com.ibm.db2.jcc.a.nn: DB2 SQL Error: SQLCODE=-206 SQLSTATE=42703 SQLERRMC=O.METADATENSATZ DRIVER=3.52.95 I tried an automatic translation of the message according to the error list published by IBM but there are placeholders inside the messages referencing other elements of the exception. While looking for these elements inside the exception I found the DB2ExceptionFormatter and tried to use it to access the missing elements. But here I stopped because the DB2ExceptionFormatter gave me a clue: Error occurred while trying to obtain message text from server. Only message tokens are available. So my question is: What do I have to configure to get the correct messages from the DB2 server? If I can get a human readable message from the server I could use it directly and wouldn't have to translate it by myself. I'm not sure what message reference you're looking at above (it seems to be iSeries?) but you're better off going to the DB2 Message Reference over here. Looking up SQL0206 gets us this page with the following information: name is not valid in the context where it is used. The SQLERRMC is ""O.METADATENSATZ"" so I would take this to mean you have sent an SQL statement to DB2 and it is reporting that ""O.METADATENSATZ"" is not valid...either the column doesn't exist or the table ""O"" does not exist. As the message reference states if you want to automatically translate DB2 error messages: To invoke message help open the command line processor and enter: ? XXXnnnnn where XXX represents a valid message prefix and nnnnn represents a valid message number. The message text associated with a given SQLSTATE value can be retrieved by issuing: ? nnnnn or ? nn where nnnnn is a five digit SQLSTATE (alphanumeric) and nn is the two digit SQLSTATE class code (first two digits of the SQLSTATE value). In your case typing ""? SQL0206"" in a DB2 CLP will get you the error message. +1 for pointing me to the better SQLSTATE list.  I found a hint here: retrieveMessagesFromServerOnGetMessage: Specifies whether JDBC SQLException.getMessage calls cause the IBM DB2 Driver for JDBC and SQLJ to invoke a DB2 for z/OS stored procedure that retrieves the message text for the error. The data type of this property is boolean. The default is false which means that the full message text is not returned to the client. I tried this but the output of sqlException.getMessage() only changed to O.METADATENSATZ without any surrounding message text. Now I found this: Before you can use certain functions of the IBM® Data Server Driver for JDBC and SQLJ on a DB2® for z/OS® subsystem you need to install a set of stored procedures and create a set of tables. ... WLM must be installed on the z/OS system. WLM is the DB2 Workload Manager that isn't available for the DB2 Express edition I'm using for development :-("
872,A,"Connect to an Oracle cluster in Java We have a pair of Oracle servers which are set up as nodes in a cluster (apologies if my terminology is way off). In my tnsnames.ora file we have an entry that looks like EXAMPLE.GOV = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 1.2.3.4)(PORT = 1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = 1.2.3.5)(PORT = 1521)) (LOAD_BALANCE = yes) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = example.gov) ) ) and this works when I connect with programs which use the tnsnames.ora file. However I also have a Java program which uses the oracle.jdbc.pool.OracleDataSource class to establish a connection public static Connection connect() throws Exception { OracleDataSource ods = new OracleDataSource(); ods.setDriverType(""thin""); ods.setServerName(""1.2.3.4""); ods.setDatabaseName(""example""); ods.setPortNumber(1521); ods.setUser(""scott""); ods.setPassword(""tiger""); return ods.getConnection(); } which just connects to one of the nodes directly. I'd like to instead use the load-balancing tnsnames.ora approach where it uses load balancing or whatever to connect to either one of the nodes so that if one of them is down then it'll automatically connect to the other. Since I only have two nodes I could easily just try opening a connection to the first node then if that doesn't work open a connection to the second one. However I'm wondering if there's a more correct way to do this. I see that there's a setTNSEntryName parameter but since my tnsnames.ora is in a nonstandard place I'd need to set the TNS_ADMIN environment variable which I'm not sure that I can even do from within Java. Nor am I certain that this would work in any case. Does anyone know how to connect to a cluster of Oracle nodes from a Java program? It's been a while since I worked with Oracle if I remember it correctly if you have your oracle client environment set properly then Oracle driver is able to pick up the same configuration so you can use the 'example.gov' name instead of the ip address. So you might want to try setting the TNS_ADMIN environment variable like you said. Sorry not much help here. For Oracle JDBC thin driver I think this could work as the connection url: jdbc:oracle:thin:@(DESCRIPTION=(LOAD_BALANCE=on) (ADDRESS=(PROTOCOL=TCP)(HOST=1.2.3.4) (PORT=1521)) (ADDRESS=(PROTOCOL=TCP)(HOST=1.2.3.5) (PORT=1521)) (CONNECT_DATA=(SERVICE_NAME=example.gov))) Use the method setUrl to set the url. If URL is set all other properties like databasename servername portNumber network protocol tnsentry and driver type will be ignored. Hope this helps!"
873,A,Is it possible in Weblogic to create readonly JDBC datasource? I am using Weblogic web server. Please let me know how can i create a readonly JDBC datasource or should i handle this in my Java code ? It means that if a usert is using a connection pool created from that data source then he should not be able to insert / update / delete.. What do you mean by readonly JDBC datasource? Shouldn't the DBMS enforce that for you? That is if you connect to a database with a certain user identification the DBMS just gives read access to that database?  The datasource allows you to obtain pooled connection instances each pooled connection instance representing a physical connection to a database that remains open during use by a series of logical connection instances. So what you are allowed to do with a pooled connection instance strictly depends on the database permissions granted to the user used to create the physical connection. In other words if you want a read only pool use a user with restricted rights at the database level when creating your pool.
874,A,Log to a database using log4j Since in log4j javadoc is WARNING: This version of JDBCAppender is very likely to be completely replaced in the future. Moreoever it does not log exceptions. What should I do to log to a database? If you are looking for an database appender which not only works but also supports connection pooling is maintained and properly documented than consider logback's DBAppender. Ironically enough the warning in the javadocs about removing JDBCAppender in future versions of log4j was written by me. Is this answer still valid after 3 yrs or there are some other database logging framework available? I can confirm it is valid I just used JDBCAppender recently. @Vincent I am logging pojo object in the log through JDBCAppender. I would like to insert different pojo object value in the data base through log. HOw to do it? Thanks.  You can use an alternative appender but really Log4j 1.2 is going to be around and standard for a long time. They developed DBAppender as part of their receivers companions which isn't officially released but you can download the source code and get your own going as well. Unless the issue of not logging exceptions bothers you JDBCAppender is just fine. Any further upgrade to 2.0 is going to be more radical than just changing JDBCAppender (if 2.0 happens) so I wouldn't worry about using it despite the warning. They clearly don't have a solid roadmap or timeline to introducing a new version and 1.2.15 was released in 2007.
875,A,Where to close statements in JDBC I am using JDBC to retrieve data from a database. I understand that a Statement needs to be closed after it is used. However I keep run into the same error telling me that no operation is allowed after the statement is closed. The structure of my code is like public void foo() { Statement; try { } catch{ } Statement.close(); } In my code I need to call this function repeatedly. I was wondering where to close the Statement. Thanks According to the Javadocs Statement.close() Releases this Statement object's database and JDBC resources immediately instead of waiting for this to happen when it is automatically closed. It is generally good practice to release resources as soon as you are finished with them to avoid tying up database resources. Which means you should close it after you done and not planning to use it again. I would actually pay more attention to closing your Connection. In your method which you say you call repeatedly you are calling Statement.close() which means that you can only use it once since after the first call you Statement is closed and cannot be used anymore. It would be nice to see some of your code if you want a better answer Same. in my practice just place the close() at the very end of code where no more extra lines are needed to executed. With Java 7 you cam use the AutoCloseable support of JDBC statements: `try ( Statement statement = .... ) { /* use statement it's closed automatically */ }` This saves you writing the `finally` block.  Note that JDBC resources should always be closed so its better to put that to the 'finally' block. You can also consider Spring DAO usage - it is a thin wrapper on top of JDBC and covers most of JDBC boilerplate stuff.  ResultSets also need to be closed. It sounds like you might be doing something like accessing a Blob the Blob object often goes back through the connection to read the byte data from the database. So read all of the byte[] data before you close the connection. If that's not possible because there's too much data and you are trying to stream the bytes then you're just going to have to stick the connection somewhere safe and call close on it later. Close statements should go into finally blocks and be null protected - but it's such common and ugly code so stick in a static method somewhere. public List someMethod() { Statement stmt; ResultSet rset; try { stmt = con.createStatement(); rset = stmt.executeQuery(....); List resultList = ...create a list // get the data from the rset return resultList; } catch (SQLException ex) { throw new MyDatabaseException(ex); } finally { } } public class DatabaseUtils { public void close(Statement stmt ResultSet rset) { try { if (rset != null) { rset.close(); } } catch (SQLException ex) { throw new MyDatabaseException(ex); } finally { if (stmt != null) { throw new MyDatabaseException(ex); } } } } Yeah - partially I was in a hurry and also I was having problems getting the code to format for some reason I just gave up and went with something that had the main ideas. Though I see I missed the call to the DatabaseUtils.close() method in the finally block. The people below got the idea :-) That code doesn’t even compile—and it wouldn’t make much sense if it did. ResultSet are closed automatically when you close the Statement. (See JavaDoc http://download.oracle.com/javase/1.4.2/docs/api/java/sql/Statement.html) An answer using standard Java APIs would have been better received I think.
876,A,"Java - JDBC connection I am getting this error:  FOR REAL Looking for database... com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) at java.lang.reflect.Constructor.newInstance(Unknown Source) at com.mysql.jdbc.Util.handleNewInstance(Util.java:409) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1118) at com.mysql.jdbc.MysqlIO.readPacket(MysqlIO.java:675) at com.mysql.jdbc.MysqlIO.doHandshake(MysqlIO.java:1078) at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2312) at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2122) at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:774) at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:49) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) at java.lang.reflect.Constructor.newInstance(Unknown Source) at com.mysql.jdbc.Util.handleNewInstance(Util.java:409) at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:375) at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:289) at java.sql.DriverManager.getConnection(Unknown Source) at java.sql.DriverManager.getConnection(Unknown Source) at test.init(test.java:38) at sun.plugin2.applet.Plugin2Manager$AppletExecutionRunnable.run(Unknown Source) at java.lang.Thread.run(Unknown Source) Caused by: java.io.EOFException: Can not read response from server. Expected to read 4 bytes read 0 bytes before connection was unexpectedly lost. at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:2502) at com.mysql.jdbc.MysqlIO.readPacket(MysqlIO.java:599) ... 17 more java.lang.NullPointerException at test.init(test.java:69) at sun.plugin2.applet.Plugin2Manager$AppletExecutionRunnable.run(Unknown Source) at java.lang.Thread.run(Unknown Source) Exception: java.lang.NullPointerException when I am trying to connect to my MySQL online. Here's my code: (yes it's signed)  //package mysqltest; import java.awt.*; import java.awt.event.*; import javax.swing.*; import java.applet.Applet; import java.awt.TextArea.*; import java.sql.*; import java.util.*; import javax.swing.plaf.*; import javax.swing.plaf.basic.*; import java.net.*; import java.applet.*; public class test extends JApplet { public JTextArea c; public void init() { c = new JTextArea(); add(c); c.append(""xxxLooking for database...""); Connection conn = null; Properties props = new Properties(); String url = ""jdbc:mysql://localhost:3306/""; String dbName = ""mystik""; String driver = ""com.mysql.jdbc.Driver""; String userName = ""root""; String password = """"; String loggedusername = getParameter(""name""); boolean online = false; try { Class.forName(driver).newInstance(); online = true; if (online) { // if user loads applet online conn = DriverManager.getConnection(""jdbc:mysql://epic.0sites.net:208/*********?user=*******&password=**********""); } else { // for localhost - testing purposes props.put(""user"" ""root""); conn = DriverManager.getConnection(""jdbc:mysql://localhost:3306/mystik"" props); } c.append(""\nConnected to the database""); c.append(""\nGetting stats for: "" + loggedusername); PreparedStatement statement = conn.prepareStatement( ""select * from `user` where `username` = '""+loggedusername+""'""); ResultSet result = statement.executeQuery(); // just a dumb mysql statement! while(result.next()) { c.append(""\nUsername: ""+result.getString(2)+ ""\nLevel: ""+result.getString(6)+""\nEXP: ""+result.getString(8)+""\n""); } PreparedStatement updateEXP = conn.prepareStatement( ""update`user` set `exp` = '666' where `username` = '""+loggedusername+""'""); updateEXP.executeUpdate(); ResultSet xresult = statement.executeQuery(); while(xresult.next()) { c.append(""\nUsername: ""+xresult.getString(2)+ ""\nLevel: ""+xresult.getString(6)+""\nEXP: ""+xresult.getString(8)+""\n""); } conn.close(); c.append(""\nDisconnected from database""); } catch (Exception e) { e.printStackTrace(); } } } What am I doing wrong? Where did i get the epic0.sites.net URL you say? well If I go to https://epic.0sites.net:2083/3rdparty/phpMyAdmin/ I can reach my phpMyAdmin... I didn't think it would work.. it didn't. I starred out sensitive info. Since you're collecting text data along the way can you put a System.out.println(c) in a finally block? That way you can at least find out how far it's getting. Dan you should not reuse existing questions for new questions/problems. This would make all answers pointless. You need to ask a new question. I've rollbacked the change. yep. back at the problem :\ Most likely your DB has run out of connections. That's one of the caveats of not closing connections properly in finally. I've warned about this in your previous question. The remedy is to restart the DB in question and fix your code accordingly that it gracefully closes the resources in finally. I have conn.close() at the very end... It was originally at end of the `try` yes. It won't be invoked when an exception is been thrown *before* that line is reached. As per your previous question it has likely occurred more than once. Now the DB has run out of connections. You need to restart the DB or wait about 8 hours until the DB forcibly closes the too-long opened connections. Otherwise you keep getting this exception even when you have fixed the code. add I see. that worked. :) but now i got new problem. i added it in. i will see if i can fix it. You need to ask a new question about the new problem. Wait It doesn't even connect to mysql... let me rework on this back to the old problem. Well either the DB is not properly restarted or the user is been blocked due to abuse (when it concerns a 3rd party hosted DB). By the way why did you add this unrelated NPE to the stacktrace? It's a regular Exception. I don't get what you are saying. Maybe I didn't sign the applet right? The sign is not the issue. That would have thrown a different exception. What I am saying if you are still getting a communications link failure then it means that the DB still doesn't have a connection to give back to you. To fix this you need to restart the DB or to wait about 8 hours (depending on DB configuration). Because the DB seem to be a 3rd party hosted one which is been shared I suspect that you didn't restart it at all.  The important part of the exception stack trace seems to be: Caused by: java.io.EOFException: Can not read response from server. Expected to read 4 bytes read 0 bytes before connection was unexpectedly lost. So it looks like you can connect but then the connection is closed. Maybe you're not connecting to a mysql server ? (Is there something else running on this port ?) What `jdbc:mysql://epic.0sites.net:208/***` in your example starred out from `jdbc:mysql://epic.0sites.net:2083/***` where 2083 is the port where an HTTPS server is running (from your HTTPS URL example)? If so @Andre is right. No I don't think so."
877,A,"Understanding JDBC internals [1] In JDBC why should we first load drivers using Class.forName(""some driver name""). Why SUN didnt take care of loading driver within the getConnection() method itself.If I pass driver name as a parameter to the getConnection() method. [2] I want to understand JBDC internals.Any pointers towards it are appreciated. With JDBC 4 you no longer need to use Class.forName(...) see here for one article explaining this: Connection to a database requires that a suitable JDBC database driver be loaded in the client's VM. In the early days of JDBC it was common to load a suitable driver via Class.forName() passing in the name of the class implementing the JDBC Driver interface. The DriverManager class later offered a more flexible means of managing JDBC drivers in a client application. For a driver to become available DriverManager's registerDriver() had to be invoked with the driver's class name. Alternatively you could specify the drivers to load via the jdbc.drivers system property. When DriverManager initializes it attempts to load the drivers associated with that property. JDBC 4 adds the J2SE Service Provider mechanism as another means to specify database drivers. For this to work driver JAR files must include the file META-INF/services/java.sql.driver. That file must contain a single line with the name of the JDBC driver's implementation of the Driver interface. Invoking getConnection() on DriverManager will load a driver so packaged if needed. Upon loading the driver an instance of the driver is created and then registerDriver() is invoked to make that driver available to clients. Have a look at Sun's JDBC link for more information on JDBC. The JDBC 4.0 Specification is relatively a nice read compared to some other specs...  There is no way for java.sql to know which class to load if you only give it the JDBC protocol name. Arguably JDBC driver jar files should be able to specify protocol name and driver class within their manifest or elsewhere under META-INF/. In my opinion you might as well construct the driver instance yourself rather than attempting to load the class with a hardwired string or fiddly services file. There isn't much to JDBC itself. The source is in src.zip of the JDK. DriverManager is the class with code.  Toolkit was right. Since JDBC 4.0 there is a mechanism that drivers will automatically register themselves using the J2SE Service Provider. Unfortunately not all JDBC vendors did update their drivers to do so. I also think that currently there are not that much JDBC drivers supporting JDBC 4.0. Meanwhile you will need to create an instance of a Driver to register the driver. The DriverManager will then check each registered driver if it accepts the JDBC url passed for a DriverManager.getConnection(). You can enable the driver logging to see what happens if driver were registered and the DriverManager tries to find the suitable driver. Therefore just call DriverManager.setLogStream() or DriverManager.setLogWriter() before. This is one of the JDBC 4.0 drivers I know: http://www.inetsoftware.de/products/jdbc/mssql/merlia"
878,A,"Is it possible to use GROUP BY with bind variables? I want to issue a query like the following select max(col1) f(:1 col2) from t group by f(:1 col2) where :1 is a bind variable. Using PreparedStatement if I say connection.prepareStatement (""select max(col1) f(? col2) from t group by f(? col2)"") I get an error from the DBMS complaining that f(? col2) is not a GROUP BY expression. How does one normally solve this in JDBC? What exactly do you want to bind? Show us all your code not just a snippet. You can bind a value like 'YYYY' but not a column name. UPDATE: Now I see what's wrong. The DBMS is not recognizing that the expression in the GROUP BY is the same expression in the SELECT list. It's seeing those as two separate expressions. Using a named bind variable avoids that problem since there's only one value. Did you try using ? rather than the named bind variables? As well which driver are you using? I tried this trivial example using the thin driver and it seemed to work fine: PreparedStatement ps = con.prepareStatement(""SELECT COUNT(*) TO_CHAR(SYSDATE ?) FROM DUAL GROUP BY TO_CHAR(SYSDATE ?)""); ps.setString(1 ""YYYY""); ps.setString(2 ""YYYY""); ps.executeQuery();  I suggest re-writing the statement so that there is only one bind argument. This approach is kind of ugly but returns the result set: select max(col1)  f_col2 from ( select col1  f(? col2) as f_col2 from t ) group by f_col2 This re-written statement has a reference to only a single bind argument so now the DBMS sees the expressions in the GROUP BY clause and the SELECT list are identical. HTH [EDIT] (I wish there were a prettier way this is why I prefer the named bind argument approach that Oracle uses. With the Perl DBI driver positional arguments are converted to named arguments in the statement actually sent to Oracle.) I didn't see the problem at first I didn't understand the original question. (Apparently several other people missed it too.) But after running some test cases it dawned on me what the problem was what the question was working. Let me see if I can state the problem: how to get two separate (positional) bind arguments to be treated (by the DBMS) as if it were two references to the same (named) bind argument. The DBMS is expecting the expression in the GROUP BY to match the expression in the SELECT list. But the two expressions are considered DIFFERENT even when the expressions are identical when the only difference is that each expression references a different bind variable. (We can demonstrate some test cases that at least some DBMS will allow but there are more general cases that will raise an exception.) At this point the short answer is that's got me stumped. The suggestion I have (which may not be an actual answer to the original question) is to restructure the query. [/EDIT] I can provide more details if this approach doesn't work or if you have some other problem figuring it out. Or if there's a problem with performance (I can see the optimizer choosing a different plan for the re-written query even though it returns the specified result set. For further testing we'd really need to know what DBMS what driver statistics etc.)  In the second case there are actually two variables - you will need to send them both with the same value. @Cade: setting both variables to the same value is not sufficient the DBMS is seeing two separate bind arguments. The DBMS is seeing different expressions in the SELECT and the GROUP BY. I was worried that might be the case. I always use stored procs."
879,A,Weird DB2 database issue : Websphere Connection Pooling I am running a query from my java based web app running in a Websphere container. This query however being pretty simple fails with a weird erorr as follows: [5/15/09 16:50:33:828 IST] 0000001e SystemErr R com.ibm.db2.jcc.b.zd: Invalid data conversion:Requested conversion would result in a loss of precision of 40000 [5/15/09 16:50:33:828 IST] 0000001e SystemErr R at com.ibm.db2.jcc.b.q.a(q.java:137) [5/15/09 16:50:33:828 IST] 0000001e SystemErr R at com.ibm.db2.jcc.b.q.a(q.java:1189) [5/15/09 16:50:33:828 IST] 0000001e SystemErr R at com.ibm.db2.jcc.b.ad.a(ad.java:1217) [5/15/09 16:50:33:828 IST] 0000001e SystemErr R at com.ibm.db2.jcc.b.ad.kb(ad.java:2977) [5/15/09 16:50:33:828 IST] 0000001e SystemErr R at com.ibm.db2.jcc.b.ad.d(ad.java:1970) [5/15/09 16:50:33:828 IST] 0000001e SystemErr R at com.ibm.db2.jcc.b.ad.d(ad.java:2342) [5/15/09 16:50:33:828 IST] 0000001e SystemErr R at com.ibm.db2.jcc.b.ad.U(ad.java:489) [5/15/09 16:50:33:828 IST] 0000001e SystemErr R at com.ibm.db2.jcc.b.ad.executeQuery(ad.java:472) [5/15/09 16:50:33:828 IST] 0000001e SystemErr R at com.ibm.ws.rsadapter.jdbc.WSJdbcPreparedStatement.executeQuery(WSJdbcPreparedStatement.java:559) The query is pretty simple : it is as simple as select field1 field2 from <xyz table> where <xyz_pk> = ? The primary key is a INTEGER(4) and has data that has values up to 99999999. But however when I run this query is run in my web app on a connection obtained from websphere connection pool it starts failing for pk values > 35k+. In the jdbc binding code I tried doing a preparedStatement.setInt() and preparedStatement.setFloat(). But nothing seems to work!! It just works for anything below 35k+ and fails for everything above that. Java's int size is much bigger than 35k+ so why would this query fail with this error? This happens just from my application when I try the same query with a database client of my choice proper results are being obtained for all values of the pkey! Did anyone faced this issue before? If yes how did you get around it? Could you provide some sample Java code and a full stack trace for the case where you used PreparedStatement.setInt()? No classes in java.sql are in the stacktrace. My bad.. the issue was in binding. My query had an integer and small int field and I was binding small to int and int to smallint hence the problem.  Integers don't have precision. There must be a float or real somewhere in the chain of column to variable binding. In that case it doesn't matter whether you start with an int Int long or even a byte; the conversion between whole and real would trigger the warning. Look at all the the bindings that happen from the column to the last variable. Does your prepared statement redefine any of your field types?  Could you maybe post the code that causes the failure? I remember having something like this on websphere and had to change the precision of the database fields. It had to do with the conversion the database and the java space in that on the java side the data type was far bigger than the datatype on the database. We changed the data type on the database and things improved.  I remember having this problem a while ago. I think I solved it by converting the value directly in the SQL statement. Something like this: select DECIMAL(field1) AS field1 field2 from ...  I think the best thing you can do is to turn on the trace logs in WAS for the JDBC resource adapter and then look at the sql that is actually being issues to the DB. Sorry cannot be much more help. Karl
880,A,Does the SQL Server JDBC driver support asynchronous operations? From some googling it appears that .NET supports asynchronous operations with SQL Server 2005+. Does the latest JDBC driver support this? I can't find a mention of it anywhere so I'm thinking it probably doesn't. But I figured it couldn't hurt to ask. Thanks! Avi The commons-dbutils library provides a nice wrapper around JDBC calls and even provides an asynchronous way of making calls: AsyncQueryRunner. Worth a look: http://commons.apache.org/dbutils/apidocs/org/apache/commons/dbutils/AsyncQueryRunner.html  No but that doesn't mean you can't do asynch database operations. You'd just put the asynch character in an appropriate layer like a message driven bean or a Process thread. I don't see why JDBC should have to support a middle tier notion like asynch processing.  JDBC is pretty much all single threaded. From Connection down it is expected only one thread will use it for it's lifetime (ok Connections can get pooled but that should be invisible to the application and only one thread should be using a Connection at a time). There is one exception which is Statement.cancel() which permits another thread to interrupt/cancel an in-progress query but I believe this is the only instance of multi-threaded-ness. Like duffymo says typically if you want async behaviour you would build something on top of JDBC (and I would guess that's what .NET is doing under the covers).
881,A,"How to catch a specific exceptions in JDBC? How to catch a specific exceptions in JDBC? Examples: primary key exception or foreign key exception. The best and DB-independent way to handle SQLException more specifically is to determine the SQL state code which can be obtained by SQLException#getSQLState(). The SQLState is a 5-char code of which the first two are common among all DB's and the last three might differ depending on the DB and/or the specific condition. Here's an extract from the spec: 02: no data 08: connection exception 07: dynamic SQL error 0A: feature not supported 21: cardinality violation 22: data exception 23: integrity constraint violation 24: invalid cursor state 25: invalid transaction state 26: invalid SQL statement name 28: invalid authorization specification 2B: dependent privilege descriptors still exist 2C: invalid character set name 2D: invalid transaction termination 2E: invalid connection name 33: invalid SQL descriptor name 34: invalid cursor name 35: invalid condition number 3D: invalid catalog name 3C: ambiguous cursor name 3F: invalid schema name So to determine whether the SQL Exception is caused by a constraint violation you can just do the following in a (fictive) SQLUtil class: public static boolean isConstraintViolation(SQLException e) { return e.getSQLState().startsWith(""23""); }  SQLException contains some database-specific info related to the exception. From the doc: Each SQLException provides several kinds of information: 1) a string describing the error. This is used as the Java Exception message available via the method getMesage. 2) a ""SQLstate"" string which follows either the XOPEN SQLstate conventions or the SQL 99 conventions. The values of the SQLState string are described in the appropriate spec. The DatabaseMetaData method getSQLStateType can be used to discover whether the driver returns the XOPEN type or the SQL 99 type. 3) an integer error code that is specific to each vendor. Normally this will be the actual error code returned by the underlying database. 4) a chain to a next Exception. This can be used to provide additional error information.  Brian's right a SQLException will be thrown for just about ANY JDBC problem. This is partially why JDBC is so annoying. The Spring library JDBC helpers provide an exception translator to look at the SQLCode SQLState etc. and throw the appropriate DataAccessException. There are many of these exception classes and they give you a better idea of what went wrong with names such as DataIntegrityViolationException DataSourceLookupFailureException PermissionDeniedDataAccessException and others."
882,A,"Retrieving Oracle Cursor with JDBC I have been experiencing some frustrations trying to make a simple Oracle cursor retrieval procedure work with JDBC. I keep on getting an error of ""[Oracle][ODBC][Ora]ORA-06553: PLS-306: wrong number or types of arguments in call to 'GETNAME'"" but I cannot figure out what I am doing wrong. Here is my code in Java: CallableStatement stmt = connection.prepareCall(""call getName(?)""); stmt.registerOutParameter(1 OracleTypes.CURSOR); stmt.execute(); stmt.close(); con.close(); Here is my procedure in Oracle: CREATE OR REPLACE PROCEDURE getName(cur out SYS_REFCURSOR) IS BEGIN OPEN cur FOR SELECT name FROM customer; END; The error occurs on stmt.execute(). Thanks in advance. By the way I am working with Oracle 10.2.0. What JDBC jar file are you compiling & executing with? I tried essentially the same thing and it worked for me. The only difference was that the Oracle JDBC library I am using does not have a method registerOutputParameter; I used registerOutParameter instead. Perhaps you are calling a generic JDBC method instead of the Oracle-specific one that support Oracle types. The only other explanation I can think of is that your Java code is connecting to the wrong schema and accessing a different getName object. Sorry I mistyped the method name. Is there any Oracle setting or non-code-related problem that may cause this error? Turned out that the cursor works fine with JDBC Oracle thin client but not with ODBC. Not sure about the cause since I did enable result sets for ODBC.  Nope this is wrong. You should not be returning a raw cursor. You should call the stored proc and iterate through the ResultSet. Depends on the database... SQL Server and Sybase for example can return result sets from a stored procedure -- but in Oracle you need to return a Cursor. No what I was talking about *two years ago* was returning a raw cursor or ResultSet out of your persistence tier. You should iterate over it load the contents into data structure object or collection of some kind and close the cursor or ResultSet. You won't have memory leaks or max # of cursors exceeded that way. I think you misunderstood. You might want to reconsider your down vote."
883,A,"HSQLDB cryptic exception message: ""feature not supported"" I have JDBC code which inserts into a database table by executing a PreparedStatement. When I run the code on an in-memory HSQLDB database (as part of a JUnit test) I get a SQLFeatureNotSupportedException with the only information being the message ""feature not supported"" and the vendor code -1500. What I'm doing is a basic insertion into a table -- I can't imagine that this is unsupported in the latest HSQLDB. My code: public Observations saveOrUpdate(final Observations observations) { try { if (connection == null) { connection = getJdbcTemplate().getDataSource().getConnection(); } // create the prepared statement String sql = ""INSERT INTO "" + Observations.TABLE_NAME + "" (OBS_YEAR WINTER SPRING SUMMER FALL ANNUAL DATA_TYPE CREATED_DATE UPDATED_DATE "" + Observations.ID_COLUMN_NAME + "") VALUES (? ? ? ? ? ? ? ? ? ?)""; PreparedStatement preparedStatement = connection.prepareStatement(sql); preparedStatement.setInt(1 observations.getYear()); preparedStatement.setBigDecimal(2 observations.getJan()); preparedStatement.setBigDecimal(3 observations.getFeb()); preparedStatement.setBigDecimal(4 observations.getMar()); preparedStatement.setBigDecimal(5 observations.getApr()); preparedStatement.setBigDecimal(6 observations.getMay()); preparedStatement.setString(7 observations.getDataType().toString()); preparedStatement.setTimestamp(8 new Timestamp(observations.getCreatedDate().getTime())); preparedStatement.setTimestamp(9 new Timestamp(observations.getUpdatedDate().getTime())); preparedStatement.setLong(10 observations.getId()); preparedStatement.executeUpdate(sql); return observations; } catch (SQLException ex) { throw new RuntimeException(ex); } } Can anyone suggest what may be the problem or anything else I should investigate further? Thanks in advance for your help. --James Try to post more information: log of the exception the version of your HSQLDB (2.0 perhaps) your java version etc. I'm searching in order to help you. I presume that it is a problem of compatibility between the jre and your hsqldb. Thanks a lot Aito. I am using the HSQLDB 2.0 JAR file. I am running the code as part of a JUnit 4 test. I launch it from Eclise IDE which is using a 1.6 JRE. The DataSource is configured using Spring and I am getting the connection from a Spring JdbcTemplate I've configured into the DAO class that contains this code. You need to call preparedStatement.executeUpdate() (without the parameter sql). You called the method PreparedStatement.executeUpdate(String sql) which is illegal according to the JDBC specification. It doesn't really make sense to pass the SQL statement again because you have already passed it when you created the PreparedStatement object. Even thought you pass the same string it's not legal to call this method. It's a bit strange that calling a method is not legal :-) but that's the way it is. All standard conforming JDBC drivers need to throw an exception in this case. But I agree the error message is cryptic. Bingo you are the winner. Thanks so much!  Some further info I found in http://hsqldb.org/doc/changelog_1_7_2.txt: The execute(String sql) executeUpdate(String sql) and executeQuery(String sql) commands are no-longer supported for PreparedStatements according to JDBC specs. Use an ordinary Statement for calling these methods.  Systemic issues with HSQLDB are often due to mismatches in server vs. driver version (any mismatch at all will not work in my experience). I mostly suspect this isn't your issue. Since you said the db is ""in memory"" I'm guessing the server & driver are the same .jar file. But in case my guess is wrong I thought I'd throw this out there. Because this is speculation shouldn't this be a comment to the question and not an answer? @Jacob Tomaw -- should it? I have never seen a guideline like that. And what's more aren't 98% of answers to questions on this site speculation on some level? If the asking person knew enough detail about his issue such that there were no need for speculation in finding the cause wouldn't he probably have been able to find the answer himself? Willis Your speculation is that your answer is unhelpful. To me it would be more helpful to ask the question that will clarify the issue for you and that the asker will know the answer to ""When you say this is an 'in memory' data base you mean that database and the test are running in the same JVM?"" as a comment. Once that question is answered you could provide an informed answer."
884,A,"Mysterious SQL blocking my stored procedure from executing on ORACLE I am trying to run a procedure on ORACLE with the thin jdbc client and c3p0. here's the code that's supposed to run:  Map<String Object> paramMap = new HashMap<String Object>(); paramMap.put(""I_NODE_ID"" nodeId); paramMap.put(""I_PARENT_ID"" parentId); paramMap.put(""I_STRUCTURE_ID"" structureId); paramMap.put(""I_FROM_DATE"" beginTime); paramMap.put(""I_TO_DATE"" END_OF_TIME); new SimpleJdbcCall(jdbcTemplate).withProcedureName(""TC_INSERT_NODE_A"").execute(paramMap); paramMap.put(""I_NOW_DATE"" currentTime); new SimpleJdbcCall(jdbcTemplate).withProcedureName(""TC_INSERT_NODE_B"").execute(paramMap); The system is seemingly hanging and the following query appears on Enterprise Manager as taking up 100% of my CPU. SELECT package_name AS procedure_cat owner AS procedure_schem object_name AS procedure_name argument_name AS column_name DECODE(position 0 5 DECODE(in_out 'IN' 1 'OUT' 4 'IN/OUT' 2 0)) AS column_type DECODE(data_type 'CHAR' 1 'VARCHAR2' 12 'NUMBER' 3 'LONG' -1 'DATE' 91 'RAW' -3 'LONG RAW' -4 'TIMESTAMP' 93 'TIMESTAMP WITH TIME ZONE' -101 'TIMESTAMP WITH LOCAL TIME ZONE' -102 'INTERVAL YEAR TO MONTH' -103 'INTERVAL DAY TO SECOND' -104 'BINARY_FLOAT' 100 'BINARY_DOUBLE' 101 1111) AS data_type DECODE(data_type 'OBJECT' type_owner || '.' || type_name data_type) AS type_name DECODE(data_precision NULL data_length data_precision) AS precision data_length AS length data_scale AS scale 10 AS radix 1 AS nullable NULL AS remarks sequence overload default_value FROM all_arguments WHERE owner LIKE :1 ESCAPE '/' AND object_name LIKE :2 ESCAPE '/' AND package_name IS NULL AND (argument_name LIKE :5 ESCAPE '/' OR (argument_name IS NULL AND data_type IS NOT NULL)) ORDER BY procedure_schem procedure_name overload sequence What does this mean? Where should I start looking to solve this problem? When you ran the SQL at the command line did it complete or did it hang. This SQL queries the parameters of a stored procedure. It looks very inefficient because it uses several (probably unnecessary) LIKE operators. This can be very slow in particular if you have a system with lots of PL/SQL and in particular with Oracle 11g which has gotten much slower for meta data queries like this. Could it be that the Spring framework runs queries like this a part of calling a stored procedure (I've never used Spring)?"
885,A,"get value from updated row I'm trying to get the new rating from an UPDATE statement in java int userID = 99; String sql = ""UPDATE table SET rating=rating+1 WHERE user_REF=""+userID; statement.executeUpdate(sql); I can just do another SELECT statement but isn't there a better way to retrieve the value or row while updating? Be cautious that most solutions are database dependent (Whether or not you want database independence in your application ofcourse matters). Also one other solution you could try is to write a procedure and execute it as follows my_package.updateAndReturnRating(refId cursor record). Of course this may/may not make the solution itself complicated but worth an ""evaluation"" atleast.  In PostgreSQL there is RETURNING clause See: http://www.postgresql.org/docs/8.3/interactive/sql-update.html thanks but i forgot to mention that i'm using mySQL. It doesn't seem to have that clause  thanks for the replies everybody i ended up doing it like this: int userID = 99; String sql = ""SELECT id rating FROM table WHERE user_REF=""+userID; ResultSet rs = statement.executeQuery(sql); rs.first(); float oldRating = rs.getFloat(""rating""); float newRating = oldRating +1; rs.updateFloat(""rating"" newRating); rs.updateRow(); return newRating; that way it (or at least seems so) does only one query to find the correct row or am i wrong? this is wrong. You're still doing two queries... one to select the old rating and one to update to the new rating and on top of that by not doing 'rating = rating +1' in SQL you've introduced a race condition into your script. What if two users execute this script at the same time? They'll both select the old rating and both update the value to the old rating plus one. Doing it inside of SQL the way my answer provided will ensure race conditions are avoided. great. Thanks a lot for the infos i'll do it your way.  In short No there is no way to do this with ANSI standard SQL. You have three options: 1) Do it in two queries - the update then the select 2) Create a stored procedure that will execute the update and then return the select 3) Use a DB-specific extension such as the PostgreSQL RETURNING clause Note that options 2) and 3) are database-specific.  In MySQL: $query1 = 'UPDATE `table` SET rating = (@rating:= rating) + 1 WHERE id = 1'; $query2 = 'select @rating';"
886,A,"JDBC Driver for MsAccess which will work on Unix I need a JDBC driver for MsAccess to be used in a Unix environment I would strongly prefer it to be an open-source Also it should support SQL statements (Jackcess came close to being my choice- but it doesn't support SQL queries) http://jackcess.sourceforge.net/faq.html#query ""doesn't support SQL queries""? What *does* does this JDBC driver do? I think its an API rather than a JDBC driver Isn't MS Access obsolete? :) Apparently not :) We are using third party applications which uses MsAccess ouch! Why would you do this? Put the data on Unix or move the app to Windows! Its a third party which generates MDB files- i have zero control on that. My challenge is to move the data generated into oracle database in an unix based enterprise application ""Doesn't support queries"" means it doesn't support the Query objects in Access databases not that it doesn't support SQL queries. I'm not sure whether the JDBC-ODBC bridge in Sun's Windows JRE supports those Query objects either -- I suspect it doesn't. To @Bozho: Access isn't actually involved in this question only the default database engine that ships with Access Jet/ACE. Neither Access nor the Jet/ACE database engine is obsolete as MS is pouring a whole lot of new development resources into it. You should seriously give the Access 2010 beta a test drive particularly if you have any chance to use it with Sharepoint. @David W. Fenton: ""Neither Access nor the Jet/ACE database engine is obsolete"" -- using Jet 4.0 and earlier with Access Forms apps has been declared as obsolete by MS. Using Jet or ACE as an application data store has been declared as obsolete by MS (other than Access Forms apps and SHarePoint obviously). I'd recommend to use a Type 4 JDBC driver (i.e. full Java) more precisely the driver from HXTT (see this answer for some alternatives). Sadly it's not an open source driver and it's not free. But if you are using Oracle I think you can spend around 300 bucks for a driver.  Can you just use a JDBC-ODBC bridge for it. If you must do SQL I've found that to be the best way. Can you do that on Unix? @RN no you can't"
887,A,"SQLSTATE 24000 - Invalid Cursor State I connect to a DB2 database and makes the following query. I don't understand why I get the error: ""invalid cursor state"". public static void blivPar() { try { Statement stmt = con.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE ResultSet.CONCUR_UPDATABLE); stmt.setMaxRows(1000); ResultSet drenge = stmt.executeQuery(""SELECT * FROM People WHERE sex='M'""); ResultSet piger = stmt.executeQuery(""SELECT * FROM People WHERE sex='F'""); drenge.first(); piger.first(); int i=0; while(drenge.next()) { while(piger.next()) { i++; System.out.print(i); stmt.execute(""INSERT INTO Couples Values ('""+drenge.getString(1) + ""''"" + drenge.getString(2) + ""''"" + piger.getString(1) + ""''"" + piger.getString(2) + ""')""); } } } catch (Exception ex) { ex.printStackTrace(); } } Thank you. Why are you doing this in a cursor when you can do this using SQL? What is your stack trace? What is the SQL code thrown by DB2? Found this on the JDBC Javadocs for the Statement interface: ""The object used for executing a static SQL statement and returning the results it produces. By default only one ResultSet object per Statement object can be open at the same time. Therefore if the reading of one ResultSet object is interleaved with the reading of another each must have been generated by different Statement objects. All execution methods in the Statement interface implicitly close a statment's current ResultSet object if an open one exists. "" see Statement javadoc So it looks to me like you need two different Statements if you want two ResultSets open at the same time. Or you need to finish processing your first ResultSet and close it so you can re-use the Statement to create the second ResultSet."
888,A,Drop all constraints in Derby via JDBC How can I drop all constraints in a Derby database via JDBC? Oh cool. I didn't know that thanks @BalusC :)Further I think Pascal has given a better answer so I skip providing my own ;) JDBC has a metadata api where you can fetch all tables/constraints. With this you should be able to build some DDL Statement to drop the constraints. Thanks. If you put that into an answer I could accept it. @ZeissS: just a comment to notify you about the above comment :) @tob: use `@nickname` to notify commenters (the ones who didn't post the original question or the answer) about a respons in comments. I'm not really sure I understand why it would be useful to drop all the constraints in your database programatically. Nonetheless for an example of code which uses the DatabaseMetaData API to find various constraints and other dependent objects (views etc.) for a particular schema in a Derby database you can have a look at the dropSchema() method in the Derby testing harness's JDBC.java utility: http://svn.apache.org/viewvc/db/derby/code/trunk/java/testing/org/apache/derbyTesting/junit/JDBC.java?view=co  You could query the system tables SYS.SYSCONSTRAINTS SYS.SYSTABLES and SYS.SYSSCHEMAS to get all constraint names and the related tables for a given schema. First a few words about those tables (from Re: System tables in Derby): SYSTABLES has one row for each table in the database. Its primary key is TABLEID which contains system-generated values. The SCHEMAID is a foreign key column which references SYSSCHEMAS. SYSSCHEMAS has one row for each schema in the database. Its primary key is SCHEMAID. ... SYSCONSTRAINTS has one row for each constraint in the database (primary unique foreign and check constraints). Its primary key is CONSTRAINTID which is a system-generated value. The TABLEID column is a foreign key referring to SYSTABLES.TABLEID. The SCHEMAID column is a foreign key referring to SYSSCHEMAS.SCHEMAID. So you could use the following query: SELECT C.CONSTRAINTNAME T.TABLENAME FROM SYS.SYSCONSTRAINTS C SYS.SYSSCHEMAS S SYS.SYSTABLES T WHERE C.SCHEMAID = S.SCHEMAID AND C.TABLEID = T.TABLEID AND S.SCHEMANAME = 'MYSCHEMA'; And then loop and build the corresponding ALTER TABLE DROP CONSTRAINT statement. References Derby support for SQL-92 features Table 22. Support for SQL-92 Features: Constraint tables Re: System tables in Derby
889,A,"Java Large database inserts I have a database in which I need to insert batches of data (around 500k records at a time). I was testing with derby and was seeing insert times of about 10-15minutes for this many records (I was doing a batch insert in Java). Does this time seem slow (working on your average laptop)? And are there approaches to speeding it up? thanks Jeff This time seems perfectly reasonable and is in agreement with times I have observed. If you want it to go faster you need use bulk insert options and disable safety features: Use PreparedStatements and batches of 5000 to 10000 records unless it MUST be one transaction Use bulk loading options in the DBMS Disable integrity checks temporarily for insert Disable indexes temporarily or delete indexes and re-create them post-insert Disable transaction logging and re-enable afterward. EDIT: Database transactions are limited by disk I/O and on laptops and most hard drives the important number is seek time for the disk. Laptops tend to have rather slow disks at 5400 rpm. At this speed seek time is about 5 ms. If we assume one seek per record (an over-estimate in most cases) it would take 40 minutes (500000 * 5 ms) to insert all rows. Now the use of caching mechanisms and sequencing mechanisms reduces this somewhat but you can see where the problem comes from. I am (of course) vastly oversimplifying the problem but you can see where I'm going with this; it's unreasonable to expect databases to perform at the same speed as sequential bulk I/O. You've got to apply some sort of indexing to your record and that takes time. That makes sense. Thanks.  Do the tables have a lot of indexes? A lot of time could be spent updating these indexes. this is more appropriate if placed as a ""comment"" there are only 2 indexes in it."
890,A,"Is there an alternative to using sun.jdbc.odbc.JdbcOdbcDriver? I recently migrated an older application we have at work from Java 1.5 to 1.6. I noticed that during the build I now get a (new) compiler warning: ... DatabaseSession.java:[920] sun.jdbc.odbc.JdbcOdbcDriver is Sun proprietary API and may be removed in a future release So I understand what that means but is there a well-known alternative that is more open-standards friendly not proprietary? What driver do you use and/or recommend and what are the advantages of it? So far I have taken the approach that it compiles in 1.6 so we'll keep using it and we can find a replacement later if the next version of Java does not support it and I will likely try to suppress the warning from showing up in the build. Am I wrong to think that? Yes use a Type 4 JDBC driver for the database you're using. The JDBC-ODBC brigde is one of the worst JDBC drivers that I had to pleasure to work with. Alternatively you might want to look into third-party JDBC-ODBC bridges such as this Easysoft product but I don't have any experience with those. +1 a type 4 is a joy to work with. No having to configure any OS-specific stuff able to use the same JDBC driver on any platform minimal intelligence required in the cross-platform installer. If the DB you're using doesn't have a type 4 driver express your displeasure to the vendor (loudly). +1 for the usage of ""worst"" :)"
891,A,How to Make JDBC Driver Work in Java 5 & 6? Java 6 comes with JDBC 4 which is not backward compatible with JDBC shipped with previous versions of Java. We have a JDBC driver which must support both Java 5 and Java 6. If I implement the new interfaces in the driver it doesn't work in Java 5 because the interfaces also uses new classes. So we have 2 versions of the driver. Is there a way to have one jar for both Java 5 and 6? Just to be clear you are implementing a JDBC driver rather than using one? Can you put a bit more information in the question. We're using jTDS which is a JDBC 3.0 driver and it works in Java 5 & 6. I think the decision should be whether you support JDBC 3.0 or 4.0 not necessarily Java 5 or 6. Yes. I am writing a driver for a special database. I don't really care about JDBC 4.0. The problem is that I don't know how to make a JDBC 3.0 driver which also works in Java 6.0. I will take a look at jTDS. Thanks! If you implement a JDBC 3.0 driver and your clients run it in Java 6 they'll get errors if they call any of the new JDBC 4.0 methods. This is rare as those new methods aren't used very often but if you want to be fool-proof the below solution (which is a hack) should do the trick: compile with java 5 (if you compile with java 6 and run in java 5 you'll get a version mismatch error) Implement your normal JDBC 3.0 driver but also include implementations for the new JDBC 4.0 methods (note: this will cause compile errors because java 5 doesn't define types like java.sql.NClob) create an exact replica of the new JDBC 4.0 interfaces (like java.sql.NClob) in a separate project (so now there's 2 projects: the original one and this one) compile both projects together and make a separate jar per project: your JDBC driver implementation (keep this jar) the new JDBC 4.0 interfaces (discard this jar) We can discard the JDBC 4.0 interfaces jar because: in Java 6 those new JDBC 4.0 interfaces are defined in Java 5 the JDBC 3.0 interfaces don't define the new methods (like Connection.createNClob()) so your users won't call them The only potential problem could be with the java 5 classloader. It may fail if it can't find the new JDBC 4.0 interfaces (like java.sql.NClob). I don't think this will happen in the Sun JVM unless you call a method which returns one of those new interfaces so you should be good. If I'm wrong and this is an issue just put the discarded jar (the one that defined the new JDBC 4.0 interfaces) on your classpath when running in Java 5.
892,A,"Get number of rows updated with PreparedStatement How to get how many rows updated with PreparedStatement? .getUpdateCount() returns 0. For executeUpdate got error: error occurred during batching: batch must be either executed or cleared my code: updTrans = dataSource.getConnection().prepareStatement(""update...""); updTrans.setInt(1 Integer.valueOf(transaksjonstatusid)); ... updTrans.addBatch(); upd = updTrans.executeUpdate(); On your last edit you added: updTrans.addBatch(); then upd = updTrans.executeUpdate() and get an error but as BalusC mentionned you should be using int [] updateCounts = stmt.executeBatch(); if you're using .addBatch(); Did you try to use: int n = preparedStatement.executeUpdate(); Here you can find some explanations on how to use a PreparedStatement. does executeUpdate() do commit? because i needn't commit oh that phase i should commit lateras batch update if executeUpdate() is executed in a transaction then no it does not commit the transaction see my edited postplease The commit can be set up through the Connection object not the Statement. You can use conn.setAutoCommit(false); execute your preparedStatement then use conn.commit(); and set back the autocommit to true if needed. @sergionni `executeUpdate()` doesn't commit unless auto-commit is `true` I believe. If you want to do a batch update though you should be using `addBatch()` and `executeBatch()`. `executeBatch()` returns an `int[]` containing the update counts for each command in the batch.  getUpdateCount is meant to be used with the execute(String sql) method. You are probably doing this: String sql = ""UPDATE some_table SET somecolumn = ? WHERE someId = ?""; PreparedStatement ps = connection.prepare(sql); ps.setString(1 val); ps.setInt(2 id); ps.executeUpdate(); In that case you should simply do int rowsUpdated = ps.executeUpdate(); It seems this returns the matching rows and not necessarily the rows affected with my setup (MySQL) - meaning rows that are already the same value as what it would be updated to are counted even though they aren't actually updated. Running the update manually gives in MySQL Workbench: 0 row(s) affected Rows matched: 1 Changed: 0 Warnings: 0... while I get 1 from the Java executeUpdate().  You should be using PreparedStatement#executeBatch() when using batches. ... updTrans.addBatch(); upd = updTrans.executeBatch(); It returns an int[] containing update counts of each batch. yesyou are correct but it returns [-2] now ) The actual return value *may* depend on the JDBC implementation used (more precisely the JDBC driver used). If you consider it wrong as opposed to the JDBC API documentation (or the JDBC driver specific documentation) then consider posting an issue report at the JDBC driver vendor/maintainer. I can't go in detail since it's unknown which one you're using.  See The Javadoc public int executeUpdate() throws SQLException Executes the SQL statement in this PreparedStatement object which must be an SQL INSERT UPDATE or DELETE statement; or an SQL statement that returns nothing such as a DDL statement. Returns: either (1) the row count for INSERT UPDATE or DELETE statements or (2) 0 for SQL statements that return nothing Throws: SQLException - if a database access error occurs or the SQL statement returns a ResultSet object"
893,A,OSGi bundle starting problem I have a Java application. I created a OSGi bundle and in Activator.start i added MyMain Class.main() .Application started but it have a problem with DB connection. 'java.sql.SQLException: An attempt by a client to checkout a Connection has timed out.' If i start my application as an application it works fine. What is wrong? Thanks a lot! More details please - what exactly is implemented in the main() method? Is all your application code in one bundle? Yes I add in my application all for bundle. And in Activator starting it. Any number of things could be going wrong. You will need to post the code. Not sure exactly what you have done but there is no need for a main method when using OSGi. A main method is for starting your program which in this case is the OSGi container NOT your code. The container will run your code by running your Activator class and in here you can instantiate your own application specific objects and call whatever methods are appropriate. Since you haven't posted the code (you should) I can only guess that you are creating your DB connection in your main method instead of a normal method which is why it is not working since the main is not called.
894,A,Suspend weblogic datasource on command line I was Wondering if there is anyway of suspending / resuming weblogic 10 jdbc datasources via the command line. I am aware that i can do this in the admin console but because our app has many different datasources it is a bit of a pain. The reason behind this is that our testers are doing error flow tests and have to simulate the db going down. Ideally i would like to give then a bat file for suspending all datasources and another one for resuming all datasources. Any ideas? Thanks You can use the WLST scripting to do that. From the command line run $BEA_HOME/wlserver10.0/common/bin/wlst.sh (.cmd on Windows): Connect to the running server. Use the managed server port as this is a server runtime property: wls:/offline> connect('weblogic''weblogic''t3://localhost:7002') Go to the serverRuntime tree: wls:/mydomain/serverConfig> serverRuntime() Navigate to the JDBCService to your managed server name the JDBCDataSource Runtime and finally to your datasource name: wls:/mydomain/serverRuntime> cd('JDBCServiceRuntime/managedsrv1/JDBCDataSourceRuntimeMBeans/MyDS') Then just suspend and resume it: wls:/mydomain/serverRuntime/JDBCServiceRuntime/managedsrv1/JDBCDataSourceRuntimeMBeans/MyDS> cmo.suspend() wls:/mydomain/serverRuntime/JDBCServiceRuntime/managedsrv1/JDBCDataSourceRuntimeMBeans/MyDS> cmo.resume() use command ls() to see the the other variables and operations.  You can record your script... might be easier than writing the batch file in some cases. You can get help with the methods via javadocs.
895,A,How to implement a database GUI in java I want to write a java program that acts as a user interface to a mysql databasethe program should do the following: 1.connect to the databaseshow available tables in the database 2.display table data 3.modify table data (inserteditdeletesort) rows I've tried to use JDBC onlybut couldn't figure out a way to put the table data in a multidimensional array is there an API i should be using instead of just JDBC? This posting shows how to get a list of all the tables a database. Another blatent plug for votes :) The link provided above by Adamski also contains my two suggestions for populating a JTable from a ResultSet. Its 2 lines of code (when you use the provided ListTableModel)!  Blatent plug for votes: Here is an answer I gave to a similar question concerning populating a JTable from a JDBC ResultSet. As Michael says there are a lot of existing SQL clients so it's definitely not worth building your own. However if you want to populate a JTable with ResultSet data for a reason other than writing your own SQL client from scratch then the linked answer may help. Essentially the two APIs you'll need are JDBC and Swing (or an alternative such as SWT). I recommend reading back data from your ResultSet on a thread other than Swing's Event Dispatch thread; Otherwise your UI will lock up during large read operations.  No JDBC is the correct API. Representing DB table data as a multidimensional array is just not a good idea. Are you aware that there's lots of existing general SQL clients in Java? I knew there might be such applicationsI was intending on implementing one of my ownthanks for your help :)
896,A,"Multiple insert in a loop in jdbc while (tokens.hasMoreTokens()) { keyword = tokens.nextToken(); System.out.println(""File= ""+fileid+"" Keyword="" + keyword); stmt.executeUpdate( ""INSERT into TEXTVALUEINVERTEDINDEX "" + ""(FILEID KEYWORD) values ('"" + fileid + ""' '"" + keyword + ""')"" ); } This is the loop in which I'm updating the rows. The problem I'm facing is that when i run this only 1 value gets updated and when I comment the stmt.executeUpdate() line it displays all the possible entries in the database. What happens if you replace ""stmt.executeUpdate"" with ""System.out.println"" and try executing the output of that directly through your SQL client? That'll tell you if the problem is client-side or server-side. Your code should work. Make sure the sentence is not throwing any Exceptions when running by surrounding it with a try/catch block: try { stmt.executeUpdate(""INSERT into TEXTVALUEINVERTEDINDEX "" + ""(FILEID KEYWORD) ""+""values ('""+fileid+""' '""+keyword+""')""); } catch (SQLException e) { e.printStackTrace(); } You should also consider using a PreparedStament instead since its use is very appropriate for your described scenario: Something like this: String sql = ""insert into textvalueinvertedindex (fileid keyword) values (??)""; PreparedStatement pstmt = conn.prepareStatement(sql); while (tokes.hasMoreTokens()) { keywords = tokens.nextToken(); pstmt.setString(1 fileid); pstmt.setString(2 keyword); pstmt.executeUpdate(); } pstmt.close(); Actually i pasted only the loop code..the try catch block is present there is no exception being thrown  If you want all updates to be applied at once you can use batch execution here is an example page not loading. strange it work for me. anyway just google for ""java jdbc addBatch"" and pick any page you like.  You need to use preparedStatements... PreparedStatement pStmt = connection.prepareStatement(""INSERT into TEXTVALUEINVERTEDINDEX (FILEID KEYWORD) values(??)""); while (tokens.hasMoreTokens()) { keyword = tokens.nextToken(); System.out.println(""File= ""+fileid+"" Keyword=""+keyword); pStmt.setString(1 fileid); //This might be pStmt.SetInt(0 fileid) depending on teh type of fileid) pStmt.setString(2 keyword); pStmt.executeUpdate(); } then using this you can extend to us batch update... PreparedStatement pStmt = connection.prepareStatement(""INSERT into TEXTVALUEINVERTEDINDEX (FILEID KEYWORD) values(??)""); while (tokens.hasMoreTokens()) { keyword = tokens.nextToken(); System.out.println(""File= ""+fileid+"" Keyword=""+keyword); pStmt.setString(1 fileid); //This might be pStmt.SetInt(0 fileid) depending on teh type of fileid) pStmt.setString(2 keyword); pStmt.addBatch(); } pStmt.executeBatch(); Not sure why your code isn't working though - but this will probably help in the long run... pStmt.setString(0 fileid); here its giving an exception column not found.the fileid ive declared as String fileid We have to give pStmt.setString(1 fileid); pStmt.setString(2 keyword); Edited the original - this is the problem with working with multplie languages I was getting mixed up with .Net which is 0 indexed...  Your date range and filter selection contained no results. This is really a comment not an answer to the question. You can always comment on your own posts and once you have sufficient [reputation](http://stackoverflow.com/faq#reputation) you will be able to [comment on any post](http://stackoverflow.com/privileges/comment)."
897,A,"Java string to double conversion I've been reading up on the net about the issues with handling float and double types in java. Unfortunately the image is still not clear. Hence i'm asking here direct. :( My MySQL table has various DECIMAL(md) columns. The m may range from 5 to 30. d stays a constant at 2. Question 1. What equivalent data-type should i be using in Java to work (i.e store retrieve and process) with the size of the values in my table? (I've settled with double - hence this post). Question 2. While trying to parse a double from a string i'm getting errors Double dpu = new Double(dpuField.getText()); for example - ""1"" -> java.lang.NumberFormatException: empty String ""10"" -> 1.0 ""101"" -> 10.0 ""101."" -> 101.0 ""101.1"" -> 101.0 ""101.19"" -> 101.1 What am i doing wrong? What is the correct way to convert a string to a double value? And what measures should i take to perform operations on such values? EDIT This is the code -  System.out.println(dpuField.getText()); Double dpu = new Double(dpuField.getText()); System.out.println(dpu); Yes the problem lies with getText() reporting the wrong value of the dpuField. This method is called on the JTextField keyTyped event. So what's going wrong here? EDIT 2 Looking at : http://journals.ecs.soton.ac.uk/java/tutorial/post1.0/ui/keylistener.html Apparently keyTyped() does not give me the keycode. I'll have to switch to keyRealeased() For decimal I believe you risk losing precision if you don't use a BigDecimal on the Java side as some decimal fractions can't be stored as a binary fraction. Prefer Double.valueOf(String) over the constructor but that's a valid way. Something else must be going on (i.e. I doubt those are the actual String values you're passing in).  Question1: It's bad idea to map DECIMAL columns to Double usually the BigDecimal is the correct type. http://java.sun.com/j2se/1.3/docs/guide/jdbc/getstart/mapping.html#1055175 Question 2: You are doing something wrong; print the String value before converting.  What equivalent data-type should i be using in Java to work (i.e store retrieve and process) with the size of the values in my table? (I've settled with double - hence this post). Since it's a DECIMAL field you should prefer java.math.BigDecimal. You can store it in DB using PreparedStatement#setBigDecimal() and you can retrieve it from DB using ResultSet#getBigDecimal(). While trying to parse a double from a string i'm getting errors This can't be true. The problem lies somewhere else. Maybe it is just not returning the data you expect to be returned or you are not using/debugging the values you expect them to be. you're right. Check the edits. Use [`JFormattedTextField`](http://java.sun.com/javase/6/docs/api/javax/swing/JFormattedTextField.html). See [this tutorial](http://java.sun.com/docs/books/tutorial/uiswing/components/formattedtextfield.html).  if you need exact precision without rounding errors you should use a BigDecimal. Your code looks OK - could it be that dpuField.getText() somehow cuts the last character from the string values you list above? Update: you say Yes the problem lies with getText() reporting the wrong value of the dpuField. This method is called on the JTextField keyTyped event. Could it be that getText() returns the value of the field before the last typed key is actually appended to it? @wretrOvian see my update. but isn't getText() called AFTER the keyTyped event occurs? Meaning that the last typed character is already on the textfield. Puzzling. :@ Anyway i think the major problem is solved here. :) here we go. It becomes clear here http://journals.ecs.soton.ac.uk/java/tutorial/post1.0/ui/keylistener.html"
898,A,How to bypass JDBC statement cache in concurrent batch processing? I'm developing a server that should receive nightly reports from hundreds of business units. Reports are currently encrypted csv-files. In total the reports should amount to 500 000 to 1 000 000 records each day that are saved to a database for later use. I've create a set of PreparedStatements for each transmission. These statements are used to batch 50 records before executing and commiting. Each record may cause up to 20 database inserts. All is well when transmissions are queued and handled one-by-one. As I tried to do this concurrently I noticed that different threads got the exact same instances of the PreparedStatements. This caused the following problem Multiple threads added statements to the same batch Batches were being executed when any of the threads decided it was time to do so Commit was called when database did not meet it's constraints as some of the threads had not had time to use some of the statements The question is: Is there are way to force a prepared statement to be created instead of reusing an existing one from the statement cache? If not is there any better way to handle the situation than by creating a separate data source for the batches that does not have statement/connection pooling dropping constraints from the database; insert order would not matter anymore forcing sequential processing Edit: Attempt to clarify the problem Let there be threads T1 and T2. Let there be prepared statements S1 and S2. Let there be batches B1 and B2. Each time S1 is used it is added to B1. Each time S2 is used it is added to B2. When commiting S1 must be commited before S2 per foreign key constraint. Problem occurs when T1 processes transmissions gleefully T2 processes transmissions innocently T1 uses statement S1 adding s1a to batch B1 containing s1a T1 uses statement S2 adding s2a to batch B2 containing s2a T1 decides it is time to commit T1 commits batch B1 containing s1a T2 uses S1 adding s1b to batch B1 containing s1b T2 uses S2 adding s2b to batch B2 containing s2a s2b T1 commits batch B1 containting s2a s2b Database says 'no no' as s2b is commited before s1b which is forbidden in the foreign key. This can be avoided with manual synchronization as well as pointed in the answers but then I still have to track separately the size of each batch instead of applying logic local to each thread. I'll give both answers an upvote as they have helped me think through my problem. I'll provide the solution I chose when I've managed to test it. You'll have to use vendor-specific methods to do what you need. Which RDBMS are you working with? Aww. That's really not what I wanted to hear. Currently the test system runs on Apache Derby. The production database will be either Oracle 10g or R. Are you trying to use multiple statements there from a single connection instance? IMO a connection pool is recommended for the behaviour you describe. The alternative is to synchrnonize manually. Thank you for your answer. Each thread has one connection. Each connection has multiple statements one PreparedStatement instance for each separate SQL statement. Each statement contains a batch. The problems is that because of statement caching each thread does not have a unique set of statements which causes problems with the batches. Connection pool and statement cache do not really help here as the connection and statement preparation events are few and far between. Still trying to understand the issue - is the order of execution for the statements the problem? I edited the question for (hopefully) some clarification of the scenario. Execution order causes the crash yes. On the other hand shared statements and batches make it impossible to trust the local state. This in my opinnion causes avoidable / non-beneficial concurrency in my scenario i.e. managing the batches separate from the actual working thread. Ah. No.. to my understanding a mechanism to identify which Thread may execute which statement(s) needs to be provided manually. )+: Sorry I couldn't be more help.  My current solution is stop worrying and start loving the shared batches. I have split the processing algorithm to two phases Parse a set of N records and save them in an intermidiate format Persist the set of N records as a batch when a lock is awarded to the current thread This allows the parsing to concurrent and batching sequential. I'll just have to find a sweet spot to minimize the waiting time between threads. The quest for a sweet spot may lead to implementing some sort of a two-phased locking scheme i.e. let each thread do as they please and on commit make sure all threads have completed their current record before the actual batch execution. In the latter solution it might be necessary to synchronize over parameter setting for each PreparedStatement although I haven't tested if that causes any trouble. It should.  The solution is vendor-specific. If your code runs under a servlet then you might be able to solve your problem by configuring the datasource in your webapp. I have done that with Oracle driver under Tomcat but I'm sure other application servers have similar ways to configure connection pooling. If your code is standalone then you'll have to use vendor-specific API. As you will target Oracle as your production database here's a quick example for Oracle JDBC driver: import oracle.jdbc.OracleConnection; ... public static void disableStatementCaching(java.sql.Connection conn) throws SQLException { ((OracleConnection)conn).setImplicitCachingEnabled(false); } ... For more info see JDBC dev guide for Oracle 10.2 Thanks for you answer. I will definitely have a look in vendor specific APIs even though I'm bit skeptical about using them. The application doesn't run as a servlet. It's published as a web service as defined by EJB3 @WebService -annotation. However using an application server defined datasource and configuring it is entirely possible. It just needs proper documentation which probably will lead to a situation where a future developer will decide to optimize the performance by enabling statement caching.
899,A,"Configuring jetty to work with JDBC datasource i have an spring web application (on glassfish server) that use JDBC connection pool. It defined in XML file like this: <resources> <jdbc-connection-pool allow-non-component-callers=""true"" associate-with-thread=""true"" connection-creation-retry-attempts=""2"" connection-creation-retry-interval-in-seconds=""10"" connection-leak-reclaim=""false"" connection-leak-timeout-in-seconds=""0"" connection-validation-method=""table"" datasource-classname=""oracle.jdbc.pool.OracleConnectionPoolDataSource"" fail-all-connections=""false"" idle-timeout-in-seconds=""2147483638"" is-connection-validation-required=""true"" is-isolation-level-guaranteed=""false"" lazy-connection-association=""true"" lazy-connection-enlistment=""true"" match-connections=""false"" max-connection-usage-count=""0"" max-pool-size=""60"" max-wait-time-in-millis=""60000"" name=""company.jdbc.sc.nonxa.pool"" non-transactional-connections=""false"" pool-resize-quantity=""2"" res-type=""javax.sql.ConnectionPoolDataSource"" statement-timeout-in-seconds=""300"" steady-pool-size=""16"" transaction-isolation-level=""read-committed"" validate-atmost-once-period-in-seconds=""1"" validation-table-name=""SC_VALIDATE"" wrap-jdbc-objects=""false""> <property name=""DataSourceName"" value=""OracleNonXADataSource""/> <property name=""ImplicitCachingEnabled"" value=""false""/> <property name=""NetworkProtocol"" value=""tcp""/> <property name=""Password"" value=""password""/> <property name=""LoginTimeout"" value=""0""/> <property name=""URL"" value=""jdbc:oracle:thin:@oradbdev.company.ru:1521:COMPANY""/> <property name=""NativeXA"" value=""false""/> <property name=""User"" value=""prog10""/> <property name=""ExplicitCachingEnabled"" value=""false""/> <property name=""PortNumber"" value=""0""/> <property name=""MaxStatements"" value=""0""/> </jdbc-connection-pool> <jdbc-resource enabled=""true"" jndi-name=""company.jdbc.sc.nonxa.db"" object-type=""user"" pool-name=""company.jdbc.sc.nonxa.pool""/> </resources> And now i need to start application inside embedded Jetty server for integration test. I'm trying to add connection pool in jetty.xml file like this: <New id=""DS"" class=""org.mortbay.jetty.plus.naming.Resource""> <Arg> <Ref id=""wac""/> </Arg> <Arg>jdbc/DS</Arg> <Arg> <New class=""oracle.jdbc.pool.OracleConnectionPoolDataSource""> <Set name=""DataSourceName"">OracleNonXADataSource</Set> <Set name=""ImplicitCachingEnabled"">false</Set> <Set name=""NetworkProtocol"">tcp</Set> <Set name=""Password"">password</Set> <Set name=""LoginTimeout"">0</Set> <Set name=""URL"">jdbc:oracle:thin:@oradbdev.company.ru:1521:COMPANY</Set> <Set name=""NativeXA"">false</Set> <Set name=""User"">prog10</Set> <Set name=""ExplicitCachingEnabled"">false</Set> <Set name=""PortNumber"">0</Set> <Set name=""MaxStatements"">0</Set> </New> </Arg> </New> It register connection pool but i also nee to register jdbc-resource with given name. How i can to do that? With Jetty you set the JNDI name of the connection pool in the configuration (here jdbc/DS). So why would you need to register a ""jdbc-resource""? This seems to be a specific step to GlassFish. i register this datasource in webxml with name but have an error. Embedded error: Object is not of type class org.mortbay.jetty.webapp.WebAppContext How can i fix it? What version of jetty are you using?"
900,A,"Oracle JDBC connection exception in Solaris but not Windows? I have some Java code that connects to an Oracle database using DriverManager.getConnection(). It works just fine on my Windows XP machine. However when running the same code on a Solaris machine I get the following exception. Both machines can reach the database machine on the network. I have included the Oracle trace logs. Mar 23 2010 12:12:33 PM org.apache.commons.configuration.ConfigurationUtils locate FINE: ConfigurationUtils.locate(): base is /users/theUser/ADCompare name is props.txt Mar 23 2010 12:12:33 PM org.apache.commons.configuration.ConfigurationUtils locate FINE: Loading configuration from the path /users/theUser/ADCompare/props.txt Mar 23 2010 12:12:33 PM oracle.jdbc.driver.OracleDriver connect FINE: OracleDriver.connect(url=jdbc:oracle:thin:@//theServer:1521/theService info) Mar 23 2010 12:12:33 PM oracle.jdbc.driver.OracleDriver connect FINER: OracleDriver.connect() walletLocation:(null) Mar 23 2010 12:12:33 PM oracle.jdbc.driver.OracleDriver parseUrl FINER: OracleDriver.parseUrl(url=jdbc:oracle:thin:@//theServer:1521/theService) Mar 23 2010 12:12:33 PM oracle.jdbc.driver.OracleDriver parseUrl FINER: sub_sub_index=12 end=46 next_colon_index=16 user=17 slash=18 at_sign=17 Mar 23 2010 12:12:33 PM oracle.jdbc.driver.OracleDriver parseUrl FINER: OracleDriver.parseUrl(url):return Mar 23 2010 12:12:33 PM oracle.jdbc.driver.OracleDriver connect FINER: user=theUser password=****** database=//theServer:1521/theService protocol=thin prefetch=null batch=null accumulate batch result =true remarks=null synonyms=null Mar 23 2010 12:12:33 PM oracle.jdbc.driver.PhysicalConnection <init> FINE: PhysicalConnection.PhysicalConnection(ur=""jdbc:oracle:thin:@//theServer:1521/theService"" us=""theUser"" p=""******"" db=""//theServer:1521/theService"" info) Mar 23 2010 12:12:33 PM oracle.jdbc.driver.PhysicalConnection <init> FINEST: PhysicalConnection.PhysicalConnection() : connectionProperties={user=theUser password=****** protocol=thin} Mar 23 2010 12:12:33 PM oracle.jdbc.driver.PhysicalConnection initialize FINE: PhysicalConnection.initialize(ur=""jdbc:oracle:thin:@//theServer:1521/theService"" us=""theUser"" access) Mar 23 2010 12:12:33 PM oracle.jdbc.driver.PhysicalConnection initialize FINE: PhysicalConnection.initialize(ur us):return Mar 23 2010 12:12:33 PM oracle.jdbc.driver.PhysicalConnection needLine FINE: PhysicalConnection.needLine()--no return java.lang.ArrayIndexOutOfBoundsException: 31 at oracle.net.nl.NVTokens.parseTokens(Unknown Source) at oracle.net.nl.NVFactory.createNVPair(Unknown Source) at oracle.net.nl.NLParamParser.addNLPListElement(Unknown Source) at oracle.net.nl.NLParamParser.initializeNlpa(Unknown Source) at oracle.net.nl.NLParamParser.<init>(Unknown Source) at oracle.net.resolver.TNSNamesNamingAdapter.loadFile(Unknown Source) at oracle.net.resolver.TNSNamesNamingAdapter.checkAndReload(Unknown Source) at oracle.net.resolver.TNSNamesNamingAdapter.resolve(Unknown Source) at oracle.net.resolver.NameResolver.resolveName(Unknown Source) at oracle.net.resolver.AddrResolution.resolveAndExecute(Unknown Source) at oracle.net.ns.NSProtocol.establishConnection(Unknown Source) at oracle.net.ns.NSProtocol.connect(Unknown Source) at oracle.jdbc.driver.T4CConnection.connect(T4CConnection.java:1037) at oracle.jdbc.driver.T4CConnection.logon(T4CConnection.java:282) at oracle.jdbc.driver.PhysicalConnection.<init>(PhysicalConnection.java:468) at oracle.jdbc.driver.T4CConnection.<init>(T4CConnection.java:165) at oracle.jdbc.driver.T4CDriverExtension.getConnection(T4CDriverExtension.java:35) at oracle.jdbc.driver.OracleDriver.connect(OracleDriver.java:839) at java.sql.DriverManager.getConnection(DriverManager.java:582) at java.sql.DriverManager.getConnection(DriverManager.java:185) The above exception is also thrown if I use OracleDataSource instead of the generic DriverManager.getConnection(). Any ideas on why the behavior is different in the different environments? It looks like there's an error in TNSNAMES.ORA from the lines java.lang.ArrayIndexOutOfBoundsException: 31 at oracle.net.nl.NVTokens.parseTokens(Unknown Source) ... at oracle.net.resolver.TNSNamesNamingAdapter.loadFile(Unknown Source) I'm not up on the oracle configuration from solaris but assuming it's similar to the win version maybe you have an issue with the formatting of this file. Can you connect through a sqlplus console from that box? I'm not sure why the thin driver decides to load a tnsnames.ora file but according to the stack trace it's definitively choking on the content of a tnsnames.ora file. I didn't even consider that it might be trying to load the tnsnames.ora file and choking on it. I'm specifying the Oracle JDBC driver in my code but it's still not clear why it's trying to load tnsnames.ora. I will explore this further. Thanks for the help.  One thing I forgot to mention is that my application is built for Java6. The Oracle database is 10g but for whatever reason upgrading to the 11g version of the driver (i.e. ojdbc6_g.jar) fixed the problem."
901,A,"Wildcards in Java PreparedStatements Here's my current SQL statement: SEARCH_ALBUMS_SQL = ""SELECT * FROM albums WHERE title LIKE ? OR artist LIKE ?;""; It's returning exact matches to the album or artist names but not anything else. I can't use a '%' in the statement or I get errors. How do I add wildcards to a prepared statement? (I'm using Java5 and MySQL) Thanks! You put the % in the bound variable. So you do  stmt.setString(1 ""%"" + title + ""%""); stmt.setString(2 ""%"" + artist + ""%""); So what if the bound variable actually had a '%' character in it? @Eric - Then you don't need to add it. There's nothing magical about doing it in the setString rather than anywhere else. If your bound variable has a literal '%' you should escape it as '\%'. See Java method java.lang.String.replace()."
902,A,"How to retrieve data which caused unique constraint violation (via Hibernate)? Is there a way to find out which record caused such a violation in Hibernate? Normally you add objects to session and at the end you persist them. If such an error occurs it takes a while to track down which record has violated the constraint. Is there way to find out which record caused (either to ""toString() in case of new objects or Primary Key in case of existing objects should simplify debug process enormously. Thanks. org.hibernate.exception.ConstraintViolationException: could not insert: [com.project.valueobject.mapping.Model] at org.hibernate.exception.SQLStateConverter.convert(SQLStateConverter.java:71) at org.hibernate.exception.JDBCExceptionHelper.convert(JDBCExceptionHelper.java:43) at org.hibernate.id.insert.AbstractReturningDelegate.performInsert(AbstractReturningDelegate.java:40) at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:2163) at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:2643) at org.hibernate.action.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:51) at org.hibernate.engine.ActionQueue.execute(ActionQueue.java:279) at org.hibernate.event.def.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:298) at org.hibernate.event.def.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:181) at org.hibernate.event.def.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:107) at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.saveWithGeneratedOrRequestedId(DefaultSaveOrUpdateEventListener.java:187) at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.entityIsTransient(DefaultSaveOrUpdateEventListener.java:172) at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.performSaveOrUpdate(DefaultSaveOrUpdateEventListener.java:94) at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.onSaveOrUpdate(DefaultSaveOrUpdateEventListener.java:70) at org.hibernate.impl.SessionImpl.fireSaveOrUpdate(SessionImpl.java:507) at org.hibernate.impl.SessionImpl.saveOrUpdate(SessionImpl.java:499) at org.hibernate.impl.SessionImpl.saveOrUpdate(SessionImpl.java:495) Using TRACE level log level displays the values of all parameters that are passed into the database.  I would implement one or more Hibernate Event Listeners and do a bit of logging before performing operations. Hopefully this is suitable for your scenario. (I suspect you are not using MySQL as I am because MySQL actually returns the offending unique key if a constraint is violated) We already have auditing interceptors but when the list is big then its not easy to track down which of the element caused the error. BTW we are using Oracle. Perhaps this post will come in use: http://technicalpickles.com/posts/tracking-down-oracle-constraint-violations-with-a-little-sql-and-toad/  I simply set a breakpoint in AbstractEntityPersister::performInsert(...) to find out the offending record. As _NT said may be MySQL supports this but not Oracle. But will keep this open to know any elegant solution. Why aren't event listeners elegant? As I explained in my above comment until I try to 'save' I will not about the constraint and then its too late. I was looking for something like you said about 'MySQL' may be its Oracle the culprit :-)"
903,A,"what databases can be used with java? I am doing an undergrad final project and need to justify my choice of MySQL for the database element of my project. Truth is it's the only one I can really use and hence I went for it. What other database systems could I have used? Any advantages and disadvantages of these over MySQL? As always the answer depends on your needs. Could you explain the role that the relational database plays in your project? Also can you clarify what is meant by ""it's the only one I can really use""? i am trying to implement access controls using a category based model in a banking environment. The database will hold data about ""customers"" and their transactions accounts etc. It also will hold details about employees. this data will then be used to categorise each user of the system and in turn will decide whether actions performed by the users will be permitted or denied. ""only one i can really use"" meaning its the only thing i have learnt about at university but in theory only - not in practice. hope that helps...?! In fact you can use every database which is accessible through a JDBC driver. Almost all self-respected RDBMS vendors provides a fullworthy JDBC driver for download at their homepage. Just Google ""[vendorname] jdbc driver download"" to find it. Here's an overview: MySQL JDBC driver PostgreSQL JDBC driver (note: older versions doesn't support generated keys). Oracle JDBC driver (note: older versions doesn't support generated keys). MSSQL JDBC driver (or performancewise better the jTDS JDBC driver) DB2 JDBC driver is hard to find in IBM's online forest but it's usually already included in the /java folder of the DB2 installation. This way you can use the JDBC API transparently to access either of the databases. As to which database to choose just look at the features robustness performance etc the RDBMS provides and the budget you have -if it isn't freeware. I myself tend to prefer PostgreSQL. Instead of a fullfledged database server you can also consider an embedded Javabased database such as Sun Oracle JavaDB Apache Derby HSQLDB or SQLite each which are of course accessible through the JDBC API the usual way. One more embedded solution to add to the list: SQLite available in both pure-Java and JNI-based versions. @Michael E: added.  You mentioned MySQL and database. For the case you are free to usa a non RDBMS you can check db4o. Advantage: pure OO/Java persistence.  You can use any relational database that has a JDBC driver. These would include PostgreSQL Hypersonic SQL MySQL SQLLite on the free side and Oracle MS SQL Server and others on the paid side. The biggest advantage accrued to MySQL in your case is that it's free and you know it. That's enough to make it suitable for what you want to accomplish.  You could have used pretty much ANY database. MSSQL SQLite Postgre Oracle or [put your choice here] There's a driver for pretty much any database to integrate with Java. This is a great place to find out all the DB's java support as well as how to integrate Hope this helps  Have a look at the list of vendors who have endorsed the JDBC API maintained by Sun. Also see the list of third-party JDBC technology-enabled drivers which are currently shipping."
904,A,"Need help in setting application name with JPA (EclipseLink) hello everybody i am using JPA with EclipseLink and oracle as DB and i need to set the property v$session of jdbc4 it allows to set an identification name to the application for auditing purposes but i had no lucky setting it up....i have been trying through entitiyManager following the example in this page: http://wiki.eclipse.org/Configuring_a_EclipseLink_JPA_Application_(ELUG) it does not show any error but does not set the application name at all... when i see the audit in oracle it is not being audited with the name i set by code ""Customers"" but with OS_program_name=JDBC Thin Client it means that the property in the code is not being set properly and i have no idea where the issue is the code i am using is the following :  emProperties.put(""v$session.program""""Customers""); factory=Persistence.createEntityManagerFactory(""clients""emProperties); em=factory.createEntityManager(emProperties); em.merge(clients); does anybody know how to do it or any idea.... thanks.- v$session.program is a JDBC connection property but Persistence.createEntityManagerFactory gets persistence unit properties. There is no direct way to pass arbitrary JDBC property into entity manager. However in EclipseLink you can use SessionCustomizer: public class ProgramCustomizer extends SessionCustomizer { @Override public void customize(Session s) throws Exception { s.getDatasourceLogin().setProperty(""v$session.program"" ""Customers""); super.customize(s); } } - emProperties.put(PersistenceUnitProperties.SESSION_CUSTOMIZER ""ProgramCustomizer"");"
905,A,"How to escape ? character in jdbc stored procedure calls I would like to call this stored procedure with jdbc: sp_msforeachtable ""ALTER TABLE ? NOCHECK CONSTRAINT all"" JDBC thinks the ? is a placeholder for an argument. In fact it is used by the SP to put in the table name. How can I call the stored procedure? I tried this: CallableStatement call = jdbcConnection.prepareCall(""call sp_msforeachtable(?)""); call.setString(1 ""\""ALTER TABLE ? NOCHECK CONSTRAINT all\""""); call.executeUpdate(); and I get a syntax error near '@P0'. I guess '@P0' is the ?. How can I call this SP? I am using SQL Server 2008 BTW. You say that the ? is supposed to be for a table name so you need to provide an actual table name before calling Statement.executeUpdate(). At that point the JDBC driver will tell the database to actually run the statement so obviously all parameters need to be bound. Maybe you meant to write this: CallableStatement call = jdbcConnection.prepareCall(""call sp_msforeachtable(?)""); call.setString(1 ""AnActualTableName""); call.executeUpdate(); or maybe you meant to write this: CallableStatement call = jdbcConnection.prepareCall(""call sp_msforeachtable(\""ALTER TABLE ? NOCHECK CONSTRAINT all\"")""); call.setString(1 ""AnActualTableName""); call.executeUpdate(); I'm not sure exactly what sp_msforeachtable() is supposed to do but I do know that you have to provide values for all parameters before calling executeUpdate()"
906,A,"What's the difference between Tomcat JNDI based and Spring/Hibernate DS based connection pooling I have been looking into connection pool options and it is somewhat unclear to me what the differences in Tomcat JNDI connection pool approach is compared to the Spring/Hibernate solution to the same. Whilst it's possible to achieve the pooling using either 1 2 the specific application we have would lend itself better to us using Tomcat given the constraints we have. Reading about there is some suggestion to just stick with Spring/Hibernate. Are there any notable differences worth mentioning between each approach? What are other's personal experience of one or the other (or both) - I have successfully been using Spring/Hibernate for years now. I might be wrong but I think if you use JNDI connection pool it will be container-wide (e.g. shared between several web applications). If you define a connection pool in your Spring context it will leave within your context (e.g. it will be application-wide). I haven't used Tomcat+JNDI option so I cannot give really good advice. The two approaches are complementary not mutually exclusive. In production systems the likes of Spring/Hibernate will obtain a reference to the connection pool from the appserver in the form of a javax.sql.DataSource usually by looking for it on the JNDI tree. It generally considered to be the appserver's ""job"" to manage the connection pool and its connections. Remember JNDI is just a place for registering objects for sharing it does in itself mandate any given connection pool mechanism. The app server creates and configures the pool and the applications (via Spring/Hibernate/whatever) use it. It's just as valid however for the applications to configure and manage the connection pool themselves. This does mean a bit more work for the application though with less reliance on the appserver. Fair enough that makes sense. Now supposing I went with Tomcat JNDI based Pooling I assume therefore I would need to turn the pooling config in Spring off in order not to pool on top of Tomcat's JNDI pooling... ? Spring doesn't have a connection pool implementation it uses whatever `DataSource` object you give it - if that happens to be a connection pool supplied by Tomcat via JNDI so much the better. true sorry I meant Hibernate Oh right. Yes Hibernate's connection pooling is strictly for development use it's not intended for production systems - it says as much in the manual: http://docs.jboss.org/hibernate/stable/core/reference/en/html/session-configuration.html#configuration-hibernatejdbc"
907,A,"How to add an Interbase connection pool to glassfish? I am attempting to add an Interbase connection pool to GlassFish v3 to use EJB 3.1 in a project. The glassfish log appears to be connecting to my database properly it spits out all my table names and indices. However I get an error INFO: fetching database metadata SEVERE: could not complete schema update java.lang.NullPointerException at interbase.interclient.ResultSet.local_Close(Unknown Source) ... And when I ping the connection pool from within Glassfish I receive ""Ping failed Exception - null"". I have the following properties set with my connectionpool: resource type: javax.sql.DataSource Datasource Classname: interbase.interclient.DataSource portNumber: 3050 as well as my database info. I can't seem to find information elsewhere. This question is similar but did not receive an answer. thanks. partial duplicate of http://stackoverflow.com/questions/1624779/how-can-i-add-a-interbase-jdbc-connection-pool-in-glassfish-v3 - but it contains additional information If the ping fails at the connection pool level then things are very likely not going to work. Any chances to use another database? If yes really do it because Interbase seems to be an outdated product and I'm not very confident with the quality of available JDBC drivers (drivers listed in this page are all so old and dusty). It looks like time has been suspended with J2EE 1.3... If not then maybe try another driver (the Firebird one for example). Update: As pointed out by Craig in a comment InterBase is maintained by Embarcadero and includes a Type 4 JDBC Driver. But still the Borland/CodeGear/Embarcadero products are IMHO on a dying trend. defintitely a possibility up to the boss in the end though. I am currently trying to get postgres working do you know anything about Sybase? reccomend it? DB2? Thanks for the advice. @kgrad PostgreSQL is a very nice open source product. In the commercial world Sybase is not the leader but it's great (MS SQL Server use the same engine). DB2 is not very friendly but definitely good. Any of those products are alive and would be better than Interbase IMHO. The final choice is often not only a technical choice though. InterBase is actively maintained and includes a maintained type 4 JDBC driver. If it's not working for a specific case support is available from Embarcadero. Unfortunately he doesn't say if he's using the current version or an old one."
908,A,Multi-user Datasources - Spring + Hibernate I'm writing a web app that supports multiple users. Each user has their own database - using H2. all database schemas are the same. I wish to use Spring + Hibernate for this application. So I'm stuck at how to associate a user's database with that user - maybe associated it in the HTTPSession and extend spring's AbstractRoutingDataSource? but wouldn't this effect Hibernate's cache? Another way is to have a SessionFactory with each datasource even though every datasource's schema is the same... so I see that as a waste. Anyways selecting the datasource needs to be dynamic - they can't be pre-configured in context files as each new user will have its own database created. Is there any existing frameworks/solutions? I don't know too much about Hibernate Shards maybe that works? Any help is appreciated! Thanks in advance. This tutorial may help you This one will be helpful  Thanks to the help from the 2 people (Pascal and org.life.java)! It is possible but with some problems: e.g. the hibernate 2nd level cache/query cache. This link supplied by Pascal is a very good resource: http://www.jroller.com/kenwdelong/entry/horizontal_database_partitioning_with_spring. My main motivation for giving each user a separate database is because the data is likely to grow rapidly thus horizontal partitioning is required.  I might be wrong about the (strict) need to have one SessionFactory per database as suggested by some resources: http://blog.springsource.com/2007/01/23/dynamic-datasource-routing/ http://forum.springsource.org/archive/index.php/t-34207.html http://www.jroller.com/kenwdelong/entry/horizontal_database_partitioning_with_spring http://www.jroller.com/mert/entry/multiple_db_with_single_sessionfactory I'll take some time to re-read everything tomorrow (I didn't get all the details to be honest) and to fully understand the implications of such a setup (although it seems clear that it will break the second-level cache). I'll come back on this later. I'm writing a web app that supports multiple users. Each user has their own database - using H2. all database schemas are the same. I wonder how this will scale... How many users do you have? How do you run H2 what mode? So I'm stuck at how to associate a user's database with that user - maybe associated it in the HTTPSession and extend spring's AbstractRoutingDataSource? You'll have to build a SessionFactory per user and associate it to the logged user (in a Map using the login as key) and then obtain a Session from a given SessionFactory. Binding the lifecycle of the SessionFactory to the HTTP session seems to be a good idea (to save some memory) but I am not sure Spring will be very helpful here. I might be wrong but a variation of the HibernateUtil class and a fully programmatic approach looks easier. I'm not sure you'll need multiple connections per user by the way. but wouldn't this effect Hibernate's cache? What cache? Another way is to have a SessionFactory with each datasource even though every datasource's schema is the same... so I see that as a waste. Oh it's a waste but that's what you want to do (one database per user). And you don't have the choice (you need one SessionFactory per datadabase). Why do you need one database per user actually? Are you sure this is a wise decision? As already hinted this means much troubles won't scale well adds complexity etc. Why not using a single database and associating data to the user? Anyways selecting the datasource needs to be dynamic - they can't be pre-configured in context files as each new user will have its own database created. Is there any existing frameworks/solutions? Not to my knowledge. Which is also why I think you'll have to do everything programatically. I don't know too much about Hibernate Shards maybe that works? Given the dynamic needs of your application I don't see how it could help. Hi Pascal Thanks for your reply. All the databases have the same schema so one SessionFactory for all these databases would be fine. Hibernate has a 2nd level cache which might contain invalid cached data if I load 2 unique entities from 2 different databases but with the same IDs. I think I can get this to work by associating the DataSource with a HttpSession and using an Interceptor to attach the DataSource in the HttpSession to ThreadLocal so that my AbstractDataSource impl can get the correct DS for the transaction. +1 for the Ken DeLong article -- it saved me a few headaches :-)
909,A,Where do you put your SQL Queries? We are using a mix of EJB 2.1 and JDBC to access our Database. I just had a co-worker mention the idea to put his SQL Queries into a .properties file. How and Where do you put your SQL Queries? EDIT: Do you inline it with the code put into the class instantiation? I use Ibatis so all the queries reside in Ibatis XML files. If not Ibatis then in DAO java code.  In DAOs since I consider them part of my application and not a configurable (changeable by a sysadmin) element of the application.  I usually add queries as static strings in the DAO implementation that uses them.  Where I work now we use properties files to store our SQL queries. I quite like it since I've always thought it looks rather messy when in the code. I dont really see it as configurable by a sys admin since they will all be bundled with the jar and hence invisible. main reason i disagree with this form is because you end up separating everything. If for any reason i require to read the code i end up having to jump over to huge property file to find it. But on the other hand it makes the code more readable and at the same time the SQL more readable by having them in separate files. Probably a matter of personal preference :)  We store our SQL queries as string literals in DAOs. The DAOs hide the potentially ugly SQL syntax from the rest of the application. When you do dig down into the DAO code having the SQL queries in the context in which they will be used helps make code easier to understand.
910,A,Encrypted JDBC connection I do a lot of work on databases over the internet. My company is instituting a policy of not sending any non-encrypted information (including vanilla JDBC). I currently connect to MS Sql Server and db2 databases (both LUW and AS/400). Is there an easy way to encrypt/decript these connections? Edit: Found an interesting and relatively simple ssh tunnelling article that may be of some help. http://www.ibm.com/developerworks/data/library/techarticle/dm-0312lurie/index.html I'd rather use stunnel (stunnel.org) instead of ssh tunelling. Don't know about those databases but oracle can be set to encrypt connection data that it sends out (& I think that it receives). The standard oracle jdbc jar copes with the encrypted data without any client configuration or programming changes. Also - if you're using VPN to connect to your databases over the internet then this will be encrypted anyway won't it?  Maybe JDBC over SSL if your databases support SSL and your JDBC drivers too. A fast googling shows that Microsoft SQL Server JDBC Driver 1.2 has support for SSL encryption and that the IBM DB2 JDBC Driver 9.1 includes SSL support to database servers that also have SSL support. Some links : SQL Server 2005 JDBC driver v1.2 Aug CTP is LIVE (2007-09-04) SSL in Microsoft SQL Server JDBC 1.2 driver (2008-02-04) What's new for V9.1: JDBC and SQLJ enhancements (2008-10-01)  Docs: For DB2: Properties for the IBM DB2 Driver for JDBC and SQLJ (look at the property sslConnection) For MSSQL: Using SSL Encryption
911,A,"SmartGWT RestDateSource and Paging (Large DataSet of) Dynamic Data I have a database table for log messages and at any time there can be inserted new rows. I want to show them in grid and when you scroll down I want to request more rows form this table (server side) but without to be affected from new added rows. The new rows only have to be visible if I refresh the whole grid. I'm not sure how can I request rows in a range (from to) using JDBC. I think there is no portable (across deferent databases) SQL query to do this? (I'm using MYSQL) I think that after reading first page of this table I have to send to the client side the Max Id from log table and after that request new rows using this Max Id as parameter in SQL (WHERE id <= MAXID) but I'm not sure how I can pass this parameter from server to client and back using RestDateSource? Do you have any better ideas how I can make this? P.S. I'm using LGPL SmartGWT version and using my own servlets for server side. I have another idea: I can find this MAXID from first page result (id of the first received row) but this will work only if I disable sorting in user interface which is not so bad idea. But how to send this parameter from client to server for another pages and how to request rows in range with JDBC? Here is what I would do; I imagine that you either have a growing-number ID or a timestamp for each of your rows. Before you start querying for data you call a webservice to query the current id (eg last line insterted is 12345). Then you add a Criteria object to your datasource that says ""rowId <= 12345"". At this point you can use the grid freely - paging sorting etc will work automatically as new rows will automatically be excluded. (Or if you use a personalized datasource and not the default RESTdataSource you basically do the same thing without using Criteria explicitly). That's exactly what i made and it works great :) And by the way how can I make ""less or equal"" crieteria? I'd go for ""rowId < (12345+1) "" See my comment on my answer below - the proposed strategy handles insertion but not deletion and also does not handle updates to already-loaded records which may also be a requirement. A more complete implementation is to have a field that when a record is added or updated gets the current timestamp then pass the timestamp of the earliest loaded records back and forth between client and server invalidating cache when there's a mismatch. We make this trivial in SmartGWT since there is a field type ""modifierTimestamp"" that does this automatically.  SmartGWT Pro and better do this automatically. Even if you don't want to use Pro you can download the evaluation (smartclient.com/builds) and watch the server-side console where the SQL queries are logged. I saw that they are using LIMIT (SQL) but they still have the problem with newly concurent inserted rows. http://www.stackoverflow.com.s3.amazonaws.com/Concurent%20Insert.png We provide a flag you can set on a response from the server to invalidate the current cache. Determining when to invalidate the cache is something you do based on a strategy similar to the above (rowId) except of course that strategy doesn't handle deletion. Since doing this requires you to have a sequence field or similar to track changes we don't turn it on automatically. But it's straightforward to add if you have the data available to do the detection. Our server framework allows you to add Java logic which runs in addition to the automatic SQL operation for this kind of usage."
912,A,"Relationships between Spring Hibernate JDBC I just start reading Sun's JDBC tutorial. I installed MySQL Connector/J and was just skimming through its menu then came across this statement: ""Although JDBC is useful by itself we would hope that if you are not familiar with JDBC that after reading the first few sections of this manual that you would avoid using naked JDBC for all but the most trivial problems and consider using one of the popular persistence frameworks such as Hibernate Spring's JDBC templates or Ibatis SQL Maps to do the majority of repetitive work and heavier lifting that is sometimes required with JDBC"" So what are the relationships between Spring Hibernate JDBC? What does the statement mean by saying ""avoid using naked JDBC""? Thanks Sarah related post:http://stackoverflow.com/questions/826165/hibernate-vs-jdbc another related question: http://stackoverflow.com/questions/2723228/which-are-the-differences-similarities-between-hibernate-and-other-frameworks-or If you use Hibernate Spring's JDBC templates or Ibatis SQL Maps you're still using JDBC but you don't have to deal with it directly. They're doing it for you and to a degree insulate you from some difficulties in the use of JDBC. Hibernate is an object-relational-mapping framework. MyBatis formerly known as iBatis is a data mapping framework. Spring is a wide-ranging set of web framework components and includes templating subsystems that allow integration with JDBC Hibernate or iBatis and abstract away some of the details of dealing with any of them. You should indeed learn JDBC but also (eventually) learn some of these others and try to avoid using JDBC directly for anything very complex. These ideas are also (especially Hibernate) closely related to the Java Persistence API (JPA) which is also certainly worth learning. You might also want to look at Java Data Objects (JDO). Don't try to learn it all at once though. Starting with JDBC is a good idea. Staying with it is not. *""Starting with JDBC is a good idea. Staying with it is not.""* +1 for that (and the rest also) Thanks. Love your answer because you also pointed out the learning direction apart from information.  ""avoid using naked JDBC"" - Don't use the JDBC API directly. Hibernate - A database persistence framework. It lets you store Java objects in databases. Pretty nifty. Spring - It's actually a web development framework. The JDBC templates are an abstraction to JDBC I think.  Alphabets > Words > Sentences. That is how we learn (natural) language. Similarly I see: JDBC API > JDBC API with Connection Pooling > Spring JDBC Template > ORM/JPA/JDO"
913,A,"In JDBC when to use Time Date and Timestamp JDBC offers me 3 different datatypes for time-related fields: ""Date"" ""Time"" and ""Timestamp"". Can someone provide a simple summary of what each one is used for and how to choose which to use for a given problem? Let's assume you have the date/time January 1 2003 2:00pm stored in a database column. The three options are used as follows: Use Date if you are only interested in the date portion of the date string. ex: January 1 2003 Use Time if you are only interested in the time portion of the date string ex: 2:00pm Use Timestamp if you want the date and time of the date string ex: January 1 2003 2:00pm Date stores the time also. Timestamp can have a finer resolution of time then Date. This answer sounds good but I am fairly sure that it is inaccurate. The java.sql.Date object contains a time (down to milliseconds). That is true but when you retrieve a date using the ResultSet.getDate() method it sets the time portion of the Date to 00:00. It's what JDBC calls ""normalizing"" when using getDate as getDate returns a java.util.Date object. Okay after further research it turns out you are correct. Thank you."
914,A,MySQLNonTransientConnectionException in JDBC program at run time Hi I have created JDBC MySQL connection. My program works fine for simple execution of query. But if I run the same program for more than 10 hours and execute query then I receives the following MySQL exception. I have not used close() method anywhere. I created database connection and opened it forever and always executed query. There is no place where I explicitly mentioned timeout for connection. I am unable to identify the problem. com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: Connection.close() has already been called. Invalid operation in this state. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after statement closed. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) Sample code for database connection:  String driver = PropertyReader.getDriver(); String url = dbURLPath; Class.forName(driver); connectToServerDB = DriverManager.getConnection(url); connectToServerDB.setAutoCommit(false); You have to make a change in the configuration file or increase the timeout period of your database. If database remains idle for more than 8 hours it is closed by default. Thanks  MySQL terminates a connection after 8 hour timeout. You can modify the timeout by setting wait_timeout variable in MySQL. Yet generally it is not such a good idea for an application to hold a connection for such a long time. A better approach is to set up a connection pool using a pooling API such as Apache DBCP and retrieve connections from the pool rather than directly though a driver. A connection pool will also take care about re-establishing a pooled connection if it dies for some reason including timeouts.  I faced the same problem too. It's because of connection timeout by mysql and generally its not a good practice to extent the timeout in mysql as it serves for many other applications. It's good to reconnect the database on timeouts (i.e when this exception occurs) or to use some open source libraries for connection pooling like Apache DBCP as @slava suggested. ORM Frameworks takes care of this by default. Cheers!!
915,A,"MySql timeouts - Should I set autoReconnect=true in Spring application? After periods of inactivity on my website (Using Spring 2.5 and MySql) I get the following error: org.springframework.dao.RecoverableDataAccessException: The last packet sent successfully to the server was 52847830 milliseconds ago. is longer than the server configured value of 'wait_timeout'. You should consider either expiring and/or testing connection validity before use in your application increasing the server configured values for client timeouts or using the Connector/J connection property 'autoReconnect=true' to avoid this problem. According to this question and the linked bug I shouldn't just set autoReconnect=true. Does this mean I have to catch this exception on any queries I do and then retry the transaction? Should that logic be in the data access layer or the model layer? Is there an easy way to handle this instead of wrapping every single query to catch this? We needed to set the following properties in order to avoid the timeout even with connection pooling; we use the Apache Commons DBCP. <property name=""validationQuery""> <value>SELECT 1</value> </property> <property name=""testOnBorrow""> <value>true</value> </property>  I would suggest that you use a connection pool instead. They improve performance and can take care of the low-level details such as reconnect after timeout etc. A good one is c3p0 but there are others. Spring has support for that though I don't know all the details. Here is the configuration of a DataSource for Spring. I've been using c3p0 for the last 3 years in production and it rocks.  This exception can have 2 causes: You aren't closing the JDBC resources properly. All of the Connection Statement and ResultSet must be closed in reversed order in the finally block of the try block where they're been acquired. This is regardless of the fact whether you're using a connection pool or not. You are closing the JDBC resources properly but using a connection pool with poor settings. You need to make sure that the connection pool don't hold connections open longer than the DB configrured timeout. Decrease the one or increase the other in the configuration."
916,A,"""Invalid SQL statement or JDBC escape terminating '}' not found."" with jTDS and Sybase I'm calling a stored procedure via ibatis. It works and has worked when using the jconn2.jar (5.5). When I swap it out for the jtds jar (1.2.5) I get an exception ""Invalid SQL statement or JDBC escape terminating '}' not found."" For more transparency I'm using Spring with DBCP. Obviously the parsing of the SQL code in jTDS is not being liked that is being accepted in jconn2. This project predates a bunch of us and I haven't used Sybase in years. The outlying chars in the data are ""-"" "":"" and ""."" Do I need to escape my parameters in the stored procedure call statement to get around this issue? Are there default settings for jconn2 that are not set for jTDS? Thanks. The answer is jConnect loosely interprets the ordering of braces and parentheses. So {call MyStoredProc(???}) is fine for jConnect. jTds has strict parsing so the mis-matched brace and parenthesis is incorrect. Not fun."
917,A,"How to check the Database Connection leakage in Java EE application? Is there any way to check the connection leakage in a Java EE application? The application is running on my local machine. It uses a MySQL database and a user enters his details into this database. In my opinion connection leakage means not closing the connection object properly. I am creating too many database connections in my application. I want to check if there is any connection leakage in the database connections. Use a connection factory for example: import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; public class ConnectionFactory { private static Connection connection; public static synchronized Connection getConnection() throws SQLException { if (connection == null || connection.isClosed()) { connection = DriverManager.getConnection(""url""); } return connection; } } This way you never leave unattended connections behind. Use a connection pool if you need more than one connection (for performance). Most appservers have a JDBC connection pool facility.  If you're using a Java EE app server you should be able to configure it to check connections when they go out and reclaim stale connections when they don't come back. Connection leakage is indeed a problem. I'd be worried if you had connection management scattered in so many places in the code that it was a big problem to find them all. I'd expect to see a Java EE connection pool that was used only within a well-defined persistence layer. Connections should be opened by a service layer that manages the transaction for that unit of work and closes it as soon as the use case is over within method scope in a finally block. If that's not true I think it's time to refactor.  log4jdbc a Java JDBC driver that can log SQL and/or JDBC calls for other JDBC drivers has a logger which logs connection open and close events as well as dumping all open connection numbers. This is very useful for hunting down connection leak problems. Another tool that you might want to check is ConnLeakFinder a simple tool to pinpoint jdbc connection leaks in java code. I don't have any experience with it though. How does this compare to p6spy? @Thorbjørn I consider it as a moderner alternative (the latest release of P6Spy was 7+ years ago): it uses SLF4J it offers some features and configuration options that I like it supports JDBC 4... I'm using it as replacement now. ConnLeakFinder worked very well for me. Thanks for the link. ... and ConnLeakFinder has not been updated since 2009 :) Wonder why that happens to these tools.  try using FindBug. It is a static code analysis tool and available as eclipse plugin as well as standalone application. Apart from Connection leackage it will find other problems in your application also"
918,A,"ClassNotFoundException when connecting to Mysql with JDBC I'm getting the following error when I try to run a simple Java JDBC program at the command line: Exception in thread ""main"" java.lang.NoClassDefFoundError: LoadDriver/java Caused by: java.lang.ClassNotFoundException: LoadDriver.java at java.net.URLClassLoader$1.run(URLClassLoader.java:200) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:188) at java.lang.ClassLoader.loadClass(ClassLoader.java:315) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:330) at java.lang.ClassLoader.loadClass(ClassLoader.java:250) at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:398) Here's the simple Java program copied right out of the JDBC docs: import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; // Notice do not import com.mysql.jdbc.* // or you will have problems! public class LoadDriver { public static void main(String[] args) { try { // The newInstance() call is a work around for some // broken Java implementations Class.forName(""com.mysql.jdbc.Driver"").newInstance(); } catch (Exception ex) { throw ex; // handle the error } } } Problem is I'm bloody sure my bash shell $ClASSPATH variable is pointed at the correct .jar file. To be sure I copied the JDBC .jar to the same directory as my program and ran it as follows: java -classpath ./mysql-connector-java-5.1.12-bin.jar LoadDriver.java I still get the same error. Edit: I followed Powerlord's suggestion below and now I am still getting virtually the same exception. I entered: javac -classpath ./mysql-connector-java-5.1.12-bin.jar LoadDriver.java java LoadDriver Whether or not I leave the classpath flag on the second command seems not to matter. I am still getting: Exception in thread ""main"" java.lang.NoClassDefFoundError: LoadDriver Caused by: java.lang.ClassNotFoundException: LoadDriver at java.net.URLClassLoader$1.run(URLClassLoader.java:200) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:188) at java.lang.ClassLoader.loadClass(ClassLoader.java:315) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:330) at java.lang.ClassLoader.loadClass(ClassLoader.java:250) at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:398) CLASSPATH error? Really? :( The problem is not the missing driver it's the missing LoadDriver class. You need to compile the .java source file to a .class file first: javac LoadDriver.java  Short version: javac requires you to put the .java at the end java requires you to not put the .java at the end. As Jim Garrison noted before he deleted his answer this command-line to run the program is wrong. java -classpath ./mysql-connector-java-5.1.12-bin.jar LoadDriver.java This tells Java to load LoadDriver/java.class What you actually want is java -classpath ./mysql-connector-java-5.1.12-bin.jar LoadDriver Provided of course that you compile it first with javac -classpath ./mysql-connector-java-5.1.12-bin.jar LoadDriver.java  I think your syntax is just wrong here. Have you already compiled LoadDriver.java using: javac -classpath ./mysql-connector-java-5.1.12-bin.jar LoadDriver.java ? If so then you should be able to do : java -classpath ./mysql-connector-java-5.1.12-bin.jar LoadDriver (Note that I removed the '.java' from the end) This was almost right. I also had to add ./ to my classpath. So the final command line was java -classpath ./:./mysql-.jar LoadDriver Actually you don't need mysql-connector-java-5.1.12-bin.jar in your classpath when compiling because the driver is only needed at runtime (it is loaded by reflection)."
919,A,Does the compiled prepared statement in the database driver still require compilation in the database? In the Oracle JDBC driver there is an option to cache prepared statements. My understanding of this is that the prepared statements are precompiled by the driver then cached which improves performance for cached prepared statements. My question is does this mean that the database never has to compile those prepared statements? Does the JDBC driver send some precompiled representation or is there still some kind of parsing/compilation that happens in the database itself? I think that this answers your question: (sorry it is powerpoint but it defines how the prepared statement is sent to Oracle how Oracle stores it in the Shared SQL pool processes it etc). The main performance gain you are getting from Prepared statements is that on the 1+nth run you are avoiding hard parses of the sql statement. http://www.google.com/url?sa=t&source=web&cd=2&ved=0CBoQFjAB&url=http%3A%2F%2Fchrisgatesconsulting.com%2FpreparedStatements.ppt&rct=j&q=java%20oracle%20sql%20prepared%20statements&ei=z0iaTJ3tJs2InQeClPwf&usg=AFQjCNG9Icy6hmlFUWHj2ruUsux7mM4Nag&cad=rja Oracle (or db of choice) will store the prepared statement java just send's it the same statement that the db will choose from (this is limited resources however after x time of no query the shared sql will be purged esp. of non-common queries) and then a re-parse will be required -- whether or not it is cached in your java application. Thanks but this isn't quite what I'm after. I understand how Oracle stores the prepared statement in the shared pool and such but I'm trying to understand what it is that is cached in the Oracle JDBC prepared statement cache. The PPT (excellent BTW) touches on the topic but doesn't go into detail.  When you use the implicit statement cache (or the Oracle Extension for the explicit Statement Cache) the Oracle Driver will cache a prepared- or callable statement after(!) the close() for re-use with the physical connection. So what happens is: if a prepared Statement is used and the physical connection has never seen it it sends the SQL to the DB. Depending if the DB has seen the statement before or not it will do a hard parse or a soft parse. So typically if you have a 10 connection pool you will see 10 parses one of it beein a hard parse. After the statement is closed on a connection the Oracle driver will put the handle to the parsed statement (shared cursor) into a LRU cache. The next time you use prepareStatement on that connection it finds this cached handle to use and does not need to send the SQL at all. This results in a execution with NO PARSE. If you have more (different) prepared statements used on a physical connection than the cache is in size the longest unused open shared cursor is closed. Which results in another soft parse the next time the statement is used again - because SQL needs to be sent to the server again. This is basically the same function as some data sources for middleware have implemented more generically (for example prepared-statement-cache in JBoss). Use only one of both to avoid double caching. You can find the details here: http://docs.oracle.com/cd/E11882_01/java.112/e16548/stmtcach.htm#g1079466 Also check out the Oracle Unified Connection Pool (UCP) which supports this and interacts with FAN. great answer thanks.
920,A,"How to ""name"" a query in postgres In postgresql a query in the querylog gets something like this: 2009-02-05 00:12:27 CET LOG: duration: 3781.634 ms execute <unnamed>: SELECT QUERY .... Is there a possibility to put something more usable into the ""< unnamed >"" placed like the url the query was requested from? Are there any other possibilities to track the origin of a query in postgresql using jdbc from java? Thanks Short answer is ""no"" The name can be set when preparing the statement using the PREPARE command but that requires rewriting all your SQL. There is no option to simply add a name parameter to your JDBC methods. The JDBC driver makes use of both named and unnamed prepared statements. It will give them a name when it wishes to reuse them which it will deem appropriate if the same PreparedStatement object is executed 5 times (though that is configurable through setting the prepareThreshold). Documentation is here More info can also be found by searching the PostgreSQL JDBC mailling list"
921,A,"JDBC not seeing updated table structure I am using Coldfusion 8 which is connecting to SQL Server 2008 the problem is I have updated a table adding a new column in SSMS but the JDBC connection is still 'seeing' the table prior to the change. How can I essentially 'refresh' the JDBC connection? Would restarting the cf server work? Same questions as on ServerFault: How are you accessing the table? SP inline query view etc.? And are you doing any query caching? Restart ColdFusion. If you add columns to the end of the table then you won't see this problem. If you add columns or rearrange other columns then you may need to restart CF to see the change. Is there a way to refresh the connection so it 'sees' the updated changes without having to restart? We had a third party company develop our website and they say they've written code that refreshes it every so often so according to them it's possible but they're being difficult to reach right now and we need to reflect these updates.  If you disable ""Maintain Connections"" on the DSN in the CF Admin you should have better luck. That's what I'd do."
922,A,"How do I map a hibernate Timestamp to a MySQL BIGINT? I am using Hibernate 3.x MySQL 4.1.20 with Java 1.6. I am mapping a Hibernate Timestamp to a MySQL TIMESTAMP. So far so good. The problem is that MySQL stores the TIMESTAMP in seconds and discards the milliseconds and I now need millisecond precision. I figure I can use a BIGINT instead of TIMESTAMP in my table and convert the types in my Java code. I'm trying to figure out if there is a better way of doing this using hibernate mysql JDBC or some combination so I can still use date functions in my HSQL and/or SQL queries? Also look at creating a custom Hibernate Type implementation. Something along the lines of (psuedocode as I don't have a handy environment to make it bulletproof): public class CalendarBigIntType extends org.hibernate.type.CalendarType { public Object get(ResultSet rs String name) { return cal = new GregorianCalendar(rs.getLong(name)); } public void set(PreparedStatement stmt Object value int index) { stmt.setParameter(index ((Calendar) value).getTime()); } } Then you'll need to map your new object using a hibernate TypeDef and Type mappings. If you are using Hibernate annotations it be along the lines of: @TypeDef (name=""bigIntCalendar"" typeClass=CalendarBigIntType.class) @Entity public class MyEntity { @Type(type=""bigIntCalendar"") private Calendar myDate; } I like this answer is there any advantage to extending CalendarType verses TimestampType? No not really. In fact you don't really *have* to extend any type just more work implementing all the methods. I'd pick the one closest to what you are trying to map.  I altered my datatyp from timestamp to decimal(173) and wrote some helper methods public static Calendar bigDec2Cal(BigDecimal tsp) { Calendar cal = Calendar.getInstance(); cal.setTimeInMillis(tsp.longValue()); return cal; } public static Date bigDec2Date(BigDecimal tsp) { Calendar cal = Calendar.getInstance(); cal.setTimeInMillis(tsp.longValue()); return cal.getTime(); } public static BigDecimal cal2BigDec(Calendar cal) { BigDecimal tsp = new BigDecimal(cal.getTimeInMillis()); return tsp; } public static BigDecimal date2BigDec(Date date) { Calendar cal = Calendar.getInstance(); cal.setTime(date); BigDecimal tsp = new BigDecimal(cal.getTimeInMillis()); return tsp; }  Why not use it in addition to the TIMESTAMP field? You would have one field (which is already defined) for storing the date without the milliseconds and another field for the milliseconds. You can still run your HSQL queries on the first field except you will have to ensure that you take care of storing the millisecond properly (via parsing of your Java Date object before you store it using Hibernate). This is an interesting approach and I think it would work. I'd still like to find out if there's an alternate approach.  For those who are still interested in this issue: MySQL 5.6.4 supports timestamps with precision. Subclassing MySQL5Dialect to override the used MySQL type solves the problem."
923,A,"can Use Hibernate and Tomcat Connection pool at same time? I have a java web Application and I use Tomcat connection pooling for it this my setting: <?xml version=""1.0"" encoding=""UTF-8""?> <Context path="""" docBase="""" debug=""5"" reloadable=""true"" crossContext=""true""> <Resource name=""jdbc/jdbcPool"" auth=""Container"" type=""javax.sql.DataSource"" maxActive=""100"" maxIdle=""30"" maxWait=""10000"" username=""root"" password=""*******"" driverClassName=""com.mysql.jdbc.Driver"" url=""jdbc:mysql://localhost:3306/dbname?autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=UTF-8""/> </Context> and my DAO:  public static Connection dbConnection() throws NamingException { Context initContext; DataSource ds = null; Connection conn = null; try { initContext = new InitialContext(); Context envContext = (Context) initContext.lookup(""java:/comp/env""); ds = (DataSource) envContext.lookup(""jdbc/jdbcPool""); conn = ds.getConnection(); }catch (SQLException ex){ logger.error(""SQLException Occurred in DAO.dbConnection() Method Exception Message is: "" + ex.getMessage() ex); } catch (RuntimeException er){ logger.fatal(""SQLException Occurred in DAO.dbConnection() Method Exception Message is: "" + er.getMessage() er); }catch(Exception rt){ logger.fatal(""Exception Occurred in DAO.dbConnection() Method Exception Message is: "" + er.getMessage() er); } return conn; } after that I want to use hibernate And I Refactor some part of my code but I want know can i use both of them in my application (I mean some part of my code use hibernate and some part use my DAO connection?) if yes what happen to that table not map in hibernate but some mapped table have relation to them? I don't know can explain my question right? if want more detail tell me. I suppose you can use them together but why would you? You can configure Hibernate to use your data source instead like described in the manual. It would be something like: hibernate.connection.datasource = java:/comp/env/jdbc/jdbcPool hibernate.dialect = org.hibernate.dialect.MySQLDialect As far as mappings go ""mapped"" tables can have relations to ""unmapped"" tables (in the database) but those relations will also be ""unmapped"" (e.g. Hibernate won't be aware of them). So if you go that way you have to make sure you won't cause any referential integrity issues while trying to say insert / update ""mapped"" entity. Tanx for you answer i must do some test on it to understand what exactly happen. This approach is described in more detail in [this blog](http://workblognotes.blogspot.ca/2010/08/hibernate-and-tomcat-database.html).  My personal preference with hibernate is is not to configure it with a connection pool at all. This can be done by simply omitting the connection pool settings in our hibernate configuration and using the openSession(Connection) method: Connection conn = ... // get from jndi Session session = sessionFactory.openSession(connection); try{ //do some work with either hte connection or the session or both }finally{ session.close(); conn.close(); } This has the advantage that you are in control of which connection is being used and where it is allocated and most importantly where it is closed this may be important if you are performing a transaction using hibernate and jdbc code. EDIT: on @ChssPly76 point about excluding hibernates inbuilt transaction management and he is quite right hibernate provides reasonable transaction support and if a given a JTA will synchronise with any on going transaction. In a none JTA app where you require both hibernate and jdbc code to operate in the same jdbc transaction it is important to make sure that the hibernate Session is using the same Connection as the jdbc code the best way to do this is to give the Connection to the session factory. Note this doesn't exclude using a Hibernate transaction object: Connection conn = ... // get from jndi Session session = sessionFactory.openSession(connection); try{ Transaction tx = new Transaction(); // //do some work with either hte connection or the session or both tx.commit(); }finally{ session.close(); conn.close(); } it'll work just fine. you mean I omit my JNDI configuration in context.xml and when I want Quering DB (don't want use hibernate )get a connection from hibernate sessionFactory? then act like a common JDBC connection? @gid Can you elaborate why? Hibernate provides its own transation management (or you'll be using JTA) so why would you care when connection is closed - or rather returned to the pool? Seems like you're just manually doing a lot of what Hibernate would do for you. Am I missing something? I mean omit the connection settings (ie the JNDI reference and or any other references to connections from the hibernate configuration)"
924,A,Using UTL_FILE to pull data from an Oracle server to a local file system using JDBC? I need to consume a file that is being generated on an Oracle server and I have been told to get it using the UTL_FILE package. I intend on consuming the file in a groovy script and have a connection to the database. It is a simple text file and I'd like to pull it down to the server and consume it as I would any other text file but I suppose I am willing to read the data from some cursor if that is what needs to happen. I am unfamiliar with PL/SQL and UTL_FILE. Does anyone know of a good way to do this? Good resource. So it is looking like I'm going to have to wrap each of the individual PL/SQL commands for opening the file and reading it line by line closing and all of the exception handling code in CallableStatements...sound about right? This will get you started with UTL_FILE: http://www.devshed.com/c/a/Oracle/Reading-Text-Files-using-Oracle-PLSQL-and-UTLFILE/ Firstly I would recommend trying the External Tables approach that Gary recommends - there is a good chance that this will meet your requirement and will let you treat the data in the file as rows from a table in your calling code. My next suggestion would be writing a function that encapsulates the UTL_FILE access and returns the lines using PIPE ROW (that way you do not need to read the whole file into memory before the code starts returning rows to the client). This function could either return a REF CURSOR (which JDBC can certainly handle) - basically a handle to the result set - or alternatively you could return a collection of object types.  CREATE OR REPLACE myType AS OBJECT (user defined structure or something as simple as textline VARCHAR2(2000)); CREATE OR REPLACE myTypeArray AS TABLE OF myType; CREATE OR REPLACE FUNCTION myFunction(pFile IN VARCHAR2) RETURN myTypeArray PIPELINED AS lvRow myType; BEGIN UTL File code to open file and iterate over contents populating lvRow PIPE ROW(lvRow); end loop close file etc END myFunction; Then access this by casting the results of the function in a select  SELECT * FROM TABLE(myFunction(:filename)) If you don't have any parameters to the function or can derive them from a table you could even wrap this in a view. The REF CURSOR approach pretty much wraps this SQL up in a function FUNCTION myFunction(pFilename) RETURN sys_refcursor IS lCursor sys_refcursor; BEGIN OPEN lCursor FOR SELECT textline FROM TABLE(CAST(myFileExtractFunction(pFilename) AS myTypeArray); RETURN lCursor; END myFunction; But as all of this is essentially re-inventing external tables double-check that they do not meet your requirement.  Depends on the size of the file. If it is relatively small then a stored procedure can read it all into one large field (VARCHAR2 CLOB or BLOB) and return that as a value. Could also be worth looking into external tables where you can select from the file just as if it was a plain database table.
925,A,Question on Prepared Statement in Java We have a Prepared Statement in Java and we hear that it is different from Statement in the Way that this prepared statement need not be compiled every time it is used. My question is where is this Compiled Statement stored ? In the Client code that uses it or is it stored by the Database ? Why would a DB Store a Compiled statement and if it does than for how long ? Databases have a query cache which means that when you execute a query the database caches the parsed/compiled query and maybe the query plan to eliminate future computations. The prepared statements are typically cached first at the application level where the application container is responsible for managing the statements cache. Most application containers have options to control the prepared statements cache (eg: glassfish). As you can see here the main difference is like you stated: with prepared statements the application reduce the cost of compiling the same statement over and over. As a side note for most app containers the statement must be exactly the same (whitespace included) in order to be reused correctly so be careful when using hand-written queries. Mig That means the JDBC Driver has the capability to convert a Prepared Statement to a Compiled Statement ? Which means the Driver is smart enough to parse a query and identify Syntactical mistakes ? AFAIK the driver doesn't parse queries only the DB does that. Every syntatic error is thrown by the DB parser. But the app server is smart enough to reuse same statements where only the args (placeholders '?') differ.
926,A,"JDBC SQL Server Database Migrations I'm working on a Java web application (Adobe Flex front-end JPA/Hibernate/BlazeDS/Spring MVC backend) and will soon reach the point where I can no longer wipe the database and regenerate it. What's the best approach for handling changes to the DB schema? The production and test databases are SQL Server 2005 dev's use MySQL and unit tests run against an HSQLDB in-memory database. I'm fine with having dev machines continue to wipe and reload the DB from sample data using Hibernate to regenerate the tables. However for a production deploy the DBA would like to have a DDL script that he can manually execute. So my ideal solution would be one where I can write Rails-style migrations execute them against the test servers and after verifying that they work be able to write out SQL Server DDL that the DBA can execute on the production servers (and which has already been validated to work agains the test servers). What's a good tool for this? Should I be writing the DDL manually (and just let dev machines use Hibernate to regenerate the DB)? Can I use a tool like migrate4j (which seems to have limited support for SQL Server if at all)? I'm also looking to integrate DB manipulation scripts into this process (for example converting a ""Name"" field into a ""First Name"" ""Last Name"" field via a JDBC script that splits all the existing strings). Any suggestions would be much appreciated! I depend on hibernate to create whatever it needs on the production server. There's no risk of losing data because it never removes anything: it only adds what is missing. On the current project we have established a convention by which any feature which requires a change in the database (schema or data) is required to provide it's own DDL/DML snippets meaning that all we need to do is to aggregate the snippets into a single script and execute it to get production up to date. None of this works on a very large scale (order of snippets becomes critical not everyone follows the convention etc.) but in a small team and an iterative process it works just fine.  What's the best approach for handling changes to the DB schema? Idempotent change scripts with a version table (and a tool to apply all the change scripts with a number greater than the version currently stored in the version table). Also check the mentioned post Bulletproof Sql Change Scripts Using INFORMATION_SCHEMA Views. To implement this you could roll out your own solutions or use existing tools like DbUpdater (mentioned in the comments of change scripts) LiquiBase or dbdeploy. The later has my preference. This is perfect. LiquiBase is the exact tool I was looking for. Thanks!"
927,A,"How can I get the name of all tables in a JavaDB database? How can i programmatically get the names of all tables in a JavaDB database? Is there any specific SQL-statement over JDBC I can use for this or any built in function in JDBC? I will use it for exporting the tables to XML and would like to do it this way so I don't miss any tables from the database when exporting. See http://stackoverflow.com/questions/2780284/how-to-get-all-table-names-from-a-database With an open Connection con do DatabaseMetaData meta = con.getMetaData(); ResultSet res = meta.getTables(null null null new String[] {""TABLE""}); System.out.println(""List of tables: ""); while (res.next()) { System.out.println( "" ""+res.getString(""TABLE_CAT"") + "" ""+res.getString(""TABLE_SCHEM"") + "" ""+res.getString(""TABLE_NAME"") + "" ""+res.getString(""TABLE_TYPE"") + "" ""+res.getString(""REMARKS"")); } res.close(); EDIT: You question is about tables see http://java.sun.com/j2se/1.5.0/docs/api/java/sql/DatabaseMetaData.html#getTables(java.lang.String java.lang.String java.lang.String java.lang.String[])"
928,A,"JDBC Connection closed by peer (weird) I'm facing sort of a strange issue with two applications of mine. Here's the setting: Two tomcat / java apps running in the same network connecting to the same MS-SQL-Server. The one app which happens to be in an DMZ in order to be accessible from the internet uses to produce ""jdbc Connection closed by peer"" exceptions in unregular intervals. Restarting the app in tomcat fixes the problem. The strange things are that the other app does not have that habit and that all the relevant logs (i.e. Windows Event Log SQL-Serverlog Network Monitoring) do not show any problems. Only my app's log's got that connection closed by peer stuff... I also checked the network settings the connection has'nt been disrupted in a month. As a last resort I'll restart the whole server tonight and install wireshark on it in order to log the net work traffic... Does anyone's got another clue what might cause this? Thx in advance  K Most firewalls (that form the dmz) drop connections that are not active. This issue is very common. You will have to set your connection pool (min size) to 0 or 1 depending on your appserver. (From memory) WebSphere recommends you set this to 1.  What's between your problematic app and the database ? Since it's in a DMZ I suspect you've got a router. If the application keeps a connection open to the database but that connection is quiet for a period (say overnight?) then in the absence of traffic the router may close that connection. I've seen behaviour like this before. I vaguely remember such a scenario detailed in Release It. Are you using database pooling with checks on the connections as they're handed out from the pool ? If the above is the problem you may want to look at Apache DBCP"
929,A,"Dealing with intermittent Database Connectivity by Writing/Executing SQL Script From Scala/Java I am developing an application that needs to store information to a database. I would like to use a Scala solution if possible. If the database connectivity fails for some reason I would like to write the raw SQL statements that would have been executed to a .sql script file. The idea is that when/if the connectivity to the database is restored I would like to execute that script in Scala/Java to bring the database back into sync. It is also nice to have the .sql script around in case there is a failure in the program so that a manual execution of the script could occur. How do I record the sql statements that I am going to execute to a file in Scala/Java? Then how do I execute a that file (or really any .sql script) in Scala/Java? You might consider changing the title to be more descriptive -- something like ""dealing with intermittent database connectivity in Java'. I added what you suggested to the title thanks for the suggestion! You might be interested in this [stack-exchange proposal](http://area51.stackexchange.com/proposals/11464/code-review?referrer=aWNm_PdciyFqjFW8CUacGw2 ""code review""). It's almost ready to begin beta just needs a few more. you can proxy your Connection object: public class ConnectionProxy { public ConnectionProxy(Object anObject) { super(anObject); } @Override public Object invoke(Object proxy Method method Object[] args) throws Throwable { Object result = method.invoke(target args); String methodName = method.getName(); if (methodName.equals(""createStatement"")) { result = ProxyBuilder.createProxy(result new StatementProxy(result)); } return result; } } in order to intercept any call to Statement.execute(String sql): public class StatementProxy { public StatementProxy(Object anObject) { super(anObject); } @Override public Object invoke(Object proxy Method method Object[] args) throws Throwable { try { return method.invoke(proxy args); } catch (SQLException sqle) { if (method.getName().contains(""execute"")) { String sql = """"; if (args != null && args[0] != null) { sql = args[0].toString(); } saveToFile(arg); } throw sqle; } } } where ProxyBuilder is a simple helper class: public final class ProxyBuilder { public static Connection tracingConnection(Connection connection) { return createProxy(connection new ConnectionProxy(connection)); } static <T> T createProxy(T anObject InvocationHandler invocationHandler) { return createProxy(anObject invocationHandler anObject.getClass().getInterfaces()); } static <T> T createProxy(T anObject InvocationHandler invocationHandler Class... forcedInterfaces) { return (T) Proxy.newProxyInstance( anObject.getClass().getClassLoader() forcedInterfaces invocationHandler); } } Of course this is not your final production code but it is a good starting point."
930,A,About the JDBC RowSet i know about what a RowSet is and all; what i would like to know is if it works properly and is accepted already or if it still has it's bugs and isn't as widely accepted as the classic ResultSet. it looks good to me so far but i want to hear more experienced views on the subject. A RowSet is a disconnected serializable version of a JDBC ResultSet. @adatapost RowSets are connected CachedRowSets WebRowSets etc are disconnected. RowSet RowSet makes life a lot easier for all JDBC programmers. No more Connection objects statement objects just a single RowSet will do everything for you. Rowsets make it easy to send tabular data over a network. They can also be used to provide scrollable result sets or updatable result sets when the underlying JDBC driver does not support them. RowSet object follows the JavaBeans model for properties and event notification it is a JavaBeans component that can be combined with other components in an application. Rowsets may have many different implementations to fill different needs. These implementations fall into two broad categories rowsets that are connected and those that are disconnected. RowSet Tutorial haha so sorry i don't mean to be rude and i appreciate your answer but i think you didn't read my question. i was asking whether it was widely accepted or it still had criticisms and people still preferred the ResultSet. sorry for the misunderstanding Yes RowSet is far better than ResultSet. Ofcourse it is correct but there are some situations where we need to use ResultSet only. can you elaborate further when it's more desirable to use a ResultSet? i can't see what ResultSet can do that RowSet can't  I think there are two factors in deciding if you RowSet is right for you: 1) Can you have the whole result in memory? Sometimes you need to parse the result set one row at a time and can't just get the whole thing in memory at once. 2) Have you tested your JDBC driver for the behavior with RowSet? I think #2 is where you start with your question. The truth is that it is basically implementation dependent if a given RowSet is robust and production ready. In theory you can use a RowSet implementation from a different vendor than the JDBC driver as well and that should work as well. well i'm using MySQL so i hope i'm right in assuming that the driver should work properly as both products are from sun... +1 for testing the JDBC driver support. 5 years ago when I was learning Java (coming from .net) I was puzzled about the number of bugs in RowSet. Turned out to be the JDBC driver's fault.
931,A,"JDBC MySQL: getting back row data from PreparedStatement executes I'm using the following setup: public MySQLProcessWriter(Connection con) throws SQLException { String returnNames[] = {""processId""""length""""vertices""}; addresser = con.prepareStatement(""INSERT INTO addressbook (length vertices activity) VALUES (? ? ?)"" returnNames); } processId corresponds to an auto-incrementing column in the addressbook table. So the idea is: I have a repeated insert I get back some of what was inserted + the auto-generated processId. However I'm getting a ""column not found"" SQLException when I attempt to addresser.getGeneratedKeys().getInt(""processId""); after executing the prepared statement (after the appropriate setting of values). The code for that is addresser.setInt(1 length); addresser.setInt(2 vertices); addresser.setDouble(3 activity); addresser.executeUpdate(); int processId = addresser.getGeneratedKeys().getInt(""processId""); inside a loop that is updating length vertices activity. So...what gives? Am I misunderstanding what the prepareStatement(sqlstring string[]) method does? You have to call next() method on ResultSet returned from getGeneratedKeys() prior to calling getInt() ResultSet rs = addresser.getGeneratedKeys(); int processId = 0; if (rs.next()) { processId = rs.getInt(""processId""); }  I think you need to call next() on the returned result set ResultSet keys = addresser.getGeneratedKeys(); int processId = -1; if (keys.next()) { processId = keys.getInt(""processId""); } well.. I guess I wasn't first... looks like we are both probably correct then."
932,A,"ResultSet using query arguments like in jdbcTemplate Haven't found in docs. Does java ResultSet supports query argumentslike jdbcTemplate? For example something like: int length = 10; ResultSet rs = stmt.executeQuery(""select MyTable.COLOR from MyTable where MyTable.LENGTH = ?"" new Object[] { length }); is it possible? Thank you. ResultSet isn't supposed to query database so why would it need query arguments? i just found method of jdbcTemplate queryForRowSet. Seems that what i need? because returned values of my sql is more than one rows. You use `Statement` to fire a SQL query not `ResultSet`. The `Statement` has a subclass which does exactly this the `PreparedStatement`. See Bozho's answer for detail. PreparedStatement allows (numbered) parameters: PreparedStatement pstmt = connection.prepareStatement( ""select MyTable.COLOR from MyTable where MyTable.LENGTH=?""); pstmt.setInt(1 desiredLength); ResultSet rs = pstmt.executeQuery(); Here's a tutorial: http://download.oracle.com/javase/tutorial/jdbc/basics/prepared.html HiBozho. I'm interested in returned value - that will be multiple rows from DB table selected by one ID param. Just iterate through the `ResultSet` the usual way using `ResultSet#next()` in a `while` loop. That's also covered in one of the chapters of the aforementioned tutorial. And this is the goal of my question- how to get ResultSet with argument ID in query. as i understand this way isn't possible: ResultSet rs = stmt.executeQuery(""select MyTable.COLOR from MyTable where MyTable.id = ?"" new Object[] { id }); Did you read Bozho's answer and the tutorial link? yes now is clear thank you BalusC"
933,A,"Why does Char(1) change to Char(3) when copying over an Oracle DBLINK? I have 2 databases and I want to transport an existing table containing a CHAR column from database A to database B. Database A is Oracle 9i has encoding WE8ISO8859P1 and contains a table ""foo"" with at least 1 column of type CHAR(1 char). I can not change the table on database A because it is part of a third party setup. Database B is my own Oracle 10g database using encoding AL32UTF8 for all kinds of reasons and I want to copy foo into this database. I setup a database link from database B to database A. Then I issue the following command: *create table bar as select * from #link#.foo;* The data gets copied over nicely but when I check the types of the columns I notice that CHAR(1 char) has been converted into CHAR(3 char) and when querying the data in database B it is all padded with spaces. I think somewhere underwater Oracle confuses it's own bytes and chars. CHAR(1 byte) is different from CHAR(1 char) etc. I've read about all that. Why does the datatype change into a padded CHAR(3 char) and how do I stop Oracle from doing this? Edit: It seems to have to do with transfering CHAR's between two specific patchlevels of Oracle 9 and 10. It looks like it is really a bug. as soon as I find out I'll post an update. Meanwhile: don't try to move CHAR's between databases like I described. VARCHAR2 works fine (tested). Edit 2: I found the answer and posted it here: http://stackoverflow.com/questions/253971/why-does-char1-change-to-char3-when-copying-over-an-oracle-dblink#263467 Too bad I can not accept my own answer because my problem is solved. The first thing I would try is Creating the table NOT as a CTAS but with a list of column definitions and try to perform an insert of the first few thousand rows. If that didn't succeed then it would be very clear why... and you'd have quick confirmation that Thomas Low is dead on accurate.  YOu need to learn the difference between the WE8ISO8859P1 NLS (which stores characters in one byte) and the AL32UTF8 which stores characters in up to four bytes. You will need to spend some quality time with the Oracle National Language Support (NLS) Documentation. Oracle automatically does the conversion through the database link in an attempt to be helpful. Try the following from your SQL prompt: ALTER SESSION NLS_NCHAR WE8ISO8859P1 create table bar as select * from #link#.foo; Yeh NLS is a pain. I bet you've had your share of quiet evenings with the docs. ;-) I would understand if the original type was ""1 char"" and it got changed to ""3 byte"" or ""4 bytes"". By why would ""1 char"" be changed to ""3 char""? I've been reading about this for 32 hours now. So I agree with Dave ""1 char"" -> ""3 bytes"" I understand. But ""1 char"" -> ""3 chars"" and adding padding is plain wrong. If I set the NLS_NCHAR I would set it to the NLS of the LOCAL database. Instead you chose to set the remote NLS. Why? Funny addition: Setting the NLS_CHAR in the session is for some reason impossible through jdbc. I tried the NLS_CHAR in SquirrelSQL to no avail. I think online Oracle documentation one big cross-reference maze which does not contain clear and helpful text.  This problem is caused by the way Oracle (mis)handles character conversions between different character sets based on the original column length definition. When you define the size of a character type column in bytes Oracle does not know how to do a conversion and bodges it. The solution is to always define the length of a character type in characters. For a more in-depth explanation of the problem and how I figured this out have a look at http://www.rolfje.com/2008/11/04/transporting-oracle-chars-over-a-dblink/"
934,A,is it possible to get the query plan out using jdbc on sql server? I am using the JTDS driver and I'd like to make sure my java client is receiving the same query plan as when I execute the SQL in Mgmt studio is there a way to get the query plan (ideally in xml format)? basically I'd like the same format output as set showplan_xml on in management studio. Any ideas? Cheers -James Some code for getting the plan for a session_id SELECT usecounts cacheobjtype objtype [text] query_plan FROM sys.dm_exec_requests req sys.dm_exec_cached_plans P CROSS APPLY sys.dm_exec_sql_text(plan_handle) CROSS APPLY sys.dm_exec_query_plan(plan_handle) WHERE cacheobjtype = 'Compiled Plan' AND [text] NOT LIKE '%sys.dm_%' --and text like '%sp%reassign%' and p.plan_handle = req.plan_handle and req.session_id = 70 /** <-- your sesssion_id here **/ Identify your Java session id. Print @@SPID from java or use SSMS and look into sys.dm_exec_sessions and/or sys.dm_exec_connections for your Java client session (it can be identified by program_name host_process_id client_net_address etc). Execute your statement. Look in sys.dm_exec_requests for the session_id found at 1. Extract the plan using sys.dm_exec_query_plan from the plan_handle found at 2. Save the plan as a .sqlplan file and open it in SSMS Alternatively you can use the Profiler attach the profiler to server and capture the Showplan XML event. Thanks Remus I (via Google of course!) have knocked together some SQL for doing this taking in a session_id as a parameter see the edit above...
935,A,"Logging JDBC/Hibernate/JPA transaction isolation levels I'm working on a Flex/BlazeDS/Spring/JPA/Hibernate web application hooked up to a Microsoft SQL Server database. It seems to be locking the tables too aggresively. From my research it looks like using the snapshot isolation policy is the best bet. I've set things up as such:  <bean id=""entityManagerFactory"" class=""org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean"" lazy-init=""true""> <property name=""persistenceUnitName"" value=""OrderManagerPersistenceUnit"" /> <property name=""dataSource"" ref=""dataSource""/> <property name=""jpaVendorAdapter""> <bean class=""org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter"" /> </property> <property name=""jpaProperties""> <props> <prop key=""hibernate.jdbc.batch_size"">${db.main.hibernate.jdbc.batch_size}</prop> <prop key=""hibernate.hbm2ddl.auto"">${db.main.hbm2ddl.auto}</prop> <prop key=""hibernate.search.default.indexBase"">${db.main.search.default.indexBase}</prop> <prop key=""hibernate.search.autoregister_listeners"">${db.main.search.autoregister_listeners}</prop> <prop key=""hibernate.show_sql"">${db.main.show_sql}</prop> <prop key=""hibernate.dialect"">${db.main.dialect}</prop> <prop key=""hibernate.connection.isolation"">${db.main.isolation}</prop> <prop key=""hibernate.ejb.naming_strategy"">com.herffjones.zebra.db.ZebraNamingStrategy</prop> </props> </property> </bean> However I'm not convinced that it's actually using hibernate.connection.isolation. It looks like I have to set some properties on the JDBC datasource as well. I'd like to verify whether or not it's currently using 4096 as the transaction isolation level for queries. What packages and log levels can I add to my logback.xml file to clearly see the isolation level that a particular query is using? Thanks! I would like to describe an issue I got on JPA/MySQL; it may inspire your investigations... Global transaction begin transaction 1) a new row on table Address (autoincrement) transaction 2) a new row on table Entreprise with a foreign key on table Addres; the new Entreprise inserted is linked to the new Adress #ID. End of Global transaction MYSQL dead-locks for this case with ResourceLocal / JPATransactionManager. Actually it seems that we cannot open several nested transactions. The global transaction seems to be merged with transactions 1) and 2). Transaction 2) ends in deadlock because data cannot be feeded with table A new #Id that is not ready. However we can see with the debugger the new adresse row#id between transaction 1 and 2. Is it similar to your issue ? Do you guess some autoincrement - relation with your deadlock? These followings are possible solutions... Solution1 Change isolation level ? -> How ?!!I don't have the answer...And I'm not shure this will change anything. Solution2 Replace JPA Entities ID generation strategy (auto or identity) into a custom sequence table. Solution3 Check if you cannot use cascade strategy on ManyToOne relationships. EntrepriseEntity{ @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name = ""id_entreprise"") private int id; @ManyToOne(fetch=FetchType.LAZYcascade=CascadeType.ALL) @JoinColumn(name = ""id_address"") private AddressEntity address; And then save both rows into a single merge() : EntrepriseEntity e=new EntrepriseEntity(); e.setAddress(new AddressEntity()); e=entityManager.merge(e); Returned instance with give you back both new #ids inserted and magic : no longer deadlock... Solution#3 is smarter but needs deeper analysis and change some code...  You should set the transaction isolation level of hibernate as 2 (the java.sql.Connection constant for READ_COMMITTED. Then execute the following in your SQL Server 2005 instance (with no active connections): ALTER DATABASE [database_name] SET ALLOW_SNAPSHOT_ISOLATION ON; ALTER DATABASE [database_name] SET READ_COMMITTED_SNAPSHOT ON; Test by executing this query: SELECT [name] snapshot_isolation_state_desc snapshot_isolation_state is_read_committed_snapshot_on FROM sys.databases WHERE [name] = 'database_name'; Now a READ_COMMITTED will be interpreted as READ_COMMITTED_SNAPSHOT in SQL Server."
936,A,"JDBC use urls to connect When you setup a URL in your jdbc properties like: jdbc:derby://localhost:1527/vehicle;create=true Does this mean all the data is being sent via HTTP on a specific port? (it seems so obviously) The short answer is no. To understand why you need to understand the syntax of a URL. The basic syntax of a URI is <url> ::= <scheme>:<scheme-specific-part> where the is an identifier that says how to interpret the stuff after the colon. Most web URLs use the 'http' scheme; e.g. http://www.example.com/somepage.html though web browsers also understand other schemes such 'ftp' 'mailto' and so on. But as you can see a JDBC URL uses the 'jdbc' scheme; for example jdbc:derby://localhost:1527/vehicle;create=true In some cases (e.g. 'http' and 'ftp') the scheme has a correspond application protocol (e.g. HTTP or FTP respectively) that may be used for accessing content. (This assumes the URL actually resolves to something that is fetchable). In other cases including the 'jdbc' scheme the URL does not denote content and does not necessarily even specify a protocol. In the JDBC case the URL is actually specifying an end point location (and other details) for accessing a database. The stuff after the second colon is JDBC driver / RDBMS specific both in syntax and in what it means. But it is highly unlikely that HTTP is involved or that a web browser would know what to do with a JDBC URL.  Quoting the chapter 6 Database connections of the specification for the JDBC API (this is an old version but I find it more clear than more recent versions about JDBC URLs): 6.3 URLs 6.3.1 Goals for JDBC database naming We need to provide a way of naming databases so that application writers can specify which database they wish to connect to. We would like this JDBC naming mechanism to have the following properties: Different drivers can use different schemes for naming databases. For example a JDBC-ODBC bridge driver may support simple ODBC style data source names whereas a network protocol driver may need to know additional information so it can discover which hostname and port to connect to. If a user downloads an applet that wants to talk to a given database then we would like to be able to open a database connection without requiring the user to do any system administration chores. Thus for example we want to avoid requiring an analogue of the human-administered ODBC data source tables on the client machines. This implies that it should be possible to encode any necessary connection information in the JDBC name. We would like to allow a level of indirection in the JDBC name so that the initial name may be resolved via some network naming system in order to locate the database. This will allow system administrators to avoid specifying particular hosts as part of the JDBC name. However since there are a number of different network name services (such as NIS DCE etc.) we do not wish to mandate that any particular network nameserver is used. 6.3.2 URL syntax Fortunately the World Wide Web has already standardized on a naming system that supports all of these properties. This is the Uniform Resource Locator (URL) mechanism. So we propose to use URLs for JDBC naming and merely recommend some conventions for structuring JDBC URLs. We recommend that JDBC URL's be structured as: jdbc:<subprotocol>:<subname> where a subprotocol names a particular kind of database connectivity mechanism that may be supported by one or more drivers. The contents and syntax of the subname will depend on the subprotocol. If you are specifying a network address as part of your subname we recommend following the standard URL naming convention of ""//hostname:port/subsubname"" for the subname. The subsubname can have arbitrary internal syntax. To summarize: The only thing in common between a JDBC URL and an HTTP URL is that both use the same standardized naming system: the Uniform Resource Locator (URL) mechanism (this is only a recommendation for JDBC1). A JDBC URL is specific to a JDBC driver (different drivers for a same database will use different schemes). Refer to the documentation of the JDBC driver for the details (for example when using Derby Network Server have a look at Derby network client URL Format). And no the protocol used by a JDBC client to talk to a database server is not HTTP (it his a database specific protocol). 1 Actually a JDBC URL may not be a real URI as mentioned in this note of the brand new JSR 221: JDBCTM 4.0 API Specification: Note - A JDBC URL is not required to fully adhere to the URI syntax as defined in RFC 3986 Uniform Resource Identifier (URI): Generic Syntax.  It has nothing to do with HTTP no. The protocol used is specific to the database and JDBC driver as is JDBC URL format. The only thing common to all JDBC URLs is the jdbc: prefix. In this specific case I'd say you have a Apache Derby JDBC URL connecting to a server on localhost port 1527 database (or maybe user) name ""vehicle"" creating it if necessary. Another example would be an Oracle JDBC URL format: jdbc:oracle:<drivertype>:<username/password>@<database> Very different to the Derby one but specifying the same sort of information."
937,A,"executeQuery() not returning Is there any condition under which PreparedStatement.executeQuery() does not return ro throw an exception ? I assume you mean fails to throw an exception when it should? It won't throw an exception if it executed without error. If it hasn't returned then it's still running your query or is still fetching the results. Try running the query outside of java using a database tool of some sort and make sure it's executing in a timely fashion.  It depends on the database you're using and the configured isolation level. A common default is that a SELECT will block if you're trying to select records that have been updated in another transaction that hasn't committed yet. Are you trying to select uncommitted data? What database are you using? Alternatively your query may just be taking a really long time. Eliminate (or confirm) this possibility by running the query through some database tool. You may also want to call setQueryTimeout() so the query won't block ""forever"". http://en.wikipedia.org/wiki/Isolation_(database_systems) OK Is this applicable to update query as well ? Where can I find more details about it. @cletus: what happened if there is no running query and stops on this line ""resultSet = preparedStatement.executeQuery()"" ..?? Also make sure you're not using sqljdbc4.jar with Java 1.6.0_29 as they're incompatible: http://stackoverflow.com/questions/8986350/jdbc-connection-hangs-with-no-response-from-sql-server-2008-r2"
938,A,"get all indexes declared in database from java Is there any standard java api that returns the indexes declared in the database. I tried using the getIndexInfo() in database meta data but that seems to expect a table name as input and does not meet my requirements. Thx. we are cloning tables in our application and as part of that we are cloning the constraints and indexes too - so i'll have to generate unique index names. hashing etc wont work due to restrictions on length of names in some db. Why? If knowing the indexes makes some difference to how your Java application executes there is something seriously wrong. There is no 100% portable ""query"" way of doing this however many DBs do implement the standard INFORMATION_SCHEMA so you can queries like this.  sql = ""select TABLE_NAME INDEX_NAME NON_UNIQUE COLUMN_NAME "" + ""from INFORMATION_SCHEMA.STATISTICS "" + ""where TABLE_SCHEMA = ? "" + ""order by TABLE_NAME INDEX_NAME SEQ_IN_INDEX""; MySQL and SQLServer support this. Oracle does not. See this page EDIT: I originally said ""no 100% portable way"" however you can use the JDBC metadata APIs which will achieve this however as noted in a previous answer this may be inefficient depending on the number of tables.  No you need to fire off some sql which will vary depending on the DBMS you are using. For example DB2 would be:- select * from sysibm.sysindexes where tbcreator = 'IMPACT'; For sqlite it would be:- Select * from sqlite_master where type = 'index'; i was hoping there would be std api to do this. looks like i have to fire a sql to do it :)  Indexes are declared on tables. So you should first retrieve all tables with DatabaseMetaData.getTables() and then loop over the table names to get all indexes. understood the logical concept but it looks like an inefficient way to do it. since i'll be making too many db hits. This is very cheap. Only opening the connection is the most expensive step. You can just do this all in the same transaction. A good alternative is to use a connection pool. How many tables do you have ? Normally this is not a performance problem."
939,A,"mysql/jdbc function in out param So i need to run a jdbc call that is going against a sql server database. CallableStatement cs = conn.prepareCall(""{ ? = call "" + spName + "" ( ? ? ? ? ? ) }""); So the sql server call is a function that has output parameters. we are using mysql database and it looks like mysql functions don't support functions with out put parameters. i tried to see if i could fake out the call using store procs with output parameters but no luck. any ideas? thanks you're right. mysql doesn't support output parameters on functions only stored procedures. you'll have to rewrite the function so it only has one return value or as a procedure where you've moved the return value to an out variable."
940,A,JDBC Thin Oracle 11g I am using oracle 11g. I write code to connect oracle database with java 1.6 but I can't connect to it. When configure the guide line to below: I have ojdbc6.jarorai18n.jar and class12.jar I set: Class_Path: %ORACLE_HOME%\jlib\orai18n.jar;r;%Oracle_home%\jdbc\ojdbc6.jar After that I run sample java code connect to oracle database but I met this error below: C:\Program Files\Java\jdk1.6.0_11\bin>javac c:\JDBCVersion.java c:\JDBCVersion.java:2: package oracle.jdbc does not exist import oracle.jdbc.*; ^ c:\JDBCVersion.java:3: package oracle.jdbc.pool does not exist import oracle.jdbc.pool.OracleDataSource; ^ c:\JDBCVersion.java:8: cannot find symbol symbol : class OracleDataSource location: class JDBCVersion OracleDataSource ods = new OracleDataSource(); ^ c:\JDBCVersion.java:8: cannot find symbol symbol : class OracleDataSource location: class JDBCVersion OracleDataSource ods = new OracleDataSource(); ^ 4 errors Could anyone help me to settle this problem? Thanks Sopolin I wonder if your problem is a mix of JDBC driver JARs. I don't know where you got yours but you should not have both classes12.jar and ojdbc6.jar. The first one is an older version for JDK 1.2; you should remove it. If you're compiling against JDK 6 use ojdbc6.jar. I'd also advise that you use the java.sql interfaces and not Oracle specific classes for your static types to keep your code generic. This is only a sample but you'll want to keep that in mind for your real applications. I understand what you tell me but I want guide me to configure it. Because I don't any experience about this. Thanks  In order to use the Oracle JDBC driver you must have the ojdbc6.jar or an equivalent on the CLASSPATH. There is no requirement for any of these JARs to be in the operating system PATH variable. You can obtain the JDBC drivers for Oracle from the JDBC/UCP page on the Oracle Technology Network. Additionally the classes12.jar file is not required if you already have ojdbcX.jar in the CLASSPATH. Briefly stated if you are using the Oracle Thin Driver for JDBC against a 11g database you'll need ojdbc5.jar/ojdbc6.jar and orai18.jar in the CLASSPATH. You'll need additional files for the OCI driver. Could you guide me to configure this problem. Thank  I'm not sure what you meant here Class_Path: %ORACLE_HOME%\jlib\orai18n.jar;%ORACLE_HOME%\oui\jlib\classes12.jar Path: %Oracle_home%\jdbc\ojdbc6.jar All the jars should be on the Class_path. You will need the directories with dlls on your PATH. Could you guide me to configure this problem. Thank
941,A,"programmatically checking for open connection in JDBC How do I check for an open connection in jdbc for oracle database? Note: conn.isClosed() cannot be used for this. I want to implement connection pool. Do you want to know if your app has a connection open or do you want to know if the DB has a connection open to anything. Use pingDatabase(int timeout) Implemented in OracleConnection since 9.0.1 Note all pingDatabase(int) does in the Type IV driver is a ""select 'x' from dual;""  See this posting. The referenced solutions are similar to the one posted here (quick query against DUAL to validate) but there is also an interesting solution provided by JBoss specific to Oracle using the proprietary PING method in the Oracle JDBC Connection class. See the code here. //Nicholas Note all pingDatabase(int) does in the Type IV driver is a ""select 'x' from dual;""  Usually a Connection Pool will also use the Connection.isClosed() method to check if the Connection is still valid. The problem is that not all JDBC drivers will handle this call correctly. So I assume that there are some simple check statements just like RealHowTo said. For Oracle he already mentioned the ""SELECT 1 FROM Dual"" which should succeed always for Oracle databases. I think that there are similar queries for the different database. I can remember that in a previous project we also implemented an own Connection Pool which used such validation queries.  Something like: Statement stmt = null; ResultSet rs =null; try { stmt = conn.createStatement(); // oracle rs = stmt.executeQuery(""SELECT 1 FROM Dual""); // others // rs = stmt.executeQuery(""SELECT 1""); if (rs.next()) return true; // connection is valid } catch (SQLException e) { // TODO : log the exception ... return false; } finally { if (stmt != null) stmt.close(); if (rs != null) rs.close(); } Note that if the connection is coming from a Connection Pool (in a Application Server for example) then the Pool may have a mechanism to check if a connection is valid or not. With BEA you specify the SELECT in the ""test-on-reserve"" property. If you are developing your own pool then you may want to take a look at how others are doing it (ex. Proxool). Depending on your environment your Connection Pool SHOULD be checking the connection. Otherwise if you lose connectivity to the DB you typically have to restart you application server to restart the pool. I strongly suspect that the executeQuery will throw an SQLException if the connection is closed."
942,A,"NullPointerException with CallableStatement.getResultSet() I have a stored proc in SQL Server 2005 which looks like the following (simplified) CREATE PROCEDURE FOO @PARAMS AS BEGIN -- STEP 1: POPULATE tmp_table DECLARE @tmp_table TABLE (...) INSERT INTO @tmp_table SELECT * FROM BAR -- STEP 2: USE @tmp_table FOR FINAL SELECT SELECT abc pqr FROM BAZ JOIN @tmp_table ON some_criteria END When I run this proc from SQL Server Management Studio things work fine. However when I call the same proc from a Java program using something like: cs = connection.prepareCall(""exec proc ?""); cs.setParam(...); rs = cs.getResultSet(); // BOOM - Null! while(rs.next()) {...} // NPE! I fail to understand why the first result set returned is NULL. Can someone explain this to me? As a workaround if I check cs.getMoreResults() and if true try another getResultSet() - THIS time it returns the proper result set. Any pointers please? (I'm using JTDS drivers if it matters) Thanks Raj Umm. Did you call `cs.execute()` or `cs.executeQuery()` at some point? Kind of pointless posting an answer after the correct answer has been selected I guess. The solution I suggest is calling set nocount on before the insert statement and set nocount off afterwards. Inserts return a resultset otherwise.  The Javadoc for getResultSet() says that it returns null ""... if the result is an update count or there are no more results"". It looks like your stored procedure would have an update count and a resultset and that the getResultSet() method is (arguably) just doing what the API contract says it should do. You could try retrieving the update count first. Otherwise stick with your ""workaround"". Yes. Also one thing I noticed is that ""executeQuery()"" seems to work all the time (never returns null). Accepting your answer anyway... @Raj - presumably if you execute using executeQuery there is no way to retrieve the update count. (Question - is the update count from the INSERT actually retrievable?)"
943,A,"Remove boilerplate from db code It seems that every time I want to perform a db query I have to write the following: Connection conn = null; Statement stmt = null; ResultSet rset = null; try { conn = dataSource.getConnection(); stmt = conn.prepareStatement(sql); // ...set stmt params rset = stmt.executeQuery(); while(rset.next()) { // Do something interesting } } finally { try { if (rset != null) rset.close(); } catch(SQLException e) { } try { if (stmt != null) stmt.close(); } catch(SQLException e) { } try { if (conn != null) conn.close(); } catch(SQLException e) { } } Is this really the best way to do this? Is there a way to at least reduce some of the clutter? Edited: as some of the comments pointed out this code wasn't long enough. By the way you should check each for being null before closing. @Robert - not that it's nice and I agree a null check should be added but the NullPointerException will be caught in the catches block (along with OutOfMemoryError and all the other rumtime exceptions that could happen). If you're going to do the JDBC code yourself it worth writing a JDBCUtils class that has safeClose methods for each JDBC class. These methods should check for null and catch/log SQLException. Don't just log exceptions but let caller know that error occured otherwise caller cannot react to a problem (and in some cases it may want to). Spring JDBC Template solves this nicely by converting exceptions to runtime exceptions hierarchy. Yes use the Sping JDBC Template classes (http://static.springsource.org/spring/docs/2.0.x/reference/jdbc.html). Or if you don't use Spring copy the template pattern that they are using in your own code.  Make a helper method? public class DBHelper { public static Object run(string sql List params ResultHandler rhandler) { Connection conn = null; Statement stmt = null; ResultSet rset = null; try { conn = dataSource.getConnection(); stmt = conn.prepareStatement(sql); int i = 0; for(Object p in params) { stmt.setObject(++i p); } rset = stmt.executeQuery(); return rhandler.handle(rset); } finally { try { rset.close(); } catch(Exception e) { } try { stmt.close(); } catch(Exception e) { } try { conn.close(); } catch(Exception e) { } } } } public interface ResultHandler { public Object handle(ResultSet) } public class Test { public static void main(String[] args) { String s = (String)DBHelper.run(""select * from mytable where col = ?"" Arrays.asList({""foo""}) new ResultHandler { public Object handle(ResultSet r) { r.first(); return r.getString(""col2""); } }(); } } You trade a lot of boilerplate for much fewer lines of boilerplate... new ResultHandler needs ()  If you already have a DataSource you can use Spring JdbcTemplate for: greatly reduced boilerplate code have a good sql exception hierarchy to handle common database problems with specific runtime exceptions (later with further Spring usage) use declarative transaction management If it seems too heavy for the moment you could implement some utility classes and methods for the 'boilerplate part'. Studying the source of JdbcTemplate should help in this case. Spring's SQL Exception hierarchy rocks. Jdbc support in Spring is something I try to use if possible or at least copy if spring is not in the project.  I would use hibernate or JPA to reduce the clutter...  DbUtils is a very useful framework I've used it for smaller projects where Spring and Hibernate are overkill. It's able to do some object mapping as well. +1 Nice catch - I like it! It looks like they've essentially packaged up the ""helper"" approach I've described. I'll have to keep it in mind for next time. :-)"
944,A,"How can I get an error or a warning from a PreparedStatement? I had an update like this: update table set col1=?col2=?col3=? where col4=?; and I filled it up like this: statement.setString(1""some_value""); statement.setString(2""some_value""); statement.setString(3""some_value""); and I forgot to add a fourth value.I did a executeUpdate and of course nothing happened to the database. I spent about 1 hour debugging it to see where it goes wrong. I then modified my code to print the SQLWarning object returned by the getWarnings method. It always returned null. I even modified the code to the buggy state it was before I set the fourth parameter and still no warning. Does anyone know how one can get an error/warning? If it matters my Connection is set to autoCommit. no all the exceptions are printed with a full stack trace. This is apparently JDBC driver specific or a ""bug"" in SQLite JDBC driver. To my experience MySQL and PostgreSQL both throws a self-explaining SQLException if a parameter is missing. MySQL for example would have thrown `java.sql.SQLException: No value specified for parameter 4` here. is your code catching and swallowing exceptions? @BalusC is that exception thrown on auto-commit too? executeUpdate returns the number of rows modified by the statement. You can check to see if this result is 0 and if it is then log your own warning."
945,A,"Beginner JDBC Result Set questions New to using JDBC and I was wondering if all operations produce a result set. For example I am making statements to insert/update to a database via: StringBuffer query1 = new StringBuffer(""UPDATE table SET col1 = value WHERE some_col = some_val""); PreparedStatement pstmt1 = con.prepareStatment(query1.toString()); ResultSet rs1 = pstmt1.executeQuery(); So would this snippet when executed just act out the appropriate update and be done? Or would I need to handle the result set in some way in order to complete the operation? Thanks for the help in advance. I'm following a template of sorts given to me by my Project Manager. I'm a new grad and new to the company so I'm trying to stick with their procedures while I learn. tthere is another method for such statements: s.execute("".."");  You should be using PreparedStatement#executeUpdate() rather than executeQuery(). It returns an int indicating the amount of affected rows. int affectedRows = preparedStatement.executeUpdate(); That said constructing a SQL string that way is not the normal idiom. You would rather like to use placeholders ? and use the PreparedStatement setters to set the values. String sql = ""UPDATE table SET col1 = ? WHERE some_col = ?""; // ... preparedStatement = connection.prepareStatment(sql); preparedStatement.setString(1 col1); preparedStatement.setString(2 someCol); int affectedRows = preparedStatement.executeUpdate(); // ... See also: Basic JDBC tutorial Using PreparedStatement Thanks for the links. And I am using the PreparedStatement setters in my actual code. I probably should have been more specific in my snippet. Apologies on my part. No problem. You're welcome.  No you don't have to handle the ResultSet - it will be empty anyway because an update operation shouldn't return results from the database. Usually you would call a different metho on the statement: StringBuffer query1 = new StringBuffer(""UPDATE table SET col1 = value WHERE some_col = some_val""); PreparedStatement pstmt1 = con.prepareStatment(query1.toString()); int rowCount = pstmt1.executeUpdate(); Actually there are situations where an UPDATE _can_ return a ResultSet and in that case execute() should be used together with getResultSet() @a_horse: That depends on the SQL string and even then you'd rather like to use `CallableStatement` instead. I'll roughly guess that you're talking about returning insert ID for that JDBC offers the `getGeneratedKeys()` method which can be used afterwards (you're only dependent on the JDBC driver if it's supported; as of now most of them supports it only Oracle's one doesn't (yet?)). See also [this question](http://stackoverflow.com/questions/3552260/plsql-jdbc-how-to-get-last-row-id). I'm not talking about getGeneratedKeys(). Several DBMS support the ""RETURNING"" clause (for UPDATE DELETE and INSERT statements). For an UPDATE statement execute() would then return a result set with all modified rows. A DELETE statement would return a result set that contains all deleted rows. @a_horse: `CallableStatement` thus. See also the link. Seems to depend on the JDBC driver and the DBMS. I can run ""DELETE FROM emp WHERE id > 42 RETURNING *"" (in PostgreSQL). When run through execute() getResultSet() will then return a result set with all deleted rows. No need for a CallableStatement ;)"
946,A,"Using a variable instead of a parameter index with a JDBC prepared statement In many programming languages something like this is possible for prepared statements: PreparedStatement statement = connection.prepareStatement( ""SELECT id FROM Company WHERE name LIKE ${name}""); statement.setString(""name"" ""IBM""); But not with java.sql.PreparedStatement. In Java one has to use parameter indices: PreparedStatement statement = connection.prepareStatement( ""SELECT id FROM Company WHERE name LIKE ?""); statement.setString(1 ""IBM""); Is there a solution to work with string variables like in the first example? Is ""${.*}"" not used somewhere else in the SQL language or are there any conflicts? Cause then I would implement it by myself (parsing the SQL string and replacing every variable by ""?"" and then doing it the Java way). Regards Kai It puzzled me too. http://www.javaworld.com/javaworld/jw-04-2007/jw-04-jdbc.html has something I used several times. Hey kd304 I wonder why you didn't leave your message as answer instead of using a comment. Cause I think it's the way for me to solve that problem. @tokel: I wasn't sure about your question being theoretical or not and my comment does not really answer your typed question. Even though ... thank you :-) As kd304 mentioned in the comment to my posting this is a very nice solution if you don't want to incorporate another 3rd party library (like Spring) into your project: Javaworld Article: Named Parameters for PreparedStatement  Standard JDBC PreparedStatements don't have this ability. Spring JDBC provides this functionality through NamedParameterJdbcTemplate. Thanks for the very good solution. The problem for me is that it will be part of another open source framework and I don't want to import so much code there. Otherwise I would have used your solution :-)  Using a raw PreparedStatement this is not possible as you say. It is possible with CallableStatement but that requires a stored procedure rather than just a SQL statement. ORM layers like Hibernate also provide named parameter substitution and Hibernate also allows you to execute native SQL bypassing the OR mapping functionality completely. So if you were really keen to use named parameters you could employ Hibernate as a way of doing this; you'd only be using a tiny fraction of its functionality. Forget my idea @laz has a much better one. I think Oracle JDBC driver supports calling regular SQL statements with named parameters when using CallableStatement not just for procedures. PostgreSQL says ""Not yet implements"" (postgresql-9.1-901.jdbc4.jar)"
947,A,"How do I unlock an Oracle user's account from Java? I'm trying to figure out why my application is unable to unlock a user's Oracle account successfully. Here's a snippet from my code: OracleDataSource ods = new oracle.jdbc.pool.OracleDataSource(); Properties props = new Properties(); props.put(""user"" ""sys""); props.put(""password"" ""sys""); props.put(""internal_logon"" ""sysdba""); ods.setConnectionProperties(props); ods.setURL(""jdbc:oracle:thin:@localhost:1523:TEST_DB""); Connection conn = ods.getConnection(); Statement stmt = conn.createStatement(); stmt.execute(""ALTER USER SCOTT ACCOUNT UNLOCK""); stmt.close(); At no point does it raise an SQLException or report any problems but the user's account doesn't actually get unlocked. Am I missing something obvious here or is there some cunning way of getting this to work? Oracle 10g statement works perfectly in SQL*Plus. What is the database version? Did you try the command in SQL Plus? I'd be very nervous about having an application connect as sysdba like this. I would prefer to have a privileged user with permission to ALTER USER remove the CREATE SESSION privilege from it and have this schema contain an account_unlock pl/sql procedure for which execute privilege is granted to the user that your application connects with. ALTER USER is powerful stuff and you probably want to restrict the attributes and even the individual users that your application can alter. And that might also solve this problem. I agree wholeheartedly unfortunately I have a specific requirement which necessitates this approach. The application is intended as a simple support tool and will only ever be able to lock/unlock a user account and change a user's password. I've changed the application to use a priviledged user rather than connecting as sysdba as you suggested I figured out a different way to meet the other requirements that necessitated using sysdba. Whilst I can't explain why it didn't work before it does now. Ta muchly!  The good news is that your code should work - I just did a quick test of it and the target account was unlocked. Two questions come to mind: How are you determining the account is still locked? Are you using *SELECT username account_status FROM DBA_USERS*? Is there an Oracle profile in place that locks the account for failed logon attempts? Perhaps there is another process trying and failing to connect with an incorrect password that is re-locking the account. Sorry to ask such basic questions but again your code does work.  It would be safer doing it through a callable statement which executes dynamic sql inside a package. That way you grant execute on a package eliminating the possibility of a SQL injection attack Isn't that what the accepted answer recommended?  I would be curious to see if this resolves the issue: stmt.execute(""BEGIN EXECUTE IMMEDIATE 'ALTER USER SCOTT ACCOUNT UNLOCK'; END;""); Sadly not. It runs but doesn't affect the account status change.  Try to set 'autocommit' property to 'true' for your jdbc connection. May be it's just set to 'false' by default and your sql is not committed. a commit is not required for an ALTER USER  It is not a ""commit"" issue since this statement does not need a commit. Things to consider: Does the statement unlock the account when you run it in SQLPLUS? Are you logging onto the correct database from java? Is there some process trying to logon into the account whith the wrong credentials resulting in a locked account? Thanks for the advice. The statement works perfectly in SQL*Plus I have checked the connection details for the database dozens of time and it is definitely the correct database and there are no other processes that could make this change other than the one I'm trying to test.  Perhaps you are running into a case-sensitivity issue with Oracle 11?  try using executeUpdate rather than just execute. e.g. stmt.executeUpdate(""ALTER USER SCOTT ACCOUNT UNLOCK"") I thought you might have been on to something here but it makes no difference..."
948,A,jdbc: when can i close what currently i have jdbc code with the following basic stucture: get Connection (do the next 4 lines several times never closing statement) get statement get result set process result set close result set close connection It occurred to me after writing this code that i need to close the statement. 1 what are the effects of not closing the statement. 2 will the following work this si will closing the statement prevent me from processing the result set as normal? get Connection (do the next 5 lines several times) get statement get result set close statement process result set close result set close connection The close behavior is specified in the JDBC Specification. Closing the Connection releases all JDBC resources associated with the connection and will implicitly close all Statements ResultSets etc. Closing the statement will close the ResultSets. Example 2 is not guaranteed to work. The statement should be closed AFTER the ResultSet has been used. The spec says that you should get an SQLException if you try to use that ResultSet (some JDBC drivers don't follow the spec strictly--and MS is not biggest offender). If you forget to close a ResultSet or Statement the worse case that happens is you consume database and JVM resources for longer than necessary. On a resource constrained or high load system this could cause memory/connection/resource errors or reduced performance.  The answer depends on your JDBC driver unfortunately. What you wrote there might work. However the general rule is that you close your statement only when you are done with the corresponding resultset. EDIT: I realize that you had a second question where you asked about the effects of not closing the statements/Resultsets and so on. The effects also depend on your JDBC driver but it could lead to significant resource leaks.  If you're using Oracle and forget to close the statements you'll get ORA-01000: maximum open cursors exceeded after a while.
949,A,"JDBC Batch Update Problem I have a slightly unique requirement with the Java-JDBC API along with Oracle Database. I have autoCommit to be default which is true for Oracle and I am using the example similar to this link. However when I add say 1000 batches and lets say each of them are inserts. And Let us assume that about 20 records violated some constraints I want the remaining 980 to go COMMITTED (and henceforth visible to any other queries using any other connection) to the database and ignore the 20 records. In the above example when one row violates any transaction then even when I commit in the catch block the transaction only commits until the first failure. I know batch updates are to be done ONLY when you are fairly sure all rows will go through and exception processing is not one but am planning to PATCH an existing database so some kind of ""bad practices"" is okay :) Any code samples will be highly appreciated. ** MORE DETAILS ** Using Simple insert/update is not okay since I am processing close to 3M rows so am batching every 1000 records. Simply adding 1000 inserts in loop (ignoring exceptions) takes way more time (about 5 seconds for every 1000 records) as opposed to the batch update < 300ms. Problem: With Oracle database the Driver seems to stop at the first FAILURE ie when 1000 rows are batched and 100th failed I want it to go ahead till the 1000th row. Me thinks this cannot be done in JDBC (with Oracle) Like the link indicates only few databases support such feature and probably Oracle is not one What keeps you from just doing the inserts one-by-one? Performance? Can you test the constraints programatically before you add the data to the batch queue? Yes please see the processing times updated in the question I cannot test them programmatically. Also the chances of a row failing is < 1 %. So while processing 1000 rows rough 6-10 records will fail. Presently the tool updates until the first failure so I have to run a while loop until all were processed. Was just wondering if the experts knew a better way !! I was looking some solution on the line of ""With Oracle database the Driver seems to stop at the first FAILURE ie when 1000 rows are batched and 100th failed I want it to go ahead till the 1000th row."" Basically I wanted to know if this can be done with Oracle JDBC driver. However a variety of answers have been proposed (most/all of which I had already considered) 1) Disabling the constraints/load data/remove offending rows/repeat this many times 2) Do all the checking before loading data 3) Decrease the batch size to 50 - 100. Unfortunately my checking cannot be done before loading and making batch size to be 50 or 100 means taking more time to do the 5M rows I have (infact the total time increased to a few hours instead of 40 mins with a batch size of 1000). I have resorted to keeping the batch size of 1000 ACCEPTING THE problem as is and put the code under a ""while"" loop and do the job until we fill up all rows. Like I said since there is NO WAY WITH ORACLE BATCH JDBC to proceed after first failure the answer to this question will be ""NOT DOABLE"" and just accept the constraints and document the fact that this tool takes about 40 mins to complete :)  You should insert into a working table that does not have the constraints then delete or fix what would be in violation and INSERT SELECT the rest over into the real table in a single SQL statement.  You can use a PL/SQL stored procedure using the SAVE EXCEPTIONS clause which will allow you to issue a bulk update and then return those rows which could not be updated. Here is a couple of example links: http://rwijk.blogspot.com/2007/11/save-exceptions.html http://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:8912264456901  Could you try the Oracle merge-when-not-matched statement? Example: http://www.idevelopment.info/data/Oracle/DBA_tips/SQL/SQL_14.shtml  Have an exceptions table and make sure your proc never raises exception but saves all exceptions in database. Once all done query exceptions table and see records could not go through.  i should check first to see if there is a constraint violation than insert that record if the contraints is not violated.  You could try this: Start with batches of 50 or 100. (Choose a size so they have a good probablity to be processed successfully). Those which fail process one-by-one. Other possibility: Disable the constraints load the data delete those rows which violate the constraints."
950,A,"Are there any issues with MySQL's i18n(indic language) support? We're evaluating MySQL and PostgreSQL for building our indic language(using utf-8 encoding) web application which will use MySQL or PostgreSQL. One of my colleagues mentioned that MySQL had issues with i18n. I mostly come from the Oracle world and although I've played a lil with MySQL I don't know enough to know that there are issues with its i18n support. Does anyone know issues with MySQL's i18n support and if PostgreSQL would be better placed for building an application with indic language support(kannada telugu tamil etc) using utf-8 encoding ? Just so you know we're going to be using J2EE to build this application and we will be using JDBC drivers to access the DB. P.S : Will anything change if we were to use Rails to build the app instead of J2EE ? Thank you MySQL doesn't support the complete utf8-encoding: Currently MySQL support for UTF-8 does not include four-byte sequences. PostgreSQL has full support for utf8. Sorry can't help you there. I don't do MySQL anymore and don't know/remember everything about the details. Just use PostgreSQL and you're safe. :) hi Frank thank you. does MySQL has full support for 3-byte sequences ?  No mysql has no issues with languages. Mysql don't deal with languages. Only with encodings. You can use any encoding supported and utf-8 is preferred one. hi Col. Shrapnel thanks for your comments. The intent was to use utf-8 encoding from the beginning. The question was ""are there issues with i18n support with this encoding ? @anjanb the whole world uses it. Col. Shrapnel That is what I thought. I'm still gunning for it . Since my colleague mentioned the issues I'm doing ""due diligence"" instead of neglecting his warning. So the whole world *should* use it. Mysql's ""utf8"" (not ""utf-8"") is a crippled implementation of the true UTF-8 encoding it does not fully support the unicode standard (basically does not support characters outside the BMP)"
951,A,"Oracle UPDATE command with multiple conditions in Java I'm having issues with the Java code below. It is supposed to update certain records in a table where the ID is given and where the STATUS column is 'good' (this is only one row at any given time). However when I run the code below it seems to be ignoring the AND STATUS = 'good' part and updating all NUMRECS wherever the ID matches. static void insertNumRecs() { PreparedStatement insert = null; try { String insertNumRecsCommand = ""UPDATE FILESTATUS SET NUMRECS = ? "" + ""WHERE ID = ? AND STATUS = 'good'""; insert = Main.con.prepareStatement(insertNumRecsCommand); insert.setInt(1 Main.numRecs); insert.setString(2 Main.docID); insert.executeUpdate(); } catch (Exception ex) {ex.printStackTrace();} finally {close(null insert);} } I've tried searching for this everywhere but I couldn't find any answers. When I run the command directly from the database it works fine which confuses me even more. Thanks in advance. That query should work and respect the `status='good'` portion. Something else must be at play. If you are testing it out by manipulating the status field yourself in another database session are you sure you committed your changes before testing the code you posted? Yes I am sure as the program won't work at all before I commit (it won't even insert the data let alone update). Thanks for the suggestion though :) Try to write ""WHERE ID = ? AND STATUS = ?"" and use insert.setString(3 ""good""); Oh my do I feel dumb. I didn't even think of this. Works perfectly! However I am somewhat curious as to why what I did above did not work... any ideas? Thank you! @ryantmer: No ideas sorry. I tried the something similar right now and it just worked fine. Only matching rows updated...  This doesn't explain the problem but I'd wonder why you don't do this: static void insertNumRecs() { PreparedStatement insert = null; try { String insertNumRecsCommand = ""UPDATE FILESTATUS SET NUMRECS = ? "" + ""WHERE ID = ? AND STATUS = ?""; insert = Main.con.prepareStatement(insertNumRecsCommand); insert.setInt(1 Main.numRecs); insert.setString(2 Main.docID); insert.setString(3 ""good""); insert.executeUpdate(); } catch (Exception ex) {ex.printStackTrace();} finally {close(null insert);} } Can't see your data so I can't tell if it's a case issue (""GOOD"" != ""good"") Sure you're connecting to the database you think you are? If the connection string points to one database and you run your test against another that would explain why you don't see the change. Thanks! Peter Lang was quicker on the trigger though ;) And the case is correct I made sure to keep everything lowercase for that reason. As for the connection everything else works fine so I have no idea why this wouldn't! =/"
952,A,"compare resultset result with a variable I am having some difficulties in java while comparing between a variable and the next resultset. In my case I want : if the temp variable = rs.next() then temp ="""" else the rs.next() value should be displayed. This is because I am getting the Tname field many times so I would like to retrieve it once. Here is my code while(rs.next()){ %> <tr> <td width=""238""> <%temp=rs.getString(""TNAME"");%> <%=temp%> </td> <td><%=rs.getString(""ID"")%></td> <% if (rs.next().equals(temp){ temp=""""; } } rs.close(); %> ResultSet#next() returns a boolean not a String containing the column value you're after. But still then you really don't want to move the cursor to the next row there. When you go back to the beginning of the while loop you have effectively skipped one row. You need to change the logic: compare the currently iterated name with the previously iterated one and only display it when it is different. Then store the currently iterated name as variable so that it can be compared in the next iteration. Here's a kickoff example based on JSTL/EL and a fictive List<Item> which is stored as ${items} in the scope: <table> <c:forEach items=""${items}"" var=""item""> <tr> <td><c:if test=""${item.name != previousName}"">${item.name}</c:if></td> </tr> <c:set var=""previousName"" value=""${item.name}"" /> </c:forEach> </table> You only need to translate it into old fashioned scriptlets yourself if you insist in using it. The above logic should be self-explaining enough.  I think you have two problems: you're iterating through your loop using rs.next() but inadvertently jumping again by your second rs.next() call. you're comparing your temp string to rs.next() and not the particular field you're interested in. It's not very clear (I think) what you want. The above is just based on some apparently obvious problems with your current solution. so how to do that how to compare the temp which has the tname with rs.next() for the next tname It may be simpler to pull out all the TNAMEs into a list and then iterate through those in a separate state rather than mix your comparisons with calls to rs.next(). You'll be separating two areas of complexity (which is most usually a good thin g)"
953,A,"How to find whether a ResultSet is empty or not in Java? How can I find that the ResultSet that I have got by querying a database is empty or not? Immediately after your execute statement you can have an if statement. For example ResultSet rs = statement.execute(); if (!rs.next()){ //ResultSet is empty }  If you use rs.next() you will move the cursor than you should to move first() why don't check using first() directly?  public void fetchData(ResultSet res JTable table) throws SQLException{ ResultSetMetaData metaData = res.getMetaData(); int fieldsCount = metaData.getColumnCount(); for (int i = 1; i <= fieldsCount; i++) ((DefaultTableModel) table.getModel()).addColumn(metaData.getColumnLabel(i)); if (!res.first()) JOptionPane.showMessageDialog(rootPane ""no data!""); else do { Vector<Object> v = new Vector<Object>(); for (int i = 1; i <= fieldsCount; i++) v.addElement(res.getObject(i)); ((DefaultTableModel) table.getModel()).addRow(v); } while (res.next()); res.close(); } I agree. I added my code below (could not include code with the comment).  Calculates the size of the java.sql.ResultSet: int size =0; if (rs != null) { rs.beforeFirst(); rs.last(); size = rs.getRow(); } (Source) Agree... I voted up the accepted answer which answers the question much more directly. As far as I know that is a bad idea... first of all you need to ensure that the result can move backwards second of all you take a performance hit when doing that. Much quicker to just use a forward only result set and use a while loop (like has already been suggested by others here)   if (rs == null || !rs.first()) { //empty } else { //not empty } Note that after this method call if the resultset is not empty it is at the beginning. This way more safe I thought. ResultSet is never null.  Definitely this gives good solution ResultSet rs = stmt.execute(""SQL QUERY""); // With the above statement you will not have a null ResultSet 'rs'. // In case if any exception occurs then next line of code won't execute. // So no problem if I won't check rs as null. if (rs.next()) { do { // Logic to retrieve the data from the resultset. // eg: rs.getString(""abc""); } while(rs.next()); } else { // No data }  Do this using rs.next(): while (rs.next()) { ... } If the result set is empty the code inside the loop won't execute."
954,A,"Hibernate is persisting entity during flush when the entity has not changed I'm having a problem where the entity manager is persisting an entity that I don't think has changed during the flush. I know the following code is the problem because if I comment it out the entity doesn't persist. In this code all I'm doing is loading the entity and calling some getters. Query qry = em.createNamedQuery(""Clients.findByClientID""); qry.setParameter(""clientID"" clientID); Clients client = (Clients) qry.getSingleResult(); results.setFname(client.getFirstName()); results.setLname(client.getLastName()); ... return results; Later in a different method I do another namedQuery which causes the entity manager to flush. For some reason the client loaded above is persisted. The reason this is a problem is because in the middle of all this there is some old code that is making some straight JDBC changes to the client. When the entity manager persists the changes made by the straight JDBC are lost. The theory we have at moment is that the entity manager is comparing the entity to the underlying record sees that it's different then persists it. Can someone explain or confirm the behavior we're seeing? You're right that the entity manager compares the objects (as long as they're not read-only in the session evicted session.clear() has been called etc) and if they don't match then it will flush them out. Tthis specific issue has bitten us before and caused exactly the same needless-flush problems -- ours was also a performance problem in a tight loop we needed to flush() the session and every time we did hundreds of unchanged objects got dumped back to the DB. In our case it was that the entities in question did not implement equals() and hashCode() correctly -- Hibernate obviously relies on those to check the object's changed and if they're incorrect in some way then it has no choice but to flush them back. From memory (it was a while ago) it was actually a subsidiary entity which didn't implement hashCode() correctly -- imagine a Student-Teacher relationship where Teacher doesn't correctly implement those methods. When dirty-checking a Student Hibernate checks in its entity cache for the Teacher thinks it's not there (due to incorrect implementations) and so thinks Student has changed reflushing it back to write out the new Teacher ID. So check hashCode() and equals() for the entitiy in question all its related entities and any other components/user types which get written to the DB. We have a custom user type converts dates in the db from 0000-00-00 to a null. We suspect that maybe that's setting the dirty flag. Using the dirtyCheck as you suggest we should be able to verify if that's the source. If it is... is there anyway to say don't let this change set the dirty flag? A LOT of very painful debugging unfortunately. I can't recall if there's useful logging in Hibernate we were able to turn on; I think in the end we worked it out only by a few strategic breakpoints in the Hibernate code. Start with DefaultFlushEntityEventListener.dirtyCheck() -- that finds all the dirty properties and so should make it obvious which properties are causing the flush back. We actually ended up writing a JUnit test case which crawled out classpath found all the entities and checked that they behaved correctly in terms of hashCode() and equals() which found a few others too. How were you able to determine that it was an improper implementation of hashcode or equals? I don't think you can exclude it. I suspect what's happening is your bean's getter isn't returning the same value Hibernate is expecting it to -- that is Hibernate is seeing 'null' from your bean but '0000-00-00' from the dehydrated database state. Not 100% sure how that comparison is done but that code in DefaultFlushEntityEventListener should help you work it out if you step through it. Turns out that our implementation of Equals was wrong. Once we got the correct logic the entity quit writing out to the db unexpectedly. @Cowan: Thanks for the tip about `DefaultFlushEntityEventListener`. It logs dirty checks at the `TRACE` level e.g. in `log4j.xml`: ` `  If your getter is performing any logic so that it is returning something other than what hibernate sent to the setter then it will be marked dirty. For instance if your getter logic is returning 0 when hibernate gave you a null from the database then it'll be marked dirty because it looks like it changed. I'm not aware of a way to tell hibernate not to mark that change as making the entity dirty. This is one that once learned by experience is difficult to forget :) Cheers for this I was getting this error message ""Application attempted to edit read only item: // Can't write to a readonly object"" and your post pointed me in the right direction. Namely I was making a defensive copy on the setter and returning a new TreeSet (for reasons that are still unclear) on the getter. After removing that logic everything worked fine!  I don't know the innards of hibernate but my guess is that you are correct. But I don't think hibernate compares with the db but compares with the local session cache. You can avoid the problem by setting the object to readOnly - hibernate then does not check for changes e.g.  session.setReadOnly(client true); Alternatively you can also evict the object using Session.evict(). Next time the object is required it will be read in from the db including any changes you made using your custom JDBC. If it's comparing with the local session cache then how is the jdbc call interacting with it. The jdbc should be going straight to the db and skipping the session (or so I thought). I am injecting the data source would that make a difference? If your jdbc layer uses the same DataSource and the DataSources is a SingleConnectionDataSource than they do interact if the hibernate call flushes before the jdbc call"
955,A,"exhausted resultset error when i get the name of the columns i'm trying to get the type and the name of the result and when enter in the loop excuting somo instructions about the metadata the resulset.next changed from true to false and give the error java.sql.SqlExcepcion exhausted resultset. Any ideas? i really dont know how solved it because i read the post with the solution of this problem and validate if the resultset it's null before begin the loop. I'm called this method with a scheduler of quartz. I'm using this in a j2ee aplication and the example it's this try { InitialContext ctx = new InitialContext(); WrapperDataSource wrapperDataSource = (WrapperDataSource)ctx.lookup(systemLogger.getConfigurationParameters().getDataSource()); conn = wrapperDataSource.getConnection(); Class.forName(""com.microsoft.sqlserver.jdbc.SQLServerDriver"").newInstance(); conn = DriverManager.getConnection(urlloginpassword); if (conn != null) { stmt = conn.createStatement(); res = stmt.executeQuery(query); if (res != null) { while (res.next()) { for (int i = 0; i < columnlength; i++) { String columnName = metadata.getColumnName(i+1); if (metadata.getColumnName(i+1).equalsIgnoreCase(systemLogger.getColumnStatus())) { columnStatusType = metadata.getColumnType(i+1); } else if (metadata.getColumnName(i+1).equalsIgnoreCase(systemLogger.getColumnDocumentId())) { columnDocumentIdType = metadata.getColumnType(i+1); } else if (metadata.getColumnName(i+1).equalsIgnoreCase(systemLogger.getColumnTimer())) { columnTimerType = metadata.getColumnType(i+1); } } } } else { __log.error(""No results found for the query""); throw new PtmServiceException(""No se encontraron resultados para el query""); } } else { __log.error(""Could not create the connection""); throw new PtmServiceException(""No se pudo crear la conexion""); } } catch(Exception e) { __log.error(""Error in the execution of the query""); throw new PtmServiceException(""Error ejecutando la busqueda""); } finally { res.close(); stmt.close(); conn.close(); } Where are you catching this exception? Where's the line causing this exception? The code which you're showing doesn't access the resultset and swallows all exceptions and would have produced different exceptions. hi and thanks for asking my question i'm catching the exception in the line `columnStatusType = metadata.getColumnType(i+1);` in the second loop of the for finally i see the problem while i'm debugging the code with ecplise in the view of the expressions i added the follow expression res.next() then each sentence that i pass for the step into bring the consequence that expression that evaluate if the resultset has more rows be evaluated again. In some point the resultset has evaluated all the rows for each step into that i made in the process of debugging. The only thing that i have to do was eliminate the expression and works fine...  The problem might not be with the code but instead could be the database. Double check that the TABLE IS NOT EMPTY. You get this error if the table is empty. Keep in mind that databases like Oracle require a commit after all your insert update alter statements .Your changes might not be visible outside the database till you run a commit over the your db I was having this problem for quite a long time. I kept on checking the table with select statement but the problem with my oracle db was that I had not issued a commit over my db.  The variable columnlength seems to hold a value larger than the number of columns returned by the query. Try with a smaller columnlength."
956,A,JDBC Dates Deprecated in Java (java.sql package) I am working with JDBC and MySQL. I have a date column that I need included in my result set. Unfortunately I cannot find a class in Java to retrieve the date. The SQL Date class is deprecated. How do you get Date objects from a result set? You can safely use the java.sql.Date class to map your MySQL DATE type. The java.sql.Date class extends the java.util.Date class so you can use this object to do all types of date calculations.  Old post but anyways: I had problems with the granularity of java.util.Date and switched to java.util.Timestamp. I also experienced limited granularity with Timestamp type (up to seconds). The columns in the database are declared as Date and to get the additional time part I retrieved it as Timestamp. Problem is it truncates the value to seconds. I investigated the Oracle default definition for timestamp which allows for 6 fractional digits. I guess the Date part in the oracle definition limits the timestamp part in Java... Cheers Grazina That is exactly as per the JDBC contract. If you want to store a date (day month year) use `java.sql.Date`. If you want to store a time (hour minute second) use `java.sql.Time`. If you want to store a timestamp (day month year hour minute second also known as datetime) use `java.sql.Timestamp`. Depending on the DB and JDBC driver used you also have milliseconds in the `Timestamp`.  I don't think the java.sql.Date class itself it deprecated only one of its constructors. You should be safe to continue using it.  You use java.sql.Date. A constructor and some methods are deprecated. The class isn't. Confused by this versus say java.util.Date or java.util.Calendar? Look at Making Sense of Java's Dates. There are three JDBC date/time types: DATE: granularity of days use java.sql.Date; TIMESTAMP: date and time use java.sql.Timestamp; TIME just the time with no date use java.sql.Time. The confusion probably arises from the fact that java.sql.Date extends java.util.Date and thus inherits its deprecated methods. Just use the right type for the type of your column. short and to the point and very helpful. +1 The problem is that the only constructor that remains is the one to create a date passing in millis. Also all of its set and get methods that don't use millis are deprecated. Unless SQL returns the date in millis this seems kind of silly. Read the javadoc more closely java.sql.Date conforms to the DATE JDBC type and the fields smaller than day are set to zero. The type is for use when you have a field that is day/month/year only and not say TIMESTAMP or TIME. What are you trying to do exactly? Oh that makes more sense thanks and don't forget that java.sql.Date is a subclass of java.util.Date (some more methods)
957,A,"can oci driver for 11g (odbc5.jar) work with 10g client? I need to connect to Oracle910 and 11 in my java application.The client will always be present where the app will be run and I want the app to just work with usernamepassword and instance (specified in tnsnames.ora).Hence I would like oci drivers with a connection string of type : jdbc:oracle:oci:@testora .Im using the driver: oracle.jdbc.driver.OracleDriver. I have a 10g client and am using jdk1.5. When I use the ojdbc14 jar from client lib path the app runs. But if I use the ojdbc5 driver then the app fails with Exception in thread ""main"" java.lang.UnsatisfiedLinkError: no ocijdbc11 in java. library.path exception. What im looking for is a way to package a single jar(ojdbc5/ojdbc14) and a single driver which will use oci drivers to connect to the client that is present on local machine(9/10/11).This is the way I would prefer it. If this is not possible can I search the unix box for oracle versionpick up the correct jar and then use it in classpath when invoking the app which is in jar format? Thanks Fell ojdbc5.jar is intended to work with jdk1.5.x either you are connecting to Oracle 10 or 11g shouldn't matter ojdbc14.jar was intended for jdk1.4.x  java.lang.UnsatisfiedLinkError: no ocijdbc11 in java.library.path This means that you are missing a DLL (ocijdbc11.dll) in the Java library path. Make sure you have that DLL and start your program like this: java -Djava.library.path=C:\mydirwiththedll com.mypackage.MyProgram im working with unix environment and tried setting the java.library.path to the LD_LIBRARY_PATH location...However now im getting the following link error : Can't load Sparc v9 64-bit .so on a Sparc 32-bit platform.How can I fix this ? my solaris machine is 64 bit and im using jdk1.5 @Jesper i have similar problem in this post http://stackoverflow.com/questions/19223416/java-lang-unsatisfiedlinkerror-no-ocijdbc11-in-java-library-path?lq=1 and i can't figure it out please advise."
958,A,How do I get name of the target table and column of foreign key column with plain JDBC I'm trying to make a piece of code using plain JDBC that fetches me the name of both target table and column of a foreign key of a specific column in specific table but going through the core interfaces I can't seem to find a direct way to do this. Is there a way to get such information about foreign keys through JDBC directly or do I have to resort to metadata queries to specific database in this case HSQLDB. If I have to use the database specific metadata queries which HSQLDB internal metadata tables hold that information? JDBC does have support for this. Check out DatabaseMetaData.getCrossReference class. Other methods on DatabaseMetdata support for querying schema catalog tables columns etc. Bear in mind some databases require extra parameters on your URL to turn on Metadata (i.e. Oracle) to optimize the calls. Don't know if HQLSB requires this.  Your best bet is Connection#getMetaData() which returns DatabaseMetaData with all methods to obtain information about all tables columns primary keys foreign keys etcetera. You're however dependent on the JDBC implementation (read: the JDBC driver make/version) whether this is fully supported. `DatabaseMetaData#getImportedKeys()` was what I was looking for thanks!
959,A,"Oracle CLOB performance I am running queries against an Oracle 10g with JDBC (using the latest drivers and UCP as DataSource) in order to retrieve CLOBs (avg. 20k characters). However the performance seems to be pretty bad: the batch retrieval of 100 LOBs takes 4s in average. The operation is also neither I/O nor CPU nor network bound judging from my observations. My test setup looks like this:  PoolDataSource dataSource = PoolDataSourceFactory.getPoolDataSource(); dataSource.setConnectionFactoryClassName(""...""); dataSource.setConnectionPoolName(""...""); dataSource.setURL(""...""); dataSource.setUser(""...""); dataSource.setPassword(""...""); dataSource.setConnectionProperty(""defaultRowPrefetch"" ""1000""); dataSource.setConnectionProperty(""defaultLobPrefetchSize"" ""500000""); final LobHandler handler = new OracleLobHandler(); JdbcTemplate j = new JdbcTemplate(dataSource); j.query(""SELECT bigClob FROM ..."" new RowCallbackHandler() { public void processRow(final ResultSet rs) throws SQLException { String result = handler.getClobAsString(rs ""bigClob""); } }); } I experimented with the fetch sizes but to no avail. Am I doing something wrong? Is there a way to speed up CLOB retrieval when using JDBC? How have you determined it's not network bound? You're talking about setting up a new JDBC connection (expensive) 2Mb worth of data to read from disk send it over the network and the overhead of the query (which isn't specified). I don't know if 4s is all that bad depending on your network layout and database setup. Clarification: I measure in *units* of 100 so the initial penalty of connecting does not count. The total network throughput stay below 2Mbit/s so I suppose it's not network bound. How long does the actual query take? About 3 seconds. I do not think that the query complexity has something to do with the throughput though (I do not use a *first_rows* hint or anything esoteric). The total size of the result set is in the ten thousands - measured over the span of the whole retrieval the initial costs (JDBC connection query return) are not relevant. Can you try to measure the difference between retrieving the CLOB column and a more ""normal"" non-indexed column but using the same tables joins and where-clauses? This should give you an indication weather the problem is caused by the CLOB or the row access. Just fetching the primary key of the CLOB containing table takes about .3s for 10k rows. Did you try selecting them using SQLPLUS or any other application (Oracle SQL Developer ?!). Does querying itself take time. Have you tried `explain plan for select bigClob from ...' ? My past experience of using oracle LOB type data to store large data has not been good. It is fine when it is under 4k since it store it locally like varchar2. Once it is over 4k you start seeing performance degrade. Perhaps things may have improved since I last tried it a couple of years ago but here are the things I found in the past for your information: As clients need to get LOBs via oracle server you may consider the following interesting situation. lob data will compete limited SGA cache with other data type if oracle decide to cache it. As clob data are general big so it may push other data lob data get poor disk read if oracle decide not to cache it and stream the data to the client. fragmentation is probably something that you haven't encountered yet. You will see if your applications delete lobs and oracle tries to reuse the lob. I don't know if oracle support online defragmenting the disk for lob (they have for indexes but it takes long time when we tried it previous). You mentioned 4s for 100 lobs of avg 20k so it's 40ms per lobs. Remember each lob needs to have to retrieved via separate Lob locater (it is not in the result set by default). That is an additional round trip for each lob I assume (I am not 100% sure on this since it was a while ago) If that is the case I assume that will be at least 5ms extra time per round trip in serial order right? If so your performance is already first limited by sequential lob fetches. You should be able to verify this by tracking the time spent in sql execution vs lob content fetching. Or you can verify this by excluding the lob column as suggested by the previous answer in the post which should tell you if it is lob related. Good luck  The total size of the result set is in the ten thousands - measured over the span of the whole retrieval the initial costs Is there an Order By in the query? 10K rows is quite a lot if it has to be sorted. Also retrieving the PK is not a fair test versus retrieving the entire CLOB. Oracle stores the table rows with probably many in a block but each of the CLOBs (if they are > 4K) will be stored out of line each in a series of blocks. Scanning the list of PK's is therefore going to be fast. Also there is probably an index on the PK so Oracle can just quickly scan the index blocks and not even access the table. 4 seconds does seem a little high but it is 2MB that needs to be possible read from disk and transported over the network to your Java program. Network could be an issue. If you perform an SQL trace of the session it will point you at exactly where the time is being spent (disk reads or network).  I had a similar issue and found the JDBC Lobs making a network call when accessin the lobs. As of Oracle 11.2g JDBC Driver you can use a prefetch. This speeded up access by 10 times...  statement1.setFetchSize(1000); if (statement1 instanceof OracleStatement) { ((OracleStatement) statement1).setLobPrefetchSize(250000); }  Thanks for all the helpful suggestions. Despite being flagged as answer to the problem my answer is that there seems to be no good solution. I tried using parallel statements different storage characteristics presorted temp. tables and other things. The operation seems not to be bound to any characteristic visible through traces or explain plans. Even query parallelism seems to be sketchy when CLOBs are involved. Undoubtedly there would be better options to deal with with large CLOBs (especially compression) in an 11g environment but atm. I am stuck with 10g. I have opted now for an additional roundtrip to the database in which I'll preprocess the CLOBs into a size optimized binary RAW. In previous deployments this has always been a very fast option and will likely be worth the trouble of maintaining an offline computed cache. The cache will be invalided and update using a persistent process and AQ until someone comes up with a better idea. Looks like a good workaround as if you retrieve 100 rows you will pay addition roundtrip but save 100 roundtrip totally you save 100-1 =99 round trips. But how did you implement it? By fetching only CLOBs + some key to identify them later and writing them into a local key-value store. I used [Oracle Berkeley DB](http://www.oracle.com/technetwork/database/berkeleydb/overview/index.html) but you could easily use SQLite or anything else I suppose."
960,A,"How to use MySQL JDBC driver in an SBT Scala broject? When I run my project for the first time during an SBT session it throws the following exception when trying to access a MySQL database: java.lang.NoClassDefFoundError: scala/Ordered When I run it again (and any time after it during the same SBT session) it throws a different one: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost/... When I was using NetBeans the same code was working Ok. Now As I use SBT for building Kate to edit and manage my project manually I get these runtime errors. MySQL JDBC driver (downloaded right from MySQL.com) JAR is in project's lib directory other libraries I've put there work ok. in the code I   import java.sql._ ... // read val dbc : Connection = DriverManager.getConnection(""jdbc:mysql://localhost/..."") val st : Statement = dbc.createStatement val rs : ResultSet = st.executeQuery(""SELECT ..."") if(rs.first) result = rs.getDouble(""field"") dbc.colse ... // write val dbc : Connection = DriverManager.getConnection(""jdbc:mysql://localhost/..."") val st : Statement = dbc.createStatement st.execute(""UPDATE ..."") dbc.colse  I've seen a question looking pretty related but no answer. The MySQL dependency must be configured in your build.sbt. Currently the style is to declare library dependencies like so: libraryDependencies ++= { val liftVersion = ""2.5.1"" Seq( ""net.liftweb"" %% ""lift-webkit"" % liftVersion % ""compile"" ""net.liftweb"" %% ""lift-mapper"" % liftVersion % ""compile"" //etc ) } Add the following inside the Seq to add mysql: ""mysql"" % ""mysql-connector-java"" % ""5.1.+"" Note that the + means that it will get the latest minor version; anything above 5.1 such as 5.1.27 (the current version at time of writing).  In the project/plugins.sbt file add a line libraryDependencies += ""mysql"" % ""mysql-connector-java"" % ""5.1.12"" Then if your in the sbt shell restart it.  In the SBT project class there should be a line:  // Declare MySQL connector Dependency val mysql = ""mysql"" % ""mysql-connector-java"" % ""5.1.12"" This will import the JDBC driver JAR file for MySQL. Did you load the driver? If you use this Util class to fetch the connections the driver will be loaded exactly one time: // Util Class object DaoUtil { import java.sql.{DriverManager Connection} private var driverLoaded = false private def loadDriver() { try{ Class.forName(""com.mysql.jdbc.Driver"").newInstance driverLoaded = true }catch{ case e: Exception => { println(""ERROR: Driver not available: "" + e.getMessage) throw e } } } def getConnection(dbc: DbConnection): Connection = { // Only load driver first time this.synchronized { if(! driverLoaded) loadDriver() } // Get the connection try{ DriverManager.getConnection(dbc.getConnectionString) }catch{ case e: Exception => { println(""ERROR: No connection: "" + e.getMessage) throw e } } } } The code is taken from a simple SBT - MySQL tutorial I wrote some time ago. If you want to download the complete tutorial see http://github.com/ollekullberg/SimpleOrder Had the same problem this fixes it! same problem and this fix isn't working"
961,A,"JDBC url with database containing spaces I'm trying to connect to a SQL Server database using JDBC the database I'm trying to connecto to contains a space and unfortunately I have no control over the name so I can't change it. The code I'm using is: String jdbcString = ""jdbc:sqlserver://"" + hostname + "":"" + port + "";databaseName=Database Name""; try { connection = DriverManager.getConnection(jdbcString username password); } I've also tried following the instructions on this link: http://msdn.microsoft.com/en-us/library/ms378428%28SQL.90%29.aspx by haveing the space inside braces: String jdbcString = ""jdbc:sqlserver://"" + hostname + "":"" + port + "";databaseName=Database{ }Name""; but that doesn't seem to work either. The error message I gee is: ERROR: Couldn't connect to the database: The connection string contains a badly formed name or value. I'm using the latest JDBC driver from Microsoft. You should use the following syntax: jdbc:sqlserver://""your Server Name"":1433;DataBaseName=""Data Base Name"" Example: jdbc:sqlserver://localhost:1433;DataBaseName=testDB  Does this work? String jdbcString = ""jdbc:sqlserver://"" + hostname + "":"" + port + "";databaseName={Database Name}""; That did work! I can't believe I didn't try that :) Thanks a lot!"
962,A,"MySQL-JDBC Question: Can I use the column name as parameter? Let's say I have a table with 3 columns: C1 C2 C3 I make a search based on the C1 column. Could I make something similar like this (this is not working - because this is not the way prepareStatement it's used:) ) String c;// the name of the column ... String sql = ""select * from table where ? = ?""; pre = con.prepareStatement(sql); pre.setString(1 c); pre.setString(1 i); rs = pre.executeQuery(); The main idea I don't want to have 3 ifs for every column. An elegant solution? shouldnt that be ..... pre.setString(1 'c1'); pre.setString(2 i); I made the correction. :) you could code up a a set of sql queries and store them in a map then grab one based on the column in question. enum column { a b c} Map<column string> str; static { str.put(a ""select * from tbl where a = ? ""); ... } then just grab one out of the map later based on the enum. String appends in sql statements have a way of becoming security problems in the future.  can't you do this: String c;// the name of the column ... String sql = ""select * from table where "" + c + "" = ?""; pre = con.prepareStatement(sql); pre.setString(1 i); rs = pre.executeQuery(); ? If not then this might be a solution: String c;// the name of the column ... String sql = ""select * from table where ('C1' = ? AND C1 = ?) OR ('C2' = ? AND C2 = ?) OR ('C3' = ? AND C3 = ?)"" pre = con.prepareStatement(sql); pre.setString(1 c); pre.setString(2 i); pre.setString(3 c); pre.setString(4 i); pre.setString(5 c); pre.setString(6 i); rs = pre.executeQuery(); I know. I wrote in the question. :) havn't seen the update; I deleted the part about passing col names to a PreparedStatement.  i think it shouldnt be a problem as it works with the position of the placeholder  so this should work if u have the i variable defined above it. pre.setString(1 ""c1""); pre.setString(2 i); should be double quotes around c1  Use a dynamic query and a java.sql.Statement: String whereClause = c + "" = "" + i; // Form the dynamic Query StringBuffer query = new StringBuffer( ""SELECT * FROM TABLE"" ); // Add WHERE clause if any query.append("" WHERE "" + whereClause); // Create a SQL statement context to execute the Query Statement stmt = con.createStatement(); // Execute the formed query and obtain the ResultSet ResultSet resultSet = stmt.executeQuery(query.toString()); just be careful with this because it can lead to sql injection  This won't work. The prepare statement parses the SQL sends to the database for validation and compilation. If question marks could substitute parts of the SQL you would loose the whole point of bound variables - speed and security. You would reintroduce SQL injection back and statements will have to be recompiled for all parameters. Wouldn't something like SELECT * FROM table WHERE c1 = ? OR c2 = ? OR c3 = ? be better (of course depending on indexes and table sizes)."
963,A,"ResultSet: Retrieving column values by index versus retrieving by label When using JDBC I often come across constructs like ResultSet rs = ps.executeQuery(); while (rs.next()) { int id = rs.getInt(1); // Some other actions } I asked myself (and authors of code too) why not to use labels for retrieving column values: int id = rs.getInt(""CUSTOMER_ID""); The best explanation I've heard is something concerning performance. But actually does it make processing extremely fast? I don't believe so though I have never performed measurements. Even if retrieving by label would be a bit slower nevertheless it provide better readability and flexibility in my opinion. So could someone give me good explanation of avoiding to retrieve column values by column index instead of column label? What are pros and cons of both approaches (maybe concerning certain DBMS)? Sure using column names increases readibility and makes maintenance easy. But using column names has a flipside. As you know SQL allows multiple column names with same name there's no guarantee that the column name you typed in the getter method of resultSet actually points to the column name you intend to access. In theory using index numbers instead of column names is preffered but it reduces the readability... Thanks  The JDBC driver takes care for the column to index look-up. So if you extract values by column name each time the driver makes a look-up (usually in hash map) to check the corresponding index for the column name.  From the java documentation: The ResultSet interface provides getter methods (getBoolean getLong and so on) for retrieving column values from the current row. Values can be retrieved using either the index number of the column or the name of the column. In general using the column index will be more efficient. Columns are numbered from 1. For maximum portability result set columns within each row should be read in left-to-right order and each column should be read only once. Of course each method (named or indexed) has its place. I agree that named columns should be the default. However in cases where a huge number of loops are required and where the SELECT statement is defined and maintained in the same section of code (or class) indexes should be ok - it is advisable to list the columns being selected not just ""SELECT * FROM..."" since any table change will break the code.  Besides the look up in Map for labels it also leads to an extra String creation. Though it will happens on stack but still it caries a cost with it. It all depends on the individual choice and till date I have used only indexes :-)  I agree with previous answers that performance is not something that can force us to select either of the approaches. It would be good to consider the following things instead: Code readability: for every developer reading your code labels have much more sense than indexes. Maintenance: think of the SQL query and the way it is maintained. What is more likely to happen in your case after fixing/improving/refactoring SQL query: changing the order of the columns extracted or changing result column names. It seems for me that changing the order of the columns extracted (as the results of adding/deleting new columns in result set) has greater probability to happen. Encapsulation: in spite of the way you choose try to isolate the code where you run SQL query and parse result set in the same component and make only this component aware about the column names and their mapping to the indexes (if you decided to use them).  I did some performance profiling on this exact subject on an Oracle database. In our code we have a ResultSet with numerous colums and a huge number of rows. Of the 20 seconds (!) the request takes to execute method oracle.jdbc.driver.ScrollableResultSet.findColumn(String name) takes about 4 seconds. Obviously there's something wrong with the overall design but using indexes instead of the column names would probably take this 4 seconds away.  The answer has been accepted none-the-less here is some additional information and personal experience that I have not seen put forward yet. Use column names (constants and not literals is preferred) in general and if possible. This is both clearer is easier to maintain and future changes are less likely to break the code. There is however a use for column indexes. In some cases these are faster but not sufficiently that this should override the above reasons for names*. These are very valuable when developing tools and general methods dealing with ResultSets. Finally an index may be required because the column does not have a name (such as an unnamed aggregate) or there are duplicate names so there is no easy way to reference both. *Note that I have written some JDBC drivers and looked inside some open sources one and internally these use column indexes to reference the result columns. In all cases I have worked with the internal driver first maps a column name to an index. Thus you can easily see that the column name in all those cases would always take longer. This may not be true for all drivers though.  I don't think using the labels impacts performance by much. But there is another reason not to use Strings. Or ints for that matter. Consider using constants. Using an int constant makes the code more readably but also less likely to have errors. Besides being more readable the constant also prevents you from making typo's in the label names - the compiler will throw an error if you do. And any IDE worth anything will pick it up. This is not the case if you use Strings or ints. See your point but I don't think this really helps that much. int COLUMN_FIRST_NAME = 13; int COLUMN_SURNAME = 14; could have a bug; maye FIRST name is 14 and SURNAME is 13. And you still have to adjust when columns are added etc. If you must use constants I'd use Strings anyway to avoid this. int constants solve readability problem but previous comment stresses that flexibility problem remains. I also would prefer String constants. But I didn't use constants in examples considering that it would make my point clearer. Rorick I see what you mean and I agree. But using constants solves at least the readability problem. The problem of using the correct int for the column you want is the same in both cases. + for String constants. use an enum instead what happens if you make a typo in the string constant? maybe you should just make each a constant of a constant? that would save you some time debugging errors  You should use string labels by default. Pros: Independence of column order Better readability/maintainability Cons: You have no control over the column names (access via stored procedures) Which would you prefer? ints? int i = 1; customerId = resultSet.getInt(i++); customerName = resultSet.getString(i++); customerAddress = resultSet.getString(i++); or Strings? customerId = resultSet.getInt(""customer_id""); customerName = resultSet.getString(""customer_name""); customerAddress = resultSet.getString(""customer_address""); And what if there is a new column inserted at position 1? Which code would you prefer? Or if the order of the columns is changed which code version would you need to change at all? That's why you should use string labels by default.  Warning: I'm going to get bombastic here because this drives me crazy. 99%* of the time it's a ridiculous micro-optimization that people have some vague idea makes things 'better'. This completely ignores the fact that unless you're in an extremely tight and busy loop over millions of SQL results all the time which is hopefully rare you'll never notice it. For everyone who's not doing that the developer time cost of maintaing updating and fixing bugs in the column indexing are far greater than the incremental cost of hardware for your infinitesimally-worse-performing application. Don't code optimizations like this in. Code for the person maintaining it. Then observe measure analyse and optimize. Observe again measure again analyse again and optimize again. Optimization is pretty much the last step in development not the first. * Figure is made up.  You can have the best of both! The speed of using indexes with the maintainability and security of using column names. First - unless you are looping thru a result set just use column names. Define a set of integer variables one for each column you will access. The names of the variables can include the name of the column: e.g. iLast_Name. Before the result set loop iterate thru the column metadata and set the value of each integer variable to the column index of the corresponding column name. If the index of the 'Last_Name' column is 3 then set the value of 'iLast_Name' to 3. In the result set loop use the integer variable names in the GET/SET methods. The variable name is a visual clue to the developer/maintainer as to the actual column name being accessed but the value is the column index and will give the best performance. NOTE: the initial mapping (i.e. column name to index mapping) is only done once before the loop rather than for every record and column in the loop.  Using the index is an attempt at optimization. The time saved by this is wasted by the extra effort it takes the developer to look up the necessary data to check if their code will work properly after the changes. I think it's our built-in instinct to use numbers instead of text."
964,A,"sql jdbc getgeneratedkeys returns column ""id"" not found column type unknown I want to retrieve the most recently updated value in the table using an insert query. these are the datatypes in my sql table. Datatype: int(11) // primary key auto increment not being assigned by sqlQuery varchar(30) timestamp // has a default value. but i am explicit assigning it using CURRENT_TIMESTAMP varchar(300) varchar(300) varchar(300) int(11) varchar(300) java code  statement.executeUpdate(sqlQuery Statement.RETURN_GENERATED_KEYS); ResultSet rs = statement.getGeneratedKeys(); System.out.println(""here: "" + rs.getMetaData().getColumnCount()); System.out.println(""here1: "" + rs.getMetaData().getColumnName(1)); // none of the following 3 works System.out.println(""id: "" + rs.getInt(1)); System.out.println(""id: "" + rs.getInt(""GENERATED_KEY"")); System.out.println(""id: "" + rs.getInt(""id"")); for a bit of background see [this][1] `rs.getMetaData().getColumnTypeName(1)` tells me column type `UNKNOWN` stack trace  SEVERE: null java.sql.SQLException at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1055) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:926) at com.mysql.jdbc.ResultSetImpl.checkRowPos(ResultSetImpl.java:815) at com.mysql.jdbc.ResultSetImpl.getStringInternal(ResultSetImpl.java:5528) at com.mysql.jdbc.ResultSetImpl.getString(ResultSetImpl.java:5448) [1]: http://stackoverflow.com/questions/2853066/sql-java-get-value-assigned-to-auto-increment-primary-key What version of MySQL and of the MySQL connector are you using? is the question unclear? You need to call rs.next(): int autoIncKeyFromApi = -1; rs = stmt.getGeneratedKeys(); if (rs.next()) { autoIncKeyFromApi = rs.getInt(1); } else { // do what you have to do } System.out.println(autoIncKeyFromApi); i was trying several combinations. not this one! That's right but I would however put that inside an `if` block. Also see [this answer](http://stackoverflow.com/questions/1915166/jdbc-how-can-we-get-inserted-record-id-in-java/1915197#1915197). @BalusC you're absolutely right. Fixed. @PascalThivent can you please explain why do we need rs.next() in here?  Maybe it's because that the sqlQuery doesn't create any new record! In this case it will return an empty ResultSet Look at the specification of getGeneratedKeys()"
965,A,"help in setting Client Info in JDBC for Oracle hello everybody i have an issue cause i have a java an application which needs to be audited so obviously i need a way in which the app can be identified with the application name so i googled and found that the ojdbc14 has the method .setClientInfo which allows to register the application with a customized name so i am trying to get it work but got the following error: *Exception in thread ""main"" java.lang.AbstractMethodError: oracle.jdbc.driver.T4CConnection.setClientInfo(Ljava/lang/String;Ljava/lang/String;)V * am using ojdbc14 with oracle 10g express if i do not set the line : connection.setClientInfo(""ApplicationName""""Customers""); it works pretty well ....AND by checking the audit info i can see that oracle gets the application name:OS_program_name=JDBC Thin Client but i need a way to change it for a customized name.- By uncommenting that line which is supposed to set the application name it returns the error above.- per oracle documentation that method is available for a Connection object  do you have any idea about how to solve this issue? thanks in advanced.- For AbstractMethodError please check http://stackoverflow.com/questions/1194990/why-do-i-get-java-lang-abstractmethoderror-when-trying-to-load-a-blob-in-the-db In order to distinguish your connections in Oracle you can use this sample code below: Properties jdbcProperties = new Properties(); this.jdbcProperties.put(""user"" userName); this.jdbcProperties.put(""password"" password); this.jdbcProperties.put(""v$session.program"" ""YourApplicationName""); DriverManager.getConnection(url jdbcProperties); then check v$session by grouping against program column for your connections.. Glad to hear that it worked. One more thing though this code won't work when you're using oci urls to connect to your Oracle db. It works for just thin urls I don't understand Oracle about this. At this point you may use DBMS_APPLICATION_INFO package to set module name and action to trace your applications. i really appreciate your help man this was really helpful to me...i applied the lines you gave me and it works fine....thanks a lot sincerely."
966,A,"statement.execute() returns error with Slash at the end of PL/SQL When executing pl/sql im obtaining an error : ORA-06550: line 1 column 316: PLS-00103: Encountered the symbol ""/"" The symbol ""/"" was ignored. PLSQL example: DECLARE SQL1 VARCHAR2 (1500); SQL2 VARCHAR2 (1500); BEGIN SQL1 := 'INSERT INTO das_html_caption VALUES (''test_test'')'; SQL2 := 'DELETE FROM das_html_caption where wording = ''test_test'''; EXECUTE IMMEDIATE SQL2; EXECUTE IMMEDIATE SQL1; EXECUTE IMMEDIATE SQL2; COMMIT; END; / Java: Statement statement = dbConnection.createStatement(); ResultSet rs = null; boolean ret = statement.execute( sql.getValue() ); is it correct error ? or i'm doing something wrong ? Thanks The slash is how you execute the anonymous block through an interactive environment such as SQL*Plus. If you are executing this block by a call from Java you don't need the terminating slash.  Found answer. Had to made more complcated request to google :) As the message indicates the compiler doesn't want to encounter the symbol ""/"" so just remove it. That simple. Let me explain. When using sqlplus or an SQL worksheet in sqldev you do well appending your PL/SQL blocks with the slash. However when using the procedure editor (native to sqldev) you'll have to remove it. Don't know why they made this set of rules but until they relax them we'll have to obey them ;-) http://forums.oracle.com/forums/thread.jspa?threadID=519670"
967,A,"Performance comparison of JDBC connection pools Does anyone have any information comparing performance characteristics of different ConnectionPool implementations? Background: I have an application that runs db updates in background threads to a mysql instance on the same box. Using the Datasource com.mchange.v2.c3p0.ComboPooledDataSource would give us occasional SocketExceptions: com.mysql.jdbc.CommunicationsException: Communications link failure due to underlying exception: ** BEGIN NESTED EXCEPTION ** java.net.SocketException MESSAGE: Broken pipe STACKTRACE: java.net.SocketException: Broken pipe at java.net.SocketOutputStream.socketWrite0(Native Method) Increasing the mysql connection timeout increased the frequency of these errors. These errors have disappeared on switching to a different connection pool (com.mysql.jdbc.jdbc2.optional.MysqlConnectionPoolDataSource); however the performance may be worse and the memory profile is noticeably so (we get fewer and much larger GC's than the c3p0 pool). You may want to have a look at some benchmark numbers up at http://jolbox.com - the site hosting BoneCP a connection pool that is faster than both C3P0 and DBCP.  Have you tried Apache DBCP? I don't know about c3po but DBCP can handle idle connections in different ways: It can remove idle connections from the pool It can run a query on idle connections after a certain period of inactivity It can also test if a connection is valid just before giving it to the application by running a query on it; if it gets an exception it discards that connection and tries with another one (or creates a new one if it can). Way more robust. Unless a lot has changed in DBCP since we stress tested it judging by this http://commons.apache.org/dbcp/changes-report.html no we found DBCP to significantly inferior in performance and handling terms. Have you looked into Proxool? can you elaborate on that? I looked briefly at Proxool and it wasn't clear that it was up-to-date but other than that I'm unfamiliar with it. Can you post more details about your experience as a complete answer? @Steve: DBCP is singlethreaded not multithreaded.  I had this error pop up with mysql & c3p0 as well - I tried various things and eventually made it go away. I can't remember but what might have solved it was the autoReconnect flag a la url=""jdbc:mysql://localhost:3306/database?autoReconnect=true"" 100 try this - Since mysql is closing connections by timeout this prob pings your db every once and a while to keep the connection alive. Thanks I did find references to this although it didn't solve my problem. +1  Whatever connection pool you use you need to assume that the connection could be randomly closed at any moment and make your application deal with it. In the case with a long-standing DB connection on a ""trusted"" network what often happens is that the OS applies a time limit to how long connections can be open or periodically runs some ""connection cleanup"" code. But the cause doesn't matter too much -- it's just part of networking life that you should assume the connection can be ""pulled from under your feet"" and deal with this scenario accordingly. So given that I really can't see the point of a connection pool framework that doesn't allow you to handle this case programmatically. (Incidentally this is another of my cases where I'm glad I just write my own connection pool code; no black boxes mysteriously eating memory and no having to fish around to find the ""magic parameter""...)  Broken pipe That roughly means that the other side has aborted/timedout/closed the connection. Aren't you keeping connections that long open? Ensure that your code is properly closing all JDBC resources (Connection Statement and ResultSet) in the finally block. Increasing the mysql connection timeout increased the frequency of these errors. Take care that this timeout doesn't exceed the DB's own timeout setting."
968,A,"Recommendation for JDBC SQL client tool Can someone recommend a good open source standalone developer tool for querying SQL databases using JDBC and exporting the results to a file? I know a lot of database vendors provide their own tools but I need one that will allow me to plug in my own custom JDBC driver and work against any database. A GUI is preferable but not required. Oracle's SQL Developer is disqualified because it seems to work only with a pre-canned set of JDBC drivers. I have also looked at the list of tools at Java-Source.net but I'm hoping someone can help me narrow down the list based on personal experience. And it needs to be standalone so non-developers can use it too which disqualifies Eclipse plug-ins. Thanks! Any particular reason to not use the export feature in PLSQL Developer? As I said I can't get SQL Developer to work with my custom driver. Are you specifically looking for GUI tools? Check this http://www.heidisql.com/ It is much faster than SQuirrel SQL.  henplus is worth trying out - its a command line jdbc client. I've used it to create production apps  I use SQuirreL SQL and I'm pretty happy with it. I'm pasting the ""Overview"" below: SQuirreL SQL Client is a graphical Java program that will allow you to view the structure of a JDBC compliant database browse the data in tables issue SQL commands etc see Introduction. The minimum version of Java supported is 1.6.x as of SQuirreL version 3.0. See the Old Versions page for versions of SQuirreL that will work with older versions of Java. SQuirreL's functionality can be extended through the use of plugins. A short introduction can be found here. To see the change history (including changes not yet released) click here. For a more detailed introduction see the English or German of our paper on SQuirreL. Susan Cline graciously took the time to document the steps she followed to setup an Apache Derby database from scratch and use the SQuirreL SQL Client to explore it. Quite some time ago Kulvir Singh Bhogal wrote a great tutorial on SQuirreL and published it at the IBM developerWorks site. He has kindly allowed us to mirror it locally. The tutorial is not really up to date but especially for doing the first steps it is still of help. SQuirrel was originally released under the GNU General Public License. Since version 1.1beta2 it has been released under the GNU Lesser General Public License. It's maybe not the most nice looking application but it does its job and pretty fast: add or configure your driver create an alias and there you go. Actually it's my favorite Universal SQL Client. This works perfectly. Thank you! +1 for SQL Squirrel. I think it's terrific. Am I in the minority that thinks SQL Squirrel is just plain awful? It runs like maple syrup on my 8 core 16GB SSD machine takes forever to open hangs all the time and the maximize button goes full screen?? Really? If only HeidiSQL could connect to DB2 then I would be much happier.  I'd like to throw in a vote for DbVisualizer. DB Visualizer isn't open source but it has a free version. Ah I missed the ""open source"" condition. Hopefully freeware is good enough though! For anything but the most basic functionality you need the commercial version and the price on that has continued to ratchet up over and over as time wears on. I understand their need to make money and in a business environment where the pockets are deeper it's an excellent tool. For individuals who are working open source or hobby programming you'll probably need to look elsewhere.  I'd agree with Pascal about SQuirrel SQL that does the job for almost everything. However if I remember rightly its support for SQL triggers is lacking - it couldn't display the source code of the trigger at least in the version I was using (3.0.2) For this scenario I found the free (but not open-source) SQL Workbench does the job which in itself is a more than decent tool. If I'm not working with triggers though I'd recommend using SQuirrel SQL Giving an upvote for SQL Workbench it's the best SQL UI I've used to date. Rock solid stable fast and loads of attention to detail. Regarding the license it seems to be open source for most practical interpretations of the term but does use a non standard license. +1 for SQL Workbench."
969,A,"com.mysql.jdbc.exceptions.jdbc4.CommunicationsException when using JDBC to access remote MySQL database /** * */ package ORM; import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; /** * @author Gwilym * @version 0.0 */ public class DatabaseConnection { private String userName=""""; private String password=""""; private String host=""""; Connection conn; /** * @param userName * @param password * @param host */ public DatabaseConnection(String userName String password String host) { this.userName = userName; this.password = password; this.host = host; } public DatabaseConnection(String userName String password String hostboolean autoConnect) { this.userName = userName; this.password = password; this.host = host; if (autoConnect) { try { Connect(); } catch (DatabaseConnectionException e) { e.printStackTrace(); } } } /** * @return the connection */ public Connection getConn() { return conn; } /** * @param userName the userName to set */ public void setUserName(String userName) { this.userName = userName; } /** * @param password the password to set */ public void setPassword(String password) { this.password = password; } /** * @param host the host to set */ public void setHost(String host) { this.host = host; } /** * Connect attempts to connect to the MySQL database * with sun JDBC * & MySQL driver * @param none * @return True iff connected; * @return False for all else; * @throws DatabaseConnectionException */ public boolean Connect() throws DatabaseConnectionException { // Attempt to load database driver try { String url = ""jdbc:mysql:""+host; System.out.println(url); //Load driver Class.forName (""com.mysql.jdbc.Driver"").newInstance (); conn = DriverManager.getConnection (url userName password); } catch (ClassNotFoundException cnfe) // driver not found { conn=null; System.err.println (""Unable to load database driver""); throw new DatabaseConnectionException(cnfe); } catch(InstantiationException ie) { conn=null; System.err.println (""Unable to Create database driver""); throw new DatabaseConnectionException(ie); } catch (IllegalAccessException iae) { conn=null; System.err.println (""Unable to Create database driver""); throw new DatabaseConnectionException(iae); } catch (SQLException sqle) { conn=null; System.err.println (""SQL error""); throw new DatabaseConnectionException(sqle); } if (conn!=null) { System.out.println (""Database connection established""); return true; } else { System.out.println (""Database connection Failed""); return false; } } /** * Disconnects the System from the mySQL database * * @param none * @return true if successful * @return false if not connection in existance */ public boolean Disconnect() { if (conn != null) { try { conn.close (); conn=null; System.out.println (""Database connection terminated normally""); return true; } catch (Exception e) { //Ignore these errors as they all result in conn.close anyway } finally { conn=null; System.gc(); // my removing the refrance to conncetion all calling the Garbage collecter we insure it is destoryed. } System.out.println (""Database connection terminated with errors""); return true; } else { System.out.println (""No Database connection present""); return true; } } } The above code is called by DatabaseConnection db =new DatabaseConnection(""USERNAME""""PASSWORD""""//tel2.dur.ac.uk:3306/dcs8s07_SEG""true); for obvious reasons I have removed the user name and password  but they can be aassumed to be correct. Right down to the problem its self I get a com.mysql.jdbc.exceptions.jdbc4.CommunicationsException when ever this code is run with the details ""The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server."" My main problem at the moment is trying to discover what is actually going wrong. In so far as I can tell the driver is being loaded correctly as my code does not throw a ClassNotFoundException rather a SQLException of some kind. So the problem is almost certainly the connection in some way. I can connect and query this database though a phpMyadmin located on the same server so I can assume that 1)The server is online 2)mySQL is working 3)the Username and password are correct 4) the database is present and i have the name correct From this and ""The driver has not received any packets from the server."" I am wondering if the URL malformed? URL= jdbc:mysql://tel2.dur.ac.uk:3306/dcs8s07_SEG or there a simple setting that is incorrect on the server whihc is not allowing me to connect? I have pondered on this problem and attempted several googles to no avail so any idea would be of great help thanks in advance SO! In addition to the last post you should also do a low-level telnet test this is the best way to verify connectivity. This test will tell you if there is a firewall or other software blocking access to that port. telnet tel2.dur.ac.uk 3306 I get some some what intresting results I pinged it and got C:\Users\Panda>ping tel2.dur.ac.uk Pinging tel2.dur.ac.uk [129.234.200.251] with 32 bytes of data: Request timed out. Request timed out. Request timed out. Request timed out. Ping statistics for 129.234.200.251: Packets: Sent = 4 Received = 0 Lost = 4 (100% loss) but I can still acess the phpMyadmin over http the telnet tel2.dur.ac.uk 3306 command did't work when I popped it into cmd Then it sounds like the port is blocked do you have control over this host and the firewalls that surround it? just shh'd into a sever on the same network and pinged it so looked like it was my firewall but I turned off the windows which is the only on I have and still get the same exception After you turned the firewall off did the telnet connection work? If so load up mysql command line tool and try connecting with that. If that works then you know the problem is with your configuration and not with your network. Hey James thanks for all your help After turning off my firewall I still cannot Ping or telnet from from my computer but can from the server I shh into I am emailing the people in charge of the server to see if imn being block from that end.  This is a wrapped exception. What's the root cause of this exception? Look further in the stacktrace. A very common root cause is java.net.ConnectException: Connection refused. I've seen this in almost 99% of the cases. If this is true in your case as well then all the possible causes are: IP address or hostname in JDBC URL is wrong. Hostname in JDBC URL is not recognized by local DNS server. Port number is missing or wrong in JDBC URL. DB server is down. DB server doesn't accept TCP/IP connections. Something in between Java and DB is blocking connections e.g. a firewall or proxy. To solve the one or the either follow the following advices: Verify and test them with ping. Refresh DNS or use IP address in JDBC URL instead. Verify it based on my.cnf of MySQL DB. Start it. Verify if mysqld is started without the --skip-networking option. Disable firewall and/or configure firewall/proxy to allow/forward the port. The username and password are irrelevant in this problem. At this point the DB can't even be reached. You would have gotten a ""Login failed"" or ""Not authorized"" SQLException otherwise. Hey Balaus I have something very close Caused by: java.net.ConnectException: Connection timed out: connect Connection timed out usu. indicates that the firewall is blocking communication. hey argherna which end do you think? my computer or the server? just shh'd into a sever on the same network and pinged it so looks like its my firewall of all the bloody things turned my firewall off still no joy sigh `Connection timed out` is less or more the same. Follow the same advice. @JMac: don't forget to `close()` all resources you openened such as `Connection` `Statement` `ResultSet` `FileInputStream` `FileOutputStream` etc. They should be `close()`d in the `finally` block of the very same `try` block as you created them. I've just encountered this problem and the wrapped exception is: Caused by: java.net.SocketException: Too many open files"
970,A,"How to use the update statement in my jsp I am having an update statament in my jsp. The problem is that when I am changing the whole fields in the jsp and executed the update statament the DB will be updated but when I am updating a certain field the other fields will be """" in the SQL statement. Also I am having a problem is that I am having a miss match in the date so what is the best format to be applied in the SQL statement in my jsp. FOr the first problem: HTML Code: <select size=""1"" name=""Nationality"" class=""content""> <option selected value=""<%=Nationality%>""><%=Nationality%></option> <% try { ResultSet rs=null; Statement st1=null; String query = ""select country_code nationality_name from nationality_lkup ""; st1 = conn1.createStatement(); rs = st1.executeQuery(query); while(rs.next()) { %> <option value=""<%=rs.getString(""country_code"")%>"" > <%=rs.getString(""nationality_name"")%></option> <% } } catch (Exception e) { e.printStackTrace(); } %> </select> and the update statament is: String sz_SQLUpdate = ""UPDATE cir SET""; z_SQLUpdate = sz_SQLUpdate + ""  nationality ='""+Nationality+""'""; Also how can I deal with the date format in the update statement? but when I am updating a certain field the other fields will be """" in the SQL statement. I am not sure if this is the complete code (the SQL shown as far would have produced a SQL syntax exception when executed) but you should at least not put a comma between SET and the first column name. If the SQL is actually syntactically valid then it may simply mean that those variables are empty at the moment you access them to inline in the SQL statement. You should either prefill those variables or just leave the associated columns away from the SQL query if those don't need to be updated. Also I am having a problem is that I am having a miss match in the date so what is the best format to be applied in the SQL statement in my jsp. The best approach is to not worry about the format and just set a fullworthy Java object representing a timestamp in the SQL statement using PreparedStatement#setTimestamp(). Also see this recent question. That said you have two major problems in the code. Raw Java code in JSP files should be avoided. It only leads to trouble in all colors not only for you but also for others now and in the future. This SQL is sensitive to SQL injection attacks and the JDBC code is prone to resource leaking. It's going to be a long story to explain how to do things properly so here are just a few links to go through carefully yourself so that you get the picture how to do things properly. Beginning and intermediate JSP/Servlet tutorials How to avoid Java code in JSP files JSP/Servlet best practices Using prepared statements in JDBC You should probably throw away that old fashioned JSP tutorial/book you're currently reading."
971,A,"PreparedStatement and setTimestamp in oracle jdbc I am using PreparedStatement with Timestamp in where clause: PreparedStatement s=c.prepareStatement(""select valueutctimestamp from t where utctimestamp>=? and utctimestamp<?""); s.setTimestamp(1 new Timestamp(1273017600000L)); //2010-05-05 00:00 GMT s.setTimestamp(2 new Timestamp(1273104000000L)); //2010-05-06 00:00 GMT ResultSet rs = s.executeQuery(); if(rs.next()) System.out.println(rs.getInt(""value"")); The result I get is different when I have different time zones on the client computer. Is this a bug in Oracle jdbc? or correct behavior? Oracle database version is 10.2 and I have tried with oracle jdbc thin driver version 10.2 and 11.1. The parameter is Timestamp and I expected that no time conversions will be done on the way. The database column type is DATE but I also checked it with TIMESTAMP column type with the same results. Is there a way to achieve correct result? I cannot change default timezone in the the whole application to UTC. Thanks for your help Please edit your question and add the types of t_begin and t_end. To set a timestamp value in a PreparedStatement in UTC timezone one should use stmt.setTimestamp(1 t Calendar.getInstance(TimeZone.getTimeZone(""UTC""))) The Timestamp value is always UTC but not always the jdbc driver can automatically sent it correctly to the server. The third Calendar parameter helps the driver to correctly prepare the value for the server. Actually it is: setTimestamp(int parameterIndex Timestamp x Calendar cal)"
972,A,Skipping ahead to a specific JDBC Record Number What is the best way to skip ahead to a specific record number in a Java JDBC resultset? You can use ResultSet#absolute() for this. Whether it works depends on the JDBC driver used however. But a new question would rise: why don't you just let the SQL query return only the particular row of interest? That would have been much more efficient than moving the cursor forth and back. Or if you're interested in any of the rows but only wanted to get the particular row better map the ResultSet to a List<Data> so that you can use List#get(). I need to get rows X through Z from A through Z out of a large dataset so a list or using absolute and working from there are great answers. thanks Keep in mind that this may be memory hogging. There's no need to duplicate the entire database contents into Java's heap memory if you only wanted the last few rows. Better fire a more specific SQL query everytime. Especially if the total rowcount gets into thousands. The only improvement I can make on this database migration script is by performing a limit from X to Z since I need all of the data (a full index scan is required). Thanks for the helpful information though I'm watching it slowly go from 1000 records/min of insertion to about 10.
973,A,"Is this use of PreparedStatements in a Thread in Java correct? I'm still an undergrad just working part time and so I'm always trying to be aware of better ways to do things. Recently I had to write a program for work where the main thread of the program would spawn ""task"" threads (for each db ""task"" record) which would perform some operations and then update the record to say that it has finished. Therefore I needed a database connection object and PreparedStatement objects in or available to the ThreadedTask objects. This is roughly what I ended up writing is creating a PreparedStatement object per thread a waste? I thought static PreparedStatments could create race conditions...  Thread A stmt.setInt(); Thread B stmt.setInt(); Thread A stmt.execute(); Thread B stmt.execute(); A´s version never gets execed.. Is this thread safe? Is creating and destroying PreparedStatement objects that are always the same not a huge waste? public class ThreadedTask implements runnable { private final PreparedStatement taskCompleteStmt; public ThreadedTask() { //... taskCompleteStmt = Main.db.prepareStatement(...); } public run() { //... taskCompleteStmt.executeUpdate(); } } public class Main { public static final db = DriverManager.getConnection(...); } Do not store the connection Get the connection when you need it. If you need bettr performance use a connection pool. AS Thilo said below do not share stuff between Threads. I believe it is not a good idea to share database connections (and prepared statements) between threads. JDBC does not require connections to be thread-safe and I would expect most drivers to not be. Give every thread its own connection (or synchronize on the connection for every query but that probably defeats the purpose of having multiple threads). Is creating and destroying PreparedStatement objects that are always the same not a huge waste? Not really. Most of the work happens on the server and will be cached and re-used there if you use the same SQL statement. Some JDBC drivers also support statement caching so that even the client-side statement handle can be re-used. You could see substantial improvement by using batched queries instead of (or in addition to) multiple threads though. Prepare the query once and run it for a lot of data in a single big batch. +1 I'll agree to that !!!  The threadsafety is not the issue here. All looks syntactically and functionally fine and it should work for about half a hour. Leaking of resources is however the real issue here. The application will crash after about half a hour because you never close them after use. The database will in turn sooner or later close the connection itself so that it can claim it back. That said you don't need to worry about caching of preparedstatements. The JDBC driver and the DB will take care about this task. Rather worry about resource leaking and make your JDBC code as solid as possible. public class ThreadedTask implements runnable { public run() { Connection connection = null; Statement statement = null; try { connection = DriverManager.getConnection(url); statement = connection.prepareStatement(sql); // ... } catch (SQLException e) { // Handle? } finally { if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } } } To improve connecting performance make use of a connection pool like c3p0 (this by the way does not mean that you can change the way how you write the JDBC code; always acquire and close the resources in the shortest possible scope in a try-finally block). Look at Apache Commons DBUtils for a light-weight wrapper that takes care of all the try/catching. We can also just use JPA. More convenient can't it be.  You're best to use a connection pool and get each thread to request a connection from the pool. Create your statements on the connection you're handed remembering to close it and so release it back to the pool when you're done. The benefit of using the pool is that you can easily increase the number of available connections should you find that thread concurrency is becoming an issue."
974,A,"JDBC query returning no rows but interactive query does? I'm attempting to retrieve data from a SolarWinds network performance database (MS SQL 2005) and a query that works perfectly fine interactively (in the Orion database manager) returns no rows when run via JDBC. Any ideas? The query itself is a shocker (I dislike MS-SQL date/time handling which I believe forces queries like this for joins by date/hour). I can cut and paste the query output by println and it works fine yet in my program it returns no rows (but throws no exceptions). I assume that query complexity doesn't matter on the basis that JDBC will not attempt to parse the query - it will just pass it through to the back end. String qtext = new String(""select rd.nodeid rd.hr rd.response rd.loss cd.cpu cd.mem bd.nomem bd.smmiss bd.mdmiss bd.bgmiss bd.lgmiss bd.hgmiss"" + "" from"" + "" (select nodeid DATEPART(hh DateTime) as hr round(avg(AvgResponseTime) 0) as response round(avg(PercentLoss) 0) as loss"" + "" from ResponseTime_Detail"" + "" where DateTime >= "" + today + "" and DateTime < "" + tomorrow + "" group by nodeid DATEPART(hh DateTime)"" + "" ) as rd"" + "" left outer join"" + "" (select nodeid DATEPART(hh DateTime) as hr round(avg(AvgLoad) 0) as cpu bound(avg(AvgPercentMemoryUsed) 0) as mem"" + "" from CPULoad_Detail"" + "" where DateTime >= "" + today + "" and DateTime < "" + tomorrow + "" group by nodeid DATEPART(hh DateTime)"" + "" ) as cd"" + "" on rd.nodeid = cd.nodeid and rd.hr = cd.hr"" + "" left outer join"" + "" (select nodeid DATEPART(hh DateTime) as hr round(avg(BufferNoMem) 0) as nomem round(avg(BufferSmMiss) 0) as smmiss round(avg(BufferSmMiss) 0) as mdmiss"" + "" round(avg(BufferBgMiss) 0) as bgmiss round(avg(BufferLgMiss) 0) as lgmiss round(avg(BufferHgMiss) 0) as hgmiss"" + "" from CiscoBuffers_Detail"" + "" where DateTime >= "" + today + "" and DateTime < "" + tomorrow + "" group by nodeid DATEPART(hh DateTime)"" + "" ) as bd"" + "" on rd.nodeid = bd.nodeid and rd.hr = bd.hr"" + "" order by rd.nodeid rd.hr;""); System.out.println(""Query from hell = ["" + qtext + ""]""); st = sol.db.createStatement(); System.out.println(""Created statement""); rs = st.executeQuery(qtext); System.out.println(""Executed statement""); while (rs.next()) { .... } Thanks all for your suggestions. I believe the issue was with interpretation of dates/times. I used a PreparedStatement as suggested and the query then worked. If it is working now then the best thing to do is to accept the closest answer. In your case you should accept an answer which suggested you to use PreparedStatement. Otherwise folks would try to give you an answer but you already resolved the thing. Save them time please. You could try running through SQuirrel SQL (http://squirrel-sql.sourceforge.net/) to rule out any jdbc issues. JDBC syntax does not terminate the SQL statement with a semi-colon. The line adding the last clause to the SQL string should read: "" order by rd.nodeid rd.hr""); SQL Server with the jtds driver returns a valid result set even with a trailing semicolon. You can even put valid SQL after the semicolon and it will still give you the result set for the first query. Invalid SQL after the semicolon causes an error. It turns out that Mike's problem was something else but here's some more on the semicolon. I believe that the semicolon is not technically part of the SQL statement. It is a statement terminator or separator commonly used by command line interfaces. The JDBC 4.0 specification doesn't mention the semicolon but doesn't include one in its example SQL. I've used both Oracle and SQLServer. Oracle gives an error: ORA-00911 invalid character My theory is that SQL Server returns an empty result set because the SQL string contains two statements and the last is empty. I'm not sure on this. Good point but it should be noted that accepting the terminating semicolon is dependent on the JDBC driver. If his doesn't it would indeed explain the cause of the problem. I have never worked with MSSQL but if I recall correctly the MySQL JDBC driver doesn't accept it while the Oracle and PostgreSQL ones did. Not sure about DB2 it's been too long ago I used DB2 for last time. I tried with and without semicolon with no change. I also tried a simpler query with the same symptoms select nodeid DATEPART(hh DateTime) as hr round(avg(AvgResponseTime) 0) as response round(avg(PercentLoss) 0) as loss from ResponseTime_Detail where DateTime >= '2009-11-03' and DateTime < '2009-11-04' group by nodeid DATEPART(hh DateTime); The DB connection is valid (i.e. isValid(10) return true) but I expect the answer is something to do with the connection  As to your query dates/timestamps are to be set using PreparedStatement#setDate()/setTimestamp(). Not only to avoid SQL injections but also to prevent from formatting mistakes in the String representation of the Date."
975,A,"Closed Cursors - SQL Best Practice I work in a large separated development team. The project I'm currently working on has an Oracle DB team that develops the stored procedures and other related components that our J2EE web-tier talks to. One thing that's arisen from development is the concept of a closed cursor when results aren't found. From my experience closed cursors signifies an exceptional circumstance; a programming error that isn't necessarily data related. In the current context it is to signify that no data has been found when an empty result set/cursor would make more sense to me. What do people think or have experience with from their perspective? Any Oracle SQL developers here that could shed the light should I be wrong from a conventional perspective? Best practices? Cheers! I'm with you. Returning an empty resultset makes the most sense to me. It is all about separation of concerns. Data retrieval is a service. Whereas handling NO_DATA_FOUND exceptions belongs to the calling application. edit I would expect to find cursor%NOTFOUND in a PL/SQL procedure which processes a ref cursor. For instance a PAYROLL routine might make use of a function in the SALES subsystem which returns a ref cursor of all the orders taken by salesmen (in a given department for a given quarter whatever). I would expect the PAYROLL routine to cycle through the returned result set and check for cursor%NOTFOUND. I would not expect the SALES function to do that and return an empty cursor if there are not no matching salesmen. Apart from violating the Principle of Least Surprise it also means either the retrieving function is doing more work (opening the ref cursor twice) or it is returning the wrong results. SQL> create function get_emps(dno number) return sys_refcursor is 2 rc sys_refcursor; 3 begin 4 open rc for select * from emp where deptno = dno; 5 return rc; 6 end; 7 / Function created. SQL> var rc refcursor SQL> SQL> exec :rc := get_emps(10) PL/SQL procedure successfully completed. SQL> print rc EMPNO ENAME JOB MGR HIREDATE SAL COMM DEPTNO ----- ---------- --------- ---------- ---------- ---- ---- ------ 7782 BOEHMER MANAGER 7839 09-06-1981 2450 10 7839 SCHNEIDER PRESIDENT 17-11-1981 5000 10 7934 KISHORE CLERK 7782 23-01-1982 1300 10 SQL> SQL> create or replace function get_emps(dno number) return sys_refcursor is 2 rc sys_refcursor; 3 lrow emp%rowtype; 4 begin 5 open rc for select * from emp where deptno = dno; 6 fetch rc into lrow; 7 if rc%notfound then 8 close rc; 9 end if; 10 return rc; 11 end; 12 / Function created. SQL> exec :rc := get_emps(15) PL/SQL procedure successfully completed. SQL> print rc ERROR: ORA-24338: statement handle not executed SP2-0625: Error printing variable ""rc"" SQL> exec :rc := get_emps(10) PL/SQL procedure successfully completed. SQL> print rc EMPNO ENAME JOB MGR HIREDATE SAL COMM DEPTNO ----- ---------- --------- ---------- ---------- ---- ---- ------ 7839 SCHNEIDER PRESIDENT 17-11-1981 5000 10 7934 KISHORE CLERK 7782 23-01-1982 1300 10 SQL> Thanks. Can you think of an example where Cursor not found might be appropriate?"
976,A,Should JDBC connection handles be per-app per-thread or per-query? Let's say we've got a web application or web service on an application server supporting JDBC connection pooling. Should I be grabbing a new Connection on a per-thread or per-query basis? Thanks! per-thread Each new request will grab a new connection (new thread = new request). There is no need for getting a new connection for each query as after each query the connection can be reused. Thanks! +1 for clarity :)  Hopefully you are grabbing them on a per-transactional-unit-of-work basis. Per query implies that you never have any logical unit of work in your system that spans more than a single query. (Maybe that's true but you still might want to think about the future!) Per-thread (which I assume to mean request-scoped rather than for the entire life of the thread?) will probably result in holding them for longer than absolutely necessary but it does allow you to manage transactions much better. (and it's how plenty of leading frameworks have worked or did work for a long time. A pattern known as Open Entity Manager In View if you'd like to do some google-fu on it) Assigning it indefinitely to a single thread means your max number of active request processors is capped at the max size of your database pool which is a definite failure in scalability. Thank you! +1 and accepted
977,A,P6spy doesn't spy on hsql jdbc driver When trying to spy on the jdbc connection to a hsqldb database it doesn't work. It looks like the org.hsqldb.jdbcDriver is not deregistered. The solution is to deregister both drivers registered by hsqldb.jar. In spy.properties you should have realdriver=org.hsqldb.jdbcDriver realdriver2=org.hsqldb.jdbc.JDBCDriver deregisterdrivers=true
978,A,"Is JDBC a big memory hog? I need to access (read in) data repeatedly from a database in my java codes and therefore adopted JDBC. However it seems to me that using JDBC takes up a lot of memory. I tried to be careful about closing the objects created for JDBC (ResultSet Statemenet) but still it seems to hog a lot of memeory especially compared to reading in input from a textfile. Does anybody know the best way to reduce memeory consumption? Thanks. How much is ""a lot"" how much data do you process and what do you do with the data you get back from queries ? Even if JDBC were a memory hog... what choice do you have? It's the main Java database library and all the DB abstraction layers use it. It is very unlikely that 'JDBC' is a memory hog. JDBC is just a pipe. The amount of memory used will depend on what database you are talking to and more importantly what sort of queries you are running and whether you are using cursors correctly. You might look at Hibernate for help in managing memory usage when working with large amounts of data. Can you explain how hibernate would use less memory than raw JDBC? Level 2 cache? @Sam Barnum: See the section Fetching Strategies on this page: http://docs.jboss.org/hibernate/core/3.3/reference/en/html/performance.html That would be the first time that I hear someone advocating Hibernate over JDBC to improve memory footprints... Since Hibernate builds upon JDBC it can only perform as well as JDBC itself. Or am I missing something? The OP is probably fetching some gargantuan ResultSet all at once instead of using cursors or other incremental techniques. Hibernate is one library that embodies strategies for incremental retrieval. @LukasEder. It can use JDBC sensibly as could the OP.  I would like to add an important point here after running into memory problems myself: I was reading large datasets from a MySQL database (about 600000 rows of 20 columns) and kept running out of heap space. I thought I could fix it by changing the fetch size but setting the fetch size on the PreparedStatement did nothing. What I discovered was that the MySQL JDBC driver I was using (version 5.1.15) doesn't implement fetch sizes. In fact for every MySQL query it loads the entire ResultSet into memory. However if you set the fetch size to Integer.MIN_VALUE then the driver will load 1 row at a time from the MySQL server....with one caveat: you cannot execute any other statements on the connection until the ResultSet is closed. It's documented here: http://dev.mysql.com/doc/refman/5.0/en/connector-j-reference-implementation-notes.html That being said if you have control over your MySQL server you can set the 'useCursorFetch' to true and the server will return the 'defaultFetchSize' number of rows instead of all of them. This is true as of version 5.0.2 of MySQL. The developer claims it's an experimental hack though so be warned: http://forums.mysql.com/read.php?39137457137457#msg-137457 Anyway moral of the story here is to check the JDBC driver your using for any peculiarities.  Its more a factor of the data you are loading than the JDBC library. Since JDBC calls involve a lot of data I'd check that you don't have a lot of objects sitting around in a collection that isn't being released and making it to the generation 2 of the heap.  JDBC is not a memory hog. The data it returns can be a huge memory hog. One common problem with JDBC is that the result sets which contain the huge amount of data (and are not always memory optimized) are not handled or closed correctly. In order to prevent memory leaks from ResultSet object lying around the developer must take careful steps to make sure the memory is released before moving on. (Java handling most memory clean-up means this is a blind spot for most developers so it isn't surprising.) Consider using this code. It uses the ""try/catch try/finally"" pattern to definitively close the result set: try{ Statement stmt = conn.createStatement(); try { ResultSet rs = stmt.createQuery(""some sql""); try { // ResultSet processing goes here } finally { rs.close(); } } finally { stmt.close(); } } catch ( SQLException ex ) { // exception processing for any problems. } This guarantees that the result set is closed - even if a exception is thrown. @BalusC - I can see why you might say that. A vanilla design has the finally{} at the end after the catch. This design solves a few problems: not checking for nulls and avoiding the ""missed close()"" trap for a second exception. First all of the close methods ALSO throw SQLException this centralizes the catch block for them. The ""missed close()"" is tricker - if you use a single finally that also has a try/catch in it and that method has more than one close() any exception skips some of the close() statements. This may not be perfect code so better ideas are always welcome! Good text but bad code. That's now how it's to be done. don't forget the conn.close() in it's own finally block! can anyone point to a better bullet-proof approach??? with all this nested try catch I always get the impression that I'm missing some combination that might leave resources open...  One time JDBC can use a lot of memory is if you're doing queries which return many rows from the database and scrolling result sets are not supported by your JDBC driver. This causes all rows to be retrieved from the server and potentially loaded into RAM. The solution is to split your queries into smaller batches or enable scrolling result sets if possible.  JDBC does not eat up very much memory for itself. It caches several pieces of metadata but the vast majority of memory is taken up by the query results usually. The idea of it is just providing a standard interface of accessing your data it is not very much of an implementation in its own right. That's why you need JDBC drivers that implement the specifics for each database product. JDBC being not resource intensive is supported by the fact that you can run JDBC even on mobile devices with JavaME - a very resource limited environment. So while you might appreciate the easier handling of data with frameworks like Hibernate or JPA you should not worry about JDBC consuming any amount of resources worth mentioning in the context of the overall application. As they say: Don't try to optimize things that are not a problem :)  I have to agree what others have said here that JDBC itself doesn't use a large memory footprint. However if you're concerned about a particular JDBC operation using a lot of memory you could use either JConsole or a profiler to see how much heap is used during said method execution.  If you ever encounter this problem then it's probably your own code which is a memory hog. This can happen if you haul the complete database contents into Java's memory. That's actually not JDBC's fault. To reduce memory consumption best is to fire as specific as possible SQL queries. Just only query the data you actually need nothing else. If you really need all the data of a table then you're probably using the wrong tool with JDBC. Decent DB servers ships with more decent import/export tools for that. Give it a look first."
979,A,"What's the best way to get the last inserted id using sqlite from Java? What's the best way to get the last inserted id using sqlite from Java? Google is giving me different answers--some say select the last-insert-rowid; others say call statement.getGeneratedKeys(). What's the best route to take? (I just want to return the id not use it for other inserts or anything.) Either approach executes the same exact SQL statement but java.sql.Statement.getGeneratedKeys() is more portable to different underlying databases. Using either the sqlite3_last_insert_rowid() C API function or the last_insert_rowid() SQL function is the correct way to retrieve the rowid generated during the last insert. SQLite supports the SQL scalar function syntax as: SELECT function-name(); Therefore if you do not have access to the C API directly you can invoke the scalar function last_insert_rowid() via a SELECT statement. If you look at the source code for the SQLiteJDBC implementation (is this what you're using?) you will see that this is exactly what the author of that JDBC wrapper has done: ResultSet getGeneratedKeys() throws SQLException { if (getGeneratedKeys == null) getGeneratedKeys = conn.prepareStatement( ""select last_insert_rowid();""); return getGeneratedKeys.executeQuery(); }  Use getGeneratedKeys() if your JDBC driver supports it. You don't want to muck around trying to get the key yourself after the insert. If your driver does not support getGeneratedKeys() then I would get the next value from the key before the insert. In what way is ""the next value from the key before the insert"" any better than ""the largest value after the insert""? Both have the same type of race condition and both rely on monotonic single increments of the key. The assumption is that the key retrieved before the insert would not be based on any query of the target table but from some key provider. In Oracle terms it would be Select sequence_name.nextval from dual. I don't know the particulars for SQL lite but some api call that returns a key in its own autonomous transaction completely independent of the insert. That said...use getGeneratedKeys()."
980,A,"""Local transaction already has 1 non-XA Resource: cannot add more resources"" error After reading previous questions about this error it seems like all of them conclude that you need to enable XA on all of the data sources. But: What if I don't want a distributed transaction? What would I do if I want to start transactions on two different databases at the same time but commit the transaction on one database and roll back the transaction on the other? I'm wondering how my code actually initiated a distributed transaction. It looks to me like I'm starting completely separate transactions on each of the databases. Info about the application: The application is an EJB running on a Sun Java Application Server 9.1 I use something like the following spring context to set up the hibernate session factories: <bean id=""dbADatasource"" class=""org.springframework.jndi.JndiObjectFactoryBean""> <property name=""jndiName"" value=""jdbc/dbA""/> </bean> <bean id=""dbASessionFactory"" class=""org.springframework.orm.hibernate3.LocalSessionFactoryBean""> <property name=""dataSource"" ref=""dbADatasource"" /> <property name=""hibernateProperties""> hibernate.dialect=org.hibernate.dialect.Oracle9Dialect hibernate.default_schema=schemaA </property> <property name=""mappingResources""> [mapping resources...] </property> </bean> <bean id=""dbBDatasource"" class=""org.springframework.jndi.JndiObjectFactoryBean""> <property name=""jndiName"" value=""jdbc/dbB""/> </bean> <bean id=""dbBSessionFactory"" class=""org.springframework.orm.hibernate3.LocalSessionFactoryBean""> <property name=""dataSource"" ref=""dbBDatasource"" /> <property name=""hibernateProperties""> hibernate.dialect=org.hibernate.dialect.Oracle9Dialect hibernate.default_schema=schemaB </property> <property name=""mappingResources""> [mapping resources...] </property> </bean> Both of the JNDI resources are javax.sql.ConnectionPoolDatasoure's. They actually both point to the same connection pool but we have two different JNDI resources because there's the possibility that the two completely separate groups of tables will move to different databases in the future. Then in code I do: sessionA = dbASessionFactory.openSession(); sessionB = dbBSessionFactory.openSession(); sessionA.beginTransaction(); sessionB.beginTransaction(); The sessionB.beginTransaction() line produces the error in the title of this post - sometimes. I ran the app on two different sun application servers. On one runs it fine the other throws the error. I don't see any difference in how the two servers are configured although they do connect to different but equivalent databases. So the question is Why doesn't the above code start completely independent transactions? How can I force it to start independent transactions rather than a distributed transaction? What configuration could cause the difference in behavior between the two application servers? Thanks. P.S. the stack trace is: Local transaction already has 1 non-XA Resource: cannot add more resources. at com.sun.enterprise.distributedtx.J2EETransactionManagerOpt.enlistResource(J2EETransactionManagerOpt.java:124) at com.sun.enterprise.resource.ResourceManagerImpl.registerResource(ResourceManagerImpl.java:144) at com.sun.enterprise.resource.ResourceManagerImpl.enlistResource(ResourceManagerImpl.java:102) at com.sun.enterprise.resource.PoolManagerImpl.getResource(PoolManagerImpl.java:216) at com.sun.enterprise.connectors.ConnectionManagerImpl.internalGetConnection(ConnectionManagerImpl.java:327) at com.sun.enterprise.connectors.ConnectionManagerImpl.allocateConnection(ConnectionManagerImpl.java:189) at com.sun.enterprise.connectors.ConnectionManagerImpl.allocateConnection(ConnectionManagerImpl.java:165) at com.sun.enterprise.connectors.ConnectionManagerImpl.allocateConnection(ConnectionManagerImpl.java:158) at com.sun.gjc.spi.base.DataSource.getConnection(DataSource.java:108) at org.springframework.orm.hibernate3.LocalDataSourceConnectionProvider.getConnection(LocalDataSourceConnectionProvider.java:82) at org.hibernate.jdbc.ConnectionManager.openConnection(ConnectionManager.java:446) at org.hibernate.jdbc.ConnectionManager.getConnection(ConnectionManager.java:167) at org.hibernate.jdbc.JDBCContext.connection(JDBCContext.java:142) at org.hibernate.transaction.JDBCTransaction.begin(JDBCTransaction.java:85) at org.hibernate.impl.SessionImpl.beginTransaction(SessionImpl.java:1354) at [application code ...] The ""Non Transactional Connections"" checkbox in the Connection Pool settings did the trick. What's wierd though is that it was unchecked in both app servers but apparently one of them was returning non-transactional connections anyways. 1 Why doesn't the above code start completely independent transactions? The app. server manages the transaction for you which can if necessary be a distributed transaction. It enlists all the participants automatically. When there's only one participant you don't notice any difference with a plain JDBC transaction but if there are more than one a distributed transaction is really needed hence the error. 2 How can I force it to start independent transactions rather than a distributed transaction? You can configure the datasource to be XA or Local. The transactional behavior of Spring/Hibernate can also be configured to use either regular JDBC transactions or delegate the management of transactions to the JTA distributed transaction manager. I suggest you switch the datasource to non-XA and try to configure Spring/Hibernate to use the JDBC transactions. You should find the relevant information in the documentation here what I suspect is the line to change: <bean id=""txManager"" class=""org.springframework.jdbc.datasource.DataSourceTransactionManager"" /> This should essentially means that you are not using the app. server distributed transaction manager. 3 What configuration could cause the difference in behavior between the two application servers? If you have really exactly the same app and configuration this means that in one case only one participant is enlisted in the dist. transaction while there are two in the 2nd case. One participant corresponds to one physical connection to a database usually. Could it be that in one case you use two schema on two different databases while in the 2nd case you use two schema on the same physical database? A more probable explanation would be that the datasource were configured differently on the two app. server. PS: If you use JTA distributed transactions you should use UserTransaction.{begincommitrollback} rather than their equivalent on the Session. Actually I was very surprised that the container was allowing the OP to call `session.beginTransaction` in a managed environment but it appears that Hibernate will automatically join the current JTA transaction in a JTA environment if you do so (works for CMT and even BMT Hibernate will start a `UserTransation` if required). See http://www.redhat.com/docs/en-US/JBoss_Hibernate/3.2.4.sp01.cp03/html/Reference_Guide/Database_transaction_demarcation-Using_JTA.html  After reading previous questions about this error it seems like all of them conclude that you need to enable XA on all of the data sources. No not all all except one (as the exception is saying) if your application server supports Logging Last Resource (LLR) optimization (which allows to enlist one non-XA resource in a global transaction). Why doesn't the above code start completely independent transactions? Because you aren't. When using beginTransaction() behind EJB Session Beans Hibernate will join the JTA transaction (refer to the documentation for full details). So the first call just works but the second call means enlisting another transactional resource in the current transaction. And since none of your resources are XA you get an exception. How can I force it to start independent transactions rather than a distributed transaction? See @ewernli answer. What configuration could cause the difference in behavior between the two application servers? No idea. Maybe one of them is using at least one XA datasource. ""my suggestion is to configure one of your resource as an XA resource"" If I do that will I be able to roll back one transaction and commit the other? ""No not all all except one"" - true thanks for pointing that out @bkail: Thanks for sharing this. FWIW LLR (aka LPS / last participant support in WAS) introduces the risk of a heuristic hazard: if the 1PC resource does not respond (timeout lost connection etc.) there is no way to know what the outcome of the XA resource branches should be."
981,A,What are the steps for connecting jdbc with mysql I'M NOT ASKING ABOUT THE CODE. I just want to know what are and all the steps involved in the connection other than coding. I'm using j2sdk1.4.0 and MySQL Server 4.1. Am very new to this area. Thanks in advance I maybe my advice will not be as useful as that from Vinegar but to keep it simple you can always do it like this: First download the'mysql-connector-java.jar' -- I suppose you already have this -- if you're in Linux a yum install mysql-connector-java will suffice. Compile your code normally Now when you need to run your app do something like this on the command line: java -classpath .:“/someplace in your computer/mysql-connector-java.jar” your app I hope this can help you get started. Good luck!  If your code cannot find the class then that's always going to be an issue with your classpath (and this isn't specific to JDBC in any way). Make sure you have the MySQL JDBC JAR on your classpath at runtime (it's probably called mysql-connector-java-3.0.17-ga.jar; if you have an IDE it can probably tell you where the class in question lives).
982,A,"Can't make JDBC connection to MySQL (using Java IntelliJ and Linux) I am having issues trying to get a database connection using the code below:  try { Class.forName(""com.mysql.jdbc.Driver""); Properties p = new Properties(); p.put(""user"" user_name); p.put(""password"" password); connection = DriverManager.getConnection(""jdbc:mysql://127.0.0.1/jsp_test"" p); } catch (SQLException ex) { // handle any errors ex.printStackTrace(); System.out.println(""SQLException: "" + ex.getMessage()); System.out.println(""SQLState: "" + ex.getSQLState()); System.out.println(""VendorError: "" + ex.getErrorCode()); return false; } catch (ClassNotFoundException e) { e.printStackTrace(); } The error message that is outputted is: /usr/lib/jvm/java-6-openjdk/bin/java -Didea.launcher.port=7532 -Didea.launcher.bin.path=/usr/bin/idea/bin -Dfile.encoding=UTF-8 -classpath /usr/lib/jvm/java-6-openjdk/jre/lib/jce.jar:/usr/lib/jvm/java-6-openjdk/jre/lib/about.jar:/usr/lib/jvm/java-6-openjdk/jre/lib/resources.jar:/usr/lib/jvm/java-6-openjdk/jre/lib/management-agent.jar:/usr/lib/jvm/java-6-openjdk/jre/lib/jsse.jar:/usr/lib/jvm/java-6-openjdk/jre/lib/charsets.jar:/usr/lib/jvm/java-6-openjdk/jre/lib/rt.jar:/usr/lib/jvm/java-6-openjdk/jre/lib/ext/localedata.jar:/usr/lib/jvm/java-6-openjdk/jre/lib/ext/sunjce_provider.jar:/usr/lib/jvm/java-6-openjdk/jre/lib/ext/sunpkcs11.jar:/usr/lib/jvm/java-6-openjdk/jre/lib/ext/dnsns.jar:/home/bedtimes/Java Projects/db_demo/out/production/db_demo:/opt/java/jre/lib/ext/mysql-connector-java-5.1.10-bin.jar:/usr/bin/idea/lib/idea_rt.jar com.intellij.rt.execution.application.AppMain Main com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:532) at com.mysql.jdbc.Util.handleNewInstance(Util.java:406) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074) at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2214) at com.mysql.jdbc.ConnectionImpl.(ConnectionImpl.java:781) at com.mysql.jdbc.JDBC4Connection.(JDBC4Connection.java:46) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:532) at com.mysql.jdbc.Util.handleNewInstance(Util.java:406) at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:352) at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:284) at java.sql.DriverManager.getConnection(DriverManager.java:620) at java.sql.DriverManager.getConnection(DriverManager.java:169) at database.Database.connect(Database.java:80) at Main.main(Main.java:13) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:616) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:110) Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:532) at com.mysql.jdbc.Util.handleNewInstance(Util.java:406) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074) at com.mysql.jdbc.MysqlIO.(MysqlIO.java:343) at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2137) ... 18 more Caused by: java.net.ConnectException: Connection refused at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:310) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:176) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:163) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:384) at java.net.Socket.connect(Socket.java:542) at java.net.Socket.connect(Socket.java:492) at java.net.Socket.(Socket.java:389) at java.net.Socket.(Socket.java:232) at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:253) at com.mysql.jdbc.MysqlIO.(MysqlIO.java:292) ... 19 more SQLException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. SQLState: 08S01 VendorError: 0 Process finished with exit code 0 I've literally no idea how to troubleshoot this error message. The database exists. The username and password exists. I've currently not added any tables to the database but I don't think that can be the issue since I'm only making a connection after all... I can provide extra information if needs be. I feel like I've tried a lot. Does anybody know any ways of getting further information on how and why it's failing? Thanks for your help! :) Can you connect to it directly (using mysql client)? The only useful bit of the traceback is `08S01` and the mysql documentation mentions something about it (http://dev.mysql.com/doc/refman/5.0/en/connector-j-usagenotes-troubleshooting.html#qandaitem-20-3-5-3-1-3). Have you tried using the url ""jdbc:mysql://localhost/jsp_test""? Mostly just a random debug guess. I can connect directly using mysql client and my username 'jsp_test'. I still can't connect if I change 127.0.0.1 to localhost. Thanks for the link I'll take a look. I'm wondering if somebody else can try doing the same thing with their own machine and mysql-connector-java-5.1.10-bin.jar You can try this instead: connection = DriverManager.getConnection(""jdbc:mysql://localhost:3306/jsp_test""""user_name""""password"");  you can try one of the following ""jdbc:mysql://localhost:3306/jsp_test""""username""""password"" or ""jdbc:mysql://'your machines ip (without quote)':3306/jsp_test""""username""""password"" or ""jdbc:mysql://127.0.0.1:3306/jsp_test""""username""""password"" as a connection string.  From your connection string this database should be on the local machine. Can you try running this command to ensure the socket is open for connections? telnet 127.0.0.1 3306 and ensure that it connects? You may not have configured your mysql instance to listen for connections from this machine or on this interface address. If the connection fails you need to modify your mysql config for example: http://www.cyberciti.biz/tips/how-do-i-enable-remote-access-to-mysql-database-server.html [bedtimes@seb ~]$ telnet 127.0.0.1 3306 Trying 127.0.0.1... telnet: Unable to connect to remote host: Connection refused ...Looks like you might be right! I'll go and try out that guide and then get back to you if it fixes the issue. C: I'm now getting: [bedtimes@seb /]$ telnet localhost 3306 Trying 127.0.0.1... Connected to localhost. Escape character is '^]'. Connection closed by foreign host. ...Does anybody know what this means? Final fix was by altering hosts.allow as specified on this page: http://bbs.archlinux.org/viewtopic.php?pid=346836#p346836 Total PITA. Thanks! C:  I had the same symptoms but for me the solution was to change the bind-address to 0.0.0.0 in /etc/mysql/my.cnf (Just posting this for others seeking an answer to this question) I completely remove the bind-address line and it fixed the same problem for me."
983,A,"Simple select not working on JDBC SQL Server? I am trying to move project which was using MySQL database to the one that uses SQL Server 2008 But the select that was working in mysql is no longer working in SQL Server PreparedStatement statement = connection .prepareStatement(""select u.user_firstnameu.user_lastname from user_details u login l where l.username=? and l.login_user = u.user_id""); statement.setString(1 userName); ResultSet resultSet = (ResultSet) statement.executeQuery(); It always gives me empty resultset even when there are values corresponding to that username When I run query using SQL Server Management Studio - query works properly i.e. it gives non-zero rows Are there any SQL Server specific change I need to do ? Don't see anything wrong here i'd look at how you get your Connection object. Perhaps your database url is pointing to the wrong schema -- perhaps the default one not your database."
984,A,"Database Migration I am working on database migration tool in java. The tool is copying database tables with their data's to the destination database. But i want it to work on different databases. Copy from mysql and create in derby etc. With JDBC we can gather enough information about the table and its columns. But i am going to ask this if i can recreate tables on java with sql free. I mean different databases have different data types and some times they differs at sql syntax. So can JDBC or any other library (can be open source) do this job at an easy and global way? PS: First question in SO i have been reading posts but first time I am contributing the site so hello everybody. Try SchemaCrawler which is also open source and written in Java. It provides programmatic access to database metadata and also allows scripting in JavaScript. http://schemacrawler.sourceforge.net/  try to see what HIBERNATE provides for migration. I know that H can generate model objects from database schema and a schema from model objects. So maybe you can reuse some parts from HIBERNATE. They have the notion of DIALECT that does exactly what you are saying: defining specifics of a db implementation. i have searched through hibernate and JDO. But i just need to replace ex: mysql longtext to derby clob. Hibernate has more abilities that i dont need and very comlicated to learn thanks anyway  Apache's DdlUtils is done what i need. When I am searching about crossdb found it and it is very useful yet powerful. It can generate a database from scratch just with the parameters. Or it can grab existing database table definitions also with index definitions. You can use delimiter if you want (it is a deadly important option for me to use Apache Derby). You can just print out these definitions or apply them directly to source database (i havent tried the second one yet). It translates definitions for the selected database. But one big problem is there is no good tutorial about how to start using it. I searched through the packages to find a good place to start. Here is what i have achieved a sample code to generate full database table create sql. DerbyPlatform dp = new DerbyPlatform(); dp.setDelimitedIdentifierModeOn(true); Database dbs = new Database(); DerbyModelReader dmr = new DerbyModelReader(dp); Database test = dmr.getDatabase(conn ""MyDBTest""); DerbyBuilder db = new DerbyBuilder(dp); String testSqlDerby = dp.getCreateTablesSql(test true true); System.out.println(testSqlDerby); System.out.println(""\n\n\n\n""); MySql50Platform mp = new MySql50Platform(); mp.setDelimitedIdentifierModeOn(true); MySqlBuilder mb = new MySqlBuilder(mp); String testSqlMysql = mp.getCreateTablesSql(test true true); System.out.println(testSqlMysql); yeah it still has some bugs. for example if you choose mysql for source and derby for target. it will choose longvarchar for text type. but some data does not fit in that type. so you have to manually set it to clob. DdlUtils is good but it still doesn't support NVARCHAR (which since Java 6 is a core JDBC type in java.sql.Types)  I'm not aware of JDBC having a generic facility to do this. You probably have to make a utility library that generates the SQL for table creation. Start with one that does ANSI SQL and test it on as many platforms as you intend to support. Remember Java is still write-once debug everywhere so you will need to test this on any platform you intend to support the system on. Subclass the generator if you have to make dialectic variations of the create statement for any of your platforms."
985,A,"How to call oracle stored procedure which include user-defined type in java? In Oracle DB: Store Procedure like: procedure getInfo ( p_ids IN IDS_TABLE p_details OUT cursor ) Type IDS_TABLE is: create or replace type IDS_TABLE as table of IDS create or replace type IDS as object ( id1 NUMBER id2 NUMBER id3 NUMBER ) How can I call getInfo in Java? This is a pretty good example. if you see java.sql.SQLException: invalid name pattern: still. Check the scope of the type that you declared in Oracle. I am using Oracle 11g and had to declare both Object of String Array and Table of Objects of my type in schema level. Spent some 3 hours and found that. oracle.sql.StructDescriptor docObjDescriptor = StructDescriptor.createDescriptor(""SSIADM.DOCUMENT_OBJECT""conn); String[] strArray = new String[] {""doc1""""file1""}; oracle.sql.STRUCT DocObject1 = new STRUCT(docObjDescriptorconnstrArray); strArray = new String[] {""doc2""""file2""}; oracle.sql.STRUCT DocObject2 = new STRUCT(docObjDescriptorconnstrArray); oracle.sql.STRUCT[] docObjArray = {DocObject1DocObject2}; arrDesc = ArrayDescriptor.createDescriptor(""DOCUMENT_TABLE"" conn); oracle.sql.ARRAY array = new ARRAY(arrDesc conn docObjArray);  Setting up a link between Oracle SQL objects and java objects manually is not a trivial task. In particular arrays (or nested tables) of user-defined objects are more complex to pass from java to Oracle than arrays of standard datatypes. In other words it is easier to call a procedure with signature: (TABLE OF NUMBER TABLE OF NUMBER TABLE OF NUMBER)` than a procedure whose signature is: (TABLE OF (NUMBER NUMBER NUMBER)) <- your case You can write a wrapper around your procedure to transform the second case into the first case. That being said it is by far not impossible to map your procedure. The following example is largely inspired by a post by Tom Kyte. Tom describes how to map a TABLE OF NUMBER using oracle.sql.ARRAY. In your case we will also have to use oracle.sql.STRUCT to map the IDS SQL object. You may also want to browse the Oracle JDBC doc in particular the chapter Working with Oracle Object Types. First is a setup similar to yours: SQL> CREATE OR REPLACE TYPE IDS AS OBJECT ( id1 NUMBER id2 NUMBER id3 NUMBER ); 2 / Type created SQL> CREATE OR REPLACE TYPE IDS_TABLE AS TABLE OF IDS; 2 / Type created SQL> CREATE OR REPLACE PROCEDURE getInfo(p_ids IN IDS_TABLE) IS 2 BEGIN 3 FOR i IN 1 .. p_ids.COUNT LOOP 4 dbms_output.put_line(p_ids(i).id1 5 || '' || p_ids(i).id2 6 || '' || p_ids(i).id3); 7 END LOOP; 8 END getInfo; 9 / Procedure created This is the java procedure: SQL> CREATE OR REPLACE 2 AND COMPILE JAVA SOURCE NAMED ""ArrayDemo"" 3 as 4 import java.io.*; 5 import java.sql.*; 6 import oracle.sql.*; 7 import oracle.jdbc.driver.*; 8 9 public class ArrayDemo { 10 11 public static void passArray() throws SQLException { 12 13 Connection conn = 14 new OracleDriver().defaultConnection(); 15 16 17 StructDescriptor itemDescriptor = 18 StructDescriptor.createDescriptor(""IDS""conn); 19 20 Object[] itemAtributes = new Object[] {new Integer(1) 21 new Integer(2) 22 new Integer(3)}; 23 STRUCT itemObject1 = new STRUCT(itemDescriptorconnitemAtributes); 24 25 itemAtributes = new Object[] {new Integer(4) 26 new Integer(5) 27 new Integer(6)}; 28 STRUCT itemObject2 = new STRUCT(itemDescriptorconnitemAtributes); 29 30 STRUCT[] idsArray = {itemObject1itemObject2}; 31 32 ArrayDescriptor descriptor = 33 ArrayDescriptor.createDescriptor( ""IDS_TABLE"" conn ); 34 35 ARRAY array_to_pass = 36 new ARRAY( descriptor conn idsArray ); 37 38 OraclePreparedStatement ps = 39 (OraclePreparedStatement)conn.prepareStatement 40 ( ""begin getInfo(:x); end;"" ); 41 42 ps.setARRAY( 1 array_to_pass ); 43 ps.execute(); 44 45 } 46 } 47 / Java created Let's call it: SQL> CREATE OR REPLACE 2 PROCEDURE show_java_calling_plsql 3 AS LANGUAGE JAVA 4 NAME 'ArrayDemo.passArray()'; 5 / Procedure created SQL> exec show_java_calling_plsql ; 123 456 PL/SQL procedure successfully completed If I was to change the table declaration for an associative array i.e. `create or replace type IDS_TABLE as table of IDS index by varchar2(50)`  what changes do I need to make to the java code? I opened a question for this. http://stackoverflow.com/questions/12731742/how-to-call-a-procedure-with-associative-arrays-in-oracle-from-java I am runnig the java code from eclipse. But the inputs are going null. My case is Table of objects. I opened a queston for this. http://stackoverflow.com/questions/20099905/call-stored-procedure-from-java-for-oracle-type-table Great +1 Works like a charm."
986,A,"Java 6 Source backward-compatibility and SQL My understanding is that in order to maintain source-compatibility Java never introduces new methods to public interfaces as that breaks existing clients implementing the interfaces. Java Release notes states In general the policy is as follows except for any incompatibilities listed further below: Maintenance releases (such as 1.4.1 1.4.2) do not introduce any new language features or APIs. They will maintain source-compatibility with each other. Functionality releases and major releases (such as 1.3.0 1.4.0 5.0) maintain upwards but not downwards source-compatibility. Yet the packages java.sql and javax.sql continue to evolve and introduce many incompatible changes. For example I noticed the following incompatible changes (introduced in Java 6): java.sql.Statement extends java.sql.Wrapper requiring new two new methods. java.sql.Statement introduces 3 new methods java.sql.PreparedStatement introduces 19 new methods! java.sql.ResultSet introduces 48 new methods! Do you know how and why these methods got added? Is java.sql being treated differently from the rest of the platform? Do you know of the discussion/JSR around these additions? Adding methods does not break upwards compatibility only downwards (which is allowed for major releases like Java 6). But the `java.sql` types are interfaces not classes. I got the following reply from a Sun Developer The general evolution policy for APIs in the JDK for feature releases like JDK 7 is Don't break binary compatibility (as defined in JLSv3 chapter 13) Avoid introducing source incompatibilities Manage behavioral compatibility change (For more much more than you'd like to read on different kinds of compatibility see ""Kinds of Compatibility: Source Binary and Behavioral"" and ""Compatibly Evolving BigDecimal"" Adding methods to interfaces is binary compatible but source incompatible so it is not commonly done. Generally the more widely implemented an interface is the less likely we are to add methods to it. The JDBC area is an exception to this policy and uses looser upgrade rules but that does cause real issues when people want to upgrade to a new JDK release. Should that be ""does *not* cause real issues""?  Note that adding new methods only break source compatibility already compiled implementations of Statement or ResultSet in a JDBC driver will continue to run on a newer JDK. Only when you try to call a new method you will get a NoSuchMethodError. Correct. That's why I restricted the question to source compatibility! This is not correct. It breaks all drivers implemented for Java 5. See my question http://stackoverflow.com/questions/1238252/how-to-make-jdbc-driver-work-in-java-5-6 @Zhang the problem in the referenced question is about binary downwards compatibility; i.e.. using Java 6 JDK while targeting Java 5 JDK. Java never promised that!  Sun never guarantees source compatibility between releases only binary compatibility. The most common example is that source code that contains 'assert' or 'enum' identifiers will not compile under JDK 1.4 (for assert) or 1.5+ (for enum) but existing .class files will still run under those newer JVMs. You can try using the -source flag to compile older .java files under newer JVMs but you may still run into problems if you're relying on jvm classes that have changed. Not quite true. I attached the policy for source compatibility in the question. They are more lenient with breaking source compatibility than binary compatibility; but they usually document these changes. `java.sql` changes aren't documented in the release notes.  They probably assume that database driver vendors that implement those methods are keeping up-to-date with new Java runtimes and that it's better to introduce useful new methods and temporarily break compatibility. Of course they could've designed it better so that breaking compatibility wouldn't be necessary…"
987,A,"Sql Server - connect with windows authentication i must connect to a sql server with windows authentication sql server is on machine 192.168.3.6 web server (client) is on my machine 192.168.3.10 I'm using JTDS driver dbUrl=jdbc:jtds:sqlserver://192.168.3.6:1099/db_test;instance=test Connection con = DriverManager.getConnection( dbUrl """" """" ); I have username and password of administrator user of sql server ! I also put ntlmauth.dll into c:\windows and c:\windows\system32 and I have always error: java.sql.SQLException: Login failed for user '(null)'. Reason: Not associated with a trusted SQL Server connection. Any idea to solve my problem ? Thank you very much See jTDS FAQ http://jtds.sourceforge.net/faq.html you will have to pass useNTLMv2=true and domain=yourdomain Wonderfull I have resolved dbUrl=jdbc:jtds:sqlserver://192.168.3.6:1099/db_test;instance=test;useNTLMv2=true;domain=workgroup Connection con = DriverManager.getConnection( dbUrl dbUser dbPwd ) I must use parameters useNTLMv2=true and domain. The value of parameter domain is no important. It works also with domain=pippo !! I do not know how .....:-) Brilliant this solved my problem as well. Solved my problem as well - thanks  What you can do is something like: String url = ""jdbc:jtds:sqlserver://MYPC/MYDB;instance=SQLEXPRESS""; Class.forName(""net.sourceforge.jtds.jdbc.Driver""); Connection conn = DriverManager.getConnection(url); Make sure you have jtds.jar in the Java build path. Also add ""-Djava.library.path=""PATH\JTDS\x64\SSO"" where 'Path' is where your SSO folder is after installing the JTDS driver (this is where you have your ntlmauth.dll). Here is a short step-by-step guide showing how to connect to SQL Server using jTDS (as well as JDBC) with Windows authentication should you need more details. Hope it helps!"
988,A,"Can a JBoss JDBC connection be invalidated so that it doesn't get resupplied from the connection pool? I have a circumstance where a JDBC connection places the Oracle session to which it is attached into a particular state (i.e. DBMS_FLASHBACK enabled mode). It's possible for the exit of this mode to fail (at least theoretically) which means that the session is left in the state erroneously. In this case the connection can be returned to the pool and obtained by another thread with the Oracle session still in DBMS_FLASHBACK enabled mode. I have proved that would actually happen. (JBoss 4.2.1) What would be ideal would be is to catch the SQLException when the mode exit fails and mark the connection as ""bad"" so that once it was returned to the pool JBoss would destroy the connection and create a new one. But I can't find any way to mark the connection for immediate destruction. Does anyone know of a way? Your Oracle database connection configuration should contain an exception sorter: <exception-sorter-class-name>org.jboss.resource.adapter.jdbc.vendor.OracleExceptionSorter</exception-sorter-class-name> This attempts to determine when an exception occurs if the connection can be reused or must be disconnected. This is on a best efforts basis and doesn't work in every case. My preference for production installs is to mark all exceptions as fatal. To do this simply set your exception sorter to org.jboss.resource.adapter.jdbc.GenericExceptionSorter.  Its a good question and I don't know the complete answer but some avenues to investigate would be to start with the JBoss failover mechanism where it tests the validity of the connection. The documentation for that is here. Then in the SQL that tests validity if something could be put in that would fail if the connection is in the DBMS_FLASHBACK enabled mode that should get JBoss to discard the connection. It probably tests on the next request for a connection not when it is returned to the pool although that should be acceptable."
989,A,"What are my options to store and query huge amounts of data where a lot of it is repeating? I am evaluating options for efficient data storage in Java. The data set is time stamped data values with a named primary key. e.g. Name: A|B|C:D Value: 124 TimeStamp: 01/06/2009 08:24:39223 Could be a stock price at a given point in time so it is I suppose a classic time series data pattern. However I really need a generic RDBMS solution which will work with any reasonable JDBC compatible database as I would like to use Hibernate. Consequently time series extensions to databases like Oracle are not really an option as I would like the implementor to be able to use their own JDBC/Hibernate capable database. The challenge here is simply the massive volume of data that can accumulate in a short period of time. So far my implementations are focused around defining periodical rollup and purge schedules where raw data is aggregated into DAY WEEK MONTH etc. tables but the downside is the early loss of granularity and the slight inconvenience of period mismatches between periods stored in different aggregates. The challenge has limited options since there is an absolute limit to how much data can be physically compressed while retaining the original granularity of the data and this limit is exacerbated by the directive of using a relational database and a generic JDBC capable one at that. Borrowing a notional concept from classic data compression algorithms and leveraging the fact that many consecutive values for the same named key can expected to be identical I am wondering if there is way I can seamlessly reduce the number of stored records by conflating repeating values into one logical row while also storing a counter that indicates effectively ""the next n records have the same value"". The implementation of just that seems simple enough but the trade off is that the data model is now hideously complicated to query against using standard SQL especially when using any sort of aggregate SQL functions. This significantly reduces the usefulness of the data store since only complex custom code can restore the data back to a ""decompressed"" state resulting in an impedance mismatch with hundreds of tools that will not be able to render this data properly. I considered the possibility of defining custom Hibernate types that would basically ""understand"" the compressed data set and blow it back up and return query results with the dynamically created synthetic rows. (The database will be read only to all clients except the tightly controlled input stream). Several of the tools I had in mind will integrate with Hibernate/POJOS in addition to raw JDBC (eg. JasperReports) But this does not really address the aggregate functions issue and probably has a bunch of other issues as well. So I am part way to resigning myself to possibly having to use a more proprietary [possibly non-SQL] data store (any suggestions appreciated) and then focus on the possibly less complex task of writing a pseudo JDBC driver to at least ease integration with external tools. I heard reference to something called a ""bit packed file"" as a mechanism to achieve this data compression but I do not know of any databases that supply this and the last thing I want to do (or can do really....) is write my own database. Any suggestions or insight ? This is EXACTLY the type of problem I have to solve except in my case I am logging many channels of sensor data. Great question! Many JDBC-capable database management systems (e.g. Oracle) provide compression in the physical storage engine. Oracle for example has the notion of a ""compressed"" table without decompression overhead: http://www.ardentperf.com/wp-content/uploads/2007/07/advanced-compression-datasheet.pdf  I would look at a column oriented database. It would be great for this sort of application Thanks Javaman. I knew about these but did not know there were so many decent open source ones. (Don't want to force users to a commercial app). So I looked at LucidDB and it looks like the ticket. The efficiency compression user defined transforms and foreign tables get me what I want.  Thanks for the answers. Cletus I appreciate the outline but one of the tradeoffs I cannot make is abandoning DB flexibility and compatibility with JDBC/Hibernate to allow the use of all the available tools. Moreover although I did not clearly state this I do not want to force my users into adopting a [possibly expensive] commercial solution. If they have Database Brand X let 'em use it. If they don't care we recommend open source Database Brand Y. Basically the application has multiple faces one of them being a repository for incoming data but another face is a reporting source and I really don't want to get into the business of writing report generators. While I have not really load tested it yet I am very impressed with LucidDB. It is a column oriented database and it provides good query performance and seemingly good data compression. It has a JDBC driver though no Hibernate dialect exists for it yet as far as I can tell. It also supports user defined transformations which in short I think will allow me to seamlessly implement my idea of compressing repeating and consecutive values into one ""row"" but blow them back out into multiple ""synthetic"" rows at query time all done invisibly to the query caller. Lastly it supports this nifty feature of foreign tables where other JDBC supporting database tables can be fronted in LucidDB. I think this may be invaluable to providing some level of support for other databases. Thanks for the pointer Javaman. It zoned me in on LucidDB.  You will probably find it interesting to listen to Michael Stonebraker's presentation at Money:Tech. He hits on a number of the things you mention needing and he illustrates how the big three elephants (SQL Server Oracle and DB2) will never be able to suite the needs of tick stores (which it looks like you are building). He digs beyond column stores which I agree is the right direction. He even discusses compression and speed which are both issues for you. here are some more links you may find interesting: LucidDB - Open Source Column Store An academic paper on column stores vs row stores Someone else blogging about a similar struggle SQLStream is worth knowing about  Hibernate (or any JPA solution) is the wrong tool for this job. JPA/Hibernate isn't a lightweight solution. In high-volume applications the overhead is not only significant but prohibitive. You really need to look into grid and cluster solutions. I won't repeat the overview of the various technologies here. I've got a lot of experience in financial market information systems. A few of the things you said stuck out to me: You have a lot of raw data; You want to apply various aggregations to that data (eg open/high/low/close daily summaries); High availability is probably an issue (it always is in these kinds of systems); and Low latency is probably an issue (ditto). Now for grid/cluster type solutions I divide them loosely into two categories: Map-based solutions like Coherence or Terracotta; and Javaspaces-based solutions like GigaSpaces. I've used Coherence a lot and the Map solution can be nice but it can be problematic too. Coherence maps can have listeners on them and you can use this sort of thing to do things like: Market price alerts (users may want a notification when a price reaches a certain level); Derivative pricing (eg an exchange-traded option pricing system will want to reprice when an underlying security changes last traded price); A trade-matching/booking system may want to match received trade notifications for reconciliation purposes; etc. All of these can be done with listeners but in Coherence for example listeners have to be cheap which leads to things like a Map having a listener than writes something to another Map and this can chain on for awhile. Also modifying the cache entry can be problematic (although there are mechanisms for dealing with that kind of problem too; I'm talking about situations like turning off a market price alert so it doesn't trigger a second time). I found GigaSpaces type grid solutions to be far more compelling for this kind of application. The read (or destructive read) operation is a highly elegant and scalable solution and you can get transactional grid updates with sub-millisecond performance. Consider the two classic queueing architectures: Request/Response: a bad message can block the queue and while you can many senders and receivers (for scalability) scaling up the number of pipes isn't always straightforward; and Publish/Subscribe: this decouples the sender and receiver but lacks scalability in that if you have multiple subscribers they'll each receive the message (not necessarily what you want with say a booking system). In GigaSpaces a destructive read is like a scalable publish-subscribe system and a read operation is like the traditional publish-subscribe model. There is a Map and JMS implementation built on top of the grid and it can do FIFO ordering. Now whaqt about persistence I hear you ask? Persistence is a consequence of deciding all the other stuff. For this kind of application I like the Persistence as a Service model (ironically written about Hibernate but it applies to anything). Basically this means your date store hits are asynchronous and it works nicely with doing summary data. Like you can have a service listening for trade notifications and persist just the ones it's interested in (aggregating in memory if required). You can do open/high/low/close prices this way. For high volume data you don't really want to write it all to the database. Not synchronously anyway. A persistent store plus a data warehouse is probably more the route you"
990,A,"Problem with Informix JDBC MONEY and decimal separator in string literals I have problem with JDBC application that uses MONEY data type. When I insert into MONEY column: insert into _money_test (amt) values ('123.45') I got exception: Character to numeric conversion error The same SQL works from native Windows application using ODBC driver. I live in Poland and have Polish locale and in my country comma separates decimal part of number so I tried: insert into _money_test (amt) values ('12345') And it worked. I checked that in PreparedStatement I must use dot separator: 123.45. And of course I can use: insert into _money_test (amt) values (123.45) But some code is ""general"" it imports data from csv file and it was safe to put number into string literal. How to force JDBC to use DBMONEY (or simply dot) in literals? My workstation is WinXP. I have ODBC and JDBC Informix client in version 3.50 TC5/JC5. I have set DBMONEY to just dot: DBMONEY=. EDIT: Test code in Jython: import sys import traceback from java.sql import DriverManager from java.lang import Class Class.forName(""com.informix.jdbc.IfxDriver"") QUERY = ""insert into _money_test (amt) values ('123.45')"" def test_money(driver db_url usr passwd): try: print(""\n\n%s\n--------------"" % (driver)) db = DriverManager.getConnection(db_url usr passwd) c = db.createStatement() c.execute(""delete from _money_test"") c.execute(QUERY) rs = c.executeQuery(""select amt from _money_test"") while (rs.next()): print('[%s]' % (rs.getString(1))) rs.close() c.close() db.close() except: print(""there were errors!"") s = traceback.format_exc() sys.stderr.write(""%s\n"" % (s)) print(QUERY) test_money(""com.informix.jdbc.IfxDriver"" 'jdbc:informix-sqli://169.0.1.225:9088/test:informixserver=ol_225;DB_LOCALE=pl_PL.CP1250;CLIENT_LOCALE=pl_PL.CP1250;charSet=CP1250' 'informix' 'passwd') test_money(""sun.jdbc.odbc.JdbcOdbcDriver"" 'jdbc:odbc:test' 'informix' 'passwd') Results when I run money literal with dot and comma: C:\db_examples>jython ifx_jdbc_money.py insert into _money_test (amt) values ('12345') com.informix.jdbc.IfxDriver -------------- [123.45] sun.jdbc.odbc.JdbcOdbcDriver -------------- there were errors! Traceback (most recent call last): File ""ifx_jdbc_money.py"" line 16 in test_money c.execute(QUERY) SQLException: java.sql.SQLException: [Informix][Informix ODBC Driver][Informix]Character to numeric conversion error C:\db_examples>jython ifx_jdbc_money.py insert into _money_test (amt) values ('123.45') com.informix.jdbc.IfxDriver -------------- there were errors! Traceback (most recent call last): File ""ifx_jdbc_money.py"" line 16 in test_money c.execute(QUERY) SQLException: java.sql.SQLException: Character to numeric conversion error sun.jdbc.odbc.JdbcOdbcDriver -------------- [123.45] I have just added Jython code that uses both ODBC and JDBC driver. Could you post the exact Java code you are using to do your insert? I solved this problem by using PreparedStatement. I think that ""Character to numeric conversion error"" is a bug in Informix JDBC driver. In other database I often use PostgreSQL there is no difference if I run query via native JDBC driver or via JDBC-ODBC bridge. I found that PostgreSQL do not accept numeric form 123.45. PostgreSQL accepts string literal with dot but this dot is handled as a thousand separator. The only correctly accepted value is string literal where comma separates decimal part. EDIT: It can be solved by setting DBMONEY=. on server side then all connections (ODBC JDBC) will work with that setting.  The Informix JDBC data type mapping documentation says the following: java.math.BigDecimal           MONEY(ps)1 Thus you need to use java.math.BigDecimal instead of java.lang.String to represent the value PreparedStatement#setBigDecimal() to set the value and ResultSet#getBigDecimal() to get the value. You can ""convert"" from String to BigDecimal by just passing it as constructor argument. The other way round can be done by calling the toString() method of BigDecimal. If I know what type column is then I should just use `123.45` (as number not as string). But ODBC version that imported data from csv build ""general"" insert queries and it was safe to tread all parameters as strings. It seems that now it is time to reorganize that code and use PreparedStatement."
991,A,"Dynamically access multiple databases? My question is very related to this one: http://stackoverflow.com/questions/932625/multiple-dynamic-data-sources-for-a-servlet-context. However I haven’t found a proper solution just yet and would like to ask it again. I have a little JSF application that talks to a MS SQL Server via JDBC. Tomcat is used as the web container. The application retrieves and stores its data from a single database. A login screen is provided. If the credentials match the ones stored in the database then access is granted and I can play around with the application. Now I would like to add more databases and provide a login screen which not only requests the username and password but the database name as well. Different databases are used because I would like to have some for testing and development. The backup plans are also not the same for every database. Currently I use JNDI Resources to look up the databases in my code. However this forces me to edit context.xml and web.xml and to restart tomcat. I don’t want to do that. The restart forces me to run around an tell everyone: “Hey I am rebooting do you mind losing all your connections?” Is the some more dynamic way to do that? I dont know the answer but if you call OSQL -L from JNI you can get a list of available SQL database instances in the area. Then you can connect and get the list of databases within. So: user enters username and password app runs OSQL -L to get the list of instances and provides a select list user selects instance jdbc uses credentials in step 1 to get a list of databases from the instance jdbc uses selected database to connect.  Create an array of datasources and let the user select which index in this array you want to use. How is this dynamic? If the DBA creates a new DB the index is not in the webapp.  You could get the databases in SQL server using a select statement and eventually discard some of them which are not relevant to your applications. ResultSet rs = stmt.executeQuery(""show databases"");  For your purposes you should really have three separate application server instances (either on three separate machines or on the same machine listening to different ports or different host headers etc). The development server instance should always look up the development database the staging server looks up the staging database etc and JNDI should be set up to reflect this. That's what JNDI is for. That said if you must set things up with just a single application server you will probably need to look into writing a custom authentication realm that does this. You could either do the actual work of determining which data source to use yourself or look into something like Hibernate Shards. Guess you are right"
992,A,"Java ResultSet how to check if there are any results Resultset has no method for hasNext. I want to check if the resultSet has any value is this the correct way if (!resultSet.next() ) { System.out.println(""no data""); } You should consider accepting the answer of Seifer. His solution is better. The second answer is the right one. You would usually do something like this: while ( resultSet.next() ) { // Read the next item resultSet.getString(""columnName""); } If you want to report an empty set add a variable counting the items read. If you only need to read a single item then your code is adequate.  you can do something like this boolean found = false; while ( resultSet.next() ) { found = true; resultSet.getString(""column_name""); } if (!found) System.out.println(""No Data"");  The best thing for to do is to check the first row so that when you intend to get the data you can avoid the mistake of skipping a row. Something like: if (!resultSet.first() ) { System.out.println(""no data""); }  That would work if you want to see if there are any rows in the result set yes. Note that next() always moves to the next row so if you are planning on doing any reading from the result set you need to take that into account. Usual usage with ResultSet (when simply reading) is: while (resultSet.next()) { ... read from the row here ... } Which obviously won't work correctly if you invoked next() once already to check if the result set was empty so watch out for that. Although there are methods for ""backing up"" they are not supported for all types of result sets.  if(reset.first) { } else { system.out.println(""No raw or reset is empty""); } Because if ResultSet has no raw then reset.first returns false.  That's correct initially the ResultSet's cursor is pointing to before the first row if the first call to next() returns false then there was no data in the ResultSet. It should be noted however that Seifer's answer below is a more elegant solution to problem. If you use this method you may have to call beforeFirst() immediately after to reset it since it has positioned itself past the first row now. But keep in mind if there /are/ rows after that test you will be pointing to the first row. So make sure you don't accidentally skip a row. Good point that the cursor (pointer) is pointing at the first row @MatthewFlaschen you're right to solve the issue of skip the first row i used a do { ... } while (rs.next); You can also just call `isBeforeFirst()` to test if there are any rows returned without advancing the cursor then proceed normally.  By using resultSet.next() you can easily get the result whether resultSet containing any value or not ResultSet resultSet = preparedStatement.executeQuery(); if(resultSet.next()) //resultSet contain some values else // empty resultSet  ResultSet result=stmt.executeQuery(sqlQuery); if(!result.next()) status= ""ERROR""; else status= ""SUCCESS"";  you could always do the next up front and just do a post loop check if (!resultSet.next() ) { System.out.println(""no data""); } else { do { //statement(s) } while (resultSet.next()); } This is the most readable solution thanks  Initially the result set object (rs) points to the BFR (before first record). Once we use rs.next() the cursor points to the first record and the rs holds ""true"". Using the while loop you can print all the records of the table. After all the records are retrieved the cursor moves to ALR (After last record) and it will be set to null. Let us consider that there are 2 records in the table. if(rs.next()==false){ // there are no records found } while (rs.next()==true){ // print all the records of the table } In short hand we can also write the condition as while (rs.next()). Your while loop will not get a chance to operate on the first row returned which seems a somewhat fatal flaw with this approach. There are plenty of suggestions above that are better than this one.  To be totally sure of rather the resultset is empty or not regardless of cursor position I would do something like this: public static boolean isMyResultSetEmpty(ResultSet rs) throws SQLException { return (!rs.isBeforeFirst() && rs.getRow() == 0); } This function will return true if ResultSet is empty false if not or throw an SQLException if that ResultSet is closed/uninitialized.  Assuming you are working with a newly returned ResultSet whose cursor is pointing before the first row an easier way to check this is to just call isBeforeFirst(). This avoids having to back-track if the data is to be read. As explained in the documentation this returns false if the cursor is not before the first record or if there are no rows in the ResultSet. if (!resultSet.isBeforeFirst() ) { System.out.println(""No data""); } Thanks yes I know but I encountered the same problem and wasn't happy with the look of moving forward to check then backward to read. I thought this simplier solution would benefit others who are in the same situation as well. Note that at least for DB2 the result set has to be a ""scrollable"" type. This can be set when you create the statement to be executed.  Best to use ResultSet.next() along with the do {...} while() syntax for this. The ""check for any results"" call ResultSet.next() moves the cursor to the first row so use the do {...} while() syntax to process that row while continuing to process remaining rows returned by the loop. This way you get to check for any results while at the same time also processing any results returned. if(resultSet.next()) { // Checks for any results and moves cursor to first row do { // Use 'do...while' to process the first row while continuing to process remaining rows } while (resultSet.next()); }"
993,A,"How to diagnose performance problems with SQL Server Views and JDBC I have a view defined in SQL server 2008 that joins 4 tables together. Executing this view in SQL Server Management Studio takes roughly 3 seconds to run and returns about 45000 records. My application is written in Java using hibernate to simply do a ""from MyViewObject"" query in HQL. When this is run the execution time is consistently around 45 seconds. I have also tried simply using JDBC to run this query and received the same level of performance so I've assumed it has nothing to do with hibernate. My question: What can I do to diagnose this problem? There is obviously something different between how Management Studio is running the query vs how my application is running the query but I have not been able to come up with much. The only thing I've come up with as a potentially viable explanation is an issue with the jtds library that contains the driver for SQL Server in Java. Any guidance here would be greatly appreciated. UPDATE I went back to trying pure JDBC and tried adding the selectMethod and responseBuffering attributes to my connection string but didn't get any improvements. I also took my JDBC code from my application and ran it from a test program containing nothing but my JDBC code and it ran in the expected 3 seconds. So to me this seems environmental for the application. My application is a Google Web Toolkit(GWT) based app and the JDBC code is being run in my primary RPC Servlet. Essentially the RPC method receives the call and immediately executes the JDBC code. Nothing in this setup gives me much indication of why the performance is terrible though. I am going to try the JDBC 3.0 driver and see if that works any better but it doesn't feel like that will fix the issue to me quite yet. My goal for the moment is to get my query working live with JDBC and then switch it back over to Hibernate so I can keep the testing simple enough. Thanks for the help so far! UPDATE 2 I'm finally starting to zero in on the source of the problem though still no idea what the actual issue is. I opened up the view in SQL Server and copied the SQL statement (rather large) exactly into my code and executed it using JDBC instead of pulling the data from the view and most of the performance issues are gone. It seems that some combination of GWT SQL Server Views and JDBC is not working properly here. I don't see keeping a very large hand-written query in my code as a long term solution but it does offer a bit more insight. Have a look at http://stackoverflow.com/questions/961078/sql-server-query-running-slow-from-java Good catch after ruling hibernate out corrected. You should maybe rephrase the title of your question the problem is not Hibernate related at all. To analyze the problem you should look up you manual for tools that display the query or execution plan. Maybe you're missing an index on a join column.  <property name=""hibernate.show_sql"">true</property> setting this will show you the SQL query generated by hibernate. Analyze the query and make sure you are not missing a relationship. reply for Update 1 and 2: Like you mentioned ran the query on your sql query and it seems like it is fast. So another thing to remember about hibernate is that it creates the object that is returned by your query (of course this depends if you initialize lazy obj. Dont remember what it is called). How many objects does your query return? also you can do a simple bench on where the issue is. For example before running the query sysout the current time and then sysout the current time after. do these for all the places that you suspect is slowing your application down."
994,A,"Building a jar with MySQL jdbc on solaris Im building a java application that uses JDBC to connect to MySQL. I have an ant script that compiles my code and then packages it along with log4j junit libshout-java and the mysql jdbc driver into one executable jar. This all works fine on ubuntu 9.10 and my code connects to mysql and away we go. However my production env will be solaris (my dev box is ubuntu) and when I came to build and run this on there i had the following errors. 17 [main] DEBUG com.radiobusi.ShoutGen.ParseConfig - [SQL SELECT * FROM RadioBusi.RadioBusi_song JOIN RadioBusi.RadioBusi_playlist WHERE RadioBusi_playlist.Name = 'Placebo 2';] 18 [main] DEBUG com.radiobusi.ShoutGen.ParseConfig - this is able to be broken up[SQL SELECT * FROM RadioBusi.RadioBusi_song JOIN RadioBusi.RadioBusi_playlist WHERE RadioBusi_playlist.Name = 'Placebo 2';] 78 [main] ERROR com.radiobusi.ShoutGen - An error occured instantiating the class ShoutGen java.lang.ExceptionInInitializerError at com.mysql.jdbc.Util.stackTraceToString(Util.java:351) at com.mysql.jdbc.Util.<clinit>(Util.java:116) at com.mysql.jdbc.NonRegisteringDriver.parseURL(NonRegisteringDriver.java:672) at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:277) at java.sql.DriverManager.getConnection(DriverManager.java:582) at java.sql.DriverManager.getConnection(DriverManager.java:185) at com.radiobusi.ShoutGen.PlayList.<init>(Unknown Source) at com.radiobusi.ShoutGen.ShoutGen.<init>(Unknown Source) at com.radiobusi.ShoutGen.ShoutGen.main(Unknown Source) Caused by: java.lang.RuntimeException: Can't load resource bundle due to underlying exception java.util.MissingResourceException: Can't find bundle for base name com.mysql.jdbc.LocalizedErrorMessages locale en_AU at com.mysql.jdbc.Messages.<clinit>(Messages.java:60) ... 9 more Caused by: java.util.MissingResourceException: Can't find bundle for base name com.mysql.jdbc.LocalizedErrorMessages locale en_AU at java.util.ResourceBundle.throwMissingResourceException(ResourceBundle.java:1521) at java.util.ResourceBundle.getBundleImpl(ResourceBundle.java:1260) at java.util.ResourceBundle.getBundle(ResourceBundle.java:715) at com.mysql.jdbc.Messages.<clinit>(Messages.java:58) ... 9 more Exception in thread ""main"" java.lang.NullPointerException at com.radiobusi.ShoutGen.ShoutGen.main(Unknown Source) My mysql database locale is en_US on solaris but my ubuntu mysql database is the also en_US. Anybody got any idea's? Im not sure what other information is needed so if you would like more information just let me know in the comments. Jars that get packaged junit-4.8.1.jar libshout.jar log4j-1.2.15.jar mysql-5.1.6.jar munderwo@opensolaris:~/ShoutGen-Java$ uname -a SunOS opensolaris 5.11 snv_111b i86pc i386 i86pc Solaris MySQL Version: MySQL 5.1.30 Cheers Mark I think the reason for this surprise surprise user error :) I removed any mysql jdbc from my lib directory in my source code and then put the mysql jdbc connector that came with opensolaris (looks like it came from sun studio) in lib/ext of java. Once I did this it all seemed to work. On closer inspection I think I might have still had the ubuntu mysql JDBC driver in my class path and quite possibly before the cross-platform jar. So I suspect that this was the problem. Thanks for all your help! Mark.  The error says: Can't find bundle for base name com.mysql.jdbc... locale en_AU So it seems currently you are running on Australian locale I think you should first try switching the locale to en_US and try whether it works. [EDIT] Also please make sure that the path where your mysql connector/driver are stored does not contain any illegal characters. See this link. well it works on my ubuntu box and that has locale set to en_AU. But i tried it and interestingly got the same message but for the en_US locale. Thoughts? also check whether the path where mysql connector is stored does not contain any illegal characters. Illegal characters can also be great culprits in such cases. I have update the answer to reflect it. the path to the jar is /export/home/munderwo/ShoutGen-Java/lib So I cant see any illegal characters in there. Thanks for the link and the help tho."
995,A,"When would isSearchable return false for an Oracle JDBC column? In what cases would a call to java.sql.ResultSetMetaData.isSearchable(int col) return false for an Oracle database? The documentation for the method doesn't really answer the question: ""Indicates whether the designated column can be used in a where clause."" I can think of only one case - when the column is the result of an aggregate function (in which case it would have to be part of a HAVING filter not a WHERE filter). Are there any other cases? This is more related to the type of the column value not how the column is selected. This information is stored in DatabaseMetaData#getTypeInfo(). The column SEARCHABLE can return either DatabaseMetaData.typePredNone (not searchable) or other values. 9: SEARCHABLE short => can you use ""WHERE"" based on this type: typePredNone - No support typePredChar - Only supported with WHERE .. LIKE typePredBasic - Supported except for WHERE .. LIKE typeSearchable - Supported for all WHERE .. Here's a snippet which displays this information: DatabaseMetaData databaseMetaData = connection.getMetaData(); ResultSet typeInfo = databaseMetaData.getTypeInfo(); System.out.println(""type name | data type | searchable""); System.out.println(""-------------------------------+-----------+------------""); while (typeInfo.next()) { String typeName = typeInfo.getString(""TYPE_NAME""); int dataType = typeInfo.getInt(""DATA_TYPE""); boolean searchable = typeInfo.getShort(""SEARCHABLE"") != DatabaseMetaData.typePredNone; System.out.printf(""%-30s | %-9d | %-9s%n"" typeName  dataType searchable); } This yields something like following on a PostgreSQL 8.4 connection:  type name | data type | searchable -------------------------------+-----------+------------ bool | -7 | true bytea | -2 | true char | 1 | true name | 12 | true int8 | -5 | true bigserial | -5 | true int2 | 5 | true int2vector | 1111 | true int4 | 4 | true serial | 4 | true regproc | 1111 | true text | 12 | true (*snip* it were about 270 rows all TRUE by the way) The data type is correlatable with ResultSetMetaData#getColumnType(). So there are no examples where this would be false? What's the point then? :) I honestly have no idea. I've never used it as well I don't see any real world benefits for this except maybe in webbased database management tools on top of JDBC. I by the way did another test on MySQL also all true. I also did a more explicit test on `typeInfo.getShort(""SEARCHABLE"") == DatabaseMetaData.typeSearchable` and it was all `true`."
996,A,Are there any illegal characters when using named parameters in JDBC? I'm using named parameters in a query to match fields in a map-like data structure. The data structure can have fields or another map-like data structure. This nested structure is repeatable ad nauseum. I would like to name the parameters in the query using an XPath like language that can be parsed to indicate further nested lookups. So the question is what characters are legal in a named parameter declaration? The named parameters should at least be compatible with the restrictions on parameternames in your database. For Oracle parameter-names consists of a letter optionally followed by more letters numerals dollar signs underscores and number signs. Parameternames should not be longer than 30 characters. So characters such as hyphens slashes and spaces are not allowed. Do you have a link by chance? I guess the answer is just that it's implementation specific. Would've thought there would be a general constraint on this like in ANSI or something but I guess not.
997,A,"How does JDBC use abstract factory? I got an exam in two days and one of the questions is how JDBC uses the abstract factory. I myself am not so skilled with design patterns so maybe somebody here has the answer. I was thinking that maybe DriverManager.getConnection(url) is an example of abstract factory but am not sure. Is it an abstract factory or is it a factory method? Obviously the purpose of the question is for you to be able to understand the Abstract Factory Pattern and how it is used. The best way for you to find this out is to read about it; here is the wikipedia article on the Abstract Factory Pattern. http://en.wikipedia.org/wiki/Abstract_factory_pattern I find it really hard learning patterns. Getting feedback from others might be what I need to understand them. Anyway I was thinking that DriverManager is the abstract factory and Connection is the abstract product. When a url is given to the abstract factory(DriverManager) it decides what kind of factory to use like WinDriverFactory DerbyDriverFactory etc. and call one of those to get the Connection. @bobjink: yes I think your assessment is correct; sounds like you have a better grasp on patterns than you may think! :-) Thx just what I wanted to hear! Still not 100% i get it. DP's used in program does not look like the ones in the books. Fx it confuses me that the abstract factory takes a String/Url and not a factory like in the example. Anyway thx for your coment :) @bobjink: yes that's correct; usage in real life doesn't look like the books. This is because the design patterns are just that patterns; they describe a certain ideal but not a precise form. Much like the sweater your grandmother made for you (say) doesn't look precisely like the pattern she used; maybe she used a different yarn maybe she made the sleeves too long (like mine did) maybe she forgot to add a collar; the specifics are dependent upon her implementation but the pattern that she used was still there. Design patterns are all about being able to ""see the forest for the trees"".  Your exam is probably going to be about Design Patters so I recommend that you go ahead and study design patters in details. A good book for this is Objects Components  Models and Patterns with ISBN 9783540698234. Please make sure to study all the patterns in detail since is mostly theory. If you need examples go to wikipedia or other sources those are very helpful to understand the theory. I am sure you will get the point if someone here points you out the answer but what the teacher is looking is for you to understand the concept. If this is an exam about JDBC instead then getting the answer from here will not be a big problem. I hope you do well in your exam."
998,A,How do I setup my MySQL with Eclipse IDE? I am using Eclipse EE IDE and I am using the MySql Connector/J driver. How do I set up a properties file with all the information(DB URL DBusernameetc) Also I see that you need a DBname and DBurl for the properties file How do I determine/create this name for the database. I have already looked at the mysql website for this and am still having trouble if somebody could pleasee help me I would appreciate it. Solution: I was able to get it working through the plugin available with Eclipse but I soon realized this limited me with the use of my Tomcat server so I re organized my directories and set up Tomcat to use with my Eclipse and also be available to other resources. You should use MyPHPAdmin or MySQL GUI tools for MySQL setup and management  Eclipse doesn't use a database for anything so even if you would create a properties file it would ignore it. If you're using the DB plugin then you can use the UI to create a connection for the database. The wizard will ask for all the informations and save them somewhere (probably not as a property file). If you need the database in your own project then you must define the format of the property file yourself read it at startup and use the information to create a datasource.
999,A,"Using a PreparedStatement to persist an array of Java Enums to an array of Postgres Enums I have a Java Enum: public enum Equipment { Hood Blinkers ToungTie CheekPieces Visor EyeShield None;} and a corresponding Postgres enum: CREATE TYPE equipment AS ENUM ('Hood' 'Blinkers' 'ToungTie' 'CheekPieces' 'Visor' 'EyeShield' 'None'); Within my database I have a table which has a column containing an array of ""equipment"" items: CREATE TABLE ""Entry"" ( id bigint NOT NULL DEFAULT nextval('seq'::regclass) ""date"" character(10) NOT NULL equipment equipment[] ); And finally when I am running my application I have an array of the ""Equipment"" enums which I want to persist to the database using a Prepared Statement and for the life of me I can't figure out how to do it. StringBuffer sb = new StringBuffer(""insert into \""Entry\"" ""); sb.append(""( \""date\"" \""equipment \"" )""); sb.append("" values ( ? ? )""); PreparedStatement ps = db.prepareStatement(sb.toString()); ps.setString(""2010-10-10""); ps.set??????????? Just to answer some of the comments below. The example is only illustrative not the exact code I'm using. I know date is probably illegal as a column name didn't really think while I was setting up the example :) I will be normalizing but wanted to if working wwith an enum array was possible. Doesn't sound like it from below without a hack of some kind You should read this. I'd suggest that your code look more like this:  // A column named ""date"" is probably illegal and not very illustrative. ""date"" is a keyword for most databases. // Building a string that never changes again and again is a waste of CPU and heap private static final String INSERT_SQL = ""insert into Entry(dateequipment) values(??)""; PreparedStatement ps = db.prepareStatement(INSERT_SQL); // Use the type system properly. Dates should be DATE type columns in a database. Why string? ps.setDate(entryDate); // You shouldn't want to insert an array of values; that's not normalized. ps.setString(equipmentEnumValue.name()); Psst `name()` not `getName()`. And on retrieval use `Enum#valueOf(String)` on the outcome of `ResultSet#getString()`. +1 for normalizing. I had already read that article duffymo works perfectly for single enum entries but not for arrays. As you suggest I should normalize but was just interested to know if the arrays were possible.  You are trying to do two non standards things in plain JDBC: enums and arrays. None of them is very straightforward - though both can be done. But I advise against both: I prefer to use ad-hoc-enums (just integers in some parametric table) and avoid arrays inside the database except in very special cases. If you insist attack one problem at a time. BTW you have two other issues: identifiers (tables and column names) with mixed cases (that must be quoted to avoid postgresql folding to lower case) and a column with a reserved sql word (date) as name. This is not bad but it certainly does not make your developer life easier... And more BTW: beware of that space after \""equipment \"" First time using Postgres so thanks for the info about case. Was wondering why I needed the quotes @McGin : some more info here http://stackoverflow.com/questions/2774406/psycopg2-doesnt-like-table-names-that-start-with-a-lower-case-letter/2776308#2776308  I ran into this exact problem and could not find a good solution. The solution I ended up settling on was to insert as an array of String: conn.createArrayOf(""varchar"" elements.toArray()); and to have an assignment cast in the DB: CREATE OR REPLACE FUNCTION cast_meal_array(src_str character varying[]) RETURNS meal_type[] AS $$ BEGIN RETURN src_str::text[]::meal_type[]; END; $$ LANGUAGE plpgsql; DROP CAST IF EXISTS (character varying[] as meal_type[]); CREATE CAST (character varying[] AS meal_type[]) WITH FUNCTION cast_meal_array(character varying[]) AS assignment; I was not happy with this solution but it does work and does not require any particular JDBC wizardry. Note that you could also probably just have the cast on your prepared statement if you're willing to do it for every statement."
1000,A,How to set Cursor type in JDBC? I'm running tomcat and have some jsp pages that display a subset of a table. I show 20 rows at a time on a single page. When the table has large amounts of data the jsp page doesn't render. I'm guessing that the ResultSet is using a client side cursor. I've worked with ASP in the past and we always used server side forward only cursors and never had any problems with large amounts of data. Our database is oracle 10g. How can I specify a server-side forward-only cursor in JDBC? The oracle driver implements server-side cursors via the FetchSize property. Unfortunately JDBC doesn't explicitly allow for setting client vs server-side cursors so different drivers implement it in different ways. Here are the other links that helped: Fetch Size Cursors Oracle Driver  Not quite answering the question but have you considered explicitly adding paging to your SELECT query using ROWNUM or ROWNUMBER in your WHERE clause? eg: for the second page of data 20 element page size: SELECT * FROM MyDataObjects WHERE rownum > 20 AND rownum < 41 This would ensure that at most one page of records are returned removing the large cursor issue. I think in oracle you need to nest the rownum using a subquery... but we had considered it. Our system is quite complex and includes live filtering that is applied while viewing multiple lists of vastly different things... The dynamic SQL made it more difficult to page via the rownum. In Oracle rownum needs to be in a subquery only if you use ORDER BY... Oracle assigns rownum before doing the ORDER BY so using where with rownum ends up selecting rows by their unsorted row number. Whoops that's what I get for writing queries without testing them. Thanks for the correction...  Statement stmt = con.createStatement(ResultSet.TYPE_FORWARD_ONLY); ResultSet rs = stmt.executeQuery(sql); This should set it but apparently some drivers ignore it. You could always try and set it again at ResultSet level. rs.setFetchDirection(ResultSet.TYPE_FORWARD_ONLY); Hope that helps. According to Connection createStatement documentation the type is forward only by default... and really with a large amount of data the performance bonus is in the server-side cursor over the forward-only portion. I'll incorporate this though. Note that I tried this code with few modifications and I did not see server side cursor type behaviour until I add stmt.setFetchSize(Integer.MIN_VALUE);
1001,A,"Connecting to hosted MySQL server with Java I've been recently trying to connect to a hosted MySQL using Java but can't get it to work. I can connect to a local MySQL with localhost using: connect = DriverManager.getConnection(""jdbc:mysql://localhost/lego?"" + ""user=******&password=*******""); (Replacing the astrisks withmy username and password) I can connect to the hosted MySQL database fine with PHP using: mysql_connect('mysql.hosts.co.uk''******''**********'); mysql_select_db('test'); My problem is I cannot connect via Java. I have an Exception which is caught if the connection doesn't work and this is always printed out. Any ideas why it isn't working? Am I doing something wrong? Thanks for your time InfinitiFizz Can you connect to the server via another mysql client such as the mysql query browser? How about with another user? Please show the exception as well as the connection string you use (with username/password replaced). I find Squirrel a very handy tool for testing database connections as it is written in java and hence uses the same connectors you use in your program. Often it's just an error in the connection string http://squirrel-sql.sourceforge.net/ Replace `catch (Exception e) { System.out.println(""Something failed""); }` by `catch (Exception e) { e.printStackTrace(); }` or just `catch (Exception e) { throw e; }` and update your question to include the valuable information you got instead. It tells something about the cause of the problem. You know once the cause is *understood* the solution is obvious ;) since it works in php (i guess you didn't try to connect from a local place with php???) it shouldn't be a port problem... but you should check that port 3306 is open... and ask the hosts company about that. Have you noticed that in the DriverManager http://java.sun.com/javase/6/docs/api/java/sql/DriverManager.html you have: getConnection(String url) but also: getConnection(String url String user String password) Perhaps it would work better...  My guess is that you need to select a non-standard port since I'd imagine the hosting server is serving lots of MySQL instances and they can't all use the normal one. I don't see selection of a port here. If that's not it perhaps there is a firewall issue somewhere along the way that's blocking the port or connection."
1002,A,"Configure Hibernate to obtain a fresh connection from a connection pool How do I configure Hibernate so that each time I call sessionFactory.openSession() it connects with a new connection from the connection pool? The connection pool is managed by Websphere Application Server and is a JDBC Data Source. Thanks What is the reason for this requirement? To avoid stale connections in the pool? I need to open 2 sessions in a single request in a web application. Right now it appears that both sessions are using the same connection because when the first session is closed (manually calling session.close()) sometimes the other session will throw a ""session closed"" exception when trying to run more queries on it. The second session is open by a child thread which means that the child thread can keep living even after the (HTTP) request is complete. Could you show a simplified code where the problem persist ? I think a session is 1:not thread safe you should not pass a session object to another thread. 2:thread bound (depending on the tx mgnt stack you use). Do you open the two sessions in the same thread ? if yes try to open each of them in a different thread I open 2 sessions in 2 different threads. How do I configure Hibernate so that each time I call sessionFactory.openSession() it connects with a new connection from the connection pool? This is the default behavior each session will get a dedicated connection from the connection pool. Right now it appears that both sessions are using the same connection because when the first session is closed (manually calling session.close()) sometimes the other session will throw a ""session closed"" exception when trying to run more queries on it. No they are not. But maybe the second connection gets released at the end of the transaction initiated for the request. Have a look at the hibernate.connection.release_mode configuration parameter you might want to use on_close. But without more details on your transaction strategy it's impossible to say anything. The second session is open by a child thread which means that the child thread can keep living even after the (HTTP) request is complete. Take my previous advice with a grain of salt you should just not spawn unmanaged threads and I don't know how the application server will behave. I explain in this other answer what would be the right way. Thanks so much I got it working. @ferrari You're welcome. Glad it's working."
1003,A,"JDBC Code Change From SQL Server to Oracle In the JDBC code I have the following that is working with SQL Server: CallableStatement stmt = connection.prepareCall(""{ call getName() }""); ResultSet rs = stmt.executeQuery(); if(rs != null) { while(rs.next()) { //do something with rs.getString(""name"") } } Multiple rows are returned for the above situation. I understand that the use of a cursor is required to loop through the table in Oracle but is there any way to keep the above code the same and accomplish the same thing? Sample PL/SQL code would be much appreciated. Thanks in advance. This is straight JDBC so it'll work with any database that has a valid JDBC driver. It assumes of course that the stored proc exists in both and that you aren't using any non-standard vendor-proprietary code in your class. The part that is RDBMS-specific I think is the ""call getName()"". I'm guessing that in SQL Server getName() is a function that returns multiple rows and that as a convention it implicitly treats these as queries. Oracle does not allow this. The closest construct I know of would be ""call ? = getName()"" which would require more involved changes to the Java code than the other answer I submitted. I don't have the stored procedure in Oracle yet. Would returning a SYS_REFCURSOR with a function suffice for the above code? Sample PL/SQL code would be nice. A ResultSet IS a cursor. I'm sure your example is a simple one but I didn't think the JDBC API had to know whether it was Oracle underneath. That's the whole point of JDBC. If it can't do it I'd say either it's poorly designed or you're misunderstanding something. Something feels wrong here. The CallableStatement should be abstracting all this for you. You should not want to return a raw cursor. You should be iterating through the ResultSet that's returned package the results into an object or collection and closing the ResultSet and Statement in method scope. Anything else is asking for resource leaks.  You could implement getName() as a pipelined function: CREATE OR REPLACE name_record AS OBJECT ( name VARCHAR2(100) ); / CREATE OR REPLACE name_table AS TABLE OF name_record; / CREATE OR REPLACE FUNCTION getName RETURN name_table PIPELINED AS n name_record; BEGIN -- I have no idea what you're doing here to generate your list of names so -- I'll pretend it's a simple query FOR i IN (SELECT name FROM someTable) LOOP n := name_record( i.name ); PIPE ROW(n); END LOOP; END; / You would need to change the actual query in Java to SELECT name FROM TABLE(getName()). I don't know of a way to write an Oracle function that will work with your existing Java code. Is the issue that you want to maintain a single Java codebase that will work with both RDBMS? If so the only thing you need to vary between the two is a string literal which you could store externally in a resource file and load a different resource depending on which database you are running against. Is there a way to approach the PL/SQL code such that nothing needs to be changed in Java?"
1004,A,"Storing database connections in session in a small scale webapp I have a j2ee webapp that's being used internally by ~20-30 people. There is no chance of significant growth in the number of users. From what I understood there's a trade-off between opening a new DB connection for each request made to the webapp (expensive but doesn't block other users when the DB is in use) to using the singleton pattern (doesn't open new connections but only allows one user at a time). I thought that since I know that only 30 users will ever use my webapp at the same time maybe the simplest and best solution would be to store the connection as a session attribute thus reducing to a minimum the amount of openings made while still allocating one connection per user. What do you think? No. Don't do that. It's perfectly ok to reconnect to the database every time you need to. Any database management system will do their own connection pool caching I think. If you want to try to keep open connections you'll make it incredible hard for yourself to manage this in a secure bug-free safe etc way. Well I now tried keeping the connection alive. the JSP's I have make a lot of small ajax requests in which I definitely saw an improvement in performance. Probably because the query+data sent in those ajax requests are rather smal so establishing the connection caused most of the overhead. Also I understand completely that this method ""looks"" wrong and like all programmers I also have an OCD against ugly code :) But when thinking it through I can't see any way in which it will cause any security or bugs... can you give me an example?  I think you're getting into premature optimization especially given the scale of the application. Opening a new connection is not that expensive and like Makach says most modern RDBMSs handle connection pooling and will hold connections open for subsequent requests. You'd be trying to write better code than the compiler so to speak.  From what I understood there's a trade-off between opening a new DB connection for each request made to the webapp That is what connection pools are for. If you use a connection pool in your application the pool once initialized is in charge of providing connections for use in the application as and when needed. In a properly tuned connection pool there are going to be enough connections created on reserve that can be provided to the application mitigating the need to create and open a connection only when the application requests for it. I thought that since I know that only 30 users will ever use my webapp at the same time maybe the simplest and best solution would be to store the connection as a session attribute Per-user connections are not a good idea primarily when a web application is concerned. In a web application it is perfectly possible for users to initiate multiple requests to the server (think multi-tabbed browsing). In such a case the use of a single connection per user will result in weird application behavior unless you synchronize access to the connection. One must also consider the side-effect of putting transient attributes into the session - Connection objects are not serializable and hence must be marked transient. If the session is deserialized at some point one has to account for the fact that the Connection object will not be available and must be re-initialized."
1005,A,How to do simple Spring JDBC transactions outside the IoC container? The project I'm working on uses straight JDBC data access in all its boilerplate glory and doesn't use any transactions. I feel like using transactions and simplifying the way data access methods are written is important especially with some changes being made currently. The project has been around for quite a while and isn't suited to an ORM framework. It also uses lots of Singletons (ugh) and untangling it to make it able to use dependency injection would be a fair amount of work and I don't think I could convince anyone that we should do that now. I like the interface of Spring JDBC specifically through its SimpleJdbcTemplate. My question is about how to enable some simple (per servlet request) transactions for this without having to set anything programmatically in every data access method or using the Spring IoC container or AOP. I've played around with my own architecture that ends up with an interface similar to SimpleJdbcTemplate's and can use a single request-local connection and transaction when calls to it are made in the context of a request (through a ServletRequestListener with a ThreadLocal). It seems to work well but I think using a good external library like Spring JDBC would be preferable. Anyone have any experience with this? Perhaps you could use TransactionTemplate and TransactionCallback as described in Programmatic Transaction Management? This doesn't work quite how I was thinking as it would require programmatically wrapping calls using the TransactionTemplate at a higher application level rather than just having every call to the JdbcTemplate use a request-local transaction if possible. It should work fine though.  Spring handles transactions for you declaratively without you having to worry about writing AOP classes. If you're using JDK 5 or higher and Spring 2.5 you have it even better with annotations. I would disagree with per-servlet transactions. You should have a service tier which is the part of the app that knows about units of work. Controllers call into services which handle transactions. I mentioned in the question that the application is not currently in the Spring container and couldn't easily be moved to it. I'd love to use the declarative transactions like that if I could.
1006,A,"What is the best way to present data from a very large resultset? I'm writing a report view of an audit trail and I need to display this in a .jsp. What's the ""best"" way to get the data from the database to the screen? We're using Spring for dependency injection Data Access Objects and Hibernate. I can use hibernate or straight jdbc for this report. If I load all the records into memory I run out of memory. Any ideas that don't involve running the query in the jsp? Just use paging and only load a certain number of rows on the page at a time.  Another way to do it is to use scroll() to stream one row at the time.  The Display Tag Library is very good at presenting paginated result sets in servlets or portlets. But it normally works with the whole list loaded into memory. So you will have to do a little work to get it to work with paginated result sets by implementing the org.displaytag.pagination.PaginatedList interface. There is a tutorial on the Display Tag web site. There isn't very much to the tutorial but then again implementing the interface is pretty easy.  It seems like this is a natural place to use pagination of your Hibernate results -- run the query at the Servlet level and paginate results in a way similar to how this person describes: http://blog.hibernate.org/Bloggers/Everyone/Year/2004/Month/08/Day/14#pagination This is the easiest method of implementing Hibernate pagination I've seen... I like it thanks for the link!"
1007,A,"What is the jTDS JDBC Connect URL to MS SQL Server 2005 Express I'm trying to connect to a MS SQL Server 2005 Express database that is running on the local host from a java program. I have tried the same connect URL (below) that I used on another system (same jave code) that was running MS SQL Server 2000. But that does not work. jdbc:jtds:sqlserver://127.0.0.1:1433/Finance Any ideas? Are you sure it is the correct instance? SQL Express tends to install as named instance like ""localhost\SQLExpress"" instead of a standard instance. So it would be something like: jdbc:jtds:sqlserver://127.0.0.1:1433/Finance;instance=<instance_name> If this doesn't work try dropping the instance name and changing the port to the port used by the named instance: jdbc:jtds:sqlserver://127.0.0.1:<instance_port>/Finance Else try to check your connectivity through OSQL.exe tool first. You can also check the jTDS FAQ on this. second option worked for me (if you specify host and port should not be needed to specify instance....)  I would suggest MicSim's url: jdbc:jtds:sqlserver://localhost/Finance;instance=sqlexpress Check this for jTDS Url Info. This also has some interesting information to help troubleshoot jtds to sql express sorts of problems. Good luck. Let us know how it goes. Thanks for the feedback. This is the first time I am working with SQLServer Express and I am finding it significantly different to SQLServer. I still cant connect properly but it is now down to user permissions not the URL. I'll get back to it as soon as I get home (it is a home system I am working on).  To check whether TCP/IP is enabled and the port is not blocked you can use ""telnet 1433"". Until telnet doesn't connect jTDS won't either. e.g c:>telnet servername 1433 to enable telnet client on windows http://social.technet.microsoft.com/wiki/contents/articles/910.how-to-enable-telnet-client-in-windows-7.aspx"
1008,A,"java.util.Date vs java.sql.Date java.util.Date vs java.sql.Date: when to use which and why? java.sql.Date - when you call methods/constructors of libraries that use it (like JDBC). Not otherwise. You don't want to introduce dependencies to the database libraries for applications/modules that don't explicitly deal with JDBC. java.util.Date - when using libraries that use it. Otherwise as little as possible for several reasons: It's mutable which means you have to make a defensive copy of it every time you pass it to or return it from a method. It doesn't handle dates very well which backwards people like yours truly think date handling classes should. Now because j.u.D doesn't do it's job very well the ghastly Calendar classes were introduced. They are also mutable and awful to work with and should be avoided if you don't have any choice. There are better alternatives like the Joda Time API ( which might even make it into Java 7 and become the new official date handling API - a quick search says it won't). If you feel it's overkill to introduce a new dependency like Joda longs aren't all that bad to use for timestamp fields in objects although I myself usually wrap them in j.u.D when passing them around for type safety and as documentation.  Congratulations you've hit my favorite pet peeve with JDBC: Date class handling. Basically databases usually support at least three forms of datetime fields which are date time and timestamp. Each of these have a corresponding class in JDBC and each of them extend java.util.Date. Quick semantics of each of these three are the following: java.sql.Date corresponds to SQL DATE which means it stores years months and days while hour minute second and millisecond are ignored. Additionally sql.Date isn't tied to timezones. java.sql.Time corresponds to SQL TIME and as should be obvious only contains information about hour minutes seconds and milliseconds. java.sql.Timestamp corresponds to SQL TIMESTAMP which is exact date to the nanosecond (note that util.Date only supports milliseconds!) with customizable precision. One of the commonest bugs in JDBC drivers in relation to these three types is that the types are handled incorrectly. This means that sql.Date is timezone specific sql.Time contains current year month and day et cetera et cetera. Finally: Which one to use? Depends on the SQL type of the field really. PreparedStatement has setters for all three values #setDate() being the one for sql.Date #setTime() for sql.Time and #setTimestamp() for sql.Timestamp. Do note that if you use ps.setObject(fieldIndex utilDateObject); you can actually give a normal util.Date to most JDBC drivers which will happily devour it as if it was of the correct type but when you request the data afterwards you may notice that you're actually missing stuff. I'm really saying that none of the Dates should be used at all. What I am saying that save the milliseconds/nanoseconds as plain longs and convert them to whatever objects you are using (obligatory joda-time plug). One hacky way which can be done is to store the date component as one long and time component as another for example right now would be 20100221 and 154536123. These magic numbers can be used in SQL queries and will be portable from database to another and will let you avoid this part of JDBC/Java Date API:s entirely. Nice answer. But isn't storing dates as longs a bit unfriendly for the DBA? Perhaps however DBA:s generally tend to their RDBMS of choice and rejecting everything that isn't about that RDBMS directly (*I'm looking at you Oracle fans*) while Java applications are expected to work with all of them. Personally I don't like to put my logic into DB at all. My mysql column is a datetime but doing ps.setDate(new java.sql.Date(myObject.getCreatedDate().getTime())); I am loosing the milliseconds portion how to fix this? To not lose your milliseconds: new java.sql.Timestamp( utilDate.getTime() ) I mentioned that it's a common *bug* that it is TZ specific while it by specification shouldn't be. you mention in one place that sql.Date - stores time zone info and in another place that it doesn't. So to conclude the understand it correctly: the sql.Date should not hold the timezone information but it does?!  The java.util.Date class in Java represents a particular moment in time (e.g. 2013 Nov 25 16:30:45 down to milliseconds) but the DATE data type in the DB represents a date only (e.g. 2013 Nov 25). To prevent you from providing a java.util.Date object to the DB by mistake Java doesn’t allow you to set a SQL parameter to java.util.Date directly: PreparedStatement st = ... java.util.Date d = ... st.setDate(1 d); //will not work But it still allows you to do that by force/intention (then hours and minutes will be ignored by the DB driver). This is done with the java.sql.Date class: PreparedStatement st = ... java.util.Date d = ... st.setDate(1 new java.sql.Date(d.getTime())); //will work A java.sql.Date object can store a moment in time (so that it’s easy to construct from a java.util.Date) but will throw an exception if you try to ask it for the hours (to enforce its concept of being a date only). The DB driver is expected to recognize this class and just use 0 for the hours. Try this: public static void main(String[] args) { java.util.Date d1 = new java.util.Date(12345);//ms since 1970 Jan 1 midnight java.sql.Date d2 = new java.sql.Date(12345); System.out.println(d1.getHours()); System.out.println(d2.getHours()); }  The only time to use java.sql.Date is in a PreparedStatement.setDate. Otherwise use java.util.Date. It's telling that ResultSet.getDate returns a java.sql.Date but it can be assigned directly to a java.util.Date. Ehm ResultSet#getDate() returns sql.Date (which extends util.Date). @Esko - ""Ehm"" I fixed that before you commented (and downvoted). Well maybe that's some caching issue then because I didn't see your edit earlier. You still have a certain semantic issue in your answer though which I go through in my answer so the downvote stands. It's important to note that the reason a java.sql.Date can be assigned to a java.util.Date is because the first is a subclass of the second. Why is it 'telling' that a `java.sql.Date` can be assigned to a `java.util.Date` when the former extends the latter? What's the point you're trying to make?  I had the same issue the easiest way i found to insert the current date into a prepared statement is this one: preparedStatement.setDate(1 new java.sql.Date(new java.util.Date().getTime()));"
1009,A,"Is JDBC secure? I am new to JDBC and the new project require me to use JDBC. What I want to know is is the JDBC secure? How to prevent ""Mysql Injection""-like problem? What are the security issues that I need to pay attention when I use JDBC? And how to ensure I mean optimize the security in order to prevent from hackers to hack the database? EDIT: I tried google if I google: ""php mysql security problems"" => it gives a lot of result if I google: ""jdbc mysql security problems"" => hardly see any related pages Does it mean using jdbc is secure? Dont need to worry about being hack? I think whenever anyone asks a question ""is x secure"" there is a high likelyhood that there is a security vulnerability in their code because security is more of a process than a fact. Code/tools/sites are not secure. They are run and used in a secure manner (or not) and may have known vulnerabilities. When people ask is X secure they tend to think that if the answer is ""yes"" they don't have to think about security anymore. And that thinking leads to vulnerabilities. JDBC is purely the transport between your program and the database. It is reasonably secure in as much as the sign on protocol is not vulnerable to network sniffing and it is very very difficult to inject anything into the network traffic. However JDBC merely transports your SQL to the database and returns the resulting dataset. If your program is vulerable to SQL injection it will be vulnerable whether you are using a direct connection odbc or jdbc. The only way to really protect yourself against sql injection is to use prepared statements with ""?"" type place holders for user input. Never string together SQL statements using unsecure input (this includes both direct user input and data from a table that was input by a user).  JDBC is a database connection protocol it's as secure as all other means to connect to database. Most secure issues have nothing to do with JDBC protocol itself. For example you can minimize the risk of SQL Injection by using Prepared Statement. This will be true regardless how you connect to the database. Great explaination. I understand now thanks.  Use prepared statements. For a hypothetical login you might use this for example: PreparedStatement stmt = conn.prepareStatement(""SELECT * FROM member WHERE member_username = ? AND member_password = ?""); stmt.setString(1 username); stmt.setString(2 password); stmt.execute(); ResultSet rs = stmt.getResultSet(); // ... This will completely shield you from SQL Injection vulnerabilities. Technically the JDBC spec does not require the driver to correctly escape the argument. I don't know which drivers do it correctly and which don't. Thanks this is what I have in my current code. I mean the prepared statements. I am relief now :) This works for PHP/MySQL as well as pretty much any other modern/web programming language. And what is the unsecure version ? @Tom: I think it does by implication. The notion of escaping only applies at the SQL syntax level. Anyway a JDBC driver that required the caller to ""SQL escape"" String arguments to setString(int String) would be so non-portable as to be unusable. ZeroCool: the unsecure version is something like conn.createStatement().execute(""SELECT * from mytable where username='""+username+""'"");  Always use field validators matching some specific regular expressions rules before passing anything to the DB acceess api.  is the JDBC secure? The security of JDBC is a property of the JDBC driver that you use. In general if your driver uses an SSL transport layer it is as secure as the strength of your SSL keys. If it uses an unencrypted transport it is not secure. How to prevent ""Mysql Injection""-like problem? When you compose an SQL query for JDBC be careful not to incorporate 'raw' strings that might contain embedded SQL. For example: String query = ""SELECT * FROM SOME_TABLE WHERE X = '"" + someString + ""' ;""; If someString contains an unescaped ""'"" character what you intend to be an SQL literal string could actually be changed into something completely different. The fix is to either reject someString if it contains any ""'"" characters (or other nasties) or preprocess it with a method that inserts SQL string escapes. Another (simpler / more reliable) approach is to use prepared statements with ""?"" placeholders and inject the values into the query using setString(...) etc. What are the security issues that I need to pay attention when I use JDBC? Apart from the above I don't know of anything specific to JDBC. Indeed neither of the above issues is specific to JDBC. And how to ensure I mean optimize the security in order to prevent from hackers to hack the database? Buy / read a good book on building secure systems. Be careful. Pay for a security expert to audit your code / system.  Or you can use the utility method: ""org.apache.commons.lang.StringEscapeUtils.escapeSql(java.lang.String str)"" to prevent sql-injection from happening. String sanitation is always be best policy to prevent sql-injection or cross-site-scripting attacks. FWIW StringEscapeUtils no longer contains the escapeSql method: http://commons.apache.org/lang/api-3.1/org/apache/commons/lang3/StringEscapeUtils.html"
1010,A,"Prevent jdbc from padding strings on sql insert and update We are using the jdbc-odbc bridge to connect to an MS SQL database. When perform inserts or updates strings are put into the database padded to the length of the database field. Is there any way to turn off this behavior (strings should go into the table without padding)? For reference we are able to insert field values that don't contain the padding using the SQL management tools and query analyzer so I'm pretty sure this is occuring at the jdbc or odbc layer of things. EDIT: The fields in the database are listed as nvarchar(X) where X = 50 255 whatever EDIT 2: The call to do the insert is using a prepared statement just like: PreparedStatement stmt = new con.prepareStatement(""INSERT INTO....""); stmt.setString(1 ""somevalue""); varchar or char? Still consider changing your driver. I hear you - we will ultimately be using jtds - however deployment is more complicated (esp if you want to use native authentication). The jdbc-odbc bridge is very easy to deploy with and our app is very light on actual SQL usage (we do maybe 50 queries and 100 inserts in a day). If you are using the bundled Sun JDBC-ODBC Bridge driver you may want to consider migrating to a proper MS SQL JDBC driver. Sun does not recommend that the bridge driver be used in a production environment. The JDBC-ODBC Bridge driver is recommended only for experimental use or when no other alternative is available. Moving to a more targeted driver may fix your problem all together or at least it will provide a production ready solution when you do fix the bug. Thanks - in this current situation we fall under the 'or when no other alternative is available'. This is client side early release. Increasing the deployment size and complexity at this phase is undesirable (but we will be on a real driver by beta release)  Are you using CHAR fields in the database or VARCHAR? CHAR pads the size of the field. VARCHAR does not. I don't think JDBC would be causing this. Yeah - that's what I was thinking. But the nvarchars are still getting padded when I make the update calls from jdbc. When I do updates using query analyzer etc... they go in without the padding.  If you can make your insert to work with regular SQL tools ( like ... I don't know Toad for MS SQL Sever or something ) then changing the driver should do. Use Microsoft SQL Server JDBC type IV driver. Give this link a try http://www.microsoft.com/downloads/details.aspx?familyid=F914793A-6FB4-475F-9537-B8FCB776BEFD&displaylang=en Unfortunately these kinds of download comes with a lot of garbage. There's an install tool and another hundreds of file. Just look for something like: intalldir\lib\someSingle.jar Copy to somewhere else and uninstall/delete the rest. I did this a couple of months ago unfortunately I don't remeber exactly where it was. EDIT Ok I got it. Click on the download and at the end of the page click on ""I agree and want to download the UNIX version"" This is a regular compressed file ( use win rar or other ) and there look for that sigle jar. That should work. I've been using the MS SQL driver on a high performance trading application for 3-4 years. Its very reliable. FYI - We've been using jtds in other projects. I've been EXTREMELY pleased with performance and responsiveness of the developers to any issues that have arisen (not many)  How are you setting the String? Are you doing?: PreparedStatement stmt = new con.prepareStatement(""INSERT INTO....""); stmt.setString(1 ""somevalue""); If so try this: stmt.setObject(1 ""somevalue"" Types.VARCHAR); Again this is just guessing without seeing how you are inserting. That does it. I probably could have worked with a different driver (jtds maybe) but the call to setObject works perfectly. Thanks!"
1011,A,"large sql resultsets in java How can I fetch large resultset in java? I have about 140000 rows with 3 columns. Well the same way you a fetch small result set in java. What are your concerns? Performance memory usage...? i would avoid loading such a data set with any kind of complex abstraction. this sounds like a ""batch job"" style application. i would recommend using raw jdbc and map it to a very compact representation without bloat with only 3 colums this should be fairly easy to hold in memory if the strings? are not overly big. avoid loading 140k rows with a tool such as hibernate. it is a great tool but you might run into memory issues if you hold that many entities in the hibernate 1st and 2nd level caches.  I recommend a batch style fetch instead of loading everything. There are performance considerations at the database end when executing a query with a big result set.  (using a java.sql.Connection to your DB): Statement st = cnxn.createStatement(); ResultSet rs = st.executeQuery(""SELECT column1column2your_mom FROM some_table""); while(rs.next()){ Object ob1 = rs.getObject(1); Object ob2 = rs.getObject(2); Ho ob3 = rs.getHo(3); doStuffWithRow(ob1ob2ob3); } Unless your DBMS is pathetically useless results will be read from disk/memory as requested and won't sit in your memory or anything crazy like that. Using the primitives-based ResultSet.getXXX methods is faster than getObject but I didn't feel like specifying column types. Just be patient and let 'er chug. Oh and stay the heck away from ORM here. I just tried this on Postgres 9.1 -- it tried to fetch the whole table into memory! Aha - a Postgres-specific problem -- I'll post the solution in a separate answer. to do this with jdbc postgresql driver you need to call `setAutoCommit(false)` on the `connection` then call `setFetchSize(FETCH_SIZE)` on your `preparedStatement`. but streaming fetch api is implemented per driver and not consistent over all of jdbc. quite annoying.  If you're using PostgreSQL you'll need to setup the Connection and the Statement as follows: Connection cnxn = ...; cnxn.setAutoCommit(false); Statement stmnt = cnxn.createStatement(); stmnt.setFetchSize(1); Otherwise your query is liable to try & load everything into memory. Thanks to http://abhirama.wordpress.com/2009/01/07/postgresql-jdbc-and-large-result-sets/ for documenting that.  There's no special way to retrieve a large result set; this can be done the same as any other database query via JDBC. The key is in how the results are handled. 140000 small records is not too many but if holding them all in application memory at once is a problem consider whether they can be processed ""streamwise"". That is use the information needed from each record then discard the record before retrieving the next. This way the memory requirement doesn't depend on the number of records in the result set. You can also use paging which is built into JDBC if I remember correctly. To avoid memory issues streaming is really the way to go. What does it mean discard the record"
1012,A,"Pattern for creating a database schema using JDBC I have a Java-application that loads data from a legacy file format into an SQLite-Database using JDBC. If the database file specified does not exist it is supposed to create a new one. Currently the schema for the database is hardcoded in the application. I would much rather have it in a separate file as an SQL-Script but apparently there is no easy way to execute an SQL-Script though JDBC. Is there any other way or a pattern to achieve something like this? The ""right"" way is to use Hibernate. Among all other benefits it is capable of creating/updating a DB schema automatically (SO1 SO2).  Your sentence ""there is now easy way to execute an SQL-Script though JDBC"" confused me for a minute but I reckon you are saying ""there is no easy way"". :) Based on what others have said yes... the perfect world scenario is to use an ORM tool like Hibernate but I also understand the fact when you are dealing with legacy stuff at work your team may not want to spend too much time refactoring that project. I agree that you should refactor out the database schema into a separate file. You can actually execute the SQL script using JDBC. I do that all the time when I run my certain testcases. Here's how I do it. I use SQL Server database in my case. So you need to tweak the code to fit your needs. String ddl = ... // load your SQL script file into this string String delimiter = ""GO""; // in my case SQL Server uses GO as delimiter you use whatever you want here. private void executeDDL(String ddl String delimiter) { Connection con = null; try { con = ... // get the connection // enable transaction con.setAutoCommit(false); Statement statement = con.createStatement(); // for every DDL statement execute it for (String sql : ddl.split(delimiter)) { if (StringUtils.isNotBlank(sql)) { statement.executeUpdate(sql); } } statement.close(); con.commit(); } catch (Exception e) { e.printStackTrace(); } finally { try { con.close(); } catch (Exception ignored) { } } } Thank you for this solution seems like I will go with this. However I was hoping for some way that feels less hacked.  In case you are working in a development environment I would advice you to use an ORM tool like Hibernate that forward engineers based on your Java Domain Models to create the DB tables. Hibernate has the feature to auto create/update the tables in case there are changes to DB schema. As you are using SQLite you could have a look at Hibernate for SQLite I have read somewhere that it not advisable to use this feature in a production environment because the incremental table creation might negatively affect the existing data."
1013,A,"How to get the insert ID in JDBC? I want to INSERT a record in a database (which is Microsoft SQL Server in my case) using JDBC in Java. At the same time I want to obtain the insert ID. How can I achieve this using JDBC API? If it is an auto generated key then you can use Statement#getGeneratedKeys() for this. You need to call it on the same Statement as the one being used for the INSERT. You first need to create the statement using Statement.RETURN_GENERATED_KEYS to notify the JDBC driver to return the keys. Here's a basic example: public void create(User user) throws SQLException { try ( Connection connection = dataSource.getConnection(); PreparedStatement statement = connection.prepareStatement(SQL_INSERT Statement.RETURN_GENERATED_KEYS); ) { statement.setString(1 user.getName()); statement.setString(2 user.getPassword()); statement.setString(3 user.getEmail()); // ... int affectedRows = statement.executeUpdate(); if (affectedRows == 0) { throw new SQLException(""Creating user failed no rows affected.""); } try (ResultSet generatedKeys = statement.getGeneratedKeys()) { if (generatedKeys.next()) { user.setId(generatedKeys.getLong(1)); } else { throw new SQLException(""Creating user failed no ID obtained.""); } } } } Note that you're dependent on the JDBC driver whether it works. Currently most of the last versions will do but if I am correct Oracle JDBC driver is still somewhat troublesome with this. MySQL and DB2 already supported it for ages. PostgreSQL started to support it short ago. No wording about MSSQL as I've never used it. For Oracle you can invoke a CallableStatement with a RETURNING clause or a SELECT CURRVAL(sequencename) (or whatever DB-specific syntax to do so) directly after the INSERT in the same transaction to obtain the last generated key. See also this answer. +1 for the extra detail about different drivers. It's better to get the next value in a sequence before the insert than to get the currval after the insert because the latter might return the wrong value in a multi-threaded environment (e.g. any web app container). The JTDS MSSQL driver supports getGeneratedKeys. (should clarify that I usually use Oracle so have very low expectations of a JDBC driver's capabilities normally). @JeeBee: as far as I know this doesn't apply if you're using the *same* statement (inside the same transaction). IIRC Hibernate also works that way. Why hasn't this answer been accepted yet? An interesting side-effect of NOT setting the Statement.RETURN_GENERATED_KEYS option is the error message which is the completely obscure ""The statement must be executed before any results can be obtained."" @BalusC Nice Post. Very Helpful. I just want to ask what's the use of generatedKeys.next(). and why the close(connection preparedStatement generatedKeys); is not working. And Why need to close these 3? Thank you. :) The `generatedKeys.next()` returns `true` if the DB returned a generated key. Look it's a `ResultSet`. The `close()` is just to free resources. Otherwise your DB will run out of them on long run and your application will break. You just have to write up some utility method yourself which does the closing task. See also [this](http://stackoverflow.com/questions/3148092/java-jdbc-mysql-connector-how-to-resolve-disconnection-after-a-long-idle-time/3148857#3148857) and [this](http://stackoverflow.com/questions/2313197/jdbc-mysql-connection-pooling-practices/2313262#2313262) answer. @BalusC thx for this helpful post. I have a question if you set autocommit(false) immediately after the ""try"" and then set it back to true in ""finally"" would you have problems by concurrent threads? i mean if thread 1 generated key ""X""  will thread 2 generate a new key other than""X"" even if thread 1 has not yet committed? Great! Thanks for share. As aways The Oracle is in diferent way of all the rest ( like IE ) ... Very helpful post.. Great explanation @ChrisWinters Thanks... your comment saved me a headache! I was getting the damn error :P If you have an insert with an ON DUPLICATE KEY clause and there is a duplicate key is there any way to get back the id/key that was duplicated? or do I have to do my own manual query? getGeneratedKeys() will not return as a new insert wasn't actually done. @BalusC I am inserting GUID's into my database table. `rs.getString(1)` gives me null back. How can I fix that?  I'm using SQLServer 2008 but I have a development limitation: I cannot use a new driver for it I have to use ""com.microsoft.jdbc.sqlserver.SQLServerDriver"" (I cannot use ""com.microsoft.sqlserver.jdbc.SQLServerDriver""). That's why the solution conn.prepareStatement(sql Statement.RETURN_GENERATED_KEYS) threw a java.lang.AbstractMethodError for me. In this situation a possible solution I found is the old one suggested by Microsoft: How To Retrieve @@IDENTITY Value Using JDBC import java.sql.*; import java.io.*; public class IdentitySample { public static void main(String args[]) { try { String URL = ""jdbc:microsoft:sqlserver://yourServer:1433;databasename=pubs""; String userName = ""yourUser""; String password = ""yourPassword""; System.out.println( ""Trying to connect to: "" + URL); //Register JDBC Driver Class.forName(""com.microsoft.jdbc.sqlserver.SQLServerDriver"").newInstance(); //Connect to SQL Server Connection con = null; con = DriverManager.getConnection(URLuserNamepassword); System.out.println(""Successfully connected to server""); //Create statement and Execute using either a stored procecure or batch statement CallableStatement callstmt = null; callstmt = con.prepareCall(""INSERT INTO myIdentTable (col2) VALUES (?);SELECT @@IDENTITY""); callstmt.setString(1 ""testInputBatch""); System.out.println(""Batch statement successfully executed""); callstmt.execute(); int iUpdCount = callstmt.getUpdateCount(); boolean bMoreResults = true; ResultSet rs = null; int myIdentVal = -1; //to store the @@IDENTITY //While there are still more results or update counts //available continue processing resultsets while (bMoreResults || iUpdCount!=-1) { //NOTE: in order for output parameters to be available //all resultsets must be processed rs = callstmt.getResultSet(); //if rs is not null we know we can get the results from the SELECT @@IDENTITY if (rs != null) { rs.next(); myIdentVal = rs.getInt(1); } //Do something with the results here (not shown) //get the next resultset if there is one //this call also implicitly closes the previously obtained ResultSet bMoreResults = callstmt.getMoreResults(); iUpdCount = callstmt.getUpdateCount(); } System.out.println( ""@@IDENTITY is: "" + myIdentVal); //Close statement and connection callstmt.close(); con.close(); } catch (Exception ex) { ex.printStackTrace(); } try { System.out.println(""Press any key to quit...""); System.in.read(); } catch (Exception e) { } } } This solution worked for me! I hope this helps!  I'm hitting Microsoft SQL Server 2008 R2 from a single-threaded JDBC-based application and pulling back the last ID without using the RETURN_GENERATED_KEYS property or any PreparedStatement. Looks something like this: private int insertQueryReturnInt(String SQLQy) { ResultSet generatedKeys = null; int generatedKey = -1; try { Statement statement = JDBCConn.createStatement(); statement.execute(SQLQy); } catch (Exception e) { errorDescription = ""Failed to insert SQL query: "" + SQLQy + ""( "" + e.toString() + "")""; return -1; } try { generatedKey = Integer.parseInt(readOneValue(""SELECT @@IDENTITY"")); } catch (Exception e) { errorDescription = ""Failed to get ID of just-inserted SQL query: "" + SQLQy + ""( "" + e.toString() + "")""; return -1; } return generatedKey; } This blog post nicely isolates three main SQL Server ""last ID"" options: http://msjawahar.wordpress.com/2008/01/25/how-to-find-the-last-identity-value-inserted-in-the-sql-server/ - haven't needed the other two yet. That the application has only one thread doesn't make a race condition impossible: if two clients insert a row and retrieve the ID with your method it may fail. Why would you? I'm just glad I'm not the poor sod who has to debug your code when allowing multiple threads!"
1014,A,"How can I know if 10385274000 fits into: NUMBER(10) for Oracle I been working the whole week to troubleshot a production error. I have eventually got the the point where I can find the culprit record which is causing all the mess. I've got the following error message: java.sql.SQLException: [BEA][Oracle JDBC Driver][Oracle]ORA-01438: value larger than specified precision allows for this column Eventuall from all the info I think this might be the wrong data the system is trying to insert: 10385274000 Into a NUMBER(10) How can I know if that value fits or no? Thank you EDIT As per Michel Todd suggestion: create table xyz( testfield number( 10 ) ); insert into xyz values( 10385274000 ) Error: ORA-01438: value larger than specified precision allowed for this column Thank you guys!!! Thank you stackoverflow EDIT Notes to my self ( not to forget what was the problem ) I had this Oracle product which stores in a database table the time of an event START_TIME|END_TIME It turns out everynight it backups this information into another table but performs a trnsformation in the process. It does store as: TOTALTIME The problem comes when this field is calculated by subtracting ENDTIME - STARTTIME. The resulting number is stored in this column which is defined as: NUMBER(10) Well it turns out if END_TIME-START_TIME are too far away in the time ( about 4 months or so ) the value ( in milliseconds ) would be SO big it won't fit in the target column ( I guess it has something like endTime.getTime() - startTime.getTime() inside the code ) All this sounds too easy and too silly now but it took me 4 day+ to find out because since this is a closed application I didn't have a clue of what was happening the only thing I've got was the stacktrace. I had to reverse enginering ( in the OLD sense of the word by hand and obviously with out the source ) all the process to find out this. When I did it I've got the same error in my ""hand coded migrator"" and find out how to solve it!! If you do use the word 'Urgent' please use it in a readable format instead of a ongoing word. If it is urgent it is urgent but people have to know that it is urgent which is hard when it is : ""Urgeeeent!"" A q&d way to do it is to create a temp table containing a number(10) and trying to insert that value. It if it works that's not the problem. The number 10 in NUMBER(10) specifies the field size. That means that the field can hold a number up to 10 characters long. Your number has 11 digits and thus the value is to large to fit. Anything smaller than (<) 10 billion (10 000 000 000) can be inserted without trouble. That's what you need to check for if you want to validate the value before inserting. Like if they were characters? A quick Google gave this reference page: http://www.techonthenet.com/oracle/datatypes.php The ""10"" in Number(10) specifies the total number of digits. Optionally you can also specify the number of decimals. To quote the link above ""For example numeric(72) is a number that has 5 digits before the decimal and 2 digits after the decimal."""
1015,A,"Avoiding CheckStyle magic number errors in JDBC queries I am working on a group project for class and we are trying out CheckStyle. I am fairly comfortable with Java but have never touched JDBC or done any database work before this. I was wondering if there is an elegant way to avoid magic number errors in preparedStatement calls consider:  preparedStatement = connect.prepareStatement(""INSERT INTO shows "" + ""(showid showtitle showinfo genre youtube)"" + ""values (default ? ? ? ?);""); preparedStatement.setString(1 title); preparedStatement.setString(2 info); preparedStatement.setString(3 genre); preparedStatement.setString(4 youtube); result = preparedStatement.executeUpdate(); The setString methods get flagged as magic numbers so far I just added the numbers 3-10 or so to the ignore list for magic numbers but I was wondering if there was a better way to go about inserting those values into the statement. I also beg you for any other advice that comes to mind seeing that code I'd like to avoid developing any nasty habits e.g. should I be using Statement or is PreparedStatement fine? Will that let me refer to column names instead? Is that ideal? etc... Thanks! As a side-note it would also be useful to know how to avoid magic numbers while retrieving the data too - i.e. `getString()` etc. I would suggest that even if you don't use Spring try using the NamedParameterJdbcTemplate instead. Take a look at http://www.dzone.com/tutorials/java/spring/spring-named-parameter-jdbc-template.html for a tutorial on how to use it.  Create an utility method which does something like this: public static void setValues(PreparedStatement preparedStatement Object... values) throws SQLException { for (int i = 0; i < values.length; i++) { preparedStatement.setObject(i + 1 values[i]); } } And use it as follows: setValues(preparedStatement title info genre youtube); or Object[] values = { title info genre youtube }; setValues(preparedStatement values); More ""best practices"" with regard to basic JDBC coding can be found in this article. Hope this helps. That is excellent thank you very much!"
1016,A,"Is Spring too complex for JDBC operations? Just been looking at the Spring framework for JDBC - it looks like there is a bit of a learning curve - and I'm still not able to find a nice up to date quick start Spring/JDBC tutorial of any quality! Is there something lighter than Spring for basic JDBC operations - or has anyone got any good links for tutorials Many thanks I'd advise to ammend your title. ""Is Spring too for JDBC operations?"". Is Spring too what? woops! Thanks though I tried to fill in the gap I hope I guessed correctly ;-) Spring JDBC was good in version 1.0 but they refactored it quite a bit in version 2.5 to make it even simpler. Have a look at JdbcTemplate and the classes in the org.springframework.jdbc.core.simple package. They're new to Spring 2.5 so you won't find them in the older books. Best to look at the reference docs on-line. Is it best to stick with version 2.5x or move over to 3? I haven't moved to 3 myself so I can't say. I don't believe there's much new in JDBC: http://www.devoxx.com/pages/viewpage.action?pageId=1704462  Check out http://static.springframework.org/spring/docs/2.5.x/reference/jdbc.html to choose a style (full 'automagic' Spring vs. most of the work done by the programmer) and learn about the basic operations on JdbcTemplate. The site has nice examples like int countOfActorsNamedJoe = this.jdbcTemplate.queryForInt( ""select count(0) from t_actors where first_name = ?"" new Object[]{""Joe""}); Anyhow you will need to invest some time into it. No matter which tutorial on Spring JDBC you will use it will still be Spring JDBC underneath. And in this case it doesn't hurt to learn from the source i.e. the Spring docs which are quite well written.  yes it has JdbcTemplate for that. http://www.techfaq360.com/tutorial/spring/JdbcTemplate.jsp  Quite the opposite. JDBC support in Spring is very simple. Here is basic example: dataSource = ... obtain data source... (e.g. via Spring config) SimpleJdbcTemplate jdbcTemplate = new SimpleJdbcTemplate(dataSource); Map<String Object> row = jdbcTemplate.queryForMap( ""SELECT * FROM MyTable WHERE ID=? LIMIT 1"" 100); JdbcTemplate and SimpleJdbcTemplate has lot of query methods you may find useful. For mapping rows to your objects take a look at RowMapper and ParameterizedRowMapper < T >. For your datasource you usually want to use some advanced DataSource with pooling support. For testing simple BasicDataSource will do: BasicDataSource ds = new BasicDataSource(); ds.setDriverClassName(""driverClassName""); ds.setUrl(""jdbc://...""); ds.setUsername(""username""); ds.setPassword(""password""); +1. That is how I first got into Spring. JDBCTemplate lib shrank my code enormously b/c I was no longer in try catch finally hell. Straight JDBC is extremely verbose and tedious with all those checked exceptions everywhere. Plus SQLExceptions may not even be related to SQL - The DataAccessException thrown captures this point much better. If the network goes down your SQL could have been perfect but...SQLException! Yeah I *love* DataAccessException hierarchy. It is much much easier to catch specific problems and not to be bothered by DB-specific error codes.  The Spring documentation is pretty good. If that doesn't help the various Spring books such as Spring in Action etc are very good. Spring is worth learning - you can get rid of a LOT of boiler plate JDBC code. It does a very good job of connection management - together with DBCP The Spring documentation is definitely thorough. Not terribly easy to parse though. It degenerates into alphabet soup pretty rapidly. A bit dense for new to web people to get their heads around."
1017,A,"Java Iterator backed by a ResultSet I've got a class that implements Iterator with a ResultSet as a data member. Essentially the class looks like this: public class A implements Iterator{ private ResultSet entities; ... public Object next(){ entities.next(); return new Entity(entities.getString...etc....) } public boolean hasNext(){ //what to do? } ... } How can I check if the ResultSet has another row so I can create a valid hasNext method since ResultSet has no hasNext defined itself? I was thinking doing SELECT COUNT(*) FROM... query to get the count and managing that number to see if there's another row but I'd like to avoid this. One option is the ResultSetIterator from the Apache DBUtils project. BalusC rightly points out the the various concerns in doing this. You need to be very careful to properly handle the connection/resultset lifecycle. Fortunately the DBUtils project also has solutions for safely working with resultsets. If BalusC's solution is impractical for you (e.g. you are processing large datasets that can't all fit in memory) you might want to give it a shot.  Its not a really bad idea in the cases where you need it it's just that you often do not need it. If you do need to do something like say stream your entire database.... you could pre-fetch the next row - if the fetch fails your hasNext is false. Here is what I used: /** * @author Ian Pojman <pojman@gmail.com> */ public abstract class LookaheadIterator<T> implements Iterator<T> { /** The predetermined ""next"" object retrieved from the wrapped iterator can be null. */ protected T next; /** * Implement the hasNext policy of this iterator. * Returns true of the getNext() policy returns a new item. */ public boolean hasNext() { if (next != null) { return true; } // we havent done it already so go find the next thing... if (!doesHaveNext()) { return false; } return getNext(); } /** by default we can return true since our logic does not rely on hasNext() - it prefetches the next */ protected boolean doesHaveNext() { return true; } /** * Fetch the next item * @return false if the next item is null. */ protected boolean getNext() { next = loadNext(); return next!=null; } /** * Subclasses implement the 'get next item' functionality by implementing this method. Implementations return null when they have no more. * @return Null if there is no next. */ protected abstract T loadNext(); /** * Return the next item from the wrapped iterator. */ public T next() { if (!hasNext()) { throw new NoSuchElementException(); } T result = next; next = null; return result; } /** * Not implemented. * @throws UnsupportedOperationException */ public void remove() { throw new UnsupportedOperationException(); } } then:  this.lookaheadIterator = new LookaheadIterator<T>() { @Override protected T loadNext() { try { if (!resultSet.next()) { return null; } // process your result set - I use a Spring JDBC RowMapper return rowMapper.mapRow(resultSet resultSet.getRow()); } catch (SQLException e) { throw new IllegalStateException(""Error reading from database"" e); } } }; }  It sounds like you are stuck between either providing an inefficient implementation of hasNext or throwing an exception stating that you do not support the operation. Unfortunately there are times when you implement an interface and you don't need all of the members. In that case I would suggest that you throw an exception in that member that you will not or cannot support and document that member on your type as an unsupported operation.  You can use ResultSetIterator just put your ResultSet in the constructor. ResultSet rs = ... ResultSetIterator = new ResultSetIterator(rs); For your information this class call 'isLast()' method.  ResultSet has an 'isLast()' method that might suit your needs. The JavaDoc says it is quite expensive though since it has to read ahead. There is a good chance it is caching the look-ahead value like the others suggest trying.  I think there's enough decry over why it's a really bad idea to use ResultSet in an Iterator (in short ResultSet maintains an active connection to DB and not closing it ASAP can lead to problems). But in a different situation if you're getting ResultSet (rs) and are going to iterate over the elements but you also wanted to do something before the iteration like this: if (rs.hasNext()) { //This method doesn't exist //do something ONCE *IF* there are elements in the RS } while (rs.next()) { //do something repeatedly for each element } You can achieve the same effect by writing it like this instead: if (rs.next()) { //do something ONCE *IF* there are elements in the RS do { //do something repeatedly for each element } while (rs.next()); }  I agree with BalusC. Allowing an Iterator to escape from your DAO method is going to make it difficult to close any Connection resources. You will be forced to know about the connection lifecycle outside of your DAO which leads to cumbersome code and potential connection leaks. However one choice that I've used is to pass a Function or Procedure type into the DAO method. Basically pass in some sort of callback interface that will take each row in your result set. For example maybe something like this: public class MyDao { public void iterateResults(Procedure<ResultSet> proc Object... params) throws Exception { Connection c = getConnection(); try { Statement s = c.createStatement(query); ResultSet rs = s.executeQuery(); while (rs.next()) { proc.execute(rs); } } finally { // close other resources too c.close(); } } } public interface Procedure<T> { void execute(T t) throws Exception; } public class ResultSetOutputStreamProcedure implements Procedure<ResultSet> { private final OutputStream outputStream; public ResultSetOutputStreamProcedure(OutputStream outputStream) { this.outputStream = outputStream; } @Override public void execute(ResultSet rs) throws SQLException { MyBean bean = getMyBeanFromResultSet(rs); writeMyBeanToOutputStream(bean); } } In this way you keep your database connection resources inside your DAO which is proper. But you are not necessarily required to fill a Collection if memory is a concern. Hope this helps.  This is really a bad idea. This approach requires that the connection is open the whole time until the last row is read and outside the DAO layer you never know when it will happen and you also seem to leave the resultset open and risk resource leaks and application crashes in the case the connection times out. You don't want to have that. The normal JDBC practice is that you acquire Connection Statement and ResultSet in the shortest possible scope. The normal practice is also that you map multiple rows into a List or maybe a Map and guess what they do have an Iterator. public List<Data> list() throws SQLException { Connection connection = null; Statement statement = null; ResultSet resultSet = null; List<Data> list = new ArrayList<Data>(); try { connection = database.getConnection(); statement = connection.createStatement(""SELECT id name value FROM data""); resultSet = statement.executeQuery(); while (resultSet.next()) { Data data = new Data(); data.setId(resultSet.getLong(""id"")); data.setName(resultSet.getString(""name"")); data.setValue(resultSet.getInteger(""value"")); list.add(data); } } finally { if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } return list; } And use it as follows: List<Data> list = dataDAO.list(); int count = list.size(); // Easy as that. Iterator<Data> iterator = list.iterator(); // There is your Iterator. Do not pass expensive DB resources outside the DAO layer like you initially wanted to do. For more basic examples of normal JDBC practices and the DAO pattern you may find this article useful. Couldn't this run into memory issues depending on the number of rows? Just query the information you actually need. In SQL you can use under each the `WHERE` and `LIMIT/OFFSET` clauses for this. Google also doesn't return all of the zillion results at once. What if I need all rows? I've got an app with 12 million rows that needs to be processed. @heffaklump Even in this case you don't need a result set iterator. Iterators are not safe for result sets if the iterators are delegated outside DAO (or even its methods). Callback functions handling one row are much better: my current project operates with hundreds of million records and they *all* can be easily exported to a CSV file no matter how much the data is because there is no need to cache whole data neither `List` (whatever) nor `WHERE`/`LIMIT`: simply delegate an object created from a result set row to the callback. I don't see why this is such a bad idea in general. `Iterators` are very short-lived objects. Let your `ResultSetIterator` also implement `AutoCloseable` and the whole thing becomes quite lean... @Lukas: it won't autoclose/release the `Statement`/`Connection`. Particularly you should understand that. Better use `CachedRowSet` if you really need to. The lifecycle of a `Statement` / `Connection` is completely independent of the lifecycle of a `ResultSet`. This is of course assuming that anyone writing a `ResultSetIterator` knows what they're doing and won't let the `Iterator` escape the DAO or whatever entity manages the `ResultSet` lifecycle. And then I still don't see why `Iterator` would be a bad type to represent a database cursor... @Lukas: *""and won't let the Iterator escape the DAO""* well there you protected yourself. Of course such an iterator is useful within the API/library you're maintaining but it's usually useless and unsafe there outside. I'd rather make it a DAO-package-private class. Wow. Don't get pissed :-) Neither I nor the OP had ever implied anything that you're suggesting at least not in explicitly written form. The question was merely about how to implement `hasNext()` which is why I thought this answer is not the best one for anyone Googling *""ResultSet"" and ""Iterator""*. Because it really isn't. The best answer should provide a correct implementation. o_O​​​​​​​​​​​​  You can get out of this pickle by performing a look-ahead in the hasNext() and remembering that you did a lookup to prevent consuming too many records something like: public class A implements Iterator{ private ResultSet entities; private boolean didNext = false; private boolean hasNext = false; ... public Object next(){ if (!didNext) { entities.next(); } didNext = false; return new Entity(entities.getString...etc....) } public boolean hasNext(){ if (!didNext) { hasNext = entities.next(); didNext = true; } return hasNext; } ... } I think this solution is better than mine since it has a smaller runtime fingerprint.  Iterators are problematic for traversing ResultSets for reasons mentioned above but Iterator like behaviour with all the required semantics for handling errors and closing resources is available with reactive sequences (Observables) in RxJava. Observables are like iterators but include the notions of subscriptions and their cancellations and error handling. The project rxjava-jdbc has implementations of Observables for jdbc operations including traversals of ResultSets with proper closure of resources error handling and the ability to cancel the traversal as required (unsubscribe).  There are a couple of things you could do depending on what you want your class A. If the major use case is to go through every single result then perhaps its best to preload all the Entity objects and throw away the ResultSet. If however you don't want to do that you could use the next() and previous() method of ResultSet public boolean hasNext(){ boolean next = entities.next(); if(next) { //reset the cursor back to its previous position entities.previous(); } } You do have to be careful to make sure that you arent currently reading from the ResultSet but if your Entity class is a proper POJO (or at least properly disconnected from ResultSet then this should be a fine approach.  You could try the following: public class A implements Iterator { private ResultSet entities; private Entity nextEntity; ... public Object next() { Entity tempEntity; if ( !nextEntity ) { entities.next(); tempEntity = new Entity( entities.getString...etc....) } else { tempEntity = nextEntity; } entities.next(); nextEntity = new Entity( entities.getString...ext....) return tempEntity; } public boolean hasNext() { return nextEntity ? true : false; } } This code caches the next entity and hasNext() returns true if the cached entity is valid otherwise it returns false. I believe you mean `return nextEntity != null;` in your `hasNext` method  Do you expect most of the data in your result set to actually be used? If so pre-cache it. It's quite trivial using eg Spring  List<Map<StringObject>> rows = jdbcTemplate.queryForList(sql); return rows.iterator(); Adjust to suit your taste.  entities.next returns false if there are no more rows so you could just get that return value and set a member variable to keep track of the status for hasNext(). But to make that work you would also have to have some sort of init method that reads the first entity and caches it in the class. Then when calling next you would need to return the previously cached value and cache the next value etc..."
1018,A,"DriverManager always returns my custom driver regardless of the connection URL I am writing a driver to act as a wrapper around two separate MySQL connections (to distributed databases). Basically the goal is to enable interaction with my driver for all applications instead of requiring the application to sort out which database holds the desired data. Most of the code for this is in place but I'm having a problem in that when I attempt to create connections via the MySQL Driver the DriverManager is returning an instance of my driver instead of the MySQL Driver. I'd appreciate any tips on what could be causing this and what could be done to fix it! Below is a few relevant snippets of code. I can provide more but there's a lot so I'd need to know what else you want to see. First from MyDriver.java: public MyDriver() throws SQLException { DriverManager.registerDriver(this); } public Connection connect(String url Properties info) throws SQLException { try { return new MyConnection(info); } catch (Exception e) { return null; } } public boolean acceptsURL(String url) throws SQLException { if (url.contains(""jdbc:jgb://"")) { return true; } return false; } It is my understanding that this acceptsURL function will dictate whether or not the DriverManager deems my driver a suitable fit for a given URL. Hence it should only be passing connections from my driver if the URL contains ""jdbc:jgb://"" right? Here's code from MyConnection.java: Connection c1 = null; Connection c2 = null; /** *Constructors */ public DDBSConnection (Properties info) throws SQLException Exception { info.list(System.out); //included for testing Class.forName(""com.mysql.jdbc.Driver"").newInstance(); String url1 = ""jdbc:mysql://server1.com/jgb""; String url2 = ""jdbc:mysql://server2.com/jgb""; this.c1 = DriverManager.getConnection( url1 info.getProperty(""username"") info.getProperty(""password"")); this.c2 = DriverManager.getConnection( url2 info.getProperty(""username"") info.getProperty(""password"")); } And this tells me two things. First the info.list() call confirms that the correct user and password are being sent. Second because we enter an infinite loop we see that the DriverManager is providing new instances of my connection as matches for the mysql URLs instead of the desired mysql driver/connection. FWIW I have separately tested implementations that go straight to the mysql driver using this exact syntax (al beit only one at a time) and was able to successfully interact with each database individually from a test application outside of my driver. IMO the main problem with this code is that it uses DriverManager. Avoid statics and stick with instances. The specific problem is the DriverManager.getConnection goes directly to attempting to connect rather than the acceptsURL that getDriver does. Therefore you connect implementation should do the same check as the acceptsURL implementation (it may even be stricter and possibly fail at runtime). As a relatively minor point the acceptsURL implementation is a little odd. if (url.contains(""jdbc:jgb://"")) { return true; } return false; contains should be startsWith. The little dance with if and returns does not help clarity. It can be written as: return url.startsWith(""jdbc:jgb://""); Correct the `connect()` method should first test `acceptsURL()`. Also see [API doc](http://java.sun.com/javase/6/docs/api/java/sql/Driver.html#connect%28java.lang.String%20java.util.Properties%29): *The driver should return ""null"" if it realizes it is the wrong kind of driver to connect to the given URL.* Thanks for the suggestion about rewriting acceptsURL. I did this and added a call to DriverManager.getDriver(url); before each of the calls to getConnection. No change from that. I'm basing the code I'm using to call the mysql drivers on 3.1.2 of http://java.sun.com/j2se/1.5.0/docs/guide/jdbc/getstart/drivermanager.html I'm open to switching it if there's a better suggestion. Ah! The return null was the part I was missing! I've done that and indeed it is no longer entering the infinite loop. However DriverManager is failing to find a driver capable of handling the mysql connection. Do I need to require users to include Class.forName(""com.mysql.jdbc.Driver"").newInstance(); before calling my driver? Yes or let your driver do it if it is supposedly tight-coupled with MySQL. As above I was already making that call before trying to connect to the mysql servers. I tried moving the call to my test-client and I'm still getting an error stating that it can't find a compatible driver for the jdbc:mysql connections Your driver could load the MySQL driver (or just construct it directly which isn't really significantly more coupled the `forName`ing from a literal string. Do you mean via DriverManager.registerDriver() ? I'm trying that currently and it is unable to find the com.mysql.jdbc package (despite it being loaded into the library [developing in NetBeans] and being able to use that driver when I call it instead of mine. Cancel that; changed my syntax to DriverManager.registerDriver(new com.mysql.jdbc.Driver()); and it found the package. But tests are still coming up unable to find a suitable driver when I reach the calls to get the mysql connections Thanks for the help! I found the remaining problem and everything appears to be working now! I'd made a typo in the getConnection calls - it's info.getProperty(""user"")"
1019,A,"Java - Communications Link Failure I just talked to my host that I have my web page at and they say they allow JDBC connections. Anyway the page you can view this at is http://mystikrpg.com/mysqltest/mysqltry.html Here is my error: **** Looking for database... com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) at java.lang.reflect.Constructor.newInstance(Unknown Source) at com.mysql.jdbc.Util.handleNewInstance(Util.java:409) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1118) at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:343) at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2308) at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2122) at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:774) at com.mysql.jdbc.JDBC4Connection.<init>(JDBC4Connection.java:49) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) at java.lang.reflect.Constructor.newInstance(Unknown Source) at com.mysql.jdbc.Util.handleNewInstance(Util.java:409) at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:375) at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:289) at java.sql.DriverManager.getConnection(Unknown Source) at java.sql.DriverManager.getConnection(Unknown Source) at test.init(test.java:38) at sun.plugin2.applet.Plugin2Manager$AppletExecutionRunnable.run(Unknown Source) at java.lang.Thread.run(Unknown Source) Caused by: java.net.SocketException: java.security.AccessControlException: access denied (java.net.SocketPermission [0:0:0:0:0:0:0:1]:4464 connectresolve) at com.mysql.jdbc.StandardSocketFactory.unwrapExceptionToProperClassAndThrowIt(StandardSocketFactory.java:407) at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:268) at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:292) ... 16 more java.lang.NullPointerException at test.init(test.java:69) at sun.plugin2.applet.Plugin2Manager$AppletExecutionRunnable.run(Unknown Source) at java.lang.Thread.run(Unknown Source) Exception: java.lang.NullPointerException and here is the code: What am I doing wrong? //package mysqltest; import java.awt.*; import java.awt.event.*; import javax.swing.*; import java.applet.Applet; import java.awt.TextArea.*; import java.sql.*; import java.util.*; import javax.swing.plaf.*; import javax.swing.plaf.basic.*; import java.net.*; import java.applet.*; public class test extends JApplet { public JTextArea c; public void init() { c = new JTextArea(); add(c); c.append(""**** Looking for database...""); Connection conn = null; Properties props = new Properties(); String url = ""jdbc:mysql://localhost:3306/""; String dbName = ""mystik""; String driver = ""com.mysql.jdbc.Driver""; String userName = ""root""; String password = """"; String loggedusername = getParameter(""name""); boolean online = false; try { Class.forName(driver).newInstance(); online = true; if (online) { // if user loads applet online conn = DriverManager.getConnection(""jdbc:mysql://localhost:4464/jsfdan_mystikdan"" ""jsfdan_muser"" ""test""); } else { // for localhost - testing purposes props.put(""user"" ""root""); conn = DriverManager.getConnection(""jdbc:mysql://localhost:3306/mystik"" props); } c.append(""\nConnected to the database""); c.append(""\nGetting stats for: "" + loggedusername); PreparedStatement statement = conn.prepareStatement( ""select * from `user` where `username` = '""+loggedusername+""'""); ResultSet result = statement.executeQuery(); // just a dumb mysql statement! while(result.next()) { c.append(""\nUsername: ""+result.getString(2)+ ""\nLevel: ""+result.getString(6)+""\nEXP: ""+result.getString(8)+""\n""); } PreparedStatement updateEXP = conn.prepareStatement( ""update`user` set `exp` = '666' where `username` = '""+loggedusername+""'""); updateEXP.executeUpdate(); ResultSet xresult = statement.executeQuery(); while(xresult.next()) { c.append(""\nUsername: ""+xresult.getString(2)+ ""\nLevel: ""+xresult.getString(6)+""\nEXP: ""+xresult.getString(8)+""\n""); } c.append(""\nDisconnected from database""); } catch (Exception e) { System.out.println(c.getText()); e.printStackTrace(); }finally { try { conn.close(); }catch(SQLException dan) {dan.printStackTrace(); } } } } You should do a nullcheck in `finally` like so `if (conn != null) try { conn.close(); } catch (SQLException e) { e.printStackTrace(); }` to avoid the NPE at end of trace because the connection is not been acquired. Quoting your code:  // if user loads applet online conn = DriverManager.getConnection(""jdbc:mysql://localhost:4464/jsfdan_mystikdan"" ""jsfdan_muser"" ""test""); An applet is a program running on the user's machine where the browser is. Thus localhost refers to the user's machine at this stage. Chances are that most users aren't running MySQL on their own machine that even if they were it wouldn't be the one your applet is after and that it would get out of the applet's sandboxed environment anyway. EDIT (after discussion in comments): From the discussions and the comments in the previous related questions it looks like you're trying to connect directly to your MySQL server from an application (applet) distributed to clients that could be anywhere which is usually the wrong approach. You were concerned about posting your username/password in your examples. That's only a minor problem compared with what could happen if you distributed your applet widely: anyone then could easily look at the traffic sent by your application to your MySQL server and get the username/password. Most MySQL servers are blocked from external access mostly because they don't provide suitable access control on their own compared with the access requirements of the overall application. This is not always the case but the access control on INSERT/SELECT/UPDATE operations on their own are often too crude to represent the functional purpose of the overall application. With most services that use a database the user-management and access control is done at the application level not at the database level. This is particularly the case when you're using a shared provider that creates a database and a user account for your entire application to use even if you want multiple users. The typical workaround for this is do develop another service (typically a web-service) that your client will call providing suitable authentication and usage context for the various operations you'd want the client to perform on the data. I'm not sure if your hosting service lets you run Java services but cheaper hosting providers tend to let you run PHP Perl and/or Python services so you could write a service in one of those languages and have your applet be a client that talk to them. Explaining how to write web services is probably out of scope of this question/answer. In general you'll probably come across 3 categories: REST-style web-services (it's an architectural style guided by the notion of resources and representations) XML-RPC (often called ""REST"" by mistake where you send fragments of XML to some web-page that will call a function/method and give you some results in return; you might be able to do the same with JSON) and SOAP (where you'll probably get more tools but might also be more bloated depending on what you're comfortable with). There have been on-going debates as to which is better but it's up to you to investigate and choose what you think is better for your application. It will probably depend on what can be deployed on your host. Neither 3306 or 4464 seem to be open to the outside world. It's quite common not to allow connection further than the local network for MySQL server. +1: Got there a minute ahead of me! In his [previous question](http://stackoverflow.com/questions/3613395/java-jdbc-connection) he was however using the right URL. I have no idea why it is changed to localhost. @Dan: by the way the `AccessControlException` is exactly the kind of exception which indicates that the applet is probably not properly signed (referring to the comments in your previous question) I wonder if in this previous question `jdbc:mysql://epic.0sites.net:208/***` isn't a typo for `jdbc:mysql://epic.0sites.net:2083/***` (blanked when removing the details by hand) and that port is responding to the HTTPS protocol not the MySQL protocol (208 would be quite unusual to run MySQL). @Bruno: He mentioned as well that he ""starred out"" sensitive info. @BalusC indeed I was just suggesting that he may have tried to connect to an HTTPS server instead of a MySQL server as the other port number values in the examples seem to indicate (I'm not sure). That would certainly trigger an exception along the lines of ""Cannot read response from server. Expected to read 4 bytes read 0 bytes before connection was unexpectedly lost."" So is this right? conn = DriverManager.getConnection(""jdbc:mysql://epic.0sites.net:4464/jsfdan_mystikdan"" ""jsfdan_muser"" ""test""); Decided that I'm not going to star out info for the sake of getting it right. I'll just change the information later. Or is THIS right? conn = DriverManager.getConnection(""jdbc:mysql://epic.0sites.net:3306/jsfdan_mystikdan?user=jsfdan_muser&password=test""); So what connection should I use? I've just edited my answer too long for comments. OOOOOk. SO I just read it... and I think I'll just drop it at this point. You lost me sorry. I get what you are saying but it's become way too much for one SIMPLE thing. It's probably not as simple as you think it is unfortunately. I've only given a few possible reasons but whether the reasons are good or not most hosting services won't let you connect to their MySQL servers from outside their local networks (where their web servers usually sit). So that's why whenever I see a game that requires that... the owner usuallys respond with ""I host myself.""? Possibly but that also implies that it's probably not a good design for the reasons I listed above. Typically if you don't enable TLS/SSL on MySQL anyone could be able to intercept the username/password you're using to connect which is likely to be common to all users it seems in your case (otherwise you'd have to do the MySQL admin when registering users). Most people decompiling the class file could get that too even when SSL/TLS is used. So I think I got it.. I should use a java getConnection PHP $_GET script to do my MySQL work? :D Generally GET if it's a read operation and POST if it makes modification. You can indeed process POST operations from PHP on the server side (and make PHP become a client to MySQL then) and you can use an HTTP client library (or URLHTTPConnection) on the Java client side. This way you can also use HTTP user authentication. I'd suggest reading on HTTP and various forms of web service design. It's likely that for a simple service emulating a simple HTML form submission (even without the HTML) will be enough. Oh I have done this. But it's just that it took too long. I mean you on Command Prompt.. everytime it flashs the little bar where you type? Well it took 5 blinks from that bar until the process of doing the URL post method was finished. I just thought the way I was looking in this topic was faster.  The NPE is because Connection conn is never initialized - that's what blows up. I'd recommend you use a database connectivity tool (like the MySQL Workbench) to establish the correct URL from your system to mystikrpg.com; once you have the correct URL you can put it in your applet. As @Bruno indicated the applet runs locally. Indeed but that NPE is only in the finally block which should contain `if (conn!=null) { conn.close(); }` that's a side-effect of the original problem."
1020,A,"sqlite database connection/locking question Folks I am implementing a file based queue (see my earlier question) using sqlite. I have the following threads running in background: thread-1 to empty out a memory structure into the ""queue"" table (an insert into ""queue"" table). thread-1 to read and ""process"" the ""queue"" table runs every 5 to 10 seconds thread-3 - runs very infrequently and purges old data that is no longer needed from the ""queue"" table and also runs vacuum so the size of the database file remains small. Now the behavior that I would like is for each thread to get whatever lock it needs (waiting with a timeout if possible) and then completing the transaction. It is ok if threads do not run concurrently - what is important is that the transaction once begins does not fail due to ""locking"" errors such as ""database is locked"". I looked at the transaction documentation but there does not seem to be a ""timeout"" facility (I am using JDBC). Can the timeout be set to a large quantity in the connection? One solution (untried) I can think of is to have a connection pool of max 1 connection. Thus only one thread can connect at a time and so we should not see any locking errors. Are there better ways? Thanx! If it were me I'd use a single database connection handle. If a thread needs it it can allocate it within a critical section (or mutex or similar) - this is basically a poor man's connection pool with only one connection in the pool:) It can do its business with the databse. When done it exits the critical section (or frees the mutex or ?). You won't get locking errors if you carefully use the single db connection. -Don Thanx Don that is what I might end up doing though setting it via a db pool would be more ""standard"" way of doing it (and less confusing since you are treating the sqlite like other databases in the code."
1021,A,"JDBC connectivity issue I'm using the NetBeans IDE(6.8). I have a DB class : package garits; import java.io.Serializable; import java.sql.*; import java.util.Properties; public class DB implements Serializable{ private static final long serialVersionUID = 1L; String dbURL = ""jdbc:mysql:///team_project""; String user = ""root""; String pwd = ""arsenal""; String dbDriver = ""com.mysql.jdbc.Driver""; private Connection dbCon; private ResultSet r; private Statement s; public DB() {} public boolean connect() throws ClassNotFoundExceptionSQLException{ Class.forName(dbDriver); Properties props = new Properties(); props.put(user ""root""); props.put(pwd ""arsenal""); props.put(""charSet"" ""UTF-8""); props.put(""lc_ctype"" ""UTF-8""); dbCon = DriverManager.getConnection(dbURLprops); //dbCon = DriverManager.getConnection(dbURLuserpwd); return true; } public void close() throws SQLException{ dbCon.close(); if(r!=null) r.close(); if(s!=null) s.close(); } public ResultSet execSQL(String sql) throws SQLException{ s = dbCon.createStatement(); r = s.executeQuery(sql); return (r == null) ? null : r; } public int updateSQL(String sql) throws SQLException{ s = dbCon.createStatement(); int r = s.executeUpdate(sql); return (r == 0) ? 0 : r; } public int updateSQL(String sql String getID) throws SQLException{ s = dbCon.createStatement(); int autoIncValue = -1; s.executeUpdate(sql Statement.RETURN_GENERATED_KEYS); ResultSet rs = s.getGeneratedKeys(); if (rs.next()) { autoIncValue = rs.getInt(1); } return autoIncValue; } } The jar file is im my library but whenever I try to connect:  private void loginButtonActionPerformed(java.awt.event.ActionEvent evt) { String result =""""; DB db = new DB(); try{ db.connect(); String query = ""Select Role From User_Account Where Username=jTextField1.getText()AND Where Password=jTextField2.getText(); ""; ResultSet rs=db.execSQL(query); while(rs.next()) { result = rs.getString(""Role""); } if(result.equals("""")) { JOptionPane.showMessageDialog(loginButton""Access denied""""Error Message""JOptionPane.ERROR_MESSAGE); } else if(result.equals(""Administrator"")) { MainPage_Admin admin = new MainPage_Admin(); } } catch(Exception e) { System.out.println(""An error has occurred""); } } I get an error(the exception is caught)-the name of the database is ""team_project"" and password is ""arsenal""-any ideas appreciated. I'm new to JDBC. There's another major problem in this JDBC code: it is leaking resources. Acquire and close them in the shortest possible scope in a `try-finally` block. Examples can be found here: http://balusc.blogspot.com/2008/07/dao-tutorial-data-layer.html MySQL database url connection property is wrong jdbc:mysql://localhost:3306/<your database name> instead of you are giving jdbc:mysql:///team_project modify and execute the program and better to handle the exception within the try/catch block instead of throws.  First step: use at least e.printStackTrace() in your catch-block to get some information from the exception. Otherwise you'll just be guessing. I get: java.sql.SQLException: Access denied for user ''@'localhost' (using password: NO) Why am I being denied access-thanks. @eli: because you don't set the user/password properties correctly. Check the two lines that put `user` and `pwd` into the `Properties`: it's wrong."
1022,A,"ResultSet to Pagination How do I convert Resultset object to a paginated view on a JSP? For example this is my query and result set: pst = con.prepareStatement(""select userName job place from contact""); rs = pst.executeQuery(); Here's a couple things you can do: Marshall the result set to some list of objects/records Based on your required page size figure out how many pages you will have based on the result set. Check request parameter for the required page and offsets based on the number of items to display on the page. So if you're on page 4 with 12 to display your offset is 48. Determine the total number of pages based on the count of the items. Display your items based on the offset that you determined (only display starting at item 48) Generate your pagination with the amount of pages based on the total number of pages that you determined. ======= That's your basic approach. You can tweak this with: Determining a way to limit the query to the page (but this wont help you with determining page sizes) Fancy ways of pagination etc.. This is not very efficient if you have a resultset with thousands of rows. Rather do the paging at database level. He just needs a starting point.  To start you need to add one or two extra request parameters to the JSP: firstrow and (optionally) rowcount. The rowcount can also be left away and definied entirely in the server side. Then add a bunch of paging buttons to the JSP: the next button should instruct the Servlet to increment the value of firstrow with the value of rowcount. The previous button should obviously decrement the value of firstrow with the value of rowcount. Don't forget to handle negative values and overflows correctly! You can do it with help of SELECT count(id). Then fire a specific SQL query to retrieve a sublist of the results. The exact SQL syntax however depends on the DB used. In MySQL and PostgreSQL it is easy with LIMIT and OFFSET clauses: private static final String SQL_SUBLIST = ""SELECT id username job place FROM"" + "" contact ORDER BY id LIMIT %d OFFSET %d""; public List<Contact> list(int firstrow int rowcount) { String sql = String.format(SQL_SUBLIST firstrow rowcount); // Implement JDBC. return contacts; } In Oracle you need a subquery with rownum clause which should look like: private static final String SQL_SUBLIST = ""SELECT id username job place FROM"" + "" (SELECT id username job place FROM contact ORDER BY id)"" + "" WHERE ROWNUM BETWEEN %d AND %d""; public List<Contact> list(int firstrow int rowcount) { String sql = String.format(SQL_SUBLIST firstrow firstrow + rowcount); // Implement JDBC. return contacts; } In DB2 you need the OLAP function row_number() for this: private static final String SQL_SUBLIST = ""SELECT id username job place FROM"" + "" (SELECT row_number() OVER (ORDER BY id) AS row id username job place"" + "" FROM contact) AS temp WHERE row BETWEEN %d AND %d""; public List<Contact> list(int firstrow int rowcount) { String sql = String.format(SQL_SUBLIST firstrow firstrow + rowcount); // Implement JDBC. return contacts; } I don't do MSSQL but it's syntactically similar to DB2. Also see this topic. Finally just present the sublist in the JSP page the usual way with JSTL c:forEach. <table> <c:forEach items=""${contacts}"" var=""contact""> <tr> <td>${contact.username}</td> <td>${contact.job}</td> <td>${contact.place}</td> </tr> </c:forEach> </table> <form action=""yourservlet"" method=""post""> <input type=""hidden"" name=""firstrow"" value=""${firstrow}""> <input type=""hidden"" name=""rowcount"" value=""${rowcount}""> <input type=""submit"" name=""page"" value=""next""> <input type=""submit"" name=""page"" value=""previous""> </form> Note that some may suggest that you need to SELECT the entire table and save the List<Contact> in the session scope and make use of List#subList() to paginate. But this is far from memory-efficient with thousands rows and multiple concurrent users. For ones who are interested in similar answer in JSF/MySQL context using h:dataTable component you may find this article useful. It also contains some useful language-agnostic maths to get the ""Google-like"" pagination nicely to work. Suppose that database insertions and deletions have been happening while the user is looking at one page. The row numbers will not be stable over time I think? The effect could be to give the user some unexpected changes in position. This is a non-concern. You don't want to view an already deleted item or miss edited data. The only resort to that would be to haul the entire DB table into Java's memory and work on that only but you don't want to do that. @BalusC - wow. Awesome answer. I can put that to good use myself. BalusC this is a good compilation but Oracle sql is wrong. I write correct sql in my answer. @Vasily: feel free to edit and update my answer. Your Oracle query doesn't work. You can't use BETWEEN with ROWNUM if the lower bound is > 1 because each row will be filtered *before* a rownum value is assigned to it. So ""where ROWNUM BETWEEN 2 and xxx"" always return an empty result set. See http://stackoverflow.com/a/13740166/191367  This Oracle example is wrong. Yes in the outer select whe have good ROWNUM values but it is still pseudo column so we can not use BETWEEN on it. We need one more select. The right sql code is: SELECT c.* FROM (SELECT c.* ROWNUM as rnum FROM (SELECT id username job place FROM contact ORDER BY id) c) c WHERE c.rnum BETWEEN 5 AND 10 Comrades using solid sql string and Statement class is SLOOOW. Oracle have to parse your SQL every time your execute it. //Slooow example Satement stmt = con.createStatement(); ResultSet rs = stmt.executeQuery(""select * from my_table where id = 11""); Use PreparedStatement and binding parameters.  //Faster example PreparedStatement ps = conn.getPrepareStatement(""select * from my_table where id = ?""); ps.setInt(1 11); And fastest solution is put your sql in oracle stored procedure and use CallableStatement to call it. //Fastest example CallableStatement cs = conn.prepareCall(""{? = call my_plsql_function(?)}""); cs.setInt(1 11);  Look up the Value List Pattern and apply that. That's typically the best way to handle these kinds of things.  You can use displaytag for paigination or resultset but u download some jar file from displattag first you create one servlet StudentList.java public class StudentList extends HttpServlet { public void service(HttpServletRequest request HttpServletResponse response) throws ServletException IOException {  ArrayList al=new ArrayList(); StudentDao stdo=new StudentDao(); // this is DAO Class (Data Acccess Object) try { al=stdo.getStudentList(); //getstudent list dao method } catch (SQLException e) { e.printStackTrace(); } catch (Exception e) { e.printStackTrace(); } request.setAttribute(""al""al); RequestDispatcher rd=request.getRequestDispatcher(""StudentPaging.jsp""); rd.forward(requestresponse); } } // dao method public ArrayList getStudentList() throws SQLExceptionException { ArrayList ai=new ArrayList(); Connection con=null; Statement st=null; ResultSet rs=null; Date dt=new Date(); SimpleDateFormat sdf=new SimpleDateFormat(""dd/MM/yyyy""); StudentInformation sdata=null; con=MyConnection.creatConnection(); if(con!=null) { st=con.createStatement(); String select=""select * from STUDENT""; System.out.println(select); rs=st.executeQuery(select); if(rs!=null) { while(rs.next()) { sdata=new StudentInformation(); sdata.setSid(rs.getString(""SID"")); sdata.setFirstName(rs.getString(""FIRSTNAME"")); sdata.setMiddleName(rs.getString(""MIDDLENAME"")); sdata.setLastName(rs.getString(""LASTNAME"")); dt=rs.getDate(""SDATE""); sdata.setDateofbirth(sdf.format(dt)); sdata.setGender(rs.getString(""GENDER"")); sdata.setAddress(rs.getString(""ADDRESS"")); sdata.setHigestQulification(rs.getString(""HIQULIFICATION"")); sdata.setLanguageKnow(rs.getString(""LANGUAGE"")); sdata.setHobby(rs.getString(""HOBBY"")); sdata.setTermCondition(rs.getString(""TERMCON"")); ai.add(sdata); } } } return ai; }"
1023,A,"Execute jdbc applet in browser import java.sql.*; import java.io.*; import java.awt.*; import java.awt.event.*; import java.applet.*; /* <applet code=""A0"" width=250 height=200> </applet> */ public class A0 extends Applet implements ActionListenerItemListener { String msg=""""; Button viewdeletecreateeditreappexit; TextField M_head; int xians=0flag; public void init() { setLayout(new FlowLayout(FlowLayout.CENTER503)); view = new Button(""view""); delete = new Button(""delete""); create = new Button(""create""); edit = new Button(""edit""); reapp = new Button(""reapp""); exit= new Button(""exit""); M_head = new TextField(15); add(view); add(delete); add(create); System.out.println(""vikram""); add(edit); add(reapp); add(exit); System.out.println(""phaneendra""); add(M_head); view.addActionListener(this); delete.addActionListener(this); create.addActionListener(this); edit.addActionListener(this); reapp.addActionListener(this); exit.addActionListener(this); M_head.addActionListener(this); } public void actionPerformed(ActionEvent ae) { String str=ae.getActionCommand(); if(str.equals(""view"")) {msg =""1"";} if(str.equals(""delete"")) {msg =""2"";} if(str.equals(""create"")) {msg =""3"";} if(str.equals(""edit"")) {msg =""4"";} if(str.equals(""reapp"")) {msg =""5"";} if(str.equals(""exit"")) {msg =""6"";} if(msg==""3"") { try{ Class.forName(""sun.jdbc.odbc.JdbcOdbcDriver""); //String filename = ""E:/vikram/conn/new/db/north.mdb""; String filename = ""./db/north.mdb""; String database = ""jdbc:odbc:Driver={Microsoft Access Driver (*.mdb)};DBQ=""; //String url =""jdbc:odbc:Driver={Microsoft Access Driver (*.mdb)};DBQ=D:\\cheminDeMaBaseEtNomdeLaBdd""; database+=filename.trim(); String head = M_head.getText(); String head1 = head.trim(); Connection con = DriverManager.getConnection(database""""""""); Statement doo = con.createStatement(); //String vi =""create table head1 (Reapporder integer Amount integer)""; String vi=""insert into head1 values(12);""; boolean i=false; i=doo.execute(vi); if(i) M_head.setText(""Failed to insert""); else M_head.setText(""record inserted""); } catch(Exception err) { System.out.println(""Error :""+err); } } } public void itemStateChanged(ItemEvent ie) { repaint(); } public void paint(Graphics g) { g.drawString(msg70200); //No use g.drawString(""ANSWER=""6200); // No use } } This is A0.txt grant { permission java.lang.RuntimePermission ""accessClassInPackage.sun.jdbc.odbc""; permission java.util.PropertyPermission ""file.encoding"" ""read""; }; A0.html file <html> <head> </head> <body> <applet code=A0 width=250 height=200></applet> </body> </html> This code is executed in Appletviewer command but not in any browser Using JDBC in an applet isn't the best of idea. Attempting to use the JDBC-ODBC is hopeless. You can't do JDBC on an Applet for security reasons. You must write an Enterprise Application (in Java .NET Python PHP) and deploy it to an application server. In that application you can publish some WebServices so your Applet can finally access your database. Something like this: APPLET <-> APPLICATION SERVER (HTTP communication) <-> BACKEND (database) Here is a Web Site explaining some security related Applet stuff. please provide how to access this applet in browser provide code.. grant {permission java.lang.RuntimePermission""accessClassInPackage.sun.jdbc.odbc"";permission java.util.PropertyPermission""file.encoding"" ""read"";}; This file kept in .jar file and then add in applet tag archeve attribute ?????  As commented by others you really don't want to do this. Just create a webservice in the server side (which can be a plain vanilla servlet) and make use of java.net.URLConnection in the applet. Basic Servlet example: protected void doGet(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { String action = request.getParameter(""action""); // Or request.getPathInfo() whatever you want. String result = someDAO.doAction(action); response.getWriter().write(result); } Basic Applet example: URL url = new URL(""http://example.com/databaseservlet?action=someaction""); URLConnection connection = url.openConnection(); InputStream result = connection.getInputStream(); // Important. This actually fires the request! Be careful with SQL injections however. Do in no way pass raw SQL queries as request parameters or pathinfo and use PreparedStatement all the time in the DAO code. As response data format you can use a plain vanilla String (as given in example) or a XML string or a JSON string or maybe even a fullworthy Java object with a little help of Serialization. in type 1 driver how can i upload my website into ftp area. and is it possible without tomcat or any other server is it possibel to run servlets? thats way am using applets."
1024,A,"How to connect SQLite with Java? I am using one simple code to access the SQLite database from Java application . My code is  import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.Statement; public class ConnectSQLite { public static void main(String[] args) { Connection connection = null; ResultSet resultSet = null; Statement statement = null; try { Class.forName(""org.sqlite.JDBC""); connection = DriverManager.getConnection(""jdbc:sqlite:D:\\testdb.db""); statement = connection.createStatement(); resultSet = statement .executeQuery(""SELECT EMPNAME FROM EMPLOYEEDETAILS""); while (resultSet.next()) { System.out.println(""EMPLOYEE NAME:"" + resultSet.getString(""EMPNAME"")); } } catch (Exception e) { e.printStackTrace(); } finally { try { resultSet.close(); statement.close(); connection.close(); } catch (Exception e) { e.printStackTrace(); } } } } But this code gives one exception like java.lang.ClassNotFoundException: org.sqlite.JDBC How can I slove thisplease help me. I guess you are not putting SQLite jar in classpath Hey i have posted a video tutorial on youtube about this you can check that and you can find here the sample code : http://myfundatimemachine.blogspot.in/2012/06/database-connection-to-java-application.html Its a lot of irrelevant code to learn about a relatively specific problem. Not saying its a bad video/code but not specific for this problem.  import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; import javax.swing.JOptionPane; public class Connectdatabase { Connection con = null; public static Connection ConnecrDb(){ try{ //String dir = System.getProperty(""user.dir""); Class.forName(""org.sqlite.JDBC""); Connection con = DriverManager.getConnection(""jdbc:sqlite:D:\\testdb.db""); return con; } catch(ClassNotFoundException | SQLException e){ JOptionPane.showMessageDialog(null""Problem with connection of database""); return null; } } }   import java.sql.ResultSet; import java.sql.SQLException; import javax.swing.JOptionPane; import org.sqlite.SQLiteDataSource; import org.sqlite.SQLiteJDBCLoader; public class Test { public static final boolean Connected() { boolean initialize = SQLiteJDBCLoader.initialize(); SQLiteDataSource dataSource = new SQLiteDataSource(); dataSource.setUrl(""jdbc:sqlite:/home/users.sqlite""); int i=0; try { ResultSet executeQuery = dataSource.getConnection() .createStatement().executeQuery(""select * from \""Table\""""); while (executeQuery.next()) { i++; System.out.println(""out: ""+executeQuery.getMetaData().getColumnLabel(i)); } } catch (SQLException ex) { JOptionPane.showMessageDialog(null ex); } return initialize; }  If you are using netbeans Download the sqlitejdbc driver Right click the Libraries folder from the Project window and select Add Library  then click on the Create button enter the Library name (SQLite) and hit OK You have to add the sqlitejdbc driver to the class path  click on the Add Jar/Folder.. button and select the sqlitejdbc file you've downloaded previously Hit OK and you are ready to go ! I struggled a lot because of this problem. I am a Java newbie and using Netbeans. It's been a frustration. Finally your answer saved my day.  I'm using Eclipse and I copied your code and got the same error. I then opened up the project properties->Java Build Path -> Libraries->Add External JARs... c:\jrun4\lib\sqlitejdbc-v056.jar Worked like a charm. You may need to restart your web server if you've just copied the .jar file.  connection = DriverManager.getConnection(""jdbc:sqlite:D:\\testdb.db""); Instead of this put connection = DriverManager.getConnection(""jdbc:sqlite:D:\\testdb"");  You need to have a SQLite JDBC driver in your classpath. ie: http://www.zentus.com/sqlitejdbc/ 8/1/2012 update since the Zentus website is down: Xerial is an extension of Zentus i am using this driver and works fine. But why it is not compacting database while creating.With FireFox sqlite plugin Database compacted from 11.5MB to 11.3MB. how to do that with java. @Dyapa You need to periodically run `VACUUM`; since JDBC doesn't actually interpret the SQL (for _very_ good reasons) just send it over. Or use a pragma per connection to run in auto-vacuum mode. @DonalFellows can u explain how to run VACUUM through java. For those experiencing this issue with Tomcat this jar needs to be put into the lib folder for respective Tomcat version. Tomcat will also need to be restarted. In the web application the jar needs to be placed into the WEB-INF lib folder as well. You don't need to add it to the build path because putting it in the WEB-INF lib folder places it there automatically. @AndroidAddict Thank you bro you saved hours of my time :) Link is now broken...."
1025,A,"Using an ODBC application with a JDBC driver My company uses Vertica. We have Python applications that connect to it with pyodbc. I do most of my development on a Mac (Snow Leopard) and unfortunately Vertica has not released ODBC drivers for Mac. They do have JDBC drivers though. I don't think developing in Jython is a good compromise. Is there any way to use JDBC drivers with an ODBC application? Some kind of ODBC connector? edit: update for vertica 5/6 can be found here https://github.com/serbaut/psycopg2 Here is a patch to make psycopg2 2.2.1 work with vertica 4.0. No ODBC needed. diff --git a/psycopg/connection_int.c b/psycopg/connection_int.c index 902fdbb..b07eee8 100644 --- a/psycopg/connection_int.c +++ b/psycopg/connection_int.c @@ -2806 +28010 @@ conn_setup(connectionObject *self PGconn *pgconn) pgres = psyco_exec_green(self psyco_datestyle); } + if (self->server_version == 0 && self->protocol == 3) { /* vertica */ + self->encoding = strdup(""UTF8""); + self->isolation_level = 0; + } else { if (pgres == NULL || PQresultStatus(pgres) != PGRES_COMMAND_OK ) { PyErr_SetString(OperationalError ""can't set datestyle to ISO""); IFCLEARPGRES(pgres); @@ -3357 +3397 @@ conn_setup(connectionObject *self PGconn *pgconn) return -1; } self->isolation_level = conn_get_isolation_level(pgres); - + } Py_UNBLOCK_THREADS; pthread_mutex_unlock(&self->lock); Py_END_ALLOW_THREADS; diff --git a/psycopg/typecast_builtins.c b/psycopg/typecast_builtins.c index e8e5a1a..45b9dbc 100644 --- a/psycopg/typecast_builtins.c +++ b/psycopg/typecast_builtins.c @@ -115 +115 @@ static long int typecast_NUMBER_types[] = {20 23 21 701 700 1700 0}; -static long int typecast_LONGINTEGER_types[] = {20 0}; +static long int typecast_LONGINTEGER_types[] = {6 20 0}; static long int typecast_INTEGER_types[] = {23 21 0}; -static long int typecast_FLOAT_types[] = {701 700 0}; -static long int typecast_DECIMAL_types[] = {1700 0}; -static long int typecast_UNICODE_types[] = {19 18 25 1042 1043 0}; +static long int typecast_FLOAT_types[] = {7 701 700 0}; +static long int typecast_DECIMAL_types[] = {16 1700 0}; +static long int typecast_UNICODE_types[] = {8 9 19 18 25 1042 1043 0}; static long int typecast_STRING_types[] = {19 18 25 1042 1043 0}; -static long int typecast_BOOLEAN_types[] = {16 0}; -static long int typecast_DATETIME_types[] = {1114 1184 704 1186 0}; -static long int typecast_TIME_types[] = {1083 1266 0}; -static long int typecast_DATE_types[] = {1082 0}; -static long int typecast_INTERVAL_types[] = {704 1186 0}; +static long int typecast_BOOLEAN_types[] = {5 0}; +static long int typecast_DATETIME_types[] = {12 13 1114 1184 704 1186 0}; +static long int typecast_TIME_types[] = {11 15 1083 1266 0}; +static long int typecast_DATE_types[] = {10 1082 0}; +static long int typecast_INTERVAL_types[] = {14 704 1186 0}; static long int typecast_BINARY_types[] = {17 0}; static long int typecast_ROWID_types[] = {26 0}; static long int typecast_LONGINTEGERARRAY_types[] = {1016 0}; I'm just going to assume this answers the question. I'm not able to verify it though as I haven't had a need for Vertica in a long time.  Yes there are ODBC-over-JDBC bridges. OpenLink among others provides one for Mac OS. Um how do I use this thing? I haven't tried it. However the product includes basic support (http://support.openlinksw.com/supportweb/SupportServicesFAQ#SupportContractNeeded). I hope the Leopard release works on Snow Leopard You mean I have to buy it before they'll explain how it works? This site is so businessy. I don't see developer documentation anywhere. Oh I found it. http://wikis.openlinksw.com/dataspace/owiki/wiki/UdaWikiWeb/InstallODBCJDBCLiteOSX  As of Vertica 6 there are native ODBC drivers for Mac OS X available from the https://my.vertica.com portal"
1026,A,"The topics that should be covered for learning JDBC I have been asked to learn JDBC. I do not know where to start. I have started with some books. It's using some SQL tables (I am also new to SQL). So I want any of you to assist me that the topics that should be covered for JDBC. I also want to know how to creae a simple DB in Windows so that database will be connected to my program. Which books materials are useful to know for: Java Beginners JDBC Connection between Java & JDBC (I do not know whether its right or not) Relation between Java & SQL. the easiest database I have found to get up & running standalone is sqlite Start by focusing on accessing a Database using SQL. JDBC just lets your write Java code to call the SQL so you need to understand SQL first and to understand SQL you need to understand Databases a little: Tables Columns Keys. So you could work through a tutorial such as this link text.  Java Beginners Head to Sun Oracle's own tutorials. The Java Tutorials - Getting started The Java Tutorials - Learning the Java language The Java Tutorials - Essential Classes The Java Tutorials - Collections JDBC Again the vendor's own tutorials are the best (only learn it after basic Java!): The Java Tutorials - JDBC basics You'd like to learn SQL first beforehand (learn it before JDBC): W3Schools - SQL tutorial Connection between Java & JDBC (I do not know whether its right or not) JDBC is a Java API (a set of interfaces and classes). There is no such thing as ""connect between Java and JDBC"". You rather want to connect between Java and the database. You use JDBC for this. You first need to know the JDBC URL of the database in question and the login username and password. Then you can connect it like follows: Connection connection = DriverManager.getConnection(url username password); How the URL should look like depends on the DB and JDBC driver in question. You'd like to consult the documentation of the JDBC driver in question. Relation between Java & SQL. Nothing. Both are separate and independent languages each with an own purpose. SQL is a database communication language. Java is an object oriented programming language. In Java you can use the JDBC API to execute SQL programmatically but that's also really all. I also want to know how to creae a simple DB in Windows so that database will be connected to my program Just choose a database server and download and install it. There are several popular choices: MySQL - JDBC driver PostgreSQL - JDBC driver Oracle - JDBC driver MS SQL Server - JDBC driver (jTDS JDBC driver is better) IBM DB2 - (no public JDBC driver it's included in DB2 install folder) Each of them also ships with DB vendor specific JDBC documentation. It's also worth to get yourself through it (only if you already understand basic JDBC!). See also: JDBC tutorial with MySQL DAO tutorial with MySQL"
1027,A,"What could be the possible cause of this exception? I get the following error when I run a java program: Exception in thread ""main"" java.lang.UnsatisfiedLinkError: t2cPingDatabase at oracle.jdbc.driver.T2CConnection.t2cPingDatabase(Native Method) at oracle.jdbc.driver.T2CConnection.doPingDatabase(T2CConnection.java:503) at oracle.jdbc.driver.PhysicalConnection.pingDatabase(PhysicalConnection.java:4886) at oracle.jdbc.driver.PhysicalConnection.pingDatabase(PhysicalConnection.java:4899) at oracle.jdbc.pool.OracleImplicitConnectionCache.testDatabaseConnection(OracleImplicitConnectionCache.java:2174) at oracle.jdbc.pool.OracleImplicitConnectionCache.performPooledConnectionTask(OracleImplicitConnectionCache.java:1343) at oracle.jdbc.pool.OracleImplicitConnectionCache.doForEveryCachedConnection(OracleImplicitConnectionCache.java:1208) at oracle.jdbc.pool.OracleImplicitConnectionCache.refreshCacheConnections(OracleImplicitConnectionCache.java:1848) at oracle.jdbc.pool.OracleConnectionCacheManager.refreshCache(OracleConnectionCacheManager.java:480) at tkpjb7382521.refreshConnectionPool(tkpjb7382521.java:199) at tkpjb7382521.test(tkpjb7382521.java:115) at tkpjb7382521.run(tkpjb7382521.java:46) at sqlj.qa.harness.AppJdbcHarness.RunTestCase(AppJdbcHarness.java:158) at sqlj.qa.harness.AppJdbcHarness.main(AppJdbcHarness.java:79) What could be the possible reason for this? What JDBC URL are you using ? There is a call to native method t2cPingDatabase made and looks like the JVM is unable to find the native method definition. Could be a library path issue.  Java throws this error when it can't find a native method referenced in a jar. So my guess is you're using the native (OCI) Oracle JDBC driver with a missing or incorrectly configured Oracle client configuration or your URL is incorrect or you're simply missing entries from your tnsnames.ora file. The easiest solution is probably just to use the Oracle thin JDBC driver instead which doesn't require the Oracle TNS client to be installed."
1028,A,"Java JDBC Connection Lost after actionPerformed in Applet If I run this code: http://www.danny92.pastebin.com/m1f84b972 You will see that my Database connection connects then disconnects after actionPerformed.... why? :( As for ""why""... actually add some code in the empty exception handling inside the `connectMySQL()` method of your code. Empty exception handlers ""eat"" errors with no complaint. There would be no error anyway since it reconnects after I call it again. Line 39 has this code:  Connection con = DriverManager.getConnection(""jdbc:mysql://localhost:3306/jgame"" props); Thus you only assign the Connection to a local variable not the con member variable in your applet. Replace it with  con = DriverManager.getConnection(""jdbc:mysql://localhost:3306/jgame"" props);  Applets have many resctrictions including network restrictions. Don't forget that applets run from the client side and not server side therefore as a policy applet was restricted to access company internal networks (the private networks)... In short your code is trying to access your database server (as it never connects because of the network restrictions placed on applets). It's trying to call a private network from a client side. Javascript follows the same restriction as it must never access a private network from client side. More info here (http://www.wutka.com/hackingjava/ch3.htm) So what would be the best way to connect a database to java applet? 1) Create a servlet that you can call from applet using URLConnection. That way servlet talks directly to the database. 2) Create a Web Service or RESTful application that your applet can call from.  I wouldn't recommend that an applet connect directly to a database. This exposes the database directly on the network - not a good practice. A better idea might be to put a servlet in between the applet and the database. This will have several beneficial effects: Servlet can manage security Servlet engine can use a connection pool Servlet can handle several simultaneous connections at once for better scaling 2. You could put a transparent pool between the applet and database server. 3. I don't follow. But +1 for not having the applet connect to the database (although it is much easier to write in some situations). ""transparent"" pool? I'm not familiar with the term. What's managing that if it's not an app server? As for 3 I'm referring to the fact that it'd be easier to scale out horizontally using servlets that connections to a database. Isn't that one of the reasons why client/server was supplanted? Guys.. you're talking to someone who's never worked with JDBC but has with mySQL. Show some links or example? :) Thanks."
1029,A,"Multithreaded JDBC Architecturally what is the best way to handle JDBC with multiple threads? I have many threads concurrently accessing the database. With a single connection and statement I get the following error message: org.postgresql.util.PSQLException: This ResultSet is closed. Should I use multiple connections multiple statements or is there a better method? My preliminary thought was to use one statement per thread which would guarantee a single result set per statement. Yes use multiple connections with a connection pool. Open the connection for just long enough to do what you need then close it as soon as you're done. Let the connection pool take care of the ""physical"" connection management for efficiency.  You should use one connection per task. If you use connection pooling you can't use prepared statements prepared by some other connection. All objects created by connection (ResultSet PreparedStatements) are invalid for use after connection returned to pool. So it's alike public void getSomeData() { Connection conn = datasource.getConnection(); PreparedStatement st; try { st = conn.prepareStatement(...); st.execute(); } finally { close(st); close(conn); } } So in this case all your DAO objects take not Connection but DataSource object (java.sql.DataSource) which is poolable connection factory indeed. And in each method you first of all get connection do all your work and close connection. You should return connection to pool as fast as possible. After connection returned it may not be physically closed but reinitialized (all active transactions closed all session variables destroyed etc.)"
1030,A,sql server query running slow from java I have a java program that runs a bunch of queries against an sql server database. The first of these which queries against a view returns about 750k records. I can run the query via sql server management studio and I get results in about 30 seconds. however I kicked off the program to run last night. when I checked on it this morning this query still had not returned results back to the java program some 15 hours later. I have access to the database to do just about anything I want but I'm really not sure how to begin debugging this. What should one do to figure out what is causing a situation like this? I'm not a dba and am not intimately familiar with the sql server tool set so the more detail you can give me on how to do what you might suggest would be appreciated. heres the code stmt = connection.createStatement(); clientFeedRS = stmt.executeQuery(StringBuffer.toString()); EDIT1: Well it's been a while and this got sidetracked but this issue is back. I looked into upgrading from jdbc driver v 1.2 to 2.0 but we are stuck on jdk 1.4 and v 2.0 require jdk 1.5 so that's a non starter. Now I'm looking at my connection string properties. I see 2 that might be useful. SelectMethod=cursor|direct responseBuffering=adaptive|full Currently with the latency issue I am running with cursor as the selectMethod and with the default for responseBuffering which is full. Is changing these properties likely to help? if so what would be the ideal settings? I'm thinking based on what I can find online that using a direct select method and adaptive response buffering might solve my issue. any thoughts? EDIT2: WEll I ended changing both of these connection string params using the default select method(direct) and specifying the responseBuffering as adaptive. This ends up working best for me and alleviates the latency issues I was seeing. thanks for all the help. a posting of your call to jdbc would be helpful in figuring out what if anything is wrong Whats the Java program? A code snippet of how you're accessing the DB is probably required. Also is SQL Server Studio limiting the results (to say the first 1000 rows) which might be skewing the results? if it was limiting the results to 1k rows how can I be sure it isn't? Are SSMS and your Java app running in the same place? If SSMS is running locally on the SQL Server and your Java app isn't it's not exactly a level comparison. yea ran the query via SSMS from the same place I'm running the java app. Are you sure the result set hasn't returned to Java at all? Or is Java taking forever to process it after it already got the first row? Quote from the MS Adaptive buffer guidelines: Avoid using the connection string property selectMethod=cursor to allow the application to process a very large result set. The adaptive buffering feature allows applications to process very large forward-only read-only result sets without using a server cursor. Note that when you set selectMethod=cursor all forward-only read-only result sets produced by that connection are impacted. In other words if your application routinely processes short result sets with a few rows creating reading and closing a server cursor for each result set will use more resources on both client-side and server-side than is the case where the selectMethod is not set to cursor. And There are some cases where using selectMethod=cursor instead of responseBuffering=adaptive would be more beneficial such as: If your application processes a forward-only read-only result set slowly such as reading each row after some user input using selectMethod=cursor instead of responseBuffering=adaptive might help reduce resource usage by SQL Server. If your application processes two or more forward-only read-only result sets at the same time on the same connection using selectMethod=cursor instead of responseBuffering=adaptive might help reduce the memory required by the driver while processing these result sets. In both cases you need to consider the overhead of creating reading and closing the server cursors. See more: http://technet.microsoft.com/en-us/library/bb879937.aspx  Try adjusting the fetch size of the Statement and try selectMethod of cursor http://technet.microsoft.com/en-us/library/aa342344(SQL.90).aspx We had issues with large result sets using mysql and needed to make it stream the result set as explained in the following link. http://helpdesk.objects.com.au/java/avoiding-outofmemoryerror-with-mysql-jdbc-driver  To start debugging this it would be good to determine whether the problem area is in the database or in the app. Have you tried changing the query such that it returns a much smaller result? If that doesnt return I would suggest targeting the way you are accessing the DB from Java.  Does it take a similar amount of time with SQLWB? If the Java version is much slower then I would check a couple of things: You shoudl get the best performance with a forward-only read-only ResultSet. I recall that the older JDBC drivers from MSFT were slow. Make sure you are using the latest-n-greatest. I think there is a generic SQL Server one and one specifically for SQL 2005.  Be sure that your JDBC driver is configured to use a direct connection and not a cusror based connection. You can post your JDBC connection URL if you are not sure. Make sure you are using a forward-only read-only result set (this is the default if you are not setting it). And make sure you are using updated JDBC drivers. If all of this is not working then you should look at the sql profiler and try to capture the sql query as the jdbc driver executes the statement and run that statement in the management studio and see if there is a difference. Also since you are pulling so much data you should be try to be sure you aren't having any memory/garbage collection slowdowns on the JVM (although in this case that doesn't really explain the time discrepancy). why do you say to use direct instead of cursor based? isn't based supposed to help with large result sets? @shsteimer Accroding to Microsoft docs Direct is faster. You should only use cursors if you need the row by row access (or in JDBC if you need distributed transactions across multiple database you have no choice.  If the query is parametrized it can be a missing parameter or a parameter that is set with the wrong function e.g. setLong for string etc. Try to run your query with all parameters hardcoded into the query body without any ? to see of this is a problem.  Pulling back that much data is going to require lots of time. You should probably figure out a way to not require that much data in your application at any given time. Page the data or use lazy loading for example. Without more details on what you're trying to accomplish it's hard to say. I'm ok with a long time I'm even ok with it taking several minutes tens of minutes is fine but hours just seems to me that something odd is going on. How is your memory doing on the box?  The fact that it is quick when run from management studio could be due to an incorrectly cached query plan and out of date indexes (say due to a large import or deletions). Is it returning all 750K records quickly in SSMS? Try rebuilding your indexes (or if that would take too long update your statistics); and maybe flushing the procedure cache (use caution if this is a production system...): DBCC FREEPROCCACHE
1031,A,"How do I get a Double out of a resultset instead of double? When working with a JDBC resultset I want to get Double instead of double since this column is nullable. Rs.getDouble returns 0.0 when the column is null. An alternative to the aforementioned ResultSet#wasNull() is to test ResultSet#getObject() on null so that you can nicely put it in a single line in combination with the ternary operator: Double d = resultSet.getObject(""column"") != null ? resultSet.getDouble(""column"") : null; instead of Double d = resultSet.getDouble(""column""); if (resultSet.wasNull()) { d = null; } Interesting point although there is a performance penalty here for calling a getter twice in the common case when the value is not null. Maybe it is possible just to cast the result of getObject to a Double? @Yoni: There's certainly no performance penalty in invoking a simple getter. The data is *already* there since `next()` has been called. but also note what the documentation of ResultSet says: `For maximum portability result set columns within each row should be read in left-to-right order and each column should be read only once.` :-@ @Carlos: that was specified over 15 years ago. This is really not an issue nowadays.  You can check for wasNull on your ResultSet to find out if the value was null. Note that you must first call one of the getter methods on a column to try to read its value and then call the method wasNull to see if the value read was SQL NULL. If you really need a Double afterwards you can create it from the double returned. +1 hardly more to say  You could just do: Double d = (Double) resultSet.getObject(""column""); then you don't have to worry if it was null. Be careful you may end with having an error like ""ClassCastException 'java.math.BigDecimal cannot be cast to java.lang.Double'""  Use ResultSet.wasNull -> http://java.sun.com/javase/6/docs/api/java/sql/ResultSet.html#wasNull%28%29 Basically it works for all primitive types you first use getDouble getInt etc. and then only if the result is 0 you use wasNull."
1032,A,"Spring JdbcTemplate and Threading Is it safe to fork off a Thread to execute an insert using a JdbcTemplate in Swing. It's a logging event and as much as possible I don't want it to affect perceived performance. Why would you think that it wouldn't be? I've not used JdbcTemplate directly from Swing but I have in several web applications (which have a separate thread per request) and I've never had any problems with threading issues from it. In this situation the template was configured once at application startup and repeatedly called with different parameters. If you're worried about threading issues you can always create a new template per logging thread...  This answer from the Spring forum says yes: http://forum.springframework.org/showthread.php?t=25965 JdbcTemplate is a singleton that won't change state once it's set.  Also note that its thread-safety is very well explained in the Spring 3.1 reference documentation: 13.2.1.2 JdbcTemplate best practices Instances of the JdbcTemplate class are threadsafe once configured. This is important because it means that you can configure a single instance of a JdbcTemplate and then safely inject this shared reference into multiple DAOs (or repositories). The JdbcTemplate is stateful in that it maintains a reference to a DataSource but this state is not conversational state. And read carefully ""once configured"" bit so don't misuse setMaxResult for limiting result set for given thread for given query as it affects all the queries and all the threads using shared JdbcTemplate instance."
1033,A,"Problem with SQL ResultSet in java How can I iterate ResultSet ? I've tried with the following code but i get the error java.sql.SQLException: Illegal operation on empty result set.  while ( !rs.isLast()) { rs.next(); int id = rs.getInt(""person_id""); SQL.getInstance().getSt().execute(""INSERT ref_person_pub(person_id) VALUES("" + id + "")""); } Update: I've found the problem. I have used only one statement from the SQL singleton. When the statement is closed it can't be used again. As per the JDBC tutorial: resultSet = statement.executeQuery(); while (resultSet.next()) { int id = resultSet.getInt(""id""); // ... } The ResultSet#next() moves the cursor forward one row from its current position and returns true if the new current row is valid. Thus the while loop will stop automatically when there are no more rows. If it is supposed to return zero or one row instead of multiple rows then rather use if instead: resultSet = statement.executeQuery(); if (resultSet.next()) { int id = resultSet.getInt(""id""); // ... } This way you have the opportunity to add an else. Update that said and unrelated to the actual problem I see more potential problems in your code: first you seem to fire multiple queries which are dependent on each other. This can be done more efficient. Are you familiar with SQL Joins? Second aren't you leaking JDBC resources? It look like that you're acquiring a statement but not getting a handle of it so that you can properly close it after use. Please consult the before linked JDBC tutorial for a basic explanation how to work properly with JDBC code and this article for several basic kickoff examples how to use JDBC properly. Otherwise your application may crash sooner or later when the DB runs out of resources. You can impossibly get `Illegal operation on empty result set` when calling `next()` on a freshly acquired resultset. So your problem lies somewhere else. Either you're accessing the wrong resultset or you're misinterpreting the exception and/or the code line where it's been caused. If `getSt` (I suggest using full words) returns the same `Statement` then it isn't a leak. My JDBC is very rusty are you allowed to carry on using an iterator whilst executing another statement on the `Statement` (bad analogy: mutating a collection whilst iterating over it)? Anyway use a `PreparedStatement` rather than dynamic SQL. Edit: Second line of `Statement` API docs: ""By default only one ResultSet object per Statement object can be open at the same time. "" @Tom: True but looking at OP's skills/knowledge shown as far (no offense) I wouldn't expect him to magically close the `Statement` correctly somehow when it is finished with its tasks. I honestly also don't see proper ways to do it in the given code. Some nasty conditional checks in the `getInstance()` call maybe? No I wouldn't do it. As per your edit: that would have thrown a different `SQLException` on `next()` and then only when another `ResultSet` is been acquired afterwards. When I try to use rs.next() in the while statement I get the same error.  while(rs.next()) { // iterate }"
1034,A,Number of sockets available for a JDBC connection at Windows 2003 My team built a Windows Service in Java that connects to a SQL Server 2005 in a Windows 2003 Server using pure JDBC (no connection pooling) with the JTDS driver. After a while the method that opens the connections to the database start raising exceptions with the following stack trace:  java.net.BindException: Address already in use: connect at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.PlainSocketImpl.doConnect(PlainSocketImpl .java:305) at java.net.PlainSocketImpl.connectToAddress(PlainSoc ketImpl.java:171) at java.net.PlainSocketImpl.connect(PlainSocketImpl.j ava:158) at java.net.Socket.connect(Socket.java:452) at java.net.Socket.connect(Socket.java:402) at java.net.Socket.<init>(Socket.java:309) at java.net.Socket.<init>(Socket.java:124) Although the programmers were careful to close connections when they were done something is not going right. For the time being we solved the problem switching to the Named Pipes protocol (since all is hosted in the same machine) but this is a temporary solution. I've googled for the problem and it seems we should be using some connection pooling library such c3p0. Is this the only solution to the problem? Could I try to raise the sockets limit in Windows 2003? It really looks like you're connections aren't being closed. That or you're trying to re-use the connection incorrectly... It's strongly recommend to use a connection pool for various performance reasons. For example you won't need to create a connection each time which is very expensive. Re-using connections makes a world of difference. Secondly do you really want to create your own pooling mechanism? It's not as simple as it appears there are lots of idiosyncratic threading issues. It's much easier to just use an existing library that's withstood the test of time.  Are you opening / closing connections at a very rapid rate? When a TCP connection is closed they hang around for a little while in the TIME_WAIT state. On Windows the default time they exist is 240 seconds. It sounds like you might have quite a few tcp connections in the TIME_WAIT state. You can check this by running netstat. If you have a huge number of tcp connections to the database server in the TIME_WAIT state a connection pool will fix your issue. You can try to raise the socket limit and/or lower the time a connection will stay in the TIME_WAIT state. But this will alter the behavior of all tcp connections. So use a connection pool :) We use dbcp as our connection pool solution in Java.
1035,A,"how can the PL/SQL datatype BINARY_INTEGER materialized as Java types? What would be the datatype in java equivalent to the PL/SQL datatype BINARY_INTEGER? If you're lazy in reading the documentation then you could also play a bit with ResultSet#getObject() to see what default type the JDBC driver returns and then use it. System.out.println(resultSet.getObject(""columnname"").getClass());  According to the Oracle documentation we can map it to either oracle.sql.NUMBER or a straightforward int primitive.  BINARY_INTEGER is a subtype of INTEGER and ranges from -2^31 to 2^31 same size as the int type in java so you could use int. (Another equivalent type in PL/SQL to BINARY_INTEGER is PLS_INTEGER and this one is faster in most operations)."
1036,A,"jdbc4 CommunicationsException I have a machine running a java app talking to a mysql instance running on the same instance. the app uses jdbc4 drivers from mysql. I keep getting com.mysql.jdbc.exceptions.jdbc4.CommunicationsException at random times. Here is the whole message. Could not open JDBC Connection for transaction; nested exception is com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: The last packet successfully received from the server was25899 milliseconds ago.The last packet sent successfully to the server was 25899 milliseconds ago which is longer than the server configured value of 'wait_timeout'. You should consider either expiring and/or testing connection validity before use in your application increasing the server configured values for client timeouts or using the Connector/J connection property 'autoReconnect=true' to avoid this problem. For mysql the value of global 'wait_timeout' and 'interactive_timeout' is set to 3600 seconds and 'connect_timeout' is set to 60 secs. the wait timeout value is much higher than the 26 secs(25899 msecs). mentioned in the exception trace. I use dbcp for connection pooling and here is spring bean config for the datasource.  <bean id=""dataSource"" destroy-method=""close"" class=""org.apache.commons.dbcp.BasicDataSource"" > <property name=""driverClassName"" value=""com.mysql.jdbc.Driver""/> <property name=""url"" value=""jdbc:mysql://localhost:3306/db""/> <property name=""username"" value=""xxx""/> <property name=""password"" value=""xxx"" /> <property name=""poolPreparedStatements"" value=""false"" /> <property name=""maxActive"" value=""3"" /> <property name=""maxIdle"" value=""3"" /> </bean> Any idea why this could be happening? Will using c3p0 solve the problem ? Can you describe how your app is handling connection pooling? I doubt that autoReconnect=true in the JDBC driver would re-pool connections from your app. The app needs to reconnect when it loses a connection.  I'd follow the advice in the exception. You should consider either: expiring and/or testing connection validity before use in your application increasing the server configured values for client timeouts or using the Connector/J connection property 'autoReconnect=true' to avoid this problem. Try adding that to your connection URL (consult the docs for the exact syntax) and see if it helps. I doubt that C3P0 will be that much better than the DBCP that you're already using. The exception is giving you some specific advice. You've tried #3. What about the other two? I know how to ask WebLogic to check connections before using them. You should find out how to do the same with Tomcat. tried it out now getting ""Could not open JDBC Connection for transaction; nested exception is com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure""  Try setting up the Apache Commons DBCP correctly. You need to set: validationQuery to SELECT 1+1 testOnBorrow to true That should fix the problem. Thnx this seems to be working at the moment.  I have seen before that Windows machines which have been moved on the network have had trouble with connecting to themselves. Is there any connectivity problems outside the JVM - i.e. mysql client connecting to the server and timing out etc?"
1037,A,Does SqlCommand optimize parameterized sql statements? I know in Java when using PreparedStatement with parameters some JDBC drivers will optimize the SQL queries by turning them into stored procedures so that all the subsequent calls will run faster. Does SqlCommand provide such optimization when accessing MS SQLServer? You can call command.Prepare() to perform this optimization. http://msdn.microsoft.com/en-us/library/system.data.sqlclient.sqlcommand.prepare.aspx
1038,A,com.mysql.jdbc.exceptions.MySQLNonTransientConnectionException: Can't call rollback when autocommit=true Im using Jboss5.0 with mysql in my application. and there will be lot of concurrent actions and DB contains considerably lot of records. this error is coming frequently.. every now and then.  com.mysql.jdbc.exceptions.MySQLNonTransientConnectionException: Can't call rollback when autocommit=true at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:888) at com.mysql.jdbc.Connection.rollback(Connection.java:5192) at org.jboss.resource.adapter.jdbc.local.LocalManagedConnection.rollback(LocalManagedConnection.java:97) at org.jboss.resource.connectionmanager.TxConnectionManager$TxConnectionEventListener.tidyup(TxConnectionManager.java:783) at org.jboss.resource.connectionmanager.BaseConnectionManager2.returnManagedConnection(BaseConnectionManager2.java:453) at org.jboss.resource.connectionmanager.TxConnectionManager$TxConnectionEventListener.connectionClosed(TxConnectionManager.java:734) at org.jboss.resource.adapter.jdbc.BaseWrapperManagedConnection.closeHandle(BaseWrapperManagedConnection.java:362) at org.jboss.resource.adapter.jdbc.WrappedConnection.close(WrappedConnection.java:155) can anyone help? Thanks in advance http://forums.sun.com/thread.jspa?threadID=5370911 thanks. if i set auto commit false for a whole  will it affect any non transactional updates. Either you are attempting to call rollback when auto commit is turned on or you're using MyISAM type tables in your database which do not support transactions (and the ability to rollback). Judging by the stacktrace a transaction to the database is failing and in an attempt to create an SQLException and rollback the transaction this exception is occurring. Unless there's more to the exception (like an indication as to where in your code the exception is being fired) then I would hazard a guess that it's due to MyISAM tables. im using innodb and it support transactions. im having both transactional and non-transactional queries. @Tamizh are you calling rollback() in your code and if so have you tried disabling auto commit before doing so? yes whenever i use transactions i first set autocommit false. and now i found its coming as WARN in jboss log file instead ERROR. so actually this is a WARNING when connections lost or blinking for long time i guess
1039,A,"JSP: execution non-English chars in mysql query I wrote a JSP code that needs to run some mysql INSERT queries that contains non-English chars (Persian). I run two types of queries first one is static application installation queries and second one is user inputs. After execution of both of queries non-English chars are imported as ""?"" as I check them in application itself and phpMyAdmin! I tried to execute these queries after connection but I didn't help: SET NAMES utf8 SET CHARACTER SET utf8 SET SESSION collation_connection = 'utf8_general_ci' What's the problem ? How can I fix it? After execution of both of queries none english chars are imported as ""?"" as I check them in application itself and phpMyAdmin! So the database (or more specifically the JDBC driver) is not using UTF-8 during INSERT. Usually the database's JDBC driver should be smart enough to use the database and/or table specified encoding for storing the data. But in some cases you have to specify the character encoding in the connection string as well. This is true in case of MySQL JDBC driver because it does not use the database-specified encoding but the client-specified encoding. How to configure it should already be answered in the JDBC driver documentation. In for example MySQL you can read it here: jdbc:mysql://localhost:3306/db_name?useUnicode=yes&characterEncoding=UTF-8 That said and unrelated to the problem you should in fact try to avoid raw Java code in a JSP file. It would only lead to another kinds of problems in the future. It worked! Thank you very much! You're welcome."
1040,A,"Call to DataSource.getConnection not returning the expected connection I have the following code:  Hashtable env1 = new Hashtable(); env1.put(javax.naming.Context.INITIAL_CONTEXT_FACTORY""com.ibm.websphere.naming.WsnInitialContextFactory""); log.info(""Executed step 1""); env1.put(javax.naming.Context.PROVIDER_URL ""iiop://myhost.com:9301""); log.info(""Executed step 2""); Context ctx = new InitialContext(env1); DataSource ds = (DataSource)ctx.lookup(""jdbc/mydatasource""); log.info(""Excecuted lookup =""+ds); conn = ds.getConnection(); I have the previous code in an standalone application that is connecting to WAS 6.1.0.3 in order to retrieve a connection from the datasource. The code is very straighforward and I have seen the same code working in a different environment but in this case when I call getConnection I get an exception. The datasource is WAS has the proper authentication alias set and when the connection is tested it works OK from the WAS side but the previous code won't work. If I change this line: conn = ds.getConnection(); to this: conn = ds.getConnection(""username""""password""); Then the code will work! But that's not what I want since the connections in the datasource should already have the credentials set. I was initially thinking this was a Sybase problem but it's also happening with Oracle so would rather say I have a problem with WAS. If you are curious about the exceptions for Sybase I get: java.sql.SQLException: JZ004: User name property missing in DriverManager.getConnection(... Properties).DSRA0010E: SQL State = JZ004 Error Code = 0 at com.sybase.jdbc2.jdbc.ErrorMessage.raiseError(ErrorMessage.java:569) at com.sybase.jdbc2.tds.LoginToken.<init>(LoginToken.java:128) at com.sybase.jdbc2.tds.Tds.doLogin(Tds.java:506) at com.sybase.jdbc2.tds.Tds.login(Tds.java:449) at com.sybase.jdbc2.jdbc.SybConnection.tryLogin(SybConnection.java:254) at com.sybase.jdbc2.jdbc.SybConnection.regularConnect(SybConnection.java:230) at com.sybase.jdbc2.jdbc.SybConnection.<init>(SybConnection.java:200) at com.sybase.jdbc2.jdbc.SybPooledConnection.<init>(SybPooledConnection.java:72) at com.sybase.jdbc2.jdbc.SybConnectionPoolDataSource.createConnection(SybConnectionPoolDataSource.java:138) at com.sybase.jdbc2.jdbc.SybDriver.connect(SybDriver.java:485) at com.sybase.jdbc2.jdbc.SybDriver.connect(SybDriver.java:517) at com.sybase.jdbc2.jdbc.SybDataSource.getConnection(SybDataSource.java:227) at com.sybase.jdbc2.jdbc.SybConnectionPoolDataSource.getPooledConnection(SybConnectionPoolDataSource.java:74) at com.ibm.ws.rsadapter.spi.InternalGenericDataStoreHelper$1.run(InternalGenericDataStoreHelper.java:897) at com.ibm.ws.security.util.AccessController.doPrivileged(AccessController.java:118) at com.ibm.ws.rsadapter.spi.InternalGenericDataStoreHelper.getPooledConnection(InternalGenericDataStoreHelper.java:892) at com.ibm.ws.rsadapter.spi.WSRdbDataSource.getPooledConnection(WSRdbDataSource.java:1181) at com.ibm.ws.rsadapter.spi.WSManagedConnectionFactoryImpl.createManagedConnection(WSManagedConnectionFactoryImpl.java:1047) at com.ibm.ws.rsadapter.spi.WSDefaultConnectionManagerImpl.allocateConnection(WSDefaultConnectionManagerImpl.java:81) at com.ibm.ws.rsadapter.jdbc.WSJdbcDataSource.getConnection(WSJdbcDataSource.java:431) at com.ibm.ws.rsadapter.jdbc.WSJdbcDataSource.getConnection(WSJdbcDataSource.java:400) And for Oracle I get this one: java.sql.SQLException: invalid arguments in callDSRA0010E: SQL State = null Error Code = 17433 at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:112) at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:146) at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:208) at oracle.jdbc.driver.T4CConnection.logon(T4CConnection.java:236) at oracle.jdbc.driver.PhysicalConnection.<init>(PhysicalConnection.java:420) at oracle.jdbc.driver.T4CConnection.<init>(T4CConnection.java:165) at oracle.jdbc.driver.T4CDriverExtension.getConnection(T4CDriverExtension.java:35) at oracle.jdbc.driver.OracleDriver.connect(OracleDriver.java:801) at oracle.jdbc.pool.OracleDataSource.getPhysicalConnection(OracleDataSource.java:297) at oracle.jdbc.pool.OracleDataSource.getConnection(OracleDataSource.java:221) at oracle.jdbc.pool.OracleConnectionPoolDataSource.getPhysicalConnection(OracleConnectionPoolDataSource.java:157) at oracle.jdbc.pool.OracleConnectionPoolDataSource.getPooledConnection(OracleConnectionPoolDataSource.java:94) at oracle.jdbc.pool.OracleConnectionPoolDataSource.getPooledConnection(OracleConnectionPoolDataSource.java:75) at com.ibm.ws.rsadapter.spi.InternalGenericDataStoreHelper$1.run(InternalGenericDataStoreHelper.java:897) at com.ibm.ws.security.util.AccessController.doPrivileged(AccessController.java:118) at com.ibm.ws.rsadapter.spi.InternalGenericDataStoreHelper.getPooledConnection(InternalGenericDataStoreHelper.java:892) at com.ibm.ws.rsadapter.spi.WSRdbDataSource.getPooledConnection(WSRdbDataSource.java:1181) at com.ibm.ws.rsadapter.spi.WSManagedConnectionFactoryImpl.createManagedConnection(WSManagedConnectionFactoryImpl.java:1047) at com.ibm.ws.rsadapter.spi.WSDefaultConnectionManagerImpl.allocateConnection(WSDefaultConnectionManagerImpl.java:81) at com.ibm.ws.rsadapter.jdbc.WSJdbcDataSource.getConnection(WSJdbcDataSource.java:431) at com.ibm.ws.rsadapter.jdbc.WSJdbcDataSource.getConnection(WSJdbcDataSource.java:400) In both cases I won't the exception if I pass the credentials to the getConnection method Thanks for your advice. It's been a long time since I've done anything with WebSFEAR^H^H^H^Hphere but it looks to me that you have a configuration problem. There was a special screen where you'd create credentials (user/pass) and later you'd apply those credentials to the created data source. It looks like that your configured data source hasn't got credentials applied. Actually the ""Authentication Alias"" is set in the datasource but seems like these credentials are not being applied.  Even after defining the user/password values as custom properties I found that the connections for Oracle weren't working. After many days I just found that the development server is running an old WAS 6.1 version the problem I'm having was fixed in WAS 6.1.0.5: PK32838: J2CA0046E WHEN USING USING CUSTOM PROP PASSWORD ON DATASOURECE I tried my code in a different WAS server with an updated WAS fix pack level and... it worked without introducing a single change in the code or in the configuration. So the solution is to upgrade the WAS server. Thanks.  Short answer: external clients don't get to use the authentication alias data Longer Answer: From the WAS J2C connection factory documentation: The alias that you configure for component-managed authentication does not apply to all clients that must access the secured resource. External Java clients with Java Naming and Directory Interface (JNDI) access can look up a Java 2 Connector (J2C) resource such as a data source or Java Message Service (JMS) queue. However they are not permitted to take advantage of the component-managed authentication alias defined on the resource. This alias is the default value that is used when the getConnection() method does not specify any authentication data like user and password or a value for ConnectionSpec. If an external client needs to get a connection it must assume responsibility for the authentication by passing it through arguments on the getConnection() call. Thanks for the pointer!!! The way I have found to overcome this issue is to provide the user and password as custom properties this works OK for Sybase (custom properties named ""USER"" and ""PASSWORD"" in uppercase) but it's not working for Oracle (custom properties named ""user"" and ""password"" in lowercase) I think it's because the Oracle's ""password"" custom property is being encrypted when entered the first time but it's not unencrypted when when I access the datasource from my external client (but works for any application deployed in WAS). I'll ask a new question for that one thanks again!"
1041,A,"Building a data layer using Spring JdbcTemplate Do you know of any resources that describe building a data access layer using Spring's JdbcTemplate classes? I'm looking for something beyond the basics described in the Spring framework documentation. Please keep us updated on what you find - I'm interested in this subject as well Is the Spring documentation lacking something you require in your data access layer? If so would you be able to offer an example of this shortcoming to help me better understand your question? I'd like to see an example of how all of the Jdbc-related classes are put together to design a DAL. I have rolled my own primitive DAL but would like to see a more comprehensive implementation. If not the online docs perhaps books will help. ""Spring in Action"" ""Pro Spring"" ""Spring Recipes"" - take your pick. I'm not sure how much detail you're looking for though. I fear that you'll be disappointed. The 2 apress books you mention have a lot of good code that give examples of using SQLFunction SQLUpdate MappingSqlQuery etc. This is more or less what I was looking for. Cheers. Thanks. Spring in Action has little beyond the 'best practices' section of the Spring docs. I'll look into the other books.  I'm not really sure of exactly what it is you are looking for but I basically create a DAO class that has a SimpleJDBCTemplate as a property. It is set via dependency injection. The public methods of the DAO abstract the interaction with the SimpleJDBCTemplate."
1042,A,"How can I connect to an Oracle database from Ant using the tnsname? I am looking for something similar to the Ant sql task but that will accept a JDBC url of the format: jdbc:oracle:thin:@TNS_NAME One possible approach seems to be to write my own Ant task that uses an OracleDataSource to create the Connection but is there a way to do this straight in Ant? EDIT: Thanks for the responses so far guys. I hope it helps if I elaborate a bit more on the error I'm getting. My Ant task looks as follows: <target name=""MyTarget"" > <property name=""oracle.net.tns_admin"" value=""/opt/oracle/product/10.2.0.1/NETWORK/ADMIN"" /> <property name=""jdbc.driver"" value=""ojdbc5.jar"" /> <property name=""jdbc.i18n.support"" value=""orai18n.jar"" /> <property name=""jdbc.driver.class"" value=""oracle.jdbc.OracleDriver"" /> <path id=""sql.class.path""> <pathelement location=""${jdbc.driver}"" /> <pathelement location=""${jdbc.i18n.support}"" /> </path> <sql driver=""${jdbc.driver.class}"" url=""jdbc:oracle:thin:@THE_TNS_NAME"" userid=""USER"" password=""PASSWORD"" classpathref=""sql.class.path"" > <![CDATA[ #SOME ARBITRARY SQL HERE ]]> </sql> </target> This fails with the error: java.sql.SQLException: Io exception: Unknown host specified Replacing the url with ""jdbc:oracle:thin:@HOST:PORT:INSTANCE"" works fine and I can also tnsping the tns name used above so I know it's valid. That should just work with the usual Ant sql task shouldn't it? Is there a problem with using it that way? It would be perfect if it just worked but I must be doing something wrong. I have updated the question with my Ant script--is there a fault? Are you connection with Oracle or MySQL ? Since we don't now yet what the exact problem is I can only assume that this might help: http://theblasfrompas.blogspot.com/2008/04/jdbc-thin-connection-using-tnsnamesora.html This link has been very useful for me in the past but in this particular case I am trying to connect from within Ant. Do I still need to specify the oracle.net.tns_admin system property? If so how would I do that? I have updated my question with the way I am currently using it. Thanks for the help. I would think so. You do it like this: which I copied from here: http://ideoplex.com/id/372/setting-java-system-properties-with-ant  Was just working with this today and stumbled upon the missing piece. The TNS location needs to be set as a system property as indicated here: Oracle thin JDBC to TNS name To establish an Oracle thin JDBC connection to a TNS alias (tnsname) make sure you pass the oracle.net.tns_admin system property to the JVM. Its value should be the directory in which your tnsnames.ora file is located. After that you can just pass the TNS alias in place of the host name in the JDBC URL. E.g. if you simply try to connect to jdbc:oracle:thin:@MYDB which is in your tnsnames.ora file you’ll get an SQLException with a detail message of Io exception: Unknown host specified. If you fire up the JVM with a -Doracle.net.tns_admin=/oracle/10g/NETWORK/ADMIN or use System.setProperty(StringString) after startup the connection will be established successfully. After doing this I was able to successfully connect using the TNS alias alone. Thanks for your answer! It's been so long since I had this problem that I can barely remember the details but your answer seems very promising :)  If you mean that you want a ""thick"" connection that uses tnsnames.ora and not the thin driver then you can wrap a call to sqlplus in the xml file: <target name=""myTarget""> <!-- login.sql should have sqlcode exit so failonerror will fail build --> <exec executable=""sqlplus"" failonerror=""true""> <arg value=""${userid}/${password}@${tnsalias}""/> <arg value=""@myScript""/> </exec> </target> ... is the basic idea. [where userid password and tnsalias are defined in your properties file] This obviously means you'll have to have at least the Instant Client stack installed.  Are you sure it's NETWORK/ADMIN and not network/admin? Unix filesystems are usually case sensitive - (assuming it's on Unix). You're quite right it is actually ""network/admin"". However I have tried both and it made no difference. I'm wondering if there isn't a better way to pass the property to the sql task (when I call the java target I use a 'sysproperty' but the sql task doesn't seem to support this...)."
1043,A,"ThreadLocal + java.sql.Connection + servlet filter = 2009? I am writing some servlets with plain old mostly-JDBC patterns. I realized that I have several objects that would like to share a single transaction and I'd like to enforce that one HTTP transaction = one database transaction. I think I can do this via passing a Connection around in a ThreadLocal variable and then having a servlet filter handling the creation/commit/rollback of said Connection. Is there an existing framework that does this that I'm not privy to or is this a reasonable late-00's way to do things? Why you can't pass the Connection as a parameter of the methods you are calling? Having a filter manage the transaction is a good approach to rolling your own transaction management. The Java EE specification provides for transaction management and alternative frameworks like Spring provide similar support (though that's not an endorsement; Spring doesn't necessarily do this well). However use of a ThreadLocal can create problems. For example there are no guarantees that a single thread is used throughout a request anything can access the Connection through the global variable and testing can become more difficult if you are depending on some global state to be set up. I'd consider using a dependency injection container to explicitly pass a Connection to objects that need one.  It is generally better to pass object with ""Parameterisation from Above"" the sleazing through with ThreadLocal. In the case of ServletFilter an attribute of the ServletRequest would be an obvious place. The interface to non-servlet dependent code can extract the Connection to meaningful context.  Most appServer todays support JTA (Java Transaction Api): A transaction that spans over multiple open/close jdbc connections. It does the ""threadLocal"" stuff for you and it's J2EE compliant. You use it like this in your filter:  public void doFilter(ServletRequest request ServletResponse response FilterChain chain) throws IOException ServletException { UserTransaction transaction = null; try { transaction = (UserTransaction)new InitialContext().lookup(""java:comp/UserTransaction""); transaction.begin(); chain.doFilter(request response); transaction.commit(); } catch (final Exception errorInServlet) { try { transaction.rollback(); } catch (final Exception rollbackFailed) { log(""No ! Transaction failed !""rollbackFailed); } throw new ServletException(errorInServlet); } } On the app-server declare a Datasource with a jndi name and use it in your code to retrieve a connection (do NOT make cx.commit() cx.rollback() or cx.setAutocommit() stuff it will interfere with JTA). You can open and close your connection several times in the same HTTP transaction JTA will take care of it: public void doingDatabaseStuff() throws Exception { DataSource datasource = (DataSource)new InitialContext().lookup(""/path/to/datasource""); Connection connection = datasource.getConnection(); try { // doing stuff } finally { connection.close(); } } more about JTA: http://stackoverflow.com/questions/840694/what-do-i-need-to-do-to-integrate-jta-into-a-j2se-application JTA looks handy I wonder if JTA integrates well with Tomcat/Jetty? I am trying to keep this part of the app as lean as possible (i.e just servlets minimal dependencies etc) I have to admit that I only used JTA on $$$ appServers. It seems that Tomcat and Jetty don't provide a JTA implementation by themselves. Jboss and JOTM provides standalone JTA impl but they comes with ejb support or seems complex. The link you gave points on BTM (http://docs.codehaus.org/display/BTM/Home) which seems to fit all your needs (active community free lightweight well documented integration and use). Honestly I don't know if it will works but it sounds pretty promising. BTW take a look at the tutorial (http://docs.codehaus.org/display/BTM/JtaBestPractices) which is remarkably concise and clear and also this bit of optimisation (http://docs.codehaus.org/display/BTM/LastResourceCommit13) With the help of these two links (below) and theses two last ones: integration with Tomcat (http://docs.codehaus.org/display/BTM/Tomcat13) integration with Jetty (http://docs.codehaus.org/display/BTM/Jetty13) I think you'll be able to quickly build a proof of concept.  If you cannot rely on a ""real"" app server and you want to avoid the not-so-lightweightness of Spring using a filter to provide a connection keep it on the thread and close it at the end of the request is indeed a practical and reasonable solution. You would need some (essentially static) accessor class that allows to get() a connection and a setRollbackOnly(). Upon end of the request from the filter's perspective make sure to catch exceptions (upon which you should log and set to rollback only) and commit/rollback close the transaction accordingly. In most applications and web containers (and JTA usually makes similar assumptions) a request will be processed by exactly one thread and associating the one database connection with the thread for re-use between layers during the request is just the right thing to do.  Spring transaction management does exactly what you describe it might be a little over whelming at first glance but all you will be needing (for the simplest case) is: org.springframework.jdbc.datasource.DataSourceTransactionManager org.springframework.jdbc.datasource.TransactionAwareDataSourceProxy org.springframework.transaction.support.TransactionTemplate Wire up your existing DataSource and wrap it in the TransctionAwareDataSourceProxy then create a DataSourceTransactionManager with the wrapped data source keep these in your ServletContext. Then for each transaction create a TransactionTemplate passing in the transaction manager and call the execute(TransactionCallback) method to run your code. eg: new TransactionTemplate(transactionManager).execute(new TransactionCallback(){ public void doInTransaction(TransactionStatus ts){ // run your code here...use the dataSource to get a connection and run stuff Connection c = dataSourceProxy.getConnection(); // to rollback ... throw a RuntimeException out of this method or call st.setRollbackOnly(); } }); The connection will be bound to a thread local so as long as you always get the connection form the same datasource i.e. the wrapped one you'll get the same connection in the same transaction. Note this is the simplest possible spring transaction setup ... not nessarly the best or recommended one for that have a look at the spring reference doc's or read spring in action. ... so I guess as a direct answer yes it is a reasonable thing to be doing it's what the spring framework has been doing for a long time. I will have to check it out I'm trying to avoid large-ish frameworks in this app (thus going with plain servlets) but if I can use Spring without going all-in it might be a solution. I kinda figured you where going for a minimal approach. Go for the modular jars spring-transaction.jar and spring-core etc you should be able to get away with out having to include the uber 2mb spring.jar I agree if you want plain JDBC it's fine but don't reinvent the wheel SpringFrameowrk JDBC support can be embedded very easy and JDBC API is pretty small and you will benefit reusing what was already written and tested. I only needed 5 .jars and I converted to JdbcTemplate-style. I hate straight JDBC programming anyway ;) good result. If you are using the JdbcTemplate stuff you won't need to use the TransactionAwareDataSourceProxy thing as the JdbcTemplate is transaction aware and will sort that stuff out for you. Ok well 7 .jars by the time I got it into a web server..."
1044,A,"Check if table exists I have a desktop application with a database embedded in it. When I execute my program I need to check that specific table exists or create it if not. Given a Connection object named conn for my database how could I check this? possible duplicate of [How can I detect a SQL table's existence in Java?](http://stackoverflow.com/questions/927807/how-can-i-detect-a-sql-tables-existence-in-java) DatabaseMetaData dbm = con.getMetaData(); // check if ""employee"" table is there ResultSet tables = dbm.getTables(null null ""employee"" null); if (tables.next()) { // Table exists } else { // Table does not exist }  Adding to Gaby's post my jdbc getTables() for Oracle 10g requires all caps to work: ""employee"" -> ""EMPLOYEE"" Otherwise I would get an exception: java.sql.SqlExcepcion exhausted resultset (even though ""employee"" is in the schema)  You can use the available meta data:  DatabaseMetaData meta = con.getMetaData(); ResultSet res = meta.getTables(null null null new String[] {""TABLE""}); while (res.next()) { System.out.println( "" ""+res.getString(""TABLE_CAT"") + "" ""+res.getString(""TABLE_SCHEM"") + "" ""+res.getString(""TABLE_NAME"") + "" ""+res.getString(""TABLE_TYPE"") + "" ""+res.getString(""REMARKS"")); } See here for more details. Thank you!!!!!! You're requesting all tables from the server and then browsing through those names locally. That is not very efficient if you just want to check if table 'X' exist. You would want to use the 3rd argument to the `getTables()` method !!! (rather than using 'null' as you do)"
1045,A,"In JDBC why do parameter indexes for prepared statements begin at 1 instead of 0? Everywhere else in Java anything with an index starts at 0. Is there a reason for the change here or is this just bad design? I was wondering the same thing especially since ResultSets are also 1-indexed. Historically databases have used 1-based indexing for bound parameters. This probably reflects the origins of relational databases in set theory and mathematics which index elements starting with one and use zero to represent a null or empty set. In shell scripts and regular expressions the zero index usually means something ""special"". For example in the case of shell scripts the zeroth ""argument"" is actually the command that was invoked. The choice for JDBC was deliberate but ultimately probably causes more confusion and difficulty than it solves. Personally I think 0-based indexing is a throwback from C pointer arithmetic which seems to have stuck... to the misfortune of us all. In mathematics it's usually easier to go with zero-indexing (in my experience (third class BSc)). I don't think zero-based indexing is a mathematical artifact. Every linear algebra book I have starts numbering rows/columns with 1. FORTRAN defaults from 1 if I recall correctly. I think zero-based indexing is a legacy from C and pointer arithmetic. The beauty of using 0-based indexing is: You can use the interval containing consecutive `N` elements as `[0 N)` and `[N 2N)` `[2N 3N)` and so on so forth. So all mainstream languages like C C++ Java JavaScript Python use the 0-based index convention originally used in C programming language. This principle also applies to generic index like `[a b)` where `a` is inclusive and `b` is exclusive.  I understand both JDBC and ODBC are based upon the X/Open Call Level Interface. So it's pre-Java history like 0-based month numbers.  Likely it's that JDBC was modeled on ODBC. I think both were modeled on an X/Open interface.  More human friendly maybe? Also Java's regular expression Matcher's group starts with 1 as the first matched group. This is standard with regular expressions as 0 is used to mean the entire match.  Personally I would chalk this up to bad design.  This was part of a plot by the original language designers to weed out the weak. In the original spec arrays were numbered from -1 and lists with 1 element returned length =0. Today only the java Calendar API remains from this diabolical plot. Argh I *hate* that about the Calendar object!"
1046,A,"JDBC prepareStatement doesn't work I'm trying to use the prepareStatement function. The code is below. After it executes it returns me a bunch of string 'vlicense' instead of the the values. When the code finishing the statement.setString() the statement becomes ""select 'vlicense' from Vehicle"". However it needs to be ""select vlicense from Vehicle"" without the quotation mark. Can anyone tell me what's the problem? Thanks a lot. statement = oConnection.prepareStatement(""select ? from Vehicle""); String tempString = ""vlicense""; statement.setString(1 tempString); resultSet = statement.executeQuery(); The ? can't be used to specify the fields just to do some filters in your query like: statement = conn.prepareStatement(""select field from Vehicle where name=?""); In your case your query is built as: select 'vlicense' from Vehicle which means: GET ME A STRING 'vlicense' FOR EACH RECORD OF 'Vehicle'. And you'll get n repeated strings depending on the number of records in your table  When you add a bind variable to a statement like this it is escaped so that actual SQL string in your example would go to the database as ""SELECT 'vlicense' FROM Vehicle' selecting a literal string instead of the column name you want. You need to concatenate that variable column name into your SQL statement before you prepare it: statement = oConnection.prepareStatement(""SELECT "" + vlicense + "" FROM Vehicle""); Bind variables are really for query parameters as opposed to dynamic queries.  You can't use parameter markers for column names table names data type names or basically anything that isn't data.  It has nothing to do with jdbc prepared-statements or mysql. It's just a wrong sql statement. If you type: ""Select 'justanexample' from Vehicle"" and the table contains 4 lines you will get 4 times 'justanexample' 'justanexample' 'justanexample' 'justanexample' as result. You did not specify your the table structure but I guess the statement should somehow look like this: ""select * from Vehicle where license = ?"" Kind Regards Chris"
1047,A,JDBC communication link failure after some time I am using JDBC with proxool connection pool to connect to mysql DB. I am selecting large number of rows from multiple threads and after some time i get an error saying communication link failure Last packet sent to the server was ...ago. I am closing connectionstatementresultSet in every thread. The fetching time increases gradually and the exception occurs after 5-10 minutes. I doubt it is a memory leak but cant find any clue. Please let me know the possible reasons. Thanks Kaka it may related on your Connection Timeout try to increase it. con.setConnectionTimeout(X); Thanks for the quick reply. But the connection is not getting timed out. The time taken by select statement to fetch almost the same amount of data is increasing gradually. It starts with 30 secs and after 5 mins it crosses 100 seconds so it has to be something related to memory leak or filled buffers etc. But not able to figure it out. Any such past experience? Thanks Kaka Found that its a memory leak due to Executor service futures.Nothing related to DB
1048,A,"What is the best way to 'ping' a database via JDBC? I'm trying to determine the best way to ping a database via JDBC. By 'best' I mean fast and low overhead. For example I've considered executing this: ""SELECT 1 FROM DUAL"" but I believe the DUAL table is Oracle-specific and I need something more generic. Note that Connection has an isClosed() method but the javadoc states that this cannot be used to test the validity of the connection. (I used `SELECT @@VERSION` on MS SQL Server but that isn't even SQL.) I'm not aware of a generic solution either. For IBM's UDB on iSeries (and perhaps other DB2 systems) it would be select 1 from SYSIBM.SYSDUMMY1;  Simply issuing the following query should be sufficient SELECT 1 that will not work with Oracle... ORA-00923: FROM keyword not found where expected  I may be out to lunch on this one but could you simply execute some non-sense query such as: SELECT * FROM donkey_giraffe_87 I don't know very much about JDBC's error handling but perhaps you could check to see if the database is at least telling you that the table does not exist. If JDBC's error codes are vendor-specific the Spring Framework has some utilities for mapping these codes to more meaningful exceptions. It could be expensive to try to query a non-exisiting table. Dictionary cache misses and error handling code.  With JDBC 4 you can use isValid(int) (JavaDoc) from the Connection Interface. This basically does the trial statement for you.  You could try to get the db name from the connection meta data and execute a matching sql staement. E.g. Connection con = null; Statement st = null; ResultSet rs = null; try { con = dataSource.getConnection(); String dbProductName = con.getMetaData().getDatabaseProductName(); Statement st = con.createStatement(); if ( ""PostgreSQL"".equalsIgnoreCase(dbProductName) ) { rs = st.executeQuery(""select version();""); } else if ( ""Oracle"".equalsIgnoreCase(dbProductName) ) { rs = st.executeQuery(""select 1 from dual""); } else { ... } } catch ( Exception ex ) { System.out.prinln(""DB not reachable""); } finally { // close statement connection etc. ... }  Yes that would be Oracle-only but there is no generic way to do this in JDBC. Most connection pool implementations have a configuration parameter where you can specify the SQL that will be used for ping thus pushing the responsiblity to figure out how to do it to the user. That seems like the best approach unless someone comes up with a little helper tool for this (of course it precludes using potentially even faster non-SQL-based methods like Oracle's internal ping function) SELECT 1 FROM DUAL works with MySQL also. See my answer JDBC 4 has a generic way (of cause not all drivers offer JDBC 4 yet).  Can you not simply execute SELECT 1 without a FROM clause against most databases? Not with Oracle: ORA-00923: FROM keyword not found where expected  MySQL has a nice mechanism documented in this SO answer. From the answer: ""/* ping */ SELECT 1"" This will actually cause the driver send a ping to the server and return a fake light-weight result set. Having said that @eckes answer is the best (using JDBC 4's Connection.isValid(int))."
1049,A,"Difference between library and native library Could anyone tell me the difference between library and native library in terms of java? I found the word ""native library"" in the following line: Type 1 - drivers that implement the JDBC API as a mapping to another data access API such as ODBC. Drivers of this type are generally dependent on a native library which limits their portability. The JDBC-ODBC Bridge driver is an example of a Type 1 driver. which you can found here ""Native Library"" generally means a non-Java library that's used by the system (so C/C++ etc). Think normal DLLs or libs. Java can load these native libraries through JNI. +1 for the reference to JNI Can java load .dll files through JNI? Absolutely. I've only done it with DLLs specifically designed to work with JNI so I'm not sure if you can load any DLL but it's generally not too difficult to create a JNI wrapper for a normal native library (annoying busywork but not generally hard).  In this context ""library"" is assumed to refer to a library written in Java (and probably distributed as a jar) whereas ""native library"" refers to a library written in something like C or OpenForth and compiled down to machine code.  A native library is a library that contains ""native"" code. That is code that has been compiled for a specific hardware architecture or operating system such as x86 or windows. Including such native library in your project may break the platform-independence of you application.  In the context of Java a library is one written in Java and available in the form of Java bytecode *.class files typically compressed into a JAR archive. By contrast a native library is one that has been compiled to machine code and is typically written in C or C++. Native libraries are *.so *.dylib *.dll *.a or *.lib files (depending on your platform) that link against the Java Native Interface (JNI) library and expose the functionality from C or C++ to Java through the Java Native Interace mechanism."
1050,A,"Getting Database connection in pure JPA setup We have a JPA application (using hibernate) and we need to pass a call to a legacy reporting tool that needs a JDBC database connection as a parameter. Is there a simple way to get access to the JDBC connection hibernate has setup? Hibernate uses a ConnectionProvider internally to obtain connections. From the hibernate javadoc: The ConnectionProvider interface is not intended to be exposed to the application. Instead it is used internally by Hibernate to obtain connections. The more elegant way of solving this would be to create a database connection pool yourself and hand connections to hibernate and your legacy tool from there. but it is exposed to the application... (: I think that might be the answer. Be careful with this approach if you are using the OpenEntityManagerInViewFilter or related classes. Requiring multiple connections to service a request can reach deadlock under the wrong conditions.  if you use EclipseLink: You should be in a JPA transaction to access the Connection entityManager.getTransaction().begin(); java.sql.Connection connection = entityManager.unwrap(java.sql.Connection.class); ... entityManager.getTransaction().commit();  Where you want to get that connection is unclear. One possibility would be to get it from the underlying Hibernate Session used by the EntityManager. With JPA 1.0 you'll have to do something like this: Session session = (Session)em.getDelegate(); Connection conn = session.connection(); Note that the getDelegate() is not portable the result of this method is implementation specific: the above code works in JBoss for GlassFish you'd have to adapt it - have a look at Be careful while using EntityManager.getDelegate(). In JPA 2.0 things are a bit better and you can do the following: Connection conn = em.unwrap(Session.class).connection(); If you are running inside a container you could also perform a lookup on the configured DataSource. When I do either of these I get a deprecation warning. I can live with it if a have to but its a bit annoying (: Its not like I want to have to do this its just pragmatically the simplest way to get things going. Yes `connection()` is deprecated in Hibernate 3.x they are changing the API (and I don't think you'll like the new API for your use case). But the change is planned for Hibernate 4.x this gives you some time. This doesn't seem to be viable using EclipseLink. you can't get the connection from the Session. It seems you may be able to unwrap the connection though - `Connection conn = em.unwrap(Connection.class)`. Doubt that's portable either though... this is no pure JPA...  I ran into this problem today and this was the trick I did which worked for me:  EntityManagerFactory emf = Persistence.createEntityManagerFactory(""DAOMANAGER""); EntityManagerem = emf.createEntityManager(); org.hibernate.Session session = ((EntityManagerImpl) em).getSession(); java.sql.Connection connectionObj = session.connection(); Though not the best way but does the job. `connection()` method is deprecated !  If you are using JAVA EE 5.0 the best way to do this is to use the @Resource annotation to inject the datasource in an attribute of a class (for instance an EJB) to hold the datasource resource (for instance an Oracle datasource) for the legacy reporting tool this way: @Resource(mappedName=""jdbc:/OracleDefaultDS"") DataSource datasource; Later you can obtain the connection and pass it to the legacy reporting tool in this way: Connection conn = dataSource.getConnection();  Since the code suggested by @Pascal is deprecated as mentioned by @Jacob I found this another way that works for me. import org.hibernate.classic.Session; import org.hibernate.connection.ConnectionProvider; import org.hibernate.engine.SessionFactoryImplementor; Session session = (Session) em.getDelegate(); SessionFactoryImplementor sfi = (SessionFactoryImplementor) session.getSessionFactory(); ConnectionProvider cp = sfi.getConnectionProvider(); Connection connection = cp.getConnection();  session.connection() is deprecated. Use Hibernate Work API instead:  session.doWork(new Work() { @Override public void execute(Connection arg0) throws SQLException { // TODO Auto-generated method stub } });"
1051,A,"JDBC Pagination I want to implement pagination using JDBC. The actual thing I want to know is ""How can i get first 50 and then next 50 records from database for page 1 and 2 respectively"" My Query is Select * from data [data table contains 20000 rows] For page #1 I get 50 records and for page #2 I want to get next 50 records. How can I implement it efficiently in JDBC? I have searched and found that rs.absolute(row) is the way to skip first page records but it takes some amount of time on large result sets and I don't want to bear this amount of time. Also I don't want to use rownum and limit + offset in query because these are not good to use in query I dont know why still I don't want to use it in query. Can anyone help me how to get limited ResultSet for pagination or is there any way JDBC is giving us? Oracle supports the standard ROW_NUMBER() window function since 8i so you can use that. You can do it as a parameterized query so you just need to set the start and end row numbers. E.g. SELECT * FROM ( SELECT * ROW_NUMBER() ORDER BY (sort key) AS rowNumber FROM <your table name> ) AS data WHERE rowNumber>=:start AND rowNumber<:end (If you're not using named parameters replace :start/:end with the positional parameter placeholder '?') See SELECT SQL Window Functions on wikipedia. The article also lists the other DBs that support the ROW_NUMBER() standard windowing function.  You should query only the data you actually need to display on the current page. Do not haul the entire dataset into Java's memory and then filter it there. It would only make things unnecessarily slower. If you actually have a hard time in implementing this properly and/or figuring the SQL query for the specific database then have a look at my answer here. Update: since you're using Oracle here's an Oracle-targeted extract from the aforementioned answer: In Oracle you need a subquery with rownum clause which should look like: private static final String SQL_SUBLIST = ""SELECT id username job place FROM"" + "" (SELECT id username job place FROM contact ORDER BY id)"" + "" WHERE ROWNUM BETWEEN %d AND %d""; public List<Contact> list(int firstrow int rowcount) { String sql = String.format(SQL_SUBLIST firstrow firstrow + rowcount); // Implement JDBC. return contacts; } what would be if after selection criteria resultset will large ? That's why i am analyzing extreme condition. and it is possible that resultset contain 100000 rows :) any ways thanks for your reply. Leave those 100.000 rows in the DB. Query **only** those you **need** to display per page. Google also doesn't query those zillion of rows at once to only show the first ten ones on the result page. how to query ? i dont want to my query vendor specific ? You have to. It's not part of ANSI SQL standard. You can also just write the queries for all the five major RDBMS vendors and add a configuration setting or a JDBC URL autodetector to detemine which DB vendor specific query you'd like to switch on. Another option is to use Hibernate/JPA which have already abstracted the DB vendor stuff away for you. Last option is to do the job in plain Java. But you really don't want to do that.  PreparedStatement pStmt = // ... however you make it pStmt.setFetchSize( /* desired number of records to get into memory */ ); Note setFetchSize(int) is only a hint - last time I was using it with MySQL for example it wasn't supported. Looking around briefly at the Oracle documentation it looks like their JDBC does support it. I wouldn't quote me on that but it's worth trying at least; and yes this answer is fragile but it might be enough less headache than implementing the robust solution. Essentially you can issue the request for everything and you only get the fetch size into memory at a time (providing you're not holding onto the previous results). So you'd set your fetch size to 50 make your connection/query display the first 50 results (causing the another fetch for the next bite of your query) and so on. also I think the LIMIT + OFFSET solutions are better in that the robustness is worth the mild extra wrangling but I wanted to point out an alternative. The problem with attempting to rely on setFetchSize(int) is that you are required to stay connected as you do the fetching. Pagination might take minutes (as users navigate back and fort). Holding a connection for that long is just not reasonable. Using (vendor-specific) SQL syntax for limiting/scoping the result is more scalable. Pull a connection from the pool and exec a paginating SQL statement (parameterized to *where* it is in the pagination) return the connection to the pool and display the results. If the user navigates away re-parameterize the SQL statement and repeat.  Are you using some kind of ORM Framework like hibernate or even Java Persistence API or just plain SQL? My Answer then: use LIMIT and OFFSET http://www.petefreitag.com/item/451.cfm Or go via ROWNUM Operator You need a wrapper arround your SQL then but basicaly it's  select * from (select bla.* ROWNUM rn from ( <your sql here> ) bla where rownum < 200) where rn >= 150' i am using standard JDBC API's with oracle 10g  I understand implicitly that you do not want the JDBC connection to have a single gigantic resultset which you keep open for a very long time and navigate when required. The usual approach is to add the SQL needed to only get a subset of the full request which unfortunately is different from database to database and will make your SQL statements vendor specific. If I recall correctly LIMIT is used with MySQL. Ask for the appropriate range for every request. I also believe that Hibernate contains functionality which allows you to do this for HQL but I am unfamiliar with it.  This is link to a hibernate solution for paginating results: http://stackoverflow.com/questions/489360/hql-row-identifier-for-pagination/840108#840108  Disclaimer: This blog post on SQL pagination & JDBC pagination is posted by me. Disregarding Hibernate pagination we can use SQL pagination / JDBC pagination SQL pagination There are two basic approaches: operating on piecemeal result set (New Query for Each Page) operating on full result set The way to do it is SQL specific For MySQL / many other SQLs it can be done with limit and offset Postgresql: http://microjet.ath.cx/WebWiki/ResultPaginationWithPostgresql.html In Oracle it use the same form as to handle ""Top-N query"" e.g. who are the 5 highest paid employee which is optimized select * from ( select a.* rownum rnum from ( YOUR_QUERY_GOES_HERE -- including the order by ) a where rownum <= MAX_ROWS ) where rnum >= MIN_ROWS Here is a very detailed explanation on ROW-NUM Similar SO Thread JDBC Pagination The question comes into mind is: when I execute the SQL how is the result being loaded? Immediately or on request? same as this SO thread First we need to understand some basics of JDBC as from Oracle Per javadoc: statement.execute() execute: Returns true if the first object that the query returns is a ResultSet object. Use this method if the query could return one or more ResultSet objects. Retrieve the ResultSet objects returned from the query by repeatedly calling Statement.getResutSet. We access data in Resultset via a cursor. Note this cursor is different from that of DB while it is a pointer initially positioned before the first row of data. The data is fetch on request. while when you do the execute() you are fetching for the first time. Then how many data is loaded? It is configurable. One can use the java API setFetchSize() method on ResultSet to control how many rows are fetched from DB a time by the driver how big the blocks it retrieves at once. For example assume the total result is 1000. If fetch size is 100 fetching the 1st row will load 100 rows from DB and 2nd to 100th row will be loaded from local memory.to query 101st row another 100 rows will be load into memory. From JavaDoc Gives the JDBC driver a hint as to the number of rows that should be fetched from the database when more rows are needed for ResultSet objects genrated by this Statement. If the value specified is zero then the hint is ignored. The default value is zero. Note the word ""hint"" - it can be override by driver specific implementation. This is also what the ""Limit Rows to 100"" feature in client like SQL developer based on. Completing the whole solution to scroll results one need to consider the ResultSet Types and ScrollableCursor in API One can find an example implementation from this post in oracle which is from the book Oracle Toplink Developer's Guide Example 112 JDBC Driver Fetch Size ReadAllQuery query = new ReadAllQuery(); query.setReferenceClass(Employee.class); query.setSelectionCriteria(new ExpressionBuilder.get(""id"").greaterThan(100)); // Set the JDBC fetch size query.setFetchSize(50); // Configure the query to return results as a ScrollableCursor query.useScrollableCursor(); // Execute the query ScrollableCursor cursor = (ScrollableCursor) session.executeQuery(query); // Iterate over the results while (cursor.hasNext()) { System.out.println(cursor.next().toString()); } cursor.close(); ..................... After all the questions boil to Which is the better way to do pagination? Note the SQL should be ORDER by to make sense in the SQL approach Otherwise it is possible to show some rows again in next page. Below is some points from Postgresql's documentation on JDBC Driver and other SO answers First off the original query would need to have an ORDER BY clause in order to make the paging solution work reasonably. Otherwise it would be perfectly valid for Oracle to return the same 500 rows for the first page the second page and the Nth page The major difference is for the JDBC way it is required to hold the connection during the fetching. This may not be suitable in stateless web application for example. For SQL way the syntax is SQL specific and may not be easy to maintain. For JDBC way The connection to the server must be using the V3 protocol. This is the default for (and is only supported by) server versions 7.4 and later. The Connection must not be in autocommit mode. The backend closes cursors at the end of transactions so in autocommit mode the backend will have closed the cursor before anything can be fetched from it. The Statement must be created with a ResultSet type of ResultSet.TYPE_FORWARD_ONLY. This is the default so no code will need to be rewritten to take advantage of this but it also means that you cannot scroll backwards or otherwise jump around in the ResultSet. The query given must be a single statement not multiple statements strung together with semicolons. Some Further reading This post is about performance tuning with optical fetch size  Input: Order Information example (A2 or D3) (A/D ascending/descending) + column Order Information example (A2 or D3) (A/D ascending/descending) + column Filter value start row start row maximum nuber of rows Result: Selected values Selected page Index of the row in this ordering Count off available data. (Save an second query) Advantage only Query for: sum of available columns with this filter only transfer the selected page from db correctly ordered without dynamic sql Disadvantage: Oracle Dependend select x.* from ( select c.pk_fieldc.numeric_a c.char_b c.char_c ROW_NUMBER( ) over(ORDER BY decode(?'A1'to_char(c.numeric_a'FM00000000')'A2'c.char_b'A3'c.char_c'A') asc  decode(?'D1'to_char(c.numeric_a'FM00000000')'D2'c.char_b'D3'c.char_c'A') desc c.pk_field asc ) AS ""idx"" COUNT (*) OVER (ORDER BY 1) ""cnt"" from myTable c where c.haystack=? ) x where x.""idx"" between greatest(nvl(?1)1) and nvl(?1)-1+?  If you are using MySQL or PostgreSQL limit and offset are your keywords. MSSqlServer and Oracle have similar features but I seems to be a bit more painful. For MySQL and PostgreSQL have a look here: http://www.petefreitag.com/item/451.cfm For Oracle have a look here: http://www.oracle-base.com/forums/viewtopic.php?f=2&t=8635 Thanks for your reply. Is there any way to achieve this functionality without using sql keywords ? @Zeeshan - not using the standard JDBC APIs. i am using standard JDBC API's with oracle 10g I have added another link to the answer where you find more information about pagination in oracle databases.  There is no efficient way of doing this by simply using JDBC. You have to formulate the limit to n rows and start from i-th item clauses directly to the SQL for it to be efficient. Depending on the database this might actually be quite easy (see MySQL's LIMIT -keyword) on other databases such as Oracle it can be a little trickier (involves subquery and using rownum pseudo column). See this JDBC Pagination Tutorial: http://java.avdiel.com/Tutorials/JDBCPaging.html"
1052,A,"RETURN_GENERATED_KEYS doesn't work using JDBC ODBC I'm trying to get insert ID while after inserting some data in my database. String sql = ""INSERT INTO ADI.DUMMY(dummy_data) VALUES('from database logger')""; PreparedStatement ps = con.prepareStatement(sql Statement.RETURN_GENERATED_KEYS); int extUptReturn = ps.executeUpdate(sql); But I got this exception: Java exception: ''java.lang.UnsupportedOperationException''; thrown from class name: ''sun.jdbc.odbc.JdbcOdbcConnection'' method name: ''prepareStatement'' file: ''JdbcOdbcConnection.java'' line: '1762' The ODBC bridge driver doesn't support it. Nothing to do against. Either replace the driver or live with it. I would just use a real JDBC driver instead of the poorly-developed feature-lacking bug-rich Sun ODBC bridge driver. Almost all self-respected server based RDBMS vendors provides a fullworthy JDBC driver for download at their homepage. Just Google ""[vendorname] jdbc driver download"" to find it. Here's an overview: MySQL JDBC driver PostgreSQL JDBC driver (note: older versions didn't support generated keys as well). Oracle JDBC driver (note: older versions didn't support generated keys as well). MSSQL JDBC driver (or performancewise better the jTDS JDBC driver) DB2 JDBC driver is hard to find in IBM's online forest but it's usually already included in the /java folder of the DB2 installation. Only for MS-Access --which actually isn't a server based RDBMS at all-- you'll be forced to stick to ODBC bridge driver unless you agree to pay for the HXTT JDBC driver. I tried to reverse my downvote based on your edit but it's too old to allow me to do so. Thanks for taking the time to edit. You said Access ""isn't a fullfledged RDBMS"". That's bashing Access period end of statement no ambiguities whatsoever and is only true if you have a WRONG definition of RDMBS. You lessened the quality of your answer by including it. You could delete that phrase and it wouldn't change the advice you give one iota. @David: I should indeed maybe have added ""server"" behind ""RDBMS"" to clarify the bit a bit more. Thank you for the nitpick and sorry that it wasn't clear to you at first glance. @David: There I put ""server based"" in. -1 for unnecessary Access bashing. The reason why there isn't a driver for it is not because it's not an RDBMS but because it's not a server database engine and shouldn't be used as a data store in the contexts in which JDBC is in use. Of course I'm one of thos who believes Java has no place on the client... Then you don't need RDBMS just ""Jet/ACE is not a database server"". And I'm the first to suggest that it's probably not appropriate for most Java-based apps for that reason. That is it's inappropriate not because it's not an RDBMS (for some definition of RDBMS) but that it's not a *server* database engine as you say. Why not edit and I'll back out my downvote. BTW it occurs to me that it may be possible to get to Jet/ACE data via the SQL Server driver after having set up your Jet/ACE database as a linked server... @David: I didn't bash Access I bashed the JDBC-ODBC bridge driver.  MAy be the JDBC implementation could not be supporting the sepcific opration. CHeck the JDBC driver used."
1053,A,Getting 'unhandled token type: unknown token: 0x53' error when connecting to MSSQL using JDBC I'm getting the following error when trying to connect to a Sql Server (2005) using JDBC: unhandled token type: unknown token: 0x53 Any ideas anyone? I would have liked a more descriptive error too!! Also I've done the 'telnet servername 1433' test and can confirm that machine can create a TCP connection. In the end the cause of this problem was that we had mirroring turned on. So to solve it without upgrading the driver we had to turn off database mirroring. But since this is a kludge really a better idea would be to use a better driver i've marked that other answer as the solution.  As an alternative to the MS dirver you could also try jTDS. I've had good experience with this driver on SQL Server 2000. The project page states it is also fit for SQL Server 2005. The drama with that is that this is part of an existing software package which only gives us the choice of MS' sqljdbc or oracle drivers.  Sounds like you're using an old driver for the pre-2005 SQL protocols. You need to use the new JDBC Driver for SQL 2005. Got it! However not sure where to place the DLLs so that they gain priority over the already-installed older versions?
1054,A,"Why do I get java.lang.AbstractMethodError when trying to load a blob in the db? I've got a problem with JDBC. I'have the following code: //blargeparam is a blob column. PreparedStatement pst =connection.prepareStatement(""update gcp_processparams_log set blargeparam= ? where idprocessparamslog=1""); pst.setBinaryStream(1inputStream); I get the following error: Exception in thread ""main"" java.lang.AbstractMethodError: oracle.jdbc.driver.T2CPreparedStatement.setBinaryStream(ILjava/io/InputStream;)V My connection string is ""jdbc:oracle:oci:@....."" The oracle version is 11g. From the error message it seems that something is missing but: when I read from the same blob column (with blob.getBytes) everything works. The dll's of the instant client are (correctly) in the library path. This is the manifest of the oracle jdbc jar in my class path: Manifest-Version: 1.0 Specification-Title: Oracle JDBC driver classes for use with JDK14 Sealed: true Created-By: 1.4.2_14 (Sun Microsystems Inc.) Implementation-Title: ojdbc14.jar Specification-Vendor: Oracle Corporation Specification-Version: Oracle JDBC Driver version - ""10.2.0.4.0"" Implementation-Version: Oracle JDBC Driver version - ""10.2.0.4.0"" Implementation-Vendor: Oracle Corporation Implementation-Time: Sat Feb 2 11:40:29 2008 I would suggest investigating your classpath very carefully. You might have two different versions of a jar file where one invokes methods in the other and the other method is abstract.  Here's what the JDK API says about AbstractMethodError: Thrown when an application tries to call an abstract method. Normally this error is caught by the compiler; this error can only occur at run time if the definition of some class has incompatibly changed since the currently executing method was last compiled. Bug in the oracle driver maybe? Yes the error terminates the JVM so it's very important to know what is causing it! As soon as I can (tomorrow) I will check if downloading the latest version of the client helps. The other thing that comes to my mind is that there is some dll conflict with a oracle client on my machine.  As described in the API of java.sql.PreparedStatement.setBinaryStream() it is available since 1.6 so it is a JDBC 4.0 API! You use a JDBC 3 Driver so this method is not available! You are right. And thank you for pointing this out I've checked this but setBinaryStream(int parameterIndex InputStream x int length) gives me the same error. No only setBinaryStream(int parameterIndex InputStream x int length) has been available in JDBC 3 not setBinaryStream(int parameterIndex InputStream x)! That's wrong setBinaryStream is available in 1.4.2 as well and also the JDBC 3.0 spec goes: ""The setBinaryStream and setObject methods may also be used to set a Blob object as a parameter in a PreparedStatement object. The setAsciiStream setCharacterStream and setObject methods are alternate means of setting a Clob object as a parameter.""  I got the same problem and resolved it. To resolve this problem you should upgrade commons-dbcp library to latest version (1.4). It will work with latest JDBC drivers. Cheers TM Thanks but I'm not using commons-dbcp.  It looks that even if the driver 10.2 is compatible with the JDBC3 it may not work with JRE6 as I've found here: http://www.oracle.com/technology/tech/java/sqlj_jdbc/htdocs/jdbc_faq.html#02_03 Which JDBC drivers support which versions of Javasoft's JDK? pre-8i OCI and THIN Drivers - JDK 1.0.x and JDK 1.1.x 8.1.5 OCI and THIN Drivers - JDK 1.0.x and JDK 1.1.x 8.1.6SDK THIN Driver - JDK 1.1.x and JDK 1.2.x (aka Java2) 8.1.6SDK OCI Driver - Only JDK 1.1.x 8.1.6 OCI and THIN Driver - JDK 1.1.x and JDK 1.2.x 8.1.7 OCI and THIN Driver - JDK 1.1.x and JDK 1.2.x 9.0.1 OCI and THIN Driver - JDK 1.1.x JDK 1.2.x and JDK 1.3.x 9.2.0 OCI and THIN Driver - JDK 1.1.x JDK 1.2.x JDK 1.3.x and JDK 1.4.x 10.1.0 OCI and THIN Driver - JDK 1.2.x JDK 1.3.x and JDK 1.4.x 10.2.0 OCI and THIN Driver - JDK 1.2.x JDK 1.3.x JDK 1.4.x and JDK 5.0.x 11.1.0 OCI and THIN Driver - JDK 1.5.x and JDK 1.6.x Oracle 10.2.0 supports: Full support for JDBC 3.0 Note that there is no real change in the support for the following in the database. Allthat has changed is that some methods that previously threw SQLException now do something more reasonable instead. result-set holdability returning multiple result-sets. So use the 11g drivers... you said you tried them and it worked so what's the problem? Yep the problem doesn't exist anymore. I just wanted to figure out what was happening.  InputStream in = new FileInputStream(file); cstmt.setBinaryStream(1 infile.length()); instead of this u need to use InputStream in = new FileInputStream(file); cstmt.setBinaryStream(1 in(int)file.length());  I do meet this problem. use ojdbc14.jar and jdk 1.6 InputStream in = new FileInputStream(file); cstmt.setBinaryStream(1 infile.length()); // got AbstractMethodError InputStream in = new FileInputStream(file); cstmt.setBinaryStream(1 in(int)file.length()); // no problem.  Just use ojdb6.jar and will fix all such issues. For maven based applications: Download and copy ojdbc6.jar to a directory in your local machine From the location where you have copied your jar install the ojdbc6.jar in your local .M2 Repo by issuing below command C:\SRK\Softwares\Libraries>mvn install:install-file -DgroupId=com.oracle -DartifactId=ojdbc6 -Dversion=11.2.0.3 -Dpackaging=jar -Dfile=ojdbc6.jar -DgeneratePom=true Add the below in your project pom.xml as ojdbc6.jar dependency <dependency> <groupId>com.oracle</groupId> <artifactId>ojdbc6</artifactId> <version>11.2.0.3</version> </dependency> PS: The issue might be due to uses of @Lob annotation in JPA for storing large objects specifically in oracle db columns. Upgrading to 11.2.0.3 (ojdbc6.jar) can resolve the issue.  Just put ojdbc6.jar in class path so that we can fix CallbaleStatement exception: oracle.jdbc.driver.T4CPreparedStatement.setBinaryStream(ILjava/io/InputStream;J)V) in Oracle. Fixed it for me too.  With JDBC that error usually occurs because your JDBC driver implements an older version of the JDBC API than the one included in your JRE. These older versions are fine so long as you don't try and use a method that appeared in the newer API. I'm not sure what version of JDBC setBinaryStream appeared in. It's been around for a while I think. Regardless your JDBC driver version (10.2.0.4.0) is quite old I recommend upgrading it to the version that was released with 11g (down here) and try again. I've updated the oracle client jdbc driver and dlls to the latest version and everything works fine. (note that I'm running on jre 6). I'm still puzzled however. It's simple enough... your driver did not support the version of the API you were using. The new one does. Face same problem but in my application. Its like what you have explained. When I deployed the new API and old implementation and this error appeared. When I got them in sync it was gone :D The link you provided seems broken. New JDBC download site is [here](http://www.oracle.com/technetwork/database/features/jdbc/index-091264.html)."
1055,A,Character problem at displaying the result of a query I am not good at jsp but I wondered what can cause such a problem when every other strings are displayed well: a JSP file queries information of people by their name at Contact (MS Exchange). the query returns the full info of the person; and the first last names are printed. Last names with apostrophes (Ex: O'reilly) aren't displayed at all. what can be possible solutions? Thanks in advance P.S. I know the way of asking is not suitable but I need information from people who had such a problem before. You need to execute the SQL query by PreparedStatement instead of Statement else your SQL query would break (and be prone to SQL injections as well). Imagine the following query: SELECT foo FROM tbl WHERE name = 'O'Reilly' That would yield a SQL syntax error. You should have seen this if you checked the server logs. You should have seen this on screen when you used a servlet instead of JSP to do the task. With PreparedStatement the query would be sanitized as follows: SELECT foo FROM tbl WHERE name = 'O\'Reilly' This way SQL do understand this query and can execute it without problems. On the other hand you need to HTML-escape the results as well otherwise it will be prone to XSS attacks. Imagine the following display: <input type='text' value='${name}'> if the ${name} is O'Reilly then the HTML would effectively end up as <input type='text' value='O'Reilly'> and you would only see the O. What would happen if the name is '><script>alert('xss')</script><input type='text' value='? To fix this use JSTL fn:escapeXml to display input: <input type='text' value='${fn:escapeXml(name)}'> (it's by the way more recommended to use doublequotes instead of singlequotes the above is just an example) That said you should technically also not be doing this inside a JSP file. Raw Java code belongs in a Java class not a JSP file. JSP is a view technology use it for the view part only.
1056,A,How to change default nls_date_format for oracle jdbc client I have defined the global nls_date_format on Oracle 10.2 XE as follows: alter system set nls_date_format='YYYY-MM-DD HH24:MI:SS' scope=spfile; When connecting on Windows the clients override it with session specific format so I need to run this line at the beginning of every session: alter session set nls_date_format='YYYY-MM-DD HH24:MI:SS'; However I have some custom code that I can't change (jdbc code using ojdbc14.jar) so I can't execute this line when receiving the connection. Is there a way to change the default value of nls_date_format for all jdbc connections? Perhaps adding something to the connection string or some environment variable that I can use? By the way sqlplus and sqldeveloper also override the server's format with their own but I found out how to change their defaults so the problem is only with jdbc connections. Set nls date format in an after logon trigger  Thanks that worked for me. The trigger that I inserted is this: CREATE OR REPLACE TRIGGER LOGINTRG AFTER LOGON ON DATABASE BEGIN EXECUTE IMMEDIATE 'ALTER SESSION SET NLS_DATE_FORMAT=''YYYY-MM-DD HH24:MI:SS'''; END LOGINTRG;  The logon trigger does not work. It runs but my nls_date_format is not changed. Oracle 11.2.0.3 Test logon wth SQL Develper using JDBC connection SQL Developer Default nls_date_format: YYYY-MON-DD HH24:MI:SS enhanced the trigger slightly to make sure it runs. [code] create table test (username varchar2(30)sid numbermytest varchar2(300)insert_date date); create or replace TRIGGER LOGINTRG AFTER LOGON ON DATABASE BEGIN insert into test select user sys_context('USERENV''SID') valuesysdate from v$parameter where name = 'nls_date_format'; EXECUTE IMMEDIATE 'ALTER SESSION SET NLS_DATE_FORMAT=''YYYY-MM-DD HH24:MI:SS'''; insert into test select user sys_context('USERENV''SID') valuesysdate from v$parameter where name = 'nls_date_format'; commit; END LOGINTRG; [/code] turned auditing on to dbextended then did 'audit all by myuser by access. to try to capture all sqls When i query test the nls_date_format is the same as in the alter session both times (this is the same as the database default). When I execute 'select * from v$parameter where name = 'nls_date_format' from with in SQL Developer my NLS_DATE_FORMAT is set to YYYY-MON-DD HH24:MI:SS. The Sql Developer default My audit command does NOT capture any alter session commands issued. Does not seem to capture logon stuff. However I don't capture SQL Developer issuing an alter session. When a date is inserted to a table with a varchar data type it is in YYYY-MON-DD HH24:MI:SS which is the SQL Developer default. Your logon trigger does NOT work. I can assure you that it is indeed working we are using it in a production system. It is designed for jdbc connection. If you are using sql developer it has its own way to set nls parameters and those might collide with your code. Also check the list of triggers in the db to see that you actually created it.
1057,A,"Defending against a 'WAITFOR DELAY' sql injection attack? The problem We need to defend against a 'WAITFOR DELAY' sql injection attack in our java application. Background [This is long. Skip to 'Solution?' section below if you're in a rush ] Our application mostly uses prepared statements and callable statements (stored procedures) in accessing the database. In a few places we dynamically build-and-execute queries for selection. In this paradigm we use a criteria object to build the query depending on the user-input criteria. For example if the user specified values for first_name and last_name the result querying always looks something like this: SELECT first_namelast_name FROM MEMBER WHERE first_name ='joe' AND last_name='frazier' (In this example the user would have specified ""joe"" and ""frazier"" as his/her input values. If the user had more or less critieria we would have longer or shorter queries. We have found that this approach is easier than using prepared statements and quicker/more performant than stored procedures). The attack A vulnerability audit reported an sql injection failure. The attacker injected the value 'frazier WAITFOR DELAY '00:00:20' for the 'last_name' parameter resulting in this sql:  SELECT first_namelast_name FROM MEMBER WHERE first_name ='joe' AND last_name='frazier' WAITFOR DELAY '00:00:20' The result: the query executes successfully but takes 20 seconds to execute. An attacker could tie up all your database connections in the db pool and effectively shut down your site. Some observations about this 'WAITFOR DELAY' attack I had thought that because we used Statement executeQuery(String) we would be safe from sql injection. executeQuery(String) will not execute DML or DDL (deletes or drops). And executeQuery(String) chokes on semi-colons thus the 'Bobby Tables' paradigm will fail (i.e. user enters 'frazier; DROP TABLE member' for a parameter. See. http://xkcd.com/327/) The 'WAITFOR' attack differs in one important respect: WAITFOR modifies the existing 'SELECT' command and is not a separate command. The attack only works on the 'last parameter' in the resulting query. i.e. 'WAITFOR' must occur at the very end of the sql statement Solution Cheap Hack or Both? The most obvious solution entails simply tacking ""AND 1=1"" onto the where clause. The resulting sql fails immediately and foils the attacker:  SELECT first_namelast_name FROM MEMBER WHERE first_name ='joe' AND last_name='frazier' WAITFOR DELAY '00:00:20' AND 1=1 The Questions Is this a viable solution for the WAITFOR attack? Does it defend against other similar vulnerabilities? I think the best option would entail using prepared statements. More work but less vulnerable. unfortunately the only person it foils is yourself. If you tack on instead of the delay ""OR 1=1"" you might end up allowing anyone and everyone to log in. Don't try to fool yourself into thinking you can manage to outsmart all those that wants to try to break your site. You're one person if your site is popular they're many. If it's not then it probably doesn't matter what if anything you do. rule #1: don't synthesize and execute code from untrusted sources... How about follow xkcd and sanitize the input. You could check for reserved words in general and for WAITFOR in particular. Please no. Don't try to sanitize with some flaky blacklisting system. If you have some mysterious but intense aversion to prepared statements then *escape* the strings. I didn't -1 you but it might seem that the first sentence of your answer could warrant a +1 (since it mentions xkcd) but then you get to the second sentence. And that's where it all falls apart. Banning reserved keywords is a strategy only the TSA can afford to spend billions on and get away with. Ha I was blinded by the authority of xkcd :-) Using prepared statements instead is obviously the way to go.  The correct way to handle SQL injection is to use parameterized queries. Everything else is just pissing in the wind. It might work one time even twice but eventually you'll get hit by that warm feeling that says ""you screwed up badly!"" Whatever you do except parameterized queries is going to be sub-optimal and it will be up to you to ensure your solution doesn't have other holes that you need to patch. Parameterized queries on the other hand works out of the box and prevents all of these attacks. Good point I guess I should have been more specific - a prepared statement won't do you any good if you pass it one big concatenated string instead of one with parameter placeholders! Which is why I said ""parameterized query"" not ""prepared query"". ""The correct way to handle SQL injection is to use parameterized queries. Everything else is just pissing in the wind"" Thank you for telling the truth! This is the answer to almost any security programming problem actually.  Everyone else has nailed this (parameterize!) but just to touch on a couple of points here: Is this a viable solution for the WAITFOR attack? Does it defend against other similar vulnerabilities? No it doesn't. The WAITFOR trick is most likely just being used for 'sniffing' for the vulnerability; once they've found the vulnerable page there's a lot more they can do without DDL or (the non-SELECT parts of) DML. For example think about if they passed the following as last_name ' UNION ALL SELECT username password FROM adminusers WHERE 'A'='A Even after you add the AND 1 = 1 you're still hosed. In most databases there's a lot of malicious things you can do with just SELECT access...  I think you suggested the solution yourself: Parameterized Queries. How did you find that your dynamically built query is quicker than using a stored procedure? In general it is often the opposite. Stored procedures won't protect you against SQL injection if you smash strings together *in the stored procedure itself* and then exec() the result. I have seen this done. The important thing to emphasise is **parametrised queries**. Good point. Thanks. Fixed the emphasis. Ah yes. In general true but in these specific cases we've found otherwise. Here's the situation: you have a DAO method which has a specification/criteria object with 30 fields on it. You could have one stored procedure with 30 parameters on it with sql that looks like this: SELECT last_name first_name FROM member WHERE (@pLastName IS NULL OR @pLastName=last_name) AND (@pFirstName IS NULL OR @pFirstName=first_name) AND (@pSerialNbr IS NULL OR @pSerialNbr=serial_nbr) AND (@pZodiacSign IS NULL OR @pZodiacSign=zodiac_sign) AND (@pPartyRank IS NULL OR @pPartyRank=party_rank) from my experience the SQL optimizers/engines perform very poorly on such procedures; they re-use a very generic access plan (usually full-table scan) rather than recognize on-the-fly to use a particular index . Additionally some of the values are in fact lists (i.e. 'WHERE rank in (123)' ). I have in places passed in comma-separated lists to a stored procedure parsed and populated a temporary table and joined against the temporary table but this in practice performs *MUCH WORSE* than a simple sql with an in clause. finally to summarize from my experience : simple sql performs best. Super-fancy sql makes for super-slow. Optimizers and access-plan-generators aren't that smart. (also we support a few different db's so have limits how many hints we can provide) If one must therefor use dynamically generated SQL sanitize the input. By which I mean escaping strings and validating numeric types etc. There is plenty of pre-existing code to do that for you.  SQL injection is SQL injection - there's nothing special about a WAITFOR DELAY. There is absolutely no excuse for not using prepared statements for such a simple query in this day and age. (Edit: Okay not ""absolutely"" - but there's almost never an excuse) No I think it's 'absolutely'. There are no exceptions. Anything you think is an exception is actually something you need to solve another way. Not really. Just parameterize the individual IN tokens (`WHERE status IN (? ? ?)`). one wrinkle: the list size can vary. dynamic list sizes present a problem AFAIK the preparedStatement sql can have a long list of '?' (i.e. upper bound of the list size); you can set the first 3 and use setNull to set the last upperbound-3. i.e. : WHERE status IN (??????????) This is a fully-solved problem: http://www.javaranch.com/journal/200510/Journal200510.jsp#a2 Any of those approaches are better than raw strings. looking over the code several of these 'finder' DAO methods generate 'IN clauses' (i.e. ""WHERE STATUS in (123)""). No excuses but these are more difficult with prepared statements.  To answer all your questions: Is this a viable solution for the WAITFOR attack? No. Just add -- to the attack string and it will ignore your fix. Does it defend against other similar vulnerabilities? No. See above. I think the best option would entail using prepared statements. More work but less vulnerable. Yes. You don't fix SQL injection yourself. You use what's already existing and you use it right that is by parametrizing any dynamic part of your query. Another lesser solution is to escape any string that is going to get inserted in your query however you will forget one one day and you only need one to get attacked."
1058,A,"Best way to manage DB connections without JNDI I have a website in which currently I am getting 1000 page views. I am expecting it will go around 30k per day in future. Now the problem for me to manage the DB connections. At present I am just connecting to DB directly from java program. I know it is worst design in the world. But for time being I have written like that. I have plan to manage connection pooling using JNDI. But the problem is my hosting provider is not supporting JNDI. Can anyone suggest me how to manage DB connections without jndi? Connection pooling does not per se require the connections to be obtained by JNDI. You can also just setup and use a connection pool independently from JNDI. Let's assume that you'd like to use C3P0 which is one of the better connection pools then you can find ""raw"" JNDI-less setup details in this tutorial. Here's an extract of the tutorial: ComboPooledDataSource cpds = new ComboPooledDataSource(); cpds.setDriverClass( ""org.postgresql.Driver"" ); //loads the jdbc driver cpds.setJdbcUrl( ""jdbc:postgresql://localhost/testdb"" ); cpds.setUser(""swaldman""); cpds.setPassword(""test-password""); Create the datasource once during application's startup and store it somewhere in the context. The connection can then be acquired and used as follows: Connection connection = null; // ... try { connection = cpds.getConnection(); // ... } finally { // ... if (connection != null) try { connection.close(); } catch (SQLException ignore) {} } Yes closing in finally is still mandatory else the connection pool won't be able to take the connection back in pool for future reuse and it'll run out of connections."
1059,A,"ORA-01000: maximum open cursors exceededwhen using Spring SimpleJDBCCall We are using Spring SimpleJdbcCall to call stored procedures in Oracle that return cursors. It looks like SimpleJdbcCall isn't closing the cursors and after a while the max open cursors is exceeded. ORA-01000: maximum open cursors exceeded ; nested exception is java.sql.SQLException: ORA-01000: maximum open cursors exceeded spring There are a few other people on forums who've experienced this but seemingly no answers. It looks like me as a bug in the spring/oracle support. This bug is critical and could impact our future use of Spring JDBC. Has anybody come across a fix - either tracking the problem to the Spring code or found a workaround that avoids the problem? We are using Spring 2.5.6. Here is the new version of the code using SimpleJdbcCall which appears to not be correctly closing the result set that the proc returns via a cursor: ... SimpleJdbcCall call = new SimpleJdbcCall(dataSource); Map params = new HashMap(); params.put(""remote_user"" session.getAttribute(""cas_username"") ); Map result = call .withSchemaName(""urs"") .withCatalogName(""ursWeb"") .withProcedureName(""get_roles"") .returningResultSet(""rolesCur"" new au.edu.une.common.util.ParameterizedMapRowMapper() ) .execute(params); List roles = (List)result.get(""rolesCur"") The older version of the code which doesn't use Spring JDBC doesn't have this problem: oracleConnection = dataSource.getConnection(); callable = oracleConnection.prepareCall( ""{ call urs.ursweb.get_roles(? ?) }"" ); callable.setString(1 (String)session.getAttribute(""cas_username"")); callable.registerOutParameter (2 oracle.jdbc.OracleTypes.CURSOR); callable.execute(); ResultSet rset = (ResultSet)callable.getObject(2); ... do stuff with the result set if (rset != null) rset.close(); // Explicitly close the resultset if (callable != null) callable.close(); //Close the callable if (oracleConnection != null) oracleConnection.close(); //Close the connection It would appear that Spring JDBC is NOT calling rset.close(). If I comment out that line in the old code then after load testing we get the same database exception. +1 with skaffman. If you can't find out the problem try to build a rock solid test case before to report a bug at http://jira.springframework.org/ Please post some code showing how you're using SimpleJdbcCall. It's extremely unlikely that this is a bug in Spring and more likely the way you're using it especially considering the non-standard way that Oracle handle resultsets. I can promise you that it's not Spring. I worked on a Spring 1.x app that went live in 2005 and hasn't leaked a connection since. (WebLogic 9. JDK 5). You aren't closing your resources properly. Are you using a connection pool? Which app server are you deploying to? Which version of Spring? Oracle? Java? Details please.  After much testing we have fixed this problem. It is a combination of how we were using the spring framework and the oracle client and the oracle DB. We were creating new SimpleJDBCCalls which were using the oracle JDBC client's metadata calls which were returned as cursors which were not being closed and cleaned up. I consider this a bug in the Spring JDBC framework in how it calls metadata but then does not close the cursor. Spring should copy the meta data out of the cursor and close it properly. I haven't bothered opening an jira issue with spring because if you use best practice the bug isn't exhibited. Tweaking OPEN_CURSORS or any of the other parameters is the wrong way to fix this problem and just delays it from appearing. We worked around it/fixed it by moving the SimpleJDBCCall into a singleton DAO so there is only one cursor open for each oracle proc that we call. These cursors are open for the lifetime of the app - which I consider a bug. As long as OPEN_CURSORS is larger than the number of SimpleJDBCCall objects then there won't be hassles. I hope you reported this if you consider it as a bug :)  The solution is not in Spring but in Oracle: you need to set the OPEN_CURSORS initialization parameter to some value higher than the default 50. Oracle -- at least as-of 8i perhaps it's changed -- would reparse JDBC PreparedStatement objects unless you left them open. This was expensive and most people end up maintaining a fixed pool of open statements that are resubmitted. (taking a quick look at the 10i docs they explicitly note that the OCI driver will cache PreparedStatements so I'm assuming that the native driver still recreates them each time) This is a resource leak the solution to a resource leak is to stop leaking not add more water. @Andrew - thank you for commenting along with your downvote. However having worked with Oracle since the early 1990s I stand by my answer. Out of the box its configuration is not suited for a complex application. Moreover the OP is using Spring which is very good about cleaning up after itself. It's still possible that the OP has written a resource leak somewhere but far less likely than if he/she were doing explicit connection management. Rereading all posts I see that the OP posted the accepted answer two months after my response indicating that it was in fact a resource leak with Spring. However given that the supposed leak was Spring attempting to cache metadata I will refer to my second paragraph and still stand by this answer.  Oracle OPEN_CURSORS is the key alright. We have a small 24x7 app running against Oracle XE with only a few apparently open cursors. We had intermittent max open cursors errors until we set the OPEN_CURSORS initialization value to > 300 This is a resource leak the solution to a resource leak is to stop leaking not add more water.  Well I've got this problem when I was reading BLOBs. Main cause was that I was also updating table and the Statement containing update clause was not closed automatically. Nasty cursorleak eats all free cursors. After explicit call of statement.close() the error disappears. Moral - always close everything don't rely on automatic close after disposing Statement.  Just be careful setting OPEN_CURSORS to higher and higher values as there are overheads and it could just be band-aiding over an actual problem/error in your code. I don't have experience with the Spring side of this but worked on an app where we had many issues with ORA-01000 errors and constantly adjusting OPEN_CURSORS just made the problem go away for a little while ..."
1060,A,"How do I make a Java ResultSet available in my jsp? I'd like to swap out an sql:query for some Java code that builds a complex query with several parameters. The current sql is a simple select.  <sql:query var=""result"" dataSource=""${dSource}"" sql=""select * from TABLE ""> </sql:query> How do I take my Java ResultSet (ie. rs = stmt.executeQuery(sql);) and make the results available in my JSP so I can do this textbook JSP? To be more clear I want to remove the above query and replace it with Java.  <% ResultSet rs = stmt.executeQuery(sql); // Messy code will be in some Controller %>  <c:forEach var=""row"" items=""${result.rows}""> <c:out value=""${row.name}""/> </c:forEach> Do I set the session/page variable in the Java section or is there some EL trick that I can use to access the variable? How sad that all the answers are going in every direction but just answering the question. I asked this same thing and answered it when I was doing J2EE but I don't remember. There may be no way to get the tag to use your rs variable but I think there is a way. You set up a session/request attribute from the Java code. However I would suggest not using a ResultSet as it has some lifecycle issues (i.e. needs to be closed). I would suggest fetching the ResultSet object in the Java code iterating over it building say a List closing the ResultSet and pass the List to the JSP. If you are using Spring the JdbcTemplates provide methods that take an SQL string and parameters and return a List> with the results of the query which might come in very handy for this. There's nothing wrong with using ResultSet in a JSP so long as the user declares it and its PreparedStatement outside the try / catch / finally and makes sure to close and null out everything (including the Connection) in the finally.  If you're using a web framework like spring mvn or struts you have a controller class that is executed before the actual jsp. This can have a method ResultSet getResult() This method will be available as ${result} within your jsp. If you're not using any of these frameworks you can still use jsp usebean and bind a javaclass to a variable (check usebean documentation). If you usebean to a variable of myBean you access it with ${myBean.result} Lastly you can also bind the result to the request parameters ""somewhere else"". In this case you address it as ${param.result}  You don't. First placing SQL into JSP even via tags is indicative of a horrible design choice. The JSP page is the ""view"" in the Model View Controller pattern. Its job is to display your model not actually do anything with it other than display it. In your controller class execute your SQL and retrieve actual Java objects that can be displayed via the JSP. Then in your JSP display them. Leave your SQL to your controller and let the JSP focus on simply displaying the data. Not only do you gain clean separation of concerns but your JSP becomes a lot simpler as a result and it is much easier to refactor Java code than JSP code later on if it needs to be done (it is a lot simpler to test Java code as well). I didn't ask for a lesson in MVC I asked how to solve a specific problem that I was wrestling with in JSP code. We should probably all dump Java/JSP for Squeak and Seaside but hey sometimes we're just trying to get a job done.  Model (Row): public class Row { private String name; // Add/generate constructor(s) getters and setters. } DAO: public List<Row> list() throws SQLException { Connection connection = null; Statement statement = null; ResultSet resultSet = null; List<Row> rows = new ArrayList<Row>(); try { connection = database.getConnection(); statement = connection.createStatement(); resultSet = statement.executeQuery(SQL_LIST); while (resultSet.next()) { Row row = new Row(); row.setName(resultSet.getString(""name"")); // ... rows.add(row); } } finally { if (resultSet != null) try { resultSet.close(); } catch (SQLException logOrIgnore) {} if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } return rows; } Controller (servlet): protected void doGet(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { try { List<Row> rows = someDAO.list(); request.setAttribute(""rows"" rows); } catch (SQLException e) { request.setAttribute(""error"" ""Retrieving rows failed.""); e.printStackTrace(); } request.getRequestDispatcher(""page.jsp"").forward(request response); } View (page.jsp): <c:forEach items=""${rows}"" var=""row""> <c:out value=""${row.name}"" /> ... </c:forEach> <c:if test=""${not empty error}"">Error: ${error}</c:if>"
1061,A,"Question about SQL catalogs - What exactly are they? Something that has been puzzling me for a bit now and an hour or two of googlin' hasn't really revealed any useful answers on the subject so I figured I'd just write the question. When I create a database in SQL using 'CREATE DATABASE DBNAME' am I implicitly creating a catalog in that database? Is it proper to refer to that 'DBNAME' as a catalog? Or is it something completely unrelated? When I use the MySQL JDBC driver to get the list of tables in a database using the getMetaData() function the ""TABLE_CAT"" column (which I would assume means 'catalog') is always set to the name of the database I've choosen. Coincidence? Or am I just completely wrong on all of this? catalog is the JDBC term for what many people (and some RDBMs) call databases. i.e. a collection of tables/views/etc. within a database system."
1062,A,"Is java.sql.Connection thread safe? To rephrase the question: should I avoid sharing instances of classes which implement java.sql.Connection between different threads? java.sql.Connection is an interface. So it all depends on the driver's implementation but in general you should avoid sharing the same connection between different threads and use connection pools. Also it is also advised to have number of connections in the pool higher than number of worker threads. An interface is a contract and a contract *could* specify that all implementations have to be thread safe. It's just that this is not the case for java.sql.Connection. Yes interface is a contract and you can put some additional requirements in the documentation that describes the contract but as you said java.sql.Connection documentation does not define thread-safety requirement and even if it defined that still thread-safety is not something that can be strictly described and enforced. Implementation may still violate the contract (sometimes by mistake sometimes by design e.g. IdentityHashMap). @AndreyAdamovich : ""advised to have number of connections in the pool higher than number of worker threads"" why? I mean if I have many connections in connection pool I will end up with problem of Thrashing..  If the JDBC driver is spec-compliant then technically yes the object is thread-safe but you should avoid sharing connections between threads since the activity on the connection will mean that only one thread will be able to do anything at a time. You should use a connection pool (like Apache Commons DBCP) to ensure that each thread gets its own connection. On that Sun JDBC guide language you quote you should have quoted the final bolded sentence. I read it as them admitting that multithreading is mostly a failure and one thread per connection is the current expectation. ""In practice we expect that most of the JDBC objects will only be accessed in a single threaded way. However some multi-thread support is necessary and our attempts in previous drafts to specify some classes as MT safe and some as MT unsafe appeared to be adding more confusion than light."" For example Postgres's implementation doesn't synchronize access to the autoCommit flag so it's not thread-safe. A voice at the back of my head is telling me that the JDBC spec requires all java.sql objects to be thread-safe but I can't find a reference to that. Your voice may refer to http://java.sun.com/j2se/1.3/docs/guide/jdbc/spec/jdbc-spec.frame9.html where it says ""We require that all operations on all the java.sql objects be multi-thread safe and able to cope correctly with having several threads simultaneously calling the same object."" @janko: that's the chap thanks glad to know I'm not going nuts"
1063,A,"Efficiently fill resultset in object model I have an object model whose structure is Dashboard   List of panels     List of containers       List of widgets If i get whole dashboard with panels + containers + widgets from Database then multiple I/O requires I want to get it in one I/O .For this i prepared a query which gives me this resultset. DASHBOARDID   PANELID  CONTAINERID  WIDGETID 13                          11                    5              2 13                          11                    5              3 13                          11                    6              4 13                          11                    6              5 13                          12                    7              6 13                          12                    7              7 13                          12                    8              8 13                          12                    8              9 Using list datastructure this model is able to be filled but it takes time i want to efficiently fill this resultset in above object model. is there nay way ? It is much easier to format your code using the `101010` editor button or indenting it by hand with 4 spaces. If you are not strictly limited to using JDBC an ORM solution would resolve your issue. E.g. in Hibernate you can easily configure your entity mapping to use lazy or eager loading. In the latter case when you load a Dashboard object the persistence framework fetches all the contained panels containers and widgets with 1 to 4 queries total (depending on configuration - note that a single join query for 4 tables might not be optimal if there are many rows) and initialize the whole object graph for you automatically.  The strict ordering and nesting in the data makes this fairly straightforward. The solution is a loop that look for changes in ID - when the ID changes a new instance is created. It iteration of the loop maintains the current dashboard panel component widget. For example Dashboard dashboard Panel panel; Container container; Widget widget; List<Dashboard> dashboards; ResultSet rs = ...; while (rs.next()) { int dashboardID = rs.getInt(1); int panelID = rs.getInt(2); int dashboardID = rs.getInt(3); int dashboardID = rs.getInt(4); if (dashboard==null || dashboardID!=dashboard.id()) { dashboard = new Dashboard(dashboardID); dashboards.add(dashboard); } if (panel==null || panelID!=panel.id()) { panel = new Panel(panelID); dashboard.add(panel); } if (container!=null || containerID!=container.id()) { container = new Container(containerID); panel.add(container); } // wimilarly for widget } // all dashboards in ""dashboards"" initialized with hierarchy"
1064,A,"Getting a JDBC connection by JNDI in Spring JDBC This page on Spring JDBC says The DataSourceUtils class … provides static methods to obtain connections from JNDI However the API doc for DataSourceUtils does not include the said static methods as far as I can see. What am I missing? Hmm... Somehow the Javadoc of DataSourceUtils is more ""accurate"" (I mean the doc is not wrong but technically you obtain a connection from a DataSource - that can be obtained via JNDI): Helper class that provides static methods for obtaining JDBC Connections from a DataSource. And the following methods should be what you're looking for: DataSourceUtils.getConnection(DataSource) DataSourceUtils.getGetConnection(DataSource) Basic example (from the MySQL documentation): // Create a new application context. this processes the Spring config ApplicationContext ctx = new ClassPathXmlApplicationContext(""ex1appContext.xml""); // Retrieve the data source from the application context DataSource ds = (DataSource) ctx.getBean(""dataSource""); // Open a database connection using Spring's DataSourceUtils Connection c = DataSourceUtils.getConnection(ds); try { // retrieve a list of three random cities PreparedStatement ps = c.prepareStatement( ""select City.Name as 'City' Country.Name as 'Country' "" + ""from City inner join Country on City.CountryCode = Country.Code "" + ""order by rand() limit 3""); ResultSet rs = ps.executeQuery(); while(rs.next()) { String city = rs.getString(""City""); String country = rs.getString(""Country""); System.out.printf(""The city %s is in %s%n"" city country); } } catch (SQLException ex) { // something has failed and we print a stack trace to analyse the error ex.printStackTrace(); // ignore failure closing connection try { c.close(); } catch (SQLException e) { } } finally { // properly release our connection DataSourceUtils.releaseConnection(c ds); }  As I understand what would be really useful to you is JndiObjectFactoryBean. This Spring factory bean returns object published in JNDI. You would configure it like this and then you would get the Connection using DataSourceUtils on the injected DataSource: <bean name=""myDataSourceInJndi"" class=""org.springframework.jndi.JndiObjectFactoryBean""> <property name=""jndiName""> <value>java:comp/env/jdbc/MyDataSource</value> </property> </bean> <bean name=""myBean"" class=""MyClass""> ... <property name=""dataSource"" ref=""myDataSourceInJndi""> ... </bean>"
1065,A,"Db2 connection problem with java I am having problem with DB2. I just installed the db2 as a db2admin and with a password. When i try to connect to database it is success full and while running any simple select query it give me following error:- DB2 SQL Error: SQLCODE=-204 SQLSTATE=42704 SQLERRMC=DB2ADMIN.LOGIN DRIVER=3.57.82 I have a database named onp and a table in it called 'login' in which there is one table called 'login' with two fields username and password. Query that i am running Select * from login; gives me error DB2 SQL Error: SQLCODE=-204 SQLSTATE=42704 SQLERRMC=DB2ADMIN.LOGIN DRIVER=3.57.82 Select * from system.login; gives me error:- (//system is schema name) DB2 SQL Error: SQLCODE=-551 SQLSTATE=42501 SQLERRMC=DB2ADMIN;SELECT;SYSTEM.LOGIN DRIVER=3.57.82 I have tried all the resources on the net and exhausted completely. Please help me SQL CODE 551 occurred because the connecting user does not have privileges to perform operations. Go to Control Center - Go to User Group and Object and select DB2ADMIN(assume this user is the one use to connect to DB2) Check all the check box as the following Grant Schema access to the user Grant Tables access to the user  You can also resolve the issue as: Just give the proper authority to the user by which you are connection to DB2.  I had the same problem and i resolved it by adding Schema in my entity : @Entity @Table(name=""MyTable"" schema=""MySchemaName"") public class MyClass implements Serializable { ... }  I don't know a lot about DB2 but looking up the error codes... The first error is because you didn't specify a schema so it couldn't find the login table. SQLCODE -204 Object not defined to DB2 DB2 apparently requires you to specify the schema name or it looks in the schema with the same name as your login user. You must use SET SCHEMA or fully qualify the table name. The second error is because you don't have the privileges to perform that select: SQLCODE -551 Error: DOES NOT HAVE THE PRIVILEGE TO PERFORM OPERATION ON OBJECT I'm not sure why the db2admin user wouldn't be able to select from this table... Resources: List of DB2 SQLCODEs Thanks I got it solved with your help. -204 would also indicate that the specified schema in a fully qualified table name is incorrect or doesn't exist. If you have a commandline the following helps `db2 ? SQLnnnn` where nnnn is the 4 digit sql code (extend with 0 on the left if needed). This will print an explanation of the error."
1066,A,"What transaction manager should I use for JBDC template When using JPA ? I am using standard JPA transaction manager for my JPA transactions. However now I want to add some JDBC entities which will share the same 'datasource'. How can I make the JDBC operations transactional with spring transaction? Do I need to switch to JTA transaction managers? Is it possible to use both JPA & JDBC transactional service with same datasource? Even better is it possible to mix these two transactions? UPDATE: @Espen : I have a dao extended from SimpleJdbcDaoSupport which uses getSimpleJDBCTemplate.update to insert a database row. When a RuntimeException is thrown from the service code the transaction never rolls back when using JPATransactionManager. It does rollback when using DatasourceTransactionManager. I tried to debug the JPATransactionManager and seems that it never performs rollback on underlying JDBCConnection(I guess due to the fact that the datasource is not necessarily has to be JDBC for JPA). My configuration setup are exactly like you explained here. Here are my test codes: <context:property-placeholder location=""classpath:*.properties""/> <!-- JPA EntityManagerFactory --> <bean id=""entityManagerFactory"" class=""org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean""> <property name=""dataSource"" ref=""dataSource""/> <property name=""persistenceXmlLocation"" value=""classpath:/persistence-test.xml"" /> <property name=""persistenceProvider""> <bean class=""org.hibernate.ejb.HibernatePersistence"" /> </property> </bean> <bean id=""transactionManager"" class=""org.springframework.orm.jpa.JpaTransactionManager""> <property name=""entityManagerFactory"" ref=""entityManagerFactory""/> </bean> <!-- <bean id=""transactionManager"" class=""org.springframework.jdbc.datasource.DataSourceTransactionManager""> <property name=""dataSource"" ref=""dataSource""></property> </bean> --> <!-- Database connection pool --> <bean id=""dataSource"" class=""org.apache.commons.dbcp.BasicDataSource"" destroy-method=""close""> <property name=""driverClassName"" value=""${database.driverClassName}"" /> <property name=""url"" value=""${database.url}"" /> <property name=""username"" value=""${database.username}"" /> <property name=""password"" value=""${database.password}"" /> <property name=""testOnBorrow"" value=""${database.testOnBorrow}"" /> <property name=""validationQuery"" value=""${database.validationQuery}"" /> <property name=""minIdle"" value=""${database.minIdle}"" /> <property name=""maxIdle"" value=""${database.maxIdle}"" /> <property name=""maxActive"" value=""${database.maxActive}"" /> </bean> <!-- Initialize the database --> <!--<bean id=""databaseInitializer"" class=""com.vantage.userGroupManagement.logic.StoreDatabaseLoader""> <property name=""dataSource"" ref=""storeDataSource""/> </bean>--> <!-- ANNOTATION SUPPORT --> <!-- Enable the configuration of transactional behavior based on annotations --> <tx:annotation-driven transaction-manager=""transactionManager""/> <!-- JPA annotations bean post processor --> <bean class=""org.springframework.orm.jpa.support.PersistenceAnnotationBeanPostProcessor""/> <!-- Exception translation bean post processor (based on Repository annotation) --> <bean class=""org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor""/> <!-- throws exception if a required property has not been set --> <bean class=""org.springframework.beans.factory.annotation.RequiredAnnotationBeanPostProcessor""/> <bean id=""userService"" class=""com.rfc.example.service.UserServiceImpl""> <property name=""userDao"" ref=""userDao""></property> <property name=""contactDao"" ref=""contactDao""></property> <property name=""callRecordingScheduledProgramTriggerDAO"" ref=""com.rfc.example.dao.CallRecordingScheduledProgramTriggerDAO""></property> </bean> <bean id=""userDao"" class=""com.rfc.example.dao.UserDaoJPAImpl"" /> <bean id=""contactDao"" class=""com.rfc.example.dao.ContactDaoJPAImpl""></bean> <bean id=""com.rfc.example.dao.CallRecordingScheduledProgramTriggerDAO"" class=""com.rfc.example.dao.CallRecordingScheduledProgramTriggerDAOJDBCImpl""> <property name=""dataSource"" ref=""dataSource""></property> </bean> AND HERE IS THE DAO: @Transactional public class CallRecordingScheduledProgramTriggerDAOJDBCImpl extends SimpleJdbcDaoSupport implements CallRecordingScheduledProgramTriggerDAO{ private static final Log log = LogFactory.getLog(CallRecordingScheduledProgramTriggerDAOJDBCImpl.class); @SuppressWarnings(""unchecked"") public CallRecordingScheduledProgramTrigger save( CallRecordingScheduledProgramTrigger entity) { log.debug(""save -> entity: "" + entity); String sql = null; Map args = new HashMap(); String agentIdsString = getAgentIdsString(entity.getAgentIds()); String insertSQL = ""insert into call_recording_scheduled_program_trigger"" + "" ( queue_id queue_id_string agent_ids_string caller_names caller_numbers trigger_id note callcenter_id creator_id_string creator_id) "" + "" values(:queueId :queueIdString :agentIdsString :callerNames :callerNumbers :triggerId :note :callcenterId  :creatorIdString :creatorId )""; args.put(""queueId"" entity.getQueueId()); args.put(""agentIdsString""agentIdsString); args.put(""callerNames"" entity.getCallerNames()); args.put(""queueIdString"" entity.getQueueIdString()); args.put(""callerNumbers"" entity.getCallerNumbers()); args.put(""triggerId"" entity.getTriggerId()); args.put(""note"" entity.getNote()); args.put(""callcenterId"" entity.getCallcenterId()); args.put(""creatorId"" entity.getCreatorId()); args.put(""creatorIdString"" entity.getCreatorIdString()); sql = insertSQL; getSimpleJdbcTemplate().update(sql args); System.out.println(""saved: ----------"" + entity); return entity; } } Here is the client code that calls the dao and throws exception (spring service) @Transactional(propagation=Propagation.REQUIRED) public void jdbcTransactionTest() { System.out.println(""entity: "" ); CallRecordingScheduledProgramTrigger entity = new CallRecordingScheduledProgramTrigger(); entity.setCallcenterId(10L); entity.setCreatorId(22L); entity.setCreatorIdString(""sajid""); entity.setNote(System.currentTimeMillis() + """"); entity.setQueueId(22); entity.setQueueIdString(""dddd""); String triggerId = ""id: "" + System.currentTimeMillis(); entity.setTriggerId(triggerId); callRecordingScheduledProgramTriggerDAO.save(entity); System.out.println(""entity saved with id: "" + triggerId ); throw new RuntimeException(); } NOTE: the code works as expected when using DatasourceTransactionManager UPDATE - 2: Ok I have found the root cause of the problem. Thanks to Espen. My entity manager configuration was like this(copied from spring pet-clinic app):  <bean id=""entityManagerFactory"" class=""org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean""> <property name=""dataSource"" ref=""dataSource""/> <property name=""persistenceXmlLocation"" value=""classpath:/persistence-test.xml"" /> <property name=""persistenceProvider""> <bean class=""org.hibernate.ejb.HibernatePersistence"" /> </property> </bean> Then I changed it to like this:  <bean id=""entityManagerFactory"" class=""org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean""> <property name=""persistenceXmlLocation"" value=""classpath:/persistence-test.xml"" /> <property name=""dataSource"" ref=""dataSource""/> <property name=""jpaVendorAdapter""> <bean class=""org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter""> <property name=""showSql"" value=""true"" /> <property name=""generateDdl"" value=""true"" /> <property name=""databasePlatform"" value=""org.hibernate.dialect.MySQL5Dialect"" /> </bean> </property> </bean> Now everything seems to be working! Can anyone explain the difference between these two approach ? Try to remove the persistenceXmlLocation property. It's an alternative to the dataSource property. The requirements for the JpaTransactionManager to work with both JPA and JDBC queries is that your entityManager uses the same dataSource as your JDBC queries and that you specify the the JPA dialect as you have already done. Maybe related http://stackoverflow.com/questions/2650409/implement-custom-jta-xaresource-for-using-with-hibernate/2651580#2651580 I've not really worked this out in detail yet as I've not mixed both JDBC and JPA but if you get your JDBC connection for an XA datasource then they are JTA transaction. So if you run your code in Stateless session bean for example with transaction turned on then you automatically get both your Entities and JDBC managed by JTA. EDIT Here is an example code from Servlet private @Resource DataSource xaDatasource; private @Resource UserTransaction utx; private @PersistenceUnit EntityManagerFactory factory; public void doGet(HttpServletRequest req HttpServletResponse res) ... { utx.begin(); //Everything below this will be in JTA Connection conn = xaDatasource.getConnection(); EntityManager mgr = factory.createEntityManager(); //Do your stuff ... utx.commit(); } Disclaimer: Code not tested. Just realize this is not Spring but I'll leave it up anyway  It's possible to mix JPA and JDBC code in the same transaction using the JpaTransactionManager. A snippet from Spring 3's JavaDoc: This transaction manager also supports direct DataSource access within a transaction (i.e. plain JDBC code working with the same DataSource). This allows for mixing services which access JPA and services which use plain JDBC (without being aware of JPA)! You should be aware though that JPA caches the queries and executes all of them at the end of a transaction. So if you want to persist some data inside a transaction with JPA and then retrieve the data with JDBC it will not work without explicitely flushing the JPA's persistence context before you attempt to retreive it with JDBC code. A code example that asserts with JDBC code that the JPA code deleted a row inside a transaction: @Test @Transactional @Rollback(false) public void testDeleteCoffeeType() { CoffeeType coffeeType = coffeeTypeDao.findCoffeeType(4L); final String caffeForte = coffeeType.getName(); coffeeTypeDao.deleteCoffeeType(coffeeType); entityManager.flush(); int rowsFoundWithCaffeForte = jdbcTemplate .queryForInt(""SELECT COUNT(*) FROM COFFEE_TYPES where NAME = ?"" caffeForte); assertEquals(0 rowsFoundWithCaffeForte); } And if you prefer to use the JpaTemplate class just replace the entityManager.flush() with jpaTemplate.flush(); In response to Sajids' comment: With Spring you can configure a transaction manager that supports both JPA and JDBC like this: <tx:annotation-driven transaction-manager=""transactionManager"" /> <!-- Transaction manager --> <bean id=""transactionManager"" class=""org.springframework.orm.jpa .JpaTransactionManager""> <property name=""entityManagerFactory"" ref=""entityManagerFactory"" /> </bean> In order to make it work the JDBC queries must be executed with the JdbcTemplate or the SimpleJdbcTemplate class. In your case with the DAO that extends the SimpleJdbcDaoSupport you should use the getSimpleJdbcTemplate(..) method. And finally to let two DAO methods participate in the same transaction call both DAO methods from a service class metho annotated with @Transactional. With the <tx:annotation-driven> element in your config Spring will handle the transaction for you with the given transaction manager. On the business layer: public class ServiceClass {.. @Transactional public void updateDatabase(..) { jpaDao.remove(..); jdbcDao.insert(..); } } Edit 2: Then something is wrong. It works for me exactly as specified in the Javadoc. Does your entity manager has a datasource property like my bean below? It will only work as long you're injecting the same datasource into the entity manager and your extended JpaDaoSupport classes. <bean id=""entityManagerFactoryWithExternalDataSoure"" primary=""true"" class=""org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean""> <property name=""dataSource"" ref=""dataSource"" /> <property name=""jpaVendorAdapter""> <bean class=""org.springframework.orm.jpa.vendor .HibernateJpaVendorAdapter"" /> </property> <property name=""jpaProperties""> <value> hibernate.format_sql=true </value> </property> </bean> @Espen Thaks for the answer. However I am more interested in standalone JDBC Dao Implementation. For example I have UserDaoJPAImpl for User and OrderDaoJDBCImpl for Order. OrderDaoJDBCImpl extends 'SimpleJdbcDaoSupport'. my 1st problem How do I make OrderDaoJDBCImpl transactional (declarative either annotation or xml). Do I have to write another transactional manager? my 2nd problem. How do I mix these two transaction? I could do this mix in EJB 2.1 CMT vs BMT transactions (uses JTA). But with Spring & JPA  is it possible without JTA? @Sajid: Declarative transactions works almost the same with Spring as with EJB 3. Instead of @TransactionAttribute you use @Transactional instead. And yes its definitely possible without JTA and with Spring. It only requires that all queries are executed against the same datasource. A I have a dao extended from SimpleJdbcDaoSupport which uses getSimpleJDBCTemplate.update to insert a database row. When a RuntimeException is thrown from the service code the transaction never rolls back when using JPATransactionManager. It does rollback when using DatasourceTransactionManager. I tried to debug the JPATransactionManager and seems that it never performs rollback on underlying JDBCConnection(I guess due to the fact that the datasource is not necessarily has to be JDBC for JPA). My configuration setup are exactly like you explained here. Yes LocalContainerEntityManagerFactoryBean is injected the datasource. Can you point me to a working code so that I can sort out the differences ? All the example applications I can see in spring source does not have the JPA/JDBC mix."
1067,A,"Monitoring DB: MySQL I am writing to ask for advice. I have to monitor certain ""insert"" on a mysql db. In what way is more convenient to do this? The application uses Servlets and MySQL. Thank you very much Are you using a persistence framework? If not you could use triggers to detect inserts. But if you are using a framework I'd use whatever it gives you. Depends on the persistence framework you're using. If it's Hibernate you need to implement an Interceptor and hook on onSave(). If it's JPA you need to use an entity method with the @PrePersist or @PostPersist annotation. If it's plain vanilla JDBC just add the code to the boilerplated DAO method. This is unrelated to servlets. The servlet is just an API for intercepting on HTTP requests. Your data access layer should be independent and transparent from that. @sangi - In StackOverflow it is a good practice to take your details and put them in your question. Also it sounds like you solved your problem so it would help if you gave your solution as an answer. I see that you are new so I thought I would point that out. Thank you for your answers. I have to add some details. WebApp uses JDBC. DB MySql. I would to know when some new data are inserted (insert made from third-party app inaccessible to me) because I have to send email alert for new data so that the user can then view it in the webapp. So I defined a Thread in ServletContextListener that periodically checks to see if there are changes in DB extracting the latest data(max timestamp) and check with a temp table(which contains data read from the last time) if the data is old or new. Thanks much."
1068,A,"JDBC/OSGi and how to dynamically load drivers without explicitly stating dependencies in the bundle? This is a biggie. I have a well-structured yet monolithic code base that has a primitive modular architecture (all modules implement interfaces yet share the same classpath). I realize the folly of this approach and the problems it represents when I go to deploy on application servers that may have different conflicting versions of my library. I'm dependent on around 30 jars right now and am mid-way though bnding them up. Now some of my modules are easy to declare the versioned dependencies of such as my networking components. They statically reference classes within the JRE and other BNDded libraries but my JDBC related components instantiate via Class.forName(...) and can use one of any number of drivers. I am breaking everything up into OSGi bundles by service area. My core classes/interfaces. Reporting related components. Database access related components (via JDBC). etc.... I wish for my code to be able to still be used without OSGi via single jar file with all my dependencies and without OSGi at all (via JARJAR) and also to be modular via the OSGi meta-data and granular bundles with dependency information. How do I configure my bundle and my code so that it can dynamically utilize any driver on the classpath and/or within the OSGi container environment (Felix/Equinox/etc.)? Is there a run-time method to detect if I am running in an OSGi container that is compatible across containers (Felix/Equinox/etc.) ? Do I need to use a different class loading mechanism if I am in a OSGi container? Am I required to import OSGi classes into my project to be able to load an at-bundle-time-unknown JDBC driver via my database module? I also have a second method of obtaining a driver (via JNDI which is only really applicable when running in an app server) do I need to change my JNDI access code for OSGi-aware app servers? Utilizing any driver within the OSGi environment requires you using a DynamicImport-Package: * statement so your bundle can resolve these packages when you load a driver with Class.forName(..). Probably the easiest way is to try to access a class that is in the org.osgi.framework package. Those should at least be always around in an OSGi environment (see snippet below). There are more sophisticated mechanisms so let me know if you need something more advanced. Also take a look at the OSGi R4.2 core spec paragraph 3.8.9 which shows some methods of finding the Bundle and BundleContext of a class and therefore indirect helps in determining if you're in a framework or not. That depends on what you're doing no generic ""yes"" or ""no"" answer here. OSGi uses classloaders and does so in a way that is not ""typical"" for a standard Java application but depending on what you're doing you might not notice. No. Take a look at the recently released OSGi enterprise specs. They have a chapter on JNDI integration in OSGi which probably allows you to leave your code (largely) unmodified. A simple example snippet:  public static boolean inOSGi() { try { Class.forName(""org.osgi.framework.FrameworkUtil""); return true; } catch (ClassNotFoundException e) { return false; } } Just make sure that you if you put this code in a bundle the bundle should import org.osgi.framework (otherwise it will never find that class). Thanks for the information especially the DynamicImport-Package: * tip which surprisingly I couldn't find via internet search. With regard to the second answer a snippet might be nice if you have time. I will flag this as the approved answer anyway though as your answered my main questions. Thank you."
1069,A,"How do I go about creating and then connecting to and querying a database in Java? I've recently started my first programming job and what I need to do as my main project is to create a program for simulating diesel generator behaviour. I'm creating this program using Java which I've never used before (all of my limited experience is with C++) and the first problem I need to overcome is to create a database to store the necessary data that will act as input to the simulator. This database problem strikes me as something that has in general been done many times before. Could anyone get me started on the right track towards achieving this with suggestions on what to use to first create the database and then what to use to access it with the simulator? In regards to the latter I've been reading over the java.sql package and it seems as though it would suit my purposes. What do you think? Thanks very much in advance. Database access in Java goes via JDBC. (Indeed all those classes are in the java.sql package) Check the JDBC Tutorial Here is a sample snippet from that tutorial to give you an impression: Connection con = DriverManager.getConnection ( ""jdbc:myDriver:wombat"" ""myLogin""""myPassword""); Statement stmt = con.createStatement(); ResultSet rs = stmt.executeQuery(""SELECT a b c FROM Table1""); while (rs.next()) { int x = rs.getInt(""a""); String s = rs.getString(""b""); float f = rs.getFloat(""c""); } JDBC is compatible with any Relational Database Management System. I like MySQL myself as it is free and has plenty of documentation on the web. But any RDBMS goes. If you're going for MySQL a simple way to get started is to install MySQL and create the database directly from the MySQL shell. PhpMyAdmin is another simple option to manage a MySQL database. (On windows in combination with XAMPP. On linux from your distro's package manager) Please add code that shows that you need to close `Connection` `Statement` and sometimes the `ResultSet` to prevent resource leaks in general case and in the presence of exceptions. If you do I'll give you +1. Of course but this is just a first impression to get you started. It also doesn't show how to deal with SQLException etc.  In one word Google or buy a book there are a million resources that have answered this very question. I didn't downvote but it looked to me the OP didn't knew where to start and in this case google is pretty useless. ""Use Google"" can be an answer to most things on SO but that doesn't really help people who are ""all at sea"" like the original poster. A post suggesting *what* to search for in Google would have been far more useful.  There are 2 parts to your question: how to create a database and how to access it from your code. Part 1: there are several light-weight database projects that you can choose from. Check out HSQLDB it's quite popular and user-friendly. You'll have to download it and you can use the built-in tools to create and populate your database with data. Part 2: The JDBC standard defines how a Java program connects to the database. The tutorial (as suggested by amarillion) is a good place to start. You'll need to put the database's JDBC driver in your classpath and you'll be able to connect to the DB from your code. Note that parts of the process (such as the driver and the connection string) are specific for the database you choose (meaning the connection string for HSQLDB is different from the one for MySQL). However JDBC is rather low-level: you have to work with objects that represent connections and SQL statements (the ones you noticed in java.sql). This is an excellent place to start but later on as your code grows you might want to consider using an O/R mapping tool. It will make your life easier but it has a learning curve. The most popular ORM for Java is Hibernate. Good luck! I would not recommend Hibernate to somebody who's never used JDBC. It might be low-level but so is a newcomer's understanding and comfort. Your two part answer is good otherwise. @duffymo: agreed I meant Hibernate as a later stage. Edited the answer to better reflect my meaning.  JDBC is the keyword. Use this to look for Tutorials on the net."
1070,A,When should I use the JDBC Persistence Adapter in ActiveMQ? Reading the ActiveMQ documentation (we are using the 5.3 release) I find a section about the possibility of using a JDBC persistence adapter with ActiveMQ. What are the benefits? Does it provide any gain in performance or reliability? When should I use it? Hey the use of journaled JDBC seems to be better than using JDBC persistence only since the journaling is very much faster than JDBC persistence. It is better than just journalled persistence only cos' you have an additional backup of the messages in the db. Journalled JDBC has the additional advantage that the same data in journal is persisted to the db later and this can be accessed by developers when needed! However when you are using master/slave ActiveMQ topology with journalled JDBC you might end up loosing messages since you might have messages in journal that are not yet into the DB!  In my opinion you would use JDBC persistence if you wanted to have a failover broker and you could not use the file system. The JDBC persistence was significantly slower (during our tests) than journaling to the file system. For a single broker the journaled file system is best. If you are running two brokers in an active/passive failover the two brokers must have access to the same journal / data store so that the passive broker can detect and take over if the primary fails. If you are using the journaled file system then the files must be on a shared network drive of some sort using NFS WinShare iSCSI etc. This usually requires a higher-end NAS device if you want to eliminate the file share as a single point of failure. The other option is that you can point both brokers to the database which most applications already have access to. The tradeoff is usually simplicity at the price of performance as the journaled JDBC persistence was slower in our tests. We run ActiveMQ in an active/passive broker pair with journaled persistence via an NFS mount to a dedicated NAS device and it works very well for us. We are able to process over 600 msgs/sec through our system with no issues. Yeap that was exactly my experience. In our tests the JDBC persistence was many times slower than the journalling option. Thanks
1071,A,"JDBC MySQL: getting bits into a BIT(M!=1) column I'm new to using JDBC + MySQL. I have several 1/0 values which I want to stick into a database with a PreparedStatement. The destination column is a BIT(M!=1). I'm unclear on which of the setXXX methods to use. I can find the references for what data comes out as easily enough but how it goes in is eluding me. The values effectively live as an ordered collection of booleans in the objects used by the application. Also I'll occasionally be importing data from flat text files with 1/0 characters. well it's not actually an array of booleans. I have an ordered collection of distinguishable binary values. Btw storing bits as array of boolean in java is a huge waste of memory. The concrete size of boolean depends on the runtime environment implementation and normally lies between 1-4 bytes(!). Consider using java.util.BitSet As to your request from below. There is no sensible way the jdbc connector could understand a boolean[] without conversion as BIT(M). You will have to convert the array to something more suitable. If converting to String for my solution or to byte[] is your choice You can use get/setObject with a byte array (byte[]). 8 bits are packed into each byte with the least significant bit being in the last array element.  To set a BIT(M) column in MySQL For M==1 setBoolean(int parameterIndex boolean x) From the javadoc Sets the designated parameter to the given Java boolean value. The driver converts this to an SQL BIT value when it sends it to the database. For M>1 The support for BIT(M) where M!=1 is problematic with JDBC as BIT(M) is only required with ""full"" SQL-92 and only few DBs support that. Check here Mapping SQL and Java Types: 8.3.3 BIT The following works for me with MySQL (at least with MySQL 5.0.45 Java 1.6 and MySQL Connector/J 5.0.8) ... PreparedStatement insert = con.prepareStatement( ""INSERT INTO bittable (bitcolumn) values (b?)"" ); insert.setString(1""111000""); ... This uses the special b'110101010' syntax of MySQL to set the value for BIT columns. My question is specifically for M!=1; I'll edit to make that more obvious. Extended answer with solution That works perfectly for when I'm importing my co-workers text files. I'd still like to avoid the conversion from data to string for the non-import cases."
1072,A,"Oracle10 and JDBC: how to make CHAR ignore trailing spaces at comparision? I have a query that has ... WHERE PRT_STATUS='ONT' ... The prt_status field is defined as CHAR(5) though. So it's always padded with spaces. The query matches nothing as the result. To make this query work I have to do ... WHERE rtrim(PRT_STATUS)='ONT' which does work. That's annoying. At the same time a couple of pure-java DBMS clients (Oracle SQLDeveloper and AquaStudio) I have do NOT have a problem with the first query they return the correct result. TOAD has no problem either. I presume they simply put the connection into some compatibility mode (e.g. ANSI) so the Oracle knows that CHAR(5) expected to be compared with no respect to trailing characters. How can I do it with Connection objects I get in my application? UPDATE I cannot change the database schema. SOLUTION It was indeed the way Oracle compares fields with passed in parameters. When bind is done the string is passed via PreparedStatement.setString() which sets type to VARCHAR and thus Oracle uses unpadded comparision -- and fails. I tried to use setObject(nstrTypes.CHAR). Fails. Decompilation shows that Oracle ignores CHAR and passes it in as a VARCHAR again. The variant that finally works is setObject(nstrOracleTypes.FIXED_CHAR); It makes the code not portable though. The UI clients succeed for a different reason -- they use character literals not binding. When I type PRT_STATUS='ONT' 'ONT' is a literal and as such compared using padded way. I would change CHAR(5) column into varchar2(5) in db. Out of question. DB doesn't belong to our group.  If you cannot change your database table you can modify your query. Some alternatives for RTRIM: .. WHERE PRT_STATUS like 'ONT%' ... .. WHERE PRT_STATUS = 'ONT ' ... -- 2 white spaces behind T .. WHERE PRT_STATUS = rpad('ONT'5' ') ...  Note that Oracle compares CHAR values using blank-padded comparison semantics. From Datatype Comparison Rules Oracle uses blank-padded comparison semantics only when both values in the comparison are either expressions of datatype CHAR NCHAR text literals or values returned by the USER function. In your example is 'ONT' passed as a bind parameter or is it built into the query textually as you illustrated? If a bind parameter then make sure that it is bound as type CHAR. Otherwise verify the client library version used as really old versions of Oracle (e.g. v6) will have different comparison semantics for CHAR. That's fine. See my updated answer then. Hmm... that makes sense. JDBC's setString uses VARCHAR to bind a string parameter. Not sure if I can use this to solve the problem but at least it becomes clearer now. You probably right: ""Oracle uses nonpadded comparison semantics whenever one or both values in the comparison have the datatype VARCHAR2 or NVARCHAR2"". I need to do a test to check it. Thanks Vlad! See my solution above. Glad the problem is fixed! V."
1073,A,mySQL jar name and location I wanted to know What jars do I need to have to connect to MySQL and Where can I download it? I googled it but there are so many of'em. Can somebody tell me what class DO I need to use.? Thanks You need the mysql-connector-java-5.1.6-bin.jar (or if you want some other version you can download that). Here is where to find them: http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.6.tar.gz/from/pick?file=Downloads/Connector-J/mysql-connector-java-5.1.6.tar.gz&mirror=pick For an example of how to connect using mysql there are plenty of tutorials here's one to check out: http://www.stardeveloper.com/articles/display.html?article=2003090401&page=1
1074,A,"Is it possible to refer to column names via bind variables in Oracle? I am trying to refer to a column name to order a query in an application communicating with an Oracle database. I want to use a bind variable so that I can dynamically change what to order the query by. The problem that I am having is that the database seems to be ignoring the order by column. Does anyone know if there is a particular way to refer to a database column via a bind variable or if it is even possible? e.g my query is SELECT * FROM PERSON ORDER BY :1 (where :1 will be bound to PERSON.NAME) The query is not returning results in alphabetical order I am worried that the database is interpreting this as:- SELECT * FROM PERSON ORDER BY 'PERSON.NAME' which will obviously not work. Any suggestions are much appreciated. ResultSet result = select.executeQuery(""SELECT * FROM PERS ORDER BY ""+columnName); will always be a NEW statement to the database. That means it is like Thilo already explained impossible to ""reorder"" an already bound calculated prepared parsed statement. When using this result set over and over in your application and the only thing which changes over time is the order of the presentation try to order the set in your client code. Otherwise dynamic SQL is fine but comes with a huge footprint. It will only be a new statement if columnName is *always* different. I'd expect columnName to only take one of a small set of values which means the detriment to the shared pool will be minimal.  No. You cannot use bind variables for table or column names. This information is needed to create the execution plan. Without knowing what you want to order by it would be impossible to figure out what index to use for example. Instead of bind variables you have to directly interpolate the column name into the SQL statement when your program creates it. Assuming that you take precautions against SQL injection there is no downside to that. Update: If you really wanted to jump through hoops you could probably do something like order by decode(? 'colA' colA 'colB' colB) but that is just silly. And slow. Don't. +1 btw I don't know if that's true for Oracle but there is definitely a downside in other databases (like DB2) - it makes much harder for the database to cache queries if you modify the query command text all the time (and not just the values of the parameters) That also happens in oracle. But you are not changing the command text all the time. There are only a few choices for the column name so there will be only five cache entries or so. Thanks a lot that makes sense to me. I will try to make the code understand when its looking at the order by clause and if it contains a bind variable there I'll replace it with its value. Hmmm... You cannot just not bind it in the first place? It can still be a parameter within your program. Trying to fix the SQL statement after it has been composed sounds tricky. Not really - the tool where the queries are built up parses the sql string for placeholders then populates the placeholders with their values. This means at some point I'm definately going to have to go back and mess around with the statement to put the column names rather than trying to bind them.  As you are using JDBC. You can rewrite your code to something without bind variables. This way you can also dynamically change the order-by e.g.:  String query = ""SELECT * FROM PERS ""; if (condition1){ query = query+ "" order by name ""; // insert more if/else or case statements } else { query = query+ "" order by other_column ""; } Statement select = conn.createStatement(); ResultSet result = select.executeQuery(query); Or even  String columnName = getColumnName(input); Statement select = conn.createStatement(); ResultSet result = select.executeQuery(""SELECT * FROM PERS ORDER BY ""+columnName); SQL is best left in the database. I disagree - this is a good suggestion Edwin thanks. It looks like I might have to do something like this. I will also need to do some removal of the placeholders from the query string when I add the order by column."
1075,A,"What files needed for JDBC connection to MySQL? I get the following error when attempting to connect to the MySQL database on my employer's local server: Unable to load database driver Details : java.lang.ClassNotFoundException: com.mysql.jdbc.Driver BUILD SUCCESSFUL (total time: 0 seconds) I think it's pretty clear that this is because I don't have my files set up properly. Only problem is I don't know what I need and where it needs to go. Is the Driver a .class file? Where can I download it? Where in my filesystem (ubuntu fwiw) do I put the file so that ""Class.forName(""com.mysql.jdbc.Driver"").newInstance();"" works? Thanks for all your help m8s. Yes it is a .class file that uses a others .class files. You call all these collections of files a library and in this particular case the library is also named: ""jdbc driver"". These libraries are usually .jar files so in your case you may try: http://www.mysql.com/products/connector/j/ To download the MySQL JDBC driver. You should put it in your classpath Thanks guys looks like I have to wait up to 48 hours for MySQL to provide us with the driver :(. In the meantime it looks like I can figure out setting up the classpath but what about the .jar file's physical location? I have read in various places that the file should live in the JDK folder or in the webapps/ROOT folder of Tomcat. @malenkylizards - If you're using Tomcat 6.x put the .jar file in the TOMCAT_HOME/lib folder that will make it available to all of the web apps. If you are using some other server you'll need to find the location for shared .jar libraries and put it there. Note that you CAN also put it under the WEB-INF/lib folder of any given web app. Why 48 hours though? @Lauri Lehtinen I couldn't say why it was 48 hours MySQL wouldn't let me download the drivers until I supplied them with an excessive amount of information including the company's address. I ended up not using their site because of course it was already downloaded I just wasn't looking in the right place. D'oh!  You can download the connector here (the .jar you need is inside the .zip/.tar.gz): http://dev.mysql.com/downloads/connector/j/ The .jar needs to be in a classpath available to your application."
1076,A,"Last batch from prepared statment won't get written unless I close the connection I'm doing a small project including a connection to sqlite. I write to two tables with a one to many relation. The last batch to the second table won't get written unless I explicitly closes the connection. I find it strange since the database is in auto-commit mode (i.e. connection.commit() throws an error). I would like to keep the connection open since I'll do quite some calls to the write method. Is there anything beside commit() I can do to force a write to the disk? Here's a close to minimal code example note that if I uncomment the conn.close() it will work as I want to. Class.forName(""org.sqlite.JDBC""); Connection conn = DriverManager.getConnection(""jdbc:sqlite:result""); Statement stat = conn.createStatement(); stat.executeUpdate(""create table if not exists "" + ""a (a1 aID INTEGER PRIMARY KEY ASC)""); stat.executeUpdate(""create table if not exists "" + ""b (aID b1 attributePathID INTEGER PRIMARY KEY ASC)""); PreparedStatement pa = conn.prepareStatement( ""insert into a (a1) values (?);""); PreparedStatement pb = conn.prepareStatement( ""insert into b (aIDb1) values (??);""); int[] aSet = new int[] {102030}; int[] bSet = new int[] {12}; for(int ai : aSet){ pa.setInt(1ai); pa.execute(); ResultSet rs = pa.getGeneratedKeys(); rs.next(); long aID = rs.getLong(1); for(int bi : bSet){ pb.setLong(1aID); pb.setInt(2bi); pb.execute(); } } //conn.close(); Haven't worked with jdbc and sqllite much but this should work: conn.setAutoCommit(false); for(int bi : bSet){ pb.setLong(1aID); pb.setInt(2bi); pb.executeUpdate(); } conn.commit(); conn.setAutoCommit(true); Also take a look at http://www.zentus.com/sqlitejdbc/ which has a nice example similar to yours. That one throws an SQLException ""SQL logic error or missing database"" on the conn.commit(); row. But the example from your link worked. The exception raised because the ResultSet was still open. So by just adding a your fix and rs.close() it worked. Glad I could help."
1077,A,"Query returns ""No data found"" JSP/Oracle I've been looking this over for a while now and can't seem to pinpoint the problem. Does anything stand out that would cause a java.sql.SQLException: No data found  ResultSet rs = null; rs = s.executeQuery(""SELECT * FROM customer""); out.println(""<tr><th>Customer ID</th><th>First Name</th>&nbsp;</th></tr>""); while(rs.next()) { out.println(""<tr><td>"" + rs.getString(""customer_id"") + ""</td><td>"" + rs.getString(""first_name"") + ""</td></tr>""); } I think I narrowed it down. customer_id is stored as a number. If I take out rs.getString(""customer_id"") out of the print then it does work. should it be getInt(""customer_id"") or something similar? This exception message is typical to the JDBC-ODBC bridge driver. Since you're apparently using an Oracle database you should be using the Oracle JDBC driver not the JDBC-ODBC bridge driver. A fullworthy JDBC driver provided by the DB vendor will perform and behave much better in all areas you can think of. The JDBC-ODBC bridge driver is full of bugs you don't want to know. I think I narrowed it down. customer_id is stored as a number. If I take out rs.getString(""customer_id"") out of the print then it does work. should it be getInt(""customer_id"") or something similar? Either replace SELECT * by SELECT colname1 colname2 colname3 or use getString(1) where 1 is the column index. But still I'd prefer using Oracle's own pure JDBC driver. Interesting. I will check it out. Is there a reason the ODBC-JDBC bridge driver would work on some pages and not others (like this one)??"
1078,A,"using Spring JdbcTemplate for multiple database operations I like the apparent simplicity of JdbcTemplate but am a little confused as to how it works. It appears that each operation (query() or update()) fetches a connection from a datasource and closes it. Beautiful but how do you perform multiple SQL queries within the same connection? I might want to perform multiple operations in sequence (for example SELECT followed by an INSERT followed by a commit) or I might want to perform nested queries (SELECT and then perform a second SELECT based on result of each row). How do I do that with JdbcTemplate. Am I using the right class? how do you perform multiple SQL queries within the same connection? The correct answer here is ""use transactions"". If you begin transaction and then perform multiple operations with JdbcTemplate each of those operations will be within the scope of the transaction and therefore are guaranteed to use the same connection. If you don't want to get involved with transactions then the alternative is to use the more primitive operations on JdbcTemplate like execute(ConnectionCallback action) where you supply an instance of ConnectionCallback which is given a Connection on which you can then perform any operations you choose. Of course but doing this you don't get JdbcTemplate's help in any of the actual operations. Transactions are really quite easy in Spring you should look into using them (see above link). You actually don't need to use an actual transaction to use the same connection. However like using transactions in Spring need to use a TransactionProxyFactoryBean or a Transaction Template. You use PROPAGATION_SUPPORTS or PROPAGATION_NEVER for the propagation and it will reuse the same connection but not start a real transaction. If you are using connection pooling don't you have to worry about not getting the same connection between statements?  I assume you want transactions? If so take a look at Spring JdbcTemplate and Transactions. On a side note I would suggest you take a look at Ibatis. Spring JDBC seems convenient but it has one major issue: the default mapping of result sets to objects uses Spring classes which is actually really slow when dealing with large result sets. You can get around this by writing your own row mappers for these queries but personally I don't want to be writing this kind of boilerplate. To give you an example of the difference: I had one query take 50 seconds with the Spring reflection-based row mapper that took 2 seconds with a hand coded row mapper. Also Spring JDBC uses inline SQL. In Java this is fairly ugly as Java (annoyingly) doesn't have a good multi-line String format. ""the default mapping of result sets to objects uses Spring classes"" can you elaborate on this? I always use RowMappers for anything that resembles querying for an object. What other option is there? I'm also curious what ""default mapping"" means here and how they use reflection. I thought RowMappers were the bread and butter of JdbcTemplate. @mattb  @spaaarky21 Spring can map resultset to objects for example using `BeanPropertyRowMapper` class (you can google examples using it). Simple query is like : `List orders = jt.query(""SELECT * FROM orders WHERE custId=?"" new BeanPropertyRowMapper(MyOrder.class) id);` And then you don't have to wrap your implementation of `RowMapper` but instead fields will be mapped to the setters of the `MyOrder` class."
1079,A,"Java and PostgreSQL stored procedure - return registered as out parameter causing issues with in parameters I'm trying to call a PostgreSQL stored procedure from a Java app; the procedure has a DATE type parameter so I'm using a java.sql.Date type with CallableStatement.setDate(). However executing the statement always results in an exception and the SQL logs show this: LOG: execute <unnamed>: select * from athlete.create_athlete($1$2$3$4$5$6$7) as result DETAIL: parameters: $1 = '' $2 = 'foo@bar.com' $3 = 'Joe' $4 = 'Blow' $5 = 'foobar' $6 = 'M' $7 = '1979-03-22 -04:00:00' ERROR: column ""dob"" is of type date but expression is of type text at character 122 HINT: You will need to rewrite or cast the expression. QUERY: INSERT INTO athlete.athlete (email first_name last_name password gender dob) VALUES ( $1  $2  $3  $4  $5  $6 ) CONTEXT: PL/pgSQL function ""create_athlete"" line 2 at SQL statement STATEMENT: select * from athlete.create_athlete($1$2$3$4$5$6$7) as result The stored procedure actually has 6 parameters (and should receive values $2 through $7 above) - the 7th comes from registering the return value as an out parameter. This has me confused - is it correct that it appears as 7 parameters when I register an out parameter for the return value? From all the docs I've read I'm under the impression that the return value has to be registered as the first parameter: registerQuery = ""{? = call athlete.create_athlete(??????)}""; ... CallableStatement cs = conn.prepareCall(registerQuery); cs.registerOutParameter(1 Types.BOOLEAN); cs.setString(2 email); ... The error above suggests to me that there's a mismatch between stored procedure parameters and the parameters supplied to the insert statement. I've been following documentation for all of this but am clearly doing something wrong. How do I supply the proper parameters to the stored procedure and retrieve the return value after the call? Due to a restriction in the OCI layer the JDBC drivers do not support the passing of BOOLEAN parameters to PL/SQL stored procedures. If a PL/SQL procedure contains BOOLEAN values you can work around the restriction by wrapping the PL/SQL procedure with a second PL/SQL procedure that accepts the argument as an INT and passes it to the first stored procedure. When the second procedure is called the server performs the conversion from INT to BOOLEAN.  It turns out the issue was that the order of parameters passed to the stored procedure did not match the order those parameters were passed to the insert statement. I don't understand why PostgreSQL would use named parameters if order is significant. For example the signature of the stored procedure was as follows: CREATE FUNCTION insert_Person (IN in_name TEXT IN in_gender CHAR(1) IN in_bdate DATE) RETURNS BOOLEAN... The INSERT statement contained within that stored procedure was as follows: INSERT INTO Person (name bdate gender) VALUES (in_name in_bdate in_gender); Changing the order of the parameters such that they matched in either the stored procedure signature or insert statement (I went with the former) resolved the issue.  Depends on signature of your stored procedure type (function/procedure). For function like one below out parameter will be first one and will have param1 and param2 as second and third parameters. DB Procedure (for function): CREATE FUNCTION my_func ( param1 INT param2 INT) RETURNS INT AS : : Java code (for function): registerQuery = ""{? = call my_func(??)}""; ... CallableStatement cs = conn.prepareCall(registerQuery); cs.registerOutParameter(1 Types.INTEGER); cs.setInteger(2 10); cs.setInteger(3 10); ... . However for procedure like one below out parameter will be third one and will have param1 and param2 as first and second parameters. DB Procedure (for procedure): CREATE PROCEDURE my_proc ( param1 INT param2 INT OUT param3 INT) BEGIN : : END; Java code (for procedure): registerQuery = ""{call my_func(???)}""; ... CallableStatement cs = conn.prepareCall(registerQuery); cs.registerOutParameter(3 Types.INTEGER); cs.setInteger(1 10); cs.setInteger(2 10); ... . Note that you can have multiple out parameters while only one return value. I'm using the former stored procedure signature so I guess that's not the problem. I find it strange that if I pass a Date to a Date parameter that I'd need to cast it for the insert (which is inserting to a Date column.) Can you please update your question with signature of your stored proc  Postgresql server supports named parameters but the jdbc driver does not support it(well not yet to my knowledge) so until such time only positional parameters is supported."
1080,A,"updateBinaryStream on ResultSet with FileStream If I try to update a FileStream column I get following error: com.microsoft.sqlserver.jdbc.SQLServerException: The result set is not updatable. Code: System.out.print(""Now let's update the filestream data.""); FileInputStream iStream = new FileInputStream(""c:\\testFile.mp3""); rs.updateBinaryStream(2 iStream -1); rs.updateRow(); iStream.close(); Why is this? Table in Sql Server 2008: CREATE TABLE [BinaryAssets].[BinaryAssetFiles]( [BinaryAssetFileId] [int] IDENTITY(11) NOT NULL [FileStreamId] [uniqueidentifier] ROWGUIDCOL NOT NULL [Blob] [varbinary](max) FILESTREAM NULL [HashCode] [nvarchar](100) NOT NULL [Size] [int] NOT NULL [BinaryAssetExtensionId] [int] NOT NULL Query used in Java: String strCmd = ""select BinaryAssetFileId Blob from BinaryAssets.BinaryAssetFiles where BinaryAssetFileId = 1""; stmt = con.createStatement(); rs = stmt.executeQuery(strCmd); I don’t know java so I’m going to assume your query is right. Have you made sure that the filestream feature is setup correctly in SQL server? Specifically there are 3 options on the SQL server configuration manager that need setting they are Enable FILESTREAM for Transact-SQL access Enable FILESTREAM for the I/O streaming access Allow remote clients to have streaming access to FILESTREAM data Make sure all of those are ticked and try again  From http://support.microsoft.com/kb/945738: This behavior is by design. That's it. There are two workarounds outlined in the article: Method 1 Change the query that returns the result set or change the configuration of the underlying table. When you do this SQL Server 2000 does not convert the cursor type. Method 2 Manually create statements to update the table in SQL Server 2000. (a bunch of code here)"
1081,A,SQLite database file created from JDBC? I have created a SQLite database from Java. Now I want to know where it is stored physically on disk so that I can push that file on to Android. You specified a database name as part of the JDBC connection URL. Look for a file with that name on your harddisk. Example: jdbc:sqlite:test.db -> look for test.db Thank you very much sir.  SQLite usually produces one file with the extension .sqlite but this is just convention the extension can be anything. As already was said the code which opens the database spefifies the path where the file should be stored so you have to look there. Thank you. Since I am not providing any path the database was created at the package's location. :-)
1082,A,"How to gather user input in a JSP so that it can be stored in database I dont know JSP. I have written the below Java JDBC code which must be integrated in JSP. import java.net.URL; import java.net.URLConnection; import java.sql.*; public class searchlink{ public static void main(String args[]) throws Exception { Connection con=null; Statement stmt=null; Statement stmtR=null; String link=""http://www.topix.com/rss/city/ellensburgwa""; String source=""Sample""; if(con==null){ SQLConnection.setURL(""jdbc:sqlserver://192.168.2.53\\SQL2005;user=sa;password=365media;DatabaseName=LN_ADWEEK""); con=SQLConnection.getNewConnection(); stmt=con.createStatement(); stmtR=con.createStatement(); } ResultSet rs; boolean hasRows=false; rs=stmt.executeQuery(""select url from urls where url='""+link+""'""); while(rs.next()){ hasRows=true; //String mem=rs.getString(1); System.out.println(""This URL already exists in DB"");} if (!hasRows) { PreparedStatement insertUrlStatement = con.prepareStatement(""INSERT INTO urls VALUES(? ? ? ? ?)""); insertUrlStatement.setInt(1 21211); insertUrlStatement.setString(2 link); insertUrlStatement.setString(3 source); insertUrlStatement.setInt(4 1); insertUrlStatement.setInt(5 0); insertUrlStatement.executeUpdate(); } } } Initially my task is to create a text box and assign the value the user enters in it to the String named link which is in the code above. Kindly advise how to build a JSP program for that. Also please let me know whether any changes are to be made in the Java code above for integrating in JSP or I can just include the whole program inside <% content %>. hello... hello... anybody there.... echo??? in the future you're putting pressure to us like in your comment and deleted answer I'll just ignore you. This is a free service. We are not obligated to post answers. Urgency is *your* problem not *ours*. I was very tempted to delete my answer as well. Just ask the question the smart way and have patience. We are not wizards. am sorry... i can understand.. will not repeat again. thanks for ur answer.. if you get past that hurdle id also suggest you use something like springs JdbcDaoSupport to manage your datasource connections. As well as cutting down the number of lines you'll need to write it also helps with connection management  Time to go learn some basics: The Model-View-Control (MVC) pattern would be a very good start. You are in luck - there are many implementations in Java: http://en.wikipedia.org/wiki/Model%E2%80%93View%E2%80%93Controller#Java  First of all you should avoid writing Java code in a JSP file. Here's a step by step: Learn at least HTTP and HTML. To the point you need to understand what HTTP is all about and distinguish the ""server side"" and ""client side"" concepts. You also need to learn HTML as web markup language and the HTML forms to collect user input. This answer contains helpful links. Learn JSP and Servlets. You need to understand that JSP is a Java based view technology which provides a template to write HTML/CSS/JS in which in turn will be sent to the webbrowser. This answer contains helpful links. Having learnt 1 and 2 start creating a JSP file with a simple HTML form with the necessary input fields:  <form action=""servleturl"" method=""post""> <input type=""text"" name=""link""> <input type=""text"" name=""source""> <input type=""submit""> </form> Then create a class which extendsHttpServlet which gathers those input parameters and saves in the database in the doPost() method:  protected void doPost(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { String link = request.getParameter(""link""); String source = request.getParameter(""source""); LinkDAO dao = new LinkDAO(); try { dao.save(link source); } catch (SQLException e) { throw new ServletException(""Saving in DB failed"" e); } request.getRequestDispatcher(""result.jsp"").forward(request response); } Map this servlet in web.xml file on an url-pattern of servleturl (at least it should be the same as where your <form action> is pointing to). Then create a DAO class which does the necessary JDBC stuff:  public class LinkDAO { public void save(String link String source) throws SQLException { // Your original code here. You should however modify it to make it // free of potential resource leaking. } } To learn a bit more how to get started with the DAO pattern you may find this article useful."
1083,A,"Flex Java BlazeDS Dashboard - use Spring/JDBC or Hibernate? I am developing a IT Monitoring Dashboard for the company I work at. The system will primarily perform monitoring of files databases and servers. There will be a small part of the system which will allow the users to configure static data about the system eg: file locations server names etc... So as the app. will be a dashboard a lot of the application will consist of publishing data to the flex client to update all the monitoring views. So there will be limited database activity ie: insert/update/deletes. I'm currently using a Spring/JDBC combination in the backend Java code. I have recently thought about moving to Hibernate for the ease of use in terms of CRUD operations (compared to Spring/JDBC). Does anyone have any ideas on this? For what I am doing is Spring/JDBC enough? Is Spring/JDBC scalable? I'm looking more into the future if the Dashboard grows in terms of users (scalability) and in terms of functionality (more database operations). PS: I haven't used hibernate before but have used JDO/Kodo and Toplink which funamentally work the same way to hibernate. Thanks Mike I am guessing you have looked at the remote class feature of blaze ds along with the pub/sub functionality. This effectively allows you to map a Java class to an action script class which can then be sent over the wire. If you already have a defined entity model on the server which you can utilize it would be easy to integrate hibernate or similar technology as it would work at the entity/domain level. You could take a top down approach and use hibernate to generate your schema for you from your annotated entity model. I am not familiar with spring/jdbc but hibernate can drastically simplify things even for simple apps. In terms of scalability hibernate should not be an issue as it has many advanced features such as second level / distributed caching. If your interested in learning how to generate JPA/hibernate mappings from an class take a look at the netbeans tutorials.  The key difference between Hibernate (and most other ORMs) versus Spring/JDBC is that most ORM's support ""lazy loading"" which can actually be very problematic in remoting applications. Suppose you are using Hibernate and have a Person class which has a collection of Address objects. If you ask Hibernate for a Person instance by default it will load only the simple properties of Person and the ""addresses"" collection will be an empty proxy. When you access ""addresses"" for the first time Hibernate will execute some SQL to magically ""lazy load"" the data into the addresses collection for you. When you pass Person with the lazy addresses up to whichever serializer in use it will walk the entire object graph and trigger lazy loading of every lazy proxy it can reach. In a complex object model this can result in literally thousands of SQL queries to fully load the object graph before sending it to the server to say nothing of the multiple megabytes of data that will be send over the wire. One of the other posters mentioned using DTO's with Hibernate and this is not a bad recommendation because it helps work around this lazy loading issue. You essentially wrap all of your entities with the DTO's and then return only DTO's to the serializer. Expanding the previous example suppose Person also has a single Department object tied to it. PersonDto can instead have a ""departmentId"" property which when accessed pulls only the ""id"" property from the underlying Department object. Since Hibernate lazy entity proxies are always populated with their identifier you can can access this data without having to lazy load the object. Since PersonDto doesn't actually expose a Department object to the serializer it will not be able to walk it and try to load all of the data. There is one alternative to using DTO's with Hibernate which is to do some very fancy things to those Hibernate lazy proxies so they play nicely with the serializer. Take a look at a project called Gilead if you want to learn more. You also mentioned scalability and of course the answer is ""it depends."" :) In terms of handling more users it will be easier to tune the SQL using Spring/JDBC which may increase performance and lessen load on the database possibly allowing you to support more users. However in terms of code maintainability and the sheer amount of work you'll need to do Hibernate may offer a better option since it automates a lot of tedious crud functionality.  I would go with Hibernate for all of the aforementioned reasons and use the DTO pattern for communicating between Java and Flex. You probably don't want to be sending your Hibernate domain objects directly over the wire.  If you've used Kodo/JDO then DataNucleus should be simple for you. Depends on the complexity of object graphs whether it would be necessary to go to such a solution as against JDBC; you don't give an idea of the relation complexity of data. With DataNucleus you have a L2 cache just like with Kodo providing much assistance in scalability. --Andy (DataNucleus)"
1084,A,"Using prepared statements with JDBCTemplate I'm using the Jdbc template and want to read from the database using prepared statements. I iterate over many lines in a csv file and on every line I execute some sql select queries with it's values. Now I want to speed up my reading from the database but I just can't get the Jdbc template to work with prepared statements. Actually I even don't know how to do it. There is the PreparedStatementCreator and the PreparedStatementSetter. As in this example both of them are created with anonymous inner classes. But inside the PreparedStatementSetter class I don't have access to the values I want to set in the prepared statement. Since I'm iterating through a csv file I can't hard code them as a String because I don't know them. I also can't pass them to the PreparedStatementSetter because there are no arguments for the constructor. And setting my values to final would be dumb too. I was used to the creation of prepared statements being fairly simple. Something like PreparedStatement updateSales = con.prepareStatement( ""UPDATE COFFEES SET SALES = ? WHERE COF_NAME LIKE ? ""); updateSales.setInt(1 75); updateSales.setString(2 ""Colombian""); updateSales.executeUpdate(): as in the Java tutorial. But unfortunately working with the jdbc template really is a pain so far. Your help would be very appreciated. I'd factor out the prepared statement handling to at least a method. In this case because there are no results it is fairly simple (and assuming that the connection is an instance variable that doesn't change): private PreparedStatement updateSales; public void updateSales(int sales String cof_name) throws SQLException { if (updateSales == null) { updateSales = con.prepareStatement( ""UPDATE COFFEES SET SALES = ? WHERE COF_NAME LIKE ?""); } updateSales.setInt(1 sales); updateSales.setString(2 cof_name); updateSales.executeUpdate(); } At that point it is then just a matter of calling: updateSales(75 ""Colombian""); Which is pretty simple to integrate with other things yes? And if you call the method many times the update will only be constructed once and that will make things much faster. Well assuming you don't do crazy things like doing each update in its own transaction... Note that the types are fixed. This is because for any particular query/update they should be fixed so as to allow the database to do its job efficiently. If you're just pulling arbitrary strings from a CSV file pass them in as strings. There's also no locking; far better to keep individual connections to being used from a single thread instead. For queries that return a single value it's pretty easy to use this technique too. The main complexity comes when you have queries that return many values; either return a `ResultSet` then or pass in a callback that will handle each returned row (with the values broken out of the `ResultSet` of course). Sorry but I don't know what that has got to do with my jdbc template problem. I can't feed a jdbc template query with a PreparedStatement. It seems that I need a `PreparedStatementCreator` or a `PreparedStatementSetter`.  By default the JDBCTemplate does its own PrepareStatement internally if you just use the .update(String sql Object ... args) form. Spring and your database will manage the compiled query for you so you don't have to worry about opening closing resource protection etc. One of the saving graces of Spring. A link to Spring 2.5's documentation on this. Hope it makes things clearer. But I want to perform a select on the database not an update. In the Spring reference http://static.springsource.org/spring/docs/2.0.x/api/org/springframework/jdbc/core/JdbcTemplate.html is written that with `update` only an insert update or delete can be performed. @user3211068 there is a `query` method you can for selects @mezmo would you mind to add a source for your statement? And is the same true for query(String sql ...)?  Try the following: PreparedStatementCreator creator = new PreparedStatementCreator() { @Override public PreparedStatement createPreparedStatement(Connection con) throws SQLException { PreparedStatement updateSales = con.prepareStatement( ""UPDATE COFFEES SET SALES = ? WHERE COF_NAME LIKE ? ""); updateSales.setInt(1 75); updateSales.setString(2 ""Colombian""); return updateSales; } }; This would work but the values I want to set are outside the inner anonymous class. Inside the class should be something like `updateSales.setString(2 fileRow.getName())` but I can't access `fileRow` form inside the class. mark the var fileRow as final  I've tried a select statement now with a PeparedStatement from the PreparedStatement class. But it turned out that it was not faster than the Jdbc template. Maybe -- as mezmo suggested -- automatically creates prepared statements. Anyway the reason for my sql selects being so slow was another one. In the WHERE clause I always used the operator LIKE when all I wanted to do was finding an exact match. As I've found out LIKE searches for a pattern and therefore is pretty slow. I'm using the operator = now and it's much faster.  class Main { public static void main(String args[]) throws Exception { ApplicationContext ac = new ClassPathXmlApplicationContext(""context.xml"" Main.class); DataSource dataSource = (DataSource) ac.getBean(""dataSource""); // DataSource mysqlDataSource = (DataSource) ac.getBean(""mysqlDataSource""); JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource); String prasobhName = jdbcTemplate.query( ""select first_name from customer where last_name like ?"" new PreparedStatementSetter() { public void setValues(PreparedStatement preparedStatement) throws SQLException { preparedStatement.setString(1 ""nair%""); } } new ResultSetExtractor<Long>() { public Long extractData(ResultSet resultSet) throws SQLException DataAccessException { if (resultSet.next()) { return resultSet.getLong(1); } return null; } } ); System.out.println(machaceksName); } }"
1085,A,Are there any JDBC implementations for NoSql databases? I just wonder if there are any JDBC implementations (in some extent as much as possible) for any NoSql DB (opensource or proprietary)? How do you think is it possible that this implementation will show as good performance as raw API of correspondent NoSql DB? Which parts cannot be implemented (transactions? CallableStatements? etc)? There is a experimental try on this regard please find https://github.com/erh/mongo-jdbc  What SUN did those days was to create abstract specifications for all relational database systems so that Java developers can work with them all easily provided the providers create implementations. That is what JDBC is. An abstract front for relational Databases. NoSQl is not Relational and there will need to exists a kind of a NoSQL Connectivity Framework probably led by Oracle so that all NoSQL database providers can implement freely and allow Java Developers access via a common ground.  Yes for MongoDB there are several lib available much like JDBCJPA. use this link I did a test application and i found that performance of the MongoDB is much better than MySQL while performing bulk inserts and fetching large no of records. If you are considering any NoSQL data store i would recommend MongoDB. +1 The link I have been looking for! Everything I need to know about Mongo thank you sir!  SQL-based DBs have more in common than different. JDBC builds on those commonalities. If you take away SQL most of the rationale for JDBC is gone! Also NoSQL DBs have pretty widely varying APIs... there's hardly anything to capture under a common set of methods. Short answer: No. it took almost half a year to realize that you're probably right. @Roman: Hehe! Thanks anyway for the late acknowledgement. :)
1086,A,Should I include main method for JPA? For the last three days i am learning JPA by various examples to change my JDBC code to JPA. Every JPA example and tutorial have main method to run it. Of course in main method only they defining EntityManager & EntityManagerFactory. I dont have main method in my web application's server side code. Is that a problem in point of using JPA. Or Creation of EntityManager & EntityManagerFactory in other classes is allowed. and it would be appreciative if anyone explain me about using hibernate in JPA. Every JPA example and tutorial have main method to run it. That's only useful for code that is intended to run outside a container which is often the case of tutorials. I don't have main method in my web application's server side code. Is that a problem in point of using JPA. No. Absolutely not. Or Creation of EntityManager & EntityManagerFactory in other classes is allowed. There is no particular restriction on EntityManagerFactory and EntityManager (beyond the fact that the EMF should be created once for the lifetime of the application and that the common pattern for the EM in a web application is entityManager-per-request i.e. to open an EntityManager at the start of a request and to flush and close it at the end). And it would be appreciative if anyone explain me about using Hibernate in JPA. Hibernate can be used as JPA provider (more precisely the implementation is provided by the satellite project Hibernate EntityManager). But your question is too vague. If you have a specific problem open another question and describe it.
1087,A,JDBC - setAutoCommit for read only operation Let's say I have a common method which creates a DB connection: Connection getConnection() throws SQLException { Connection con = ... // create the connection con.setAutoCommit(false); return con; } I put the setAutoCommit(false) call here so that callers of this method never have to worry about setting it. However is this a bad practice if the operation executed by the caller is only reading data? Is there any extra overhead? My personal opinion is that it's better to centralize the logic in one place that way callers never have to set the auto commit and this avoids code redundancy. I just wanted to make sure it didn't incur any unnecessary overhead for a read only operation. I would never have autoCommit set to true anywhere in the application. The performance overhead if at all any is nothing compared to the side effects of a autocommit=true connection. You say you would never use this connection for DML. But that is the intention maintained perhaps by coding standards etc. But in practice it is possible to use this connection for DML statements. This is enough reason for me to never set auto-commit on. Select statements are definitely going to take some memory/CPU/network. Let the overhead of autocommit be a (very marginal) fixed overhead on every select statement to make sure data integrity and stability of your application is maintained.  I put the setAutoCommit(false) call here so that callers of this method never have to worry about setting it. This is fine IMO and I personally believe that one should never ever enable auto-commit mode inside an application. So my recommendation would be to turn off auto-commit. However is this a bad practice if the operation executed by the caller is only reading data? Is there any extra overhead? From a strict performance point of view it's starting and ending a database transaction for every SQL statement that has an overhead and may decrease the performance of your application. By the way SELECT statements are affected by setAutoCommit(boolean) according to the javadoc: Sets this connection's auto-commit mode to the given state. If a connection is in auto-commit mode then all its SQL statements will be executed and committed as individual transactions. Otherwise its SQL statements are grouped into transactions that are terminated by a call to either the method commit or the method rollback. By default new connections are in auto-commit mode. The commit occurs when the statement completes. The time when the statement completes depends on the type of SQL Statement: For DML statements such as Insert Update or Delete and DDL statements the statement is complete as soon as it has finished executing. For Select statements the statement is complete when the associated result set is closed. For CallableStatement objects or for statements that return multiple results the statement is complete when all of the associated result sets have been closed and all update counts and output parameters have been retrieved.  Autocommit doesn't have any value for SELECT queries. But turning autocommit off is indeed a more common practice. More than often you'd like to fire queries in a transaction. Most of the connection pools also by default turns it off. I would however suggest to make it a configuration setting of your connection manager and/or to overload the method taking a boolean argument so that you at least have any control over it for the case that. Hello BalusC. Could you elaborate on the first sentence? That's not how I read the javadoc. @Pascal: that was indeed a bit poorly phrased. I see. Better now IMO.
1088,A,"Java named parameter's name (for Oracle JDBC function result) I'm going to call a function and set some parameters by name example:  Connection c = null; ResultSet rs = null; String query; PreparedStatement ps; CallableStatement cs = null; try { c = DbUtils.getConnection(); cs = c.prepareCall(""{? = call get_proc_name(? ?) }""); cs.registerOutParameter(1 OracleTypes.VARCHAR); cs.setInt(""in_proc_type"" ProcTypes.SELECT); cs.setLong(""in_table_id"" tableId); // here I should use something like cs.registerOutParameter(""result"" OracleTypes.VARCHAR); cs.execute(); PL/SQL function parameters are: CREATE OR REPLACE FUNCTION get_proc_name ( in_proc_type IN NUMBER /*1 - insert 2 - update 3 - delete 4 - select*/ in_table_name IN VARCHAR2 := NULL in_table_id IN NUMBER := NULL in_table_type_id IN NUMBER := NULL is_new IN NUMBER := 0 ) RETURN VARCHAR2 The question is how to register result as an out parameter and then get it from oracle to java? I can register in/out parameters by name because I know theirs names from function but I don't know how go get function result what variable name use for it. Manuals describe only usage in/out params with procedures not functions. Oracle version: 11.1.0.6.0 Java version: 1.6.0_14 The solution is to use only indexes for settings parameters. Such code works as expected (mixing indexes and named parameters doesn't work; so the problem of using named parameter for result variable could not be solved imho):  c = DbUtils.getConnection(); cs = c.prepareCall(""{? = call get_proc_name(in_proc_type => ? in_table_id => ?) }""); cs.registerOutParameter(1 java.sql.Types.VARCHAR); cs.setInt(2 ProcTypes.SELECT); cs.setLong(3 tableId); cs.execute(); String procName = cs.getString(1); cs.close();  CallableStatement has a bunch of registerXXX methods that take index. That's how you register the result. It is parameter number 1. In your case cs.registerOutParameter( 1 java.sql.Types.VARCHAR); <SPECULATION> BTW because you are using index for result you may need to use index-oriented setXXX methods and provide a full parameter list. </SPECULATION> I got ""Invalid column index"" on line with cs.registerOutParameter( 0 java.sql.Types.VARCHAR); @Kerb. Sorry it's 1 I've corrected the answer.  You register the function result as if it were the first parameter. Obviously this shifts the numbering of the actual parameters. Your already existing line cs.registerOutParameter(1 OracleTypes.VARCHAR); is all it takes. After the call get your result like this: String result = cs.getString(1); I got exception ""The number of parameter names does not match the number of registered praremeters"" on line with ""cs.execute();"" .... p.s. I've just forgotten to remove this line when posted the code. IIRC you cannot mix positional and named parameters you it seems like you have to use positional parameters for the whole statement i.e. cs.setInt(2 ProcTypes.SELECT); cs.setLong(3 tableId);"
1089,A,"Which should I close first the PreparedStatement or the Connection? When using a PreparedStatement in JDBC should I close the PreparedStatement first or the Connection first? I just saw a code sample in which the Connection is closed first but it seems to me more logical to close the PreparedStatement first. Is there a standard accepted way to do this? Does it matter? Does closing the Connection also cause the PreparedStatement to be closed since the PreparedStatement is directly related to the Connection object? Where did you see it? Although according to the spec the statement should be closed when the connection is closed JDBC drivers have been seen to have issues with this so it is considered good practice to explicitly close the statement (and the result set). Close things in the inverse order you opened them. All things. The statement. I would expect you to close (in order) the result set the statement the connection (and check for nulls along the way!) i.e. close in reverse order to the opening sequence. If you use Spring JdbcTemplate (or similar) then that will look after this for you. Alternatively you can use Apache Commons DbUtils and DbUtils.close() or DbUtils.closeQuietly(). Indeed. Some JDBC drivers will throw an exception on closing a result set or statement after the connection is closed. That's correct. To the point: close the *resources* in **reversed order** as you acquired them.  The following procedures should be done (in order) The ResultSet The PreparedStatement The Connection. Also it's advisable to close all JDBC related objects in the finally close to guarantee closure. //Do the following when dealing with JDBC. This is how I've implemented my JDBC transactions through DAO.... Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { conn = .... ps = conn.prepareStatement(...); //Populate PreparedStatement rs = ps.executeQuery(); } catch (/*All relevant exceptions such as SQLException*/Exception e) { logger.error(""Damn stupid exception: ""  e); } finally { if (rs != null) { try { rs.close(); rs = null; } catch (SQLException e) { logger.error(e.getMessage() e.fillInStackTrace()); } } if (ps != null) { try { ps.close(); ps = null; } catch (SQLException e) { logger.error(e.getMessage() e.fillInStackTrace()); } } try { if (conn!= null && !conn.isClosed()){ if (!conn.getAutoCommit()) { conn.commit(); conn.setAutoCommit(true); } conn.close(); conn= null; } } catch (SQLException sqle) { logger.error(sqle.getMessage() sqle.fillInStackTrace()); } } You can see I've checked if my objects are null and for connection check first if the connection is not autocommited. Many people fail to check it and realise that the transaction hasn't been committed to DB. All of that finally boilerplate should be condensed into a utility method (for example `DBUtils.close(rs ps conn);`). Also the advice about autocommit depends on the situation. Sometimes when there is an exception you do not want to commit at all. Also the effort of explicitly setting the reference to null is almost always unneeded because it will get dereferenced when the method exits which is hopefully very soon after this otherwise the method is likely too long. @Yishai - thanks I was wondering about that. @Yishai yes I forgot to mention that if there are exceptions and autocommit is off you can do a rollback...Thanks for showing this."
1090,A,"clarification of cursors in oracle with jdbc I have situation where a 3rd party open source product I am using is running out of cursors in Oracle and receiving the error: java.sql.SQLException: ORA-01000: maximum open cursors exceeded My maximum cursors is set to 1000 and I am trying to figure out if the code that is reaching this limit is doing something incorrectly or if I simply need to increase my limit. After some investigation I found a point in the code at which a ResultSet is created thereby increasing my open cursor count by 1. However that ResultSet is soon closed after use.... BUT the cursor count remains where it is. I was able to reproduce the logic in a simple JDBC application outside of the 3rd party open source project. package gov.nyc.doitt.cursor; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; public class CursorTest { public static void main(String[] args) { Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { Class.forName(""oracle.jdbc.driver.OracleDriver""); conn = DriverManager.getConnection(""jdbc:oracle:thin:@myhost:1537:mydb"" ""username"" ""password""); // as expected: there are 0 cursors associated with my session at this point ps = conn.prepareStatement(""select my_column from my_table where my_id = ?""); ps.setInt(1 86); // as expected: there are 0 cursors associated with my session at this point rs = ps.executeQuery(); // opens 1 cursor // as expected: there is 1 open cursor associated with my session at this point } catch (Throwable t) { t.printStackTrace(); } finally { // as expected: there is 1 open cursor associated with my session at this point try { rs.close(); } catch (SQLException e) { System.err.println(""Unable to close rs""); } // not expected: there is still 1 open cursor associated with my session at this point try { ps.close(); } catch (SQLException e) { System.err.println(""Unable to close simplePs""); } // not expected: there is still 1 open cursor associated with my session at this point try { conn.close(); } catch (SQLException e) { System.err.println(""Unable to close conn""); } // as expected: at this point my session is dead and so are all the associated cursors } } } I found some Oracle documentation that made me think that all open cursors would be closed if you closed our ResultSet and PreparedStatements but my open cursors seem to be hanging around. See this FAQ (http://download.oracle.com/docs/cd/B10501%5F01/java.920/a96654/basic.htm#1006509) which says ""Closing a result set or statement releases the corresponding cursor in the database."" Only based on my test that doesn't seem to happen so I must be lacking some basic understanding. Can anyone explain how Oracle handles cursors or point me to some documentation that will enlighten me? Thanks! The code looks fine i think.Are you using the driver provided by oracle itself. Your code looks perfectly OK. Quite long time ago I've encountered a similar problem. As far as I remember the issue was in delayed garbage collection. Database cursor won't close until garbage collector finds and releases the appropriate object. If statements are created frequently you can run into this issue. Try to invoke garbage collector manually from time to time: Runtime r = Runtime.getRuntime(); r.gc(); just to check this supposition. I am using the latest driver. This is just test code to help me understand how it works so no coding changes are being made to accommodate anything. If I move all of the PreparedStatement and ResultSet logic into separate method then the cursors go away after the PreparedStatement and ResultsSet are closed but before the connection is closed (in otherwords once they are out of scope). Thanks! This more sounds like a bug in the JDBC driver used. If you can upgrade the JDBC driver to the latest compatible version available. This is preferred above changing the JDBC coding to fit an implementation-specific (mis)behaviour."
1091,A,"PLSQL JDBC: How to get last row ID? What's PLSQL (Oracle) equivalent of this SQL server snippet? BEGIN TRAN INSERT INTO mytable(content) VALUES (""test"") -- assume there's an ID column that is autoincrement SELECT @@IDENTITY COMMIT TRAN In C# you can call myCommand.ExecuteScalar() to retrieve the ID of the new row. How can I insert a new row in Oracle and have JDBC get a copy of the new id? EDIT: BalusC provided a very good starting point. For some reason JDBC doesn't like named parameter binding. This gives ""Incorrectly set or registered parameters"" SQLException. Why is this happening?  OracleConnection conn = getAppConnection(); String q = ""BEGIN INSERT INTO tb (id) values (claim_seq.nextval) returning id into :newId; end;"" ; CallableStatement cs = (OracleCallableStatement) conn.prepareCall(q); cs.registerOutParameter(""newId"" OracleTypes.NUMBER); cs.execute(); int newId = cs.getInt(""newId""); @Aren - `max(n)+1` doesn't scale and doesn't work in a multi-user environment. Select the max of the id field + 1 ? You can use getGeneratedKeys() By explicitly selecting key field. Here is a snippet:  // change the string to your connection string Connection connection = DriverManager.getConnection(""connection string""); // assume that the field ""id"" is PK and PK-trigger exists String sql = ""insert into my_table(id) values (default)""; // you can select key field by field index int[] colIdxes = { 1 }; // or by field name String[] colNames = { ""id"" }; // Java 1.7 syntax; try-finally for older versions try (PreparedStatement preparedStatement = connection.prepareStatement(sql colNames)) { // note: oracle JDBC driver do not support auto-generated key feature with batch update // // insert 5 rows // for (int i = 0; i < 5; i++) // { // preparedStatement.addBatch(); // } // // int[] batch = preparedStatement.executeBatch(); preparedStatement.executeUpdate(); // get generated keys try (ResultSet resultSet = preparedStatement.getGeneratedKeys()) { while (resultSet.next()) { // assume that the key's type is BIGINT long id = resultSet.getLong(1); assertTrue(id != 0); System.out.println(id); } } } refer for details: http://docs.oracle.com/cd/E16655_01/java.121/e17657/jdbcvers.htm#CHDEGDHJ  Normally you would use Statement#getGeneratedKeys() for this (see also this answer for an example) but this is as far (still) not supported by the Oracle JDBC driver. Your best bet is to either make use of CallableStatement with a RETURNING clause: String sql = ""BEGIN INSERT INTO mytable(id content) VALUES (seq_mytable.NEXTVAL() ?) RETURNING id INTO ?; END;""; Connection connection = null; CallableStatement statement = null; try { connection = database.getConnection(); statement = connection.prepareCall(sql); statement.setString(1 ""test""); statement.registerOutParameter(2 Types.NUMERIC); statement.execute(); int id = statement.getInt(2); // ... Or fire SELECT sequencename.CURRVAL after INSERT in the same transaction: String sql_insert = ""INSERT INTO mytable(content) VALUES (?)""; String sql_currval = ""SELECT seq_mytable.CURRVAL FROM dual""; Connection connection = null; PreparedStatement statement = null; Statement currvalStatement = null; ResultSet currvalResultSet = null; try { connection = database.getConnection(); connection.setAutoCommit(false); statement = connection.prepareStatement(sql_insert); statement.setString(1 ""test""); statement.executeUpdate(); currvalStatement = connection.createStatement(); currvalResultSet = currvalStatement.executeQuery(sql_currval); if (currvalResultSet.next()) { int id = currvalResultSet.getInt(1); } connection.commit(); // ... For named binding use an ORM like Hibernate/JPA. Basic JDBC doesn't support it. Hi BalusC thanks for the help. Can you take a look at my edit see if you can solve that other mystery? You need to specify the placeholder index not the column name. Replace `""newId""` by `2` in `registerOutParameter()`. Do you mean ""SELECT seq_mytable.CURRVAL from dual"" instead of ""SELECT CURRVAL(seq_mytable)""? @Patrick: Oh drat I had PostgreSQL SQL syntax in mind I'll update (previously PostgreSQL used to have the same problem of not supporting [`Statement#getGeneratedKeys()`](http://stackoverflow.com/questions/1915166/jdbc-how-can-we-get-inserted-record-id-in-java/1915197#1915197) so that the same ""workaround"" was necessary but since about a year ago they finally fixed their JDBC driver to support it). In practice I have a long insert statement with 15-some parameters which I prefer having named binding if I could. JDBC will complain about having mixed binding if I use question mark. Do I must go with ordinal binding when out-parameter is used? I believe there is nothing incorrect with the JDBC specification from Oracle Driver's perspective. The prepareStatement call needs to be told to return auto-generated keys like this. conn.prepareStatement(sql Statement.RETURN_GENERATED_KEYS); @Subramanian: So it has changed recently? So the example in the linked answer works for Oracle now? Note that both answers are posted 2 years ago.  You can use Oracle's returning clause. insert into mytable(content) values ('test') returning your_id into :var; Check out this link for a code sample. You need Oracle 10g or later and a new version of JDBC driver."
1092,A,sql server 2005:how to connect to sql server 2005 on platform jboss 3.0? i have deployed my application on jboss 3.I have restored a database back up of sql server 2000 on sql server 2005.then i have downloaded the jr file jdbc connection to sql server 2005.My connection string setting is as below.  <datasources> <local-tx-datasource> <jndi-name>SLBDataSource</jndi-name> <connection-url>jdbc:sqlserver:\\RAVIGARG\SQLSERVER2005;DatabaseName=Sahil_test_12_12_09;SelectMethod=cursor</connection-url> <driver-class>com.microsoft.jdbc.sqlserver.SQLServerDriver</driver-class> <min-pool-size>10</min-pool-size> <max-pool-size>100</max-pool-size> <user-name>sa</user-name> <password>sa</password> </local-tx-datasource> But i am getting exception as below.  WARN [JBossManagedConnectionPool] Throwable while attempting to get a new connection: org.jboss.resource.JBossResourceException: Could not create connection; - nested throwable: (java.sql.SQLException: [Microsoft][SQLServer 2000 Driver for JDBC] Unable to connect. Invalid URL.) Just a suggestion: you might want to use jTDS instead. It is much more stable than Microsoft's drivers delivers great performance and works with all kinds of flavors of SQL Server. We've been using it on our production servers for years. This would be the appropriate connect string: jdbc:jtds:<server_type>://<server>[:<port>][/<database>][;<property>=<value>[;...]] You can find out everything about driver names etc. in the jTDS FAQ.  According to Building the Connection URL the general form of a connection url is jdbc:sqlserver://[serverName[\instanceName][:portNumber]][;property=value[;property=value]] So if RAVIGARG is ther server name try something like this instead (note the forward slashes): jdbc:sqlserver://RAVIGARG\SQLSERVER2005;databaseName=Sahil_test_12_12_09;SelectMethod=cursor PS: According to the stracktrace you are using a JDBC driver for SQL Server 2000. This is not the root cause of the problem but maybe you should consider upgrading it as you are using SQL Server 2005. If you do so note that the driver class name is com.microsoft.sqlserver.jdbc.SQLServerDriver so update your <driver-class> accordingly. See SQL Server 2005 JDBC Driver Documentation. Thanks.I have replaced jar file for jdbc driver in lib of jboss but i think i need to make change for jdbc driver somewhere else too.can u pls tell me where shd i make change to upgrade jdbc driver to 2005. I think you need to update your driver-class. I've updated my answer.
1093,A,"Connection Pooling over New Connection instance per Thread (JDBC) I am creating a multi-threaded application. However I have experienced lots of unexpected behavior from my application when I have one connection object serving all threads. I am in a dilemma. Should I let every thread create use and dispose its own connection object or should I use a connection pool? I have tried connection pooling which makes the application painfully shower. However my intuition is that if I let every thread create its own connection object I might get a ""too many connection"" error. Please let me know if there is any way to assist in this. Regards. Regardless of the threading issue you should definitely go for a connection pool. It will greatly increase connecting performance. Then to the threading issue this is indeed a major problem. The normal JDBC idiom is to acquire and close all resources in the shortest possible scope. I.e. all should happen in the very same method block. The problem symptoms which you're describing confirms that you aren't closing those resources properly. Closing should always happen regardless of whether the connection is coming from a pool or not. Closing a non-pooled connection will prevent it from being timed-out by the database when it's been hold open for a too long time. Closing a pooled connection will actually release it back to the pool and make it available for the next lease. Here's how the normal JDBC idiom look like for the case of a INSERT. public void create(Entity entity) throws SQLException { // Declare. Connection connection = null; PreparedStatement statement = null; try { // Acquire. connection = database.getConnection(); statement = connection.prepareStatement(SQL_CREATE); // Use. statement.setSomeObject(1 entity.getSomeProperty()); // ... statement.executeUpdate(); } finally { // Close. if (statement != null) try { statement.close(); } catch (SQLException logOrIgnore) {} if (connection != null) try { connection.close(); } catch (SQLException logOrIgnore) {} } } You're welcome. Don't forget to mark the answer accepted. See also http://stackoverflow.com/faq :) Hi BalusC Thanks for your response. My threads are now dealing with their own connection object closing their defined ResultSet and Statement objects. This solved the ""too many connection"" problem. I also solved the threading issue by introducing a locking mechanism. I introduced custom startstoppause and resume methods in all my threads. Three threads can only be active at given time. - main ""producer"" and ""worker"". I have many workers but one ""producer"" Here is the pseudo code for the algorithm 1. Start Main Thread 2. Start the Producer Thread 3. Start while-true loop 4. While producer has not paused main thread sleep for x time 5. Start a worker who will pick the data that concerns him/her :) 6. While worker is working main thread sleep for x time 7. end while-true loop"
1094,A,"JDBC connection for a background thread being closed accessing in Websphere I have an application running in Websphere Portal Server inside of Websphere Application Server 6.0 (WAS). In this application for one particular functionality that takes a long time to complete I am firing a new thread that performs this action. This new thread opens a new Session from Hibernate and starts performing DB transactions with it. Sometimes (haven't been able to see a pattern) the transactions inside the thread work fine and the process completes successfully. Other times however I get the errors below: org.hibernate.exception.GenericJDBCException: could not load an entity: [OBJECT NAME#218294] ... Caused by: com.ibm.websphere.ce.cm.ObjectClosedException: DSRA9110E: Connection is closed. Method cleanup failed while trying to execute method cleanup on ManagedConnection WSRdbManagedConnectionImpl@642aa0d8 from resource jdbc/MyJDBCDataSource. Caught exception: com.ibm.ws.exception.WsException: DSRA0080E: An exception was received by the Data Store Adapter. See original exception message: Cannot call 'cleanup' on a ManagedConnection while it is still in a transaction.. How can I stop this from happening? Why does it seem that WAS wants to kill my connections even though they're not done. Is there a way I can stop WAS from attempting to close this particular connection? Thanks I mentioned two possible causes in my other answer: 1. the hibernate.connection.release_mode optional parameter or 2. a problem with unmanaged threads. Now that I read this question I really start to think that your problem may be related to the fact that you're spawning your own threads. Since they aren't managed by the container connections used in these treads may appear as ""leaked"" (not closed properly) and I wouldn't be surprised if WAS tries to recover them at some point. If you want to start a long running job you should use a WorkManager. Don't spawn threads yourself. Thank you very much I will look into WorkManager do you know of any examples for this? @ferrari You could start here http://publib.boulder.ibm.com/infocenter/wasinfo/v6r1/index.jsp?topic=/com.ibm.websphere.express.doc/info/exp/asyncbns/concepts/casb_workmgr.html"
1095,A,"how to install JDBC and how to use it to connect to mysql? i am trying to install JDBC but i dont know how when you only have the jar file i copied it to my java ext folder but it keep giving me an error can anyone show me how to complete install the driver and use it? below is the codes that i used import java.sql.*; public class Test1 { public static void main (String[] args) { String url = ""jdbc:mysql://localhost:3306/sabayafr_sabmah""; String username = ""root""; String password = ""ma""; Connection connection = null; try { System.out.println(""Connecting database...""); connection = DriverManager.getConnection(url username password); System.out.println(""Database connected!""); } catch (SQLException e) { System.err.println(""Cannot connect the database!""); e.printStackTrace(); } finally { System.out.println(""Closing the connection.""); if (connection != null) try { connection.close(); } catch (SQLException ignore) {} } } } And below is the Response that i get Cannot connect to database server Update # 3 C:\Users\AlAsad\Desktop>java -cp .;mysql-connector-java-5.0.8-bin.jar Test1 Connecting database... Cannot connect the database! java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ sabayafr_sabmah at java.sql.DriverManager.getConnection(Unknown Source) at java.sql.DriverManager.getConnection(Unknown Source) at Test1.main(Test1.java:12) Closing the connection. As BalusC mentioned: please replace `System.err.println (""Cannot connect to database server"");` with `e.printStackTrace()` and post the exception. The library that contains the Driver (net.sourceforge.jtds.jdbc.Driver) needs to be on the classpath. Assuming you start your application with java Test1 then simply do java -cp .;driver.jar Test1 where 'driver.jar' should be exchanged with the filename (relative or full path) of your database driver lib. EDIT A classpath tutorial will exceed the comments section below this question. Please take a cup of coffee and look at this page. It will most likely help you to continue. Hey Andreas_D when i added to my java application `java -cp .;driver.jar my.product.Class` i get and error @Mahmoud - you know that my fragments are just examples to explain the general approach !? Copying the exact line into your environment will not work. i didn't copy the exact line i copied the method and changed to the real information but i keep not getting what is my.product.class at the end of the method Ah sorry replace `my.product.Class` with `Test1` (the class that contains the main method). Hey @Andreas_D i have update the question  Try putting your .jar file in the classpath.  You certainly have JDBC problems but the exception isn't telling you that. Read it again: Exception in thread ""main"" java.lang.NoClassDefFoundError: Test1 Caused by: java.lang.ClassNotFoundException: Test1 It's your Test1.class that it can't find not the JDBC driver. You should not be copying anything into the jre/lib/ext directory. That's for library extensions not JDBC JARs. It wasn't meant as a crutch for people who don't understand how CLASSPATH works. I'd write it more like the following. Those close methods will come in handy. When I run it on my machine adding the MySQL JDBC JAR to my CLASSPATH I get the following result: C:\java -classpath .\mysql-connector-java-5.1.6-bin.jar; persistence.utils.DatabaseUtils product: MySQL version: 5.1.24-rc-community major : 5 minor : 1 Here is the source code: package persistence.utils; import java.sql.Connection; import java.sql.DatabaseMetaData; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; public class DatabaseUtils { public static final String DRIVER = ""com.mysql.jdbc.Driver""; public static final String URL = ""jdbc:mysql://localhost:3306/contacts""; public static final String USERNAME = ""contacts""; public static final String PASSWORD = ""contacts""; public static void main(String[] args) { Connection connection = null; try { String driver = ((args.length > 0) ? args[0] : DRIVER); String url = ((args.length > 1) ? args[1] : URL); String username = ((args.length > 2) ? args[2] : USERNAME); String password = ((args.length > 3) ? args[3] : PASSWORD); connection = getConnection(driver url username password); DatabaseMetaData metaData = connection.getMetaData(); System.out.println(""product: "" + metaData.getDatabaseProductName()); System.out.println(""version: "" + metaData.getDatabaseProductVersion()); System.out.println(""major : "" + metaData.getDatabaseMajorVersion()); System.out.println(""minor : "" + metaData.getDatabaseMinorVersion()); } catch (Exception e) { e.printStackTrace(); } finally { close(connection); } } public static Connection getConnection(String driver String url String username String password) throws ClassNotFoundException SQLException { Connection connection = null; Class.forName(driver); connection = DriverManager.getConnection(url username password); return connection; } public static void close(Connection connection) { try { if (connection != null) { connection.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void close(Statement statement) { try { if (statement != null) { statement.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void close(ResultSet resultSet) { try { if (resultSet != null) { resultSet.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void rollback(Connection connection) { try { if (connection != null) { connection.rollback(); } } catch (SQLException e) { e.printStackTrace(); } } } Check the question edit history. He edited his question a lot of times removing/replacing the original coding and problems with every sort of new problem he encountered. +1 regardless for the effort of explaining the ""current"" problem :)  'I am trying to install JDBC' You don't have to install JDBC. It is part of the JDK & JRE.  You're trying to connect MySQL with the URL of a jTDS JDBC driver which is designed specifically for Microsoft SQL Server. This ain't ever going to work. Even not when you fix the current problem by placing the JAR file in classpath. You really need the MySQL JDBC driver. Also see this answer for a short but complete tutorial Hey @BalusC i totall understand i used that method but i am confused on how to install the driver to my class You need to add the JAR file containing the JDBC driver to the runtime classpath. The linked answer explains that in detail. If you're using an IDE just add JAR file as *Library* to *Build Path*. If you're using `java.exe` then you need to specify its path in `-cp` argument. The path should be either absolute e.g. `c:/path/to/mysql-connector.jar` or relative to current working directory e.g. `mysql-connector.jar` when the JAR file is in the same folder from where you execute the `java.exe`. I have updated my Question please look into it at the moment i am getting cant connect to database As per your edit: you should **never** suppress exceptions without a good reason. Add `e.printStackTrace()` or just `throw e` after `System.err.println()`. You'll get valuable information about the exception type and message. The `try` block namely contains several lines of code which can throw completely different exceptions. Apart from a missing driver the URL may for instance be wrong or the user may not be authorized. After adding `e.printStackTrace();` it appears that the drivers is still missing after adding `java -cp driver.jar Test1` Then the driver is not there where you expect it is or the path/filename is plain wrong. It's at least certainly not named `driver.jar`. It's something like `mysql-connector-java-5.1.7-bin.jar`. Download the ZIP file containing MySQL JDBC driver extract it and you'll see a JAR file. This needs to be added to the runtime classpath. sorry that was my mistake i was adding the wrong driver but still i am getting an error where i posted it up on update #2 Add the path of `Test1` to the classpath as well :) Assuming it's the current working directory add `.` and separate the classpath paths using semicolon `;`. I.e. `java -cp .;mysql-connector.jar Test1`. please look at the error on update #3 You forgot to load the driver using `Class#forName()`. Please look at [the linked answer](http://stackoverflow.com/questions/2839321/java-connectivity-with-mysql/2840358#2840358) for a short but complete tutorial. didn't understand? Run `Class.forName(""com.mysql.jdbc.Driver"");` *before* `DriverManager#getConnection()` call. It's in a separate `try` block in the linked answer. Please breathe deep and carefully take the steps from top to bottom. Don't hurry ;) You're welcome. Follow my answers and links to learn from me ;) you are the master THANK YOU THANK YOU a million time man now i can start with my project your the best and i hope to learn from you  On the other hand if you are using an IDE such as Netbeans or Eclipse you can add the jar file as a resource to the project. Your advice is correct but I hate it when people do things with IDEs that they don't understand. Everyone who uses Java ought to know command line and CLASSPATH."
1096,A,"Is there a portable way to have ""SELECT FIRST 10 * FROM T"" semantic? I want to read data in blocks of say 10k records from a database. I found Result limits on wikipedia and it seems obvious that this can't done with sql in a portable way. Another approach could be JdbcTemplate which offers many methods for queries but how could I decide that enough rows have been read. Through the callbacks like RowMapper and ResultSetExtractor it can't be indicated that enough data has been read. EDIT: I was looking for a solution for JdbcTemplate This post suggests to use setMaxRows which I had overlooked. If you want a portable way you need to move up an abstraction layer as there's no portable SQL way(not one that databases actually implement anyways) - and use ORM mappers like e.g hibernate. If you do need raw JDBC you'll have to write specific SQL for eache specific database - which is often the case anyway as writing 100% portabl SQL is pretty hard in all but the trivial cases. The last resort is to run the query without any restrictions and just iterate over the 10 first results you get back - though this doesn't leverage the database capabilities and would be quite bad if your query results in many rows.  There is an ANSI standard syntax from SQL:2008: SELECT t.* FROM TABLE t FETCH FIRST 10 ROWS ONLY ...but it's not supported on most databases at this time. I can understand why everyone breaks the standard on this. Why require four keywords when `LIMIT` is enough? @dan04: Now that's just plain crazy talk =) Hmmm. Another standard way that will be implemented so infrequently as to be off-standard.  Grab Hibernate or JPA. Both are familiar with various database dialects and will handle the nasty DB specifics under the hoods transparently. In Hibernate you can paginate using Criteria#setFirstResult() and Criteria#setMaxResults(). E.g. List users = session.createCriteria(User.class) .addOrder(Order.asc(""id"")) .setFirstResult(0) // Index of first row to be retrieved. .setMaxResults(10) // Amount of rows to be retrieved. .list(); In JPA you can do similar using Query#setFirstResult() and Query#setMaxResults(). List users = em.createQuery(""SELECT u FROM User u ORDER BY u.id""); .setFirstResult(0) // Index of first row to be retrieved. .setMaxResults(10) // Amount of rows to be retrieved. .getResultList(); Actually rather than having to do the whole mapping thing you can use the Dialect classes in Hibernate to modify SQL to include a limit. Dialect defines a getLimitString() method you can use to extract the mechanism for building limits for various DBs This is one of the beauties of ORM. In MySql you can also do this with the LIMIT command.  There is no portable way of doing that on plain SQL because different SQL Engines use different syntaxes for that. Use a Database Abstraction Layer or DBAL. http://en.wikipedia.org/wiki/Database_abstraction_layer http://jonasbandi.net/wiki/index.php/ORM_Solutions_for_Java  No. Thats why database abstraction layers like Hibernate contains SQL dialects where you choose the one to use with your database."
1097,A,What's the cause of (and treatment for) this java MySQL exception? I'm getting the following exception when executing the first preparedstatement after a period of inactivity: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure The last packet successfully received from the server was 2855054 milliseconds ago. The last packet sent successfully to the server was 123 milliseconds ago. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) at java.lang.reflect.Constructor.newInstance(Unknown Source) at com.mysql.jdbc.Util.handleNewInstance(Util.java:406) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1074) at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3052) at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:2938) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3481) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1959) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2109) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2648) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2077) at com.mysql.jdbc.PreparedStatement.executeQuery(PreparedStatement.java:2228) This only shows up if my application hasn't communicated with MySQL recently. Subsequent queries execute normally. I suspect it's some kind of timeout issue but the periods of inactivity are way below the 8 hour timeout for MySQL. Any suggestions? I'm getting the following exception when executing the first preparedstatement after a period of inactivity This is just my guess - the MySQL connection is closed be default after some time of inactivity since database connections are valuable assets so they should have been managed well by code. Check the code regards the database connection control and you may find the answer there. Although by MySQL timeout setting the timeout value is 8 hours - it is still possible in your code (or in someone else's code?) the connection is to be closed after a certain time of inactivity.  Are you using a connection pool? If so you can just turn on connection pool checking/monitoring so you'll be ensured that your client thread gets a working MySQL connection each time. Most pools have a way of specifying a low-effort piece of SQL to execute before a connection is borrowed or sometimes even in the background during idle periods (for better performance at the risk of some bad connections being issued to client threads). Also w.r.t. the time < 8h issue does MySQL count idleness from the last packet received or the last significant event (a query etc.)? I recall seeing in the MySQL driver code that there's a heartbeat signal implemented. After doing some searching I decided to use c3p0 which seems to have solved the problem. Thanks for the suggestions. I'm not using a connection pool as it seemed unnecessary but maybe I was wrong. Is there a pool implementation you recommend? Apache's DBCP (http://commons.apache.org/dbcp/) is pretty good and includes the functionality you're looking for. As both a positive and negative it works independently of any other software components one is using. If you're working with an app server of any sort it probably has connection pooling pre-integrated along with lifecycle events (start my pool kill my pool).
1098,A,"Guice JDBC and managing database connections I'm looking to create a sample project while learning Guice which uses JDBC to read/write to a SQL database. However after years of using Spring and letting it abstract away connection handling and transactions I'm struggling to work it our conceptually. I'd like to have a service which starts and stops a transaction and calls numerous repositories which reuse the same connection and participate in the same transaction. My questions are: Where do I create my Datasource? How do I give the repositories access to the connection? (ThreadLocal?) Best way to manage the transaction (Creating an Interceptor for an annotation?) The code below shows how I would do this in Spring. The JdbcOperations injected into each repository would have access to the connection associated with the active transaction. I haven't been able to find many tutorials which cover this beyond ones which show creating interceptors for transactions. I am happy with continuing to use Spring as it is working very well in my projects but I'd like to know how to do this in pure Guice and JBBC (No JPA/Hibernate/Warp/Reusing Spring) @Service public class MyService implements MyInterface { @Autowired private RepositoryA repositoryA; @Autowired private RepositoryB repositoryB; @Autowired private RepositoryC repositoryC; @Override @Transactional public void doSomeWork() { this.repositoryA.someInsert(); this.repositoryB.someUpdate(); this.repositoryC.someSelect(); } } @Repository public class MyRepositoryA implements RepositoryA { @Autowired private JdbcOperations jdbcOperations; @Override public void someInsert() { //use jdbcOperations to perform an insert } } @Repository public class MyRepositoryB implements RepositoryB { @Autowired private JdbcOperations jdbcOperations; @Override public void someUpdate() { //use jdbcOperations to perform an update } } @Repository public class MyRepositoryC implements RepositoryC { @Autowired private JdbcOperations jdbcOperations; @Override public String someSelect() { //use jdbcOperations to perform a select and use a RowMapper to produce results return ""select result""; } } To inject a data source you probably don't need to be bound to a single data source instance since the database you are connecting to features in the url. Using Guice it is possible to force programmers to provide a binding to a DataSource implementation (link) . This data source can be injected into a ConnectionProvider to return a data source. The connection has to be in a thread local scope. You can even implement your thread local scope but all thread local connections must be closed & removed from ThreadLocal object after commit or rollback operations to prevent memory leakage. After hacking around I have found that you need to have a hook to the Injector object to remove ThreadLocal elements. An injector can easily be injected into your Guice AOP interceptor some thing like this:  protected void visitThreadLocalScope(Injector injector DefaultBindingScopingVisitor visitor) { if (injector == null) { return; } for (Map.Entry Binding> entry : injector.getBindings().entrySet()) { final Binding binding = entry.getValue(); // Not interested in the return value as yet. binding.acceptScopingVisitor(visitor); } } /** * Default implementation that exits the thread local scope. This is * essential to clean up and prevent any memory leakage. * * The scope is only visited iff the scope is an sub class of or is an * instance of {@link ThreadLocalScope}. */ private static final class ExitingThreadLocalScopeVisitor extends DefaultBindingScopingVisitor { @Override public Void visitScope(Scope scope) { // ThreadLocalScope is the custom scope. if (ThreadLocalScope.class.isAssignableFrom(scope.getClass())) { ThreadLocalScope threadLocalScope = (ThreadLocalScope) scope; threadLocalScope.exit(); } return null; } } Make sure you call this after the method has been invoked and closing the connection. Try this to see if this works.  I would use something like c3po to create datasources directly. If you use ComboPooledDataSource you only need instance (pooling is done under the covers) which you can bind directly or through a provider. Then I'd create an interceptor on top of that one that e.g. picks up @Transactional manages a connection and commit/ rollback. You could make Connection injectable as well but you need to make sure you close the connections somewhere to allow them to be checked into the pool again.  If your database change infrequently you could use the data source that comes with the database's JDBC driver and isolate the calls to the 3rd party library in a provider (My example uses the one provided by the H2 dataabse but all JDBC providers should have one). If you change to a different implementation of the DataSource (e.g. c3PO Apache DBCP or one provided by app server container) you can simply write a new Provider implementation to get the datasource from the appropriate place. Here I've use singleton scope to allow the DataSource instance to be shared amongst those classes that depend on it (necessary for pooling). public class DataSourceModule extends AbstractModule { @Override protected void configure() { Names.bindProperties(binder() loadProperties()); bind(DataSource.class).toProvider(H2DataSourceProvider.class).in(Scopes.SINGLETON); bind(MyService.class); } static class H2DataSourceProvider implements Provider<DataSource> { private final String url; private final String username; private final String password; public H2DataSourceProvider(@Named(""url"") final String url @Named(""username"") final String username @Named(""password"") final String password) { this.url = url; this.username = username; this.password = password; } @Override public DataSource get() { final JdbcDataSource dataSource = new JdbcDataSource(); dataSource.setURL(url); dataSource.setUser(username); dataSource.setPassword(password); return dataSource; } } static class MyService { private final DataSource dataSource; @Inject public MyService(final DataSource dataSource) { this.dataSource = dataSource; } public void singleUnitOfWork() { Connection cn = null; try { cn = dataSource.getConnection(); // Use the connection } finally { try { cn.close(); } catch (Exception e) {} } } } private Properties loadProperties() { // Load properties from appropriate place... // should contain definitions for: // url=... // username=... // password=... return new Properties(); } } To handle transactions a Transaction Aware data source should be used. I wouldn't recommend implementing this manually. Using something like warp-persist or a container supplied transaction management however it would look something like this: public class TxModule extends AbstractModule { @Override protected void configure() { Names.bindProperties(binder() loadProperties()); final TransactionManager tm = getTransactionManager(); bind(DataSource.class).annotatedWith(Real.class).toProvider(H2DataSourceProvider.class).in(Scopes.SINGLETON); bind(DataSource.class).annotatedWith(TxAware.class).to(TxAwareDataSource.class).in(Scopes.SINGLETON); bind(TransactionManager.class).toInstance(tm); bindInterceptor(Matchers.any() Matchers.annotatedWith(Transactional.class) new TxMethodInterceptor(tm)); bind(MyService.class); } private TransactionManager getTransactionManager() { // Get the transaction manager return null; } static class TxMethodInterceptor implements MethodInterceptor { private final TransactionManager tm; public TxMethodInterceptor(final TransactionManager tm) { this.tm = tm; } @Override public Object invoke(final MethodInvocation invocation) throws Throwable { // Start tx if necessary return invocation.proceed(); // Commit tx if started here. } } static class TxAwareDataSource implements DataSource { static ThreadLocal<Connection> txConnection = new ThreadLocal<Connection>(); private final DataSource ds; private final TransactionManager tm; @Inject public TxAwareDataSource(@Real final DataSource ds final TransactionManager tm) { this.ds = ds; this.tm = tm; } public Connection getConnection() throws SQLException { try { final Transaction transaction = tm.getTransaction(); if (transaction != null && transaction.getStatus() == Status.STATUS_ACTIVE) { Connection cn = txConnection.get(); if (cn == null) { cn = new TxAwareConnection(ds.getConnection()); txConnection.set(cn); } return cn; } else { return ds.getConnection(); } } catch (final SystemException e) { throw new SQLException(e); } } // Omitted delegate methods. } static class TxAwareConnection implements Connection { private final Connection cn; public TxAwareConnection(final Connection cn) { this.cn = cn; } public void close() throws SQLException { try { cn.close(); } finally { TxAwareDataSource.txConnection.set(null); } } // Omitted delegate methods. } static class MyService { private final DataSource dataSource; @Inject public MyService(@TxAware final DataSource dataSource) { this.dataSource = dataSource; } @Transactional public void singleUnitOfWork() { Connection cn = null; try { cn = dataSource.getConnection(); // Use the connection } catch (final SQLException e) { throw new RuntimeException(e); } finally { try { cn.close(); } catch (final Exception e) {} } } } } That gets me quite a bit of the way there. The question still remains about when to take the connection out of the datasource and share it amongst the repositories and safely closing it afterwards. A connection should only be taken from the repository for the period which it is required. I.e. generally while the transaction is alive. Within your code you should always get and close the connection in the same method. For transactions you should rely on a data source that is transaction aware and will internally associate the connection with a thread local to provide transaction support."
1099,A,What is JDBC? What is JDBC and where can I start learning about? I know it's a way to access databases with Java but what problems does it solve? Is it an ORM (or does it try to be)? Does it abstract away differences between databases at the syntax level? What does it do? and what does it not do? Java Database Connectivity (JDBC) is an API for the Java programming language that defines how a client may access a database. It provides methods for querying and updating data in a database. JDBC is oriented towards relational databases.  You've practically answered your own question. It provides a common interface for accessing databases which means that regardless of the nuances of individual databases or how they are implemented your API calls are the same. It is not an ORM.  JDBC is a driver that allows you to access database. It provides you with a very raw way to access the database using SQL. Its primary function is to allow you (the user) to run SQL commands on the database. It is not an ORM and never will be. The sun website http://java.sun.com/docs/books/tutorial/jdbc/ has a nice tutorial for JDBC. If you are interested in a ORM try http://www.hibernate.org/.  No JDBC isn't an ORM. It's the Java Database Connectivity API and basically it provides a database-agnostic access layer with a provider model (so that new database drivers can be added easily). Vendors can add more functionality for specific database features if they wish but developers can ignore those features if they wish to work with multiple databases. There's no mapping involved - just modeling for connections (and pools) prepared statements stored procedures result sets etc.
1100,A,Enumerate Open JDBC Connections? How do I enumerate/count all open JDBC connections? I've seen this thread which doesn't answer my question. My interest is in writing test code in which the object being tested (call it ConnectionUser) maintains its own connection. In my tests I want to do things like verify that instantiating ConnectionUser doesn't open a connection and that calling ConnectionUser.open results in one open connections. I'm not interested in enumerating/counting connections in the production code itself or implementing a connection pool. I've thought about using something like jmockit to verify invocations of the static DriverManager.getConnection method but would prefer something less abstract - i.e have the driver just give me a list of all open connections. How do I enumerate/count all open JDBC connections? If you are not using a wrapper class around DriverManager then you can't. I've thought about using something like jmockit to verify invocations of the static DriverManager.getConnection method but would prefer something less abstract - i.e have the driver just give me a list of all open connections. Maybe... but the driver won't give you that information. Actually if you want to test your code in isolation then using mocks is the way to go. After all how do you know the driver is not lying to you :) So indeed I'd use JMockit to replace the DriverManager and mock the static method calls and make the required verifications.
1101,A,"Tomcat6 MySql JDBC Datasource configuration I've always used Spring's dependency injection to get datasource objects and use them in my DAOs but now I have to write an app without that. With Spring I can write something like this: <bean id=""dataSource"" class=""org.springframework.jdbc.datasource.DriverManagerDataSource""> <property name=""driverClassName"" value=""com.mysql.jdbc.Driver"" /> <property name=""url"" value=""jdbc:mysql://127.0.0.1/app?characterEncoding=UTF-8"" /> <property name=""username"" value=""u"" /> <property name=""password"" value=""p"" /> </bean> But how can I use datasource in my DAOs without Spring or anything? I'm using servlets and JSPs only. Performance is very important factor. You can declare your data source as a JNDI object and retrieve a datasource via a JNDI lookup: DataSource ds = (DataSource) envCtx.lookup(""jdbc/EmployeeDB""); as documented here and here. That's as bare-bones as you can get so from there on performance is completely up to you. You're welcome. :) Thanks for this too.  Believe it or not people were writing applications before Spring and some are still not using it :) In your case you could use Tomcat connection pool (and there is a complete configuration example for MySQL in the documentation). Let me summarize it: First put your driver in $CATALINA_HOME/lib. Then configure a JNDI DataSource in Tomcat by adding a declaration for your resource to your Context: <Context path=""/DBTest"" docBase=""DBTest"" debug=""5"" reloadable=""true"" crossContext=""true""> <!-- maxActive: Maximum number of dB connections in pool. Make sure you configure your mysqld max_connections large enough to handle all of your db connections. Set to -1 for no limit. --> <!-- maxIdle: Maximum number of idle dB connections to retain in pool. Set to -1 for no limit. See also the DBCP documentation on this and the minEvictableIdleTimeMillis configuration parameter. --> <!-- maxWait: Maximum time to wait for a dB connection to become available in ms in this example 10 seconds. An Exception is thrown if this timeout is exceeded. Set to -1 to wait indefinitely. --> <!-- username and password: MySQL dB username and password for dB connections --> <!-- driverClassName: Class name for the old mm.mysql JDBC driver is org.gjt.mm.mysql.Driver - we recommend using Connector/J though. Class name for the official MySQL Connector/J driver is com.mysql.jdbc.Driver. --> <!-- url: The JDBC connection url for connecting to your MySQL dB. --> <Resource name=""jdbc/TestDB"" auth=""Container"" type=""javax.sql.DataSource"" maxActive=""100"" maxIdle=""30"" maxWait=""10000"" username=""javauser"" password=""javadude"" driverClassName=""com.mysql.jdbc.Driver"" url=""jdbc:mysql://localhost:3306/javatest""/> </Context> Declare this resource in your web.xml: <web-app xmlns=""http://java.sun.com/xml/ns/j2ee"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd"" version=""2.4""> <description>MySQL Test App</description> <resource-ref> <description>DB Connection</description> <res-ref-name>jdbc/TestDB</res-ref-name> <res-type>javax.sql.DataSource</res-type> <res-auth>Container</res-auth> </resource-ref> </web-app> And get the datasource with a JNDI lookup in your application: Context initCtx = new InitialContext(); Context envCtx = (Context) initCtx.lookup(""java:comp/env""); DataSource ds = (DataSource) envCtx.lookup(""jdbc/TestDB""); Connection conn = ds.getConnection(); ... use this connection to access the database ... conn.close(); Note that such lookup is usually coded in a ServiceLocator (when you can't have a a DI container or a framework inject it for you). Thanks a lot! I'll try it. It's beyond me why this didn't have at least a single upvote. @BalusC: Damn I'll never get that Unsung Hero badge! Just kidding of course thank you very much. Lol. You've got to have a [long journey](http://odata.stackexchange.com/stackoverflow/s/345/how-unsung-am-i). @BalusC If that ever happens I quit! @PascalThivent which location is preferable for the Context file  I used to get error with sybase I had missing META-INF folder in WebContent folder. Putting context.xml in that fixed the error Cannot create JDBC driver of class '' for connect URL 'null'... // www.abbulkmailer.com My context.xml looks like <Context path=""/reports"" docBase=""reports"" debug=""5"" reloadable=""true"" crossContext=""true""> <Resource name='jdbc/ASCSybaseConnection' auth='Container' type='javax.sql.DataSource' username='fdd' password='555' driverClassName='com.sybase.jdbc2.jdbc.SybDriver' maxActive='100' maxIdle='100' minIdle='10' removeAbandoned=""true"" removeAbandonedTimeout=""60"" testOnBorrow=""true"" logAbandoned=""true"" url='jdbc:sybase:Tds:1.3.4.5:654/DB'/> </Context>"
1102,A,"Parameterized Query: Check if field is in array of values in SELECT statement I'm trying to configure a parameterized query to the effect of: SELECT field1 FROM myTable WHERE field2 IN (1234) The database I'm using is Postgres. This query run successfully unparameterized but I'd like to use a parameterized query with a JdbcTemplate to fill in the list for valid field2 values (which are integers). Trying various values for var (""1234"" ""[1234]"" ""{1234}"" or ""(1234)"") I've tried variations on the query: myJdbcTemplate.query(""SELECT field1 FROM field2 IN (?)"" new Object[]{ var }) and myJdbcTemplate.query(""SELECT field1 FROM field2 IN (?::integer[])"" new Object[]{ var }) and also myJdbcTemplate.query(""SELECT field1 FROM field2 IN ?::integer[]"" new Object[]{ var }) On a side note resources that describe how to parameterize queries would also be really helpful. All of these queries throw PSQLExceptions that indicate the operator fails or that there's a type mismatch -- which seems reasonable as I can't figure out how to parameterize the query. I took another look at the manual it looks like to search arrays there's an alternative syntax something like: SELECT field1 FROM myTable WHERE field2 = ANY(ARRAY[1234]) Which can be parameterized as: myJdbcTemplate.query(""SELECT field1 FROM myTable WHERE field2 = ANY(?::integer[])"") new Object[]{ ""{1234}"" })  Take a look at the Spring Data Access web page particularly section 11.7.3 where using the NamedParameterJdbcTemplate to build an 'IN' clause is covered. e.g. NamedParameterJdbcTemplate jdbcTemplate = new NamedParameterJdbcTemplate(dataSource); String sql = ""select * from emp where empno in (:ids)""; List idList = new ArrayList(2); idList.add(new Long(7782)); idList.add(new Long(7788)); Map parameters = new HashMap(); parameters.put(""ids"" idList); List emps = jdbcTemplate.query(sql parameters new EmpMapper()); Thanks -- this is exactly what I was looking for.  I'm think you can't use parameters in this way only dynamic query.  query = ""SELECT field1 FROM field2 IN (""+paramStr+"")"" or if you has a perfomance or a query len issues you can fill temporary table with your params and then  create tempTable (param int) insert into tempTable values (1) insert into tempTable values (2) insert into tempTable values (3) insert into tempTable values (4) query = ""SELECT field1 FROM field2 IN (select param from tempTable)"""
1103,A,"Can I connect to SQL Server using Windows Authentication from Java EE webapp? I am currently investigating how to make a connection to a SQL Server database from my Java EE web application using Windows Authentication instead of SQL Server authentication. I am running this app off of Tomcat 6.0 and am utilizing the Microsoft JDBC driver. My connection properties file looks as follows: dbDriver = com.microsoft.sqlserver.jdbc.SQLServerDriver dbUser = user dbPass = password dbServer = localhost:1433;databaseName=testDb dbUrl = jdbc:sqlserver://localhost:1433 I have zero problems with connecting to a SQL Server database in this fashion when using SQL Server authentication. Is there any way I can retrieve the credentials of the user's Windows Authentication and use that authentication for SQL Server? UPDATE: I know in ASP.net there is a way to set up Windows Authentication for access to the webapp which is exactly what I am looking for except I want to pass that token off to SQL Server for access to the database. I do not think one can push the user credentials from the browser to the database (and does it makes sense ? I think not) But if you want to use the credentials of the user running Tomcat to connect to SQL Server then you can use Microsoft's JDBC Driver. Just build your JDBC URL like this: jdbc:sqlserver://localhost;integratedSecurity=true; And copy the appropriate DLL to Tomcat's bin directory (sqljdbc_auth.dll provided with the driver) MSDN > Connecting to SQL Server with the JDBC Driver > Building the Connection URL Why doesn't pushing user credentials from the browser to the database make sense? I think that multi-hop authentication is EXACTLY what the OP was looking for here. Given I'm 3 years late on this reply but I'd like to understand your rationale.  I was having issue with connecting to MS SQL 2005 using Windows Authentication. I was able to solve the issue with help from this and other forums. Here is what I did: Install the JTDS driver Do not use the ""domain= "" property in the jdbc:jtds:://[:][/][;=[;...]] string Install the ntlmauth.dll in c:\windows\system32 directory (registration of the dll was not required) on the web server machine. Change the logon identity for the Apache Tomcat service to a domain User with access to the SQL database server (it was not necessary for the user to have access to the dbo.master). My environment: Windows XP clinet hosting Apache Tomcat 6 with MS SQL 2005 backend on Windows 2003  look at http://jtds.sourceforge.net/faq.html#driverImplementation What is the URL format used by jTDS? The URL format for jTDS is: jdbc:jtds:<server_type>://<server>[:<port>][/<database>][;<property>=<value>[;...]] ... domain Specifies the Windows domain to authenticate in. If present and the user name and password are provided jTDS uses Windows (NTLM) authentication instead of the usual SQL Server authentication (i.e. the user and password provided are the domain user and password). This allows non-Windows clients to log in to servers which are only configured to accept Windows authentication. If the domain parameter is present but no user name and password are provided jTDS uses its native Single-Sign-On library and logs in with the logged Windows user's credentials (for this to work one would obviously need to be on Windows logged into a domain and also have the SSO library installed -- consult README.SSO in the distribution on how to do this). Very useful information - especially about the domain!  Unless you have some really compelling reason not to I suggest ditching the MS JDBC driver. Instead use the jtds jdbc driver. Read the README.SSO file in the jtds distribution on how to configure for single-sign-on (native authentication) and where to put the native DLL to ensure it can be loaded by the JVM. Question really is looking for the SSO (single sign on). @jim: if you have authentication based on Kerberos on Linux then you can have SSO but from I could find the only way to use it for MS SQL authentication on Linux is by DataDirect driver. Why is the JTDS driver preferable? I understand it does not support connection pooling which for me is essential. This is more work than it is worth and has consequences for performance. Microsoft's driver yielded roughly 20% performance gains alone when we replaced jTDS. In some very specific circumstances jTDS performs better and we use it for those. It's not a general solution and generally not worth the effort.  This actually works for me: Per the README.SSO that comes with the jtdsd distribution: In order for Single Sign On to work jTDS must be able to load the native SPPI library (ntlmauth.dll). Place this DLL anywhere in the system path (defined by the PATH system variable) and you're all set. ---- I placed it in my jre/bin folder I configured a port dedicated the sql server instance (2302) to alleviate the need for an instance name - just something I do. lportal is my database name. jdbc.default.url=jdbc:jtds:sqlserver://192.168.0.147:2302/lportal;useNTLMv2=true;domain=mydomain.local"
1104,A,How do I monitor a database for new entries? I have an application solution which is made up of a web app written in Python (using Django framework) and a Java application which runs on the server. The web application receives data and stores it into a database queue. The Java application is then to process the received data and also store the results in a database. My question is how can the Java application be notified that there is new data in the database? Right now it seems like I will have to regularly poll the database for new data. Is there any way around this? PS. I have considered running the web app using Jython and using the Observer pattern but my host does not support Servlets. Polling for this scenario is the usual way. Unless the database specifically supports it polling is the only option I know of. However if your concern is load on the Java server you could have another server that does nothing but polls for changes and then notifies your Java server when changes have occurred. I don't know if that is any better than doing a simple polling from the Java server (not knowing your specific problem space and hardware constraints). Hope that helps. Edit: after reading your statement again it seems like you are already doing a messaging like framework (with the queue in the java application) so the database change could simply be another message that goes into the queue. If it needs priority you could give the messages priority marks so that they get processed when they need to be processed. @Damien: Exactly. I was trying to get to that point and failed miserably in my description. Thanks for adding in the tip :) Thanks for your response. Yes it is a messaging framework but I do not have priorities for now. The users just should not wait too long to get a response. If I poll too often when load is light I feel like I'm wasting resources. If I poll less often when load is high users may start feeling the latency. I guess I'll have to find a good balance. Polling often is probably better if you're worried about performance try to optimize your database. I think the queue should be an empty table when there's no message (don't keep old records there). @Damien thanks for the tip.
1105,A,"Java - JDBC driver and MySQL database connection issues Ok - I found the driver version that goes with the database.. however now I get the following. Got an exception! Communications link failure due to underlying exception: ** BEGIN NESTED EXCEPTION ** java.net.ConnectException MESSAGE: Connection timed out: connect STACKTRACE: java.net.ConnectException: Connection timed out: connect at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333) at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195) at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366) at java.net.Socket.connect(Socket.java:525) at java.net.Socket.connect(Socket.java:475) at java.net.Socket.(Socket.java:372) at java.net.Socket.(Socket.java:215) at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:256) at com.mysql.jdbc.MysqlIO.(MysqlIO.java:271) at com.mysql.jdbc.Connection.createNewIO(Connection.java:2771) at com.mysql.jdbc.Connection.(Connection.java:1555) at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:285) at java.sql.DriverManager.getConnection(DriverManager.java:582) at java.sql.DriverManager.getConnection(DriverManager.java:185) at freelancebillingapp.customerInfoUI.jButton1MouseClicked(customerInfoUI.java:221) at freelancebillingapp.customerInfoUI.access$000(customerInfoUI.java:12) at freelancebillingapp.customerInfoUI$1.mouseClicked(customerInfoUI.java:59) at java.awt.AWTEventMulticaster.mouseClicked(AWTEventMulticaster.java:253) at java.awt.Component.processMouseEvent(Component.java:6266) at javax.swing.JComponent.processMouseEvent(JComponent.java:3255) at java.awt.Component.processEvent(Component.java:6028) at java.awt.Container.processEvent(Container.java:2041) at java.awt.Component.dispatchEventImpl(Component.java:4630) at java.awt.Container.dispatchEventImpl(Container.java:2099) at java.awt.Component.dispatchEvent(Component.java:4460) at java.awt.LightweightDispatcher.retargetMouseEvent(Container.java:4574) at java.awt.LightweightDispatcher.processMouseEvent(Container.java:4247) at java.awt.LightweightDispatcher.dispatchEvent(Container.java:4168) at java.awt.Container.dispatchEventImpl(Container.java:2085) at java.awt.Window.dispatchEventImpl(Window.java:2475) at java.awt.Component.dispatchEvent(Component.java:4460) at java.awt.EventQueue.dispatchEvent(EventQueue.java:599) at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:269) at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:184) at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:174) at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:169) at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:161) at java.awt.EventDispatchThread.run(EventDispatchThread.java:122) ** END NESTED EXCEPTION ** Last packet sent to the server was 1 ms ago. ** I forgot to add - I tried disabling my firewall (zonealarm) but that didn't have any effect. Wait a sec - you've got a mysql database open to the entire internet on a standard port? Are you *asking* to get hacked? And watch out for customers named ""Little Bobby Tables"". You're asking for an injection attack. This may not solve it but it tells you that someone else has had this problem. Make sure you have the precise version of JDBC driver to match your version of MySQL. I would strongly urge you to rewrite your code more like this. You aren't closing resources properly at all. Adapt it to your own needs. I created a local MySQL database on my machine and added a customer table. It worked just fine. package persistence; import java.sql.Connection; import java.sql.Driver; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.ResultSetMetaData; import java.sql.SQLException; import java.sql.Statement; import java.util.ArrayList; import java.util.LinkedHashMap; import java.util.List; import java.util.Map; public class DatabaseUtils { private static final String URL = ""jdbc:mysql://localhost:3306/contacts""; private static final String USERNAME = ""contacts""; private static final String PASSWORD = ""contacts""; public static final String SELECT_SQL = ""select customer_id name street city state zip phone url from customer order by customer_id""; public static final String INSERT_SQL = ""insert into customer(name street city state zip phone url) values(???????)""; public static void main(String[] args) { Connection connection = null; try { connection = getConnection(URL USERNAME PASSWORD); List<Map> rows = findAllCustomers(connection); for (Map row : rows) { System.out.println(row); } } catch (SQLException e) { e.printStackTrace(); } finally { close(connection); } } public static List<Map> findAllCustomers(Connection connection) throws SQLException { List<Map> rows = new ArrayList<Map>(); PreparedStatement st = null; ResultSet rs = null; try { st = connection.prepareStatement(SELECT_SQL); rs = st.executeQuery(); while (rs.next()) { rows.add(map(rs)); } } finally { close(rs); close(st); } return rows; } private static Map<String Object> map(ResultSet rs) throws SQLException { Map<String Object> row = new LinkedHashMap<String Object>(); ResultSetMetaData meta = rs.getMetaData(); int numColumns = meta.getColumnCount(); for (int i = 1; i <= numColumns; ++i) { String column = meta.getColumnName(i); Object value = rs.getObject(i); row.put(column value); } return row; } public static Connection getConnection(String url String username String password) throws SQLException { Driver driver = DriverManager.getDriver(url); DriverManager.registerDriver(driver); return DriverManager.getConnection(url username password); } public static void close(Connection connection) { try { if (connection != null) { connection.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void close(Statement st) { try { if (st != null) { st.close(); } } catch (SQLException e) { e.printStackTrace(); } } public static void close(ResultSet rs) { try { if (rs != null) { rs.close(); } } catch (SQLException e) { e.printStackTrace(); } } public void rollback(Connection connection) { try { if (connection != null) { connection.rollback(); } } catch (SQLException e) { e.printStackTrace(); } } }   /* Connection */ import com.mysql.jdbc.Connection; import java.sql.DriverManager; public class PersonalConnection { private String url = ""jdbc:mysql://localhost:3306/""; private String schema = ""database name""; private String uname = """"; private String password = """"; private Connection connection; public Connection openConnection() { try { try { DriverManager.registerDriver(new com.mysql.jdbc.Driver()); } catch (Exception ex) { } connection = (Connection) DriverManager.getConnection(url + schema uname password); } catch (Exception ex) { } return connection; } public void closeConneciton() { try { connection.close(); } catch (Exception ex) { } } } /* Servlet */ response.setContentType(""text/html;charset=UTF-8""); PrintWriter out = response.getWriter(); DetailsBean db = new DetailsBean(); String name = request.getParameter(""name""); String countryname = request.getParameter(""countryname""); String statename = request.getParameter(""statename""); db.setName(name); db.setCountry(countryname); db.setState(statename); DetailsManager dm = new DetailsManager(); String result = dm.insertDetailsManager(db); if (result.equals(""true"")) { /* RequestDispatcher rd = request.getRequestDispatcher(""StateDetails.jsp?name="" + db.getName()); rd.forward(request response);*/ response.sendRedirect(""StateDetails.jsp""); } else { out.print(result); } /* DAO */ /* * To change this template choose Tools | Templates * and open the template in the editor. */ import com.mysql.jdbc.Connection; import java.sql.PreparedStatement; import java.sql.ResultSet; public class DetailsDAO { private Connection connection; private PersonalConnection con; public DetailsDAO() { con = new PersonalConnection(); } public String insertRecordDAO(DetailsBean db) { int rowcount=0; try { connection=con.openConnection(); String query = ""INSERT INTO personal_details(user_namecountry_namestate_name) values(???);""; PreparedStatement ps = connection.prepareStatement(query); ps.setString(1 db.getName()); ps.setString(2 db.getCountry()); ps.setString(3 db.getState()); rowcount = ps.executeUpdate(); if(rowcount==1) { return ""true""; } else { return ""false""; } } catch (Exception ex) { return ex+""""; } finally { con.closeConneciton(); } } public ResultSet getGetails() throws Exception { connection=con.openConnection(); String query=""SELECT * from state_details""; PreparedStatement ps=connection.prepareStatement(query); ResultSet rs=ps.executeQuery(); return rs; } } /*Manager*/ /* * To change this template choose Tools | Templates * and open the template in the editor. */ import java.util.ArrayList; public class DetailsManager { DetailsDAO detdao = new DetailsDAO(); public String insertDetailsManager(DetailsBean db) { String rowcount = detdao.insertRecordDAO(db); return rowcount; } } /*Bean*/ /* * To change this template choose Tools | Templates * and open the template in the editor. */ public class DetailsBean { private String name; private String country; private String state; public String getCountry() { return country; } public void setCountry(String country) { this.country = country; } public String getName() { return name; } public void setName(String name) { this.name = name; } public String getState() { return state; } public void setState(String state) { this.state = state; } }  Can mysql accept network connections? When you connect with the ""mysql"" command line program you're not doing a network connection but when you do with JDBC you are making a network connection. Try using ""-h localhost"" in your mysql command line to see. Yes - the database is hosted on a godaddy server and I haven't had any problems connecting to this database or others hosted on the same server with other programs. I just reinstalled windows 7 and the jdbc driver I don't know if maybe something installed wrong? I've never had this error happen before. If it matters - I am using netbeans to build the program. Netbeans is immaterial. I wouldn't like being able to connect directly to a database over the Internet this way. @Jason I'd say then that @duffymo has it right and throwing random versions of the JDBC driver at the problem aren't going to help - you've got to get the one that came with that version of MySQL."
1106,A,"Implement a Tomcat Realm with LDAP authentication and JDBC authorization I'm working in a legacy environment where an LDAP server is used only for authentication and contains no roles and authorization is done against a database which contains the user-role mapping but no passwords. My plan is to implement a new Tomcat Realm by extending JNDIRealm and overriding the role methods to call an encapsulated JDBCRealm. My realm is declared in server.xml: <Realm className=""com.example.LdapJdbcRealm"" connectionURL=""ldap://ldaphost:389"" resourceName=""LDAP Auth"" userPattern=""uid={0} ou=Portal dc=example dc=com"" dbConnectionURL=""jdbc:oracle:thin:@oracledb:1521:dbname"" userTable=""db_user"" userNameCol=""user_id"" userRoleTable=""db_user_role_xref"" roleNameCol=""role_id"" /> This is a combination of the standard property names for JNDIRealm & JDBCRealm with a little change as they both use connectionURL. package com.example; import org.apache.catalina.Realm; import org.apache.catalina.Context; import org.apache.catalina.deploy.SecurityConstraint; import org.apache.catalina.connector.Request; import org.apache.catalina.connector.Response; import org.apache.catalina.realm.JNDIRealm; import org.apache.catalina.realm.JDBCRealm; import java.security.Principal; import java.io.IOException; public class LdapJdbcRealm extends JNDIRealm implements Realm { private JDBCRealm jdbcRealm = new JDBCRealm(); protected static final String info = ""com.example.LdapJdbcRealm/1.0""; protected static final String name = ""LdapJdbcRealm""; public String getDbConnectionURL() { return jdbcRealm.getConnectionURL(); } public void setDbConnectionURL(String dbConnectionURL) { jdbcRealm.setConnectionURL(dbConnectionURL); } public String getUserTable() { return jdbcRealm.getUserTable(); } public void setUserTable(String userTable) { jdbcRealm.setUserTable(userTable); } public String getUserNameCol() { return jdbcRealm.getUserNameCol(); } public void setUserNameCol(String userNameCol) { jdbcRealm.setUserNameCol(userNameCol); } public String getUserRoleTable() { return jdbcRealm.getUserRoleTable(); } public void setUserRoleTable(String userRoleTable) { jdbcRealm.setUserRoleTable(userRoleTable); } public String getRoleNameCol() { return jdbcRealm.getRoleNameCol(); } public void setRoleNameCol(String roleNameCol) { jdbcRealm.setRoleNameCol(roleNameCol); } public boolean hasResourcePermission(Request request Response response SecurityConstraint[]constraints Context context) throws IOException { return jdbcRealm.hasResourcePermission(request response constraints context); } public boolean hasRole(Principal principal String role) { return jdbcRealm.hasRole(principal role); } } This mostly seems to work the authorization returns a Principal from LDAP which has no roles as expected. That same Principal enters hasResourcePermission() and fails because it doesn't have the require roles in it. Clearly I'm missing some crucial code. I'm looking for solutions. I could try extending JDBCRealm and adding LDAP authentication but that seems like more work. I also believe that this LDAP authentication/DB authorization is not an uncommon pattern. Is there an alternative solution already available? It is not within my control to add roles to LDAP or passwords to the DB so those are not solutions for me. Thank you in advance for your help in this. Yes I'm working with Tomcat 6.0.18 I still get emails about this question with regular frequency so here is the final product for all to use. LdapJdbcRealm.java package org.apache.catalina.realm; import org.apache.catalina.Realm; import org.apache.catalina.Context; import org.apache.catalina.connector.Request; import org.apache.catalina.connector.Response; import org.apache.catalina.deploy.SecurityConstraint; import javax.naming.directory.DirContext; import java.io.IOException; import java.security.Principal; import java.util.List; /** * LdapJdbcRealm is a minimal implementation of a <b>Realm</b> to connect to LDAP * for authentication and a database for authorization.<br> * <br> * Example server.xml configuration fragment:<br> * <pre> &lt;Realm className=""org.apache.catalina.realm.LdapJdbcRealm"" connectionURL=""ldap://ldaphost:389"" resourceName=""LDAP Auth"" driverName=""oracle.jdbc.driver.OracleDriver"" userPattern=""uid={0} ou=Portal dc=example dc=com"" dbConnectionName=""dbuser"" dbConnectionPassword=""dbpassword"" dbConnectionURL=""jdbc:oracle:thin:@oracledb:1521:dbname"" userTable=""users"" userNameCol=""user_id"" userRoleTable=""user_role_xref"" roleNameCol=""role_id"" /&gt; * </pre> * * @author Greg Chabala * * Created by IntelliJ IDEA. * User: gchabala * Date: Jul 14 2009 * Time: 4:56:37 PM */ public class LdapJdbcRealm extends JNDIRealm implements Realm { /** * Encapsulated <b>JDBCRealm</b> to do role lookups */ private JDBCRealm jdbcRealm = new JDBCRealm(); /** * Descriptive information about this <b>Realm</b> implementation. */ protected static final String info = ""org.apache.catalina.realm.LdapJdbcRealm/1.0""; /** * Descriptive information about this <b>Realm</b> implementation. */ protected static final String name = ""LdapJdbcRealm""; /** * Set the all roles mode. * * @param allRolesMode authentication mode */ public void setAllRolesMode(String allRolesMode) { super.setAllRolesMode(allRolesMode); jdbcRealm.setAllRolesMode(allRolesMode); } /** * Return the username to use to connect to the database. * * @return username * @see JDBCRealm#getConnectionName() */ public String getDbConnectionName() { return jdbcRealm.getConnectionName(); } /** * Set the username to use to connect to the database. * * @param dbConnectionName username * @see JDBCRealm#setConnectionName(String) */ public void setDbConnectionName(String dbConnectionName) { jdbcRealm.setConnectionName(dbConnectionName); } /** * Return the password to use to connect to the database. * * @return password * @see JDBCRealm#getConnectionPassword() */ public String getDbConnectionPassword() { return jdbcRealm.getConnectionPassword(); } /** * Set the password to use to connect to the database. * * @param dbConnectionPassword password * @see JDBCRealm#setConnectionPassword(String) */ public void setDbConnectionPassword(String dbConnectionPassword) { jdbcRealm.setConnectionPassword(dbConnectionPassword); } /** * Return the URL to use to connect to the database. * * @return database connection URL * @see JDBCRealm#getConnectionURL() */ public String getDbConnectionURL() { return jdbcRealm.getConnectionURL(); } /** * Set the URL to use to connect to the database. * * @param dbConnectionURL The new connection URL * @see JDBCRealm#setConnectionURL(String) */ public void setDbConnectionURL(String dbConnectionURL) { jdbcRealm.setConnectionURL(dbConnectionURL); } /** * Return the JDBC driver that will be used. * * @return driver classname * @see JDBCRealm#getDriverName() */ public String getDriverName() { return jdbcRealm.getDriverName(); } /** * Set the JDBC driver that will be used. * * @param driverName The driver name * @see JDBCRealm#setDriverName(String) */ public void setDriverName(String driverName) { jdbcRealm.setDriverName(driverName); } /** * Return the table that holds user data.. * * @return table name * @see JDBCRealm#getUserTable() */ public String getUserTable() { return jdbcRealm.getUserTable(); } /** * Set the table that holds user data. * * @param userTable The table name * @see JDBCRealm#setUserTable(String) */ public void setUserTable(String userTable) { jdbcRealm.setUserTable(userTable); } /** * Return the column in the user table that holds the user's name. * * @return username database column name * @see JDBCRealm#getUserNameCol() */ public String getUserNameCol() { return jdbcRealm.getUserNameCol(); } /** * Set the column in the user table that holds the user's name. * * @param userNameCol The column name * @see JDBCRealm#setUserNameCol(String) */ public void setUserNameCol(String userNameCol) { jdbcRealm.setUserNameCol(userNameCol); } /** * Return the table that holds the relation between user's and roles. * * @return user role database table name * @see JDBCRealm#getUserRoleTable() */ public String getUserRoleTable() { return jdbcRealm.getUserRoleTable(); } /** * Set the table that holds the relation between user's and roles. * * @param userRoleTable The table name * @see JDBCRealm#setUserRoleTable(String) */ public void setUserRoleTable(String userRoleTable) { jdbcRealm.setUserRoleTable(userRoleTable); } /** * Return the column in the user role table that names a role. * * @return role column name * @see JDBCRealm#getRoleNameCol() */ public String getRoleNameCol() { return jdbcRealm.getRoleNameCol(); } /** * Set the column in the user role table that names a role. * * @param roleNameCol The column name * @see JDBCRealm#setRoleNameCol(String) */ public void setRoleNameCol(String roleNameCol) { jdbcRealm.setRoleNameCol(roleNameCol); } @Override public SecurityConstraint[] findSecurityConstraints(Request request Context context) { return jdbcRealm.findSecurityConstraints(request context); } @Override public boolean hasUserDataPermission(Request request Response response SecurityConstraint []constraints) throws IOException { return jdbcRealm.hasUserDataPermission(request response constraints); } @Override public boolean hasResourcePermission(Request request Response response SecurityConstraint[]constraints Context context) throws IOException { return jdbcRealm.hasResourcePermission(request response constraints context); } @Override public boolean hasRole(Principal principal String role) { return jdbcRealm.hasRole(principal role); } /** * Return a List of roles associated with the given User. If no roles * are associated with this user a zero-length List is returned. * * @param context unused. JDBC does not need this field. * @param user The User to be checked * @return list of role names * * @see JNDIRealm#getRoles(DirContext User) * @see JDBCRealm#getRoles(String) */ @Override protected List<String> getRoles(DirContext context User user) { return jdbcRealm.getRoles(user.username); } }  You haven't specified the version of Tomcat you're using so I'm going with 6.x here. It looks like you're delegating hasResourcePermission to JDBC while leaving both findSecurityConstraints and hasUserDataPermission in hands of JNDI. You should delegate all of them or none of them. Update: JNDIRealm calls protected getRoles(DirContext User) as part of its authenticate() method. You need to override that and forward it to JDBCRealm's getRoles(). Moving to package org.apache.catalina.realm worked very well. I had also neglected to specify a driver so I added getters and setters for that as well as DB user and password. All is working well now thank you. I've overridden findSecurityConstraints() & hasUserDataPermission() to call though JDBCRealm. However JDBCRealm's getRoles() is protected. How do you propose I call it? You have 3 choices: use reflection (`Method.setAccessible()` will help with `protected`) move your realm implementation to `org.apache.catalina.realm` package or forgo the JDBCRealm altogether and write your own code to retrieve roles from the database)."
1107,A,"java.sql.SQLException: OALL8 is in an inconsistent state On weblogic 9 We are getting this error ""java.sql.SQLException: OALL8 is in an inconsistent state "" when executing our web app on weblogic 9. The jdk used is 1.5 and database is Oracle10.2g We have switched out oracle drivers ojdbc14.jar with ojdbc5.jar. We have also added orai18n.jar. We have ensured that this change of jar occurs with the web app library as well as other weblogic server classpaths where ojdbc14.jar existed. The problem persists Any pointers would help regards Sameer The solution is to upgrade your jdbc driver to version 11.2 please check the link below: http://www.experts-exchange.com/Database/Oracle/Q_24893929.html"
1108,A,"java connectivity with mysql error I just started with the connectivity and tried this example. I have installed the necessary softwares. Also copied the jar file into the /ext folder.Yet the code below has the following error import java.sql.*; public class Jdbc00 { public static void main(String args[]){ try { Statement stmt; Class.forName(""com.mysql.jdbc.Driver""); String url = ""jdbc:mysql://localhost:3306/mysql"" DriverManager.getConnection(url""root"" ""root""); //Display URL and connection information System.out.println(""URL: "" + url); System.out.println(""Connection: "" + con); //Get a Statement object stmt = con.createStatement(); //Create the new database stmt.executeUpdate( ""CREATE DATABASE JunkDB""); stmt.executeUpdate( ""GRANT SELECTINSERTUPDATEDELETE"" + ""CREATEDROP "" + ""ON JunkDB.* TO 'auser'@'localhost' "" + ""IDENTIFIED BY 'drowssap';""); con.close(); }catch( Exception e ) { e.printStackTrace(); }//end catch }//end main }//end class Jdbc00 But it gave the following error D:\Java12\Explore>java Jdbc00 java.lang.ClassNotFoundException: com.mysql.jdbc.Driver at java.net.URLClassLoader$1.run(Unknown Source) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Unknown Source) at Jdbc00.main(Jdbc00.java:11) Could anyone please guide me in correcting this? The jar file that contains the MySQL driver class (com.mysql.jdbc.Driver) isn't being found on the classpath when you run your application. This is what the ClassNotFoundException is complaining about. You'll need to add it either to the CLASSPATH environment variable or using the classpath option when running Java. For example: java -cp mysql-connector-java-5.0.8-bin.jar Jdbc00 Use the name and location of whatever MySQL connector jar file you're using. (If you haven't already installed MySQL on localhost so your application has something to connect to you might have to do that too.)  As @Ash says the problem is that the Connector/J drivers are not on your classpath. You can download the latest version (5.0.12) from this page."
1109,A,slow sqlite insert using the jdbc drivers in java I just inserted 1million records into a simple sqlite table with five columns. It took a whooping 18 hours in java using the jdbc drivers! I did the same thing in python2.5 and it took less than a minute. The speed for select queries seem fine. I think this is an issue with the jdbc drivers. Is there a faster driver for sqlite3 in java? Speed of inserting large numbers of rows is important for my schema migration script and I'd rather not have to use an external script to do the migrations if I don't have to. EDIT: fixed with connection.setAutoCommit(false); thanks Mark Rushakoff for hinting me to the solution :) Did you have your queries autocommitted? That could explain why it took so long. Try wrapping them in a begin / end so that it doesn't have to do a full commit for every insert. This page explains begin/end transaction while the FAQ touches on inserts/autocommits. That did the trick thanks!  If you want to further optimize you can look into batching your insert queries together. So you can change 1 million inserts to 1000 inserts of 1000 batches.
1110,A,"Running a Java Thread in intervals I have a thread that needs to be executed every 10 seconds. This thread contains several calls (12 - 15) to a database on another server. Additionally it also accesses around 3 files. Consequently there will be quite a lot of IO and network overhead. What is the best strategy to perform the above? One way would be to use the sleep method along with a while loop but that would be a bad design. Will a class similar to Timer be helpful in this case? Also would it be better to create a couple of more threads (one for IO and one for JDBC) instead of having them run in one thread? Why is the sleep a bad design? Granted it won't be every 10 seconds rather every 10+n seconds. But you can't guarantee 10 seconds anyway if one of the passes takes 12 seconds to complete. If you're just trying to minimize load on the server it makes little difference whetehr it a sleep or timer. I was referring the sleep along with the while loop as a bad design. Since it might not be very intuitive to decide on the when and how of terminating the thread. I find that a ScheduledExecutorService is an excellent way to do this. It is arguably slightly more complex than a Timer but gives more flexibility in exchange (e.g. you could choose to use a single thread or a thread pool; it takes units other than solely milliseconds). ScheduledExecutorService executor = Executors.newSingleThreadScheduledExecutor(); Runnable periodicTask = new Runnable() { public void run() { // Invoke method(s) to do the work doPeriodicWork(); } }; executor.scheduleAtFixedRate(periodicTask 0 10 TimeUnit.SECONDS); If you were not using a single threaded executor I might be inclined to wrap the doPeriodicWork() call in a ""synchronized (this)"" block just to be safe. That would certainly protect; declaring doPeriodicWork as synchronized would accomplish the same thing and probably be a little cleaner. That being said there are probably smaller critical sections within doPeriodicWork that could be protected individually if moving to a thread pool.  Have a look at the Timer and TimerTask classes. They are exactly what you want. You can make a TimerTask implementation that takes your thread object in a constructor. The run method will then call the threads run method. // Perhaps something like this Timer t = new Timer(); t.scheduleAtFixedRate(yourTimerTask 0 10 * 1000); // Hopefully your task takes less than 12 seconds 12 ??????? - <- need that many ?'s to reach 10 chars minimum :-) oops while i was typing I was thinking 12 seconds.... ! . 10 Chars is just a suggestion! I just tried to enter ""! ."" and I get the dreaded ""Please enter at least 10 characters."" under the input box when I click on AddComment. It doesn't actually enter the comment. How'd you do that?? If you type !. you can trick the system. It seems to count space as a character and then remove extra ones when it feels like it. ! . Yeah you can't put spaces at the start or end they need to be in the middle! Who wrote this crap? :-) Heh Its a neat little trick though.  One option is to create a ScheduledExecutorService to which you can then schedule your job: ScheduledExecutorService ex = Executors.newSingleThreadScheduledExecutor(); ex.scheduleWithFixedDelay(...); If you did decide to have multiple threads then you can create a ScheduledExecutorService with more threads (again via the Executors class). In terms of how many threads and what you put in each thread in terms of performance I'd say this depends on: for your particular application can one thread genuinely ""do work"" while another one is waiting for I/O? would your multiple threads ultimately ""thrash the same resource"" (e.g. read from files in different locations on the same dsk) and thus slow one another down or would they be simultaneously hitting different resources?"
1111,A,"Oracle JDBC select with WHERE return 0 Similar question to: http://stackoverflow.com/questions/903488/strange-problem-with-jdbc-select-returns-null but people didn't ask for this. My code: public int myMethod(String day) throws SQLException{ String sql = ""Select count(*) from MyTable WHERE someColumn = "" + day; Connection connection = ConnFactory.get(); PreparedStatement prepareStatement = null; ResultSet resultSet = null; int ret = -1; try{ prepareStatement = connection.prepareStatement(sql); resultSet = prepareStatement.executeQuery(sql); if(resultSet.next()){ ret = resultSet.getInt(1); } } catch(SQLException sqle){ // closing statement & ResultSet log and throw exception } finally{ // closing statement & ResultSet } ConnFactory.kill(connection); return ret; } This code always return 0. I try to log sql before execution and try to run it in SQLdeveloper and get correct value (over 100). When I remove WHERE sql = ""Select count(*) from MyTable query return number of all rows in table. I use Oracle 10g with ojdbc-14.jar (last version from maven repo) and Java 6. If it returns 0 there are no rows matching your WHERE. Plain and simple. Run the same query in a client (e.g. SQLDeveloper) and see what the result is. karim79 is good answer you forgot add apostrophe signs in your ""day"" value String sql = ""Select count(*) from MyTable WHERE someColumn = '"" + day + ""'"";  day has not been quoted correctly I would suggest using a prepared statement like a prepared statement as follows: ... try { prepareStatement = connection.prepareStatement(""Select count(*) from MyTable WHERE someColumn = ?""); prepareStatement.setString(1day); ... is the same as: sql = ""Select count(*) from MyTable WHERE someColumn = '"" + day + ""'""; with several advantages over the latter (mainly security and performance). See: http://java.sun.com/docs/books/tutorial/jdbc/basics/prepared.html  First of all using sql like this is not advisable. Because it leads to SQL injection. In the future try using like below and use PreparedStatement to execute String sql = ""Select count(*) from MyTable WHERE someColumn = ? "" For your solution did you try String sql = ""Select count(*) from MyTable WHERE someColumn = '"" + day + ""'"";"
1112,A,"Error in getting Date input form user and storing in database using JSF I am developing a web application based on JSF technology. I use Eclipse as the IDE and using Apache Derby as a database. When getting user input I have one of the fields as a date field i.e Date of Birth. But when I update the database table I get error report.  Date Of Birth: <h:inputText value=""#{employeeBean.dob}""> <f:convertDateTime type=""date"" pattern=""yyyy-mm-dd""/> </h:inputText> Since the derby database accepts date in the format yyyy-mm-dd I give input in the same way and have also used the same format. This is the error I get.  Exception while setting value for expression : #{employeeBean.dob} of component with path : {Component-Path : [Class:javax.faces.component.UIViewRootViewId: /homepage.jsp] [Class: javax.faces.component.html.HtmlFormId: j_id_jsp_996426310_1] [Class: javax.faces.component.html.HtmlInputTextId: j_id_jsp_996426310_6]} Caused by: java.lang.IllegalArgumentException - Cannot convert 1/8/87 5:39 AM of type class java.util.Date to class java.sql.Date Some one help me with this. Apart from the problem your `yyyy-mm-dd` pattern is wrong. It's now saying `year-minute-day`. You want `year-Month-day`. Learn here about the right patterns: http://java.sun.com/javase/6/docs/api/java/text/SimpleDateFormat.html ya you were right.. And error identified by Bozho was also the reason for the problem. After changing both got the answer. thanks to both of u.. Since JSF uses java.util.Date and derby perhaps expects java.sql.Date you have to do something in order to acoomodate this gap: change the type of the managed bean property to java.util.Date if doing only the above doesn't work convert between the two before saving. This can be done with the following constructor (Note that I don't know how you are going to persist the object to the database so I'm guessing) java.sql.Date date = new java.sql.Date(jsfProvidedDate.getTime()); Correct that was the problem and I had the pattern also wrong as suggested by BalusC. I changed the type to java.util.Date stored the variable in a string with the desired pattern and stored in the database. :-) Thank you."
1113,A,"Problem reading special characters from teradata - JDBC I use teradata and the below query outputs ""Altlüd"" when run using a teradata client. select name as name from MYTABLE where selector=? Whereas I get ""Altl?d"" as the output when I try to execute the query using a java client(jdbc with teradata drivers). I am using ""UTF-8"" charset and I have also tried Latin charset with no luck. I have also tried this to troubleshoot. while (rs.next()) { System.out.println(rs.getString(1)); Reader rd = rs.getCharacterStream(1); int charr = rd.read(); while (charr >= 0) { System.out.println(charr + "" = "" + ((char) charr)); charr = rd.read(); } } And the output is Altl?dersdorf 65 = A 108 = l 116 = t 108 = l 65533 = ? 100 = d If you look at the output produced the int value for the spl character is 65533 which shouldn't be the case. Infact it returns 65533 for all the special characters. Any clues/pointers will be appreciated. Thanks!!! Chedine How to set charset as LATIN9_OA for teradata driver? Seems to be the Unicode Replacement character U+FFFD. JDBC client and server do not use the same encoding for characters. The client seems to try UTF-8 but the server does offer any non UTF format. I do not know teradata but you should look for any database and or server settings for the encoding and/or locale. Yes. Specifying the charset as LATIN9_OA solved the problem  Try to use CHARSET=UTF-16 as client side parameter. One easy way is to set LC_ALL = LANG = en_US.UTF-16 and then run your Java program."
1114,A,Hibernate for stored procedure access We have business restriction in accessing the database only through stored procedure calls. Caching is also not allowed. Is there value in using Hibernate framework where in you are not using the features like building object relationship based complex queries or caching? We are using considering using the lightweight jdbc option. Would you provide insight into why your company imposes this restriction? For instance if it is for performance reasons you can argue that Hibernate (actually your connection pool) caches PreparedStatements which mitigates this concern. The database serves as a backup facility on distributed system for a DB residing on mainframe. All access to mainframe DB is based on stored procedures written in COBOL. So access to backup facility wehn needed must mimic the real access. Hibernate's lazy loading and entity mapping still brings a lot of value to the table. I would go for it.  Hibernate makes sense if you're going to map objects to tables. I don't see how HQL can benefit you otherwise. I would look into JDBC or Spring JDBC instead.
1115,A,"Connection Pooling - How much of an overhead is it? I am running a webapp inside Webpshere Application Server 6.1. This webapp has a rules kind of engine where every rule obtains its very own connection from the websphere data source pool. So I see that when an use case is run for 100 records of input about 400-800 connections are obtained from the pool and released back to the pool. I have a feeling that if this engine goes to production it might take too much time to complete processing. Is it a bad practice to obtain connections from pool that frequently? What are the overhead costs involved in obtaining connections from pool? My guess is that costs involved should be minimal as pool is nothing but a resource cache. Please correct me if I am wrong. Usually the default connection pool and datasource properties are not always suitable for your production environment. You may need to tweak properties such as the ""Maximum connections"" and ""Statement cache size"" to values higher than 10. A connection pool is all about connection re-use. If you are holding on to a connection at times where you don't need a connection then you are preventing that connection from being re-used somewhere else. And if you have a lot of threads doing this then you must also run with a larger pool of connections to prevent pool exhaustion. More connections takes longer to create and establish and they take more resources to maintain; there will be more reconnecting as the connections grow old and your database server will also be impacted by the greater number of connections. In other words: you want to run with the smallest possible pool without exhausting it. And the way to do that is to hold on to your connections as little as possible. I have implemented a JDBC connection pool myself and although many pool implementations out there probably could be faster you are likely not going to notice because any slack going on in the pool is most likely dwarfed by the time it takes to execute queries on your database. In short: connection pools just love it when you return their connections. Or they should anyway. Don't reinvent the wheel. Use a good pool implementation instead - you will need it some day (oh stale connections hang? etc.) This can be a long discussion but the wheel was not reinvented. Rather a new wheel design was created with a performance profile distinct from all other existing wheels. Same reason we have multiple java.util.Map implementations ;-)  I think this is a poor design. Sounds like a Rete rules engine run amok. If you assume 0.5-1.0 MB minimum per thread (e.g. for stack etc.) you'll be thrashing a lot of memory. Checking the connections in and out of the pool will be the least of your problems. The best way to know is to do a performance test and measure memory wall times for each operation etc. But this doesn't sound like it'll end well. Sometimes I see people assume that throwing all their rules into Blaze or ILOG or JRules or Drools simply because it's ""standard"" and high tech. It's a terrific resume item but how many of those solutions would be better served by a simpler table-driven decision tree? Maybe your problem is one of those. I'd recommend that you get some data see if there's a problem and be prepared to redesign if the data tells you it's necessary.  Could you provide more details on what your rules engine does exactly? If each rule ""firing"" is performing data updates you may want to verify that the connection is being properly released (Put this in the finally block of your code to ensure that the connections are really being released). If possible you may want to consider capturing your data updates to a memory buffer and write to the database only at the end of the rule session/invocation. If the database operations are read-only consider caching the information. As bad as you think 400-800 connections being created and released to the pool is I suspect it'll be much much worse if you have to create and close 400-800 unpooled connections.  To really check if your pool is a bottle neck you should profile you program. If you find the pool is a problem then you have tuning problem. A simple pool should be able to handle 100K allocations per second or more or about 10 micro-seconds. However as soon as you use a connection it will take between 200 and 2000 micro-seconds to do something useful.  Connection pooling keeps your connection alive in anticipation if another user connects the ready connection to the db is handed over and the database does not have to open a connection all over again. This is actually a good idea because opening a connection is not just a one-go thing. There are many trips to the server (authentication retrieval status etc) So if you've got a connection pool on your website you're serving your customers faster. Unless your website is not visited by people you can't afford not to have a connection pool working for you.  The pool doesn't seem to be your problem. The real problem lies in the fact that your ""rules engine"" doesn't release connections back to the pool before completing the entire calculation. The engine doesn't scale well so it seems. If the number of database connections somehow depends on the number of records being processed something is almost always very wrong! If you manage to get your engine to release connections as soon as possible it may be that you only need a few connections instead of a few hundred. Failing that you could use a connection wrapper that re-uses the same connection every time the rules engine asks for one that somewhat negates the benefits of having a connection pool though... Not to mention that it introduces many multithreading and transaction isolation issues if the connections are read-only it might be an option. I once created a webapp that kept the connection alive all through the computation (passing it from function to function) so that each function won't have to get it's own connection from the pool. But it was a bad idea (as you point out) because there's a lot more going around in those functions than data retrieval. So yes free your connection as soon as possible."
1116,A,Is this the correct way to sort rows which have the same insert datetime? When I execute a query from my application (Java JDBC) it is returning the row with seq 83 first. But I want the row with seq 84. seq | dtCreated | 84 | 2009-09-14 16:16:23 | 83 | 2009-09-14 16:16:23 | 82 | 2009-09-14 16:15:01 | Is this query correct ? I'm interpreting this to mean that if there are ties in dtCreated sort using seq. select * from mim order by dtCreated DESC seq DESC; Yes you are inerpreting correct. An Example You can sort on multiple columns and you can sort different columns in different directions. For example to sort by type of animal in ascending order then by birth date within animal type in descending order (youngest animals first) use the following query: See the result from SELECT name species birth FROM pet ORDER BY species birth DESC provided in the example. Do you have a citation that backs this up ?
1117,A,Which jar to use for connecting to MS SQL server Can some one please guide me to understand which jar file i need to include in my application to be able to set up a jdbc connection with ms sql server. thanks in advance. The Microsoft SQL Server JDBC Driver version 2.0 provides sqljdbc.jar and sqljdbc4.jar class library files to be used depending on your preferred Java Runtime Environment (JRE) settings. sqljdbc4.jar class library requires a Java Runtime Environment (JRE) of version 6.0 or later.  sqljdbc.jar and sqljdbc4.jar class library files to be used depending on your preferred Java Runtime Environment (JRE) settings. For more information about which JAR file to choose see System Requirements for the JDBC Driver. Downloads for them can be found here  You can use jtds jar you will also need to add the dll/so to you java library path. +1 for open source  http://www.microsoft.com/downloads/details.aspx?FamilyID=99B21B65-E98F-4A61-B811-19912601FDC9&displaylang=en MS JDBC Driver. Has documentation.
1118,A,How can I set the IDENTITY_INSERT option for a JDBC PreparedStatement? I need to copy data into an MSSQLServer 2005 database table which has an identity column. I've seen how to disable the identity column by executing SET IDENTITY_INSERT <table> ON before the insert queries. How can I do this when I'm using PreparedStatements to do batch inserts and I can't change the statement during the operation? You can include SET IDENTITY_INSERT ON/OFF as part of the prepared statement. This way you only execute one command from the perspective of the client. Thanks but how? Say I have: INSERT INTO NAMES_TABLE (idname) VALUES (??) Which I want to use addBatch to do lots of inserts quickly. How would I modify this to do the SET... part as well?  D'oh. Easy figured it out I think. Create a Statement first execute SET IDENTITY_INSERT ON. Close statement. Create PreparedStatement do batch stuff close preparedstatement. Create a Statement execute SET IDENTITY_INSERT OFF. Close and tidy up. Welcome any refinements or advice on issues with this... Pat urself on the back :) You should be able to do this as part of one prepared statement you just have to separate the lines.
1119,A,"Unable to close JDBC resources! We are running a websphere commerce site with an oracle DB and facing an issue where we are running out of db connections. We are using a JDBCHelper singleton for getting the prepared statements and cosing the connections. public static JDBCHelper getJDBCHelper() { if (theObject == null){ theObject = new JDBCHelper(); } return theObject; } public void closeResources(Connection con PreparedStatement pstmt ResultSet rs){ try{ if(rs!=null){ rs.close();} }catch(SQLException e){ logger.info(""Exception closing the resultset""); }try{ if(pstmt!=null) { pstmt.close(); } }catch(SQLException e){ logger.info(""Exception closing the preparedstatement""); }try{ if(con!=null){ con.close(); } }catch(SQLException e){ logger.info(""Exception closing the connection""); } } However when we try getting the connection using a prepStmt.getConnection() for passing to the close resources after execution it throws an sql exception. Any idea why? Does the connection get closed immediately after execution? And is there something wrong in our use of the singleton JDBCHelper? EDIT Part of the code which makes the prepared statementexecutes and closes the connection PreparedStatement pstmt = jdbcHelper.getPreparedStatement(query); try{ //rest of the code int brs = pstmt.executeUpdate(); } finally{ try { jdbcHelper.closeResources(pstmt.getConnection()pstmt); } catch (SQLException e1) { logger.logp(Level.SEVERECLASS_NAMEmethodName""In the finally block - Could not close connection"" e1); } } This code seems to be written for single threaded operation only as it's lacking any synchronisation code. The getJdbcHelper() method for instance is likely to create two JdbcHelpers. If I'm not mistaken there's even no guarantee that a second thread will see theObject long after a primary thread has created it. Although they usually will by virtue of the architecture the JVM runs on. If you're running this inside a web server you're likely to be running into race issues where two threads are modifying your connection at the same time. Unless you rolled your own connection pool or something. Brian is right use one of the freely available libraries that solve this (hard) problem for you.  Your connection will most likely come from a pool and closing it actually will return the connection to the pool (under the covers). I think posting the code which gets the connection uses it and closes it via JDBCHelper will be of more use. Re. your singleton I'm not sure why you're using this since it doesn't appear to have anything to warrant it being a singleton. Check out Apache Commons DbUtils which does this sort of stuff and more besides. thanks... have updated with a part of the code...looks straightforward though"
1120,A,"Duplicate set of columns from one table to another table My requirement is to read some set of columns from a table. The source table has many - around 20-30 numeric columns and I would like to read only a set of those columns from the source table and keep appending the values of those columns to the destination table. My DB is on Oracle and the programming language is JDBC/Java. The source table is very dynamic - there are frequent inserts and deletes happen on it. Whereas at the destination table I would like to keep the data for at least 30 days. My Setup is described as below - Database is Oracle. Number of rows in the source table = 20 Million rows with 30 columns Number of rows in destinationt table = 300 Million rows with 2-3 columns The columns are all Numeric. I am thinking of not doing a vanilla JDBC connection open and transfer the data which might be pretty slow looking at the size of the tables. I am trying to take the dump of the selected columns of the source table using some sql like - SQL> spool on SQL> select c1c5c6 from SRC_Table; SQL> spool off And later use SQLLoader to load the data into the destination database. The source table is storing time series data and the data gets purged/deleted from source table within 2 days. Its part of OLTP environment. The destination table has larger retention period - 30days of data can be stored here and it is a part of OLAP environment. So the view on source table where view selects only set of columns from the source table does not work in this environment. Any suggestion or review comments on this approach is welcome. EDIT My tables are partitioned. The easiest way to copy data is to exchange partition netween tables *ALTER TABLE <table_name> EXCHANGE PARTITION <partition_name> WITH TABLE <new_table_name> <including | excluding> INDEXES <with | without> VALIDATION EXCEPTIONS INTO <schema.table_name>;* but since my source and destination tables have different columns so I think exchange partition will not work. Please supply some sample data 5-7 rows: what you have and what you want to get. Hundreds of *columns* in one table? That's bad mmmkay. I am new to the forum and not sure how to edit the main question to provide more information. Man I hope the column names aren't really c1 c5 and c6 Shamik okay you're loading an OLAP database with OLTP data. What's the acceptable latency? Does your OLAP need today's data before people come in to the office tomorrow morning or is it closer to real time. Saying the Inserts are ""frequent"" doesn't mean anything. Some of us are used to thousands of txns/sec - to others 1/sec is a lot. And you say there's a lot of data. Same idea. I've read people's post where they have HUGE tables with a couple million records. i have table with hundreds of billions of records. SO again. A real number is very helpful. Do not go with the trigger suggested by Schwern. If you believe your insert volume is large it means you've probably have had issues in that area. A trigger will just make it worse. Oracle provide lots of different choices for getting data from OLTP to OLAP. Instead of reinventing the wheel use something already written. Oracle Streams was BORN to do this exact job. You can roll your own streams with using Oracle AQ. You can capture inserted rows without a trigger by using either Database Change Notification or Change Data Capture. This is an extremely common problem which is why I've listed 4 technologies designed to solve it. Advanced Queuing Streams Change Data Capture Database Change Notification Start googling these terms and come back with questions on those. you'll be better off than building your own from the ground up or using triggers. The better question is is it overkill to rebuild streaming for just one table. You probably think it's overkill because you've not used it. It's just some calls to some packages. But if you want to roll your own start with AQ. That's very easy to setup. Hi Mark thanks for the comments. I was wondering whether straming is an overkill for just one table. But I would do more research on this.  On a tangential note you might want to look at Oracle's partitioning here and here. Partitioning enables tables and indexes to be split into smaller more manageable components and is a key requirement for any large database with high performance and high availability requirements. Oracle Database 11g offers the widest choice of partitioning methods including interval reference list and range in addition to composite partitions of two methods such as order date (range) and region (list) or region (list) and customer type (list). Faster Performance—Lowers query times from minutes to seconds Increases Availability—24 by 7 access to critical information Improves Manageability—Manage smaller 'chunks' of data Enables Information Lifecycle Management—Cost-efficient use of storage Partitioning the table into daily partitions would make archiving easier as described here Lowers **SOME** queries from minutes to seconds. Queries not using the partition key in the where clause will go in the opposite directions. Noted. Cheers Mark. That's correct. you can only exchange if EVERYTHING is identical... indexes compression not tablespace... etc. My tables are partitioned. The easiest way to copy data is to exchange partition but since my source and destination tables have different columns so I think exchange partition woould not work. Any comments?  The problem seems a little vague and frankly a little odd. The fact that there's hundreds of columns in a single table and that you're duplicating data within the database suggests a hosed database design. Rather than do it manually it sounds like a job for a trigger. Create an insert trigger on the source table to copy columns to the destination table just after they're inserted. Another possibility is that since it seems all you want is a slice of the data in your original table rather than duplicating it a cardinal sin of database design create a view which only includes the columns and ranges you want. Then just access that view like any other table. I'm willing the guess that the root of the problem is accessing just the information you want in your source table is too slow. This suggests you might be able to fix that with better indexing. Also your source table is probably just too damn wide. Since I'm not an Oracle person I leave the syntax of this as an exercise for the reader but the concept should be sound. Shamik.... TOTALLY AGREE! If copying data were a cardinal sin we'd not need ETL or Replication tools. the REAL Cardinal Sin is trying to create complex reports against OLTP databases. Those tend to be huge. Huge SQL Huge performance hogs. Even if it's not even if they were OLAP and OLTP sets of tables in the same database it's still not HOSED. You need to allow for the possibility that even those things which are 75% incorrect can still be used to great efficiency some of the time. @Mark I beg ignorance of OLAP/OLTP. A lot of detail was missing from the post when I responded. If the OP is stuck with some fixed schema that's one thing but when someone presents a solution which involves duplicating data and very wide table I immediately take a skeptical eye to the schema. Wait are you pushing data between two different *databases*?"
1121,A,"Error with varchar(max) column when using net.sourceforge.jtds.jdbc.Driver I have a MS SQL database running (MS SQL 2005) and am connecting to it via the net.sourceforge.jtds.jdbc.Driver. The query works fine for all the columns except one that is a varchar(max). Any ideas how to get around this issues? I am using the jdbc driver to run a data index into a SOLR implementation. (I do not control the database so the first prize solution would be where I can tweak the SQL command to get the desired results) Thanks What's the query? select b.Title  Permalink  Subject  PlainText  Tags  convert(nvarchar(50) m.CreationDate 127) as MessageCreationDate  convert(nvarchar(50) m.LastDateUPdated 127) as MessageLastDateUpdated  m.messageid FROM blog b (NOLOCK) inner join message m (NOLOCK) on b.BlogId = m.BlogId where b.deleted = 0 and m.deleted = 0 I have found what looks to be a answer. In setting up the driver for the connection to SQL server I did not specify useLobs=false. I am a bit worried about what this will mean for performance but at least for now it works. <dataSource driver=""net.sourceforge.jtds.jdbc.Driver"" url=""jdbc:jtds:sqlserver://server/database;useLOBs=false"" user=""user"" password=""password"" /> JDBC driver settings always seem very random to me great simple example! Had the same problem and this solution worked for me :). However I was interested in knowing why this worked and there is a great description at their site : http://jtds.sourceforge.net/faq.html  search for useLOBs if you want to know why :) Thanks a lot man..you have saved my life....  I had the same problem with connecting to MS SQL 2K3. The useLOBs=false did not work for me but changing the SELECT to CAST(Name AS varchar(255))'Name' worked for me."
1122,A,Where to store a DataSource resource in a Java web app? This is a rookie question. What's the best place to put @Resource private DataSource ds; in a web application? Do I put it in a servlet context listener or maybe there's a better place for it? Also do I create a new Connection object in my doGet()/doPost() or should I do it somewhere else? What's the best practice for stuff like this? Thank you! What's the best place to put @Resource DataSource in a web application? Do I put it in a servlet context listener or maybe there's a better place for it? In the very same class where you'd like to call DataSource#getConnection(). Also do I create a new Connection object in my doGet()/doPost() or should I do it somewhere else? You usually do that in a method of a DAO class where you'd like to interact with the DB in a try block where you close the Connection (and Statement and ResultSet if any) in the finally block. In a more abstracted and flexible setup you could also do DataSource#getConnection() in a DAO manager class or a transaction manager class.
1123,A,"Update more than one row atomically I need to execute a select and then update some of the rows in the ResultSet in an atomic way. The code I am using looks like (simplified): stmt = con.createStatement(ResultSet.TYPE_SCROLL_SENSITIVE ResultSet.CONCUR_UPDATABLE); rs = stmt.executeQuery(""SELECT ...""); while (rs.next()) { if (conditions_to_update) { rs.updateString(...); rs.updateRow(); } } Can I guarantee that the updates are going to be executed atomically ? If not how could I assure that ? What happens if any other process has changed the database row that you are updating via updateRow() ? Is there any way to lock the rows in the ResultSet ? ""What happens if any other process has changed the database row that you are updating via updateRow() ? Is there any way to lock the rows in the ResultSet ?"" In Oracle you can kinda mark certain rows for update by issuing the following SQL. select cola colB from tabA for update; The next transaction/thread/app that tries to update this row will get an exception. see this for more details -- http://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:4530093713805 Good Luck BR ~A  Use transactions.  There's probably a whole heap of technologies and concepts that come into play here and things start to get fairly sticky when you start considering multi-threaded / multi request applications. As Iassevk stated you should look into using Transactions to ensure the atomic nature of your updates - a very low-level example would be to do something along the lines of: ... con.setAutoCommit(false); try { while (rs.next()) { if (conditions_to_update) { rs.updateString(...); rs.updateRow(); } } con.setAutoCommit(true); } catch (Exception ex) { //log the exception and rollback con.rollback; } finally { con.close(); } All the updates would then be batched into the same transaction. If any of the updates generated an Exception (such as an invalid value or the connection failing part way through the results) the whole lot would be rolled back. (Finally added because I am a champion of it ;p ) This however won't address your second issue which is two competing methods trying to update the same table - a race condition. There are in my mind two main approaches here - each has it's merits and drawbacks. The easiest approach would be to Lock the table - this would require minimal code changes but has a pretty big drawback. Working on the assumption that as with most applications it's more read that write: locking the table will prevent all other users from viewing the data with the likelihood the code will hang waiting for the lock to release before the connection time-out kicks in and throws an exception. The more complex approach is to ensure that the methods for performing these updates are implemented in a thread-safe manner. To that end: All the updates for this table pass through a single Class That class implements a Singleton pattern or exposes the update methods as Static methods The update methods utilise the Synchronized keyword to prevent race conditions Thank you. I was looking for a method to lock the table a concrete row or even a single cell using JDBC (or at least standard SQL). I suppose that's not possible."
1124,A,"Best way to use a PostgreSQL database as a simple key value store I am being required to use a postgreSQL database and it will replace my current use of berkeleyDB. Although; I realize this is not an ideal situation it is beyond my control. So the question is... If you were required to make postgreSQL into a key value store how would you go about doing this while making it as efficient as possible? My values are byte arrays and my key's are strings I could impose some restrictions on the lengths of these strings. I assume I should use a blob for my value and primary key column holding the key but as I am just venturing into this journey I am curious if anyone in the stack overflow community has done this or if there are any specific 'gotchas' I should look out for. I am... absolutely astounded by the absurdity of this idea. You're new here aren't you :-) ... as am I. You have my sympathies OP. We are watching the genesis of a future article for dailywtf.com. :-( What does those byte arrays actually represent? File contents? Serialized objects? Others? They are actually serialized actionscript objects sent to a server... but the server code does not know or care what is in them. And yes I agree this is somewhat absurd to use a relational database as a key value store. But some of the advantages of using the database are still maintained such as efficient file io encryption user access restrictions etc... So is it really that crazy? Yes. http://www.metabrew.com/article/anti-rdbms-a-list-of-distributed-key-value-stores/ Thanks for the link... I would certainly like to use a true key value store if possible. I am not sure if any of these are approved to be used in a department of defense project and trying to get them approved is a concern as it is not a timely task. I will do a bit more searching. What do you need to store as a value ? Strings ? Ints ? Objects (e.g. serialized Java objects). A simple implementation would work with a 3 column table looking like: NAME(VARCHAR) TYPE(VARCHAR) VALUE(VARCHAR) (perhaps the TYPE is some enumeration). The above wouldn't work for binary data like serialised objects though and perhaps you need a BLOB there. Alternatively (and probably a much better idea) have you seen Apache Commons Configuration ? You can back that with a database (via JDBC) and you can store properties such that you retrieve them thus: // get a property called 'number' Double double = config.getDouble(""number""); Integer integer = config.getInteger(""number""); That may save you a lot of grief in terms of implementation. You may have a problem with saving binary data in that you'd have to serialise it prior to insertion and post-retrieval. But I've used this in the past for storing intsdoubles and serialised Java objects via XStream so I can confirm it works well.  The extension in Postgresql to properly do this is called hstore. It works in a similar fashion as you would expect other key-value store systems. Just load the extension. The syntax is unique but if you have ever used redis or mongo you will get it quickly. Don't make it harder than it is. I understand we often don't get to pick our tools and have to make do. Here is the document page: http://www.postgresql.org/docs/9.1/static/hstore.html This is the correct answer...  If you are forced to use relational database I would suggest to try to find structure in your data to take advantage of the fact since you forgo the advantage of speed you got with unstructured data and key-value store. The more structure you find the better advantage you get out of your predicament. Even if you only find structure in the keys. Also consider if you will only need sequential or random access to your data and in which ratio and structure your database by this requirement. Are you going to do queries on your values by type for example? Each of those questions could have effect on how you structure your database. One specific consideration about blobs in postgresql they are internally represented as pg_largetable (loid:oidpageno:int4data:bytea). The size of the chunks is defined by LOBBLKSIZE but typically 2k. So if you can use byte arrays in your table instead of blobs and limit size of your value/key pair under blocksize you can avoid this indirection through second table. You could also increase the block size if you have access to configuration of the database. I'd suggest to go looking for structure in data and patterns in data access and then ask your question again with more detail.  It really should be dependant on what the key will be. If it will always be a string under 255 characters then use a Varchar as yoru PK and then use a blob (assuming a large value) for the value. if it will always be a number use int etc. In other words need more info to really give you a good answer :)"
1125,A,"Unicode in Java EE and save question mark in database When I insert persian information using Java EE 6 (JSF and JPA) my information save question mark for example ""علی"" ===> ""???"" my database is Mysql and my table is UTF-8 . when insert persian data directly in database is correct and save correct. I know that with change one property in Java EE my problem go to solved but I don`t know where is it? I think that you need to set the following parameters in your connection URL: jdbc:mysql://host:port/db?useUnicode=true&characterEncoding=UTF-8 I change sun-resources.xml but not solved http://paste.ideaslabs.com/show/XWBCp5zl0Y @Jeus I suggest trying to isolate the problem. So write a simple class using JDBC to validate the connection URL. Once you'll get it working work on the app server configuration. looks like you added spaces in that JDBC URL that you shouldn't have. Remove the spaces e.g. do not write a space before and after the ? = and & and write UTF-8 instead of utf-8. i use JPA and i dont have problem in insert data correctly in database with query browser mysql but then insert with use my app insert ? in database @Jeus I understood that so the MySQL setup seems ok. But is it working from Java? No? Is it a problem with the driver? You don't know. Is it a problem with the app server setup? You don't know. So try to isolate the problem start with a simple Java class using JDBC to validate the behavior of the JDBC driver. Then work on the app server config. i test this and set this in sun-resource.xml but not solved i understand u and test all say u this is first app with jEE6 and already write other JSE app and this dosnt its problem with encoding . im run a already program for test again. and this work correct .  with change in my.cnf (mysql configure file) in /etc/mysql (linux) and add this 2 tag solved my problem default-character-set=utf8 default-collation=utf8_persian_ci I suspect a bug in the MySQL JDBC driver."
1126,A,"CallableStatement setString - Unsupported character(s)? I have a Java application decoding a UTF-8 encoded String received over the wire and saving it to a varchar column in my database (SQL Server 2000). I am saving the record using JDBC's CallableStatement (calling the setString method to set the parameter for this column). The problem I'm seeing is that a particular String has been written that contains ASCII value 0 (NUL). This suggests to me that SQL server cannot represent a particular Unicode character and the JDBC driver has decided to substitute in ASCII value 0 although I may be wrong. Has anyone else encountered this problem? Is there a mechanism I can use to cause the CallableStatement call to fail in this situation? Ideally I would like to guarantee that data has been saved exactly as specified or else ""fail fast"". My database character set is Latin1_General_AS_CS. Thanks in advance. Which JDBC driver are you using? Don't use Microsoft's use jTDS or something else. I'm using Microsoft's own driver. I will probably change it but don't want to risk any knock-on effects of doing this at the moment. To be honest changing from Microsoft's driver is the first thing I'd try - it has a very bad reputation - we use jTDS in our production systems. You need to be using 'NVARCHAR' type in the database.  Just a WAG but would using .setBytes(String parameterName byte[] x) do trick? The byte array would come from myString.getBytes(). You might want to try using using different character sets with getBytes() too."
1127,A,"Character encoding while reading data using Java-JDBC from Oracle database We have data stored in oracle 10g db which contains french character set. The requirement is to read the data and generate a output file using Java. I checked the validity of the data in Oracle db via SQL*plus and it looks good. From windows: set NLS_LANG=AMERICAN.AL32UTF8 sqlplus scott/tiger sql> select billing_address from MYTABLE t where ADDRESS_ID=1 ; billing_address ----------------------- MONTRÉAL QUÉ Now when I read the table from Java to generate a output file the character is all garbled and I see question marks in place of É. Is there any special encoding that I need to set when I try to read/write the data in Java. Am using the ojdbc14.jar and setting the encoding as UTF-8. Update: Here's my java code snippet.  Charset cs1 = Charset.forName(""UTF-8""); PreparedStatement pStmt = conn.prepareStatement(""select * from talbe where address_id=1""); ResultSet rs = pStmt.executeQuery(); Writer w = null; FileOutputStream fos = null; if(rs.next()) { String billingaddress = rs.getString(""BILLING_ADDRESS""); fos = new FileOutputStream(new File(""myout.dat"")); w = new BufferedWriter(new OutputStreamWriter(foscs1)); w.write(billingaddress); } Did you think about encoding the data when writing it to the output file? Attached herewith snippet of my java code. Charset cs1 = Charset.forName(""UTF-8""); PreparedStatement pStmt = conn.prepareStatement(""select * from table where address_id=1""); ResultSet rs = pStmt.executeQuery(); Writer w = null; FileOutputStream fos = null; if(rs.next()) { String billingaddress = rs.getString(""BILLING_ADDRESS""); fos = new FileOutputStream(new File(""myout.dat"")); w = new BufferedWriter(new OutputStreamWriter(foscs1)); w.write(billingaddress); } Actually the problem was with the initial charset that was set while loading the data into the oracle database. we changed the charset in the sql*loader control file and it works fine now. which charset did you changed to our charset is AL16UTF16 is it ok?  A couple of things to check... Your jdbc url should have ?useUnicode=true&characterEncoding=utf8 in it somewhere Your JVM should have all the different char-sets installed that you need Maybe something is happening in the code to write to file/read from file Can you post some of your java code if your problem still persists? Point 1 is MySQL JDBC driver specific. He's using Oracle. It's however a good direction to look the cause for."
1128,A,"SQl Query to Hibernate Query I have a MYSQL query that I use to retrieve random rows from a table. The query is : SELECT * FROM QUESTION WHERE TESTID=1 ORDER BY RAND() LIMIT 10; Now I need to change this query to Hibernate. Did a bit of Googling but couldn't find the answer. Can someone provide help on this. Thanks The random function is different between each underlying DB and is not a standard part of SQL92. Given that you will need to implement a SQLDialect for the given database type you are using. eg:  class PostgresSQLDialect extends org.hibernate.dialect.PostgreSQLDialect { PostgresSQLDialect() { super() registerFunction( ""rand"" new NoArgSQLFunction(""random"" Hibernate.DOUBLE) ); } } Then you will need to define that dialect in the config  hibernate { dialect='com.mycompany.sql.PostgresSQLDialect' }  According to this post you can do that : String query = ""from QUESTION order by newid()""; Query q = session.createQuery(query); q.setMaxResults(10); Not sure if it will work (especially for the random part) but you can try it :)"
1129,A,"How can I set a timeout on spring DriverManagerDataSource We are using DriverManagerDataSource from the Spring framework (version 2.5) to pool connections to Oracle. However it seems that these connections don't have any timeout defined - yesterday after emergency database restart we had a thread hanging on a socket read inside the database connection. How can I set the timeout to say 10 mins so that it raises an exception next time? If your Oracle driver implementation supports a timeout property you can pass it through to the underlying implementation via getConnectionProperties().put(key timeout) I'm assuming you realise that DriverManagerDataSource isn't a connection pool? From the docs: NOTE: This class is not an actual connection pool; it does not actually pool Connections. It just serves as simple replacement for a full-blown connection pool implementing the same standard interface but creating new Connections on every call. [..] If you need a ""real"" connection pool outside of a J2EE container consider Apache's Jakarta Commons DBCP or C3P0. You may also be interested in OCI Connection Pooling?  Oracle has a builtin connection pool: oracle.jdbc.pool.OracleDataSource. I recommend you use that directly. The reference for Oracle JDBC (10gR2 other versions will be similar) is in http://download.oracle.com/docs/cd/B19306_01/java.102/b14355/toc.htm. Points of interest: Configuration of data sources Statement caching Implicit connection caching (and specially timeout properties)  I ended up changing the bean in the Spring context in the following way: <bean id=""myDataSource"" class=""org.springframework.jdbc.datasource.DriverManagerDataSource"" autowire=""no""> <property name=""url"" value=""${jdbc.url}""/> <property name=""username"" value=""${jdbc.username}""/> <property name=""password"" value=""${jdbc.password}""/> <property name=""connectionProperties""> <props> <prop key=""oracle.net.READ_TIMEOUT"">60000</prop> </props> </property> </bean> I don't know if it works yet. Did not work for me!"
1130,A,"Do prepared statements slow down program conspicuously? I am writing a software that requires me to prepare statements and set the values execute the query and get results within a loop. This loop might have over 7000 cycles. If I use simple statements rather than prepared statements will the execution speed change greatly? Here is the pseudo code Prepare Statements Get a list from somewhere Iterate through the list get the prepared statements and do some db querying and close the new resources like result sets. populate a map using the result and values from the initial list Thanks. Performance is nice but the real win with PreparedStatements is the parameter binding can do done via the API rather than string concatenation. This is particularly useful for date types. Also prevents SQL injection attacks. @amber there is a preparation overhead which may take a while to buy back before the prepared statements is faster in wall time. @Thorbjørn Can you please explain a bit more. I believed the preparation time for Statement and PreparedStatement be same. Why do you believe that? There is simply more work to do for the database to prepare a prepared statement (placeholders internal datastructures to be kept etc) than for a simple statement. Some databases do a LOT of work hence the time spent may take longer to ""pay back"" in the optimization. However simply because of http://xkcd.com/327/ prepared statements are useful. Prepared statements are generally *faster* than regular queries if you're repeatedly running the same query. @Thorbjørn Ravn Andersen. First Hahaa for (http://xkcd.com/327/). You are right. A prepared statement will mean more work for the database server. The database server is already too busy with other transactions so I might resort to using simple statements. Thanks I believe your conclusion is incorrect. Prepared statements are FASTER then non-prepared statements if you repeatedly use the same statement with multiple sets of data. I'm unaware of a situation where this is not true. Once you've prepared a statement its sent to the DB server which then only has to accept the data each time you call it -- it doesn't have to reprocess the statement every time you bind new data. So the simple answer is: No. They don't. Actually if you execute a statement only once or twice the setup time of a prepared statement might outweigh the gain during execution:) I meant in his situation in general. His proposed scenario was ""iterating through a list"". I was unclear in my response. Edited my original post for clarity.  Prepared statement are faster for repetitive tasks. http://download.oracle.com/javase/tutorial/jdbc/basics/prepared.html : If you want to execute a Statement object many times it normally reduces execution time to use a PreparedStatement object instead.  Just some things which popped up : make sure you do not create the prepared statements in your loops. There is some overhead involved but pays back for itself after the 3rd query or so. Actually with large parameter list it might even be faster for a single query. Something which does speed up things considerably is running all your queries in a single (or a couple of large) transactions. If it are large datasets you might to 1000 queries per transaction or something similar. (Of course the semantics of your domain model must allow for this but in my experience that is almost always the case). The number of queries you can bunch up in a single transaction is somewhat database dependent so some experimentation and reading maybe required.  You might also consider retrieving multiple values per statement: SELECT id value FROM table WHERE id IN (? ? ? ? ? ?) This will be faster than individual queries. This is exactly what I was doing. My point was you could iterate through the list in steps of 10 or so items per database call."
1131,A,"What is the optimum number of sqls run in batch? I am trying to load the data in Oracle server remotely. I am doing ""executeBatch()"" for every 50 sqls that are added in batch. (thru JDBC) What is the optimum number of sqls run in batch? Is it unlimited? Quoted from oracle documentation If you are using parameterized SQL (you configure your Login by calling Login method bindAllParameters) the maximum batch writing size is the number of statements to batch (default: 100). If you are using dynamic SQL the maximum batch writing size is the size of the SQL string buffer in characters (default: 32000). There's no such thing as an ""universal optimal value"". Each situation has its optimal value which depends on a lot of things (including the probability a statement might fall the average time taken per statement the importance of the timing in your specific business situation etc.)"
1132,A,JDBC opening a new database session I just want to make sure that if I use the following I am opening a separate DB session and not resuing the same one (for testing I need individual sessions). Connection connection = DriverManager.getConnection(URLUSERPASSWORD); each time I do the above code I run my query then do a connection.close() So for example: while(some condition) { Connection connection = DriverManager.getConnection(URLUSERPASSWORD); //now use the connection to generate a ResultSet of some query connection.close(); } So each iteration of the loop (each query) needs its own session. Is this properly opening separte sessions as I need (and if not what would I need to add/change)? thanks If possible kindly add the code too The javadoc says: Attempts to establish a connection to the given database URL Slightly woolly language and I suspect that this is up to the JDBC driver but I'd be surprised if this did anything other than open a new connection. I suppose it's possible for a JDBC driver to perform connection pooling under the hood but I'd be surprised to see that. In the case of the Oracle JDBC driver this will open a new connection every time. This is a relatively slow process in Oracle you may want to consider using a connection pool (e.g. Apache Commons DBCP or c3p0) to improve performance. Exactly that ambiguous language is the reason I wasn't sure.. Oh ok great I am using Oracle..so I guess my code is fine then.
1133,A,ORM solutions (JPA; Hibernate) vs. JDBC I need to be able to insert/update objects at a consistent rate of at least 8000 objects every 5 seconds in an in-memory HSQL database. I have done some comparison performance testing between Spring/Hibernate/JPA and pure JDBC. I have found a significant difference in performance using HSQL.. With Spring/Hib/JPA I can insert 3000-4000 of my 1.5 KB objects (with a One-Many and a Many-Many relationship) in 5 seconds while with direct JDBC calls I can insert 10000-12000 of those same objects. I cannot figure out why there is such a huge discrepancy. I have tweaked the Spring/Hib/JPA settings a lot trying to get close in performance without luck. I want to use Spring/Hib/JPA for future purposes expandability and because the foreign key relationships (one-many and many-many) are difficult to maintain by hand; but the performance requirements seem to point towards using pure JDBC. Any ideas of why there would be such a huge discrepancy? You might want to rename this question as the title isn't very descriptive of the actual question. What would you suggest? All that mapping ... it can get a little bit expensive with all the arcane logic and all the reflection and consistency-checking that it has to do. The point of mapping is not to boost performance of course. Typically you take a performance hit. But what you lose in performance you (can) gain many times over in developer productivity consistency testability reliability and so many more coveted attributes. Typically when you need the extra performance and you don't want to give up mapping you drop in some more hardware.  Never use one technology for all problems. Depending on the problem decide what technology to use. Of course jpa or hibernate is slower than jdbc. jdbc is on lower level than jpa. Also a db professional with jdbc can write more optimized sql than jpa. If you gave critical point where speed is required jpa is not your choise.  As a minimum you need to do batch inserts in Hibernate: http://www.hibernate.org/hib_docs/reference/en/html/batch.html Saves a lot of round-trip time. And as Justice mentioned the primary goal of Hib is not computer performance but developer performance. Having said that it's usually possible to achieve comparable (not equal but not that much worse) to JDBC results. It may seen the docs have moved. Try here http://docs.jboss.org/hibernate/core/3.3/reference/en/html/batch.html Also this is mentioned by the docs but easy to miss. Batch mode will be disabled ignored if you are doing inserts and working with entities which have an auto-generated primary key.  We have similar experience comparing Hibernate with JDBC in batch mode (Statement#executeBatch()). Basically it seems like Hibernate just doesn't do that well with bulk operations. In our case the Hibernate implementation was fast enough on our production hardware. What you may want to do is to wrap your database calls in a DAO giving your application a consistent way of accessing your data. Implement your DAOs with Hibernate where it's convenient and with JDBC where the performance requirements call for it. Did you do Hib batch as well? In my tests Hib batches and JDBC batch were almost identical.  Hibernate maintains a first-level cache of objects to use in dirty checking as well as to act as a Unit of Work and Identity Map. This adds to the overhead especially in bulk-type operations. For bulk operatons you may want to investigate StatelessSessions that don't maintain this state. Docs may have moved. http://docs.jboss.org/hibernate/core/3.3/reference/en/html/batch.html
1134,A,"Beanshell jdbc connection i want to connect to my database using beanshell script. my code works with java but beanshell doesn't work with the same code. Class not found exception will be thrown. does it have other usage or can't i connect to database with beanshell? Thanks Bilal @ Plínio Pantaleão the code is like this addClassPath(""C:\\mysql-connector-java-5.1.13\\mysql-connector-java-5.1.13-bin.jar""); import com.mysql.jdbc.Driver; import java.sql.Connection; Connection conn = null; Class.forName(""com.mysql.jdbc.Driver"").newInstance(); and the exception is java.lang.ClassNotFoundException: com.mysql.jdbc.Driver at java.net.URLClassLoader$1.run(Unknown Source) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.gjt.sp.jedit.bsh.Reflect.invokeMethod(Reflect.java:134) at org.gjt.sp.jedit.bsh.Reflect.invokeStaticMethod(Reflect.java:98) at org.gjt.sp.jedit.bsh.Name.invokeMethod(Name.java:871) at org.gjt.sp.jedit.bsh.BSHMethodInvocation.eval(BSHMethodInvocation.java:75) at org.gjt.sp.jedit.bsh.BSHPrimarySuffix.doSuffix(BSHPrimarySuffix.java:102) at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval(BSHPrimaryExpression.java:80) at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval(BSHPrimaryExpression.java:47) at org.gjt.sp.jedit.bsh.Interpreter.eval(Interpreter.java:644) at org.gjt.sp.jedit.bsh.Interpreter.eval(Interpreter.java:738) at org.gjt.sp.jedit.bsh.Interpreter.eval(Interpreter.java:727) at org.gjt.sp.jedit.BeanShellFacade._eval(BeanShellFacade.java:148) at org.gjt.sp.jedit.BeanShellFacade.eval(BeanShellFacade.java:113) at org.gjt.sp.jedit.BeanShellFacade.evalSelection(BeanShellFacade.java:85) at org.gjt.sp.jedit.BeanShell.evalSelection(BeanShell.java:71) at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.gjt.sp.jedit.bsh.Reflect.invokeMethod(Reflect.java:134) at org.gjt.sp.jedit.bsh.Reflect.invokeStaticMethod(Reflect.java:98) at org.gjt.sp.jedit.bsh.Name.invokeMethod(Name.java:871) at org.gjt.sp.jedit.bsh.BSHMethodInvocation.eval(BSHMethodInvocation.java:75) at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval(BSHPrimaryExpression.java:102) at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval(BSHPrimaryExpression.java:47) at org.gjt.sp.jedit.bsh.BSHBlock.evalBlock(BSHBlock.java:130) at org.gjt.sp.jedit.bsh.BSHBlock.eval(BSHBlock.java:80) at org.gjt.sp.jedit.bsh.BshMethod.invokeImpl(BshMethod.java:362) at org.gjt.sp.jedit.bsh.BshMethod.invoke(BshMethod.java:258) at org.gjt.sp.jedit.bsh.BshMethod.invoke(BshMethod.java:186) at org.gjt.sp.jedit.BeanShellFacade.runCachedBlock(BeanShellFacade.java:225) at org.gjt.sp.jedit.BeanShell.runCachedBlock(BeanShell.java:423) at org.gjt.sp.jedit.BeanShellAction.invoke(BeanShellAction.java:73) at org.gjt.sp.jedit.gui.InputHandler.invokeAction(InputHandler.java:352) at org.gjt.sp.jedit.jEdit$4.invokeAction(jEdit.java:3255) at org.gjt.sp.jedit.jEdit$4.invokeAction(jEdit.java:3237) at org.gjt.sp.jedit.EditAction$Wrapper.actionPerformed(EditAction.java:221) at javax.swing.AbstractButton.fireActionPerformed(Unknown Source) at javax.swing.AbstractButton$Handler.actionPerformed(Unknown Source) at javax.swing.DefaultButtonModel.fireActionPerformed(Unknown Source) at javax.swing.DefaultButtonModel.setPressed(Unknown Source) at javax.swing.AbstractButton.doClick(Unknown Source) at javax.swing.plaf.basic.BasicMenuItemUI.doClick(Unknown Source) at javax.swing.plaf.basic.BasicMenuItemUI$Handler.mouseReleased(Unknown Source) at java.awt.AWTEventMulticaster.mouseReleased(Unknown Source) at java.awt.Component.processMouseEvent(Unknown Source) at javax.swing.JComponent.processMouseEvent(Unknown Source) at java.awt.Component.processEvent(Unknown Source) at java.awt.Container.processEvent(Unknown Source) at java.awt.Component.dispatchEventImpl(Unknown Source) at java.awt.Container.dispatchEventImpl(Unknown Source) at java.awt.Component.dispatchEvent(Unknown Source) at java.awt.LightweightDispatcher.retargetMouseEvent(Unknown Source) at java.awt.LightweightDispatcher.processMouseEvent(Unknown Source) at java.awt.LightweightDispatcher.dispatchEvent(Unknown Source) at java.awt.Container.dispatchEventImpl(Unknown Source) at java.awt.Window.dispatchEventImpl(Unknown Source) at java.awt.Component.dispatchEvent(Unknown Source) at java.awt.EventQueue.dispatchEvent(Unknown Source) at java.awt.EventDispatchThread.pumpOneEventForFilters(Unknown Source) at java.awt.EventDispatchThread.pumpEventsForFilter(Unknown Source) at java.awt.EventDispatchThread.pumpEventsForHierarchy(Unknown Source) at java.awt.EventDispatchThread.pumpEvents(Unknown Source) at java.awt.EventDispatchThread.pumpEvents(Unknown Source) at java.awt.EventDispatchThread.run(Unknown Source) Can you post the code (script and classpath config) and the exception? A ClassNotFoundException simply means that the in the message mentioned class is missing in the runtime classpath. Just add the JDBC driver JAR file to the runtime classpath of the beanshell script. Here's an extract of the documentation: Changing the Class Path addClassPath( URL | path ) Add the specified directory or archive to the classpath. Archives may be located by URL allowing them to be loaded over the network. Examples: addClassPath( ""/home/pat/java/classes"" ); addClassPath( ""/home/pat/java/mystuff.jar"" ); addClassPath( new URL(""http://myserver/~pat/somebeans.jar"") ); Then to load the driver class you need to use Beanshell's provided getClass() method instead of the standard Class#forName(). Here's an extract of the documentation: Loading Classes Explicitly In order to perform an explicit class lookup by name while taking into account any BeanShell class path modification you must use a replacement for the standard Class.forName() method. The getClass() command will load a class by name using the BeanShell classpath. Alternately you can consult the class manager explicitly: name=""foo.bar.MyClass""; c = getClass( name ); c = BshClassManager.classForName( name ); // equivalent @BalusC i have already added the classpath. however it didn't work. Then you did something wrong. It's hard to tell what based on the little information given as far. What i have done are: 1- I have copied Jar folder to beanshells lib directory 2- I have added the classpath like this addClassPath( ""/home/pat/java/mystuff.jar"" ); 3- I have importet the library i used external libraries many times like this i have controlled everything. i am sure i must do something else. the error is in this line Class.forName(""com.mysql.jdbc.Driver"").newInstance(); com.mysql.jdbc.Driver is not found but if i instance new Driver like Driver d = new Driver(); it works if it was import failure that would not work too. You can't use `Class#forName()` in bsh. See also the same documentation. I've updated the answer. It Works! Thanks @BalusC it was because of loading class."
1135,A,"JBoss 3.2.2 and JDBC upgrade Moved a bunch of databases from sql server 2000 to 2008. One of the applications is on JBoss 3.2.2 and is now failing to connect to the database. The particular error is ""The incoming tabular data stream (TDS) remote procedure call (RPC) protocol stream is incorect. Parameter 1 (""""): Data type 0x38 is unknown."" I looked around google for a while have determined this is because I'm using MS SQL Server 2000 Driver for JDBC and this driver will not work with MSSql server 2008. It will connect but will not work. So my question is how do I get Jboss to use the new MSSql server JDBC driver version 2. I'm not familiar with JBoss at all. The new driver comes with a JAR file but I'm not sure how to tell JBoss to use that instead of the old driver. Thank you in advance for all your help. One thing you should know is that JBoss 3 is really really old (released in **2004** iirc). Perhaps you should consider upgrading. That's true but it won't solve the JDBC configuration issue :) We're in the process of moving everything to a new system so upgrade at this point is out of the question. Most often  to make the JDBC driver class available to JBoss the driver's jar is copied to the lib directory of the default server configuration (assuming that is the configuration you are running of course). So in order to make JBoss use the new driver remove the old jar from the lib directory (if it's not there look at the startup script and find from where it's added to the $CLASSPATH) replace it with the new driver update your mssql-ds.xml if required (especially the <connection-url> and <driver-class> check the driver documentation) restart Jboss. Removing the msbase.jar mssqlserver.jar and msutil.jar causes a connection error. Then I copy the new sqljdbc.jar into the lib folder and get the following error. Could not create connection; - nested throwable: (org.jboss.resource.JBossResourceException: Failed to register driver for: com.microsoft.jdbc.sqlserver.SQLServerDriver; - nested throwable: (java.lang.ClassNotFoundException: No ClassLoaders found for: com.microsoft.jdbc.sqlserver.SQLServerDriver). BTW after copying the new driver I do modify the mssql-ds.xml file to read the new driver. thank you figured it out. problem is with JRE. I'm using 1.4 and the new JDBC 2.0 driver from MS does not support 1.4 it says I have to upgrade to 5.0. The SQL Server 2005 JDBC driver class name is **""com.microsoft.sqlserver.jdbc.SQLServerDriver""**. In addition the SQL Server 2005 JDBC driver has a different URL prefix from the SQL Server 2000 JDBC driver. The SQL Server 2000 JDBC driver uses an URL prefix of ""jdbc:microsoft:sqlserver://"" while the SQL Server 2005 JDBC driver uses an URL prefix of **""jdbc:sqlserver://""**. http://blogs.msdn.com/jdbcteam/archive/2007/06/15/java-lang-classnotfoundexception-com-microsoft-jdbc-sqlserver-sqlserverdriver.aspx Well indeed according to http://www.microsoft.com/downloads/details.aspx?FamilyID=99b21b65-e98f-4a61-b811-19912601fdc9&displaylang=en you need Java 5.0 or later. But I think my previous comment still apply. Yes I did notice the url prefix is different. I used the MS JDBC 1.2 driver which MS says is for SQL 2005 but it works for 2008. I'm back in business. Thank you very much for all the help. I think this puts me in the right path. I found a mssqlserver.jar in jboss\server\all\lib but didn't find it in defaul or minimal. And I'm not sure if this is the old driver or not is there a way I can make sure? I'm using eclipse as IDE can you tell me how to check the $CLASSPATH? Thanks Yes this is it (jboss/server/all/lib is shared by all configurations). One way to make sure would be to remove the jar and check if you get a ClassNotFoundException at JBoss startup (in other words you shouldn't be able to access a database at all). But I'm sure its the jar you're looking for."
1136,A,"improving speed of query processing having major issues with my query processing time :( i think it is because the query is getting recompiled evrytime. but i dont see any way around it. the following is the query/snippet of code: private void readPerformance(String startTime String endTime String performanceTable String interfaceInput) throws SQLException IOException { String interfaceId iDescp iStatus = null; String dtime ingress egress newLine append routerId= null; StringTokenizer st = null; stmtD = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY java.sql.ResultSet.CONCUR_READ_ONLY); stmtD.setFetchSize(Integer.MIN_VALUE); BufferedReader interfaceRead = new BufferedReader(new FileReader(interfaceInput)); BufferedWriter pWrite = new BufferedWriter(new FileWriter(""performanceInput.txt"")); while((newLine = interfaceRead.readLine())!= null){ st = new StringTokenizer(newLine""""); while(st.hasMoreTokens()){ append = st.nextToken()+CSV+st.nextToken()+st.nextToken()+CSV+st.nextToken(); System.out.println(append +"" ""); iStatus = st.nextToken().trim(); interfaceId = st.nextToken().trim(); append = append + CSV+iStatus+CSV+interfaceId; System.out.println(append +"" ""); pquery = "" Select d.dtimed.ifInOctets d.ifOutOctets from ""+performanceTable+""_1_60"" +"" AS d Where d.id = "" +interfaceId + "" AND dtime BETWEEN "" +startTime+ "" AND ""+ endTime; rsD = stmtD.executeQuery(pquery); /* interface query*/ while(rsD.next()){ dtime = rsD.getString(1); ingress= rsD.getString(2); egress = rsD.getString(3); pWrite.write(append + CSV + dtime+CSV+ingress+CSV+egress+NL); }//end while }//end while }// end while pWrite.close(); interfaceRead.close(); rsD.close() ; stmtD.close(); } my interfaceId value keeps changing. so i have put the query inside the loop resulting in recompilation of query multiple times. is there any betetr way? can i sue stored procedure in java? if so how? do not have much knowledge of it. current processing time is almost 60 mins (:(()!!! Text file getting generated is over 300 MB Please help!!! Thank you. The irony of a non-performant readPerformance function is striking. From the looks of things you are kicking off multiple select queries (even 100's based on your file size) Instead of doing that from your input file create a comma delimited list of all the interfaceId values and then make 1 SQL call using the ""IN"" keyword. You know the performanceTable startTime and endTime arent changing so the query would look something like this SELECT d.dtimed.ifInOctets d.ifOutOctets FROM MyTable_1_60 as d WHERE dtime BETWEEN '08/14/2010' AND '08/15/2010' AND d.id IN ( 10 18 25 13 75 ) Then you are free to open your file dump the result set in one swoop.  You can use a PreparedStatement and paramters which may avoid recompiling the query. Since performanceTable is constant this can be put into the prepared query. The remaining variables used in the WHERE condition are set as parameters. Outside the loop create a prepared statement rather than a regular statement:  PreparedStatement stmtD = conn.prepareStatement( ""Select d.dtimed.ifInOctets d.ifOutOctets from ""+performanceTable+""_1_60 AS d""+ "" Where d.id = ? AND dtime BETWEEN ? AND ?""); Then later in your loop set the parameters:  stmtD.setInteger(1 interfaceID); stmtD.setInteger(2 startTime); stmtD.setInteger(3 endTime); ResultSet rsD = stmtD.executeQuery(); // note no SQL passed in here It may be a good idea to also check the query plan from MySQL with EXPLAIN to see if that is part of the bottleneck also. Also there is quite a bit of diagnostic string concatenation going on in the function. Once the query is working removing that may also improve performance. Finally note that even if the query is fast network latency may slow things down. JDBC provides batch execution of multiple queries to help reduce overall latency per statement. See addBatch/executeBatch on Connection. tried wat u said :) got down time from 80 mins to 10 mins :). feel soo much happy. 10 is still more but 80 is too much :P  More information required but I can offer some general questions/suggestions. It may have nothing to do with the compilation of the query plan (that would be unusual) Are the id and dtime columns indexed? How many times does a query get executed in the 60mins? How much time does each query take? If the time per query is large then the problem is the query execution itself not the compilation. Check the indexes as described above. If there are many many many queries then it might be the sheer volume of queries that is causing the problem. Using PreparedStatement (see mdma's answer) may help. Or you can try and batch the interfaceIDs you want by using an ""in"" statement and running a query for every 100 interfaceIDs rather than one for each. EDIT: As a matter of good practice you should ALWAYS use PreparedStatement as it will correctly handle datatypes such as dates so you don't have to worry about formatting them into correct SQL syntax. Also prevents SQL injection."
1137,A,"Where to close java PreparedStatements and ResultSets? Consider the code: PreparedStatement ps = null; ResultSet rs = null; try { ps = conn.createStatement(myQueryString); rs = ps.executeQuery(); // process the results... } catch (java.sql.SQLException e) { log.error(""an error!"" e); throw new MyAppException(""I'm sorry. Your query did not work.""); } finally { ps.close(); rs.close(); } The above does not compile because both PreparedStatement.close() and ResultSet.close() throw a java.sql.SQLException. So do I add a try/catch block to the finally clause? Or move the close statements into the try clause? Or just not bother calling close? Also note: ""When a Statement object is closed its current ResultSet object if one exists is also closed. "" http://java.sun.com/j2se/1.5.0/docs/api/java/sql/Statement.html#close() It should be sufficient to close only the PreparedStatement in a finally and only if it is not already closed. If you want to be really particular though close the ResultSet FIRST not after closing the PreparedStatement (closing it after like some of the examples here should actually guarantee an exception since it is already closed). According to the documentation you reference calling Statement.close() on an already-closed Statement has no effect. Closing a Statement multiple times doesn't throw an exception so it stands to reason that doing the same for a ResultSet should be equally innocuous. The ResultSet documentation doesn't explicitly say this but it also doesn't say that you shouldn't close it more than once...The whole point of this pedantic rant is that it doesn't GUARANTEE an exception. Although it would be good to close the ResultSet first just in case some implementation behaves that way. I can't help myself. I have to point out that this is a really useful answer and the one above that says ""use a framework"" just makes me cringe.  If you're really hand-rolling your own jdbc it definitely gets messy. The close() in the finally needs to get wrapped with its own try catch which at the very least is ugly. You can't skip the close although the resources will get cleared when the connection is closed (which might not be right away if you're using a pool). Actually one of the main selling points of using a framework (e.g. hibernate) to manage your db access is to manage the connection and result set handling so you don't forget to close. You can do something simple like this which at least hides the mess and guarantees that you don't forget something. public static void close(ResultSet rs Statement ps Connection conn) { if (rs!=null) { try { rs.close(); } catch(SQLException e) { logger.error(""The result set cannot be closed."" e); } } if (ps != null) { try { ps.close(); } catch (SQLException e) { logger.error(""The statement cannot be closed."" e); } } if (conn != null) { try { conn.close(); } catch (SQLException e) { logger.error(""The data source connection cannot be closed."" e); } } } and then finally { close(rs ps null); } This solution works very well if you're rolling your own because the SQLExceptions thrown by the close methods are unrecoverable anyway. Another neat way to go about it is to throw a RuntimeException subclass from this method which bubbles up to a code layer that can manage the DB failure. Always close statements leaving them open after connection is closed might produce problems: see more at http://stackoverflow.com/questions/321418/where-to-close-java-preparedstatements-and-resultsets. Note that according to the JavaDoc for Statement the ResultSet is closed as a side-effect of closing the statement so it's not strictly necessary in this example (but doesn't hurt). http://java.sun.com/javase/6/docs/api/java/sql/Statement.html#close() I wrote it this way because it's useful to be able to flexibly close with some of the objects as null. So you can use the same function to close any subset of (statement resultset connection) objects. You shouldn't ignore exceptions from closing a resource. In the case of a JDBC operation for example it means that whatever you did inside your `try` block probably didn't really happen. The approach taken by the ARM implementation is exemplary: throw `close()` exception if it's the only one otherwise preserve it by chaining to the main exception. Just looked at this again - this is a very old answer and was written in Java6 days. You could probably write this a bit more neatly in Java7 using AutoCloseables if the relevant objects support it. @SteveB. Thanks I was wondering about that erickson below has an answer using AutoCloseables. Cleaned my legacy code up nicely. Since yours is the accepted answer you might edit it to point viewers to his :)  I know this is an old question but just in case someone is looking for the answer java now has the try-with-resouce solution. static String readFirstLineFromFile(String path) throws IOException { try (BufferedReader br = new BufferedReader(new FileReader(path))) { return br.readLine(); } } This is the same as Guido Garcia´s answer. Try with resource requires the resource to be AutoCloseable.  focus finally clause finally { try { rs.close(); ps.close(); } catch (Exception e) { // Do something } } I think you have to modify 2 points. First use try & catch again in fainlly clause. Second do rs.close() before doing ps.close(). fly1997@naver.com  I usually have a utility method which can close things like this including taking care not to try to do anything with a null reference. Usually if close() throws an exception I don't actually care so I just log the exception and swallow it - but another alternative would be to convert it into a RuntimeException. Either way I recommend doing it in a utility method which is easy to call as you may well need to do this in many places. Note that your current solution won't close the ResultSet if closing the PreparedStatement fails - it's better to use nested finally blocks.  Don't waste your time coding low-level exception management use an higher-level API like Spring-JDBC or a custom wrapper around connection/statement/rs objects to hide the messy try-catch ridden code. I also agree with this. Spring will wrap checked exception into unchecked because in most cases application cannot recover from DB exceptions.  In Java 7 you should not close them explicitly but use automatic resource management to ensure that resources are closed and exceptions are handled appropriately. Exception handling works like this:  Exception in try | Exception in close | Result -----------------+--------------------+---------------------------------------- No | No | Continue normally No | Yes | Throw the close() exception Yes | No | Throw the exception from try block Yes | Yes | Add close() exception to main exception | | as ""suppressed"" throw main exception Hopefully that makes sense. In allows pretty code like this: private void doEverythingInOneSillyMethod(String key) throws MyAppException { try (Connection db = ds.getConnection()) { db.setReadOnly(true); ... try (PreparedStatement ps = db.prepareStatement(...)) { ps.setString(1 key); ... try (ResultSet rs = ps.executeQuery()) { ... } } } catch (SQLException ex) { throw new MyAppException(""Query failed."" ex); } } Prior to Java 7 it's best to use nested finally blocks rather than testing references for null. The example I'll show might look ugly with the deep nesting but in practice well-designed code probably isn't going to create a connection statement and results all in the same method; often each level of nesting involves passing a resource to another method which uses it as a factory for another resource. With this approach exceptions from a close() will mask an exception from inside the try block. That can be overcome but it results in even more messy code and requires a custom exception class that provides the ""suppressed"" exception chaining present in Java 7. Connection db = ds.getConnection(); try { PreparedStatement ps = ...; try { ResultSet rs = ... try { ... } finally { rs.close(); } } finally { ps.close(); } } finally { db.close(); } It'd be less ugly if you put the finally on the same line as the closing brace. ;) Ctrl-Shift-F to your heart's content! ;) @ceving No one has suggested that closing statements may be avoided. What are you responding to? It is a bad idea if you do not close statements. If you use connection pools your code will end up with `ORA-01000: maximum open cursors exceeded`. Closing statements helps because Oracles Universal Connection Pool (UCP) does also statement pooling.  Do no omit calling close. It may cause problems. I prefer adding try/catch block to the finally.  For file I/O I generally add a try/catch to the finally block. However you must be careful not to throw any exceptions from the finally block since they will cause the original exception (if any) to be lost. See this article for a more specific example of database connection closing.  I use this.. finally { if (ps != null) ps.close(); if (rs != null) rs.close(); } That doesn't answer the question - because ps.close() and rs.close() can both throw SqlException.  If your are using Java 7 you can use the improvements in the exception handling mechanisms in those classes that implement AutoCloseable (i.e. PreparedStatement Resultset) You might also find this question interesting: Closing ResultSet in Java 7"
