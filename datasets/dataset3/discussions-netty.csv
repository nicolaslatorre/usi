0,A,"How to handle different (url) websocket connections in netty Websocket example in netty (examples) has a http request handler which: performs hand shaking (at first) (then) handles different types of WebSocket frames eventually ""TextWebSocketFrame""s. There is only one url for websocket connections in this example. The problem is when TextWebSocketFrame based actual websocket communication starts there is no direct way to determine websocket url from TextWebSocketFrames themselves (correct me if I am wrong). So how to handle different (url) websocket connections in netty? One solution can be registering channels and their ""websocket connection urls"" during handshaking process. The other is having only one websocket connection url and resolving different contexts by adding extra information to websocket messages (TextWebSocketFrames). I don't find these solutions elegant so any ideas? It is my understanding that when you perform a web socket handshake it is to a specific URL. That is specified in the web socket standard. See RFC 6455. Hence there is no URL information in the TextWebSocketFrame because the assumption is that the frame will be sent to the URL to which the socket is bound. To handle different URLs you will have to either: Setup a different pipeline and bind to a different IP and/or port for each URL or Like you stated customise the hand shake and store the URL with the channel. Personally I've just used JSON in a TextWebSocketFrame. In my JSON I have a field that states the intended action. This field is used for routing to the appropriate message handler. I think it comes down to a design decision. WebSockets are intended for long lived connections where a request message can have 0 1 or > 1 responses. This contrasts the REST style 1 request and 1 responses model. Hope this helps. thanks for your answer and your RFC 6455 implementation in netty. i hope you guys finish netty 3.3 and 4.0 very soon. No problems. It coding and (autobahn) testing of web sockets is finished. Just waiting for a release."
1,A,"Can Netty efficiently handle scores of outgoing connections as a client? I'm creating a client-server relationship whereby a single client will be connected to an arbitrary number of servers using persistent TCP connections. The actual number of servers is as-of-yet undetermined but the design goal is to shoot for 1000. I found an example using direct Java NIO that nearly completely matches my mental model of how this could work: http://drdobbs.com/jvm/184406242 In general it opens up all of the channels and adds them to a single thread monitoring java.nio.channels.Selector. The use of the Selector in particular is what allows this to scale far better than using the standard thread-per-channel. I would rather use a (slightly) higher level socket framework like Netty than direct Java NIO. Unfortunately I have not been able to determine how Netty would handle a case like this. That is the examples and discussions I've found all tend to center around the server side with accepting scores of concurrent connections. But what about doing this from the client side? If I create a large number of channels and just wait on their events how is Netty going to handle this at the back-end? If Netty will let you open an outgoing connection register it for OP_CONNECT and handle the OP_CONNECT event to register for OP_READ everything after that is the same whether server or client. This isn't a direct answer to your question but I hope it is helpful nonetheless. Below I describe a way for you to determine the answer that you are looking for. This is something that I recently did myself for an upcoming project. Compared to OIO (Old IO) the asynchronous nature of the Netty framework and NIO will indeed provide much better memory and CPU usage characteristics for your application. The way buffers are handled in Netty will also be of benefit as it will help you to avoid copying byte buffers. The point is that all of the thread pool and NIO details will be handled for you allowing you to focus on your business logic. You mentioned the NIO Selector and you will benefit from that; the nice thing about Netty is that you get the benefits without having to worry about that implementation yourself because it is already done for you. My understanding of the client side is that it is very similar to the server side and should provide you with commensurate performance gains (as long as your business logic doesn't introduce any performance issues). My advice would be to throw together a prototype that more or less does what you want. Leave out any time consuming details and just add in the basic Netty handlers that you need to make something that works. Then I would use jmeter to invoke your client to apply load to the server and client. Using something like jconsole or jvisualvm will show you the performance characteristics of the client and server under load. You could also try jprobe. You can add a listener in jmeter that will indicate the throughput. I would advise to use jmeter in server mode the client on another machine and the server on yet another. This is a bit of up front work but if you decide to move forward you will have these tools ready to go for further testing as your proceed. I suspect a decent Netty implementation that doesn't introduce any extraneous poorly performing components will give you the performance characteristics you are looking for but the only way to know for sure is to measure the system under the expected load. You need to define what the expected load looks like and the desired performance characteristics under such load. Given these inputs you can measure your system to find out if it will meet your expectations. I personally don't think anyone can tell you if it will behave in the desired manner. You have to measure it. It's the only reliable way to know if the system can meet your needs. I would rather use a (slightly) higher level socket framework like Netty than direct Java NIO. This is the correct approach. You can try implementing your own NIO server and client but why do that when you have the benefit of a highly refined framework at your fingertips already?  Netty will use up to x worker threads that handle the work for you. Each worker thread will have one Selector that is used to register Channels to it. The number of used workers is configurable and by default 2 * cpu-count. its kind of round-robin so its not exact distributed across them Ah. That sounds perfect. Are the channels distributed evenly between the Selectors then? Say we have a 16-core system and 1024 open connections. That implies 32 worker threads (by default) each serving 32 Channels?  As you can see in the example from Netty's doc [http://netty.io/docs/stable/guide/html/#start.9][1] you can control exactly the number of worker threads (meaning the number of underlying selectors) on the Client side. Netty solves a numbers of issues that are very hard to handle in a simple way such as NIO vs SSL and have a lot of default encoder/decoder for Zip... etc. I started using Netty a few week ago and it was quite fast to came into. (I recommend dowloading the project with all the example code inside there is a lot of documentation in it that can not be found on the url above.  ChannelFactory factory = new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); ClientBootstrap bootstrap = new ClientBootstrap(factory); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline(new TimeClientHandler()); } }); bootstrap.setOption(""tcpNoDelay"" true); bootstrap.setOption(""keepAlive"" true); bootstrap.connect(new InetSocketAddress(host port)); Good luck Renaud Thank you! Your response and Norman's response both pointed out the core bit of knowledge that I was missing -- that worker threads each have an underlying Selector. That is key. You welcome! (:"
2,A,"unable to read response in http client using netty I am able to write my http request over the connection made to the server but I am unable to read the response from the server(not sure if there is any response or not).. How can I check it and then read it? My server is returning json in response.. Client code : public class NettyClient { public static void main(String[] args) throws Exception { URI uri = new URI(""http://myurl.com/v1/v2?param1=value1""); String scheme = uri.getScheme() == null? ""http"" : uri.getScheme(); String host = uri.getHost(); int port = 443; boolean ssl = ""https"".equalsIgnoreCase(scheme); // Configure the client. EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .handler(new NettyClientInitializer(false)); // Make the connection attempt. Channel ch = b.connect(host port).sync().channel(); // Prepare the HTTP request. HttpRequest request = new DefaultHttpRequest( HttpVersion.HTTP_1_1 HttpMethod.GET ""http://myurl.com/v1/v2?param1=value1""); request.headers().set(HttpHeaders.Names.HOST host); request.headers().set(HttpHeaders.Names.CONNECTION HttpHeaders.Values.KEEP_ALIVE); //request.headers().set(HttpHeaders.Names.ACCEPT_ENCODING HttpHeaders.Values.GZIP); // Send the HTTP request. ch.writeAndFlush(request); // Wait for the server to close the connection. ch.closeFuture().sync(); } finally { // Shut down executor threads to exit. group.shutdownGracefully(); } } } Initializer code : public class NettyClientInitializer extends ChannelInitializer<SocketChannel> { private final boolean ssl; public NettyClientInitializer(boolean ssl) { this.ssl = ssl; } @Override public void initChannel(SocketChannel ch) throws Exception { // Create a default pipeline implementation. ChannelPipeline p = ch.pipeline(); p.addLast(""log"" new LoggingHandler(LogLevel.INFO)); // Enable HTTPS if necessary. /* if (ssl) { SSLEngine engine = SecureChatSslContextFactory.getClientContext().createSSLEngine(); engine.setUseClientMode(true); p.addLast(""ssl"" new SslHandler(engine)); } */ p.addLast(""codec"" new HttpClientCodec()); // Remove the following line if you don't want automatic content decompression. // p.addLast(""inflater"" new HttpContentDecompressor()); // Uncomment the following line if you don't want to handle HttpChunks. //p.addLast(""aggregator"" new HttpObjectAggregator(1048576)); p.addLast(""handler"" new NettyClientHandler()); } } Handler code : public class NettyClientHandler extends SimpleChannelInboundHandler<HttpObject> { @Override public void channelRead0(ChannelHandlerContext ctx HttpObject msg) throws Exception { if (msg instanceof HttpResponse) { HttpResponse response = (HttpResponse) msg; System.out.println(""STATUS: "" + response.getStatus()); System.out.println(""VERSION: "" + response.getProtocolVersion()); System.out.println(); if (!response.headers().isEmpty()) { for (String name: response.headers().names()) { for (String value: response.headers().getAll(name)) { System.out.println(""HEADER: "" + name + "" = "" + value); } } System.out.println(); } if (HttpHeaders.isTransferEncodingChunked(response)) { System.out.println(""CHUNKED CONTENT {""); } else { System.out.println(""CONTENT {""); } } if (msg instanceof HttpContent) { HttpContent content = (HttpContent) msg; System.out.print(content.content().toString(CharsetUtil.UTF_8)); System.out.flush(); if (content instanceof LastHttpContent) { System.out.println(""} END OF CONTENT""); } } } @Override public void exceptionCaught( ChannelHandlerContext ctx Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } } In the console I can see the request being written but after that the request is flushed the channel is then inactive and then unregistered. Could the reason be that my query parameters are not being sent or json issue or am I missing something in my code? The problem likely lies in the fact you're connecting to your server on port 443 int port = 443; ... Channel ch = b.connect(host port).sync().channel(); But your NettyClientInitializer doesn't support SSL (it's commented out of the pipeline) and you construct it as if SSL is not being used anyway new NettyClientInitializer(false) Your code works fine if you change the port to 80. now it gives me 302 status code i.e. ""Moved Temporarily"".. please tell me how is that handled in netty? That 302 is a valid HTTP response which you've managed to read using your netty client. Why your server is returning a 302 I can't tell you but the issue isn't with Netty. It would be up to you to decide (in your NettyClientHandler) how to deal with a 302. If you want to verify further you could use curl -v to attempt the same URL from a command line and you'll see a 302 returned. This might not be so obvious when testing from a browser because it will automatically follow the redirect. can you please tell me in the same code how can I close the connection instantly as soon as I receive the complete response? because right now it takes around 15 minutes to completely close the connection which is very high as per my requirement I figured that out myself.. thanks Derek for your answer.. Sure Mitaksh if you accept the answer to this question I'll respond with an answer to the other one you've submitted."
3,A,"Trouble with Netty IdleStateHandler - am I testing it the wrong way? I have a toy Netty server and am trying to send heartbeat messages to clients when nothing has happened on their channels. I am testing this by telnetting to the server writing a message and then not sending anything but I get no hearbeat! Console: >>telnet localhost 6969 Trying 127.0.0.1... Connected to localhost. Escape character is '^]'. >>foo Did you say 'foo'? MyPipelineFactory.java public class MyPipelineFactory implements ChannelPipelineFactory { private final Timer timer; private static final ChannelHandler stringDecoder = new StringDecoder(); private static final ChannelHandler stringEncoder = new StringEncoder(); private final ChannelHandler idleStateHandler; public MyPipelineFactory(Timer t) { this.timer = t; this.idleStateHandler = new IdleStateHandler(timer 5 5 5); } public ChannelPipeline getPipeline() { // create default pipeline from static method ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""idleStateHandler"" this.idleStateHandler); // heartbeat pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(1024 Delimiters.lineDelimiter())); //pipeline.addLast(""frameDecoder"" new LengthFieldBasedFrameDecoder(102401)); // get header from message pipeline.addLast(""stringDecoder"" stringDecoder); pipeline.addLast(""stringEncoder"" stringEncoder); pipeline.addLast(""ServerHandler"" new ServerHandler()); // goes at the end return pipeline; } } HeartbeatHandler.java public class HeartbeatHandler extends IdleStateAwareChannelHandler { @Override public void channelIdle(ChannelHandlerContext ctx IdleStateEvent e) { if (e.getState() == IdleState.READER_IDLE) { System.out.println(""Reader idle closing channel""); //e.getChannel().close(); e.getChannel().write(""heartbeat-reader_idle""); } else if (e.getState() == IdleState.WRITER_IDLE) { System.out.println(""Writer idle sending heartbeat""); e.getChannel().write(""heartbeat-writer_idle""); } else if (e.getState() == IdleState.ALL_IDLE) { System.out.println(""All idle sending heartbeat""); e.getChannel().write(""heartbeat-all_idle""); } } } Fixed: I forgot to have the HeartbeatHandler which requires the IdleStateHandler (this part wasn't obvious to me). That works. public class MyPipelineFactory implements ChannelPipelineFactory { private final Timer timer; private static final ChannelHandler stringDecoder = new StringDecoder(); private static final ChannelHandler stringEncoder = new StringEncoder(); private final ChannelHandler idleStateHandler; private final ChannelHandler heartbeatHandler; public MyPipelineFactory(Timer t) { this.timer = t; this.idleStateHandler = new IdleStateHandler(timer 5 5 5); this.heartbeatHandler = new HeartbeatHandler(); } public ChannelPipeline getPipeline() { // create default pipeline from static method ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""idleStateHandler"" this.idleStateHandler); pipeline.addLast(""heartbeatHandler"" this.heartbeatHandler); // heartbeat pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(1024 Delimiters.lineDelimiter())); //pipeline.addLast(""frameDecoder"" new LengthFieldBasedFrameDecoder(102401)); // get header from message pipeline.addLast(""stringDecoder"" stringDecoder); pipeline.addLast(""stringEncoder"" stringEncoder); pipeline.addLast(""ServerHandler"" new ServerHandler()); // goes at the end return pipeline; } } Norman’s answer is a really helpfulbut what I'd like to point out another thing: the idleStateHandler and the heartbeatHandler should be channel specific so in the PipeLineFactory  you shouldn't construct these two handlers as private members but need to create new ones in the getPipeline() method. You's also have a channel map to save the constructed channels if you need to release them you'd better also stop the timer to release the resources.  You missed to add the HeartbeatHandler in the ChannelPipeline. You need to add IdleStateHandler AND HeartbeatHandler to the ChannelPipeline to have it work. ah that wasn't clear from the docs that I need both.thanks again could it be that HeartbeatHandler is no longer needed in 3.5.9? You still need both"
4,A,"What happens if the client acts wrong connecting to Netty server? So say I have the following decoder... public class MyDecoder extends FrameDecoder1 { @Override protected Object decode( ChannelHandlerContext ctx Channel channel ChannelBuffer buffer)2 { if (buffer.readableBytes() < 4) { return null; } return buffer.readBytes(4); } } What happens if a client connects and never sends 4 bytes? 1- Client connects sends 3 bytes closes connection. Netty discards everything related to that connection right all resources ""freed""? 2- Client connects sends 3 bytes does not close connection and keeps it open. Another client connects and does the same thing and it continues. At this point resources are taken right? Is there a default way to handle this or do I need to attach a read timeout handler or something? Thanks 1) Yes as soon as the channel is closed it will release the buffered bytes. 2) Have a look at IdleStateHandler and IdleStateAwareHandler. These will help you to disconnect the client after some inactivity. Thanks seems right! I'll try it!"
5,A,"What does it mean channel.id()? I'm trying to count any ""new"" client who connect to my HTTP server based on Netty 4 CR1. Before CR1 it seems that channel.id was unique for any requests from a client. Now I have a different channel id per request. I would like to understand what unique meant ? In my use case how can I detect if the request come from the same client. The API say : Channel.id() ""Returns the unique integer ID of this channel."" Link: http://netty.io/4.0/api/io/netty/channel/Channel.html#id() Thanks It means what the javadocs says... It is unique per Channel which means per connection. So if multiple requests are served via the same Channel the id will stay the same as the connection is not dropped. I'm looking at the example : HttpStaticFileServer. It seems that the connection drop after every request because the channel id changes. ` May 23 2013 9:17:19 AM [HttpStaticFileServerHandler] messageReceived INFO: Channel id : -530815764 INFO: Channel id : -1375019911 INFO: Channel id : -195845856` I think that the behavior was different in the past. If this is not a bug how do you keep track of the current user connected ? I would like to develop something like a ""session"". Thanks Recently this channel.id() has been deprecated. This is no longger support by Netty 4.0 final."
6,A,"Netty HTTP Authetication for Client Look at the test code I have written below. Using pure java I set an Authenticator and make a URI call to get some xml data and convert it to an object. I wrote the code below to test performance of hotpotato (netty) vs. pure java (no pipelining). The trouble is I can't figure out how to Authenticate my request with hotpotato or netty code for either is acceptable I just want to test the performance diff (i.e. see how many requests will be performed in 5 seconds).  public static void main(String[] args) throws Exception { Authenticator.setDefault(new MyAuthenticator(""DummyUser"" ""DummyPassword"")); int timeToTestFor = 5000; //5 seconds; int count = 0; System.out.println(""Start time""); long starttime = System.currentTimeMillis(); do { URL url = new URL( ""http://example.com/rest/GetData.ashx?what=pizza&where=new%20york&visitorId=12345&sessionId=123456""); SearchResultsDocument doc = SearchResultsDocument.Factory.parse(url); count++; } while (System.currentTimeMillis() - starttime < timeToTestFor); System.out.println(""DONE Total count="" + count); System.out.println(""Netty/Hotpotatoe Start time""); count = 0; starttime = System.currentTimeMillis(); do { // Create & initialise the client HttpClient client = new DefaultHttpClient(); client.init(); // Setup the request HttpRequest request = new DefaultHttpRequest(HttpVersion.HTTP_1_0 HttpMethod.GET ""/rest/GetData.ashx?what=pizza&where=new%20york&visitorId=12345&sessionId=123456""); // Execute the request turning the result into a String HttpRequestFuture future = client.execute(""example.com"" 80 request new BodyAsStringProcessor()); future.awaitUninterruptibly(); // Print some details about the request System.out.println(""A >> "" + future); // If response was >= 200 and <= 299 print the body if (future.isSuccessfulResponse()) { System.out.println(""B >> ""+future.getProcessedResult()); } // Cleanup client.terminate(); count++; } while (System.currentTimeMillis() - starttime < timeToTestFor); System.out.println(""DONE Total count="" + count); } Here is working example of using basic authentication with Netty only. Tested with Jetty as a server requiring basic authentication. import java.net.InetSocketAddress; import java.util.concurrent.Executors; import org.jboss.netty.bootstrap.ClientBootstrap; import org.jboss.netty.buffer.ChannelBuffer; import org.jboss.netty.buffer.ChannelBuffers; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.channel.Channels; import org.jboss.netty.channel.ExceptionEvent; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.SimpleChannelHandler; import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory; import org.jboss.netty.handler.codec.base64.Base64; import org.jboss.netty.handler.codec.http.DefaultHttpRequest; import org.jboss.netty.handler.codec.http.HttpChunkAggregator; import org.jboss.netty.handler.codec.http.HttpClientCodec; import org.jboss.netty.handler.codec.http.HttpHeaders; import org.jboss.netty.handler.codec.http.HttpMethod; import org.jboss.netty.handler.codec.http.HttpResponse; import org.jboss.netty.handler.codec.http.HttpVersion; import org.jboss.netty.util.CharsetUtil; public class BasicAuthTest { private static final int PORT = 80; private static final String USERNAME = """"; private static final String PASSWORD = """"; private static final String URI = """"; private static final String HOST = """"; public static void main(String[] args) { ClientBootstrap client = new ClientBootstrap( new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); client.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""codec"" new HttpClientCodec()); pipeline.addLast(""aggregator"" new HttpChunkAggregator(5242880)); pipeline.addLast(""authHandler"" new ClientMessageHandler()); return pipeline; } }); DefaultHttpRequest request = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.GET URI); request.addHeader(HttpHeaders.Names.HOST HOST); String authString = USERNAME + "":"" + PASSWORD; ChannelBuffer authChannelBuffer = ChannelBuffers.copiedBuffer(authString CharsetUtil.UTF_8); ChannelBuffer encodedAuthChannelBuffer = Base64.encode(authChannelBuffer); request.addHeader(HttpHeaders.Names.AUTHORIZATION encodedAuthChannelBuffer.toString(CharsetUtil.UTF_8)); client.connect(new InetSocketAddress(HOST PORT)).awaitUninterruptibly().getChannel() .write(request).awaitUninterruptibly(); } public static class ClientMessageHandler extends SimpleChannelHandler { @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) throws Exception { e.getCause().printStackTrace(); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { HttpResponse httpResponse = (HttpResponse) e.getMessage(); String json = httpResponse.getContent().toString(CharsetUtil.UTF_8); System.out.println(json); } } } Thanks the example with a pipeline is much appreciated but is there a way to do it without using pipelining? Oh wait you use `awaitUninterruptibly()` I'm guessing this means the example is not using a pipeline? Pipeline is used of cause. If you mean the pipeline with HttpClientCodec in it. This example is very crud and doesn't even stop the execution. It is just the illustration of the fact that basic authentication is simply one header in the HttpRequest. (http://en.wikipedia.org/wiki/Basic_access_authentication) Thanks for this. It almost worked for me. Encoding gave chunked output which was mitigated by adding a parameter: Base64.encode(authChannelBuffer false). Also the header value needed to be changed just a bit: request.addHeader(HttpHeaders.Names.AUTHORIZATION ""Basic "" + encodedAuthChannelBuffer.toString(CharsetUtil.UTF_8));"
7,A,"Netty - Correct usage of a decoder I have once again a question about Netty. My scenario is: incoming message (TCP) = header[byteintbyte] body[bytes] I have a packet class which holds the header & body with some methods. My channel pipeline is: ProtocolDecoder > SessionHandler My idea of the ProtocolDecoder is that it receives a message splits it up and creates a Packet variable to pass on to the next handler in the pipeline. The code of the ProtocolDecoder class: public class ProtocolDecoder extends ByteToMessageDecoder { @Override protected void decode(ChannelHandlerContext ctx ByteBuf in List<Object> out) throws Exception { int opCode; int length; boolean encrypt; if (in.readableBytes() < 6) { return; } if (out.size() != 1) { Packet pa = new Packet(); opCode = in.readByte(); length = in.readInt(); encrypt = in.readByte() == 1; pa.setOpcode(opCode); pa.setEncrypted(encrypt); pa.setLength(length); out.add(pa); in.discardReadBytes(); } Packet p = (Packet) out.get(0); if (in.readableBytes() >= p.getLength()) { p.setPayload(in.copy()); } } } The SessionHandler has this code: @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { Packet p = (Packet) msg; System.out.println(""Packet: "" + p.toString()); } So my two questions are: Is this the correct usage of the ByteToMessageDecoder? How do I solve the error: ""java.lang.UnsupportedOperationException: direct buffer"" when I access the direct buffer (array() method) in the toString() method of the packet? UPDATE: I remade the decoder like supposed to and this is my outcome: http://pastebin.com/wQz2LbYT I wasn't sure if I had to put the code here because this post would become pretty big. Anyways it seems to work fine now :) thanks alot! Just a some more tips... you may just use in.readSlice(...) to slice out some memory without memory copy. If you really want to do the memory copy I would replace Unpooled.buffer(...) with ctx.alloc().buffer(...). This way you will be used the BytebufAllocator that was configured for the Channel and so may be able to used pooled ByteBufs. You don't use the ByteToMessageDecoder correctly as once you add something to the List (out) it will be removed once the method returns and forwarded to the next ChannelInboundHandler in the ChannelPipeline. If you need to hold a reference to your packet until you add it to out use a field in the class for it. You can only access the array() if hasArray() returns true. Otherwise the buffer itself is backed by native memory. In this case you will need to use one of its getBytes(...) methods to copy the content to an array. That said if you only want to get the content of the buffer as string you can use ByteBuf.toString(Charset) for this."
8,A,"netty http request getContent sometime give a headers in body I'm using netty in client mode using ClientBootstrap. When i'm trying to recieve a message most times it works fine and return me only a body but sometimes( the server always return same response) i get a headers inside content when i call a message.getContent(): Content-type: text/xml;charset=windows-1251 Content-length: 649 Connection: keep-alive <?xml version=""1.0"" encoding=""windows-1251""?> <response> <status> <code>0</code> </status> <detail> Obviously it should be only body of http request.. And when it return header part in a body the body part itself is a cutted by the size of the headers. Here is my PipileniFactory: public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = pipeline(); if (isSecure) { SSLContext clientContext = SSLContext.getInstance(""TLS""); clientContext.init(null new TrustManager[]{DUMMY_TRUST_MANAGER} null); SSLEngine engine = clientContext.createSSLEngine(); engine.setUseClientMode(true); pipeline.addLast(""ssl"" new SslHandler(engine)); } pipeline.addLast(""codec"" new HttpClientCodec()); pipeline.addLast(""aggregator"" new HttpChunkAggregator(1048576)); pipeline.addLast(""timeout"" new ReadTimeoutHandler(timer timeout TimeUnit.MILLISECONDS)); pipeline.addLast(""handler"" ibConnectorHandler); return pipeline; } And here is messageReceived from ibConnectorHandler: public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { logger.info(""Received""); HttpResponse response = (HttpResponse) e.getMessage(); ChannelBuffer resContent = response.getContent(); byte[] content = null; if (resContent.readable()) { content = Arrays.copyOf(resContent.array() resContent.readableBytes()); logger.debug(Arrays.toString(req.getParams().toArray()) + ""----------"" + new String(content)); } } i'm using netty 3.5.8. UPD When all is correct the resContent is instanceof org.jboss.netty.buffer.BigEndianHeapChannelBuffer. And when it shows header resContent is instanceof org.jboss.netty.buffer.SlicedChannelBuffer. So there is a problem when netty used a org.jboss.netty.buffer.SlicedChannelBuffer for a content of http message. In ""Arrays.copyOf(resContent.array() resContent.readableBytes())"" you don't respect the offset in the array. You need to also hand in the the offset which you can get from ChannelBuffer.arrayOffset() + ChannelBuffer.readerIndex(); See: http://static.netty.io/3.5/api/org/jboss/netty/buffer/ChannelBuffer.html#arrayOffset() Yep thanks that was issue. I finished using resContent.getBytes which respect offset. Btw this code was working fine in netty 3.5.1 It was working fine in 3.5.1 because we made some optimization which will safe you from some byte-copies and so speed up things. in 3.5.1 we always created a new buffer for the content and copied things over."
9,A,"Netty - How to pass information between handlers in the same pipeline I would like to create a pipeline of handlers such as: public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( new ObjectEncoder() new ObjectDecoder() new AuthenticationServerHandler() new BusinessLogicServerHandler()); } The key here is that I'd like the AuthenticationServerHandler to be able to pass the login information to the BusinessLogicServerHandler. I do understand that you can use an Attachment however that only stores the information for that handler the other handlers in the pipeline cannot access it. I also noticed there was something called ChannelLocal which might do the trick however I cannot find any real information on how to use it. All I've seen is people create a static instance to it but how do you retrieve and access the info in another handler? Assuming that's the correct method. My question is: how you do pass information between handlers in the same pipeline. In the example above how do I pass the login credentials from the AuthenticationServerHandler to the BusinessLogicServerHandler? I pass information from one handler to the next ones by using dedicated instances to compose the pipeline for each channel and by having the handlers reference each others within each pipeline. The passing of information is made the old way very simply without any problem.  I wasn't a fan of the ChannelLocal implementation with the lack of an internal static map so what I ended up doing was putting my object on the Channel's attachment for now: ctx.getChannel().setAttachment(myobj); Then I make ""myobj"" basically a context POJO that contains all the information gathered about the request so far. public class RequestContext { private String foo = """"; public String getFoo(){ return foo; } public void setFoo(String foo){ this.foo = foo; } } RequestContext reqCtx = new RequestContext(); reqCtx.setFoo(""Bar""); ctx.getChannel().setAttachment(reqCtx); reqCtx = (RequestContext)ctx.getChannel().getAttachment(); It's not elegant but it works... Yes but the attachment doesn't traverse to the other handlers in your pipeline which is the issue I'm having. The attachement on the Channel does. I'm using it now and it works fine. It goes wherever the channel goes.  ChannelLocal is the way to go atm. Just create an static instance somewhere and then access it from within your handlers by pass the Channel to the set/get method. This way you can share stuff between your channels. We are not using it anymore at Apache James Protocols but I think you can get the idea from the old code: http://svn.apache.org/viewvc/james/protocols/tags/protocols-1.5/impl/src/main/java/org/apache/james/protocols/impl/ChannelAttributeSupport.java?view=markup http://svn.apache.org/viewvc/james/protocols/tags/protocols-1.5/impl/src/main/java/org/apache/james/protocols/impl/AbstractChannelUpstreamHandler.java?view=markup Here's an example for ChannelLocal. http://stackoverflow.com/questions/8449663/usage-of-nettys-channellocal @Veebs That's the example I was looking at but how do you access the static final LocalChannel from the other handler? Or more importantly how do you access the AuthnticationServerHandler from BusinessLogicHandler? That's the part I'm missing.... @Veebs Also how does that work for storing stateful information since it's a static member? @StephaneGrenier did you have a look at the two links I posted? It does exactly what Veebs is telling you. That's what I understood (more or less in concept) but I haven't found any examples anywhere on exactly how to do this. I'm still a bit fuzzy on the details... From my understanding you can declare the static in another class that is known to both AuthnticationServerHandler and BusinessLogicHandler. It should be OK for stateful information because the set() and get() both require the channel as a parameter; i.e. the channel is used to return stateful information for that channel. I did but it didn't make sense to me. I finally just understood the link: http://www.assembla.com/code/argonms/subversion/nodes/trunk/src/argonms/center/recv/RemoteServerListener.java?rev=44"
10,A,"Using Guice's @SessionScoped with Netty How do I implement @SessionScoped in a Netty based TCP server? Creating Custom Scopes is documented in Guice manual but it seems that the solution only works for thread based and not asynchronous IO servers. Is it enough to create the Channel Pipeline between scope.enter() and scope.exit()? Does Netty support ""sessions objects""? It looks the Channel.getId() is the Netty alike. So you could use the [example](http://code.google.com/p/google-guice/wiki/CustomScopes) and switch the ThreadLocal out for a map of  Object>>. Disclaimer : this answer is for Netty 3. I've not had the opportunity to try Netty 4 yet so I don't know if what follows can be applied to the newer version. Netty is asynchronous on the network side but unless you explicity submit tasks to Executors or change threads by any other means the handling of ChannelEvents by the ChannelHandlers on a pipeline is synchronous and sequential. For instance if you use Netty 3 and have an ExecutionHandler on the pipeline the scope handler should be upstream of the ExecutionHandler; for Netty 4 see Trustin Lee's comment. Thus you can put a handler near the beginning of your pipeline that manages the session scope for example: public class ScopeHandler implements ChannelUpstreamHandler { @Override public void handleUpstream(ChannelHandlerContext ctx ChannelEvent e) { if (e instanceof WriteCompletionEvent || e instanceof ExceptionEvent) ctx.sendUpstream(e); Session session = ...; // get session presumably using e.getChannel() scope.enter(); try { scope.seed(Key.get(Session.class) session); ctx.sendUpstream(e); } finally { scope.exit(); } } private SessionScope scope; } A couple of quick remarks: You will want to filter some event types out especially WriteCompletionEvent and ExceptionEvent which the framework will put at the downstream end of the pipeline during event processing and wil cause reentrancy issues if not excluded. In our application we use this kind of handler but actually only consider UpstreamMessageEvents. The try/finally construct is not actually necessary as Netty will catch any Throwables and fire an ExceptionEvent but it feels more idiomatic this way. HTH Are you using you own SessionScope that extends SimpleScope? @jkj Yes that is what my example assumes. Nice work @ThomasDufour! The idea should also work for Netty 4. However if a user specifies an `EventExecutor` for a handler when setting up a pipeline you'll have to set up the scope again because the event will be handed off to a different thread. (just like it is with `ExecutionHandler` in Netty 3.) Thanks @TrustinLee I've edited the answer to mention `ExecutionHandler` in the Netty 3 case."
11,A,"Netty 4.0.21.Final OpenSSL client context support This question is based on netty-4.0.21.Final the current stable recommended release. When will Netty project support OpenSSL client ssl context ? Right now it seems this feature is not supported. /** * Creates a new client-side {@link SslContext}. * * @param provider the {@link SslContext} implementation to use. * {@code null} to use the current default one. * @param certChainFile an X.509 certificate chain file in PEM format. * {@code null} to use the system default * @param trustManagerFactory the {@link TrustManagerFactory} that provides the {@link TrustManager}s * that verifies the certificates sent from servers. * {@code null} to use the default. * @param ciphers the cipher suites to enable in the order of preference. * {@code null} to use the default cipher suites. * @param nextProtocols the application layer protocols to accept in the order of preference. * {@code null} to disable TLS NPN/ALPN extension. * @param sessionCacheSize the size of the cache used for storing SSL session objects. * {@code 0} to use the default value. * @param sessionTimeout the timeout for the cached SSL session objects in seconds. * {@code 0} to use the default value. * * @return a new client-side {@link SslContext} */ public static SslContext newClientContext( SslProvider provider File certChainFile TrustManagerFactory trustManagerFactory Iterable<String> ciphers Iterable<String> nextProtocols long sessionCacheSize long sessionTimeout) throws SSLException { if (provider != null && provider != SslProvider.JDK) { throw new SSLException(""client context unsupported for: "" + provider); } return new JdkSslClientContext( certChainFile trustManagerFactory ciphers nextProtocols sessionCacheSize sessionTimeout); } There is no timeline to have openssl support for the client side. It's not pretty high priority atm but we love contributions"
12,A,How to decipher ASN/BER packets I am working on an SNMP manager with the Java language. I am currently working on a custom ASN/BER codec backed by the power of Netty. I have made a decent way in and understand the low-level stuff but I have never worked with protocol analysis before. I dont really understand how to decrypt information out of the packet I can use. Now on to the specifics. I understand that type information is encoded into the packet in hex values I have been able to identify types present in the packet by looking over the Wireshark output of an SNMP trap packet. What I don't understand is how can I find out the contextual information? Like so: (Taken from JoeSnmp) public static final byte OCTETSTRING = (byte) 0x04; public static final byte APPLICATION = (byte) 0x40; public static final byte SMI_IPADDRESS = (ASN1.APPLICATION | 0x00); I have been able to find the value for OCTET_STRING by looking at the SMI RFC but how did they find the application context value? I dont want a reference to the answer I want to know how I can find the answer myself looking at the packet. As you can probably tell I'm new to the whole protocol analysis and network application field so if you have any other related resources I would also be happy to look over those :). Thanks in advance for your help! Basically the APPLICATION value is a hardcoded constant. The value for the APPLICATION constant is obtained from the ASN.1 BER encoding specifications. In ASN.1 BER encodings each value has an associated tag and length. A tag is composed of tag class and tag number. There are four tag classes: universal application context-specific private. These four values are encoded as two bits on the positions 8 and 7 of the first octet of the tag encoding. The bits corresponding to the application class are 01 (bit 8 and bit 7) and translated in hex this gives the 0x40 bit mask which is used below to compute the tag values using bitwise operations. For more details about the BER encoding see for example http://luca.ntop.org/Teaching/Appunti/asn1.html. Thank you for the well thought out and informative answer it helped clear a few things up!
13,A,"Web Socket & Netty - Received Message Type on messageReceived I'm trying the Netty's WebSocketServer(Netty WebSocketServer). I want to send messages to this server from a native web socket client(from: http://www.tutorialspoint.com/html5/html5_websocket.htm) with a code as follows: <!DOCTYPE HTML> <html> <head> <script type=""text/javascript""> function WebSocketTest() { if (""WebSocket"" in window) { alert(""WebSocket is supported by your Browser!""); // Let us open a web socket var ws = new WebSocket(""ws://localhost:3210/websocket""); ws.onopen = function() { // Web Socket is connected send data using send() ws.send(""Message to send""); alert(""Message is sent...""); }; ws.onmessage = function (evt) { var received_msg = evt.data; alert(""Message is received...""); }; ws.onclose = function() { // websocket is closed. alert(""Connection is closed...""); }; } else { // The browser doesn't support WebSocket alert(""WebSocket NOT supported by your Browser!""); } } </script> </head> <body> <div id=""sse""> <a href=""javascript:WebSocketTest()"">Run WebSocket</a> </div> </body> </html> However in the handler's messageReceived method it sees the incoming message in BigEndianHeapChannelBuffer type. What do I need to change in server code? Which browser are you using? The code in Netty 3.2 supports HyBi-00. Most browsers have moved on from that version. See post. Netty 3.3 (3.2 branch of the source) and 4.0 (master branch of the source) contains support for the latest web socket standards (RFC 6455). My recommendation is to use netty 3.2 branch. Hope this helps. I think you may be accidentally trying to deploy it. Try mvn jar or mvn package. yeap it works with mvn package. however I'm still getting BigEndianHeapChannelBuffer. By the way I'm using chromium 14.0.835.202 (Developer Build 103287 Linux) and I've downloaded https://github.com/netty/netty/tree/3.2 You need to use the WebSocketX package. Try running the example https://github.com/netty/netty/tree/3.2/src/main/java/org/jboss/netty/example/http/websocketx/server from your browser. Thanks for your reply I've downladed the source and I'm trying to build via maven but it asks me ""GPG Passphrase"" I couldn't find any info about it. do you know the passphrase? or what should I do? Thanks a lot WebSocketX package worked well.  Please note that netty's stable release doesn't support the newer websocket versions used by browsers. You might want to check if websocket connection is being established successfully."
14,A,"very basic netty usage: call method on received objects for the Netty ObjectEcho example branch 4.0 where does the server receive an object from the client? More importantly where in either ObjectEchoServer or ObjectEchoServerHandler can a method on the received object be invoked? The object is being received on the server: BUILD SUCCESSFUL Total time: 2 seconds Jul 23 2014 11:44:04 PM io.netty.handler.logging.LoggingHandler channelRegistered INFO: [id: 0x93baa167] REGISTERED Jul 23 2014 11:44:04 PM io.netty.handler.logging.LoggingHandler bind INFO: [id: 0x93baa167] BIND(0.0.0.0/0.0.0.0:4454) Jul 23 2014 11:44:04 PM io.netty.handler.logging.LoggingHandler channelActive INFO: [id: 0x93baa167 /0:0:0:0:0:0:0:0:4454] ACTIVE Jul 23 2014 11:44:10 PM io.netty.handler.logging.LoggingHandler logMessage INFO: [id: 0x93baa167 /0:0:0:0:0:0:0:0:4454] RECEIVED: [id: 0x8c8385a6 /127.0.0.1:33803 => /127.0.0.1:4454] Jul 23 2014 11:44:10 PM io.netty.handler.logging.LoggingHandler channelRegistered INFO: [id: 0x8c8385a6 /127.0.0.1:33803 => /127.0.0.1:4454] REGISTERED Jul 23 2014 11:44:10 PM io.netty.handler.logging.LoggingHandler channelActive INFO: [id: 0x8c8385a6 /127.0.0.1:33803 => /127.0.0.1:4454] ACTIVE Jul 23 2014 11:44:10 PM io.netty.handler.logging.LoggingHandler logMessage INFO: [id: 0x8c8385a6 /127.0.0.1:33803 => /127.0.0.1:4454] WRITE: Sun Jun 16 16:15:54 PST 1878 Jul 23 2014 11:44:10 PM io.netty.handler.logging.LoggingHandler flush INFO: [id: 0x8c8385a6 /127.0.0.1:33803 => /127.0.0.1:4454] FLUSH Jul 23 2014 11:44:10 PM io.netty.handler.logging.LoggingHandler close INFO: [id: 0x8c8385a6 /127.0.0.1:33803 => /127.0.0.1:4454] CLOSE() Jul 23 2014 11:44:10 PM io.netty.handler.logging.LoggingHandler channelInactive INFO: [id: 0x8c8385a6 /127.0.0.1:33803 :> /127.0.0.1:4454] INACTIVE Jul 23 2014 11:44:10 PM io.netty.handler.logging.LoggingHandler channelUnregistered INFO: [id: 0x8c8385a6 /127.0.0.1:33803 :> /127.0.0.1:4454] UNREGISTERED ^Cthufir@dur:~/NetBeansProjects/ObjectEchoServer$ thufir@dur:~/NetBeansProjects/ObjectEchoServer$ How does the server literally handle the received object? How is a method from the object invoked? I absolutely realize this is a very basic question. I've flipped through a book on netty but wasn't able to find a relevant section explaining this fundamental functionality. I've modified the server code as follows: package io.netty.example.objectecho; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import java.util.logging.Logger; /** * Handles both client-side and server-side handler depending on which * constructor was called. */ public class ObjectEchoServerHandler extends ChannelInboundHandlerAdapter { private static final Logger log = Logger.getLogger(ObjectEchoServerHandler.class.getName()); @Override public void channelRead(ChannelHandlerContext ctx Object msg) { log.warning(msg.toString()); ctx.write(msg); } @Override public void channelReadComplete(ChannelHandlerContext ctx) { log.info(""finished reading..?""); ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { cause.printStackTrace(); ctx.close(); } } but cannot seem to invoke msg.toString() as I would expect nor log ""finished reading"". Each and every time an object is received the server should process that object and pass it off to another class -- but how? How do I at a minimum invoke toString on the receive object? It's clearly being received it's logged as received. This happens in the server class and not the handler? see also http://stackoverflow.com/questions/24855307/simplest-possible-pojo-echo-with-netty#comment38732695_24855307 I downloaded the source from the link above then modified the ObjectEchoServerHandler as you posted. Works for me. Do you get an error message or any other output? I get output. How do I iñvoke methods on the object? Even toString would be helpful. How do I pass the object to some other class? Or send the object back? Basic ""operations"" along those lines. Calling toString explicitly in the handler would be very helpful. well it does for me. the `msg.toString()` generates the output of Object.toString() as a warning and `log.info(""finished reading..?"");` appears too. did you modify any other code from the example? @moh-aw pls note that the warning log in channelRead never prints. Neither does ""finished reading"" log. @Moh-Aw not sure what the problem was seems to be working now. client output: BUILD SUCCESSFUL Total time: 1 second Jul 25 2014 10:18:59 PM io.netty.example.objectecho.ObjectEchoClientHandler channelActive INFO: [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255] Jul 25 2014 10:18:59 PM io.netty.example.objectecho.ObjectEchoClientHandler channelRead server output: BUILD SUCCESSFUL Total time: 1 second Jul 25 2014 10:18:48 PM io.netty.handler.logging.LoggingHandler channelRegistered INFO: [id: 0xe7cb1e59] REGISTERED Jul 25 2014 10:18:48 PM io.netty.handler.logging.LoggingHandler bind INFO: [id: 0xe7cb1e59] BIND(0.0.0.0/0.0.0.0:4454) Jul 25 2014 10:18:48 PM io.netty.handler.logging.LoggingHandler channelActive INFO: [id: 0xe7cb1e59 /0:0:0:0:0:0:0:0:4454] ACTIVE Jul 25 2014 10:18:59 PM io.netty.handler.logging.LoggingHandler logMessage INFO: [id: 0xe7cb1e59 /0:0:0:0:0:0:0:0:4454] RECEIVED: [id: 0xc5d3dfbf /127.0.0.1:33250 => /127.0.0.1:4454] Jul 25 2014 10:18:59 PM io.netty.example.objectecho.ObjectEchoServerHandler channelRead WARNING: [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255] Jul 25 2014 10:18:59 PM io.netty.example.objectecho.ObjectEchoServerHandler channelReadComplete INFO: finished reading..? Jul 25 2014 10:18:59 PM io.netty.example.objectecho.ObjectEchoServerHandler channelRead WARNING: [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255] Jul 25 2014 10:18:59 PM io.netty.example.objectecho.ObjectEchoServerHandler channelReadComplete INFO: finished reading..? I think it's the same code...not sure what the problem was. Infinite loop established :) server handler: package io.netty.example.objectecho; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import java.util.logging.Logger; /** * Handles both client-side and server-side handler depending on which * constructor was called. */ public class ObjectEchoServerHandler extends ChannelInboundHandlerAdapter { private static final Logger log = Logger.getLogger(ObjectEchoServerHandler.class.getName()); @Override public void channelRead(ChannelHandlerContext ctx Object msg) { log.warning(msg.toString()); ctx.write(msg); } @Override public void channelReadComplete(ChannelHandlerContext ctx) { log.info(""finished reading..?""); ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { cause.printStackTrace(); ctx.close(); } }"
15,A,Why can't I iterate over a ChannelLocal? I don't know the internals of ChannelLocal but currently it seems not possible to iterate. I think of it as a collection of channel-object-mappings so I think it should be possible. Is there a way? There isn't a way atm... But I like the idea we could just let it implement Iterable. Could you open a issue for this at our bugtracker [1]. [1] https://github.com/netty/netty/issues Just for the record.. We just released 3.4.3.Final and included the feature in it. See http://netty.io/blog/2012/05/05/ The feature was implemented from Norman Maurer for the upcoming release 3.5.0.Final https://github.com/netty/netty/issues/307 Thank you!
16,A,How to have timelimits with Netty? I am looking at using netty to implement a server for an AI bot competition. The chat example is a good start since the protocol I have designed is similar to a line based chat server except for one major difference. The bots are asked to make a turn and have a maximum time limit to respond. If a bot fails to respond in time the server will take a default action for that bot. In particular I'm implementing The Resistance game. A leader will pick a team and then all the bots have to submit a yes or no vote. I want to wait until either all bots have voted or a timeout (eg. 2 seconds) occurs in which case I will assign an action for the bots that have yet to respond. How can I implement this using Netty? Netty provides transport level protocol. Looks like you need to implement own protocol of session and app. levels. My solution to this problem is to have a Game object running on a thread that uses CountDownLatch to wait upto the timelimit and collects all the votes from the Netty handlers. Any missing votes are given a default vote. If I want to avoid having a thread for each game I have built a Fiber library which provides cooperative lightweight threads. Then each Game object can be a fiber load balanced between a thread per CPU core.
17,A,"Multiple handlers in netty I would like to make a kind of logging proxy in netty. The goal is to be able to have a web browser make HTTP requests to a netty server have them be passed on to a back-end web server but also be able to take certain actions based on HTTP specific things. There's a couple of useful netty exmaples HexDumpProxy (which does the proxying part agnostic to the protocol) and I've taken just a bit of code from HttpSnoopServerHandler. My code looks like this right now: HexDumpProxyInboundHandler can be found at http://docs.jboss.org/netty/3.2/xref/org/jboss/netty/example/proxy/HexDumpProxyInboundHandler.html //in HexDumpProxyPipelineFactory public ChannelPipeline getPipeline() throws Exception { ChannelPipeline p = pipeline(); // Note the static import. p.addLast(""handler"" new HexDumpProxyInboundHandler(cf remoteHost remotePort)); p.addLast(""decoder"" new HttpRequestDecoder()); p.addLast(""handler2"" new HttpSnoopServerHandler()); return p; } //HttpSnoopServerHandler public class HttpSnoopServerHandler extends SimpleChannelUpstreamHandler { public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { HttpRequest request = (HttpRequest) e.getMessage(); System.out.println(request.getUri()); //going to do things based on the URI } } Unfortunately messageReceived in HttpSnoopServerHandler never gets called - it seems like HexDumpProxyInboundHandler consumes all the events. How can I have two handlers where one of them requires a decoder but the other doesn't (I'd rather have HexDumpProxy as it is where it doesn't need to understand HTTP it just proxies all connections but my HttpSnoopHandler needs to have HttpRequestDecoder in front of it)? I've not tried it but you could extend HexDumpProxyInboundHandler and override messageReceived with something like super.messageReceived(ctx e); ctx.sendUpstream(e); Alternatively you could modify HexDumpProxyInboundHandler directly to that the last thing messageReceived does is call super.messageReceived(ctxe). This would only work for inbound data from the client. Data from the service you're proxy-ing would still be passed through without you code seeing it. I tried that and it's much closer to what I want but there is still a problem. Most of the requests are proxied correctly but a few of them end up having the first few hundred bytes cut off which results in an invalid request to the backend server (and the page doesn't render or isn't returned at all). It seems like the HttpRequestDecoder is consuming some of the request before the proxy can send it on. It works when I modify HexDumpProxyInboundHandler to do outboundChannel.write(msg.copy()) or outboundChannel.write(msg.duplicate()) I'm not sure what the difference is to know which one to use I posted another question at http://stackoverflow.com/questions/10215001/whats-the-difference-between-channelbuffer-copy-and-channelbuffer-duplicate There could be a race condition between the code that writes the buffer to the network and the HttpRequestDecoder because they'll both be manipulating the same buffer object. Try sending either a wrapped version or a copy of the original buffer upstream."
18,A,Dealing with fragmentation in Netty I am designing a binary protocol for client/server communication using Netty and the number of bytes sent is not fixed amount and can be arbitrary size. The client is sending something like this: first 4 bytes to represent an id number the remaining bytes is a String In the example I have seen the message has been a fixed size but the String content could be any size and need to ensure it is not fragmented when received by the server. How would I achieve this in Netty? Thanks in advance. Or if its line based you could just use the DelimiterBasedFrameDecoder for the job. See: http://netty.io/docs/stable/api/org/jboss/netty/handler/codec/frame/DelimiterBasedFrameDecoder.html Thanks! It looks like I need to create my own implementation of a FrameDecoder.  How are you determining the end of message? A zero? I would check out the Netty replaying decoder: http://docs.jboss.org/netty/3.2/api/org/jboss/netty/handler/codec/replay/ReplayingDecoder.html It makes things easy for you. Just keep reading until you find a zero. If you run out of bytes before you reach the zero an exception will be thrown to exit the decode method. When more bytes are available the decode method will be called again with the existing bytes and the new bytes combined in one ChannelBuffer. This cycle can repeat until you have the whole message in the ChannelBuffer...which then you can pass up to the next layer for processing. If it was possible to change your protocol I would add a length as being able to read to length is far more efficient than checking every byte for a zero. Yes. Once you have a length you can instead use the LengthFieldBasedFrameDecoder (if your messages are likely to be very large though it is probably better to write your own based on SimpleChannelUpstreamHandler so that the buffer is only allocated once). Hi Gareth thanks for the answer - very appreciated. I am currently not using anything to determine the end of a message. Once I retrieve the id by invoking buffer.readLong() I then invoke buffer.toString(String charsetName) - which is not ideal. When you refer to sending the size of the payload are you suggesting to add it to the beginning and wait until the length is received and use that arbitrary number to determine to wait for more bytes on the server? Thanks very much!
19,A,"Using SPDY with Netty I've set up MOD_SPDY on my Apache server and now want to retrofit my client code to use Netty's SPDY implementation to send my requests to the server over a SPDY channel. This is my first experience using Netty so I think I get that I need to somehow configure my Channel and then send requests through it. The problem is that it doesn't seem very clear exactly how to configure the channels and even after that how to track multiple HTTP requests inside the channel that might be executing concurrently. I've googled around and found the SPDY package: http://netty.io/docs/stable/api/org/jboss/netty/handler/codec/spdy/package-summary.html but the documentation is still quite thin there. I didn't seem to find any examples of using the code only the announcement that it exists in the latest release. Does someone have an example about how to construct a SPDY channel and then send/track multiple requests and responses through it? Also how would this function when the server does not support SPDY and the channel falls back to a standard SSL connection? If you're not tied to Netty maybe you can try Jetty's SPDY see http://webtide.intalio.com/2012/03/spdy-support-in-jetty/ and http://www.smartjava.org/content/how-use-spdy-jetty. @svordet Bill already has a server he needs a client. Actually it looks like sbordet is correct; Jetty also has a SPDY client that might be easier to work with: http://wiki.eclipse.org/Jetty/Feature/SPDY#Using_SPDY_Client_Applications Only example I could find on Netty and SPDY is a test code for SessionHandler and socket echo test. I'm yet to make this thing running but Your client should make pipeline consisting of SpdyFrameCodec SpdySessionHandler and your handler. Your handler should be modeled after EchoHandler in session test because that way SpdySessionHandler does job of decoding raw frames into more meaningful ones and does some things as required by SPDY protocol. As for fall-backing there are SpdyHttpCodec in snapshot version of the Netty that translates from SPDY to HTTP. That way you can build your client handler in terms of HTTP and receive messages that came either through SPDY or HTTP transparently. To do this it is required to implement something similar to port unification example. All that said. There is room for few utility classes/handlers to make all of this an ""out of the box"" experience. I wanted to make a working example but am lacking time right now for it and there would be too much code to simply paste it here as answer. Ah so I just request multiple channels from the factory and under the hood the SPDY handlers will multiplex them? In what order should I add the handlers? Unfortunately it's not that simple but it is possible to make it using provided classes. I'm interested in making this work myself so I'll try to build working code later.  There aren't much examples for using spdy with jetty. I'm usually not one for shameless promotion but I just wrote down a complete example on how to do what you want. I've configured netty to serve spdy when the client supports it and fall back to http when spdy isn't available. You can find the code at: http://www.smartjava.org/content/using-spdy-and-http-transparently-using-netty Ah like that. Then you can still use pretty much the same approach and set of handlers. But instead of using a ServerBootstrap use a ClientBootstrap Thanks for the answer but I'm looking for the opposite. I want an HTTP *Client* that will use SPDY when available but fall back to regular HTTP."
20,A,Netty 4: NioEventLoop rebuild selector too often In the log file at the TRACE level for Netty I have such situation: 09:22:11772 [DEBUG main .logging.InternalLoggerFactory] Using Log4J as the default logging framework 09:22:11780 [DEBUG main til.internal.PlatformDependent] UID: 1000 09:22:11780 [DEBUG main til.internal.PlatformDependent] Java version: 7 09:22:11781 [DEBUG main til.internal.PlatformDependent] -Dio.netty.noUnsafe: false 09:22:11783 [DEBUG main il.internal.PlatformDependent0] java.nio.ByteBuffer.cleaner: available 09:22:11783 [DEBUG main il.internal.PlatformDependent0] java.nio.Buffer.address: available 09:22:11784 [DEBUG main il.internal.PlatformDependent0] sun.misc.Unsafe.theUnsafe: available 09:22:11784 [DEBUG main il.internal.PlatformDependent0] sun.misc.Unsafe.copyMemory: available 09:22:11784 [DEBUG main il.internal.PlatformDependent0] java.nio.Bits.unaligned: true 09:22:11784 [DEBUG main til.internal.PlatformDependent] sun.misc.Unsafe: available 09:22:11784 [DEBUG main til.internal.PlatformDependent] -Dio.netty.noJavassist: false 09:22:11840 [DEBUG main til.internal.PlatformDependent] Javassist: available 09:22:11841 [DEBUG main til.internal.PlatformDependent] -Dio.netty.tmpdir: /tmp (java.io.tmpdir) 09:22:11841 [DEBUG main til.internal.PlatformDependent] -Dio.netty.bitMode: 64 (sun.arch.data.model) 09:22:11841 [DEBUG main til.internal.PlatformDependent] -Dio.netty.noPreferDirect: false 09:22:11843 [DEBUG main tTypeParameterMatcherGenerator] Generated: io.netty.util.internal.__matchers__.ru.concerteza.amber.pult2.message.MessageMatcher 09:22:11872 [DEBUG main nnel.MultithreadEventLoopGroup] -Dio.netty.eventLoopThreads: 8 09:22:11899 [DEBUG main netty.channel.nio.NioEventLoop] -Dio.netty.noKeySetOptimization: false 09:22:11899 [DEBUG main netty.channel.nio.NioEventLoop] -Dio.netty.selectorAutoRebuildThreshold: 512 09:22:11902 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@d8f211f 09:22:11903 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@2fc7812d 09:22:11903 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@52f1c9dc 09:22:11903 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@7ffbb50e 09:22:11903 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@662bebc6 09:22:11903 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@4d844891 09:22:11903 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@27b84f59 09:22:11903 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@3561706e 09:22:11904 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@6e6d863f 09:22:11905 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@5888cabc 09:22:11905 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@7cb62a0c 09:22:11905 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@1b82b9cb 09:22:11905 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@2373cc89 09:22:11905 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@779488e 09:22:11905 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@2b8a6677 09:22:11905 [TRACE main netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@b4d24f6 09:22:11966 [DEBUG main etty.util.ResourceLeakDetector] -Dio.netty.leakDetectionLevel: simple 09:22:12250 [DEBUG main til.internal.ThreadLocalRandom] -Dio.netty.initialSeedUniquifier: 0x6c1182c32deadabe 09:22:12260 [DEBUG main .channel.ChannelOutboundBuffer] -Dio.netty.threadLocalDirectBufferSize: 65536 09:22:12292 [DEBUG main io.netty.buffer.ByteBufUtil ] -Dio.netty.allocator.type: unpooled 09:22:12294 [DEBUG main io.netty.util.NetUtil ] Loopback interface: lo 09:22:12294 [DEBUG main io.netty.util.NetUtil ] Loopback address: /0:0:0:0:0:0:0:1%1 (primary) 09:22:12294 [DEBUG main io.netty.util.NetUtil ] Loopback address: /127.0.0.1 09:22:12295 [DEBUG main io.netty.util.NetUtil ] /proc/sys/net/core/somaxconn: 128 09:22:47569 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47569 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@5f72f8be 09:22:47569 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47576 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47576 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@7528b2e6 09:22:47576 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47582 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47582 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@42f95621 09:22:47582 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47588 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47588 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@7f85b2e0 09:22:47588 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47594 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47594 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@22a2d188 09:22:47594 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47600 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47600 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@6f6a497b 09:22:47600 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47606 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47606 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@2afe6362 09:22:47606 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47612 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47612 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@232eccfb 09:22:47612 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47618 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47618 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@559384c8 09:22:47618 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47631 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47632 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@47f2925c 09:22:47632 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47638 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47639 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@666faeb 09:22:47639 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47645 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47646 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@52e35d95 09:22:47646 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47652 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47653 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@4d150bb6 09:22:47653 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. 09:22:47659 [WARN pGroup-3-1 netty.channel.nio.NioEventLoop] Selector.select() returned prematurely 512 times in a row; rebuilding selector. 09:22:47659 [TRACE pGroup-3-1 netty.channel.nio.NioEventLoop] Instrumented an optimized java.util.Set into: sun.nio.ch.EPollSelectorImpl@20b40143 09:22:47659 [INFO pGroup-3-1 netty.channel.nio.NioEventLoop] Migrated 0 channel(s) to the new Selector. And so on. I have this after channel disconnected. This behavior happens only during some scenarios not every time. Where should I search for a problem? What does this often selector rebuildings mean? That sounds strange. Could you please open a bug report in our issue tracker and add informations like OS java version kernel version and also when this happens. Thanks!  The problem was that the worker thread from new NioEventLoopGroup() have been interrupted from the other thread. See: bug report.
21,A,Netty - How to properly to serve web socket and raw tcp in one single server? I want to use a single instance of netty to serve both web socket(socketio) and raw tcp connections. What i am doing now is to have ONLY a RoutingHandler at start which checks the first byte if it is '['  then remove the RoutingHandler and add tcp handlers to the channel pipeline otherwise add web socket handlers. The code looks like : public class RoutingHandler extends SimpleChannelInboundHandler<ByteBuf> { private final ServerContext context; public RoutingHandler(final ServerContext context) { this.context = context; } @Override protected void channelRead0(final ChannelHandlerContext ctx final ByteBuf in) throws Exception { if (in.isReadable()) { ctx.pipeline().remove(this); final byte firstByte = in.readByte(); in.readerIndex(0); if (firstByte == 0x5B) { this.context.routeChannelToTcp(ctx.channel()); } else { // websocket this.context.routeChannelToSocketIO(ctx.channel()); } ctx.pipeline().fireChannelActive(); final byte[] copy = new byte[in.readableBytes()]; in.readBytes(copy); ctx.pipeline().fireChannelRead(Unpooled.wrappedBuffer(copy)); } } } The code seems to be working but it does not seem the best way to do it especially I am kind of hacking the channel lifecycle by manually calling fireChannelActive() because adding extra handlers do not trigger the active event again hence some initialization code is not run. IS there anything wrong with my solution? What is a better way to do it? Thanks To see this in action take a look at the following game server which does this exactly. It is much the same way mentioned in Nicholas answer. The relevant files that will do this are ProtocolMux and LoginProtocol.  This is referred to as Port Unification. There is a good example of it here although it demonstrates switching between TCP and HTTP (with SSL and/or GZip detection) and not websockets but the principles are the same. Basically you will read in the first 5 bytes to sniff the protocol (more or less as you did) and when the protocol is identified modify the handlers in the pipeline accordingly. Since you need to initiate a websocket through HTTP anyway the example should work for you if you add the websocket upgrade procedure as outlined in this example. Thanks for the pointer it definitely helps
22,A,"Networking Design [Using Netty] I'm working on a multiplayer gaming project and I'm a tad bit confused on how to set it up. Mainly because I'm not familiar with the Netty framework. Should each player have his own Pipe for handling packets? Or should there just be one pipe for handling all inbound packets? If a player should have his own packet how would i make that player the owner of the pipeline? Currently this is my server-code public static void main(String[] params) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG 100) .handler(new LoggingHandler(LogLevel.DEBUG)) .childHandler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel channel) throws Exception { ChannelPipeline pipeline = channel.pipeline(); pipeline.addLast(new LoggingHandler(LogLevel.DEBUG)); pipeline.addLast(""PacketHandler"" new SinglePacketPipe()); System.err.println(""Connection Established - Pipes constructed..""); } }); ChannelFuture future = bootstrap.bind(SERVER_PORT).sync(); System.err.println(""Server initialized..""); // When the server socket is closed destroy the future. future.channel().closeFuture().sync(); } finally { // Destroy all executor groups bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } By definition a Channel in Netty always has its own pipeline. That is if you have 1000 connections you have 1000 pipelines. It is completely up to you to let them have the same set of handlers in those pipelines or to let some of them have different pipeline configuration. Note that a pipeline is dynamically configurable. You can decide what handlers to add/remove in the initChannel() or in your handler's channelRegistered() (or even in any handler methods)."
23,A,Chunking WebSocket Frames with Netty 3.5 Looking through the Netty source I see all the support for chunking TextWebSocketFrames. Meaning the continuation frames the decoder handling and so on. Though I am having a problem figuring out what to use to actually create the chunked frames do I need to write this myself? The encoder seems to be missing it and not sure how I would use the ChunkedWriteHandler without extending it. Thanks. You will need to handle the writing of the frames by yourself so it is up to you to send them in the right sequence and make sure you write them out in the correct order.
24,A,"Best way to search a netty ChannelBuffer for a string (without making a new string)? I have proxy server implemented using Netty in which I decode HTTP requests and then write these requests to an outgoing channel based on their path. I need to extract some information from the content of the HTTP request for some future processing (basically find a substring of the form ""request-id:"" and record for later use. What is the best way to do this? Obviously I can dump the content of the channel buffer into a string and use standard java string searching techniques but is there a straightforward and low-overhead way to do this in netty without creating a new string? For example if there were something like an asCharSequence(CharSet) method for ChannelBuffer I could just use a java Pattern/Matcher. I bumped into this issue a while ago as I was trying to sniff the content type of the bytes contained within a ChannelBuffer. It occurred to me that you might use: channelBuffer.toByteBuffer().asCharBuffer() which you could then pass to a regex Pattern.Matcher since this will not re-allocate the buffer rather it just gets wrapped and re-represented as it were. But this doesn't work because the CharBuffer needs to be Charset.decoded which is probably just as bad as converting the ChannelBuffer to a string. One of the issues with ChannelBufferIndexFinder is that it tends to work best when searching for one specific byte where as when you're searching for a String (or more basically a byte array of length > 1) I could not get it work the way I wanted. I started work on this ChannelBufferIndexFinder implementation called ByteSequenceIndexFinder which helps to find an actual sequence of bytes within a ChannelBuffer but there's a couple of issues with it: Because of the way ChannelBuffer.bytesBefore(...) works it does not return the direct offset of the located array but rather the end of it so you have to subtract byte array length +1 from the returned index to get the offset of the beginning of the byte sequence within the byte buffer. Since the finder must keep state (the number of bytes matched so far) it's not thread safe. I tried replacing the simple state (of one int) with a ThreadLocal but the performance was drastically reduced but it remains an option. There's actually an alternate calling method which is non-standard that address issue #1 and it works like this: ChannelBuffer bufferToSearch = ...; String searchStr = ""....""; ByteSequenceIndexFinder finder = new ByteSequenceIndexFinder(searchStr.getBytes()); int startingOffset = finder.findIn(bufferToSearch); That startingOffset is the offset of the first byte of the matched byte sequence within the channel buffer. Hopefully it might be helpful to you if you need something like this. This is the beginnings of a test case for it.  Can't you use ChannelBuffer.indexOf(...) and pass a ChannelBufferIndexFinder into the method ? http://netty.io/3.6/api/org/jboss/netty/buffer/ChannelBuffer.html#indexOf(int%20int%20org.jboss.netty.buffer.ChannelBufferIndexFinder)"
25,A,"Proper setup for DefaultEventExecutorGroup in Netty 4.0 I am misunderstanding either the role or the setup for the DefaultEventExecutorGroup. I have a handler: HandlerClass: public RequestEventHandler extends LongDelayThreadCapable private final static int SLEEP_IN_SECONDS = 10; public RequestEventHandler() { super(ConfigurationRequestEventHandler.supportedEvent); } @Override public void userEventTriggered(final ConfigurationRequestEvent event) throws Exception { System.out.println(""CONFIGURATION REQUEST @ "" + new Date()); // Simulate a long query to a legacy JDBC connection Thread.sleep(ConfigurationRequestEventHandler.SLEEP_IN_SECONDS * 1000); System.out.println(""CONFIGURATION ANSWER @ "" + new Date()); } which I added to the pipeline like so: Pipeline addition: public SetupTest(final List<ChannelHandler> channelHandlers) { super(); handlers = channelHandlers; executorGroup = new DefaultEventExecutorGroup(Constants.EXECUTOR_THREADS); } public void initChannel(final ChannelPipeline pipeline) throws Exception { Assert.notNull(pipeline ""Pipeline must not be null""); if (handlers != null) { for (final ChannelHandler h : handlers) { if (h instanceof LongDelayThreadCapable) { pipeline.addLast(executorGroup h.getClass().getSimpleName() h); } else { pipeline.addLast(h); } } } } My expectation is that if three events were to come in rapid succession that the events would be handled asynchronously and subsequently the output of the process would be: run CONFIGURATION REQUEST @ [date] CONFIGURATION REQUEST @ [date] CONFIGURATION REQUEST @ [date] CONFIGURATION ANSWER CONFIGURATION ANSWER CONFIGURATION ANSWER but instead the output indicates serial processing: run CONFIGURATION REQUEST @ [date] CONFIGURATION ANSWER CONFIGURATION REQUEST @ [date] CONFIGURATION ANSWER CONFIGURATION REQUEST @ [date] CONFIGURATION ANSWER I have seen a number of posts where there is discussion and statements are made that Netty 4.0 will always use a single thread. This seems contradictory to the idea of this EventGroup. Is it possible to have multiple long queries going at the same time and if so how do we wire pieces together to provide this functionality? It will use the same EventExecutor for the same Channel as otherwise you may would get out of order processing of your handler which is not what you want for TCP. If you really want to do this just use your own Executor in your handler and dispatch stuff manually. So the multiple threads allocated in the DefaultEventExecutorGroup really speak to how many rapid succession calls could come in from multiple channels. So if 10 channels had similar requests come in then they would be processed asynchronously. But when the events all happen in the same channel they are processed serially in order to maintain proper order. Yes? yes this is exactly what happens"
26,A,"Buffer Returned from LengthFieldBasedFrameDecoder too small I am currently evaluating Netty to handle socket comms for a Java client to integrate with a C++ server. The messaging protocol has the following structure - (Type)(SubType)(Length)(MessageBody) with size <4bytes><4bytes><4bytes><...> - The Length includes the header. Following the Netty api I subclass LengthFieldBasedFrameDecoder to receive a valid full packet and then decode each packet depending on the type received. From docs I'm using - lengthFieldOffset = 8 lengthFieldLength = 4 lengthAdjustment = -12 (= the length of HDR1 + LEN negative) initialBytesToStrip = 0 It works fine for about 5 minutes (I'm getting one message every 5 seconds or so) and then the decode event contains a ChannelBuffer that is much shorter than the size of the message. (I have received this message multiple times before the crash). I then obviously get an BufferUnderflowException in my internal decode code. Am I doing something wrong? Should I be guaranteed the correct sized buffer for the message when using LengthFieldBasedFrameDecoder? LengthFieldBasedFrameDecoder class - public class CisPacketDecoder extends LengthFieldBasedFrameDecoder { public CisPacketDecoder(int maxFrameLength int lengthFieldOffset int lengthFieldLength int lengthAdjustment int initialBytesToStrip) { super(maxFrameLength lengthFieldOffset lengthFieldLength lengthAdjustment initialBytesToStrip); } @Override protected Object decode(ChannelHandlerContext ctx Channel channel ChannelBuffer buf) throws Exception { CisMessage message = null; int type = buf.getInt(0); //Type is always first int CisMessageType messageType = CisMessageType.fromIntToType(type); if(messageType != null) { message = messageType.getObject(); if(message != null) { message.decode(buf.toByteBuffer()); } else { System.out.println(""Unable to create message for type "" + type); } } //mark the Channel buf as read by moving reader index buf.readerIndex(buf.capacity()); return message; } } And instantiated here. public class PmcPipelineFactory implements ChannelPipelineFactory { @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""encoder"" new CisPacketEncoder()); pipeline.addLast(""decoder"" new CisPacketDecoder(1024 8 4 -12 0)); pipeline.addLast(""handler"" new MsgClientHandler()); return pipeline; } } You need to call super.decode(..) and operate on the returned ChannelBuffer in your decode(..) method. So it would be like this; public class CisPacketDecoder extends LengthFieldBasedFrameDecoder { public CisPacketDecoder(int maxFrameLength int lengthFieldOffset int lengthFieldLength int lengthAdjustment int initialBytesToStrip) { super(maxFrameLength lengthFieldOffset lengthFieldLength lengthAdjustment initialBytesToStrip); } @Override protected Object decode(ChannelHandlerContext ctx Channel channel ChannelBuffer buf) throws Exception { // THIS IS IMPORTANT!!!!! ChannelBuffer decoded = (ChannelBuffer) super.decode(ctx channel buf); if (decoded == null) { return null; } // NOW ONLY OPERATE ON decoded CisMessage message = null; int type = decoded.getInt(0); //Type is always first int CisMessageType messageType = CisMessageType.fromIntToType(type); if(messageType != null) { message = messageType.getObject(); if(message != null) { message.decode(decoded.toByteBuffer()); } else { System.out.println(""Unable to create message for type "" + type); } } return message; } } Be sure to check the UPPERCASE comments . Thank you very much all working well now. Don't think I would have found that one on my own!"
27,A,best way to code for Netty FrameDecoder.decode I am running into problems coding the FrameDecoder.decode() for a tcp netty client. protected Object decode(ChannelHandlerContext ctx Channel channel ChannelBuffer buffer) throws Exception { In the above signature  the buffer is supposed to contain the bytes that need to be framed. But then why does an obejct have to be returned ? I am aware that if the returned object is null  this indicates that more data is required into this buffer but what happens if I return a buffer with some unread bytes of a partial frame in it ? Will this be invoked with the more bytes added ? Lets say a given invocation of decode() has a buffer with 100 bytes in it. Out of this 100  there are 2 full frames of 25 and 55 bytes and partial frame of 20 bytes. Can I just read the first full frame ( of 25 bytes ) and return the buffer ( with 75 bytes in it - 1 full frame of 55 bytes and another 20 bytes of a partial frame ) ? Will this cause any bytes to be overwritten the next time decode is invoked ? or will it be ok for me to read the next frame ( of 55 bytes ) in the next invocation ? You will return one frame per each call of decode. The FrameDecoder will continue to read and forward the read frames until you return null. The bytes left in the FrameDecoder will get saved and once a new ChannelBuffer was received both will get merged and the FrameDecoders decode(..) method will get called again. Can you please explain a bit with ref to my 100 bytes buffer case : 1. Is it necessary for the frame to be returned ? I mean can I not simply get the bytes of a frame and call a callback  passing these bytes to the callback ? ChannelBuffer frame = buffer.readBytes(length); // length is the number of bytes in the frame callback.invoke(frame) 2. If I read first frame of 25 bytes  then will the next invocation contain the remaining two frames to read now ? or will that lead to corruption of data ?
28,A,Netty: ClosedChannelException when closing channel Why when i'm trying to close channel I got ChannelClosedException thrown? Closing with Channel.close() exception's stacktrace: java.nio.channels.ClosedChannelException at org.jboss.netty.channel.socket.nio.NioWorker.cleanUpWriteBuffer(NioWorker.java:645) at org.jboss.netty.channel.socket.nio.NioWorker.close(NioWorker.java:601) at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.handleAcceptedSocket(NioServerSocketPipelineSink.java:119) at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.eventSunk(NioServerSocketPipelineSink.java:76) at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:60) at org.jboss.netty.channel.Channels.close(Channels.java:720) at org.jboss.netty.channel.AbstractChannel.close(AbstractChannel.java:200) at ru.greencubes.player.PlayerWorkerThread.closeConnection(PlayerWorkerThread.java:107) at ru.greencubes.player.PlayerWorkerThread.shutDown(PlayerWorkerThread.java:282) at ru.greencubes.player.NetworkPlayerThread.disconnect(NetworkPlayerThread.java:1289) at ru.greencubes.player.NetworkPlayerThread.disconnect(NetworkPlayerThread.java:1272) at ru.greencubes.server.Server.run(Server.java:1590) at ru.greencubes.server.ServerThread.run(ServerThread.java:12) I think you should just ignore this. It just told you that the channel was already closed when it tried to write the remaining bytes to the channel. So nothing to worry about. I got the same issue. Is there any way to ensure that the remaining bytes are written to the channel before closing it? I have something like `ch.write(msg); ch.close();` Yes... Use a ChannelFuture. ch.write(msg).addListener(ChannelFuture.CLOSE); CLOSE doesn't exist in ChannelFuture. Sorry its ChannelFutureListener.CLOSE It seems that my problem is another one which we are discussing here: http://stackoverflow.com/questions/8975009
29,A,How to migrate Netty 3.6 to Netty 4.0 for server chunked responses? I've been looking to see how to upgrade a netty 3.x server that uses chunked responses to 4.0. In 3.6.X I used the DefaultHttpChunk and DefaultHttpChunkTrailer classes to do this but I can't quite figure out how to map to the new classes in 4.0. The two implementations of HttpResponse let me to believe that DefaultHttpResponse could act the the chunked portion but I see no equivalent to DefaultHttpChunkTrailer so I can set the trailers. Can somebody point me in the right direction? Also is there a rough idea as to when 4.0 will be code complete and released? Thanks Senthil. Its now like this: HttpChunk -> HttpContent LastHttpChunk -> LastHttpContent HttpResponse / HttpRequest just hold the headers etc but no content.
30,A,"Netty TCP example: how do I send/receive objects? Can I send/receive any sort of object? Looking at the method signature it uses MessageEvent: public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { which according to the API inherits from Object. So just cast that whatever type is expected? Or perhaps use instanceof? From the Netty TPC example on wikipedia: package nettyserver; import java.util.logging.Level; import java.util.logging.Logger; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelStateEvent; import org.jboss.netty.channel.ExceptionEvent; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.SimpleChannelUpstreamHandler; /* Next up is our custom ChannelHandler. You can see that by the name this is an UpstreamHandler. * An UpstreamHandler can receive anything that the Server receives additionally an DownstreamHandler can * capture packets that the server is about to send. However depending on where in the hierarchy level the handler * is placed it can be triggered in different states. * |------| |------| |------| * | DSH1 |->-(""ABCDE"")->| DSH2 |->-(""BCD"")->| DSH3 |->-(""DCB"")->[WEB] * |------| |------| |------| * * Above are three DownstreamHandlers each one with a specific task. * The first (DSH1) DownstreamHandler is the DelimiterBasedFrameDecoder that just output * a String ""ABCDE"" down the stream. The second (DSH2) DownstreamHandler intercepts the output from the * previous DownstreamHandler and performs its specific logic on the input which in this case * is to remove the vowels. Now the third (DSH3) DownstreamHandler will intercept the outgoing message * and it is assigned to reverse the order of the letters. When there's no DonstreamHandlers left in the * ChannelPipeline the output will be sent to the client/server. * * The same principle applies to UpstreamHandlers. If you want to combine the functionality * of the SimpleChannelDownstreamHandler and the SimpleChannelUpstreamHandler there is the class called * SimpleChannelHandler. The SimpleChannelHandler class implements both the Down- and Up-stream interfaces * which allows the handler to manage messages going both ways. * * In this example the SimpleChannelUpstreamHandler will be used. * * */ public class MyMessageHandler extends SimpleChannelUpstreamHandler { private Logger logger = Logger.getLogger(MyMessageHandler.class.getSimpleName()); @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { /* The messageReceived method is where all the messages that passes this UpstreamHandler * will be caught. Below we can use the class MessageEvents getMessage() to retrieve * the message it has intercepted. */ System.out.println(""Server :: Received a new message saying: "" + e.getMessage()); /* We can also use the class MessageEvents getChannel() to retrieve the Channel object * created by the ChannelFactory we instantiated in the Server class. We can then use the Channel * to perform a write() operation on the pipeline (This will go downstream from beginning of the * pipeline to the end). * It is important that you append a newline separator '\n' if you want the ChannelBuffer to be * cleaned and forwarded from the FrameDelimiter. By appending the 'delimiter' you send the * String to its target destination. */ e.getChannel().write(""Hello client! Your IP is "" + e.getRemoteAddress() + ""!\n"" + ""We received your message saying: "" + e.getMessage() + ""\n""); /* We must not forget to call the super.messageReceived(...) for our superclass. If you do not do this * the message will be stuck in the pipeline. */ super.messageReceived(ctx e); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) throws Exception { /* Override method for exceptions. It's good practice to Log the errors that occur in your * errors. */ logger.log(Level.SEVERE e.getCause().toString()); /* We always call the method superclass. */ super.exceptionCaught(ctx e); } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { System.out.println(""Server :: "" + e.getChannel().getRemoteAddress() + "" has connected!""); /* We can specifically handle new connections. * For example add the Channel to a ChannelGroup. */ /* We always call the method superclass. */ super.channelConnected(ctx e); } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { /* We can also handle when a disconnection occur. * Here we could remove the Channel from abovementioned ChannelGroup. */ System.out.println(""Server :: "" + e.getChannel().getRemoteAddress() + "" has disconnected from the Server.""); /* We always call the method superclass. */ super.channelDisconnected(ctx e); } } Admittedly this question made more sense when I first woke up but now that I've written it down...in for a penny. There tons of examples at the netty github repository: https://github.com/netty/netty/tree/3.9/src/main/java/org/jboss/netty/example what are the requirements? https://github.com/netty/netty/blob/3.9/pom.xml or just Netty itself? depends on the example the error for the example is: http://stackoverflow.com/questions/24821923/error-package-org-jboss-netty-channel-socket-nio-does-not-exist"
31,A,Which port to use for RPC calls from Android to Netty remote server if the port 80 taken by Tomcat? I need to implement remote RPC calls from Android device to Netty remote server. The call originates on Android device the server returns the reply then the connection is closed. I plan to use something like RESTful services for these communications. On which port should I run the service? One obvious idea would be to run on port 80 but the port 80 is taken by the Apache Tomcat server that runs on the same machine. I know that a classic Tomcat servlet can service my calls but I want to give Netty a chance. I am not sure if it is ok to use an arbitrary high port like 8080 as probably it may be blocked by some firewall (WLAN router GSM provider device internal etc). Would it be the right approach to use repurpose for Netty RPC some other general usage port (like IMAP port 143) if there is no such service runing on the server? I would advise ports above 1024. Although Netty can use any port ports below 1024 can be classed as privileged. Your application will either need to run as root or use an equivalent to jsvc to start as root get the necessary permissions and then downgrade the user. As for what port you should use - if this is in a corporate environment behind a firewall then you should talk to your sysadmin as they may need to open a port on the firewall. I wouldn't arbitrarily repurpose a port because it may not be open on the firewall or your sysadmins may have services running on the port that might clash.
32,A,How to check if I/O operation is blocking or non-blocking? I am using Netty as the base of my server and JDBC for MySQL. I used BoneCP to pool my JDBC connections. In my server the only I/O operation is JDBC connections.(and PrintWriter for logging exception to a text file) I know that each JDBC connection uses single thread. However if I use BoneCP to pool my connections it will somewhat simulate an asynchronous I/O until all connections are filled. Correct me if I'm wrong. So I was wondering how many connection creations(or JDBC executions) per given period will generate a blocking I/O. What are some ways that I could test if my server is blocked or not? JDBC is a synchronous API meaning that the calling thread blocks for each operation to complete. Given that an operation can take a long time (relatively speaking) to complete then regardless of whether the JDBC driver uses blocking or non-blocking I/O from Netty's perspective it should be considered a blocking operation. Using a connection pool doesn't change this - it just reduces the overhead in obtaining a connection to the database. Assume you perform a select operation and that operation takes 100's of milliseconds to complete because it's returning a lot of data. If you perform that operation on Netty's I/O worker thread then all channels managed by that thread will stall until the JDBC operation completes. How you resolve this really depends on your application requirements. For example test if the database can respond fast enough such that you can perform Netty JDBC operations in the I/O worker thread without impacting clients. This is probably only viable for a lightly loaded server with few client connections. depending on which version of Netty you're using there are different thread pool and executor models you can add to your pipeline to offload JDBC operations from the I/O thread. If you're using a recent enough version of Netty 3 (3.6 I think) or Netty 4 you could offload the JDBC operation to a completely independent thread pool and then raise a custom event on the Netty I/O thread when the JDBC operation completes to continue processing the request. Another point to consider is that if the database is relatively slow and your server is under load you'll need to either place an upper bound on the number of connections you allow or you'll have to suspend reads on Netty channels to give the database an opportunity to catch up
33,A,Save object to memcached with Finagle memcached client com / twitter / finagle / memcached / Client extends BaseClient[ChannelBuffer] so the set is defined as set(key: String flags: Int expiry: Time value: ChannelBuffer): Future[Unit] My question is how can I convert my java Object to a netty ChannelBuffer or I have some other way to set object other than String? Thanks Finally I used thrift to do the serialization. It's just my case because I have heavily used thrift. The disadvantage of thrift serialization: you had to define the struct of the object in the IDL. The advantage is: simple TSerializer serializer = new TSerializer(); byte[] bytes = serializer.serialize(obj); ChannelBuffer buffer = ChannelBufferUtils.bytesToChannelBuffer(bytes);  It's up to you! You can use whatever serialization library you want there is plenty of alternatives. memcached only consider it as a array of bytes.
34,A,"How to run multi applications on the built-in server of play framework 1.2.4? If we want to run the sample application ""booking"" we need to run this command: play run booking Then you can access this hotel booking application like this: [http://localhost:9000/hotels] But if you want to run both ""yabe"" and ""booking"" samples I don't know how. While the tomcat can do this just put them together into the ""webapp"" folder. As play official site seems not mentioned this does anyone know how to run multi applications on the built-in server of play framework(version 1.2.4)? You should to run it on the different ports it can be configured with application.conf For live production you need additional use some frontend HTTP server to allow to co-exists many apps on different ports but working in separate domains on port 80 - see Apache example and ProxyPass settings for the vhost section"
35,A,How netty manage the health of Socket I am beginner in both Java Socket Programming and Netty. Currently  we have a application which uses a pure Java Socket Connection where we manage the health of socket by our own. I wish to understand how netty manages sockets? For how long the port will be open? What will happen if socket connection is dropped? How Netty is maintaining the tcp session? Netty is completely transparent with respect to managing the underlying tcp socket details. For how long the port will be open? Netty allows you to set SO_TIMEOUT on the channel - this is basically a tcp property that raises read timeout alerts and you can write code to respond to this and drop the connection if you desire so. See ChannelOptions What will happen if socket connection is dropped? If you use a SimpleChannelUpstreamHandler  then its channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) will be invoked. See SimpleChannelUpstreamHandler How Netty is maintaining the tcp session? Not sure exactly what you mean but it basically is the same mechanics used in the a tcp protocol. @trustin - yes it is OIO i am referring too ( because NIO is non-blocking ). and if theres no alerts on SO_TIMEOUT whats the significance of allowing this option to be setup on the channel ? SO_TIMEOUT works only for the OIO transport and Netty does not close a connection or raise any exceptions or alerts because of it. SO_TIMEOUT is a read timeout. It doesn't cause the connection to be dropped and it wouldn't be observed by Netty anyway as it is in non-blocking mode. Shorter SO_TIMEOUT is for shorter duration it will wait for each `InputStream.read()`. This is an important tuning parameter for OIO because `InputStream.read()` will block if there's nothing in the recv buffer. The default is 1 second which means `InputStream.read()` will wait at most for 1 second until it checks its task queue. @EJP - corrected myself. Thanks for pointing out. Netty also has a blocking mode if one wants to use.
36,A,"Netty sendBufferSize receiveBufferSize bootstrap options Could you explain me the idea behind sendBufferSize receiveBufferSize options that are used together with bootstrap: bootstrap.setOption(""sendBufferSize"" 1048576); bootstrap.setOption(""receiveBufferSize"" 1048576); I noticed they can improve performance of the following code when big-size data is transferred between clients: // encode method in OneToOneEncoder subclass -> 1st client ChannelBuffer buffer = ChannelBuffers.buffer(capacity); buffer.writeInt(myData); // decode method in FrameDecoder subclass -> 2nd client int myData = buffer.readInt(); Thanks! These options specify the buffer sizes on the Channel's underlying Java Socket instances. There is a good summary of what those mean in What are SO_SNDBUF and SO_RECVBUF."
37,A,"Are there any restrictions in writing multiple http responses? I am building a HTTP proxy with netty which supports HTTP pipelining. Therefore I receive multiple HttpRequest Objects on a single Channel and got the matching HttpResponse Objects. The order of the HttpResponse writes is the same than I got the HttpRequest. If a HttpResponse was written the next one will be written when the HttpProxyHandler receives a writeComplete event. The Pipeline should be convenient: final ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""writer"" new HttpResponseWriteDelayHandler()); pipeline.addLast(""deflater"" new HttpContentCompressor(9)); pipeline.addLast(""handler"" new HttpProxyHandler()); Regarding this question only the order of the write calls should be important but to be sure I build another Handler (HttpResponseWriteDelayHandler) which suppresses the writeComplete event until the whole response was written. To test this I enabled network.http.proxy.pipelining in Firefox and visited a page with many images and connections (a news page). The problem is that the browser does not receive some responses in spite of the logs of the proxy consider them as sent successfully. I have some findings: The problem only occurs if the connection from proxy to server is faster than the connection from proxy to browser. The problem occurs more often after sending a larger image on that connection e.g. 20kB The problem does not occur if only 304 - Not Modified responses were sent (refreshing the page considering browser cache) Setting bootstrap.setOption(""sendBufferSize"" 1048576); or above does not help Sleeping a timeframe dependent on the responses body size in before sending the writeComplete event in HttpResponseWriteDelayHandler solves the problem but is a very bad solution. I found the solution and want to share it if anyone else has a similar problem: The content of the HttpResponse is too big. To analyze the content the whole HTML document was in the buffer. This must be splitted in Chunks again to send it properly. If the HttpResponse is not chunked I wrote a simple solution to do it. One needs to put a ChunkedWriteHandler next to the logic handler and write this class instead of the response itself: public class ChunkedHttpResponse implements ChunkedInput { private final static int CHUNK_SIZE = 8196; private final HttpResponse response; private final Queue<HttpChunk> chunks; private boolean isResponseWritten; public ChunkedHttpResponse(final HttpResponse response) { if (response.isChunked()) throw new IllegalArgumentException(""response must not be chunked""); this.chunks = new LinkedList<HttpChunk>(); this.response = response; this.isResponseWritten = false; if (response.getContent().readableBytes() > CHUNK_SIZE) { while (CHUNK_SIZE < response.getContent().readableBytes()) { chunks.add(new DefaultHttpChunk(response.getContent().readSlice(CHUNK_SIZE))); } chunks.add(new DefaultHttpChunk(response.getContent().readSlice(response.getContent().readableBytes()))); chunks.add(HttpChunk.LAST_CHUNK); response.setContent(ChannelBuffers.EMPTY_BUFFER); response.setChunked(true); response.setHeader(HttpHeaders.Names.TRANSFER_ENCODING HttpHeaders.Values.CHUNKED); } } @Override public boolean hasNextChunk() throws Exception { return !isResponseWritten || !chunks.isEmpty(); } @Override public Object nextChunk() throws Exception { if (!isResponseWritten) { isResponseWritten = true; return response; } else { HttpChunk chunk = chunks.poll(); return chunk; } } @Override public boolean isEndOfInput() throws Exception { return isResponseWritten && chunks.isEmpty(); } @Override public void close() {} } Then one can call just channel.write(new ChunkedHttpResponse(response) and the chunking is done automatically if needed."
38,A,Error Compiling Netty latest (Master) version I would like to test some of the latest features locate in netty Master branch at github. (git://github.com/netty/netty.git) I'm doing the following steps: Open new empty directory on my local machine Type git init Type git pull git://github.com/netty/netty.git Compile pom.xml using maven as follow: mvn clean package I now get the following compliation error: [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 13.855s [INFO] Finished at: Sun Jan 08 12:14:21 IST 2012 [INFO] Final Memory: 16M/176M [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:compile (default-compile) on project netty: Compilation failure: Compilation failure: [ERROR] \tradair\tools\netty\src\main\java\io\netty\util\internal\LegacyLinkedTransferQueue.java:[65561] type parameters of <E>E cannot be determined; no uniqu e maximal instance exists for type variable E with upper bounds Ejava.lang.Object [ERROR] \tradair\tools\netty\src\main\java\io\netty\util\internal\LegacyLinkedTransferQueue.java:[73953] type parameters of <E>E cannot be determined; no uniqu e maximal instance exists for type variable E with upper bounds Ejava.lang.Object [ERROR] \tradair\tools\netty\src\main\java\io\netty\util\internal\LegacyLinkedTransferQueue.java:[82757] type parameters of <E>E cannot be determined; no uniqu e maximal instance exists for type variable E with upper bounds Ejava.lang.Object [ERROR] \tradair\tools\netty\src\main\java\io\netty\util\internal\LegacyLinkedTransferQueue.java:[88065] type parameters of <E>E cannot be determined; no uniqu e maximal instance exists for type variable E with upper bounds Ejava.lang.Object Can you please advise what I'm doing wrong. I don't see such an error when I tried it. It ends in a failure however not because of compilation errors as in your case. The failure I see are in the _unit tests_. I am using Maven 3.0.3 with Java 6. A minor side note: The idiomatic recipe for downloading and building netty is to simply:`git clone git://github.com/netty/netty.git`. You don't have to `git init` and `git pull`. You are correct about git!!! Any other ideas on how to compile the latest version? That's a java bug (I hit it before also). Upgrade to latest jdk and it will work. I don't recall what exactly version of java was giving the problems Great works with jdk1.6.0_30 but now I get another error an 9 2012 1:49:20 PM io.netty.handler.ssl.AbstractSocketSslEchoTest ARNING: Unexpected exception from the client side ava.net.SocketException: Software caused connection abort: recv failed any idea what to next.  LinkedTransferQueue back-porting was done recently in master so you better try with latest version of JDK 6 (>= 1.6.0_25 a compiler bug?) Great works with jdk1.6.0_30 but now I get another error `an 9 2012 1:49:20 PM io.netty.handler.ssl.AbstractSocketSslEchoTest ARNING: Unexpected exception from the client side ava.net.SocketException: Software caused connection abort: recv failed` any idea what to do now?
39,A,How to get String from HTTP response to form another request Netty 4.0.10 I'm very new to Netty and not very versed in Java and I'm trying to make a client that connects and downloads a HLS stream from Wowza. My goal is not to view the video but to be able to make multiple simultaneous connections for stress testing a HLS stream provided by a Wowza server. I've been using the HttpSnoopClient example as a starting point and the example client successfully connects and downloads the playlist content from the url provided as an argument (wowza-server/stream-name/playlist.m3u8). Now i have to form a new connection/request using the original URI and replacing playlist.m3u8 with a part of the received response that I'm parsing (something like chunklistxxxx.m3u8). After that i need to process that response that will give me links to video files and form new consecutive connections/requests for downloading those files. After the downloads are finished the process is repeated for new chunks. My question is: How can i get the processed String from HttpSnoopClientHandler back to the main class so i can form a new connection? Typically you could define a member field in your HttpSnoopClientHandler: class HttpSnoopClientHandler ... { final BlockingQueue<String> content = new LinkedBlockingQueue<>(); final StringBuilder contentBuffer = new StringBuilder(...); public void channelRead0(...) { // On every HttpContent: contentBuffer.append(...); // On LastHttpContent: content.add(contentBuffer.toString()); contentBuffer.setLength(0); } } Then you can get the content from your Main class: HttpSnoopClientHandler h = channel.pipeline().get(HttpSnoopClientHandler.class); String content = h.content.poll(timeout timeUnit);
40,A,"Writing two types of message to a channel with Netty 4.x With Netty's new 4.x API there have been some changes (some big some small). I have migrated an old server core of mine to work with the new API but I cannot figure out a way to solve this problem. In 3.x I could use  MessageEvent e This allowed me to cast e to the type I needed (in this case ServerMessage and String as those were the two types used for server->client messages). When using 3.x I could do:  public void writeRequested(ChannelHandlerContext chctx MessageEvent e) { if(e.getMessage() instanceof ServerMessage) //change { ServerMessage message = (ServerMessage) e.getMessage(); Channels.write(chctxe.getFuture()message.getData()); logger.debug(""Message sent (id: ""+message.getMessageID()+ "" data: ""+message.getMessageBody()+"")""); } else if(e.getMessage() instanceof String) { String data =(String)e.getMessage(); ChannelBuffer buffer = ChannelBuffers.buffer(data.length()); buffer.writeBytes(data.getBytes()); Channels.write(chctxe.getFuture()buffer); logger.debug(""Written string (possible <policy-file-request />) to client #id ->"" + +Environment.getGameInstance().getManager().getSession(chctx.getChannel()); } } However with 4.x I am a bit confused to what I can use. I have partially implemented simple sending like so; public void encode(ChannelHandlerContext ctx ServerMessage msg ByteBuf buffer) { if(msg instanceof ServerMessage) { ServerMessage message = (ServerMessage)msg; ctx.channel().write(message.getData()); logger.debug(""Message sent (id: ""+message.getMessageID()+ "" data: ""+message.getMessageBody()+"")""); } else { // string stuff here } } My basic problem is that how would I go about writing a String as well as a ServerMesssage to the client? (My String is a simple ) Any help is greatly appreciated! Just use the common super-class of the two messages and then cast as you did in 3.x if you really want to use the same ChannelHandler for both Objects. Anyway I think it would be much more clean if you just use two different ChannelHandler."
41,A,"Play Framework Websocket server does not process Ping frames from netty client Dealing with Websockets I took netty's client and a server (code pasted below) which I built with Play Framework (2.2.1) using Scala (2.10.2). The server does not react on client's Ping messages. Neither takes the Iteratee notice of any incoming Ping message nor does the Framework itself respond to Ping messages. However my application processes incoming binary frames. This looks strange to me because in Netty's code Binary frames are pretty similar to Ping frames. The only difference which I am aware of is the OpCode i.e. 0x9 for Ping and 0x2 for Binay. Can anyone explain this behaviour and give me a hint how to deal with Websocket Ping/Pong frames in Play Framework? def connect = WebSocket.using[Array[Byte]] { request => // connection attempts are also indicated if client sends 'PingWebSocketFrame' Logger.info(""Someone just connected!?"") val (out channel) = Concurrent.broadcast[Array[Byte]] // Messages of netty's type 'PingWebSocketFrame' never enter here val in = Iteratee.foreach[Array[Byte]] { msg => // the following line is printed if netty's 'BinaryWebSocketFrame' was sent BUT // never if netty's 'PingWebSocketFrame' was sent why? println(""Some Binary data arrived being of length "" + msg.length + "" [bytes]"") } (in out) } I found a further discussion about Websocket ping frames in Play [here](https://groups.google.com/forum/#!searchin/play-framework/websocket$20ping/play-framework/D3veSt-Cv3Y/hgsXiT5lfDsJ) Playframework didn't support pingframe. It simply ignored it. Now that is fixed in master https://github.com/playframework/playframework/pull/2130"
42,A,"Memory leak in my ByteToMessageDecoder class I am new to netty. I have to use static pipelines (because the project manager prefers it). And it is a little bit difficult because I have to handle RTP and RTSP protocols on the same line. Althought it almost works but there is memory leak. I guess the fault in my splitter class. Moreover I think the error might be near bypass method (because the developers of netty - in order the avoide infinitive loop - do not allow to leave ByteBuf unchanged that is why I had to create the bypass method.) If you have any idea please help me! (Thanks in advance!) Here is my code: import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.MessageList; import io.netty.handler.codec.ByteToMessageDecoder; import java.util.ArrayList; import java.util.List; public class Splitter extends ByteToMessageDecoder { private ByteBuf bb = Unpooled.buffer(); final RtspClientHandler rtspClientHandler; final RtpClientHandler rtpClientHandler; public Splitter(RtspClientHandler rtspClientHandler RtpClientHandler rtpClientHandler) { this.rtspClientHandler = rtspClientHandler; this.rtpClientHandler = rtpClientHandler; } protected void bypass(ByteBuf in MessageList<Object> out) { bb.writeBytes(in); in.discardReadBytes(); bb.retain(); out.add(bb); } @Override protected void decode(ChannelHandlerContext ctx ByteBuf in MessageList<Object> out) throws Exception { if (rtspClientHandler.getRTSPstate() == RtspClientHandler.RTSP_CLIENT_STATE.READY) { if (in.getByte(0) == 0x24 && in.readableBytes() > 4) { int lengthToRead = in.getUnsignedShort(2); if (in.readableBytes() >= (lengthToRead + 4)) { in.skipBytes(4); if (in.getByte(16) == 0x67 || in.getByte(16) == 0x68) { final byte bytes[] = new byte[lengthToRead]; in.readBytes(bytes); in.discardReadBytes(); SPSPPSbuffer spspps = new SPSPPSbuffer(); spspps.setSPSPPS(bytes); out.add(spspps); } else { final byte packetArray[] = new byte[lengthToRead];// copy packet. in.readBytes(packetArray); in.discardReadBytes(); out.add(packetArray); } } } else { bypass(in out); } } else { bypass(in out); } } } What are the symptoms of the leak? Exception raised from which line any other? Null pointer exception raised from netty after 30 minutes of working. The Heap Memory Usage was raising continuously. When it reached about 25GBytes the exception raised. Have you still the stacktrace on screen / some file? It at least tells where it failed on that case. Sorry I cleared it by mistake but on Monday I am going to repeat the test. (Because the camera can be reached only in my workplace.) It seems I could manage to solve it. The main thing is: I had to use a collector ByteBuf in which I collects all bytes coming from the net (I had to clear the input ByteBuf) because there are 4 cases possible: The num. of bytes (in the collector) are less than the RTP chunk size The num. of bytes (in the collector) are equals the RTP chunk size The num. of bytes (in the collector) are bigger than the RTP chunk size More than one chunks are in the collector ByteBuf. Here is the code: import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.MessageList; import io.netty.handler.codec.ByteToMessageDecoder; public class Splitter extends ByteToMessageDecoder { private ByteBuf collector = Unpooled.buffer(); final RtspClientHandler rtspClientHandler; final RtpClientHandler rtpClientHandler; public Splitter(RtspClientHandler rtspClientHandler RtpClientHandler rtpClientHandler) { this.rtspClientHandler = rtspClientHandler; this.rtpClientHandler = rtpClientHandler; } @Override protected void decode(ChannelHandlerContext ctx ByteBuf in MessageList<Object> out) throws Exception { collector.writeBytes(in); in.discardReadBytes(); in.clear(); if (rtspClientHandler.getRTSPstate() != RtspClientHandler.RTSP_CLIENT_STATE.READY) { System.out.println(""RTSP communication in progress""); collector.retain(); out.add(collector); return; } if (collector.readableBytes() > 0 && collector.getByte(0) != 0x24) { System.out.println(""Clearing the Unpooled.buffer() (because it does not start with 0x24)""); collector.readerIndex(collector.writerIndex()); collector.discardReadBytes(); } System.out.println(""*****New bytes arrived""); while (collector.readableBytes() > 0 && collector.getByte(0) == 0x24) { System.out.println(""Length: "" + collector.readableBytes()); if (collector.readableBytes() > 4) { int lengthToRead = collector.getUnsignedShort(2); if (collector.readableBytes() >= (lengthToRead + 4)) { collector.skipBytes(4); if (collector.getByte(16) == 0x67 || collector.getByte(16) == 0x68) { final byte bytes[] = new byte[lengthToRead]; collector.readBytes(bytes); collector.discardReadBytes(); SPSPPSbuffer spspps = new SPSPPSbuffer(); spspps.setSPSPPS(bytes); out.add(spspps); } else { final byte packetArray[] = new byte[lengthToRead];// copy packet. collector.readBytes(packetArray); collector.discardReadBytes(); out.add(packetArray); } } else { System.out.println(""Not enough length "" + (lengthToRead + 4) + "" byte should be required (together with 4 bytes header)""); return; } } else { System.out.println(""Less than 5 bytes""); return; } } } }"
43,A,"Netty 4.0.x Correctly catch a ConnectException I'm developing an application with Netty and I need to handle the ConnectException on the client side thrown in case for example of a connect timeout. Here's the code import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.util.concurrent.Future; import io.netty.util.concurrent.FutureListener; public class ConnectTest { public static void main(String[] args) throws Exception { Bootstrap b = new Bootstrap(); b.group(new NioEventLoopGroup()).channel(NioSocketChannel.class) .handler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { } }); final ChannelFuture f = b.connect(""0.0.0.0"" 8080); f.addListener(new FutureListener<Void>() { @Override public void operationComplete(Future<Void> future) throws Exception { if (!f.isSuccess()) System.out.println(""Test Connection failed""); } }); f.sync(); } } And this is the result:  Test Connection failed Exception in thread ""main"" java.net.ConnectException: Connection refused: no further information: /0.0.0.0:8080 at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source) at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:208) at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:287) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:524) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:464) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:378) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:350) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116) at java.lang.Thread.run(Unknown Source) As you can see the listener works fine but i still get an ugly stacktrace printed out and I can't figure out where to intercept it. Any hints? Can you include a (SSCCE)[http://www.sscce.org/] and stack trace? the culprit is f.sync() You could handle ConnectExceptions in the listener :  final ChannelFuture f = b.connect(""0.0.0.0"" 8080); f.addListener(new FutureListener<Void>() { @Override public void operationComplete(Future<Void> future) throws Exception { if (!f.isSuccess()) { System.out.println(""Test Connection failed""); handleException(future.cause()); } } }); //f.sync(); ok that solves the problem but i don't get it what if I want the calling thread (Main in the example) to wait for the bootstrap to connect? Are you telling me that sync() should never be called on a ChannelFuture obtained from a connect? Usually you want everything to be asynchronous and try not blocking but if you have to ... handle exceptions with try-catch block around f.sync() ok got it I tried before with a try catch around the f.sync but with a catch on ConnectException and not on Exception. So f.sync isn't really the culprit you solved my problem but i suggest you to correct the answer just to make things more clear"
44,A,"ES timeout after upgrade on a single cluster So I've had ES version 0.19.4 and wanted to upgrade to 0.20.6 as my clusters didn't have any information that I couldn't easily recover I deleted the indices's and completely cleared down my es data folder removed the 0.19.4 version and as I start up I somehow cannot use my original cluster name the ES starts fine with any other cluster name but not with ""aggr"" the one I used before as I wanted to make sure nothing else is using old Elastic Search I even rebooted the computer (don't have any on startup software on this test system) so essentially everything is clear but I can't use the old cluster name... The stack: [2013-04-03 13:37:59902][WARN ][discovery.zen.ping.multicast] [Orchid] failed to connect to requesting node [Kaur Benazir][by0TZFhXR1mUxBd9T6bi9w][inet[/xxx.xxx.xx.xxx.xxxx]]{client=true data=false} org.elasticsearch.transport.ConnectTransportException: [Kaur Benazir][inet[/xxx.xxx.xx.xxx.xxxx]] connect_timeout[30s] at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:671) at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:610) at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:580) at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:127) at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:536) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:722) Caused by: java.net.ConnectException: connection timed out at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:136) at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:82) at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312) at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:41) at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) ... 3 more All of the elasticsearch.yml settings are commented out apart from: cluster.name: aggr Also when Elastic Search starts on my testing machine which is connected on internal network I see in the logs: [2013-04-03 13:37:27281][INFO ][node ] [Orchid] {0.20.6}[4484]: initializing ... [2013-04-03 13:37:27287][INFO ][plugins ] [Orchid] loaded [] sites [] [2013-04-03 13:37:29633][INFO ][node ] [Orchid] {0.20.6}[4484]: initialized [2013-04-03 13:37:29633][INFO ][node ] [Orchid] {0.20.6}[4484]: starting ... [2013-04-03 13:37:29710][INFO ][transport ] [Orchid] bound_address {inet[/0:0:0:0:0:0:0:0:9300]} publish_address {inet[/**My internal IP**:9300]} [2013-04-03 13:37:32739][INFO ][cluster.service ] [Orchid] new_master [Orchid][MzSRtsCfR2W3S_QyG_QLQg][inet[/**My internal IP**:9300]] reason: zen-disco-join (elected_as_master) [2013-04-03 13:37:32818][INFO ][discovery ] [Orchid] aggr/MzSRtsCfR2W3S_QyG_QLQg [2013-04-03 13:37:32857][INFO ][http ] [Orchid] bound_address {inet[/0:0:0:0:0:0:0:0:9200]} publish_address {inet[/**My internal IP**:9200]} [2013-04-03 13:37:32857][INFO ][node ] [Orchid] {0.20.6}[4484]: started [2013-04-03 13:37:32945][INFO ][gateway ] [Orchid] recovered [0] indices into cluster_state And in the error log right afterwards I see the log for my server machine which is connected with and external IP: [2013-04-03 13:37:59902][WARN ][discovery.zen.ping.multicast] [Orchid] failed to connect to requesting node [Kaur Benazir][by0TZFhXR1mUxBd9T6bi9w][inet[/**My external IP**:9301]]{client=true data=false} org.elasticsearch.transport.ConnectTransportException: [Kaur Benazir][inet[/**My external IP**:9301]] connect_timeout[30s] How can this be? How can my system start on my internal machine and throw an error linking to my external machine? Again the only setting set in the ES.yml is the cluster name.. It looks like you still have old client node running somewhere: [Kaur Benazir][inet[/xxx.xxx.xx.xxx.xxxx]] You need to shut it down before starting the cluster with the new version. This client is probably running in your web application that is using elasticsearch an while you upgraded elasticsearch server you didn't upgrade elasticsearch library in this application. Do you have any java app running on xxx.xxx.xx.xxx? Try shutting it down. Try this shut everything down and try running `curl xxx.xxx.xx.xxx:yyyy` where yyyy is port in the log - 100. So if it was 9300 try connecting to 9200. Do you get back a response? Changing version is a big deal. Elasticsearch nodes with different versions shouldn't be combined into the same cluster. And you cannot run two elasticsearch clusters with the same cluster name but different versions on the same network unless you turn off multicast which is clearly enabled on this machine. okay so it doesn't return anything just hangs however I noticed something different when the elasticsearch starts I get weird info in the loggs they slipped by me I will edit my post in a second Kaur Benazir is a client node. Do you have some stale instance of your web app running? Try killing all java processing on you machine. I have an Elastic Search instance running on my external server but how should that intervene the startup of an elastic search instance on an internal machine that is trying to host on a localhost? I never had this problem before. That's what I thought was happening the problem is I only run ES on my localhost and restarted a couple of times to make sure all the programs get killed. And none of them automatically start up :/ Main reason why I'm asking.. Can your external machine receive multicast packets from your internal machine? Updated the answer. I do not know this but I got about 7 machines rigged onto that one and none of them had any problems with each and individual locally hosted Elastic Search how would that change things? As I said the only change made was the version of ES. p.s. I'm really glad you're helping me not many people out there comment on ES threads. My typical approach to starting my apps is start ES>start app> close app> stop ES. And yes I made sure all the webapps of mine that use elastic search are killed as I said restarted couple times as well. :/ I'm in a pickle I know your answer should be correct I had the same feeling after doing some digging.. Still can't identify the problem though."
45,A,"netty in applet throws AccessControlException I am using netty 3 in applet and when I start it from a browser it gives me following stacktrace in Java Console if I run from Eclipse Applet Viewer then this issue does not happen: network: Cache entry not found [url: http://<IP address>/crossdomain.xml version: null] network: Connecting http://<IP address>/crossdomain.xml with proxy=DIRECT network: Connecting http://<IP address>:80/ with proxy=DIRECT java.net.ConnectException: Connection refused: connect at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) at java.net.DualStackPlainSocketImpl.socketConnect(Unknown Source) at java.net.AbstractPlainSocketImpl.doConnect(Unknown Source) at java.net.AbstractPlainSocketImpl.connectToAddress(Unknown Source) at java.net.AbstractPlainSocketImpl.connect(Unknown Source) at java.net.PlainSocketImpl.connect(Unknown Source) at java.net.SocksSocketImpl.connect(Unknown Source) at java.net.Socket.connect(Unknown Source) at sun.net.NetworkClient.doConnect(Unknown Source) at sun.net.www.http.HttpClient.openServer(Unknown Source) at sun.net.www.http.HttpClient.openServer(Unknown Source) at sun.net.www.http.HttpClient.<init>(Unknown Source) at sun.net.www.http.HttpClient.New(Unknown Source) at sun.net.www.http.HttpClient.New(Unknown Source) at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(Unknown Source) at sun.net.www.protocol.http.HttpURLConnection.plainConnect(Unknown Source) at sun.net.www.protocol.http.HttpURLConnection.connect(Unknown Source) at com.sun.deploy.net.CrossDomainXML$3.run(Unknown Source) at java.security.AccessController.doPrivileged(Native Method) at com.sun.deploy.net.CrossDomainXML.privilegedConnect(Unknown Source) at com.sun.deploy.net.CrossDomainXML.check(Unknown Source) at com.sun.deploy.net.CrossDomainXML.check(Unknown Source) at sun.plugin2.applet.SecurityManagerHelper.checkConnectHelper(Unknown Source) at sun.plugin2.applet.AWTAppletSecurityManager.checkConnect(Unknown Source) at sun.nio.ch.SocketChannelImpl.connect(Unknown Source) at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.connect(NioClientSocketPipelineSink.java:150) at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:113) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:771) at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:60) at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591) at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582) at org.jboss.netty.channel.Channels.connect(Channels.java:541) at org.jboss.netty.channel.AbstractChannel.connect(AbstractChannel.java:210) at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:227) at org.jboss.netty.bootstrap.ClientBootstrap.connect(ClientBootstrap.java:188) at org.mypackage.Myclass.connect(Client.java:80) And also this Exception caught: [id: 0x00498342] EXCEPTION: java.security.AccessControlException: access denied (""java.net.SocketPermission"" ""<IP address>:18090"" ""connectresolve"") Exception caught: [id: 0x00498342] EXCEPTION: java.nio.channels.ClosedChannelException I test at local PC but specify its IP address to connect. This is line 80 in my connect method: future = bootstrap.connect(new InetSocketAddress(host port)); I have tried to surround it with no success  AccessController.doPrivileged( new PrivilegedAction<Void>() { public Void run () { MyClass.connect(type userId secondValue); return null; } } ); Please advice how can I solve it? Is applet signed ? @fatfredyy no I have figured out that I need to sign it. Haven't tried it yet though I was able to solve the problem. First I have tried to connect to 127.0.0.1 but for that I had to install Jetty and put my applet and hmtl inside jetty. So it started to work for localhost only. Socket connection to originating server of an unsigned Java applet It still didn't work for 10.x.y.z so I had to sign applet Is is possible to sign a java applet for free? and also to create crossdomain.xml in jetty like here: access denied (java.net.SocketPermission 127.0.0.1:8080 connectresolve)"
46,A,"Netty on Android - Accessing sun.misc.Unsafe I have experimenting with netty-4-alpha websockets (great work!) + SSL on native Android communicating with a netty server. I got it running BUT only after I made a change to how to get hold of the sun.misc.Unsafe instance in LinkedTransferQueue. Unfortunately the UnsafeDetectUtil class only checks if sun.misc.Unsafe can be loaded but on Android it fails when it tries to fetch the actual Unsafe instance since (on android) it is not called ""theUnsafe"" but instead ""THE_ONE"". Once I tried with that it worked fine. My question is if you are interested in fixing this so netty can run on Android? I can of course fix it and send a pull request. Two possible solutions: - Improve the UnsafeDetectUtil so it actually tries to fetch the unsafe instance before it returns true. - Change LinkedTransferQueue so it also tries with ""THE_ONE"" (not sure how Unsafe is implemented on Android so it might be safer to not use it there). Please fill a pullrequest with improved UnsafeDetectUtil. I will merge it asap then! Thanks Great pull request has been sent Thanks changes were merged into netty."
47,A,Can I call `Channel.write()` in non-Netty thread? For some reason I need write messages to channel(the operation is at server side and the channel is already connected.) in non-netty thread. But I found that my client can't get the message though I got the success future. So how can I do this in right way? And my netty version is 3.6.6-final. There is no restriction to what thread you call `write` from. Especially on the client side it is regular practice to call it from your own thread and I can attest from personal experience that it works. channel.write() is thread safe so don't worry about that . Thanks for your advice. Finally I got the message and I found it was going wrong because the bad string encoding method.
48,A,Benefits of Netty over basic ServerSocket server? I need to create a relatively simple Java tcp/ip server and I'm having a little trouble determining if I should use something like Netty or just stick with simple ServerSocket and InputStream/OutputStream. We really just need to listen for a request then pass the new client Socket off to some processing code in a new thread. That thread will terminate once the processing is complete and the response is sent. I like the idea of pipelines decoders etc. in Netty but for such a simple scenario it doesn't seem worth the added up front development time. It seems like a bit overkill for our initial requirements but I'm a little nervous that there are lots of things I'm not considering. What if any are the benefits of Netty for such simple requirements? What am I failing to consider? If this is one of your first projects with sockets use low-level to gain a better understanding. When evaluate higher-level API and choose the one you like more: Netty Mina ProtocolBuffers etc. First write the logic of your service so that it's independent of your communication layer. As Victor Sorokin said there's a learning advantage to doing it yourself. So it ought to be worthwhile to write it with sockets. It will involve less effort to get started and if it works well enough then you're off to the races. If you find that you need more scalability/robustness later you can switch to netty. Just write a new netty layer that communicates for your service logic layer and swap them out.  The main advantage of Netty over simply reading from and writing to sockets using streams is that Netty supports non-blocking asynchronous I/O (using Java's NIO API); when you use streams to read and write from sockets (and you start a new thread for each connected accepted from a ServerSocket) you are using blocking synchronous I/O. The Netty approach scales much better which is important if your system needs to be able to handle many (thousands) of connections at the same time. If your system does not need to scale to many simultaneous connections it might not be worth the trouble to use a framework like Netty. Some more background information: Threads are relatively expensive resources in an operating system. Each thread needs memory for the stack (which can be for example 2 MB in size). When you create thousands of threads this is going to cost a lot of memory; also operating systems have limits on the number of threads that can be created. So you don't want to start a new thread for each accepted connection. The idea of asynchronous I/O is to decouple the threads from the connections (no one-to-one relation). There can be many more connections than threads and whenever some event happens on one of the connections (for example data is received) a thread from a thread pool is temporarily used to handle the event.  I think that the benefits of using netty are not immediate but actually come later when requirements change and maintenance becomes more complex for your project. Netty brings built in understanding of the HTTP protocol so that you can provide simple RESTful web services. Also you have the option of utilizing asynchronous request processing that netty provides as a framework so that you can potentially get better performance and service several orders of magnitude more concurrent requests.
49,A,Handling received messages directly in the Client (using nio trough the netty-framework) I have made an client - server example using netty. I have defined handlers for the server and the client. Basically I connect with the client to the server and send some messages. Every received message gets send back (with the content of the message being converted to upper case). All the work on the received messages on server and client-side is done by the defined handlers. But I would like to use or better receive/accept some of the messages directly in the client not (just) in the handler. So my question is is it possible to have some listener to receive messages directly in the client-program and not in its handlers. The thin is I would like to access the received messages within the (executable) program (basically the class with a main method) that created a new client object using something like a timer which (or a loop) which would periodically check for new messages. I would appreciate if someone could help me with this issue. Or at least tell me if its even possible with netty . You're looking to translate netty's event-based model into a polling model. A simple way to do that is to create a message queue: //import java.util.concurrent.BlockingQueue; //import java.util.concurrent.LinkedBlockingQueue; BlockingQueue queue = new LinkedBlockingQueue(); You need to make the queue available to your handler as a constructor argument and when a message arrives you put it into the queue: // Your netty handler: queue.put(message); On the client end you can poll the queue for messages: // The polling loop in your program: message = queue.poll(5 TimeUnit.SECONDS); The BlockingQueue offers you the choice between waiting for a message to arrive (take()) waiting a certain amount of time for a message to arrive (poll(long TimeUnit)) or merely checking whether any message is available right now (poll()). From a design perspective this approach kills the non-blocking IO advantage netty is supposed to give you. You could have used a normal Socket connection for the same net result. thx. thats basically what I implemented now. altough your right that it kills the advantages i need to use it atm (because i dont want to implement some further message handling)
50,A,"Netty 4.0.0.Beta1 ChannelHandlerContext.readable(boolean) gone need replacement in netty 4.0.0.AlphaX there was the ChannelHandlerContext.readable(boolean) method to suspend incoming traffic. The new documentation for 4.0.0.Beta1 still says: In 4.0 each ChannelHandler is given with its own boolean flag called 'readable' in its ChannelHandlerContext. The flag tells if the handler wants Netty to read inbound traffic or not. The problem: The readable(boolean) method is gone and now I can only find a ChannelHandlerContext.fireChannelReadSuspended() method. What about resuming traffic? Does anyone know how to suspend/resume incoming traffic on netty 4 pipelines after Beta1 upgrade? Thank you. N.B.: The ""proxy"" example still has a TODO: // TODO: Suspend incoming traffic until connected to the remote host. // Currently we just keep the inbound traffic in the client channel's outbound buffer. You can now use the ChannelOption.AUTO_READ for this. Just set it to false on the ChannelConfig of the Channel if you want to suspend and set it back to true once you want to start read again automatically. You can even go further now by trigger the reads from hand all the time which can help to keep the memory foot-print to a minimum when writing for a example a proxy. I just updated the proxy example[1] this morning to show this in action. [1] https://github.com/netty/netty/tree/master/example/src/main/java/io/netty/example/proxy It's in the ""new and noteworthy"": https://netty.io/Documentation/New+and+Noteworthy. By the way the TODO in HexDumpProxyFrontendHandler.java is still there! Don't your patch fix it? thanks man! I was browsing the source from the beta1 tag! btw where is the docs from you quoted ? I would like to fix them :) thanks.. Also I missed to remove the TODO I just removed it. :)"
51,A,"Does ""content-encoding: gzip"" necessarily mean the content is in gzip format? When a server response comes with ""Content-Encoding: gzip"" does it necessarily mean that the response body is in gzip format? I am decoding the incoming response body (perhaps incorrectly) and am getting a ""Not in GZIP format"" exception. Yes if it contains ""Content-Encoding: gzip"" it must be gzip compressed."
52,A,AIO in Netty 4.0.0.CR9 I am currently Porting my Netty Server to Version 4 (4.0.0.CR9). While everything works so far I would also like to try out the performance benefits of the new java7 nio2 implementation. But it seems that the required classes like AioEventLoopGroup etc. are not inside the netty-all or other packages downloaded with the netty bundle. Has the NIO2 Support been removed from Netty? Yes it has bee removed as it was not any faster then nio. I'm working on a project using AIO instead of NIO because actually AIO provides basically much better performance under windows. NIO is just a cheap wrapper around readiness APIs like select epoll kqueue. As everybody know windows' select ist rubbish on windows you have to use IOCP which does not fit well into a selector based API. Also AIO supports async file it would have been very nice to treat files as channels and to compose them with socket channels. But no AIO in netty =( Look at node.js C# .Net Golang etc the call-me-on-finished APIs are a much better abstraction if you want to be truly platform independent.
53,A,"jvm conf for normal gc at high load I have server application based on Netty. It decode message (from json) and send it back to the client (simple echo). When i have a lot of messages send from one client (more than 15k/second) garbage collector don't start and memory usage grown up. How can i configure jvm to decrease gc pauses and decrease memory usage? Your description sounds like a memory leak. Does the garbage collector eventually start or do you end up with an OutOfMemoryError? If you don't then it sounds like you're running into a situation where objects are living long enough to get into the tenured generation (I'm assuming Sun JVM here). And the solution to that is to increase the size of the young generation relative to the tenured generation. Here's a link that explains the Sun JVM generational collector (it's for the 1.5 JVM but I believe that the options haven't changed for 1.6): http://www.oracle.com/technetwork/java/gc-tuning-5-138395.html The options that you would want to experiment with are NewRatio which is the ratio between the young and tenured generations and SurvivorRatio which is the ratio between Eden and the two survivor spaces. I might try the following: -XX:NewRatio=1 gives the young generation half of the object heap -XX:SurvivorRatio=2 makes each survivor space be half that of Eden These two settings will make the ""Eden"" space for new objects take 1/4 of the heap. This is pretty big so hopefully most objects will spend their entire lives in Eden. The survivor ration gives another 1/4 of the heap to the survivor spaces (1/8 to each) to hold objects with a medium life. Of course don't blindly set options. Instead use jconsole (part of the JDK distribution) to see what's really happening with your heap. You might find that the default survivor ratio of (1:6) is better than what I've suggested.  To configure jvm to decrease gc pauses and decrease memory usage you need to choose an appropriate GC collector. CMS is a low pause collector. You can set -XX:+UseConcMarkSweepGC to enable it. And you can fine-tune other parameters such as -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=nn to control GC pause."
54,A,"Highly concurrent HTTP with Netty and NIO I am working through the example Netty HTTP Client code in order to make http requests within a concurrent threaded environment. However my system breaks completely (with a slew of exceptions) at fairly low throughput. In almost pseudo-code: ClientBootstrap bootstrap = new ClientBootstrap(new NioClientSocketChannelFactory()) bootstrap.setPipelineFactory(new HttpClientPipelineFactory()); ChannelFuture future = bootstrap.connect(new InetSocketAddress(host port)); Channel channel = future.awaitUninterruptibly().getChannel(); HttpRequest request = new DefaultHttpRequest(); channel.write(request); In the example to make a request I create a ClientBootstrap and from there (through a few hoops) a Channel to write the HTTPRequest. This all works and is good. However in a concurrent situation should every request be going through the same hoops? I think that is what's breaking things for me at the moment. Should I be reusing the connection or structuring my client in an entirely different way? Also: I am doing this in Clojure if that makes any difference at all. do you have experience with aleph? I have tried another async clojure http client but it doesn't work at the levels of throughput I need to sustain. maybe you should use https://github.com/ztellman/aleph ? No you're doing things right. You must however keep a reference to your Channel instance. Once you have that channel as long as it is open you don't need to create another bootstrap. (If that's what you're doing.) This is what I used in a recent project : class ClientConnection (constructor) // Configure the client. bootstrap = new ClientBootstrap( new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool() ) ); // Set up the pipeline factory. bootstrap.setPipelineFactory( new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( // put your handlers here ); } } ); class ClientConnection.connect(String host int port) if (isConnected()) { throw new IllegalStateException(""already connected""); } // Start the connection attempt. ChannelFuture future = bootstrap.connect(new InetSocketAddress(host port)); channel = future.awaitUninterruptibly().getChannel(); // Wait until the connection is closed or the connection attempt fails. channel.getCloseFuture().addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { new Thread(new Runnable() { public void run() { // Shut down thread pools to exit // (cannot be executed in the same thread pool! bootstrap.releaseExternalResources(); LOG.log(Level.INFO ""Shutting down""); } }).start(); } }); So basically I only keep a reference to bootstrap and channel however the former is pretty much not used outside of these lines of code. Note: you should only execute bootstrap.releaseExternalResources(); once when the application is exiting. In my case the client sends some files then close the channel and exit. Once you have a connected Channel instance you need only to use that one until you close it again. Once it is closed you can recall the bootstrap to create a new Channel again. Personally I find Netty a little bit hard to understand at first but once you grasp how it works it is simply the best NIO framework in Java. IMO. `bootstrap` will also be useful if you want to make another connection and utilize existing machinery (underlying Netty NIO worker threads)."
55,A,"Draft10 with WSS I'm trying to run Netty Draft10 latest example on top of SSL (WSS) https://github.com/netty/netty/tree/master/src/main/java/org/jboss/netty/example/http/websocketx/server I'm using the following port configuration: Port: 80: Apache non ssl Port: 443: Apache ssl Port: 8080: Tomcat Port: 8877: Netty Web non SS Port: 9977: Netty SSL But when I embedd the SSL handler code public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { //TODO - Tamir - Add support for Wss // Get the SslHandler in the current pipeline. // We added it in SecureChatPipelineFactory. final SslHandler sslHandler = ctx.getPipeline().get(SslHandler.class); // Get notified when SSL handshake is done. ChannelFuture handshakeFuture = sslHandler.handshake(); handshakeFuture.addListener(new Greeter(sslHandler)); } into the WebSocketServerHandler class I get an error message java.lang.IllegalArgumentException: empty text at org.jboss.netty.handler.codec.http.HttpVersion.<init>(HttpVersion.java:95) at org.jboss.netty.handler.codec.http.HttpVersion.valueOf(HttpVersion.java:68) at org.jboss.netty.handler.codec.http.HttpRequestDecoder.createMessage(HttpRequestDecoder.java:81) at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:198) at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:107) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:470) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:443) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:275) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:262) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:340) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:271) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:191) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662) java.lang.IllegalArgumentException: invalid version format: ?_?_?__ This is my pipeline code SSLEngine engine = SecureChatSslContextFactory.getServerContext().createSSLEngine(); engine.setUseClientMode(false); pipeline.addLast(""ssl"" new SslHandler(engine)); // On top of the SSL handler add the text line codec. pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); // and then business logic. pipeline.addLast(""handler"" new WebSocketServerHandler()); Any ideas? Cheers Tamir Since I came across this issue my self I thought it might be worth mentioning: Under some circumstances The parsing of initialLine parameter HttpRequestDecoder is wrong. this might happen if you don't add a path to the URI  i.e you try ws://localhost:8080 without adding /websocket to the URL. return new DefaultHttpRequest(HttpVersion.valueOf(initialLine[2]) HttpMethod.valueOf(initialLine[0]) initialLine[1]); The HTTP version field is supposed to be in initialLine[2] but instead it appears in initialLine[1].  I've just uploaded a working example of web sockets with SSL which I've merged with master. See pull request: https://github.com/netty/netty/pull/53. The new code is in src/main/java/org/jboss/netty/example/http/websocketx/sslserver Please read package-info.java for setup instructions. Let me know if it works for you. Thanks. Can you please mark this as answered so our filter don't keep show this issue. Thanks. This is working great!!!"
56,A,Efficient way to convert io.netty.buffer.ByteBuf to java.nio.ByteBuffer I came across this query: Create a ByteBuf in Netty 4.0.0.Beta1 about conversion from byte[] to ByteBuf and ByteBuffer to ByteBuf. I was curious to know about the conversion the other way: io.netty.buffer.ByteBuf to java.nio.ByteBuffer and how to do it efficiently with minimal/no copying? I did some reading and with some trial and error I found this inefficient way of converting it (with two copies): // io.netty.handler.codec.http.FullHttpRequest fullHttpRequest; ByteBuf conByteBuf = fullHttpRequest.content (); int numReadBytes = conByteBuf.readableBytes (); conBytes = new byte[numReadBytes]; conByteBuf .readBytes (conBytes); // First Copy ByteBuffer conByteBuffer = ByteBuffer.allocate (conBytes.length); conByteBuffer.put (conByteBuf); // Second Copy My question is can we avoid one or both the copies and make the internal buffer of ByteBuffer to use the internal buffer of ByteBuf. Thanks! You can at least use ByteBuffer.wrap() to avoid the second copying. It seems Dev's response below will help eliminate even that. Can we still avoid the first copy?  You should be able to use ByteBuf.nioBuffers(). Which will return a view of the ByteBuf as an array of ByteBuffer objects. In most cases this array will only have one element but in some of the more complicated implementations of ByteBuf there may be multiple underlying ByteBuffer objects and ByteBuf.nioBuffers() can return them as-is instead of merging them as would a call to ByteBuf.nioBuffer(). You can tell ahead of time what the array length will be by using ByteBuf.nioBufferCount()
57,A,Trying to test latency on Jersey 2.0 (Async vs Sync) Even though stackoverflow has helped many times before it is the first time I make a question. So enough sucking-up and lets get on to the issue :) I am very new to RESTful services and even more to Jersey and I have been messing around with it for the past 3/4 weeks for a project and I have to questions that i really hope you can help me with: The first one is if anyone knows a good and simple way to measure latency and requests/s with 1 or multiple clients since i have experienced that Jersey has a high latency and need some more concrete data to help me decide to which extent is it a good option for me. The second question is more like a follow up to the first one. Knowing that Jersey invokes resources asynchronously I believe that is the cause for the high latency so I was trying to do Synchronously but I can't really understand the whole invocations that Jersey does. Does anyone have a solution for what I am trying to do or can at least explain to me the process in which Jersey invokes resources? I believe this second question is a more complicated one to answer (since most people are probably using 1.12/13 until 2.0 is final) but any help would be greatly appreciated since i am a beginner and some concepts are a little out of grasp for me at the time being (will keep trying to learn though ;) ) Edit: PS: i may have not mentioned it but i am using a netty4.0a2 container. You could give jMeter a try. It allows you to easily simmulate different scenarios of concurrent requests and load amounts and also has nice components for statistics summarization and visual analysis of the response times.
58,A,"Java Netty load testing issues I wrote the server that accepts connection and bombards messages ( ~100 bytes ) using text protocol and my implementation is able to send about loopback 400K/sec messages with the 3rt party client. I picked Netty for this task SUSE 11 RealTime JRockit RTS. But when I started developing my own client based on Netty I faced drastic throughput reduction ( down from 400K to 1.3K msg/sec ). The code of the client is pretty straightforward. Could you please give an advice or show examples how to write much more effective client. Iactually more care about latency but started with throughput tests and I don't think that it is normal to have 1.5Kmsg/sec on loopback. P.S. client purpose is only receiving messages from server and very seldom send heartbits. Client.java public class Client { private static ClientBootstrap bootstrap; private static Channel connector; public static boolean start() { ChannelFactory factory = new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); ExecutionHandler executionHandler = new ExecutionHandler( new OrderedMemoryAwareThreadPoolExecutor(16 1048576 1048576)); bootstrap = new ClientBootstrap(factory); bootstrap.setPipelineFactory( new ClientPipelineFactory() ); bootstrap.setOption(""tcpNoDelay"" true); bootstrap.setOption(""keepAlive"" true); bootstrap.setOption(""receiveBufferSize"" 1048576); ChannelFuture future = bootstrap .connect(new InetSocketAddress(""localhost"" 9013)); if (!future.awaitUninterruptibly().isSuccess()) { System.out.println(""--- CLIENT - Failed to connect to server at "" + ""localhost:9013.""); bootstrap.releaseExternalResources(); return false; } connector = future.getChannel(); return connector.isConnected(); } public static void main( String[] args ) { boolean started = start(); if ( started ) System.out.println( ""Client connected to the server"" ); } } ClientPipelineFactory.java public class ClientPipelineFactory implements ChannelPipelineFactory{ private final ExecutionHandler executionHandler; public ClientPipelineFactory( ExecutionHandler executionHandle ) { this.executionHandler = executionHandle; } @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder( 1024 Delimiters.lineDelimiter())); pipeline.addLast( ""executor"" executionHandler); pipeline.addLast(""handler"" new MessageHandler() ); return pipeline; } } MessageHandler.java public class MessageHandler extends SimpleChannelHandler{ long max_msg = 10000; long cur_msg = 0; long startTime = System.nanoTime(); @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { cur_msg++; if ( cur_msg == max_msg ) { System.out.println( ""Throughput (msg/sec) : "" + max_msg* NANOS_IN_SEC/( System.nanoTime() - startTime ) ); cur_msg = 0; startTime = System.nanoTime(); } } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { e.getCause().printStackTrace(); e.getChannel().close(); } } Update. On the server side there is a periodic thread that writes to the accepted client channel. And the channel soon become unwritable. Update N2. Added OrderedMemoryAwareExecutor in the pipeline but still there is very low throughput ( about 4k msg/sec ) Fixed. I put executor in front of the whole pipeline stack and it worked out! Actually the server will be remote. I implemented the emulator to test how much messages per sec can the client process. And it turns out that naive netty client implementation is slow. Your code says ItchClientPipelineFactory but then the pasted code is for ClientPipelineFactory. Is this just a naming error or is it the case that ItchClientPipelineFactory has non optimal code in it (ie is not using the right messagehandler) and you forgot you were still using it ? I would send the timestamp in the messages and get the latency of each message. This may give you more detail as to what the delay is. If you are only communicating on the same host and latency is critical to you you might consider using shared memory instead. they are the same Did you see this post and try its suggestions: http://stackoverflow.com/questions/8444267/how-to-write-a-high-performance-netty-client thx for link but i've seen this and it doesn't help. It seems like the server writes much more fast that client can process ( the channel on server eventually become unwritable ). But I cannot figure out what is wrong with the client. Why it can't process much more messages... If the server is sending messages with a fixed size (~100 bytes) you can set the ReceiveBufferSizePredictor to the client bootstrap this will optimize the read bootstrap.setOption(""receiveBufferSizePredictorFactory"" new AdaptiveReceiveBufferSizePredictorFactory(MIN_PACKET_SIZE INITIAL_PACKET_SIZE MAX_PACKET_SIZE)); According to the code segment you have posted: The client's nio worker thread is doing everything in the pipeline so it will be busy with decoding and executing the message handlers. You have to add a execution handler. You have said that channel is becoming unwritable from server side so you may have to adjust the watermark sizes in the server bootstrap. you can periodically monitor the write buffer size (write queue size) and make sure that channel is becoming unwritable because of messages can not written to the network. It can be done by having a util class like below. package org.jboss.netty.channel.socket.nio; import org.jboss.netty.channel.Channel; public final class NioChannelUtil { public static long getWriteTaskQueueCount(Channel channel) { NioSocketChannel nioChannel = (NioSocketChannel) channel; return nioChannel.writeBufferSize.get(); } } Jestan thank you for the answer. I added ExecutionHandler in the pipeline before actual business logic handler ( where I measure throughput ) but it didn't work out. Still the throuhput is very low and server channel is not writable. I tried to find class NioSocketChannel but failed. @EgorLakomkin so your issue is not solved yet? NioSocketChannel is missing or package `org.jboss.netty.channel.socket.nio` is missing? what is the Netty version? Netty 4.x doesn't seem to allow access to a writeBufferSize object and it seems the package has changed as well."
59,A,netty is http parser re-usable and how? I need re-usable async http parsing code. Does netty perhaps contain some api for just the parsing portion? (I always have a belief that parsers should be separate and re-usable and not tied to the framework so I hope netty's is reusable as well). ie. It would be great to feed in bytes like so and it returns null if there is not yet enough bytes private byte[] previousData; byte[] data = incomingMergedWithPrevious(previousData); HttpResponse resp = httpResponseParser.parse(data); if(resp == null) { return; //we do not have full data to parse yet } //otherwise fire the response to someone else. OR maybe I could re-use the code a different way. All I know is I get bytes that don't always have all the http headers yet since it is asynch stuff. Any way to parse stuff? NOTE: Also I want to do chunking so I am not sure it should return HttpResponse every time but maybe an List where one subclass is HttpHeaders and another is HttpChunk. thanks Dean You can use the DecoderEmbedder probably in conjunction with HttpMessageDecoder. There's an example on the DecoderEmbedder page. It sounds like you want to use the pollAll method. You'll need to check the type of each returned object if you want to process HttpResponse and HttpChunk messages differently. it's too bad they didn't make it more of a component in the first place so their own tests didn't have to create a special class to test it :( but thanks very much for the great answer. This shouldn't be a problem. You just need to add HttpContentDecompressor to the handler list in the correct order. So the list is HttpMessageDecoderHttpContentDecompressor. Calling pollAll should return the fully parsed and decompressed HTTP message or chunk. hmmmmm will that work with compression as well? ewwww netty is throwing a runtime ReplayException on normal behavior of half packets coming in.....that's not very performant. (they should really do what play did so the stack trace of that guy is not filled in).
60,A,why netty can not make a distinction between socket close and socket half close i got an interest problem when i close (OIO) socket outputstream with half close manner Netty server detect the event and trigger the ChannelClose method in handler but in client side the socket is open and connected then i complete close socket in client but this time Netty server get no reflect. doesn't it very strange? Sorry I don't understand your problem... Can you give some more details? Nobody can tell the difference. Shutdown for output sends a FIN. Close sends a FIN unless it has already been sent i.e. by a shutdown. FIN appears at the receiver as the EOS (EOF) condition. The server got the FIN from the shutdown saw that as EOS closed the socket your client got the FIN saw that as EOS closed the socket and sent ... nothing to the server because the FIN had already been sent. oh my god... I have to study something with TCP/IP.
61,A,"HTTP request and IP address I have got the ip address from the HTTP request object using request.getRmeoteAddr() => 127.0.0.0 However im using netty and when I use SocketAddress socketAddress = channel.getRemoteAddress(); InetSocketAddress inetAddr = (InetSocketAddress)socketAddress; ipAddress = inetAddr.getAddress().toString(); => 0.0.0.0.0.1 This is causing me problems when trying to compare i want them in the same fomrat... any ideas? use getHostAddress(); that should do it. InetSocketAddress inetAddr = (InetSocketAddress)socketAddress; String address = inetAddr.getAddress().getHostAddress(); http://docs.oracle.com/javase/1.4.2/docs/api/java/net/InetAddress.html#getHostAddress() nope that didnt work im afraid... can you paste the full code? SocketAddress socketAddress = channel.getRemoteAddress(); String ipAddress = socketAddress.toString(); LOGGER.info(""ip address from socket: "" + ipAddress); //if(socketAddress instanceof InetSocketAddress){ InetSocketAddress inetAddr = (InetSocketAddress)socketAddress; InetAddress inetAddress = inetAddr.getAddress(); LOGGER.info(inetAddress.getHostAddress()); check above the inetAddress has a host address which you can use...  When you've a class that represents something that can be represented as lots of different strings then don't compare the strings; compare objects of that class. but im storing the address. So needed to compare the address So parse the address into an object of that type? yep sure.. see above"
62,A,Adding authentication to netty telnet example I am totally new to Netty and Java but this afternoon I have managed to create a chat server based on the Netty telnet sample. It works great and I have '/' slash commands working so people can do things like set their name which I currently store in ctx->setAttachment(name). I have a back end database server I want to connect them with so I can get their name this way but I'll need to add authentication each user first. I know I could do that with more slash commands. But I wanted to see if I could do it using a handler in the event chain. Have a handler that checks if a user is authenticated and if they are not does the logic for authenticating them. And then somehow stores they are authenticated. And if they are authenticated it lets my current chat handler do its work instead. Can anyone please provide some links or tips for doing this? My knowledge with Netty is very very basic right now. Thanks in advance. It really depends.. You can for example have a custom SimpleChannelUpstreamHandler that handle the authentication and remove it once its done. Something like this: public class AuthHandler extends SimpleChannelUpstreamHandler { @Override public void messageReceived( ChannelHandlerContext ctx MessageEvent e) throws Exception { if (auth(e)) { // remove handler after auth was done ctx.getPipeline().remove(this); } } // Returns true if auth was successfully private boolean auth(MessageEvent e) { .... } } Worked a charm. I had tried using a handler that extended SimpleChannelHandler but it stopped connection calls going through to the main handler. So it stopped me from creating the user session. I had started to write code to work around that but this is so much simpler. Many thanks!
63,A,"Multiple ClientBootstrap issue I'm coding a tool for load testing of a websocket server. I need create a lot(tens of thousands) of client connections to the server. So I have a some Client class. Inside this class I create new versions of: ChannelPipelineFactory(with my handlers and the webscoket client handshaker) ClientBootstrap In the run() method I have the following code: public void run() { clientBootstrap.setPipelineFactory(clientChannelPipelineFactory); ChannelFuture future = clientBootstrap.connect( new InetSocketAddress( clientConfiguration.getHost() clientConfiguration.getPort() ) ); try { future.awaitUninterruptibly().rethrowIfFailed(); WebSocketClientHandshaker handshaker = clientChannelPipelineFactory.getHandshaker(); channel = future.getChannel(); handshaker.handshake(channel).awaitUninterruptibly().rethrowIfFailed(); } catch (Exception e) { log.error(""Error in the client channel"" e); stop(); } } The channel that is returned by ChannelFuture is saved as field in the Client. Then I do my work and trying to close all opened channles. The stop() method: public void stop() { log.debug(String.format(""Close channel for client(%s)"" id)); if (channel != null) { if (channel.isWritable()) { log.debug(String.format(""Channel for client(%s) is writable"" id)); ChannelFuture writeFuture = channel.write(new CloseWebSocketFrame()); writeFuture.addListener(ChannelFutureListener.CLOSE); } } clientBootstrap.releaseExternalResources(); } But when the stop() is called on any clients it closes all channels!? p.s. Code that closes all channels(single threaded): for (FSBBridgeServerClient client : clients) { for (FSBBridgeServerClient subClient : clients) { log.debug(""c:"" + subClient.getChannel()); log.debug(""c:"" + subClient.getChannel().isOpen()); } client.stop(); } Some debug log: 2012-04-04 17:19:29441 DEBUG [main] ClientApp - c:[id: 0x2344b18f /127.0.0.1:38366 => localhost/127.0.0.1:5544] 2012-04-04 17:19:29441 DEBUG [main] ClientApp - c:true 2012-04-04 17:19:29442 DEBUG [main] ClientApp - c:[id: 0x01c20eb7 /127.0.0.1:38367 => localhost/127.0.0.1:5544] 2012-04-04 17:19:29442 DEBUG [main] ClientApp - c:true 2012-04-04 17:19:34414 DEBUG [main] ClientApp - c:[id: 0x2344b18f /127.0.0.1:38366 :> localhost/127.0.0.1:5544] 2012-04-04 17:19:34414 DEBUG [main] ClientApp - c:false 2012-04-04 17:19:34414 DEBUG [main] ClientApp - c:[id: 0x01c20eb7 /127.0.0.1:38367 :> localhost/127.0.0.1:5544] 2012-04-04 17:19:34414 DEBUG [main] ClientApp - c:false I think your problem is calling clientBootstrap.releaseExternalResources();. According to the documentation ... this method simply delegates the call to ChannelFactory.releaseExternalResources(). Thanks seems that was a problem."
64,A,"maximum throughput in distributed processing (with netty 4.0) We build system for distributed processing and want to use netty (4.0) for the network I/O stack. The following situation: We got a producer task A and a consumer task B. Task A produces data in 64K chunks and transmits it to task B. Task B can be in certain circumstances compute intensive and consume the 64K blocks slower than produced by task A. Task A and B are connected by a tcp channel. We think about this approach: Task A produces the chunks and put it in a local queue. A chunk is automatically taken from the queue when the tcp channel is free and the next 64K can be written into the channel (does netty give us such a signal/event?). If the queue on Task A exceeds a fixed limit of stored chunks we block task A until task B have consumed chunks. In essence we want a ""receiver triggered write"" for task A to fully utilize the tcp channel without congesting it. The goal of this design should be maximum data throughput. There are several questions now :) Is that a good design for enabling maximum throughput? What would be a better design to fully utilize the tcp channel? Is netty the right framework for these scenarios? (I am pretty new to netty but I really like the clean abstractions/designs of the framework!) Can such a design be realized with netty? => (does it give us such a signal/event from the receiver site?) What would be the best design with netty to enable maximum throughput? Are there other framework which are more suitable? Any idea and note is welcome!!! Many thanks in advance!!! Tobi here is a few remarks: general design : you're mentioning a ""distributed"" processing but do not specify if you would have multiple instances of Task A and Task B processor. If you just have one Task A processor and one Task B processor the data throughput will be determined by the slower one. I understand that one average B is slower but it can be faster so introducing a buffer between A and B looks like a good idea. So I think the design is fine if you want/need to stick to a single A and a single B instance but that you might consider having multiple instances if B is indeed slower (you would then have more B instances than A) netty or other frameworks : yes you could do that in Netty. However I think you would have to write the ""TCP channel is free"" signal. I don't have much experience but I would think that frameworks like http://akka.io/ implementing message passing and actor model would be interesting to look at."
65,A,Usage of Netty's ChannelLocal The JavaDocs for Netty explain ChannelLocal to be similar to ThreadLocal however I've got some questions about it's usage. ThreadLocal is a static class with static methods that access instance-specific objects. ChannelLocal is not static have a static internal map or have static methods. The documentation doesn't include an example of accessing ChannelLocal or placing an object into ChannelLocal so I was hoping someone could give me some insight into it's usage. Thanks! The ChannelLocal is used to assign some data to a Channel. Here's an example: // Declare public static final ChannelLocal<Integer> data = new ChannelLocal<Integer>(); // Set data.set(e.getChannel() 1); // Get int a = data.get(e.getChannel()); Here's a couple of real life example: http://www.assembla.com/code/argonms/subversion/nodes/trunk/src/argonms/center/recv/RemoteServerListener.java?rev=44 http://eucalyptus.sourcearchive.com/documentation/1.6.2/ServiceSinkHandler_8java-source.html Not sure myself. You may want to ask the dev's forum: http://groups.google.com/group/netty. I know that in the latest netty master (upcoming netty 4.0 release) there is discussion on depreciating ChannelLocal and providing a getAttachment/setAttachment on the channel. https://github.com/netty/netty/issues/101 Interesting. Ok thanks for the usage examples I know where to go from here! I'm curious why the internal map for ChannelLocal isn't static: ` private final ConcurrentMap map = new ConcurrentIdentityWeakKeyHashMap(); ` If I use a ChannelLocal in two separate classes I'll need to re-register my ChannelLocal object between those classes. It would make more sense to have an internal static map so if I put something in ChannelLocal for one class I can get the same object out from another class without having to pass the ChannelLocal around. Note: inside a WeakKeyHashMap the value should not reference the key otherwise the map entry won't be garbage collected. The [ChannelHandler javadoc](http://netty.io/3.5/api/org/jboss/netty/channel/ChannelHandler.html) also has a great chapter to learn various recommended ways to manage stateful information with some examples.
66,A,Is it possible to use Netty 3.x and 4.0 in the same app or will there be classname conflicts? I'm evaluating the use of netty 4 for some future work but it will have to work within our existing webapp logic which has an indirect dependency on Netty 3.x as a result of some third-party libraries we require. I know there was significant re-factoring in netty 4.0. As a result I was wondering if it's possible to use both in the same application or if there is still some overlap that would result in classname conflicts or possibly some other [not-so-obvious] side effect. Thanks Yes it is possible... Netty 3 use org.jboss.netty as package name and Netty 4 io.netty so no problem at all. Great thanks for the verification!
67,A,"How to use Netty for server to server binary websocket communication? BACKGROUND: I have application server logic that hosts stateful object instances. I plan to have multiple servers - each hosting stateful object instances. NOTE: this is not a cluster with the same objects mirrored but more of a federated model. Each instance of my application server is using Netty and supports HTTP and WebSockets. I wish to use the Netty WebSocket plumbing as the communication layer for not only server_1/server_2 but also for server_1/object_A talking to server_2/object_X. For Example: Server_1 has objects {OA OB OC} and Server_2 has objects {OX OY OZ} S1:OA could communicate with S2:OX S1:OB could also communicate with S2:OX QUESTION (s): 1) Is there a recommended approach to communicate between objects running in different servers using Netty? Are there any examples? 2) Should I cache the Channel between servers and funnel all object-object requests over that? Is this thread-safe? 3) OR should I use separate Channels for server and object level communication - dynamically creating/destroying them as needed? From a network utilization standpoint I would think option #2 would be preferred for all bi-directional communication between Server_1 and Server_2. If you need any clarification or more details please don't hesitate to ask. If you want to send over Java classes I would recommend to use the marshalling encoder/decoder that ships with Netty[1]. To your other question all operations on a Channel are Thread-safe. [1] https://github.com/netty/netty/tree/3/src/main/java/org/jboss/netty/handler/codec/marshalling Thanks Norman! To follow-up on the options am I correct in assuming 1 Channel between each respective server pairing would be recommended? On the marshalling aspect we don't actually need to send java objects across but data - and we have our own binary serialization/deserialization logic. If we're using our own binary encoding/decoding is there a specific set of classes we should derive from when building the pipeline? It really depends on how your ""logic"" is.. Maybe FrameDecoder and OneToOneEncoder but I can only guess without more infos. Yes one Channel is the way to go Excellent thanks. As I'm cutting my teeth on Netty with this prototype I'm sure I'll have some more questions as I dig deeper."
68,A,"How to use ChunkedStream properly Here's my use case... I have an upstream service that sends my Netty app data over the network and that data needs to be published to multiple clients connected to Netty. The data pushed to the clients must be HTTP ""Transfer-Encoding: chunked."" I found ChunkedStream and though that maybe I could create a PipedInputStream and a PipedOutputStream (connected to the PipedInputStream) and write the ChunkedStream to the channel. Then when data is received from my upstream service I could write the data into the PipedOutputStream of the channels and it'd be sent to the clients: In channelConnected PipedInputStream in = new PipedInputStream(); PipedOutputStream out = new PipedOutputStream(in); ctx.getChannel().write( new PersistentChunkedStream(in) ); Separate thread publishes data to a connected channels ChannelBuffer buff = ChannelBuffers.copiedBuffer(""FOO""CharsetUtil.UTF_8); out.write( buff.array() ); channel.get(ChunkedWriteHandler.class).resumeTransfer(); I had to extend ChunkedStream to return null from nextChunk if there are 0 bytes available (to ""suspend"" the write without the thread hanging) so I call resumeTransfer after I write to the PipedOutputStream of the associated channel. When I debug and step through the code I can see flush of ChunkedWriteHandler being called which does call: Channels.write(ctx writeFuture chunk currentEvent.getRemoteAddress()); with the bytes I wrote into the PipedOutputStream but it's never received by the client. HTTP curl ~ $ curl -vN http://localhost:8080/stream * About to connect() to localhost port 8080 (#0) * Trying 127.0.0.1... connected * Connected to localhost (127.0.0.1) port 8080 (#0) > GET /stream HTTP/1.1 > User-Agent: curl/7.19.7 (universal-apple-darwin10.0) libcurl/7.19.7 OpenSSL/0.9.8r zlib/1.2.3 > Host: localhost:8080 > Accept: */* > < HTTP/1.1 200 OK < Transfer-Encoding: chunked < ### NOTE: NO ""FOO"" TRANSMIT BACK ### Any thoughts? Maybe there's a better way to accomplish this? Mystery deepens... here's a WireShark capture of the fragment transmit http://screencast.com/t/DZ8SzYI7m. I'm not sure if the extra octets at the end are causing the problem or not. Gebus... ok so the extra octets were the problem. I had to NOT use the ChannelBuffer but a plain string instead like `out.write(""5\r\nFOO\r\n\r\n"".getBytes());` (5 = number of bytes in message = ""FOO\r\n"" the CRLF after the 5 and at the are per spec as delimiting the chunk length and the chunk body). Problem not really SOLVED but I can work with it... I can do the same with `ChannelBuffers.wrappedBuffer(""5\r\nFOO\r\n\r\n"".getBytes(CharsetUtil.UTF_8));` Here's a screenshot of just before it writes ""FOO"" to the channel: http://screencast.com/t/XATjUfCsre6U Note that you can see the chunk contains ""70 79 79"" = FOO It's really strange because I can see `write0` of `NioWorker` being called and writing to the channel but nothing on the other end. I even make sure to use ""-N"" of curl to prevent buffering on the client side. I've also let it run in a loop for awhile thinking something needed to be flushed but still no dice. It's gotta be me. I can see it in WireShark. Maybe there's a terminator I'm not passing to inform curl the chunk has been received. I got further when I read from Wikipedia that `chunked` data must be prefixed with the number of octets and that wasn't being included in the data sent through the ChunkedStream so I changed ""FOO"" to ""3\r\nFOO"" and it now comes back on the client but `curl` blows up with ""Received problem 3 in the chunky parser"" and the connection is closed. I know this is an old question but hopefully this helps someone. The ChunkedStream does NOT imply HTTP Chunking...it's an unfortunate naming collision best I can tell. Chunked streams are there just to avoid loading an entire item into memory effectively the ChunkedWriter calls back into the ChunkedStream after each chunk to ask for more data. As it turns out you CAN use the ChunkedStream paradigm to create something that does HTTP chunking for you from a standard input stream. The code below implements ChunkedInput and takes an InputStream. It also automatically appends the trailing http chunk to indicate EOF but does so only once as per the ChunkedInput spec. public class HttpChunkStream implements ChunkedInput { private static final int CHUNK_SIZE = 8192; boolean eof = false; InputStream data; HttpChunkStream (InputStream data) { this.data= data; } byte[] buf = new byte[CHUNK_SIZE]; @Override public Object nextChunk() throws Exception { if (eof) return null; int b = data.read(buf); if (b==-1) { eof=true; return new DefaultHttpChunk(ChannelBuffers.EMPTY_BUFFER); } DefaultHttpChunk c = new DefaultHttpChunk(ChannelBuffers.wrappedBuffer(buf0b)); return c; } @Override public boolean isEndOfInput() throws Exception { return eof; } @Override public boolean hasNextChunk() throws Exception { return isEndOfInput()==false; } @Override public void close() throws Exception { Closeables.closeQuietly(data); } }  I wonder why you even want to use the PipedInputStream / PipedOutputStream. I think it would be away cleaner / easier to just call Channel.write(..) directly without your data. Just be aware to submit as much data as you can in Channel.write(..) as its an expensive operation. You can call Channel.write(..) from any thread that you want as its thread-safe. I know you need to send in chunks but you can do this just with Channel.write(..) just be sure you don't close the Channel before you are done with it. Channel.write(..) just write ChannelBuffers the same is true for ChunkedInput.. Again I think it would be better to directly write ChannelBuffers via Channel.write(...). You may want to join the netty irc channel so we can talk about it in more details. I will join the channel in a few minutes Timezones make this difficult. I'm in the channel during the day but I'll try to be on late a few evenings and see if I can catch you. Because to chunk data I have to pass a ChunkedInput to Channel.write(..). Currently the only implemented ChunkedInputs are for Files and Streams. Since the data I'm getting to forward to clients is not a file and is persistent I figured I'd try to use a stream. Then I could connect the streams and forward data from upstream to connected clients. (continued) In my example I have a client connected waiting for data from the server so when the server gets some data from upstream it needs to send it to the client (but chunked). The connection stays open and when more data comes from upstream it's piped to the client. I was looking for a way to intermittently send chunked data to a client with a persistent connection. (fyi PipedInput/PipedOutputStream was just what I was using for my test case) I talked with Ryan in the irc channel. Using DefaultHttpResponse and DefaultHttpChunk is the way to go.. So I tried a standard ChannelStream passing in an input stream and it didn't work. I had to extend ChannelStream to return `null` from `nextChunk` when the stream had no bytes available and return `isEndOfInput` as null all the time... I had similar issues (running Netty 4.0.8) I solved it using a custom ChunkOutputStream : https://gist.github.com/codingtony/6564901 I hope it can help someone.  Just to add some more content to the answer provided by Norman. When sending arbitrary chunked data you must first send a new DefaultHttpResponse (one time only): HttpResponse res = new DefaultHttpResponse(); res.setChunked(true); res.setHeader(Names.TRANSFER_ENCODING Values.CHUNKED); channel.write(res); Then anytime you want to write to the channel with an arbitrary chunk call: HttpChunk chunk = new DefaultHttpChunk(ChannelBuffers.wrappedBuffer(str.getBytes(CharsetUtil.UTF_8))); channel.write(chunk); And don't forget to write a zero-length chunk to signal end of response to the browser: channel.write(new DefaultHttpChunk(ChannelBuffers.EMPTY_BUFFER));"
69,A,"Lot of UDP requests lost in UDP server with Netty I wrote a simple UDP Server with Netty that simply prints out in logs the messages (frames) received. To do that I created a simple frame decoder decoder and a simple message handler. I also have a client that can send multiple requests sequentially and/or in parallel. When I configure my client tester to send for example few hundred of requests sequentially with a small delay between them my server written with Netty receives them all properly. But at the moment I increase the number of simultaneous requests in my client (100 for example) coupled with sequential ones and few repeats my server starts loosing many requests. When I send 50000 requests for example my server only receives about 49000 when only using the simple ChannelHandler that prints out the received message. And when I add the simple frame decoder (that prints out the frame and copies it into another buffer) in front of this handler the server only handles half of the requests!! I noticed that no matter the number of workers I specify to the created NioDatagramChannelFactory there is always one and only one thread that handles the requests (I am using the recommended Executors.newCachedThreadPool() as the other parameter). I also created another similar simple UDP Server based on the DatagramSocket coming with the JDK and it handles every requests perfectly with 0 (zero) lost!! When I send 50000 requests in my client (with 1000 threads for example) I received 50000 requests in my server. Am I doing something wrong while configuring my UDP server using Netty? Or maybe Netty is simply not designed to support such load?? Why is there only one thread used by the given Cached Thread Pool (I noticed that only one thread and always the same is used by looking in JMX jconsole and in by checking the thread name in the output logs)? I think if more threads where used as expected the server would be able to easily handle such load because I can do it without any problem when not using Netty! See my initialization code below: ... lChannelfactory = new NioDatagramChannelFactory( Executors.newCachedThreadPool() nbrWorkers ); lBootstrap = new ConnectionlessBootstrap( lChannelfactory ); lBootstrap.setPipelineFactory( new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { ChannelPipeline lChannelPipeline = Channels.pipeline(); lChannelPipeline.addLast( ""Simple UDP Frame Dump DECODER"" new SimpleUDPPacketDumpDecoder( null ) ); lChannelPipeline.addLast( ""Simple UDP Frame Dump HANDLER"" new SimpleUDPPacketDumpChannelHandler( lOuterFrameStatsCollector ) ); return lChannelPipeline; } } ); bindChannel = lBootstrap.bind( socketAddress ); ... And the content of the decode() method in my decoder: protected Object decode(ChannelHandlerContext iCtx Channel iChannel ChannelBuffer iBuffer) throws Exception { ChannelBuffer lDuplicatedChannelBuffer = null; sLogger.debug( ""Decode method called."" ); if ( iBuffer.readableBytes() < 8 ) return null; if ( outerFrameStatsCollector != null ) outerFrameStatsCollector.incrementNbrRequests(); if ( iBuffer.readable() ) { sLogger.debug( convertToAsciiHex( iBuffer.array() iBuffer.readableBytes() ) ); lDuplicatedChannelBuffer = ChannelBuffers.dynamicBuffer( iBuffer.readableBytes() ); iBuffer.readBytes( lDuplicatedChannelBuffer ); } return lDuplicatedChannelBuffer; } And the content of the messageReceived() method in my handler: public void messageReceived(final ChannelHandlerContext iChannelHandlerContext final MessageEvent iMessageEvent) throws Exception { ChannelBuffer lMessageBuffer = (ChannelBuffer) iMessageEvent.getMessage(); if ( outerFrameStatsCollector != null ) outerFrameStatsCollector.incrementNbrRequests(); if ( lMessageBuffer.readable() ) { sLogger.debug( convertToAsciiHex( lMessageBuffer.array() lMessageBuffer.readableBytes() ) ); lMessageBuffer.discardReadBytes(); } } You are aware that UDP has no delivery guarantees right? Yes I know that there is no such delivery guarantees but my load tests are done locally and I do not loose anything with my simple server using DatagramSocket instead of Netty stuff. I am also currently analyzing the requests with WireShark to validate that nothing is lost in one case (without netty) and that packets are lost when using netty. @The4Summers If you can see that packets are being lost with Netty Netty isn't processing the incoming packets quickly enough or you aren't so the socket receive buffer is filling so incoming packets are being discarded having nowhere else to go. Speed up your receiving or slow down your sending. You have not properly configured the ConnectionlessBootstrap instance. You have to configure followings with optimum values. SO_SNDBUF size SO_RCVBUF size and a ReceiveBufferSizePredictorFactory lBootstrap.setOption(""sendBufferSize"" 1048576); lBootstrap.setOption(""receiveBufferSize"" 1048576); lBootstrap.setOption(""receiveBufferSizePredictorFactory"" new AdaptiveReceiveBufferSizePredictorFactory(MIN_SIZE INITIAL_SIZE MAX_SIZE)); check DefaultNioDatagramChannelConfig class for more details. The pipeline is doing everything using the Netty work thread. If worker thread is overloaded it will delay the selector event loop execution and there will be a bottleneck in reading/writing the channel. You have to add a execution handler as following in the pipeline. It will free the worker thread to do its own work. ChannelPipeline lChannelPipeline = Channels.pipeline(); lChannelPipeline.addFirst(""execution-handler"" new ExecutionHandler( new OrderedMemoryAwareThreadPoolExecutor(16 1048576 1048576)); //add rest of the handlers here I am glad that it worked for you. Thread pool executors are used to create worker threads in NioDatagramChannel pipelines. One worker thread can be assigned to a DatagramChannel to do non blocking read/write. If your application is listening on more than one port many worker threads (default is cpu size * 2) will be created and assigned to DatagramChannel in a round robin fashion. If you want to have more worker threads you can specify in NioDatagramChannelFactory constructor. Still I can not believe that the netty app is losing packets! Are you sure that your decoder is working properly? Why don't you use a frame decoder comes with netty (FixedLengthFrameDecoder LengthFieldBasedFrameDecoder ..) and count the number of messages in your handler? is this line correct? if ( iBuffer.readableBytes() < 8 ) return null; Finally adding these buffer size options help a bit but I still loosing frames. My real implementation is more complex than the example I shown in this question. We have implemented our own protocol over UDP and we have a special decoder to validate we have a complete and valide frame (preamble command length crc etc.) and the minimum frame lenght is 8 bytes (this is why in my example I kept this validation). Yes I could try with a fixedLengthFrameDecoder since I know the max size of my frame is 1088 bytes. Thanks for the hint about the buffer size options! However regarding the execution handler I tried it after this post and yes it help a bit but I was still loosing half of the requests when a decoder and an handler is used. I'm sure that increasing the buffer will help lot more. However I still not understand why we must specify a thread pool executor and a number of workers when instantiating the NioDatagramChannelFactory class if they are never used!!?? I also had a similar request loosing issue. After some investigation it turns out that [Netty UDP don't support multi-threading](http://stackoverflow.com/questions/10514469/threads-not-executing-concurrently-in-netty-udp-server). So during high load time some of the requests were silently dropped. After adding custom Executor pool to process the requests packet dropping issue was also solved."
70,A,Is there any way to read from one Netty channel only as fast as you can write to another? We're experiencing an issue in LittleProxy where OutOfMemoryErrors are popping up when reading from a fast server LittleProxy is proxying access to and writing to a slow client configured to use the proxy. The problem is that the data coming in from the server buffers up in memory faster than we can write it to the client. LittleProxy is just a simple HTTP proxy built atop Netty. Is there any easy way to throttle the read from the remote server to be exactly the same speed as the client is able to read it? See: https://github.com/adamfisk/LittleProxy/issues/53 and https://github.com/adamfisk/LittleProxy why not just pause reading from the server? The discussion here may help you: https://groups.google.com/forum/?fromgroups=#!topic/netty/Zz4enelRwYE @irreputable Sure you could do that but it would be a bit crude. Ideally we'd read from the server at exactly the same rate as the client is reading from us. Just pausing periodically would be pretty clunky. You could have a look at source code of : org.jboss.netty.example.proxy.HexDumpProxyInboundHandler It set the inbound channel readeable flag according to outbound channel's status. Hope this could help. Yup that should do it. Going to implement and test the fix before marking it as the answer but definitely looks right. A variation on that technique worked great -- thanks @Jian Jin!!
71,A,"How to check if a message is really delivered in Netty using websocket? I'm developing a websocket application by using Netty. I'd like to know if a message is really delivered from a source to a destination. In particular let's assume that a client and a server have an open channel and exchange some messages for a while. At a certain point the client goes down but the channel is still active in Netty. I tried to use isReachable() before sending the message but this method seems to be buggy in some scenarios (e.g. a machine with Win7 is up but isReachable() returns false). Now my idea is to implement a mechanism using ACKs namely the server sends the message and the client sends back an ack. To do that I need a timeout to see if after a certain interval the corresponding ack does not arrive. Is there something similar in Netty? Regarding isReachable() - it's only a best effort API. The documentation points out that it tries to send an ICMP echo request or create a TCP connection to port 7 on the destination host both of which are highly likely to be blocked by a firewall. Is this happening in your case? As for the acknowledgement there's nothing in Netty that provides this as standard but it shouldn't be too difficult to implement. Firstly each message needs to be uniquely identifible by some sort of identifier possibly a sequence number but a globally unique identifier means you can potentially recover across disconnections. Then you want to create a combined handler that implements both ChannelInboundHandler and ChannelOutboundHandler (assuming Netty 4). When a message is sent add the message to a map indexed by its id create a timer associated with the message id. Add it to another map indexed by message id forward the message When the ACK is received cancel the timer and remove the timer and message from their respective maps. If the timer fires use the associated id to decide what to do with the timer and message (possibly retransmit and reset the timer). Netty provides a HashedWheelTimer for efficiently managing lots of timers with a resolution suitable for this kind of activity. You may also want to consider putting a limit on the number of retries so you can stop and raise an error rather than continually indefinitely. Ok my problem is the same of this: http://stackoverflow.com/questions/21677864/netty-writeandflush-with-future-is-successfull-to-killed-host You replied to that too! :) Thank you very much for your response johnstir. Win7 replies to ping requests if the command is executed by a shell but not by java. For that reason I said it might be a little buggy. I'm not sure if this could be ""too much"" for my software. It's like a chat so it forwards a lot of messages and the software should contain many many timers. Ok let's suppose for a moment that my software tries to do its best with no ACK but what if it only wants to check the client still connected before sending a message? Which alternatives do we have to isReachable()? I should just emphasise that isReachable() isn't really suited for your needs. I hope you've found an answer but on the point about having lots of timers this is usually dealt with by restricting the amount of messages you can have outstanding at any one time. So for example you send 10 messages and put them in a queue (called a send window) and leave the others queued in some other data structure. When a message is ACK'd you remove it from the send window and send another message from your other queue thus filling the send window again. This limits the outstanding messages and timers."
72,A,"Custom Netty ServerChannel implementation I have two systems I'd like to integrate one which uses a completely in-house networking stack and one (specifically Flazr) which uses Netty. I want to proxy the Flazr Netty-based RTMP stream over our in-house HTTP stack to yield a system that speaks RTMPT. To accomplish this I need a Netty object that acts like a socket but lets me do all of the ""low-level"" stuff myself - basically just wrapping the data in HTTP and passing it down our custom networking stack. In other words I don't want Netty to manage any sockets for me - I want to insert my own stuff between the socket and Netty. I suspect that the right way to go about this is to extend AbstractServerChannel and create a *Factory class but I'm uncertain as to how the rest of Netty expects data to be flowing through the ServerChannel. My custom ServerChannel need to be able to: Notify Netty when a new client connects via our existing HTTP system Push data up to Netty when it arrives Poll for new messages from Netty at the request of a client Clean up Netty state when the HTTP session times out (or the RTMP stream is closed cleanly) Any pointers on how ServerChannel ServerChannelFactory are to be implemented? I found the javadocs rather lacking in this area. Some specific questions: How should my implementation respond to ""InterestOps""-type stuff? Is ServerChannel.write what is called for messages that come all the way down the stack? What's up with the two different overloads? How do I need to implement ServerChannel.(dis)connect? Should I still do all of this stuff through ServerBootstrap or is that too high-level for this stuff? Thanks! Before anyone asks: YES I would love to replace our custom networking stack with a Netty-based one but that's a large engineering task that I'd have a hard time justifying. Baby steps. Its look like you are trying to implement a new asynchronous transportso it will be worth to have a look on NIO TCP transport (other than Datagram classes). I am not sure how relevant it is but it will help to understand how to write a new transport service for Netty (since you have asked about Server Client Channels Factories and all) It will be easier If you can understand the Netty event model and how goes through the pipeline. This is my understanding about how it works. upstream events (event from network) starts from Channel/ServerChannelBoss/NioWorker and send through the pipeline until it reaches the last handler. downstream events starts from last downstream handler and send through the pipeline and sinks at ChannelSink channel sink process the events and take action or put the messages on channel's queues. In more details (I assume some one is looking on Nio TCP transport classes to write their custom transport for Netty). NioWorker - on selector events for the channels (all NioClientSocketChannel NioAcceptedSocketChannel) runs the nio loop - data received from network: fire message received - poll write queue and does non blocking write - poll task queue for interested op events and take suspend/resume the channel? . Boss runs Server NIO event loop. accept client socke creates a NioAcceptedSocketChannel and register selectors for NioWorker NioClientSocketPipelineSink has a worker thread pool executor. submit NioWorker runnables to worker thread pool at constructor. client channel downstream events sinks here and put to channels write queue/task queue intercept some upstream state events and manages the state of the channel NioServerSocketPipelineSink has boss thread pool. Submit Nio worker runnables to executor at creation. submit boss runnable with ServerSocketChannel to executor on bind event. server channel downstream events sinks here intercept some upstream state events and manages ServerSocketChannel state. How should my implementation respond to ""InterestOps""-type stuff? It depends on the nature of the channel (blocking/non blocking) and constrains. Is ServerChannel.write what is called for messages that come all the way down the stack? What's up with the two different overloads? server channel no need to support those method calls I think you are referring to Channel's ChannelFuture write(Object message); ChannelFuture write(Object message SocketAddress remoteAddress); its there for connectionless transport. for tcp both are actually doing the same thing. How do I need to implement ServerChannel.(dis)connect? server channel no need to support those method calls but you should implement bind unbind here. Should I still do all of this stuff through ServerBootstrap or is that too high-level for this stuff? server/client bootstraps are just helper classes to manage pipeline resources and provide a facade to bind connect & disconnect. You have to implement most of the logic in Client Server Channel Impls Client Server Pipeline sinks BossWorker classes then you have to implement client & server channel factories using above classes if these things are done you can simply setup you server & client using bootstrap classes. I am assuming this pertains to netty 3.x.x the code for netty 4.x.x will change completely when it comes to the transport implementation."
73,A,Application design using Netty I am looking for some theoretical advice on implementing a quiz server using Netty. The three major requirements of the server would be: The server is authoritative and controls the progression of the quiz. For example users register to take part in the quiz (like room/lobby). Once ready the server progresses through the questions and moves on to the next after a certain period of time has elapsed or when everyone answers. The user has ten seconds to answer the question. The amount of time they take to answer the question and the amount of time they have remaining is important to the quiz. The users participating in the quiz would be geographically diverse (i.e. over WAN links). It has to be scalable e.g. a quiz might have ten questions and thirty users while the next might have one hundred questions and ten thousand users. Would Netty be a suitable solution for this? Are there any good books on Netty? I couldn't see any Kindle books on Amazon. Can anyone offer any advice or samples regarding the second point (specifically a time-critical client/server example that takes latency/transmission time in to account)? Unfortunately I don't know any books about netty but the online documentation together with JavaDocs and examples are pretty good. Here is a handful of examples: if you want to serve thousands of concurrent users/connections non-blocking I/O is your only choice. Java (and OS) won't handle thousands of threads effectively needed for blocking I/O. netty can without creating that many threads. netty is as good as underlying protocol (TCP/IP or UDP). You cannot work around network latency. E.g. sending a packet from USA to Europe will take around 150 ms. if timing is so important you might need to synchronize the clocks somehow or use central time source. Check out ntp you must decide how your protocol will interact with the server: short request/response connections established every time users wants to upload question or get new one - think http. This will be very slow but quite reliable (you don't have to worry about long-lasting connections being interrupted establishing one connection per user lasting throughout the whole quiz. This will minimize latencies but you must handle broken connections and reconnects manually. Hybrid approach - choose http protocol with Keep-alive option in netty avoid copying of byte arrays (ChannelBuffer/ByteBuf is pretty good at that) and creating too much garbage avoid blocking I/O operations in netty worker threads. Monitor how many worker threads are utilized avoid queueing of netty events. Thanks Tomasz that's given me something to go on.
74,A,"netty websocket connection via java client Is it possible to create a websocket connection in java code without the handshake request? I know how to create one with a handhsake request using the following:  String request = ""GET "" + path + "" HTTP/1.1\r\n"" + ""Upgrade: WebSocket\r\n"" + ""Connection: Upgrade\r\n"" + ""Host: "" + host + ""\r\n"" + ""Origin: "" + origin + ""\r\n"" + extraHeaders.toString() + ""\r\n""; But i want o avoid the above and once i open a socket connection just want to send frames down the channel?.. is this possible? Double-posting questions? http://stackoverflow.com/questions/12402577/netty-websocket-connection-without-handshake cheers i deleted the other one... You cannot create a WebSocket connection without the WebSocket handshake. The WebSocket handshake and framing is a critical part of the protocol. The handshake is HTTP compatible and allows WebSockets to more easily interact with existing web infrastructure. Among other things the handshake adds security mechanisms and allows Cross Origin Resource Sharing (CORS). After the handshake each WebSocket frame is still not raw data. WebSocket is a message based protocol so the frame headers contain message delineation frame length message type (binary text ping etc) etc. Also data from the client (browser) to the server must be masked using a running XOR mask. This is to avoid a theoretical vulnerability in HTTP intermediaries (proxies HTTP caches etc). Don't be misled by the ""Socket"" in the name. WebSockets has many benefits of raw TCP sockets such as being full-duplex bi-directional long-lived and low latency but it is a message based transport protocol layered on raw TCP sockets and using an HTTP friendly handshake. See the official IETF 6455 WebSocket spec for more details."
75,A,"Simple way to use Netty to build an http proxy server? I'm new to Netty and am looking at using it to make a simple http proxy server that receives requests from a client forwards the requests to another server and then copies the response back to the response for the original request. One extra requirement is that I be able to support a timeout so that if the proxied server takes too long to respond the proxy will respond by itself and close the connection to the proxied server. I've already implemented such an application using Jetty but with Jetty I need to use too many threads to keep inbound requests from getting blocked (this is a lightweight app that uses very little memory or cpu but the latency of the proxied server is high enough that bursts in traffic cause either queueing in the proxy server or require too many threads). According to my understanding I can use Netty to build a pipeline in which each stage performs a small amount of computation then releases it's thread and waits until data is ready for the next stage in the pipeline to be executed. My question is is there a simple example of such an application? What I have so far is a simple modification of the server code for the basic Netty tutorial but it lacks all support for a client. I saw the netty client tutorial but am not sure how to mix code from the two to create a simple proxy app. public static void main(String[] args) throws Exception { ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); ServerBootstrap bootstrap = new ServerBootstrap(factory); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline( new HttpRequestDecoder() new HttpResponseEncoder() /* * Is there something I can put here to make a * request to another server asynchronously and * copy the result to the response inside * MySimpleChannelHandler? */ new MySimpleChannelHandler() ); } }); bootstrap.setOption(""child.tcpNoDelay"" true); bootstrap.setOption(""child.keepAlive"" true); bootstrap.bind(new InetSocketAddress(8080)); } private static class MySimpleChannelHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { HttpRequest request = (HttpRequest) e.getMessage(); HttpResponse response = new DefaultHttpResponse(HttpVersion.HTTP_1_1 HttpResponseStatus.OK); response.setContent(request.getContent()); Channel ch = e.getChannel(); ChannelFuture f = ch.write(response); f.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { Channel ch = future.getChannel(); ch.close(); } }); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { e.getCause().printStackTrace(); Channel ch = e.getChannel(); ch.close(); } } you would have to look at LittleProxy to see how they did it as it is written on top of Netty."
76,A,Difference between handlerUpstream and sendUpstream in netty I am new to NIO and Netty framework. I am developing the sample HTTP server using netty so I can handle thousands of clients connection asynchronously. I have used multiple handlers for encoding decoding aggregating and many. When message received event occurred at one handler then I pass it to next handler and so on. For passing an even I have used ctx.sendUpstream(e) //ctx-ChannelHandlerContext e-event But going through the source code of the netty I came across the another method handleUpstream(ctx e) I have tried to debug the netty source code I am really confused between the usage of the sendUpstream() and handleUpstream(). How they differ from each other?Which one I should use? Right Netty 3 uses ChannelUpstreamHandler.handleUpstream() to process incoming messages and ctx.sendUpstream() to pass messages further upstream. Netty 4 has other methods like ctx.fireChannelRead() Thanks for your answer. Let's say handler1 on the event messageReceived process on that data and wants to pass it to handler2 using sendUpstream(). Then handler2 also process that data in messageReceived() event only. So Do I need to process data in handleUpstream() method instead of messageRecieved() in handler2 ? It depends on handlers and adapters you are using. Base interface ChannelUpstreamHandler has single method handleUpstream() (no messageReceved()). So if you implement this interface you should use handleUpstream(). If you are using adapter like SingleChannelHandler you should process messages in messageReceived() @Igror I got it. Thanks a lot. You mean to say if I implement the ChannelUpstreamHandler() then I should override handleUpstream() method and If I extends SimpleChannelUpstreamhandler then I should use messageReceived(). But my question is If I implement ChannelUpstreamhandler() then how Can I handle channelConnected() channelDisconnected() events as there is only one method handleUpstream() in the interface? Netty's sink sends upstream messages to notify about channel state changes - ChannelStateEvent. SimpleChannelUpstreamHandler processes these messages as following: if (e instanceof ChannelStateEvent) { ChannelStateEvent evt = (ChannelStateEvent) e; switch (evt.getState()) { case CONNECTED: if (evt.getValue() != null) { channelConnected(ctx evt); } else { channelDisconnected(ctx evt); } break; ... }
77,A,"How to send a HTTP 100-continue response with netty I instantiated a netty 4 (using netty-all-4.0.9.jar) service and initialized the channel by adding 3 ChannelHandler objects: pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""handler"" new MyHandler()); When testing w/ curl HTTP PUTing a file to my server and I found MyHandler.channelRead is not called immediately for requests with Expect: 100-continue header is sent (curl is waiting for the server to reply with 100 Continue. This means my handler is not able to reply with a HTTP/1.1 100 Continue response to tell the client (curl) to initiate the actual upload of the file immediate. Interestingly further debugging this issue with telnet shows that a channelRead is called right once the actual body is being uploaded (right after the first byte is received). Any hints on how to handle PUT requests with 'Expect: 100-continue' header properly to trigger 100 Continue response immediately? Examples coming with netty (e.g. HttpHelloWorldServerHandler.java) have the following code in the channelRead() method: if (is100ContinueExpected(req)) { ctx.write(new DefaultFullHttpResponse(HTTP_1_1 CONTINUE)); } I appears the helloworld handler in the example works fine. I investigated further and found that I had a HttpContentDecompressor in the channel pipeline. Removing it solved my problem. Thanks for the hint with the helloworld handler - working backward from here pointed me the root cause (even though I'm not sure why it behaves like this - you can easily reproduce thgis behavior by adding 'p.addLast(""deflater"" new HttpContentDecompressor()' to the HttpHelloWorldServerInitializer class."
78,A,"Netty - UDP server I am having an UDP Netty based server. It has a SimpleChannelUpstreamHandler pipelined where I override the messageReceived method. I need to write back some information now and then. I could only do that by using the socket information from MessageEvent.getRemoteAddress() and the channel from MessageEvent.getChannel(). In order to be able to reuse this information I keep in in a static map. This turns into MessageEvent.getChannel().write(""foo"" MessageEvent.getRemoteAddress()); What I would have expected was to have MessageEvent.getChannel().getRemoteAddress() work which is not the case. It always gives me null. Am I doing something wrong ? Is there a better way for writing back than keeping the channel and remote address in some member ? when using a UDP (Datagram) channel as a server channel you only bind it on a local address and no connection is made. this is why there is no remote address associated with the channel and you always get null when calling MessageEvent.getChannel().getRemoteAddress(). this behavior is expected and correct. the same single UDP ""server"" channel handles all incoming client requests. when using a UDP channel as a client channel one can create a ""connection"" by connecting the channel to a remote address. in this case the channel will have a configured remote address (although no actual connection is made) and calling MessageEvent.getChannel().getRemoteAddress() will return the configured remote address. connecting a UDP channel prevents the user from using the channel to send data to remotes addresses other then the one configured on the channel. trying to do so will throw an exception. connecting a client channel is optional in UDP a client can operate properly with a channel which is only binded on a local address as long as it saves the remote address. I think you have two options: saving the clients remote addresses with the client identifier and using the ""server"" channel to sent the data. saving the channel won't work because the same channel will used for communicating with all clients. creating a new connected channel for each client and saving the new channels with the client identifiers. I believe the first option is better.  As you're probably aware UDP is a connection-less transport. A single channel can receive data from and write data to any destination address. Therefore a UDP channel does not have an associated remote address in the way that a TCP channel does. While I think it's possible to get netty to associate a UDP channel with a specific remote address I haven't got the details to hand and to be honest I think getting the address from the message event is the better option. This leads into your second question in that yes you will need to keep the remote address somewhere. I've not done any UDP programming in Netty so I'm not sure if you need to map the remote address to a channel object or whether Netty is always returning the same channel object regardless. It's worth checking this as you may only need to keep a single reference to the channel. Thanks! What I would have expected though was to have the remote address via the Channel for later usage. If that's not practical maybe throwing an unsupported operation exception would be better. Regarding channel referencing I am not sure whether I am doing it right. I am expecting multiple clients to connect each sending some data along with a unique client identifier. I map the channel to this unique identifier. Thoughts ?  1) Take a look at this UDP upstream handler. To get the remote address of the sender you can use the following code SocketAddress remoteAddress = datagramPacket.sender(); 2) What @johnstlr mentioned is right it is not correct to associate a UDP channel with a single remote address. But you can use a concurrent hashmap to do lookups as shown in the above file. This game server actually uses sessions which have both TCP and UDP connections. This makes it easy to send reliable data over TCP and all the frame data over UDP."
79,A,Netty 4 - What is the expectation and strategy for connecting out and queuing messages When calling clientBootstrap.connect(host port) if I have lots of requests that can be made to this host/port before the channel is established (ie-if I call channel.write(message)) on this channel before it's connected then is it expected that: 1) Netty 4 will queue this message internally and that I simply call flush once it's connected? I had that expectation but is not working for me so want to confirm. If that's the expectation I could share some code. OR 2) Is the expectation that I need to track connection state and queue these messages myself and only call writeMessage() myself once I know the connection is established. OR 3) Other strategy? Thank you in advance. You can not call write before it is connected. If you do so the ChannelFuture will be failed with NotYetConnectedException. Thanks Norman. I confirmed that is exactly what I am seeing so will handle this case at my layer.
80,A,"IllegalReferenceCount in my custom netty Decoder I am getting just started with Netty (Using 4.0.15.Final). I want to read messages from an existing hardware device that talks a proprietary protocol. I have implemented this as follows: public class Xml2StreamProtocolDecoder extends ByteToMessageDecoder { private static final int LENGTH_OF_START_SENTINEL_IN_BYTES = 1; private static final int LENGTH_OF_END_SENTINEL_IN_BYTES = 1; private static final int LENGTH_OF_LENGTH_FIELD_IN_BYTES = 4; @Override protected void decode( ChannelHandlerContext ctx ByteBuf in List<Object> out ) throws Exception { if( in.readableBytes() > LENGTH_OF_START_SENTINEL_IN_BYTES + LENGTH_OF_LENGTH_FIELD_IN_BYTES) { short startSentinel = in.readUnsignedByte(); if (startSentinel != 0x01) { throw new CorruptedFrameException( ""startsentinel not as expected was "" + startSentinel + "" while we expect 0x01"" ); } int messageLength = getMessageLength( in ); if( in.readableBytes() >= messageLength + LENGTH_OF_END_SENTINEL_IN_BYTES ) { ByteBuf result = in.slice( in.readerIndex() messageLength ); in.skipBytes( messageLength ); short endSentinel = in.readUnsignedByte(); if( endSentinel != 0x00 ) { throw new CorruptedFrameException( ""endsentinel not as expected was "" + endSentinel + "" while we expect 0x00"" ); } out.add( result ); } else { // Not enough bytes yet in the frame. Wait on next pass with more bytes. } } else { // Not enough bytes yet to read out the length of the frame. Wait on next pass with more bytes. } } private int getMessageLength( ByteBuf in ) { int msglen1 = in.readUnsignedByte(); int msglen2 = in.readUnsignedByte(); int msglen3 = in.readUnsignedByte(); int msglen4 = in.readUnsignedByte(); return ((msglen4 * 256 * 256 * 256) + (msglen3 * 256 * 256) + (msglen2 * 256) + msglen1); } } I have a unit test that works fine like this: ByteBuf input = Unpooled.buffer(); input.writeBytes( .... ); Xml2StreamProtocolDecoder decoder = new Xml2StreamProtocolDecoder(); EmbeddedChannel channel = new EmbeddedChannel( decoder ); channel.writeInbound( input ); assertThat(channel.inboundMessages()).isNotNull().hasSize( 2 ); However when I add a 2nd decoder (which is a standard Netty class) in the pipeline to convert the bytes into a String like this: EmbeddedChannel channel = new EmbeddedChannel( decoder new StringDecoder( Charset.forName( ""UTF-8"" ) ) ); Then the unit test fails with the following exception: Feb 25 2014 10:11:26 AM io.netty.channel.embedded.EmbeddedChannel recordException WARNING: More than one exception was raised. Will report only the first one and log others. io.netty.handler.codec.DecoderException: io.netty.util.IllegalReferenceCountException: refCnt: 0 decrement: 1 at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:99) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:338) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:324) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:153) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:338) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:324) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) at io.netty.channel.embedded.EmbeddedChannel.writeInbound(EmbeddedChannel.java:169) at com.flir.its.test.Xml2StreamProtocolDecoder2Test.testWith2Messages(Xml2StreamProtocolDecoder2Test.java:188) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.testng.internal.MethodHelper.invokeMethod(MethodHelper.java:640) at org.testng.internal.Invoker.invokeMethod(Invoker.java:627) at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:798) at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1102) at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:137) at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:121) at org.testng.TestRunner.runWorkers(TestRunner.java:1009) at org.testng.TestRunner.privateRun(TestRunner.java:683) at org.testng.TestRunner.run(TestRunner.java:553) at org.testng.SuiteRunner.runTest(SuiteRunner.java:311) at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:306) at org.testng.SuiteRunner.privateRun(SuiteRunner.java:268) at org.testng.SuiteRunner.run(SuiteRunner.java:217) at org.testng.TestNG.runSuite(TestNG.java:1062) at org.testng.TestNG.runSuitesLocally(TestNG.java:956) at org.testng.TestNG.run(TestNG.java:874) io.netty.handler.codec.DecoderException: io.netty.util.IllegalReferenceCountException: refCnt: 0 decrement: 1 at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:99) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:338) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:324) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:153) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:338) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:324) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) at io.netty.channel.embedded.EmbeddedChannel.writeInbound(EmbeddedChannel.java:169) at com.flir.its.test.Xml2StreamProtocolDecoder2Test.testWith2Messages(Xml2StreamProtocolDecoder2Test.java:188) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.testng.internal.MethodHelper.invokeMethod(MethodHelper.java:640) at org.testng.internal.Invoker.invokeMethod(Invoker.java:627) at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:798) at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1102) at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:137) at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:121) at org.testng.TestRunner.runWorkers(TestRunner.java:1009) at org.testng.TestRunner.privateRun(TestRunner.java:683) at org.testng.TestRunner.run(TestRunner.java:553) at org.testng.SuiteRunner.runTest(SuiteRunner.java:311) at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:306) at org.testng.SuiteRunner.privateRun(SuiteRunner.java:268) at org.testng.SuiteRunner.run(SuiteRunner.java:217) at org.testng.TestNG.runSuite(TestNG.java:1062) at org.testng.TestNG.runSuitesLocally(TestNG.java:956) at org.testng.TestNG.run(TestNG.java:874) at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:75) at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:120) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120) Caused by: io.netty.util.IllegalReferenceCountException: refCnt: 0 decrement: 1 at io.netty.buffer.AbstractReferenceCountedByteBuf.release(AbstractReferenceCountedByteBuf.java:115) at io.netty.buffer.AbstractDerivedByteBuf.release(AbstractDerivedByteBuf.java:50) at io.netty.util.ReferenceCountUtil.release(ReferenceCountUtil.java:68) at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:91) ... 35 more at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:75) at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:120) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120) Caused by: io.netty.util.IllegalReferenceCountException: refCnt: 0 decrement: 1 at io.netty.buffer.AbstractReferenceCountedByteBuf.release(AbstractReferenceCountedByteBuf.java:115) at io.netty.buffer.AbstractDerivedByteBuf.release(AbstractDerivedByteBuf.java:50) at io.netty.util.ReferenceCountUtil.release(ReferenceCountUtil.java:68) at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:91) ... 35 more Why is this happening? Am I doing something wrong in my Xml2StreamProtocolDecoder ? Thanks for the tip @BrianRoach. It did not fix the issue. One thing you need to mark and reset the buffer if you decide you need to wait for the next pass due to not having a full frame. See my decode here - https://github.com/basho/riak-java-client/blob/develop/src/main/java/com/basho/riak/client/core/netty/RiakMessageCodec.java#L40 (not saying it'll solve your issue but noticed you hadn't done so) Take a look to ByteBuf::retain() Replacing `out.add(result)` with `out.add(result.retain())` indeed fixes the issue. See also http://stackoverflow.com/questions/20612430/when-do-i-have-to-use-bytebuf-retain-in-a-netty4-encoder"
81,A,"Not able to send messages from server to client via Netty I am just getting started with Netty so please bear with me if this sounds really stupid. What I am trying to accomplish is ask the server to send a ping message to the client upon successful connection to a client. For that I have overridden the channelActive method of the ChannelInboundHandlerAdapter class. When the client connects to the server I can see the ""client connected"" being printed but somehow the server does not send the message to the client. I guess I am doing something really wrong here. Can anyone please help me out? Here's the code snippet in the server- public class ChatServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelActive(final ChannelHandlerContext ctx) { System.out.println(""client connected""); String msg = ""ping""; final ChannelFuture f = ctx.writeAndFlush(msg); f.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) { if(future.isSuccess()) { System.out.println(""Wrote message on active""); } } }); } Client code - public class ChatClientHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx Object msg) { System.out.println(""Msg: "" + (String)msg); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { System.out.println(""Exception...closing channel""); ctx.close(); } } The problem is I don't see the message being printed out in the client upon channelRead() so I am assuming the server hasn't sent the message to the client. Please let me know if you need any other part of the code too. I'm using Netty 4.0.21. Thanks! You will need to send a ByteBuf to have the data sent out Typically in the pipeline near the start of the pipeline will be an encoder which is responsible for taking your message and turning it into a ByteBuf to send onto the network. Have a look at the Write a time server section of the netty user guide; http://netty.io/wiki/user-guide-for-4.x.html Here they wrap a time value into the ByteBuf. For your example you'll want to try; String msg = ""ping""; final ByteBuf byteBufMsg = ctx.alloc().buffer(msg.length()); byteBufMsg.writeBytes(msg.getBytes()); ctx.writeAndFlush(byteBufMsg); As mentioned by Norman in the comments you can also add a StringEncoder to the pipeline. This is particularly nice as it also has a StringDecoder which compliments it on the client side. Adding these before your ChatServerHandler will allow you to keep your class as is in the example. Your pipeline setup would look something like (From StringEncoder example); // Encoder pipeline.addLast(""stringEncoder"" new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(""chatServer"" new ChatServerHandler()); And on your client pipeline; // Decoders pipeline.addLast(""frameDecoder"" new LineBasedFrameDecoder(80)); //This terminates strings on line endings ie \n pipeline.addLast(""stringDecoder"" new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(""chatClient"" new ChatClientHandler()); And update msg to being; String msg = ""ping\n""; As it needs the line ending so LineBasedFrameDecoder will read the message out correctly. Other available encoders can be see from the MessageToMessageEncoder subclasses list as well as the MessageToMessageDecoder for available decoders. Thanks for that piece @NormanMaurer! Do you know if is there anything the user guide that outlines some of the available encoders? Had a look through didn't see anything that jumped out other than using [MessageToByteEncoder](http://netty.io/wiki/user-guide-for-4.x.html#wiki-h3-15). More info available at [StringEncoder](http://netty.io/4.0/api/io/netty/handler/codec/string/StringEncoder.html) for it's usage. Other encoders can be seen from the subclasses for [MessageToMessageEncoder](http://netty.io/4.0/api/io/netty/handler/codec/MessageToMessageEncoder.html) Alternative you can also add a StringEncoder to the ChannelPipeline that will handle the encoding from String -> ByteBuf for you. Thanks @NormanMaurer for your input and Doswell for an updated answer extremely useful."
82,A,"awaitUninterruptibly in netty I thought awaitUninterruptibly means block code execution until operation complete but seems not like that: public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { ChannelFuture f = e.getChannel().close(); f.awaitUninterruptibly(); // ok not netty i/o thread I use a Execution Handler System.out.println(""bbb "" + System.currentTimeMillis()); } public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""aaa "" + System.currentTimeMillis()); } I found ""bbb"" is execute before ""aaa"" If I turn to debug mode and goes line by line ""aaa"" is before ""bbb"" because code execution has been slow down. Did I misunderstand awaitUninterruptibly? await only effect on current thread but using ExectionHandler or a thread pool worker threads the close might executed by another thread so await is useless. It requires adding ChannelFutureListener to do this. The I/O worker thread signals the future as soon as the channel is closed and then goes on to process the callbacks. In this case your thread pool thread is being rescheduled before the I/O worker is able to fire the associated disconnected unbound and closed events. When you run through the debugger you're changing the way the threads are scheduled. Generally future's are used to determine when the requested operation has completed not that any other operations that may be triggered by the operation completing have also completed. Take a look at https://github.com/netty/netty/blob/master/src/main/java/io/netty/channel/socket/nio/NioWorker.java specifically the void close(NioSocketChannel channel ChannelFuture future) method for the exact logic. If you really want to structure it in that way you could override closeRequested on SimpleDownstreamChannelHandler. This would allow you to save your state as part of the closing process. Then when the future completes your state will have been saved. Whether this is the best approach depends on your application. I would suggest that you call close and wait on the future in a handler above the thread pool. Generally I would be very cautious about blocking an I/O thread in any circumstance. Is there any way to do what I want to? Seems hard if using execution handler What type of executor are you passing to your execution handler. IN retrospect I'm a little surprised that you saw ""aaa"" before ""bbb"" in debug mode if you're using OrderMemoryAwareThreadPoolExecutor as you shouldn't see further events until messageReceived has returned. Are the two methods shown above in the same upstream handler? Also can you explain why you need to see channelDisconnected before messageReceived returns? yes I am using OrderMemoryAwareThreadPoolExecutor 2 methods belong to one Handler which below execution handler in pipeline. When a account has been log on twice I need kick the former one offline but before close former's channel I need to save it's data. So I hope codes in channelDisconnected could be executed complete before codes in messageReceived which handle next one log on. Any suggest? In netty doc the typical way seems should be make log on to a independent handler and put it above execution handler That's why ""aaa"" before ""bbb"" in debug because messageReceived called and channelDisconnected called belong to distinct handler object. I thought you ask whether or not belong to one handler class sorry Thanks. I put save code in override channelDisconnected because it works normal offline also. I found put log on code above thread pool will be more difficult to control that even don't guarantee event process sequence. If 2 people log on same account at same time that will be worse. Finally I found that ChannelFutureListener can do this but requires you re-arrange code"
83,A,Netty performance comparison with other alternatives Is there a performance comparison between Netty 4 (or older version) against other alternatives such as Apache HTTPCore Apache Mina etc? I haven't experienced MINA nor HTTPCore but you can find different benchmark around like http://wiki.apache.org/HttpComponents/HttpCoreBenchmark or report of lower perf for MINA here Netty vs Apache MINA However it seems that there is not such a huge difference in perf whereas documentation community activity coding style etc. seem quite unequal. I would recommend to make a decision on those factors as you will have difficulties finding a definitive answer as regards perf.  We have benchmarked Netty against CoralReactor for a TCP client and server exchanging messages over loopback. The full results can be seen here and the test basically consists of: The first JVM runs the client the second JVM runs the server. The client connects to the server and sends a 256-byte message to the server. The first 8 bytes of the message is the timestamp marked by the client of when the message was sent. The server receives the message reads the timestamp reads the remaining 248 bytes and calculates the latency from client to server (one-way latency). The server then echoes back the message to the client. The client receives the echo and send the next message with a new timestamp. To warmup we send 1 million messages. Then we send another 1 million messages and benchmark the latencies. We found that Netty performs with an average latency of 21.167 micros per message while CoralReactor performs with an average latency of 2.061 micros per message without producing any garbage for the GC.
84,A,"Netty Comet Async request time out I'm trying to create long polling Comet using Jboss Netty. How can I configure time out of 30 sec? Following the documentaton: @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""handler"" new HTTPRequestHandler()); Timer timer = new HashedWheelTimer(); pipeline.addLast(""timeout"" new IdleStateHandler(timer 30 30 0)); return pipeline; but it doesn't work and my request lasts forever. How can this be solved? Does it mean that I need to implement Callable<T> then call Future.get with timeout parameter and terminate request if TimeOutException occurs? Then should I use Future<ChannelFuture>? Is there any other approach? Code: FutureExecutor executor = FutureExecutor.getInstance(); @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { HttpRequest request = (HttpRequest) e.getMessage(); ChannelFuture channelFuture = null; Callable<ChannelFuture> myRunnable = new MyCallable(e); Future<ChannelFuture> future = executor.fireEvent(myRunnable); try{ channelFuture = future.get(40TimeUnit.SECONDS); }catch (TimeoutException ex) { channelFuture = e.getChannel(Response timeOutResponse); // handle the timeout } catch (InterruptedException ex) { channelFuture = e.getChannel(Response interaptedResponse); } catch (ExecutionException ex) { channelFuture = e.getChannel(Response errorResponse); } finally{ future.cancel(true); channelFuture.addListener(ChannelFutureListener.CLOSE); } } and inside of Callable I'm just monitoring BlockedQueue: @Override public ChannelFuture call() { final BlockingQueue<String> queue =..... while (true){ Message message = queue.take(); ChannelBuffer partialresponse = ChannelBuffers.buffer(message.toJson()); ChannelFuture future = e.getChannel().write(partialresponse); return future; } } First of you should share one instance of HashedWheelTimer between your pipelines as it will create one thread per instance. But now to your problem.. If you use a IdleStateHandler you also need to implement an IdleStateAwareHandler or IdleStateAwareChannelUpstreamHandler which will react on the IdleState events which get triggered by the IdleStateHandler. So if you want for example to disconnect the Channel after it was idle for you could just call Channel.close() on it after receiving the event. See also: http://netty.io/docs/stable/api/org/jboss/netty/handler/timeout/IdleStateAwareChannelUpstreamHandler.html Another solution would be to add the ReadTimeoutHandler and then act on the ReadTimeoutException when you caught it in the exceptionCaught(..) method. See: http://netty.io/docs/stable/api/org/jboss/netty/handler/timeout/ReadTimeoutHandler.html Calling future.get(40TimeUnit.SECONDS) within messageReceived is really a bad thing as you will block the io-worker/thread. Better would be to move the logic out of netty into another component. The component would just keep a reference to the Channel and use Channel.write(..) if needed. Another way (which is kind of ugly) is to add an ExecutionHandler in front of your handler as this will at least move the blocking operation out of the ioworker/thread. The Problem with your code is that Future.cancel() will not work as you aspected. As your Callable is already running.. I just added code which explains what am I doing exactly I'm just monitoring blocked queue for 40 seconds and return message as JSON if I have something in the queue or return 200 OK with empty response if queue is empty and 40 second timeout occured. thank you for your responseif I open new thread within messageReceived will pass Channel reference there and call Future.get from there. would it be enough? Then I need to think how can I stop this thread once Channel.writes completes. Am I correct? Well you said you use one thread per channel. If you store the ChannelFuture in the BlockedQueue it really depends on how you access it (how many threads). I wonder why you even need todo this.. Why not just register directly a listener to the ChannelFuture which will then get notified once its done ? Or do you need to be able to act on ChannelFuture in an other way ? I guess some sample code would help... That's fine thank you. I'm implementing Async Comet using and I have Thread for each channel which monitors BlockedQueue my problem is that IdleStateAwareChannelUpstreamHandler doesn't stop thread from working. Sorry I don't get it... Even if you use one thread per channel its not a good idea to ""NOT"" share the HashedWheelTimer as it comes with some overhead. If you need to cancel your thread from within the idle handling you will need to offer a method todo so. But thats more something in the scope of your code then in netty. I still think you should avoid from using one thread per Channel.... Can you please me what do you mean by ""thread Per Channel""? If I'm running Callable = new Callable(Channel) and I'm mnitoring my BlockedQueue am I using thread per Channel?"
85,A,"Bandwidth throttling with OMATPE My web server (custom built on top of Netty) uses a web client (also custom built with Netty) to make proxied requests to S3. Client -> Webserver|Webclient -> S3 The purpose of the system is to pipe file uploads directly to S3 with a little bit of logic: Webserver accepts client request (POST); Sets Client channel readability to false and verifies a bunch of stuff; When everything is successfully verified it uses the Webclient to connect to S3; When the Webclient connects to S3: it sends a 100-Continue back to the client it sets Client channel readability to true From there on all chunks received by the Webserver are handed over to the Webclient to forward. In the (highly unlikely) event that the connection between Client and Webserver is faster than the connection between Webclient and S3 I need to throttle the connection between Client and Webserver. The approach I took was simply keep a counter of bytes received by the Webserver (which increments every time Client sends data) and that decrements every time that a write of Webclient completes. Whenever the amount of data on this buffer goes over a given threshold the Client's channel readability is set to false. This works great until I add an OrderedMemoryAwareThreadPoolExecutor to the server's pipeline. A simple solution is to use an OioClientSocketChannelFactory on the Webclient. This causes the calls to Channel.write to be blocking so when messageReceived() is called on the Webserver's handler — and consequently Channel.write is called on the Webclient — throttling happens ""naturally"". However if I use a NioClientSocketChannelFactory on the Webclient then calls to Channel.write become asynchronous and throttling stops working. Basically what I'm noticing here is that Channel.setReadability(false) seems to bear no effect when an OrderedMemoryAwareThreadPoolExecutor is inserted into the pipeline. How can I perform throttling using OMATPE in the pipeline? 1) OrderedMemoryAwareThreadPoolExecutor also monitors the channel memory (in your case received data size) and suspend/enable reading when it above/below the configured max size (through OrderedMemoryAwareThreadPoolExecutor constructor). 2) When its used with an ExecutionHandler the handler may discards channel state events if some attachment found in the context (But that context attachment is usually set by OrderedMemoryAwareThreadPoolExecutor to not allow above upstream handlers to change the channel state and cause OutofMemoryException ).  boolean readSuspended = ctx.getAttachment() != null; if (readSuspended) { // Drop the request silently if MemoryAwareThreadPool has // set the flag. e.getFuture().setSuccess(); return; } I think you have to configure min max channel memory size of OMATPE or you may have an context attachment leads to this situation? Nope I'm not using any attachments. So I guess with OMATPE I don't even need to perform bandwidth throttling on my top level handler right? It depends on how the data transfer happens between Webserver-> WebClient pipline. I think use of OMATPE is to avoid OutOfMemoryException due to fast read + SEDA like pipline. I think to get it working add your channel handler which monitors the traffic before OMATPE in the server pipeline will solve the issue. Have a look on org.jboss.netty.handler.traffic.ChannelTrafficShapingHandler.  As Jestan said please refer to org.jboss.netty.handler.traffic.ChannelTrafficShapingHandler in the master. Also you will have to configure your receiveBufferSizePredictorFactory so that it does not return too large value. Otherwise Netty will just allocate a large buffer and fill it really quickly. Use AdaptiveReceiveBufferSizePredictorFactory with a smaller maximum in combination with ChannelTrafficShapingHandler."
86,A,How to set arbitrary delay between request and response in Netty? I'm implementing a primitive http server and I have a handler extending SimpleChannelInboundHandler. I have a method that's processing requests and I want to make a delay after processing specific request. How should I implement the pause so that server's behaviour still conforms to standards? I mean client (browser etc.) should not behave like connection is lost or something like that but just wait till the necessary amount of time passes. You could just use: ctx.executor().schedule(...) This way you could do the write in the Runnable you pass to the schedule call. Thank you it works just as I wanted!
87,A,"In Netty can you read a ChannelBuffer twice in 3.x? Can you re-read a ChannelBuffer in Netty 3.x ? Meaning can you create two separate ChannelBufferInputStreams using the same ChannelBuffer object and read with no additional marking/resetting necessary? Are you always guaranteed this will work or only if backed by a certain type of source? Yes if you create separate views over the original buffer there should be no problem: ChannelBuffer original = ChannelBuffers.wrappedBuffer(""xyzzy"" .getBytes()); InputStream x = new ChannelBufferInputStream(original.duplicate()); InputStream y = new ChannelBufferInputStream(original.duplicate()); Here you can read idependently from x and y without affecting the indexes of the original buffer."
88,A,error: package org.jboss.netty.channel.socket.nio does not exist Which JAR contains org.jboss.netty.channel.socket.nio? I'm not using maven or ivy just ant (from netbeans). Ant compile gives: -do-compile: [javac] Compiling 4 source files to /home/thufir/NetBeansProjects/EchoClient/build/classes [javac] /home/thufir/NetBeansProjects/EchoClient/src/net/bounceme/dur/netty/client/ObjectEchoClient.java:3: error: package org.jboss.netty.channel.socket.nio does not exist [javac] import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory; In the classpath is: thufir@dur:~/NetBeansProjects/EchoClient/nbproject$ thufir@dur:~/NetBeansProjects/EchoClient/nbproject$ head -n 58 project.properties | tail -n 29 endorsed.classpath= excludes= file.reference.netty-all-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/all-in-one/netty-all-4.0.21.Final-sources.jar file.reference.netty-all-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/all-in-one/netty-all-4.0.21.Final.jar file.reference.netty-buffer-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-buffer-4.0.21.Final-sources.jar file.reference.netty-buffer-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-buffer-4.0.21.Final.jar file.reference.netty-codec-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-codec-4.0.21.Final-sources.jar file.reference.netty-codec-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-codec-4.0.21.Final.jar file.reference.netty-codec-http-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-codec-http-4.0.21.Final-sources.jar file.reference.netty-codec-http-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-codec-http-4.0.21.Final.jar file.reference.netty-codec-socks-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-codec-socks-4.0.21.Final-sources.jar file.reference.netty-codec-socks-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-codec-socks-4.0.21.Final.jar file.reference.netty-common-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-common-4.0.21.Final-sources.jar file.reference.netty-common-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-common-4.0.21.Final.jar file.reference.netty-example-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-example-4.0.21.Final-sources.jar file.reference.netty-example-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-example-4.0.21.Final.jar file.reference.netty-handler-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-handler-4.0.21.Final-sources.jar file.reference.netty-handler-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-handler-4.0.21.Final.jar file.reference.netty-tcnative-1.1.30.Fork2-linux-x86_64.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-tcnative-1.1.30.Fork2-linux-x86_64.jar file.reference.netty-tcnative-1.1.30.Fork2-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-tcnative-1.1.30.Fork2-sources.jar file.reference.netty-transport-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-transport-4.0.21.Final-sources.jar file.reference.netty-transport-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-transport-4.0.21.Final.jar file.reference.netty-transport-rxtx-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-transport-rxtx-4.0.21.Final-sources.jar file.reference.netty-transport-rxtx-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-transport-rxtx-4.0.21.Final.jar file.reference.netty-transport-sctp-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-transport-sctp-4.0.21.Final-sources.jar file.reference.netty-transport-sctp-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-transport-sctp-4.0.21.Final.jar file.reference.netty-transport-udt-4.0.21.Final-sources.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-transport-udt-4.0.21.Final-sources.jar file.reference.netty-transport-udt-4.0.21.Final.jar=/home/thufir/jars/netty-4.0.21.Final/jar/netty-transport-udt-4.0.21.Final.jar includes=** thufir@dur:~/NetBeansProjects/EchoClient/nbproject$ Which was downloaded from: http://netty.io/downloads.html netty-4.0.21.Final.tar.bz2 I added each JAR from that download to the project. Yes I realize it's not using the CLI javac classpath but the JAR's are visible in the project as well as in the output above. I looked through some of the JAR's and was unable to find this specific class. You seem to be trying to build an application developed against netty 3.x using netty 4.0. There have been API changes including channel creation and bootstrap. Also the package prefix changed from org.jboss.netty to io.netty reflecting the project status change. Use the API documentation (which no longer documents NioClientSocketChannelFactory) corresponding to the release you're using and checkout the provided examples (netty-example-4.0.21.Final-sources.jar) to help port any code you have that's built against netty 3.x. mystery solved! The sample code was from the github repository for netty. I'll take a closer look at this tomorrow before I accept answer to be sure that I understand what's going on.
89,A,Netty3: websockets with SSL on Android I've decided to describe problem which I met using Netty library. Currently I work on Android client that send and receive data through websocket and that was the reason why Netty library was chosen. Now I have NIO mechanism which handle SSL connection using websockets. Everything works fine expect one a little bit unusual scenario - when Android client and the server send data to each other in the same time (few requests per second) after a while 'write' operation's ChannelFutureListener never calls 'operationComplete'. I've made some research and found information that this kind of problem can occur when ssl handshake isn't finished . However I think this scenario doesn't apply to my situation when data is received and sent properly until this extreme situation. Have you any idea where I should looking for solution for this problem? My research: At first I found that this problem occurs on Netty4 too but unfortunately Netty3 hasn't channel method like 'writeAndFlush'. Then I found bug:Issue 1823 which was fixed by this commit and was described here which could be closely related to my problem. Unfortunately I have problems with build Netty to jar - I have problems with HashedWheelTimer which calls NoClassDefFoundError everytime when I want to use it. Is it fault how I build this project or is it this branch internal problem? Unfortunately the newest Netty on maven repository (3.9.0.Final) doesn't include this fix. I've observer strange behaviour of my application: when 'operationComplete' isn't called and I close channel (channel.close()) I get few 'operationComplete' calls from every unfinished 'write' operation. Moreover when I observe state of threads in pool after problem occurs thread which is responsible for channel is in 'WAIT' state. I am not sure what is a result and what is a cause. I will really appreciate any ideas what can I do. PS. Move to Netty4/5 is latest considered option - I suppose it will cost me a lot of time. Krzysztof Skrzynecki Can you please show me the ClassNotFoundException? Also you can download a snapshot from here: https://oss.sonatype.org/content/repositories/snapshots/io/netty/netty/3.9.1.Final-SNAPSHOT/ Hi unfortunately yours link is dead. Anyway I've used [this](https://secure.motd.kr/jenkins/job/netty-3.9/lastSuccessfulBuild/artifact/target/netty-3.9.2.Final-SNAPSHOT.jar) one and still I have problem with not found class: 'Caused by: java.lang.NoClassDefFoundError: org.jboss.netty.util.HashedWheelTimer' when I call 'private static Timer timer = new HashedWheelTimer();' According to main problem of this 'Netty3 WebSockets with SSl on Android' issue there wasn't any problem with Netty library itself. I've found that it was classic Readers-writers problem with one boolean flag which was shared resource. I got wrong track because I found that other users has similar problems and that was the reason why I thought Netty is a cause. For others users who want to use Netty on Android I have just one word - everything works just fine.
90,A,"Changing DynamicChannelBuffer in Netty to String and back to ChannelBuffer My web server is written in Scala using Twitter's Finagle library which in turn relies on Netty. As such the request content is returned as a DynamicChannelBuffer. If I upload an image to the server using curl from the Terminal like this:  curl -T ""abc.jpg"" http://127.0.0.1:8080/test/image Then I can read and forward the image to a backend webserver using a SOAP packet that looks like this:  <soap:Envelope xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" xmlns:soap=""http://schemas.xmlsoap.org/soap/envelope/""> <soap:Header> <AuthHeader xmlns=""http://www.testtesttest.co.za/""> <LogonID>testtesttest</LogonID> <Password>testtesttest</Password> </AuthHeader> </soap:Header> <soap:Body> <uploadFile xmlns=""http://www.testtesttest.co.za/""> <FileDetails> <FileName>image.jpg</FileName> <FileContents> {(Base64.encode(request.getContent())).toString(UTF_8) </FileContents> </FileDetails> </uploadFile> </soap:Body> </soap:Envelope> In the example above the code: (Base64.encode(request.getContent())).toString(UTF_8) converts the request content to a base 64 encoded string. The problem is that I need to read the image content from Multipart Http request that is sent from a PhoneGap mobile app. PhoneGap gives me no option to send only the image and insists in doing the file upload as a multipart request. To break the multipart request apart I change the request.getContent() result into a string using toString(UTF_8) and then getting the image data part by splitting the http multipart message into it's separate chunks:  var requestParts = request.content.toString(UTF_8).split(""\\Q--*****org.apache.cordova.formBoundary\\E"") val imageParts = requestParts(3).split(""\\n\\s*\\n"") val imageHeader = imageParts(0) val imageBody = imageParts(1) This is crappy I know (I'll improve later) but does the trick for now. imageBody now has the image content as a string. Now if I put the imageBody back into the SOAP packet I have to encode it again using:  val encoder = new BASE64Encoder(); val encodedImage = encoder.encode(imageBody) At this point the image is just garble. It's size looks right but I'm messing something up with the string conversion or encoding. For the first example I'm using Netty's encoder but for the second example I'm using the standard java encoder. The reason is that Netty's encoder can only encode objects of type ChannelBuffer. I don't want to say this too loud but I've been struggling with this for more than a day. Any help here will be GREATLY appreciated. +1 for your struggles So this works: image --> [curl] ------> post1 --> [your code] --> soap msg 1 --> [back-end] This does not: image --> [phonegap] --> post2 --> [your code] --> soap msg 2 --> [back-end] To solve this type of problem reliably you need to understand which encoding is used in each step. Assuming you can use the same image can you check the raw encoded content in post1 and post2 and infer which encoding is being used? Then when you understand that log the content in your code as you decode and recode the message. That way you can ensure it's the same in soap msg1 and soap msg2. Thank you. I like the way you laid it out. It kind-of clears the head a little. The same photo from PhoneGap does not look excatly like the one from curl. My guess was that PhoneGap did a bit of compression behind the scenes but yes it may be it's encoding also. I kept thinking that it was me who wrote to string and back but maybe that's not the problem."
91,A,"Netty SimpleChannelInboundHandler close channel I have handler that extends SimpleChannelInboundHandler. I use it for handling websocket frames. What is the best way to detect that connection was closed from client side (for browser closed or network connection crashed)? I see there are two methods in ChannelInboundHandlerAdapter: channelUnregistered and channelInactive. Can I use its for detectiong channel closing? You should use channelInactive() which is triggered when a channel cannot perform communication anymore. channelUnregistered() has different meaning although channelUnregistered() is always triggered after channelInactive().  with netty 4 i use channelUnregistered maybe you are worried about the warning on the log i solved it changing the log level because it is already handled by the method but always appear <logger name=""io.netty"" additivity=""false""> <level value=""ERROR"" /> <appender-ref ref=""console"" /> </logger>"
92,A,"Order of initialization in Java: exception with Netty 4.0.7 I am hitting a problem with Netty at class initialization. I thought static fields are always initialized before instance fields but apparently this is not the case: Class AbstractByteBuff contains a static final ResourceLeakDetector<ByteBuf> leakDetector Class AbstractReferenceCountedByteBuf extends AbstractByteBuff Class UnpooledUnsafeDirectByteBuf extends AbstractReferenceCountedByteBuf The first time an UnpooledUnsafeDirectByteBuf is created a Null Pointer Exception is thrown in its constructor: protected UnpooledUnsafeDirectByteBuf(ByteBufAllocator alloc int initialCapacity int maxCapacity) { super(maxCapacity); if (alloc == null) { throw new NullPointerException(""alloc""); } if (initialCapacity < 0) { throw new IllegalArgumentException(""initialCapacity: "" + initialCapacity); } if (maxCapacity < 0) { throw new IllegalArgumentException(""maxCapacity: "" + maxCapacity); } if (initialCapacity > maxCapacity) { throw new IllegalArgumentException(String.format( ""initialCapacity(%d) > maxCapacity(%d)"" initialCapacity maxCapacity)); } this.alloc = alloc; setByteBuffer(ByteBuffer.allocateDirect(initialCapacity)); leak = leakDetector.open(this); } The exception is thrown from the code leak = leakDetector.open(this); . By inspecting with intellij Idea I have found out that the leakDetector variable is null. How this is possible? It's a static variable initialized in the superclass of the superclass of the current class. The source code is available on Github all the classes which raise the problem are available in the following package: https://github.com/netty/netty/tree/master/buffer/src/main/java/io/netty/buffer The three sources are the following : https://github.com/netty/netty/blob/master/buffer/src/main/java/io/netty/buffer/UnpooledUnsafeDirectByteBuf.java https://github.com/netty/netty/blob/master/buffer/src/main/java/io/netty/buffer/AbstractReferenceCountedByteBuf.java https://github.com/netty/netty/blob/master/buffer/src/main/java/io/netty/buffer/AbstractByteBuf.java This last one AbstractByteBuff contains the leakDetector. Please note I am not compiling the sources but just linking to Netty 4.0.7 final. Here the stackTrace: o.netty.handler.codec.EncoderException: java.lang.NullPointerException at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:131) at io.netty.channel.DefaultChannelHandlerContext.invokeWrite(DefaultChannelHandlerContext.java:643) at io.netty.channel.DefaultChannelHandlerContext.write(DefaultChannelHandlerContext.java:633) at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:115) at io.netty.channel.DefaultChannelHandlerContext.invokeWrite(DefaultChannelHandlerContext.java:643) at io.netty.channel.DefaultChannelHandlerContext.writeAndFlush(DefaultChannelHandlerContext.java:689) at io.netty.channel.DefaultChannelHandlerContext.writeAndFlush(DefaultChannelHandlerContext.java:713) at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:893) at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:239) at com.logentries.net.NettyBasedAsyncLogger.logLine(NettyBasedAsyncLogger.java:54) at com.logentries.logback.LogentriesAppender.append(LogentriesAppender.java:105) at com.logentries.logback.LogentriesAppender.append(LogentriesAppender.java:15) at ch.qos.logback.core.AppenderBase.doAppend(AppenderBase.java:85) at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:48) at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:280) at ch.qos.logback.classic.Logger.callAppenders(Logger.java:267) at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:449) at ch.qos.logback.classic.Logger.filterAndLog_1(Logger.java:421) at ch.qos.logback.classic.Logger.debug(Logger.java:514) at io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76) at io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:37) at io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:37) at io.netty.buffer.UnpooledByteBufAllocator.newDirectBuffer(UnpooledByteBufAllocator.java:49) at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:132) at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:123) at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:76) at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107) at io.netty.channel.DefaultChannelHandlerContext.invokeWrite(DefaultChannelHandlerContext.java:643) at io.netty.channel.DefaultChannelHandlerContext.write(DefaultChannelHandlerContext.java:633) at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:115) at io.netty.channel.DefaultChannelHandlerContext.invokeWrite(DefaultChannelHandlerContext.java:643) at io.netty.channel.DefaultChannelHandlerContext.access$2000(DefaultChannelHandlerContext.java:29) at io.netty.channel.DefaultChannelHandlerContext$WriteTask.run(DefaultChannelHandlerContext.java:887) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:354) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:366) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101) at java.lang.Thread.run(Thread.java:662) Caused by: java.lang.NullPointerException at io.netty.buffer.UnpooledUnsafeDirectByteBuf.<init>(UnpooledUnsafeDirectByteBuf.java:72) at io.netty.buffer.UnpooledByteBufAllocator.newDirectBuffer(UnpooledByteBufAllocator.java:49) at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:132) at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:123) at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:76) at io.netty.handler.codec.MessageToByteEncoder.write(MessageToByteEncoder.java:107) ... 36 more how is this constructor being invoked? normal program flow or part of some other class' static init? normal program flow. what's scary is that if I do a debug / step by step everything works fine. It looks like I am hitting a jvm problem with jdk 1.6u25 if that's the case then something is messed up. maybe you need to make sure all your classes are recompiled? can you show the actual exception trace and the `leakDetector` definition? what is the stack trace of the actual exception? added stacktrace thanks :) The stack trace indicates your problem: at io.netty.util.internal.logging.Slf4JLogger.debug(Slf4JLogger.java:76) at io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:37) at io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:37) ""<clinit>"" means that the classes are in the midst of their class initialization. it looks like ResourceLeakDetector is generating a log statement during class initialization (before AbstractByteBuf's class init completes and leakDetector is assigned). UPDATE: Probably the most confusing part looking at the entire stack trace is that it is not apparent what has not happened yet. The key bit is that the static class initialization of UnpooledUnsafeDirectByteBuf has not yet happened! the current status of the jvm is: UnpooledByteBufAllocator is trying to create a new instance of UnpooledUnsafeDirectByteBuf UnpooledUnsafeDirectByteBuf class is loaded (but not initialized) AbstractReferenceCountedByteBuf class is loaded (but not initialized) since it is the parent of UnpooledUnsafeDirectByteBuf AbstractByteBuf class is loaded (but not initialized) since it is the parent of AbstractReferenceCountedByteBuf AbstractByteBuf class initialization begins (since parents are inited before children) leakDetector is still null ResourceLeakDetector class is loaded since it is referenced by AbstractByteBuf class init ResourceLeakDetector class initialization begins which includes a log statement ...bunch of other method calls are made... UnpooledByteBufAllocator creates a new instance of UnpooledUnsafeDirectByteBuf (this is a recursive call to this method) new instance of UnpooledUnsafeDirectByteBuf is allocated (the class has already been loaded but not yet initialized) NullPointerException If you removed the logging call from ResourceLeakDetector class init what would happen is: same same same same same same ResourceLeakDetector class initialization runs to completion AbstractByteBuf class initialization completes leakDetector is now assigned AbstractReferenceCountedByteBuf class initialization runs to completion UnpooledUnsafeDirectByteBuf class initialization runs to completion UnpooledByteBufAllocator creates a new instance of UnpooledUnsafeDirectByteBuf life proceeds happily I don't agree. I am actually coding a logger and this might be confusing. But the cause is here: Caused by: java.lang.NullPointerException at io.netty.buffer.UnpooledUnsafeDirectByteBuf.(UnpooledUnsafeDirectByteBuf.java:72) @Edmondo1984 - feel free to disagree all you want but the answer is right there in the stack trace. the stack trace is the _exact state_ of the system when the problem occurred. AbstractByteBuf line 37 is the line where leakDetector is assigned. since the assignment hasn't happened yet leakDetector is still null. yes but why it is null if it is a final static member defined on the parent class of the current class? @Edmondo1984 - because the parent class has not finished class initialization yet as you can see from the stack trace. you have a circular static dependency problem see e.g. http://stackoverflow.com/questions/6416408/static-circular-dependency-in-java why it has not ? Can you please detail your answer? Awesome ! but why does the log statement produce this effect? @Edmondo1984 - detailed ouch I got it. My logger was called recursively from netty ... :("
93,A,Netty data streaming performance + websocket performance I wanted to look at some particular performance numbers for netty and have looked over the various links in the related articles section on the netty website. But most of them talk about the number of simultaneous connections to a netty server and not about the data transfer rate or something similar which I wish to look over. Also  any performance numbers specifically for a netty websocket server ? (I understand it may depend on the websocket protocol used as well to some extent  is it ?) If someone has done some work / seen some links on the web in any of the 2 areas  could they please share some data numbers / insights ? You can run the AutoBahn tests against Netty. It includes some performance tests. For instructions see here for netty 4 and here for netty 3.  Vague numbers are not going to be of much help here. The number of parameters involved is so large that only a much more concrete case can give you reasonable numbers. What do you need to achieve? Maximum transfer speed you can test by sending the same byte (or block of bytes) again and again to an already connected client. That gives you an upper limit (for the hardware OS and protocol stack versions and settings).
94,A,"What does ChannelOption.SO_BACKLOG do? .option(ChannelOption.SO_BACKLOG 100) is shown in the Netty 4 upgrade doc. Can you explain what it does? Thanks! It's a passed through socket option determining the number of connections queued. http://docs.oracle.com/javase/7/docs/api/java/net/ServerSocket.html The maximum queue length for incoming connection indications (a request to connect) is set to the backlog parameter. If a connection indication arrives when the queue is full the connection is refused. More on netty channels: http://seeallhearall.blogspot.de/2012/06/netty-tutorial-part-15-on-channel.html Note that the final statement in the Javadoc is incorrect. Whether the connection is refused is platform-dependent and not under Java's control. @EJP thanks for the clarification. Is there any source for this platform-dependency? I only found something about the *default*: *""The default backlog tends to OS specific. We try to use a default backlog of 50 (this is not part of the specification and thus is implementation specific).""* (http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4304037) I discovered it by experiment on Windows Solaris Linux and a few more platforms which I've forgotten. It's also mentioned in a paper cited in my book *Fundamental Networking in Java* but I don't have a copy to hand."
95,A,"Implement Cross Origin Resource Sharing (CORS) on Resteasy + Netty server Integrating Resteasy in my netty 4 + Guice application works perfectly using server adapter provided by Resteasy (great job guys). Now my JAX-RS server runs on a different port as my HTTP server (also based on Netty). So I need to implement Cross Origin Resource Sharing (CORS) on my Resteasy server by adding following HTTP headers to the response: Access-Control-Allow-Origin : * Access-Control-Allow-Methods : GETPOSTPUTDELETEOPTIONS Access-Control-Allow-Headers : X-Requested-With Content-Type Content-Length For now I have forked NettyJaxrsServer and RestEasyHttpResponseEncoder classes and it works quite good (but not a very ""clean"" solution to me). I just wonder how to add those headers to response using something like a customized encoder that I could add to my Netty pipeline (or something else...) Thanks. Solution : create a SimpleChannelInboundHandler like this: public class CorsHeadersChannelHandler extends SimpleChannelInboundHandler<NettyHttpRequest> { protected void channelRead0(ChannelHandlerContext ctx NettyHttpRequest request) throws Exception { request.getResponse().getOutputHeaders().add(""Access-Control-Allow-Origin"" ""*""); request.getResponse().getOutputHeaders().add(""Access-Control-Allow-Methods"" ""GETPOSTPUTDELETEOPTIONS""); request.getResponse().getOutputHeaders().add(""Access-Control-Allow-Headers"" ""X-Requested-With Content-Type Content-Length""); ctx.fireChannelRead(request); } } and add this to Netty pipeline just before RestEasyHttpResponseEncoder. NOTE: Finnally I have added RestEasyHttpRequestDecoder RestEasyHttpResponseEncoder and RequestHandler at the end of my existing Netty Http server pipeline so I don't need CORS headers anymore."
96,A,"How to correctly limit bandwith usage with Java netty? For a download client that I developed in Java using the netty nio lib I also implemented a bandwith limitation feature. Technically I do so via a GlobalTrafficShapingHandler object. Based on this class' JavaDoc I initialize the nio client pipeline as follows: ... trafficHandler = new GlobalTrafficShapingHandler( new HashedWheelTimer() 0 0 1000); execHandler = new ExecutionHandler( new OrderedMemoryAwareThreadPoolExecutor(20 0 0)); ... public ChannelPipeline getPipeline() throws Exception { // create default pipeline ChannelPipeline pipeline = pipeline(); // traffic shaping handler pipeline.addLast(""global-traffic-shaping"" trafficHandler); // SSL support if(useSSL) { SSLEngine sslEngine = createSSLEngine(); pipeline.addLast(""ssl"" new SslHandler(sslEngine)); } // memory executor pipeline.addLast(""memory-executor"" execHandler); // business logic pipeline.addLast(""data-processing"" new NettyNioClientHandler( nettyNioClient localer logger ncMgr username useSSL)); return pipeline; } And during runtime I then set the max. download speed via public void setDlSpeedLimit(long limit) { if(limit < 0) return; trafficHandler.configure(0 limit * 1000L); } Ok so basically the netty nio functionality works fine and fast. When I set the max. download speed in the application I can also see that the bandwidth usage is indeed capped at a max. level. I monitor the bandwith usage via trafficHandler.getTrafficCounter().getLastReadThroughput(); However unfortunately the max. speed I monitor is not to what I have set it before not even close. For example I originally (w/o limit) have a download speed of about 2000 kb/s then I set the limit to 300 kb/s as described above but the real download speed is then varying from 700-900 kb/s. So my problem in this case is: I can see that the traffic shaper is doing something but not as I wanted it to. Do I miss something here any step in the pipeline initialization for example? Thanks in advance for your help! Your getPipeline() is instantiating GlobalTrafficShapingHandler every time a new pipeline is requested. You should only instantiate one and reuse it in all pipelines instead. This is also true for other classes such as HashedWheelTimer. Netty has quite a few classes that must be shared among pipelines. Usually the documentation clearly mentions this. You should examine each classes' javadoc and make sure you are following them. You are of course right in reality I did as you suggested in my code. The GlobalTrafficShapingHandler HashedWheelTimer and ExecutionHandler is created before in the class constructor. Sorry if my original post has confused you in that regard. I have updated it accordingly.  Ok so it seems there are not other ideas. The only thing that helped me a bit was to increase the timing counter to 5-10 sec. Cheers!"
97,A,"How to store unsigned short in java? So generally I'm using Netty and it's BigEndianHeapChannelBuffer to receive unsinged short (from c++ software) in Java. When I do it like this: buf.readUnsignedByte(); buf.readUnsignedByte(); it returns: 149 and 00. Till now everything is fine. Because server sent 149 as unsigned short [2 bytes]. Instead of this I would like to receive unsigned short (ofc after restarting my application): buf.readUnsignedShort(); and magic happens. It returns: 38144. Next step is to retrieve unsigned byte: short type = buf.readUnsignedByte(); System.out.println(type); and it returns: 1 which is correct output. Could anyone help me with this? I looked deeper and this is what netty does with it: public short readShort() { checkReadableBytes(2); short v = getShort(readerIndex); readerIndex += 2; return v; } public int readUnsignedShort() { return readShort() & 0xFFFF; } But still I can't figure what is wrong. I would like just be able to read that 149. Endiness is the issue obviously. The sequence 149-0 is *little*-endian: the first byte is the little byte. Not much magic 149*256+0=38144. You have specified BigEndian so this seems correct the most significant byte is sent first. You probably mean ""unsigned short [2 bytes]"" Shorts signed or unsigned are 2 bytes. Ints are 4 bytes. yes of course 2 bytes sorry for mistake. @RogerLindsjö could you explain it more? Why do you multiply it by 256? I think I missed some of my classes with 2's complement and etc. @mickula The short is two bytes where one of the bytes is ""worth"" 256 times as much as the other Since you use BigEndian the first byte is the one ""worth"" more. Similar to the decimal number 123 of the digits 1 2 and 3. The first position is with 10 times the next position which is worth 10 times the next and so on. So 1 * 100 + 2 * 10 + 3 = 123 when the digits are transferred one at a time. If you see 1 2 and 3 as little endian you would use 1 + 2 * 10 + 3 * 100 = 321. The 256 is because the size of a byte is 256. ok thank you ;]. I will copy your comment to answer. The answer is to change endianness. Thanks to Roger who in comments wrote: Not much magic 149*256+0=38144. You have specified BigEndian so this seems correct the most significant byte is sent first and: @mickula The short is two bytes where one of the bytes is ""worth"" 256 times as much as the other Since you use BigEndian the first byte is the one ""worth"" more. Similar to the decimal number 123 of the digits 1 2 and 3. The first position is with 10 times the next position which is worth 10 times the next and so on. So 1 * 100 + 2 * 10 + 3 = 123 when the digits are transferred one at a time. If you see 1 2 and 3 as little endian you would use 1 + 2 * 10 + 3 * 100 = 321. The 256 is because the size of a byte is 256. – Thanks to his comments I just switched endianess in server bootstrap by adding: bootstrap.setOption(""child.bufferFactory"" new HeapChannelBufferFactory(ByteOrder.LITTLE_ENDIAN));  You could also borrow a page from the Java DataInputStream.readUnsignedShort() implementation: public final int readUnsignedShort() throws IOException { int ch1 = in.read(); int ch2 = in.read(); if ((ch1 | ch2) < 0) throw new EOFException(); return (ch1 << 8) + (ch2 << 0); }"
98,A,"Bi-directional Netty Server I have a server which needs to have bi-directional connection to clients and provide web services for few websites. In fact webservice is a dealer which roots requests of web sites to clients. The Scenario is: Dealer starts it's web service and at the same time listening on port 12345. Client-A sends its username to port 12345 of dealer and keeps on listening on same port. Dealer receives username validates user and keep a connection to user. Website-1 invokes doOperation(operation-XUser-A) from dealer's web service. Dealer checks if user-A exists and send a request of ""operation-X"" to it. User-A invokes ""Operation-X"" and sends back the result to dealer. Dealer sends back the result to Website. As you see in scenario server needs to send unsolicited messages to clients and gets the respond immediately to serve web sites. Firstly I implemented a multi-threaded bidirectional socket solution which worked fine for few clients but got performance problems and unfortunately we have more than 10k concurrent users. Then I found netty. It looks like a very promising solution. But it's asynchronous and event driven nature makes me worry. Some more it seems to be unidirectional. http://apache-avro.679487.n3.nabble.com/Writing-Unsolicited-Messages-to-a-Connected-Netty-Client-td3675163.html So the question is how to have an asynchronous handshaking ( something like : http://biasedbit.com/handshaking-tutorial-with-netty/ ) and then send the requests from dealer and get the result? ** Any feedback advice and knowledge sharing is highly appreciated Netty allows you to write any kind of protocol over TCP (actually UDP and others as well but let's stick to TCP). Once a TCP connection is established between two parties any party can send data at any time all according to a protocol of some kind. The terms client and server does not really apply to an established TCP connection but some protocols like HTTP does of course distinguish between the roles of the connection endpoints. So no Netty is not unidirectional in the sense of the Avro link--that is probably a consequence of how Avro is using and exposing Netty functionality. In your case the ""dealer"" needs to manage the active channels that represents client connections and website connections and coordinate messages sent and received between them. This is nothing special and you can probably find several similar examples and solutions floating around. Dear forty two Thanks. You gave me the confidence to go further. However this is my very first project using netty and sockets and I couldn't find any sample. All I need is to find a working example to do POC and then write my own. Do you have or know any? Ya I have looked at it the difference in my approach and netty's examples is in my case server needs to initiate the communication; it needs to find the channel's channel base on username and send a message to it. While in chat servers server is answering to a client's request A chat server is ""initiating"" the communication for all clients except the one that sends a message so I really don't see the difference. yes that's the point it initiates after recieving. I will need a public function to send message to a ""specific user"" anytime I want @NilNull Have a look at the [secure chat server example](http://netty.io/4.1/xref/io/netty/example/securechat/package-frame.html). I believe it has some of the characteristics you describe. So what's stopping you? Go ahead and write the code. If you run in to problems come back with another question. Please have a look on http://stackoverflow.com/questions/24969448/get-a-channel-send-a-request-and-get-result-in-netty"
99,A,Why does netty have its own ConcurrentHashMap? I noticed that Netty has some internal Concurrent HashMap utilities. I'm curious why Netty doesn't use the ConcurrentHashMap that's built into the Java Core. Is the Netty implementation better in some way or does it have some new functionality? I'm working on a project that needs a Concurrent HashMap and I'm debating whether I should use the netty implementation but I can't see any difference in the source code. Read the documentation or if you're brave dive into the source code. Perhaps netty supported Java 1.4 at some point and it wasn't removed. Which utilities are you referring to? ConcurrentHashMap didn't exist until JSR-166 which was released in Java 5 as the java.util.concurrent package. Netty doesn't include their own ConcurrentHashMap because it's superior - in fact it's certainly just a copy of JSR-166 - it's so they can run on Java 1.4. For your own projects you should just use java.util.concurrent.ConcurrentHashMap if you can take a dependency on Java 5. And if you can't then you should just include it in your product (and change the package name so that it doesn't conflict with the Java 5 runtime's included projects.) Any time you can get Doug Lea or Brian Goetz to write your thread-safe code for you you probably should. Thanks so much! This makes perfect sense. I looked at the source code for Netty's ConcurrentHashMap and I couldn't see anything different but I wanted to make sure I wasn't missing something.
100,A,"Spring JMS with JBoss 7.11 (HornetQ) I am trying to create a sample JMS application. All I want it to do is start up and have the producer send a message to the consumer when data is sent to an endpoint. I am having trouble with my spring configuration and I don't know what dependencies I need to bring in (and what versions) with Maven. I started with a simple Roo project. Firstly does my spring xml look ok and secondly are my maven dependencies right? From the error I get I think I've got an outdated dependency being pulled in from Maven. I've also added a guest user/role to my jboss configuration. Here is the relevant section of my spring xml: <bean id=""jnditemplate"" class=""org.springframework.jndi.JndiTemplate""> <property name=""environment""> <props> <prop key=""java.naming.factory.initial"">org.jboss.naming.remote.client.InitialContextFactory</prop> <prop key=""java.naming.provider.url"">remote://127.0.0.1:4447</prop> <prop key=""java.naming.security.principal"">guest</prop> <prop key=""java.naming.security.credentials"">password1</prop> </props> </property> </bean> <bean id=""connectionfactory"" class=""org.springframework.jndi.JndiObjectFactoryBean""> <property name=""jndiTemplate"" ref=""jnditemplate""/> <property name=""jndiName"" value=""jms/RemoteConnectionFactory""/> </bean> <bean id=""destination"" class=""org.springframework.jndi.JndiObjectFactoryBean""> <property name=""jndiTemplate"" ref=""jnditemplate""/> <property name=""jndiName"" value=""jms/queue/test""/> </bean> <bean id=""credentialsconnectionfactory"" class=""org.springframework.jms.connection.UserCredentialsConnectionFactoryAdapter""> <property name=""targetConnectionFactory"" ref=""connectionfactory""/> <property name=""username"" value=""guest""/> <property name=""password"" value=""password1""/> </bean> <bean id=""jmstemplate"" class=""org.springframework.jms.core.JmsTemplate""> <property name=""connectionFactory"" ref=""credentialsconnectionfactory""/> <property name=""defaultDestination"" ref=""destination""/> </bean> <bean class=""org.springframework.jms.listener.SimpleMessageListenerContainer""> <property name=""connectionFactory"" ref=""credentialsconnectionfactory""/> <property name=""destination"" ref=""destination""/> <property name=""messageListener"" ref=""receiver""/> </bean> <bean id=""sender"" class=""com.example.web.Producer""> <property name=""jmsTemplate"" ref=""jmstemplate""/> </bean> <bean id=""receiver"" class=""com.example.web.Consumer""/> Here is the relevant section of my POM:  <spring.version>3.2.0.RELEASE</spring.version> <hornetq.client.version>2.3.0.Final</hornetq.client.version> ... <dependency> <groupId>org.springframework</groupId> <artifactId>spring-jms</artifactId> <version>${spring.version}</version> </dependency> <dependency> <groupId>org.jboss.as</groupId> <artifactId>jboss-as-ejb-client-bom</artifactId> <version>7.1.1.Final</version> <type>pom</type> </dependency> <dependency> <groupId>org.hornetq</groupId> <artifactId>hornetq-core-client</artifactId> <version>${hornetq.client.version}</version> </dependency> <dependency> <groupId>org.hornetq</groupId> <artifactId>hornetq-jms-client</artifactId> <version>${hornetq.client.version}</version> </dependency> <dependency> <groupId>org.jboss</groupId> <artifactId>jboss-ejb-client</artifactId> <version>1.0.5.Final</version> <scope>runtime</scope> </dependency> <dependency> <groupId>org.jboss.ejb3</groupId> <artifactId>jboss-ejb3-ext-api</artifactId> <version>2.0.0-beta-2</version> </dependency> <dependency> <groupId>org.jboss.netty</groupId> <artifactId>netty</artifactId> <version>3.2.9.Final</version> </dependency> <dependency> <groupId>org.hornetq</groupId> <artifactId>hornetq-core</artifactId> <version>2.0.0.GA</version> <scope>compile</scope> </dependency> <dependency> <groupId>org.hornetq</groupId> <artifactId>hornetq-jms</artifactId> <version>2.0.0.GA</version> <scope>compile</scope> </dependency> <dependency> <groupId>org.hornetq</groupId> <artifactId>hornetq-logging</artifactId> <version>2.0.0.GA</version> <scope>compile</scope> </dependency> <dependency> <groupId>org.hornetq</groupId> <artifactId>hornetq-transports</artifactId> <version>2.0.0.GA</version> <scope>compile</scope> </dependency> And the relevant section of my jboss standalone.xml:  <subsystem xmlns=""urn:jboss:domain:messaging:1.1""> <hornetq-server> <persistence-enabled>true</persistence-enabled> <journal-file-size>10240</journal-file-size> <journal-min-files>2</journal-min-files> <connectors> <netty-connector name=""netty"" socket-binding=""messaging""/> <netty-connector name=""netty-throughput"" socket-binding=""messaging-throughput""> <param key=""batch-delay"" value=""50""/> </netty-connector> <in-vm-connector name=""in-vm"" server-id=""0""/> </connectors> <acceptors> <netty-acceptor name=""netty"" socket-binding=""messaging""/> <netty-acceptor name=""netty-throughput"" socket-binding=""messaging-throughput""> <param key=""batch-delay"" value=""50""/> <param key=""direct-deliver"" value=""false""/> </netty-acceptor> <in-vm-acceptor name=""in-vm"" server-id=""0""/> </acceptors> <security-settings> <security-setting match=""#""> <permission type=""send"" roles=""guest""/> <permission type=""consume"" roles=""guest""/> <permission type=""createNonDurableQueue"" roles=""guest""/> <permission type=""deleteNonDurableQueue"" roles=""guest""/> </security-setting> </security-settings> <address-settings> <address-setting match=""#""> <dead-letter-address>jms.queue.DLQ</dead-letter-address> <expiry-address>jms.queue.ExpiryQueue</expiry-address> <redelivery-delay>0</redelivery-delay> <max-size-bytes>10485760</max-size-bytes> <address-full-policy>BLOCK</address-full-policy> <message-counter-history-day-limit>10</message-counter-history-day-limit> </address-setting> </address-settings> <jms-connection-factories> <connection-factory name=""InVmConnectionFactory""> <connectors> <connector-ref connector-name=""in-vm""/> </connectors> <entries> <entry name=""java:/ConnectionFactory""/> </entries> </connection-factory> <connection-factory name=""RemoteConnectionFactory""> <connectors> <connector-ref connector-name=""netty""/> </connectors> <entries> <entry name=""RemoteConnectionFactory""/> <entry name=""java:jboss/exported/jms/RemoteConnectionFactory""/> </entries> </connection-factory> <pooled-connection-factory name=""hornetq-ra""> <transaction mode=""xa""/> <connectors> <connector-ref connector-name=""in-vm""/> </connectors> <entries> <entry name=""java:/JmsXA""/> </entries> </pooled-connection-factory> </jms-connection-factories> <jms-destinations> <jms-queue name=""testQueue""> <entry name=""queue/test""/> <entry name=""java:/queue/test""/> <entry name=""java:jboss/exported/jms/queue/test""/> </jms-queue> <jms-queue name=""DemoQueue""> <entry name=""/queue/DemoQueue""/> </jms-queue> <jms-topic name=""testTopic""> <entry name=""topic/test""/> <entry name=""java:jboss/exported/jms/topic/test""/> </jms-topic> </jms-destinations> </hornetq-server> </subsystem> <subsystem xmlns=""urn:jboss:domain:weld:1.0""/> </profile> and the error I receive when I try to start it up through eclipse/vmware vFabric  org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.jms.listener.SimpleMessageListenerContainer#0' defined in ServletContext resource [/WEB-INF/spring/webmvc-config.xml]: Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: org.hornetq.utils.HornetQThreadFactory.<init>(Ljava/lang/String;Z)V at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1486) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:295) At least some dependencies in the pom.xml are flat out wrong. Look at the bottom for hornetq-logging hornetq-transports hornetq-jms etc. These do not exist anymore in the 2.3.X releases and should be removed. As a rule if you have any JAR from the main HornetQ project it should use the same version. Remove all those jars using 2.0.0.GA. Some of those were renamed in either case you should try to only have org.hornetq JARs using the same version. In the case of your pom that would be 2.3.0-Final. BTW the latest version is 2.3.2-Final and you should upgrade to that IMHO. IIRC hornetq-jms was broken into hornetq-jms-server or hornetq-jms-client. You probably want hornetq-jms-client. Core was also broken into hornetq-core-client and hornetq-server. Search for JARs available with version number 2.3.2.Final here https://repository.jboss.org/nexus/index.html#nexus-search;quick~org.hornetq (do some more advanced search)."
101,A,"Netty 4.0 HTTP Chunks memory leaks? I'm trying to make HTTP Transfer Encoding Chunked work with Netty 4.0. I had success with it so far. It works well with small payloads. Then I tried with large data it started to hang. I suspect there might be a problem with my code or maybe a leak with ByteBuf.copy(). I stripped down my code to the bare minimum to be sure that I had no other source of leak or side effect and I've ended down to write this test. The complete code is here. Basically it sends 1GB of 0x0 when you connect with wget to port 8888. I reproduce the problem when I connect with wget http://127.0.0.1:8888 -O /dev/null Here's the handler :  protected void channelRead0(ChannelHandlerContext ctx FullHttpMessage msg) throws Exception { DefaultHttpResponse response = new DefaultHttpResponse(HTTP_1_1 OK); HttpHeaders.setTransferEncodingChunked(response); response.headers().set(CONTENT_TYPE ""application/octet-stream""); ctx.write(response); ByteBuf buf = Unpooled.buffer(); int GIGABYTE = (4 * 1024 * 1024); // multiply 256B = 1GB for (int i = 0; i < GIGABYTE; i++) { buf.writeBytes(CONTENT_256BYTES_ZEROED); ctx.writeAndFlush(new DefaultHttpContent(buf.copy())); buf.clear(); } ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT).addListener(ChannelFutureListener.CLOSE); } Is there anything wrong with my approach? EDIT : With VisualVM I've found that there is a memory leak in the ChannelOutboundBuffer. The Entry[] buffer keeps growing addCapacity() is called multiple times. The Entry array seems to contains copies of the buffers that are (or should) be written to the wire. I see with wireshark data coming in... Here's a Dropbox link to the heapdump It's with 4.0.8 Final which version ? I have found what I was doing wrong. The for loop that writeAndFlush() was not working well and is likely to be cause of the leak. I tried various things (see many revisions in the gist link). See the gist version at the time of writing. I have found out that the best way to achieve what I wanted to do without memory leaks was to extends InputStream and write to the context (not using writeAndFlush()) the InputStream wrapped in an io.netty.handler.stream.ChunkedStream.  DefaultHttpResponse response = new DefaultHttpResponse(HTTP_1_1 OK); HttpHeaders.setTransferEncodingChunked(response); response.headers().set(CONTENT_TYPE ""application/octet-stream""); ctx.write(response); InputStream is = new InputStream() { int offset = -1; byte[] buffer = null; @Override public int read() throws IOException { if (offset == -1 || (buffer != null && offset == buffer.length)) { fillBuffer(); } if (buffer == null || offset == -1) { return -1; } while (offset < buffer.length) { int b = buffer[offset]; offset++; return b; } return -1; } // this method simulates an application that would write to // the buffer. // ONE GB (max size for the test; int sz = 1024 * 1024 * 1024; private void fillBuffer() { offset = 0; if (sz <= 0) { // LIMIT TO ONE GB buffer = null; return; } buffer = new byte[1024]; System.arraycopy(CONTENT_1KB_ZEROED 0 buffer 0 CONTENT_1KB_ZEROED.length); sz -= 1024; } }; ctx.write(new ChunkedStream(new BufferedInputStream(is) 8192)); ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT).addListener(ChannelFutureListener.CLOSE); The code is writing 1GB of data to the client in 8K chunks. I was able to run 30 simultaneous connection without memory or hanging problems."
102,A,Netty 4 leak exception at HttpObjectAggregator I'm getting an exception on my netty server while it's under heavy load. (Testing with LOIC etc...) I want to know that I do something wrong or it's a bug in the HttpObjectAggregator. WARNING: LEAK: ByteBuf was GC'd before being released correctly. The following stack trace shows where the leaked object was created rather than where you failed to release it. io.netty.util.ResourceLeakException: io.netty.buffer.CompositeByteBuf@1c0eeb6 at io.netty.util.ResourceLeakDetector$DefaultResourceLeak.<init>(ResourceLeakDetector.java:174) at io.netty.util.ResourceLeakDetector.open(ResourceLeakDetector.java:116) at io.netty.buffer.CompositeByteBuf.<init>(CompositeByteBuf.java:60) at io.netty.buffer.Unpooled.compositeBuffer(Unpooled.java:353) at io.netty.handler.codec.http.HttpObjectAggregator.decode(HttpObjectAggregator.java:138) at io.netty.handler.codec.http.HttpObjectAggregator.decode(HttpObjectAggregator.java:50) at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:89) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:334) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:320) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:173) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:334) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:320) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:100) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:497) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:465) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:359) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101) at java.lang.Thread.run(Thread.java:722) Most likely you forgot to release the message after handling it. Did you call release() on it ? Well thanks for the answer I have some questations. I have fixed it by calling release in the next handler but I'm not 100% sure that I did it correctly. When should I call the release method? After finished all read/handling operations on it? I'm using a FullHttpRequest and releasing it after validation and I can work on it without any problems even after releasing thats ok or I should release it after all handling? Release after all handling
103,A,"Netty 4 Outbound Message Handler Closing Connection I'm experimenting with a custom outbound message handler in Netty 4 and cannot seem to get it to work. The handler just logs a statement and is added toward the bottom of the channel pipeline. My understanding is that these handlers are invoked from the bottom up in order once a write operation is issued. The idea with the custom handler was that it would be executed prior to any other outbound message handlers. Unfortunately when I add this logging handler to the pipeline I see the log statement but then Netty seems to immediately close the connection. Here's my channel initializer and outbound handler code. HttpOutboundHandler.java public class HttpOutboundHandler extends ChannelOutboundMessageHandlerAdapter<DefaultFullHttpResponse> { private static final Logger logger = LoggerFactory.getLogger(HttpOutboundHandler.class); @Override public void flush(ChannelHandlerContext context DefaultFullHttpResponse response) throws Exception { logger.debug(""Executing outbound handler.""); } } HttpChannelInitializer.java @Override protected void initChannel(SocketChannel socketChannel) throws Exception { pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""aggregator"" new HttpObjectAggregator(1048576); pipeline.addLast(""compressor"" new HttpContentCompressor(gzipLevel)); pipeline.addLast(""outboundHandler"" outboundHandler); pipeline.addLast(eventExecutorGroup ""inboundHandler"" inboundHandler); } Finally here's the logger output. [DEBUG] (Slf4JLogger:71) - [id: 0xbddf00cf /0:0:0:0:0:0:0:1:57402 => /0:0:0:0:0:0:0:1:8080] ACTIVE [DEBUG] (HttpOutboundHandler:19) - Executing outbound handler. [DEBUG] (Slf4JLogger:71) - [id: 0x942993c1 /0:0:0:0:0:0:0:1:57403 :> /0:0:0:0:0:0:0:1:8080] INACTIVE Answering my own question in case anyone else finds this. It turns out I needed to add the message to the next outbound message buffer (which I believe has the effect of passing it to the next handler in the chain). I also needed to retain the message. The updated code now looks like... public class HttpOutboundHandler extends ChannelOutboundMessageHandlerAdapter<DefaultFullHttpResponse> { private static final Logger logger = LoggerFactory.getLogger(HttpOutboundHandler.class); @Override public void flush(ChannelHandlerContext context DefaultFullHttpResponse response) throws Exception { logger.debug(""Executing outbound handler.""); ChannelHandlerUtil.addToNextOutboundBuffer(context response.retain()); } }"
104,A,In Netty 4 do I need to set option -XX:MaxDirectMemorySize? Netty 4 can use direct memory. I think I should/must set option -XX:MaxDirectMemorySize when starting Java process that uses Netty. I think that in most cases you won't need to set the direct memory size. If you get to a point were you run out of direct memory you should first see if you are using the direct memory correctly before setting it manually. Check that you are not creating to many io workers and by that Creating to many direct buffers instead reusing io workers.  You don't need too.. But it will give the JVM a hint how much direct memory is allowed to be allocated. If that option is not set Netty can only use up to 64 MB of direct memory? You can get the maximum available direct memory via `PlatformDependent.maxDirectMemory()`  It really depends on how much direct memory your application is going to use. By default the maximum available size of direct memory of JVM is same with the maximum heap size although it differs between JVM vendors and versions. io.netty.util.internal.PlatformDependent.maxDirectMemory() returns the maximum direct memory size in bytes so you might want to use it for debugging purposes. Actually Netty logs that value if you set the log level of io.netty.util.internal.PlatformDependent to DEBUG.
105,A,"Netty Guice Integration I know that Netty had a Guice Integration a while ago (see https://issues.jboss.org/browse/NETTY-69) somehow this Guice Integration is missing for 3.5.3. What was the reason to remove the integration? Has anyone ever done a manual Guice Integration with Netty and can point out some of the gotchas? Ok I found an example how to do this: https://gist.github.com/1653087 Basically the Entry point of the application extends from com.google.common.util.concurrent.AbstractIdleService and the Pipeline is built with Providers. All the other things are pretty straightforward ""standard Guice"" things."
106,A,Limit number of connections per IP on Netty I've been searching for a while a way to limit the connections per IP on Netty using its IPFilter class. However there is no JavaDoc explanation to do that kind of limitations. The only way i've found is using the 'ConnectionPerIPLimitUpStreamHandler' released on jboss two years ago but Norman Maurer said that it was no longer needed cuz this feature has been added to the IPFilter class. So in resume I need an explanation on how we could limit connections per IP address on Netty using its IPFilter class. Looks to me like you can take the source to OneIpFilterHandler and 1) change the concurrent map so the values are Integer to hold the count. 2) change the place where it checks the IP of a new connection to allow if the count is below the threshhold. 3) change that same place to increment the count when you allow 4) change the place where it releases an IP address to reduce the count and remove the map entry if its zero. Think about concurrent issues through all this. I know this is vague. But its an idea. It might help you. Yes i've thought adding my own filter to the pipeline would be the only way to do that however i'm looking for a 'precompiled-in-netty' way and i've readed a comment of Norman Maurer which said it was included on the IPFilter class. I hope he can get onto this question and resolve it.
107,A,How to send content using Netty Http Client? I'm using Netty Http client to send requests to a http server. I am re-using the channel and keeping the connection live to reuse it between requests. My problem is that although the get method works perfectly I can' manage to send content in put or post. Following is the code I am using but in my server the http request input stream is empty. Any ideas? HttpRequest request = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.valueOf(method) uri.toASCIIString()); if (payLoad != null) { request.setContent(ChannelBuffers.wrappedBuffer(payLoad)); } Note: payload is a bytearray. Thanks Yair Since your GET requests work fine I assume that you write it to channel correctly. Therefore I would focus on http post: From http request point of view you have to specify few more headers in your request. At the very least have a look at Host Connection Accept-Encoding Content-Type and Content-Length. my bet is on content-length either that or transport-encoding must be specified as chunked
108,A,"How to build a FTP server with Netty? I have built a server application with netty that now needs to act as a ftp server as well. Basically I just need to support authentication/login and file upload via ftp. Unfortunately there seems to be no pure java implementation of ftp so I could simply write my own decoder/encoder/handler set. Apache MINA provides a complete ftp server but how could I do it simple and easy with netty? I already integrated jetty for web service support but I can't find ftp support for jetty neither. It would be marvelous to get some hints. I think I checked out all google hits on ""java ftp"" but they just seem to provide ftp client stuff. Best regards Martin I wrote netty handler for receiving files over FTP - netty-ftp-receiver. It's small and straightforward and may be used as a starting point. I've ported the code to Netty 4.0 see my [fork](https://github.com/codingtony/netty-ftp-receiver). I will try to add features to this code base as well.  If it's Netty you're interested in I found an open source FTP server based on it: http://waarp.github.com/WaarpFtp/ Maybe you could reuse some parts of the project? I guess this source file might be the most interesting to you: https://github.com/waarp/WaarpFtp/blob/master/src/main/java/org/waarp/ftp/core/control/NetworkHandler.java As there seems to be no further input on existing ""pure"" implementations of ftp I will mark your answer as final one. Cheers! Thank you I think i can learn from that."
109,A,Can someone explain the ProtobufVarint32FrameDecoder code I am trying to write my own Protobuf frame decoder and I'm basing it off: https://github.com/netty/netty/blob/master/codec/src/main/java/io/netty/handler/codec/protobuf/ProtobufVarint32FrameDecoder.java I'm just wondering why it creates the new byte[5]; Doesn't it just need to read the first byte to get the length. Why does it need the for loop? Because the length is represented as variable length field as described in here.
110,A,Netty 3 HTTPS client hangs forever I have a Netty 3 client over HTTPS. I can't puzzle out why it's not working and just hangs until timeout. It works perfectly fine over HTTP (remove the SSL handler from the pipeline and change port from 443 to 80). Here's a gist (in scala): https://gist.github.com/4396611 What am I doing wrong? I've tested with Netty from 3.5.9 to 3.6.0. My JDK is 1.6.0_37 on OS X. Regards Stéphane You missed to issue the handshake once the channel is connected. The easiest way is to use setIssueHandshake on the SslHandler before add it to the pipeline. http://static.netty.io/3.6/api/org/jboss/netty/handler/ssl/SslHandler.html#setIssueHandshake(boolean) The second method from the javadoc (doing the handshake explicitly after connecting and writing in a listener on the handshake future) actually work thanks! I'll go this way but I'm still puzzled about why the first method didn't work. Here is the working gist: https://gist.github.com/4398272 I added setIssueHandshake(true) but it still doesn't work. I updated the gist.
111,A,"What effect does using Action.async have since Play uses Netty which is non-blocking Since Netty is a non-blocking server what effect does changing an action to using .async? def index = Action { ... } versus def index = Action.async { ... } I understand that with .async you will get a Future[SimpleResult]. But since Netty is non-blocking will Play do something similar under the covers anyway? What effect will this have on throughput/scalability? Is this a hard question to answer where it depends on other factors? The reason I am asking is I have my own custom Action and I wanted to reset the cookie timeout for every page request so I am doing this which is a async call: object MyAction extends ActionBuilder[abc123] { def invokeBlock[A](request: Request[A] block: (abc123[A]) => Future[SimpleResult]) = { ... val result: Future[SimpleResult] = block(new abc123(... result)) result.map(_.withCookies(...)) } } The take away from the above snippet is I am using a Future[SimpleResult] is this similar to calling Action.async but this is inside of my Action itself? I want to understand what effect this will have on my application design. It seems like just for the ability to set my cookie on a per request basis I have changed from blocking to non-blocking. But I am confused since Netty is non-blocking maybe I haven't really changed anything in reality as it was already async? Or have I simply created another async call embedded in another one? Hoping someone can clarify this with some details and how or what effect this will have in performance/throughput. def index = Action { ... } is non-blocking you are right. The purpose of Action.async is simply to make it easier to work with Futures in your actions. For example: def index = Action.async { val allOptionsFuture: Future[List[UserOption]] = optionService.findAll() allOptionFuture map { options => Ok(views.html.main(options)) } } Here my service returns a Future and to avoid dealing with extracting the result I just map it to a Future[SimpleResult] and Action.async takes care of the rest. If my service was returning List[UserOption] directly I could just use Action.apply but under the hood it would still be non-blocking. If you look at Action source code you can even see that apply eventually calls async: https://github.com/playframework/playframework/blob/2.3.x/framework/src/play/src/main/scala/play/api/mvc/Action.scala#L432 Thanks I read that earlier. So having a future that calls a future etc. doesn't really effect performance per say? i see so in my ""MyAction"" what is the net effect of using me using a future and callinf result.map? And what if i do Myaction.async in my controller? (compared to using the default Action) Well I thought I answered your question. You should have a look at this page of the documentation: http://www.playframework.com/documentation/2.3.x/ScalaAsync"
112,A,"Is it possible that the messages client received is out of order as the netty server write  for (int i = 1; i <= 100; i++) { ctx.writeAndFlush(Unpooled.copiedBuffer(Integer.toString(i).getBytes(Charsets.US_ASCII))); } ctx.writeAndFlush(Unpooled.copiedBuffer(""ABCD"".getBytes(Charsets.US_ASCII))).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { ctx.channel().close(); } }); I write this in the channelRead() mehtod of my netty server handler it will reponse ""12345...100ABCD"" back to the client as soon as the server receive a request. As far as I see the order of the message client received from the netty server is always ""12345...100ABCD"". I don't know is this just by chance? Maybe sometime it would be ""32451...ABCD100"" (out of the server write order)? Is it possible that the server execute clientChannel.writeAndFlush(msg1); clientChannel.writeAndFlush(msg2); clientChannel.writeAndFlush(msg3); but the client received msg2-msg1-msg3 or msg3-msg1-msg2 but not the write order msg1-msg2-msg3 In the proxy sample of netty project https://github.com/netty/netty/tree/master/example/src/main/java/io/netty/example/proxy the HexDumpProxyBackendHandler writes: @Override public void channelRead(final ChannelHandlerContext ctx Object msg) throws Exception { inboundChannel.writeAndFlush(msg).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) { ctx.channel().read(); } else { future.channel().close(); } } }); } It makes sure that it trigger next channelRead() (That is inboundChannel.writeAndFlush(msg) in channelRead()) only if the wirteAndFlush() operation is finished. So what's the purpose to write ctx.channel().read() in the listener and execute it when future.isSuccess() ? Isn't it to make sure that the messages writes to the client are received in a right order? If I change it to @Override public void channelRead(final ChannelHandlerContext ctx Object msg) throws Exception { inboundChannel.writeAndFlush(msg); ctx.channel().read(); } Will it cause some issues? No it is not possible. TCP ensures that. Hi EJP. So why the proxy example in netty project wirte that way? Please have a look at what I added in the question. :D I have no idea why that sample code does a reads on write success but it certainly has nothing to do with ensuring correct sequencing. I don't understand why you think it could possibly do anything of the kind. I don't see why. The channel should be read when there is data to be read. None of this has anything to do with correct sequencing. Your thought processes elude me. It does a read on write success to trigger next channelRead() event. And I think it makes sure that it trigger next channelRead() (That is inboundChannel.writeAndFlush(msg) in channelRead()) only if the wirteAndFlush() operation is finished. So I think things of the kind is possible to heppen if I change the code to what I pasted. Original link: https://github.com/netty/netty/tree/master/example/src/main/java/io/netty/example/proxy Allright since it has no problem so far it remains to be seen. Maybe I should check the netty source code about channel.writeAndFlush() method more carefully. Thanks for your tips EJP :D  As EJP states either technique should guarantee the ordering. The difference between the example and how you've changed it is a question of flow control. In the original example the inbound channel will only be read after the data has been successfully flushed to the network buffers. This guarantees that it only reads data as fast as it can send it preventing Netty's send queue from building up and thus preventing out of memory errors. The altered code reads as soon as the write operation is queued. If the outbound channel is unable to keep up there's a chance you could see out of memory errors if you're transferring a lot of data. :D thx for your explaination now I'm clear about it"
113,A,How to limit in netty length of websocket frame received by server I am implementing a WebSocket service using netty 3.4. I need to limit the frame size to avoid DoS attacks with very very long frames. I want the connection to be dropped after 32KB of data even if the frame was not finished yet and it was not passed to my Handler. Is there any way to do that? Given the code as it stands at the moment doesn't look like it at the moment. You will have to extend WebSocket08FrameDecoder and change the code in toFrameLength(). If I get a chance I'll put in a pull request for the next release. thank you for pointing that code. But it seems that better solution is to embed the test right after the line framePayloadBytesRead += rbytes; in decode() and test if framePayloadBytesRead is not larger than limit. That would prevent from accumulating data in the memory right after the TCP packet was read. Done. Refer to Issue #283. Thanks Edekzkrainykredek you are spot on.
114,A,"Netty How to send an object How to send an object using netty. When i try to send a String object everything is ok. channel.writeAndFlush(new String(""df"")); But when i try to send an simple object server get errors public class Message implements Serializable { private static final long serialVersionUID = 1L; } channel.writeAndFlush(new Message()); io.netty.channel.DefaultChannelPipeline$TailHandler exceptionCaught WARNING: An exceptionCaught() event was fired and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. io.netty.handler.codec.DecoderException: java.lang.NullPointerException at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:259) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:141) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:340) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:326) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:116) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:494) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:461) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:378) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:350) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101) at java.lang.Thread.run(Thread.java:744) Caused by: java.lang.NullPointerException at io.netty.handler.codec.serialization.CompactObjectInputStream.readClassDescriptor(CompactObjectInputStream.java:55) at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1601) at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370) at io.netty.handler.codec.serialization.ObjectDecoder.decode(ObjectDecoder.java:73) at io.netty.handler.codec.LengthFieldBasedFrameDecoder.decode(LengthFieldBasedFrameDecoder.java:343) at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:228) ... 11 more class ChatServerInitializer extends ChannelInitializer<SocketChannel> { @Override protected void initChannel(SocketChannel arg0) throws Exception { ChannelPipeline pipeline = arg0.pipeline(); pipeline.addLast(""decoder"" (new ObjectDecoder(null))); pipeline.addLast(""encoder"" new ObjectEncoder()); pipeline.addLast(""handler"" new ChatServerHandler()); } } it is not right: new ObjectDecoder(null) Try to do like this:  serverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { socketChannel.pipeline().addLast( new ObjectDecoder(ClassResolvers.softCachingResolver(ClassLoader.getSystemClassLoader())) new ObjectEncoder() new Handler()); } });  You specified null when you construct a ObjectDecoder and that's causing a NullPointerException here. Instead you have to specify something like ClassResolvers.weakCachingResolver(MyMessage.class.getClassLoader())."
115,A,"Any difference between ctx.write() and ctx.channel().write() in netty? I noticed that the ctx is different from handler to handler even these handlers are in the same pipeline for example  p.addLast(""myHandler1"" new MyHandler1()); p.addLast(""myHandler2"" new MyHandler2()); in MyHander1 @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { System.err.println(""My 1 ctx: "" + ctx + "" channel: "" + ctx.channel()); super.channelRead(ctx msg); } in MyHandler2 @Override protected void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { System.err.println(""My 2 ctx: "" + ctx + "" channel: "" + ctx.channel()); } and the output: My 1 ctx: io.netty.channel.DefaultChannelHandlerContext@ba9340 channel: [id: 0xdfad3a16 /127.0.0.1:60887 => /127.0.0.1:8090] My 2 ctx: io.netty.channel.DefaultChannelHandlerContext@1551d7f channel: [id: 0xdfad3a16 /127.0.0.1:60887 => /127.0.0.1:8090] I noticed that the ctx is different but the channel is the same one So it there any difference between invoke ctx.write() and ctx.channel().write() ? Yes there is... Channel.write(..) always start from the tail of the ChannelPipeline and so pass through all the ChannelOutboundHandlers. ChannelHandlerContext.write(...) starts from the current position of the ChannelHandler which is bound to the ChannelHandlerContext and so only pass those ChannelOutboundHandlers that are in front of it. Thanks Norman I got it!"
116,A,"Netty compile error I can't compile netty anymore. mvn compile gives the following: [INFO] --- maven-compiler-plugin:2.3.2:compile (default-compile) @ netty-common --- [INFO] Compiling 60 source files to /home/dennis/git/netty4/common/target/classes [INFO] ------------------------------------------------------------- [ERROR] COMPILATION ERROR : [INFO] ------------------------------------------------------------- [ERROR] Unable to locate the Javac Compiler in: /opt/java/jre1.6.0_30/../lib/tools.jar Please ensure you are using JDK 1.4 or above and not a JRE (the com.sun.tools.javac.Main class is required). In most cases you can change the location of your Java installation by setting the JAVA_HOME environment variable. [INFO] 1 error My configuration: export JAVA_HOME=/opt/java/jre1.6.0_30 export M2_HOME=/opt/apache-maven-3.0.3 export M2=$M2_HOME/bin export PATH=$JAVA_HOME/bin:$PATH export PATH=$M2:$PATH A part of my path: $echo $PATH /opt/java/jre1.6.0_30/bin:/opt/apache-maven-3.0.3/bin:/opt/git/bin:[...] Maven status: dennis@denpc:~/git/netty4$ mvn --version Apache Maven 3.0.3 (r1075438; 2011-02-28 18:31:09+0100) Maven home: /opt/apache-maven-3.0.3 Java version: 1.6.0_30 vendor: Sun Microsystems Inc. Java home: /opt/java/jre1.6.0_30 Default locale: de_DE platform encoding: UTF-8 OS name: ""linux"" version: ""2.6.24-30-generic"" arch: ""i386"" family: ""unix"" Any ideas? Please ensure you are using JDK 1.4 or above and not a JRE [...] It might have to do with this line in the error given in your post above. I believe you might want to make sure that you have the path to your JDK set as well. Otherwise it's just finding the JRE (jre1.6.0_30). Note: The JDK might be found in your Java SDK folder. I was sure that I just installed the `JDK`...but it was the `JRE`. It is compiling now Thanks. Glad it's working for you!"
117,A,Websocket connection in case of browser crash Pardon me if the question is simple  but I don't know what will happen in this general scenario : If due to some issue or failure / system failure (any kind of failure  etc) the browser crashes  what will happen to a websocket connection that was running ? Will it be closed or what will be its state ? I am using netty websocket implementation. Now  specifically in netty websocket implementation  in the above scenario  what would happen ? (When I tried  I get this : if I close the browser manually  the connection is closed but if I kill the browser process  this does not happen). If the connection is not closed  how can I detect it / handle it while sending messages  otherwise while sending messages  a ClosedChannelException occurs when trying to send a message. EDIT : Apart from checking for the above mentioned error  is there a way of knowing that the websocket connection has been closed when using the netty implementation ? I think you'll have to catch ClosedChannelException and handle that in the same way you would for a connection that was cleanly closed. If your websocket sessions are expensive and you want to spot killed connections more quickly you could periodically send a ping request to each client. Netty has a PingWebSocketFrame class which looks like it'd support this for you. The first alternative seems fine  but the second option hmm... I am using websockets so that I won's have to unnecessarily ping periodically (also an advantage of websockets) and the reason for trying to spot killed connections is due to the fact that the exception is thrown up. @shg Periodic pings are not necessary. I only included them as an option in case you were unable to wait for a ClosedChannelException to spot a killed connection.
118,A,"YourKit showing 16 MB byte[] being allocated when WebSocket client connects to WebSocket server I'm using the Netty beta 2 websocket functionality in a java 7 se embedded app where I'm trying to make the footprint as small as possible. I'm running with -Xms8m and -Xmx32m. When I profile the app in YourKit as soon as the client establishes the websocket channel with the server the fundamental byte[] type size jumps from 2 MB to 16 MB. NOTE: this is after the handshake but before any websocket message is sent Has anyone else seen this and do you know what is doing this allocation? Thanks I think this happens because of our pooled ByteBufAllocator that is used in Netty 4 by default. It will allocate big chunks of byte put it in the pool and use only ""slices"" of it when request smaller sizes. This helps with memory layout on the heap etc. If you want to have low-memory usage (and loose some performance) use the unpooled ByteBufAllocator. For clients: bootstrap.option(ChannelOption.ALLOCATOR UnpooledByteBufAllocator.DEFAULT); For Servers: bootstrap.childOption(ChannelOption.ALLOCATOR UnpooledByteBufAllocator.DEFAULT); In general we want to use all the max-performance/throughput options but in this case memory footprint is definitely a consideration. Thanks for the tip Norman."
119,A,Server Bootstrap releaseExternalResources stuck in loop My issue seems to be related to: https://issues.jboss.org/browse/NETTY-433 I'm trying to stop my Netty server but this call never returns: serverBootstrap.releaseExternalResources(); It's looping forever in the ExecutorUtil.terminate method when trying to shutdown the worker ThreadPoolExecutor: org.jboss.netty.util.internal.ExecutorUtil.terminate() for (;;) { es.shutdownNow(); es.awaitTermination.. } The problem is I don't have any control over the Client connecting to my Server. Is there a way for the server to force the server to stop and simple close the channel and stop worker threads? Yes stopping it normally. Believe it is because a Client still has a channel open to my server so I cannot release resources? Any way around this? You sure you're not trying to stop the server using a worker thread ? The key part I personally missed according to the Netty API is:  public class MyHandler extends SimpleChannelUpstreamHandler { @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) { // Add all open channels to the global group so that they are // closed on shutdown. allChannels.add(e.getChannel()); } } In other words you also have to override a method in your handler.  What you can do to ensure that your child channels are closed before you do a releaseAllResources is to register all created child channels in a ChannelGroup. When you shutdown you can call close() on the ChannelGroup and this will close all the channels in it.
120,A,"Netty HTTPRequest doesn't captured posted JSOn I am attempting to build a REST service using Netty on the backend. I need to be able to post raw JSON to the service outside of any key/value parameters. Content-type=applicaiton/json not form multi-part. I am able to get the initial part of the service to receive the request but when I cast the MessageEvent content to HTTPRequest it no longer has any posed data associated with it. That leaves me with no ability to get the JSON data back. In order to access the posted JSON do I need to use a different process for extracting the data from the MessageEvent? Here is the snippet in question.  @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { System.out.println(""The message was received""); HttpRequest request = (HttpRequest) e.getMessage(); if (request.getMethod() != POST) { sendError(ctx METHOD_NOT_ALLOWED); return; } // Validate that we have the correct URI and if so then parse the incoming data. final String path = sanitizeUri(request.getUri()); decoder = new HttpPostRequestDecoder(request); System.out.println(""We have the decoder for the request""); List<InterfaceHttpData> datas = decoder.getBodyHttpDatas(); for (InterfaceHttpData data : datas){ System.out.println(data.toString()); } What am I missing that it causing this? Do I need to use the ChunkedWrite portion? I am a noob to Netty so forgive me if this is basic. I found lots of other questions about posting raw JSON to other URL's from inside Netty but nothing about receiving it. I've only used HttpPostRequestDecoder to read application/x-www-form-urlencoded or mime data. Try just reading the data directly form the request as per the snoop example. ChannelBuffer content = request.getContent(); if (content.readable()) { String json = content.toString(CharsetUtil.UTF_8); }"
121,A,how to stream a response over HTTP with netty I'm using Netty 3.6.6 and I'd like to send a large response back to the caller. I can't copy the response body into a ChannelBuffer as in some cases it will be very large. I'm migrating a server from CXF to Netty previously I could just use the OutputStream provided by CXF to write the data. I originally tried to just send the response without content and then continued to write data to the Channel in a series of 8k buffers. This failed as the client seemed to get the original response and see no data and complain. I tried setting the response as chunked but this didnt seem to make a difference nor did setting the chunked header the client always saw an empty stream. I saw the file server example for 3.6.6 and that's similar to what I want to do except the data will not be a file. I saw the ChunkedStream & NioStream which seemed close to what I need except they take InputStream/ReadableByteChannel whereas I have an OutputStream; I could try using the PipedInput & OutputStreams but that seems like it would introduce an unfortunate bottleneck. I'm sure there's a way to stream a lot of data back to the client in response to a request but I'm just not seeing how to do it unless I have a file. I am also curious how you let the client know the response is complete if the connection is keep-alive and you're streaming content but don't know the content length. Seems like the client would wait forever for the connection to close in those cases. Modifying the static file server example from 3.6.6 to remove the content-length header (just comment it out) specify that its a chunked response  response.setChunked(true); response.setHeader(Names.TRANSFER_ENCODING Values.CHUNKED); and then using ChunkedNioStream to send the file after writing the response:  // Write the initial line and the header. ch.write(response); final ReadableByteChannel aIn = java.nio.channels.Channels.newChannel(new FileInputStream(file)); ChannelFuture writeFuture = ch.write(new ChunkedNioStream(aIn)); Yields the undesired behavior the client gets a couple hundred bytes and then stop receiving basically what I'm seeing in my application. The correct thing only seems to happen with a content-length which is not feasible in my use case. When you attempt to write a ChunkedNioStream to ChunkedWriteHandler it merely produces a stream which contains the content of the ChunkedNioStream only. That is it produces ChannelBuffers rather than HttpChunks. Because HttpMessageEncoder handles only HttpMessage and HttpChunk ChannelBuffer produced by ChunkedNioStream is bypassed to the wire without HTTP chunk header prepended causing your browser confused. To fix this problem you have to implement your own ChunkedInput which produces HttpChunks instead of ChannelBuffers. However I must agree that this might be a challenging task so you might just want to fork HttpMessageEncoder so that it also understands ChannelBuffer and treats it just like HttpChunk. Please take a look at this part of HttpMessageEncoder for more information.
122,A,Single thread per channel netty OIO Related question: Single thread per channel model with netty OIO I've written an OIO client-server using netty where I send a number of messages from server to client (and vice--versa) after the connection is up. As far as I can tell it looks like writes to channel block reads from channel. Is that normal behaviour for netty? Yes. Netty's OIO transport performs read and write in the same thread. Therefore while you write the read for the channel which is being written is blocked.
123,A,"Netty SSL and websockets I want to configure SSL for one way websocket basically server pushes information to the webpage and i need this secured. I have set up the pipeline as follows: ChannelPipeline pipeline = Channels.pipeline(); SSLEngine engine = serverSslContext.getServerContext().createSSLEngine(); engine.setUseClientMode(false); pipeline.addLast(""ssl"" new SslHandler(engine)); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""aggregator"" new HttpChunkAggregator(65536)); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""handler"" webSocketHandler); my handler: public class WebSocketHandler extends SimpleChannelUpstreamHandler { public void messageReceived(ChannelHandlerContext ctx MessageEvent event) throws Exception {.... } public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception {.... } } my sslserverContext class:  try { // Key store (Server side certificate) String algorithm = Security.getProperty(""ssl.KeyManagerFactory.algorithm""); if (algorithm == null) { algorithm = ""SunX509""; } try { KeyStore ks = KeyStore.getInstance(""JKS""); FileInputStream fin = new FileInputStream(keyStoreFilePath); ks.load(fin keyStoreFilePassword.toCharArray()); // Set up key manager factory to use our key store // Assume key password is the same as the key store file // password KeyManagerFactory kmf = KeyManagerFactory.getInstance(algorithm); kmf.init(ks keyStoreFilePassword.toCharArray()); // Initialise the SSLContext to work with our key managers. serverContext = SSLContext.getInstance(PROTOCOL); serverContext.init(kmf.getKeyManagers() null null); } catch (Exception e) { throw new Error(""Failed to initialize the server-side SSLContext"" e); } } catch (Exception ex) { if (LOGGER.isErrorEnabled()) { LOGGER.error(""Error initializing SslContextManager. "" + ex.getMessage() ex); } //System.exit(1); } my javascript page :  var location = ws://localhost:8989/websocket; ws = new WebSocket(location); ws.onopen = function(event) { alert(""open""); } ws.onclose = function(event) { alert(""closed""); } Every time i try to connect with ssl configured it calls ""channelDisconnected"" but never goes any further the method ""messageRecieved"" is never called. However if i remove the ssl handler fromt he pipeline everything works fine i have tried to follow the example : https://github.com/netty/netty/blob/3/src/main/java/org/jboss/netty/example/http/websocketx Anyone got any ideas? The exception im getting is the following: org.jboss.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 474554202f70697420485454502f312e310d0a557067726164653a20776562736f636b65740d0a436f6e6e656374696f6e3a20557067726164650d0a486f73743a206c6f63616c686f73743a383538350d0a4f726967696e3a20687474703a2f2f6c6f63616c686f73743a383038300d0a507261676d613a206e6f2d63616368650d0a43616368652d436f6e74726f6c3a206e6f2d63616368650d0a5365632d576562536f636b65742d4b65793a204c7538506d6541477237474b35794c4431655a6679513d3d0d0a5365632d576562536f636b65742d56657273696f6e3a2031330d0a5365632d576562536f636b65742d457874656e73696f6e733a20782d7765626b69742d6465666c6174652d6672616d650d0a557365722d4167656e743a204d6f7a696c6c612f352e30202857696e646f7773204e5420362e313b20574f57363429204170706c655765624b69742f3533372e333620284b48544d4c2c206c696b65204765636b6f29204368726f6d652f32372e302e313435332e313136205361666172692f3533372e33360d0a436f6f6b69653a204a53455353494f4e494453534f3d38394439323935323630334642333832464246434330393933373436343043420d0a0d0a I figured out the exception the error was due to client code not calling with wss. But connection still closes during the handshaking.. my handler is never called... You need to call handshake() explicit Use wss://localhost:8989/websocket instead of ws://localhost:8989/websocket. Because you are using SSL which works with wss protocol secured protocol. If you only want to work with ws protocol you need to remove the SSLHandler from the pipeline."
124,A,Dynamic domains and subdomains using Play 2.0 Framework I am using Play 2.0 framework which I know use the Netty HTTP server by default. How can you set virtual host so that www.domain1.com redirect to www.maindomain.com/sites/domain1.com/? Since Play 2.0 the routing is much more restreint and nobody seems to answer this question anywhere. In Play 1.0 it was possible to do it inside the route file but now it is impossible :( I am also using the jar production files (with dist) just to be clear and I know Netty is there but I have no clue how to add virtual host. It seems like I've found the answer of my own question. Having a lot of PHP background and no Web application background I wasn't understanding correctly the principle of front-end and back-end with Play 2.0. What I need to do is keep Play running on 9000 and have a front-end Apache server (a different one!). Then virtual hosts are as easy as before. I don't need to touch to the Netty HTTP server. <VirtualHost *:80> ProxyPreserveHost On ServerName www.domain1.com ProxyPass /excluded ! ProxyPass / http://127.0.0.1:9000/sites/domain1.com/ ProxyPassReverse / http://127.0.0.1:9000/sites/domain1.com/ </VirtualHost> You can get more infos at http://www.playframework.org/documentation/2.0.4/HTTPServer
125,A,"Using Netty 4 how do I write a handler that can inject messages on a periodic basis and still pass messages through? I am trying to write a class that injects a message into a channel every minute. I have figured out how to accomplish this using the code below but I think my flush method is wrong. After flushing upstream messages I am noticing the socket gets immediately closed. public class Pinger extends ChannelOutboundMessageHandlerAdapter<ByteBuf> { private static final ByteBuf DUMMY = Unpooled.wrappedBuffer(""DUMMY"".getBytes()); @Override public void connect(ChannelHandlerContext ctx SocketAddress remoteAddress SocketAddress localAddress ChannelPromise promise) throws Exception{ super.connect(ctx remoteAddress localAddress promise); ctx.executor().scheduleAtFixedRate(new RepeatTask(ctx) 0 60 TimeUnit.SECONDS); } private final class RepeatTask implements Runnable { private final ChannelHandlerContext ctx; public RepeatTask(ChannelHandlerContext ctx){ this.ctx = ctx; } public void run() { if(ctx.channel().isActive()){ ctx.write(DUMMY.copy()); } } } @Override public void flush(ChannelHandlerContext ctx ByteBuf msg) throws Exception { ctx.nextOutboundMessageBuffer().add(msg); ctx.flush(); } } I would to also note that this handler is in the middle of a complex pipeline. I think I figured out how to make this work. ChannelStateHandlerAdapter is a much better class to inherit from. public class Pinger extends ChannelStateHandlerAdapter { private static final ByteBuf DUMMY = Unpooled.wrappedBuffer(""DUMMY"".getBytes()); @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.fireChannelActive(); ctx.executor().scheduleAtFixedRate(new PingTask(ctx) 0 60 TimeUnit.SECONDS); } private final class RepeatTask implements Runnable { private final ChannelHandlerContext ctx; public RepeatTask(ChannelHandlerContext ctx){ this.ctx = ctx; } public void run() { if(ctx.channel().isActive()){ ctx.write(DUMMY.copy()); } } } @Override public void inboundBufferUpdated(ChannelHandlerContext ctx) throws Exception { ctx.fireInboundBufferUpdated(); } }"
126,A,Netty http keep-alive timeout on second read I am writing a webgame server using netty and intend to use keep-alive to have more performance. If I use CachedThreadPool for boss and worker executor the server work fine for both keep-alive and non keep-alive connection. But if I use FixedThreadPool(1) one for boss and one for worker the first respond made it to the client but if browser use that connection to send second request it will blocked out and timeout at server I close that connection and firefox open new socket this socket also work fine at first respond.(I already include Connection Keep-alive and ContentLength to the respond header and double check it with httpAnalyzer tool. So can someone please tell me why this happen and what is the best practice about using thread with netty for an webgame server. if netty is async this shouldn't be happen right ? You should always use a CachedThreadPool and use the constructor of NioSocketChannelFactory to limit the used threads. I think its also documented in the javadocs. this seem to be the way with netty I just need to make sure I not do something wrong Thanks
127,A,How does asychronous programming work in Netty? Does it make things more chatty? Normally you make a call to a service it blocks until a thread in the pool is available and then it returns a result. With Netty or futures in general you get don't block and return immediately. Only when you actually need the value you call .get() or whatever the API is and then you will block till you receive data back. When dealing with services or client/server model this means you will connect/disconnect from the server more so when doing asych. programming correct? (with the benefit of not blocking). Is this correct? Is Netty basically designed using SEDE (staged event-driven architecture) and using Java's NIO data types). No. Using Netty asynchronously means that operations that manage connections and push I/O around are executed in separate threads and the original caller is later informed of the outcome of the requested operations or an interested listener is called back when there is data available to be read. Your application threads can block if you want them to but this is not necessary since you can define a callback that will be executed when the asynchronous operation completes. When dealing with services or client/server model this means you will connect/disconnect from the server more so when doing asych programming correct? (with the benefit of not blocking). Is this correct? Virtually nothing in that paragraph is correct. I recommend this tutorial as a better explanation of these fundamental concepts.(full disclosure I wrote it). excellent that is a great writeup thanks I'll look that over. BTW do you think this model will always be more scalable than using threadpools? how can one prove that? Sort of :) Looking forward to part 2 to put the theory into a real world scenerio like ajax and long polling on the web. thanks man! Well it *does* use thread pools but if you mean will it be more scalable than using traditional blocking I/O invoked in separate [thread-pool] threads I'm afraid I have to give you the stock answer: It depends. The hard features of non-blocking NIO (like Netty) are the elimination of Thread-Per-Connection and elimination of polling type functions that suck up bandwidth and CPU. The soft features are more diffused but I think the Netty pipeline and encoder/decoder architecture lends itself to very efficient network I/O processing but it is not exclusive to NIO. Know what I mean ?
128,A,"Flexible timeout mechanism in JBoss Netty? I am considering moving my Java NIO implementation over to JBoss Netty as it provides a much cleaner model than I have implemented. The implementation manages a number of client connections to components over TCP using a proprietary protocol. One aspect of my implementation that I cannot see in Netty is the ability to set arbitrary timeouts which: Wait for some data to be read from the Component. I know that Netty has a ReadTimeoutHandler but can the timeout value be changed/turned off easily by the Component as it moves through the state machine? Wait for time to elapse so that I can reconnect to the Component (to give the Component time to be restarted after a disconnect). This is entirely unrelated to communication and is a simple timeout however I'd like the timeout 'event/exception' to be presented to the handler class in the same manner as other communication-related timeouts. Can this timeout mechanism be accomplished using Netty? Conclusion: Given I would need to implement a timeout mechanism which would run within the its own thread I am not going to convert to using Netty after all. @someguy: No I'm using the term Handler for the class that 'represents' the component I'm communicating with. @secmask: They are client connections to multiple components. What kind of channel you are implementing server or client? You mean ""handle"" not ""handler""... @someguy: Well a handle is a resource identifier and it's not that. I'm using it in its generic sense so don't worry about it. Yes it's usually called the ""handle"". A ""handler"" on the other hand 'is an asynchronous callback subroutine that handles inputs received in a program' (wikipedia). See ChannelConfig. The method setConnectTimeoutMillis(int) sets the timeout in milliseconds. You can invoke this method via a Bootstrap instance by calling setOption(String Object). The name would be ""connectTimeoutMillis"" and the value would be the desired timeout in milliseconds. The following snippet shows how to set the connect timeout to 5000 milliseconds (5 seconds). ClientBootstrap bootstrap... // bootstrap instance bootstrap.setOption(""connectTimeoutMillis"" 5000); Many thanks - however (and I think I wasn't clear here) - I use timeout value to throttle the reconnect. The scenario is that the connection goes down and I want to give the component a chance to be restarted before connecting. Will the method you describe satisfy that condition? OK that makes sense thanks. Yes the timeout value changes for each state. @trojanfoe In that case you'll have to implement something like that yourself as far as I know. As for the first part of your new question I think you would have to use a different `ReadTimeoutHandler`. I guess you would have a different instance for each ""state""."
129,A,"Implementing a request timeout using Netty in Camel I have a Camel application that communicates with a remote server over TCP using the netty component. The server has a tendency to hang and so I want to be able to add a configurable timeout on a request so that if a response isn't returned in X amount of time I'd get an exception. The mina component has this capability in the timeout parameter but the netty component doesn't appear to have a corresponding option. I tried accomplishing this with a ReadTimeoutHandler and that came close... but not quite. It starts with creating a HashedWheelTimer when initializing the CamelContext: HashedWheelTimer timer = new HashedWheelTimer(); JndiRegistry jndi = new JndiRegistry(); jndi.bind(""MyClientPipelineFactory"" new MyClientPipelineFactory(timer)); And then add it to my pipeline: public class MyClientPipelineFactory extends ClientPipelineFactory { private final Timer timer; public MyClientPipelineFactory(Timer timer) { this.timer = timer; } public ChannelPipeline getPipeline(NettyProducer producer) throws Exception { ChannelPipeline p = pipeline(); p.addLast(""timeout"" new ReadTimeoutHandler(timer 30)); // more stuff return p; } } Finally I catch any exceptions in my routes configuration: onException(ReadTimeoutException.class) .handled(true) .process(new Processor() { public void process(Exchange exchange) throws Exception { Exception exception = (Exception) exchange.getProperty(Exchange.EXCEPTION_CAUGHT); throw new ApplicationException(""Connection timed out"" exception); } }); This almost works. Unfortunately it is channel specific and not request specific. So as long as I'm communicating with the server I'm fine. But 30 seconds after I am done I get a ReadTimeoutException thrown. The problem is that it's looking for any activity on the wire and not the request/response pairs that I care about. Am I missing something here? Is there an inherent way of doing request timeouts using Camel+Netty or is there some way to make the ReadTimeoutException work? (Camel 2.9.2/Netty 3.3.1) I wonder if we could add some kind of support for this. To trigger timeout on the given exchange request/reply pair. I assume ReadTimeoutHandler is from Netty? I guess we could peak in the code and see if we can only let it trigger if there is ""in-flight"" exchanges. A trick is also how to handle if a reply come back later and a timeout was already triggered. Then Camel would need to deal with this to cancel processing the reply. I am not sure if that is so easy to do.  I'm not familiar with Camel but a quick look at the Mina and Netty components suggests that the required functionality is a feature of the Mina component not Mina and it's missing from the Netty component. In camel trunk the Mina producer has a code path for when sync is true whereas the Netty producer doesn't appear to have similar functionality. It might be worth taking the question to the camel mailing lists. A possible workaround is to create a custom Netty handler that is request / response aware so you have a handler in your pipeline that starts a timer when the request is sent and cancels the timer when the response is received."
130,A,Designing a netty application that uses many types of packets I wonder what's the most maintainable/correct way to implement a server based on netty that handles a bunch of different packet types (mmo server to be precise) i.e. login packets move packets etc. It would be perfect to ultimately have every packet represented by a POJO. Assuming every packet begins with an unique constant-length identifier: is it better to have multiple decoders (I'd like to take advantage of the ReplayingDecoder class) or just one decoder that delegates further decoding to other classes based on decoded packet id? Any suggestions and/or links would be appreciated. Most times in live there is not one single best solution. I always prefer a single decoder that delegates further decoding to other methods in the same decoder class or to other classes based on decoded packet type ID. In MINA we had a DemuxingIoHandler which does something like that easily at the cost of internal complexity but with ReplayingDecoder it's usually as simple as switch-case. That was the first solution that came to my mind but I wanted to make sure. I'll stick to that then - thanks Trustin.
131,A,"Netty 4.0 channel.id() returns negative integer? When trying to log the channel ID for debugging purposes: @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { // TODO: Investigate negative id LOGGER.info(""Established Connection with = {} Channel Id = {}"" ctx .channel().remoteAddress() ctx.channel().id()); } I got the following: 2013-06-08 22:12:49468 [nioEventLoopGroup-2-1] INFO com.zeedoo.mars.server.HandshakeHandler - Established Connection with = /127.0.0.1:59236 Channel Id = -1228118933 And pretty much all other channel ids I got are negative also I'm just wondering if this is an intended behavior? And if so what's the rationale behind it? Thanks a lot! Intended or not no idea but it's as good a number as another if all you need is a number ;) It is intentional. AbstractChannel either allocates a unique negative id or accepts a user-specifed positive unique id. The ID ranges are separated to avoid duplicate conflicts. @littlejedi You call the construtor that accepts an Integer id (not every concrete channel impl does). That's how but why is another matter. how do I assign an ID to the channel?"
132,A,Is it safe to use same thread pools across multiple ServerBootstraps? I have a netty-based application which listens to multiple tcp ports. So each port is initialized like this bootstrap = new ServerBootstrap(new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newFixedThreadPool(Settings.getDemuxPoolSize()) Settings.getDemuxPoolSize())); But having so many thread pools (and I have really many open TCP ports) looks like a waste to me. Question is: is it safe to use SAME thread pools across multiple server bootstraps in Netty? (Maybe some thread-local channel references etc.?) You would better be off to create a WorkerPool and then share it between the different NioServerSocketChannelFactory instances. So you can use the same Workers for different ChannelFactory instances. Something like: WorkerPool<NioWorker> workerPool = new NioWorkerPool<NioWorker>(Executors.newCachedThreadPool() size); NioServerSocketChannelFactory factory = new NioServerSocketChannelFactory(Executors.newCachedThreadPool() workerPool); NioServerSocketChannelFactory factory2 = new NioServerSocketChannelFactory(Executors.newCachedThreadPool() workerPool); .... I guess you are right. But could you please clarify what is the difference? Because official user guide from netty.io proposes using CachedThreadPools and does not mention NioWorkerPools at all?
133,A,"Asynchronous HTTP client with Netty I'm new to netty and still strugling to find my way. I'm looking to create an http client that works asynchronously. The netty examples of http only show how to wait for IO operations and not how to use addListener and so I've been trying to figure this out for the last few days. I'm trying to create a request class that will handle all of the different states of a request from connecting sending the data handling the response and then closing of the connection. In order to do that my class extends SimpleChannelUpstreamHandler and implements ChannelFutureListener. I use a ChannelPipelineFactory which adds the (this) instance the class (as a SimpleChannelUpstreamHandler) to the pipeline as a handler. The connection is created like this: this.state = State.Connecting; this.clientBootstrap.connect(this.address).addListener(this); Then the operationComplete method: @Override public void operationComplete(ChannelFuture future) throws Exception { State oldState = this.state; if (!future.isSuccess()) { this.status = Status.Failed; future.getChannel().disconnect().addListener(this); } else if (future.isCancelled()) { this.status = Status.Canceled; future.getChannel().disconnect().addListener(this); } else switch (this.state) { case Connecting: this.state = State.Sending; Channel channel = future.getChannel(); channel.write(this.createRequest()).addListener(this); break; case Sending: this.state = State.Disconnecting; future.getChannel().disconnect().addListener(this); break; case Disconnecting: this.state = State.Closing; future.getChannel().close().addListener(this); break; case Closing: this.state = State.Finished; break; } System.out.println(""request operationComplete start state: "" + oldState + "" end state: "" + this.state + "" status: "" + this.status); } private HttpRequest createRequest() { String url = this.url.toString(); HttpRequest request = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.GET url); request.setHeader(HttpHeaders.Names.HOST this.url.getHost()); request.setHeader(HttpHeaders.Names.CONNECTION HttpHeaders.Values.CLOSE); request.setHeader(HttpHeaders.Names.ACCEPT_ENCODING HttpHeaders.Values.GZIP); return request; } The class also overrides the messageReceived method: @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { System.out.println(""messageReceived""); HttpResponse response = (HttpResponse) e.getMessage(); ChannelBuffer content = response.getContent(); if (content.readable()) { System.out.println(""CONTENT: "" + content.toString(CharsetUtil.UTF_8)); } } The problem is that I get this output: request operationComplete start state: Connecting end state: Sending status: Unknown request operationComplete start state: Sending end state: Disconnecting status: Unknown request operationComplete start state: Closing end state: Finished status: Unknown request operationComplete start state: Disconnecting end state: Finished status: Unknown As you can see the messageReceived of the is not being executed for some reason even though the pipeline factory adds the instance of this class to the pipeline. Any ideas what I'm missing here? Thanks. Edit I managed to finally get this working thanks to the help of @JestanNirojan in case someone will be interested in the solution: public class ClientRequest extends SimpleChannelUpstreamHandler { .... public void connect() { this.state = State.Connecting; System.out.println(this.state); this.clientBootstrap.connect(this.address); } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { this.state = State.Sending; System.out.println(this.state); ctx.getChannel().write(this.createRequest()); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { HttpResponse response = (HttpResponse) e.getMessage(); ChannelBuffer content = response.getContent(); if (content.readable()) { System.out.println(""CONTENT: "" + content.toString(CharsetUtil.UTF_8)); } this.state = State.Disconnecting; System.out.println(this.state); } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { this.state = State.Closing; System.out.println(this.state); } @Override public void channelClosed(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { this.state = State.Finished; System.out.println(this.state); } private HttpRequest createRequest() { String url = this.url.toString(); HttpRequest request = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.GET url); request.setHeader(HttpHeaders.Names.HOST this.url.getHost()); request.setHeader(HttpHeaders.Names.CONNECTION HttpHeaders.Values.CLOSE); request.setHeader(HttpHeaders.Names.ACCEPT_ENCODING HttpHeaders.Values.GZIP); return request; } } is HttpResponse the full HttpResponse or can ti be a chunk? I have 1000's of chunks coming back and want one event per chunk or the memory will explode resulting in out of memory. The HttpResponse is the full response you can't chunk it as far as I know. You should go lower then that probably with [HttpResponseDecoder](http://static.netty.io/3.5/api/org/jboss/netty/handler/codec/http/HttpResponseDecoder.html). You are using a ChannelFutureListener to do all operations in the channel (which is bad) and the future listener will be executed right after calling those channel operations. The problem is After sending the message channel is disconnected immediately and the handler can not receive the response message which comes later.  ........ case Sending: this.state = State.Disconnecting; future.getChannel().disconnect().addListener(this); break; ........ you should not block the channel future thread at all. The best approach is extend the SimpleChannelUpstreamHandler's  channelConnected(..) {} messageReceived(..) {} channelDisconnected(..) {} methods and react to those events. you can keep the state in that handler too. Oh. That was simple. Thanks a lot for the info I wish Netty had better documentation on this."
134,A,"How can I get number of active connections? Is it real to get a number of active connections to your server? I wrote a simple http server and I need to know how many active connections does he have. I tried this but it gives me wrong result after 10000 requests @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { super.channelInactive(ctx); StatusData.decreaseConnectionCounter(); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { super.channelActive(ctx); log.info(""Channel "" + ctx.channel() + "" is now active""); StatusData.increaseConnectionCounter(); } I change my class so it's look like this StatusData and when I generating 10000 requests in 100 threads it counts correctly. class StatusData{ private AtomicInteger counter = new AtomicInteger(); public void increaseConnectionCounter() { synchronized (counter){ int newValue = counter.intValue() + 1; counter.set(newValue); } } public void decreaseConnectionCounter() { synchronized (counter){ int newValue = counter.intValue() - 1; counter.set(newValue); } } public int getActiveConnectionCounter() { return counter.get(); } } Are you using an `AtomicInteger` inside StatusData? Now I user AtomicInteger thank you. Your solution looks correct. It's most likely a bug in StatusData like not use AtomicLong. Thank you for answer. I found a problem"
135,A,"Netty OIO client-server remains blocked in java.net.SocketOutputStream.write(byte[]) EDIT: created github repo: https://github.com/istiillyes/client-server-netty I've created a client-server using netty 4.0.15.Final and performed some tests using both OIO and NIO. I'm sending some Strings with varying sizes [1KB 10KB 100KB]. I need the server and client to be able to send messsages in parallel so the test looks like this: Start server (create channel to accept connections) Start client (create channel that connects to server) Send 100 messages from client to server (and vice versa) when channel becomes active. Using NIO the messages are transsmitted and everything works fine. Using OIO both server and client remains blocked in java.net.SocketOutputStream.wirte(byte[]) after some time and never return. Any idea why this happens? Is there something wrong in how I'm using netty? I did this same test using plain java sockets and it worked. So I'm guessing either I don't use netty properly or this is a bug. I added here the code where I create the channels and the channel handlers. This is the stack trace from client captured using YourKit: pool-1-thread-1 [RUNNABLE IN_NATIVE] java.net.SocketOutputStream.write(byte[]) io.netty.buffer.UnpooledUnsafeDirectByteBuf.getBytes(int OutputStream int) io.netty.buffer.AbstractByteBuf.readBytes(OutputStream int) io.netty.channel.oio.OioByteStreamChannel.doWriteBytes(ByteBuf) io.netty.channel.oio.AbstractOioByteChannel.doWrite(ChannelOutboundBuffer) io.netty.channel.AbstractChannel$AbstractUnsafe.flush0() io.netty.channel.AbstractChannel$AbstractUnsafe.flush() io.netty.channel.DefaultChannelPipeline$HeadHandler.flush(ChannelHandlerContext) io.netty.channel.DefaultChannelHandlerContext.invokeFlush() io.netty.channel.DefaultChannelHandlerContext.flush() io.netty.channel.ChannelOutboundHandlerAdapter.flush(ChannelHandlerContext) io.netty.channel.DefaultChannelHandlerContext.invokeFlush() io.netty.channel.DefaultChannelHandlerContext.flush() io.netty.channel.ChannelOutboundHandlerAdapter.flush(ChannelHandlerContext) io.netty.channel.DefaultChannelHandlerContext.invokeFlush() io.netty.channel.DefaultChannelHandlerContext.flush() io.netty.handler.logging.LoggingHandler.flush(ChannelHandlerContext) io.netty.channel.DefaultChannelHandlerContext.invokeFlush() io.netty.channel.DefaultChannelHandlerContext.write(Object boolean ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.writeAndFlush(Object ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.writeAndFlush(Object) io.netty.channel.DefaultChannelPipeline.writeAndFlush(Object) io.netty.channel.AbstractChannel.writeAndFlush(Object) client.ClientHandler.channelActive(ChannelHandlerContext) io.netty.channel.DefaultChannelHandlerContext.invokeChannelActive() io.netty.channel.DefaultChannelHandlerContext.fireChannelActive() io.netty.channel.ChannelInboundHandlerAdapter.channelActive(ChannelHandlerContext) io.netty.handler.logging.LoggingHandler.channelActive(ChannelHandlerContext) io.netty.channel.DefaultChannelHandlerContext.invokeChannelActive() io.netty.channel.DefaultChannelHandlerContext.fireChannelActive() io.netty.channel.ChannelInboundHandlerAdapter.channelActive(ChannelHandlerContext) io.netty.channel.DefaultChannelHandlerContext.invokeChannelActive() io.netty.channel.DefaultChannelHandlerContext.fireChannelActive() io.netty.channel.ChannelInboundHandlerAdapter.channelActive(ChannelHandlerContext) io.netty.channel.DefaultChannelHandlerContext.invokeChannelActive() io.netty.channel.DefaultChannelHandlerContext.fireChannelActive() io.netty.channel.DefaultChannelPipeline.fireChannelActive() io.netty.channel.oio.AbstractOioChannel$DefaultOioUnsafe.connect(SocketAddress SocketAddress ChannelPromise) io.netty.channel.DefaultChannelPipeline$HeadHandler.connect(ChannelHandlerContext SocketAddress SocketAddress ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.invokeConnect(SocketAddress SocketAddress ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.connect(SocketAddress SocketAddress ChannelPromise) io.netty.channel.ChannelOutboundHandlerAdapter.connect(ChannelHandlerContext SocketAddress SocketAddress ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.invokeConnect(SocketAddress SocketAddress ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.connect(SocketAddress SocketAddress ChannelPromise) io.netty.channel.ChannelOutboundHandlerAdapter.connect(ChannelHandlerContext SocketAddress SocketAddress ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.invokeConnect(SocketAddress SocketAddress ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.connect(SocketAddress SocketAddress ChannelPromise) io.netty.channel.ChannelDuplexHandler.connect(ChannelHandlerContext SocketAddress SocketAddress ChannelPromise) io.netty.handler.logging.LoggingHandler.connect(ChannelHandlerContext SocketAddress SocketAddress ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.invokeConnect(SocketAddress SocketAddress ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.connect(SocketAddress SocketAddress ChannelPromise) io.netty.channel.DefaultChannelHandlerContext.connect(SocketAddress ChannelPromise) io.netty.channel.DefaultChannelPipeline.connect(SocketAddress ChannelPromise) io.netty.channel.AbstractChannel.connect(SocketAddress ChannelPromise) io.netty.bootstrap.Bootstrap$2.run() io.netty.channel.ThreadPerChannelEventLoop.run() io.netty.util.concurrent.SingleThreadEventExecutor$2.run() java.lang.Thread.run() Code that creates the acceptor channel: final class ServerChannelFactory { private static final Logger LOGGER = Logger.getLogger(ServerChannelFactory.class); protected static Channel createAcceptorChannel( final ChannelType channelType final InetSocketAddress localAddress final ServerHandler serverHandler ) { final ServerBootstrap serverBootstrap = ServerBootstrapFactory.createServerBootstrap(channelType); serverBootstrap .childHandler(new ServerChannelInitializer(serverHandler)) .option(ChannelOption.SO_BACKLOG Resources.SO_BACKLOG); try { ChannelFuture channelFuture = serverBootstrap.bind( new InetSocketAddress(localAddress.getPort())).sync(); channelFuture.awaitUninterruptibly(); if (channelFuture.isSuccess()) { return channelFuture.channel(); } else { LOGGER.warn(String.format(""Failed to open socket! Cannot bind to port: %d!"" localAddress.getPort())); } } catch (InterruptedException e) { LOGGER.error(""Failed to create acceptor socket."" e); } return null; } private static class ServerChannelInitializer extends ChannelInitializer<SocketChannel> { private ChannelHandler serverHandler; private ServerChannelInitializer(ChannelHandler serverHandler) { this.serverHandler = serverHandler; } @Override protected void initChannel(SocketChannel ch) throws Exception { // Encoders ch.pipeline().addLast(Resources.STRING_ENCODER_NAME new StringEncoder(CharsetUtil.UTF_8)); ch.pipeline().addBefore(Resources.STRING_ENCODER_NAME Resources.FRAME_ENCODER_NAME new LengthFieldPrepender(Resources.FRAME_LENGTH_FIELD_SIZE)); // Decoders ch.pipeline().addLast(Resources.STRING_DECODER_NAME new StringDecoder(CharsetUtil.UTF_8)); ch.pipeline().addBefore(Resources.STRING_DECODER_NAME Resources.FRAME_DECODER_NAME new LengthFieldBasedFrameDecoder(Resources.MAX_FRAME_LENGTH Resources.FRAME_LENGTH_FIELD_OFFSET Resources.FRAME_LENGTH_FIELD_SIZE Resources.FRAME_LENGTH_ADJUSTMENT Resources.FRAME_LENGTH_FIELD_SIZE)); // Handlers ch.pipeline().addLast(Resources.LOGGING_HANDLER_NAME new LoggingHandler()); ch.pipeline().addLast(Resources.SERVER_HANDLER_NAME serverHandler); } } } Server Handler: final class ServerHandler extends ChannelInboundHandlerAdapter { private static final Logger LOGGER = Logger.getLogger(ServerHandler.class); int noMessagesReceived = 0; @Override public void channelActive(io.netty.channel.ChannelHandlerContext ctx) throws java.lang.Exception { for(int i=0; i< Resources.NO_MESSAGES_TO_SEND; i++) { ctx.channel().writeAndFlush(MessageStore.getMessage(i)); } } @Override public void channelRead(final ChannelHandlerContext ctx final Object msg) { noMessagesReceived++; if(noMessagesReceived == Resources.NO_MESSAGES_TO_SEND) { ctx.channel().writeAndFlush(MessageStore.getMessage(0)); } } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { FileUtils.write(Resources.SERVER_OUTPUT String.format(""Received %d messages"" noMessagesReceived)); } @Override public void exceptionCaught(final ChannelHandlerContext ctx final Throwable cause) throws Exception { LOGGER.error(String.format(""Exception in %s"" this.getClass().getName()) cause); } } Server Bootstrap Factory: public class ServerBootstrapFactory { private ServerBootstrapFactory() { } public static ServerBootstrap createServerBootstrap(final ChannelType channelType) throws UnsupportedOperationException { ServerBootstrap serverBootstrap = new ServerBootstrap(); switch (channelType) { case NIO: serverBootstrap.group(new NioEventLoopGroup() new NioEventLoopGroup()); serverBootstrap.channel(NioServerSocketChannel.class); return serverBootstrap; case OIO: serverBootstrap.group(new OioEventLoopGroup() new OioEventLoopGroup()); serverBootstrap.channel(OioServerSocketChannel.class); return serverBootstrap; default: throw new UnsupportedOperationException(""Failed to create ServerBootstrap "" + channelType + "" not supported!""); } } } Code that creates the connector channel: final class ClientChannelFactory { private static final Logger LOGGER = Logger.getLogger(ClientChannelFactory.class); protected static Channel createConnectorChannel( ChannelType channelType final ClientHandler clientHandler InetSocketAddress remoteAddress ) { final Bootstrap bootstrap = BootstrapFactory.createBootstrap(channelType); bootstrap.handler(new ClientChannelInitializer(clientHandler)); try { final ChannelFuture channelFuture = bootstrap.connect(new InetSocketAddress(remoteAddress.getAddress() remoteAddress.getPort())) .sync(); channelFuture.awaitUninterruptibly(); if (channelFuture.isSuccess()) { return channelFuture.channel(); } else { LOGGER.warn(String.format( ""Failed to open socket! Cannot connect to ip: %s port: %d!"" remoteAddress.getAddress() remoteAddress.getPort()) ); } } catch (InterruptedException e) { LOGGER.error(""Failed to open socket!"" e); } return null; } private static class ClientChannelInitializer extends ChannelInitializer<SocketChannel> { private ChannelHandler clientHandler; private ClientChannelInitializer(ChannelHandler clientHandler) { this.clientHandler = clientHandler; } @Override protected void initChannel(SocketChannel ch) throws Exception { // Encoders ch.pipeline().addLast(Resources.STRING_ENCODER_NAME new StringEncoder(CharsetUtil.UTF_8)); ch.pipeline().addBefore(Resources.STRING_ENCODER_NAME Resources.FRAME_ENCODER_NAME new LengthFieldPrepender(Resources.FRAME_LENGTH_FIELD_SIZE)); // Decoders ch.pipeline().addLast(Resources.STRING_DECODER_NAME new StringDecoder(CharsetUtil.UTF_8)); ch.pipeline().addBefore(Resources.STRING_DECODER_NAME Resources.FRAME_DECODER_NAME new LengthFieldBasedFrameDecoder(Resources.MAX_FRAME_LENGTH Resources.FRAME_LENGTH_FIELD_OFFSET Resources.FRAME_LENGTH_FIELD_SIZE Resources.FRAME_LENGTH_ADJUSTMENT Resources.FRAME_LENGTH_FIELD_SIZE)); // Handlers ch.pipeline().addLast(Resources.LOGGING_HANDLER_NAME new LoggingHandler()); ch.pipeline().addLast(Resources.CLIENT_HANDLER_NAME clientHandler); } } } Client Handler: public final class ClientHandler extends ChannelInboundHandlerAdapter { private static final Logger LOGGER = Logger.getLogger(ClientHandler.class); private int noMessagesReceived = 0; @Override public void channelActive(io.netty.channel.ChannelHandlerContext ctx) throws java.lang.Exception { for(int i=0; i< Resources.NO_MESSAGES_TO_SEND; i++) { ctx.channel().writeAndFlush(MessageStore.getMessage(i)); } } @Override public void channelRead(final ChannelHandlerContext ctx final Object msg) throws Exception { noMessagesReceived++; if (noMessagesReceived > Resources.NO_MESSAGES_TO_SEND) { ctx.channel().close(); } } @Override public void channelInactive(final ChannelHandlerContext ctx) throws Exception { FileUtils.write(Resources.CLIENT_OUTPUT String.format(""Received %d messages"" noMessagesReceived)); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) throws Exception { LOGGER.error(String.format(""Exception in %s"" this.getClass().getName()) cause); } } Bootstrap Factory: public class BootstrapFactory { private BootstrapFactory() { } public static Bootstrap createBootstrap(final ChannelType channelType) throws UnsupportedOperationException { Bootstrap bootstrap = new Bootstrap(); switch (channelType) { case NIO: bootstrap.group(new NioEventLoopGroup()); bootstrap.channel(NioSocketChannel.class); return bootstrap; case OIO: bootstrap.group(new OioEventLoopGroup()); bootstrap.channel(OioSocketChannel.class); return bootstrap; default: throw new UnsupportedOperationException(""Failed to create Bootstrap "" + channelType + "" not supported!""); } } } Channel Type: public enum ChannelType { // New IO - non-blocking NIO // Old IO - blocking OIO; } write() blocks when the sender is way ahead of the receiver. It's not a good idea to combine blocking and non-blocking I/O like this.  Because Netty's OIO transport performs read and write in the same thread it does not read while write is in progress. The problem is if both client and server are implemented with the OIO transport they might end up writing to each other and waiting for each other to read what they are writing. The workaround is 1) to use NIO for at least one side or 2) to be extremely careful not to fill the peer's socket receive buffer up to its max size. Practically (2) isn't very easy to achieve so it's always recommended to use the NIO transport at least for the server side. Thank you for your answer Trustin. In netty 3.x if you always write from a separate thread (not the I/O worker) than the write is processed by the calling thread so read will never be blocket by write. (reads being processed on the I/O worker). Right? The problem is in the code that configures the pipeline. At the last step you need to decouple the clienthandler/serverhandler from the read current thread using a EventLoopGroup instance that processes stuff on a different thread."
136,A,"Communication between Client and ClientHandler in Netty I am developing an auction system on top of Netty. I use Netty because googling has taught me that NIO can deal with much larger clients than ordinary socket programming can. Basically I am a starter in Netty. I have covered the tutorials and user guide. And that is it. So plz understand if my question doesn't qualify as a ""problem"". The following is the pseudo-code of my client. public class AuctionClient { private boolean loggedIn; public AuctionClient() //constructor /// .... // various functions /// public void run() { while (true) { int option = getUserOption(); //get user menu selection switch(option) { case 1: login(); //user enters username and password. The info is converted into JSON string and sent to AuctionServer. //AuctionServer returns true if the info is correct false otherwise break; case 2: startAuction(); //start a new auction break; case 3: makeBid(); //make a bid to an existing auction break; case 4: logout(); //log out from the AuctionServer break; default: break; } } } public static void main() // Creates AuctionClient class and runs it. } This is the gist of what I am trying to do. The problem is I want to enable startAuction() makeBid() and logout() only if the variable loggedIn is true. So I have to know if the login was successful in order to change the value of loggedIn. But since it is the AuctionClientHandler(though now shown here) that deals with the result of login() there is no way for AuctionClient to know if the login was successful. Is there a graceful way to solve this problem. I want to avoid using BlockingQueue to pass information between AuctionClient and AuctionClientHandler. Or is there a better design for the auction system? Any help would be appreciated. Edward I think your problem can be boiled down to a simple fact. You need to hold ""state"" from a previous operation. For this need to create a new handler each time in your PipelineFactory implementation. For e.g. pipeline.addLast('MyAuctionHandler'new AuctionHandlerClass()); The first time login happens successfully your LoginHandler which is in the pipeline should send a message to the AuctionClientHandler say a special object which you can then use to set the login flag to true. For example code you might want to take a look at a Java Game Server I have published. It also deals with similar login session management etc. This is the handler which deals with login only difference is that this handler is not stateful since I moved the state to a session LookupService class. As I said above I am currently using SynchronousQueue(not what I actually wanted but it's woking). Your game server code would definitely be a big help for me. Right now I am saving open channels in a HashMap using userid as the key. But keeping a separate class for session management seems more sophisticated. Thanks for the info.  Another way would be to store the state as attachment on the Channel. Channel.setAttachment(..); I am currently managing with SynchronousQueue. setAttachment() seems to be somewhat similar approach. Thanks for the tip!!"
137,A,"android websocket connection timeout with wAsync (atmosphere) I previously wrote a Java SE client based on wAsync. It works rock-solid with version 1.0.RC1 connected to Atmosphere 1.1.RC1. I followed this example from Jeanfrancois to accomplish this task Everything works JSON encoding subscribing broadcasting and sending a POST to a URI. Good so far. However putting this example to Android would raise a timeout exception when trying to subscribe to a resource. As you can see in the log I wanted to open a socket on http://localhost:8080/resource/playerpool Again this worked fine on the Java SE 6 client. Anyone has a clue why this would run into a timeout on the Android emulator while being the exact code from the Java SE client? I did set the permission in the AndroidManifest.xml <uses-permission android:name=""android.permission.INTERNET"" /> <uses-permission android:name=""android.permission.ACCESS_NETWORK_STATE""/> Below the Android log when trying to open the connection on the socket. 04-24 06:27:41.043: W/System.err(1512): java.net.ConnectException: connection timed out to ws://localhost:8080/resource/playerpool?X-Atmosphere-Transport=long-polling&X-atmo-protocol=true&X-Atmosphere-tracking-id=0&X-Atmosphere-Framework=1.0&X-Cache-Date=0 04-24 06:27:41.051: W/System.err(1512): at com.ning.http.client.providers.netty.NettyConnectListener.operationComplete(NettyConnectListener.java:103) 04-24 06:27:41.051: W/System.err(1512): at org.jboss.netty.channel.DefaultChannelFuture.notifyListener(DefaultChannelFuture.java:427) 04-24 06:27:41.051: W/System.err(1512): at org.jboss.netty.channel.DefaultChannelFuture.notifyListeners(DefaultChannelFuture.java:418) 04-24 06:27:41.051: W/System.err(1512): at org.jboss.netty.channel.DefaultChannelFuture.setFailure(DefaultChannelFuture.java:380) 04-24 06:27:41.051: W/System.err(1512): at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139) 04-24 06:27:41.051: W/System.err(1512): at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:82) 04-24 06:27:41.051: W/System.err(1512): at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312) 04-24 06:27:41.051: W/System.err(1512): at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:41) 04-24 06:27:41.051: W/System.err(1512): at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) 04-24 06:27:41.051: W/System.err(1512): at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) 04-24 06:27:41.051: W/System.err(1512): at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1076) 04-24 06:27:41.051: W/System.err(1512): at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:569) 04-24 06:27:41.051: W/System.err(1512): at java.lang.Thread.run(Thread.java:856) 04-24 06:27:41.051: W/System.err(1512): Caused by: java.net.ConnectException: connection timed out 04-24 06:27:41.051: W/System.err(1512): at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:136) 04-24 06:27:41.051: W/System.err(1512): ... 8 more 04-24 06:27:41.063: W/System.err(1512): java.util.concurrent.ExecutionException: java.net.ConnectException: connection timed out to ws://localhost:8080/rest-group-e/playerpool?X-Atmosphere-Transport=long-polling&X-atmo-protocol=true&X-Atmosphere-tracking-id=0&X-Atmosphere-Framework=1.0&X-Cache-Date=0 04-24 06:27:41.063: W/System.err(1512): at com.ning.http.client.providers.netty.NettyResponseFuture.abort(NettyResponseFuture.java:327) 04-24 06:27:41.063: W/System.err(1512): at com.ning.http.client.providers.netty.NettyConnectListener.operationComplete(NettyConnectListener.java:107) 04-24 06:27:41.063: W/System.err(1512): at org.jboss.netty.channel.DefaultChannelFuture.notifyListener(DefaultChannelFuture.java:427) 04-24 06:27:41.074: W/System.err(1512): at org.jboss.netty.channel.DefaultChannelFuture.notifyListeners(DefaultChannelFuture.java:418) 04-24 06:27:41.074: W/System.err(1512): at org.jboss.netty.channel.DefaultChannelFuture.setFailure(DefaultChannelFuture.java:380) 04-24 06:27:41.074: W/System.err(1512): at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139) 04-24 06:27:41.074: W/System.err(1512): at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:82) 04-24 06:27:41.074: W/System.err(1512): at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312) 04-24 06:27:41.074: W/System.err(1512): at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:41) 04-24 06:27:41.074: W/System.err(1512): at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) 04-24 06:27:41.083: W/System.err(1512): at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) 04-24 06:27:41.083: W/System.err(1512): at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1076) 04-24 06:27:41.083: W/System.err(1512): at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:569) 04-24 06:27:41.083: W/System.err(1512): at java.lang.Thread.run(Thread.java:856) 04-24 06:27:41.083: W/System.err(1512): Caused by: java.net.ConnectException: connection timed out to ws://localhost:8080/rest-group-e/playerpool?X-Atmosphere-Transport=long-polling&X-atmo-protocol=true&X-Atmosphere-tracking-id=0&X-Atmosphere-Framework=1.0&X-Cache-Date=0 04-24 06:27:41.083: W/System.err(1512): at com.ning.http.client.providers.netty.NettyConnectListener.operationComplete(NettyConnectListener.java:103) 04-24 06:27:41.083: W/System.err(1512): ... 12 more 04-24 06:27:41.083: W/System.err(1512): Caused by: java.net.ConnectException: connection timed out 04-24 06:27:41.083: W/System.err(1512): at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:136) 04-24 06:27:41.083: W/System.err(1512): at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:82) 04-24 06:27:41.083: W/System.err(1512): at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312) 04-24 06:27:41.083: W/System.err(1512): at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:41) 04-24 06:27:41.083: W/System.err(1512): ... 3 more http://localhost:8080/resource/playerpool In the Android emulator/device this URL will try to connect to an HTTP server running on the emulator/device itself which probably doesn't exist unless you've another Android app acting as a HTTP server running on it. Is your web service running on the host machine of the emulator? Try replacing localhost with 10.0.2.2. In the emulator this IP refers to your host machine according to Android Emulator documentation I forgot! Thanks for the reminder."
138,A,Netty - Framing I created this small example. I have an EchoServer on Port 8080 and a LogServer on Port 9090 (exemplary in this example). Both are started on the same machine (with Server which contains the main). Server started on port 8080 Server started on port 9090 As soon a client -- via telnet -- connects the EchoServer establishes a connection to the LogServer. Now I am entering a long text let's say 5000 character (see the long_text in the example) even if bash cannot handle it: EchoServer Received: 1024 LogServer Received: 1024 EchoServer Received: 2048 LogServer Received: 2048 EchoServer Received: 1025 LogServer Received: 1025 If I enter the text again I am getting: EchoServer Received: 2048 LogServer Received: 2048 EchoServer Received: 2049 LogServer Received: 2049 Let's do it again: EchoServer Received: 3072 EchoServer Received: 1025 LogServer Received: 3072 LogServer Received: 1025 And again: EchoServer Received: 4096 EchoServer Received: 1 LogServer Received: 4096 LogServer Received: 1 The last time: EchoServer Received: 4097 LogServer Received: 4097 My observation: First of all the data is fragmented. Additionally each time the fragmends are extended by 1024 bytes (1024204830724096...). I guess the last behavious is because of the TCP slow start. How can I achive the forwarding to the LogServer without fragmentation such my text will arrive as one single message? I guess the problem is how I connect to the LogServer. [EDIT1] I changed the logs. It seems that it's already happening between telnet and the EchoSever. Anyway I still have the problem in the real environment. The whole message (some Kilobyte) is arriving via WebSockets and the Forwarding to another Connection is fragmented. [EDIT2] I did some more research (with wireshark -- the log). I guess it has noting to do with TCP Slow Start. The data (I was sending 4095 times the letter A) arriving on the machine as three correct TCP packets: Frame 1 (1506 bytes) with 1440 bytes TCP data (41 41 41 ... 41 41 41/HEX) Frame 2 (1506 bytes) with 1440 bytes TCP data (41 41 41 ... 41 41 41/HEX) Frame 3 (1283 bytes) with 1217 bytes TCP data (41 41 41 ... 41 0d 0a/HEX) All 4095 A characters + CRLF arrived as expected. The EchoServer said: EchoServer Received: 1024 EchoServer Received: 2048 EchoServer Received: 1025 It also received the 4095 characters + CRLF but it is different fragmented than the TCP segments (exactly same as the first log above). How can I avoid this Netty behavior? In non-blocking I/O there's no practical way to get the number of available bytes in socket receive buffer. Because of that problem Netty predicts the number of available bytes. It starts from 1024 and then increases the prediction depending the number of read bytes. You can shcnage this behavior by employing a different prediction algorithm. The default implementation is AdaptiveReceiveBufferSizePredictor and you might want to take a look into its source code to write your own one. However no matter what prediction algorithm you choose you have to keep in mind that TCP/IP is a streaming protocol which means you can always get messages in a split or merged form. Please refer to the user guide: http://netty.io/docs/stable/guide/html/ (See the 'Dealing with a Stream-based Transport' section.) Thanks for giving me some details. Finally I implemented something like the `LengthFieldPrepender` on application side. Thus I leave the TCP behavior like it is and handle it in the application Btw: am I right that a `FIN` of a TCP-Paket always sends a Message to the pipe? Doesn't it make sense to set the value to the standard Ethernet frame size -- 1500 Byte? In my opinion it should improve Netty not to extend the `ChannelBuffer` -- save some instructions -- for a single full frame.  You require a FrameDecoder in your pipeline can which assemble bytes from the network into complete frames. In your case I think you need to combine the StringDecoder and DelimiterBasedFrameDecoder. Take a look at the Telnet example and specifically the TelnetServerPipelineFactory
139,A,Netty 3.2.6 to Netty 4.0x migration I have following specific queries on migration a) I am currently using IdleStateAwareChannelUpstreamHandler to handle channelIdle event along with other regular ChannelUpstream event callbacks. When this is migrated to 4.0x model what should be the equivalent approach ? b) What is the equivalent EventExecutor for OrdredMemoryAwareThreadPoolExecutor in 4.0x ? c) In 3.2.6 I had used channelId from event objects of handler-callbacks to keep track of clients uniquely. For example in channelConnected callback I used to obtain the channelId from evt.getChannel().getId(). Since events are more fine-grained in 4.0x what is the best way to obtain Netty-generated unique channel id ? I had checked if ChannelHandlerContext provides a means to obtain the same. But I could not find an equivalent I am referring to javadocs at http://netty.io/4.0/api/ Thanks in advance a) See the javadocs of the IdleStateHandler. You need to intercept IdleStateEvents in the userEventTriggered(..) method. b) specify a EventExecutor when adding a ChannelHandler to the ChannelPipeline. See https://github.com/netty/netty/wiki/New-and-noteworthy#no-more-executionhandler---its-in-the-core c) There is currently no id() on the Channel anymore. You can use Channel.hashCode() for now. Most likely the id() will come back in a later release. Thanks Norman. I will take a closer look at the EventExecutor as to how it ensures order
140,A,"How can I use two sockets in the main using Netty I am a Netty beginner and would like to run a server socket and a client socket at the same time using Netty. However when I have tried it I could run only one socket and the other one could not. Actually what I want is I am going to communicate with a websocket of Webbrowser and pass it to a client socket in the same app to send it to a TCP/IP socket server. Your help would be appreciated. Here is my code: public class WsServer { private int port; public WsServer(int port){ this.port = port; } public void run() throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new WsServerInitializer()); Channel ch = b.bind(port).sync().channel(); System.out.println(""Web socket server started at port "" + port + '.'); System.out.println(""Open your browser and navigate to http://localhost:"" + port + '/'); ch.closeFuture().sync(); } finally { InternalSocket.close(); bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } public class WsServerInitializer extends ChannelInitializer<SocketChannel> { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""codec-http"" new HttpServerCodec()); pipeline.addLast(""aggregator"" new HttpObjectAggregator(65536)); pipeline.addLast(""handler"" new WsSocketHandler()); } } public class WsSocketHandler extends WebSocketServerHandler { private static final Logger logger = Logger.getLogger(WsSocketHandler.class); protected static final String WEBSOCKET_PATH = ""/websocket""; private WebSocketServerHandshaker handshaker; @Override public void channelRead0(ChannelHandlerContext ctx Object msg) throws Exception { //super.channelRead0(ctx msg); if (msg instanceof FullHttpRequest) { handleHttpRequest(ctx (FullHttpRequest) msg); } else if (msg instanceof WebSocketFrame) { handleWebSocketFrame(ctx (WebSocketFrame) msg); } } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { super.channelReadComplete(ctx); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) throws Exception { super.exceptionCaught(ctx cause); } private void handleHttpRequest(ChannelHandlerContext ctx FullHttpRequest req) throws Exception { // Handle a bad request. if (!req.getDecoderResult().isSuccess()) { sendHttpResponse(ctx req new DefaultFullHttpResponse(HTTP_1_1 BAD_REQUEST)); return; } // Allow only GET methods. if (req.getMethod() != GET) { sendHttpResponse(ctx req new DefaultFullHttpResponse(HTTP_1_1 FORBIDDEN)); return; } // Send the demo page and favicon.ico if (""/"".equals(req.getUri())) { ByteBuf content = WebSocketServerIndexPage.getContent(getWebSocketLocation(req)); FullHttpResponse res = new DefaultFullHttpResponse(HTTP_1_1 OK content); res.headers().set(CONTENT_TYPE ""text/html; charset=UTF-8""); setContentLength(res content.readableBytes()); sendHttpResponse(ctx req res); return; } if (""/favicon.ico"".equals(req.getUri())) { FullHttpResponse res = new DefaultFullHttpResponse(HTTP_1_1 NOT_FOUND); sendHttpResponse(ctx req res); return; } // Handshake WebSocketServerHandshakerFactory wsFactory = new WebSocketServerHandshakerFactory( getWebSocketLocation(req) null false); handshaker = wsFactory.newHandshaker(req); if (handshaker == null) { WebSocketServerHandshakerFactory.sendUnsupportedWebSocketVersionResponse(ctx.channel()); } else { handshaker.handshake(ctx.channel() req); } } private void handleWebSocketFrame(ChannelHandlerContext ctx WebSocketFrame frame) { // Check for closing frame if (frame instanceof CloseWebSocketFrame) { handshaker.close(ctx.channel() (CloseWebSocketFrame) frame.retain()); return; } if (frame instanceof PingWebSocketFrame) { ctx.channel().write(new PongWebSocketFrame(frame.content().retain())); return; } if (!(frame instanceof TextWebSocketFrame)) { throw new UnsupportedOperationException(String.format(""%s frame types not supported"" frame.getClass() .getName())); } // Send the uppercase string back. String receivedText = ((TextWebSocketFrame) frame).text(); //System.out.println(""========= receivedText:"" + receivedText); handleWsSocketRequest(ctx receivedText); //logger.debug(String.format(""%s received %s"" ctx.channel() receivedText)); //ctx.channel().write(new TextWebSocketFrame(receivedText.toUpperCase())); } private void handleWsSocketRequest(ChannelHandlerContext ctx String receivedText){ System.out.println(""[WebSocketHandler]"" + receivedText); if (StringUtils.isBlank(receivedText)) return; try { //InternalClient client = InternalClient.getInstance(""localhost"" 31200); //client.send(receivedText); // } catch (Exception e1) { //e1.printStackTrace(); //} //} protected ChannelFuture send(ChannelHandlerContext ctx String msg){ System.out.println(String.format(""%s sent: %s"" ctx.channel() msg)); return ctx.channel().write(new TextWebSocketFrame(msg)); } protected static void sendHttpResponse( ChannelHandlerContext ctx FullHttpRequest req FullHttpResponse res) { // Generate an error page if response getStatus code is not OK (200). if (res.getStatus().code() != 200) { ByteBuf buf = Unpooled.copiedBuffer(res.getStatus().toString() CharsetUtil.UTF_8); res.content().writeBytes(buf); buf.release(); setContentLength(res res.content().readableBytes()); } // Send the response and close the connection if necessary. ChannelFuture f = ctx.channel().write(res); ctx.channel().flush(); if (!isKeepAlive(req) || res.getStatus().code() != 200) { f.addListener(ChannelFutureListener.CLOSE); } } protected static String getWebSocketLocation(FullHttpRequest req) { return ""ws://"" + req.headers().get(HOST) + WEBSOCKET_PATH; } } public class InternalClient { private String host; private int port; private InternalClientHandler handler; private InternalClient(String host int port){ this.host = host; this.port = port; handler = new InternalClientHandler(); } public void run() throws Exception { EventLoopGroup workerGroup = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); // (1) b.group(workerGroup); // (2) b.channel(NioSocketChannel.class); // (3) b.option(ChannelOption.SO_KEEPALIVE true); // (4) b.handler(new InternalClietnIntializer()); // Start the client. ChannelFuture f = b.connect(host port).sync(); // (5) System.out.println(""[InternalClient] Connects to "" + host + "":"" + port + '.'); // Wait until the connection is closed. f.channel().closeFuture().sync(); } finally { workerGroup.shutdownGracefully(); } } public void send(String msg){ handler.send(msg); } } public class InternalClietnIntializer extends ChannelInitializer<SocketChannel> { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); // On top of the SSL handler add the text line codec. pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(1024 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""handler"" new InternalClientHandler()); } } public class InternalClientHandler extends ChannelInboundHandlerAdapter { ChannelHandlerContext context; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { super.channelActive(ctx); this.context = ctx; System.out.println(""[InternalClientHandler]channelActive""); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { cause.printStackTrace(); ctx.close(); } @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { System.out.println(""channelRead ""); String recvText = """" + msg; System.out.println(""###[InternalClientHandler]Received###"" + recvText); if (StringUtils.isBlank(recvText)){ return; } } public void send(String msg) { if (context!=null){ context.channel().writeAndFlush(msg + ""\r\n""); System.out.println(""###[InternalClientHandler]Sent###"" + msg + ""\r\n""); } } } public class ServerMain { public static void main(String[] args) throws Exception { int port = 31300; try { WsServer server = new WsServer(port); server.run(); //Below does not run InternalClient client = new InternalClient(""localhost"" port+1000); client.run(); } catch (Exception e) { e.printStackTrace(); System.exit(-1); } } } Please show you code... This is because you call channel.closeFuture().sync(). This will block until the Channel is closed again. You will need to remove the line Thank you so much."
141,A,java Tigase Perforamnce Why Tigase Server can reach so many connections? http://www.tigase.org/content/tigase-load-tests-again-500k-user-connections Could I reach 100000 connections hypothetically with Netty? I've made Netty accepted 100k connection with Netty. In theory a socket is identified by src_ipsrc_portdst_ipdst_portprotocol. Because port is in range (0-65k) each client IP is limited about 65k connections to server so if you have two ip address(two clients host) you can easily reach such that number of concurrent connections.
142,A,"Is it a good idea to use Sec-WebSocket-Key to identify the websocket client connection? In the servlet world there would be things like cookies and HttpSession for me to identify who was hitting my restful service to route the request to the correct data. Is it a good idea to use the Sec-WebSocket-Key as though it is a cookie identifying the client connection? Specifically I am using the socko scala library (an akka webserver based on netty) to implement a websocket server starting from the demo app at socko-examples. Socko is wrapping a netty Channel and passing a netty WebSocketFrame into the application code. I would then like to dispatch the frame of incoming data based on ""some identity"" for the client connection which I have previously associated to the end users data (e.g their shopping basket). To do this I have written extension methods to expose the Sec-WebSocket-Key http header as though it is a top level property of the objects which come into the application by digging out the http header from the original websocket handshake: package org.mashupbots.socko.examples.websocket // pimp my library pattern to add extension method object ChatWebSocketExtensions { import org.mashupbots.socko.events.WebSocketFrameEvent class WebSocketFrameEventWithSecWebSocketKey(wsFrame: WebSocketFrameEvent) { def secWebSocketKey: String = { wsFrame.initialHttpRequest.headers.get(""Sec-WebSocket-Key"").getOrElse(""null"") } } implicit def webSocketFrameEventWithSecWebSocketKey(wsFrame: WebSocketFrameEvent) = new WebSocketFrameEventWithSecWebSocketKey(wsFrame) import org.mashupbots.socko.events.WebSocketHandshakeEvent; class WebSocketHandshakeEventWithSecWebSocketKey(event: WebSocketHandshakeEvent) { def secWebSocketKey: String = { val option = Option(event.nettyHttpRequest.getHeader(""Sec-WebSocket-Key"")) return option.getOrElse(""null""); } } implicit def webSocketHandshakeEventWithSecWebSocketKey(event: WebSocketHandshakeEvent) = new WebSocketHandshakeEventWithSecWebSocketKey(event) } Thats only some syntactic sugar so that the app code does not have to go digging around in the low level objects to get the Sec-WebSocket-Key header and just access it as though it were a first class property:  val routes = Routes({ case WebSocketHandshake(wsHandshake) => wsHandshake match { case GET(PathSegments(""websocket"" :: roomNumber :: Nil)) => { log.info(""Handsake to join room "" + roomNumber) wsHandshake.authorize(onComplete = Some((event: WebSocketHandshakeEvent) => { val identity = event.secWebSocketKey; log.info(""Authorised connection:"" + identity); // do something with this identified user connection })) } } case WebSocketFrame(wsFrame) => { // Once handshaking has taken place we can now process frames sent from the client val identity = wsFrame.secWebSocketKey; log.info(""chat from:"" + identity); // do something with this identified data frame } }) My question is whether this is good practice or is there a better way to identify the user connection? I read the wording not the code. I'm looking for a similar solution. I'm wondering session management is done in Tomcat etc. via HTTP Headers right? Maybe that can be leveraged? as there is no forum (yet) for socko i am pointing out this question on their issue tracker over at https://github.com/mashupbots/socko/issues/62 'Sec-WebSocket-Key' identifies a connection. However I'm not too sure if using 'Sec-WebSocket-Key' is a good ideas to identify a ""session"". This is because 'Sec-WebSocket-Key' does not accommodate scenario where the connection is dropped and the client is required to establish a new connection. A new 'Sec-WebSocket-Key' may be issued. The user would loose his/her session. With HTTP a session is typically associated with a cookie or an id in the URL - both of which are independent of the HTTP connection. In this way multiple HTTP connections may be used for a single user session. I would suggest you use something similar for your web socket ""session"". As part of your hand-shake and successful login get the server to send the client a session id. The client should send the session id back to the server with each request. In this way you can use javascript like https://github.com/joewalnes/reconnecting-websocket to provide network resiliency in your application code. Hope this helps."
143,A,"Are netty and comet related somehow? A little confused how are netty and comet related or are they seperate and they work together somehow? I've read a bit about using netty and comet to build real-time applications confused how they work together. Pretty sure comet is an idea a way of doing ""reverse ajax"". And netty is an implementation of this ""idea"". Cometd is an implementation of the Bayeux Protocol (http://svn.cometd.com/trunk/bayeux/bayeux.html) This protocol has multiple implementations of which cometd is likely the most popular. The point of a Bayeux implementation is that it allows the server to do asynchronous messaging over HTTP that includes the elusive ""server push"". Instead of the client polling every say 5 seconds to the server for updates the server can ""call"" the client when it has an update. It uses the technique of Long Polling. Essentially an HTTP connection is held open between the client and server. When the server finally has something to ""tell"" the client it responds to the open connection. The connection or ""long poll"" is immediately reestablished. To prevent HTTP Timeouts the connection can be automatically re-establised over various time periods. I'm not exactly sure what the relationsh9ip between Netty and Cometd is or if there is one. I suspect Netty would be very useful in implementing the Bayeux Protocol (the documentation seems to hint at this) because one of the weaknesses of the Bayeux Protocol and scaling is the sheer volume of open HTTP Connections that must be handled. If they block you have a problem because that's too many threads.  As far as I understand Netty is a framework/library while Comet is a concept (sort of one-way websockets and as Chad said a kind of ""reverse ajax""). Although the new form of functionality eventually [termed as Comet](http://infrequently.org/2006/03/comet-low-latency-data-for-the-browser/) was push from server to client the requirement for client to server communication was still present. This is was generally achieved in Comet HTTP transports using a 2nd HTTP connection. The streaming/polling server -> client connection has been known as the back channel and the client -> server (standard) communication is sometimes referred to as the command channel; for achieving things like subscripions."
144,A,Netty Pipeline object parsing Currently I have a single handler at the end of my netty pipeline that does almost all the request logic. (Parsing a object from json using jackson authentication rate limiting etc. Would it be a better use of the pipeline structure to put these at stages along the pipeline after the executer? It's matter of re-usability etc. Often you have a handler for decoding one for encoding and one for the business logic. This allows for better re-usability and also for easier testing.
145,A,"Netty 4.0.17 basic server grabs a bunch of TCP ports on loopback on windows I'm running an echo server on windows 7 ultimate using jdk 1.7.0 (u51) 64bit. java version ""1.7.0_51"" Java(TM) SE Runtime Environment (build 1.7.0_51-b13) Java HotSpot(TM) 64-Bit Server VM (build 24.51-b03 mixed mode) On Linux / Mac netstat shows that this process only grabs the specified port (9809 for the example for listening). However on windows it also grabs a bunch of other TCP ports on loopback (127.0.0.1). EDIT: The behavior is the same for netty versions 4.0.17.Final and the just released 4.0.18.Final Netstat listing for one run (the PID was 4956): PS C:\Users\xxxx> netstat -ano | select-string 4956 TCP 0.0.0.0:9809 0.0.0.0:0 LISTENING 4956 TCP 127.0.0.1:50682 127.0.0.1:50683 ESTABLISHED 4956 TCP 127.0.0.1:50683 127.0.0.1:50682 ESTABLISHED 4956 TCP 127.0.0.1:50684 127.0.0.1:50685 ESTABLISHED 4956 TCP 127.0.0.1:50685 127.0.0.1:50684 ESTABLISHED 4956 TCP 127.0.0.1:50686 127.0.0.1:50687 ESTABLISHED 4956 TCP 127.0.0.1:50687 127.0.0.1:50686 ESTABLISHED 4956 TCP 127.0.0.1:50688 127.0.0.1:50689 ESTABLISHED 4956 TCP 127.0.0.1:50689 127.0.0.1:50688 ESTABLISHED 4956 TCP 127.0.0.1:50690 127.0.0.1:50691 ESTABLISHED 4956 TCP 127.0.0.1:50691 127.0.0.1:50690 ESTABLISHED 4956 TCP 127.0.0.1:50692 127.0.0.1:50693 ESTABLISHED 4956 TCP 127.0.0.1:50693 127.0.0.1:50692 ESTABLISHED 4956 TCP 127.0.0.1:50694 127.0.0.1:50695 ESTABLISHED 4956 TCP 127.0.0.1:50695 127.0.0.1:50694 ESTABLISHED 4956 TCP 127.0.0.1:50696 127.0.0.1:50697 ESTABLISHED 4956 TCP 127.0.0.1:50697 127.0.0.1:50696 ESTABLISHED 4956 TCP 127.0.0.1:50698 127.0.0.1:50699 ESTABLISHED 4956 TCP 127.0.0.1:50699 127.0.0.1:50698 ESTABLISHED 4956 TCP 127.0.0.1:50700 127.0.0.1:50701 ESTABLISHED 4956 TCP 127.0.0.1:50701 127.0.0.1:50700 ESTABLISHED 4956 TCP 127.0.0.1:50702 127.0.0.1:50703 ESTABLISHED 4956 TCP 127.0.0.1:50703 127.0.0.1:50702 ESTABLISHED 4956 TCP 127.0.0.1:50704 127.0.0.1:50705 ESTABLISHED 4956 TCP 127.0.0.1:50705 127.0.0.1:50704 ESTABLISHED 4956 TCP [::]:9809 [::]:0 LISTENING 4956 These don't show up on Linux/Mac only on Windows. I'm assuming this is some sort of IPC mechanism on windows (per worker thread perhaps) but wished to ask if anyone can authoritatively clarify this for me. The issue is since netty / java grabs these local ports running any other apps trying to bind to these ports (mostly dev servers debuggers allocating random high ports) fail with a permission denied type error message. I mostly work on linux/mac so wondering if I missed some obvious redmondism :) The echo server code is given below: ( I boiled it down to a basic server to test) package test; import io.netty.bootstrap.ServerBootstrap; import io.netty.buffer.ByteBuf; import io.netty.channel.Channel; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInitializer; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; public class TestServer extends ChannelInitializer<SocketChannel>{ private int port = 9809; public TestServer(int port) { this.port = port; } public void run() throws Exception { NioEventLoopGroup pool = new NioEventLoopGroup(); try { ServerBootstrap bootstrap = new ServerBootstrap(); Channel c = bootstrap.group(pool).channel(NioServerSocketChannel.class).childHandler(this).bind(port).sync().channel(); c.closeFuture().sync(); } finally { pool.shutdownGracefully(); } } /** * @param args */ public static void main(String[] args) throws Exception { int port = 9809; TestServer server = new TestServer(port); server.run(); } @Override protected void initChannel(SocketChannel channel) throws Exception { channel.pipeline().addLast(""handler"" new Handler()); } private class Handler extends SimpleChannelInboundHandler { @Override protected void channelRead0(ChannelHandlerContext ctx Object obj) throws Exception { ByteBuf buf = (ByteBuf)obj; ctx.writeAndFlush(buf.retain()); } } } Do you still see this problem with 4.0.18.Final? (It's out just today: http://search.maven.org/#artifactdetails|io.netty|netty-all|4.0.18.Final|jar) @trustin - tried with 4.0.18.Final and still get the extra ports grabbed. I think I remember this is just how java NIO works on Windows so there is nothing we can do about it in Netty. Norman looks like you're right. I think each selector grabs two ports on loopback for windows/java nio (almost looks like a socketpair for IPC). tried with a basic nio echo server Thanks Norman. I just wished confirmation that it was not something I was doing wrong. BTW any pointers/links in nio documentation/code about this behavior on Windows? my google-fu is betraying me at the moment in locating anything of help."
146,A,"Simple Netty Echo Server/Client not receiving messages I'm trying to write a simple echo server with Netty. I'm reading Netty in Action MEAP v8 to get down some theory and learn the core basics of Netty. The client connects successfully but no messages get through from the client. I am able to telnet a message to the server and receive the response so I guess the issue is on the client I just have no idea what is wrong due to me being new to Netty. Here is the client: public class Client { private final String host; private final int port; public Client(String host int port) { this.host = host; this.port = port; } public void start() throws Exception { EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .remoteAddress(new InetSocketAddress(host port)) .handler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new EchoClientHandler()); } }); ChannelFuture f = b.connect().sync(); f.channel().closeFuture().sync(); } finally { group.shutdownGracefully().sync(); } } public static void main (String [] args) throws Exception { new Client(""127.0.0.1"" 11235).start(); } } And the Client handler: (I did try appending '\r\n' to the sent message but that did not make a difference which I found here: Netty Client to Server message) @Sharable public class EchoClientHandler extends SimpleChannelInboundHandler<ByteBuf> { public void channelActive(ChannelHandlerContext ctx) { System.out.println(""Connected""); ctx.write(Unpooled.copiedBuffer(""Netty MAY rock!"" CharsetUtil.UTF_8)); } protected void channelRead0(ChannelHandlerContext ctx ByteBuf in) throws Exception { System.out.println( ""Client received: "" + in.toString(CharsetUtil.UTF_8)); } public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { cause.printStackTrace(); ctx.close(); } } The server: public class EchoServer { private final int port; public EchoServer(int port) { this.port = port; } public void start() throws Exception { EventLoopGroup group = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(group) .channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(port)) .childHandler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { System.out.println(""New client connected: "" + ch.localAddress()); ch.pipeline().addLast(new EchoServerHandler()); } }); ChannelFuture f = b.bind().sync(); f.channel().closeFuture().sync(); } finally { group.shutdownGracefully().sync(); } } public static void main (String [] args) throws Exception { new EchoServer(11235).start(); } } The server handler: @Sharable public class EchoServerHandler extends ChannelInboundHandlerAdapter { public void channelRead(ChannelHandlerContext ctx Object msg) { ByteBuf in = (ByteBuf) msg; System.out.println( ""Server received: "" + in.toString(CharsetUtil.UTF_8)); ctx.write(in); } public void channelReadComplete(ChannelHandlerContext ctx) { ctx.writeAndFlush(Unpooled.EMPTY_BUFFER) .addListener(ChannelFutureListener.CLOSE); } public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { cause.printStackTrace(); ctx.close(); } } It must be something small I'm missing so any help will preserve my fleeting sanity and will be much appreciated! Instead of write use writeAndFlush in your ClientHandler: public void channelActive(ChannelHandlerContext ctx) { System.out.println(""Connected""); ctx.writeAndFlush(Unpooled.copiedBuffer(""Netty MAY rock!"" CharsetUtil.UTF_8)); } exactly...it is fixed for the next MEAP update. Thank you that worked! And @NormanMaurer RESPECT to Mr Author waiting in suspense for the next update!"
147,A,"Play framework 2.2 ""hot fixing"" live production server I'm fiddling around with Play Framework 2.2 trying various scenarios and coming from LAMP environment I have this question: is some form of hot fixing possible on live production server? If so how exactly does it work? If no then what is the closest thing? Server OS is Centos 6.4. Equivalent example in LAMP would be re-uploading some file with a hot fix. This is not possible with Play (or most other web frameworks for that matter). To allow zero time deploys you typically have a load balancer and then do rolling upgrades across your nodes taking one node at a time out of the cluster to upgrade it. ...and of course Play makes this easier given that it is stateless. :-)  You cannot hot fix a play framework application like you would a php application. Everything in a play framework application is compiled so if you hot-switch one of your files on the server the change will not have any affect before it is compiled and the server is restarted. Instead of hot fixing consider having a reverse proxy in front of your play application (Apache and Nginx are good alternatives). When you need to update your application just upload it to a new folder and start it with a new port number. When the new server instance is up and running switch the reverse proxy to point at the new instance. Then shut the old instance down. With this approach you can safely update your server without downtime. Actually you can ""almost"" hotfix if you compile the stage binaries on another machine move them over kill play and run the stage script. It will be down for a few seconds but it's much better than the alternative. Also use varnish if you want a proxy/loadbalancer. It's much much more efficient :)"
148,A,"Sending TCP packets via Netty Netty is dividing the data into different packets? I'm currently using Netty 4.0.7.Final to write a server that receives images (size: ~10k) over TCP. I modified Netty's sample echo client handler to just read a file into bytes and send it over to my Netty server. public EchoClientHandler(int firstMessageSize) throws IOException { File image = new File(""google.jpeg""); byte[] imageBytes = FileUtils.readFileToByteArray(image); byte[] bytes = Base64.encodeBase64(imageBytes); String base64 = new String(bytes); //System.out.println(""base64=""+ base64); firstMessage = Unpooled.copiedBuffer(base64 CharsetUtil.UTF_8); } My test image is 9k and I can see the whole image is being sent via Netty logging io.netty.handler.logging.LoggingHandler logMessage INFO: [id: 0x132baef0 /127.0.0.1:49710 => localhost/127.0.0.1:2112] WRITE(11964B) However when the Netty server receives the message it seems to be dividing the message into two packets the first packet is 1024 bytes and the second one is 10940 bytes which adds up to 1024+10940 = 11964 bytes (total size of the image) 2013-08-24 22:56:33700 [nioEventLoopGroup-3-1] INFO MessageDecoder - capacity = 1024 2013-08-24 22:56:33700 [nioEventLoopGroup-3-1] INFO MessageDecoder - readable bytes = 1024 2013-08-24 22:56:33709 [nioEventLoopGroup-3-1] INFO MessageDecoder - capacity = 16384 2013-08-24 22:56:33710 [nioEventLoopGroup-3-1] INFO MessageDecoder - readable bytes = 10940 Here's what my decoder looks like (although I doubt the decoder has anything to do with it it looks like Netty is handling this before it even reaches the decoder) public class MessageDecoder extends ByteToMessageDecoder { private static final Logger LOGGER = LoggerFactory.getLogger(MessageDecoder.class); @Override protected void decode(ChannelHandlerContext ctx ByteBuf in List<Object> out) throws Exception { // Convert to String first LOGGER.info(""capacity = "" + in.capacity()); LOGGER.info(""readable bytes = "" + in.readableBytes()); String rawString = in.readBytes(in.readableBytes()).toString(CharsetUtil.UTF_8); LOGGER.info(""Received base64 String={}"" rawString); } I also tried large number of files it looks Netty is always dividing a message into packets of 1024 bytes + whatever size for the rest of the file?? I'm wondering why Netty is doing this ? And is there a way to just get the complete packet in one-go? Thanks so much. I do not think Netty is doing this. This has to do with how tcp/ip works. It depends on what routers your message is going through. For example MTU(maximum transmission unit) is about 1400 bytes on any WLAN. Netty doesn't fragment anything but IP and TCP do. thanks a lot I was able to resolve using a DelimiterBasedFrameDecoder (comes with Netty) and specified the maximum frame size If you'd like to abstract fragmentation from your handler you need to frame your messages. This can be done easily by making use of the LengthFieldPrepender when sending and the LengthFieldBasedFrameDecoder when receiving. This ensures that your message decoder only sees a byte buffer representing a full message. Note that your frame handlers should be first in your ChannelPipeline except when you are also using an SSL handler and/or compression handler in which case SSL should be first followed by compression followed by the frame handlers. Being first in the pipeline means that a handler will be first to handle and inbound event and last to handle an outbound event."
149,A,ChannelInboundByteHandlerAdapter Alternative in Netty 4.0.7 Hey I noticed that ChannelInboundByteHandlerAdapter has been removed and i was wonder if there is an alternative? SimpleChannelInboundHandlerAdapter . See also http://netty.io/news/2013/06/18/4-0-0-CR5.html
150,A,"Not able to send an object with netty I've used some examples to send and receive strings and they have worked perfectly. The thing is I have tried to adapt the code(reading the api and examples) to send serializable objects and they dont work. I don't get any error message channel read method is never invoked so server never gets the message. I read it could be related to some kind of delimeter but I can't find any clue regarding it Here is the code i won't include handler added and removed because they work Server initiaizer protected void initChannel(SocketChannel arg0) throws Exception { ChannelPipeline pipeline = arg0.pipeline(); pipeline.addLast(""decoder"" new ObjectDecoder(null)); pipeline.addLast(""encoder"" new ObjectEncoder()); pipeline.addLast(""handler"" new ChatServerHandler()); } Channel read public void channelRead0(ChannelHandlerContext arg0 Message message) throws Exception { Channel incoming = arg0.channel(); System.out.println(""received ""+ message.getContent() + ""from "" + message.getSender() + ""\r\n"" ); } Run server public void run() throws InterruptedException{ EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try{ ServerBootstrap bootstrap = new ServerBootstrap() .group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChatServerInitializer()); bootstrap.bind(port).sync().channel().closeFuture().sync(); } And here is the client protected void initChannel(SocketChannel arg0) throws Exception { ChannelPipeline pipeline = arg0.pipeline(); pipeline.addLast(""decoder"" new ObjectDecoder(null)); pipeline.addLast(""encoder"" new ObjectEncoder()); pipeline.addLast(""handler"" new ChatClientHandler()); } and the main (server says client connected) public void run(){ EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap() .group(group) .channel(NioSocketChannel.class) .handler(new ChatClientInitializer()); Channel channel = bootstrap.connect(hostport).sync().channel(); BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); Message message = new Message(); message.setReceiver(""user""); message.setSender(""user 2""); try { message.setContent(in.readLine()); channel.write(message); System.out.println(""Sent "" + System.currentTimeMillis()); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } Last the message class without get/set public class Message implements Serializable { private static final long serialVersionUID = 1L; private String sender; private String receiver; private String content; public Message(String sender String receiver String content){ this.setSender(sender); this.setReceiver(receiver); this.setContent(content); } Thanks a lot for your time Check the ChannelFuture returned from the write operation. I bet it was failed. You are right sir it did fail. Do you have any clue regarding why would it fail? i think im writing it the right way and the cause method is throwing null it wouldn't throw anything or I don't know the right way to catch it. i am trying to catch any exception and it won't catch anything. Also I ask for isDone() and it says false so maybe that is the reason why I am not getting any exception. Thanks in advance if it was failed there should be a Throwable. Can you show the stacktrace ? I wrote a cycle afterwards while(!future.isDone()) (future is the channelfuture that write returned and it never comes out. Now I see... you need to call channel.writeAndFlush(..) to actually flush it out to the socket. See the apidocs ;)"
151,A,Netty: stop reconnecting and shutdown I plan to modify Netty UptimeClient (see here). The original version is designed to run endlessly: it reconnects to the host in case of disconnection. I'd like to add a 'terminate' method in UptimeClient.java. The method would disconnect or stop the reconnection process from an outside thread shutdown Netty gracefully and return. Since the client channel can change because of the reconnection process would it be safe to keep all channels returned by 'bootstrap.connect()' in a ChannelGroup and call 'close' using the group before releasing Netty's resources? How would you implement a 'terminate' method? (edit: using 3.7.0) In Nety 4.0 you can just call shutdownGracefully(...) on the EventLoopGroup that manages all your channels. Then all existing channels will be closed automatically and the reconnection attempt should be rejected. Please feel free to file an issue if this doesn't work. If you are using Netty 3.x unfortunately there's no automatic mechanism for this. You have to ensure to close all channels because the event loop will not terminate itself until it has a channel to manage. For more information please refer to NioClientChannelFactory ('Life cycle of threads and graceful shutdown') Is there an equivalent mechanism using version 3.7.0? EventLoopGroup exists only in Netty 4.+. Updated the answer.
152,A,Java: encrypted server/clients bi-directional communication? What is the best way to establish an encrypted bi-directional communication between a server and multiple clients? The server has persistence database and will send data to clients and clients will send back data. This must be encrypted for best protection against network sniffing tools and etc. Would Netty server be a good candidate for this? Can I use sockets with netty and client applications to connect to the server? Thank you. You can just encrypt the socket and send whatever protocol you like over the wire. HTTPS is just one of them. For example we have implemented SMTPS on top of netty without any problems. You just need to define the protocol write the encoder / decoder and add them with the SslHandler in the pipeline. Thats it.  If you mean that communication protocol is HTTP and you are using standard HTTP environment (HTTP server Servlets JSPs etc) user HTTPS communication. It guarantees encryption and protection of your data in both directions. what other non http solution exists? I ask this because I read that to get https certificate is super expensive. You don't need to use a Certification Authority in order to use SSL. If you bundle the server's public key within your client CA are not needed ... which means that you don't have to pay anything.
153,A,Why ChannelOutboundHandler exceptions not caught by exceptionCaught() method? (Netty 4.0.4.Final) (version: Netty 4.0.4.Final) If an exception rises in ChannelInboundHandler I can handle it in exceptionCaught() method but if the exception rises in ChannelOutboundHandler I can't. Because exceptionCaught() is not a call. Why is this so? There is only way to handle outbound exception by analize Future result like this: channel.writeAndFlush(serverPacket).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { future.cause().printStackTrace(); } } }); But it is very inconveniently. It's by design... Outbound operations only are notified via the Future as otherwise we would need to do double notifications which has some performance penalty. If you want to to have it propagated to the exceptionCaught handler you can just add the ChannelFutureListener.FIRE_EXCEPTION_ON_FAILURE as Listener to the returned ChannelFuture. Thank you! Using ChannelFutureListener.FIRE_EXCEPTION_ON_FAILURE is good solution for me. @Megaprog please accept the answer if it is correct. Thats how its done in SO
154,A,netty sever-to-server data streams I have two Java netty servers that need to pass lots of messages between themselves fairly frequently and I want it to happen fairly promptly. I need a TCP socket between the two servers that I can send these messages over. These messages are already-packed byte[] arrays and are self-contained. The servers are currently both running HTTP interfaces. What is the best way to do this? For example websockets might be a good fit yet I am unable to find any websocket client examples in netty.. I'm a netty newbie so would need some strong simple examples. It surely can't be so hard?! Are you going to use the 3.x.x or 4.x.x version? @EeroAaltonen 3.2.0.Final Since you mentioned HTTP you could look at the HttpStaticFileServer in the examples. When established a TCP connection is a Channel. To send your messages you need to write them to a ChannelBuffer and call channel.write. Of course this does not cover message borders. The Telnet example shows a case where the messages are delimited by the newline character. the downvote wasn't me. The doing-your-own-delimiters thing looks like the way to go. If it doesn't look appropriate please describe in more detail what you are searching for. how to do basic message passing over a socket between to servers. Netty doesn't seem to really advocate any communication protocol over the other. You need to decide that yourself. And what was the downvote for?
155,A,"Netty 4.0 - StringDecoder and ChannelInboundMessageHandlerAdapter not working I'm using netty 4.0.0-CR3 following the example on server-side: https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/telnet/TelnetServerPipelineFactory.java I've constructed my pipeline as follows: private static final StringDecoder DECODER = new StringDecoder(CharsetUtil.UTF_8); @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""decoder"" DECODER); // and then business logic pipeline.addLast(""serverHandler"" new ServerHandler()); } And handler: public class ServerHandler extends ChannelInboundMessageHandlerAdapter<String> { private static final Logger LOGGER = LoggerFactory.getLogger(ServerHandler.class); public void messageReceived(ChannelHandlerContext ctx String request) throws Exception { // Displays the message LOGGER.info(""Received: "" + request); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) throws Exception { LOGGER.error(""Unexpected exception from downstream."" cause); ctx.close(); } } I created a simple C# client that encodes String into bytes and send to the server. However I don't see EITHER StringDecoder's decode() OR handler's messageReceived() called. I then removed StringDecoder() in pipeline and changed the handler to be: public class Handler extends ChannelInboundByteHandlerAdapter { @Override protected void inboundBufferUpdated(ChannelHandlerContext ctx ByteBuf in) throws Exception { System.out.println(""called "" + in.toString(CharsetUtil.UTF_8)); } } Now it works properly. Functionally both pipelines should work right? Why is the first setup not working? The client code is the same. Thanks a lot! The documentation for StringDecoder clearly states that it must be used in conjunction with a ByteToMessageDecoder if used over a stream connection (such as TCP). The example you refer to has such a handler in front of the StringDecoder. Correct. Please add `LineBasedFrameDecoder` before `StringDecoder` if you are dealing with a line-based protocol.  Thanks guys! so I added the following: pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.nulDelimiter())); And this still didn't work until I explicitly add '\0' to the end to String in C# : ASCIIEncoding encoder = new ASCIIEncoding(); int index = random.Next(0 2); byte[] buffer = encoder.GetBytes(list[index] +　""\0""); The weird thing is that I was using Netty 3.6 previously and everything worked fine even without a FrameDecoder (only StringDecoder was there / client code was same) but now I have to do the steps above to make it to work..........?"
156,A,"Netty write several messages through one channel I'm newbie in Netty. I want send several messages through one channel in this way channel.writeAndFlush(Unpooled.copiedBuffer(""TBD"" CharsetUtil.UTF_8)).sync() channel.writeAndFlush(Unpooled.copiedBuffer(""TBD1"" CharsetUtil.UTF_8)).sync() But this code produce java.nio.channels.ClosedChannelException. How to do it correctly? This means the Channel was closed before. You should investigate the cause for this. That's a comment not an answer to the question I just found the reason in channel.close at server side"
157,A,"TCP Netty Ensure message received I am creating client-server system that should be able to work in ustable network. It assumes that connection could be broken at one time and then system must reconnect and continue it's work. I'am using Netty and stucked with a problem: how do we know that message which we sent was received by another host? I was thinking for this purpose ChannelFuture could be used and i can simply try to send message again if it fails in attached future listener: ChannelFuture fut = channel.write(message); fut.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { LOGGER.error(""Message send failed. Message: "" + message future.getCause()); //Queue message to be send after reconnect } } }); But when i done i noticed that listener never prints error. (I tested this by unpluging from network when system hardly works) Also i noticed that all futures for messages which i send comes into 'done' state and there is way to no ensure message was received (not using acknowledge messages) As i know TCP protocol guaranties that message would be received and when working with it we can know which send packages reached their destination and which not. I can't believe that Netty does not allow to know it. Is there a good way to know that message was delivered? You're misunderstanding TCP. TCP does not guarantee that your message is received. It provides a reliable ordered byte stream. It doesn't know anything about your message and cannot tell you when it has been received by the remote host. Therefore neither can Netty. Netty can only tell you that your message has been written to the operating system buffers before it is transmitted. This is what your code is detecting. To be sure that your message has been received the receiver must send back an explicit acknowledgement. The best way to achieve this depends on the expected behaviour of your protocol but usually involves maintaining a table of all messages that have been sent but not yet acknowledged."
158,A,"JMS consumer inside a Netty handler? I'm designing a quite complicated system and was wondering what the best way is to put a jms consumer (activemq vm protocol non persitent) inside a netty handler. Let me explain i have several clients connecting to my netty server using websockets. For every client connection i create a jms consumer that listens for interesting messages on one or more topics. If a interesting message arrives i need to do a extra step (additional filtering) before sending the message to the client using the websocket. Is the following a good way to do this: inside a SimpleChannelInboundHandler i declare a private non static consumer the consumer is initialized in channelActive the consumer is destroyed in channelInactive when a message is received by consumer i do the extra filter a send it using ctx.channel().write() In this setup i'm a bit worried that the consumer might turn into slow consumer and slow everything down cause the websocket goes over the internet. I came up with a more complex one to decouple the ""receiving of message by consumer"" and ""sending of message through a websocket"". inside a SimpleChannelInboundHandler i declare a private non static consumer the consumer is initialized in channelActive the consumer is destroyed in channelInactive when a message is received by consumer i put it in a blockedqueue every minute i let a thread (created for every client) look in the queue and send the found messages to the client using ctx.channel().write(). At this point i'm a bit worried about the extra thread per client. Or is there maybe a better way to accomplish this task? This is a classic slow consumer problem and the first step to resolving it is to determine what the appropriate action is when a slow consumer is detected. If it is acceptable that the slow consumer misses messages then the solution is some variation on dropping messages or unsubscribing them from the feed. For example if it's acceptable that the client misses messages then when one is received from JMS check if the channel is writable. If it isn't drop the message. If you want to give yourself a bit more of a buffer (although OS buffers are quite large) you can track the number of write completion future's that haven't completed (ie the messages haven't been written to the OS send buffer) and drop messages if there are too many outstanding write requests. If the client may not miss messages and is consistently slow then the problem is more difficult. One option might be to divert messages to a JMS queue with a specific header value then open a new consumer that reads messages from that queue using a JMS selector. This will put more load on the JMS server but might be appropriate for temporary slowness and hopefully it won't interfere with you main topic feeds. Alternatively you might want to stash the messages in a different store such as a database so you can poll for messages when they can be sent. If you do this right a single polling thread can cope with many clients (query for clients which have outstanding messages then for each client load a bunch of messages). However this isn't as convenient as using JMS. I wouldn't go with option 2 because the blocking queue is only going to solve the problem temporarily and you can achieve the same thing by tracking how many write operations are waiting to complete. Thank you for your thoughts on the subject John i appreciate it you given me a lot to think about."
159,A,Netty 4.x client file upload I've written an Http client around the new netty 4.0 lib. I can't seem to find where/how a post request should include files. One use case I've found now is uploading photos to a third party API. The DefaultHttpRequest class has setContent for a buffer to be passed in but is there any utility to encode the post parameters (inc file fields)? HTTP Post support is not yet ported to netty 4. It's on the to-do-list atm.. No not really.. its just that the whole multipart package would need to get ported to the new api Okay. There used to be a client file upload example before the move from the org.jboss namespace. Where has that gone? I want to have a look at how the multipart package was used previously and I'll have a go at porting over the next week or so. Is there a discussion somewhere already about how this is going to be done? I'm going to need it soon so I'd make an attempt at porting it to the new API.
160,A,Limiting the size of inbound buffer in netty 4 cr6 How can I limit the size of inbound buffers that are being created by netty when client sends large files? I want a client to stop sending data over the network when ByteBuf is full and resume once it becomes ready to receive more data. Here is my handler code: public class MyDecoder extends ChannelInboundHandlerAdapter { @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { // limit the size of recieving buffer to 1024 ctx.channel().config().setRecvByteBufAllocator(new FixedRecvByteBufAllocator(1024)); } @Override public void messageReceived(ChannelHandlerContext ctx MessageList<Object> msgs) throws Exception { ByteBuf byteBuf = msgs.<ByteBuf>cast().get(0); // stop after this line in debugger to check size of the actual payload per messageReceived invocation int bufferSize = byteBuf.readableBytes(); } } Now suppose that in my test I write: EmbeddedChannel ch = new EmbeddedChannel(new MyDecoder()); ch.writeInbound(Unpooled.wrappedBuffer(<<<here is a byte representation of a large file say 100 mb>>>)); ch.readInbound(); // etc... Now when in debugger I get to a line where bufferSize is calculated I always get the full size of my large file. The only difference FixedRecvByteBufAllocator makes at that point is when its size is set to 0 - all other values yield same results. In netty 4 cr2 there was a method that served that purpose newInboundBuffer but there is no such construct in cr6 and onwards. The FixedRecvByteBufAllocator should limit the buffer to max 1024 bytes if this is not the case its a bug.
161,A,"How to setup sub channels on web socket I am using play20 I have web sockets that use Netty 3.5.0 and i need to find way to use sub channels on each socket. it is possible and how ? Thanks. You can just use a different prefix for messages on each of the channels. For example if you want to send ""hello"" on channel 1 you send ""1hello"" instead. Then you have an web socket handler that parses these messages and dispatches them to other actors or iteratees according to the prefix. Thanks  from server side i have one out channel how can i send 2 messages to client at the same time with blocking one of the message. something like Multiplexing the web socket If you have one channel to one client the messages will arrive at the client sequentially no matter what you do. The trick then is to process the messages at the client in an asynchronous manner. Maybe you can use web workers for that but it really depends on what the client is doing with those messages."
162,A,How to read from org.jboss.netty.channel? I need to read directly from channel. I'm using netty. in my ChannelHandler I have this function:  public void messageReceived(ChannelHandlerContext ctx MessageEvent e) ChannelBuffer buf = (ChannelBuffer) e.getMessage(); Channel ch = e.getChannel(); //I need to read somthing from ch not from buf } Why do you need to do this? You automatically get the inbound data at the message so why should there be any reason to read from the channel directly? This seems to break the Netty event handling and I would avoid it at any cost. You can't read directly from the Channel as netty does deliver data read from the channel automatically to your handler. If you want read directly from the Channel you may use directly nio. .............tnx
163,A,"ClientBootstrap releaseExternalResources() throws an IllegalStateException I am using netty to connect and disconnect. But I get an exception when I try to disconnect and I can't quite understand what causes it. I have a global: private ClientBootstrap bootstrap_; When I try to connect I perform the following: First initialization: ChannelFactory channelFactory = null; channelFactory = new OioClientSocketChannelFactory(Executors.newCachedThreadPool()); bootstrap_ = new ClientBootstrap(channelFactory); Followed by:  bootstrap_.setPipelineFactory(() -> { ChannelPipeline pipeline = Channels.pipeline(); // SOME CODE }); bootstrap_.setOption(""remoteAddress"" addr); bootstrap_.setOption(""tcpNoDelay"" true); bootstrap_.setOption(""keepAlive"" true); bootstrap_.setOption(""configureBlocking"" false); bootstrap_.setOption(""connectTimeoutMillis"" 5000); And execute:  bootstrap_.connect(addr); Which does return success. Shortly after I close all the channels and try executing: bootstrap_.releaseExternalResources(); to stop the connection and it returns an IllegalStateException thrown by ExecutorUtil.java  ""An Executor cannot be shut down from the thread "" + ""acquired from itself. Please make sure you are "" + ""not calling releaseExternalResources() from an "" + ""I/O worker thread."" I have no idea why such an exception would be thrown and what exactly causes it to happen. Thanks in advance to any help this issue is really bugging me. The error message is telling you that you cannot call releaseExternalResources from a thread managed by an executor which in itself is managed by releaseExternalResources. It results in a deadlock because releaseExternalResources is trying to shutdown the executor which won't return until the thread that has called releaseExternalResources returns (which it can't). I would guess that you're calling releaseExternalResources from a thread managed by the executor passed to OioClientSocketChannelFactory possibly from within a handler. This won't work. You need to call it from a completely separate thread. One option is to block your main application thread until you're ready to shutdown signal the application thread and have it call releaseExternalResources just before your application exits. Amazing!!! It worked thanks you :)"
164,A,use netty developing a game please help me? I am a student the latest in the study netty feel it great. I want to use it to write a timely interactive little game. Don't know how to write disposal layer. Separate processing business logic module Handler in how to deal with it? Do not know how to start. thank you The user guide http://netty.io/docs/stable/guide/html/ is also a good place to start. Remember to click on the javadoc links because the javadoc contains alot of information.  I think the best start would be to have a look at the examples [1] that are provided by netty. Once you are done with that come back with more specific questions. [1] https://github.com/netty/netty/tree/3/src/main/java/org/jboss/netty/example  Here is a Netty Game Server I have written and published to Github. This has both client and the server side of a multi player game. It maybe a bit more involved than your requirements but the wiki page might help you out to understand netty usage. thank you very much.
165,A,"Proper way to pool client channels in netty? I'm getting a java.nio.channels.NotYetConnectedException in the following code because I'm trying to write to a channel that is not yet open. Essentially what I have is a channel pool in which I grab a channel to write to if one is free and I create a new channel if one is not available. My problem is that when I create a new channel the channel is not ready for writing when I call connect and I don't want to wait for the connection to open before returning because I don't want to block the thread. What's the best way to do this? Also is my logic for retrieving/returning channels valid? See code below. I have a simple connection pool like the following: private static class ChannelPool { private final ClientBootstrap cb; private Set<Channel> activeChannels = new HashSet<Channel>(); private Deque<Channel> freeChannels = new ArrayDeque<Channel>(); public ChannelPool() { ChannelFactory clientFactory = new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); cb = new ClientBootstrap(clientFactory); cb.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline( new HttpRequestEncoder() new HttpResponseDecoder() new ResponseHandler()); } }); } private Channel newChannel() { ChannelFuture cf; synchronized (cb) { cf = cb.connect(new InetSocketAddress(""localhost"" 18080)); } final Channel ret = cf.getChannel(); ret.getCloseFuture().addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture arg0) throws Exception { System.out.println(""channel closed?""); synchronized (activeChannels) { activeChannels.remove(ret); } } }); synchronized (activeChannels) { activeChannels.add(ret); } System.out.println(""returning new channel""); return ret; } public Channel getFreeChannel() { synchronized (freeChannels) { while (!freeChannels.isEmpty()) { Channel ch = freeChannels.pollFirst(); if (ch.isOpen()) { return ch; } } } return newChannel(); } public void returnChannel(Channel ch) { synchronized (freeChannels) { freeChannels.addLast(ch); } } } I'm trying to use this inside a handler as follows: private static class RequestHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) { final HttpRequest request = (HttpRequest) e.getMessage(); Channel proxyChannel = pool.getFreeChannel(); proxyToClient.put(proxyChannel e.getChannel()); proxyChannel.write(request); } } Instead of adding the new channel to activeChannels immediately after bootstrap.connect(..) you have to add a listener to the ChannelFuture which was returned by bootstrap.connect(..) and add the channel to activeChannels in the added listener. That way getFreeChannel() will never get the channel that is not connected yet. Because it is likely that activeChannels is empty even if you called newChannel() (newChannel() will return even before connection is established) you have to decide what to do in such a case. If I were you I would change the return type of getFreeChannel() from Channel to ChannelFuture so that the caller gets notified when the free channel is ready. I don't suppose you have any ideas why I'm still getting 'connection reset by peer' (see http://stackoverflow.com/questions/15818767/what-events-do-i-need-to-listen-to-in-order-to-reuse-a-client-connection-in-nett)."
166,A,"Netty java getting data from ByteBuf How to get a byte array from ByteBuf efficiently in the code below? I need to get the array and then serialize it. package testingNetty; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; public class ServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx Object msg) { System.out.println(""Message receive""); ByteBuf buff = (ByteBuf) msg; // There is I need get bytes from buff and make serialization byte[] bytes = BuffConvertor.GetBytes(buff); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { // Close the connection when an exception is raised. cause.printStackTrace(); ctx.close(); } } So what's problem is? What do you mean by bytes massive in the above context? Bytes massive means a byte[] wich contains seriziable object Can you please post the complete code. Also mention the which version of netty you are using? I use 4.0.9 version of Netty ByteBuf buf = ... byte[] bytes = new byte[buf.readableBytes()]; buf.readBytes(bytes); If you don't want the readerIndex to change: ByteBuf buf = ... byte[] bytes = new byte[buf.readableBytes()]; int readerIndex = buf.readerIndex(); buf.getBytes(readerIndex bytes);"
167,A,Exception in netty io.netty.util.concurrent.BlockingOperationException: I am new to netty and learning the basis of nettty but when i add some part sendResponseHtml(request ctx.channel() HttpResponseStatus.OK array); after i am getting following error. can any one suggest the reason behind the exception . and i am not able to handle where the exception occured. io.netty.util.concurrent.BlockingOperationException: AbstractChannel$CloseFuture@3b8e2477(incomplete) at io.netty.util.concurrent.DefaultPromise.checkDeadLock(DefaultPromise.java:391) at io.netty.channel.DefaultChannelPromise.checkDeadLock(DefaultChannelPromise.java:157) at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:252) at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:129) at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:28) at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:219) at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:117) at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:28) at com.gps.concurrent.ffdfdfd.exceptionCaught(ffdfdfd.java:4045) at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:271) at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:249) at io.netty.channel.ChannelHandlerAdapter.exceptionCaught(ChannelHandlerAdapter.java:79) at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:271) at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:249) at io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:131) at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:271) at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:249) at io.netty.channel.DefaultChannelPipeline.fireExceptionCaught(DefaultChannelPipeline.java:775) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.handleReadException(AbstractNioByteChannel.java:82) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:156) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116) at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137) at java.lang.Thread.run(Thread.java:745) You MUST NOT call ChannelFuture.sync() in your ChannelHandler. Show me the exact code and stack trace. not working i removed .sync() from java code. it works when i apply at caught exception. @Norman - The sync from the handler was indeed my issue and clearing it fixed it so thank you. Can you give some background as to what is happening in the code to make that statement a poor choice?
168,A,"The netty server seems to be blocked when I add a ExecutionHandler? THE SCENE: I am writing a echo client and server. The data being transfered is a string: Client encode a stringand send it to server. Server recv data decode string then encode the received string send it back to client. The above process will be repeated 100000 times.(Note: the connection is persistent). DEFERENT CONTIONS: When I run ONE server and TWO client at the same time everything is okevery client receives 100000 messages and terminated normally. But When I add a ExecutionHandler on server and then run ONE server and TWO client at the same time one client will never terminate and the network traffic is zero. I cant locate the key point of this problem for now will you give me some suggestions? MY CODE: string encoder  string decoder client handler  server handler  client main server main. //Decoder======================================================= import java.nio.charset.Charset; import org.jboss.netty.buffer.ChannelBuffer; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.handler.codec.frame.FrameDecoder; public class Dcd extends FrameDecoder { public static final Charset cs = Charset.forName(""utf8""); @Override protected Object decode(ChannelHandlerContext ctx Channel channel ChannelBuffer buffer) throws Exception { if (buffer.readableBytes() < 4) { return null; } int headlen = 4; int length = buffer.getInt(0); if (buffer.readableBytes() < length + headlen) { return null; } String ret = buffer.toString(headlen length cs); buffer.skipBytes(length + headlen); return ret; } } //Encoder ======================================================= import org.jboss.netty.buffer.ChannelBuffer; import org.jboss.netty.buffer.ChannelBuffers; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.handler.codec.oneone.OneToOneEncoder; public class Ecd extends OneToOneEncoder { @Override protected Object encode(ChannelHandlerContext ctx Channel channel Object msg) throws Exception { if (!(msg instanceof String)) { return msg; } byte[] data = ((String) msg).getBytes(); ChannelBuffer buf = ChannelBuffers.dynamicBuffer(data.length + 4 ctx .getChannel().getConfig().getBufferFactory()); buf.writeInt(data.length); buf.writeBytes(data); return buf; } } //Client handler ======================================================= import java.util.concurrent.atomic.AtomicInteger; import java.util.concurrent.atomic.AtomicLong; import java.util.logging.Level; import java.util.logging.Logger; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelStateEvent; import org.jboss.netty.channel.Channels; import org.jboss.netty.channel.ExceptionEvent; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.SimpleChannelUpstreamHandler; /** * Handler implementation for the echo client. It initiates the ping-pong * traffic between the echo client and server by sending the first message to * the server. */ public class EchoClientHandler extends SimpleChannelUpstreamHandler { private static final Logger logger = Logger .getLogger(EchoClientHandler.class.getName()); private final AtomicLong transferredBytes = new AtomicLong(); private final AtomicInteger counter = new AtomicInteger(0); private final AtomicLong startTime = new AtomicLong(0); private String dd; /** * Creates a client-side handler. */ public EchoClientHandler(String data) { dd = data; } public long getTransferredBytes() { return transferredBytes.get(); } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) { // Send the first message. Server will not send anything here // because the firstMessage's capacity is 0. startTime.set(System.currentTimeMillis()); Channels.write(ctx.getChannel() dd); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { // Send back the received message to the remote peer. transferredBytes.addAndGet(((String) e.getMessage()).length()); int i = counter.incrementAndGet(); int N = 100000; if (i < N) { e.getChannel().write(e.getMessage()); } else { ctx.getChannel().close(); System.out.println(N * 1.0 / (System.currentTimeMillis() - startTime.get()) * 1000); } } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { // Close the connection when an exception is raised. logger.log(Level.WARNING ""Unexpected exception from downstream."" e.getCause()); e.getChannel().close(); } } //Client main ======================================================= import java.net.InetSocketAddress; import java.util.ArrayList; import java.util.List; import java.util.concurrent.Executors; import org.jboss.netty.bootstrap.ClientBootstrap; import org.jboss.netty.channel.ChannelFuture; import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.channel.Channels; import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory; /** * Sends one message when a connection is open and echoes back any received data * to the server. Simply put the echo client initiates the ping-pong traffic * between the echo client and server by sending the first message to the * server. */ public class EchoClient { private final String host; private final int port; public EchoClient(String host int port) { this.host = host; this.port = port; } public void run() { // Configure the client. final ClientBootstrap bootstrap = new ClientBootstrap( new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); // Set up the pipeline factory. bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline(new Dcd() new Ecd() new EchoClientHandler(""abcdd"")); } }); bootstrap.setOption(""sendBufferSize"" 1048576); bootstrap.setOption(""receiveBufferSize"" 1048576); bootstrap.setOption(""tcpNoDelay"" true); bootstrap.setOption(""writeBufferLowWaterMark"" 32 * 1024); bootstrap.setOption(""writeBufferHighWaterMark"" 64 * 1024); List<ChannelFuture> list = new ArrayList<ChannelFuture>(); for (int i = 0; i < 1; i++) { // Start the connection attempt. ChannelFuture future = bootstrap.connect(new InetSocketAddress( host port)); // Wait until the connection is closed or the connection // attempt // fails. list.add(future); } for (ChannelFuture f : list) { f.getChannel().getCloseFuture().awaitUninterruptibly(); } // Shut down thread pools to exit. bootstrap.releaseExternalResources(); } private static void testOne() { final String host = ""192.168.0.102""; final int port = 8000; new EchoClient(host port).run(); } public static void main(String[] args) throws Exception { testOne(); } } //server handler ======================================================= import java.util.concurrent.atomic.AtomicLong; import java.util.logging.Level; import java.util.logging.Logger; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.Channels; import org.jboss.netty.channel.ExceptionEvent; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.SimpleChannelUpstreamHandler; /** * Handler implementation for the echo server. */ public class EchoServerHandler extends SimpleChannelUpstreamHandler { private static final Logger logger = Logger .getLogger(EchoServerHandler.class.getName()); private final AtomicLong transferredBytes = new AtomicLong(); public long getTransferredBytes() { return transferredBytes.get(); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { // Send back the received message to the remote peer. transferredBytes.addAndGet(((String) e.getMessage()).length()); Channels.write(ctx.getChannel() e.getMessage()); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { // Close the connection when an exception is raised. logger.log(Level.WARNING ""Unexpected exception from downstream."" e.getCause()); e.getChannel().close(); } } //Server main ======================================================= import java.net.InetSocketAddress; import java.util.concurrent.Executors; import org.jboss.netty.bootstrap.ServerBootstrap; import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.channel.Channels; import org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory; import org.jboss.netty.handler.execution.ExecutionHandler; import org.jboss.netty.handler.execution.OrderedMemoryAwareThreadPoolExecutor; /** * Echoes back any received data from a client. */ public class EchoServer { private final int port; public EchoServer(int port) { this.port = port; } public void run() { // Configure the server. ServerBootstrap bootstrap = new ServerBootstrap( new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); System.out.println(Runtime.getRuntime().availableProcessors() * 2); final ExecutionHandler executionHandler = new ExecutionHandler( new OrderedMemoryAwareThreadPoolExecutor(16 1048576 1048576)); // Set up the pipeline factory. bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { System.out.println(""new pipe""); return Channels.pipeline(new Dcd() new Ecd() executionHandler new EchoServerHandler()); } }); bootstrap.setOption(""child.sendBufferSize"" 1048576); bootstrap.setOption(""child.receiveBufferSize"" 1048576); bootstrap.setOption(""child.tcpNoDelay"" true); bootstrap.setOption(""child.writeBufferLowWaterMark"" 32 * 1024); bootstrap.setOption(""child.writeBufferHighWaterMark"" 64 * 1024); // Bind and start to accept incoming connections. bootstrap.bind(new InetSocketAddress(port)); } public static void main(String[] args) throws Exception { int port = 8000; new EchoServer(port).run(); } } Can you please post thread stacks for hanged clients/server when they hanged? You can obtains them via jstack utility or jvisualvm (JDK) or send ""kill -3 JAVA_PID"" signal if you're running linux/unix box (see http://stackoverflow.com/questions/4876274/kill-3-to-get-java-thread-dump) I added some log on key point it seems that the Decoder on server fails to execute ""Channels.fireMessageReceived(context result remoteAddress)""so the message can't reach to EchoServerHandler  it is lost. I am looking for the reason now. Is there any exception during the call to fireMessageReceived? Please post it Hi SirVaulterScoff thanks for your help. I have done this before the client and server are all blocked on Selector.poll(). It means that they are all wait on reading  this seems correct. do you need more details? Hi SirVaulterScoff there is no exception it is lost silently. Please check this post http://stackoverflow.com/questions/8688322/exception-when-client-sends-message-to-server I'd also suggest you to connect to your client with debugger and set exception breakpoint (Intellij Idea can set that kind of breakpoints - not sure about eclipse) and see if you get the exception I am debugging it with netty source code  maybe I will find out the reason tommorow  and post it here. I have found the reason now it is a hard work but full with pleasure. When added a ExecutionHandler the message will be wrapped into a Runnable task and will be executed in a ChildExecutor. The key point is here : A task maybe added to ChildExecutor when the executor almostly exit  then is will be ignored by the ChildExecutor. I added three lines code and some comments the final code looks like below and it works nowshould I mail to the author? : private final class ChildExecutor implements Executor Runnable { private final Queue<Runnable> tasks = QueueFactory .createQueue(Runnable.class); private final AtomicBoolean isRunning = new AtomicBoolean(); public void execute(Runnable command) { // TODO: What todo if the add return false ? tasks.add(command); if (!isRunning.get()) { doUnorderedExecute(this); } else { } } public void run() { // check if its already running by using CAS. If so just return // here. So in the worst case the thread // is executed and do nothing boolean acquired = false; if (isRunning.compareAndSet(false true)) { acquired = true; try { Thread thread = Thread.currentThread(); for (;;) { final Runnable task = tasks.poll(); // if the task is null we should exit the loop if (task == null) { break; } boolean ran = false; beforeExecute(thread task); try { task.run(); ran = true; onAfterExecute(task null); } catch (RuntimeException e) { if (!ran) { onAfterExecute(task e); } throw e; } } //TODO NOTE (I added): between here and ""isRunning.set(false)""some new tasks maybe added. } finally { // set it back to not running isRunning.set(false); } } //TODO NOTE (I added): Do the remaining works. if (acquired && !isRunning.get() && tasks.peek() != null) { doUnorderedExecute(this); } } }  This was a bug and will be fixed in 3.4.0.Alpha2. See https://github.com/netty/netty/issues/234"
169,A,"Netty 4 (A1) - AttributeMap with multiple handlers I'm trying to pass an object from one handler to another using the ChannelContext.attr() method: private class TCPInitializer extends ChannelInitializer<SocketChannel> { @Override public void initChannel(final SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new ReadTimeoutHandler(mIdleTimeout)); pipeline.addLast(new HostMappingHandler<SyslogHandler>(mRegisteredClients mChannels)); pipeline.addLast(new DelimiterBasedFrameDecoder(MAX_FRAME_SIZE Delimiters.lineDelimiter())); pipeline.addLast(new Dispatcher()); } } The HostMappingHandler is a template class that maps hosts to data: public class HostMappingHandler<T> extends ChannelStateHandlerAdapter { public static final AttributeKey<HostMappedObject> HOST_MAPPING = new AttributeKey<HostMappedObject>(""HostMappingHandler.attr""); private final ChannelGroup mChannels; private final Map<String T> mMap; public HostMappingHandler(Map<String T> registrations ChannelGroup channelGroup) { mChannels = channelGroup; mMap = registrations; } @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception { SocketAddress addr = ctx.channel().remoteAddress(); T mappedObj = null; if (addr instanceof InetSocketAddress) { String host = ((InetSocketAddress) addr).getHostName().toLowerCase(); mappedObj = mMap.get(host); } if (mappedObj != null) { // Add the channel to the list so it can be easily removed if unregistered mChannels.add(ctx.channel()); // Attach the host-mapped object ctx.attr(HOST_MAPPING).set(new HostMappedObject<T>(mappedObj)); } else { log.debug(""Bad host ["" + addr + ""]; aborting connection request""); ctx.channel().close(); } super.channelRegistered(ctx); } @Override public void inboundBufferUpdated(ChannelHandlerContext ctx) throws Exception { // Find the parser for this host. If the host is no longer registered // disconnect the client. if (ctx.channel().remoteAddress() instanceof InetSocketAddress) { InetSocketAddress addr = (InetSocketAddress) ctx.channel().remoteAddress(); T handler = mMap.get(addr.getHostName().toLowerCase()); if (handler == null) { log.debug(""Host no longer registered""); ctx.channel().close(); } else { log.debug(""Sanity Check: "" + ctx.attr(HostMappingHandler.HOST_MAPPING).get()); } } super.inboundBufferUpdated(ctx); } // ================================================== public static class HostMappedObject<C> { private final C mObj; public HostMappedObject(final C in) { mObj = in; } public C get() { return mObj; } } } And the dispatcher is currently very simple: private static class Dispatcher extends ChannelInboundMessageHandlerAdapter<Object> { @Override public void messageReceived(final ChannelHandlerContext ctx final Object msg) throws Exception { HostMappingHandler.HostMappedObject wrapper = ctx.attr(HostMappingHandler.HOST_MAPPING).get(); log.debug(""Received: "" + wrapper); } } Incidentally the initializer and dispatcher are private classes of a ""server"" object. However when I run a unit test that registers the localhost and attempts to connect to it it fails and my debug output shows: HostMappingHandler.inboundBufferUpdated: Sanity Check: test.comms.netty.HostMappingHandler$HostMappedObject@eb017e Dispatcher.messageReceived: Received: null So the mapping is definitely preserved between channel registration and receiving an inbound message in the HostMapper class and investigating a little further in the debugger shows that the attribute map for the context in Dispatcher does have an entry - the problem is that the value is NULL and not the object. Am I missing something obvious or just an alpha bug? Edit: I've worked around the problem for now by attaching the data to the Dispatcher's context by having the HostMappingHandler also take a class to attach to. The bug appears to be that setting an attribute in a handler's ChannelHandlerContext causes the attribute to appear in another handler with the correct key but NULL value. Without knowing the desired workflow the bug is that either the key shouldn't appear at all or the value should not be null. public HostMappingHandler(final Map<String T> registrations final ChannelGroup channelGroup final Class<? extends ChannelHandler> channelHandler) { mChannels = channelGroup; mMap = registrations; mHandler = channelHandler; } //... @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception { //... // Attach the host-mapped object ctx.pipeline().context(mHandler).attr(HOST_MAPPING).set(new HostMappedObject<T>(mappedObj)); //... } AttributeMap in ChannelHandlerContext is bound to the context and that's why the attribute you set in one context is not visible in other context. Please note that Channel also implements AttributeMap. You can just use the attribute map bound to a channel: ctx.channel().attr(...) ...; Thanks! I got confused when the key appeared in the other ChannelHandlerContext just with a null value. Thanks this solved my problem also corrected my thought that `ChannelHandlerContext` is only for current handler not for all handlers."
170,A,Do LocalChannel/LocalServerChannel serialize data written to them? I would like to use LocalChannel & LocalServerChannel to have an in-jvm link between a client and server. I was wondering if i can pass objects unchanged via the channel between them without having to encode/decode them along the way. You can pass the objects without usual encoding/decoding the message events are exchanged between paired channels directly. Is there an example of this around? Or is it at simple as the the message attached on messageReceived is the original object I sent through the channel?
171,A,Queuing messages to prevent Server failure I have a Netty client sending messages asynchronously to a TCP Netty server. In order to preserve the order the server ChannelPipeline has and ExecutionHandler coupled with an OrderedMemoryAwareThreadPoolExecutor. My understanding is messages sent to the server are queued up in the channel. If the server dies while messages queued up in the channel I need to prevent message loss. My current solution is to add each message to a queue on the Client side and only remove them from the queue when I receive an Ack message from the server for each message. What do you think? What you're suggesting is fairly common and is sometimes known as a send window. I've used similar techniques before although I stored my sent messages in a map because the server could theoretically process and acknowledge them out of order. TCP uses similar techniques as do protocols like SMPP and even JMS providers that allow asynchronous sends (hornetQ for example). HTTP pipelining is similar although that does require requests to be processed and acknowledged in order. One thing you have to consider is what the server does with retransmitted messages. It may have already processed the original message but the ack was lost before it reached your client. For example if the messages are requesting a payment of some kind you don't want to charge the person twice because the ack got lost.
172,A,The Right Way To Minimize Memory Usage With Netty I have two scenarios in Netty where I am trying to minimize memory copies and optimize memory usage: (1) Reading a very large frame (20 Megabites). (2) Reading lots of very little frames (20 megabites at 50 bites per frame) to rebuild into one message at a higher level in the pipeline. For the first scenario as I get a length at the beginning of the frame I extended FrameDecoder. Unfortunately as I don't see how to return the length to Netty (I only indicate whether the frame is complete or not) I believe Netty is going through multiple fill buffer copy and realloc cycles thus using for more memory than is required. Is there something I am missing here? Or should I be avoiding the FrameDecoder entirely if I expect this scenario? In the second scenario I am currently creating a linked list of all the little frames which I wrap using ChannelBuffers.wrappedBuffer (which I can then wrap in a ChannelBufferInputStream) but I am again using far more memory than I expected to use (perhaps because the allocated ChannelBuffers have spare space?). Is this the right way to use Netty ChannelBuffers? In the end it appeared the best way to handle my FrameDecoder issue was to write my own on top of the SimpleChannelUpstreamHandler. As soon as I determined the length from the header I created the ChannelBuffer with size exactly matching the length. This (along with other changes) significantly improved the memory performance of my application.  There is a specialized version of frame decoder called LengthFieldBasedFrameDecoder. Its handy when you have a header with message length. It can even extract the message length from header by giving an offset. Actually ChannelBuffers.wrappedBuffer does not creates copies of received data it creates a composite buffer from given buffers so your received frame data will not be copied. If you are holding the composite buffers/ your custom wrapper in the code and forgot to nullify memory leaks can happen. These are practices I follow Allocate direct buffers for long lived objects slice it on use. when I want to join/encode multiple buffers into one big buffer. I Use ChannelBuffers.wrappedBuffer If I have a buffer and want to do something with it/portion of it I make a slice of it by calling slice or slice(0..) on channel buffer instance If I have a channel buffer and know the position of data which is small I always use getXXX methods If I have a channel buffer which is used in many places for make something out of it always make it modifiable slice it on use. Note: channelbuffer.slice does not make a copy of the data it creates a channel buffer with new reader & write index. I appreciate the response but you are pretty much indicating what I am already doing. The LengthFieldBasedFrameDecoder as it extends Frame Decoder inherits its issues (you can't avoid the fill buffer/realloc and copy cycles). I know that wrappedBuffer does not create copies but I am still using much more memory than expected (heap increased 3-4 times the message size). @Gareth Without seeing the code its hard to tell any thing.I just checked the FrameDecoder and and found out that It is using DynamicChannel buffer witch starts from 256 bytes so I am not sure how its going to grow when you receive 20MBs I think its better to write your own version of FrameDecoder with a fixed buffer.
173,A,netty.io delivering static web content I was wondering if there is a way to deliver static web content (esentially css js and html) using a netty.io instance. I need this together with a web socket server and I would like to have a unique infrastructure. Sure... Just encode it in a FullHttpResponse and write it back. It's all just bytes..
174,A,"Parallel/Multithreaded reading from ByteBuffer/Netty ByteBuff Heyho ByteBuffers as well as netty's ByteBuff use indices to store where they currently ""are"". At the start of my application I load multiple files in ByteBuffers/ByteBuffs to read later from those. Also the bytebuffers are immutable after loading. My problem is now that multiple clients should be able to read from those byte buffers but because they use the same reader/writer indices it won't work. Is there a easy way of maintaining the indices maybe per thread? Does netty have some ""tools"" to achive this? I've already read that nio ByteBuffers do not support multiple threads but is this also true if you only read from them? Basically I'm only looking for a way to send data which is stored in memory very fast over netty. You can call duplicate on the ByteBuf for every new Thread and use the returned ByteBuf. Those will share the same content but not the same indices. ByteBuf duplicate = ByteBuf.duplicate(); k thanks so I should be safe to go :D For my netty buffers I could use Allocator.wrappedBuffer(...) to fix the indices. So reading from multiple threads should be safe right? As long as you use get*() and not read*() yes as read*() will increase the readerIndex."
175,A,How to enable logging done by netty code? I have written an HTTP server using netty framework. I have done logging for the HTTP server (). I also want to enable the logging done inside the netty code.What steps do I need to follow to print the log statements of the netty code? Just configure the InternalLoggerFactory of needed and set the right delegation. By default it will first try to use slf4j log4j and then JUL.
176,A,"UDP Netty setOption ConnectionlessBootstrap or ChannelConfig I'm using Netty 3.6.6 Final and I'm looking to set the sendBufferSize and receiveBufferSize options in a UDP Netty IO Client implementation what is the difference between ConnectionlessBootstrap setOption() and ChannelConfig setOption()? Which of the 2 setOption methods should i utilize or does it matter? DatagramChannelFactory datagramChannelFactory = new NioDatagramChannelFactory(Executors.newCachedThreadPool()); ConnectionlessBootstrap connectionlessBootstrap = new ConnectionlessBootstrap(datagramChannelFactory); connectionlessBootstrap.setPipelineFactory(...); ChannelFuture channelFuture = connectionlessBootstrap.connect(new InetSocketAddress(host port)); channelFuture.awaitUninterruptibly(); Channel channel = channelFuture.getChannel(); ChannelConfig channelConfig = channel.getConfig(); // Now do this: channelConfig.setOption(""sendBufferSize"" udpSendBufferSize); channelConfig.setOption(""receiveBufferSize"" udpReceiveBufferSize); // or do this: connectionlessBootstrap.setOption(""sendBufferSize"" udpSendBufferSize); connectionlessBootstrap.setOption(""receiveBufferSize"" udpReceiveBufferSize); It doesn't matter... Normally you use ChannelConfig per Channel and Bootstrap for all Channels. a follow-on query does setOption on the send and receive Buffer Size modify the system values or just allocate sizes to internal Netty queues? Or do i need to use the sysctl command on linux and ndd command on Solaris to set the Max UDP Buffer Sizes?"
177,A,"Netty Frame Decoder Corrupted on multiple messages I have implemented a NettyDecoder in one of my application The protocol of the application is simple first four characters would be the message length then the message. The frame decoder logic is import java.nio.ByteBuffer; import org.apache.commons.io.IOUtils; import org.jboss.netty.buffer.ChannelBuffer; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.handler.codec.frame.FrameDecoder; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import sun.nio.cs.StandardCharsets; public class ITMDecoder extends FrameDecoder { public static String bytesToStringUTFCustom(byte[] bytes) { char[] buffer = new char[bytes.length >> 1]; for(int i = 0; i < buffer.length; i++) { int bpos = i << 1; char c = (char)(((bytes[bpos]&0x00FF)<<8) + (bytes[bpos+1]&0x00FF)); buffer[i] = c; } return new String(buffer); } protected Object decode(ChannelHandlerContext ctx Channel channel ChannelBuffer buf) throws Exception { Logger logger = LoggerFactory.getLogger(ITMDecoder.class); // Make sure if the length field was received. if (buf.readableBytes() < 4) { // The length field was not received yet - return null. // This method will be invoked again when more packets are // received and appended to the buffer. return null; } // The length field is in the buffer. // Mark the current buffer position before reading the length field // because the whole frame might not be in the buffer yet. // We will reset the buffer position to the marked position if // there's not enough bytes in the buffer. buf.markReaderIndex(); // Read the length field. byte[] twoBytesLength = new byte[4]; for(int i = 0 ; i < 4 ; i++) twoBytesLength[i] = buf.getByte(i); String str = new String(twoBytesLength ""UTF-8""); Short shortValue = Short.parseShort(str); int length = shortValue.intValue() + 4; // Make sure if there's enough bytes in the buffer. if (buf.readableBytes() < length) { // The whole bytes were not received yet - return null. // This method will be invoked again when more packets are // received and appended to the buffer. // Reset to the marked position to read the length field again // next time. buf.resetReaderIndex(); return null; } // There's enough bytes in the buffer. Read it. ChannelBuffer frame = buf.readBytes(length); // Successfully decoded a frame. Return the decoded frame. return frame; } } Channel Pipeline Logic is:  ServerBootstrap bootstrap = new ServerBootstrap( new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( new ITMDecoder() new M3AlertHandler() ); }; }); It works fine when the transaction volume is around 2 tps . However the frame decoder corrupts when transactions are send with higher tps. I have checked the same with Socket workbench with one long message of 2 variable lengths The message i used to sent to the server is Message 1 = 00051234500041234 Repeated the same 1000 times and the sent it in a second the decoder corrupts after 5/6 messages ? Is there anything that I am missing which will actually make it work properly? for(int i = 0 ; i < 4 ; i++) twoBytesLength[i] = buf.getByte(i); You should never assume that the index of the first byte is 0. The index of the first byte is buf.readerIndex(). for (int i = 0; i < 4; i ++) { twoBytesLength[i] = buf.getByte(buf.readerIndex() + i); } You could optimize byte buffer access even further but that's not the scope of the question. Thanks i used readByte() instead i guess this is what the above code pretty much do."
178,A,NIO and Asynchronous IO choice I have written a server which processes requests concurrently using 1 thread per connection socket. But in the future it might grow much so I decided to change it already now for something more scalable as long as threads are quite expensive. I have read about 3 options - raw NIO NIO framework like Netty or Asynchronous IO from java SE7. But I have never used either of those so I am confused which of them to use for my task and how. The task is quite simple: There is a sever which accepts connection. When it accepts one it should allocate something like a listener for incoming requests (right now threads work for me that way). IE. when there is a connection a new thread is not allocated. But when a formatted request comes somehow the JVM invokes the required listener (which is associated with its channel or socket..) and processes the request. Then the thread is returned to the pool or sth and the listener is also waiting for incoming requests. THere might be 10k+ listeners. Also the server itself might send a message to the client at any time asynchronously (so it needs to find the connection from the pool and send the message). Or multicast the message to 1k+ clients. The server accepts a custom protocol so having some connection-break features or message-size functionality is also a bonus. I have been trying to check the above mentioned options for this but I didnt quite get which one best suits my needs as long as I have never worked with any of those. I checked Netty and it seems like very heavyweight. Is my task easy to achieve with NIO or NIO2? Or shall I use sth like MINA or Netty? If it is easy to avoid programming mistakes I would like to stick to raw APIs of java like NIO. But if it error prone maybe its better to work with Netty? Don't program with NIO directly; it's a lot more subtle than it first appears. I don't like AIO either; its threading model is very confusing. My recommendation would be that you go with Netty.
179,A,"Netty 4 - Outbound message at head of pipeline discarded I am using Netty 4 RC1. I initialize my pipeline at the client side: public class NodeClientInitializer extends ChannelInitializer<SocketChannel> { @Override protected void initChannel(SocketChannel sc) throws Exception { // Frame encoding and decoding sc.pipeline() .addLast(""logger"" new LoggingHandler(LogLevel.DEBUG)) // Business logic .addLast(""handler"" new NodeClientHandler()); } } NodeClientHandler has the following relevant code: public class NodeClientHandler extends ChannelInboundByteHandlerAdapter { private void sendInitialInformation(ChannelHandlerContext c) { c.write(0x05); } @Override public void channelActive(ChannelHandlerContext c) throws Exception { sendInitialInformation(c); } } I connect to the server using:  public void connect(final InetSocketAddress addr) { Bootstrap bootstrap = new Bootstrap(); ChannelFuture cf = null; try { // set up the pipeline bootstrap.group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new NodeClientInitializer()); // connect bootstrap.remoteAddress(addr); cf = bootstrap.connect(); cf.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture op) throws Exception { logger.info(""Connect to {}"" addr.toString()); } }); cf.channel().closeFuture().syncUninterruptibly(); } finally { bootstrap.shutdown(); } } So what I basically want to do is to send some initial information from the client to the server after the channel is active (i.e. the connect was successful). However when doing the c.write() I get the following warning and no package is send: WARNING: Discarded 1 outbound message(s) that reached at the head of the pipeline. Please check your pipeline configuration. I know there is no outbound handler in my pipeline but I didn't think I need one (at this point) and I thought Netty would take care to transport the ByteBuffer over to the server. What am I doing wrong here in the pipeline configuration? Netty only handle messages of type ByteBuf by default if you write to the Channel. So you need to wrap it in a ByteBuf. See also the Unpooled class with its static helpers to create ByteBuf instances."
180,A,"Netty: send messages to all (TCP) clients from outside the pipeline I'm migrating my ""plain NIO"" (= I used the packages from the JDK directly) TCP server to Netty 4. I have threads that send messages to all clients like health-checking packets chat message broadcasts direct chat messages to a single client ... using a Collection of SocketChannels that I keep somewhere. How do I do that in Netty? Would it be wise to simply share a ChannelGroup between one of the Netty handlers and the threads that need to send messages? The channel would look like this: public class ChannelCollectorHandler extends ChannelInboundMessageHandlerAdapter<String> { private static final ChannelGroup channels = new DefaultChannelGroup(); public SecureChatServerHandler(ChannelGroup channels) { this.channels = channels; } @Override public void channelActive(final ChannelHandlerContext ctx) throws Exception { channels.add(ctx.channel()); } ... } in all the threads I would then simply do: channels.write(...); will that work? Yes this will work without problems. ChannelGroup was designed for tasks like this. Yes... It's the same as call Channel.write for each of them Where will it start processing the outbound messages on the pipeline? Always at the ""end"" (so the first outbound handler) or ...?"
181,A,"Reading XML data in Netty 3.6.x I'm new to Netty and Java and I'm trying to build up a simple Netty server that reads XML from a separate client (The client will keep sending me XMLs with a fixed format). For each XML I need to do some processing. I've looked at examples at echo-client/server and Object echo-client/server and trying to decide which one I should model after I'm not exactly sure if I should use a ChannelInboundByteHandlerAdapter or a ChannelInboundMessageAdapter? And are there utility packages in Netty 3.6.x that handle demarshalling XMLs? How should I handle converting the raw data to XML? Also I don't know how stable 4.0.0.Beta is since this app is not too complicated I wonder if it's just OK to use the 3.6.x.Final as it's probably more stable. Thanks a bunch!! Create XMLDecoder XMLEncoder class(extends OneToOneEncoder) in Server program. And add ChannelPipeline as keys ""decoder"" ""encoder"". In decode of XMLDecoder class Convert received xml to custom class using JAXB. If a server send to client using xml convert response custom class to xml string in encode method of XmlEncoder. sorry I have limited English proficiency. Thanks! I think I got what I asked for."
182,A,"How to tell for a particular request that all available worker threads are BUSY I have a high-rate UDP server using Netty (3.6.6-Final) but notice that the back-end servers can take 1 to 10 seconds to respond - i have no control over those so cannot improve latency there. What happens is that all handler worker threads are busy waiting for response and that any new request must wait to get processed over time this response comes very late. Is it possible to discover for a given request that the thread pool is exhausted so as to intercept the request early and issue a server busy response? I would use an ExecutionHandler configured with an appropriate ThreadPoolExecutor with a max thread count and a bounded task queue. By choosing differenr RejectedExecutionHandler policies you can either catch the RejectedExecutionException to answer with a ""server busy"" or use a ""caller runs policy"" in which case the IO worker thread will execute the task and create a push back (but that is what you wanted to avoid). Either way an execution handler with a limited capacity is the way forward."
183,A,"MQTT over WebSockets using Netty? I want to use MQTT over Websockets. In Netty using Websockets is quite easy: ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""codec-http"" new HttpServerCodec()); pipeline.addLast(""aggregator"" new HttpObjectAggregator(65536)); pipeline.addLast(""handler"" new WebSocketServerHandler()); I've found MQTT broker (moquette) which is based on Netty.  NettyMQTTHandler handler = new NettyMQTTHandler(); ServerBootstrap b = new ServerBootstrap(); b.group(m_bossGroup m_workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); //pipeline.addFirst(""metrics"" new BytesMetricsHandler(m_metricsCollector)); pipeline.addFirst(""idleStateHandler"" new IdleStateHandler(0 0 Constants.DEFAULT_CONNECT_TIMEOUT)); pipeline.addAfter(""idleStateHandler"" ""idleEventHandler"" new MoquetteIdleTimoutHandler()); //pipeline.addLast(""logger"" new LoggingHandler(""Netty"" LogLevel.ERROR)); pipeline.addLast(""decoder"" new MQTTDecoder()); pipeline.addLast(""encoder"" new MQTTEncoder()); pipeline.addLast(""metrics"" new MessageMetricsHandler(m_metricsCollector)); pipeline.addLast(""handler"" handler); } }) .option(ChannelOption.SO_BACKLOG 128) .option(ChannelOption.SO_REUSEADDR true) .childOption(ChannelOption.SO_KEEPALIVE true); So in the theory I should be able to send MQTT over Websocket but I have no idea if it possible using Netty? Does any have any clues or ideas how to do that? Should I use MessageToMessageCodec and BinaryWebSocketFrame? Cheers! Let me assume your MQTTDecoder consumes ByteBufs and produces some MQTT message objects and MQTTEncoder does the opposite which is usually the case. Then the ByteBufs your codec works with is not a Web Socket message. They need to become the payloads of the Web Socket frames. I would insert the following handlers into the pipeline: A MessageToMessageDecoder that transforms a WebSocket text (or binary) frame into a ByteBuf so that MQTTDecoder can consume it. The transformation should be very simple - just get the content of the Web Socket frame. A MessageToMessageEncoder that transforms a ByteBuf into a Web Socket text (or binary) frame so that Netty's WebSocketFrameEncoder can consume it. The transformation should also be very simple - just wrap the ByteBuf encoded by MQTTEncoder with a Web Socket frame object. The resulting pipeline will look like the following: HttpResponseEncoder HttpRequestDecoder HttpObjectAggregator(65536) WebSocketServerProtocolHandler(""/your-websocket-endpoint-path"") WebSocketFrameToByteBufDecoder extends MessageToMessageDecoder ByteBufToWebSocketFrameEncoder extends MessageToMessageEncoder MQTTEncoder MQTTDecoder MessageMetricsHandler handler WebSocketServerProtocolHandler will perform necessary handshaking with your web socket client and insert WebSocketFrameEncoder and WebSocketFrameDecoder right before WebSocketFrameToByteBufDecoder. The resulting pipeline after successful handshake will look like the following: WebSocketFrameEncoder WebSocketFrameDecoder WebSocketFrameToByteBufDecoder extends MessageToMessageDecoder ByteBufToWebSocketFrameEncoder extends MessageToMessageEncoder MQTTEncoder MQTTDecoder MessageMetricsHandler handler Thanks for the clues. I've simply changed MQTTDecoder and MQTTEncoder to MessageToMessageDecoder / MessageToMessageEncoder and it works like a charm ;-) Code: https://code.google.com/p/moquette-mqtt/issues/attachmentText?id=37&aid=370006000&name=NettyAcceptor.java&token=mb3cYVwbJqfgqAU19vC3QjEqjIw%3A1395163623412 Yeah if you have full control over your codec implementation you can even do that."
184,A,"How do I shutdown and reconfigure an AsyncHttpClient that is using NettyAsyncHttpProvider I'm constructing an AsyncHttpClient like this: public AsyncHttpClient getAsyncHttpClient() { AsyncHttpClientConfig config = new AsyncHttpClientConfig.Builder() .setProxyServer(makeProxyServer()) .setRequestTimeoutInMs((int) Duration.create(ASYNC_HTTP_REQUEST_TIMEOUT_MIN TimeUnit.MINUTES).toMillis()) .build(); return new AsyncHttpClient(new NettyAsyncHttpProvider(config) config); } This gets called once at startup and then the return value is passed around and used in various places. makeProxyServer() is my own function to take my proxy settings an return a ProxyServer object. What I need to do is be able to change the proxy server settings and then recreate the AsyncHttpClient object. But I don't know how to shut it down cleanly. A bit of searching on leads me to believe that close() isn't gracefull. I'm worried about spinning up a whole new executor and set of threads every time the proxy settings change. This won't be often but my application is very long-running. I know I can use RequestBuilder.setProxyServer() for each request but I'd like to have it set in one spot so that all callers of my asyncHttpClient instance obey the system-wide proxy settings without each developer having to remember to do it. What's the right way to re-configure or teardown and rebuild a Netty-based AsyncHttpClient? Heh I just got the tumbleweed badge for this question. As I mentioned in the question I worked around this by doing setProxyServer() per-request but the overall problem of being able to shutdown and rebuild a Netty-based AsyncHttpClient seems like it would interest more people. You should be holding a RequestHandle instance for all your unfinished requests. When you want to shut down you can loop through and call isFinished() on all of them until you they are all done. Then you know you can safely close it and no pending requests will be killed. Once it's closed just build a new one. Don't try to reuse the existing one. If you have references to it around change those to reference a Factory that will return the current one. This seems like it should be a comment to the answer about close() not a whole new answer. Edited to recommend ""building"" a new Object instead of trying to re-use the current one. The mentioned concern was around spinning up new executors because it's a long lived app. Since close will stop existing ones (according to @NSH) this would not be an issue.  The problem with using AsyncHttpClient.close() is that it shuts down the thread pool executor used by the provider then there is no way to re-use the client without re-building it because as per documentation the executor instance cannot be reused once ts is shutdown. So there is no way but re-build the client if you go that way (unless you implement your own ExecutorService that would have another shutdown logic but it is a long way to go IMHO). However from looking into the implementation of NettyAsyncHttpProvider I can see that it stores the reference to the given AsyncHttpClientConfiginstance and calls its getProxyServerSelector() to get the proxy settings for every new NettyAsyncHttpProvider.execute(Request...) invocation (i.e. for every request executed by AsyncHttpClient). Then if we could make the getProxyServerSelector() return the configurable instance of ProxyServerSelector that would do the thing. Unfortunately AsyncHttpClientConfig is designed to be a read-only container instantiated by AsyncHttpClientConfig.Builder. To overcome this limitation we would have to hack it using say ""wrap/delegate"" approach: Create a new class derived from AsyncHttpClientConfig. The class should wrap the given separate AsyncHttpClientConfig instance and implement the delegation of the AsyncHttpClientConfig getters to that instance. To be able to return the proxy selector we want at any given point of time we make this setting mutable in a this wrapper class and expose the setter for it. Example: public class MyAsyncHttpClientConfig extends AsyncHttpClientConfig { private final AsyncHttpClientConfig config; private ProxyServerSelector proxyServerSelector; public MyAsyncHttpClientConfig(AsyncHttpClientConfig config) { this.config = config; } @Override public int getMaxTotalConnections() { return config.maxTotalConnections; } @Override public int getMaxConnectionPerHost() { return config.maxConnectionPerHost; } // delegate the others but getProxyServerSelector() ... @Override public ProxyServerSelector getProxyServerSelector() { return proxyServerSelector == null ? config.getProxyServerSelector() : proxyServerSelector; } public void setProxyServerSelector(ProxyServerSelector proxyServerSelector) { this.proxyServerSelector = proxyServerSelector; } } Now in your example wrap your AsyncHttpClient config instance with our new wrapper and use it to configure the AsyncHttpClient: Example: MyAsyncHttpClientConfig myConfig = new MyAsyncHttpClientConfig(config); return new AsyncHttpClient(new NettyAsyncHttpProvider(myConfig) myConfig); Whenever you invoke myConfig.setProxyServerSelector(newSelector) the new request executed by NettyAsyncHttpProvider instance in your client will use the new proxy server settings. A few hints/warnings: This approach relies on the internal implementation of NettyAsyncHttpProvider; therefore make your own judgement on maintainability future Netty libraries versions upgrade strategy etc. You could always look at the Netty source code before upgrading to the new version. At the current point I personally think it is unlikely to change too much to invalidate this implementation. You could get ProxyServerSelector for ProxyServer by using com.ning.http.util.ProxyUtils.createProxyServerSelector(proxyServer) - that's exactly what AsyncHttpClientConfig.Builder does. The given example has no synchronization logic for accessing proxyServerSelector; you may want to add some as your application logic needs. Maybe it is a good idea to submit a feature request for AsyncHttpClient to be able to setup a ""configuration factory"" for the AsyncHttpProvider so all these complications would vanish :-) In fact AsyncHttpClientConfig has a protected proxyServerSelector field of ProxyServerSelector type; it could be re-used in MyAsyncHttpClientConfig to store the mutable ProxyServerSelector value."
185,A,"Failed to create a selector / Unable to establish loopback connection / Connection timed out I am running a Java socket.io server (com.corundumstudio.socketio implementation) it used to work OK but now just after I start() the server I get this error message: Exception in thread ""main"" org.jboss.netty.channel.ChannelException: Failed to c reate a selector. at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(A bstractNioSelector.java:338) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(Abstrac tNioSelector.java:96) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractN ioWorker.java:51) at org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45 ) at org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWork erPool.java:45) at org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWork erPool.java:28) at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.newWorker(Ab stractNioWorkerPool.java:99) at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(Abstrac tNioWorkerPool.java:69) at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool .java:39) at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool .java:33) at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<ini t>(NioServerSocketChannelFactory.java:149) at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<ini t>(NioServerSocketChannelFactory.java:131) at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<ini t>(NioServerSocketChannelFactory.java:115) at com.corundumstudio.socketio.SocketIOServer.start(SocketIOServer.java: 76) at biu_nlp_net.CommonSocketIOServer.start(CommonSocketIOServer.java:67) at biu_nlp_net.LexicalEntailmentServer.main(LexicalEntailmentServer.java :188) **Caused by: java.io.IOException: Unable to establish loopback connection** at sun.nio.ch.PipeImpl$Initializer.run(Unknown Source) at sun.nio.ch.PipeImpl$Initializer.run(Unknown Source) at java.security.AccessController.doPrivileged(Native Method) at sun.nio.ch.PipeImpl.<init>(Unknown Source) at sun.nio.ch.SelectorProviderImpl.openPipe(Unknown Source) at java.nio.channels.Pipe.open(Unknown Source) at sun.nio.ch.WindowsSelectorImpl.<init>(Unknown Source) at sun.nio.ch.WindowsSelectorProvider.openSelector(Unknown Source) at java.nio.channels.Selector.open(Unknown Source) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(A bstractNioSelector.java:336) ... 15 more **Caused by: java.net.ConnectException: Connection timed out: connect** at sun.nio.ch.Net.connect0(Native Method) at sun.nio.ch.Net.connect(Unknown Source) at sun.nio.ch.Net.connect(Unknown Source) at sun.nio.ch.SocketChannelImpl.connect(Unknown Source) at java.nio.channels.SocketChannel.open(Unknown Source) ... 25 more I run this with Java 7 on Windows 2003. This could be because of a firewall problem... You will need to check in detail here. I don't think so because sometimes it does work OK. Definitely not. The selector doesn't use any network resources except a local socket created on I think 127.0.0.2. Nothing to do with any firewall.  Problem solved after rebooting the Windows machine. Probably a tired server..."
186,A,extends ChannelHandlerAdapter but does not override or implement a method from ChannelHandlerAdapter What does this method from EchoClientHandler override? @Override public void channelActive(ChannelHandlerContext ctx) { ctx.writeAndFlush(firstMessage); } compile error: -do-compile: [mkdir] Created dir: /home/thufir/NetBeansProjects/NettyEcho/build/empty [mkdir] Created dir: /home/thufir/NetBeansProjects/NettyEcho/build/generated-sources/ap-source-output [javac] Compiling 4 source files to /home/thufir/NetBeansProjects/NettyEcho/build/classes [javac] /home/thufir/NetBeansProjects/NettyEcho/src/io/netty/example/echo/EchoClientHandler.java:27: error: method does not override or implement a method from a supertype [javac] @Override [javac] ^ code from github: package io.netty.example.echo; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; /** * Handler implementation for the echo client. It initiates the ping-pong * traffic between the echo client and server by sending the first message to * the server. */ public class EchoClientHandler extends ChannelHandlerAdapter { private final ByteBuf firstMessage; /** * Creates a client-side handler. */ public EchoClientHandler() { firstMessage = Unpooled.buffer(EchoClient.SIZE); for (int i = 0; i < firstMessage.capacity(); i ++) { firstMessage.writeByte((byte) i); } } @Override public void channelActive(ChannelHandlerContext ctx) { ctx.writeAndFlush(firstMessage); } @Override public void channelRead(ChannelHandlerContext ctx Object msg) { ctx.write(msg); } @Override public void channelReadComplete(ChannelHandlerContext ctx) { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { // Close the connection when an exception is raised. cause.printStackTrace(); ctx.close(); } } When I look at ChannelHandlerAdapter I don't see these methods... You are mixing up versions. In Netty 4 you have for EchoClientHandler: public class EchoClientHandler extends ChannelInboundHandlerAdapter And in Netty 4 ChannelInboundHandlerAdapter has a channelActive method. Your link is for EchoClientHandler in Netty 5 for which ChannelHandlerAdapter has been updated and has a lot more methods including channelActive. Use netty 4 branch for examples that fit netty 4. As stated above master is netty 5 frustrating. so the sample code for EchoClientHandler is for Netty 5? Netty 4 is recomended... How do I know which sample code is for Netty 4? Your links are from the current version being developped. To get the 4.0 API you go on http://netty.io/wiki/index.html and click on the version 4.0 API reference link or source code link. does the sample at https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/echo/EchoClientHandler.java use netty 4 or 5? This is Netty 5 since it the version currently being developed
187,A,"Netty or java.net.Socket for green field project? When starting a green field project is it recommended now to use Netty project instead of java.net.Socket? When to use Netty and when to use java.net.Socket? The project is to connect to Redis. I edit the question So you want to create your own java client for redis instead of using existing? Yes definitely! Not because the current libs aren't good but because I can! :) What kind of project are you starting? What do you need sockets or netty for? One is synchronous and the other asynchronous so you need to make the choice how you want to program. The synchronous way is more obvious in the simple case but usually the asynchronous approach wins as the requirements get tougher. Async is the definite winner in thriftyness with system resources and also in flexibility. To that Netty is on its own a great modern Java library. I edit my question the project needs to connect to Redis Since redis is all about performance I say netty is a great match for it. Even if Netty is Asynchronous? I don't see what you mean by ""even if"". Do you imply that asynchronous equals less performant? No no I'm not implying anything :) Just wondering.  I would use Netty. It is simple enough when you want to do synchronous operations (using OIO). It is extensible through modifying the netty pipeline allowing you to easily modify or add to the behavior at runtime (which seems like something a redis client might want to do) If you have to you can switch to asynchronous operations (using NIO/NIO2/AIO) without having to modify all your handlers. (hint: you probably want to implement the Redis marshallers/unmarshallers as netty channel handlers). I implemented just the SUB (as in PUB/SUB) for a redis java client and it is nice to not have to block when you're subscribing."
188,A,Netty 4.0 on multiple ports with multiple protocols? I'm looking for a server example that would combine a http handler on port 80 and a protobuf handler on another port in the same jar. Thanks! I don't know what exactly you are looking for. Its just about creating two different ServerBootstrap instances configure them and call bind(..) thats it. Ah ok. I was confused as calling sync on the closeFuture is just a way to keep the program from exiting. Thanks!
189,A,"Clojure TCP Server with Aleph I am attempting to write a simple TCP server using Aleph. Everything works fine except I am unsure of how I should detect when a channel has been closed. From the documentation: When the client closes the connection both sides of the channel will be immediately sealed. The final message from the channel will be nil However I never seem to receive this final nil message. If I inspect the channel I do see that it has been closed. Here is my code: (use 'lamina.core 'aleph.tcp 'gloss.core) (defn process-msg [ch msg] (if (closed? ch) (println ""Channel has been closed"") ;This never happens (do-some-processing msg))) (start-tcp-server (fn [ch client-info] (receive-all ch (partial process-msg ch)) {:port 10000 :frame (string :utf-8 :delimiters [""\n""])}) Should I be doing something differently? Is my frame keeping the nil message from being processed? I could have a separate thread monitoring my channels and checking whether or not they have been closed but this seems like a poor design. I would prefer to use Aleph but right now its looking like I will need to use a raw Netty handler. Using Netty directly would be fine but I'd prefer to use Aleph if possible since it feels a little more idiomatic. To register a callback for when a channel is closed or drained use (on-closed ch callback) or (on-drained ch callback) which both take a callback with zero arguments. https://github.com/ztellman/lamina/wiki/Channels Thanks. This is exactly what I was looking for. I didn't think to check the Lamina documentation."
190,A,"Netty ClientBootstrap SSL Handshake Terminates--Channel/ClientBootstrap closing? My Connection to my test application keeps terminating in the same place without any errors. I think perhaps something is triggering the channel/connection to close but I don't know what it could be. Where exactly it closes changes slightly if I change printouts in the code so the timing appears to be on a different thread. I've been working on this for four days now and list myself as officially stuck. Here is my connection code:  final HttpQueryRequestImpl realRequest = (HttpQueryRequestImpl) getPredecessorQueryResolver().resolvePredecessorResults(getPredecessorResults() getQueryRequest() getId()); // Configure the client. // TODO determine if this ClientBootstrap object can be reused. Indications in the doucmentation // seem to say yes with caveats. Reusing the pool would improve performance. Caveats must be investigated. final ClientBootstrap bootstrap = new ClientBootstrap( new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); // Set up the event pipeline factory. bootstrap.setPipelineFactory(new HttpSnoopClientPipelineFactory()); // TODO audit and timestamp logging if (logger.isInfoEnabled()) { logger.info(""Starting connection to !"" + realRequest.getUri()); } // Start the connection attempt. // ChannelFuture future = bootstrap.connect(new InetSocketAddress(realRequest.getHost() realRequest.getPort())); logger.info(realRequest.getHost() + "" "" + realRequest.getPort()); ChannelFuture future = bootstrap.connect(new InetSocketAddress(""myname.organization.com"" 8443)); // register some things to happen after the channel completes future.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { logger.error(""Error connecting to "" + realRequest.getHost() + "":"" + realRequest.getPort() + "" "" + realRequest.getUri()); bootstrap.releaseExternalResources(); } else { if (logger.isInfoEnabled()) { logger.info(""Connected to "" + realRequest.getHost() + "":"" + realRequest.getPort() + "" "" + realRequest.getUri()); } // Send the HTTP request. Channel channel = future.getChannel(); HttpRequest request = new DefaultHttpRequest( HttpVersion.HTTP_1_1 HttpMethod.GET ""/factorial""); request.setHeader(HttpHeaders.Names.HOST ""myname.organization.com""); request.setHeader(HttpHeaders.Names.CONNECTION HttpHeaders.Values.CLOSE); request.setHeader(HttpHeaders.Names.ACCEPT_ENCODING HttpHeaders.Values.GZIP); ChannelFuture writeFuture = channel.write(request); writeFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { logger.info(""Wrote data complete""); // TODO once bootstrap is reused get rid of this // Shut down executor threads to exit. // bootstrap.releaseExternalResources(); } }); } } }); This is what my output looks like with SSL debugging enabled: 32 [main] INFO nettyliteserver.remotequeries.HttpsQuery - Starting connection to !https://myname.organization.com:8443/factorial 32 [main] INFO nettyliteserver.remotequeries.HttpsQuery - myname.organization.com 8443 *** found key for : myname.organization.com chain [0] = [ [ Version: V1 Subject: CN=myname.organization.com OU=myname.organization.com O=myname.organization.com L=myname.organization.com ST=myname.organization.com C=US Signature Algorithm: SHA1withRSA OID = 1.2.840.113549.1.1.5 Key: Sun RSA public key 1024 bits modulus: 94642469145065852073118930371145672868332389407646565010478303790446281089121119363888463093443199472593726155607365724815252704927244864250811984977900576391208121343883948799873869280369621492901495505803717080952775289840654752626694613842653754724186814688913115288788127483906065658243886585022651573993 public exponent: 65537 Validity: [From: Fri Mar 09 13:29:22 EST 2012 To: Sat Mar 09 13:29:22 EST 2013] Issuer: C=US CN=myname.organization.com ST=myname.organization.com L=myname.organization.com EMAILADDRESS=myname.organization.com OU=myname.organization.com O=myname.organization.com SerialNumber: [ 71c8] ] Algorithm: [SHA1withRSA] Signature: 0000: C5 55 9C 1D 76 CE 05 87 45 0D C3 15 9C DB 0B 3A .U..v...E......: 0010: 70 0E 50 0C DB DB B4 62 2F BA A3 30 48 C0 D2 E9 p.P....b/..0H... 0020: 45 9C 3C C0 4A 84 7B 21 51 78 93 F1 63 4C 61 37 E.<.J..!Qx..cLa7 0030: 21 97 E8 38 F9 62 C5 EA 02 53 28 4F F8 EC 01 F2 !..8.b...S(O.... 0040: 08 70 DB 96 D5 1D 9E 0A 89 33 D3 1D C8 79 8B C1 .p.......3...y.. 0050: 6E 07 C4 98 FA 55 85 80 D4 10 AF A7 E5 A7 94 FA n....U.......... 0060: 45 CB DA 7C FA 66 C6 FC 69 A4 B2 05 01 C6 DC 8E E....f..i....... 0070: AC 15 7D A2 FC 25 DF FE 19 80 D4 27 07 EA D6 3F .....%.....'...? 0080: 5C 73 5F 63 0B 4E 02 FC 49 EA 76 69 FA 82 5B 1B \s_c.N..I.vi..[. 0090: 3B 45 6B 95 DC 8F C2 E8 A9 6C 10 CD 9B E0 59 D7 ;Ek......l....Y. 00A0: DC E6 69 2C F9 DB 99 F7 7F E3 76 81 13 CD B3 FE ..i......v..... 00B0: 1D AD 32 7D 6F 74 A9 12 4B 06 E2 9F E9 1F EF 8A ..2.ot..K....... 00C0: 1F CA 1D B8 08 47 00 1D 19 53 87 0A E3 FA B4 B5 .....G...S...... 00D0: 99 4F B9 97 5D D0 EE 0D DD 09 5F 3C 41 31 D6 18 .O..]....._<A1.. 00E0: 5C 39 01 8E DA D9 27 85 FE 0F C5 EE 00 A3 27 44 \9....'.......'D 00F0: C0 A1 42 EA 13 5B 66 3B 64 E3 EA 9B 23 20 0B C6 ..B..[f;d...# .. 0100: 66 DB AB 79 77 97 3E 4A D0 C7 79 C4 D2 E7 BD 1A f..yw.>J..y..... 0110: F3 90 39 A2 A4 69 A9 A1 4E A3 0B 92 93 9F 8F 4F ..9..i..N......O 0120: C3 4F CE E7 20 D6 45 4D 9B E0 B2 58 EC 96 19 99 .O.. .EM...X.... 0130: E0 F3 BB E4 EF 7E 1D C7 C3 48 8B D0 7D 2D 8C 3A .........H...-.: 0140: 1A AF 77 3A 83 F4 51 C9 D6 DE BE 24 3B 03 7C A9 ..w:..Q....$;... 0150: 4B 5C C4 6E 59 AB E2 02 63 73 CE 98 8A D0 45 D5 K\.nY...cs....E. 0160: 6C FE 23 79 93 69 D5 74 0D AF FE 23 AE BB 3F E4 l.#y.i.t...#..?. 0170: 9C 05 87 E1 2E 91 51 D6 44 55 7E 66 73 1D BB C2 ......Q.DU.fs... 0180: F3 E8 4D CA 50 D9 6D 2A AD 84 EF C7 70 4B 15 EA ..M.P.m*....pK.. 0190: C4 E0 33 3E 44 89 A3 97 8C 32 17 FD B9 DD 22 FB ..3>D....2...."". 01A0: 08 CF 1E 49 78 B7 2F 8E 60 66 58 3D 57 6F 21 72 ...Ix./.`fX=Wo!r 01B0: D3 87 38 9C DD EB 60 D8 BD 06 A8 04 FD 2D 59 EA ..8...`......-Y. 01C0: 82 A8 E8 E7 73 81 1E DE FD 51 33 0C F7 47 AE 34 ....s....Q3..G.4 01D0: 58 57 DD CE FD 12 68 A6 A8 2E 58 4F C7 6A 1E 27 XW....h...XO.j.' 01E0: 39 EF C7 BE 75 32 96 99 6B 1B E6 23 2A A5 0E 2F 9...u2..k..#*../ 01F0: 35 0A 0C 0C FA 92 65 1D DC 17 56 57 C4 08 89 48 5.....e...VW...H ] chain [1] = [ [ Version: V1 Subject: C=US CN=myname.organization.com ST=myname.organization.com L=myname.organization.com EMAILADDRESS=myname.organization.com OU=myname.organization.com O=myname.organization.com Signature Algorithm: SHA1withRSA OID = 1.2.840.113549.1.1.5 Key: Sun RSA public key 4096 bits modulus: 806866056348410276765741718640530245144236832502515305762072630647553277327953919063172921502880537921571234334570551528531888439605163701867371172813984927986527584575335107418628498623377289440387978453125866503947773575289298639780740830349842738718874502642354354786938153803982142709595698253667527748252780647208422256786989310056682111281793756866001585577762899819782647308899956239433307951381179494148030342543127196354965114705680137760255253494869690234155019595101679874833401305309080790668924554791611347641826073186513714032079267845800910995372117962695304732667441462587341743926848435668491205343373472147947564642450777593350053051331533112897445884090255314793988795654376385927964164743689070718825504556057816253883950563232708345137230621100544965407234099088514072120925433729718654307794068734283314839693884400349895261851764957828001331060077733384251643023885026867016629337741393451760864161087662305445338147618921663305526880031574988450298248773113067904762125722376437187045162922144483754266350990810318433387352520742359961188082219224300651116723774686748606066644650420169490565673256120050113505389581136874611045622641221693918773655462724374483166653830081719164259720121105179323613660081321 public exponent: 65537 Validity: [From: Fri Mar 09 13:29:15 EST 2012 To: Sat Mar 09 13:29:15 EST 2013] Issuer: C=US CN=myname.organization.com ST=myname.organization.com L=myname.organization.com EMAILADDRESS=myname.organization.com OU=myname.organization.com O=myname.organization.com SerialNumber: [ c1e2c18c f327ad81] ] Algorithm: [SHA1withRSA] Signature: 0000: 8A EB 65 0E 88 09 BE 9A BA 88 FB CA 9A D4 53 F4 ..e...........S. 0010: B0 5C 91 67 BD C9 35 67 2D 37 78 2D 5C E6 4B 26 .\.g..5g-7x-\.K& 0020: E9 8E 20 3D DE 92 9B 29 A7 CB CC 5F 4E E3 CD 1A .. =...)..._N... 0030: FA 5B EB 0D 42 DC 17 05 4E D6 34 72 43 46 6C 55 .[..B...N.4rCFlU 0040: 99 FF AC 00 2E BF 28 5D 4A 6A 21 DE 72 9E 6C 7A ......(]Jj!.r.lz 0050: A6 10 28 27 21 72 0F 69 09 04 D3 FB A7 83 DF 81 ..('!r.i........ 0060: E2 78 BD 0B 4F D7 AA B4 CC E2 E4 3B A5 30 A3 14 .x..O......;.0.. 0070: B4 83 75 DC E6 8C 01 9A B2 BA FF 0D 3F AA F1 30 ..u.........?..0 0080: A0 33 A9 CC 13 08 72 8F E2 75 1D 3B 30 B8 82 3C .3....r..u.;0..< 0090: 9A A0 A3 68 18 60 C0 1F E4 2E 06 D6 1B B8 46 6F ...h.`........Fo 00A0: AB D3 C9 AD 89 E6 E7 48 12 0F 90 A5 B8 A2 17 51 .......H.......Q 00B0: 41 AF 1E 62 6C D2 48 B2 41 C6 CE 1D 4E B1 F7 90 A..bl.H.A...N... 00C0: 34 26 E0 5D 95 7B BD 93 BA 4C D1 7A 08 A9 1E 57 4&.].....L.z...W 00D0: 03 EE F2 EC BD 8E 36 43 1D 4F 9E 39 56 A8 E4 B6 ......6C.O.9V... 00E0: 44 6C D5 D3 8C F0 FE 1F 87 87 67 2D E6 05 7E BA Dl........g-.... 00F0: 18 FB 6C 0B D8 80 19 08 27 8F 60 09 A6 BA 68 55 ..l.....'.`...hU 0100: 05 13 A8 9C 04 06 F8 24 A1 52 DB 67 69 2E FE 12 .......$.R.gi... 0110: A5 23 D1 2E 56 EA 54 08 83 DD 91 43 45 8B F6 97 .#..V.T....CE... 0120: 01 65 CC 32 4C FA D6 89 81 83 B4 21 92 F4 EC 29 .e.2L......!...) 0130: 68 87 51 A0 FC B7 7D BD 90 F8 A1 F8 68 82 CF 03 h.Q.........h... 0140: 4E 9C C2 FA AF 4A D3 AD 0B AB AB 73 4B B4 95 B0 N....J.....sK... 0150: EC 64 6B 8E 2B D4 E1 41 96 19 EC E9 6B 92 51 8A .dk.+..A....k.Q. 0160: D8 C1 87 FC DB B4 12 BD 14 AB 5C 07 73 AA DE CE ..........\.s... 0170: E5 05 8F E9 CC 9F C4 2A B6 0F 5D 40 8E 7A 82 7E .......*..]@.z.. 0180: CD 28 88 8F 01 3E 6C EF E7 01 58 2E C9 3F 0E 44 .(...>l...X..?.D 0190: 4D 1A 2B BB 0D 51 76 38 26 D4 89 5C 9B AB 63 FA M.+..Qv8&..\..c. 01A0: 4B 63 7C DC 0E 05 01 BB E4 97 73 03 4F 83 71 1E Kc........s.O.q. 01B0: B6 CB A6 62 F9 21 1B F2 24 D3 85 1D E6 31 87 E4 ...b.!..$....1.. 01C0: D6 74 09 70 C3 D0 4C 35 7E F1 49 5A 60 B7 02 72 .t.p..L5..IZ`..r 01D0: 04 C9 83 AD 5E 63 1F 7B 97 4C 35 7F 15 88 D5 5D ....^c...L5....] 01E0: DA 3B F6 80 9B 07 E5 86 4B 67 F6 B2 66 DE 81 6C .;......Kg..f..l 01F0: FF B6 99 D1 06 EF 3A 27 68 8D F2 EE 72 C4 48 64 ......:'h...r.Hd ] *** adding as trusted cert: Subject: CN=myname.organization.com OU=myname.organization.com O=myname.organization.com L=myname.organization.com ST=myname.organization.com C=US Issuer: C=US CN=myname.organization.com ST=myname.organization.com L=myname.organization.com EMAILADDRESS=myname.organization.com OU=myname.organization.com O=myname.organization.com Algorithm: RSA; Serial number: 0x71c8 Valid from Fri Mar 09 13:29:22 EST 2012 until Sat Mar 09 13:29:22 EST 2013 adding as trusted cert: Subject: C=US CN=myname.organization.com ST=myname.organization.com L=myname.organization.com EMAILADDRESS=myname.organization.com OU=myname.organization.com O=myname.organization.com Issuer: C=US CN=myname.organization.com ST=myname.organization.com L=myname.organization.com EMAILADDRESS=myname.organization.com OU=myname.organization.com O=myname.organization.com Algorithm: RSA; Serial number: 0xc1e2c18cf327ad81 Valid from Fri Mar 09 13:29:15 EST 2012 until Sat Mar 09 13:29:15 EST 2013 trigger seeding of SecureRandom done seeding SecureRandom trigger seeding of SecureRandom done seeding SecureRandom Using SSLEngineImpl. 985 [main] INFO nettyliteserver.ssl.FlexibleErrorSslHandler - handleDownstream That's where it terminates. I've changed the printouts around a bit so that sometimes I also get one more line the printout from logger.info(""Connected to "" + realRequest.getHost() + "":"" + realRequest.getPort() + "" "" + realRequest.getUri()); but I really don't know what is causing it to shut down. I tried overriding the netty SSLHandler and on all it's public operations added a printout but the close() channelConnected() channelDisconnected() etc methods are never being called. Neither is handshake(). My pipeline is set up to do a handshake: public class HttpSnoopClientPipelineFactory implements ChannelPipelineFactory { public ChannelPipeline getPipeline() throws Exception { // Create a default pipeline implementation. ChannelPipeline pipeline = pipeline(); // Enable HTTPS SSLEngine engine = SecureChatSslContextFactory.getClientContext().createSSLEngine(); engine.setUseClientMode(true); System.out.println(""HERE!!!!!!!!!!!!""); pipeline.addLast(""ssl"" new SslHandler(engine)); pipeline.addLast(""codec"" new HttpClientCodec()); // Remove the following line if you don't want automatic content decompression. pipeline.addLast(""inflater"" new HttpContentDecompressor()); // Uncomment the following line if you don't want to handle HttpChunks. //pipeline.addLast(""aggregator"" new HttpChunkAggregator(1048576)); pipeline.addLast(""handler"" new HttpSnoopClientHandler()); return pipeline; } } My custom SSLHandler is really the same as the library's SslHandler I just overrode the methods to add printouts before delegating to the super version. It looks like the only thing being called on it is handleDownstream() You need to call SslHandler.handshake() by yourself after the connect success. Something like: future.getChannel().getPipeline(SslHandler.class).handshake(); This needs to get done in your ChannelFuture that gets returned by the connect method or a SimpleChannelUpstreamHandler implementation that you add to the ChannelPipeline Hi thanks for responding. I think that is in my pipeline although it's not executing. My pipeline is in the main question now... This did help although I actually ended up with code that looked like: `SslHandler sslHandler = (SslHandler) future.getChannel().getPipeline().get(""ssl"");` The other issue was that the stuff I was running was inside a junit test and the junit test was ending before the handshake because it was asynchronous! Whoops....  Netty documentation states: Handshake If isIssueHandshake() is false (default) you will need to take care of calling handshake() by your own. In most situations were SslHandler is used in 'client mode' you want to issue a handshake once the connection was established. if setIssueHandshake(boolean) is set to true you don't need to worry about this as the SslHandler will take care of it. see javadoc So you should set isIssueHandshake on SslHandler before estamblishing the connection: SslHandler sslHandler = new SslHandler(engine); setIssueHandshake(boolean); pipeline.addLast(""ssl"" sslHandler);"
191,A,Java program shutdown on Linux I am running a java server program on Linux in a virtual instance (from provider). It is a complex program based on Netty. I start it using: nohup java -jar server.jar > server.txt Then it works fine. But sometimes it crashes - around 1 time in a week (there is no more process listening on the port). When I read logs and server.txt there is nothing in there. No exception detected or log information. But the program shuts down. What can be the reason for such a behaviour? Any suggestion would be appreciated. Please run your code like this: nohup java -jar server.jar >server.txt 2>&1 This will log any errors produced and you can add them here for help or figure out on your own.
192,A,"Sending a Message to All Browsers using Java based socket io client for netty I'm currently trying to send a message to all the browsers form java based client for socket io socket.io-netty.But currently it is sending message to only one browser at a time. the snippent is following: public class IOClientListener implements INSIOHandler { private INSIOClient ioClient=null; private final static Logger log=LoggerFactory.getLogger(IOClientListener.class); @Override public void OnConnect(INSIOClient client) { System.out.println(""A user connected :: "" + client.getSessionID()); client.send(""Hey you are connected to myhope.com""); } @Override public void OnDisconnect(INSIOClient client) { System.out.println(""A user disconnected :: "" + client.getSessionID() + "" :: hope it was fun""); } @Override public void OnMessage(INSIOClient client String message) { System.out.println(""A message received:: "" + message + "" :: hope it was fun""); } @Override public void OnShutdown() { } public INSIOClient getIOClient(){ return this.ioClient; } } I want to know how to broadcast the message using this client. Thanks in Advance you can use Netty ChannelGroup for this purpose .... static ChannelGroup allClientChannels = new DefaultChannelGroup(); @Override public void OnConnect(INSIOClient client) { System.out.println(""A user connected :: "" + client.getSessionID()); client.send(""Hey you are connected to myhope.com""); allClientChannels.add(client.getCTX().getChannel()); } @Override public void OnDisconnect(INSIOClient client) { System.out.println(""A user disconnected :: "" + client.getSessionID() + "" :: hope it was fun""); allClientChannels.remove(client.getCTX().getChannel()); } ... //when you want to send a broadcase message allClientChannels.write(yourMessage); For more detail have a look on ChannelGroup API Doc the message should be a channel buffer I am not familiar with socket.io I guess it might support pipeline of handlers like in Netty so you have to have a encoder handler after the broad cast handler then send the message after encoding it to a channel buffer object. I've tried this and I've written allClients.write(message) but I receive ""IllegalArgumentException: unsupported message type: ..."". How do you send message?"
193,A,Multiple clients using Netty Iam starting with Netty and I've tried the echo example I would like to simulate lots of clients connected to a server instead of just one like on the example. I can see on the EchoClient code that the client is initiated by new EchoClient(host port firstMessageSize).run(); As a very first attempt I tried to put that inside a for loop that iterates 1000 times for (int i=0;i<1000;i++){ new EchoClient(host port firstMessageSize).run(); } But this isn't working. How can I do in order to create many client connections? I would like to simulate many connections to an already done tcp server. You should share the ClientSocketChannelFactory between your different clients. The rest should be the same as in the example. If you not share you will create too many threads.
194,A,Netty app hangs when I try to close a io.netty.channel.Channel using closeFuture() My Netty app hangs when I try to close a io.netty.channel.Channel TCP/IP client connection. I do: ch.isOpen(); //this is TRUE ch.closeFuture().sync(); //never returns stack trace for the thread calling sync is here. JavaFX Application Thread@583 prio=5 in group 'main' status: 'WAIT' at java.lang.Object.wait(Object.java:-1) at java.lang.Object.wait(Object.java:502) at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:260) at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:129) at io.netty.channel.DefaultChannelPromise.await(DefaultChannelPromise.java:28) at io.netty.util.concurrent.DefaultPromise.sync(DefaultPromise.java:224) at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:117) at io.netty.channel.DefaultChannelPromise.sync(DefaultChannelPromise.java:28) at MyClient.stop(MyClient.java:46) Is there something that can prevent a channel from closing? Can I force it closed another way? Thanks! `Bootstrap b = new Bootstrap(); b.bind(port).sync().channel().closeFuture().await();` Usually you bind a channel to the bootstrap. closeFuture.sync() is not for closing the Channel but rather allows you to block until the Channel is closed. For closing the Channel you would call Channel.close(). quite right! I thought I had tried close() also but apparently not because it works as advertised. Thanks a lot.
195,A,"UDP with netty different pipeline per remote host not working I'm having troubles getting netty to work with UDP. The biggest problem is that once I make a connection to the server and finish doing the interactions between the server and client the server becomes useless. I can't make any other connection to it from the same client or any other (different host). I feel like their is something really simple and easy I'm missing. I have configured the server to create a new pipeline (I think?) for each new host that connects to it with the following code: public class DistinctChannelPipelineFactory implements ChannelPipelineFactory { private final ChannelPipelineFactory pipelineFactory; public DistinctChannelPipelineFactory(ChannelPipelineFactory pipelineFactory) { this.pipelineFactory = pipelineFactory; } @Override public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline(new DistinctChannelPipelineHandler(pipelineFactory)); } } With DistinctChannelPipelineHandler looking this where I try I to make a different pipeline per remote host and timing them out after 10 seconds.  private final LoadingCache<SocketAddress ChannelPipeline> pipelines; public DistinctChannelPipelineHandler(ChannelPipelineFactory factory) { this.pipelines = CacheBuilder.newBuilder() .concurrencyLevel(1) .expireAfterAccess(10 SECONDS) .removalListener(new PipelineRemovalListener()) .build(new PipelineCacheLoader(factory)); } public void handleUpstream(ChannelHandlerContext ctx ChannelEvent e) throws Exception { if (e instanceof MessageEvent) { final ChannelPipeline pipeline = pipelines.get(((MessageEvent) e).getRemoteAddress()); if (!pipeline.isAttached()) { pipeline.attach(ctx.getChannel() ctx.getPipeline().getSink()); pipeline.sendUpstream(new UpstreamChannelStateEvent(ctx.getChannel() OPEN TRUE)); } pipeline.sendUpstream(e); } if (e instanceof ChannelStateEvent) { for (final ChannelPipeline pipeline : pipelines.asMap().values()) { final ChannelStateEvent cse = (ChannelStateEvent) e; pipeline.sendUpstream(new UpstreamChannelStateEvent(ctx.getChannel() cse.getState() cse.getValue())); } } } public void handleDownstream(ChannelHandlerContext ctx ChannelEvent e) throws Exception { if (e instanceof MessageEvent) { final ChannelPipeline pipeline = pipelines.get(((MessageEvent) e).getRemoteAddress()); if (!pipeline.isAttached()) { pipeline.attach(ctx.getChannel() ctx.getPipeline().getSink()); } pipeline.sendDownstream(e); } else { ctx.sendDownstream(e); } } private static final class PipelineCacheLoader extends CacheLoader<SocketAddress ChannelPipeline> { private final ChannelPipelineFactory factory; public PipelineCacheLoader(ChannelPipelineFactory factory) { this.factory = factory; } @Override public ChannelPipeline load(SocketAddress key) throws Exception { return factory.getPipeline(); } } private static final class PipelineRemovalListener implements RemovalListener<SocketAddress ChannelPipeline> { private static final Logger logger = LoggerFactory.getLogger(PipelineRemovalListener.class); @Override public void onRemoval(RemovalNotification<SocketAddress ChannelPipeline> n) { logger.info(""UDP connection timed out removing connection for {}"" n.getKey()); n.getValue().sendUpstream(new UpstreamChannelStateEvent(n.getValue().getChannel() OPEN FALSE)); } } This is how I'm initializing the server: @Provides public ConnectionlessBootstrap getConnectionlessBootstrap(DatagramChannelFactory channelFactory @LocalAddress SocketAddress localAddress final UdpPipelineFactory pipelineFactory) { final ConnectionlessBootstrap bootstrap = new ConnectionlessBootstrap(channelFactory); bootstrap.setOption(""localAddress"" localAddress); bootstrap.setPipelineFactory(new DistinctChannelPipelineFactory(pipelineFactory)); return bootstrap; } @Provides @Singleton public DatagramChannelFactory getDatagramChannelFatory(@WorkerExecutor Executor worker) { final DatagramChannelFactory channelFactory = new NioDatagramChannelFactory(worker); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { channelFactory.releaseExternalResources(); } }); return channelFactory; } I have omitted where I actually add all my handlers as I didn't think thats where the problem lies. Am I missing something fundamental here? I just want a pipeline per unique remote address that times out. It's awfully frustrating firing up the server and having it literally work for only client/server interaction only! I have verified through debugging that once I hit it with additional requests it does NOT create a new pipeline. So it seems like the original pipeline is staying around in a very stale state which is why it won't accept any other requests. Thoughts? Suggestions? Made a fundamental mistake. With ConnectionlessBootstrap everything runs over the same channel and we were closing the channel after each call to the server...thus disabling UDP. That's what our TCP code does and it took a while to realize it works differently. Hope someone else saves some time and headaches off of this."
196,A,"Netty large messages not going through. INTEREST_CHANGED event thrown twice I have a server working on Netty. The client sends some handshake messages and the server replies. These are small messages and there is no issue with these. However when the server tries to send some large messages (each 131139 bytes in size) it seems like they are being been sent the ChannelFuture's isSuccess() returns true and getCause() returns null. However the client never gets the full message only the first 4097 bytes of the first message. After 4 or 5 messages netty stops trying to send new messages. I am reading the channel's isWritable() before sending a message (it always returns true). The next message is attempted only when the operationComplete of the ChannelFutureListener is fired. After the message is written to the channel the log shows the ""INTEREST_CHANGED"" event is thrown twice and the isWritable changes to false and then immediately to true. But the message never reaches the client.  INFO [New I/O worker #7] (HashSender.java:33) - Attempting send a message: 0 INFO [New I/O worker #7] (HashSender.java:68) - Is channel writable: true INFO [New I/O worker #7] (FrameLengthPrepender.java:46) - outgoing packet lenght: 131139 INFO [New I/O worker #7] (ClientHandler.java:32) - [id: 0xdbb48b90 /192.168.0.3:60105 => /192.168.0.4:25025] INTEREST_CHANGED INFO [New I/O worker #7] (ClientHandler.java:33) - Is channel writable: true INFO [New I/O worker #7] (HashSender.java:16) - Message Successfully sent. Channel isDone: true success: true cancelled: false error: null INFO [New I/O worker #7] (HashSender.java:33) - Attempting send a message: 1 INFO [New I/O worker #7] (HashSender.java:68) - Is channel writable: true INFO [New I/O worker #7] (FrameLengthPrepender.java:46) - outgoing packet lenght: 131139 INFO [New I/O worker #7] (ClientHandler.java:32) - [id: 0xdbb48b90 /192.168.0.3:60105 => /192.168.0.4:25025] INTEREST_CHANGED INFO [New I/O worker #7] (ClientHandler.java:33) - Is channel writable: false INFO [New I/O worker #7] (ClientHandler.java:32) - [id: 0xdbb48b90 /192.168.0.3:60105 => /192.168.0.4:25025] INTEREST_CHANGED INFO [New I/O worker #7] (ClientHandler.java:33) - Is channel writable: true INFO [New I/O worker #7] (HashSender.java:16) - Message Successfully sent. Channel isDone: true success: true cancelled: false error: null INFO [New I/O worker #7] (HashSender.java:33) - Attempting send a message: 2 INFO [New I/O worker #7] (HashSender.java:68) - Is channel writable: true INFO [New I/O worker #7] (FrameLengthPrepender.java:46) - outgoing packet lenght: 131139 INFO [New I/O worker #7] (ClientHandler.java:32) - [id: 0xdbb48b90 /192.168.0.3:60105 => /192.168.0.4:25025] INTEREST_CHANGED INFO [New I/O worker #7] (ClientHandler.java:33) - Is channel writable: false INFO [New I/O worker #7] (ClientHandler.java:32) - [id: 0xdbb48b90 /192.168.0.3:60105 => /192.168.0.4:25025] INTEREST_CHANGED INFO [New I/O worker #7] (ClientHandler.java:33) - Is channel writable: true INFO [New I/O worker #7] (HashSender.java:16) - Message Successfully sent. Channel isDone: true success: true cancelled: false error: null INFO [New I/O worker #7] (HashSender.java:33) - Attempting send a message: 3 INFO [New I/O worker #7] (HashSender.java:68) - Is channel writable: true INFO [New I/O worker #7] (FrameLengthPrepender.java:46) - outgoing packet lenght: 131139 INFO [New I/O worker #7] (ClientHandler.java:32) - [id: 0xdbb48b90 /192.168.0.3:60105 => /192.168.0.4:25025] INTEREST_CHANGED INFO [New I/O worker #7] (ClientHandler.java:33) - Is channel writable: false INFO [New I/O worker #7] (ClientHandler.java:32) - [id: 0xdbb48b90 /192.168.0.3:60105 => /192.168.0.4:25025] INTEREST_CHANGED INFO [New I/O worker #7] (ClientHandler.java:33) - Is channel writable: true INFO [New I/O worker #7] (HashSender.java:16) - Message Successfully sent. Channel isDone: true success: true cancelled: false error: null INFO [New I/O worker #7] (HashSender.java:33) - Attempting send a message: 4 INFO [New I/O worker #7] (HashSender.java:68) - Is channel writable: true INFO [New I/O worker #7] (FrameLengthPrepender.java:46) - outgoing packet lenght: 131139 INFO [New I/O worker #7] (ClientHandler.java:32) - [id: 0xdbb48b90 /192.168.0.3:60105 => /192.168.0.4:25025] INTEREST_CHANGED INFO [New I/O worker #7] (ClientHandler.java:33) - Is channel writable: false INFO [New I/O worker #7] (ClientHandler.java:32) - [id: 0xdbb48b90 /192.168.0.3:60105 => /192.168.0.4:25025] INTEREST_CHANGED INFO [New I/O worker #7] (ClientHandler.java:33) - Is channel writable: true INFO [New I/O worker #7] (HashSender.java:16) - Message Successfully sent. Channel isDone: true success: true cancelled: false error: null INFO [New I/O worker #7] (HashSender.java:33) - Attempting send a message: 5 INFO [New I/O worker #7] (HashSender.java:68) - Is channel writable: true INFO [New I/O worker #7] (FrameLengthPrepender.java:46) - outgoing packet lenght: 131139 INFO [New I/O worker #7] (ClientHandler.java:32) - [id: 0xdbb48b90 /192.168.0.3:60105 => /192.168.0.4:25025] INTEREST_CHANGED INFO [New I/O worker #7] (ClientHandler.java:33) - Is channel writable: false Can anyone please tell me why the messages are not going through? Update: Its actually 4097 bytes of the first message. I didn't count the first 4 bytes that mark the packet length. Update: If the outgoing packet length is less than or equal to 4097 bytes everything works smoothly. Netty breaks only when the packets are larger than 4097 bytes. Its 4097 not 4096. Does it ring a bell? The channel interest change events are nothing to worry about. Netty 3.x maintains an internal write buffer with a high water mark for each channel. This represents the amount of data waiting to be flushed to operating system buffers. If the outstanding data exceeds this value then the channel is set to non-writable. The default value is 64K so your large message immediately triggers the channel interest change event. Netty then sets the channel to writable again once data has been flushed to the system buffers. I think the message is being sent. Can you provide details of the client? Update: Its actually 4097 bytes of the first message. I didn't count the first 4 bytes that mark the packet length. The client is written in c++. Its a very mature code and I am re-writing the server (which was originally blocking instead of asynchronous). I am pretty sure whenever large messages are sent the client gets only the first 4093 bytes of the first message. I ran some more experiments and found out that if the outgoing packet length is less than or equal to 4097 bytes everything works smoothly. Netty breaks only when the packets are larger than 4097 bytes. Its 4097 not 4096. Does it ring a bell? Ok my bad. The problem was on the client side. There was an infinite loop on the thread reading the socket so the incoming data was not being processed."
197,A,"Enforce SSL on Play! Framework I'm currently using Play! 1.2.2 and its new Netty client framework. I haven't found a straightforward method to enforce SSL although can get HTTP and HTTPS to serve asynchronously. Does anyone that's worked with Play! have a straightforward method of enforcing SSL? Not sure if I need to create redirects or if this can be solved quickly in a conf file. In the controller you can check against request.secure and either do a redirect or return 403/access denied. You can force SSL for a whole controller doing this: public static class ForceSSL extends Controller { @Before static void verifySSL() { if (request.secure == false) redirect(""https://"" + request.host + request.url); } } ... and annotate another controller: @With(ForceSSL.class) public class Foo extends Controller { .... } See also http://groups.google.com/group/play-framework/browse_thread/thread/7b9aa36be85d0f7b If using heroku this code will cause ""Too Many Redirects"". Use the similar code from here: http://stackoverflow.com/questions/7415030/enforce-https-routing-for-login-with-play-framework  There are a couple of ways to enforce SSL. Firstly you can set all your actions to use the .secure() method for example <a href=""@{Application.index.secure()}"">index page</a> Alternatively and probably the best way is to do this via a frontend HTTP server such as Apache Nginx or Lighttpd. The idea of the frontend http server is that your application runs on port 9000 but is not accessible from the outside network. HTTP is responsible for all incoming requests and is configured to only accept HTTPS. The HTTPS is handled by the HTTP server and the request is then forwarded on to Play. This leaves your entire Play application to work as normal and the SSL is offloaded to another application. This same method can be applied to a load balancer rather than HTTP server but I am guessing the majority of people will go with the far cheaper alternative of a HTTP server unless running in a corporate environment. Very helpful and I appreciate the consideration of multiple methods."
198,A,"port unification with persistent channel I am trying to adapt the Port Unification example to my codebase. The issue I think I'm having is that a channel is kept open between the client & server until either the server shuts down or the client is finished its task or more specifically the same pipeline is used the entire time. So the workflow in the example where the unifier handler is removed from the pipeline does not work. The issue I was seeing with the Port Unification example as-is was that my client kept pre-pending the magic bytes to each request but the server side channel removed the port unification handler the first request that came in once the message was determined to be a valid protocol message. Subsequent messages over the channel which contained the prefix magic bytes from the client were not able to be processed because the unification handler was no longer in the pipeline to consume the magic bytes resulting in the messages being malformed. I was able to get around this by leaving the unification handler in the pipeline but then each time the sniffer identified the protocol it was adding protocol handlers. Since the pipeline was persistent for the life of the channel I kept adding the same handlers over and over again. This was easy enough to workaround by adding an attribute to the channel to avoid re-adding stuff to the pipeline. Now the issue I'm seeing is for messages broken up into several buffers. If the client sends 2k bytes broken into two messages. The first message is correctly sniffed and passed onto the next handler (LengthFieldBasedFrameDecoder to be specific). It does not have all the bytes so it waits for the rest. When the next message comes in with the rest of the bytes because i cannot remove the unifier from the pipeline I sniff again and the sniff fails. Is there a workaround for this or a better way to accomplish the same thing? UPDATE: Moving the consumption of the magic bytes out of the unifier seems like the right approach but what still continues to be the issue (or seems to be) is that dynamically altering the pipeline does not work the same in netty 4 as it does in netty 3. my client protocol is prepending all requests w/ a byte sequence to identify it. with netty 3 we simply skipped over the bytes in the ChannelBuffer removed the unifier and added the appropriate protocol handling to service that request. the same thing happened on all subsequent requests and it worked perfectly. however with netty 4 once we've removed the handler from the pipeline that eats the magic bytes its gone for the lifetime of the Channel which persists until the client closes it. so before it seemed like the pipeline/ChannelHandlerContext was new for each message going through the channel it's re-used each time and i think this is where the problem is. afaict this makes this type of dynamic changing of the pipeline difficult or impossible in practice. i want something to consume only the first N bytes of each request but i can't leave it in the pipeline because large requests broken into several ByteBuf's will all have their first N bytes eaten which badly breaks things. Update 2: I think the behavior I'm now seeing is related to what I've mentioned in a followup topic: how to manage a prefixed byte sequence which identifies your protocol The port unification example does not expect the client to switch protocol. If you really want to support that you have to come up with a mechanism for the client to say: ""I'm done using this specific protocol for now next message may use a different protocol"" and then have the PortUnificationServerHandler re-inserted in a cleared pipeline. UPDATE: After reading the scenario again I think your problem is that your unification handler is consuming the ""magic bytes"". It shouldn't. The Netty example doesn't. The unifictaion handler should just determine the protocol install the corrcet handler sequence and get out. The new handler sequence should see the first byte buffer unchanged i.e. no bytes should've been consumed. @Michael Ok but that's how I interpreted the scenario. that's cool i just wanted to clarify. what i need is the ability for the unifier handler to only get called once *per read*; when the message from the client is broken up into multiple ByteBuf's that's when there are problems. the original example just removes the unifier which gets around this but you can't do that if you plan on re-using the channel. my use case does not seem that unusual so its hard to believe that the netty folks don't have a solution for this situation Suggestion: First make a handler that can read and process one of your protocols. Aggregating split messages should be easy if you have a properly framed protocol. When that works incorporate it in a unification handler. I currently only have one protocol and 20k LOC of code that worked w/ netty 3.x and has done so for 2+ years. I'm trying to port it to use Netty 4 and its clear that how the unification handler used to work is not compatible with how it works in Netty 4. I *think* that's due to lifecycle changes in Channel & ChannelHandlerContext; previously i think a new pipeline was constructed for each message exchange now it seems like there's only one for the lifetime of the channel. which makes dynamic modifications much harder the client is not switching protocols. it's simply sending a second message over the channel. its an async RPC client-server. the first RPC exchange b/w the two is fine the second is a failure either because the unifier is not in the pipeline or if it is the second request is large enough that it's broken into several ByteBuf's Your suggestion that the unifier doesnt remove the magic bytes makes sense an error on my part. But something has to remove those bytes and I don't understand how it can be done when the request is broken across several ByteBuf's. having a handler that would eat the two bytes is easy but having it eat only the initial two bytes seems tricky. I should point out that the exact same setup in 3.6.6 worked fine. all ive done is migrate the codebase to netty 4"
199,A,"Why does Netty client connection future.operationComplete get called within the caller thread? Below I have demonstrated how I connect using Netty NioClientSocketChannelFactory. Connect returns a future and I can check if the connection is successful/failed. My understanding is that the connection process is non-locking and so the operationComplete method will be called by netty thread (not within the caller thread) And so the caller thread will exit. Most of the time it works this way on various windows deployments I have. But on one of the deployments I noticed that when connection fails the operationComplete method is invoked in my caller thread instead of netty thread. The exception thrown in also caught in the caller thread. I did not expect this. In my code when connection fails I reattempt a connection (not demonstrated below)...and since it happens in my caller thread I never return from my connect call since the operationComplete is called in my caller thread. What am I doing wrong? NOTE-I dont have the future.awaitUninterruptibly call anywhwere. public static void main(String[] args) { String host = ""localhost""; int port = 5555; ChannelFactory factory = new NioClientSocketChannelFactory(Executors .newCachedThreadPool() Executors.newCachedThreadPool()); MyHandler handler = new MyHandler(); PipelineFactory factory = new PipelineFactory(handler); ClientBootstrap bootstrap = new ClientBootstrap(factory); ChannelFuture future = bootstrap.connect(new InetSocketAddress(host port)); future.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) { // SUCCESS } else { // FAILURE } } }); } You should not make any assumption in which Thread the actual ChannelFutureListener is notified. Most of the times this will be the IO-Thread (Worker) of Netty but sometimes this also can be the caller Thread. I still don't understand why it would not ""return"" for you in that case. It wont return because I try to reconnect right away - Assuming I'm in IO thread :(. ok I'll change code to remove that assumption. Is this generally true for any concurrency type of implementation where a future is returned? I thought that if a method (anyone in java world) returns a future the future's listener is always called by another thread."
200,A,Connect to external HTTP server from Netty I need some help with understanding how to write HTTP router which recognizes HTTP header as routing criteria. I found the link https://github.com/cgbystrom/netty-tools/blob/master/src/main/java/se/cgbystrom/netty/http/router/RouterHandler.java which seems to do the routing itself. But now it is not clear how to connect to another HTTP server send HTTP request wait for HTTP response forward the HTTP response to client can somebody please give me some explanations? http://static.netty.io/3.5/xref/org/jboss/netty/example/proxy/package-summary.html the example of proxy server in Netty essentially what I wanted
201,A,netty  tomcat threading model I am a newbie to this and I am sorry if my question may seem to be too naive to experienced netty  tomcat users. I am running a Netty websocket server(using the sample code and running on port 8090) configured through spring inside tomcat(running on port 8080). I am trying to understand the threading models of both and overall how would it work. As I understand tomcat by deafult sets the maxThreads = 200 (max number of active threads). While netty uses boss threads to create and connect/bind sockets and then pass them off to the worker threads  which do the actual asynchronous I/O. Now I am trying to understand : If the threads used by Netty would be taken from the tomcat pool and hence decrease the number of active threads) ? For each websocket connection would a separate thread be allocated and used (I am not very clear about websocket implementation though I think the answer to this should be no). Overall  how would it affect the number of simultaneous clients connecting to the webapp and the websocket server? EDIT : And accordingly are there any specific points that should be kept in mind while coding the weboscket server ? In Netty you specify the ThreadPool by pass an Executor to the constructor. So as long as you don't use the same pool as you use in Tomcat it should not effect the avaible threads. Netty's Webseocket implementation can be used with its NIO transport. In this case you would share a number of threads between connections. So there is not 1:1 mapping from connection to threads. About the first part - If declaring the threadPool by doing `Executors.newCachedThreadPool()`  I understand it would be a different pool  right ? And the second part  could you please throw some more light on it ? If your server is using NioServerSocketChannelFactory Netty will use by default 2 * Runtime.getRuntime().availableProcessors() worker threads to process connections. Incoming connections are load balanced across the threads and unless you have an execution handler in your pipeline each connection is guaranteed to be processed by the same thread throughout the lifetime of the connection. @johnstlr : Thanks for the reply. I am new to netty and would like to know apart from the netty api docs  where could I find good documentation regarding all these important snippets of information.Netty is great but I am not able to find good documentation and hence have many fundamental questions. I don't know if it will answer all of your questions but definitely check out http://seeallhearall.blogspot.co.uk/2012/05/netty-tutorial-part-1-introduction-to.html. Note though that there are some significant changes coming in Netty 4.0.
202,A,"ExecutionHandler and Boss thread I'm starting with ""bare"" netty in a project. I'm still going through all the amazing javadocs but there's a point I did not get. So far what I got: There's one Boss thread which starts the bootstrap and binds the server to a socket port right? The worker threads (could be many of those) handle the incoming connections and create proper channels and pipelines right? But we then have the ExecutionHandler which also can spam several other threads right? My point being is that if I have 10 worker threads and a ExecutionHandler of corepoolsize=16 it means I may end with 160 concurrent threads on my system given a very heavy load? Sorry it feels dumb the question but I'm just trying to make sense out of this part on the docs. Cheers Your understanding for Boss and Workers is right. For the ExecutionHandler its a bit different. The ExecutionHandler hands-of event processing to an extra ThreadPool. This helps to make sure you don't ""block"" the Worker threads. The ExecutionHandler MUST be shared between the different Channels and so also across the Workers. So if you have a Worker count of 10 and a core-thread-pool-size of 16 you will have 26 threads + the boss thread. Hope this makes it clear. Thanks a lot it really made it clear. And thanks for the project :) Probably the coolest things we have in java today are built on top of netty. Cheers man Nice to hear that!"
203,A,Running discard server on netty I downloaded netty from here and unzipped/untarred it. Now I want to run Discard Server which is the first example in most netty tutorials. If I unjar netty-example-4.0.0.CR2.jar I can see io/netty/example/discard/DiscardServer.class and I know this has main method too. My question is: how do I run discard server? I tried java -jar netty-common-4.0.0.CR2.jar io.netty.example.discard.DiscardServer which yields: Failed to load Main-Class manifest attribute from netty-common-4.0.0.CR2.jar I tried unjarring the jar putting main class name as following in the manifest file: Main-Class: io.netty.example.discard.DiscardServer Running the jar still gives me the error: Could not find the main class: io.netty.example.discard.DiscardServer. Program will exit. You only load the netty-common-4.0.0.CR2.jar in java but the examples are in the netty-example-4.0.0.CR2.jar file and they depend on some of the other jar files from netty. Therefore you must specify your classpath with the option -cp to use them. java -cp netty-example-4.0.0.CR2.jar;netty-transport-4.0.0.CR2.jar;netty-common-4.0.0.CR2.jar;netty-buffer-4.0.0.CR2.jar io.netty.example.discard.DiscardServer Hope this helps.
204,A,"Netty http server responses This is probably simple but I couldn't figure it out. My Netty 4 based http server is causing http clients to hang on its response. It manages to send through its response payload (as observed using curl as a client) but the clients seem not to realize that the response has finished and they indefinitely wait for it to complete. Observed using curl as well as firefox and chrome. Only if I modify the code to close the channel (channel.close as seen inline below) then do the clients acknowledge that the response is done. Otherwise they just continue waiting for it to complete. I wish for the channel to stay open so that the next client request will not require opening a new connection (I wish to have keep-alive behavior) so closing the channel doesn't seem plausible. So I'm not sure how should the server mark the response as over - without closing the connection. The server code: val response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1 HttpResponseStatus.OK) val buf = new StringBuilder buf.append(""hello"") response.data.writeBytes(Unpooled.copiedBuffer(buf CharsetUtil.UTF_8)) ctx.write(response).addListener(new ChannelFutureListener(){ def operationComplete(channelFuture: ChannelFuture){ if (channelFuture.isSuccess){ println(""server write finished successfully"") //channelFuture.channel.close <===== if uncommented clients receive the response otherwise they just keep waiting forever } else println (""server write failed: "" + channelFuture.cause + ""\n"" + channelFuture.cause.getStackTraceString) } }) What am I missing?? Not really I'm not actively adding any headers. Should I? Yes. Without the Content-Length header your client doesn't know when to stop reading. If your content is just ""hello"" then add: Content-Length: 5. Thanks. Was a bit naive thinking writeBytes would take care of that.... Isn't there some other way of using Netty API to compose response data while simultaneously taking care of both content and length? isn't the response's data length managed transparently somewhere in the API? I'm new to Netty No there isn't. I have helper classes to do it but that's something you need to handle on your own. Thanks a lot. Care to turn this into an answer so I can mark it as your answer? or if you don't care I'll 'Answer My Own Question' to close it off. Off topic: I may be pursuing other ways than netty + http for my server as I don't want to go into low level programming for accomplishing mere obvious outcomes if this was any indication. Are you sending a Content-Length header? You need a Content-Length header or else the client won't know when to stop reading and will continually poll for more data."
205,A,Why Netty need thread pools? Coming from a node.js background I'm confused that it's not single threaded in Netty as in node.js. (The NioServerSocketChannelFactory document states that there are boss threads and worker threads) Maybe it's because unlike in node.js many of the existing Java libs are not async. But even if it's the case why not just let users to create threads as necessary? Isn't it more natural and conceptually aligned with async event-driven architecture? My knowledge of node.js and javascript are relatively limited but isn't node.js limited by the fact that javascript has no support for multithreading? The use of boss and worker threads in Netty is about being able to utilise multiple processor cores without needing to run multiple processes. The JVM is quite heavy so it makes sense to limit the number of instances needed. Also I suspect it's far quicker for an operating system to switch between threads than complete processes. Boss threads are used to accept incoming connections but the processing of a connection is handed off to a worker thread. I don't have a reference to hand but I dimly remember the Grizzly project publishing some performance results showing this was more performant than trying to accept incoming connections and process those connections in the same thread. Accepted connections are load balanced on worker threads in a round robin fashion. The worker threads do not interact with each other unless you explicitly write code to do so. Therefore the worker thread model is pretty much identical to my understanding of node.js. Netty deals with non-async libraries by providing mechanisms which allow an application to define a thread model via thread pools which is independent of the boss and worker threads. To help with this Netty also provides a few custom thread pools which are aware of the memory resources being used by a given connection and can also guarantee the ordering of events generated by connection. However it is not necessary to use these mechanisms. An application is free to use whatever thread model best suits. Please note that my answer applies to Netty 3. There have been significant changes in Netty 4 including being able to use the same threads to both accept incoming connections and process I/O if desired. It's also possible for the application to choose which I/O thread will handle a particular channel's events rather than being limited to pure round robin load balancing. Having said that the separation of boss and worker threads can still be applied to Netty 4.
206,A,Netty 4 using a different key other than Channel to maintain event order In Netty 3 there is an OrderedMemoryAwareThreadPoolExecutor and in documentation described how to change ordering key: http://docs.jboss.org/netty/3.2/api/org/jboss/netty/handler/execution/OrderedMemoryAwareThreadPoolExecutor.html In Netty 4 this was class replaced with EventExecutorGroup approach. As I understand if I will use DefaultEventExecutorGroup it will maintain order by channel (btw is it correct?). But if I have several sessions multiplexed on one channel and i want to use other key for parallel execution then channel is there a way to make it in Netty 4? Not with anything that is provided by Netty itself atm. You may be able to use a custom EventExecutorInvoker which will be part of Netty 4.1. Could you please open an issue with your use-case explained at our issue tracker so we can keep track ? Thanks for answer. Here is added issue: https://github.com/netty/netty/issues/2498
207,A,"Netty NIO Udt Attempt Giving Error and I cannot find the answer in the Docs Sorry for the possibly bad title but it is exactly as it says. I am new to Netty and this is my second attempt at a networked solution to what I am trying to do. The first solution straight java.nio UDP works but is inefficient and slower than I can stand. I keep getting an error on start up and cannot find the solution. The error tells me that there is no such field Rendezvous in the class io.netty.channel.udt.nio.NioUdtProvider. From the javadocs it seems that this specifies what the thread does. Am I missing a jar? What happened? Can I get any pointers on how to solve this? I am using Netty 4.0.0.1 CR1. It is the only release I found with that works with the examples. I also have barchart-udt-core-2.2.0 and jsch in my classpath. The problem is occurring in my server's main class (not named main). At the following line.  final ThreadFactory connectionFactory=new UtilThreadFactory(""connect""); final ThreadFactory acceptFactory=new UtilThreadFactory(""accept""); final NioEventLoopGroup acceptGroup = new NioEventLoopGroup(1acceptFactoryNioUdtProvider.MESSAGE_PROVIDER); final NioEventLoopGroup connectGroup=new NioEventLoopGroup(1connectionFactoryNioUdtProvider.MESSAGE_PROVIDER); More specifically the error occurs in the last two lines. I receive the following error code when working with both the MsgEchoServer example and my NettyServer.  Nov 07 2013 5:07:53 PM netty.NettyServer main INFO: init Exception in thread ""main"" java.lang.NoSuchFieldError: RENDEZVOUS at io.netty.channel.udt.nio.NioUdtProvider.<clinit>(NioUdtProvider.java:68) at netty.NettyServer.run(NettyServer.java:103) at netty.NettyServer.main(NettyServer.java:191) I have tried to find a netty 4x jar that contains these definitions specifically a full Netty release but get the same or different errors. My UtilThreadFactory code is below and is pretty much the same as from http://grepcode.com/file/repo1.maven.org/maven2/io.netty/netty-example/4.0.0.CR1/io/netty/example/udt/echo/message/MsgEchoServer.java?av=f Thanks UtilThread  package Netty; import java.util.concurrent.ThreadFactory; import java.util.concurrent.atomic.AtomicInteger; public class UtilThreadFactory implements ThreadFactory{ private static final AtomicInteger counter=new AtomicInteger(); private final String name; public UtilThreadFactory(final String name) { this.name=name; } public Thread newThread(final Runnable runnable) { return new Thread(runnablename+'-'+counter.getAndIncrement()); } } *UPDATE* I upgraded like requested and get the exact same error. I am now running Netty 4.0.12 with the jars 4.0.12 and 4.0.12-FINAL in my path. The same error occurs whether I have one or other jars and I cleared my eclipse cache. The same problem happens in STS spring tools. Any help is appreciated. Thanks Please upgrade to netty 4.0.12.Final ... Your version is quite old and we have working examples in there with UDT. Ok I've upgraded and the same error occurs even with the example code. I cleared my eclipse cache too. Is there a problem with IDE's and Netty?  Thanks for all of the help. I found the culprit after moving all of the jars to my classpath and reading through their contents. Something was missing from the udt-core as apparently I had a few older versions. I really wish wildfly/the netty guys would document this a little better. I downloaded the udt-core jar and this solved the problem. The latest jars are difficult to find. They are at http://repo1.maven.org/maven2/com/barchart/udt/ Hi - I am using netty-all 5.0.0.Alpha1 and I am getting the same error. I chose to build the netty-all jar file through MVN and I am seeing the same problem. Any suggestions? I hope this doesn't get flagged This error specifically came from barchart-udt-core. It is a separate jar that must be downloaded and placed in your classpath. Have you tried doing that? Also Norman Maurer helped write the program his profile is below. Thanks - It turns out the examples that come with Netty 5.0.0.Alpha1 are outdated. When I used the current examples from here the worked fine: https://github.com/netty/netty/tree/master/example/src/main/java/io/netty/example"
208,A,"Where is Channel.setInterestOps in Netty 4x I am using netty for developing my server. I am looking for setting the setInterestOps for a channel. In netty 3 there is a method call setInterestOps in Channel class. But in netty 4 I can't find it. Can anybody tell me where it is? Thank you Channel.setInterestOps() in Netty 3 was used to suspend or resume the read operation of a Netty Channel. Its name and mechanic were unnecessarily low-level so we changed how we deal with the suspension and resumption of the inbound traffic. First we added a new outbound operation called read(). When read() is invoked Netty will read inbound traffic once and it will trigger at least one channelRead() event and a single channelReadComplete() event. Usually you continue to read by calling ctx.read() in channelReadComplete(). However because having to call ctx.read() for every channelReadComplete() is not very interesting Netty has an option called autoRead which is turned on by default. When autoRead is on Netty will automatically trigger a read() operation on every channelReadComplete(). Therefore If you want to suspend the inbound traffic all you need to do is to turn the autoRead option off. To resume turn it back on. Thank you very much for the detailed and clear answer  Use Channel.config().setAutoRead(true/false); Thank you for replying. The documentation for the function says ""Sets if ChannelHandlerContext.read() will be invoked automatically so that a user application doesn't need to call it at all. The default value is true."" But for Channel.setReadable it is ""Suspends or resumes the read operation of the I/O thread asynchronously."" The docs for setAutoRead sounds confusing to me. Does both mean the same thing?"
209,A,"Camel : Use of netty:tcp and JDBC components I have a the following camel route which listen message from a TCP socket and send the body to a database. from(""netty:tcp://localhost:5150?sync=false&keepAlive=true"") .transform().simple(""insert into mytable (DATA) values (\""${in.body}\"");"") .to(""jdbc:mydb""); And the following which send a message to the first: from(""direct:input"").to(""netty:tcp://localhost:5150?sync=false&keepAlive=true""); I tested it with a JUnit like this: @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = ""classpath:applicationContext.xml"") public class OutputRoutesTest { @Autowired protected CamelContext camelContext; @EndpointInject(uri = ""direct:input"") private ProducerTemplate template; @Test @DirtiesContext public void testTCPSend() throws Exception { String body = ""foo?""; NotifyBuilder notify = new NotifyBuilder(camelContext).whenDone(1).create(); try { template.sendBody(body); } finally { template.stop(); } boolean matches = notify.matches(5 TimeUnit.SECONDS); assertTrue(matches); } } When I start the test a have the following stacktrace: 12:05:36.502 [Camel (camel-1) thread #22 - NettyOrderedWorker] ERROR o.a.c.processor.DefaultErrorHandler - Failed delivery for (MessageId: ID-M249-52364-1373537133834-0-3 on ExchangeId: ID-M249-52364-1373537133834-0-4). Exhausted after delivery attempt: 3 caught: java.sql.SQLException: Data source is closed java.sql.SQLException: Data source is closed at org.apache.commons.dbcp.BasicDataSource.createDataSource(BasicDataSource.java:1362) ~[commons-dbcp-1.4.jar:1.4] at org.apache.commons.dbcp.BasicDataSource.getConnection(BasicDataSource.java:1044) ~[commons-dbcp-1.4.jar:1.4] at org.apache.camel.component.jdbc.JdbcProducer.processingSqlBySettingAutoCommit(JdbcProducer.java:76) ~[camel-jdbc-2.11.0.jar:2.11.0] at org.apache.camel.component.jdbc.JdbcProducer.process(JdbcProducer.java:63) ~[camel-jdbc-2.11.0.jar:2.11.0] at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61) ~[camel-core-2.11.0.jar:2.11.0] at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:73) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.impl.InterceptSendToEndpoint$1.process(InterceptSendToEndpoint.java:164) ~[camel-core-2.11.0.jar:2.11.0] at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:73) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.SendProcessor$2.doInAsyncProducer(SendProcessor.java:122) ~[camel-core-2.11.0.jar:2.11.0] at org.apache.camel.impl.ProducerCache.doInAsyncProducer(ProducerCache.java:298) ~[camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:117) ~[camel-core-2.11.0.jar:2.11.0] at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:73) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.processNext(DelegateAsyncProcessor.java:99) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:90) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.management.InstrumentationProcessor.process(InstrumentationProcessor.java:72) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:73) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.processNext(DelegateAsyncProcessor.java:99) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:90) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.interceptor.BacklogTracerInterceptor.process(BacklogTracerInterceptor.java:84) ~[camel-core-2.11.0.jar:2.11.0] at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:73) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.processNext(DelegateAsyncProcessor.java:99) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:90) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.interceptor.TraceInterceptor.process(TraceInterceptor.java:91) ~[camel-core-2.11.0.jar:2.11.0] at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:73) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.RedeliveryErrorHandler.processErrorHandler(RedeliveryErrorHandler.java:390) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:273) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.RouteContextProcessor.processNext(RouteContextProcessor.java:46) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:90) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.interceptor.DefaultChannel.process(DefaultChannel.java:335) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:73) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.Pipeline.process(Pipeline.java:117) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.Pipeline.process(Pipeline.java:80) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.RouteContextProcessor.processNext(RouteContextProcessor.java:46) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:90) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.UnitOfWorkProcessor.processAsync(UnitOfWorkProcessor.java:150) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.UnitOfWorkProcessor.process(UnitOfWorkProcessor.java:117) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.RouteInflightRepositoryProcessor.processNext(RouteInflightRepositoryProcessor.java:48) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:90) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.util.AsyncProcessorHelper.process(AsyncProcessorHelper.java:73) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.processNext(DelegateAsyncProcessor.java:99) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:90) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.management.InstrumentationProcessor.process(InstrumentationProcessor.java:72) [camel-core-2.11.0.jar:2.11.0] at org.apache.camel.component.netty.handlers.ServerChannelHandler.processAsynchronously(ServerChannelHandler.java:118) [camel-netty-2.11.0.jar:2.11.0] at org.apache.camel.component.netty.handlers.ServerChannelHandler.messageReceived(ServerChannelHandler.java:102) [camel-netty-2.11.0.jar:2.11.0] at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) [netty-3.6.5.Final.jar:na] at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) [netty-3.6.5.Final.jar:na] at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) [netty-3.6.5.Final.jar:na] at org.jboss.netty.handler.execution.ChannelUpstreamEventRunnable.doRun(ChannelUpstreamEventRunnable.java:43) [netty-3.6.5.Final.jar:na] at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:67) [netty-3.6.5.Final.jar:na] at org.jboss.netty.handler.execution.OrderedMemoryAwareThreadPoolExecutor$ChildExecutor.run(OrderedMemoryAwareThreadPoolExecutor.java:314) [netty-3.6.5.Final.jar:na] at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885) [na:1.6.0_05] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907) [na:1.6.0_05] at java.lang.Thread.run(Thread.java:619) [na:1.6.0_05] 12:05:36.503 [Camel (camel-1) thread #22 - NettyOrderedWorker] DEBUG org.apache.camel.processor.Pipeline - Message exchange has failed: so breaking out of pipeline for exchange: Exchange[Message: insert into mytable (DATA) values (""foo?"");] Exception: java.sql.SQLException: Data source is closed 12:05:37.473 [Camel (camel-1) thread #23 - ShutdownTask] DEBUG o.a.c.impl.DefaultShutdownStrategy - Route: route2 preparing to shutdown complete. The message are received by the camel route but it can't be sent to the database. It seems like a connection problem with the database but I also tried by replacing the TCP endpoint by ""direct:output"" and the data have been inserted in base. Where am I wrong ? I think I may have misunderstood the way to use netty:tcp component. Thanks for your help. I'm using Camel 2.11 and Spring 3.1.2 Can you try with setting  .to(""jdbc:mydb?resetAutoCommit=false""); Thanks works great ! So simple"
210,A,Channel.messageReceived event in Netty In a TCP based server-client model using Netty Channels  is there any correspondence between the number of Channel.write() from the server and the corresponding Channel.messageReceived() on the receiving client ? If I do a 10 writes() on the sender  does it mean the messageReceived() will be invoked 10 times on the listening client ? or Netty can aggregate the sent data ( from the write()s on the sender ) into more or less number of messageReceived() events on the client ? Is there a way to configure this behaviour in Netty ? Yes there is a way to do this but you'll have to give us more in order to do anything else.  Its not guaranteed that you have a 1:1 mapping for your Channel.write(..) and messageReceived calls. You need to use some FrameDecoder subclass (maybe write your own) which will buffer the ChannelBuffer until you receive enough data to dispatch your message to the next ChannelHandlers in the ChannelPipeline on the Server. Netty already ships with some ready to use FrameDecoder implementations like The DelimiterBasedFrameDecoder (for example) which will take care to buffer the data until it receive a Delimiter and then dispatch it to the next handlers in the ChannelPipeline. See [1] for more details. [1] http://netty.io/docs/stable/api/org/jboss/netty/handler/codec/frame/FrameDecoder.html
211,A,When is channelInactive called with keepalive on? I have a SimpleChannelInboundHandler which handles a few http requests: CacheServerHandler extends SimpleChannelInboundHandler<FullHttpRequest> When i do not explicitly close the channel/connection and keepalive is true will channelInactive be called every time after channelRead0 is done? Or will channelInactive only be called once when the channel/connection is closed? I ask this because when keepalive is true on a http connection the connection isn't closed by client and client can send multiple requests without opening/closing the connection. ChannelInactive() will only be called when the channel is closed. This is the contract. Thanks Norman for clearing it up the function name did make me a bit confused.
212,A,Netty based server in servlet container I have a network server that was implemented using Jboss Netty. It servers the application over both raw TCP and HTTP and running as a stand alone process. Clients connected with TCP can transfer data to clients connected with HTTP and vice versa. Now I'm required to make it work in servlet environment. Does netty provide a standard way for doing so or that I have to write my adapter? What can I do with the TCP transport? can I include it in the servlet container ? this is a similar question but without a clear answer The Netty implementation already handles HTTP? Or does it just handle the raw TCP connections right now? If it handles both already why the need for a servlet container? You can create an HttpTunnelingServlet that links to your existing Netty implementation. See the org.jboss.netty.channel.socket.http API docs. This document uses a Spring bean to do the Netty setup. But it should be easy enough to move your configuration and setup to a ServletListener. I am not 100% sure if this will work though since the setup needs to connect to a LocalAddress that's specified in the servlet config. The issue may be that the address is not valid until the servlet starts up which happens I think after listeners start. Another option would be to sublcass HttpTunnelingServlet and add to the init() implementation. Whatever method you use you will still have to setup and also start the TCP channels etc too like you were doing before.
213,A,Netty Framework: When is channelOpen called? According to the Netty guide: http://static.netty.io/3.5/guide/#start.12 To keep track of open sockets you need to modify the TimeServerHandler to add a new open Channel to the global ChannelGroup TimeServer.allChannels:  @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) { TimeServer.allChannels.add(e.getChannel()); } I implemented channelOpen on my business logic handler. I don't see it called when a new client makes a connection. Can anyone say in detail when channelOpen is called? Also can I write an upstream handler to be inserted before the ExecutionHandler and expect channelOpen to be called at the appropriate time or does one have to implement channelOpen on the business logic handler? I'd like to be able to implement channelOpen separately from the business logic handler if possible. The events comes in in this order: channelOpen(..) channelBound(..) channelConnected(..) ... cannelDisconnected(..) channelUnbound(..) channelClosed(..) So channelOpen(..) should be called as first thing when a client connects..
214,A,"worker thread being blcoked in Netty I know netty uses reactor pattern to avoid creating thread for each connection the core concept about this pattern is a ""selecter"" or epoll system call in linux. But I also heard about that if a handler never close it's channel it will occupy one worker thread and block it doesn't it mean each connetion will use(block) one threadso for each accepted socket we still need to create a thread ? for example if I write a server with 10000 persistent connectionsdoes this server need 10000 worker threads?? The contradiction between those two things above confused me can anyone explain me if I understand it wrong? thank you~ ======================================== an example (with only 1 worker thread ) which can always process one client's event in the same time. import java.net.InetSocketAddress; import java.util.concurrent.Executors; import org.jboss.netty.bootstrap.ServerBootstrap; import org.jboss.netty.buffer.ChannelBuffer; import org.jboss.netty.channel.*; import org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory; public class Netty_test { public static void main(String[] args) { ChannelFactory factory =new NioServerSocketChannelFactory(Executors.newCachedThreadPool()Executors.newFixedThreadPool(1)); ServerBootstrap bootstrap = new ServerBootstrap(factory); ChannelPipelineFactory cpf=new ChannelPipelineFactory(){ public ChannelPipeline getPipeline() { return Channels.pipeline(new testHandler()); } }; bootstrap.setPipelineFactory(cpf); bootstrap.setOption(""child.tcpNoDelay"" true); bootstrap.bind(new InetSocketAddress(100)); } } class testHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { System.out.println(""messageReceived handler work.""); e.getChannel().write(e.getMessage()); ctx.sendUpstream(e); } } No your 10000 connections will share the worker threads. One worker thread will handle multiple connections/channels. This is why it is very important not to block the worker threads. But in my example aboveserver can only handle one persistent connection . I have tried this example both in Win7 and Linux(CentOS 5) with netty-3.2.4.Final.jar. You have more workers than threads. Change your factory to be with 1 worker and you will see that it can handle multiple connections. Like this: `NioServerSocketChannelFactory(Executors.newCachedThreadPool()Executors.newFixedThreadPool(1) 1);` It works! Many thanks!!  1) In reactor pattern the dispatcher get one event by listening to a list of event queues and passing the event to concrete event handler. The event handler can be executing by only one thread thread pools or per event per thread. depends on your implementation. 2) You can add timeout timer per channel and reset this timer on incoming data. If the timer timeout then close this channel to prevent too many idle channels. my 0.2 cents? so how can my server serve two connections simultaneously by one thread?? It seems not working unless I close one channel of them. Netty framework should support the non-blocking IO mode serving many connection concurrently by threading pool. here is link to describe this feature http://www.slideshare.net/zaubersoftware/non-blocking-io-with-netty in chinese http://www.kafka0102.com/2010/06/167.html"
215,A,"How to refuse incoming connections in Netty? I have a Netty TCP server and I want to reject/refuse incoming connection attempts selectively (based on their remote address). I guess I have to use ServerBootstrap.setParentHandler(ChannelHandler) but what do I do in the ChannelHandler? What event am I handling? How do I refuse the connection? After having looked at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink in the Netty sources I am fairly certain that Netty accepts all incoming connections and there is no way to refuse them (but of course they can be closed after being accepted). As far as I know there is no way to refuse an incoming connection from a port selectively from socket API level. Perhaps you need to configure iptables or something similar.  As Norman said there is no way to refuse the connection but you can close it immediately by adding a Netty's IpFilterHandler to server pipeline as the first handler. It will also stop propagating the upstream channel state events for filtered connection too. @ChannelHandler.Sharable public class MyFilterHandler extends IpFilteringHandlerImpl { private final Set<InetSocketAddress> deniedRemoteAddress; public MyFilterHandler(Set<InetSocketAddress> deniedRemoteAddress) { this.deniedRemoteAddress = deniedRemoteAddress; } @Override protected boolean accept(ChannelHandlerContext ctx ChannelEvent e InetSocketAddress inetSocketAddress) throws Exception { return !deniedRemoteAddress.contains(inetSocketAddress); } } if you have list of patterns of IP address to block you can use IpFilterRuleHandler //Example: allow only localhost: new IPFilterRuleHandler().addAll(new IpFilterRuleList(""+n:localhost -n:*""))  If you have several network interfaces and you want to accept connections from one interface only you just need to set the local address in ServerBootstrap. This may be enough if your server is running in a machine that's connected to several networks and you want to serve only one of them. In this case any connection attempts from the other networks would be refused by the OS. Once you have a connection in the application layer it's too late to refuse it. The best you can do is close it immediately. This is enough if for example you want the server available only on localhost and invisible to the outside world: the loopback network 127.0.0.0/8 is served by a separate interface. Edited to note that if you have several network interfaces you can bind just one and have the OS refuse connections on the others. Right. But is there no way to refuse the connection in Netty? (Again I'm sure this has to do with `ServerBootstrap.setParentHandler()`)"
216,A,"Worker threads in netty 4 I am writing a server in which I want to process the messages from clients in separate worker threads. In my channelRead0() of inbound handler I get the message and I want to process the message with a worker thread (my handleWebSocketFrame has to be executed in a worker thread.) . Can anybody tell me how to do it? public class WebSocketSslServerHandler extends SimpleChannelInboundHandler<Object> { .... @Override public void channelRead0(ChannelHandlerContext ctx Object msg) throws Exception { if (msg instanceof WebSocketFrame) { handleWebSocketFrame(ctx (WebSocketFrame) msg); } } } As I understand it the ""channelRead0()"" method is already executed using a worker thread by Netty. You can tune Netty itself to set the amount of worker threads available see comments in [this answer](http://stackoverflow.com/a/14976589/3080094). Thank you for your answer. OK. I've done that Glad to help but please verify it works as expected and if it does maybe describe the solution in an answer to your own question so others can get the same insight. As vanOekel said the ""channelRead0()"" method is already executed using a worker thread by Netty. Since I wanted to run some heavy operation on each client message I can use Java's built in thread pooling technique with in the channelRead0(). I am also incorporating johnstlr's idea of passing a reference of the thread pool to ChannelInitializer used by ServerBootstrap. This can then pass it to WebSocketSslServerHandler in its constructor. public class WebSocketSslServerHandler extends SimpleChannelInboundHandler<Object> { ExecutorService cachedPool; public WebSocketSslServerHandler (ExecutorService pool) { this.cachedPool = pool; } @Override public void channelRead0(ChannelHandlerContext ctx Object msg) throws Exception { if (msg instanceof WebSocketFrame) { cachedPool.submit(new MessageHandler(ctx (WebSocketFrame) msg)); } } } as @johnstlr pointed out or you could add ```EventExecutorGroup``` to your handler (check the doc at http://netty.io/4.0/api/io/netty/channel/ChannelPipeline.html ) and then call ```ctx.executor().submit(new MessageHandler(ctx (WebSocketFrame) msg));``` Thanks johnstlr and jknair. But I couldn't find how to attach the cached thread pool to my handler. I found how it is done for client side but not for server side. Could you help me? I don't know if it's intentional but that code will create a new thread pool for every instance of WebSocketFrame. You want to create the threadpool once when the application starts and submit tasks to the same instance. Assuming you create an instance of your server side handler for each connection you need to pass a reference to the thread pool to the ChannelInitializer used by your ServerBootstrap. This can then pass it to your handler in its constructor (or by some other means). If your handler is shared for all connections you need to pass the thread pool to the handler when you create it. I'm not sure if the same applies to jknair's suggestion as I'm still on Netty 3. Thank you johnstlr"
217,A,Netty: Number of outstanding requests In apache there is server-status page which tells me the current status of the server. In particular it tells me the number of requests currently ('currently' as in at the time when the server-status page is accessed) being processed. Is there some way to find out the same in Netty? It's not built in but conceptually it is easy to implement (or easy to describe anyways ;) ) Create a Sharable ChannelHandler: Implements ChannelUpstreamHandler Implements ChannelDownstreamHandler Add an AtomicInteger field inFlightRequests which is incremented on up and decremented on down. Expose the inFlightRequests through JMX so you can monitor the value. You should also decrement inFlightRequests in a SimpleChannelUpstreamHandler.exeptionCaught callback. You might want to add an errors counter like the inFlightRequests counter which is incremented on caught exceptions. Add the [same] ChannelHandler instance to all created pipelines as the first handler.
218,A,Camel netty c++ java integration I've got a legacy code written in c++ that send and receive data via socket UDP on a port. I need this software inside an enterprise environment using Java as main technology and activeMQ queue as communication channels. My questions: is it possible to use apache camel-netty to do this? Is there any example I can use for this kind of goal? The Camel netty docs is well done and you should easily be up and running with sending and receiving UDP datagrams with Camel. If you want codesamples you have a large set which include sending and receiving UDP in the test cases for camel-netty. You should give camel-netty a spin and try it. The Camel developers have gone done hard work to make sure every aspect of camel-netty is well documented and thouroughly covered by test cases. If you have detailed questions regarding handling a specific aspect of UDP handling in Camel that is not visibly covered by the documentation return here to ask it and surely you will get some help.
219,A,"Running Netty 3.3.1-Final Secure Chat example out of the box gives error ""Client/Server mode not yet set."" I'm running the Netty 3.3.1 Secure Chat example out of the box and it is erroring out. It appears to be the Client that is having the problem--an error that reads ""Client/Server mode not yet set."" I read the documentation on SSLHandler that says ""If isIssueHandshake is false (default) you will need to take care of calling handshake by your own. In most situations were SslHandler is used in 'client mode' you want to issue a handshake once the connection was established. if setIssueHandshake is set to true you don't need to worry about this as the SslHandler will take care of it. "" I tried setting setIssueHandshake to true in the client before the sslHandler.handshake method was called but that did not change/fix the error. Any guesses? Thank you for any assistance for this netty newbie! This is the client output: Mar 2 2012 10:25:27 AM securechat.SecureChatClientHandler handleUpstream INFO: [id: 0x00c2a132] OPEN Mar 2 2012 10:25:27 AM securechat.SecureChatClientHandler handleUpstream INFO: [id: 0x00c2a132 /127.0.0.1:3082 => localhost/127.0.0.1:8443] BOUND: /127.0.0.1:3082 Mar 2 2012 10:25:27 AM securechat.SecureChatClientHandler handleUpstream INFO: [id: 0x00c2a132 /127.0.0.1:3082 => localhost/127.0.0.1:8443] CONNECTED: localhost/127.0.0.1:8443 Mar 2 2012 10:25:27 AM securechat.SecureChatClientHandler exceptionCaught WARNING: Unexpected exception from downstream. java.lang.IllegalStateException: Client/Server mode not yet set. at com.sun.net.ssl.internal.ssl.SSLEngineImpl.kickstartHandshake(SSLEngineImpl.java:609) at com.sun.net.ssl.internal.ssl.SSLEngineImpl.beginHandshake(SSLEngineImpl.java:667) at org.jboss.netty.handler.ssl.SslHandler.handshake(SslHandler.java:358) at securechat.SecureChatClientHandler.channelConnected(SecureChatClientHandler.java:54) at securechat.SecureChatClientHandler.handleUpstream(SecureChatClientHandler.java:43) at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:61) at org.jboss.netty.handler.ssl.SslHandler.channelConnected(SslHandler.java:1202) at org.jboss.netty.channel.Channels.fireChannelConnected(Channels.java:227) at org.jboss.netty.channel.socket.nio.NioWorker$RegisterTask.run(NioWorker.java:786) at org.jboss.netty.channel.socket.nio.NioWorker.processRegisterTaskQueue(NioWorker.java:250) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:192) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:619) This is the server output: INFO: [id: 0x01893efe /127.0.0.1:3082 => /127.0.0.1:8443] OPEN Mar 2 2012 10:25:27 AM securechat.SecureChatServerHandler handleUpstream INFO: [id: 0x01893efe /127.0.0.1:3082 => /127.0.0.1:8443] BOUND: /127.0.0.1:8443 Mar 2 2012 10:25:27 AM securechat.SecureChatServerHandler handleUpstream INFO: [id: 0x01893efe /127.0.0.1:3082 => /127.0.0.1:8443] CONNECTED: /127.0.0.1:3082 It's a known bug in the example. If you take a look into SecureChatClientPipelineFactory.java you'll see that the line that calls SSLEngine.setUseClientMode(true) has been commented out by mistake. Please uncomment it and then it will work. This issue has been fixed in 3.4.0.Alpha1."
220,A,"Netty ServerBootstrap - asynchronous binding? First here's a reference to where I read all of what I know now regarding this question: http://docs.jboss.org/netty/3.2/api/org/jboss/netty/bootstrap/ServerBootstrap.html#bind%28%29 Although not explicitly specified by the documentation it would seem that ServerBootstrap.bind is synchronous - because it does not return a ChannelFuture but rather a Channel. If that is the case then I do not see any way to make an asynchronous bind using the ServerBootstrap class. Am I missing something or will I have to roll my own solution? Best regards I ended up rolling my own bootstrap implementation with the following addition: public ChannelFuture bindAsync(final SocketAddress localAddress) { if (localAddress == null) { throw new NullPointerException(""localAddress""); } final BlockingQueue<ChannelFuture> futureQueue = new LinkedBlockingQueue<ChannelFuture>(); ChannelHandler binder = new Binder(localAddress futureQueue); ChannelHandler parentHandler = getParentHandler(); ChannelPipeline bossPipeline = pipeline(); bossPipeline.addLast(""binder"" binder); if (parentHandler != null) { bossPipeline.addLast(""userHandler"" parentHandler); } getFactory().newChannel(bossPipeline); ChannelFuture future = null; boolean interrupted = false; do { try { future = futureQueue.poll(Integer.MAX_VALUE TimeUnit.SECONDS); } catch (InterruptedException e) { interrupted = true; } } while (future == null); if (interrupted) { Thread.currentThread().interrupt(); } return future; }  In Netty 3.6 there is an async bind. Here's the javadoc: http://netty.io/3.6/api/org/jboss/netty/bootstrap/ServerBootstrap.html#bindAsync()"
221,A,cURL <-> Netty: getContent over 1024 characters I am using LittleProxy which implements Netty . I am trying to receive the content of an HTTP request (which contains XML). This works perfectly until I receive content over 1024 characters (bytes?). I still see the request coming in and I can see the correct content-length from the HTTP header. However the content is not returned at all (empty string). How can I receive more content? My HTTP requests contain SOAP message sent by cURL who will definitely exceed 1024 bytes. Hmmm I am starting to suspect this a cURL problem (which I am using to send a HTTP POST request with XML). Add code. Please. We won't be able to solve your problem without knowing it... I am using the LittleProxy source code almost unaltered... The code is here: https://github.com/adamfisk/LittleProxy It was a cURL problem apparently there are some complications when sending a file over 1024 bytes. Since I used cURL purely for testing purposes I moved to a simple Java program to send my SOAP messages. Now LittleProxy (or Netty) handles the content just fine way passed 1024 bytes.
222,A,"Building Netty on Mac OSX Lion under Java 1.6.x I'm trying to build The Netty Project on Mac OS X Lion which has Java 1.6.x. (IDE: NetBeans). Then I get the following error: [enforcer:enforce] Rule 0: org.apache.maven.plugins.enforcer.RequireJavaVersion failed with message: Detected JDK Version: 1.6.0-31 is not in the allowed range [1.7.0). ------------------------------------------------------------------------ BUILD FAILURE ------------------------------------------------------------------------ If Netty only requires java 1.5 or above I'm looking for a way to enable compiling under java 1.6.x. Thanks in advance. Did you download the source for the stable release or an unstable release? The download page says ""JDK 1.5 or above is all that you need to run Netty. However the unstable releases might require a newer JDK version."" I downloaded the stable version available at site. netty-3.4.2.Final-dist.tar.bz2 (Stable 27-Apr-2012) You need to have java7 to build but only require java5 to run. This is because we enable/disable some features at runtime depending on the java version. See also [1]. [1] https://github.com/netty/netty/blob/4e528c10fae3abaa932e751c831aa48a23645744/README.md Thanks. Since I'm using mac I'd have to wait for official java 7 for mac or use previous netty release till then. Java7 for osx is out. See http://www.oracle.com/technetwork/java/javase/downloads/index.html. Im also using osx BTW you can run netty 3.4.x also with java5 just not compile it. I was waiting for the update from Apple. But now I'm using java 7 on my mac thanks to you."
223,A,"Netty 4 - Slicing issue I am trying to create a zero-copy application with netty 4.0.10.Final. I have problems with slicing. Here is my decode (problematic) method: @Override protected void decode(ChannelHandlerContext chc ByteBuf bb List<Object> list) throws Exception { int readableBytes = bb.readableBytes(); if (readableBytes < LENGTH_OF_HEADER) { LOGGER.debug(""skipping bb - too few data for header: "" + readableBytes); return; } int length = bb.getUnsignedShort(bb.readerIndex() + LENGTH_INDEX_IN_HEADER); LOGGER.debug(""length of actual message: {}"" length); if (readableBytes < length) { if (LOGGER.isDebugEnabled()) { LOGGER.debug(""skipping bb - too few data for msg: "" + readableBytes + "" < "" + length); LOGGER.debug(""bb: "" + ByteBufUtils.byteBufToHexString(bb)); } return; } LOGGER.debug(""whole bb: "" + ByteBufUtils.byteBufToHexString(bb)); LOGGER.debug(""Protocol message received type:{}"" bb.getByte(bb.readerIndex() + 1)); ByteBuf messageBuffer = bb.slice(bb.readerIndex() length); list.add(messageBuffer); bb.skipBytes(length); bb.retain(); LOGGER.debug(""BB after slice: "" + ByteBufUtils.byteBufToHexString(bb)); } My application / netty can receive also incomplete messages. Whole pipeline processing works fine while whole messages are received. My pipeline starts at ServerBootstrap -> ChannelInitializer -> ByteToMessageDecoder -> ByteToMessageDecoder -> MessageToMessageDecoder. Problem occurs when a frame with incomplete message arrives. Typical usecase: - received frame shorter then expected message (messages have length field in the header) - received another frame that completes the incomplete message and carries another incomplete message - slice for complete message is created and incomplete message waits for the rest of its body (all three .byteBufToHexString() logs are correct) - slice is passed to the next ChannelHandler (which is also ByteToMessageDecoder) - the data sent inside the sliced-bytebuf has been changed - bytes of incomplete message are used instead of the complete message bytes - if the complete message is longer than the incomplete one (usually it is) the rest of the complete message bytes is used Example (bold - complete message italics - incomplete message): Original buffer - 01 02 03 04 05 06 07 08 09 0A Sliced buffer - 01 02 03 04 05 06 07 Next-handler buffer - 08 09 0A 04 05 06 07 This happens only with first ""framed"" message and the incomplete message. Messages between these two look fine. Same result with .readSlice(). Copying data works (as the data in copied bytebufs are not shared) Does anyone see a mistake ? Can anyone help ? I think this was fixed in Netty 4.0.12.Final as port of this commit: https://github.com/netty/netty/commit/8930cefab8640fa1bef3d1d49f93a23184b1bafe Thank you bumping netty's version solves the problem. (I must check changelog more carefully next time) awesome... Thanks for let me know. I must admit the commit message was also not very helpful here :/ Shame on me"
224,A,"Decoding GET and POST methods with Netty I need to create a server application with Netty that will receive requests both like ""GETs"" or ""POSTs"". In case of GET requests the parameters would come as query parameters. I have been checking that HttpRequestDecoder would be suitable for the GET requests and HttpPostRequestDecoder for the post. But how could I handle both at the same time? Not very familiar with Netty so I would appretiate a little bit of help :) You want to first check the request type and switch on the value (GET/POST/PUT/DELETE etc...) http://docs.jboss.org/netty/3.1/api/org/jboss/netty/handler/codec/http/HttpMethod.html  The netty provisions us to handle a request as a pipeline where you define the pipeline as a sequence of handlers. One sequence could be like this: p.addLast (""codec"" new HttpServerCodec ()); p.addLast (""handler"" new YourHandler()); where p is an instance of ChannelPipeline interface. You can define the YourHandler class as follows: public class YourHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead (ChannelHandlerContext channelHandlerCtxt Object msg) throws Exception { // Handle requests as switch cases. GET POST... // This post helps you to understanding switch case usage on strings: // http://stackoverflow.com/questions/338206/switch-statement-with-strings-in-java if (msg instanceof FullHttpRequest) { FullHttpRequest fullHttpRequest = (FullHttpRequest) msg; switch (fullHttpRequest.getMethod ().toString ()) { case ""GET"": case ""POST"": ... } } } } You can use the instance of directive to know which kind of object it is: if (msg instanceof FullHttpRequest) { FullHttpRequest fullHttpRequest = (FullHttpRequest) msg; } I have updated the code snippet in my answer for more clarity! I have tried this approach but I can not map the msg as FullHttpRequest. Channel read is called many times with different objects: DefaultHttpRequest LastHttpContent."
225,A,"messageReceived (netty) not called my source TestMessage - is my protobuf object  @Override public ChannelPipeline getPipeline() { ChannelPipeline next = Channels.pipeline(); next.addLast(""frameDecoder"" new ProtobufVarint32FrameDecoder()); next.addLast(""protobufDecoder"" new ProtobufDecoder(TestMessage.getDefaultInstance())); next.addLast(""frameEncoder"" new ProtobufVarint32LengthFieldPrepender()); next.addLast(""protobufEncoder"" new ProtobufEncoder()); return next; } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { Channel ch = e.getChannel(); if (ch.isOpen()) { TestMessage req = (TestMessage) e.getMessage(); System.out.println(req.getMessage()); ch.close(); } } send Socket fromserver = new Socket(""localhost"" 7283); PrintWriter out = new PrintWriter(fromserver.getOutputStream() true); TestMessage.Builder message = TestMessage.newBuilder(); message.setMessage(""message .....""); message.build(); out.println(message); out.close(); fromserver.close(); I have a question. Where is messageReceived()? ProtobufVarint32FrameDecoder ProtobufDecoder ProtobufVarint32LengthFieldPrepender ProtobufEncoder four classes are in netty. But messageReceived() method must locate in CustomHandler class. And the class have to add next instance of ChannelPipeline. ex) if i make a ProtobufHandler class(extends SimpleChannelHandler) for messageReceived() ChannelPipeline next = Channels.pipeline(); next.addLast(""frameDecoder"" new ProtobufVarint32FrameDecoder()); next.addLast(""protobufDecoder"" new ProtobufDecoder(TestMessage.getDefaultInstance())); next.addLast(""frameEncoder"" new ProtobufVarint32LengthFieldPrepender()); next.addLast(""protobufEncoder"" new ProtobufEncoder()); next.addLast(""protobufHandler"" new ProtobufHandler()); //add this. sorry I have limited English proficiency."
226,A,Netty 4.x Http Multipart Package Where is the io.netty.handler.codec.http.multipart package in the latest Netty 4 Alpha releases? The all-in-one JAR file netty-4.0.0.Alpha5.jar doesn't have the package and the code is not in the master branch in github... Thank you! It's not ported yet... It's on the to-do list and should be done before final is cut.
227,A,Netty client multiple requests First I'll explain the situation and the logic that I'm trying to implement: I have multiple threads each put result of it work some object called Result into queue QueueToSend My NettyClient runs in thread and takes Result from QueueToSend every 1 milisecond and should connect to server and send a message that is created from Result. I also need this connections to be asynch. So I need the Result list to be known by NettyHandler to send right message and process right result and then again send response. So I initialize NettyClient bootstrap bootstrap = new ClientBootstrap( new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); and sets pipeline once when app starts. Then every milisecond I take Result object from QueueToSend and connect to server ChannelFuture future = bootstrap.connect(new InetSocketAddress(hostport); ResultConcurrentHashMap.put(future.getChannel().getId() result); I decided to use static ConcurrentHashMap to save every result object taken from QueueToSend assosiated with channel. The first problem takes place in NettyHandler in method channelConnected when I am trying to take Result object assosiated with channel from ResultConcurrentHashMap. @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) { Channel channel = ctx.getPipeline.getChannel(); Result result = ResultConcurrentHashMap.get(channel.getId()); } But sometimes result is null (1 of 50) even thought it should be in ResultConcurrentHashMap. I think it happens cause that channelConnected event happens before NettyClient runs this code: ResultConcurrentHashMap.put(future.getChannel().getId() result); May be it will not appear if I run NettyServer and NettyClient not on localhost both but remotely it will take moretime to estabilish the connection. But I need a solution for this issue. Another issue is that I am sending messages every 1 milisecond asynchromously and I suppose that messages are may be mixed and server can not read them properly. If I run them one by one it will be ok : future.getChannel().getCloseFuture().awaitUninterruptibly(); But I need asynchromus sending and process right results assosiated with channel and send responses. What should I implement? ChannelFutures are executed asynchronously before the events get fired. For example channel connect future will be completed before firing the channel connected event. So you have to register a channel future listener after calling bootstrap.connect() and write your code in the listener to initialize the HashMap then it will be visible to the handler.  ChannelFuture channelFuture = bootstrap.connect(remoteAddress localAddress); channelFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { resultConcurrentHashMap.put(future.getChannel().getId() result); } }); I guess you have to interchange data between threads (result producer Netty client) using a blocking queue not a hashmap. After calling bootstrap.connect() create a BlockingQueue as a channel local. the handler can lookup for the queue when client its ready to send and poll the queue for every 1 ms. from result producer just offer the data.No data will be lost because of delayed netty client start. Thanks for your replay. But it will not work in my case. I have big amount of result produser and need to keep asynchronous channels sending reciving messages as much as i can. Now i am 90% ready to say that frame mixing is server problem. Your first answer helped of to solve first problem so i accept your answer. thanks My NettyClient takes result object from queue every 1 milisec so the result object changes in netty client every 1 milisec if cannel connection will appear in 2 milisec I will have another result object assosiated with this channel? Or not?
228,A,JBoss Netty : Support for SNI (Server Name Indication) Does the SSL implementation in JBoss Netty support Server Name Indication? It's more or less the same answer as for this question: Java 7 supports SNI but only from the client side. Yes. Thanks. I see that now.
229,A,How to marry NioServerSocketChannelFactory and WorkManager I am looking to implement a JCA Resource adapter to accept socket connections from within J2EE container. I need to somehow be able to use WorkManager to manage threads in netty's NioServerSocketChannelFactory Any Help is greatly appreciated. Got it! NioServerSocketChannelFactory takes two Executor(s) boss and worker as parameters to the constructor. so all I need to do is develop a facade to WorkManager to implement execute(Runnable) method that will use workManager.schedule(...) call.
230,A,"Conditional ExecutionHandler in pipeline The server I'm developing has different tasks to perform based on messages received from clients some tasks are very simple and require little time to perform but other may take a while. Adding an ExecutionHandler to the pipeline seems like a good solution for the complicated tasks but I would like to avoid threading simple tasks. My pipeline looks like this: pipeline.addLast(""decoder"" new MessageDecoder()); pipeline.addLast(""encoder"" new MessageEncoder()); pipeline.addLast(""executor"" this.executionHandler); pipeline.addLast(""handler"" new ServerHandler(this.networkingListener)); Where MessageEncoder returns a Message object (for decode) which defines the requested task. Is there a way to skip the execution handler based on the decoded message? The question can be generalized to: is there a way to condition whether or not the next handler will be used? Thanks. Instead of using ExecutionHandler as is you can extend it to override its handlerUpstream() method to intercept the upstream events and call ctx.sendUpstream(e) for the MessageEvents whose message meets your criteria. All other events could be handled by the ExecutionHandler via super.sendUpstream(e). That is: public class MyExecutionHandler extends ExecutionHandler { public void handleUpstream(ctx evt) throws Exception { if (evt instanceof MessageEvent) { Object msg = ((MessageEvent) evt).getMessage(); if (msg instanceof ExecutionSkippable) { ctx.sendUpstream(evt); return; } } super.handleUpstream(evt); } ... }  You can remove it (or add it on demand) from the pipeline inside your MessageDecoder before you send the message upstream. You can also check the message inside your executionHandler and just pass it upstream. In case you cannot modify these two files you can create another handler which removes executionHandler based on the message type. I understand that from the `MessageDecoder.decode` method I can get the pipeline from the `ChannelHandlerContext` and remove/add the `ExecutionHandler` but I would rather deal with that logic in the `ExecutionHandler` itself how can that be done? Probably by overriding `handleUpstream` but how should I implement it? just return in case it's a simple task?"
231,A,Netty java.io.StreamCorruptedException: Unsupported version: 0 Hello，I'm developing a server which is using Netty.The goal is to be able to send objects back and forth.So I configured the server with using ObjectDecoderInputStream and ObjectEncoderOutputStream. so I have a client also using Netty to communicate with the server. The client work well. Whenever I use Java's socket to receive an Serializable Object from the server. Something strange happened I got an exception below: java.io.StreamCorruptedException: Unsupported version: 0 at org.jboss.netty.handler.codec.serialization.CompactObjectInputStream.readStreamHeader(CompactObjectInputStream.java:38) at java.io.ObjectInputStream.<init>(Unknown Source) at org.jboss.netty.handler.codec.serialization.CompactObjectInputStream.<init>(CompactObjectInputStream.java:30) at org.jboss.netty.handler.codec.serialization.ObjectDecoderInputStream.readObject(ObjectDecoderInputStream.java:115) at com.bvd.main.Client.readResponse(Client.java:139) at com.bvd.main.Client.getFile(Client.java:80) at com.bvd.main.Client.main(Client.java:163) Sending an object from the client:  public static void writeRequest(Message requestMsg OutputStream outputStream) { byte[] bytes = null; ByteArrayOutputStream byteOutputStream = new ByteArrayOutputStream(); try { ObjectEncoderOutputStream objectOutputStream = new ObjectEncoderOutputStream( byteOutputStream 8192); objectOutputStream.writeObject(requestMsg); objectOutputStream.flush(); bytes = byteOutputStream.toByteArray(); byteOutputStream.close(); objectOutputStream.close(); outputStream.write(bytes); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } } and the code that the client received an object:  public static Object readResponse(InputStream inputStream) { int count = 0; Object object = null; try { byte[] lenBuffer = new byte[4]; while ((count = inputStream.read(lenBuffer)) < 4) { } System.out.println(ByteBuffer.wrap(lenBuffer).getInt()); int infolen = ByteBuffer.wrap(lenBuffer).getInt(); byte[] objBuffer = new byte[infolen]; while ((count = inputStream.read(objBuffer)) < infolen) { } byte[] totalBuf = new byte[4 + infolen]; System.arraycopy(lenBuffer 0 totalBuf 0 lenBuffer.length); System.arraycopy(objBuffer 0 totalBuf lenBuffer.length objBuffer.length); ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream( totalBuf); System.out.println(byteArrayInputStream.available()); ObjectDecoderInputStream objectDecoderInputStream = new ObjectDecoderInputStream( new BufferedInputStream(byteArrayInputStream)); object = objectDecoderInputStream.readObject(); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } catch (ClassNotFoundException e) { // TODO Auto-generated catch block e.printStackTrace(); } return object; } What confuse me more is when I set the length of an object's content being sent(the object carries part of a file that have been converted to byte[])on the server of 2858(byte) the client above works well; and when I change the length 2859 or bigger the StreamCorruptedException occurs above. ps: sending objects work well the server received successfully and decode it correctly all the questions are about objects receiving from the server. Sorry for my poor English any help is appreciated. Thanks. in both of your read loops your are going to get bogus data if you end up making more than one read call:  while ((count = inputStream.read(lenBuffer)) < 4) { } while ((count = inputStream.read(objBuffer)) < infolen) { } every time you call read it will write to the beginning of the byte[]. so each time you loop around you are overwriting part of the data in the buffer not reading an entire buffer's worth of data. you need to keep track of the current offset (based on the amount of data you have read so far) and pass that into thread read() call. also you should be accumulating to count not assigning to it. Sorry to reply you so late. I made a mistake that the **read()** method can be blocked to read enough bytes I want. I had solved the problem so I write a method to read any length of bytes I need.
232,A,"Apache Camel - from netty to file I'm using the netty component for socket communication between two systems request and response. This is the route <from uri=""netty:tcp://localhost:61616?encoder=#encoder""/> <to uri=""netty:tcp://localhost:61618?decoder=#decoder""/> <log message=""Receive ${body}""> <to uri=""file://data?fileName=data2&amp;charset=utf-8""/> Everything works fine the data I send is buffer type as well as the response received. I can see this data as String using the log ${body} but there's nothing in the file where is suppossed to store this data. I'm guessing that camel uses a converter (from buffer to string) for logging the body as plain text but why is not saving something in the file using a default converter for this???? I appreciate any comments of how to resolve this. Thank you !!! Since your paylaod is ByteBuffer you need to explicitly convert to either String or byte[] <from uri=""netty:tcp://localhost:61616?encoder=#encoder""/> <to uri=""netty:tcp://localhost:61618?decoder=#decoder""/> <convertBodyTo type=""byte[]""/> <log message=""Receive ${body}""> <to uri=""file://data?fileName=data2&amp;charset=utf-8""/> You can even use type=""java.lang.String"" Please refer to the link http://camel.apache.org/type-converter.html Hope it helps... Thank you. I was close using  which doesn't works of course :P."
233,A,"Receiving larger bytebuffer Android I'm using the framework Netty with Android and having problems when I receive large amounts of data: @Override public void channelRead(final ChannelHandlerContext ctx Object msg) { bufferIn = (ByteBuf) msg; if (bufferIn.readableBytes() >= 4) { size = bufferIn.readInt(); result = bufferIn.toString(CharsetUtil.ISO_8859_1); if(size == result.length){ Log.d(""D"" ""RECEIVED: "" + size + "" "" + result); } ctx.flush(); } bufferIn.release(); } When I receive the data it comes in packets and I'm not knowing how to receive that parcels. Thanks I add the line: ch.pipeline().addLast(new NettyDecoder() new NettyHandler(service size message listener)); On the decoder: class NettyDecoder extends ByteToMessageDecoder @Override protected void decode(final ChannelHandlerContext theContext final ByteBuf in List<Object> out) throws Exception { if (in.readableBytes() < 4) { return; } in.markReaderIndex(); int dataLength = in.readInt(); if (in.readableBytes() < dataLength) { in.resetReaderIndex(); return; } byte[] decoded = new byte[dataLength]; in.readBytes(decoded); out.add(decoded); //out.add(in.readBytes(in.readableBytes())); } On the handler: void channelRead(final ChannelHandlerContext ctx Object msg) { ByteBuf m = (ByteBuf) msg; bufferIn.writeBytes(m); m.release(); if (bufferIn.readableBytes() >= 4) { size = bufferIn.readInt(); for (int i = 0; i < bufferIn.capacity(); i ++) { byte b = bufferIn.getByte(i); result += (char) b; } } Log.d(""WEB"" ""RESULT: "" + size + "" "" + result.getBytes().length + "" "" + result); bufferIn.release(); But now I don't receive any message on the NettyHandler. Can someone teachs me how to receive the messages on the handler? I think you want to extend ByteToMessageDecoder and let it do the job of aggregation of needed. See the javadocs of it for more details. There are many codecs that use it within netty... Just check the codec module. Ok Norman I'll look for that do you know where can I find a example?"
234,A,"camel-netty causing deadlock when multiple tcp stations are configured in route I m getting the following exception when trying to use more than two netty endpoints in a single route. java.lang.IllegalStateException: await*() in I/O thread causes a dead lock or sudden performance drop. Use addListener() instead or call await*() from a different thread. Sample route :  from(""netty:tcp://localhost:7000?textline=true"") .bean(DummyProcessor.class) .to(""netty:tcp://localhost:7001?textline=true"") .bean(DummyProcessor.class) .to(""netty:tcp://localhost:7002?textline=true"") .bean(DummyProcessor.class) .to(""netty:tcp://localhost:7003?textline=true"") .bean(DummyProcessor.class) .to(""netty:tcp://localhost:7004?textline=true"") .bean(DummyProcessor.class); camel version : 2.11 netty 3.6.5 possible duplicate Deadlock when using netty with Apache Camel This has been fixed by CAMEL-6442: https://issues.apache.org/jira/browse/CAMEL-6442"
235,A,"Netty handlers for different URL I have simple netty4 server with one handler public class UploadServer { private final int port; public UploadServer(int port) { this.port = port; } public void run() throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ServerInitializer()); Channel ch = b.bind(port).sync().channel(); ch.closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port; if (args.length > 0) { port = Integer.parseInt(args[0]); } else { port = 8080; } new UploadServer(port).run(); } private class ServerInitializer extends ChannelInitializer<SocketChannel>{ @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline p = ch.pipeline(); p.addLast(""decoder"" new HttpRequestDecoder()); p.addLast(""encoder"" new HttpResponseEncoder()); p.addLast(""handler"" new UploadServerHandler()); } } and this handler public class UploadServerHandler extends SimpleChannelInboundHandler<Object> { @Override protected void channelRead0(ChannelHandlerContext channelHandlerContext Object o) throws Exception { System.out.println(""HEllO""); } } and i have two problems: if i start this project and go to localhost:8080 in browser i see two ""HEllO"" in console. the i want know how implement mapping some little handlers for different url in my uploadserverhandler. sorry for bad englsh The two ""Hello"" in the console are probably related to the fact that your browser is making two calls one for index.html and the other for the favicon. You can use curl or wget to avoid requesting the favicon. For url mapping different handlers the way I do it (not sure that it is the best way though) is that I get the URI in the main handler with:  String uri = request.getUri(); and then test the URI against my knwown URIs and redirect to other handlers accordingly. Thank you! but what about request with parameters? look like ""xxx.net/getbyname?name=mike""? Re: request params - Use [QueryStringDecoder](http://netty.io/4.0/api/io/netty/handler/codec/http/QueryStringDecoder.html)  Java have a look at this once. Let me know is this what you are looking for ?"
236,A,"Netty vs Apache MINA They both provide roughly the same functionality. Which one should I choose to develop my high-performance TCP server? What are the pros & cons? Would also be interesting to add Grizzly to the comparison. Grizzly is a completely different beast. There was even the idea of Grizzly support for MINA when the both groups talked. @Hardcoded you say grizzly is a completely different beast I'm a new comer to this can you please point out the differences or give me an article to read on that? I'd really appreciate it. Grizzly has a different background and the last time I look at it it was mostly suited to HTTP-based applications. I just looked at the examples and was surprised to see that they are using very similar structure as with MINA or Netty. So the beast isn't that different anymore I performance tested 2 ""Google Protobuffer RPC"" implementations where one was based on Netty (netty-protobuf-rpc) and the other based on mina (protobuf-mina-rpc). Netty ended up being consistently faster ( +- 10% ) for all message sizes - which backs up the overall performance claim on the Netty web site. Since you want to squeeze every bit of efficiency out of your code when you use such an RPC library i ended up writing protobuf-rpc-pro based on Netty. I have used MINA in the past but find their documentation of the 2.0 stuff has big holes and the breaking of API backward compatibility a big minus.  MINA has more out-of-the-box features at the cost of complexity and relatively poor performance. Some of those features were integrated into the core too tightly to be removed even if they are not needed by a user. In Netty I tried to address such design issues while retaining the known strengths of MINA. Currently most features available in MINA are also available in Netty. In my opinion Netty has cleaner and more documented API since Netty is the result of trying to rebuild MINA from scratch and address the known issues. If you find that an essential feature is missing please feel free to post your suggestion to the forum. I'd be glad to address your concern. It is also important to note that Netty has faster development cycle. Simply check out the release date of the recent releases. Also you should consider that MINA team will proceed to a major rewrite MINA 3 which means they will break the API compatibility completely. Oh @trustin is the author of both MINA and Netty.  I prefer Netty. Twitter also chose Netty to build its new Search System and sped it up to 3x faster. Ref: Twitter Search is Now 3x Faster We chose Netty over some of its other competitors like Mina and Jetty because it has a cleaner API better documentation and more importantly because several other projects at Twitter are using this framework.  While MINA and Netty have similar ambitions they are quite different in practice and you should consider your choice carefully. We were lucky in that we had lots of experience with MINA and had the time to play around with Netty. We especially liked the cleaner API and much better documentation. Performance seemed better on paper too. More importantly we knew that Trustin Lee would be on hand to answer any questions we had and he certainly did that. We found everything easier in Netty. Period. While we were trying to reimplement the same functionality we already had on MINA we did so from scratch. By following the excellent documentation and examples we ended up with more functionality in much much less code. The Netty Pipeline worked better for us. It is somehow simpler than MINAs where everything is a handler and it is up to you to decide whether to handle upstream events downstream events both or consume more low-level stuff. Gobbling bytes in ""replaying"" decoders was almost a pleasure. It was also very nice to be able to reconfigure the pipeline on-the-fly so easily. But the star attraction of Netty imho is the ability to create pipeline handlers with a ""coverage of one"". You've probably read about this coverage annotation already in the documentation but essentially it gives you state in a single line of code. With no messing around no session maps synchronization and stuff like that we were simply able to declare regular variables (say ""username"") and use them. But then we hit a roadblock. We already had a multi-protocol server under MINA in which our application protocol ran over TCP/IP HTTP and UDP. When we switched to Netty we added SSL and HTTPS to the list in a matter of minutes! So far so good but when it came to UDP we realised that we had slipped up. MINA was very nice to us in that we could treat UDP as a ""connected"" protocol. Under Netty there is no such abstraction. UDP is connectionless and Netty treats it as such. Netty exposes more of the connectionless nature of UDP at a lower level than MINA does. There are things you can do with UDP under Netty than you can't under the higher-level abstraction that MINA provides but on which we relied. It is not so simple to add a ""connected UDP"" wrapper or something. Given time constraints and on Trustin's advice that the best way to proceed was to implement our own transport provider in Netty which would not be quick we had to abandon Netty in the end. So look hard at the differences between them and quickly get to a stage where you can test any tricky functionality is working as expected. If you're satisfied that Netty will do the job then I wouldn't hesitate to go with it over MINA. If you're moving from MINA to Netty then the same applies but it is worth noting that the two APIs really are significantly different and you should consider a virtual rewrite for Netty - you won't regret it! re: earlier comment by Josh on lack of support for UDP in Netty: I don't understand why you couldn't use a few pages of hand-crafted code to do what you need rather than abandoning Netty. UDP is listening on a different port anyway. I have been testing Netty vs. Nginx and am quite impressed (Netty scoring about the same or better under load).  In Netty site you can find some performance reports. As expected :-) they point out Netty as the framework with the best performance. I never used Netty but I already used MINA to implement a TCP protocol. The implementation of encoding and decoding was easy but the implementation of the state machine was not so easy. MINA provides some classes to aid you when implementing the state machine but I found them kind of hard to use. In the end we decided to ditch MINA and implement the protocol from scratch and surprisingly we ended with a faster server.  MINA and Netty were initially designed and build by the same author. That's why they are so similiar to each other. MINA is designed at a slightly higher level with a little more features while Netty is a little faster. I think that there's not much difference at all the basic concepts are the same.  I've only ever used MINA to build a small http like server. The biggest problems I've run into with it so far: It will hold your ""request"" and ""response"" in memory. This is only an issue because the protocol I choose to use is http. You could use your own protocol however to get around this. No option to provide a stream off disk in case you want to serve up large files. Again can be worked around by implementing your own protocol Nice things about it: Can handle a lot of connections If you choose to implement some sort of distributed work system then knowing when one of your nodes goes down and loses connection is useful for restarting the work on another node. When you say ""stream off disk for large files"" don't people normally use UDP for that? No. They use kernel sendfile (exposed in Java as FileChannel.transferTo) over TCP."
237,A,netty threads distribution A Channel is attached to a single EventLoop durring Channel.Unsafe#register. The registration is distributed by a modulo operation in EventExecutorGroup#next. A ChannelHandlerContext is bound to a single thread -- often the same thread as the Channel. Channels may be unevenly deregistered or the workload is unevenly distributed between these channels. By chance it is possible to have a single thread handling the complete workload. Is there a pattern to prevent this case or is this an unavoidable structural problem? You can force to use just one Thread if you construct the NioEventLoopGroup with the argument 1 . Other then that I think we could only improve it by calculate how many channels are on an EventLoop and choose the next based on this. But even this may not be a good way as some Channel may do more heavy work then the others. So it is a structural trait and the thread model has to be rewritten to prevent excessive load on a single thread bound to multiple channels. I'll test if individual dispatching to others may act as a workaround. Should I file an issue?
238,A,"How to get Netty websocket client example working I'm struggling to get the netty example websocket client working. I've compiled successfully with 4.0.0.Alpha8 but when I try to connect to a server (also a netty example) I get: Exception in thread ""main"" io.netty.handler.codec.http.websocketx.WebSocketHandshakeException: Invalid handshake response upgrade: websocket at io.netty.handler.codec.http.websocketx.WebSocketClientHandshaker13.finishHandshake(WebSocketClientHandshaker13.java:204) which makes no sense to me whatsoever given that this piece of code reads:  String upgrade = response.getHeader(Names.UPGRADE); if (!Values.WEBSOCKET.equalsIgnoreCase(upgrade)) { throw new WebSocketHandshakeException(""Invalid handshake response upgrade: "" + response.getHeader(Names.UPGRADE)); } And as the message in the exception demonstrates the Upgrade header does contain websocket as expected. Any idea what's going on? Use latest code from master. I just fixed this two days ago... Ah! I was looking at master and didn't realise that it had changed since 4.0.0.Alpha8. Thanks! Any idea when this will make it into a release? I'm not sure that I'm up to working out how to build and install a local version of netty just yet :-) You can find the snapshots here: https://repository-netty.forge.cloudbees.com/snapshot/ Just add SslHandler in the ChannelPipeline and WSS will be used. https://github.com/netty/netty/tree/master/example/src/main/java/io/netty/example/http/websocketx/client indicates only ws is handled is wss handled ? where can I find an example? Thanks  Try using the latest in master. I've just done so and running io.netty.example.http.websocketx.client.WebSocketClient against io.netty.example.http.websocketx.html5.WebSocketServer seems to work for me. WebSocket Client connecting WebSocket Client connected! WebSocket Client sending message WebSocket Client sending ping WebSocket Client sending close WebSocket Client received message: MESSAGE #0 WebSocket Client received pong WebSocket Client disconnected!"
239,A,"Issues getting Netty sample ""HttpUploadServer"" to read HTTP PUT data works fine with HTTP POST I am trying to get the sample Netty HttpUploadServer to receive an uploaded file via HTTP PUT code found here: https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/http/upload/HttpUploadServerHandler.java To test an HTTP POST file upload I use this curl command: curl -F ""myfile=@testfile.txt"" http://127.0.0.1:8080 To test an HTTP PUT file upload I use this curl command: curl -T ""testfile.txt"" http://127.0.0.1:8080 I commented out the writeMenu and return as i'm using curl and not a web browser. Using curl to POST everything seems to work fine however with PUT I am not getting any data in readHttpDataAllRecieve (HttpUploadServerhandler): private void readHttpDataAllReceive(Channel channel) { List<InterfaceHttpData> datas = null; try { datas = decoder.getBodyHttpDatas(); System.out.println(""size "" + datas.size()); } catch (NotEnoughDataDecoderException e1) { // Should not be! e1.printStackTrace(); responseContent.append(e1.getMessage()); writeResponse(channel); Channels.close(channel); return; } for (InterfaceHttpData data: datas) { writeHttpData(data); } responseContent.append(""\r\n\r\nEND OF CONTENT AT FINAL END\r\n""); } datas = decoder.getBodyHttpDatas(); datas always has a 0 size with PUT but not with POST. Thanks for any ideas I'm not a CURL expert but maybe CURL is just sending the file ""as is"" when you PUT rather than as multipart MIME when you POST. The content type for a PUT is typically the type of the file; e.g. text/xml. For a post it is multipart/form-data HttpPostRequestDecoder read and decodes multipart MIME. See comments at https://github.com/netty/netty/blob/master/codec-http/src/main/java/io/netty/handler/codec/http/HttpPostRequestDecoder.java#L187 The end result is that for PUT from CURL check if you can change the content type of multi-part/formdata. However this is not efficient because of MIME encoding. I think a better option is to just handle the uploaded data. Basically when you get the initial HTTP request open a file. As you receive each chunk write it to the file. On the last chunk close the file. I wrote something a while ago. See https://github.com/chililog/chililog-server/blob/master/src/main/java/org/chililog/server/workbench/ApiRequestHandler.java#L133 Hope this helps. Many thanks Veebs your code on github was very helpful I ended up creating a custom handler."
240,A,"Java Netty data break I am using in my project netty-3.5.3.Final to transfer files. Unfortunately sometimes I get the wrong data. For example I am downloading a file size of 1 GB. After receiving the file contains 5 ""mistakes"". All errors affect the individual bytes. This is a ""logical"" change Ë -> ë (CB -> EB) C+2 = E À -> à (C0 -> E0) C+2 = E Ú -> ú (DA -> FA) D+2 = F œ -> ¼ (9C -> BC) 9+2 = B -> $ (04 -> 24) 0+2 = 2 e.t.c. (Not every Ë becomes ë only ~1/100000000...000..) The process of obtaining the file: ChannelBuffer buf = (ChannelBuffer) e.getMessage(); //SimpleChannelHandler.messageReceived(...).. ByteBuffer bbuf = buf.toByteBuffer(); RandomAccessFile bos = new RandomAccessFile(...""rw""); bos.write(bbuf.array() 0 bbuf.position()); bos.close(); Data are not subject to any changes. Why can it happen? Do you know what a [SSCCE](http://sscce.org/) is? I think your write code is wrong. Could you try this: ChannelBuffer buf = ... OutputStream out = new FileOutputStream(...) buf.readBytes(out buf.readableBytes()); out.close(); Looks like it works. But where the mistake in my case?"
241,A,Server push using websocket in netty I want to implement basic server push mechanism using websockets in netty ( not a chat application). Can anyone provide some pointers and example... Take a look at the netty WebSocket Server xsource examples. They're quite good and self explanatory. Also I have been putting together a test project to demonstrate Ajax push using netty. See the websocket package in netty-ajax-server. First off you need the websocket client to connect to the server and wait for data. (i.e. you cannot initiate a websocket connection to a client unilaterally from the server.) Then you need to keep a reference to the client's Channel somewhere where it can be referenced from the C class instance. The netty-ajax-server uses a ChannelGroup in a singleton. Then the C instance needs to get the Channel reference and write the dynamically generated data to the channel which will deliver it to the client. You also need to make sure you have the appropriate downstream handlers to encode the data. Thanks for the quick reply.I went through the netty-ajax-server example.I was wondering if there would be some way to send data that is generated on the fly. For eg: I have a WebSocketServerHandler class There is another class C which generates data on the fly how can I send data generated by C through the websocket ?
242,A,implementing a background process responding to the client in an atmosphere+netty/jetty application We have a requirement to to support 10k+ users where every user initiate a request and waits for a response from the server (the response can take as long as 20-30 seconds to arrive). it is only one request from the client and after a long processing by the server a response will be transmitted and then the connection will disconnect. in the background the server will do some DB search and wait for other background processes to notify on completion before responding to the client. after doing some research i figured out we will need to use something like the atmosphere framework to support websockets/sse event/long polling along with an asynchronous server like netty (=> nettosphere) or jetty. As for my experience - mostly Java EE world and Tomcat server. my questions are: what will be easier to implement in regard to my experience and our requirement: atmosphere + netty or atmoshphere+jetty? which one can scale better has an easier learning curve and easier to implement other java technologies? how do u implement in atmosphere a response that is sent only to the originating client and not broadcast to the rest of the clients? (all the examples i found are broadcast). how can i implement in netty (or jetty) when using the atmosphere framework our response? i.e. the client send a request after it is received in the server some background processes are run and when they finish i need to locate the connection and transmit the response. is that achievable? Look into [cometd](http://cometd.org/) too. Some thoughts: At 10k+ users with 20-30 second response latency you likely hit file descriptor limits if using just 1 network interface. Consider a solution that uses multiple network interfaces. Your description of your request/response can be handled entirely with standard Servlet 3.0 standard HTTP/1.1 Async request handling and large timeouts. If your clients are web browsers and you don't start sending a response from the server until the 20-30 second window you might hit browser idle timeouts. Atmosphere and Cometd do the same things supporting long duration connections with connection technique fallbacks and with logical channel APIs. Your concerns about the threads are misplaced threads are only alive and allocated based on actual active processing. Said another way ... Thread count != Connection count when Servlet 3.0 Async is in the mix. Know that with Atomosphere and Cometd the long duration request/response is handled with alternate connection types (http streaming http long polling websocket etc). If on a web browser responses from these types of connections will then have to be processed by yourself in javascript to then be displayed how you want in the browser. It would probably help you to read up on the Bayeux Protocol BOSH and the like. You will quickly learn that all of these techniques will use more than 1 connection over the life of the request/response (with various javascript side management) in order to accomplish their goals. as regarding your #3+#4 comments- i thought we need atmosphere to handle the connections. As regarding #2- wouldn't i need to spawn a lot of threads to handle the requests? or can i just keep asyncServlet in a cache and access it when the background process access the server?  I believe the AKKA framework will handle this sort of need. I am looking at using it to handle scaling issues possibly with a RabbitMQ to help off load work to potentially other servers that may be added later to scale as needed.
243,A,"How to avoid Diffie-Hellman for SSL connections with Java/Netty? I am using Netty as backend in a Java-based Usenet client. The library is working fine however in some circumstances I can't connect to a remote server via SSL because of exactly this error: Java: Why does SSL handshake give 'Could not generate DH keypair' exception? Unfortunately it seems that for whatever reason this Java error still has not been fixed yet. And since the remote server is not under my control I need a workaround here. One such ""solution"" according to the link above is to avoid DH during SSL handshake at all (not very pretty but maybe better than nothing). However I am no SSL expert so I am not really sure how I can implement that within Netty; or better: within my solution that is based on Netty. By now I am creating connections as this: // configure the Netty client ClientBootstrap bootstrap = new ClientBootstrap(clSockChannelFactory); // configure the pipeline factory bootstrap.setPipelineFactory(channelPipelineFactory); bootstrap.setOption(""tcpNoDelay"" true); bootstrap.setOption(""keepAlive"" true); bootstrap.setOption(""child.receiveBufferSizePredictorFactory"" new AdaptiveReceiveBufferSizePredictorFactory()); // start the connection attempt InetSocketAddress isa = new InetSocketAddress(serverAddress port); ChannelFuture future = bootstrap.connect(isa); ... channel = future.getChannel(); ... Ok that's fine but where can I disable cipher suites before I connect the SSL socket as desribed in the thread above? Thanks in advance for all your help! Kind regards Matthias PS: By the way any ideas why this problem has not been addressed in Java yet? I'm not familiar with Netty but I would suggest following the approach in the secure chat example. I'm not sure what default SSL/TLS keys/trust settings you have but if you don't have a custom SSLContext try SSLContext.getDefault(). Then create an SSLEngine using SSLContext.createSSLEngine(). On this SSLEngine you should be able to enable the cipher suites you want. Assuming you're using the Oracle JRE (or OpenJDK) you'll find the list of cipher suites in the Sun Provider documentation. After this (this is the Netty-specific part) set an SslHandler using something like this (see Netty example): pipeline.addLast(""ssl"" new SslHandler(engine)); Thanks a lot mate. This is exactly what I was looking for!"
244,A,"Best practice to route requests to delegate them to different methods in netty? Does netty have built-in support for this somehow? If it doesn't have where should I do this and how should this be implemented? I don't believe that there is built-in support. However it is not too difficult to implement as a switch statement in your Handler. Have a look at this web socket example.  @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { Object msg = e.getMessage(); if (msg instanceof HttpRequest) { handleHttpRequest(ctx (HttpRequest) msg); } else if (msg instanceof WebSocketFrame) { handleWebSocketFrame(ctx (WebSocketFrame) msg); } } private void handleHttpRequest(ChannelHandlerContext ctx HttpRequest req) throws Exception { // Allow only GET methods. if (req.getMethod() != GET) { sendHttpResponse(ctx req new DefaultHttpResponse(HTTP_1_1 FORBIDDEN)); return; } // Send the demo page and favicon.ico if (req.getUri().equals(""/"")) { HttpResponse res = new DefaultHttpResponse(HTTP_1_1 OK); ChannelBuffer content = WebSocketServerIndexPage.getContent(getWebSocketLocation(req)); res.setHeader(CONTENT_TYPE ""text/html; charset=UTF-8""); setContentLength(res content.readableBytes()); res.setContent(content); sendHttpResponse(ctx req res); return; } else if (req.getUri().equals(""/favicon.ico"")) { HttpResponse res = new DefaultHttpResponse(HTTP_1_1 NOT_FOUND); sendHttpResponse(ctx req res); return; } // Handshake WebSocketServerHandshakerFactory wsFactory = new WebSocketServerHandshakerFactory( this.getWebSocketLocation(req) null false); this.handshaker = wsFactory.newHandshaker(req); if (this.handshaker == null) { wsFactory.sendUnsupportedWebSocketVersionResponse(ctx.getChannel()); } else { this.handshaker.handshake(ctx.getChannel() req); } } In messageReceived() we route based on the type of message received. Then in handleHttpRequest() we route based on URI. Hope this helps."
245,A,"When is ""java.io.IOException:Connection reset by peer"" thrown?  25/Dec/2011 13:37:39 ERROR GServerHandler - java.io.IOException: Connection reset by peer java.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcher.read0(Native Method) at sun.nio.ch.SocketDispatcher.read(Unknown Source) at sun.nio.ch.IOUtil.readIntoNativeBuffer(Unknown Source) at sun.nio.ch.IOUtil.read(Unknown Source) at sun.nio.ch.SocketChannelImpl.read(Unknown Source) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:323) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:282) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:202) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source) at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) at java.lang.Thread.run(Unknown Source) This log is from a game server implemented using netty. What can cause this exception ? I guess the wizard of the coast casted a spella gainst you so every single io operation you do will fail. Provide the code which cause the exception otherwise we will not be abel to help you Well the client has rejected/closed the connection. You'd need the client logs to see what was the cause. @andreapier since this exception seems to be network related I can not provide the source code. thanks for the answer (and the joke) though java.io.IOException: Connection reset by peer The other side has abruptly aborted the connection in midst of a transaction. That can have many causes which are not controllable from the server side on. E.g. the enduser decided to shutdown the client or change the server abruptly while still interacting with your server or the client program has crashed or the enduser's internet connection went down or the enduser's machine crashed etc etc.  I think this should be java.net.SocketException as its definition is stated for a TCP error. /** * Thrown to indicate that there is an error in the underlying * protocol such as a TCP error. * * @author Jonathan Payne * @version %I% %G% * @since JDK1.0 */ public class SocketException extends IOException {  java.io.IOException in Netty means your game server tries to send data to a client but that client has closed connection to your server. And that exception is not the only one! There're several others. See BadClientSilencer in Xitrum. I had to add that to prevent those errors from messing my log file. It doesn't mean only that and it isn't confined to just Netty either. I don't understand. WorM posted the stack trace with a read operation but all answers explain writing problem.  To expand on BalusC's answer any scenario where the sender continues to write after the peer has stopped reading and closed its socket will produce this exception. In other words an application protocol error. For example if you write something to the peer that the peer doesn't understand and then it closes its socket in protest and you then continue to write the peer's TCP stack will issue an RST which results in this exception and message at the sender."
246,A,Netty - Ignore failed setting of IP_TOS My users are reporting this error to me and I would like to silently ignore it since it is a non crucial part of my application. 2013-02-09 15:20:15 [WARNING] Failed to set a channel option: [id: 0x8cf59443 /84.100.204.150:51292 => /87.98.181.225:22091] io.netty.channel.ChannelException: java.net.SocketException: Invalid argument: no further information at io.netty.channel.socket.DefaultSocketChannelConfig.setTrafficClass(DefaultSocketChannelConfig.java:264) at io.netty.channel.socket.DefaultSocketChannelConfig.setOption(DefaultSocketChannelConfig.java:115) at io.netty.bootstrap.ServerBootstrap$ServerBootstrapAcceptor.inboundBufferUpdated(ServerBootstrap.java:264) at io.netty.channel.DefaultChannelHandlerContext.invokeInboundBufferUpdated(DefaultChannelHandlerContext.java:1170) at io.netty.channel.DefaultChannelHandlerContext.fireInboundBufferUpdated0(DefaultChannelHandlerContext.java:1148) at io.netty.channel.DefaultChannelHandlerContext.fireInboundBufferUpdated(DefaultChannelHandlerContext.java:1127) at io.netty.channel.DefaultChannelPipeline.fireInboundBufferUpdated(DefaultChannelPipeline.java:903) at io.netty.channel.socket.nio.AbstractNioMessageChannel$NioMessageUnsafe.read(AbstractNioMessageChannel.java:84) at io.netty.channel.socket.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:397) at io.netty.channel.socket.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:361) at io.netty.channel.socket.nio.NioEventLoop.run(NioEventLoop.java:301) at io.netty.channel.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:110) at java.lang.Thread.run(Unknown Source) Caused by: java.net.SocketException: Invalid argument: no further information at sun.nio.ch.Net.setIntOption0(Native Method) at sun.nio.ch.Net.setSocketOption(Unknown Source) at sun.nio.ch.SocketChannelImpl.setOption(Unknown Source) at sun.nio.ch.SocketAdaptor.setIntOption(Unknown Source) at sun.nio.ch.SocketAdaptor.setTrafficClass(Unknown Source) at io.netty.channel.socket.DefaultSocketChannelConfig.setTrafficClass(DefaultSocketChannelConfig.java:262) ... 12 more To accomplish this I am simply setting the IP_TOS option in my ServerBootstrap: childOption(ChannelOption.IP_TOS 0x18) If you know where I would need to place a handler or option to ignore a failure in setting this option please let me know. md_5 Here's an example bootstrap code that sets an option:  Bootstrap b = new Bootstrap(); b.group(new NioEventLoopGroup() new NioEventLoopGroup()) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { try { ch.config().setTrafficClass(0x18); } catch (ChannelException e) { // Ignore } ch.pipeline().addLast( new LoggingHandler(LogLevel.INFO) new EchoServerHandler()); } });
247,A,ClosedChannelException after sending async message and then closing channel Netty is throwing the following exception when i send a message asynchronously from my client and then close the channel. java.nio.channels.ClosedChannelException at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:133) at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:324) at org.jboss.netty.channel.socket.nio.SocketSendBufferPool$PooledSendBuffer.transferTo(SocketSendBufferPool.java:239) at org.jboss.netty.channel.socket.nio.NioWorker.write0(NioWorker.java:469) at org.jboss.netty.channel.socket.nio.NioWorker.writeFromTaskLoop(NioWorker.java:392) at org.jboss.netty.channel.socket.nio.NioSocketChannel$WriteTask.run(NioSocketChannel.java:276) at org.jboss.netty.channel.socket.nio.NioWorker.processWriteTaskQueue(NioWorker.java:268) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:199) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662) My send code is as follows: Channels.write(clientChannel messageObject); My close code is as follows:  ChannelGroupFuture future = ALL_CHANNELS.close(); future.awaitUninterruptibly(); if (null != clientBootstrap) { clientBootstrap.releaseExternalResources(); } Is there anything I need to do to flush the Channel before closing? I had a similar problem. The fix for me was to close on the ChannelFuture returned by the write. ChannelFuture f = clientChannel.write(messageObject); f.addListener(ChannelFutureListener.CLOSE); Hope this works for you. Excellent. This was bugging me for days. None of the Netty examples I've found do this. Nope spoke to soon. This didn't work. Subsequent message sends now fail because the channel is closed. I think you need to only close the channel when you finish sending/receiving - i.e. after the last write.  Sorry I don't understand your problem. You now close the channel after the write is complete (like Veebs suggested) and now you complain it fails for new writes as the channel is closed ? If you need more then write operation you need to add the ChannelFutureListener.CLOSE to the last future that was returned. Hope it helps..
248,A,"Which JVM does netty Use? Which JVM does Netty Use? I am new to Server Development. I am a bit concerned about paying for JVMs. Henceforth I asked this question... Being a library can't you use it with multiple JVMs -- or rather any that could run say JBoss? (Why would it be tied to or ""use"" one?) It uses ... whatever one you're using or want to use. All JVMs have to be compliant with the JLS (Java Language Specification) or they're not really a JVM. Netty currently requires a Java 1.6 1.5 (or later) JVM however the next release is going to require 1.6 or higher. (Edited to correct dumb user error on my part looking at the wrong branch on github) I suppose we have pay for the Container. I know Apache is Free for Commercial Usage. Are there any other Containers that are free for commercial usage... Erm ... there's only a couple that *aren't*. Tomcat Glassfish JBoss etc etc are all open source. In fact I can't think of a servlet container that isn't free (IBM WebSphere maybe?). You can purchase *support contracts* but they are not mandatory. And you don't have to pay for that. @Bill - indeed. @maerics - I checked the `.pom` for the current version before posting ... it targets 1.6 Ah documentation lag =) @maerics - actually ... you made me double-check. 3.2.0 requires 1.5 the next release is requiring 1.6 - I didn't change the damn branch in github when I was looking thanks for keeping me honest :) Thanks for the Info Brian"
249,A,How to handle a large stream that is mostly written to disk in netty (use ChunkedWriteHandler?)? I have a binary protocol with some unknown amount of initial header data (unknown length until header is fully decoded) followed by a stream of data that should be written to disk for later processing. I have an implementation that decodes the header and then writes the file data to disk as it comes in from one or more frames in ChannelBuffers (so my handler subclasses FrameDecoder and builds the message step by step not waiting for one ChannelBuffer to contain the entire message and writing the file data to disk with each frame). My concern is whether this is enough or if using something like ChunkedWriteHandler does more than this and is necessary to handle large uploads. Is there a more optimal way of handling file data than just writing it directly to disk from the ChannelBuffer with each frame? It should be enough as long as the throughput is good enough. Otherwise you might want to buffer the received data so that you don't make system calls too often (say 32KiB bounded buffer) when the amount of received data is not large enough. Netty could be even faster if it exposed the transferTo/From operation to a user but such a feature is not available yet. Thank you Trustin! Good suggestion about the buffer I had not considered small frames.  You should also think about adding an ExecutionHandler in front if your Handler. This will help you to not get blocked by the disk I/O. Otherwise you may see slow downs on heavy disk access.
250,A,"Reading and Writing to ChannelBuffer is not working properly I want to read the binary data stored in the ChannelBuffer object contained in an HttpResponse. I have tried with the below code to read and save from the ChannelBuffer but it is not working. What is the correct way of reading the binary data stored in the channel buffer? ChannelBuffer chanBuff = response.getContent(); FileOutputStream outputStream = new FileOutputStream(outputFileName); outputStream.write(chanBuff.array()); outputStream.close(); The above code throws an exception from chanBuff.array() (UnsupportedOperationException). Not sure what is the correct way of copying byte array from ChannelBuffer. The purpose of storing this content (e.g. media) is to save and transcode it. However I am consistently getting the saved file size as zero. I also intend to copy the processed data back into the HTTP Response via ChannelBuffer. For writing back into HTTP Message I have the below code. This code sometimes throws ArrayOutOfBoundException. What is the correct approach here? ChannelBuffer dynamicBuffer = dynamicBuffer(); dynamicBuffer.clear(); dynamicBuffer.ensureWritableBytes(fileLen); ChannelBufferOutputStream buffOutStream = new ChannelBufferOutputStream(dynamicBuffer); byte[] byteBuf = new byte[4096]; int bytesRead = -1; int offSet = 0; while ((bytesRead = inStream.read(byteBuf)) != -1) { buffOutStream.write(byteBuf offSet bytesRead); offSet += bytesRead; } response.setContent(EMPTY_BUFFER); response.setContent(buffOutStream.buffer()); response.setHeader(""Content-Type"" contType); response.setHeader(""Content-Length"" fileLen); Is this the correct approach? In your second example you should not keep increasing the offset. That's an offset into the buffer not the file. You should use zero for the offset throughout."
251,A,"how can i write a file data by read chunk chunk and write to channel in netty? i used netty 3.6 and i want to write a file data to a channel by any region and also with encryption i write a file data with FileRegion on a channel and dont have any problem and worked as fine and dont eat my RAM but i want to read chunk chunk for encypted (by RC4)(chunk size is 512) befor wirte to channel  i used this code: if (e.getChannel().isWritable()) { FileInputStream fin = new FileInputStream(file); byte[] data = new byte[512]; for (int i = 512; i < file.length(); i += 512) { fin.read(data); index_range += 512; e.getChannel().write(ChannelBuffers.wrappedBuffer(RC4.encrypte(data))); } int remain_len=(int)(file.length() - index_range); if(remain_len>0){ data = new byte[remain_len]; fin.read(data); e.getChannel().write(ChannelBuffers.wrappedBuffer(RC4.encrypte(data))); } fin.close(); } but i get Exception in thread ""pool-5-thread-1"" java.lang.OutOfMemoryError: Java heap space  i also used RandomAccessFile class but problem is as same  how can i resolved this problem Use ChunkedWriteHandler and ChunkedNioFile. Then you can intercept the produced ChannelBuffer and do the encryption on the fly. Thanks @normanm  i search for see any example to do this but i can not find any  can you show me your explain in a example code please https://github.com/netty/netty/blob/3/src/main/java/org/jboss/netty/example/http/file/HttpStaticFileServerHandler.java#L172 Thanks a lot netty master  @normanm The example you give used ChunkedFile in server side can I use ChunkedFile when I posted a request?"
252,A,Netty requires sending in the same thread as select() which delays sends Is it possible for Netty to create a worker thread that does all the sends for a group of sockets? It appears that currently netty posts outbound messages to a queue and attempts to wake up the selector which then copies the data into an unused buffer and sends it. This takes time. Is it possible to send directly from a different thread? It is not possible. Netty has no idea about from which thread a user will call write(). Therefore it needs a write request queue and a dedicated loop to perform writes. Otherwise the application will suffer from contention depending on how a user wrote his/her application. Under load having a dedicated I/O loop and running a protocol with pipelining seem to yield higher throughput.
253,A,"No executor to a Netty pipeline. What happens? For example Floodlight openflow stack uses Netty for it's IO and it defines following Pipeline factory class. public class OpenflowPipelineFactory implements ChannelPipelineFactory { protected Controller controller; protected ThreadPoolExecutor pipelineExecutor; protected Timer timer; protected IdleStateHandler idleHandler; protected ReadTimeoutHandler readTimeoutHandler; public OpenflowPipelineFactory(Controller controller ThreadPoolExecutor pipelineExecutor) { super(); this.controller = controller; this.pipelineExecutor = pipelineExecutor; this.timer = new HashedWheelTimer(); this.idleHandler = new IdleStateHandler(timer 20 25 0); this.readTimeoutHandler = new ReadTimeoutHandler(timer 30); } @Override public ChannelPipeline getPipeline() throws Exception { OFChannelState state = new OFChannelState(); ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""ofmessagedecoder"" new OFMessageDecoder()); pipeline.addLast(""ofmessageencoder"" new OFMessageEncoder()); pipeline.addLast(""idle"" idleHandler); pipeline.addLast(""timeout"" readTimeoutHandler); pipeline.addLast(""handshaketimeout"" new HandshakeTimeoutHandler(state timer 15)); if (pipelineExecutor != null) pipeline.addLast(""pipelineExecutor"" new ExecutionHandler(pipelineExecutor)); pipeline.addLast(""handler"" controller.getChannelHandler(state)); return pipeline; } } But in fact as Floodlight gives null to the second argument of the constructor the execution handler and executor object is never assigned to the pipeline. ... final ServerBootstrap bootstrap = createServerBootStrap(); bootstrap.setOption(""reuseAddr"" true); bootstrap.setOption(""child.keepAlive"" true); bootstrap.setOption(""child.tcpNoDelay"" true); bootstrap.setOption(""child.sendBufferSize"" Controller.SEND_BUFFER_SIZE); ChannelPipelineFactory pfact = new OpenflowPipelineFactory(this null); bootstrap.setPipelineFactory(pfact); InetSocketAddress sa = new InetSocketAddress(openFlowPort); final ChannelGroup cg = new DefaultChannelGroup(); cg.add(bootstrap.bind(sa)); ... My question is 'what happens if there's no pipeline executor is set to the pipeline'? Any default pipeline executor is assumed? If it is OrderedMemoryAwareThreadPoolExecutor executor is always assumed? Thank you in advance waiting for some help from the Netty and Floodlight specialists. If there is no ExecutionHandler in the ChannelPipeline all events will be handled by the IO thread. If a ExecutionHandler is added the events are off-loaded to an extra Thread-Pool for the handlers after the ExecutionHandler. This allows blocking operations. Thank you. But I'd like to give you one more question. In your answer you mentioned 'IO thread' what IO thread you mean by the word? Oh... never mind. I read [http://netty.io/3.6/guide/#start.7] and understood what did you mean by the 'IO thread'. It was a great help. Thank you!"
254,A,How does downstream events work in jboss's netty? Just started playing around with netty in implementing my own server. Took me a while to get the hang of it but now I was able to accept clients by writing my own MessageHandler and inside messageReceived I was able to read from the buffer and did some business logic related to the data received. However the question now is how do I write data into connected clients? I saw the sample code where you can write to the channel in the event of a new message like this: public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { Channel ch = e.getChannel(); ch.write(e.getMessage()); } but what if you don't want to write the data back at that point? What if the client stays connected in the socket and waits until some event occurs in the server? In that case how will my server find the right socket to write to? Am I suppose to keep a reference to the channel object? Is this the convention? I looked further into the code and saw a method called writeRequested. Is that related? Who calls that? And is it needed? As long as you have the reference to the Channel (or ChannelHandlerContext) you can call Channel.write() (or Channels.write()) from anywhere any thread. writeRequested() is called when you trigger the writeRequested event by calling Channel.write() or calling ChannelHandlerContext.sendDownstream(MessageEvent).
255,A,"ChannelHandlerContext.attr is not accessible from inside userEventTriggered I am using netty for developing my server. I am also implementing the Idle state handling in netty. I got it working but an issue I recently found out. I can't access the channel context attributes inside the userEventTriggered method. here is my code and can anybody tell me why it is not possible. I am setting it like public static final AttributeKey<Agent> CLIENT_MAPPING = AttributeKey.valueOf(""clientMapping""); ... ctx.attr(CLIENT_MAPPING).set(agent); and inside handler I am getting the value like (this is working perfectly) Agent agent = ctx.attr(CLIENT_MAPPING).get(); But inside userEventTriggered it is returning null. (I am sure that it is set before this function is being called.) public class Server { ... public void run() throws Exception { ... ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup). channel(NioServerSocketChannel.class). childHandler(new SslServerInitializer()); ... } } class SslServerInitializer extends ChannelInitializer<SocketChannel> { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); .... pipeline.addLast(""idleStateHandler"" new IdleStateHandler(0 0 Integer.parseInt(Main.configurations.get(""netty.idleTimeKeepAlive.ms"")))); pipeline.addLast(""idleTimeHandler"" new ShelloidIdleTimeHandler()); } } class ShelloidIdleTimeHandler extends ChannelDuplexHandler { @Override public void userEventTriggered(ChannelHandlerContext ctx Object evt) throws Exception { if (evt instanceof IdleStateEvent) { try { // This I am getting null but I confirmed that I set the attribute from my handler and is accessible inside handler. Agent agt = ctx.attr(WebSocketSslServerHandler.CLIENT_MAPPING).get(); ctx.channel().writeAndFlush(new TextWebSocketFrame(""{\""type\"":\""PING\"" \""userId\"": \"""" + agt.getUserId() + ""\""}"")); } catch (Exception ex) { ctx.disconnect(); ex.printStackTrace(); } } } } Are you sure you set and get it in the same ChannelHandler? If you want to set and get it in different ChannelHandler you need to use Channel.attr(...) Yes. While the client is connected for the first time I am setting the ChannelHandlerContext attribute. so whenever the channel is idle it will call the userEventTriggered with that ChannelHandlerContext is it? Still I am not able to get the attributes Yaah. I got it by Channel.attr(............)"
256,A,"Java Interop -- Netty + Clojure I'm trying to use netty via clojure. I'm able to startup the server however it fails to initialize an accepted socket. Below are the error message and code respectively. Does anyone know what is/or could be wrong? I believe the issue is with (Channels/pipeline (server-handler)) Thanks. Error Message #<NioServerSocketChannel [id: 0x01c888d9 /0.0.0.0:843]> Jun 6 2012 12:15:35 PM org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink WARNING: Failed to initialize an accepted socket. java.lang.IllegalArgumentException: No matching method found: pipeline project.clj (defproject protocol ""1.0.0-SNAPSHOT"" :description ""Upload Protocol Server"" :dependencies [ [org.clojure/clojure ""1.2.1""] [io.netty/netty ""3.4.5.Final""]]) core.clj (ns protocol.core (:import (java.net InetSocketAddress) (java.util.concurrent Executors) (org.jboss.netty.bootstrap ServerBootstrap) (org.jboss.netty.channel Channels ChannelPipelineFactory SimpleChannelHandler) (org.jboss.netty.channel.socket.nio NioServerSocketChannelFactory) (org.jboss.netty.buffer ChannelBuffers))) (def policy ""<content>Test</content>"") (defn server-handler ""Returns netty handler."" [] (proxy [SimpleChannelHandler] [] (messageReceived [ctx e] (let [ch (.getChannel e)] (.write ch policy) (.close ch))) (channelConnected [ctx e] (let [ch (.getChannel e)] (.write ch policy) (.close ch))) (exceptionCaught [ctx e] (let [ex (.getCause e)] (println ""Exception"" ex) (-> e .getChannel .close))))) (defn setup-pipeline ""Returns channel pipeline."" [] (proxy [ChannelPipelineFactory] [] (getPipeline [] (Channels/pipeline (server-handler))))) (defn startup ""Starts netty server."" [port] (let [channel-factory (NioServerSocketChannelFactory. (Executors/newCachedThreadPool) (Executors/newCachedThreadPool)) bootstrap (ServerBootstrap. channel-factory)] (.setPipelineFactory bootstrap (setup-pipeline)) (.setOption bootstrap ""child.tcpNoDelay"" true) (.setOption bootstrap ""child.keepAlive"" true) (.bind bootstrap (InetSocketAddress. port)))) There are three problems with your code Java interop with vararg Channels.channel() method. you can make a vector of channel handlers and wrap it with (into-array ChannelHandler ..) You can not write String objects directly to a Netty Channel. you have to write the string to a ChannelBuffer first and write that buffer or use a StringCodecHandler. Writing to Netty channel is asynchronus so you can not close it immediately. you have to register a future listener and close the channel when its done. Here is the working code.  (ns clj-netty.core (:import (java.net InetSocketAddress) (java.util.concurrent Executors) (org.jboss.netty.bootstrap ServerBootstrap) (org.jboss.netty.buffer ChannelBuffers) (org.jboss.netty.channel Channels ChannelFutureListener ChannelHandler ChannelPipelineFactory SimpleChannelHandler) (org.jboss.netty.channel.socket.nio NioServerSocketChannelFactory) (org.jboss.netty.buffer ChannelBuffers))) (def policy (ChannelBuffers/copiedBuffer (.getBytes ""<content>Test</content>""))) (defn server-handler ""Returns netty handler."" [] (proxy [SimpleChannelHandler] [] (messageReceived [ctx e] (let [ch (.getChannel e)] (.addListener (.write ch policy) (ChannelFutureListener/CLOSE)))) (channelConnected [ctx e] (let [ch (.getChannel e)] (.addListener (.write ch policy) (ChannelFutureListener/CLOSE)))) (exceptionCaught [ctx e] (let [ex (.getCause e)] (println ""Exception"" ex) (-> e .getChannel .close))))) (defn setup-pipeline ""Returns channel pipeline."" [] (proxy [ChannelPipelineFactory] [] (getPipeline [] (let [handler (server-handler)] (Channels/pipeline (into-array ChannelHandler [handler])))))) (defn startup ""Starts netty server."" [port] (let [channel-factory (NioServerSocketChannelFactory. (Executors/newCachedThreadPool) (Executors/newCachedThreadPool)) bootstrap (ServerBootstrap. channel-factory)] (.setPipelineFactory bootstrap (setup-pipeline)) (.setOption bootstrap ""child.tcpNoDelay"" true) (.setOption bootstrap ""child.keepAlive"" true) (.bind bootstrap (InetSocketAddress. port)))) Have a look at Aleph (also uses Netty) which can used to build clients and servers in many different protocols with nice Clojure API. Thanks for the clear and detailed explanation it was very helpful. I certainly plan on trying Aleph but I figured I'd get two birds with one stone -- learn netty while practicing clojure."
257,A,When do i have to use ByteBuf.retain() in a Netty4 Encoder? I am writing a Encoder that NUL-Terminates a JSON-Message so it can be decoded in case the message is fragmented. I found this sample ->click where ByteBuf.retain() was called in the end to write an existing ByteBuf to the output. Why did they do that and why is it needed? Here's my Encoder: public class FrameEncoder extends MessageToMessageEncoder<ByteBuf> { @Override protected void encode(ChannelHandlerContext ctx ByteBuf msg List<Object> out) throws Exception { out.add(msg.retain()); out.add(ctx.alloc().buffer(1).writeByte(NUL)); } } By default MessageToMessageEncoder releases original message after encoding. It's consistent with the typical use case of MessageToMessageEncoder when your encoder returns new message as a result of encoding so that original message can be safely discarded after encoding. However orginal message should not be discarded when it's used as a part of the result as in your case. In this case you need to call retain() explicitly. From the javadoc of MessageToMessageEncoder: Be aware that you need to call ReferenceCounted.retain() on messages that are just passed through if they are of type ReferenceCounted. This is needed as the MessageToMessageEncoder will call ReferenceCounted.release() on encoded messages.
258,A,How to send event to other handler in netty? Unlike boost.asio netty has no read-like method. It is unconvenient in following situation: A management node manage some nodes and clients connect to management node to retrieve information resides in nodes. When management node receive client's request it sends a request to the correspond node and waiting for the node response. When the node response and management node gets the information in its ‘messageReceived’ function how to send the information to the channel which belong to client? It needs send a event to Handler of client request. 1.get client request 2.send request to a node 3.read response of that node 4.send response to client all these 4 step can be done in one function in boost.asio. But netty does not support step3 the read function is independent user can not call it directly. The only way is after receive the response in handler between management node and node re-send it to handler between management node and client. What is the typical way to do this? Netty uses async i/o operations hence step 2 is async and yes you cannot block till you get step 3. In most cases like this(not specific to Netty) what you can do is: 1) provide unique id's to your requests the node's are supposed to echo back the unique id's in their responses. 2) Store them in a hashmap with key as unique id of request and channel(between management node and client) as its value 3) When you receive the response from the node in management node you can lookup the channel from hashmap using unique id and then send the response to client. You can also take a look at Bruno de carvalho's Netty load balancer which will give you another perspective to the same issue. He uses tunneling to achieve the same effect. I am put client's channel id into package sends from management node to node so when node response I know which client channel I should use. I suppose there is some utilities or typical trick could solve this problem. BTW I feel netty's design philosophy is some kind of restrict. In fact the 4 steps I said could done in async also asio do it by chain of complete callback handlers. In netty the channel.write() will provide you a ChannelFuture. You can add a FutureListener to this future object i.e a callback so you have similar facility in Netty also. So you can wait on step 2 or do some logic at its end but step 3 is coming from client so this callback will not help. In asio I could add a callback2 in step2 this callback2's job is async read from node(step 3). And add a callback3 in step3(callbacks has been chained) it do step4 job. The key is async read is not allow user to invoke in netty
259,A,"Unable to write DefaultHttpResponse to a channel in netty: ""unsupported message type: class org.jboss.netty.handler.codec.http.DefaultHttpResponse"" This specific question is related to a possible resolution to the following question. I have two pipelines in which I'm receiving a client request one one channel then firing off a request on a second channel then copying the response content into a new DefaultHttpResponse which I attempt to write to the original channel. However this results in the following exception: java.lang.IllegalArgumentException: unsupported message type: class org.jboss.netty.handler.codec.http.DefaultHttpResponse at org.jboss.netty.channel.socket.nio.SocketSendBufferPool.acquire(SocketSendBufferPool.java:53) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.write0(AbstractNioWorker.java:468) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromTaskLoop(AbstractNioWorker.java:432) at org.jboss.netty.channel.socket.nio.AbstractNioChannel$WriteTask.run(AbstractNioChannel.java:366) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.processWriteTaskQueue(AbstractNioWorker.java:350) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:246) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:35) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) Does anyone know why this might be happening? For reference here's the code for my two pipelines (I know I'm doing some thread unsafe things here but I'm trying to get this working for a single-threaded client before I move on): private static Channel channel; private static Map<Channel Channel> proxyToClient = new ConcurrentHashMap<Channel Channel>(); public static void main(String[] args) throws Exception { ChannelFactory clientFactory = new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); final ClientBootstrap cb = new ClientBootstrap(clientFactory); cb.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline( new HttpRequestEncoder() new HttpResponseDecoder() new ResponseHandler()); } }); ChannelFuture cf = cb.connect(new InetSocketAddress(""localhost"" 18080)); channel = cf.awaitUninterruptibly().getChannel(); ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); ServerBootstrap sb = new ServerBootstrap(factory); sb.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline( new HttpRequestDecoder() new RequestHandler()); } }); sb.setOption(""child.tcpNoDelay"" true); sb.setOption(""child.keepAlive"" true); sb.bind(new InetSocketAddress(2080)); } private static class ResponseHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) { final HttpResponse proxyResponse = (HttpResponse) e.getMessage(); Channel clientChannel = proxyToClient.get(e.getChannel()); HttpResponse clientResponse = new DefaultHttpResponse(HttpVersion.HTTP_1_1 HttpResponseStatus.OK); clientResponse.setContent(proxyResponse.getContent()); clientChannel.write(clientResponse).addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { Channel ch = future.getChannel(); ch.close(); } }); } } private static class RequestHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) { final HttpRequest request = (HttpRequest) e.getMessage(); proxyToClient.put(channel e.getChannel()); channel.write(request); } } How about adding a HttpResponseEncoder in your server pipeline? Your server should know how to convert the DefaultHttpResponse object to bytes so it can send it over the wire."
260,A,"ChannelInboundMessageHandlerAdapter vs. ChannelOutboundMessageHandlerAdapter According to Documentation ChannelInboundMessageHandlerAdapter should be used for inbound messages and ChannelOutboundMessageHandlerAdapter should be used for outbound messages. If I look at netty example I can see that ChannelInboundMessageHandlerAdapter is always used on Client and server even id client sends messages to Server. Where each of the handler should be used? ChannelInboundMessageHandler is used for inbound messages so received messages. ChannelOutboundMessageHandler us used for outbound message so ""to-be-send"" messages. You only need the ChannelOutboundMessagehandler if you need for example transform messages before they are written to the socket."
261,A,"Netty throws IOException:A connection with a remote socket was reset by that socket I'm using Netty3.5.9(jdk1.6.43) for my socket connectionsmost of the time it works wellbut sometimes it shows: java.io.IOException:A connection with a remote socket was reset by that socket at sun.nio.ch.FileDispatcher.read0(Native Method) at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:33) at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:234) at sun.nio.ch.IOUtil.read(IOUtil.java:201) at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:236) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:321) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:280) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:200) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:896) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918) at java.lang.Thread.run(Thread.java:735) 2013-7-2 8:54:18 org.jboss.netty.channel.SimpleChannelUpstreamHandler null WARNING: EXCEPTION please implement cfca.xfraud.collector.system.sockettype.netty.NettyAnalyzerHandler.exceptionCaught() for proper handling. which my exceptionCaught() method is: public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) throws Exception {  log.error("""" e.getCause()); super.exceptionCaught(ctx e); } Though the IOException shows sometimesbut the whole application seems has no any bad influence and stills works wellso what's the real problemand what should I change the code to prevent the exception. it really says ""java.io.IOException:A connection with a remote socket was reset by that socket""I am quite sure. Does it *really* say ""java.io.IOException:A connection with a remote socket was reset by that socket""? or does it say ""connection reset by peer""? This is nothing to be concerned about ... It means that the remote peer closed the connection and netty detect it when the read is done. So you are safe to ignore the exception. okthank you so muchbut how can I prevent writing this exception log to log files. after allIt makes me feel uncomfortable to see this excepiton words... override exceptionCaught(...) and swallow them ?"
262,A,Channel addresses after closing connection in Netty 4.0 I looked at some of the source code in Netty 4.0 and I noticed that AbstractChannel's localAddress and remoteAddress are volatile and not final. Are these addresses guaranteed to be set and available when channelActive is triggered? And more importantly what do localAddress() and remoteAddress() return when/after channelInactive is triggered? Do channels keep the addresses even after the connection is closed? I'm working with the NIO channels and mostly on Windows if it makes any difference. These are set lazy which means basically the first time you try to access them.
263,A,"PooledByteBufAllocator's buffer will released in HttpServerCodecHandler if allocated from ChannelHandlerContext? I am allocating a buffer using PooledByteBufAllocator with Direct Pool are true  which is the allocator specified in channel  during server setup. I use this allocator to create a response. Do I need to release this buffer in response or will release of this response buffer pool be handled in HttpServerCodec? I am doing this to get performance benefits and less gc. Pipeline code: pipeline.addLast(""decoderEncoder"" new HttpServerCodec()); pipeline.addLast(""aggregator"" new HttpObjectAggregator(1024 * 1024));// 1 MB data size pipeline.addLast(""handler"" httpRequestHandlerProvider.get()); ServerBootstrap code: serverBootstrap.group(bossGroup workerGroup).channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(8800)).childHandler(serverChannelInitializer) // disable nagle's algorithm .childOption(ChannelOption.TCP_NODELAY true) // allow binding channel on same ip port .childOption(ChannelOption.SO_REUSEADDR true).childOption(ChannelOption.ALLOCATOR new PooledByteBufAllocator(true)).bind() .sync(); In Response code  in my custom 'handler' - httpRequestHandler: private void sendResp(final String responseString final ChannelHandlerContext ctx) { byte[] bytes = responseString.getBytes(Charsets.UTF_8); FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1 HttpResponseStatus.OK ctx.alloc().buffer(bytes.length).writeBytes(bytes) false); } If you write the response Netty will take care to release to buffer for you. thanks! Read your book  is awesome . case studies are good too. thanks feedback welcome :)"
264,A,"Netty eclipse ""no mandatory external dependencies""? import errors I just downloaded Netty for a personal client-server-project from here: http://netty.io/downloads/netty-3.3.0.Final-dist.tar.bz2 On the download page http://netty.io/downloads/ it says there are ""no mandatory external dependencies"". You only need a JDK 1.5 or higher. So I just set up a java project in eclipse IDE using my 1.6 JDK and got multiple errors saying ""import cannot be resolved"". Examples: org.jboss.logging com.google org.osgi javax.servlet That tells me that there are actually some external libraries needed. Or am I doing anything wrong? Can anyone tell me where to find all these libraries since I could not find any clues on the Netty pages where to get them (I know that javax.servlet is part of Tomcat and JBoss AS distribution but why do they then say that no external libraries are needed). Are you trying to build netty from source? There's a pom.xml file in the root implying that netty can be built by maven. You'll find all those dependencies in the pom file. ""No mandatory external dependencies"" means that you need no jar other than the netty jar to run your application. External dependecies is probably needed for some of the examples definitively for testing and perhaps for some special but optional run time features. Yeah well thanks. Sorry that I did not comment over the weekend. I am actually writing my own server for a personal game project and wanted to have a look at netty source to get a better understanding of how SocketChannels and all this stuff works. I am currently thinking that just using Netty and learning how it works is maybe the better approach. :)  The dependencies are only used for building and are marked as optional. The dependencies are only needed if you want for example use slf4j for logging in netty. Beside this netty can be used within your project without pulling in any third-party dependencies."
265,A,Create a ByteBuf in Netty 4.0 Two simple questions which I am not able to solve by ready in the documentation: I have a 'byte[]'. How can i convert it to a ByteBuf? I have a NIO 'ByteBuffer How can i convert it to a ByteBuf? The documentation seems pretty clear to me: Creation of a buffer It is recommended to create a new buffer using the helper methods in Unpooled rather than calling an individual implementation's constructor. Then in Unpooled you've got options of wrapping or copying. For example: Unpooled.copiedBuffer(ByteBuffer) Unpooled.copiedBuffer(byte[]) Unpooled.wrappedBuffer(ByteBuffer) Unpooled.wrappedBuffer(byte[]) Choose whichever method is appropriate based on whether you want changes made in the returned ByteBuf to be passed through to the original byte array/buffer. I haven't seen the section 'Creation of a buffer'. Damn :)
266,A,"How many timeouts can a Netty HashedWheelTimer handle? The doc says ""The default number of ticks per wheel (i.e. the size of the wheel) is 512. You could specify a larger value if you are going to schedule a lot of timeouts."" Does it mean by default it can only handle 512 timeouts? If I want 100 thousand timeouts of 25 seconds (for SockJS) what value should I set to number of ticks per wheel? The wheel is basically a hashtable with separate chaining whose hash function is 'time to notification'. The separate chaining is implemented as an unbounded ordered set so a wheel can practically hold unlimited number of timeouts. If you schedule a timeout that times out in a distant future (i.e. large delay) the large delay will be divided by wheelSize * tickDuration and use its remainder as the hash of the timeout. Therefore the current slot in a wheel can hold both the timeouts that will expire within the next tickDuration and the timeouts that will expire in (tickDuration * wheelSize * n) ms where the variable n will decrease as the timer thread iterates over the wheel. The latter will cost some CPU time when the timer thread visits the slot because it's not really their turn to get expired. (This is similar to collisions in traditional hashtables). To reduce the chance of the collisions you can increase the size of the wheel. For example if you are sure most timeouts scheduled are going to expire within a minute you can make wheelSize * tickDuration a minute (e.g. 600 slots * 100 ms). For the detailed information about hashed wheels please read this."
267,A,"Accessing an instance of Netty server from inside a Netty Handler I am writting a Netty Server for a multiplayer game and I am not sure if I need to synchronize in some way a variable that lives in the server but is accessed by the ChannelHandler. At the server level I am using an ArrayList to store the different matches the server will be serving. Each match will be referencing 2 channels (I store for the match the ChannelHandlerContetx for each one). When I create the ChannelHandler that extends from SimpleChannelInboundHandler I pass an instance of the server to the constructor and I store the server as an instance variable in the handler. When channelActive is fired the ChannerlHandler will search for a match in the ArrayList (that lives in the server instance) in ""Waiting"" state. If it finds one it bounds to it and changes the match status. If not a new Match is created and then the channel bounds to it leaving it in Waiting status. I know that channels are Thread Safe. But here the different channels are accessing the same server's ArrayList instance. In this case should I take care of synchronizing the access to the ArrayList? Note in case it adds to my question: As I am going to have a database on the backend I am passing a DefaultEventExecutor in the .addLast() method when the handler is being created. If you have more than one eventLoop you are going to have concurrent access to the static ArrayList across multiple eventLoops. So YES you should take care of synchronizing the access to the ArrayList."
268,A,"StreamCorruptedException occurs during object decoding I am writing a netty client and server application that will write JVM GC stats to a time-series database to analyse for around 300 servers. However my pipeline is throwing lots of these exceptions: 10/02/2012 10:14:23.415 New I/O server worker #2-2 ERROR GCEventsCollector - netty error java.io.StreamCorruptedException: invalid type code: 6E at java.io.ObjectInputStream.readObject0(Unknown Source) at java.io.ObjectInputStream.defaultReadFields(Unknown Source) at java.io.ObjectInputStream.readSerialData(Unknown Source) at java.io.ObjectInputStream.readOrdinaryObject(Unknown Source) at java.io.ObjectInputStream.readObject0(Unknown Source) at java.io.ObjectInputStream.readObject(Unknown Source) at org.jboss.netty.handler.codec.serialization.ObjectDecoder.decode(ObjectDecoder.java:94) at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:282) at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:216) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:349) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:280) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:200) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source) at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) at java.lang.Thread.run(Unknown Source) It looks like it's creating an OutputStream but one already exists - so it throws that specific exception. It appears in my AIT environment where >300 servers are connecting but not in DEV where 1 agent is only connecting. I suspect it is either a bug in the object decoder or I have incorrect code somewhere. Please could anyone explain why this happens? Here is the collector: public class GCEventsCollector extends AbstractDataCollector { protected static final Logger logger = Logger.getLogger(GCEventsCollector.class); private static final ExecutorService WORKERS = Executors.newCachedThreadPool(); private static final ChannelGroup GROUP = new DefaultChannelGroup(""gc-events""); private final int port; private final ServerBootstrap bootstrap; public GCEventsCollector(final int port) { logger.info(""Creating GC Events collector on port "" + port); this.port = port; this.bootstrap = newServerBootstrap(port); } /** * Creates a bootstrap for creating bindings to sockets. Each channel has a pipeline which contains the * logic for handling a message such as encoding decoding buffering etc. * * @param port port of socket * @return configured bootstrap */ private ServerBootstrap newServerBootstrap(int port) { ExecutorService bossExecutor = Executors.newCachedThreadPool(); ExecutorService workerExecutor = Executors.newCachedThreadPool(); NioServerSocketChannelFactory channelFactory = new NioServerSocketChannelFactory(bossExecutor workerExecutor); ServerBootstrap bootstrap = new ServerBootstrap(channelFactory); ChannelHandler collectorHandler = new CollectorHandler(); bootstrap.setPipelineFactory(new CollectorPipelineFactory(collectorHandler)); bootstrap.setOption(""localAddress"" new InetSocketAddress(port)); return bootstrap; } protected KDBCategory[] getKDBCategories() { return new KDBCategory[] { KDBCategory.GC_EVENTS }; } /** * Bind to a socket to accept messages * * @throws Exception */ public void doStart() throws Exception { Channel channel = bootstrap.bind(); GROUP.add(channel); } /** * Disconnect the channel to stop accepting messages and wait until disconnected * * @throws Exception */ public void doStop() throws Exception { logger.info(""disconnecting""); GROUP.close().awaitUninterruptibly(); } class CollectorHandler extends SimpleChannelHandler { @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { super.channelOpen(ctx e); GROUP.add(e.getChannel()); } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { super.channelConnected(ctx e); logger.info(""channel connected""); } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { super.channelDisconnected(ctx e); logger.info(""channel disconnected""); } @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) throws Exception { if (logger.isDebugEnabled()) { logger.debug(""Received GcStats event: "" + e.toString()); } WORKERS.execute(new Runnable() { public void run() { saveData(KDBCategory.GC_EVENTS (GcEventsPersister) e.getMessage()); } }); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) throws Exception { logger.error(""netty error"" e.getCause()); } } private static class CollectorPipelineFactory implements ChannelPipelineFactory { private final ChannelHandler handler; private CollectorPipelineFactory(ChannelHandler handler) { this.handler = handler; } @Override public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline(new ObjectDecoder() handler); } } } Here is the agent: public class GCEventsAgent { private final static Logger logger = Logger.getLogger(GCEventsAgent.class); private static final ExecutorService bosses = Executors.newCachedThreadPool(); private static final ExecutorService workers = Executors.newCachedThreadPool(); private static final Timer timer = new HashedWheelTimer(); private static final String localHostName; private static final ParseExceptionListener exceptionListener = new ExceptionListener(); static { String name = """"; try { name = InetAddress.getLocalHost().getHostName(); } catch (UnknownHostException e) { logger.error(""cannot retrieve local host name"" e); } localHostName = name; } public static void main(final String[] args) { checkArgument(args.length >= 3 ""Usage: GCEventsAgent [log4j cfg] [mba cfg] [server cfg] [process 1] ... [process n]""); System.setProperty(""log4j.configuration"" ""file:log4j.properties""); final String log4jConfig = args[0]; DOMConfigurator.configure(log4jConfig); final String mbaConfig = args[1]; final String serverConfigPath = args[2]; final ServerConfig serverCfg = new ServerConfig(serverConfigPath); setup(serverCfg args); } private static void setup(ServerConfig cfg String[] args) { final String host = cfg.getParameter(String.class ""host""); final int port = cfg.getParameter(Integer.class ""port""); if (args.length == 3) configurePolling(cfg host port); else configureProcesses(cfg args host port); } private static void configureProcesses(final ServerConfig cfg final String[] args final String host final int port) { final List<File> logFiles = logFiles(cfg args); logger.info(""Initializing GC Agent for ["" + host + "":"" + port + ""]""); final NioClientSocketChannelFactory channelFactory = new NioClientSocketChannelFactory(bosses workers); final ClientBootstrap bootstrap = new ClientBootstrap(channelFactory); bootstrap.setOption(""remoteAddress"" new InetSocketAddress(host port)); final GCParserFactory parserFactory = new DefaultParserFactory(); final AgentProcessHandler agentHandler = new AgentProcessHandler(bootstrap logFiles parserFactory); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline(new ObjectEncoder() agentHandler); } }); bootstrap.connect().awaitUninterruptibly(); } private static void configurePolling(ServerConfig cfg String host int port) { final int frequency = cfg.getParameter(Integer.class ""frequency""); final NioClientSocketChannelFactory channelFactory = new NioClientSocketChannelFactory(newCachedThreadPool() newCachedThreadPool()); final ClientBootstrap bootstrap = new ClientBootstrap(channelFactory); bootstrap.setOption(""remoteAddress"" new InetSocketAddress(host port)); final GcParserSupplier parserSupplier = new GcParserSupplier(); final ConcurrentMap<File Tailer> tailerMap = Maps.newConcurrentMap(); final ParseExceptionListener exceptionListener = new ExceptionListener(); final Set<File> discoveredSet = Sets.newHashSet(); final File directory = new File(cfg.getParameter(String.class ""logDirectory"")); final TailManager tailManager = new TailManager(discoveredSet tailerMap parserSupplier exceptionListener localHostName); final DetectionTask detectionTask = new DetectionTask(directory discoveredSet tailManager); final FileWatcher fileWatcher = new FileWatcher(Executors.newScheduledThreadPool(1) detectionTask frequency); final Timer timer = new HashedWheelTimer(); final EfxAgentHandler agentHandler = new EfxAgentHandler(bootstrap tailManager fileWatcher timer); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline(new ObjectEncoder() agentHandler); } }); bootstrap.connect().awaitUninterruptibly(); } private static List<File> logFiles(ServerConfig cfg String[] args) { String logDir = cfg.getParameter(String.class ""logDirectory""); final int n = args.length; List<File> logFiles = new ArrayList<File>(n-3); for (int i = 3; i < n; i++) { String filePath = logDir + args[i] + "".gc.log""; try { File file = new File(filePath); if (!file.exists()) { logger.info(""missing log file so creating empty file at path: "" + filePath); File dir = file.getParentFile(); dir.mkdirs(); if (file.createNewFile()) logger.info(""successfully created empty file at path: "" + filePath); } logFiles.add(file); } catch (IOException e) { logger.error(""error creating log file at path: "" + filePath); } } return logFiles; } static final class AgentPauseListener implements GCEventListener<CMSType CMSHeap> { private final Channel channel; private final GcEventsPersister.Builder builder; private byte state; private AgentPauseListener(Channel channel GcEventsPersister.Builder builder) { this.channel = channel; this.builder = builder; } @Override public void onPause(PauseDetail<CMSType> pauseDetail) { logger.info(""onPause""); checkState(state == 0x00 || state == 0x01); builder .collectionType(pauseDetail.getType() == null ? null : pauseDetail.getType().toString()) .start(new Instant(pauseDetail.getStartTimestamp())) .end(new Instant(pauseDetail.getEndTimestamp())) .pause(pauseDetail.getType() == null ? false : pauseDetail.getType().isPause()) .duration(pauseDetail.getPauseMillis()); if (state == 0x00) channel.write(builder.build()); else state |= 0x02; } @Override public void onHeapBefore(HeapDetail<CMSHeap> details) { logger.info(""onHeapBefore""); checkState(state == 0x00); builder.heapBefore(used(details)).heapBeforeTotal(total(details)); state |= 0x01; } @Override public void onHeapAfter(HeapDetail<CMSHeap> details) { logger.info(""onHeapAfter""); checkState(state == 0x03); builder.heapAfter(used(details)).heapAfterTotal(total(details)); channel.write(builder.build()); state = 0x00; } private final long used(HeapDetail<CMSHeap> details) { return used(details CMSHeap.PAR_NEW_GENERATION) + used(details CMSHeap.CMS_GENERATION) + used(details CMSHeap.CMS_PERM_GENERATION); } private final long used(HeapDetail<CMSHeap> heapDetail CMSHeap gen) { final Map<CMSHeap HeapDetail.HeapMetric> sizes = heapDetail.getSizes(); final long used = sizes.get(gen).getUsed(); logger.info(""used = "" + used); return used; } private final long total(HeapDetail<CMSHeap> details) { return total(details CMSHeap.PAR_NEW_GENERATION) + total(details CMSHeap.CMS_GENERATION) + total(details CMSHeap.CMS_PERM_GENERATION); } private final long total(HeapDetail<CMSHeap> heapDetail CMSHeap gen) { final Map<CMSHeap HeapDetail.HeapMetric> sizes = heapDetail.getSizes(); return sizes.get(gen).getTotal(); } } static final class ExceptionListener implements ParseExceptionListener { @Override public void onParseError(int lineNo String input String error) { logger.error(""error parsing: "" + lineNo + "" - "" + input + "" - "" + error); } } static final class ReconnectTask implements TimerTask { private final ClientBootstrap bootstrap; ReconnectTask(ClientBootstrap bootstrap) { this.bootstrap = bootstrap; } @Override public void run(Timeout timeout) throws Exception { bootstrap.connect(); } } static class AgentProcessHandler extends SimpleChannelHandler { private final ClientBootstrap bootstrap; private final List<File> logFiles; private final GCParserFactory parserFactory; private final Set<Tailer> tailers = new HashSet<Tailer>(4); public AgentProcessHandler(ClientBootstrap bootstrap List<File> logFiles GCParserFactory parserFactory) { this.bootstrap = bootstrap; this.logFiles = logFiles; this.parserFactory = parserFactory; } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { logger.info(""channel connected""); for (File logFile : logFiles) { logger.info(""setting up scraper for logfile: "" + logFile); GCParser parser = parserFactory.getParser(); GcEventsPersister.Builder builder = new GcEventsPersister.Builder(logFile.getName() localHostName); GCEventListener gcEventListener = new AgentPauseListener(e.getChannel() builder); TailerListener listener = new LogLineListener(parser gcEventListener exceptionListener); Tailer tailer = Tailer.create(logFile listener 1000L true); tailers.add(tailer); } } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { logger.error(""channel disconnected""); stopTailers(); scheduleReconnect(); } private void scheduleReconnect() { timer.newTimeout(new ReconnectTask(bootstrap) 5L TimeUnit.SECONDS); } private final void stopTailers() { for (Tailer tailer : tailers) { tailer.stop(); } tailers.clear(); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) throws Exception { final Throwable cause = e.getCause(); logger.error(cause); if (cause instanceof ConnectException) { stopTailers(); scheduleReconnect(); } } }; private static class LogLineListener extends TailerListenerAdapter { private final GCParser parser; private final GCEventListener pauseListener; private final ParseExceptionListener exceptionLister; public LogLineListener(GCParser parser GCEventListener listener ParseExceptionListener exceptionLister) { this.parser = parser; this.pauseListener = listener; this.exceptionLister = exceptionLister; } @Override public void handle(String line) { logger.info(""handle(String line)""); parser.matchLine(line pauseListener exceptionLister); } } private static final class GcParserSupplier implements Supplier<GCParser<CMSType CMSHeap>> { @Override public GCParser<CMSType CMSHeap> get() { return new CMSParser(); } } private static final class TailManager implements FileHandler { private final Set<File> discoveredSet; private final ConcurrentMap<File Tailer> tailerMap; private final Supplier<GCParser<CMSType CMSHeap>> parserSupplier; private final ParseExceptionListener exceptionListener; private final String host; private volatile boolean go; private TailManager(final Set<File> discoveredSet final ConcurrentMap<File Tailer> tailerMap final Supplier<GCParser<CMSType CMSHeap>> parserSupplier final ParseExceptionListener exceptionListener final String host) { this.discoveredSet = discoveredSet; this.tailerMap = tailerMap; this.parserSupplier = parserSupplier; this.exceptionListener = exceptionListener; this.host = host; } public void stop() { go = false; for (Tailer tailer : tailerMap.values()) tailer.stop(); tailerMap.clear(); } public void start() { go = true; } @Override public void onNew(final File file final Channel channel) { checkState(go); GCParser<CMSType CMSHeap> parser = parserSupplier.get(); String fileName = file.getName(); GcEventsPersister.Builder builder = new GcEventsPersister.Builder(fileName host); AgentPauseListener eventListener = new AgentPauseListener(channel builder); Function<Void Void> removeTail = new Function<Void Void>() { @Override public Void apply(@Nullable final Void input) { final Tailer tailer = tailerMap.remove(file); tailer.stop(); discoveredSet.remove(file); return null; } }; GcTailAdaptor listener = new GcTailAdaptor(logger parser eventListener exceptionListener removeTail); tailerMap.put(file Tailer.create(file listener 1000L true)); } @Override public void onDelete(File file Channel channel) { checkState(go); final Tailer tailer = tailerMap.remove(file); tailer.stop(); } } static class EfxAgentHandler extends SimpleChannelHandler { private final ClientBootstrap bootstrap; private final TailManager tailManager; private final FileWatcher fileWatcher; private final Timer timer; public EfxAgentHandler(ClientBootstrap bootstrap TailManager tailManager FileWatcher fileWatcher Timer timer) { this.bootstrap = bootstrap; this.tailManager = tailManager; this.fileWatcher = fileWatcher; this.timer = timer; } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { logger.info(""channel connected""); tailManager.start(); fileWatcher.start(e.getChannel()); } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { logger.error(""channel disconnected""); tailManager.stop(); fileWatcher.stop(); scheduleReconnect(); } private void scheduleReconnect() { timer.newTimeout(new ReconnectTask(bootstrap) 5L TimeUnit.SECONDS); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) throws Exception { final Throwable cause = e.getCause(); logger.error(cause); if (cause instanceof ConnectException) { tailManager.stop(); scheduleReconnect(); } } } static final class GcTailAdaptor extends TailerListenerAdapter { private final Logger logger; private final GCParser parser; private final GCEventListener eventListener; private final ParseExceptionListener exceptionListener; private final Function<Void Void> removeTail; private volatile long lastTail; GcTailAdaptor(final Logger logger final GCParser parser final GCEventListener eventListener final ParseExceptionListener exceptionListener final Function<Void Void> removeTail) { this.logger = logger; this.parser = parser; this.eventListener = eventListener; this.exceptionListener = exceptionListener; this.removeTail = removeTail; } @Override public void handle(String line) { lastTail(); parser.matchLine(line eventListener exceptionListener); } private final void lastTail() { final long t = System.currentTimeMillis(); if (lastTail == 0L) { lastTail = t; return; } if ((t-lastTail)>=1800000L) removeTail.apply(null); } @Override public void handle(Exception ex) { logger.error(ex); } } @VisibleForTesting final static class DetectionTask implements Runnable { private final File directory; private final Set<File> discovered; private final FileHandler handler; private volatile Channel channel; DetectionTask(final File directory final Set<File> discovered final FileHandler handler) { this.discovered = discovered; this.handler = handler; this.directory = directory; } public void setChannel(Channel channel) { this.channel = channel; } public boolean removeStaleFile(File file) { checkArgument(discovered.contains(file) ""file is not discovered so cannot be stale""); return discovered.remove(file); } public void run() { final File[] files = directory.listFiles(); for (int i=0 n=files.length; i<n; i++) { final File file = files[i]; synchronized (discovered) { if (!discovered.contains(file)) { discovered.add(file); handler.onNew(file channel); } } } final ImmutableSet<File> logFiles = ImmutableSet.copyOf(files); final ImmutableSet<File> diff = Sets.difference(discovered logFiles).immutableCopy(); for (File file : diff) { discovered.remove(file); handler.onDelete(file channel); } } } @VisibleForTesting static interface FileHandler { void onNew(File file Channel channel); void onDelete(File file Channel channel); } @VisibleForTesting final static class FileWatcher { private final ScheduledExecutorService executor; private final DetectionTask detectionTask; private final int frequency; private volatile ScheduledFuture<?> task; @VisibleForTesting FileWatcher(ScheduledExecutorService executor DetectionTask detectionTask int frequency) { this.executor = executor; this.detectionTask = detectionTask; this.frequency = frequency; } public void start(Channel chanel) { task = executor.scheduleAtFixedRate(detectionTask 0L frequency TimeUnit.SECONDS); detectionTask.setChannel(chanel); } public void stop() { task.cancel(true); detectionTask.setChannel(null); } public static FileWatcher on(File directory FileHandler handler int frequency) { checkNotNull(directory); checkNotNull(handler); checkArgument(directory.isDirectory() ""file is not a directory""); checkArgument(directory.canRead() ""no read access to directory""); checkArgument(0 < frequency ""frequency must be > 0""); final HashSet<File> objects = Sets.newHashSet(); final DetectionTask task = new DetectionTask(directory objects handler); final ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1); return new FileWatcher(executorService task frequency); } } } Show us the codez please. Edited to add the agent and collector code I have incorrect code somewhere. Correct. Specifically you almost certainly have different ObjectInput/OutputStream lifetimes at server and client. Use the same streams for the life of the socket and don't do any I/O over those sockets via any other means. @algolicious Almost certainly unless they are carefully synchronized at both ends. I'm not touching any OutputStreams outside of netty. I do however use only one connection to send serialized Java objects from different threads - is that an issue?  I discovered why this happens. I am using a deprecated ObjectDecoder that's not compatible with my client's ObjectEncoder. I am just sending a ByteBuffer instead and it's fine now."
269,A,Using SSL Certificates on Netty I'm trying to build a simple client-server application using Netty which uses SSL certificates . I looked around and I could only find the secure chat example [here]. It uses bogus certificates. Could you help me to findout how to do a proper implementation of SSL certificates (self-signed) in Netty? Thanks in advanced. I found this posying very useful http://maxrohde.com/2013/09/07/setting-up-ssl-with-netty/  Try the secure websockets example. https://github.com/netty/netty/tree/master/example/src/main/java/io/netty/example/http/websocketx/sslserver Thanks. Will check it out. Thanks @veebs. Worked like a charm.  I would recommend against self signed certificates. It's not worth the trouble. You can get signed certificate for free from StartSSL. Check out the link below on how to convert a signed certificate into PKCS12 format and use it in SSLContext to be used with Netty. http://blog.hintcafe.com/post/33709433256/https-server-in-java-using-netty-and-keystore
270,A,Software-Design Issues I'm planing to build a software in client-server-design. Technology should be Java. Server should have a communication layer for web-services (e.g. RESTful Jersey) RMI JSF. Clients can be: Fatclients in Swing or Browser clients in JSF. In my focus are JBoss Netty for the server Jersey looks much more simple but Netty would have more other interfaces which could be interesting too. Does Netty offer something for RMI? I read somewhere that JSF and RESTful doesn't fit together. Are there web-service implementations which fit to a JSF implementation like icefaces? Thanks! Wow this question would win any buzzword bingo contest. I would suggest to use Spring Framework. Using it you can implement RMI REST etc over the same service implementation and it is very simple to do. On top of it your design will benefit from Dependency Injection paradigm used by Spring. Check it out at http://www.springsource.org/about Spring could be something but I'm afraid that it's a overhead quite a big piece of software. Don't be. In Spring you only use/load what you need.
271,A,"Netty Channel.write from another string do not work private void handleWebSocketFrame(ChannelHandlerContext ctx WebSocketFrame frame) { // Check for closing frame if (frame instanceof CloseWebSocketFrame) { handshaker.close(ctx.channel() (CloseWebSocketFrame) frame.retain()); return; } if (frame instanceof PingWebSocketFrame) { ctx.channel().write(new PongWebSocketFrame(frame.content().retain())); return; } if (!(frame instanceof TextWebSocketFrame)) { throw new UnsupportedOperationException(String.format(""%s frame types not supported"" frame.getClass() .getName())); } // Send the uppercase string back. String request = ((TextWebSocketFrame) frame).text(); if (logger.isLoggable(Level.FINE)) { logger.fine(String.format(""%s received %s"" ctx.channel() request)); } Message msg = new Message(ctx.channel() request); ReadQueueHandler.getInstance().addMessageToProcess(msg); } public class ReadQueueHandler implements Runnable { private static int POOL_SIZE = 3; private static ReadQueueHandler instance; private final BlockingQueue<Message> messageQueue; private final ExecutorService threadPool; private final int threadPoolSize; private final boolean isActive; private ReadQueueHandler() { this.threadPoolSize = POOL_SIZE; this.threadPool = Executors.newFixedThreadPool(threadPoolSize); this.messageQueue = new LinkedBlockingQueue<Message>(); isActive = true; initThreadPool(); } private void initThreadPool() { for (int i = 0; i < this.threadPoolSize; i++) { this.threadPool.execute(this); } } /** * Add message to read queue * * @param message * - adding message */ public void addMessageToProcess(Message message) { if (message != null) { this.messageQueue.add(message); } } @Override public void run() { while (isActive) { Message message = null; try { message = this.messageQueue.take(); } catch (InterruptedException e) { System.out.println(""Exceptio "" + e); /* * TODO Add logging */ } if (message != null) { Channel channel = message.getChannel(); channel.write(new TextWebSocketFrame(""Message handled "")); } } } public static ReadQueueHandler getInstance() { if (instance == null) { instance = new ReadQueueHandler(); } return instance; } } If i execute Channel.write(""something"") instead of adding data to queue then all work fine and client get data. But if Channel.write("""") execute from another thread than data is not got. What can be reason? Channel write can not be execute from another thread? For me it seems like you forgot to call flush() after the write is done to guaranteer it's flushed to the socket. For example you could fix this by use: channel.writeAndFlush(new TextWebSocketFrame(""Message handled ""));"
272,A,How to handle different type of clients in Netty 4.0 For a server using Netty 4.0 1) Can i use one handler to handle data coming from clients which are developed in different languages?(for example : c# flash objective-c javascript) 2) Should i use ChannelInboundByteHandler or ChannelInboundMessageHandler for the above situation? thank you.. 1) Yes You can use single handler to handle data coming from different clients. If your server processes row bytes sent by clients then you can process at server side but if they are sending objects then you should make appropriate objects at server side. you can get clear idea about handlers from http://www.znetdevelopment.com/blogs/2009/04/21/netty-using-handlers/ 2)Answer of second question depends on your requirement you can use any of them as per your requirement.
273,A,What happens when shared MemoryAwareThreadPoolExecutor's threshold is reached? What happens to the channels when the MemoryAwareThreadPoolExecutor's channel or total threshold is reached? The MemoryAwareThreadPoolExecutor is set into an ExecutionHandler that's on every pipeline before the I/O-Handler. My current state of information: I found: channel.setReadable(false) is called. That means all read-operations on all channels are stopped right? So incoming data will not be delivered to any pipeline won't it? When I got it right you should devide your code at the end of a pipeline into a non-blocking business-handler and a blocking business handler with an execution handler before the blocking one. Example: -> Decoder Encode NonBlockingHandler ExecutionHandler I/O-Handler That's where I think it would be better to get the messages at least to the last handler before the execution handler. If I am right then messages that would not need to be processed by the I/O-Handler will not get into NonBlockingHandler until Thread-Pool of the execution handler is below threshold again. I admit that this will not guarantee the execution of the messages in received order per channel. But let's just assume that it is not necessary. Best regards and cheers to Netty! Channel.setReadable(false) will only affect the Channel on which it was called an no other channels. Thank you very much!  When the channel threshold for a given channel is reached channel.setReadable(false) will be called thus preventing further reads from that channel. When enough data has been processed channel.setReadable(true) will be called allowing data to be read again. In the meantime any unread data will be stored in the OS network stack buffers or backed up to the sending host. When the total threshold is reached the IO thread trying to queue the request is blocked until enough data has been processed. You have to be really careful with this because it can lead to deadlock in the following situation: Channel (or channels) receives data faster than can be processed Channel (or channels) queue more than the total threshold limit blocking the IO thread The thread pool thread writes some data back to the channel and waits for it to complete. The thread pool thread is never released because the IO thread is blocked waiting for it to return and thus cannot process the write request. One other thing unless you are queuing ChannelBuffers in the thread pool you really need to create a custom implementation of ObjectSizeEstimator to ensure the thread pool can manage the thresholds properly.
274,A,"Netty 3.3.x breaks compatibility with Java5 I've discovered a compatibility problem with Netty and Java5. The ""String"" class in Java 5 does not support specifing the charset using the ""Charset"" class but only with the charset name expressed as String (eg. constructor getBytes). I've seen at least two different places ""QueryStringDecoder"" at line 380 ""WebSocketServerHandshaker13"" at line 22 where the code breaks when executed in a Java 5 environment Is it possible having a 3.3.2 build that fix the problem for those who cannot upgrade to Java 6 in a short time but needs to use netty 3.3.x? Thanks why you cant upgrade to 3.4.x ? Ok it will now be possible to disable the use of Unsafe via a System property in the next 3.4.1.Final release. See https://github.com/netty/netty/issues/272. I'm compiling netty by myself in order to disable the use of the ""Unsafe"" class (applying a small patch in UnsafeDetectionUtil) because that cause serious problem in a VM that I cannot upgrade at the moment. But I cannot compile the 3.4 branch because of the Java7 compiler required so I compile the 3.3 branch after patching (and fixing the charset bugs for Java5). If you know any other trick to disable the use of the Unsafe class I'll be very happy to upgrade do 3.4 branch. In alternative is it possible for you to consider releasing a 3.4 version which permit disabling Unsafe? In the latest 3.4.x code base we fallback to disable unsafe if we can not use it. This will be released as 3.4.1 hopefully at end of the week. The java 7 is only needed for compile you can still run with java5 as we disable /enable features based on the jaa version on runtime Unsafe is used only in the LinkedTransferQueue. If it fails to instance it it use LegacyLinkedTransferQueue which not use Unsafe. It's the same behaviour that 3.3.x. The problem is that in my VM Unsag class is present and does not fail to instance but when it's used it reports to me an invalid memory access like I posted in another question a couple of days ago. That's the reason why I'd like to have a way to programmatically disable it. Please open a issue in netty's bugtracker for that. I think we could introduce a System property which can disable it. Anyway like I said its a jdk bug and you should maybe just upgrade the jvm. But I can also see that it can be useful to disable it. Great! Thank you Norman! How is the check to detect if you can use it Unsafe or not? I know that Java7 is only needed for compiling but until there is no way for me to programmatically disable Unsafe I have to compile Netty by myself with Java6 3.4.1.Final is out now.. Please upgrade to netty-3.4.1.Final once it is out. It will fix all your problems as we now also support to disable the use of Unsafe. Just add ""-Dorg.jboss.netty.tryUnsafe=false"" to the startup script."
275,A,"netty websocket protocols support I tried to look this over in the Netty documentation but was unable to find it : which all websocket protocols does Netty websocket implementation support ? I am trying to check for browser compatibility and hence also wanted to see the protocols as mentioned above. Going through the websocket server example in Netty 3.5.3  I see in the WebSocketServerIndexPage class that window.MozWebSocket is also used  hence am I right that hybi-07 and hybi-10 is also supported without any specific code to be written? (Pardon me I am not much aware of the differences in the various protocols but it seems to be mentioned everywhere). Not sure what you're true question is but if you're trying to check for compatibility js: `typeof window.WebSocket === ""function""` condition should do the trick @MattLo : I am just trying to look for various protocols Netty implementation supports  since various browsers and versions support different websocket protocols. According to the netty api docs it supports 3 versions of the Hybi drafts - 00 10 and 17. Most intermediate versions could be covered by one of these if you needed. This will give you support for most browsers as summarised by http://en.wikipedia.org/wiki/WebSocket.  Netty supports protocol versions HyBi 00 (which is the same as Hixie 76) HyBi 8-10 and HyBi 13-17 (17 is the same as IETF 6455). Each browser supports a single version of the protocol. HyBi 00-76 covers current released versions of iOS. IETF 6455 covers recent versions of Chrome and Firefox (and Opera if once they enable it by default) and IE 10. For browsers without native WebSocket support but with Flash you can use web-socket-js as a fallback and that supports IETF 6455 (albeit without binary data types). In other words Netty supports basically all browsers that have WebSocket support. Thanks for the clarification. I've removed the Safari scaremongering from my answer now"
276,A,"Channel.channelInterestChanged in Netty I am working with Netty Channels and when sending lots of data across the channel  I notice that the Channel.channelInterestChanged event gets fired which immediately results in Channel.isWritable() to return false.( there is another thread doing a Channel.write() and this thread fails immediately ). My question is : why is the Channel's interests getting changed ? or rather who is changing it ? Nothing in code that I wrote ( server or client ) changes the interests. It gets changed because you write more data to the Channel then it can transmit in a given time. Netty queues the data for you until some treshold is hit once it is hit Channel.isWritable() will return false. You have to adjust the writeBufferHighWaterMark and writeBufferLowWaterMark if you want to change how many bytes are allowed to get queued/buffered before Channel.isWritable() returns false. ServerBootstrap sb = .... sb.setOption(""writeBufferHighWaterMark"" ..); sb.setOption(""writeBufferLowWaterMark"" ..); Anyway you should make sure that your code that calls Channel.write(...) does check Channel.isWritable() and only write to if it returns true. The problem you have are often seen in slow networks. [1] http://netty.io/docs/stable/api/org/jboss/netty/channel/socket/nio/NioChannelConfig.html"
277,A,"Akka remoting- Cann't assign requested address I am trying an example of Akka-Remoting. Every time I start my remote actor system I get this exception [INFO] [11/25/2013 18:50:19.811] [main] [Remoting] Starting remoting Exception in thread ""main"" org.jboss.netty.channel.ChannelException: Failed to bind to: /10.147.137.44:2555 at org.jboss.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272) at akka.remote.transport.netty.NettyTransport$$anonfun$listen$1.apply(NettyTransport.scala:391) at akka.remote.transport.netty.NettyTransport$$anonfun$listen$1.apply(NettyTransport.scala:388) at scala.util.Success$$anonfun$map$1.apply(Try.scala:206) at scala.util.Try$.apply(Try.scala:161) at scala.util.Success.map(Try.scala:206) at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:67) at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:82) at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:59) at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:59) at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72) at akka.dispatch.BatchingExecutor$Batch.run(BatchingExecutor.scala:58) at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:42) at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) Caused by: java.net.BindException: Cannot assign requested address at sun.nio.ch.Net.bind0(Native Method) at sun.nio.ch.Net.bind(Net.java:444) at sun.nio.ch.Net.bind(Net.java:436) at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214) at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74) at org.jboss.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:366) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:290) at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744) Here is my application.conf details remoteCalculator{ akka { actor { provider = ""akka.remote.RemoteActorRefProvider"" } remote { transport = ""akka.remote.netty.NettyRemoteTransport"" log-received-messages = on log-sent-messages = on log-remote-lifecycle-events = on enabled-transports = [""akka.remote.netty.tcp""] netty.tcp { hostname = ""10.147.137.44"" port = 2555 log-received-messages = on log-sent-messages = on log-remote-lifecycle-events = on } } } } I tried finding the possibility of another application listening to the port 2555 by executing following command sudo netstat -anp | grep 2555 But it doesn't gives anything. Please help me find out the reason why the application is not able to bind on the configured address. I got the root cause of the problem. Actually it was not a configuration/proramming issue. I am working on a virtual host (Ubuntu) inside my window OS and I had not enabled the network bridge. So the virtual host was not able to identify the hostName. After enabling the network bridge the issue got solved."
278,A,"Netty update sample code HttpStaticFileServerHandler to also return directory listing when a directory URL is specified I'm wondering how I could modified this great example handler found here: https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/http/file/HttpStaticFileServerHandler.java To also provide the ability to return a directory listing of files? Currently it will only serve files if the exact path and name to the file is specified I would like to modify it such that I could specify a base path and get a listing of the files on the path Thanks for any thoughts or ideas You can try inserting the following at line #126. if (file.isDirectory()) { String[] contents = file.list(); StringBuilder sb = new StringBuilder(); for (String name: contents) { sb.Append(name); sb.Append(""\n""); } HttpResponse response = new DefaultHttpResponse(HTTP_1_1 OK); response.setContent(ChannelBuffers.copiedBuffer(sb.toString() CharsetUtil.UTF_8)); response.setHeader(CONTENT_TYPE ""text/plain; charset=UTF-8""); if (isKeepAlive(request)) { response.setHeader(CONTENT_LENGTH response.getContent().readableBytes()); response.setHeader(CONNECTION HttpHeaders.Values.KEEP_ALIVE); } ChannelFuture future = e.getChannel().write(response); if (!(isKeepAlive(request)) { future.addListener(ChannelFutureListener.CLOSE); } return; } Caution: I've just typed this up off the top of my head. You may get a compile error or two. This works perfect thanks Veebs! I just made a few tweaks to what you had so it would return the files wrapped with HTML links.  i would imagine you would change the branch which returns an error if the target is not a ""file"" to instead return the directory listing as some sort of text/html file."
279,A,Can netty be used to server data to backbone on the front end? I know node.js is usually used to server as a backend to backbone.js but can netty also do this? I prefer the jvm and was hoping someone could provide some production worthy code that serves as a backend to backbone.js. And the main point of this is to be able to have a real-time web application so it would use long-polling to maintain a connection with the client to update the UI (say someone updated something via a mobile device the browser should react to this). Wait what code are you asking? backend netty code to respond to client connections keep alive long polling and updates being sent to backbone. Backbone is 100% backend agnostic. Our entire site is built on top of Backbone for the front-end and the backend is entirely in Java. Personal projects have used Python and Flask to handle the API layer. Backbone was originally culled from a RoR project... do you use netty for long-polling to keep a constant connection to your backbone front end though? that is what I am interested in for real time updates. @user1361315 Use [socket.io](http://socket.io) my friend! It's got backends in many languages including java. What I like about Backbone is that it's very agnostic. It does nothing for you in terms of socket communication so use a library which works for you. FYI - I know trello and possibly this site both use it. which socket.io implementation did you use? We don't use socket.io at work but I have built demos on top of the node.js implementation and the gevent based Python implementation.
280,A,"Tranferring Java objects using Netty I am using Netty4 to develop a Client/Server application. I need to transfer different types of Java Objects (POJOs) from the client to server and vice-verse. I am bit confused on how the client or the server would know the type of the java object received? Also is it a good idea to transfer Java objects like this (or) try to use a format like JSON/XML/Proto-buffers and convert the message to Java Object after receiving? You could use Protobuf or just Serialization. Netty ships decoder/encoder for both o them. My question is more like How would i know the object type that I received? Should I check with ""instanceof""? Thanks. It should be part of your protocol. If you use something like serialization you can just check for the instanceof. If you build your own binary protocol for example you could encode it in the tcp stream etc. any examples of using protobufs?  Objects are more of a concept that exist virtually in memory and you can not transfer them as they are. You have to use some way of serialization. Serialization results in a stream of data that describes the state and type of your data in a way that all involved sides can understand. Java comes with a serialization mechanism (Serializable) which does not require much work from your side. The serialized information it produces contains the class name so the other side knows which class is responsible to create objects from the serialized data. Using that mechanism requires that both sides share the same classes (e.g. sharing a common library) and they must both be written in Java (* possible that there are ways around that). It's also a good idea if they have the exact same version of the class. Once you update just one side it may get difficult because that can change the way how state is expressed. Other serialization mechanisms like JSON Protocol Buffer ... are typically independent of your concrete implementation and language. They still contain a description of all the required state but you are not bound to certain classes or even the concept of Objects. Especially in the context of Netty Does one vs. the other have any advantages (may be amount of data transfer!)? I already have Serializable java objects. I don't know netty much but Protobuf is less data to transfer since it transfers binary data while JSON is text. Text requires multiple times the size of a binary. But you can GZIP compress text so it's not much more in the end. https://github.com/eishay/jvm-serializers/wiki compares some serialization mechansims and they all have advantages and disadvantages"
281,A,Starting a netty application on a linux server I have written a little netty server application packed in a jar file that I want to deploy on a linux server. Since I have no professional experience with deploying java applications I was wondering if it is enough to start the netty server by doing: java -jar NettyServer.jar NettyServer & Obviously a script could be created to ensure the correct user starts the process etc. but is this the way (stand-alone) java services is being deployed? It seems almost too easy considering every other question/answer seems to mention some big hunky container-bean-glassfish-tomcat-whatnot (which I might consider later on if/when issues arise) You might want to check out something like `supervisor` or `god` so that you can run it as a Linux service at startup etc. I personally prefer Upstart to start services on linux. http://upstart.ubuntu.com/ It is very easy to use and can also restart your application on crash. I hope it helps. thx for another great tip!  yes thats the way - no container needed!! I built a middleware (http://sourceforge.net/projects/serviceconnecto/) using netty as underlaying framework. It's the way i start my server as well! Just verify the classpath is set correctly - meaning libraries are in correct place and the jar archive is correctly built.
282,A,"What to write in MyServerHandler for Netty websocket I have wrote my websocket server class and wrote ServerPiplineFactory class but I don't know to write in MyServerHandler class. MyServerHandler class is like  public class DiscardServerHandler extends SimpleChannelUpstreamHandler { private static final String WEBSOCKET_PATH = ""/websocket""; @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { Object msg = e.getMessage(); //ctx.getChannel().write(msg); //msg.getClass(); if (msg instanceof HttpRequest) { //ctx.getChannel().write(msg); } else if (msg instanceof WebSocketFrame) { System.out.println(""I am WebSocketFrame""); } } So I don't know what should I write if I receive HttpRequest and how to send it back to the browser. So if write something like below in my jsp file  </script> var WEBSOCKET_URL = ""ws://localhost:8090/websocket""; $(document).ready(function() { ws = new WebSocket(WEBSOCKET_URL); ws.onopen = function(event) { alert(""test""); $('#status').text(""Waiting....""); }; ws.onmessage = function(event) { var message = jQuery.parseJSON(event.data); alert(message); } var encoded = $.toJSON(""test message""); ws.send(encoded); }); </script> <body> <p id=""status"">&nbsp;</p> </body> and debug this jsp then it goes to messageReceived then I don't understand what to do then to how websocket server comunicate with server. So if someone can help me to find the document on this or explain a bit about this that would be great. You will need to issue the handshake. Have a look at the websocket example at [1]. [1] https://github.com/netty/netty/blob/3/src/main/java/org/jboss/netty/example/http/websocketx/server/WebSocketServerHandler.java Hi Norman Thanks for your response. I looked at the link and found a class WebSocketServerHandshakerFactory do I need this? because if I use this I need to use 5-6 classes under websocketx package. Also I don't understand WebSocketServerIndexPage.getContent(getWebSocketLocation(req)); Its just getting content from java class do I need this also because I have jsp file instead of this java for getting the content. I am not able to completely understand WebSocketServerHandler.java class as am new to websockets and using it first time"
283,A,How to get network traffic statistics? I'm using Netty 3.5.4.Final. How can one get the number of inbound and outbound transferred bytes within a single netty client/server instance? Current or average upload/download speed would be nice too. The package org.jboss.netty.handler.traffic provides the classes you need. You could install a GlobalTrafficShapingHandler (read and write limitation = 0) in your pipeline to measure throughput and the number of bytes that went through your pipeline.
284,A,"Processing Multi-form data in Netty With a client like this StringBody body = new StringBody(""form_username"" Charset.forName(""UTF-8"")); multipart.addPart(""username"" body); ByteArrayBody bBody = new ByteArrayBody(bs ""form_command.dat""); multipart.addPart(""data"" bBody); httppost.setEntity(multipart); How are the values supposed to be retrieved in the netty server. I already have a HttpRequestDecoder added to the pipeline. And the messageReceived handled thus HttpRequest request = (HttpRequest) e.getMessage(); this.mRequest = request; if (is100ContinueExpected(request)) { send100Continue(e); } ChannelBuffer content = request.getContent(); if (content.readable()) { System.out.println(""Content()\n"" + content.toString(CharsetUtil.UTF_8) + ""\r\n""); } Print outputs . Content() --Xdq2t6unVsUp191MKhpR6BXz5P7Eoo Content-Disposition: form-data; name=""username"" Content-Type: text/plain; charset=UTF-8 Content-Transfer-Encoding: 8bit form_username --Xdq2t6unVsUp191MKhpR6BXz5P7Eoo Content-Disposition: form-data; name=""data""; filename=""form_command.dat"" Content-Type: application/octet-stream Content-Transfer-Encoding: binary --Xdq2t6unVsUp191MKhpR6BXz5P7Eoo-- End of contents You need to use the new HttpPostRequestDecoder. This is only available in the upcoming Netty 3.5 (3 branch) and Netty 4 (master branch). Here an example usage. If you need to use it now you can just copy the files mentioned in this pull request into your project namespace and use it. Hope this helps. I have tried to backport the updates but got stuck in resolving SeekAheadOptimize which I believe should be in HttpPostBodyUtil. Is there a downloadable jar file of this backports. or git commands to get the ""back-ported"" files. Thanks. Planning to get rid of it once 3.5 has been released. Here's one that I've done. https://github.com/mashupbots/socko/tree/master/socko-webserver/src/main/java/org/mashupbots/socko/postdecoder."
285,A,Netty two-way and n-client UDP I am trying to write an application which will run in many machines and these machines will communicate with each other through sending a stream of UDP packets. Usually one machine will be sending many packets to another machine until they switch and another one will do the same to another machine and so forth. Choosing UDP is due to the nature of the application (real-time/speed more important than reliability). I also understand that UDP is a connectionless protocol. By doing a quick prototype I managed to create a NIO Datagram Server (bind) and a NIO Datagram Client (connect). However I realized that I can only send one way only from the client to the server (or maybe I am missing something?). I couldn't send in the opposite direction. Also since UDP is a connectionless protocol I thought that it was supposed to accept many clients sending packets to it (n-client to one server) and the other way around (server sending to clients one-by-one or multi/broad-cast). Should I create a server in the client listening to a different port to acheive two-way? Can n-client send packets to one server at the same time? I just want someone to clear this thing to me. No need for sample code (although it will be greatly appreciated) you can give me some pointers. Thank you. For what you are describing you need one server thread and one more client thread in EACH and EVERY instance of your program running on different machines. Create a multi threaded program with a serving thread and a client thread - the client thread needs to know about all servers - IP and Port. The server simply listens on a port on the current machine. If you run this same program on multiple machines You will get a p2p group. You can also set up a tracker on a free server in the internet. A tracker program will rest in a well known URL and will maintain a list of participating machines. Each instance of your program when started on a machine will update the tracker of details necessary to connect to it and the tracker can maintain a list of this data and share it all with any new instance coming up later. Ok can I use the same port for the client and server threads for both ends or I must pick different ones for in/out->out/in? If server is listening on a port its better to leave it free and use some other port for the client connection. You can fix Port A in all machine for server thread running in each machine and similarly fix Port B as port for client thread in all machines. Thanks the code is now offically ugly and need a rewrite.
286,A,Client-Server application for Android with Netty integration I need to develop an application on Android platform that enables a client to communicate/request a command to the server and enables the server to response to the client's request. I read about Netty and I want to implement it to my project but I'm new to socket programming it was written in Java so implementing it to Android is not that hard I guess. I'm looking for examples online but I'm lost in finding a good example for Android. Can someone here can give me example/s to start with or tell me how can I achieve those features to my application? Are you sure Netty works on Android? Are you sure it's not overkill? ah yes i saw forums too that Netty works at Android i just don't know where to start and how to start Netty is an asynchronous event-driven network application framework. (asynch I/O Java NIO high-performance) I think that Netty is a valuable framework for multiple client connection or multiple server connection. Android devices normally have very limited resources. I would recommend that you use java blocking socket at android devices. can you give an example for that?  Netty supports both NIO and OIO but Android has broken support for NIO so you can only use the OIO (blocking I/O) transport. Also SSLEngine in Android is also broken which mean you can't implement SSL with Netty on Android. (or possible probably using an alternative socket factory?) Therefore I would not recommend using Netty for Android devices although it's also true that many people seems to use Netty on Android successfully somehow. What is your suggestion for android client to connect netty server ? What do you mean by 'Android has broken support for NIO'? I googled `android nio broken support` but cannot find related information. I'm about to use netty on Android for nio therefore I think it's safer to ask first. You are correct. The issues that prevented people from using NIO in Android were all fixed before ICS and that's why Netty is going to support Android officially from its next major release: https://github.com/netty/netty/issues/2127  I would not recommend using Netty on Android as it is taking some javassist classes which are not recognized by the Android VM (Dalvik) such as the javassist.ClassPool class. Take a good old java socket and wrap it around a nice helper class and it should do it.
287,A,Apache Shiro integration and Netty ExecutionHandler/OrderedMemoryAwareThreadPoolExecutor I just added an ExecutionHandler to my server pipeline just before my main business logic handler as recommended in the documentation. I am using Apache Shiro http://shiro.apache.org/ for security. It worked fine until I added the ExecutionHandler. The issue: Shiro's execution context is bound to the current thread in which you obtain the Subject object. So if the Subject is obtained in the worker thread but the business logic executes in a separate ExecutionHandler managed thread then the two execution contexts won't be connected as far as Shiro is concerned. Thus Shiro in the ExecutionHandler thread will fail to be aware that the Subject is in fact authenticated. So I'm getting Authentication errors. It is possible to associate a given Subject with a Runnable before passing it to Executor.execute() so that the security context is maintained. See: http://shiro.apache.org/subject.html Based on this I think need to find a way to associate the current Shiro Subject with the ExecutionHandler Runnable. I'm still trying to fully understand the ExecutionHandler and OrderedMemoryAwareThreadPoolExecutor implementations. Basically I need to call subject.associateWith(aRunnable) just before aRunnable is passed to Executor.execute(aRunnable). Does anyone have thoughts on where/how I could hook Shiro into the mix? Thanks Matt Would be interesting to see how you integrated shiro and Netty. If it is opensource could you share the link? Maybe paste it as a github gist. Shiro can automate the thread handoffs for you. You should be able to just use one of the SubjectAwareExecutor SubjectAwareExecutorService or SubjectAwareScheduledExecutorService implementations out of the box. You can wrap the actual ExecutorService that will execute the Runnables and you're good. For example: ExecutorService myExistingExecutorService = //get from somewhere ExecutorService useThis = new SubjectAwareExecutorService(myExistingExecutorService); You can 'inject' or configure the useThis instance anywhere in your application and the calling code doesn't ever need to know Shiro exists. For example an unaware component calling useThis.submit(someRandomRunnable) has no idea that Shiro is in use but the Shiro Subject will still be retained across threads. Check out the respective JavaDoc pages for more. HTH! Les Not that I'm aware of. No worries - hopefully you can do it when you get the rep. Glad to help! Please award the answer if you feel it is sufficient. I've wired up the `SubjectAwareExecutorService` in my application context and everything works very well now. Many thanks for this. It's exactly what I was looking for. Cheers Matt I would but I don't have the reputation yet to vote up. Is there any other way to award?
288,A,"Netty/Grails web integration for embedded socket listener I am trying to embed Netty within a Grails (spring) webapp. I have all the pieces figured out and know how to use them the only thing I dont know is which piece should I use? The Netty app is going to be strictly for UDP and listen on port 162. Does this mean that I should set it up as a servlet? Would it be an HTTP servlet since its embedded in a webapp? Or should I just configure it as a standalone tack-on socket app that runs alongside Grails? I know what I'm asking for is rather confusing and ambiguous but thats because I'm just as confused myself. Any help would be appreciated thank you. The Netty app is going to be strictly for UDP and listen on port 162. Does this mean that I should set it up as a servlet? Not exactly. Using a servlet means incoming requests are limited to HTTP; you need UDP. Or should I just configure it as a standalone tack-on socket app that runs alongside Grails? Yes this is the correct approach. Your Netty/UDP service will run inside Grails and Grails has a nice bootstrap feature with servletContext hooks for managing the service's lifecycle important when using sockets to ensure the listening thread on the socket terminates properly. Assuming your Netty service is something like this: public MyNettyService extends Thread { def port def init(){ ... } public void run(){ //start listener } def shutdown(){ ... } } Configure the service in resources.groovy:  nettyService(MyNettyService){ bean -> bean.initMethod = ""init"" port = 12345 } In BootStrap.groovy configure the service to start and shutdown with the container: class BootStrap { def nettyService def init = { servletContext -> nettyService.start() } def destroy = { nettyService.shutdown() } } That's what I usually do but the Grails folks here are fanatical; I'm sure someone else will show an easier way. Hope it helps! I've tried everything I still can't get it to work :(. If someone could look at this and help me it would be great. https://gist.github.com/diljotr/9030299 What's not working? That log file is a mile long you need to be specific. I see the service `init` was called that's good. What else is working? Where is it not working? When I run-app with grails I get a single anonymous ""error"" that I haven't been able to track down the cause of. And the message for `Ready for connections` is called but when I send a test packet there is no more logging done which indicates that the socket did not bind properly. Furthermore: when I do `bootstrap.bind(new InetSocketAddress(""localhost"" 162)).sync()` I don't even get the final message `Ready for connections`. The anonymous error is thrown AFTER `new Bootstrap()` OMG IT WORKED!! Turns out for some weird reason GNS3 lost connection to my localhost adapter. Once I restarted GNS3 I was able to receive the `Message received of type DatagramPacket` message. Thanks a lot Raffian :). I would rep you but sadly I have less than 15 rep."
289,A,"ByteBuf with JSON? I am a student who just started using Netty! I am building a server that communicates with android and iOS. The primary task of my server will be sending and recieving JSON files with images(10 jpegs) and texts(less than 100 character). My server's framework is Netty. I built my server from ""HttpUploadServer"" from the Netty 4.0.6 example jar. As my server's primary task is to upload and download JSON files I only used multipart POST part from the example. So here is my question. Netty's HttpRequestEncoder and HttpResponseDecoder turns Http requests into ByteBuf and ByteBuf to responses. However what happens when I try to communicate with JSON? Does the encoder and decoder turn JSON into a ByteBuf and sends it? What is the normal way Netty users send and recieve JSON through HTTP? For sending and receiving JSON messages you don't need to add any Handlers. Http Encoders/Decoders are enough. Here is a example that uses JSON to send and receive. http://kevinwebber.ca/multiplayer-tic-tac-toe-in-java-using-the-websocket-api-netty-nio-and-jquery/ Regards Rama Krishna. this URL is not working now.. can you please post another link.. I want to read JSON returned by that URL... and if possible then please tell me the way to pass query parameters with the URL I am unable to find an example code for that Mitaksh try the URL again; I edited and fixed it."
290,A,"Netty - How to get server response in the client I'm mostly there with Netty but one concept is still alluding me and I can't find anything in the tutorials and so on. Firstly I do understand that Netty is asynchronous but there must be a way for a client to call the server and be able to get a response beyond the handler. Let me explain more. I have a client as illustrated below. And please note that I understand it's bootstrapped and a new connection is established on each call that's just there to make the example smaller and more succinct. Please ignore that fact. Client.java // ServerResponse is a result from the server in this case // a list of users of the system (ignore that each time it's all bootstrapped). public User[] callServerForInformationFromGUIWidget() { ClientBootstrap bootstrap = new ClientBootstrap(...); bootstrap.setPipelineFactory(...); ChannelFuture future = bootstrap.connect(new InetSocketAddress(host port)); Channel channel = future.awaitUninterruptibly().getChannel(); // Where request is a POJO sent to the server // with a request such as get me a list of users RequestPojo request = new RequestPojo(requestUserListCommand); ChannelFuture lastWriteFuture = channel.write(request); if(lastWriteFuture != null) lastWriteFuture.awaitUninterruptibly(); } Now I understand how to get the data on the server and fire back the result. The only thing is how do I handle it on the client side? Yes the clientHandler class can do something like the following: ClientHandler.java @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { User[] users = (User[])e.getMessage(); } The problem is how does the client code actually get that result? All the examples are similar to a chat service where the event fires off something else on the client that's not waiting on a response. Even the http client example I found lacking this. The documentation overall is really good but it's lacking on how to do callbacks. Anyways in this case I need the client to get the response from the server and based on the results it will do what it needs. In other words how do I write the client to do something like this: IdealClient.java // ServerResponse is a result from the server in this case // a list of users of the system. public User[] callServerForInformationFromGUIWidget() { ... RequestPojo request = new RequestPojo(requestUserListCommand); ChannelFuture lastWriteFuture = channel.write(request); if(lastWriteFuture != null) lastWriteFuture.awaitUninterruptibly(); User[] users = resultFromCallToServer(); performSomeAction(users); } Because the handler doesn't know who is looking for the answer or who asked the question. And if it's done in the handler than how? Back to my comments about the examples the http client (and handler) examples just dump the result to System.out. If you had a GUI how would you pass the result from your request up to the GUI? I never saw any examples for this. You have to handle it in the Handler with messageReceived(). I'm not sure what your issue is exactly. My guess is you have a response to a request that changes depending on what request was made? Maybe a concrete description of something you are doing of a response that has to know what request it came from. One thing you might be able to do is to pass a long living object the handler that knows the outstanding request and it can match up the response when it receives it. The pipeline factory method can pass a reference to a manager type object to the Handler. This was pretty much what I was trying to say. Your Handler is created in the PipelineFactory which is easy to pass parameters to the Handler from there:  bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.nulDelimiter())); pipeline.addLast(""decoder"" new XMLDecoder() ); pipeline.addLast(""encoder"" new XMLEncoder() ); // notice here I'm passing two objects to the Handler so it can // call the UI. pipeline.addLast(""handler"" new MyHandler(param1 param2)); return pipeline; } }); When you create your pipeline you'll add your Handler upon a new connection. Simply pass one or more objects that allows it to communicate back to the UI or a controller. You want to use callbacks(listeners) to handle responses like hotpottao asych mode http://hotpotato.biasedbit.com/ (which is also uses Netty) then you have to handle that inside the messageReceived :)  I think this kind of callbacks are not provided by default because they are more specific to the protocol/what application does ? Modified my answer with code to try and explain what I meant in my original answer. I'd have a controller that can update my UI how it sees fit and pass that to the Handler. I wouldn't pass individual UI elements directly to the Handler because that's too much coupling between my low level network and the UI components I choose to use. @chubbard That's the part I was missing. I didn't understand what you meant by: ""One thing you might be able to do is to pass a long living object the handler that knows the outstanding request and it can match up the response when it receives it. The pipeline factory method can pass a reference to a manager type object to the Handler."" In retrospect now that I get it it makes a lot of sense but trying to get it without seeing the code or still learning the framework well unfortunately it was too hard to decipher. So for example in the http client example the result is just dumped to System.out. What if you had a GUI you had to pass the result to? For example it had to be passed up to a JTextArea that the handler isn't aware of or maybe a JDialog etc. In other words a JButton is pressed and the event calls the server through the client. How do you basically pass the result from the server back up to the JButton's calling method. To add because the JButton handler may display the result in JTextArea maybe it will be a JDialog etc.  Jestan is correct. In my case I have a client that need to process price tick data. I use Antlr for the parsing. I fire my events in my parser but in my case my protocol is String based. Below is an example without Antlr I pass the String message in your case it could be the users. //----------------- Event -------------- public class DataChangeEvent { private String message; public DataChangeEvent(String message) { this.message = message; } public String getMessage() { return message; } } //----------------- Listener -------------- public interface DataChangeListenter { public void dataChangeEvent(DataChangeEvent event); } //----------------- Event Handler that fires the dataChange events -------------- // This class needs to be static since you need to register all your classes that want to be notified of data change events public class DataChangedHandler { private static List<DataChangeListenter> listeners = new ArrayList<DataChangeListenter>(); public static void registerDataChangeListener(DataChangeListenter listener) { listeners.add(listener); } public static void fireDataChange(DataChangeEvent dataChangeEvent) { for(DataChangeListenter listenter : listeners) { listenter.dataChangeEvent(dataChangeEvent); } } } //----------------- Example class that implements the listener and registers itself for events -------------- public class ProcessMessage implements DataChangeListenter { public ProcessMessage() { DataChangedHandler.registerDataChangeListener(this); } public void dataChangeEvent(DataChangeEvent event) { //Depending on your protocal I use Antlr to parse my message System.out.println(event.getMessage()); } } //---------------- Netty Handler ----------- public class TelnetClientHandler extends SimpleChannelHandler { private static final Logger logger = Logger.getLogger(TelnetClientHandler.class.getName()); @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { String message = (String) e.getMessage(); DataChangedHandler.fireDataChange(message); } }"
291,A,"Haproxy + netty: Way to prevent exceptions on connection reset? We're using haproxy in front of a netty-3.6-run backend. We are handling a huge number of connections some of which can be longstanding. Now the problem is that when haproxy closes a connection for means of rebalancing it does so by sending a tcp-RST. When the sun.nio.ch-class employed by netty sees this it throws an IOException: ""Connection reset by peer"". Trace: sun.nio.ch.FileDispatcherImpl.read0(Native Method):1 in """" sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39):1 in """" sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225):1 in """" sun.nio.ch.IOUtil.read(IOUtil.java:193):1 in """" sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:375):1 in """" org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:64):1 in """" org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:109):1 in """" org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312):1 in """" org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:90):1 in """" org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178):1 in """" java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145):1 in """" java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615):1 in """" java.lang.Thread.run(Thread.java:724):1 in """" This causes the following problems per configuration: option http-pretend-keepalive This is what works best (as haproxy seems to close most connections with a FIN rather than RST) but still produces about 3 exceptions per server per second. Also it effectively neuters loadbalancing because some incoming connections are very longstanding whith very high throughput: with pretend-keepalive they never get rebalanced to another server by haproxy. option http-keep-alive Since our backend expects keep-alive connections to really be kept alive (and hence does not close them on its own) this setting amounts to every connection eventually netting one exception which in turn crashes our servers. We tried adding prefer-last-server but it doesn't help much. option http-server-close This should theoretically work for both proper loadbalancing and no exceptions. However it seems that after our backend-servers respond there is a race as to which side sends its RST first: haproxy or our registered ChannelFutureListener.CLOSE. In practice we still get too many exceptions and our servers crash. Interestingly the exceptions generally get more the more workers we supply our channels with. I guess it speeds up reading more than writing. Anyways I've read up on the different channel- and socketoptions in netty as well as haproxy for a while now and didn't really find anything that sounded like a solution (or worked when I tried it). The Tomcat Nio-handler just does: } catch (java.net.SocketException e) { // SocketExceptions are normal Http11NioProtocol.log.debug (sm.getString (""http11protocol.proto.socketexception.debug"") e); } catch (java.io.IOException e) { // IOExceptions are normal Http11NioProtocol.log.debug (sm.getString (""http11protocol.proto.ioexception.debug"") e); } So it seems like the initial throw by the internal sun-classes (sun.nio.ch.FileDispatcherImpl) really is inevitable unless you reimplement them yourself.  'Connecton reset by peer' is usually caused by writing to a connection that had already been closed by the other end. That causes the peer to send an RST. But it almost certainly had already sent a FIN. I would re-examine your assumptions here. Very few applications deliberately send RSTs. What you are most probably encountering is an application protocol error. If that's unavoidableso is the ECONNRESET. My source for haproxy specifically sending RST is here: http://www.formilux.org/archives/haproxy/1111/5108.html ""Haproxy uses an RST to close the connection to the backend server precisely because of this otherwise it would not work at all."" Verifying that tcpdump for me did not show *any* FINs being sent to the backend except with http-pretend-keepalive. ps: Using latest haproxy 1.5.21"
292,A,Is Netty handler unique for each connection? I've been looking over at the proxy server example from Netty website: The example source code handler has a volatile variable private volatile Channel outboundChannel; which takes care of the channel that connects to another server for proxy. This got me to wonder if this is the correct and safe way to implement for multiple connections for proxy. I would like to allow multiple connections(inbound) to connect to different outbounds while making sure that every inbound connection is uniquely linked to the outbound channel. According to my knowledge Netty generates a new pipeline for each connection. Does this mean a newly generated handler by pipeline factory is uniquely dedicated to the new connection(channel)? p.s. If I have 1000 active connections to my Netty server does this mean there are 1000 different pipelines? There is one pipeline created per connection but the pipeline may contain both shared and exclusive handlers. Some handlers do not keep state and a single instance can be inserted into multiple [all] pipelines. Netty provided handlers that can be shared are annotated with ChannelHandler.Sharable. See the section titled Shared and Exclusive Channel Handlers in this tutorial. Right but if I declare an exclusive channel handler for each connection (that is each pipeline) does that mean that channel handler is dedicated to that specific connection only? Correct. You could reimplement a given handler to be Sharable by keeping all state in attachments or ChannelLocals.
293,A,Is Netty ChannelHandlerContext.set/getAttachment() thread safe? It has been suggested that one way to store stateful information across invocations of a handler is by using setAttachment() and getAttachment() methods in the ChannelHandlerContext object attached with the handler. But I don't see any synchronization around setting/getting the attachment in the implementaiton classes of ChannelHandlerContext. In that case how could one possibly ensure the visibility of the attachment across invocations of a handler object e.g. across multiple calls to messageReceived() on the same handler object when these calls are presumably invoked in different threads? The attachment itself is volatile so yeah it is thread-safe: https://github.com/netty/netty/blob/3/src/main/java/org/jboss/netty/channel/DefaultChannelPipeline.java#L715
294,A,Starting playframework netty in prodmode with ssl I'm trying to start a Play appication in Prodmode with a SSL-certificate. I created a jks file with java keytool and it worked without problems. Now I want to start the application on my Server with the following command ./bin/myApplication -Dhttps.keyStore=/var/www/vhosts/myApplication.de/ssl/ssl.jks -Dhttps.keyStorePassword=123456 -Dhttps.port=443 -Dhttp.port=disabled -Dhttps.keyStoreAlgoritm=jks The Problem is is the following error: [error] p.nettyException - Exception caught in Netty java.lang.IllegalArgumentException: empty text at org.jboss.netty.handler.codec.http.HttpVersion.<init>(HttpVersion.java:97) ~[io.netty.netty-3.7.1.Final.jar:na] at org.jboss.netty.handler.codec.http.HttpVersion.valueOf(HttpVersion.java:62) ~[io.netty.netty-3.7.1.Final.jar:na] at org.jboss.netty.handler.codec.http.HttpRequestDecoder.createMessage(HttpRequestDecoder.java:75) ~[io.netty.netty-3.7.1.Final.jar:na] at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:189) ~[io.netty.netty-3.7.1.Final.jar:na] at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:101) ~[io.netty.netty-3.7.1.Final.jar:na] at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:500) ~[io.netty.netty-3.7.1.Final.jar:na] [error] p.nettyException - Exception caught in Netty java.lang.IllegalArgumentException: invalid version format: ﾼMￚﾚ▒Eￆ￐￹/L￀ﾛﾁKﾕ￁0V&M at org.jboss.netty.handler.codec.http.HttpVersion.<init>(HttpVersion.java:102) ~[io.netty.netty-3.7.1.Final.jar:na] at org.jboss.netty.handler.codec.http.HttpVersion.valueOf(HttpVersion.java:62) ~[io.netty.netty-3.7.1.Final.jar:na] at org.jboss.netty.handler.codec.http.HttpRequestDecoder.createMessage(HttpRequestDecoder.java:75) ~[io.netty.netty-3.7.1.Final.jar:na] at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:189) ~[io.netty.netty-3.7.1.Final.jar:na] at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:101) ~[io.netty.netty-3.7.1.Final.jar:na] at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:500) ~[io.netty.netty-3.7.1.Final.jar:na] I alredy tried to start the application local with play generated certificate and it worked fine. The application is running also in Prodmode without SSL... Can anyone help me? Try the Activator TLS example: https://github.com/typesafehub/activator-play-tls-example  Ok I found my mistake here my complete way to get (and start) the play application in prod mode: Order a ssl certificate for that I created a csr-file with that command openssl req -nodes -newkey rsa:2048 -keyout myserver.key -out server.csr Important (I think this was my mistake) the server software used to generate the CSR is tomcat not java webserver When I got my crt-file by the ssl provider I made a p12-file openssl pkcs12 -export -in server.crt -inkey myserver.key -out abc.p12 Then I created a jks-file keytool -importkeystore -srckeystore server.p12 -srcstoretype PKCS12 -destkeystore abc.jks -deststoretype jks Now it's possible to start the server http://www.playframework.com/documentation/2.1.x/ConfiguringHttps
295,A,"OOM Netty with broken or slow clients I have a Netty Server (3.6.2) that generates some data and broadcast to subscribed clients. Sometimes some clients seem to don't get the data because the client is broken or the network resources are in poor condition. In this case the server fills the Channel write queue and keeps generating events and eventually this could lead to an OutOfMemoryError. One solution could be check if the channel isWritable() before writing and don't write in negative case (anyway I have to store this messages or I'll lose them). But I'd rather disconnect clients that are not flushing the write buffer in some time or at the pace I'm generating the broadcast events. How could I do that? How could implement this write buffer is not being flushed ""timeout""? Should I close clients if isWritable is false? I'd really appreciate any ideas. Thank you. Yeah you could close the connection if Channel.isWritable() returns false. Isn't it a bit drastic? In a Websocket connection maybe a client is just slow temporary and can recover pace. Isn't there some kind of timeout mechanism to implement in the handler like ""if this client is not writable for more than x period disconnect it?"". I want to avoid the OOM but I wouldn't want to have a lot of clients loosing messages just because there is a temporary network problem. WriteTimeoutHandler could be used to specify the maximum time allowed to write any single buffer. It'll throw an exception if the time is exceeded. This would achieve your goal but you still need to stop writing if channel.isWritable returns false to prevent OOM before the write timeout occurs. Alternatively you could size the write buffer to the level of the maximum backlog you can sustain. Norman's answer would then be valid because channel.isWritable() == false would occur at the point at which the backlog is consider to be too great."
296,A,"How to add authenticated user (principal) information to ChannelHandlerContext (or anywhere else?) In short I'm doing 2-way SSL and the client certificate is used to identify my end user. The SSLHandler does a fine job of that and the SSLHandler knows all about that principal. How do I share that information with other handlers so they can do their job throughout the channel pipeline? Here is where my SSLHandler extension finds the user principal... ... class MySslHandler extends SSLHandler{ .... public void messageReceived( ChannelHandlerContext ctx MessageEvent e) throws Exception{ logger.info(""messageReceived""); super.messageReceived(ctx e); try{ System.out.println(""!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! "" + getPrincipalCertificate().getSubjectDN().toString()); } catch(Throwable t){ logger.error(""Unable to see principal "" t); } } /** * * @return Return the user certificate of the principal * @throws SSLPeerUnverifiedException if the peer is not yet verified */ public X509Certificate getPrincipalCertificate() throws SSLPeerUnverifiedException{ return getEngine().getSession().getPeerCertificateChain()[0]; } } I presumably should add information to the ChannelHandlerContext so it's then available for the duration of the SSL Session and to all my other handlers but I can't figure out how to do that. Is this the wrong approach? Any suggestions? Thanks! If you need to share it between ChannelHandlers you need to use a static ChannelLocal instance. Ths is needed as ChannelHandlerContext is per ChannelHandler. See http://netty.io/docs/stable/api/org/jboss/netty/channel/ChannelLocal.html Thank you that did work!"
297,A,"Netty - second request to the same connection When I send second request handler does not process response here is code: public class Test extends SimpleChannelUpstreamHandler { protected boolean close = false; public static void main(String[] args) throws URISyntaxException { String url = ""http://example.com""; ChannelFactory channelFactory = new NioClientSocketChannelFactory(Executors.newCachedThreadPool() Executors.newCachedThreadPool()); final URI uri = new URI(url); ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""codec"" new HttpClientCodec()); pipeline.addLast(""inflater"" new HttpContentDecompressor()); pipeline.addLast(""aggregator"" new HttpChunkAggregator(1048576)); pipeline.addLast(""handler"" new Test()); Channel channel = channelFactory.newChannel(pipeline); InetSocketAddress inetAddress = new InetSocketAddress(uri.getHost() 80); channel.connect(inetAddress).addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) throws Exception { System.out.println(""connected""); Channel channel = future.getChannel(); if (!future.isSuccess()) { future.getCause().printStackTrace(); } else { HttpRequest request = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.GET uri.toASCIIString()); request.setHeader(HttpHeaders.Names.HOST uri.getHost()); request.setHeader(HttpHeaders.Names.CONNECTION HttpHeaders.Values.CLOSE); request.setHeader(HttpHeaders.Names.ACCEPT_ENCODING HttpHeaders.Values.GZIP); channel.write(request); System.out.println(""sent first request""); } } }); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { System.out.println(""done""); if (!close) { URI uri = new URI(""http://example.com""); HttpRequest request = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.GET uri.toASCIIString()); request.setHeader(HttpHeaders.Names.HOST uri.getHost()); request.setHeader(HttpHeaders.Names.CONNECTION HttpHeaders.Values.CLOSE); request.setHeader(HttpHeaders.Names.ACCEPT_ENCODING HttpHeaders.Values.GZIP); e.getChannel().write(request).addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture arg0) throws Exception { System.out.println(""sent second request""); } }); close = true; } else { ctx.getChannel().close(); System.out.println(""closing""); } } } In output I see only: connected sent first request done sent second request Why there is no second ""done""? You instruct the server to close the connection so that is probably what's happening (add a channelClosed() method to check). This is in fact fortunate otherwise you would've created an infinite loop (until the ops at example.com blacklists you as a DOS attack ;-) ). Thx that was a problem now it's ok changed to KEEP_ALIVE I don't want to close connection(such as doing browsers) this is just example and to do a dos attack i think i must send more then few requests in second. Added close channel after second request But you add the header `Connection: close` to your request. THat will cause either your stack or the server to close the connection after the first request."
298,A,"Netty: How to make sure Channel.close() was fired by the I/O thread I am using Netty 3.6.2 here is my pipeline factory pseudocode： private final static ThreadPoolExecutor executor = new OrderedMemoryAwareThreadPoolExecutor(8 4194304 4194304 5L TimeUnit.MINUTES); public ChannelPipeline getPipeline() throws Exception { ChannelPipeline p = pipeline(); p.addLast(""frameDecoder"" protobufFrameDecoder); p.addLast(""protobufDecoder"" protobufDecoder); p.addLast(""executor"" new ExecutionHandler(executor)); p.addLast(""handler"" handler); p.addLast(""frameEncoder"" protobufFrameEncoder); p.addLast(""protobufEncoder"" protobufEncoder); return p; } in this way the handler's messageReceived() was called in different thread pool instead of worker thread pool now I want to close channel in case some exception happened in messageReceived() but according to here: http://netty.io/wiki/thread-model.html any upstream events triggered as a side effect of the downstream event must be fired from the I/O thread. simply call ctx.getChannel().close() is not safe in exceptionCaught() I am trying to use this way to solve this issue NettyServerSocketFactory.getWorkerExecutor().execute(new Runnable() { @Override public void run() { channel.close(); } }); here is NettyServerSocketFactory code: public class NettyServerSocketFactory extends NioServerSocketChannelFactory { private static Executor bossExecutor = Executors.newCachedThreadPool(); private static Executor workerExecutor = Executors.newCachedThreadPool(); public static Executor getBossExecutor() { return bossExecutor; } public static Executor getWorkerExecutor() { return workerExecutor; } public NettyServerSocketFactory() { super(bossExecutor workerExecutor); } } but it seems not work any advice will be appreciated. Channel#close() triggers a downstream event that will ventually reach the ChannelSink where the event is ""handed over"" to the worker associated with the channel for further processing. The worker will eventually fire a channel closed event and the worker will make sure that the event is sent upstream on the IO thread. This is how it currently works maybe the document you are referring to is discussing a previous situation where the event indeed was delivered on the calling thread."
299,A,"Netty how to implement an HTTP connection limiter which sends a response (503) prior to closing channel Currently in my pipeline I have a simple handler to reject connections when my server gets overloaded:  public class RequestFilter extends SimpleChannelHandler { @Override public void channelConnected(final ChannelHandlerContext ctx final ChannelStateEvent e) throws Exception { requestLimiter(ctx e); super.channelConnected(ctx e); } } private void requestLimiter(final ChannelHandlerContext ctx final ChannelStateEvent e) { if(threshold < counter) { ctx.getChannel().close(); } } When the counter exceeds the threshold the channel is closed that all seems to work fine. Now I'd like to enhance this by first sending an HTTP 503 response prior to closing the channel. What i've tried so far is this method below instead of closing the channel immediatly I try to write a response to the channel and then handle closing it with a channelfuture listener so it's closed when the write is complete. However whats happening is I get a ton of exceptions about ""already sent a response can't send more than 1"" followed by stack overflow. protected void sendResponse(Channel channel HttpResponse response) { if (channel.isConnected()) { channel.write(response).addListener(ChannelFutureListener.CLOSE); log.trace(""response sent""); } else if (!channel.isConnected()) { log.trace(""attempted to send response but the channel was closed""); } else { log.trace(""Not sure why this would happen""); } } Any thoughts or examples I could look at? thanks Edit: stacktrace java.lang.IllegalStateException: cannot send more responses than requests at org.jboss.netty.handler.codec.http.HttpContentEncoder.writeRequested(HttpContentEncoder.java:104) at org.jboss.netty.handler.timeout.WriteTimeoutHandler.writeRequested(WriteTimeoutHandler.java:152) at org.jboss.netty.handler.stream.ChunkedWriteHandler.flush(ChunkedWriteHandler.java:262) at org.jboss.netty.handler.stream.ChunkedWriteHandler.handleDownstream(ChunkedWriteHandler.java:119) at org.jboss.netty.handler.execution.ExecutionHandler.handleDownstream(ExecutionHandler.java:165) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at com.test.RequestFilter.sendResponse(RequestFilter.java:98) Your final case is can't happen code. Post your stack trace. Added stacktrace to question Apparently it's sending multiple responses (Who'd have thunk). Can you hook sending a response to see when else it's happening? You might use wireshark to watch the transfer if you are unable to watch it programmatically I don't think it is sending multiple responses. I think that it's [trying] to send one which is one more than the number of requests which is zero because the the event is being triggered by the connect channel event and the pipeline has yet to see any http requests. I would change your code to not do this on connect but rather trigger the 503 response on the first request. If the channel is then closed adios client but if the client's first request sneaks in under the threshold then remove the bouncer from the pipeline (assuming that once a client is in they're in for good). Make sense ?"
300,A,"What are the main differences between Netty and JGroups? JGroups seems to be in existence since late 90's. Why do we need Netty when we have JGroups? Is it because JGroups is based on thread pooling while Netty is asynchronous? Is that the only difference? JGroupss goal is clustering and reliable messaging with a focus on group communication ie. sending messages to a group of nodes (one-to-many). Its mainly used to implement decentralized peer-to-peer systems. Netty's focus is (afaict) point to point messaging (one-to-one). A typical implementation would be a client-server architecture. Disclaimer: I'm the JGroups lead and don't know too much about Netty...  Netty is a general purpose network framework with which you can write ""any"" network related application. So it is much more generic then JGroups."
301,A,a board game server with using combination of tcpudp good idea? I am coding board game server using Netty. Using TCP at every part of the game. But I am having issues most of the time. Even though have posted several questions tried many configuration parameters I am still having issues (latency and un-expected disconnect issues at most) My idea is using TCP while visitors playing the game. Other than this if you are exploring rooms checking tables looking for friends etc. will use UDP instead. Can I expect performance increase ? Server: JAVA Linux Client: Adobe Flash No because in the end you will have to account for those udp messages not getting where they are going. If I know my friend is playing and when I search for friends he doesn't come up I'll just run the search over again. If you truly have too much traffic (which seems bizarre for a board game server) you can always isolate different functionality to different servers. For example one server could be dedicated to chat another to lobbies and another 3 to running games. load is not that much to be honest. 6500 concurrent users. no problem with server. but still having issues like http://stackoverflow.com/q/8735731/378737 .  On a related note. Here is a netty game server which has an as3 client in the same repo. It also support UDP but you need to use Java/C other language client not flash.
302,A,Does a single Netty worker thread manage all the handlers in a pipeline? I am new to Netty. I am trying to find out if all the handlers in a Channels's pipeline are managed by a single worker thread. In that case won't the worker thread be locked by the handlers to finish. Or is each handler handled by different available worker threads ? Thanks Sudha Each handler of a Channel is executed in the worker thread by default. So if you need todo any blocking work you need to todo it in an other Thread. How you do this depends on if you use netty 3 or netty 4. In netty 3 you would use the ExecutorHandler. In netty 4 you would specify an other EventExecutor when adding the ChannelHandler to the ChannelPipeline. Thanks for clarifying my doubt.
303,A,"Netty - buffering response on write I have an app on Netty where I'm setting tcpNoDelay to true (for both the server and ""child"" sockets). When I ""curl"" to my server with -vN (N disables the client buffer) and then slowly write data to the channel nothing propagates to the client until some buffer limit is reached and then it's pushed to the client. I should note that I'm writing back Chunked data (so the client stays connected until we close it). I have used Wireshark to make sure that I get nothing sent to the client until the buffer limit is reached and then I see a bunch of TCP packets flood to the client. Ideally this should be smooth. Strangely this doesn't happen with the instance I run on my local machine (Mac OS X Lion Java 1.6.0_31). Only presents itself on the server which is Ubuntu Java 1.6.0_20. I can't imagine the slight version mismatch from _20 to _31 is the reason. Server options being set: nioStreamBootstrap.setOption(""child.tcpNoDelay"" true); nioStreamBootstrap.setOption(""child.keepAlive"" true); nioStreamBootstrap.setOption(""tcpNoDelay"" true); Client ""curl"": curl -vN http://my.remote.server/some/path My logs show the write being made to the client channel: --- Message received from downstream --- Writing message upstream --- Message received from upstream --- Writing message downstream (note that the ""Writing message downstream"" call immediately precedes the channel.write(obj) call) So I'm not sure if it's OS-related Java-related or Netty-related. Suggestions? Appears to be an Ubuntu server issue. Can't replicate issue on CentOS or Mac OS X."
304,A,"How get file data from post request in NETTY 4? I can send this POST request with some jpg file to my server POST /formpostmultipart HTTP/1.1 Host: localhost:8080 Connection: keep-alive Content-Length: 621551 Cache-Control: max-age=0 Accept: text/htmlapplication/xhtml+xmlapplication/xml;q=0.9image/webp*/*;q=0.8 Origin: http://localhost:8080 User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/37.0.2031.2 Safari/537.36 Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryY1m4URqQ5ydALOrQ Referer: http://localhost:8080/upload Accept-Encoding: gzipdeflatesdch Accept-Language: ru-RUru;q=0.8en-US;q=0.6en;q=0.4 what must i do for get file from this request and save to disk for example? p.s. sorry for my bad english i solve this problem with HttpPostRequestDecoder. for example if (request.getMethod().equals(HttpMethod.POST)) { decoder = new HttpPostRequestDecoder(dataFactory request); decoder.setDiscardThreshold(0); if (decoder != null) { if (msg instanceof HttpContent) { HttpContent chunk = (HttpContent) msg; decoder.offer(chunk); readChunk(channelHandlerContext); if (chunk instanceof LastHttpContent) { resetPostRequestDecoder(); } } } private void readChunk(ChannelHandlerContext ctx) throws IOException { while (decoder.hasNext()) { InterfaceHttpData data = decoder.next(); if (data != null) { try { switch (data.getHttpDataType()) { case Attribute: break; case FileUpload: FileUpload fileUpload = (FileUpload) data; File file = new File(""C:\\test\\"" + fileUpload.getName); if (!file.exists()) { file.createNewFile(); } try (FileChannel inputChannel = new FileInputStream(fileUpload.getFile()).getChannel(); FileChannel outputChannel = new FileOutputStream(file).getChannel()) { outputChannel.transferFrom(inputChannel 0 inputChannel.size()); sendSimpleResponse(ctxCREATED""file name: "" +file.getAbsolutePath()); } break; } } catch (InterruptedException e) { e.printStackTrace(); } finally { data.release(); } } } } private void resetPostRequestDecoder() { request = null; decoder.destroy(); decoder = null; }"
305,A,"Why Netty uses reflection to replace members in sun.nio.ch.SelectorImpl class with array based set? While browsing through the Netty code base I came across below code block in NioEventLoop.java. SelectedSelectionKeySet selectedKeySet = new SelectedSelectionKeySet(); Class<?> selectorImplClass = Class.forName(""sun.nio.ch.SelectorImpl"" false PlatformDependent.getSystemClassLoader()); // Ensure the current selector implementation is what we can instrument. if (!selectorImplClass.isAssignableFrom(selector.getClass())) { return selector; } Field selectedKeysField = selectorImplClass.getDeclaredField(""selectedKeys""); Field publicSelectedKeysField = selectorImplClass.getDeclaredField(""publicSelectedKeys""); selectedKeysField.setAccessible(true); publicSelectedKeysField.setAccessible(true); selectedKeysField.set(selector selectedKeySet); publicSelectedKeysField.set(selector selectedKeySet); selectedKeys = selectedKeySet; Why Netty uses reflection to change a member of java library class sun.nio.ch.SelectorImpl? I see one advantage instead of using Set from java collections it uses array based Set which I believe will be faster. Is there any other specific reason for that ? That would depend on what magic if any was in the SelectedSelectionKeySet class but it's a very poor piece of practice. It was mainly done to reduce GC. Trustin did some testing here and found this more efficient."
306,A,Is it OK to perform long operations in ChannelInboundHandler.channelRead I'm using netty 4 and I'm trying to get used to their programming model. But here's a question that I haven't been able to find a satisfactory answer for in netty's documentation: Is is alright to perform long operations in ChannelInboundHandler.channelRead()? If I do so am I going to compromise the throughput of my application? Should I avoid doing that and use channelRead() only for enqueuing tasks into an Executor? It is not ok to dod anything long running. You will need todo it on another thread then the IO Thread.
307,A,"error in Using netty with jedis I'm using netty and redis (jedis client) and in each request the query method of redisdb call when i test it in Apache benchmarking with this command ab -c 10 -n 10 localhost:2080 the below error occurs.  Mar 10 2014 3:29:48 PM io.netty.channel.DefaultChannelPipeline$TailHandler exceptionCaught WARNING: An exceptionCaught() event was fired and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. java.lang.NullPointerException at redis.clients.jedis.Protocol.sendCommand(Protocol.java:39) at redis.clients.jedis.Protocol.sendCommand(Protocol.java:33) at redis.clients.jedis.Connection.sendCommand(Connection.java:80) at redis.clients.jedis.BinaryClient.append(BinaryClient.java:200) at redis.clients.jedis.Client.append(Client.java:125) at redis.clients.jedis.Jedis.append(Jedis.java:616) at com.kdgames.server.asyncdatabase.redisdb.query(redisdb.java:14) at ServerInboundHandler.channelRead0(ServerInboundHandler.java:41) at ServerInboundHandler.channelRead0(ServerInboundHandler.java:1) at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:103) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:340) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:326) at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:340) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:326) at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:340) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:326) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:155) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:340) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:326) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:116) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:494) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:461) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:378) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:350) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101) at java.lang.Thread.run(Unknown Source) and here is the code public class redisdb { Jedis jedis; public redisdb() { jedis = new Jedis(""192.168.56.101"" 6179); } public void query() { jedis.append(""foo"" ""bar""); } } Rather wild guess: in a multithreaded environment you should use a connection pool as described in Jedis documentation. The code would look like: public class redisdb { JedisPool pool; public redisdb() { pool = new JedisPool(new JedisPoolConfig() ""192.168.56.101"" 6179) } public void query() { Jedis jedis = pool.getResource(); try { jedis.append(""foo"" ""bar""); } catch (JedisConnectionException e) { // returnBrokenResource when the state of the object is unrecoverable if (null != jedis) { pool.returnBrokenResource(jedis); jedis = null; } } finally { /// ... it's important to return the Jedis instance to the pool once you've finished using it if (null != jedis) pool.returnResource(jedis); } } } And don't forget to close the connections when closing your application: pool.destroy();"
308,A,"In Netty 4 what's the difference between ctx.close and ctx.channel.close? Is there any difference? Is ctx.close just a shorter version of ctx.channel.close? Let's say we have three handlers in the pipeline and they all intercept the close() operation and calls ctx.close() in it. ChannelPipeline p = ...; p.addLast(""A"" new SomeHandler()); p.addLast(""B"" new SomeHandler()); p.addLast(""C"" new SomeHandler()); ... public class SomeHandler extends ChannelInboundHandlerAdapter { @Override public void close(ChannelHandlerContext ctx ChannelPromise promise) { ctx.close(promise); } } Channel.close() will trigger C.close() B.close() A.close() and then close the channel. ChannelPipeline.context(""C"").close() will trigger B.close() A.close() and then close the channel. ChannelPipeline.context(""B"").close() will trigger A.close() and then close the channel. ChannelPipeline.context(""A"").close() will close the channel. No handlers will be called. So when you should use Channel.close() and ChannelHandlerContext.close()? The rule of thumb is: If you are writing a ChannelHandler and wanna close the channel in the handler call ctx.close(). If you are closing the channel from outside the handler (e.g. you have a background thread which is not an I/O thread and you want to close the connection from that thread.) In general ctx.channel.close should be used? Can you give examples where ctx.close should be used? In general you can use ctx.close() when you know the ""later"" ChannelHandler's in the ChannelPipeline not care about the close event. Answer updated.  ctx.close() starts to flow through the ChannelPipeline from the point of the ChannelHandlerContext while ctx.channel().close() will start from the tail of the ChannelPipeline all the time."
309,A,JBoss Netty with JSON I would like my Ajax code to connect a server through Netty. For that purpose I need a JSON decoder and encoder in the server side Netty handler. Is there any out of the box implementation for this or should I write my own? Thanks Gil As I know there is no built in JSON decoder/encoder but it does not mean that you have to start from basic HTTP Handlers. 1) Have the HttpRequestDecoder HttpResponseEncoder in the server pipeline. 2) then implement HttpContentDecoder HttpContentEncoder abstract classes for JSON decoding & encoding here you have to implement the newContentDecoder newContentEncoder methods by providing a OneToOneEncoder/Decoder implementation for JSON. You can use Google Gson to write the OneToOneEncoder/Decoder implementation. then add HttpContentDecoder HttpContentEncoder implementations in the pipeline. for more detail you can have a look on HttpContentDecompressor HttpContentCompressor source code.
310,A,"Netty 4 And Server Chunked Responses I'm trying to migrate my server code that used to use the chunked classes to respond to some requests. Based on feedback I received on a question I asked previously I wrote to a channel a DefaultHttpResponse (with Transfer-Encoding: chunked) some content with DefaultHttpContent and lastly DefaultLastHttpContent. This is all over SSL if that matters. My pipeline is fairly basic with: if (sslFactory != null) { SSLEngine engine = sslFactory.createSSLEngine(false); engine.setUseClientMode(false); p.addLast(""ssl"" new SslHandler(engine)); } p.addLast(""decoder"" new HttpRequestDecoder(connectConfig.maxInitialLineLength() connectConfig.maxHeaderSize() connectConfig.maxChunkSize())); // Uncomment the following line if you don't want to handle HttpChunks. p.addLast(""aggregator"" new HttpObjectAggregator(1048576)); p.addLast(""encoder"" new HttpResponseEncoder()); p.addLast(""deflater"" new HttpContentCompressor()); ChannelHandler handler = new BusinessRequestHandler(...); // if enabled use the execution handler if (eventExecutor.isDefined()) { p.addLast(eventExecutor.get() ""handler"" handler); } else { p.addLast(""handler"" handler); } In any case none of this is ever sent out the wire as I confirmed with tcpdump/Wireshark. I also added a completion handler to the write and they all indicated that the write was done. If I switch to using a FullHttpResponse and skip chunking it then everything works fine and the content is written out. I then looked at HttpContentEncoder::encode and I don't see how a HttpResponse by itself will be passed through. It will if it is set to a status code of 100 but that clearly isn't correct for this use case. As far as I can tell that function will return null for my use case. What am I missing? Thanks Senthil. The link that Tustin provided below fixed some issues but other issues are still unresolved and I documented it [here](https://github.com/netty/netty/issues/1280). It's all fixed now. It's a bug in Netty 4.0.0.CR1. Fix has been pushed today: https://github.com/netty/netty/issues/1275"
311,A,"Can't POST JSON to server using Netty I'm stuck on a really really basic problem: Using HttpRequest to POST a wee bit of JSON to a server using Netty. Once the channel is connected I prepare the request like this: HttpRequest request = new DefaultHttpRequest( HttpVersion.HTTP_1_1 HttpMethod.POST postPath); request.setHeader(HttpHeaders.Names.CONTENT_TYPE ""application/json""); String json = ""{\""foo\"":\""bar\""}""; ChannelBuffer buffer = ChannelBuffers.copiedBuffer(json CharsetUtil.UTF_8); request.setContent(buffer); channel.write(request); System.out.println(""sending on channel: "" + json); The last line prints out {""foo"":""bar""} which is well-formed JSON. However a really simple echo server I wrote in Python using Flask shows the request but it has no body or json field like the body couldn't be parsed into JSON correctly. When I simply use curl to send the same data then the echo server does find and parse the JSON correctly: curl --header ""Content-Type: application/json"" -d '{""foo"":""bar""}' -X POST http://localhost:5000/post_path My pipeline in Netty is formed with: return Channels.pipeline( new HttpClientCodec() new MyUpstreamHandler(...)); Where MyUpstreamHandler extends SimpleChannelUpstreamHandler and is what attempts to send the HttpRequest after the channel connects. Again I'm at a total loss. Any help would be greatly appreciated. As Veebs said you have to set some http headers I too had same the problem and lost for hours I got it working with following code :).  import static org.jboss.netty.handler.codec.http.HttpHeaders.Names.*; ...... HttpRequest httpRequest = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.POST ""/post_path""); final ChannelBuffer content = ChannelBuffers.copiedBuffer(jsonMessage CharsetUtil.UTF_8); httpRequest.setHeader(CONTENT_TYPE ""application/json""); httpRequest.setHeader(ACCEPT ""application/json""); httpRequest.setHeader(USER_AGENT ""Netty 3.2.3.Final""); httpRequest.setHeader(HOST ""localhost:5000""); httpRequest.setHeader(CONNECTION ""keep-alive""); httpRequest.setHeader(CONTENT_LENGTH String.valueOf(content.readableBytes())); httpRequest.setContent(content); channel.write(httpRequest);  Not sure if you have http keep alive on or not but if you do you may have to send the content length in the header. This was indeed the problem. I had originally put the following: `request.setHeader(HttpHeaders.Names.CONTENT_LENGTH String.valueOf(buffer.getByteArray().length));` But the underlying `byte[]` of the buffer seems to come from a pool and is not derived from the `json` that the buffer was copied from. And so looking back it was returning `53` instead of `13`. At this point I omitted this call to `setHeader` sort of hoping that Netty would simply add it for me based on the parameter passed to `request.setContent`. As Jestan pointed out I must use `buffer.readableBytes()`."
312,A,Working with JDBC transaction in Netty message processing I have written an SMPP 3.4 messaging system using Netty 4. Once I have received a new message submission (submit_sm packet) that I am happy to accept onto the platform I write back an smpp response and then write the accepted message onto a local persistent queue (e.g. perhaps a database). Assuming JDBC as the message store for this example; durability and consistency is key and although I can't wrap both the JDBC insert and the SMPP Socket write into a transaction I do at least want to role back the JDBC insert should the smpp response channel.write operation fail. My current approach is to maintain a new thread pool that processes the JDBC insert and the SMPP response in a single thread. First I insert the message into the database and then I call channel.writeAndFlush().awaitUninterruptibly() in order to check the operation completed successfully. If the operation failed I can roll back the database transaction. Does this seem like the correct approach? I can't use a ChannelFutureListener on the ChannelFuture because I need to stay in the same thread so as not to break the transaction boundary. I presume that in my approach there has to be some communication from the IO Thread selected and the thread where I block for the result of the IO operation? All the best Jon Dispatching the received request to another thread pool to handle a JDBC transaction and to call channel.write*() from the JDBC thread is perfectly fine. One thing to keep in mind is that it is possible that the peer does not receive your response even if your write future is fulfilled. A fulfilled write future only tells you that O/S accepted your write request. The TCP/IP stack of the O/S will try its best to send the response to the peer but it will eventually fail if the connection is broken permanently. In such a case the client will probably re-attempt the request and it will lead to duplicate transaction. To avoid this kind of cases you usually have some kind of identifier for each request and the server keeps the list of recent of request IDs to reject duplicate requests. Thanks very helpful particularly the part about the write future. My pleasure. Don't forget to mark it as answered. :-)
313,A,"Netty channelRead I have started working with Netty and have a question. I am bootstrapping Netty as shown in the examples. def connect { try { bootstrap.group(group) .channel(classOf[NioSocketChannel]) .remoteAddress(new InetSocketAddress(host port)) .handler(new ChannelInitializer[SocketChannel] { override def initChannel(ch: SocketChannel) { ch.pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)) .addLast(new NettyConnectionChannelInbound) } }) val future: ChannelFuture = bootstrap.connect.sync future.channel.closeFuture.sync } finally { group.shutdownGracefully } } I have another class with the channelRead method in it class NettyConnectionChannelInbound extends ChannelInboundHandlerAdapter { override def channelRead(ctx: ChannelHandlerContext msg: Any) { println(msg) } } When I run my application val nc = new NettyConnection nc.connect println(""After connection"") It doesn't ever seem to get to the println after the connect call. Is this expected or am I doing something wrong? Does it just sit and wait for incoming messages to come in if I don't close the socket after receiving something? That is because closeFuture().sync() will block until the channel is closed. So I don't think this is what you want... Thank you. That makes sense now that you point that out. I had just taken the example given on the Netty site and didn't think about the fact that I was blocking there until the channel closed."
314,A,Netty Stream URL / InputStream I'm trying to expand on the functionality here: https://github.com/netty/netty/tree/3/src/main/java/org/jboss/netty/example/http/file By providing support to stream URLs instead of Files as the content I'd like to serve is in the classpath within my JAR. Unfortunately I can't seem to figure out a good way to stream a URL or InputStream with Jetty nor can I find any examples. Examples or reference to JavaDoc would be appreciated to help get me on the right path. Just use ChunkedWriteHandler and write an ChunkedStream that wraps the InputStream. This should work out quite all.. It works for me as long as I close the channel. If I try to comply with KeepAlive the client (a browser actually) receive the chunks but then the connection hold and the client wait forever. Simply start from HttpStaticFileServerHandler.java in example/http/file and change the ChunkedFile to a ChunkedStream to reproduce. Any clue? Sorry don't get it... can you write a test that reproduce it ? Yeah will be much more simple with code :-) I simply edited the HTTP file server in io.netty.example.http.file (form 4.0.0.CR1) to write a ChunkedStream instead of a ChunkedFile and not setting the Content-Size header. Now the browser receive the data and then waits forever. Here is the modified HttpStaticFileServerHandler.java: https://gist.github.com/eskatos/5311587 I expected it to work as is but it seems I'm missing something. I updated the gist with the diff against 4.0.0.CR1 so you can quickly see the small change that cause the issue. I finished by asking a separate question for clarity purpose: http://stackoverflow.com/questions/15829810/changing-netty-4-http-file-server-example-to-use-chunkedstream-instead-of-chunke
315,A,"SPDY client and server in java using netty Server import java.util.concurrent.atomic.AtomicReference; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelStateEvent; import org.jboss.netty.channel.Channels; import org.jboss.netty.channel.ExceptionEvent; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.SimpleChannelUpstreamHandler; import org.jboss.netty.handler.codec.spdy.DefaultSpdySynStreamFrame; public class SpdyChannelUpStreamHandler extends SimpleChannelUpstreamHandler { volatile Channel channel; final AtomicReference<Throwable> exception = new AtomicReference<Throwable>(); @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { System.out.println(""Channel In Open Stage""); channel = e.getChannel(); } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { System.out.println(""Channel In Connected Stage""); Channels.write(channel new DefaultSpdySynStreamFrame(1 1 (byte)0)); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { System.out.println(""Message Received on Server Side""); Channels.write(channel e.getMessage() e.getRemoteAddress()); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) throws Exception { if (exception.compareAndSet(null e.getCause())) { e.getChannel().close(); } } } import static org.jboss.netty.channel.Channels.pipeline; import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.handler.codec.spdy.SpdyFrameDecoder; import org.jboss.netty.handler.codec.spdy.SpdyFrameEncoder; import org.jboss.netty.handler.codec.spdy.SpdySessionHandler; public class SpdyPipeLineFactory implements ChannelPipelineFactory{ @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = pipeline(); pipeline.addLast(""decoder"" new SpdyFrameDecoder(2)); pipeline.addLast(""encoder"" new SpdyFrameEncoder(2)); //pipeline.addLast(""sessionHandler""new SpdySessionHandler(2true)); pipeline.addLast(""handler"" new SpdyChannelUpStreamHandler()); return pipeline; } import java.net.InetSocketAddress; import java.util.concurrent.Executors; import org.jboss.netty.bootstrap.ServerBootstrap; import org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory; public class StartServer { public static void main(String[] args){ ServerBootstrap bootStrapServer = new ServerBootstrap(new NioServerSocketChannelFactory(Executors.newCachedThreadPool() Executors.newCachedThreadPool())); bootStrapServer.setPipelineFactory(new SpdyPipeLineFactory()); bootStrapServer.bind(new InetSocketAddress(8443)); } } This is SPDY enabled server example that I was able to put together using netty libraries by reading at multiple places on the internet. When I run this server and Connect using SPDY client My connection is successful because I can see the messages in the function that channelOpen and channelConnected. There are couple questions that I want to ask as I have very limited understanding of SPDY protocol. I will start with the first thing that I want to do. 1 - How can server sends the messages to client  currently I do this in channelConnected method which I can see on the client side  but that gives me very limited chance to send the message and channelConnected event happens once during the Channel Setup process  is there any way to get the handle to currently all open channel on SPDY server and identify these channels so that I could select the channels on demand and use them to send the messages? Your best bet is to create a shared ChannelGroup and whenever a new channel connects add the channel to the ChannelGroup. You will need to figure out how to identify the channel you want to send to based on the channel meta-data available (such as remote address or channel ID). Then you can retrieve the channel from the ChannelGroup and write messages to it. Additional advantages of the ChannelGroup are When channels close they are automatically removed from the ChannelGroup. You can call close on the ChannelGroup to close all the contained channels. You can invoke writes on the ChannelGroup to to write a message to all the contained channels. I wrote an extended Channel wrapper so I can associate additional meta-data to a channel. Part of my protocol is that when a new channel connects I send it a WHO message and the client responds with some client-identity values which I add to the channel wrapper. I also implemented a JMX interface that exposes the channels in the group so I can see exactly what clients are connected."
316,A,"Excessive memory usage with uncontrolled clients (websocketx) When sending uncontrolled amounts of TextWebSocketFrames to a simple Netty WebSocket echo server implementation (slightly modified version of the implementation found in the examples package) without waiting for a client side sync() on the ChannelFuture the heap memory usage on the server is growing exponentially until it finally goes out of memory. Testcase: the client does not wait until the actual bytes have been written nor does it wait for the server to ""echo"" the text back to the client before writing the next text frame for (int i = 0; i < 10000000; i++) { ch.write(new TextWebSocketFrame(""Message #"" + i)); } When observing the yourkit memory profiler (15 seconds into the test with approx. 20.000 frames written) the number of BigEndianHeapChannelBuffer objects has grown excessively. BigEndianHeapChannelBuffer 284509 (objects) 9104288 (shallow size) (after ~30.000 frames sent within 10 second window) On the server side a big pile up can be observed mainly from BigEndianHeapChannelBuffers and CompositeChannelBuffers objects which are never cleaned nor garbage collected (which might not be possible as references are held). I'm guessing this has something to do with the (single) worker thread not being able to write the downstream ""echo"" response to the client channel because it's busy processing the rapidly incoming requests from the client Is there a way to prevent/throttle this (accidental denial of service) on the server side? In Netty most I/O operations are asynchronous. Therefore writing thousands of messages without waiting for the previous writes to be finished will get you an OutOfMemoryError. To avoid that I prefer having a counter variable to count the number of pending writes. For example: private final AtomicInteger pendingWrites = new AtomicInteger(); ... while (pendingWrites.get() < MAX_PENDING_WRITES) { pendingWrites.incrementAndGet(); ch.write(msg).addListener(new ChannelFutureListener() { ... pendingWrites.decrementAndGet(); if (pendingWrites.get() < MAX_PENDING_WRITES) { // resume writing here } } } Alternatively you can use ChunkedWriteHandler which essentially does the same job. Thank you for the answer. Does this mean that I should throttle the writes (downstream) on the server side instead of throttling the reads (upstream) from the client? Yes. Whenever you stream a large data I'd recommend throttling. So basically to prevent any type of denial of service from a rogue client (pumping insane amounts of small packages not according to protocol) you always need to throttle the writes (downstream). Shouldn't this be always the case (as in default behaviour from Netty)?"
317,A,How can I limit the threads netty uses for client connections Is there a way to limit how many threads netty uses for client connections (Netty is the client which connect to a remote server). I am using 1 NioEventLoopGroup which is passed into each Bootstrap. Each of those Bootstraps gets the same ChannelInitializer reference (I used to create different initializers for each Bootstrap but it seems to work fine sharing the same reference). I am connected from my Java application to many hardware devices which act as the server. I have noticed that currently up to 16 threads are used (I am on an 8 core machine from what I have read Netty uses 2 times the number of cores by default). They are named nioEventLoopGroup-2-1 to nioEventLoopGroup-2-16 from what I see in my logging. The 17th server I connect to will run on nioEventLoopGroup-2-1 again. 1) Is there a way to change this default of threads used? 2) Any idea why the group starts to count from 2? I saw in the source code that it is also possible to set it via a System property: io.netty.eventLoopThreads  If you pass 1 to the NioEventLoopGroup and share the instance between the bootstraps only one client will be used.
318,A,"Asynchronous calls in my netty Client does not get handled I have written a Netty server which sends asynchronous messages. The server is working as expected. I can telnet to the server with a couple of telnet sessions and the asynchronous messages gets written out. I have written a Netty Client but the client seems to be event driven and not asynchronous. On the server when the client connects; the server writes back to the client ""Welcome"" and the messages get handled in the client by the messageReceived event any asynchronous event does not fire any event within the SimpleChannelHandler. Question: How do I get the Netty client to pick up asynchronous message/events? At the moment it is event driven. Just to add the client is the Netty Telnet client.[http://netty.io/docs/stable/xref/org/jboss/netty/example/telnet/package-summary.html] The Server Code //---------Server code--------------- import java.net.InetSocketAddress; import java.util.concurrent.Executors; import org.jboss.netty.bootstrap.ServerBootstrap; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory; public class TestServer { private final ServerBootstrap clientServerBootstrap; private EchoServerFactory echoServerFactory; private Channel appChannel; public TestServer() { this.clientServerBootstrap = new ServerBootstrap( new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); this.clientServerBootstrap.setOption(""child.tcpNoDelay"" true); } public static void main(String[] args) { try { TestServer test = new TestServer(); test.start(); for(int i = 0; i < 100; i++) { long time = System.currentTimeMillis()+1000; String data = ""setPhase();d(112.2342""+time+"");""; System.out.println(data); test.write(data); Thread.sleep(1000); } } catch(Exception ex) { ex.printStackTrace(); } } public void start() { echoServerFactory = new EchoServerFactory(); clientServerBootstrap.setPipelineFactory(echoServerFactory); InetSocketAddress isaApp = new InetSocketAddress(""127.0.0.1"" 9090); appChannel = clientServerBootstrap.bind(isaApp); Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() { public void run() { stop(); } })); } public void write(String message) throws Exception { echoServerFactory.write(message); } public void stop() { clientServerBootstrap.releaseExternalResources(); } } //---------------Factory---------------------------- import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.handler.codec.frame.DelimiterBasedFrameDecoder; import org.jboss.netty.handler.codec.frame.Delimiters; import org.jboss.netty.handler.codec.string.StringDecoder; import org.jboss.netty.handler.codec.string.StringEncoder; public class EchoServerFactory implements ChannelPipelineFactory { EchoServerHandler handler = new EchoServerHandler(); public EchoServerHandler getHandler() { return handler; } public void write(String message) throws Exception { handler.write(message); } public ChannelPipeline getPipeline() throws Exception { // Create a default pipeline implementation. ChannelPipeline pipeline = org.jboss.netty.channel.Channels.pipeline(); // Add the text line codec combination first pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); // and then business logic. pipeline.addLast(""handler"" handler); return pipeline; } } //---------------Handler---------------------------- import java.net.InetAddress; import java.net.InetSocketAddress; import java.util.ArrayList; import java.util.Date; import java.util.List; import java.util.concurrent.atomic.AtomicLong; import java.util.logging.Level; import java.util.logging.Logger; import org.jboss.netty.buffer.ChannelBuffer; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelEvent; import org.jboss.netty.channel.ChannelFuture; import org.jboss.netty.channel.ChannelFutureListener; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelStateEvent; import org.jboss.netty.channel.ChildChannelStateEvent; import org.jboss.netty.channel.ExceptionEvent; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.SimpleChannelHandler; import org.jboss.netty.channel.SimpleChannelUpstreamHandler; import org.jboss.netty.channel.WriteCompletionEvent; import org.jboss.netty.channel.group.ChannelGroup; import org.jboss.netty.channel.group.DefaultChannelGroup; public class EchoServerHandler extends SimpleChannelHandler { private static final Logger logger = Logger.getLogger(EchoServerHandler.class.getName()); static final ChannelGroup channels = new DefaultChannelGroup(); public void write(String message) throws Exception { channels.write(message); } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { Channel channel = e.getChannel(); channels.add(channel); channel.write(""Welcome\n\n""); } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { // Unregister the channel from the global channel list // so the channel does not receive messages anymore. //channels.remove(e.getChannel()); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { // Send back the received message to the remote peer. System.out.println(""------------------------->""+e.getMessage()); Channel ch = e.getChannel(); ChannelFuture f = ch.write(e.getMessage()); /* f.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { Channel ch = future.getChannel(); System.out.println(""Completed : ""+ch.isOpen()); } });*/ } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { // Close the connection when an exception is raised. logger.log( Level.WARNING ""Unexpected exception from downstream."" e.getCause()); e.getChannel().close(); } } The Client Code //---------------- Client Code ------------------- import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.net.InetSocketAddress; import java.util.concurrent.Executors; import org.jboss.netty.bootstrap.ClientBootstrap; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelFuture; import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory; import org.jfree.ui.RefineryUtilities; /** * Simplistic telnet client. */ public class TelnetClient { private final String host; private final int port; public TelnetClient(String host int port) { this.host = host; this.port = port; } public void run() throws IOException { // Configure the client. ClientBootstrap bootstrap = new ClientBootstrap( new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); // Configure the pipeline factory. bootstrap.setPipelineFactory(new TelnetClientPipelineFactory()); bootstrap.setOption(""tcpNoDelay"" true); // Start the connection attempt. ChannelFuture future = bootstrap.connect(new InetSocketAddress(host port)); // Wait until the connection attempt succeeds or fails. Channel channel = future.awaitUninterruptibly().getChannel(); if (!future.isSuccess()) { future.getCause().printStackTrace(); bootstrap.releaseExternalResources(); return; } // Read commands from the stdin. ChannelFuture lastWriteFuture = null; BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); for (;;) { String line = in.readLine(); if (line == null) { break; } // Sends the received line to the server. lastWriteFuture = channel.write(line + ""\r\n""); // If user typed the 'bye' command wait until the server closes // the connection. if (line.toLowerCase().equals(""bye"")) { channel.getCloseFuture().awaitUninterruptibly(); break; } } // Wait until all messages are flushed before closing the channel. if (lastWriteFuture != null) { lastWriteFuture.awaitUninterruptibly(); } // Close the connection. Make sure the close operation ends because // all I/O operations are asynchronous in Netty. channel.close().awaitUninterruptibly(); // Shut down all thread pools to exit. bootstrap.releaseExternalResources(); } public static void main(String[] args) throws Exception { try { // Parse options. String host = ""127.0.0.1""; int port = 9090; new TelnetClient(host port).run(); } catch(Exception ex) { ex.printStackTrace(); } } } //---------------- Client Factory ------------------- import static org.jboss.netty.channel.Channels.*; import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.handler.codec.frame.DelimiterBasedFrameDecoder; import org.jboss.netty.handler.codec.frame.Delimiters; import org.jboss.netty.handler.codec.string.StringDecoder; import org.jboss.netty.handler.codec.string.StringEncoder; /** * Creates a newly configured {@link ChannelPipeline} for a new channel. */ public class TelnetClientPipelineFactory implements ChannelPipelineFactory { public ChannelPipeline getPipeline() throws Exception { // Create a default pipeline implementation. ChannelPipeline pipeline = pipeline(); // Add the text line codec combination first pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(1118192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); // and then business logic. pipeline.addLast(""handler"" new TelnetClientHandler2()); return pipeline; } } //----------------- Client handler ------------------- import java.util.logging.Level; import java.util.logging.Logger; import org.jboss.netty.channel.ChannelEvent; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelStateEvent; import org.jboss.netty.channel.ChildChannelStateEvent; import org.jboss.netty.channel.ExceptionEvent; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.SimpleChannelHandler; import org.jboss.netty.channel.WriteCompletionEvent; /** * Handles a client-side channel. */ public class TelnetClientHandler extends SimpleChannelHandler { private static final Logger logger = Logger.getLogger(TelnetClientHandler.class.getName()); @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { System.out.println(""messageReceived""); String message = (String) e.getMessage(); parseMessage(message); } private void parseMessage(String message) { try { System.out.println(""Messatge --> ""+message); } catch (Exception ex) { ex.printStackTrace(); } } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { System.out.println(e.getCause()); logger.log(Level.WARNING""Unexpected exception from downstream."" e.getCause()); e.getChannel().close(); } } Your question is not quite clear in Netty request and response are handled separately(the calling thread will proceed immediately after submitting the request: that is asynchronous) you want to fire some other event when a message is received or you want to write in asynchronous style with callbacks to handle the response? @Jestan I have added my server and client code. I hope this makes things a bit clearer. My problem is that my Netty client does only get the ""Welcome"" message and not the other messages ""setPhase();d(112.23421327816096855);..."" while all telnet sessions via the OS gets all the messages. My expectation is that the client will receive all incoming messages via the messageReceived event. Since you are using delimiter based frame decoder in the Netty Client App it expects the delimiter at end of each message but it looks like the server is not sending message with delimiter. String data = ""setPhase();d(112.2342""+time+"");""; System.out.println(data); test.write(data); after above messages are sent frame decoder is keep waiting even after it received many messages. It works in telnet because telnet session expects one character at a time. You have done it correctly only for the first message. channel.write(""Welcome\n\n""); Thank you very much spot on!!!"
319,A,Netty - Find Channel ID I just started working with Netty. I already have a server and im writing code for a client. In the client i set a new PipelineFactory for the ClientBootstrap object with this code  bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline(new ResponseHandler()); } } ); where ResponseHandler() is my class that extends SimpleChannelHandler. Im looking to find the Channel ID. I did  bootstrap.getPipeline().getChannel().getId(); but it throws IllelgalStateException and says i cant call getPipeline() because i have called setPipelineFactory(). What is the method to obtain the Channel ID ? Have you called connect? Netty tutorial I think after connecting you can get the channel ID on all the methods of SimpleChannelHandler with ChannelEvent.getChannel().getId()
320,A,"Netty 4 Java 7 JVM SIGSEGV crash under load I have a binary protocol implemented with Netty that is being performance tested and the JVM is crashing with the below report. I do not know how to repeat the crash but it does happen regularly and only under heavy load. I have the following dependencies: java 7.0_51-b13 netty 4.0.18_Final fedora 20 It appears that the array copy is occurring in the nioEventLoopGroup thread. The performance test I am running is sending a large number of small messages over ~50 TCP connections. Where a large number is about 1 million 200 byte messages per connection. Each message has 2 response messages sent back. This is what I am doing to create Netty: Bootstrap: m_serverBootstrap.group(m_eventLoopGroup) .channel(NioServerSocketChannel.class) .localAddress(m_config.getSmppPort()) .childAttr(InternalAttributeKeys.METRICS m_metricRegistry) .childHandler(new CustomServerChannelInitializer()); m_serverBindChannelFuture = m_serverBootstrap.bind().sync(); CustomerServerChannelInitializer protected void initChannel(SocketChannel ch) throws Exception { log.info(""initChannel(SocketChannel ch) {} {} ""chthis); ch.pipeline() .addLast(new IpFilterHandler()) .addLast(new ProtocolEncoder()) .addLast(new LengthFieldBasedFrameDecoder(4 * 1024 0 4 -4 0)) .addLast(new ProtocolDecoder()) .addLast(new WindowingHandler()) .addLast(new SequenceNumberAssignmentHandler()) .addLast(""idleState"" new IdleStateHandler(idleTime idleTime idleTime)) .addLast(""idleDisconnect"" m_idleDisconnectHandler) .addLast(""auth"" m_authHandler) .addLast(""catchall"" new CatchallHandler(false)); ch.config().setAllocator(PooledByteBufAllocator.DEFAULT); ch.config().setAutoRead(true); log.info(""finished initChannel(SocketChannel ch) {} {} ""chthis); } After initial connection the pipeline is altered again in the authHandler @Override protected void channelRead0(ChannelHandlerContext ctx CustomMessage msg) throws Exception { ResponseMessage response = auth(msgctx); ctx.pipeline().replace(""auth"" ""msghandler"" new MessageHandler()); ctx.pipeline().replace(""idleState"" ""inactivityPeriod"" new IdleStateHandler()); ctx.pipeline().addAfter(""msghandler"" ""responsehandler"" new ResponseHandler()); ctx.pipeline().addAfter(""responsehandler"" ""heartbeat"" new HeartbeatHandler()); ctx.pipeline().addAfter(""heartbeat"" ""disconnect"" new DisconnectHandler()); ctx.channel().closeFuture().addListener(new CleanupChannelFutureListener(ctx)); ctx.writeAndFlush(response); } jvm report. I have a detailed report if it helps http://pastebin.com/RV0KqPMf If the JMX threads in the detailed report are bothering you I can and have reproduced the issue without them. # # A fatal error has been detected by the Java Runtime Environment: # # SIGSEGV (0xb) at pc=0x00007ffa9eb18eaa pid=1731 tid=140710808540928 # # JRE version: Java(TM) SE Runtime Environment (7.0_51-b13) (build 1.7.0_51-b13) # Java VM: Java HotSpot(TM) 64-Bit Server VM (24.51-b03 mixed mode linux-amd64 compressed oops) # Problematic frame: # v ~StubRoutines::jbyte_disjoint_arraycopy # # Core dump written. Default location: /home/user/dir/core or core.1731 # # If you would like to submit a bug report please visit: # http://bugreport.sun.com/bugreport/crash.jsp # --------------- T H R E A D --------------- Current thread (0x00007ff9fc06f800): JavaThread ""nioEventLoopGroup-2-12"" [_thread_in_Java id=1912 stack(0x00007ff9c9b250000x00007ff9c9c26000)] siginfo:si_signo=SIGSEGV: si_errno=0 si_code=1 (SEGV_MAPERR) si_addr=0x00007ff987df7715 What is the best way to find out what is causing this SIGSEGV in the JVM? No idea. Just when I get a bug like this I always make sure I'm using the latest version. If you reported it to the netty devs it is probably the first thing they would suggest. I can reliably reproduce this now. I found that the issue was present in 4.0.18.Final and 4.0.19.Final. It was not in 4.0.20.Final and 4.0.21.Final. So the fix was likely in 4.0.20.Final. Netty 4.0.21 is out. Have you tried that on the off chance it fixes it? Using Netty 4.0.21 may have fixed it. Previously a connection would receive ~150000 messages (200bytes) and then crash the JVM. But it appears to get past that now and behave as expected. Thanks! Any idea what the fix may have been? Upgrading from Netty 4.0.18.Final to 4.0.20.Final fixed this issue. Thanks for let us know :)  This is definitely a Netty bug. Netty 4.x heavily uses Unsafe API - Oracle JDK internal API that allows raw memory access. See PlatformDependent0.java from Netty sources. The crash log tells that the problem happens inside Unsafe.copyMemory call where the target is a byte[] array in Java Heap young generation and the source points to an unmapped memory region. Most likely this is caused by an attempt to get bytes from a native buffer that has been previously released. There are no sanity checks inside Unsafe API so any misuse typically ends up with a JVM crash."
321,A,"Exception caught in RequestBodyHandler below is the code when user uploads a video from mobile application to S3 def uploadVideo = Action(parse.multipartFormData) { implicit request => try { var height = 0 var width = 0 request.body.files.map { mov => var videoName = System.currentTimeMillis() + "".mpeg"" amazonS3Client.putObject(bucketVideos videoName mov.ref.file) } val map = Map(""result"" -> ""success"") Ok(write(map)) } catch { case e: Exception => Ok(write(Map(""result"" -> ""error""))) } } the above code work fine but in case user cancel while uploading of video then error occurs  [error] play - Exception caught in RequestBodyHandler java.nio.channels.ClosedChannelException: null at org.jboss.netty.channel.socket.nio.AbstractNioWorker.cleanUpWriteBuffer(AbstractNioWorker.java:434) ~[netty.jar:na] at org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromUserCode(AbstractNioWorker.java:129) ~[netty.jar:na] at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.handleAcceptedSocket(NioServerSocketPipelineSink.java:99) ~[netty.jar:na] at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.eventSunk(NioServerSocketPipelineSink.java:36) ~[netty.jar:na] at org.jboss.netty.channel.Channels.write(Channels.java:725) ~[netty.jar:na] at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71) ~[netty.jar:na] and this doesn't go to catch block!! 1.can this is harmfull to server or not?(because it is not needed any response if error occours) 2.if yes how to handle? This is all happening in Play's internals that are handling parsing the body of the Request. In fact during the upload to your server you haven't even reached the try block yet because the file hasn't finished uploading. Only once the upload is complete do you have the TemporaryFile available. So no you can't catch this error and why would you want to? The user closed the connection. They're not even waiting for a response so why send one? Let Play handle it. This is also not a good way of handling an upload though. For small files it's passable but if someone is proxying a huge video upload through your server to S3 it's going to: Take almost twice is long to serve the response (which will cause the user to hang while you upload to S3). Block one of Play's threads for handling requests for the entire time that file is uploading to S3 and given enough of these uploads (not many at all) you will no longer be able to process requests until an upload has completed. Consider at least creating a separate ExecutionContext to use for handling uploads or even better look into having the user upload directly to S3 via a signed form which would remove the need to proxy the upload at all. i post the simmilar question for review please review it http://codereview.stackexchange.com/questions/55544/uploading-a-video-using-future-in-s3"
322,A,How to know if a channelDisconnected comes from the client or server in a Netty client We're having a couple of Netty clients with handlers which are sharable and doesn't containt any mutable state. The handler is added to a StaticChannelPipline. I would like to know if there's a way to know if a channelDisconnected is due to the server closing the connection or not to be able to notify that case by invoking a callback that the client has specified. You could override SimpleChannelDownstreamHandler.closeRequested() to get notified when your application calls Channel.close(). However even if you called Channel.close() there is always a race condition where a remote peer attempted to close the connection at the same time. Therefore it's not a good idea to determine your application's behavior depending 'which side` closed the connection. Alternatively you could define a good-bye message in your protocol and require a client to send the good-bye message before disconnecting. Then you know better if the client terminated its connection as it intended or not. Thanks. I wanted to know that to be able to invoke a client listener callback when the server closed the connection. I'll settle with having a isConnected() method that the user of the client can use instead.
323,A,"How does the Netty threading model work in the case of many client connections? I intend to use Netty in an upcoming project. This project will act as both client and server. Especially it will establish and maintain many connections to various servers while at the same time serving its own clients. Now the documentation for NioServerSocketChannelFactory fairly specifies the threading model for the server side of things fairly well - each bound listen port will require a dedicated boss thread throughout the process while connected clients will be handled in a non-blocking fashion on worker threads. Specifically one worker thread will be able to handle multiple connected clients. However the documentation for NioClientSocketChannelFactory is less specific. This also seems to utilize both boss and worker threads. However the documentation states: One NioClientSocketChannelFactory has one boss thread. It makes a connection attempt on request. Once a connection attempt succeeds the boss thread passes the connected Channel to one of the worker threads that the NioClientSocketChannelFactory manages. Worker threads seem to function in the same way as for the server case tho. My question is does this mean that there will be one dedicated boss thread for each connection from my program to an external server? How will this scale if I establish hundreds or thousands of such connections? As a side note. Are there any adverse side effects for re-using a single Executor (cached thread pool) as both the bossExecutor and workerExecutor for a ChannelFactory? What about also re-using between different client and/or server ChannelFactory instances? This is somewhat discussed here but I do not find those answers specific enough. Could anyone elaborate on this? Since NioClientSocketChannelFactory and OioClientSocketChannelFactory are easily replaceable with each other you may just pick any of them right now. After you will be ready to do some performance testing you may switch to another and see if it will give better or worse performance. For very simple case I have done this here: https://gist.github.com/1120694 Note: They are replaceable but behave a little differently in case of not proper usage - I have a comment about it in the gist mentioned above. @IvanSopov I never really considered using the _Oio_ versions of the ChannelFactories since I know that they use a dedicated thread per connection and I do not feel comfortable having the thread count being directly proportional to the connection count. My worry was that _NioClientSocketChannelFactory_ would also do this (for clients not for servers) but this has now been disproven. This is not a real answer to you q regarding how the Netty client thread model works. But you can use the same NioClientSocketChannelFactory to create single ClientBootstrap with multiple ChannelPipelineFactorys  and in turn make n number of connections. Take a look at the example below. public static void main(String[] args) { String host = ""localhost""; int port = 8090; ChannelFactory factory = new NioClientSocketChannelFactory(Executors .newCachedThreadPool() Executors.newCachedThreadPool()); MyHandler handler1 = new MyHandler(); PipelineFactory factory1 = new PipelineFactory(handler1); AnotherHandler handler2 = new AnotherHandler(); PipelineFactory factory2 = new PipelineFactory(handler2); ClientBootstrap bootstrap = new ClientBootstrap(factory); // At client side option is tcpNoDelay and at server child.tcpNoDelay bootstrap.setOption(""tcpNoDelay"" true); bootstrap.setOption(""keepAlive"" true); for (int i = 1; i<=50;i++){ if(i%2==0){ bootstrap.setPipelineFactory(factory1); }else{ bootstrap.setPipelineFactory(factory2); } ChannelFuture future = bootstrap.connect(new InetSocketAddress(host port)); future.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { future.getChannel().write(""SUCCESS""); } }); } } It also shows how different pipeline factories can be set for different connections so based on the connection you make you can tweak your encoders/decoders in the channel pipeline. I ran it in eclipse debug it does NOT create 50 threads. Yes that is a good point. I knew that you could do this for the server version already but I did not consider it for the client version. However will it not still consume a dedicated thread from the _bossExecutor_ for each ClientBootstrap-based connection I createfrom it just like it does with the ServerBootstrap instances I bind on the server side? Or did I misunderstand how the NioClientSocketChannelFactory works? You can actually do this one instance of client bootstrap also. See the updated code. Thank you for confirming that for me. I would still be very much interested in understanding a bit more about what the boss threads do in the client connection case but at least now my fears about there being a one-to-one relationship have been discarded. The netty community nabble is quite active you could ask it there. Trustin normally answers these q himself. http://www.jboss.org/netty/community  I am not sure your question has been answer. Here's my answer: there's a single Boss thread that is managing simultaneously all the pending CONNECTs in your app. It uses nio to process all the current connects in a single (Boss) thread and then hands each successfully connected channel off to one of the workers.  Your question mainly concerns performance. Single threads scale very well on the client. Oh and nabble has been closed. You can still browse the archive there."
324,A,What im i missing to be able to import io.netty.handler.ssl.util.* if I already added the maven dependency? I have a small Netty server and im trying to follow the chat example. I'm using maven and already added the dependency as follows:  <dependency> <groupId>io.netty</groupId> <artifactId>netty-all</artifactId> <version>5.0.0.Alpha1</version> </dependency> Now when I try to import SelfSignedCertificate or any other class from io.netty.handler.ssl.util. Eclipse complains because it's not in the .jar file that was added by that dependency. Any hint on what should i include? Thanks! Version 5.0.0.Alpha1 is actually a pretty old version (December 22 2013). According to The Central Repository the latest version of io.netty is 4.0.19.Final released on April 30 2014. However if you look at the pom file for the chat example program you can see that it's importing version 5.0.0.Alpha2-SNAPSHOT of all the netty code. A little further research shows that the API docs for 5.0.0.Alpha2-SNAPSHOT don't include that package but if you go out to github and look at the handler code you can see that the util package was added 24 days ago and the example you linked shows as only 18 days old. I think you're going to either have to wait for that package to be merged into a release or go download and build 5.0.0.Alpha2-SNAPSHOT yourself and install it locally. You still won't be able to compile anything depending on io.netty.handler.ssl.util using 4.x.x. That package only exists in some SNAPSHOT code on github it hasn't been released anywhere yet. I did research that package and it doesn't seem that it will be ever available. It looks that it is some util for testing that won't be exported. I'll try to build it but i think i'll be better with just falling back to 4.x.x right?
325,A,"Netty 4 - in-vm ephemeral channels I'm looking to migrate from our current Netty 3.x to the new Netty 4.x however I don't see an equivalent to the 3.x's (org.jboss.netty.channel.local.LocalAddress) ephemeral addresses. There is an equivalent class in the new package structure however it looks like it is used for a different purpose not to mention a package-private constructor. Does anyone know how I can migrate 3.x ephemeral address to 4.x? There doesn't seem to be anything in the migration documentation either. http://netty.io/wiki/new-and-noteworthy.html Client connection:  int port = 10000; ClientBootstrap clientBootstrap = new ClientBootstrap(); clientBootstrap.connect(new LocalAddress(port)); Server connection:  int port = 10000; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.bind(new LocalAddress(port)); Thanks Apologies have updated the question now Can you show me the code you want to ""migrate"" ? It should be all in the io.netty.channel.local package Apologies. I didn't realise that the LocalAddress constructor had changed from a LocalAddress(int) to LocalAddress(String). So in Netty 4.x it is now int port = 10000; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.bind(new LocalAddress(Integer.toString(port)));"
326,A,"ClassNotFoundException for a type that is available to the OSGi runtime ( io.netty.common ) the following seemingly trivial issue has been driving me mad for the last day and a half: - the bundle ""netty-worker-service"" exports a simple interface that wraps around a type provided ( exported ) by io.netty.transport package com.github.andlaz.netty.worker.service.api; import io.netty.channel.nio.NioEventLoopGroup; public interface NettyWorkerService { public NioEventLoopGroup getWorkerGroup(); } it also implements this interface and declares it as a service: package com.github.andlaz.netty.worker.service.impl; import io.netty.channel.nio.NioEventLoopGroup; import aQute.bnd.annotation.component.Component; import com.github.andlaz.netty.worker.service.api.NettyWorkerService; @Component(immediate=true) public class NettyWorkerServiceImpl implements NettyWorkerService { private final NioEventLoopGroup workerGroup = new NioEventLoopGroup(); @Override public NioEventLoopGroup getWorkerGroup() { return workerGroup; } } bnd creates the following component xml: <component name=""com.github.andlaz.netty.worker.service.impl.NettyWorkerServiceImpl"" immediate=""true""> <implementation class=""com.github.andlaz.netty.worker.service.impl.NettyWorkerServiceImpl""/> <service> <provide interface=""com.github.andlaz.netty.worker.service.api.NettyWorkerService""/> </service> </component> and manifest.mf: Manifest-Version: 1.0 Bnd-LastModified: 1397806521471 Bundle-ManifestVersion: 2 Bundle-Name: com.github.andlaz.netty.worker.service Bundle-SymbolicName: netty-worker-service Bundle-Version: 1.0.0 Created-By: 1.7.0_45 (Oracle Corporation) Export-Package: com.github.andlaz.netty.worker.service.api;version=""1.0"" ;uses:=""io.netty.channel.nio"" Import-Package: com.github.andlaz.netty.worker.service.api;version=""[1.0 2)""io.netty.channel.nio;version=""[4.05)"" Private-Package: com.github.andlaz.netty.worker.service.impl Service-Component: OSGI-INF/com.github.andlaz.netty.worker.service.impl. NettyWorkerServiceImpl.xml Tool: Bnd-2.2.0.20130927-173417 Not too complex stuff right? However with the following bndrun configuration: -runfw: org.apache.felix.framework;version='[45)' -runee: JavaSE-1.7 -runsystemcapabilities: ${native_capability} -resolve.effective: active -runbundles: io.netty.buffer;version='[4.0.184.0.19)'\ io.netty.common;version='[4.0.154.0.16)'\ io.netty.transport;version='[4.0.154.0.16)'\ netty-worker-service;version=latest\ org.apache.felix.configadmin;version='[1.6.01.6.1)'\ org.apache.felix.gogo.command;version='[0.12.00.12.1)'\ org.apache.felix.gogo.runtime;version='[0.10.00.10.1)'\ org.apache.felix.gogo.shell;version='[0.10.00.10.1)'\ org.apache.felix.log;version='[1.0.11.0.2)'\ org.apache.felix.scr;version='[1.8.21.8.3)'\ osgi.enterprise;version='[4.2.04.2.1)' -runrequires: osgi.identity;filter:='(osgi.identity=org.apache.felix.gogo.shell)'\ osgi.identity;filter:='(osgi.identity=org.apache.felix.gogo.command)'\ osgi.identity;filter:='(&(osgi.identity=netty-worker-service)(version>=1.0.0))'\ osgi.identity;filter:='(&(osgi.identity=org.apache.felix.log)(version>=1.0.1))' while everything resolves correctly i'm seeing the following in logs.. 014.04.18 09:35:31 INFO - Bundle: org.apache.felix.framework - [java.lang.Object aQute.launcher.Launcher] - ServiceEvent REGISTERED 2014.04.18 09:35:31 INFO - Bundle: osgi.enterprise - BundleEvent STARTED 2014.04.18 09:35:31 INFO - Bundle: org.apache.felix.scr - BundleEvent STARTED 2014.04.18 09:35:31 INFO - Bundle: org.apache.felix.scr - [org.apache.felix.scr.impl.ScrGogoCommand] - ServiceEvent REGISTERED 2014.04.18 09:35:31 ERROR - Bundle: netty-worker-service - [com.github.andlaz.netty.worker.service.impl.NettyWorkerServiceImpl(0)] Failed creating the component instance; see log for reason 2014.04.18 09:35:31 ERROR - Bundle: netty-worker-service - [com.github.andlaz.netty.worker.service.impl.NettyWorkerServiceImpl(0)] Error during instantiation of the implementation object - org.apache.felix.log.LogException: java.lang.NoClassDefFoundError: io/netty/util/concurrent/EventExecutorGroup at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:800) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.findClass(BundleWiringImpl.java:2279) at org.apache.felix.framework.BundleWiringImpl.findClassOrResourceByDelegation(BundleWiringImpl.java:1501) at org.apache.felix.framework.BundleWiringImpl.access$400(BundleWiringImpl.java:75) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.loadClass(BundleWiringImpl.java:1955) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:800) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.findClass(BundleWiringImpl.java:2279) at org.apache.felix.framework.BundleWiringImpl.findClassOrResourceByDelegation(BundleWiringImpl.java:1501) at org.apache.felix.framework.BundleWiringImpl.access$400(BundleWiringImpl.java:75) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.loadClass(BundleWiringImpl.java:1955) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:800) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.findClass(BundleWiringImpl.java:2279) at org.apache.felix.framework.BundleWiringImpl.findClassOrResourceByDelegation(BundleWiringImpl.java:1501) at org.apache.felix.framework.BundleWiringImpl.access$400(BundleWiringImpl.java:75) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.loadClass(BundleWiringImpl.java:1955) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at org.apache.felix.framework.BundleWiringImpl.getClassByDelegation(BundleWiringImpl.java:1374) at org.apache.felix.framework.BundleWiringImpl.searchImports(BundleWiringImpl.java:1553) at org.apache.felix.framework.BundleWiringImpl.findClassOrResourceByDelegation(BundleWiringImpl.java:1484) at org.apache.felix.framework.BundleWiringImpl.access$400(BundleWiringImpl.java:75) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.loadClass(BundleWiringImpl.java:1955) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at com.github.andlaz.netty.worker.service.impl.NettyWorkerServiceImpl.<init>(NettyWorkerServiceImpl.java:11) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at java.lang.Class.newInstance(Class.java:374) at org.apache.felix.scr.impl.manager.SingleComponentManager.createImplementationObject(SingleComponentManager.java:253) at org.apache.felix.scr.impl.manager.SingleComponentManager.createComponent(SingleComponentManager.java:127) at org.apache.felix.scr.impl.manager.SingleComponentManager.getService(SingleComponentManager.java:871) at org.apache.felix.scr.impl.manager.SingleComponentManager.getServiceInternal(SingleComponentManager.java:838) at org.apache.felix.scr.impl.manager.AbstractComponentManager.activateInternal(AbstractComponentManager.java:850) at org.apache.felix.scr.impl.manager.AbstractComponentManager.enable(AbstractComponentManager.java:419) at org.apache.felix.scr.impl.config.ConfigurableComponentHolder.enableComponents(ConfigurableComponentHolder.java:376) at org.apache.felix.scr.impl.BundleComponentActivator.initialize(BundleComponentActivator.java:172) at org.apache.felix.scr.impl.BundleComponentActivator.<init>(BundleComponentActivator.java:120) at org.apache.felix.scr.impl.Activator.loadComponents(Activator.java:258) at org.apache.felix.scr.impl.Activator.access$000(Activator.java:45) at org.apache.felix.scr.impl.Activator$ScrExtension.start(Activator.java:185) at org.apache.felix.utils.extender.AbstractExtender.createExtension(AbstractExtender.java:259) at org.apache.felix.utils.extender.AbstractExtender.modifiedBundle(AbstractExtender.java:232) at org.apache.felix.utils.extender.AbstractExtender.addingBundle(AbstractExtender.java:192) at org.osgi.util.tracker.BundleTracker$Tracked.customizerAdding(BundleTracker.java:467) at org.osgi.util.tracker.BundleTracker$Tracked.customizerAdding(BundleTracker.java:414) at org.osgi.util.tracker.AbstractTracked.trackAdding(AbstractTracked.java:256) at org.osgi.util.tracker.AbstractTracked.trackInitial(AbstractTracked.java:183) at org.osgi.util.tracker.BundleTracker.open(BundleTracker.java:156) at org.apache.felix.utils.extender.AbstractExtender.startTracking(AbstractExtender.java:150) at org.apache.felix.utils.extender.AbstractExtender.doStart(AbstractExtender.java:142) at org.apache.felix.scr.impl.Activator.doStart(Activator.java:117) at org.apache.felix.utils.extender.AbstractExtender.start(AbstractExtender.java:114) at org.apache.felix.scr.impl.Activator.start(Activator.java:92) at org.apache.felix.framework.util.SecureAction.startActivator(SecureAction.java:645) at org.apache.felix.framework.Felix.activateBundle(Felix.java:2146) at org.apache.felix.framework.Felix.startBundle(Felix.java:2064) at org.apache.felix.framework.BundleImpl.start(BundleImpl.java:955) at aQute.launcher.Launcher.update(Launcher.java:378) at aQute.launcher.Launcher.activate(Launcher.java:303) at aQute.launcher.Launcher.run(Launcher.java:193) at aQute.launcher.Launcher.main(Launcher.java:89) Caused by: java.lang.ClassNotFoundException: io.netty.util.concurrent.EventExecutorGroup not found by io.netty.common [2] at org.apache.felix.framework.BundleWiringImpl.findClassOrResourceByDelegation(BundleWiringImpl.java:1532) at org.apache.felix.framework.BundleWiringImpl.access$400(BundleWiringImpl.java:75) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.loadClass(BundleWiringImpl.java:1955) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) at org.apache.felix.framework.BundleWiringImpl.getClassByDelegation(BundleWiringImpl.java:1374) at org.apache.felix.framework.BundleWiringImpl.searchImports(BundleWiringImpl.java:1553) at org.apache.felix.framework.BundleWiringImpl.findClassOrResourceByDelegation(BundleWiringImpl.java:1484) at org.apache.felix.framework.BundleWiringImpl.access$400(BundleWiringImpl.java:75) at org.apache.felix.framework.BundleWiringImpl$BundleClassLoader.loadClass(BundleWiringImpl.java:1955) at java.lang.ClassLoader.loadClass(ClassLoader.java:358) ... 66 more 2014.04.18 09:35:31 INFO - Bundle: netty-worker-service - [com.github.andlaz.netty.worker.service.api.NettyWorkerService] - ServiceEvent REGISTERED 2014.04.18 09:35:31 INFO - Bundle: org.apache.felix.scr - [org.osgi.service.cm.ManagedService] - ServiceEvent REGISTERED 2014.04.18 09:35:31 INFO - Bundle: org.apache.felix.scr - [org.apache.felix.scr.ScrService] - ServiceEvent REGISTERED 2014.04.18 09:35:31 INFO - Bundle: org.apache.felix.scr - [org.osgi.service.cm.ConfigurationListener] - ServiceEvent REGISTERED 2014.04.18 09:35:31 INFO - Bundle: org.apache.felix.log - BundleEvent STARTED 2014.04.18 09:35:31 INFO - Bundle: org.apache.felix.log - [org.osgi.service.log.LogReaderService] - ServiceEvent REGISTERED 2014.04.18 09:35:31 INFO - Bundle: org.apache.felix.log - [org.osgi.service.log.LogService] - ServiceEvent REGISTERED g! tl;dr : io.netty.util.concurrent.EventExecutorGroup is nowhere to be found. Caused by: java.lang.ClassNotFoundException: io.netty.util.concurrent.EventExecutorGroup not found by io.netty.common [2] i verified the following: - io.netty.transport correctly imports this type from io.netty.common - io.netty.common contains and exports this type i dont know how to proceed with debugging this. Any pointers are greatly appreciated! project source is available at https://github.com/andlaz/netty-worker-service ( nb: i just noticed a mixing of minor versions of netty packages in runbundles setting all versions to [4.0.154.0.16) made no difference - however : )- with netty 4.0.18 i can no longer reproduce this - everything works flawlessly. -runbundles: io.netty.buffer;version='[4.0.185)'\ io.netty.common;version='[4.0.185)'\ io.netty.transport;version='[4.0.185)'\ i'll have to check changes between .15 and .18 but the update seemed to have fixed whatever was causing this. I finally figured this out. A bit of backstory: i use Nexus to create an .m2 proxy repository of Maven Central this gives me the safety of my dependencies not vanishing in to thin air ( not that central has been doing that ). On top of this however i have an OBR proxy ( proxy of a proxy :-) ) that filters out Bundles from whatever is cached in my proxy of Central and indexes bundles in a repository.xml Works flawlessly - i add <type>bundle</type> dependencies in my poms that are fetched through my Central proxy; as soon as the proxy downloads the artifacts the OBR repository.xml is updated and the packages in the bundle become resolve-able through OBR. But then Netty happened. Their -sources.jar has complete Bundle headers matching that of their actual bundles When this makes its way in to an OSGI framework it is resolved correctly all headers ( names versions exports imports) are matching the actual bundle so there is no way for you to tell that you loaded a bundle that is exporting .java files So... Netty 4.0.15 forgot to include the class in their jar?? Wow... Nope it is there.."
327,A,Two way SSL authentication in Netty I'm working on a Server and Client based app which require two way SSL authentication. (Client authenticates server and Server authenticate client both using SSL Certificates.) I'm quite new to Netty and have few doubts regarding this. Is two way authentication possible using Netty? Can it be simply achievable by adding another SslHandler to the pipelinefactories of both server and client? If the above is true how can I grab the required SslHandler at the ChannelConnected() method to do the SslHandshake? And Is it possible to invoke the second handshake at the ChannelConected() method by calling the pipeline back again? Are there any examples I could refer to regarding this? I really appreciate any help regarding this answers or a push in right direction. Thanks in advanced. Two way authentication requires that both server and client have certificates that the other trusts. The client needs to generate a private key store it in his keystore and get it signed by somebody that the server's truststore trusts. It isn't just a matter of what code you write.  Is two way authentication possible using Netty? Yes Can it be simply achievable by adding another SslHandler to the pipelinefactories of both server and client? Yes If the above is true how can I grab the required SslHandler at the ChannelConnected() method to do the SslHandshake? You need the setup the keystore and the truststore correctly when creating your SSLContext. And Is it possible to invoke the second handshake at the ChannelConected() method by calling the pipeline back again? From memory client and server authentication is done in the 1st handshake. On the client install the client's private key in the keystore and the server's public key in the truststore. On the server install the server's private key in the keystore and the client's public key in the truststore. Are there any examples I could refer to regarding this? Here's an example I did for websockets. It only shows you how to setup the server keystore. You will have to add a truststore as the 2nd parameter of serverContext.init(kmf.getKeyManagers() null null); Here's a similar example in Scala with trust store setup. Here's a good java guide on how to setup SSLContext. Hope this helps. Thanks for that. You're not closing the trust store's input stream in your scala example. In addition it's preferable to use `Key/TrustManagerFactory.getDefaultAlgorithm()` instead of forcing `SunX509` which isn't the JSSE default for the TMF and which wouldn't work with a non Sun/Oracle-based JRE (e.g. IBM).  SSL is a presentation layer protocol and the SSL handshake happens right after the socket connection is established and the before the application layer gets a usable socket connection. No matter what application you are using if you have the SSL protocol layer in place then you can work over SSL. Two way authentication is just a matter of configuration as mentioned by @EJP above. If both the parties can establish and validate each other trust chain then the handshake succeeds. Refer the netty configuration manual for configuring SSL truststores. The SSL handshake doesn't necessarily happen straight after the connection is established it can happen after some plain text communication (e.g. with `STARTTLS`-like protocols or HTTP proxy `CONNECT`) or after re-negotiation (typically to get a client-cert if it isn't requested in the first handshake). @Bruno but isnt the plain text communication part of the SSL session establishment process? Not really it's usually normal application protocol before the handshake really starts (via `Client Hello`). Often it happens after at most of couple of application request/resp but it could happen after a longer exchange in principle.
328,A,"Handling Http status code 302 Moved Temporarily in Netty I am getting 302 status code for the http request I am making to my URL.. I want it to be handled by my netty code.. My client code :  public static void main(String[] args) throws Exception { URI uri = new URI(""http://myurl.mydomain.com/v1/v2?param1=value1&param2=value2""); String host = uri.getHost(); int port = 80; // Configure the client. EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .handler(new NettyClientInitializer()); // Make the connection attempt. Channel ch = b.connect(host port).sync().channel(); // Prepare the HTTP request. HttpRequest request = new DefaultHttpRequest( HttpVersion.HTTP_1_1 HttpMethod.GET uri.toString()); request.headers().set(HttpHeaders.Names.HOST host); request.headers().set(HttpHeaders.Names.CONNECTION HttpHeaders.Values.KEEP_ALIVE); request.headers().set(HttpHeaders.Names.CACHE_CONTROL HttpHeaders.Values.NO_CACHE); /*// Set some example cookies. request.headers().set( HttpHeaders.Names.COOKIE ClientCookieEncoder.encode( new DefaultCookie(""my-cookie"" ""foo"") new DefaultCookie(""another-cookie"" ""bar""))); */ // Send the HTTP request. ch.writeAndFlush(request); // Wait for the server to close the connection. ch.closeFuture().sync(); } finally { // Shut down executor threads to exit. group.shutdownGracefully(); } } My handler code : public class NettyClientHandler extends SimpleChannelInboundHandler<HttpObject> { @Override public void channelRead0(ChannelHandlerContext ctx HttpObject msg) throws Exception { if (msg instanceof HttpResponse) { HttpResponse response = (HttpResponse) msg; System.out.println(""STATUS: "" + response.getStatus()); System.out.println(""VERSION: "" + response.getProtocolVersion()); System.out.println(); if (!response.headers().isEmpty()) { for (String name: response.headers().names()) { for (String value: response.headers().getAll(name)) { System.out.println(""HEADER: "" + name + "" = "" + value); } } System.out.println(); } if (HttpHeaders.isTransferEncodingChunked(response)) { System.out.println(""CHUNKED CONTENT {""); } else { System.out.println(""CONTENT {""); } } if (msg instanceof HttpContent) { HttpContent content = (HttpContent) msg; System.out.print(content.content().toString(CharsetUtil.UTF_8)); System.out.flush(); if (content instanceof LastHttpContent) { System.out.println(""} END OF CONTENT""); } } } @Override public void exceptionCaught( ChannelHandlerContext ctx Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } } My initializer code : public class NettyClientInitializer extends ChannelInitializer<SocketChannel> { @Override public void initChannel(SocketChannel ch) throws Exception { // Create a default pipeline implementation. ChannelPipeline p = ch.pipeline(); p.addLast(""log"" new LoggingHandler(LogLevel.INFO)); // Enable HTTPS if necessary. /* if (ssl) { SSLEngine engine = SecureChatSslContextFactory.getClientContext().createSSLEngine(); engine.setUseClientMode(true); p.addLast(""ssl"" new SslHandler(engine)); } */ p.addLast(""codec"" new HttpClientCodec()); // Remove the following line if you don't want automatic content decompression. // p.addLast(""inflater"" new HttpContentDecompressor()); // Uncomment the following line if you don't want to handle HttpChunks. p.addLast(""aggregator"" new HttpObjectAggregator(1048576)); p.addLast(""handler"" new NettyClientHandler()); } } I referred to this link with similar problem : redirect - handling http 302 moved temporarily using netty but the code in this using 3.x version of the library and also there is no answer to this question as of now.. I am using Netty 4.0.12 library.. Please tell me how to handle this using Netty You can modify your NettyClientHandler to check for 302 Redirects and open a new connection to handle the HTML content of the redirect. Changes made to NettyClientHandler: //We know this is a redirect... if(response.getStatus().code() == HttpResponseStatus.FOUND.code()){//When its a 302... if(response.headers().names().contains(""Location"")) { System.out.println(""We have a redirect...""); //Now we will do the process over to get the actual content... Main.main(new String[]{response.headers().get(""Location"")}); } } Changes made to main() as an example to handle the content of the redirect: String urlPlace = ""http://initial.com""; if(args != null && args.length > 0) { urlPlace = args[0]; } URI uri = new URI(urlPlace); String host = uri.getHost(); int port = uri.getPort(); if(port == -1) { port = 80; } When we get a HTTP Status code 302 it is the ""servers"" responsibility to set the Location header for the new URL location in order for the client to handle appropriately. See Wikipedia 302 can you please tell me in the same code how can I close the connection instantly as soon as I receive the response? because right now it takes around 5 minutes to completely close the connection. the connection does gets closed immediately but it unable to read the response.. it displays it as null // Send the HTTP request. ch.writeAndFlush(request).addListener(ChannelFutureListener.CLOSE);"
329,A,"Sending and receiving JSON I am using Apache HttpComponets to post data like this to Netty. I use Gson for working JSON. Request.Post(""http://localhost:9090/print"").bodyString(getJSon() ContentType.APPLICATION_JSON) This netty code does not seem to receive the JSON response. I am sure that my code is wrong. What could be the error here ? @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { logger.info( ""channelRead"" + msg ); if( msg instanceof HttpRequest ){ this.request = ( HttpRequest ) msg; logger.info( ""["" + request.getUri() + ""]""); } if( msg instanceof HttpContent ){ HttpContent content = (HttpContent)msg; ByteBuf buf = content.content(); logger.info( ""["" + buf.toString(CharsetUtil.UTF_8) + ""]""); if (msg instanceof LastHttpContent) { LastHttpContent trailer = (LastHttpContent) msg; writeResponse( trailer ctx); } } } private boolean writeResponse(HttpObject currentObj ChannelHandlerContext ctx) { logger.info( getJSon() ); ByteBuf response = Unpooled.copiedBuffer( getJSon() CharsetUtil.UTF_8); ctx.write( response ); /* Where is 'isKeepAlive' method in the API ? */ //boolean keepAlive = isKeepAlive(request); //keepAlive; return false; } What channel pipeline are you using? SimpleChannelInboundHandler Is this what you are asking ? This is not enough to process http requests. You need to add a handler to extract HttpRequest from ByteBuf. You can take a look at the Netty http examples. I have added http decoders and encoders. Shouldn't be asking simple questions like this :-)  You need to call ctx.writeAndFlush(...) to actual flush it out to the socket. `((ByteBuf) msg ).toString(io.netty.util.CharsetUtil.US_ASCII)` INFO nioEventLoopGroup-3-1 com.remote.printer.PrintResponseHandler - POST /print HTTP/1.1 Content-Length: 4 Content-Type: application/json; charset=UTF-8 Host: localhost:9090 Connection: Keep-Alive User-Agent: Apache-HttpClient/4.3 (java 1.5) Accept-Encoding: gzipdeflate Actually I couldn't receive the JSON and print it. What is the type of 'Object' ? Seems that both 'instanceof' checks fail."
330,A,"Netty 4 not work in more than 4 channels i have some netty-server which i use for uploading files on amazon s3.i try do some test with jmeter and i get strange trouble: my server get just 4-files and start uploading them. other files handle after one of those 4files complete uploading. i thing that netty must work with many threads not 4.sorry for my english i need help and hope for your advices. there is my handler  protected void channelRead0(ChannelHandlerContext channelHandlerContext HttpObject msg) throws Exception { if (msg instanceof HttpRequest) { System.out.println(""request""); request = (HttpRequest) msg; reqURI = request.getUri(); QueryStringDecoder queryStringDecoder = new QueryStringDecoder(reqURI); switch (queryStringDecoder.path()) { case (""/getfile""): sendSimpleResponse(channelHandlerContext OK ""getfile""); break; case (""/upload""): showUploadForm(channelHandlerContext); break; case (""/formpostmultipart""): if (request.getMethod().equals(HttpMethod.POST)) { decoder = new HttpPostRequestDecoder(dataFactory request); decoder.setDiscardThreshold(0); } else { sendSimpleResponse(channelHandlerContext BAD_REQUEST """"); } break; default: sendSimpleResponse(channelHandlerContext NOT_FOUND """"); } } if (decoder != null) { if (msg instanceof HttpContent) { HttpContent chunk = (HttpContent) msg; decoder.offer(chunk); readChunk(channelHandlerContext); if (chunk instanceof LastHttpContent) { resetPostRequestDecoder(); } } } } private void readChunk(ChannelHandlerContext ctx) throws IOException { while (decoder.hasNext()) { InterfaceHttpData data = decoder.next(); if (data != null) { try { switch (data.getHttpDataType()) { case Attribute: break; case FileUpload: FileUpload fileUpload = (FileUpload) data; System.out.println(""send file call""); logger.info(""start upload""); AWSfunctions aws = new AWSfunctions(); aws.sendFile(fileUpload); break; } } finally { data.release(); } } } } and this class for work with amasons3. (you can see that i try give more connections for clientbut this not work too) public class AWSfunctions { AmazonS3 connection; AWSfunctions() { Config conf; String AccessKeyId; String SecretKey; AWSCredentials credentials; ClientConfiguration clientConfiguration; conf = ConfigFactory.load(); AccessKeyId = conf.getString(""AWSCredentials.AWSAccessKeyId""); SecretKey = conf.getString(""AWSCredentials.AWSSecretKey""); credentials = new BasicAWSCredentials(AccessKeyId SecretKey); clientConfiguration = new ClientConfiguration(); clientConfiguration.setProtocol(Protocol.HTTP); clientConfiguration.setMaxConnections(200); System.out.println(clientConfiguration.getMaxConnections()); connection = new AmazonS3Client(credentials clientConfiguration); } public void sendFile(FileUpload fileUpload) throws IOException { Random rnd = new Random(); File file; file = fileUpload.getFile(); System.out.println(""upload started""); connection.putObject(new PutObjectRequest(""test-for-est"" String.valueOf(rnd.nextInt()) file)); System.out.println(""Upload completed""); }} oh it very simple. i did some change in server class... public void run() throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ServerInitializer()); ChannelFuture ch = b.bind(port).sync(); ch.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } change EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); to EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(20);"
331,A,Netty client bounded queue discard policy Hitting an OutMemoryError connecting to 3rd party server which cannot process requests fast enough. Tried NioClientSocketChannelFactory to pass in the executor service with the bounded queue and discard policy (ThreadPoolExecutor.DiscardPolicy) but still got OutOfMemoryError. What am I missing? Thanks If your client-side Netty channel's write buffer fills up and the server is not reading it fast enough you will see OutOfMemoryError on the client side. To avoid that you have to stop writing if Channel.isWritable() returns true. You will be notified with a channelInterestOpsChanged event when the status of Channel.writable' changes. Then you can check again ifChannel.isWritable()returnsfalse` and continue writing. If it is OK to discard the pending data I would simply not call Channel.write() if Channel.isWritable() returns false. You can configure when Channel.writable property changes with the watermark properties provided in NioSocketChannelConfig. Also please take a look into the 'discard' example that uses this technique. Seems to have worked. By the way should I bother using bounded worker pool or just use the cached one thats is used in the samples? Thanks Any particular reason why it must? And if it must then why leave the option to change it? Just curious now hehe Worker pool must be the cached one. I'll try let you know. Wouldn't it be sensible if Netty automatically backed off? There's no risk in doing a timed wait here since we're already putting enough pressure on the system.
332,A,Is FrameDecoder not safe in non-single-connection situation? FrameDecoder use one ChannelBuffer instance(field cumulation) to sum up all Channel's raw data then pass to decode. There are chances when part of Channel A's data of whole frame(app level frame) write to cumulation then part of Channel B's data of whole frame write to cumulation. As I understand cumulation should use ChannelLocal to store different instance for different Channel to avoid this situation. Does the situation do exists or I understood the code wrong? You should use a new instance of the class that extends FrameDecoder for every new connection (channel). This is true for all ChannelHandlers that are not marked with the @Sharable [1] annotation. [1] http://netty.io/docs/stable/api/org/jboss/netty/channel/ChannelHandler.Sharable.html
333,A,Netty4 Unexpected exception in the selector loop I have implemented a HTTP client using Netty4.0.0.CR3. I am managing a pool of client connection toward server Based on certain event an event handler thread pick one connection from the pool send the HTTP request to server wait for response (FullHttpResponse) and then release connection back to pool. Now problem which I am facing is that under heavy load I am getting these warnings in my log ` 15:56:59.828 nioEventLoopGroup-37-1 WARN i.n.c.nio.NioEventLoop - Slf4JLogger.warn() : Unexpected exception in the selector loop. java.util.concurrent.RejectedExecutionException: event executor terminated at io.netty.util.concurrent.SingleThreadEventExecutor.reject(SingleThreadEventExecutor.java:711) ~[netty-all-4.0.0.CR3.jar:na] at io.netty.util.concurrent.SingleThreadEventExecutor.addTask(SingleThreadEventExecutor.java:306) ~[netty-all-4.0.0.CR3.jar:na] at io.netty.util.concurrent.SingleThreadEventExecutor.execute(SingleThreadEventExecutor.java:696) ~[netty-all-4.0.0.CR3.jar:na] at io.netty.channel.AbstractChannel$AbstractUnsafe.invokeLater(AbstractChannel.java:968) ~[netty-all-4.0.0.CR3.jar:na] at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:750) ~[netty-all-4.0.0.CR3.jar:na] at io.netty.channel.nio.NioEventLoop.closeAll(NioEventLoop.java:521) ~[netty-all-4.0.0.CR3.jar:na] at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:329) ~[netty-all-4.0.0.CR3.jar:na] at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:114) [netty-all-4.0.0.CR3.jar:na] at java.lang.Thread.run(Thread.java:680) [na:1.6.0_45] ` Now what i want to ask is will these warnings will create any problem if yes any pointers on how to solve this or I can ignore them. Regards !! I think you shutdown EventLoopGroup before all requests are handled. Be sure to use EventLoopGroup.shutdownGracefully(). If you shutdown the EventLoopGroup before everything is handled it will produce such an error I don'T think there is anything special required here. Thanks a lot. One more queryI am using apache commons pool creating multiple http connections toward the server and using a common (`NioEventLoopGroup`) for each client. Now if a connection is closed how do I do the cleanup as I am calling `EventLoopGroup.shutdownGracefully()` only at the closure of pool. How do I manage individual connection cleanup. Thanks for the replying. I am not calling EventLoopGroup.shutdown() instead in my client I am calling `channel.closeFuture();` followed by `bootstrap.shutdown();` for clearing up connection toward server. Is this the correct way ? or should i do it differently What you mean with connection cleanup ? Call EventLoopGroup.shutdownGracefully() Http-server closes connections or there is no activity idle connections are needed to be released as per pool configuration. For such connection any specific cleanup is required.
334,A,Netty hello world example not working I have following code to echo input received by Netty- import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; public class MyHandler extends SimpleChannelInboundHandler{ @Override protected void channelRead0(ChannelHandlerContext ctx Object msg) throws Exception { ByteBuf in = (ByteBuf) msg; try { System.out.println(in.toString(io.netty.util.CharsetUtil.US_ASCII)); } finally { in.release(); } } } I am invoking it as follows-  try { ServerBootstrap b = new ServerBootstrap(); // (2) b.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) // (3) .childHandler(new ChannelInitializer<SocketChannel>() { // (4) @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new MyHandler()); } }) .option(ChannelOption.SO_BACKLOG 128) // (5) .childOption(ChannelOption.SO_KEEPALIVE true); // (6) // Bind and start to accept incoming connections. ChannelFuture f = b.bind(port).sync(); // (7) // Wait until the server socket is closed. // In this example this does not happen but you can do that to gracefully // shut down your server. f.channel().closeFuture().sync(); } finally { workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } When I send a curl request to this Netty server while I do see system.out working (I can see the curl request in console) I get this exception- May 01 2014 6:25:01 PM io.netty.channel.DefaultChannelPipeline$TailHandler exceptionCaught WARNING: An exceptionCaught() event was fired and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. io.netty.util.IllegalReferenceCountException: refCnt: 0 decrement: 1 at io.netty.buffer.AbstractReferenceCountedByteBuf.release(AbstractReferenceCountedByteBuf.java:102) at io.netty.buffer.WrappedByteBuf.release(WrappedByteBuf.java:819) at io.netty.buffer.SimpleLeakAwareByteBuf.release(SimpleLeakAwareByteBuf.java:34) at io.netty.util.ReferenceCountUtil.release(ReferenceCountUtil.java:68) at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:110) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:341) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:327) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:116) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:494) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:461) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:378) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:350) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116) at java.lang.Thread.run(Thread.java:744) What am I doing wrong? Using 4.0.18.Final with JDK 8.0 on Windows 7 You must not call ByteBuf.release() in the channelRead0(...) method as SimpleChannelInboundHandler will take care of this for you.
335,A,"Why is Netty giving me only 768 Bytes from UDP messages I have set the ""receiveBufferSize"" option to 1024 but for some reason I'm still getting only 768 bytes in messageReceived. The header of the data indicates that size of the data being sent is 1004. Below is the initialization code for the server: public static void main(String[] args) throws Exception { ConnectionlessBootstrap b = new ConnectionlessBootstrap(new NioDatagramChannelFactory()); // Options for a new channel b.setOption(""receiveBufferSize"" 1024); System.out.println(b.getOptions()); b.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( new MyUDPPacketDecoder() new StdOutPrintHandler()); } }); b.bind(new InetSocketAddress(myPort)); } You need to set an additional option - receiveBufferSizePredictorFactory. in order to predict how much space it needs to allocate in order to hold the incoming message netty uses a predictor that predicts the amount of byte to allocate. there are two type of receive buffer size predictors adaptive and fixed-size. the predictors are created by a predictor factory which creates one for each channel created by the bootstrap. if no predictor factory is set for the bootstrap (or no predictor is set manually for the channel) the channel uses the default 768 byte fixed-size predictor. all messages bigger then 768 bytes are cut down to that size. you can add: b.setOption(""receiveBufferSizePredictorFactory"" new FixedReceiveBufferSizePredictorFactory(1024)); you can read about the predictors and their factories in netty documentation ReceiveBufferSizePredictor Inteface ReceiveBufferSizePredictorFactory Inteface Could you add a citation for the default predictor being 768 byte fixed-size predictor? [DatagramChannelFactory](http://static.netty.io/3.6/api/org/jboss/netty/channel/socket/DatagramChannelConfig.html). look at setReceiveBufferSizePredictor(ReceiveBufferSizePredictor) '_The default predictor is FixedReceiveBufferSizePredictor(768)_"
336,A,"How to turn off Netty library debug output? I am using Netty (via the Ning async HTTP library) to retrieve documents via HTTP. This produces a huge amount of debug output the console as listed below for a single document request. Anyone know how to turn this off? I really don't need to see this output. I'm calling from Scala if that makes any difference. 15:07:14.273 [run-main] DEBUG c.n.h.c.p.n.NettyAsyncHttpProvider - Non cached request DefaultHttpRequest(chunked: false) GET /api/search.json?q=foo HTTP/1.1 Host: www.documentcloud.org Connection: keep-alive Accept: */* User-Agent: NING/1.0 using Channel [id: 0x2839ca40] 15:07:14.930 [New I/O client worker #1-1] DEBUG c.n.h.c.p.n.NettyAsyncHttpProvider - Request DefaultHttpRequest(chunked: false) GET /api/search.json?q=foo HTTP/1.1 Host: www.documentcloud.org Connection: keep-alive Accept: */* User-Agent: NING/1.0 Response DefaultHttpResponse(chunked: true) HTTP/1.1 200 OK Content-Type: application/json; charset=utf-8 Content-Length: 10477 Connection: keep-alive Vary: Accept-Encoding Status: 200 X-Powered-By: Phusion Passenger (mod_rails/mod_rack) 3.0.13 ETag: ""4f8f766d639dd84d014dfee3abb45de2"" X-Runtime: 611 Cache-Control: private max-age=0 must-revalidate Server: nginx/1.2.1 + Phusion Passenger 3.0.13 (mod_rails/mod_rack) 15:07:14.941 [New I/O client worker #1-1] DEBUG c.n.h.c.p.netty.NettyConnectionsPool - Adding uri: http://www.documentcloud.org:80 for channel [id: 0x2839ca40 /10.5.165.61:56133 => www.documentcloud.org/75.101.159.206:80] 15:07:16.921 [New I/O client worker #1-1] DEBUG c.n.h.c.p.n.NettyAsyncHttpProvider - Channel Closed: [id: 0x2839ca40 /10.5.165.61:56133 :> www.documentcloud.org/75.101.159.206:80] with attachment com.ning.http.client.providers.netty.NettyAsyncHttpProvider$DiscardEvent@63182c3d 15:08:13.924 [Timer-0] DEBUG c.n.h.c.p.netty.NettyConnectionsPool - Entry count for : http://www.documentcloud.org:80 : 0 judging by the abbreviated package names seems to me slf4j/logback is being used for logging here. in that case just try including a logback.xml configuration file in your classpath. something along the lines of <?xml version=""1.0"" encoding=""UTF-8"" ?> <configuration> <appender name=""STDOUT"" class=""ch.qos.logback.core.ConsoleAppender""> <encoder> <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern> </encoder> </appender> <root level=""INFO""> <appender-ref ref=""STDOUT""/> </root> <logger name=""com.ning.http.client"" level=""WARN""/> </configuration> the above xml would cause anything under com.ning.http.client (and downwards) to omit only warnings and worse to the output which will be streamed to system.out. anything else will ommit INFO+ you can find more information on configuring logback here: http://logback.qos.ch/manual/configuration.html worked thanks! I had to place it in src/main/resources this also works on Scala projects if you're using the Scala-Dispatch library. Place it in the same location `src/main/resources`  Late posting for an old question I know but I recently had to turn off annoying repetitive INFO level logging coming from netty: [main] INFO com.ning.http.client.providers.netty.NettyAsyncHttpProvider - Number of application's worked threads is 16 In my case I needed to disable it programmatically. Looking into slf4j org.slf4j.impl.SimpleLogger (the logger facade called by netty) I discovered an easy way to control the default slf4j log level for all SimpleLogger instances in your own startup code: System.setProperty(SimpleLogger.DEFAULT_LOG_LEVEL_KEY ""warn""); or for just the logger instance I was interested in: System.setProperty(SimpleLogger.LOG_KEY_PREFIX + ""com.ning.http.client"" ""warn""); The value can be any of ""trace"" ""debug"" ""info"" ""warn"" or ""error"" with the default being ""info""."
337,A,"How can i block writes on a pipeline for reconfiguration of the pipeline? Im writing a server that regularly needs to change the format of the send/received messages. when this happens the server should send a notification that all future messages have the new format and read all received in the old format until the client sends his ack. i thought about keeping a reference to the decoder shared by all pipelines and reconfigure it from the outside as needed. I'm worried about concurrency in this case. how can i make sure that no writes are handled by the pipeline while i'm working on the decoder? and how to be sure that the notification is the first message handled after reconfiguration? the only other way i see is to send a ""notification"" object through the pipeline (by using channel.write) catch the object in the decoder and do the reconfig then while forwarding the notification message. In this case there shouldn't be any concurrency in the pipeline. would this be the better/state of the art way to do this? i decided to use the second way. A StateHandler catches ConfigurationEvents reconfigures the pipeline. Unfortunately this means that i can't be sure that all channels use the same configuration because race conditions between the reconfiguration and extremely young channels can happen. but i'm pretty sure this won't matter in my case."
338,A,Is netty's udp running in single-threaded mode? Is netty's udp running in single-threaded mode? I have configured the NioDatagramChannelFactory like below: new NioDatagramChannelFactory(Executors.newFixedThreadPool(4) 4)); But when I running the code as a server and lunch more than 20 clients to send udp packages continuously to it the server still use only one worker thread. Why? Normally it should use 4 worker threads here. So how are you seeing that it only use one thread ? Did you check with jstack to see how many worker threads are running ? You should also use new NioDatagramChannelFactory(Executors.newCachedThreadPool() 4)); This should take care of having at max. 4 worker threads. Norman I tested it by changing the EchoServer by changing the channel factory to NioDatagramChannelFactory but I can only see one worker thread but with the NioServerChannelFactory I can see 8 worker threads. (tested both with more than 20 clients) I tested with my fork at branch 3 (last commit is 2c2d64a75ea9c636c90b8b16293296a47c7cfd32) I could not test with latest 3 branch.
339,A,"Netty TCP Socket Overhead I'm a starter with Netty and my aim is to send data objects through TCP sockets; but I have many number of data objects and I want to send using POJO like shown here. However the issue is that I need to convert all my objects to byte arrays and ""only send these byte arrays with TCP overhead"" over the network. Considering this my question is that is Netty will add overhead to my byte array or just encoded byte arrays + TCP overhead will be sent over Netty TCP sockets? Netty doesn't add any protocol of its own. It just sends the bytes you send. It wouldn't be much use otherwise. Is there any official support/document about this topic or any mention about it? Thank you for the answer btw."
340,A,"Netty allows same port to be bound multiple times by different programs I'm a noob to Sockets Programming.Maybe am asking a fundamental question. Please bear with me. I wrote a sample netty server and started it from console. It runs fine. The problem i have is that when i run the same server from two console windows i'd expect one of them to throw 'Address already in use' exception. It does not do that and I dont understand why. Please help.  public static void main(String[] args) { ChannelFactory cf = new NioServerSocketChannelFactory(Executors.newFixedThreadPool(100) new MemoryAwareThreadPoolExecutor(10002048250962TimeUnit.SECONDS)); //ChannelFactory cf = new OioServerSocketChannelFactory(Executors.newFixedThreadPool(100) Executors.newCachedThreadPool()); ServerBootstrap bootstrap = new ServerBootstrap(cf); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline(new ChannelHandler(""test"")); } }); bootstrap.setOption(""child.keepAlive"" true); bootstrap.setOption(""child.tcpNoDelay"" true); bootstrap.setOption(""child.reuseAddress"" true); bootstrap.setOption(""child.connectTimeoutMillis"" 30000); //NEVER bootstrap.setOption(""child.readWriteFair"" true); //bootstrap.setOption(""disconnect"" true); bootstrap.setOption(""tcpNoDelay"" true); bootstrap.setOption(""reuseAddress"" true); bootstrap.setOption(""connectTimeoutMillis"" 30000); bootstrap.setOption(""readWriteFair"" true); bootstrap.bind(new InetSocketAddress(9998)); } @Nikolai: so if process 1 does `bind(INADDR_ANYportX)` then process 2 succeeds when it tries `bind(addressAportX)` but it fails if it tries `bind(INADDR_ANYportX)`? Is the behaviour OS/stack dependent? @Nikolai: tnx for pointing that out. I knew about the UDP/multicasting behaviour I guess I need to brush up on the TCP side... This is standard behavior for TCP see e.g. Stevens UNP section 7.5. UDP on the other hand allows for completely duplicate bindings. `bootstrap.setOption(""reuseAddress"" true);`: the reuseAddress allows binding to already bound address:port. @Eugen what you said is wrong - with `SO_REUSEADDR` he should be able to bind same port on a *specific address/interface* after wildcard is bound but he should not be able to bind to wildcard twice. @user1623175 can you confirm with `netstat -na` that your app is actually listening on the port? @NikolaiNFetissov netstat -na shows both in LISTENING state! However in reality only one of the 2 instances actually receives user inputs. The other just appears to be dormant. If i connect to the port using telnet only one of the 2 started sessions consistently receives my inputs the other is...just dormant.. But when i kill the console that Is receiving my inputs the other one (that appeared dormant) starts to receive my inputs. I'd be happy if i could get the 2nd console to throw 'Address already in use'. @EugenConstantinDinca Thanks. Your tip did it. I changed it to false and now am getting the 'address already in use' exception. Thanks so much for opening my eyes to what was in front of me. Am an idiot. Serves me right to use a setting without thinking about it. @EugenConstantinDinca am not able to mark your response as an answer. Could you kindly post the same tip about 'ReuseAddress"" an answer so that i can flag it as 'The Answer' and you can get due credit please? @NikolaiNFetissov am on Win7 using java se 7 and jboss netty @Nikolai: in UNP the section about SO_REUSEADDR lists the ""should be able to bind same port on a specific address/interface after wildcard is bound but he should not be able to bind to wildcard twice"" behavior as a possibility not the only one. It mentions that ""completely duplicate bindings"" is possible ""if the transport protocol supports it"". Hmm what weird platform/OS are you on? To sum up the many comments above: The bootstrap.setOption(""reuseAddress"" true); option will allow binding to an already bound ip:port combination. This is usually used to be able to restart a server if it crashed/got killed (so while the socket is still in the TIME_WAIT state). In Windows it is possible to have two completely different programs bind the exact same ip:port. So even if in your app you have bootstrap.setOption(""reuseAddress"" false); it is still possible for another app (i.e. malicious) that enables SO_REUSEADDR to succesfully bind on your ip:port. See here for more details: http://msdn.microsoft.com/en-us/library/windows/desktop/ms740621(v=vs.85).aspx"
341,A,"Chat Server with Netty I wrote a simple chat server with netty a friend and I have been testing it with telnet. When both of us are connected it says the size of the group is 1. Whenever writing to the list of users it only writes to whoever sent the message. How can I fix this? import org.jboss.netty.channel.SimpleChannelHandler; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelStateEvent; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.group.ChannelGroup; import org.jboss.netty.channel.group.DefaultChannelGroup; public class ServerChannelHandler extends SimpleChannelHandler { private ChannelGroup users = new DefaultChannelGroup(); @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { users.write(e.getMessage()); } @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { users.add(e.getChannel()); System.out.println(""Opened. ""); System.out.println(users.size()); } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { users.remove(e.getChannel()); } } you must share the same instance of the handler for all created ChannelPipeline instances. Or declare the ChannelGroup as static final Nice good eye norman. +1 Wow how did I miss that.. Thank you I was creating a new ChannelHandler whenever a channel would connect."
342,A,"Netty channel.write not writing message I'm trying to make my first steps with Netty for this purpose i wrote simple server on Netty and simple client on oio plain TCP. Client sends random text packet and must receive ""ack"" message. See the handler method:  @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { ctx.write(""Ack""); ctx.flush(); ByteBuf in = (ByteBuf) msg; StringBuilder sb = new StringBuilder(); try { while (in.isReadable()) { sb.append((char) in.readByte()); } } finally { ReferenceCountUtil.release(msg); } LOG.debug(""Incoming message. ACK was send""); String myaddr = ctx.channel().remoteAddress().toString(); String message = ""Message from "" + myaddr + "" :"" + sb.toString(); LOG.debug(message); sendToOther(myaddr message); } The problem is - when i try to send back ""Ack"" string - client receives nothing. But when i try to send back message that incoming - it works fine and i see echo in my client.  @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { ctx.write(msg); ctx.flush(); write() method needs Object and i tried to send (Object)String - but nothing happened. I also tried to send ByteBuf (i saw that in one article) and it's still not working too. When i send back incoming message as echo - it works. When i send thomething else - it don't. Please help me i just can't figure where my mistake is. I solved this problem. Point was that you need to send ByteBuff only. So we need create it and write some thing to it and only then we can write it into chanel pipe. in my case it was like : String ack = ""ACK""; ByteBuf out = ctx.alloc().buffer(ack.length()*2); out.writeBytes(ack.getBytes()); ctx.write(out); ctx.flush(); LOG.debug(""Incoming message. ACK was send""); May be this is not exelent sollution but it works as example. You will see why it fails if you replace your ctx.write(""Ack""); ctx.flush(); in your serverHandler with the following: ChannelFuture cf = ctx.write(""Ack""); ctx.flush(); if (!cf.isSuccess()) { System.out.println(""Send failed: "" + cf.cause()); } It should give you a message saying that String is not supported. ByteBuf should work though: ctx.write(Unpooled.copiedBuffer(""Ack"" CharsetUtil.UTF_8)); ctx.flush(); on the client side edit the channelRead method: ByteBuf in = (ByteBuf) msg; System.out.println(""Client received: "" + in.toString(CharsetUtil.UTF_8)); Thanx for your answer! Your solution is better than i found myself."
343,A,"Changing localhost in java I'm writing simple server using netty. By default I work with him using localhost:8080 but can I change this to somthingAnother:8080 ? I can use only java and I don't know on which OS my program will work. I can't open hosts.txt file and write new host there by myself. I tried to use new InetSocketAddres(String hostname int port) You can bind ServerBootsrap to a host name using bind(String hostname int port) or bind(SocketAddress localAddress) where localAddress = InetSocketAddress(Sttring hostname int port) I tried ChannelFuture f = b.bind(""someName""8080).sync() but it gives me ""java.net.SocketException: Unresolved address"". You should use real resolvable hostname or IP address like this b.bind(""10.1.2.3"" 8080) Thank you for answer. I think I solved my problem.  The hostname is unsurprisingly the name of the host - the server where your service (in this case netty) runs. By default the name 'localhost' means 'the machine I'm running on' - so you cannot change where that name points to. However you can add another name to the machine you're working on using the hosts file which will be local to your machine (that is the name will be associated with an IP address only on your machine) using DNS which will make the name world-wide bu it will also require a publicly accessible IP address. What do you want to do? Thank you for answer. I want to add another name to hosts file. On Windows edit %windir%\System32\drivers\etc\hosts on Linux edit /etc/hosts. No localhost just means IP address 127.0.0.1 and only processes on the same machine can connect to it. Okay thank you. I was thinking that I can do it without editing hosts file. Now i will do it."
344,A,"getting binary data after you set StringDecoder as pipeline decoder If you created your pipe like this:  pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); Is there any way to get the raw data from a pipeline that usually handles text? I'd really like to do this:  public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { // Save data received from the server. Object msg = e.getMessage(); byte[] rawdata = new byte[((ChannelBuffer)msg).readableBytes()]; ((ChannelBuffer)msg).getBytes(0 rawdata); tmpTarFile.write(rawdata); } The channel is mostly text but sometimes I need to read raw binary out of it. In this case the msg that comes in is a String object because of the StringDecoder in the pipeline. I'd like to get the channelbuffer data beneath that string... On the server side the data was written with this:  ChannelBuffer databuffer = ChannelBuffers.buffer(blobstream.size()); databuffer.writeBytes(blobstream.toByteArray()); e.getChannel().write(databuffer); Looks like I have to turn off the stringencoder/decoder (which converts it into a ChannelBuffer w/ raw byte access) and convert bytes to/from Strings... If you want to get the raw ChannelBuffer you will need to remove the Decoder from the pipeline and then once you want to handle String's again just add it back. You could also extend the StringDecoder and based on some logic decode it or not. Something like that: public class FlexibleStringDecoder extends StringDecoder { @Override protected Object decode(ChannelHandlerContext ctx Channel channel Object msg) throws Exception { if (decodeToString(msg)) { return super.decode(ctx channel msg); } return msg; } public boolean decodeToString(Object msg) { // Add some logic here.... return true; } } Thanks Norman. FYI I did end up getting rid of the StringDecoder/Encoder and now process the channel buffers myself. It was easier in my case because I didn't need the StringDecoder's special language-specific features...."
345,A,"How to change HTTP port that Play2 is listening on The documentation says: $ play start Note: the HTTP port can be set by passing -Dhttp.port system variable but I'm still hitting 9000 port taken error $ /opt/play-2.0/play start -Dhttp.port=9001 [info] Loading project definition from /my/path [info] Set current project to marmurka (in build file:/my/path/) (Starting server. Type Ctrl+D to exit logs the server will remain in background) Play server process ID is 27505 [info] play - Application started (Prod) Oops cannot start the server. org.jboss.netty.channel.ChannelException: Failed to bind to: /0.0.0.0:9000 at org.jboss.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:298) at play.core.server.NettyServer.<init>(NettyServer.scala:63) at play.core.server.NettyServer$.createServer(NettyServer.scala:131) at play.core.server.NettyServer$$anonfun$main$5.apply(NettyServer.scala:153) at play.core.server.NettyServer$$anonfun$main$5.apply(NettyServer.scala:152) at scala.Option.map(Option.scala:133) at play.core.server.NettyServer$.main(NettyServer.scala:152) at play.core.server.NettyServer.main(NettyServer.scala) Caused by: java.net.BindException: Address already in use at sun.nio.ch.Net.bind(Native Method) at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:137) at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:77) at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.bind(NioServerSocketPipelineSink.java:140) at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.handleServerSocket(NioServerSocketPipelineSink.java:92) at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.eventSunk(NioServerSocketPipelineSink.java:66) at org.jboss.netty.channel.Channels.bind(Channels.java:462) at org.jboss.netty.channel.AbstractChannel.bind(AbstractChannel.java:186) at org.jboss.netty.bootstrap.ServerBootstrap$Binder.channelOpen(ServerBootstrap.java:343) at org.jboss.netty.channel.Channels.fireChannelOpen(Channels.java:170) at org.jboss.netty.channel.socket.nio.NioServerSocketChannel.<init>(NioServerSocketChannel.java:77) at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.newChannel(NioServerSocketChannelFactory.java:137) at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.newChannel(NioServerSocketChannelFactory.java:85) at org.jboss.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:277) ... 7 more Please see [this question](http://stackoverflow.com/questions/8205067/how-do-i-change-the-default-port-9000-that-play-uses-when-i-execute-the-run) @JulienRichard-Foy thanks that solves the question this worked for me `play ""run 8080""`Ubuntu 12.04 play 2.2.2 Also note that the server remains in the background Ctrl+D does not kill it (though it does if you use run instead of start). So if you are wondering why the port is still in use... that's probably the reason.  First type: play then in console type: start 9001 The same for development mode. First: play then: run 9001 Another way use qoutes: play ""start 9001"" play ""run 9001"" Thanks it solves the problem. Nice tip about the quoted ""run "" syntax."
346,A,How to find all the clients that connected from specific hostname in ChannelGroup I am learning about the netty framework and Google protobuf so now I am writing some simple server and client applications. I wrote a server based on the SecureChat example that come from netty and I want to write a method that return all the channels that connected from a specific ip (no matter what port). I have a ChannelGroup that holds all the connected channels and I thought about using the write method - write(Object message SocketAddress remoteAddress) but in the SocketAddress class I have to insert port. So I thought about other ways but the only way I found working is using a for loop but there is another ways? Some way that will give me better performance? Thanks BBLN. You could have your own ChannelGroup implementation which supports this. For this you could have a Map of Channels that are using the InetAddress of the Channel as key. So you will be able to lookup all Channels by IP in a fast way.
347,A,"JUnit and Netty cause application to end prematurely Note: I am using JUnit 4.11 and Netty 3.6.5. I am trying to test some basic functionality in my complicated server app. I want to extract simply the networking functionality and do some unit tests. However when I try to create a unit test the application simply exits. However if I put a dummy public static void main it works correctly but outside of JUnit obviously. Here's the sscce: public class SimpleNetwork { private Injector inj; @Before public void startInjector() { Module mod = new AbstractModule() { @Override protected void configure() { // Guice stuff you don't need to see it works fine } }; inj = Guice.createInjector(mod); } // **When I run this using JUnit the application ends immediately.** @Test public void testNetwork() { NioServer server = inj.getInstance(NioServer.class); server.run(); // **This prints in both scenarios** System.out.println(""Hello World""); } // **When I run this the application works as expected.** public static void main(String[] args) { SimpleNetwork sn = new SimpleNetwork(); sn.startInjector(); sn.testNetwork(); } } Netty stuff is *asynchronous* the test runner doesn't wait for other threads to finish you have to arrange for that in your test method. Can you debug into NioServer? @fge Yes the `run` method has a debug `println` that happens @durron597 I was a bit too quick in my initial comment. That can't work because the `run` returns immediately and the real server runs in a background thread. See my answer for a proposed alternative. Junit will exit the test as soon as the junit thread is done whereas your `main` will wait for non daemon threads to terminate before exiting. You need to pause the junit thread and wait for whatever event to happen. It can be a CountdownLatch for example. @YvesMartin It's very similar to this: https://github.com/netty/netty/blob/3/src/main/java/org/jboss/netty/example/discard/DiscardServer.java @assylias Can you give an example as an answer? @durron597 Can you modify the code of your NioServer implementation? @assylias Of course I can but that would defeat the purpose of unit testing What is `NioServer` code ? Please provide a reference or a snippet. Junit will exit the test as soon as the junit thread is done whereas your main will wait for non daemon threads to terminate before exiting. You need to pause the junit thread and wait for whatever event to happen. It is not clear what you are trying to test. If you just need to test that your server can start then your current test does just that. In particular the link you provide shows a server that runs in a background thread so the run method returns immediately. So your test checks that the run method returns without problems. If you want to actually exercise your server by sending data and checking what is received (for example). In that case you need to include the code that tests the server in the same test method. A more typical way of testing something like that would be to start the server once for the whole test class: private NioServer server; @BeforeClass public void beforeClass() { server = getServer(); server.run(); } @Test public void testOne() { sendSomeDataToServer(""data""); assertEquals(""data"" server.getLastReceivedData()); } (I am not 100% sure about the JUnit syntax as I use testNG but it should be something like that) This class is part of the server testing environment. Are you saying start the server in `@BeforeClass` then make some client connections to itself? @durron597 That is one way yes. Another way would be to use mock objects. What exactly are you trying to test? When do you expect the test to pass or fail? If you clarify that it will be easier to help you. Huh. Asking that question makes me wonder if my approach is trying to cover too much code all at once. I started to type ""make sure the server constructs and deconstructs objects correctly"" except why aren't I testing the encoders directly then? @durron597 In which case one approach would be to mock the server and manually pass a message and check that the output of the decoding method is as expected (for example). Anyway this was helpful; I might give this the bounty but I'm going to wait the 5 days. @durron597 Sure you should wait and see if you get more answers. 2 last things: (a) Learning to use a mocking framework can take a bit of time but it is a good investment and would help you solve that sort of issue elegantly. (b) in the code you linked earlier there is not much to test in DiscardServer. The core of the server (decoding/encoding) really is in the DiscardServerHandler which you should test separately."
348,A,"Java client peer-to-multipeer using Netty I'm writing a process which must connect (and keep alive) to several (hundreds) remote peers and manage messaging / control over them. I made two versions of this software: first with classic ""thread-per-connection"" model the second using standard java NIO and selectors (to reduce thread allocation but has problems). Then looking around I found Netty can boost a lot in most cases and I started a third one using it. My goal is to keep resource usage quite low keeping it fast. Once written the pipeline factory with custom events and dynamic handler switching I stopped on the most superficial part: its allocation. All the examples I read use a single client with single connection so I got the doubt: I set up a ChannelFactory and a PipelineFactory so every (new ClientBootstrap(factory)).connect(address) makes a new channel with a new pipeline. Is it possible to make a shared pipeline and defer business logic to a thread-pool? If so how? Using standard java NIO I managed to use two small small thread pools (threads < remote peers) taking advantage of selectors; I had however troubles on recycling listened channels for writing. Communication should happen through a single channel which can receive timed messages from the remote peer or make a 3-way control (command-ack-ok). On second hand: once the event as reached the last handler what happens? Is it there I extract it or can I extract a message from any point? You should only have one bootstrap (i.e one ChannelFactory and one PipeLineFactory). Pipelines or even individual channel handlers may be shared but they are usually created unique per channel. You can have an ExecutionHandler in your pipeline to transfer execution from the IO worker threads to a thread pool. But why don't you read the exhaustive documentation at http://netty.io/wiki/ ? You'll find answers to every question of your's there."
349,A,Listen for both TCP and UDP packets on the same port I there a way in Netty (old and new api) to listen to incoming TCP connection and receive UDP packets on the same port? I am running a single instance of netty server that is listening on port 80. Depending on either a TCP or UDP message the server needs to switch to appropriate handlers. Yes you can. Let me know if you can't.  I guess you already have a ServerBootstrap set up with a specific pipe line factory. All you have to do is create a ConnectionlessBoostrap with a DatagramChannelFactory set it up with a handler pipe line of your needs and bind to the same port.
350,A,"Netty Camel samples I'm a newbie to Netty. I'm looking for some samples. (Preferably but not necessarity using Camel Netty Component and Spring) Specifically a sample Netty app that consumes TCP messages. Also how can I write a JUnit test that can test this netty app? Thanks Dar I assume you still want to integrate with Camel. I would first look at the camel documentation . After that frustrates you you will need to start experimenting. I have one example where I created a Camel Processor as a Netty Server. The Netty components work such that a From endpoint is a server which consumes and a To endpoint is a client which produces. I needed a To endpoint that was a server and the component did not support that. I simply implemented a Camel Processor as a spring bean that started a Netty Server when it was initialized. The JBoss Netty documentation and samples are very good though. It is worthwhile to step through them. Here is my slimmed down example. It is a server that sends a message to all the clients that are connected. If you are new to Netty I highly suggest going through the samples I linked to above: public class NettyServer implements Processor { private final ChannelGroup channelGroup = new DefaultChannelGroup(); private NioServerSocketChannelFactory serverSocketChannelFactory = null; private final ExecutorService executor = Executors.newCachedThreadPool(); private String listenAddress = ""0.0.0.0""; // overridden by spring-osgi value private int listenPort = 51501; // overridden by spring-osgi value @Override public void process(Exchange exchange) throws Exception { byte[] bytes = (byte[]) exchange.getIn().getBody(); // send over the wire sendMessage(bytes); } public synchronized void sendMessage(byte[] message) { ChannelBuffer cb = ChannelBuffers.copiedBuffer(message); //writes to all clients connected. this.channelGroup.write(cb); } private class NettyServerHandler extends SimpleChannelUpstreamHandler { @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { super.channelOpen(ctx e); //add client to the group. NettyServer.this.channelGroup.add(e.getChannel()); } // Perform an automatic recon. @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { super.channelConnected(ctx e); // do something here when a clien connects. } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { // Do something when a message is received... } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { // Log the exception/ } } private class PublishSocketServerPipelineFactory implements ChannelPipelineFactory { @Override public ChannelPipeline getPipeline() throws Exception { // need to set the handler. return Channels.pipeline(new NettyServerHandler()); } } // called by spring to start the server public void init() { try { this.serverSocketChannelFactory = new NioServerSocketChannelFactory(this.executor this.executor); final ServerBootstrap serverBootstrap = new ServerBootstrap(this.serverSocketChannelFactory); serverBootstrap.setPipelineFactory(new PublishSocketServerPipelineFactory()); serverBootstrap.setOption(""reuseAddress"" true); final InetSocketAddress listenSocketAddress = new InetSocketAddress(this.listenAddress this.listenPort); this.channelGroup.add(serverBootstrap.bind(listenSocketAddress)); } catch (Exception e) { } } // called by spring to shut down the server. public void destroy() { try { this.channelGroup.close(); this.serverSocketChannelFactory.releaseExternalResources(); this.executor.shutdown(); } catch (Exception e) { } } // injected by spring public void setListenAddress(String listenAddress) { this.listenAddress = listenAddress; } // injected by spring public void setListenPort(int listenPort) { this.listenPort = listenPort; } }"
351,A,Long Polling - Problems with Internet Explorer 8 I'm trying to implement long polling using Netty and jQuery. I have it working correctly with Chrome and Firefox but Internet Explorer 8 is causing me problems. I'm executing the following code which sends a request to my server waits until a response is received from the server and then sends another request. function longPollRequest() { $.ajax({ url: '/test-path' type: 'GET' success: function(data textStatus jqXHR) { longPollRequest(); console.log('Received: ' + data); } }); } However in IE8 I'm running into an infinite loop which is freezing the browser. The interesting part is that my server is only receiving the first request from IE. I'm really puzzled as to what is going on. If anyone has any ideas I would really appreciate the help. The first line should be `function longPollRequest() {` instead. Is that just a typo in your post? I bet IE8 caches your request: Have your tried `url: '/test-path?nocache='+(Math.random*900000+100000).toString() @Jocob Ya that was just a typo. Fixed. Disable caching and see if that fixes your issue: function longPollRequest () { $.ajax({ url : '/test-path' type : 'GET' cache : false success : function(data textStatus jqXHR) { longPollRequest(); console.log('Received: ' + data); } }); } This will force jQuery to append a time-stamp to each request. If the response is cached then it will return very quickly and there's a good chance that's what's causing your infinite loop. You could also force a minimum delay between AJAX requests: var lastRequestTime = 0; function longPollRequest () { $.ajax({ url : '/test-path' type : 'GET' cache : false success : function(data textStatus jqXHR) { var delay = ((new Date().getTime()) - lastRequestTime); if (delay > 1000) { delay = 0; } else { delay = (1000 - delay); } setTimeout(longPollRequest delay); console.log('Received: ' + data); } }); } This checks the current time against the time of the last AJAX request. If it's more than one second then just run the function again without a delay otherwise make the code wait until a second has gone by between requests. There is probably a more elegant way of defining the delay variable but the above code should get you started. Awesome your solution works. Thanks for pointing me in the right direction. I ended up specifying the Cache-Control: no-cache response header for all long-polling responses and it is working as well.
352,A,"How Netty uses thread pools? Can you please explain how Netty uses thread pools to work? Do I understand correctly that there are two kinds of thread-pools: boss and worker. Boss ones are used to do I/O and worker are used to call user callbacks (messageReceived) to process data? Description related to Netty Nio implementation (3.2.4.Final) NioServerSocketChannelFactory. The worker thread pool has to be able to deliver at least Number of Workers threads (currently default 2*number of cores). Why? In case of this implementation each worker has his own selector loop this means that each worker will ""eat up"" one thread to sleep on the selector. Also that worker (and associated thread) is responsible for doing all the actual writes and reads (including fireing events on the pipeline that means handlers are executed in that workers thread). In case of the boss thread pool actually the thread pool is unneeded because current implementation acquires only a single thread from it. That thread sleeps on the selector for server socket most of the time after accepting connection that connection is registered with a worker. From that moment on worker is responsible for serving that connection.  This is from NioServerSocketChannelFactory document A ServerSocketChannelFactory which creates a server-side NIO-based ServerSocketChannel. It utilizes the non-blocking I/O mode which was introduced with NIO to serve many number of concurrent connections efficiently. How threads work There are two types of threads in a NioServerSocketChannelFactory; one is boss thread and the other is worker thread. Boss threads Each bound ServerSocketChannel has its own boss thread. For example if you opened two server ports such as 80 and 443 you will have two boss threads. A boss thread accepts incoming connections until the port is unbound. Once a connection is accepted successfully the boss thread passes the accepted Channel to one of the worker threads that the NioServerSocketChannelFactory manages. Worker threads One NioServerSocketChannelFactory can have one or more worker threads. A worker thread performs non-blocking read and write for one or more Channels in a non-blocking mode. In Nio model bossThread take care all bounded socket(listen socket) workerThread take care Accepted-socket (included IO and call event method such as messageReceivedd)."
353,A,"Netty.writeAndFlush with future is successfull to killed host We have a Netty (4.0.15) based Websocket server running on Ubuntu v10 and during resiliency testing we do: kill -9 server send some data from client expect writeAndFlush failure on client For some reasons sometimes we see: writeAndFlush success and then after java.io.IOException: Connection reset by peer So is it possible the writeAndFlush sometimes completes successfully even if the server is gone whilst other times it fails? Maybe this occurs because of the schedule of the OS socket clean-up mechanism for killed processes? Client test code:  channel.writeAndFlush(new TextWebSocketFrame(""blah blah"")).addListeners( <snip> public void operationComplete(ChannelFuture future) { assert future.isSuccess() == false; <-- sometimes this is not triggered } </snip> Thanks for any ideas It sounds like an OS-level socket clean-up issue. However setting the socket option SO_KEEPALIVE may decrease the likelihood of this occurring (i.e. improve dead socket detection). Give it a shot. @brettw Thanks we can cope this issue happening just need to provide an explanation why it happens. Meanwhile found [this](http://lazyjavadev.blogspot.ie/2013/05/sucessfull-java-socket-send-with-broken.html) blog giving some more information. It's a simple race condition and something that you have to accept can happen. You can only determine that the remote host has disappeared by not receiving data from it. Generally this is achieved by setting a timer and assuming that if data hasn't been received (possibly in response to a keep alive message) the remote host is dead. Essentially TCP assumes that the remote host is dead if it attempts to retransmit some data a certain number of times without receiving an acknowledgement or it does not receive a response to keep alive (which is usually off by default). However assuming there is room in your host's send buffer you can continue to call writeAndFlush successfully as it will simply be queued in the network buffers. WriteAndFlush is considered to have succeeded once Netty has written the data to the kernel send buffer. There is no way of determining whether the data reached the remote host without an application level acknowledgement. Thus you may be calling writeAndFlush while TCP is in the process of determining that the remote host has died and so writeAndFlush succeeds but the data is not sent. Alternatively you may call writeAndFlush at the same time as TCP determines the remote host is dead and therefore raises an error. There's a lot more information on TCP retransmission and keep alive here and here"
354,A,Logic behind camel ServicePool when used with Netty I have a camel instance with a Netty endpoint that consolidates many incoming requests to send to a single receiver. More specifically this is a web service whereby each incoming SOAP request results in a Producer.sendBody() into the camel subsystem. The processing of each request involves different routes but they will all end up in the single Netty endpoint to send on to the next-level server. All is fine as long as I only have a handful of incoming requests at any one time. If I start having more than 100 simultaneous requests though I get this exception: java.lang.IllegalStateException: Queue full at java.util.AbstractQueue.add(AbstractQueue.java:71) ~[na:1.6.0_24] at java.util.concurrent.ArrayBlockingQueue.add(ArrayBlockingQueue.java:209) [na:1.6.0_24] at org.apache.camel.impl.DefaultServicePool.release(DefaultServicePool.java:95) [camel-core-2.9.2.jar:2.9.2] at org.apache.camel.impl.ProducerCache$1.done(ProducerCache.java:297) ~[camel-core-2.9.2.jar:2.9.2] at org.apache.camel.processor.SendProcessor$2$1.done(SendProcessor.java:120) ~[camel-core-2.9.2.jar:2.9.2] at org.apache.camel.component.netty.handlers.ClientChannelHandler.messageReceived(ClientChannelHandler.java:162) ~[camel-netty-2.9.2.jar:2.9.2] at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.3.1.Final.jar:na] This is coming from the DefaultServicePool that's used by the Netty component. The DefaultServicePool uses an ArrayBlockingQueue as the backend to the queue and it sets it to a default capacity of 100 Producers. It uses a service pool for performance reasons to avoid having to keep creating and destroying often-reused producers. Fair enough. Unfortunately I'm not getting the logic on how it is implemented. This all starts in ProducerCache::doInAsyncProducer which starts off by calling doGetProducer. Said method attempts to acquire a Producer from the pool and if that fails it creates a new Producer using endpoint.getProducer(). It then makes sure that the service pool exists using pool.addAndAcquire. That done it returns to the calling function. The doInAsyncProducer does its thing until it's finished in which case it calls the done processor. At this point we're completely done processing the exchange so it releases the Producer back to the pool using pool.release Here is where the rubber hits the road. The DefaultServicePool::release method inserts the Producer into the ArrayBlockingQueue backend using an add. This is where my java.lan.IllegalStateException is coming from. Why? Well let's look through a use case. I have 101 simultaneous incoming requests. Each of them hits the Netty endpoint at roughly the same time. The very first creates the service pool with the capacity of 100 but it's empty to start. In fact each of the 101 requests will create a new Producer from the endpoint.getProducer; each will verify that they don't exceed the capacity of the service pool (which is empty); and each will continue on to send to the server. After each finishes it tries to do a pool.release. The first 100 will succeed since the pool capacity hasn't been reached. The 101st request will attempt to add to the queue and will fail since the queue is full! Is that right? If I'm reading that correctly then this code will always fail whenever there are more than 100 simultaneous requests. My service needs to support upwards of 10000 simultaneous requests so that's just not going to fly. It seems like a more stable solution might be to: Pre-allocate all 100 Producers on initialization Block during acquire until a Producer is available Absolutely do not create your own non-pool Producers if using a ServicePool In the meantime I'm thinking of throttling incoming requests. What I'm hoping for with this question is to learn if I'm reading that logic correctly and to see if it can get changed. Or am I using it wrong? Is there a better way to handle this type of thing? Yes the logic should IMHO be improved. I have logged a ticket to improve this. https://issues.apache.org/jira/browse/CAMEL-5703
355,A,Connection pooling in Netty I'm trying to build a reverse proxy with Netty and I'd like to keep a pool of open sockets to the backend servers instead of every incoming socket requiring a new socket from the reverse proxy to a backend server. Can you do this with Netty? How? Thanks for any help Ok answering my own question there is a nice example how to do this in the LittleProxy source code. In particular in HttpRequestHandler.java follow the usage of endpointsToChannelFutures. Looks like the code has been updated and endpointsToChannelFutures renamed to externalHostsToChannelFutures.
356,A,ChannelHandler is not a sharable Handler Alright so I am experimenting with Netty 4.0.19 (which is great by the way) and having one connection works fine but once there are multiple connections there is an error that the handler is not a shared handler and cannot have multiple items. This is my Handler class: ChannelManager.java I was thinking maybe every connection needs its own handler but then I'm not sure how I will implement that in my current environment. Any suggestions or ideas? EDIT : I wasn't sure how to ask this question on google... so excuse me if this question already exists. I think it has something to do with line 59 in the code. I saw some use of a ChannelInitializer but I don't know how to use that. if your handler can be shared between multiple clients you need to annotate the class with: @ChannelHandler.Sharable
357,A,"What's the different between the Java and Clojure code? EventLoopGroup bossGroup = new NioEventLoopGroup(); // (1) EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); // (2) b.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) // (3) .childHandler(new ChannelInitializer<SocketChannel>() { // (4) @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast( new 6MessageDecoder() new LoginHandler()); } }) .option(ChannelOption.SO_BACKLOG 128 ) // (5) .childOption(ChannelOption.SO_KEEPALIVE true); // (6) // Bind and start to accept incoming connections. ChannelFuture f = b.bind(port).sync(); // (7) // Wait until the server socket is closed. // In this example this does not happen but you can do that to gracefully // shut down your server. f.channel().closeFuture().sync(); } finally { workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } I write it in clojure: (let [bossGroup (NioEventLoopGroup.) workerGroup (NioEventLoopGroup.) bootstrap (ServerBootstrap.)] (.. bootstrap (group bossGroup workerGroup) (channel NioServerSocketChannel) (childHandler (proxy [ChannelInitializer] [] (initChannel [ch] (.. ch (pipeline) (addLast (MessageDecoder.) (LoginHandler.) )) ))) (option ChannelOption/SO_BACKLOG (int 128)) (childOption ChannelOption/SO_KEEPALIVE true) (bind (int 8080)) (sync) (channel) (closeFuture) (sync) ;(childHandler (ChannelInitializer<SocketChannel>.)) ) ) The code written in clojure can runbut when i test it: telnet 127.0.0.1 8080 Trying 127.0.0.1... Connected to localhost. Escape character is '^]'. Connection closed by foreign host. It doesn't work. However the Java code can work. What's wrong with it? (bind) seems worked. when i run the clojure code againit prompts:com.intellij.rt.execution.application.AppMain.main(AppMain.java:120) Caused by: java.net.BindException: Address already in use ""Address already in use"" means that some other process is already listening on port 8080. Don't run two programs at the same time which want to listen on the same port. I run the code written in clojure for the second timeI mean the (bind 8080) seems worked in the first time.But I can't telnet the 8080 port. Got the reason: In clojure java's variable arguments is not well supported.(From my point of view.) so， (addLast (MessageDecoder.) (LoginHandler.) ) is not the correct syntax to call addLast(ChannelHandler... handlers) ` netty complains "" method not found""but it catches the exception and prints a warning use log4j.I had not seen this warnning before because log4j is not configured. the out put: Escape character is '^]'. means the binding and listenning is worked. now it worked with this code: (.addLast (.pipeline ch) (doto (make-array ChannelHandler 2) (aset 0 (MessageDecoder.)) (aset 2 (ServerHandler.)) ) )"
358,A,Using Netty with Scala I use Netty 4.0.0.CR3 in my Scala 2.10.1 application. This client side code ... val b: Bootstrap = new Bootstrap b.group(group).channel(classOf[NioSocketChannel]).handler(new QueryWebClientIntializer) ... causes the compilation error not found: value classOf b.group(group).channel(classOf[NioSocketChannel]).handler(new QueryWebClientIntializer) This server side code ... val b: ServerBootstrap = new ServerBootstrap b.group(bossGroup workerGroup).channel(classOf[NioServerSocketChannel]).childHandler(new QueryWebServerInitializer(server)) ... works perfectly. What am I doing wrong? have you tried `Predef.classOf`? @Alexlv Strangely enough it worked thank you Predef.classOf[]. Thanks to @AlexIv
359,A,How does a http client associate an http response with a request (with Netty) or in general? Is a http end point suppose to respond to requests from a particular client in order that they are received? What about if it doesn't make sense to in the case of requests handled by cluster behind a proxy or in requests handled with NIO where one request is finished faster than the other? Is there a standard way of associating a unique id with each http request to associate with the response? How is this handled in clients like http componenets httpclient or curl? The question comes down to the following case: Suppose I am downloading a file from a server and the request is not finished. Is a client capable of completing other requests on the same keep-alive connection? I won't re-write CodeCaster's answer because it is very well worded. In response to your edit - no. It is not. A single persistent HTTP connection can only be used for one request at once or it would get very confusing. Because HTTP does not define any form of request/response tracking mechanism it simply would not be possible. It should be noted that there are other protocols which use a similar message format (conforming to RFC822) which do allow for this (using mechanisms such as SIP's cSeq header) and it would be possible to implement this in a custom HTTP app but HTTP does not define any standard mechanism for doing this and therefore nothing can be done that could be assumed to work everywhere. It would also present a problem with the response for the second message - do you wait for the first response to finish before sending the second response or try and pause the first response while you send the second response? How will you communicate this in a way that guarantees messages won't become corrupted? Note also that SIP (usually) operates over UDP which does not guarantee packet ordering making the cSeq system more of a necessity. If you want to send a request to a server while another transaction is still in progress you will need to create a new connection to the server and hence a new TCP stream. Facebook did some research into this while they were building their CDN and they concluded that you can efficiently have 2 or 3 open HTTP streams at any one time but any more than that reduces overall transfer time because of the extra packet overhead cost. I would link to the blog entry if I could find the link...  Whenever a TCP connection is opened the connection is recognized by the source and destination ports and IP addresses. So if I connect to www.google.com on destination port 80 (default for HTTP) I need a free source port which the OS will generate. The reply of the web server is then sent to the source port (and IP). This is also how NAT works remembering which source port belongs to which internal IP address (and vice versa for incoming connections). As for your edit: no a single http connection can execute one command (GET/POST/etc) at the same time. If you send another command while you are retreiving data from a previously issued command the results may vary per client and server implementation. I guess that Apache for example will transmit the result of the second request after the data of the first request is sent. +1 - Nice succinct explaination. Altoid Muncher I think you might do well to [read up on some of the basics of TCP](http://en.wikipedia.org/wiki/Transmission_Control_Protocol) the transport layer protocol that HTTP (usually) operates on. Relatively high-level software such as a web browser or cURL does not have to worry about this it is handled by the underlying TCP/IP stack of the operating system. For further reading that is closely related to this as @CodeCaster mentioned read up on [NAT (Network Address Translation)](http://en.wikipedia.org/wiki/Network_address_translation) +1 for the nice answer. A caveat: a single HTTP connection *can* execute multiple requests when using HTTP Pipelining (wiki: http://en.wikipedia.org/wiki/HTTP_pipelining example: http://info-chaitra.blogspot.com/2011/03/http-persistent-connection.html). The catch is that the requests must be idempotent: GETs are fine but no POSTs. @LucaInvernizzi true but the server will not send multiple resources at the same time it's still FIFO: the data of the second response will be sent after all the data of first response has been sent. There is no multiplexing as there is in SPDY for example. Oh and don't say +1 when you don't upvote. ;-) Thanks. I forgot to actually upvote but fixed it now :)
360,A,"SSL on service(on CentOS) does not work I am running a HTTP server using Netty 4.0.11 with OpenJDK 1.7. I am using CentOS 6.3. Everything works fine when I just use ""java -jar myServer.jar"" on the command. However when I put the it on the service I get an exception saying the channel can't be initialized. It's strange because everything works fine on just command line. But on service something seems to go wrong. Nov 07 2013 4:26:00 PM io.netty.channel.ChannelInitializer channelRegistered WARNING: Failed to initialize a channel. Closing: [id: 0x921deb84 /14.63.176.113:17319 => /172.27.125.139:1003] java.lang.NullPointerException at server.BookkServerInitializer.initChannel(BookkServerInitializer.java:23) at server.BookkServerInitializer.initChannel(BookkServerInitializer.java:18) at io.netty.channel.ChannelInitializer.channelRegistered(ChannelInitializer.java:70) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRegistered(DefaultChannelHandlerContext.java:162) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRegistered(DefaultChannelHandlerContext.java:148) at io.netty.channel.DefaultChannelPipeline.fireChannelRegistered(DefaultChannelPipeline.java:730) at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:442) at io.netty.channel.AbstractChannel$AbstractUnsafe.access$100(AbstractChannel.java:374) at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:418) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:354) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:353) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101) at java.lang.Thread.run(Thread.java:724) And here's where the exception is called. package server; import handler.BookkServerHandler; import handler.DeleteConnections; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; import io.netty.handler.codec.http.HttpContentCompressor; import io.netty.handler.codec.http.HttpContentDecompressor; import io.netty.handler.codec.http.HttpServerCodec; import io.netty.handler.ssl.SslHandler; import io.netty.handler.timeout.IdleStateHandler; import util.ssl.ServerSslContext; import javax.net.ssl.SSLEngine; class BookkServerInitializer extends ChannelInitializer<SocketChannel> { public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); if (!System.getProperty(""os.name"").equals(""Windows 7"")) { SSLEngine engine = ServerSslContext.getInstance().serverContext().createSSLEngine(); engine.setUseClientMode(false); pipeline.addLast(""ssl"" new SslHandler(engine)); } pipeline.addFirst(""connectionDeleter"" new DeleteConnections()); pipeline.addFirst(""idleState"" new IdleStateHandler(3 3 3)); pipeline.addLast(""codec"" new HttpServerCodec()); pipeline.addLast(""inflater"" new HttpContentDecompressor()); pipeline.addLast(""deflater"" new HttpContentCompressor(9 15 9)); pipeline.addLast(""handler"" new BookkServerHandler()); } } The exception log shows that my SSLEngine is where to problem is. I tested the server without SSL it works!!! What's going on with SSL with service?? Solved by changing the directory of the keystore. I used to store my keystore in the same directroy as the jar file. So i used the path ""keystore"". Just change it to ""/DirectoryOfTheKeystore/keystore"". It works!!"
361,A,"Handling ReadTimeoutHandler time out I just can't realize why my read time out is not working. All I want to do is just to wait for 10 seconds for some thread to put message to BlockedQueue<String> and on timeout return some kind of response on client. public class NioAsynChatPipelineFactory implements ChannelPipelineFactory { private static Timer timer = new HashedWheelTimer(); private final ChannelHandler timeoutHandler = new ReadTimeoutHandler(timer 10); @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""handler"" new NioAsynChatHandler()); pipeline.addLast(""timeout"" this.timeoutHandler); return pipeline; } } Now my handler looks like this. public class NioAsynChatHandler extends SimpleChannelUpstreamHandler{ @Override public void handleUpstream( ChannelHandlerContext ctx ChannelEvent e) throws Exception { super.handleUpstream(ctx e); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) throws Exception { System.out.println(""Exception""); \\writing some kind of response and closing channel. } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { Thread thread = new Thread(new ConsmerTask(e.getChannel())); thread.start(); } and inside ConsumerTask I'm just waiting for BlockingQueue to get response public class ConsumerTask implements Runnable{ private Channel channel; public ConsumerTask(Channel channel){ this.channel = channel; } @Override public void run() { try{ while(true){ String message = queue.take(); } } catch(InterruptedException ex){ Thread.currentThread.interrupt(); } finally{ //write something to channel and close it } } My problem is that I don't see that any excpetion occurs on time out. What am I doing wrong? Update:  public static final BlockingQueue<String> blockingQueue = new LinkedBlockingQueue<String>(); Actually my question is more generic How to close channel on timeout while it is waiting for something in external thread? Update 2: Another question: due to the fact that I'm running external thread in Cha would it be better to use OrderedMemoryAwareThreadPoolExecutor in pipeline? Will it increase performance. shouldn't you use poll() instead of take? What implementation did you choose for the BlockingQueue? Actually it doesn't matter whether I'm using poll() or take(). In poll I can specify time out and no while(true) loop required while take() gets items immediately. Regarding blocking queue see my update. It's basically because you put the ReadTimeoutHandler in the wrong position. Please put it in the first position of the pipeline (i.e. before all handlers)."
362,A,"ConcurrentIdentityWeakKeyHashMap and Integer keys Though internal I presumed that it is safe to use ConcurrentIdentityWeakKeyHashMap generally. However the following code: ConcurrentIdentityWeakKeyHashMap map = new ConcurrentIdentityWeakKeyHashMap(); for(int key = 0; key < 132; key++){ map.put(key key); } for(int key = 0; key < 132; key++){ System.out.println(map.get(key)); } produces: 0 1 .. 124 125 126 127 null null null null Is this a bug or a misconception on my side (i.e. ""shouldn't be used with Integers"" or ""internal use only"")? EDIT: based on Lucianos comments I altered the code a bit to make it hold a reference to the (I hope at least) very same Integer in the list and in the map:  ArrayList<Integer> list = new ArrayList<Integer>(132); ConcurrentIdentityWeakKeyHashMap<Integer Integer> map = new ConcurrentIdentityWeakKeyHashMap<Integer Integer>(); for(int key = 0; key < 132; key++){ Integer key2 = key; list.add(key2); map.put(key2 key2); } for(int key = 0; key < 132; key++){ System.out.println(map.get(list.get(key))); } Now it works... Integer up to 127 are precached in the Integer class so they will never be garbage collected. OK so what's the point then? Did you mean to say that values with keys up to 127 are never GCed and everything above is GCed instantly? Also it uses identity ( == ) to compare keys so when you do get(key) the autoboxing creates a new Integer object with the key number but that object is different than the one saved on the Map so the identity equals operator returns false therefore you get a null value."
363,A,ByteBuffer vs ChannelBuffer I am using some framework implemented on the top of netty. I am sending a message from client to server using two options below. I suppose that this two snippets should write same bytes to the socket it behavior at server side is different. How is it different? Option 1: okay ChannelBuffer buf = ChannelBuffers.buffer(1); buf.writeByte(0x1c); e.getChannel().write(buf); Option 2: fails ByteBuffer buf = ByteBuffer.allocate(1); buf.put(0x1c); e.getChannel().write(ChannelBuffers.wrappedBuffer(buf)); Before you can write the ByteBuffer to the Channel you have to call buf.flip(); This is making the bytes visible for write. yeah now it produces the same result. where can I read more about the nature of this issue. thanks! @NikolayKuznetsov A simple explanation you can find in the [docs](http://docs.oracle.com/javase/6/docs/api/java/nio/Buffer.html#flip())
364,A,In netty4 is there an guaranteed order between notifications after connecting to remote server? When one calls channel.connect a future is returned. Then for each outbound-handler .connect() is called passing a promise. (I guess they are really the same object but let's ignore that.) So far so clear. At some point listeners added to (a) the future to (b) the promise are notified about completion. Also at some point (c) .channelActive() will be called on all inbound handlers (as far as I understood this replaces .connected from netty-3.x). And finally there is the point in time (d) when isActive() returns true for the first time. Question: Is there a defined order between (a) to (d)? Context: I'm trying to implement a handler that writes a message to the channel on connection. It works mostly well but sometimes it seems that handler is not the first one to get to write. The order is guaranteed but it may trigger an event earlier then you are able to add the listener itself as everything is async. If you want to make sure that your ChannelFutureListener is called before channelActive() in all cases you can just create a ChannelPromise via channel.newPromise() add a ChannelListener to it and then pass the ChannelPromise to the connect method. The contract is that the ChannelPromise will always be notified before the corresponding methods in ChannelOutboundHandler/ChannelInboundHandler So the promise that is passed in the outboundhandler.connect is notified before channelActive handlers are called. Right? Moreover is there a guaranteed order between listeners on the same promise/future? I.e. if I want to be sure that some handlers listener is notified before any listeners up the stack I have to create a new promise (for the ctx.connect call) and notify the one the handler received as argument afterwards.
365,A,"Proguard and Netty on Android Basically I am trying the same as this guy: How can I tell proguard to assume a package is not used? but am not able to add any comments. I keep getting warnings like this: Warning: org.jboss.netty.logging.Slf4JLogger: can't find referenced class org.slf4j.Logger Basically org.jboss.netty.logging.Slf4JLogger is referencing third party library class org.slf4j.Logger which is not part of my project. org.jboss.netty.logging.Slf4JLogger is not used either. So I try to tell proguard not to load/use org.jboss.netty.logging.Slf4JLogger as proposed by Eric Lafortune but constantly fail in doing so. I added -injars libs/netty-3.3.1.Final.jar(!**Slf4JLogger) or -injars libs/netty-3.3.1.Final.jar(!**Slf4JLogger.class) but this does not seem to do anything. Even -injars libs/netty-3.3.1.Final.jar(""!whatever is in here"") yields the same results so I assume this option does not do anything... How can I tell Proguard to not consider several specific classes in the netty.jar? I am using netty 4 now and found above can not work on netty 4 could anybody help further? Thanks a lot. Using the latest ADT (18.0) which fixes some problems with ProGuard integration (as compared to ADT 16.00) I was able to successfully run my Netty based app with the following additional ProGuard Settings:  # Get rid of warnings about unreachable but unused classes referred to by Netty -dontwarn org.jboss.netty.** # Needed by commons logging -keep class org.apache.commons.logging.* {*;} #Some Factory that seemed to be pruned -keep class java.util.concurrent.atomic.AtomicReferenceFieldUpdater {*;} -keep class java.util.concurrent.atomic.AtomicReferenceFieldUpdaterImpl{*;} #Some important internal fields that where removed -keep class org.jboss.netty.channel.DefaultChannelPipeline{volatile <fields>;} #A Factory which has a static factory implementation selector which is pruned -keep class org.jboss.netty.util.internal.QueueFactory{static <fields>;} #Some fields whose names need to be maintained because they are accessed using inflection -keepclassmembernames class org.jboss.netty.util.internal.**{*;} My conclusions about why a specific line is needed may not be 100% precise and this is definitly not the must tuned solutions but at least it works. Feel free to edit if you think you can improve this."
366,A,"How to send nessage to a client in netty I am a Netty beginner and struggling to manage client list. I save device ID and divice name when a client connects and when a different client wants to send a message to the client by device ID how can I handle this? I have seen the examples how to use ChannelGroup to save the connected clients. But it is only for channel and it has attributeKey but it is for different purpose. Do I just map or list instead of ChannelGroup? Is there any good idea? Your answer would be appreciated. You could just implement your own ChannelGroup that stores the clients differently and lets you find a client by ID. But since you only want to relay a message to ONE connected client I don't see much sense in using a group. As far as I understand ChannelGroups are supposed to make broadcast messages easier. I think a simple HashMap with the ID as key would be enough. Thanks for your answer. I am thinking ChannelGrop for just future purpose. `ConcurrentHashMap` would be better Could you explain more ""I think a simple HashMap with the ID as key would be enough.""? HashMap will store an object which includes ID and what? ChannelHandlerContext or something else? `HashMap channelMap` for example. If you want to send it to a single client you retrieve the according channel from the map and just `writeAndFlush`"
367,A,"Netty how to read chunked HTTP response without using one of the 4.0.0 alpha releases? I noticed that in the Netty 4.0.0 alpha releases an HTTP response object has a method to to test for chunking (isChunked()). In The 3.5.7.Final release only the request object has a method to test for chunking. Using 3.5.7.Final how could I go about reading in a chunked response? Code below that I used for a 4.0.0 alpha test: @Override public void messageReceived(ChannelHandlerContext context MessageEvent event) throws Exception { try { log.trace(""Message received""); if (newMessage) { log.trace(""New message""); HttpResponse response = (HttpResponse) event.getMessage(); log.trace(""STATUS: [{}] VERSION [{}]"" response.getStatus() response.getProtocolVersion()); if (!response.getHeaderNames().isEmpty()) { for (String name: response.getHeaderNames()) { for (String value: response.getHeaders(name)) { log.trace(""HEADER: [{}] = [{}]"" name value); } } } newMessage = false; if (response.isChunked()) { requestContentStream = new ByteArrayOutputStream(); readingChunks = true; log.trace(""CHUNKED CONTENT {""); return; } else { log.trace(""Request not chunked""); writeNonChunkedData(response); responseComplete(event); return; } } else if (readingChunks) { log.trace(""Reading chunks""); HttpChunk chunk = (HttpChunk) event.getMessage(); if (chunk.isLast()) { log.trace(""Read last chunk""); readingChunks = false; writeChunkedData(); responseComplete(event); return; } else { log.trace(""Buffering chunk content to byte buffer""); requestContentStream.write(chunk.getContent().array()); return; } } else { log.error(""Error handling of MessageEvent expecting a new message or a chunk from a previous message""); //setError(context INTERNAL_SERVER_ERROR); super.messageReceived(context event); } }catch (Exception ex) { log.error(""Exception: [{}]"" ex); //setError(context INTERNAL_SERVER_ERROR); super.messageReceived(context event); } } HttpResponse.isChunked() also exist in netty 3.5.7. Not sure why you think it doesn't .. See [1] and [2]. [1] https://github.com/netty/netty/blob/3/src/main/java/org/jboss/netty/handler/codec/http/HttpMessage.java [2] https://github.com/netty/netty/blob/3/src/main/java/org/jboss/netty/handler/codec/http/HttpResponse.java Apologies my IDE was not using correct javadoc. Everything is working good"
368,A,Why is an EventLoopGroup required for a client connected over a LocalChannel? This may actually pertain to client's in general using Bootstrap -- clearly the group is required for any client. But if you have multiple clients running on a single JVM you really eat up a lot of memory creating an EventLoopGroup for each and can pretty easily OOM yourself. I was able to work around this by having a global EventLoopGroup that is shared amongst all clients in the JVM and uses reference counting to make sure its cleanly inited and destroyed but this seems more like a workaround than the intended design. And there didn't seem to be any EventLoopGroup implementation that would just use a single-threaded executor something that would execute the calls of the client serially; which I realize is somewhat at odds with Netty's async nature but it's a legit use case. EventLoopGroup is intended to be shared between multiple client channels. You don't need to create a new EventLoopGroup for each channel you create. I'm not sure why you had to introduce reference counting for the life cycle of EventLoopGroup but you could just shut it down when your application is about to terminate itself. Alternatively you can specify a ThreadFactory that creates a daemon thread then JVM will terminate without waiting for the threads created by EventLoopGroup. Netty actually provides DefaultThreadFactory which is convenient for creating a daemon thread. To make EventLoopGroup single-threaded just specify 1 as a constructor parameter. I went with the reference counting approach because at first each client was creating its own EventLoopGroup and load testing which was spawning many clients to hit a remote server ate up a ton of memory even when single threaded. I could have injected a global event group into the clients and let it be re-used that way but the ref counting was an easier approach. If group was optional that would have been fine. For me at least the thread pool for the client is too heavyweight and i just needed a way around that when load testing. Or if there was an easy way to specify some sort of callerRuns group similar to ThreadPoolExecutor.CallerRunsPolicy that would have worked fine. The clients were already in their own thread. Lastly if there was an easy way to create a group that wraps an existing ExecutorService which then I could have managed separately which would have been useful (granted that similar to what i do now) Any suggestion for an improvement on the Netty side with respect to your use case?
369,A,"Netty 4.0 - instanciate DefaultChannelGroup I am currently migrating my project from Netty 3.x to 4.0.4 Final and i have a little question about ChannelGroups. DefaultChannelGroup needs now an EventExecutor in the constructor. Unfortunately i didn´t really understand the thread model of Netty 4.0 yet. How can i instanciate an EventExecutor for my ChannelGroups? I just want the write operations beeing executed in several threads. ChannelGroup newChannelGroup = new DefaultChannelGroup(name new DefaultEventExecutorGroup(1).next()); Is this the right way? The code that's used in the examples is: ChannelGroup channelGroup = new DefaultChannelGroup (name GlobalEventExecutor.INSTANCE); The doc says about GlobalEventExecutor: **Please note it is not scalable to schedule large number of tasks to this executor; use a dedicated executor.** Maybe there will be a large number of task in my case. So i think i need a dedicated one It's easy enough to create a dedicated one but the [docs](http://netty.io/4.0/api/io/netty/channel/group/DefaultChannelGroup.html) say that the group uses the ""EventExecutor to notify the ChannelGroupFuture's"" so I assume (but am not 100% sure) that it will be sufficient. You are right. I misunderstood the doc. Thanks"
370,A,"Understanding Netty's use of Threads In netty events that flow through a channel pipeline occur in order as each channel is effectively only assigned to one thread and each handler calls each other in turn. This makes sense and alleviates many syncronisation issues. However if you use an IdleStateHandler from my reading of the source it appears that the channelIdle event will be 'processed' in the context of the Timers thread (the thread the HashedWheelTime is using for example). Is this case or have I missed something? If it is the case does this mean that it is possible for an idlestate event and an IO event (example a messageRecieved event) to be executing on the same channel at the same time? Also as I could save the ChannelHandler ctx and use it in a different thread to 'write' to a channel for example thus also have an event going downstream in one thread and upstream in another thread at the same time on the same channel? Finally which thread do ChannelFutures execute in? All of these use cases are perfectly acceptable and not a criticism of Netty at all I am actually very fond of the library and make use of it everywhere. Its just that as I try to do more and more complex things with it I want to understand more about how it works under the hood so that I can ensure I am using the proper and just the right amount (no more no less) of syncronisation (locking). However if you use an IdleStateHandler from my reading of the source it appears that the channelIdle event will be 'processed' in the context of the Timers thread (the thread the HashedWheelTime is using for example). Is this case or have I missed something? If it is the case does this mean that it is possible for an idlestate event and an IO event (example a messageRecieved event) to be executing on the same channel at the same time? Yes you have missed the concept of ordered event execution available in the Netty If you are not haveing ExecutionHandler with OrderedMemoryAwareThreadPoolExecutor in the pipeline you can not have the ordered event execution specially channel state events from IdleStateHandler. Also as I could save the ChannelHandler ctx and use it in a different thread to 'write' to a channel for example thus also have an event going downstream in one thread and upstream in another thread at the same time on the same channel? Yes its correct. More over If you want to have ordered event execution in the downstream you have have an downstream execution handler impl with OrderedMemoryAwareThreadPoolExecutor. Finally which thread do ChannelFutures execute in? The are executed by Oio/Nio Worker threads But if your down stream handler is consuming some type of event and firing another type of event to below the downstream then your downstream handler can optionally handle the future execution. this can be done by get the future form downstream event and calling future.setSuccess() Thanks for elaborating :)  Yes the channelIdle event and downstream / upstream event could be fired at the same time. So if your handler does implement at least two of the three you need to add proper synchronization. I guess we should make it more clear in the javadocs.. Now the other questions.. You can call Channel.write(...) from every thread you want too.. So its possible to just store it somewhere and call write whenever you want. This also gives the ""limitation"" that you need have proper synchronization for ""downstream"" handlers. ChannelFutures are executed from within the worker thread. Thanks for the answer exactly what I needed to know."
371,A,Can a Netty NIO channel be writable but not connected? I have a handler that receives an channelInterestChanged callback then tests the channel's isWritable() method in that callback and fires a writeRequest event downstream if it is. Sometimes if this occurs right as the channel is being opened the channel throws an exception event with the cause as java.nio.channels.NotYetConnectedException. Should isWritable() == true assume isConnected() == true or did I screw this up? Example: @Override public void channelInterestChanged(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { MyMessage msg; while(ctx.getChannel().isWritable()){ msg = queue.poll(); Channels.write(ctx Channels.succeededFuture(ctx.getChannel()) msg); } } Stacktrace: java.nio.channels.NotYetConnectedException at org.jboss.netty.channel.socket.nio.AbstractNioWorker.cleanUpWriteBuffer(AbstractNioWorker.java:696) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromUserCode(AbstractNioWorker.java:421) at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:116) at org.jboss.netty.channel.Channels.write(Channels.java:733) at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:65) at org.jboss.netty.channel.Channels.write(Channels.java:733) at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:65) at org.jboss.netty.channel.Channels.write(Channels.java:733) at org.jboss.netty.channel.Channels.write(Channels.java:694) <--- this call is guarded by `isWritable()` at foo.bar.MyHandler.channelInterestChanged(MyHandler.java:44) <--- My handler at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:61) at org.jboss.netty.channel.Channels.fireChannelInterestChanged(Channels.java:361) at org.jboss.netty.channel.Channels$3.run(Channels.java:349) at org.jboss.netty.channel.socket.ChannelRunnableWrapper.run(ChannelRunnableWrapper.java:41) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.processEventQueue(AbstractNioWorker.java:373) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:254) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:35) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662) Connectable and writable are the same condition under the hood. Make sure you test connectable first and when it fires complete the connection and lose all interest in the connectable state/event if it succeeds. Don't register interest in writing until the connection completes. I added a test for `isConnected()` which fixed the problem. I guess I (wrongly) assumed that the channel can't be writable if it isn't connected. @Dev I'm not familiar with the Netty API but under the NIO hood you or it should have called `SocketChannel.finishConnect()` when `OP_CONNECT` fired and only registered `OP_WRITE` if `finishConnect()` returned true.
372,A,how to manage a prefixed byte sequence which identifies your protocol This is related to my question regarding the unification setup (port unification with persistent channel) I am attempting to send a two byte sequence prefixed to all traffic for my protocol; I am doing this so there is something to sniff in the unification handler when i update to support more than one protocol. On the client i have a simple outbound handler at the end of the pipeline that prefixes the ByteBuf with the two protocol identifying bytes and a simple inbound handler in the front of the server pipeline which will extract them. I've managed to get this working for small messages. The subsequent handler in the server queue is a LengthFieldBasedFrameDecoder which I'm using to frame in the incoming traffic (protobuf objects). What appears to be happening is the client sends a large request say 5M. I get a series of 64k buffers that come through the server pipeline the last one of which passes over the threshold the LengthFieldBasedFrameDecoder is waiting for it extracts the frame and passes it on for handling -- this happens correctly. At this point everything breaks. From what I can tell the last 64k buffer from the client contained the rest of the data for the frame the 2 byte sequence signaling the start of the next request and then some more content. I think this data is sitting in the frame decoder which now will use the two protocol magic bytes as the length of the next frame which is incorrect and things break down from there. The DelimiterBasedFrameDecoder looks like it would work in this case since that two byte sequence will break apart each logical frame/request but that seems like overkill in this scenario. Is there some other decoder that would work in this case or should I stick with the DelimiterBasedFrameDecoder? Usually when you are using a length field frame decoder it should be first in the pipeline unless you are also using SSL or compression handlers which will go before your frame handler. The easiest solution is just to put your protocol id handler after the frame handler instead of before. I take your point and while that might work in a single protocol setup that will fail when I include something based on the PortUnification example Netty provides. Then there's no way to tell if the first N bytes are the frame size or the protocol identifier.  The DelimiterBasedFrameDecoder is roughly what you want in this situation but it does not handle the delimiter being the front of the frame rather than the end so if you use it in this case it will basically eat your traffic. Using the indexOf method from DelimitedBasedFrameDecoder you can put together a very simple decoder to use on a server channel that will split incoming traffic by the delimiter sequence while eating the delimiter: public static final class DelimitingProtocolDecoder extends ByteToMessageDecoder { private final ByteBuf mDelimiter; public DelimitingProtocolDecoder(final ByteBuf theDelimiter) { mDelimiter = theDelimiter; } @Override protected void decode(final ChannelHandlerContext theContext final ByteBuf theInput final List<Object> theOutput) throws Exception { int aIndex = indexOf(theInput mDelimiter); while (aIndex != -1) { if (aIndex > 0) { ByteBuf aBuffer = theContext.alloc().buffer(aIndex aIndex); theInput.readBytes(aBuffer); theOutput.add(aBuffer); } theInput.skipBytes(mDelimiter.capacity()); aIndex = indexOf(theInput mDelimiter); } theOutput.add(theInput.readBytes(theInput.readableBytes())); } }  If you look through the documentation for LengthFieldBasedFrameDecoder there is a great example of how to do just what you are trying to do. The fourth example has a fixed width header in front of the length field and it configures the FrameDecoder not to strip any of the header info. EDIT For your server the LengthFieldBasedFrameDecoder should come first then your handler that checks the header can remove the header and length fields and pass the data on accordingly. On the client side you can use a LengthFieldPrepender then add an additional handler after that to prepend your header data. Ah yep. Didnt look closely enough at the docs that's precisely what I wanted and works the same as the approach I mentioned in my answer. This is definitely the right way to go thanks
373,A,"Safe way to encrypt a network application Alright I'd like to know my current way to encrypt a network connection(will be explained in the next few lines) is safe and efficient. Also I'm trying to keep in mind that I want to use as less bytes(to transfer) as possible as this might be used for Android. My current way is by using the two encryption methods: RSA(keysize= 512) and AES(keysize= 128) What I did is: Server generates an RSA Public Key and a Private Key. When a client connects the server sends the Public RSA Key to the client. The client generates an AES Key and encrypts the AES Key using the public RSA Key provided by the server. The client sends his encrypted AES Key and the server decrypts the encrypted AES Key using the Private RSA Key. Now if I am correct it's impossible to sniff any packets from the client side as you can't possibly decrypt the AES Key(no private key). Is this a secure way? Or is there some sort of backdoor somewhere? This isn't my only question though; Because my application is built in Java it's always possible to reverse engineer it. Since the client generates the AES Key and saves it in memory is it possible to get hold of the AES Key? Final question: It takes me around 300ms to generate a keypair using this code: I'd like your people's opinions and/or improvements. private RSAKeySet(RSAPublicKey publicKey PrivateKey privateKey) { this.publicKey = publicKey; this.privateKey = privateKey; byte[] mod = publicKey.getModulus().toByteArray(); byte[] exp = publicKey.getPublicExponent().toByteArray(); localPublicKeySpec = ByteBuffer.allocate(mod.length + exp.length + 8); localPublicKeySpec.putInt(mod.length); localPublicKeySpec.put(mod); localPublicKeySpec.putInt(exp.length); localPublicKeySpec.put(exp); localPublicKeySpec.flip(); } public static final RSAKeySet generateKeys(int keySize) throws GeneralSecurityException { RSAKeySet set; long start = System.currentTimeMillis(); KeyPairGenerator kpg = KeyPairGenerator.getInstance(""RSA""); kpg.initialize(keySize); KeyPair kp = kpg.genKeyPair(); set = new RSAKeySet((RSAPublicKey) kp.getPublic() kp.getPrivate()); System.err.println(""RSA keys generated ("" + (System.currentTimeMillis() - start) + ""ms)""); return set; } I'm using Netty is 300ms affordable? Thanks in advance. No this isn't secure - your scheme is broken at step #1 as you have no way to guarantee that the public key you receive was generated by the server or by a man-in-the-middle intercepting traffic and either eavesdropping or altering the data before sending it on to the real server. The second problem is that a 512 bit RSA key is far too small to be secure. A single modern desktop PC can factor such a key in less than a month and with multiple machines could probably be brought down to days/hours. Whilst you're generating a new key each time someone could still easily record traffic and then factor the keys offline if they only needed to eavesdrop the connection. With regards accessing the AES key in-memory yes that's entirely possible however anyone with access to the client process' memory also has access to the plaintext data prior to it being encrypted at all. This is something that's going to be an issue regardless the particular encryption method used though ensuring that the keys do not persist in memory beyond their period of use will limit the period during which such an attack is possible. This is however somewhat more difficult to achieve in something like Java where the GC could move data around and leave multiple copies of a key in memory even if you zero the key data after use. In summary I'd strongly suggest that you don't try and invent your own crypto scheme but instead use an existing well established and proven scheme such as SSL. My expertise isn't Java but I would be pretty certain that the means to establish an SSL session exists within the API. Thanks opened my eyes. I'd vote up but I don't have enough reputation."
374,A,"How could I display the asynchronous result in HTML page through a HTTP request? I am developing an analysis system based on netty version 4 and a web client application based on tomcat. The web app accepts user's input then send it to analysis machine. Finally prints the response in the HTML page. This is code in a servlet of sending user's input to analysis node : protected void doGet(HttpServletRequest request HttpServletResponse response) throws ServletException IOException { String input = request.getParameter(""input""); Channel ch = pool.borrowObject(); Protocol.Builder builder = Protocol.newBuilder().setInput(input); ch.writeAndFlush(builder.build()); } Netty works asynchronously so the http request ends after sending. This is code in response handler: @Override protected void channelRead0(ChannelHandlerContext ctx Protocol response) throws Exception { pool.returnObject(ctx.channel()); //How could I code here to display response to the HTML page that user requested? } I have been struggling here for some weeks. I tried to use a public thead-safe queue to make http request waiting there until got the response from queue. But that made the whole request become synchronous. Could anyone tell how to do on this ? Many thanks! Twitter's Finagle is wrapper for netty that does this (and more). Most of the examples for writing finagle clients are in scala but I know it can be used with java too. You can get started here: https://blog.twitter.com/2011/finagle-protocol-agnostic-rpc-system @norman-maurer Could you please take a look at this if you have time ? Much appreciated. Thanks. I will take a look. Here is an example of using Finagle to write a Java Server: https://github.com/toulouse/finagle-java-test/blob/master/src/main/java/se/atoulou/www/Main.java I assume the Java Client is simlar. Thanks @eSniff The issue here is that the default servlet request lifecycle is synchronous. The only way you're going to solve this within a servlet container is to make use of servlet 3.0 asynchronous request processing. This way you can pass the request to Netty and return then write the response asynchronously when it arrives. Some links to help you get started Java Servlet 3.0 Asynchronous Support How To Use Asynchronous Servlets To Improve Performance Thanks! You pointed me the correct way to do this."
375,A,"What events do I need to listen to in order to reuse a client connection in Netty (getting ""Connection reset by peer"")? I'm getting java.io.IOException: Connection reset by peer when I try to reuse a client connection in Netty (this does not happen if I send one request but happens every time if I send two requests even from a single thread). My current approach involves the following implementing a simple ChannelPool whose code is below. Note that the key method obtains a free channel from the freeChannels member or creates a new channel if none are available. The method returnChannel() is the method responsible for freeing up a channel when we are done with the request. It is called inside the pipeline after we process the response (see messageReceived() method of ResponseHandler in the code below). Does anyone see what I'm doing wrong and why I'm getting an exception? Channel pool code (note use of freeChannels.pollFirst() to get a free channel that has been returned via a call to returnChannel()): public class ChannelPool { private final ClientBootstrap cb; private Deque<Channel> freeChannels = new ArrayDeque<Channel>(); private static Map<Channel Channel> proxyToClient = new ConcurrentHashMap<Channel Channel>(); public ChannelPool(InetSocketAddress address ChannelPipelineFactory pipelineFactory) { ChannelFactory clientFactory = new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); cb = new ClientBootstrap(clientFactory); cb.setPipelineFactory(pipelineFactory); } private void writeToNewChannel(final Object writable Channel clientChannel) { ChannelFuture cf; synchronized (cb) { cf = cb.connect(new InetSocketAddress(""localhost"" 18080)); } final Channel ch = cf.getChannel(); proxyToClient.put(ch clientChannel); cf.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture arg0) throws Exception { System.out.println(""channel open writing: "" + ch); ch.write(writable); } }); } public void executeWrite(Object writable Channel clientChannel) { synchronized (freeChannels) { while (!freeChannels.isEmpty()) { Channel ch = freeChannels.pollFirst(); System.out.println(""trying to reuse channel: "" + ch + "" "" + ch.isOpen()); if (ch.isOpen()) { proxyToClient.put(ch clientChannel); ch.write(writable).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture cf) throws Exception { System.out.println(""write from reused channel complete success? "" + cf.isSuccess()); } }); // EDIT: I needed a return here } } } writeToNewChannel(writable clientChannel); } public void returnChannel(Channel ch) { synchronized (freeChannels) { freeChannels.addLast(ch); } } public Channel getClientChannel(Channel proxyChannel) { return proxyToClient.get(proxyChannel); } } Netty pipeline code (Note that RequestHandler calls executeWrite() which uses either a new or an old channel and ResponseHandler calls returnChannel() after the response is received and the content is set in the response to the client): public class NettyExample { private static ChannelPool pool; public static void main(String[] args) throws Exception { pool = new ChannelPool( new InetSocketAddress(""localhost"" 18080) new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline( new HttpRequestEncoder() new HttpResponseDecoder() new ResponseHandler()); } }); ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); ServerBootstrap sb = new ServerBootstrap(factory); sb.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline( new HttpRequestDecoder() new HttpResponseEncoder() new RequestHandler()); } }); sb.setOption(""child.tcpNoDelay"" true); sb.setOption(""child.keepAlive"" true); sb.bind(new InetSocketAddress(2080)); } private static class ResponseHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) { final HttpResponse proxyResponse = (HttpResponse) e.getMessage(); final Channel proxyChannel = e.getChannel(); Channel clientChannel = pool.getClientChannel(proxyChannel); HttpResponse clientResponse = new DefaultHttpResponse(HttpVersion.HTTP_1_1 HttpResponseStatus.OK); clientResponse.setHeader(HttpHeaders.Names.CONTENT_TYPE ""text/html; charset=UTF-8""); HttpHeaders.setContentLength(clientResponse proxyResponse.getContent().readableBytes()); clientResponse.setContent(proxyResponse.getContent()); pool.returnChannel(proxyChannel); clientChannel.write(clientResponse); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { e.getCause().printStackTrace(); Channel ch = e.getChannel(); ch.close(); } } private static class RequestHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) { final HttpRequest request = (HttpRequest) e.getMessage(); pool.executeWrite(request e.getChannel()); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { e.getCause().printStackTrace(); Channel ch = e.getChannel(); ch.close(); } } } EDIT: To give more detail I've written a trace of what's happening on the proxy connection. Note that the following involves two serial requests performed by a synchronous apache commons client. The first request uses a new channel and completes fine and the second request attempts to reuse the same channel which is open and writable but inexplicably fails (I've not been able to intercept any problem other than noticing the exception thrown from the worker thread). Evidently the second request completes successfully when a retry is made. Many seconds after both requests complete both connections finally close (i.e. even if the connection were closed by the peer this is not reflected by any event I've intercepted): channel open: [id: 0x6e6fbedf] channel connect requested: [id: 0x6e6fbedf] channel open writing: [id: 0x6e6fbedf /127.0.0.1:47031 => localhost/127.0.0.1:18080] channel connected: [id: 0x6e6fbedf /127.0.0.1:47031 => localhost/127.0.0.1:18080] trying to reuse channel: [id: 0x6e6fbedf /127.0.0.1:47031 => localhost/127.0.0.1:18080] true channel open: [id: 0x3999abd1] channel connect requested: [id: 0x3999abd1] channel open writing: [id: 0x3999abd1 /127.0.0.1:47032 => localhost/127.0.0.1:18080] channel connected: [id: 0x3999abd1 /127.0.0.1:47032 => localhost/127.0.0.1:18080] java.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:218) at sun.nio.ch.IOUtil.read(IOUtil.java:186) at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:63) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.processSelectedKeys(AbstractNioWorker.java:373) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:247) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:35) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) Finally figured this out. There were two issues causing a connection reset. First I was not calling releaseConnection() from the apache commons HttpClient that was sending requests to the proxy (see the follow up question). Second executeWrite was twice issuing the same call to the proxied server in the case the connection was reused. I needed to return after the first write rather than continuing with the while loop. The result of this double proxy call was that I was issuing duplicate responses to the original client mangling the connection with the client."
376,A,JBoss Netty framework HTTP website Hello everybody I'm trying to make my own web site with framework JBoss Netty server starts OK. But how I can load my website to server? For example i all ready have index.html what I must do to see this page on server ? Take a look at webbit on github they are doing this You should head over to the examples page and look at both the HTTP (Snoop) and the HTTP (File Server) samples. The second one will actually server static pages which is what you're after if I understand your question correctly. Thank you ill check examples again
377,A,"Netty problems with custom handler for HTTP PUT requests ""cannot send more responses than requests"" I am working on a Netty server I am having issues with a custom handler I created to receive file uploads via HTTP PUT requests. Everything seems to work fine when I just send a few files at a time however after about 300 connections the server seems to ""break"". The server will then throw the follow exception on each received request. After this starts happening the server no longer handles the requests and needs to be restarted:  java.lang.IllegalStateException: cannot send more responses than requests at org.jboss.netty.handler.codec.http.HttpContentEncoder.writeRequested(HttpContentEncoder.java:104) at org.jboss.netty.handler.execution.ExecutionHandler.handleDownstream(ExecutionHandler.java:165) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) .... Here is my handler source channelRecieved all the requests i'm handling are chunked so I will include those methods below: @Override public void messageReceived(ChannelHandlerContext context MessageEvent event) throws Exception { try { log.trace(""Message recieved""); if (newMessage) { log.trace(""New message""); HttpRequest request = (HttpRequest) event.getMessage(); setDestinationFile(context request); newMessage = false; if (request.isChunked()) { log.trace(""Chunked request set readingChunks true and create byte buffer""); requestContentStream = new ByteArrayOutputStream(); readingChunks = true; return; } else { log.trace(""Request not chunked""); writeNonChunkedFile(request); requestComplete(event); return; } } else if (readingChunks){ log.trace(""Reading chunks""); HttpChunk chunk = (HttpChunk) event.getMessage(); if (chunk.isLast()) { log.trace(""Read last chunk""); readingChunks = false; writeChunkedFile(); requestComplete(event); return; } else { log.trace(""Buffering chunk content to byte buffer""); requestContentStream.write(chunk.getContent().array()); return; } // should not happen } else { log.error(""Error handling of MessageEvent expecting a new message or a chunk from a previous message""); } } catch (Exception ex) { log.error(""Exception: ["" + ex + ""]""); sendError(context INTERNAL_SERVER_ERROR); } } This is how I am writing the chunked requests: private void writeChunkedFile() throws IOException { log.trace(""Writing chunked file""); byte[] data = requestContentStream.toByteArray(); FileOutputStream fos = new FileOutputStream(destinationFile); fos.write(data); fos.close(); log.debug(""File upload complete [chunked] path: ["" + destinationFile.getAbsolutePath() + ""] size: ["" + destinationFile.length() + ""] bytes""); } This is how I send the response and close the connection: private void requestComplete(MessageEvent event) { log.trace(""Request complete""); HttpResponse response = new DefaultHttpResponse(HTTP_1_1 OK); Channel channel = event.getChannel(); ChannelFuture cf = channel.write(response); cf.addListener(ChannelFutureListener.CLOSE); } I have tried a few things in requestComplete one being just channel.close() which didn't seem to help. Any other thoughts or ideas? Here is my pipeline: @Override public ChannelPipeline getPipeline() throws Exception { final ChannelPipeline pipeline = pipeline(); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""deflater"" new HttpContentCompressor()); pipeline.addLast(""ExecutionHandler"" executionHandler); pipeline.addLast(""handler"" new FileUploadHandler()); return pipeline; } Thanks for any thoughts or ideas Edit: sample log entry when logging between deflator and handler in pipeline: 2012-03-23T07:46:40.993 [New I/O server worker #1-6] WARN NbEvents [c.c.c.r.d.l.s.h.SbApiMessageLogger.writeRequested] [] - Sending [DefaultHttpResponse(chunked: false) HTTP/1.1 100 Continue] 2012-03-23T07:46:40.995 [New I/O server worker #1-6] WARN NbEvents [c.c.c.r.d.l.s.h.SbApiMessageLogger.writeRequested] [] - Sending [DefaultHttpResponse(chunked: false) HTTP/1.1 500 Internal Server Error Content-Type: text/plain; charset=UTF-8] 2012-03-23T07:46:41.000 [New I/O server worker #1-7] DEBUG NbEvents [c.c.c.r.d.l.s.h.SbApiMessageLogger.messageReceived] [] - Received [PUT /a/deeper/path/testFile.txt HTTP/1.1 User-Agent: curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.12.9.0 zlib/1.2.3 libidn/1.18 libssh2/1.2.2 Host: 192.168.0.1:8080 Accept: */* Content-Length: 256000 Expect: 100-continue Somethin not related to the problem but adding the ExectionHandler at the end of the ChannelPipeline does not give you any advances. The ExecutionHandler will only work for the ChannelHandlers that are behind it in the ChannelPipeline How do you add the HttpContentEncoder to the ChannelPipeline ? I don't see it in your code ? Do you share an instance by any chance ? Thanks I updated my pipline so that pipeline.addLast(""handler"" new FileUploadHandler()); comes after the executionHandler. As for the HttpContentEncoder I am not using that anywhere in my code do I need to be? I thought response encoding was handled by HttpResponseEncoder(). I also tried adding pipeline.addLast(""chunkedWriter"" new ChunkedWriteHandler());. I still have the same problem using the ChunkedWriteHandler however the exception on the server is now different: java.nio.channels.ClosedChannelException at org.jboss.netty.handler.stream.ChunkedWriteHandler.discard(ChunkedWriteHandler.java:171) HttpContentCompressor is a sub class of HttpContentEncoder thats how HttpContentEncoder was added to the pipeline? HttpContentEncoder has state which only allows to send one response for one request received (HTTP_CONTINUE is excluded) any handler is sending more than one response for a request at a time? What executionHandler does in the pipeline? I would simply add a org.jboss.netty.handler.logging.LoggingHander in between deflater and executionhandler to find out what HttpResponse is causing this exception. Thanks Jestan I don't think any handler is sending more than one response if it is it's not my intention. I am only using what's defined above in the pipeline my custom handler FileUploadHandler does send a response but it should only be happening when the request has completed (see method requestComplete in above example). Also I did NOT have handling for HTTP CONTINUE in any of my code I did try adding htat into my handler using is 100ContinueExpected and then sending back a continue but that seemed to create more problems. With a continue response I cant even upload 1 file I added a logging handler between deflator and the execution handler it shows me the log message. I added a sample entry from the log above This ended up being a problem with my implementation not related to any of the code posted here the logic posted here seems sound and works fine. That said many thanks to all for the helpful comments! It would be helpful to others seeing the same error to post something about what problem you discovered w/ your implementation."
378,A,Netty 4 headers: Should I use static methods or instance methods? http://netty.io/4.0/api/io/netty/handler/codec/http/HttpHeaders.html Netty 4 now has both static methods or instance methods to manipulate headers. For example: HttpHeaders#get and HttpHeaders.getHeader. As I remember the static methods have just been added recently. Is that true that from now on I should use the static methods because they are faster and the instance methods will be deprecated in the future? The static methods are there for a long time. So it not matter what you use.
379,A,"how is HawtDispatch different from Java's Executors? (and netty) Frustratingly HawtDispatch's website describes it as ""thread pooling and NIO event notification framework API."" Let's take the 'thread pooling' part first. Most of the Executors provided by Java are also basically thread pools. How is HawtDispatch different? It is also apparently an ""NIO event notification framework API."" I'm assuming it is a thin layer on top NIO which takes incoming data and passes to its notion of 'thread pool' and passes it to a consumer when the thread pool scheduler finds the time. Correct? (Any improvement over NIO is welcomed). Has anyone done any performance analysis of netty vs HD? HawtDispatch is designed to be a single system wide fixed size thread pool. It provides implements 2 flavors of Java Executors: Global Dispatch Queue: Submitted Runnable objects are executed concurrently (You get the same effect using a Executors.newFixedThreadPool(n) executor) Serial Dispatch Queue: Submitted Runnable objects are executed serially (You get the same effect using a Executors.newSingleThreadExecutor() executor) Unlike the java executor model all global and serial dispatch queues share a single fixed size thread pool. You can use thousands of serial dispatch queues without increasing your thread count. Serial dispatch queues can be used like Erlang mailboxes to drive reactive actor style applications. Since HawtDispatch is using a fixed size thread pool for processing all global and serial queue executions all Runnable tasks it executes must be non-blocking. In a way this is similar to the NodeJS architecture except it using multiple threads instead of just one. In comparison to Netty HawtDispatch is not a framework for actually processing socket data. It does not provide a framework for how encode/decode buffer and process the socket data. All it does is execute a user configured Runnable when data can be read or written on the non-blocking socket. It's up to you application then to actually read/write the socket data. Thanks @Hiram. I hope you expand expand the HawtDispatch documentation a bit to introduce it to those who don't know anything about Apple's libdispatch. Frankly this description is a good start. Perhaps something which expands on the benefits of HD over just using Executors."
380,A,using netty HttpObjectDecoder with DatagramPacket to decode SSDP message The SSDP protocol is an HTTP like protocol over UDP. I was hoping to use the netty HttpObjectDecoder / FullHttpRequest/Response classes to process it. Is there a way to put the MessagetoMessageDecoder for decoding UDP DatagramPackets into the pipeline so that the ByteBuf style TCP type decoders can use it or will I need to write a new stack that mirrors the netty Http classes? You can do by using EmbeddedChannel in your own handler. We plan to make this easier with a decorator in the future but this was not done yet[1]. [1] https://github.com/netty/netty/issues/1350 Please share your code. I'm doing something obvious but can't work it out. The EmbeddedChannel is getting the ByteBuf but it firing ChannelReadComplete instead of MessageReceived (i'm using the 5.0 API). Thanks Norman that's where I got to this morning as well (chapter 10 made it easy - I can see me using the LogHandler and the EmbeddedChannel all the time now) i'm creating a small decoder for UDP and putting the other handlers in the embedded channel and firing the bytes in (i'm calling it a message to stream bridge). Thanks for the response.
381,A,Netty/mina cooperation. Is it possible to wrap netty's ChannelBuffer to MINA's IOBuffer? Idea is to integrate apache vysper to existing netty application. Is it possible to ChannelBuffer from client being connected to netty as mina'a ChannelBuffer so it could be deligated to the vysper? Idea is to make custom netty based endpoint for apache vysper obtain ChanellBuffer and pass it to vysper. Apache Vysper uses MINA an non-blocking I/O-Framework similar to netty. When I designed Vysper I tried not to couple MINA too tightly to the rest of Vysper. So in theory it should be possible to replace MINA with netty if you want to go that route. Looking at the source code you'd need to port all the functionality from package https://svn.apache.org/repos/asf/mina/vysper/trunk/server/core/src/main/java/org/apache/vysper/mina to netty and replace it's usages. It's do-able but requires some work. Additionally Vypser uses XMPP as a protocol which is based on/is a subset of XML. Vysper uses a non-blocking XML parser 'nbxml' which is a subproject of Vysper. (https://svn.apache.org/repos/asf/mina/vysper/trunk/nbxml) You'd need to replace this with a netty version of nbxml too. On the Vysper mailing list at dev@mina.apache.org I'd be able to help you with this in detail. Another route would be to use netty endpoints and - as Norman suggested - somehow pass the buffers to Vysper/MINA. This sounds like an elegant approach but I doubt it is more feasible than the previous approach. I don't know if netty has a non-blocking XML parser that matches Vysper's needs. It probably would require some ugly stunts to wrap netty around MINA. A last advice would be to use Vypser as-is. MINA didn't receive as much love over the last years as netty but it is a non-blocking IO-framework too. If you really are stuck to netty consider using it as a proxy having netty at one endpoint and Vysper/MINA at another and just route bytes you receive at the netty endpoint through to Vysper/MINA.  I guess you could just write your own impl that wraps it. Or use the backed bytearray and wrap this.
382,A,"Wrong encoding when running from JAR from Eclipse works perfectly I am facing the problem similar to How to Force a jar to uses(or the jvm runs in) utf-8 instead of the system's default encoding. There is a server and client java applications. If I run both of them from Eclipse then everything works just fine. If I make jars then a String exchanged between them gets spoiled (wrong encoding). If I run both images with -Dfile.enconding=utf-8 JVM parameter then it works okay. But since the link above says that it is not the best solution (at least requires running jar from bat) I have tried to solve the issue with specifying encoding to BufferedReader. But it fails and with jar it is difficult to debug. This code is for sending request and getting one line in JSON format as reply. The reply is proved to have UTF-8 encoding. public static String sendRequest (String request) { if (request == null) return null; try { URL url = new URL(request); HttpsURLConnection con = (HttpsURLConnection)url.openConnection(); BufferedReader inReader = new BufferedReader(new InputStreamReader(con.getInputStream() Charset.forName(""UTF-8""))); String line = inReader.readLine(); inReader.close(); return line; } catch (Exception e) { e.printStackTrace(System.err); } return null; } This is how the line look like {""response"":[{""uid"":123456""first_name"":""Имя""""last_name"":""Фамилия""}]} Then I prepare it to use in Gson.fromJson() int beginIndex = reply.indexOf('['); int endIndex = reply.indexOf(']'); reply = reply.substring(beginIndex + 1 endIndex); SocialPerson vkPerson = new Gson().fromJson(reply SocialPerson.class); After that the String is being sent to server using Netty's ChannelBuffer generated with ChannelBuffers.wrappedBuffer() and NettyUtils.writeStrings() I try to debug Client in Eclipse and Server running from jar then Eclipse shows that until the string is really given to framework to deliver it looks valid. Then I debug Server and Client runs from Jar and once string being received it already looks like rubbish. At server side  private final String username; private final String password; public SimpleCredentials(ChannelBuffer buffer) { this.username = NettyUtils.readString(buffer); this.password = NettyUtils.readString(buffer); } Where do you think the problem can be? Sorry I can not post all the code here. UPD: username is generated from firstName and lastName ChannelBuffer buffer = ChannelBuffers.wrappedBuffer(opCode NettyUtils.writeStrings(userId userName refKey)); Can you show us the code that calls NettyUtils.writeStrings()? @Isaac I have put it in update. You shouldn't be using the file.encoding system property. The best way to avoid such encoding issues is to never assume anything about default platform encodings and always provide an encoding when constructing readers or when converting bytes to Strings and vice versa. Your sendRequest method seems to be OK with respect to handling encodings: it reads characters from the input explicitly mentioning that it expects the stream to be encoded in UTF-8. However we can't see the other end of the client/server sequence. Quoting you: After that the String is being sent to server using Netty's ChannelBuffer generated with ChannelBuffers.wrappedBuffer() and NettyUtils.writeStrings() You also mentioned that you can't attach the entire code here which is understandable; therefore I'd advise that you look into how exactly you're sending those strings out and whether or not you're explicitly specifying an encoding while doing so. EDIT as per OP's update: well I'm sorry that I am not familiar with Netty but still I'll take a shot here. Doesn't NettyUtils.writeStrings() or any of the code that calls it accept a character encoding? I can't find the JavaDoc to any NettyUtils online. Work with me here. :-) I has appeared to be not Netty thing but a class from person author of framework so I might need to contact him as well I agree. I looked at the code for `NettyUtils` and it ends up calling `StringEncoderWrapper` to actually do the serialization. I'm sure that it (or some code that ends up being called *by* it) ends up making assumptions about the default platform encoding. The problem is that framework above netty does the sending. [NettyUtils.java](https://github.com/menacher/java-game-server/blob/master/jetserver/src/main/java/org/menacheri/jetserver/util/NettyUtils.java)  When you read the network stream you need to reencode your strings manually if the automatically way fails. It is possible that the libiary which you are using is ignoring the content encoding or maybe it is missing in the HTTP-response. Somewhere in your code will be a byte array which you can convert in the String constructor: String xxx = new String(bytes ""utf-8""); If you get the String with the wrong encoding you can check this code: String rightEncoded = new String(wrongEncodedString.getBytes(""Cp1252"") ""utf-8""); [Default encoding in Java](http://stackoverflow.com/questions/1749064/how-to-find-default-charset-encoding-in-java) this sounds as question worth studying for me Maybe also a solution to force utf-8 to set as the default encoding: `System.setProperty(""file.encoding"" ""utf-8"");` Setting a system property programmatically will affect all code running within the same JVM which is hazardous especially when discussing such a low-level system property. @Isaac > Setting a system property programmatically will affect all code >running within the same JVM which is hazardous In my System it does not happen. I use `System.getProperty(""file.encoding"")` and it gives me cp1252 at startup even though before it was set to utf-8 by another instance of application. Who resets the file.encoding back to original value? I have tried that line (cp1251) in my case. I have applied it to server and it worked when both images run as jar. Then I have changed client to Eclipse and it started to fail. Because in this situation client sends UTF-8 and server tries to decode it as if it cp1251. Good point I didn't know that. Well I already get it as Strings from framework. Should I get bytes from String and construct a new String with specified encoding? Btw the downvote was not from me :) @NikolayKuznetsov I made an edit that should work. Can I get to know the encoding of the String I get? I am not sure it is cp1252 On a ninja googling I found that this encoding maybe the default encoding. If this doesn't work try some other like us-ascii or so. `System.out.println(name.getBytes().length + "" : "" + Arrays.toString(name.getBytes()));` gives me same result byte to byte before sending and at reception. That is perfect normal you need to set the codepages. See again my line above. My variable `wrongEncodedString` is in your case `name`."
383,A,"Netty : does it need to care TCP segments reassembly? I have a question regarding to TCP segments reassembly. I learned the packet could be devided into multiple segments (this is something to do with MSS). i.e) Message flow (Assumption): Client sends a packet that is passed from application layer In client side's TCP layer the packet divided into 3 segments. the segments passed to Client's IP layer. the Server's IP layer receives the segments. In server side's TCP layer it receives the 3 packets and reassembles it as one packet. Server's application layer receives the one packet. My understaning is that TCP layer is where the divided segments get reassembled. Correct me if I am wrong. Here is the thing what I really want to clarify. When using Netty Server side's ""messageReceived()"" method gets called only one time or 3 times? If the TCP layer is the place where the divided segments gets reassembled the ""messageReceived()"" method gets called only once correct? Then is it really neccesarry to use something like ""ReplayingDecoder"" to guarantee the number of bytes server is receiving? Your help is greatly appreciated. Additional Question: If the server fails to reassemble the segments because one of them is lost or something then the TCP layer pass the incomplete packet to the application layer? It *should* be. Remember that this should form a stack so layer 3 should be a black box (in reality it rarely is) with a sendData and recvData interface. Layer 4 should not care whatsoever how the data is split and transmitted (and equally layer 3 should be able to be seamlessly replaced with another similar block without any code changes). The OSI model is there such that each layer shouldn't need in-depth knowledge of other layers. @slugonamission The sliding window protocol is only weakly related to segment reassembly and not at all to packet reassembly and there is no guarantee whatsoever about how many reads will be necessary. I am currently creating the server side with Netty and wondering if I should handle the segment reassembly by myself by using ""ReplayingDecoder."" What I can not understand cleary is here http://static.netty.io/3.6/guide/#start.10 The case described in the documentation is.. it is trying to combine 2 separate messages (I assume they are 2 distinct messages passed from client's application layer). My original question is how I should handle when one message could be split in multiple segments. You can see the difference here. I should still use ""ReplayingDecoder"" to guarantee the msg size? It should get done in the TCP layer. Have a look at the sliding window protocol for more information on how this happens. @slugonamission Thank you. I had a weak understanding about the fact ""sliding window"" is used for the segment reassembly. So I can assume that Server side's ""messageReceived()"" method gets called only once? @M.I TCP takes care of TCP segmentation. That's nothing you need to worry about. However TCP does not present you the programmer with an interface to send packets. TCP gives you a byte stream much like a normal file. If your application sends packets/messages meaningful to your application you need some way to receive one full such message - and simply calling a receive function on a TCP socket might give you just 1 byte of data. Or 16kbyte of data (if your receive buffer is that big.) You need a way to carve your own messages out of that stream much as you would reading them from a file @nos Thank you so much for the clear explanation. So TCP takes care of the TCP segmentation then it passes the byte stream to the application. Now the programmer I need to explicitly prepare receive buffer size - and here we can find ""ReplayingDecoder"" is useful. I hope my understanding is correct finally.. the packet could be divided into multiple segments Upside down or bad terminology. TCP sends segments which are divided into packets and which may be further split into sub-packets en route. My understanding is that the TCP layer is where divided segments get reassembled. Packet reassembly takes places in the IP layer not the application (or the TCP layer). Segment reassembly takes place in the TCP layer. ""messageReceived()"" method gets called only one or 3 times? It gets called any number of times from 1 to N where N is the length of the byte stream. There is no guaranteed 1::1 correspondence between sender sends and receiver receives. If the server fails to reassemble the segments because one of them is lost or something then the TCP layer pass the incomplete packet to the application layer? Absolutely not. TCP doesn't pass packets to the application layer at all. It passes an intact correctly sequenced byte stream or nothing. Wondering if i should handle the segment reassembly by myself You don't and can't handle any of it yourself. TCP provides a byte stream to the application not segments or packets. Thank you so much for answering my questions one by one clearly. You help me understand what I should be aware of in order to proceed with solid TCP network programmming with Netty."
384,A,Parsing java InputStream which has several protobuf inside Format of incoming message 1st byte is fixed protobuf message in role of header (9 bytes) protobuf message in role of contents (4 bytes) I implement two protobuf messages in one network packet for flexibility. This is how I am trying to parse the message: ByteArrayInputStream is = new ByteArrayInputStream(buf.array()); System.out.println(is.available()); is.skip(1); System.out.println(is.available()); MessageHeader header = MessageHeader.parseFrom(is); System.out.println(is.available()); Output is 14 13 0 So the problem is that parseFrom tries to read the inputStream until the end and does not stop once first protobuf reading is done. What would be the best way to parse the message having this kind of format? When I write to and parse from now I use writeDelimitedTo and parseDelimitedFrom and it works.
385,A,"Keep client from closing connection to a netty server (is there something I need to set)? I'm debugging a problem with a netty proxy I'm writing and I've noticed that even if I skip the 'proxy' aspect and implement a simple http server and send two requests serially from a commons httpclient the commons httpclient closes the connection and the second request is made in a different connection. If I proxy the request on the other hand the second request uses the same connection but I get a 'connection reset' exception when I try to write the response to the second request to the client's channel. Code for my pipeline and basic handler:  ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); ServerBootstrap sb = new ServerBootstrap(factory); sb.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline( new HttpRequestDecoder() new HttpResponseEncoder() new RequestHandler()); } }); private static class RequestHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) { HttpResponse clientResponse = new DefaultHttpResponse(HttpVersion.HTTP_1_1 HttpResponseStatus.OK); clientResponse.setHeader(HttpHeaders.Names.CONTENT_TYPE ""text/html; charset=UTF-8""); clientResponse.setContent(ChannelBuffers.wrappedBuffer(new byte[] {1 2 3})); System.out.println(""here: "" + e.getChannel()); e.getChannel().write(clientResponse); } } Here is tcpdump on port 2080 showing the client closing the connection (open-handshake push push close-handshake open-handshake push push close-handshake): [master] sudo tcpdump -i any '(port 2080)' tcpdump: verbose output suppressed use -v or -vv for full protocol decode listening on any link-type LINUX_SLL (Linux cooked) capture size 65535 bytes 15:13:22.396482 IP localhost.localdomain.45724 > localhost.localdomain.autodesk-nlm: Flags [S] seq 3122841582 win 32792 options [mss 16396sackOKTS val 880723828 ecr 0nopwscale 7] length 0 15:13:22.396499 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.45724: Flags [S.] seq 604436385 ack 3122841583 win 32768 options [mss 16396sackOKTS val 880723829 ecr 880723828nopwscale 7] length 0 15:13:22.396511 IP localhost.localdomain.45724 > localhost.localdomain.autodesk-nlm: Flags [.] ack 1 win 257 options [nopnopTS val 880723829 ecr 880723829] length 0 15:13:22.406805 IP localhost.localdomain.45724 > localhost.localdomain.autodesk-nlm: Flags [P.] seq 1:1600 ack 1 win 257 options [nopnopTS val 880723839 ecr 880723829] length 1599 15:13:22.406817 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.45724: Flags [.] ack 1600 win 256 options [nopnopTS val 880723839 ecr 880723839] length 0 15:13:22.446068 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.45724: Flags [P.] seq 1:63 ack 1600 win 256 options [nopnopTS val 880723878 ecr 880723839] length 62 15:13:22.446083 IP localhost.localdomain.45724 > localhost.localdomain.autodesk-nlm: Flags [.] ack 63 win 257 options [nopnopTS val 880723878 ecr 880723878] length 0 15:13:22.449192 IP localhost.localdomain.45724 > localhost.localdomain.autodesk-nlm: Flags [F.] seq 1600 ack 63 win 257 options [nopnopTS val 880723881 ecr 880723878] length 0 15:13:22.449360 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.45724: Flags [F.] seq 63 ack 1601 win 256 options [nopnopTS val 880723881 ecr 880723881] length 0 15:13:22.449371 IP localhost.localdomain.45724 > localhost.localdomain.autodesk-nlm: Flags [.] ack 64 win 257 options [nopnopTS val 880723881 ecr 880723881] length 0 15:13:22.449716 IP localhost.localdomain.35737 > localhost.localdomain.autodesk-nlm: Flags [S] seq 929672323 win 32792 options [mss 16396sackOKTS val 880723882 ecr 0nopwscale 7] length 0 15:13:22.449729 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.35737: Flags [S.] seq 1626218986 ack 929672324 win 32768 options [mss 16396sackOKTS val 880723882 ecr 880723882nopwscale 7] length 0 15:13:22.449737 IP localhost.localdomain.35737 > localhost.localdomain.autodesk-nlm: Flags [.] ack 1 win 257 options [nopnopTS val 880723882 ecr 880723882] length 0 15:13:22.449986 IP localhost.localdomain.35737 > localhost.localdomain.autodesk-nlm: Flags [P.] seq 1:1600 ack 1 win 257 options [nopnopTS val 880723882 ecr 880723882] length 1599 15:13:22.449992 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.35737: Flags [.] ack 1600 win 256 options [nopnopTS val 880723882 ecr 880723882] length 0 15:13:22.453566 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.35737: Flags [P.] seq 1:63 ack 1600 win 256 options [nopnopTS val 880723886 ecr 880723882] length 62 15:13:22.453582 IP localhost.localdomain.35737 > localhost.localdomain.autodesk-nlm: Flags [.] ack 63 win 257 options [nopnopTS val 880723886 ecr 880723886] length 0 15:13:22.475867 IP localhost.localdomain.35737 > localhost.localdomain.autodesk-nlm: Flags [F.] seq 1600 ack 63 win 257 options [nopnopTS val 880723908 ecr 880723886] length 0 15:13:22.475998 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.35737: Flags [F.] seq 63 ack 1601 win 256 options [nopnopTS val 880723908 ecr 880723908] length 0 15:13:22.476012 IP localhost.localdomain.35737 > localhost.localdomain.autodesk-nlm: Flags [.] ack 64 win 257 options [nopnopTS val 880723908 ecr 880723908] length 0 Here is what happens if I use the proxy which essentially saves the channel from messageReceived() and looks up this channel a little later to write the response. Note that here the channel is not closed but is instead reset by the client leading to an IOException 'connection reset': [master] sudo tcpdump -i any '(port 2080)' tcpdump: verbose output suppressed use -v or -vv for full protocol decode listening on any link-type LINUX_SLL (Linux cooked) capture size 65535 bytes 15:11:02.055316 IP localhost.localdomain.58266 > localhost.localdomain.autodesk-nlm: Flags [S] seq 1055230627 win 32792 options [mss 16396sackOKTS val 880583487 ecr 0nopwscale 7] length 0 15:11:02.055333 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.58266: Flags [S.] seq 596566447 ack 1055230628 win 32768 options [mss 16396sackOKTS val 880583487 ecr 880583487nopwscale 7] length 0 15:11:02.055344 IP localhost.localdomain.58266 > localhost.localdomain.autodesk-nlm: Flags [.] ack 1 win 257 options [nopnopTS val 880583487 ecr 880583487] length 0 15:11:02.066169 IP localhost.localdomain.58266 > localhost.localdomain.autodesk-nlm: Flags [P.] seq 1:1600 ack 1 win 257 options [nopnopTS val 880583498 ecr 880583487] length 1599 15:11:02.066188 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.58266: Flags [.] ack 1600 win 256 options [nopnopTS val 880583498 ecr 880583498] length 0 15:11:02.071439 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.58266: Flags [P.] seq 1:1568 ack 1600 win 256 options [nopnopTS val 880583503 ecr 880583498] length 1567 15:11:02.071450 IP localhost.localdomain.58266 > localhost.localdomain.autodesk-nlm: Flags [.] ack 1568 win 256 options [nopnopTS val 880583503 ecr 880583503] length 0 15:11:02.076384 IP localhost.localdomain.58266 > localhost.localdomain.autodesk-nlm: Flags [P.] seq 1600:3199 ack 1568 win 256 options [nopnopTS val 880583508 ecr 880583503] length 1599 15:11:02.080625 IP localhost.localdomain.autodesk-nlm > localhost.localdomain.58266: Flags [P.] seq 1568:3135 ack 3199 win 256 options [nopnopTS val 880583513 ecr 880583508] length 1567 15:11:02.102018 IP localhost.localdomain.58266 > localhost.localdomain.autodesk-nlm: Flags [R.] seq 3199 ack 3135 win 256 options [nopnopTS val 880583534 ecr 880583513] length 0 Is there something I'm missing in my handler to keep the client from closing the connection? EDIT: Reading the response seems to cause the connection reset to go away and the connection to be torn down normally. Any idea why this println prevents the connection reset after the second request? httpClient.executeMethod(method); System.out.println(method.getResponseBodyAsString()); Your handler is sending a HTTP v1.1 response where keep-alive is the default connection type so as long as your client is expecting v1.1 and not v1.0 and behaves correctly then you shouldn't have to do anything more to indicate to the client to keep the connection open. If your client is expecting HTTP v1.0 you could add a ""Connection: keep-alive"" header. If keep alive were the problem wouldn't the client be sending a FIN instead of a RST?  Finally figured this out. There were a couple of issues. The most important issue was that I was not calling method.releaseConnection() from the commons HttpClient that initiated the call to this proxy. For some reason calling getResponseBodyAsString() or getResponseBodyAsStream.close() both eliminated the reset problem as well."
386,A,"Reusing routes for inbound/outbound communication I have the following two routes: Route 1 from(""netty:tcp://localhost:5050?textline=true&encoder=#customStringEncoder&decoder=#customDecoder"") .routeId(""inboundSocketRoute"") .doTry() .unmarshal(beanIO) .bean(inboundInterfaceProcessor ""processInterfaceData"") .doCatch(ValidationException.class UnidentifiedRecordException.class InvalidRecordException.class) .bean(inboundInterfaceProcessor ""processInterfaceDataError"") .end(); Route 2 String server = ""123.45.67.89:5050""; from(""jms://queue:evOutboundDataInterface"") .routeId(""outboundInterfaceRoute"") .doTry() .bean(outboundInterfaceProcessor ""processOutboundData"") .to(""netty:tcp://"" + server + ""?textline=true&requestTimeout=10000&encoder=#customStringEncoder&decoder=#customDecoder"") .bean(outboundInterfaceProcessor ""processSequence"") .doCatch(ReadTimeoutException.class) .bean(outboundInterfaceProcessor ""handleTimeout"") .doCatch(ConnectException.class) .bean(outboundInterfaceProcessor ""handleConnectionError"") .end(); Route 1 is triggered by incoming data from an external server. The incoming data is parsed by BeanIO and eventually ends up in my InterfaceProcessor which treats inbound data. Route 2 is triggered by a JMS message (which is sent by my software) and it should send a message back to the external server on the same port. In my current setup I start my own server (route 1) and client (route 2). I don't think this will work as both connections are always active. This way when I want to send a message to the external server from route 2 it probably won't be able to connect to the external server. However when I receive a message on route 1 I am able to send a message back to the external server (from within the processor that is bound to that route) by having inboundInterfaceProcessor.processInterfaceData() return the String that will be sent to the external server. Because I'm able to send a message back to the external server from route 1 I'm thinking about triggering inboundInterfaceProcessor from outboundInterfaceProcessor to send a message to the external server from route 2. How should I do this? Is this even possible with Camel/Netty? Or should I use another approach to this problem? I solved this by having the external server poll for data that would normally be sent through the second route. Every message is answered with an acknowledge message so when this acknowledgement is received by the inbound interface I can check for more outgoing interface data. It isn't ideal but it works. :)"
387,A,"MVC front-end for netty client I've adapted the Quote Of The Moment (QOTM) a bit and would like to build a GUI front-end. It's simple enough to pass objects from the DatagramClientHandler to the GUI. However it seems intractable for the GUI to reference the handler. The QuotesGUI class extends JFrame to take advantage of the Netbeans drag-and-drop palette to add Swing components easily. It's quite verbose. Apparently the solution is to: Well It depends as there are more then one solution. One could be to inject a listener to the ChannelHandler which then will get notified once the message was received. An other solution could be to send events to a topic once a message was received and register the interested swing parts on the topic so they get notified. http://stackoverflow.com/a/8780410/262852 DatagramClientHandler: package net.bounceme.dur.netty; import io.netty.buffer.Unpooled; import io.netty.channel.Channel; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.channel.socket.DatagramPacket; import io.netty.util.CharsetUtil; import java.net.InetSocketAddress; import java.util.logging.Logger; import net.bounceme.dur.client.gui.QuotesGUI; public class DatagramClientHandler extends SimpleChannelInboundHandler<DatagramPacket> { private static final Logger log = Logger.getLogger(DatagramClientHandler.class.getName()); private final QuotesGUI gui = new QuotesGUI(); private volatile Channel channel = null; DatagramClientHandler() { log.info(""starting..""); gui.setVisible(true); } private DatagramPacket getNext() { DatagramPacket packet = new DatagramPacket( Unpooled.copiedBuffer(""QOTM?"" CharsetUtil.UTF_8) new InetSocketAddress(""localhost"" 4454)); return packet; } @Override public void channelRead0(ChannelHandlerContext ctx DatagramPacket msg) throws Exception { String response = msg.content().toString(CharsetUtil.UTF_8); log.info(response); gui.setQuote(response); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { log.severe(cause.toString()); ctx.close(); } } sample method from the GUI. public void setQuote(String packet) { text.setText(packet); } Separate your layers the GUI should have no (real) knowledge of the handler. It also employes that you breaching the single thread rules of Swing (updating the UI from outside the context of the EDT). Instead you could set up a listener `interface` which can respond to changes in the handler and make appropriate changes. This could also be backed with a `SwingWorker` which would allow the handler to work in a separate thread but provides methods by which the UI can be updated/notified safely... @MadProgrammer yes that's my question. Just in pseudo code would you elaborate? Of course I would like to separate the layers -- I just don't know how. Start by separating your layers of responsibilities... I would probably start by defining some kind of listener interface which can registered with an instance of DatagramClientHandler. This interface would allow interested parties to be notified of changes or events within DatagramClientHandler and deal with those events as they see fit... public interface MessageListener { public void quoteRecieved(SimpleChannelInboundHandler source String quote); public void errorOccured(SimpleChannelInboundHandler source Throwable cause); } Then you would need to provide support for the listener... public class DatagramClientHandler extends SimpleChannelInboundHandler<DatagramPacket> { private static final Logger log = Logger.getLogger(DatagramClientHandler.class.getName()); //private final QuotesGUI gui = new QuotesGUI(); private volatile Channel channel = null; private List<MessageListener> listeners; DatagramClientHandler() { listeners = new ArrayList<MessageListener>(25); //... } public synchronized void addMessageListener(MessageListener listener) { listeners.add(listener); } public synchronized void removeMessageListener(MessageListener listener) { listeners.remove(listener); } protected synchronized void fireQuoteRecieved(String quote) { for (MessageListener listener : listeners) { listener.quoteRecieved(this quote); } } @Override public void channelRead0(ChannelHandlerContext ctx DatagramPacket msg) throws Exception { String response = msg.content().toString(CharsetUtil.UTF_8); log.info(response); fireQuoteRecieved(response); } //...etc... Now when you want to receive notifications you would register an instance of MessageListener with an instance of DatagramClientHandler... The problem you will have is ensuring that any updates you make to the UI are carried out in the EDT correctly... //... public void quoteRecieved(SimpleChannelInboundHandler source final String quote) { SwingUtilities.invokeLater(new Runnable() { public void run() { text.setText(packet); } }); } Now if you really wanted to you could further decouple the code with another interface... public interface QuoteFactory { public synchronized void addMessageListener(MessageListener listener); public synchronized void removeMessageListener(MessageListener listener); } This would then be implemented by DatagramClientHandler and you UI would require an instance of QuoteFactory to be passed to it so that it could register interest in been notified when something happens..."
388,A,In what order are Netty handlers called? I am new to Netty and a little confused about ChannelPipelines. The concept looks rather elegant but I am struggling with two points: How is the order of handler calls defined? How does the framework handle upstream sends to a encoder? or downstream sends to an decoder? Do they just get passed along? Can they even occur? 1) The handlers are called like this: upstream => from the first to the last downstream => from the last to the first 2) upstream is never passed to an encoder and downstream never to a decoder Thanks for that. So should my 'business logic' generally be the final handler in the list?
389,A,"What Channel handlers to use to send custom Java objects via Netty 4? So I am just getting started with Netty 4 and I am trying to pass a message from a client to the server and back. I had initially tried sending only Strings and my server's initChannel() method was defined as below: public class Initializer extends ChannelInitializer<SocketChannel> { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(""stringEncoder"" new StringEncoder(CharsetUtil.UTF_8)); ch.pipeline().addLast(""stringDecoder"" new StringDecoder(CharsetUtil.UTF_8)); ch.pipeline().addLast(""chatHandler"" new Handler()); } } The Handler class contains the channelRead() etc. event-handlers. Now I want to extend this so as to send custom objects instead of Strings. In that case what should be the best way to go about it? What encoders and decoders in netty can I use to extend them to achieve my purpose? Ideally what I should be looking for are ChannelHandlers that can convert from custom object type to ByteBuf and vice-versa right? Or am I missing something? Thanks in advance. You should use your own decoder/encoder implementation for that. Alternative you could use either the protobuf support or the codec that uses java serialization / jboss marshalling for that."
390,A,"How can I get the Client Certificate in Netty Handler to identify user? I am successfully running Netty with 2-way SSL (see Set up Netty with 2-way SSL Handsake (client and server certificate)). However in some of my handlers I need to know about the user who is using the application. I find that I can't figure out how to get information like the user certificate DN in my handlers. I would think it would be available in the ChannelHandlerContext somewhere but it is not. Any suggestions? I know the SSLEngine has access to it somewhere but I don't see anything about obtaining access in the SSLEngine public API. I know it has access in the handshake operation.... but how do I get it? SSLEngine.getSession().getPeerCertificateChain(). The zeroth entry is the peer's own certificate. This did indeed solve the problem. Thank you! Play! Framework uses netty in its background and I want the SSL client certificate how could I get the current SSLEngine??  The SSLEngine can be fetched through the Pipline/ChannelHandlerContext ChannelHandlerContext ctx = ... SslHandler sslhandler = (SslHandler) ctx.channel().pipeline().get(""ssl""); sslhandler.engine().getSession().getPeerCertificateChain()[0].getSubjectDN()); This allows you to get the certificates in the Handler Objects. Pay attention that the SSL-Handshake needs to be finished when you do this. Otherwise you will get a javax.net.ssl.SSLPeerUnverifiedException: peer not authenticated exception. To avoid this you can listen for a userEvent (in our case HandshakeCompletionEvent) in the handler which could look the following: @Override public void userEventTriggered(ChannelHandlerContext ctx Object evt) { logger.info(""userEventTriggered: {0} Class: {1}"" evt.toString() evt.getClass()); if (evt instanceof HandshakeCompletionEvent) { fetchCertificate(ctx); } }"
391,A,Can i overwrite the remoteAddress as provided by the Channel in Netty 4? Im implementing a Proxy Protocol decoder in Netty 4. This protocol allows an external proxy (in this case HAProxy) to provide remote address details to an internal server behind the proxy server. To include this in my pipeline i need to override the SocketAddress provided by the Netty Channel. I guess i could just put the address provided by Proxy Protocol on the channel as an attribute but id prefer to keep the decoder non-specific to my application if possible and just update the remoteAddress directly on the channel. any ideas? As Norman mentioned it's currently impossible. However there's an ongoing discussion on how we have to implement proxy support seamlessly. Exposing the backend remote address is also one of the questions we have to answer for proper proxy support. Please feel free to join the discussion: https://github.com/netty/netty/pull/1740 thanks for the clarification are there any plans to implement transparent support (without using attributes) down the track? e.g. netty 5. IIUC you expect: `channel.remoteAddress()` returns the proxied remote address instead of the address of the proxy server right? That's actually my plan. The plan is to add such special attributes in 4.x so people don't need to wait for 5. Do you think it's better having more type-safe API such as: `channel.isProxied()? channel.proxyInfo().remoteAddress() : channel.remoteAddress()`? my preference would be for the proxied remoteAddress to be updated transparently on the channel yep that would be perfect. it keeps the proxy as a pipeline detail rather than something you need to worry about at a higher level. Cool. Please keep in mind you can even make a contribution. :-) ha :) yeah i'd love to unfortunately im still very much a novice when it comes to this stuff...  Nope you can't override it as it is specific to the transport.
392,A,"Design query on defining new events on top of an existing set of events for a socket protocol I wrote a java server and client program using JBoss Netty. In order to send some data to the remote client and receive data back from them I have defined events and handlers for each event. On the wire each event is just a single byte(opcode) header followed by the message bytes. Initially I had only supported TCP and had defined events like LOG_INLOG_OUTDATA_INDATA_OUT etc in my program. For e.g public static final int LOG_IN = 0x08; public static final int LOG_OUT = 0x0a; Then I decided to support UDP also and ended up having events like LOGIN_UDP LOGIN_TCP DATA_OUT_TCP or DATA_OUT_UDP etc so that based on the event generated the correct event handler would get the event and write it to the appropriate socket and remote port. As you can see the first issue I am facing is that I have almost doubled the number of defined events and event handlers on adding UDP. Is there a better way to approach this scenario? The second(minor) issue I am facing is that events like DATA_OUT make sense when you are writing from server to client but when receiving the same event at the client side ""DATA_OUT"" does not make such sense since it is actually incoming data for the client. For the moment I have a decoder which will translate DATA_OUT to DATA_IN. Is this the best approach? You can use factory pattern to create connection on the basis of the type channel i.e. TCP or UDP. Other details will you have to define once in this case Instead Calling DATA_OUT you can call it as SERVER_OUT same way SERVER_IN no you have only one event login instead of login_udp or login_tcp only connection type will change. So I need to have different event number for UDP and TCP events right? I can use the factory pattern to create connection but that does not really solve my multi-event for same event type problem. Thanks for the SERVER_IN and out suggestion. Its better than DATA_IN out."
393,A,Netty.io messageReceived override without instanceof In netty MessageEvent (wrapper for messages) has a method Object getMessage() to get the real carried message from the network. Reading the source I noticed they heavily use the instanceof operator to switch among methods. However having a wide variety of message types I would like to avoid a method like this: public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { if (e.getMessage() instanceof MessageType1) { ... } else if (e.getMessage() instanceof MessageType2) { ... } ... { ... } else if (e.getMessage() instanceof MessageTypeN) { ... } else { ctx.sendUpstream(e); } } Writing different methods taking advantage of polymorphism would be much better like: public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { // MessageType implements Message if (e.getMessage() instanceof Message) { handleMessage(ctx (Message) e.getMessage()); } else { ctx.sendUpstream(e); } } void handleMessage(ChannelHandlerContext ctx MessageType1 m) { ... } ... void handleMessage(ChannelHandlerContext ctx MessageTypeN m) { ... } But i cannot due to downcasting limitations. Is there a clean way to do this or am I tied to instanceof cascade? I could bring the logic out the Handler using .doSomething() methods inside Message sub-types but I'd like to keep the business logic inside the netty pipeline. you can try to use Class.isAssignableFrom() or Class.isInstance() methods. I would however end up to another long chain of if-else-if cascade I'm looking for something less verbose. Those two method are anyway a valid alternative to instanceof. Thank you :) Solved applying Visitor Pattern: public interface Handler { void handleMessage(ChannelHandlerContext ctx MessageType1 m); void handleMessage(ChannelHandlerContext ctx MessageType2 m); ... void handleMessage(ChannelHandlerContext ctx MessageTypeN m); } then: @Sharable public class MessageHandler extends SimpleChannelHandler implements Handler { ... @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { if (e.getMessage() instanceof Message) { Message m = (Message) e.getMessage(); m.handleTo(ctx this); } else { ctx.sendUpstream(e); } } @Override public void handleMessage(ChannelHandlerContext ctx MessageType1 m) { ... } and public interface Message { /* * Will be { * handler.handleMessage(ctx this); * } * everywhere. */ void handleTo(ChannelHandlerContext ctx Handler handler); }
394,A,Netty Frame Decoding based on Header i am using netty 3.4.5 version. As i receive packets from network the length of the frame is based on header. i.e header1-->data with length 70 bytes. header2-->data with length 140 bytes. header3-->data with length 28 bytes. i want to use lengthbasedframedecoder in netty. please suggest me how to do this. Also suggest me if there is any other way to do it. thank you Actually this is not a length field based frame if the `headerX` not indicates the length of the remain bytes . @jilen please give an idea to achieve above scenario... After reading netty source code I find the easiest way is to override `getUnadjustedFrameLength` method in `LengthFieldBasedFrameDecoder`(that requires length of `header1header2header3` are same ) for example if your header is a 4 bytes int you may override that method as ```switch(buf.getUnsignedInt) {case header1 : return 70; case header2: return 140;}``` thank you jilen.. i think this works.. If the header1 header2header3 are with same length you could do this by override the getUnadjustedFrameLength in LengthFieldBasedFrameDecoder like this. switch(buf.getUnsignedInt) { //get header here case header1 : return 70; case header2: return 140; case header3: return 28; } i Didn't check with this code. Have u checked it.?? does it work for u??
395,A,How to read from CompositeChannelBuffer? During my testing I am loading an JPG image from browser with netty based littleproxy sitting between server and client. While loading this particular image. The channel buffer is of CompositChannelBuffer. I am reading the following way but is not working. if (chanBuff instanceof CompositeChannelBuffer) { CompositeChannelBuffer compChanBuf = ((CompositeChannelBuffer) chanBuff); int noOfComps = compChanBuf.numComponents(); List<ChannelBuffer> buffList = compChanBuf.decompose(0 noOfComps); ListIterator<ChannelBuffer> itr = buffList.listIterator(); int offSet = 0; int bytesRead = -1; while (itr.hasNext()) { ChannelBuffer buf = (ChannelBuffer) itr.next(); bytesRead = buf.array().length; outputStream.write(buf.array() offSet bytesRead); offSet += bytesRead; } } I also tried the below code but this also not able to write to the file. if (chanBuff instanceof CompositeChannelBuffer){ FileOutputStream outputStream = new FileOutputStream(outputFileName); CompositeChannelBuffer compChanBuf = ((CompositeChannelBuffer) chanBuff); int noOfComps = compChanBuf.numComponents(); compChanBuf.getBytes(0 outputStream noOfComps); ChannelBuffer dynamicBuf = dynamicBuffer(); compChanBuf.getBytes(0 dynamicBuf); array = dynamicBuf.array(); outputStream.write(array); } What is the correct way to read the CompositChannelBuffer? Just do it like you would do for other buffers like: ChannelBuffer buf = ... OutputStream out = ... buf.getBytes(0 out buf.readableBytes()); Thanks Norman. This worked! In what situation we use decompose then? Just want to understand as I already touched that API and would be useful to know. Thanks again! Most of the times you not need to cast to CompositeChannelBuffer at all. It just gives you some more advanced operations like access directly a component on index x etc.
396,A,Netty SSL and memory usage I am stress testing my Netty 4.0.4 project which is loosely based on the SecureChat example. When I connect 15k clients to my server I see that I am using roughly 800MB of memory! I've been tweaking what I can to get that lower since I'll eventually need to support up to 100K clients. So as a test I removed the SSL handler and my memory usage fell to just over 200MB. Is this just par for the course? Is there a way to reuse the SSLEngine or SSLHander or must they both be instantiated for each channel? Would you mind if I ask you to send me the heap dump? t at motd dot kr. An SSLEngine is specific to a single channel. It's not the SSLEngines that are taking all this memory it's the SSLSessions and their associated secrets keys certificates etc.
397,A,"Closing down a Netty UDP Server I have a written a very simple UDP Server using Netty - it quite happily binds itself and accepts messages but I can'y figure out how to unbind it. Am I missing something or does Netty not expose the necessary APIs to unbind a server? Edit Here is the code I am using to bind the server: DatagramChannelFactory f = new NioDatagramChannelFactory(Executors.newCachedThreadPool()); ConnectionlessBootstrap b = new ConnectionlessBootstrap(f); ChannelPipeline p = b.getPipeline(); p.addLast(""encoder"" new StringEncoder()); p.addLast(""decoder"" new StringDecoder()); p.addLast(""logic"" this); chan = b.bind(new InetSocketAddress(port)); netty provides many entry points to setting up a server I don't know which one you've used. You should be able to simply .unbind (or .close) the Channel you get back from ServerBootstrap.bind I have edited the question to show the code I'm using - seems like .close() does exactly what I'm looking for. With UDP it should be ConnectionlessBootstrap and not ServerBootstrap (which is for TCP)."
398,A,"jboss netty channel buffers thread safety I'm writing small utility app (JBoss Netty based) which should perform some trivial login against http requests. Imagine an image buffer private static byte[] image = DatatypeConverter.parseBase64Binary(""...some base64 data here....""); private static final ChannelBuffer imageBuf = ChannelBuffers.wrappedBuffer(image); So the question is: Is it correct to share this imageBuf across multiple threads for writing? Or should I create the new one for each response? And it is no longer JBoss Netty I think. Netty moved to a new home netty.io Nope its not safe to share the ChannelBuffer accross Threads. ChannelBuffer's are not thread-safe"
399,A,"invalid pixel in Firefox because of content charset setting in Netty server I am developing an http server with Netty. On some occasions the server must answer a 1x1 transparent pixel. So I hard-coded a GIF transparent pixel in base64 and returned it with the following code : String pixel_string= new String (Base64.decodeBase64(""R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="")); HttpResponse response = new DefaultHttpResponse(HttpVersion.HTTP_1_1 HttpResponseStatus.OK); response.setContent(ChannelBuffers.copiedBuffer(pixel_string CharsetUtil.UTF_8)); EDIT : I also set the content-type : response.setHeader(HttpHeaders.Names.CONTENT_TYPE ""image/gif""); In Chrome everything is fine. However Firefox tells me that it cannot display the pixel (which is pretty bad for my app) as the pixel data in invalid. After many investigations I finally figured out a fix by changing the charset to Iso-8859-1. response.setContent(ChannelBuffers.copiedBuffer( responseBuilder.pixel_string CharsetUtil.ISO_8859_1)); I don't understand why it works which makes me think that I may run into troubles in some cases. I tried to change the Firefox preferences (to have UTF8 as default) but it doesn't change much. Why does Firefox accept the ISO-8859 encoding and not UTF-8 ? Can I change that ? Would someone have a clue on the origin of the issue and how to be sure that it will work whatever the user's setting ? Thanks It's not Firefox that's accepting the encoding or not. It's your server. When you do your base64 decode you produce a string that contains some characters... but what you really produced was bytes that you're then thinking of as characters somehow. Since a Java String is a container that holds a UTF-16 string in practice what you're doing is taking each byte treating it as a a 16-bit integer and constructing the UTF-16 ""string"" made up of those code units. But when you want to put all this on the network you have to convert you string to bytes and the argument to copiedBuffer says how to do that. If converting to UTF-8 any character that came from a byte that had the high bit set will end up getting encoded as a two-byte UTF-8 sequence. On the other hand if converting to ISO-8859-1 the conversion just drops the high byte of each UTF-16 code unit (which in your case is always zero anyway). So the conversion to ISO-8859-1 produces the actual byte array you got out of base64-decoding while the conversion to UTF-8 produces.... something else which may or may not actually make any sense depending on the exact byte values. Thanks Boris my understanding of your answer is that I should avoid storing the pixel code in a String and favor a byte array. I'll try that. @Pixou Yeah I think using a byte array here would be a much better fit for what's going on.  The copiedBuffer constructor you call is not appropriate for the type of data (binary) you are using. According to the JavaDoc of the Netty API the one you are calling is: Creates a new big-endian buffer whose content is the specified string encoded in the specified charset. Which means that your binary data is being ""converted"" to UTF-8 (which is meaningless). If you try to save the generated file and look at it with a hex editor you'll probably see that it is corrupted. Try with something like this (untested code): static byte[] pixel_data = Base64.decodeBase64(""R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==""); HttpResponse response = ... response.setHeader(HttpHeaders.Names.CONTENT_TYPE ""image/gif""); response.setContent(ChannelBuffers.copiedBuffer(pixel_data)); I edited my question : I do set the content-type. Image files are binary but I need to specify the charset as I use a String to store the image in my code. Maybe I should use a byte [] instead of String I edited my answer too according to your edit... hope it helps! Thanks Ale I'll try that as also advised by Boris You could use `wrappedBuffer` rather than `copiedBuffer`."
400,A,"long polling netty nio framework java How can I do long-polling using netty framework? Say for example I fetch http://localhost/waitforx but waitforx is asynchronous because it has to wait for an event? Say for example it fetches something from a blocking queue(can only fetch when data in queue). When getting item from queue I would like to sent data back to client. Hopefully somebody can give me some tips how to do this. Many thanks You could also do the following in [sfnrpc]: http://code.google.com/p/sfnrpc Object object = RPCClient.getInstance().invoke(""#URN1""""127.0.0.1:6878""""echo""true60"""" objArrclassArr sl); The true causes communication to be synchronous.  You could write a response header first and then send the body (content) later from other thread. void messageReceived(...) { HttpResponse res = new DefaultHttpResponse(...); res.setHeader(...); ... channel.write(res); } // In a different thread.. ChannelBuffer partialContent = ...; channel.write(partialContent); Does this actually work? Can you write to a channel from another thread? It's thread-safe? Yes it's thread-safe How does the ""different thread"" know which channel to use? For example client1 does a long poll do I have to put the channel in a HashMap and fetch it once the event has occurred so that I can send the partial content?  You can use netty-socketio project. It's implementation of Socket.IO server with long polling support. On web side you can use Socket.IO client javascript lib."
401,A,"Netty 4 proxy: howto stop reading after the first PDU until the next read() call? The situation: I re-used the proxy from the Netty 4 examples to create my own. The key difference between the example and my implementation is that the proxy only connects to its remote peer after the first protocol data unit is processed. The relevant parts of my front-end handler: @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.channel().read();// read the first message to trigger ""channelRead0(...)"" } @Override protected void channelRead0(final ChannelHandlerContext ctx UCPPacket ucpPacket) throws Exception { if(!this.authenticated) {// authenticate the client then forward this packet this.authenticateAndForwardPacket(ctx ucpPacket); } else {// forward the packet this.forwardPacket(ctx ucpPacket); } } private void forwardPacket(final ChannelHandlerContext ctx UCPPacket ucpPacket) { if (outboundChannel.isActive()) { outboundChannel.writeAndFlush(ucpPacket).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) {// forwarding the packet succeeded so read the next one ctx.channel().read(); } else { future.channel().close(); } } }); } else { // this (often) happens when you don't set setSingleDecode(true) on the DelimiterBasedFrameDecoder LOGGER.error(""FIXME: avoid else"");//FIXME: ... } } The pipeline: DelimiterBasedFrameDecoder ==> UcpDecoder ==> FrontendHandler The problem: The first read() on the Channel will often read the bytes of multiple protocol data units which means that even with AUTO_READ set to false 2 or more UCPPackets will often have to be processed. Can I somehow tell Netty that I'm done with the ByteBuf after the first UCPPacket is decoded (until I call read() again)? Or what else can I do? Blocking the subsequent UCPPackets in the channelRead0 method of the front-end handler until this.authenticated == true is obviously a no go (as this would block an IO thread). What I tried: I tried setSingleDecode(true) on DelimiterBasedFrameDecoder but that didn't work well. The first frame gets decoded correctly but even after the proxy has forwarded that PDU and has called read() again the DelimiterBasedFrameDecoder doesn't do anything. I can only assume that this is because the read() call judged that it would be ""pointless"" to call the handlers on the pipeline when no new inbound bytes where read. The thing is... Netty has already read the bytes for the second (and last) UCPPacket so it has those bytes stored somewhere. Note: when I kill the client process the proxy does process those bytes which proves what I said: it does have the unhandled bytes it just doesn't trigger the handlers. I guess that there's a decodeLast or something that gets called when the channel goes inactive. You will need to queue them somewhere and handle it by yourself as we not know how much data we should read. I think we may be able to provide a generic ChannelInboundHandler which will queue messages. Would you mind to open also an issue so we can provide such a handler? https://github.com/netty/netty/issues done: https://github.com/netty/netty/issues/2072 In my case DelimiterBasedFrameDecoder already provides this feature so the only thing I needed was ""pipeline.fireChannelRead(Unpooled.EMPTY_BUFFER);"" instead of the ""ctx.channel().read();"" call."
402,A,NioEventLoopGroup vs AioEventLoopGroup I am a new comer to Netty and Java NIO. I am using Netty 4.0 RC3. I am confused by the difference between NioEventLoopGroup and AioEventLoopGroup. I see that NioEventLoopGroup is using Java NIO.1 selectors and channels. AioEventLoopGroup is using NIO.2 java.nio.channels.AsynchronousChannelGroup. What difference does it make from a programming & performance standpoint and when should I use which eventloopgroup? Also most examples in Netty documentation is using NioEventLoopGroup. If I am using Java 7 can I just replace NioEventLoopGroup with AioEventLoopGroup and expect things to work? Well Aio* is still very new while Nio* is there for ages. We added it to Netty as we hope it will get some more improvements over the time. For now I would stay with Nio* for production.
403,A,Netty 4 MessageToByteEncoder with FileRegion I am migrating from raw NIO to netty. The response I need to send back is as follows short long long long file I have the following working example and was wondering how to move the FileRegion into the encoder. MessageToByteEncoder @Override protected void encode(final ChannelHandlerContext ctx final BlockResponse msg final ByteBuf out) throws Exception { out.writeShort(DataServerMessage.DATA_SERVER_RESPONSE_MESSAGE); out.writeLong(msg.getBlockId()); out.writeLong(msg.getOffset()); out.writeLong(msg.getLength()); } ChannelInboundHandlerAdapter  ctx.write(new BlockResponse(blockId offset readLength)); FileChannel channel = closer.register(file.getChannel()); ChannelFuture future = ctx.writeAndFlush(new DefaultFileRegion(channel offset readLength)); future.addListener(ChannelFutureListener.CLOSE); I think that if i did writeAndFlush in the adapter to the response (and put the file in there) then I could do another writeAndFlush in the encoder but then the encoder would need to close it. Is there another way? Thanks! EDIT: Here is the updated code that works: public static final class Encoder extends MessageToMessageEncoder<BlockResponse> { private static final int HEADER_LENGTH = 2 + 4 * 3; // short 3 longs @Override protected void encode(final ChannelHandlerContext ctx final BlockResponse msg final List<Object> out) throws Exception { out.add(createHeader(ctx msg)); if (msg.getChannel() != null) { out.add(new DefaultFileRegion(msg.getChannel() msg.getOffset() msg.getLength())); } } private ByteBuf createHeader(final ChannelHandlerContext ctx final BlockResponse msg) { ByteBuf header = ctx.alloc().buffer(HEADER_LENGTH); header.writeShort(DataServerMessage.DATA_SERVER_RESPONSE_MESSAGE); header.writeLong(msg.getBlockId()); header.writeLong(msg.getOffset()); header.writeLong(msg.getLength()); return header; } } ChannelInboundHandlerAdapter ChannelFuture future = ctx.writeAndFlush(new BlockResponse(blockId offset readLength channel)); future.addListener(ChannelFutureListener.CLOSE); future.addListener(new ClosableResourceChannelListener(file)); If you need to also trigger a FileRegion from within an encoder you need to use a MessageToMessageEncoder and allocate the ByteBuf by your own inside there. Thanks works perfectly! So the header i allocate my self (from ctx) and send it out as out.add(header) then I say out.add(fileRegion)? Ill try this out thanks!
404,A,"PacketHandler:74 - Error during data processing on mrniko/netty-socket.io? i'm working with socket.io (mrniko/netty-socket.io server on java side and socket.io.js on client side) the problem is when i send json object from client to server  after recieving and showing the data  it gives error ""Error during data processing"" while its entertaining string data fine (i.e. sending & receiving ). Any idea if i'm doing something wrong ?? here is the code (server side) @OnMessage public void onMessageRecieved(SocketIOClient client String data AckRequest ackRequest){ System.out.println(""client is ""+client+"" data is ""+data); } here is client side code where i'm sending the data var socket = io.connect('http://www.example.com:9090' { 'reconnection delay' : 2000 'force new connection' : true }); var data1 = { user : document.getElementById('t1').value pass : document.getElementById('p1').value }; socket.send(JSON.stringify(data)); i have also tried socket.json.send(JSON.stringify(data)); its sending and also displaying on server side but when i pass it in any other function for further operations  it gives error ""Error during data processing"". for parsing i'm using JsonReader reader = new JsonReader(new StringReader(data)); JsonObject json = new JsonParser().parse(reader).getAsJsonObject(); System.out.println(json.get(""value1"").toString()); please tell me if i'm going wrong ? Have you checked an https://github.com/mrniko/netty-socketio-demo project? It uses json message in ""chat example"". As for your case. On client try this: var socket = io.connect('http://www.example.com:9090' { 'reconnection delay' : 2000 'force new connection' : true }); var data1 = { user : document.getElementById('t1').value pass : document.getElementById('p1').value }; socket.send(data); // you don't need to use JSON.stringify On the server side: // LoginObj should have a ""user"" and ""pass"" fields  server.addJsonObjectListener(LoginObj.class new DataListener<LoginObj>() { @Override public void onData(SocketIOClient client LoginObj data AckRequest ackRequest) { data.getUser(); data.getPass(); } }); Thanks Nikita :)"
405,A,"Netty Serve connected clients with data from mongo db trying hardly to find a solution / answer for my problem. I am having a backend server that is producing data (information) which is being stored into a mongo db database. An additional server (running netty) should serve the connected clients (10k clients). Where should i place the database query since not all clients are interested in the same information? I came up with following ideas: # 1 Having a separate thread in the application which is hosting the netty server performing the database query and looping over all connected clients and sending (channel.writeAndFlush(info)) the information (if the client is interested in it). The first problem i see is that i am having only one thread which should serve all clients. Second i am retrieving much information out of the database and fiter it in the application even if the interested client is not connected. I think that this could lead to performance issues. # 2 Perform a much more detailed query within the channel thread (maybe idlestatehandler?) and send all received data back to the client I am interested to know which concept would be better in scalability and performance. I am sure this is a common use case. But i was not able to find a solution. Many thanks in advance Your idea sounds OK to me. Maybe you could maintain some data structure instead of the simple list of channels so you don't always have to loop over the channel list. What other problems do you see with your idea? @trustin I thought instead of having one big thread querying the database i could make use of the channel thread and query only for the needed data. But where to place that code? I don't think you want to use the channel thread because with 10K clients and assuming 4 CPUs by default you'll have 1250 clients per thread and you won't be able to write data to all clients bound to a given thread while you're querying mongo-db. I'd use a separate thread pool. For each channel just queue a task to retrieve the data for that channel. When the query returns you can post a user event to the channel to perform the write in the I/O thread (perhaps post 'info' as one of the user event fields). This way you can tune the size of the thread pool taking into account things like server capacity and maximum number of connections to mongo-db. If the channels are persistent and you're periodically polling for data while the channel is connected the same model works. Just use a ScheduledExecutorService instead of a normal executor and schedule the task to repeat. You will have to deal with the channel closing while the query is running. If this happens relatively infrequently I'd be tempted to catch the exception Netty throws when you try to queue the user event in your executor rather than try to check if the channel is open before posting the event. Thank you the concept seems to work. What is the name for this design pattern? I'm not sure if there's a specific pattern name. It shares elements of SEDA where an ""event"" is handed off to the next thread pool for handling but it's not quite the same."
406,A,Multiple port server with Netty 4? I want to bind two server socket (eg. port 8000 8001) within one Netty application. I tried to merge DiscardServer and EchoServer example to test. But in the first server initialization code ChannelFuture f = bootstrap1.bind(port).sync(); f.channel().closeFuture().sync(); // <-- program blocks here The program execution blocks so the second server initialization code can't reach. How can I start two different port servers with Netty 4.0? Just comment the clause f.channel().closeFuture().sync(); // <-- program blocks here To add a little bit the line waits until the server socket is closed.
407,A,Jetty And Netty integration I want to build a nio based java web server. Jetty is light weighted java server and Netty is an asynchronous event-driven network application nio framework. can any one help me to integrate this two? That is pretty pointless: Jetty already provides NIO (which is default in Jetty 7). Finagle you can easily and within minutes spin up a Netty based web server using Finagle. Finagle is an open source project by Twitter.  You could build up your own webserver by using only netty. See the examples for this: http://docs.jboss.org/netty/3.2/xref/org/jboss/netty/example/http/
408,A,Use Jetty or Netty? We're in the process of writing a high-performance server for processing messages. We've been using Jetty for several years and like it but Netty looks like it has some cool features. In particular it has support for asynchronous processing so a thread doesn't have to be tied up waiting for the system to process a given message. It's designed to solve the C10k problem. I know that Jetty has some support for NIO internally. Does it also have an asynchronous model? The messages are likely to be in http format. Does Netty have any performance advantages over Jetty when doing plain old http? I'd like to have all the convenient features of a real servlet container but not at the cost of reduced performance. Jetty has had support for asynchronous request processing since version 6 (see here) using a proprietary API. More recent versions support the asynchronous API as part of the Servlet 3.0 API like any other compliant implementation. Using Netty would seem like a lot of work for little gain unless you have highly specific requirements. Otherwise Jetty would do the job for you with minimal effort. Good advice although we've decided to go with Netty. The servlet 3.0 api for async support is convoluted. It's hard to follow what's going on and easy to mess up. Plus Netty is going to be a lot better for low-level protocol handling in the future. But your answer is a good one. @skaffman: have any pointers to some articles/blogs where Jetty vs Netty is discussed in more detail? from the point of view of should one use Netty or stick with Jetty (or Tomcat or whatnot)
409,A,"Server sending a greeting message with websocket and netty -> causing exception I have a websocket server using Netty (4.0.17) that answers requests from a JavaScript client. The communication works fine but I have an exception when I try to immediately send a greeting message when a client connects. My code looks like that : public class LiveOthelloWSHandler extends SimpleChannelInboundHandler<TextWebSocketFrame> { @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { super.channelActive(ctx); ChannelFuture f = ctx.channel().writeAndFlush(new TextWebSocketFrame(""(gameID=0)[LiveOthelloServer=""+ VERSION_NUMBER + ""]\n"")); } // ... @Override protected void channelRead0(ChannelHandlerContext ctx TextWebSocketFrame frame) throws Exception { final String request = frame.text(); Channel thisChannel = ctx.channel(); // Do something with request // Write back thisChannel.writeAndFlush(new TextWebSocketFrame(response + ""\n"")); } } The channelRead0() is ok the client sends messages and the server answers back without any issue. What doesn't work is the ""greetings"" part. I would like to send a welcoming message to the client (the string using VERSION_NUMBER in the ChannelActive() method) but I always get an exception : java.lang.UnsupportedOperationException: unsupported message type: TextWebSocketFrame I guess this is maybe because the channelActive() gets invoked as soon as the connection is established but before the websocket handshake is complete. How can I wait for the handshake to be finished and then send the greeting message (without the client having sent any request yet)? For information my initialization is: @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast( new HttpRequestDecoder() new HttpObjectAggregator(65536) new HttpResponseEncoder() new WebSocketServerProtocolHandler(""/websocket"") myLiveOthelloWSHandler); Just RTFM... http://netty.io/4.0/api/io/netty/handler/codec/http/websocketx/WebSocketServerProtocolHandler.html Best way to detect handshake is to override ChannelInboundHandler.userEventTriggered... So I just had to add: @Override public void userEventTriggered(ChannelHandlerContext ctx Object evt) throws Exception { super.userEventTriggered(ctx evt); if (evt == WebSocketServerProtocolHandler.ServerHandshakeStateEvent.HANDSHAKE_COMPLETE) { ChannelFuture f = ctx.channel().writeAndFlush(new TextWebSocketFrame(""(gameID=0)[LiveOthelloServer=""+ VERSION_NUMBER + ""]\n"")); } }"
410,A,Does the connection timeout if the client never sends a FIN packet to close the connection? I have an HTTP server implemented with Netty. It takes long-poll connections for pushing messages to the browsers. In most of the times the server won't try to close the connection. In a TCP session if any side wants to close the connection it sends a FIN packet to the other. What if the server doesn't receive FIN from the client in the cases such as 1) the user has hard network failures or 2) someone tries to attack the server is it guaranteed that the Netty server will receive a timeout (or other kind of) exception after a given time? If it's true I don't need to add a Read/WriteTimeoutHandler into my channel pipeline which closes the channel when the Timer triggers timeout. I have to close the channel in either way otherwise I will leak resources. is it guaranteed that the Netty server will receive a timeout (or other kind of) exception after a given time? No. There is a SocketTimeoutException that is thrown if the socket is in blocking mode and a read timeout has been set. There is an IOException: connection reset which can happen if TCP keepalive has been enabled and the connection really stays broken for 2 hours: this does not include the case where the peer is merely silent with the connection remaining operative. Otherwise no.  According to TCP state diagram both sides FIN should be sent to close the connections both sides. But if the FIN is lost as in you scenarios TCP will overcome with proper timeout values.
411,A,"How to decode http POST data in Java? I'm using Netty and I've got to accept and parse http POST requests. As far as I can tell Netty doesn't have built-in support for POSTs only GETs. (It's a fairly low-level library that deals with primitive network operations. Using a servlet container which does all this stuff out of the box is not an option.) If I have the content of a POST request as an array of bytes what's the fastest and most bug-free way to parse it into a Map of parameters? I could write this myself but there must be some methods built into the JDK that make this easier. And I'll bet there are some gotchas and corner cases to deal with. can you give sample code of what you are trying to do? You can use HttpPostRequestDecoder in Netty 4.x. It supports all kinds of POST body. Netty 4.x is marked as alpha at the moment but very stable. See BodyParser in Xitrum. If you only need to parse simple body you can still use QueryStringDecoder in Netty 3.x by treating the POST body like the part after ""?"" in URL like this: QueryStringDecoder decoder = new QueryStringDecoder(""?"" + request.getContent.toString(org.jboss.netty.util.CharsetUtil.UTF_8)); How can we decode http pst request with json content-type? Get the JSON string from the request body then use JSON processing libraries like Jackson (Java) or JSON4S (Scala) etc. to process it: `String jsonString = request.getContent.toString(org.jboss.netty.util.CharsetUtil.UTF_8);`  Netty has an advanced POST request decoder (HttpPostRequestDecoder) which can decode Http Attributes FileUpload Content with chunked encoding. Here is an simple form decoding example public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { HttpRequest request = (HttpRequest) e.getMessage(); HttpPostRequestDecoder decoder = new HttpPostRequestDecoder(new DefaultHttpDataFactory(false) request); InterfaceHttpData data = decoder.getBodyHttpData(""fromField1""); if (data.getHttpDataType() == HttpDataType.Attribute) { Attribute attribute = (Attribute) data; String value = attribute.getValue() System.out.println(""fromField1 :"" + value); } } Sorry I was referring to Netty 4.0.X which is not available yet. As you have said HttpPostRequestDecoder from the Netty Extension library which is now merged with Netty 4.0.X. You can download it from here http://sourceforge.net/projects/goldengate/files/NettyExtension/1.1.9/ Are you sure? I googled that class and found only a third-party library named ""Netty Extension"" that has it. It that what you're talking about? How can we decode http pst request with json content-type? How to send query parameters using Get method in Netty?  Which version of netty are you using? Netty's HttpRequest supports POST method. Not aware of any library which could parse bytes to map of params. This is usually what a servlet container does. Take a look at tomcat's source on how they have implemented processParameters() method http://svn.apache.org/repos/asf/tomcat/tc7.0.x/trunk/java/org/apache/tomcat/util/http/Parameters.java This is helpful. Looks like they march through the bytes and split on '=' and '&'. I may have to do something similar."
412,A,"Camel Netty UDP listener listening on 0.0.0.0 and not receiving packets I'm new to Camel Netty and UDP but I've been researching this for a while and still can't figure out what's going on. All I'm trying to do is implement a UDP listener using Camel and Netty (currently on Windows 7 but will be moving the project to Linux). My spring config is as follows: <camel:camelContext id=""test""> <camel:route> <camel:from uri=""netty:udp://localhost:5150?sync=false""/> <camel:to uri=""log:cameltest?level=DEBUG""/> <camel:to uri=""file://outbox""/> </camel:route> </camel:camelContext> The listener appears to starts fine (running through Eclipse). However when I do a netstat I see this: UDP 0.0.0.0:5150 UDP [::ffff:127.0.0.1]:5150 when I am expecting it to be listening on 127.0.0.1. Nothing I've read online is clear on if this is expected behavior for Camel/Netty/UDP. I'm testing this by sending from a Java NIO UDP Client. If an NIO UDP Server is listening it receives the packet fine (all done through localhost). I also tested a Camel/Netty/TCP listener and that works fine. Why is the listener listening to all local addresses? And if so why isn't it receiving my packet from localhost? I would add a logging handler and log out all the channel events. I've debugged as far as I could go all the way up to the native `bind0` method in `sun.nio.ch.Net`. I didn't see anything unusual and no exceptions were thrown. It looks like no matter what hostname I specify it still tries to listen on all local addresses. I just tried to make my NIO UDP Server listen at 0.0.0.0 and it receives packets from my NIO client just fine. Still don't know why the camel version isn't... I figured it out. This was my final spring context: <bean class=""org.jboss.netty.handler.codec.string.StringDecoder"" id=""stringDecoder""> <constructor-arg value=""ISO_8859_1"" /> </bean> <camel:camelContext id=""test""> <camel:route> <camel:from uri=""netty:udp://localhost:5150?decoder=#stringDecoder&amp;disconnectOnNoReply=false&amp;sync=false""/> <camel:to uri=""log:cameltest?level=DEBUG""/> <camel:to uri=""file://outbox""/> </camel:route> </camel:camelContext> After doing some research on UDP and Netty I found out that listening on 0.0.0.0:[port#] seemed to be the default behavior for Netty/UDP. For more information on what 0.0.0.0 means see this link. A fellow programmer suggested (because I'm essentially working with a framework within a framework) to take out the camel stuff and try to get it working in Netty. I tried this and I was able to get it working and was also able to send to it from my NIO UDP Client. For a while I thought the problem was in camel because I couldn't see anything wrong with the Netty implementation. After hours of step-by-step debugging in the Netty/UDP Camel/TCP and the ""broken"" Camel/UDP I noticed that the Camel Netty implementation used a ConnectionlessBootstrap from the org.jboss package to bind the connection. In my Netty implementation I was using Bootstrap from the io.netty package. I found an example using the ConnectionlessBootstrap and org.jboss package from http://massapi.com/class/org/jboss/netty/bootstrap/ConnectionlessBootstrap.java.html. When I got it working I compared the implementation to mine and noticed he had an encoder and decoder on both ends. This is where I got the idea to add a CharsetUtil.ISO_8859_1 decoder to my listener and managed to get the project working. I also noticed I was only able to send to it once at a time. Setting the property disconnectOnNoReply to false allowed the listener to receive multiple times without disconnecting. Hope this helps someone out in the future. :) [edit] Actually after further testing the ""disconnectOnNoReply"" may not be needed. I just tried it without it and it works."
413,A,"What I'm doing wrong when I implement gpsd tcp feed with netty? I'm mocking a fake GPS device NMEA-0183 feed via TCP/IP. I've written a lightweight server on the top of Netty (http://netty.io/) and Java Marine API (http://ktuukkan.github.io/marine-api/). Server waits for the channel activation and once channel is activated by the gpsd it starts writing NMEA sentences to buffer. Please see my code below (generally taken from Netty examples): import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; /** * Discards any incoming data. */ public class TCPSentenceGenerator { private int port; public TCPSentenceGenerator(int port) { this.port = port; } public void run() throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); // (1) EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); // (2) b.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) // (3) .childHandler(new ChannelInitializer<SocketChannel>() { // (4) @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new TCPSentenceGeneratorHandler()); } }) .option(ChannelOption.SO_BACKLOG 128) // (5) .childOption(ChannelOption.SO_KEEPALIVE true); // (6) // Bind and start to accept incoming connections. ChannelFuture f = b.bind(port).sync(); // (7) // Wait until the server socket is closed. // In this example this does not happen but you can do that to gracefully // shut down your server. f.channel().closeFuture().sync(); } finally { workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port; if (args.length > 0) { port = Integer.parseInt(args[0]); } else { port = 9090; } new TCPSentenceGenerator (port).run(); } } and import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; import io.netty.util.ReferenceCountUtil; import net.sf.marineapi.nmea.parser.*; import net.sf.marineapi.nmea.sentence.*; import net.sf.marineapi.nmea.util.Time; public class TCPSentenceGeneratorHandler extends ChannelInboundHandlerAdapter { // (1) @Override public void channelActive(final ChannelHandlerContext ctx) { while (true) { RMCSentence rmcs = new RMCParser(""$GPRMC154653V4428.2011N00440.5161W000.5342.8050407N*7F""); try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } String RMCsentenceString = rmcs.toSentence(); System.out.println(""Char number is "" + RMCsentenceString.length()); System.out.println(""Byte number is "" + RMCsentenceString.getBytes().length); final ByteBuf outtext = ctx.alloc().buffer(RMCsentenceString.getBytes().length); // (2) outtext.writeBytes(RMCsentenceString.getBytes()); ctx.writeAndFlush(outtext); // (3) System.out.println(rmcs.toString()); } } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { // (4) // Close the connection when an exception is raised. cause.printStackTrace(); ctx.close(); } } When I start my server running and then attach gpsd to it via gpsd -N -n -D8 tcp://localhost:9090 I'm getting strange output to the debug logs: gpsd:UNK: ISGPS preamble ok parity fail gpsd:UNK: ISGPS lock never achieved gpsd:UNK: Character discarded buffer 69 chars = *7F$GPRMC154653V4428.2011N00440.5161W000.5342.8050407N*7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF gpsd:UNK: ISGPS word tag not correct skipping byte gpsd:UNK: Character discarded buffer 68 chars = 7F$GPRMC154653V4428.2011N00440.5161W000.5342.8050407N*7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF gpsd:UNK: ISGPS word tag not correct skipping byte gpsd:UNK: Character discarded buffer 67 chars = F$GPRMC154653V4428.2011N00440.5161W000.5342.8050407N*7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF gpsd:UNK: ISGPS lock never achieved gpsd:UNK: Character discarded buffer 66 chars = $GPRMC154653V4428.2011N00440.5161W000.5342.8050407N*7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF gpsd:RAW: packet sniff on tcp://localhost:9090 finds type -1 gpsd:PROG: no /etc/gpsd/device-hook present skipped running DEACTIVATE hook gpsd:INFO: hunt on tcp://localhost:9090 failed (15.019291 sec since data) gpsd:WARN: device read of tcp://localhost:9090 returned error or packet sniffer failed sync (flags {ERROR}) gpsd:INFO: closing GPS=tcp://localhost:9090 (6) gpsd:SPIN: close(6) in gpsd_close(tcp://localhost:9090) gpsd:PROG: no /etc/gpsd/device-hook present skipped running DEACTIVATE hook gpsd:INFO: reconnection attempt on device 0 gpsd:PROG: no /etc/gpsd/device-hook present skipped running ACTIVATE hook gpsd:INFO: opening TCP feed at localhost port 9090. gpsd:SPIN: TCP device opened on fd 6 gpsd:INFO: gpsd_activate(): activated GPS (fd 6) gpsd:RAW: flagging descriptor 6 in assign_channel() First part is okay it just displays how sentences are extracted from the buffer. But what is wrong with gpsd:RAW: packet sniff on tcp://localhost:9090 finds type -1 why the packet type -1 if it is correctly read? and finally if you want gpsd working you should provide at least 2 types of sentences:  GGASentence ggas= new GGAParser(""$GPGGA0846033806.0267N02348.1719E1045.61454.0M34.5M*77""); RMCSentence rmcs= new RMCParser(""$GPRMC084603A3806.0267N02348.1719E8315.7213.50409135EA*36""); And RMC should have 'date' field non-empty  I'm an idiot. I have forgotten to add ""\r\n"" to the sentence before write and flush it. With this addition everything works. The thing that guided me was the gpsfeed+ GPS simulator (http://gpsfeed.sourceforge.net/) feed consumed by gpsd with debug level 8. It showed that chars in the accepted sentence and displayed that such sentences are okay for gpsfeed."
414,A,"Netty Increase ChannelBuffer Size Hello I have a Netty Server with a handler that should accept strings. It seems to only receive content up to 1024 bytes. How can i increase Buffer size. I have already tried bootstrap.setOption(""child.sendBufferSize"" 1048576); bootstrap.setOption(""child.receiveBufferSize"" 1048576); without success. The handler is as below public class TestHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { ChannelBuffer buf = (ChannelBuffer) e.getMessage(); String response = """"; if (buf.readable()) { response = buf.toString(CharsetUtil.UTF_8); System.out.println(""CONTENT: "" + response); } System.out.println(response); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { e.getCause().printStackTrace(); Channel ch = e.getChannel(); ch.close(); } } In version 4.0.10.Final for UDP Buffer size is set to 2048 bytes. If You want to increase it set ChannelOptions as follows: option(ChannelOption.SO_RCVBUF int bytes) and also option(ChannelOption.RCVBUF_ALLOCATOR new FixedRecvByteBufAllocator(int Bytes))  Are you using UDP ? If so packets will max out at 1024 bytes. This code comment is in the QOTM code sample: Allow packets as large as up to 1024 bytes (default is 768). You could increase or decrease this value to avoid truncated packets or to improve memory footprint respectively. Please also note that a large UDP packet might be truncated or dropped by your router no matter how you configured this option. In UDP a packet is truncated or dropped if it is larger than a certain size depending on router configuration. IPv4 routers truncate and IPv6 routers drop a large packet. That's why it is safe to send small packets in UDP. If you are using TCP you should add a frame decoder and a string decoder into your pipeline before yout handler; Something like this: pipeline.addLast(""frameDecoder"" new DelimiterBasedFrameDecoder(80960 Delimiters.lineDelimiter())); pipeline.addLast(""stringDecoder"" new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(""myHandler"" new TestHandler()); Mind you you will need to modify your test handler because the MessageEvent will actually contain your string. @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { String response = (String) e.getMessage(); System.out.println(response); } Make sense ? Thanks Nicholas. It is possible to use my own delimeter. Brilliant!!! This is a MUST-READ tutorial by Nicholas. http://seeallhearall.blogspot.kr/2012/06/netty-tutorial-part-15-on-channel.html... p.addLast(""frameDecoder"" new DelimiterBasedFrameDecoder(8192 ChannelBuffers.wrappedBuffer("""".getBytes()))); Thanks Nicholas. Now I notice that the last line is not printed.Why? Good question. Can you put a full end-of-line delimiter at the end of the last line ? UDP packets do have a default max size of 768 but if you increased max size does not max out at 1024. the max size can be increase as detailed in the following post: [Why is Netty giving me only 768 Bytes from UDP messages](http://stackoverflow.com/questions/11525712/why-is-netty-giving-me-only-768-bytes-from-udp-messages)"
415,A,Netty ClosedChannelException I am new to netty and I followed this example to write a static file server using netty. But whenever the server serves a large js file. It runs into ClosedChannelException. The following is my code where I write chunkedFile as http response. When a large js file is being served I get closedChannelException and the raf file is also closed. Could you help me figure out what I have done wrong here? Also is there a simple tutorial where I get understand the basic flow of control in netty?  // Write the content. ChannelFuture writeFuture = null; try { long fileLength = raf.length(); HttpResponse response = new DefaultHttpResponse( HttpVersion.HTTP_1_1 HttpResponseStatus.OK); response.setHeader(HttpHeaders.Names.CONTENT_LENGTH fileLength); Channel c = ctx.getChannel();  // Write the initial line and the header. c.write(response); writeFuture = c.write(new ChunkedFile(raf 0 fileLength 8192)); } finally { raf.close(); if (writeFuture != null) writeFuture.addListener(ChannelFutureListener.CLOSE); } } < Calling raf.close() in the finally block is wrong as it may not have it written yet. In fact netty will take care to close it after the write is complete. Figured out that ChunkedFile takes care of closing the raf file. Thanks! Thanks for the help! Since netty writes asynchronously the close in finally block seems to be the culprit. Could you also tell me where netty takes care of closing the raf file? Is there a document or a tutorial that I can read to understand this better?
416,A,"Chrome : websocket connection not closed when browser closed I am using Netty websockets and everything seems to work fine except this minor issue : If I close the browser / tab of the js websocket client  the websocket connection is automatcally closed when using Mozilla firefox (currently using firefox 14) but the same thing does not happen in Chrome 20/21. Anyone seen a similar issue / can anyone tell why is the connection not closed automatically ? Chrome doesn't close the connection when a user will close the window or browser. It will trigger an Error event. A possible workaround could look like this:  @OnError public void onErr(Throwable t) { onClose(this.container.getWsSession() null); } But this will close the connection every time an Error is triggered. You may wan't to check the throwable before closing the connection by yourself. For more discussion please join this question: Websocket: Closing browser triggers onError() in chrome but onClose() event in Firefox  I guess I should have checked this earlier in the chromium bug section but I was not sure if it is a bug. It has been reported earlier by someone and a chromium bug already exists : Issue 51687 : WebSocket: Send close with code 1001 on reload / tab close Update : Someone has submitted a patch to fix this issue can be seen in the above link. Chrome still won't close the connection when you close the browser. :(  This may not be right but I cannot post a comment to your question. Chrome/Chromium does not really close if you have an App running and have selected ""Continue running background apps when Chromium is closed"" from Settings-->Under the hood. It may be that it treats the websocket connection as an app. Try looking at your running processes and kill any chrome/chromium process you find. Again this is just speculation on my part. No  I don't think so as even after disabling that option  the websocket connection is not closed on closing the tab. It may be a bug in Chrome then. You should open a bug report with the chromium project. I posted it here so as to confirm if someone else has seen it or there is some option available to solve it."
417,A,the memory usage of netty normal in this dump? for 13K users I have the following memory dump. I will paste the top 7 consumers. Netty seems to consume too much memory. Is this normal ? (Netty Version:3.2.7 implementing IdleStateAwareChannelUpstreamHandlerTotal Memory Netty Memory Usage:2.5GB minimum )  num #instances #bytes class name ---------------------------------------------- 1: 23086640 923465600 org.jboss.netty.util.internal.ConcurrentHashMap$Segment 2: 28649817 916794144 java.util.concurrent.locks.ReentrantLock$NonfairSync 3: 23086640 554864352 [Lorg.jboss.netty.util.internal.ConcurrentHashMap$HashEntry; 4: 118907 275209504 [I 5: 5184704 207388160 java.util.concurrent.ConcurrentHashMap$Segment 6: 5184704 130874832 [Ljava.util.concurrent.ConcurrentHashMap$HashEntry; 7: 1442915 115433200 [Lorg.jboss.netty.util.internal.ConcurrentHashMap$Segment; could you make the dump somewhere avaible ? I would like to have a deeper look with mat. That does sound like a lot. Are you sure all resources are cleaned when a user disconnects? the only references that I am keeping is for Channel ChannelGroup object. Should I do something special after user disconnects ? Because my User (keeps references for Channel ChannelGroup istances) instance count is identical with the concurrent user count. I would check whether you get this much memory usage after 13000 user connect but don't disconnect. Or you get this usage only after users disconnect and re-connect many times. there may be misunderstanding: 4.4GB is the total memory usage. The numbers above indicates that Netty using 2.5GB minimum. By the way do i have to consider some facts while cleaning resources (special for netty) ? I would test to see what the nature of the problem first. its probably increases after disconnect and re-connects many times. I have not restarted server for about 4 days. If that is the case you have a resource leak. It is possible you have such a leak even if you are doing everything you are supposed to with netty. I would try to reproduce the problem and see what memory is used after all the users have disconnected. I assume you are only looking at live objects. ;) dumped using this command :jmap -histo:live It looks like the memory usage is not normal. Here are some facts about Netty internal memory usage One channel has two ReentrantLocks (one read lockone write lock) Channel stores all channel references in a org.jboss.netty.util.internal.ConcurrentHashMap internally and automatically removes on close (This is to assign unique channel ids). ChannelGroup stores channel references in a org.jboss.netty.util.internal.ConcurrentHashMap on add() and automatically removes on close. There will be one ConcurrentHashMap$HashEntry per item stored in org.jboss.netty.util.internal.ConcurrentHashMap. so you can calculate the expected memory usage if your handlers are not leaking any references. can i say that Channel objects are not released after disconnect found a leak that is causing netty objects not to be garbage collected. currently heap size is only 200MB for 10K users. which seems to be good.
418,A,"Netty TCP message - any chance the request under the MTU size gets fragmented? I have read couple posts what makes the TCP packet gets fragmented. It seems to me it depends upon the MTU size - the request that exceeds the limit gets fragmented. Here is my question regarding to Netty. Assume that MTU size is 1500 and the request is 1000 bytes. Then what the server's messageReceived() method receives is always exactly 1000 bytes in one shot or any chance it gets fragmented? I want to make sure the message that server receives is not fragmented. If you think I am not understanding TCP or Netty well enough then please point me to what I need to study? I figured out my question is very similar to this. Dealing with fragmentation in Netty What I want to double check is whether or not the fragmentation occurs even the request size is less than MTU limit. If yes then I need the ReplayingDecoder. Your suggestion is greatly appreciated. I've never tried it and I don't think you can set it from within Java either. I believe you are correct in that your messages won't be fragmented but will be dropped if the network can't transport them. There's another issue here and that's the size of the buffer Netty uses to read data from the socket. If it's too small Netty will return the data in multiple calls to messageReceived. You can set a ReceiveBufferSizePredictorFactory on bootstrap to be sure - see answer here http://stackoverflow.com/questions/8985389/java-netty-load-testing-issues For TCP the maximum segment size is more important than the MTU. The MTU is always larger than the maximum data TCP can put into a single TCP segment. See http://en.wikipedia.org/wiki/Maximum_segment_size . Unless you're in total control of the network infrastructure your app will run on I would just deal with the possibility of fragmentation. At least that way it's guaranteed to work. If you know that all your requests are guaranteed to be a certain size use FixedLengthFrameDecoder - http://static.netty.io/3.6/api/org/jboss/netty/handler/codec/frame/FixedLengthFrameDecoder.html @johnstlr What you pointed out is EXACTLY what I wanted to know. I understood it is SAFE to deal with the possibility of fragmentations. Many Thanks! @johnstlr Thank you so much! @johnstlr Additional question. If the ""Don't Fragment"" under Flags in IP layer is set to 1 then there is no need to apply this ""safety net?"" Am I understanding correctly? That will depend on your protocol. For example if each message is contains a length field specifying the length of the message you could use LengthFieldBasedFrameDecoder. If you can only tell if a message is complete by parsing it then you may need a custom FrameDecoder implementation. @johnstlr Thank you so much for your support again. I created custom FrameDecoder that reads the number of bytes it should receive from property file. I am not satisfied with this approach but it works for now. @johnstlr Actually I do not think FixedLengthFrameDecoder works for my case since each request's message size differs (1st msg = 8 bytes 2nd msg = 20 bytes 3rd msg = 40 bytes). I could find several decoders but.. I have very hard time switching the buffer sizes. Could you please suggest me what decoder I should use for such scenario? You may want to take a look at org.jboss.netty.handler.codec.replay.ReplayingDecoder. Here is a link to the online documentation: ReplayingDecoder Thank you jdb. I'll take a look. I am sure I will have more questions as I continue learning..."
419,A,"What happens to multiple messages in ByteToMessageDecoder? I've got a question about ByteToMessageDecoder. The decode method has signature public void decode(ChannelHandlerContext ctx ByteBuf in List<Object> out) where out is the output for the next handler in the pipeline. If I insert multiple messages by calling out.add() multiple times what will the next handler see? For example pipeline is ByteToMessageDecoder -> SimpleChannelInboundHandler<String> in ByteToMessageDecoder's decode method I call out.add(""first"") out.add(""second"") out.add(""third"") Given that SimpleChannelInboundHandler's message handling method has signature protected void channelRead0(ChannelHandlerContext ctx String message) what will I see for the message parameter? Will the channelRead0 be called three times? I suppose trying it and finding out was out of the question? Every message contained in the List will be forwarded to the next handler via the fireChannelRead(...) call. So your handler will be called three times in your example."
420,A,"Netty - Client difficult read response I'm using Netty 4 for sending a protocol string to a device that should answer with another protocol string. I have done two classes EthClient and EthClientHandler. EthClient: connection = new EthClientHandler(message); b.group(group) .channel(NioSocketChannel.class) .remoteAddress(host port) .option(ChannelOption.TCP_NODELAY true) .option(ChannelOption.SO_KEEPALIVE true) .handler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast( new DelimiterBasedFrameDecoder(2048 true Unpooled.copiedBuffer(""\u0004"".getBytes())) new StringEncoder() new StringDecoder() new ReadTimeoutHandler(READ_TIMEOUT TimeUnit.SECONDS) connection ); } }); f = b.connect(); f.channel().closeFuture(); ... EthClientHandler: public class EthClientHandler extends SimpleChannelInboundHandler<String> { private String message; public EthClientHandler(message) { this.message = message; } @Override public void channelActive(ChannelHandlerContext ctx) { ctx.writeAndFlush(message); } @Override public void channelRead0(ChannelHandlerContext ctx String msg) throws Exception { gestString(msg); ctx.writeAndFlush(message); } } When start connection it send protocol string but device doesn't answer me. Using Wireshark to understand if device answer something I found this conversation:  445 2.835161000 192.168.1.135 192.168.1.252 TCP 54 49570 > exlm-agent [FIN ACK] Seq=1 Ack=1 Win=65088 Len=0 454 2.871899000 192.168.1.252 192.168.1.135 TCP 60 exlm-agent > 49570 [FIN ACK] Seq=1 Ack=2 Win=256 Len=0 455 2.871947000 192.168.1.135 192.168.1.252 TCP 54 49570 > exlm-agent [ACK] Seq=2 Ack=2 Win=65088 Len=0 617 3.835746000 192.168.1.135 192.168.1.252 TCP 66 49575 > exlm-agent [SYN] Seq=0 Win=8192 Len=0 MSS=1460 WS=4 SACK_PERM=1 622 3.866775000 192.168.1.252 192.168.1.135 TCP 60 exlm-agent > 49575 [SYN ACK] Seq=0 Ack=1 Win=256 Len=0 MSS=576 623 3.866839000 192.168.1.135 192.168.1.252 TCP 54 49575 > exlm-agent [ACK] Seq=1 Ack=1 Win=65088 Len=0 624 3.867209000 192.168.1.135 192.168.1.252 IPA 57 unknown 0x04 [Malformed Packet] 641 3.937626000 192.168.1.252 192.168.1.135 TCP 60 exlm-agent > 49575 [ACK] Seq=1 Ack=4 Win=256 Len=0 So after the last ACK I didn't received anything else and connection went in Read Timeout. If I put a breakpoint in my code on the ctx.writeAndFlush(message) at channel sturtup and after a second I resume the program device send me protocol string: 2036 13.113369000 192.168.1.135 192.168.1.252 TCP 66 51135 > exlm-agent [SYN] Seq=0 Win=8192 Len=0 MSS=1460 WS=4 SACK_PERM=1 2037 13.144752000 192.168.1.252 192.168.1.135 TCP 60 exlm-agent > 51135 [SYN ACK] Seq=0 Ack=1 Win=256 Len=0 MSS=576 2038 13.144833000 192.168.1.135 192.168.1.252 TCP 54 51135 > exlm-agent [ACK] Seq=1 Ack=1 Win=65088 Len=0 2069 13.319494000 192.168.1.135 192.168.1.252 IPA 57 unknown 0x04 [Malformed Packet] 2073 13.366926000 192.168.1.252 192.168.1.135 TCP 60 exlm-agent > 51135 [ACK] Seq=1 Ack=4 Win=256 Len=0 2092 13.458136000 192.168.1.252 192.168.1.135 IPA 72 unknown 0x30 [Malformed Packet] 2093 13.460564000 192.168.1.135 192.168.1.252 IPA 57 unknown 0x04 [Malformed Packet] 2102 13.514205000 192.168.1.252 192.168.1.135 TCP 60 exlm-agent > 51135 [ACK] Seq=19 Ack=7 Win=256 Len=0 2123 13.621507000 192.168.1.252 192.168.1.135 IPA 72 unknown 0x30 [Malformed Packet] So I really don't understand why this kind of result. Someone know how can I resolve it? It could be a Netty problem or a device problem? Edit: Added DelimiterBasedFramdeDecoder in the bootstrap handler but result doesn't change. At first startup it receive correctly protocol string from device but if I try to disconnect e reconnect the problem come out again. StringDecoder requires a framing decoder in front of it. Place a LineBasedFrameDecoder to handle a text line properly. StringEncoder does not append ""\r\n"" for you. If you did not please do. These two changes will probably make it work. Hi @trustin the protocol string that i send to it finished with EOT (\u0004): ' String message = ""\u0002N\u0004"" ' I put new DelimiterBasedFrameDecoder(2048 true Unpooled.copiedBuffer(""\u0004"".getBytes())) in the bootstrap and it read it at startup but if I try to disconnect and reconnect it doesn't work yet.  Resolved adding a pause before ctx.writeAndFlush(message) in EthClientHandler class in channelActive. @Override public void channelActive(final ChannelHandlerContext ctx) { ctx.channel().eventLoop().schedule(new Runnable() { @Override public void run() { ctx.writeAndFlush(message); } } 1 TimeUnit.SECONDS); } Thanks for your help"
421,A,"Netty messageReceived writing object not working Server code: public static void main(String[] args) { try { ServerBootstrap bootstrap = new ServerBootstrap(new NioServerSocketChannelFactory(Executors.newCachedThreadPool() Executors.newCachedThreadPool())); bootstrap.setPipelineFactory(new PipelineFactory()); bootstrap.bind(new InetSocketAddress(""localhost"" port)); System.out.println(""Listening on "" + port); } catch(Exception exception) { exception.printStackTrace(); } } Pipeline: import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.channel.DefaultChannelPipeline; import org.jboss.netty.handler.codec.serialization.ClassResolvers; import org.jboss.netty.handler.codec.serialization.ObjectDecoder; public class PipelineFactory implements ChannelPipelineFactory { @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = new DefaultChannelPipeline(); try { pipeline.addLast(""decoder"" new ObjectDecoder(ClassResolvers.cacheDisabled(getClass().getClassLoader()))); pipeline.addLast(""messagehandler"" new MessageHandler()); } catch(Exception exception) { exception.printStackTrace(); } return pipeline; } } I override the messageReceiveed method in my MessageHandler class: @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { try { if (!e.getChannel().isConnected()) { System.out.println(""Not connected to server...""); return; } Message message = (Message) e.getMessage(); queueMessage(message); super.messageReceived(ctx e); } catch(Exception exception) { exception.printStackTrace(); } } The object I'm trying to send (Message): public class Message { private String text; private byte rights; public Message(String text int rights) { this.text = text; this.rights = (byte) rights; } public String getText() { return this.text; } public byte getRights() { return this.rights; } } Finally my Client code: public static void main(String[] args) { try { ClientBootstrap bootstrap = new ClientBootstrap(new NioClientSocketChannelFactory(Executors.newCachedThreadPool() Executors.newCachedThreadPool())); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline(new ObjectEncoder() new ObjectDecoder(ClassResolvers.cacheDisabled(getClass().getClassLoader()))); } }); ChannelFuture cf = bootstrap.connect(new InetSocketAddress(""localhost"" 5656)); cf.awaitUninterruptibly(); Channel channel = cf.getChannel(); channel.write(new Message(""Hello"" 0)); if (channel.isConnected() && cf.isDone()) { System.out.println(""Message sent!""); } else { System.out.println(""Message has not been sent killing client.""); } } catch(Exception exception) { exception.printStackTrace(); } } If I change the Message Object to Date So I write a Date Object it works fine. The messageReceived method is not actually being called since I tried just printing a random sentence in the start of the messageReceived method and it didn't print. I'm new to netty and networking its self so I'm pretty clueless now I've tried a couple of things all resulting with no difference to my current situation. I'm not sure why but it just doesn't want to write the Message Object maybe it's the encoding part of it?? Even then a Date will send perfectly fine so I'm stumped any help is appreciated thanks. Please could you include more of your code I am having some issues like you had. Could you include your handler class for client and server? and everything else you could include would help me very much. I am trying to send some objects. Thanks in advance Your Message class must implement java.io.Serializable."
422,A,"OutOfMemory when parsing String XML to Java Objects Problem - Memory Utilization keeps growing in my program when parsing an XML string. I have an XML stream coming in live on a TCP port. I use Netty to pull the xml data out and then I use XStream to deserialize/unmarshal the XML String into Java Object tree. When I monitor memory consumption using netbeans profile I see the HEAP growing over time and then finally JVM throws OutOfMemory exception. I traced the call Stack and I've attached a screenshot of one my tests in action. The memory consumption seems to be happening when I deserialize/unmarshal the XML String into Java Objects. I've tried different parsers within XStream to do the parsing - XPP3KXMLSTAX. I've even tried JAXB instead of XStream to unmarshal. No matter what parser I use the problem persists. I've tried all these different parsers so far but I have the same issue.  xstream1 = new XStream(new KXml2Driver()); xstream2 = new XStream(new StaxDriver()); xstream3 = new XStream(new JDomDriver()); xstream4 = new XStream(new Xpp3Driver()); Like I mentionedI've even tried JAXB to unmarshal instead of XStream...still same issue. If you look at the attached image its this Arrays.copyOfRange call right under the char[] that shows up.... No matter which parser it is this call always shows up at the top of the trace. I'm completely lost on how to fix or approach this problem PLS NOTE - I'm not reading XML from a file. I get a live stream of data containing small XML chunks. I extract each chunk to convert it into Java objects for further processing Thanks A Well on the evidence you've shown us the simplest explanation is that your JVM's heap is too small. Try adding an ""-Xmx"" option as described in the manual entry for the java command. If that doesn't work then you need to take a deeper look at what your application is doing: Is there an upper bound on the size of these ""small"" XML chunks? Could you be getting a chunk that is bigger than you have allowed for? Is your application's processing keeping stuff from each chunk in a long lived in-memory data structure? Can you place an upper bound on the size of that data structure? Perhaps by throwing stuff out? (Or by using ""weak references"" so that the GC will throw them out?) Is your application leaking memory? A) No upper bound B) I dont keep anything intentionally...unless there's a bug. C) This is what I was trying to figureout and things are just pointing out at this parsing area I've mentioned where the memory seems to be happening. If you are not retaining any data then it is hard to see how you are leaking memory in the XML parsing or anything else. But either way there are ways to track down storage leaks. For example: http://www.oracle.com/technetwork/java/javase/memleaks-137499.html#gbywf My application did have a memory leak - works fine after fixing it.  Answer above is solid. I would only add that an object graph in memory can be expensive. If I understand your description you have a stream of XML which contains a number of small XML chunks? SAX parsing might be your answer along with a pipeline approach. As the SAX parser finds each chunk of work it passes it to a downstream process without having to pull all the objects into memory. If we assume that the chunks are indeed small and have a bounded size then it is not a stretch to assume that a corresponding DOM will be small(-ish) and bounded. In that scenario converting to a SAX parser is a lot of work ... compared with just increasing the heap size. Guys - As mentioned in my post I've already tried STAXXPP3KXML2 and JDOM....All give me same issues... I want to believe its a leak in my own code but the stack trace I see in profiler points out somewhere completely different. I'm having a hard time mapping it back to my own code. I'm currently switching to use another solution currently - Abandon XML and just do serialize/deserialize my Java Data Object between my client and server. If that also gives me a memory leak then I could possibly try and trace the memory leak in my own code I think you are probably misinterpreting the profiler output. The fact that the failed allocation occurs in the parser does NOT mean that the parser is leaking memory."
423,A,How can I set the content of a outbout HttpResponse in Netty4? How can I add content to a DefaultHttpResponse?. In Netty 3.x there was a setContent()-method. I could not find any details on how to use the HTTP classes in Netty 4. It seems like there are a few En/Decoders that can be used together with HTTP Packets but I have no clue how. You can either send a sequence of: HttpResponse  n * HttpContent LastHttpContent of just use FullHttpResponse The DefaultHttpContent DefaultLastHttpContent and DefaultFullHttpResponse take a ByteBuf as constructor parameter. Wow I wonder why I haven't seen this... Pretty simple. Thank you.
424,A,"Does Netty provide reliable-ordered UDP messaging? Does anyone know if Netty provides reliable messaging (acks) and sequence ordering for UPD messages? I am looking for a Java messaging library that will allow me to write a game server but provide that functionality so that I don't have to write it. TCP? Why search for a reimplementation of all it´s features? Simply broadcasting/multicasting is impossible anyways because with your requirements you´ll have to treat every peer separately even if you make a broadcast (at least you´ve to remember which ACKs you´ve received so far etc.) No - I do not want to use TCP. I am following the recommendations in this guide: http://trac.bookofhook.com/bookofhook/trac.cgi/wiki/IntroductionToMultiplayerGameProgramming Which guide? And sorry to say that *wanting* to ""reimplement"" TCP nowadays on a major OS is plain stupid (no i´m NOT saying ""you are stupid"") I added the guide in my first comment after pressing enter - sorry about that...still getting used to using this post's UI - it seems that one has to press shift-enter to go to the next line...:). The guide warns to stay away from TCP when writing game servers. And my question is if Netty provides the optional reliable delivery with ACKs and sequence ordering so that I can use that when needed instead of trying to use TCP. Hence if there is a library that does this I won't have to reimplement it will I? I believe even with optional reliable delivery and sequence ordering UDP will be much faster still so when you write a game server it is worth the trouble of doing this. Well...of course you can tailor it to your program needs and can end up faster than a generic TCP implementation. But don´t expect too much difference in 2014. About Netty: Isn´t that a Java lib? Until now I thought of C++ (I´m sure I came from the C++ question page). (If you´re concerned about TCP/UDP difference...Java?) Yes...Netty is a Java library but I found UDP examples out there. So apparently it handles UDP as well. I'll be reading more about it in the next few days but wanted to see if anyone out there may know of the question to my answer and if Netty does/does not offer reliability and sequence ordering. I was also hoping that perhaps someone out there might know of another Java library that does this if Netty does not. I thought about writing the server in C++ but I prefer not to I am good at C++ but I am very good at Java and I have written tons of multi-threaded back end server code. OK - I found the answer. It does! It provides UDT via these packages: io.netty.channel.udt io.netty.channel.udt.nio Which include these classes: UdtChannel UdtChannelConfig UdtChannelOption UdtMessage UdtServerChannel UdtServerChannelConfig and these ones: NioUdtAcceptorChannel NioUdtByteAcceptorChannel NioUdtByteConnectorChannel NioUdtByteRendezvousChannel NioUdtMessageAcceptorChannel NioUdtMessageConnectorChannel NioUdtMessageRendezvousChannel NioUdtProvider And it also provides plain UDP via these classes: DatagramChannel DatagramChannelConfig DatagramPacket"
425,A,"Netty ChannelPipelinefactory getPipeline() input parameters I have a question about what type of input can be provided to the getPipeline()... I want that method to return a different pipeline for different ip addresses  basically the pipeline is same but some of the resources used by some of the handlers per stage may be or may not be same given the client IP. eg. I want to share a object which is input to a stage(handler) based on IP same IP=same Object. I want this to happen at getPipeline() itself if possible. Because ChannelPipelineFactory.getPipeline() does not accept any parameters you cannot do what you want to with ChannelPipelineFactory. Instead I'd recommend you to make ChannelPipelineFactory.getPipeline() return a new pipeline with a handler which sets up the pipeline. That is the channel will start with a pipeline with a single handler and the single handler's channelConnected() could append the actual handlers to the pipeline and remove itself. Here's an example: public class MyChannelPipelineFactory implements ChannelPipelineFactory { public ChannelPipeline getPipeline() { return Channels.pipeline(new MyChannelInitializer()); } } public class MyChannelInitializer extends SimpleChannelUpstreamHandler { public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent evt) { Channel ch = ctx.getChannel(); ChannelPipeline p = ch.getPipeline(); if (matchesA(ch.getRemoteAddress()) { // Protocol A p.addLast(""A.decoder"" new DecoderA()); p.addLast(""A.encoder"" new EncoderA()); } else { // Protocol B p.addLast(""ssl"" new SslHandler(...)); p.addLast(""B.decoder"" new DecoderB()); p.addLast(""B.encoder"" new EncoderB()); } p.addLast(""commonLogic"" new CommonLogicHandler()); p.remove(this); ctx.sendUpstream(evt); } } Curious why getPipeline wouldn't be able to accept any arguments if I remember factory method pattern properly they almost always have some input arguments based on which they return a proper implementor of the interface in question. Simply it was a design mistake. :-)"
426,A,Web Services client using Java NIO (Netty?) I have written a simple client to test my Web Service but I am investigating the possibility of using the JBoss Netty framework rather than blocking sockets in order to increase the number of concurrent connections I can make to the Web Service. I understand that JBoss itself uses Netty but I am using Tomcat (for the time being) and have no knowledge of it. Has anyone done this or used something similar? Whether you use NIO or plain IO you can use up to 10K concurrent connections. IO will use more resources to do this but if you have plenty of memory or less than 1 K concurrent connections you are unlikely to notice a significant difference. BTW I would be curious to know if you see a difference. But if each connection is blocking a thread aren't I limited by the number of threads I can create? Yes but question there is whether your concurrency will raise to that level? Modern OS/JVM combo can typically support up to low-thousands of threads if most are inactive most of the time. We have used both Netty and MINA in our implementations. Both wrap the underlying java NIO classes to make things a bit easier and concise. We went with Netty when comparing the two. We found that Netty was a bit easier and provided us more powerful uses for NIO. I'd suggest taking a look at this post as it has a pretty good comparison of the two. Can ask what implementation you are talking about? Did you have to write your Web Services API or did you modify an existing implemention? So we use JBossWS as our webservice provider (however we've moved almost everything to REST services now). We also use Netty separately for doing streaming. I'm pretty sure given the stack traces I've seen on JBoss WS that they are leveraging Netty under the hood. So you may just want to leverage that library.  Instead of trying to integrate someone else's Socket handling library into Tomcat why not turn on Tomcat's NIO services? It may require upgrading to Tomcat 6.0 but depending on your experience with JBoss it might be a easier solution. That's a useful answer as I might well run into problems with scalability in the server however I want to use Netty (or whatever) in the test client not the server. This should have more up votes very handy tip I didn't even realize was an option. Tomcat with direct byte buffers on NIO very nice. Thanks Edwin. It's worth noting however that this only covers part of Servlet handling -- your actual request handling still needs a thread to bind to (for regular Servlet API at least). It can be useful but depending on where most time is spent not necessarily sufficient.
427,A,"Netty client uses only one thread I'm implementing a binary protocol above TCP/IP and using Netty to achieve this. My problem is that the performance is rather poor (600 msg/s). I'm connecting as a client to a server with one connection only. When I investigated running instance with JTop I saw that Netty was using 1 worker thread very heavily and the other 5 worker threads are doing nothing (0% ussage). I was digging on the web and all I found is mention of ExecutionHandler. But why should I use this if those 6 worker threads should be enough. Or am I misunderstanding how Netty uses these threads? My Netty init code: this.channelFactory = new NioClientSocketChannelFactory(this.executors DaemonExecutors.newCachedDaemonThreadPool() 1 6); this.clientBootstrap = new ClientBootstrap(channelFactory); this.channelGroupHandler = new ClientChannelGroupHandler(this.channels); this.clientBootstrap.getPipeline().addLast(""ChannelGroupHandler"" this.channelGroupHandler); Thanks for any hints Matous Are you saying that you're using a single client to connect to the server? Why would the server use the other threads then one thread per client you know. I'm implementing a client which right now connects with just one connection in the future there will be much more. I thought that the whole point of using NIO is that one connection can be serviced by multiple threads? You've got it completely wrong. NIO allows you to use a **single** thread to service multiple connections. Aha I never really digged too deep into NIO thanks for poining that out. Do you have any good resource on this that I can read? With regards to threading? Anyway this explains the behaviour that I'm seeing in Netty. Thanks! Can I accept comments somehow? The reason you only see one worker thread being used is because you are making only a single connection to the server. Had you made multiple connections more worker threads would have been used. If each connection's work is suited for parallelization then you can implement a handler that uses threads internally but Netty won't to do that for you. As for the NIO/OIO distinction it's true that the idea of NIO is to have one thread handling the events for multiple connections. However this doesn't mean one thread will handle the all the work. The ""single thread"" only dispatches work to other (i.e. worker) threads. Here is an excerpt from the Netty doc: How threads work There are two types of threads in a NioServerSocketChannelFactory; one is boss thread and the other is worker thread. Boss threads Each bound ServerSocketChannel has its own boss thread. For example if you opened two server ports such as 80 and 443 you will have two boss threads. A boss thread accepts incoming connections until the port is unbound. Once a connection is accepted successfully the boss thread passes the accepted Channel to one of the worker threads that the NioServerSocketChannelFactory manages. Worker threads One NioServerSocketChannelFactory can have one or more worker threads. A worker thread performs non-blocking read and write for one or more Channels in a non-blocking mode. Thanks for response! From what I'm seeing on the client side one worker thread handles all the work of my connection. I will make some experiments with more connections once I tweak my server simulator so it is able to accept more then one connection :). But anyway it seems that traffic coming from the client connection is handled always by the same worker/thread (its not distributed). Failed to find any description about this in Netty documentation but I am happy with the explanation Kayaman pointed out. Will check Netty code to confirm when I have the time.  NIO or rather the non-blocking version of NIO (""New"" I/O) allows you to use a single thread for multiple connections since the thread doesn't block (hence the name) on the read/write operations. Blocking I/O requires a thread for each connection as the blocking would prevent you from handling traffic between different connections. This allows you to perform more efficient communication since you no longer have thread overhead for one. A decent tutorial is available here (the original Oracle tutorial seems to have vanished from the face of the Google). It's true that Netty only uses one boss thread but it does use multiple worker thread to process the work necessary for those events. He only has a single connection. There's not enough work for the other worker threads."
428,A,"Question about Netty's Channel.write(Object) signature - Unclear documentation The Netty library (written in Java) defines the following write method in the channel interface: ChannelFuture write(Object message) However the Javadoc does not explain how this method is going to use the provided message to extract data and send it. It is not like one could pass any object. It does not make sense. The user guide shows a call example with a ChannelBuffer but it does not connect the dots between the signature and the usage. My question what is the proper use of this method? And why hasn't it been defined like this: ChannelFuture write(ChannelBuffer message) Is there a special use case for 'object'? Is there any documentation about this? I think the ""Speaking POJO"" section of the user guide explains it fairly well: http://docs.jboss.org/netty/3.2/guide/html/start.html#start.pojo. Simply put a stream or frame of bytes can be converted to Java objects upstream and vice versa downstream. Thanks for your answer. I would personally have designed the API with two method signatures (Object and ChannelBuffer) and document each properly."
429,A,Netty 4 - Is there a strategy to attach an app/service level ID to a Future and have it echoed back in operationComplete(future)? Other strategy? With Netty 4 when calling write(msg) with a service that handles a high number of messages I currently have one write listener. Is there a strategy to attach a service/app level ID to a Future. This way when the write listener operationComplete(Future) fires I can have that ID echoed back to me. This would allow me to keep one listener (and not have a MAP lookup) as well as not having to have a listener instance for every write. Other strategies? thanks in advance. You could implement your own ChannelPromise which includes this id and pass the ChannnelPromise as last argument into the write call. Netty itself does not support this. Thanks Norman. That seems to be exactly what I am looking for. I extended DefaultChannelPromise and simply pass in the object I want to grab for a particular write operation. When the listener operationComplete() fires the future is of this promise instance so I can get at the object in question
430,A,"ChunkedWriteHandler did not handle 100 Continue response properly to send all the chunks I have used the netty 4.0.9 (or 12) HttpUploadClient way to send large (>8K) post request. However after the first chunk sent to the server the server sent back ""100 continue"". The ChunkedWriteHandler did not handle the ""100 Continue"" to send the remaining chunk. Instead the 100 Continue was passed upstream the top handler which can't handle. How can the ChunkedWriteHandler be modified to handle the ""100 Continue"" response to resume sending the remaining chunk to finish the large post request? This bug is fixed in 4.0.15 for the AbstractMemoryHttpData.java getChunk() function. The exception was IllegalReferenceCountException in AbstractByteBuf.java. However in the ChunkedWriteHandler.java doFlush() there is catch(final Throwable t) which may prevent any future other exception to propagate unless explicitly check it.  ChunkedWriteHandler is a protocol agnostic handler so you should not add anything specific to HTTP. Instead you could update your last handler in the pipeline so that it understands 100-Continue message. Before writing any chunks you'd better wait for 100-Continue response first. Alternatively you could just remove the Expect: 100-continue header from your request then the HTTP server will not send such a response. Thanks for the response. The request did not have the ""Expect: 100-Continue"" the server sent the ""100-Continue"" anyway which I have no control. The second method was also tried with the following: channel.writeAndFlush(request); // Header parts only. Then in the handler after the 100-Continue received. channel.writeAndFlush(requestEncoder); // Send the request body parts. However only the first chunk was sent not the second part. So any idea how to debug this? Trustin: Thanks for the response. Hmm if you can write a simple HTTP client and server code that demontrates the problem without contacting any public server I'd be happy to investigate further. Please feel free to file an issue."
431,A,"Netty pipeline warning Netty 4 issues a warning ""Discarded 1 inbound message(s) that reached at the end of the pipeline. Please check your pipeline configuration"". What does it mean? how should it be handled? (previously reproduced here until solved per the accepted answer but I'd rather have the general explanation about what does it mean and how the pipeline works) Trying to max out netty feedback the client-side pipeline is set as follows: pipeline.addLast(""logger"" new LoggingHandler(LogLevel.TRACE)) pipeline.addLast(""HttpRequestEncoder"" new HttpClientCodec) pipeline.addLast(""handler"" new myHandler) All I'm getting logged on the client-side by Netty while two http messages are sent by it and successfully received and acknowledged by the server side is: 12 [main] DEBUG io.netty.util.internal.InternalLoggerFactory - Using Log4J as the default logging framework 164 [nioEventLoopGroup-1-2] DEBUG io.netty.channel.nio.SelectorUtil - Using select timeout of 500 164 [nioEventLoopGroup-1-2] DEBUG io.netty.channel.nio.SelectorUtil - Epoll-bug workaround enabled = false 229 [nioEventLoopGroup-1-2] WARN io.netty.channel.DefaultChannelPipeline - Discarded 1 inbound message(s) that reached at the end of the pipeline. Please check your pipeline configuration. 230 [nioEventLoopGroup-1-2] WARN io.netty.channel.DefaultChannelPipeline - Discarded 1 inbound message(s) that reached at the end of the pipeline. Please check your pipeline configuration. Whereas logging is set up minimally as so: BasicConfigurator.configure InternalLoggerFactory.setDefaultFactory(new Log4JLoggerFactory) This means that a message reached the end of the pipeline and no ""inbound handler"" was able to handle it. This most of the times shows a ""configuration"" error in the ChannelPipeline. enable debug logging in netty and it should log what kind of message is dropped Thanks this is more or less what I thought it means but am looking for suggestions on how to explore a solution. In my case (as seen inside the repo running main.scala) the pipeline is setup for http on both the sender and receiver sides and the messages sent are http. Could you suggest how can it be explored? ""configuration error"" is a very generic notion. Also can that message that supposedly went unhandled be extracted somehow? Added logging outputs in the question body. Didn't get too much logging info there. Should I enable logging any differently? Netty log the discarded inbound message at DEBUG level. Using 4.0.0.Beta3 I get this log: """"""DEBUG io.netty.channel.DefaultChannelPipeline - Discarded inbound message io.netty.handler.codec.http.LastHttpContent$1@b68d372 that reached at the end of the pipeline. Please check your pipeline configuration.""""""  In Netty 4 HTTP decoders used in servers or clients always generates multiple message objects per a single HTTP message: 1 * HttpRequest / HttpResponse 0 - n * HttpContent 1 * LastHttpContent In other words: a server receive 1 HttpRequest 0-n HttpContent(s) and 1 HttpLastContent a client receive 1 HttpResponse 0-n HttpContent(s) and 1 HttpLastContent. So if your handler only consume HttpRequest/HttpResponse the other messages will reach the end of the pipeline. You need to consume them this is where your pipeline is ""misconfigured"". OTOH you can add a HttpObjectAggregator to your pipeline so that FullHttpRequest/FullHttpResponse messages are generated instead: pipeline.addLast( ""http-aggregator"" new HttpObjectAggregator( MAX_SIZE ) ); But it means that the whole request or response including the body entity is loaded before your handler is invoked. Maybe you don't want that YMMV. So how come the discarded message warning is issued on the client side? Doesn't your answer imply that the problem is with the decoder which is on the server side? what am I missing? Thanks! From what I understand this is true for servers AND clients. Both use the HttpCodec and work in the same way. I edited my answer to make that clear. Yeah in one place in my answer I did not put HttpResponse next to HttpRequest. I edited it once again to fix that and added some content to make explicit that server or client doesn't matter (just swap *Request for *Response). Not sure how this applies to the client in the edited answer (are you saying the client receives a LastHttpContent object from the server which makes it issue the warning?). I expected the client receiving http responses not http requests."
432,A,"Asynch client connection in Netty server handler I need to open a TCP/IP client connection with my Netty Server business handler. So Receive request on server socket keep socket open Go through the pipleine and reach business handler... In business handler open asynch client connection send request to 3rd party When response received from 3rd party reply back to originating client. So in the ""business"" handler is there a way to fire asynch call to 3rd party and then when the 3rd party replies back some how attach back to that channel and reply back to the origin? Or just simply in the business handler open to 3rd party send receive reply back close channel. It's bassicaly a 1 to 1 type of thing 1 request made 1 request/response from 3rd party respond back with result. I think you are looking for something which is kind of similar to what we do in the netty examples. It's not 100% the same but kind of. Checkout the Proxy example source code: https://github.com/netty/netty/tree/3.2/src/main/java/org/jboss/netty/example/proxy Actually what I want is to receive TCP/IP and then proxy to HTTP. So I guess i can use the Hexdup sample and combine it with the HTTP Client sample? @JestanNirojan Thanks I'll look into it. But my biggest concern was the way to map the client events back to the requester in an asynch fashion. Which it seems the Hexdump sample is showing... Unless you telling me there a full proxy example with a sample Netty server on there.. :) But doesn't also Netty HTTP Client do this also? @user432024 Have a look on http://hotpotato.biasedbit.com/ its a simple client library built for this purpose (http client library for servers) which is also uses Netty. Yes ""proxy"" is what I was looking for. So I receive TCP/IP with a message in it do small transform and then forward that message asynch to the 3rd party provider get back response from 3rd party and all the way back to the requester."
433,A,"Sharing one instance of HashedWheelTimer In this question Netty Comet Async request time out It was suggested to me to share one instance of HashedWheelTimer between pipelines. My current code looks like this @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""handler"" new HTTPRequestHandler()); Timer timer = new HashedWheelTimer(); pipeline.addLast(""timeout"" new IdleStateHandler(timer 30 30 0)); return pipeline; As far as I ca see I do share one instance of HashedWheelTimer between pipeline but create new instance of IdleStateHandler each time. Is it wrong? Can anybody help me on how to do it correctly? Should I make instances of IdleStateHandler and HashedWheelTimer static? It is wrong. With this pipeline each new channel will have its own HashedWheelTimer instance. From Netty HashedWheelTimer doc you should make sure to create only one instance and share it across your application. One of the common mistakes that makes your application unresponsive is to create a new instance for every connection. You should change HashedWheelTimer instance as static keep the IdleStateHandler as it is. Thank you for the reply Will it be ok to initiate HashedWheelTimer outside of Pipeline factory class and pass its reference in constructor? Which method is preferred? Initializing HashedWheelTimer instance as static and passing the reference should be fine if you have multiple pipelines factory method is preferred. @JestanNirojan thanks this answer was useful for me too. So should the same `HashedWheelTimer` be shared between various `ChannelPipeline`s? In other words can I declare a static `Timer` variable inside the `ChannelPipelineFactory` class and use it across all my `ChannelPipeline`s I create by calling `Channels.pipeline()`?"
434,A,"How to implement ObjectDecoder(ClassResolver) in Netty 3.2.7 In netty version 3.2.5 in method public ChannelPipeline getPipeline() throws Exception { ... } have a decoder defined as follows: pipeline.addLast(""decoder"" new ObjectDecoder()); I have upgraded to Netty version 3.2.7 which has the ObjectDecoder() deprecated and it now requires a ClassResolver. Does anyone have a code example of how to implement the new ObjectDecoder(ClassResolver) in the getPipeline() method in version 3.2.7? Here's the documentation on Netty ClassResolver. http://netty.io/docs/stable/api/org/jboss/netty/handler/codec/serialization/ClassResolvers.html Pick the class resolver that best meets your requirements. I think you maybe able to do something like this: new ObjectDecoder(ClassResolvers.weakCachingConcurrentResolver(null)) Hi this link may be of help: http://markmail.org/message/4ftws33dxehbzbwd. Try specifying a ClassLoader. You may want to mark this question as answered and open another question if you still have problems. Thanks. Veebs thanks for that solution which works. I now have an exception (which is not related to this solution). The exception occurs when the client sends the message to the server. I have posted the first part of this exception. Does anyone know how this can be resolved. java.io.InvalidClassException: failed to read class descriptor at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1567) at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1496) @Veebs: I see it in the code but not in the API (javadocs)... What exactly does this do and mean?"
435,A,"JBoss Netty and UDP: multithread? I've written a simple UDP server using Netty. The server listens on one port on a certain interface. ChannelFactory factory = new NioDatagramChannelFactory( Executors.newCachedThreadPool()); ConnectionlessBootstrap bootstrap = new ConnectionlessBootstrap(factory); bootstrap.getPipeline().addLast(""MyHandler"" new TestHandler()); bootstrap.bind(new InetSocketAddress(InetAddress.getByName(""192.168.1.100"") 8080)); I use a client that sends a lot of UDP datagrams to the server. When I profile my app with VisualVM I see that there are only one thread (named New I/O worker #1) that processes the incoming messages. Is it as expected? If yes how a single thread can handle a big amount of incoming messages? I've already written an application with Spring integration that listens on a port for UDP datagrams (using a UDP inbound channel adapter) and there is one thread that listens on the port but this thread passes the incoming messages for processing to other threads of a pool. Thanks How many cores do you have on your machine? If your handler pipe line does not do any blocking or any lengthy processing it is very probable that the I/O processing will always be a lot faster than the network i.e. the IO thread will be idle and waiting for work quite a large fraction of its time. No need to allocate another thread from the pool. If on the other hand you handler involves lengthy processing or blocking calls e.g. data base or file access then you should hand of the processing to an ExecutionHandler that transfer processing from the IO worker pool to a another thread pool.  I would suggest you use Reactor pattern with java.nio - take a look at this - Is it not something that is handled internally by Netty? I admit I know Netty less. I have used JBoss remoting in the past and JBoss remoting ""wraps"" for in one of its usages java.nio. As a good practice I suggest to learn the API basics before looking at wrapper frameworks. Reactor pattern is a pattern not used just in nio but also in other frameworks and APIs (not just Java). I think the provided article will give you a good start and then if you want to ""ease your life"" with Netty - go for it :)"
436,A,"Writing different message in different TextAreas with TextWebsocketFrame in netty For writing to a socket I am using. channels.writeAndFlush(new TextWebSocketFrame(String msg)); and in my webpage (that is displayed to the client) I obtain the data from the event(event.data) and display it in the text area(say T1). but i have 2 text area's (say T1 and T2) and in both of them I want to display different data.I cant figure out a way to do this. So if i could get some implementation or some way to get the desired functionality. Thanks. You will need to encode in the WebSocketFrame some ""marker"" that can be used to detect to which frame the text goes. For example you could use Json or something like this By setting some flag in json and retrieving that flag value from json in javascripts and then on the basis of that flag value i should decide in which text area ""event.data"" should be called(to fetch data from websocket)Is this what you meant? Basically yes..."
437,A,"Netty 4 ChannelInboundMessageHandlerAdapter Which methods of class ChannelInboundMessageHandlerAdapter will actually get called when this class has been instantiated and connected to a pipeline? obviously messageReceived is (as was the case in Netty 3). What about the other methods listed on its documentation? Must an implementation override any of its other methods other than messageReceived in order to process messages? You only need to override messageReceived to process messages. You ""can"" override others if you want some ""special"" handling. Thanks. I think this should be documented more clearly even if the only documentation is Javadoc. It's not as obvious as it can be browsing the Netty 4 Javadoc. IMHO. Contributions welcome... we love patches even for javadoc :)"
438,A,"Netty Proxy delayed response I am creating a proxy with Netty framework but I am noticing that the last messages that is received tends to delay before passing to the next node. Design: Client|<---------->| Proxy |<------------>| Server Basically the issue comes when the server initiates a message their is a delay before passing it to the client or if the server sends a subsequent message right after the first message then first message goes through and the second message delays for some seconds. Why is this the case? Is there some configuration parameter that I am missing? Startup.java  Executor executor = Executors.newCachedThreadPool(); ServerBootstrap sb = new ServerBootstrap( new NioServerSocketChannelFactory(executor executor)); // Set up the event pipeline factory. ClientSocketChannelFactory cf = new NioClientSocketChannelFactory(executor executor); sb.setPipelineFactory( new ProxyPipelineFactory(cf remoteHost remotePort)); sb.setOption(""child.tcpNoDelay"" true); sb.setOption(""child.keepAlive"" true); // Start up the server. sb.bind(new InetSocketAddress(localPort)); ProxyPipelineFactory.java @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline p = pipeline(); p.addLast(""handler"" new ClientHandler(cf remoteHost remotePort)); return p; } ClientHandler.java @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { // Suspend incoming traffic until connected to the remote host. final Channel inboundChannel = e.getChannel(); inboundChannel.setReadable(false); // Start the connection attempt. ClientBootstrap cb = new ClientBootstrap(cf); cb.setOption(""child.tcpNoDelay"" true); cb.setOption(""child.keepAlive"" true); ChannelPipeline p = cb.getPipeline(); p.addLast(""famer"" new DelimiterBasedFrameDecoder(8192 false new ChannelBuffer[]{ChannelBuffers.wrappedBuffer(""</cmd>"".getBytes())})); p.addLast(""handler"" new ServerHandler(e.getChannel() trafficLock)); ChannelFuture f = cb.connect(new InetSocketAddress(remoteHost remotePort)); outboundChannel = f.getChannel(); f.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) { // Connection attempt succeeded: // Begin to accept incoming traffic. inboundChannel.setReadable(true); } else { // Close the connection if the connection attempt has failed. inboundChannel.close(); } } }); } @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) throws Exception { BigEndianHeapChannelBuffer msg = (BigEndianHeapChannelBuffer) e.getMessage(); if (log.isDebugEnabled()) { byte[] bytes = new byte[msg.capacity()]; msg.readBytes(bytes); msg.setIndex(0 bytes.length); StringBuilder out = new StringBuilder(""\nPROXY[ "").append(e.getChannel().getRemoteAddress()).append("" ---> Server ]""); out.append(""\nMESSAGE length="").append(bytes.length).append(""\n"").append(new String(bytes)); log.debug(out.toString()); } synchronized (trafficLock) { outboundChannel.write(msg); // If outboundChannel is saturated do not read until notified in // OutboundHandler.channelInterestChanged(). if (!outboundChannel.isWritable()) { e.getChannel().setReadable(false); } } } ServerHandler.java @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) throws Exception { BigEndianHeapChannelBuffer msg = (BigEndianHeapChannelBuffer) e.getMessage(); proxy(e.getChannel() msg); } private void proxy(Channel connection ChannelBuffer raw) { synchronized (trafficLock) { inboundChannel.write(raw); // If inboundChannel is saturated do not read until notified in // ClientHandler.channelInterestChanged(). if (!inboundChannel.isWritable()) { connection.setReadable(false); } } } You disable the connection's readability where do you turn it on again for reading further bytes? You can read Prxoy Server example on netty.io which does exactly the same thing. private void proxy(Channel connection ChannelBuffer raw) { synchronized (trafficLock) { inboundChannel.write(raw); // If inboundChannel is saturated do not read until notified in // ClientHandler.channelInterestChanged(). if (!inboundChannel.isWritable()) { connection.setReadable(false); } } }"
439,A,"ChannelPipelineCoverage is deprectated. Is there a drop-in replacement? I'm trying to eliminate warnings produced by a library I have to work with. I've bumped the netty version for the library to 3.5.4.Final. However the ChannelPipelineCoverage annotation appear to be deprecated. My question is: Is there any easy drop-in replacement or does this require extensive coding? If so I would love some references on how to start! Is a class without @ChannelHandler.Shareable() the same as a class with @ChannelPipelineCoverage(""one"")? Not sure if you have figured it out by now but the name has been changed to ""Sharable"" as described:NETTY-283: Logged Change Request here: and some mailing archive here: suggesting to use: import org.jboss.netty.channel.ChannelHandler.Sharable to set the reference in your Java class."
440,A,"Sending message with external call in netty socket programming I'm new to socket programming and Netty framework. I was trying to modify the Echo Server example so that the message is not sent from client as soon as a message is received but a call from another thread would trigger the client send a message to the server. The problem is the server does not get the message unless the client sends it from readChannel or MessageReceived or channelActive which are where the server is specified with a parameter (ChannelHandlerContext). I couldn't manage to find a way to save the server channel and send a message later and repeatedly. Here's my Client Handler code; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; public class EchoClientHandler extends ChannelHandlerAdapter { ChannelHandlerContext server; @Override public void channelActive(ChannelHandlerContext ctx) { this.server = ctx; } @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { // ctx.write(msg); //not } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { //ctx.flush(); } public void externalcall(String msg) throws Exception { if(server!=null){ server.writeAndFlush(""["" + ""] "" + msg + '\n'); } } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { // Close the connection when an exception is raised. ctx.close(); } } When Client creates the handler it also creates a thread with a ""SourceGenerator"" object which gets the handler as parameter so as to call the externalcall() method.  import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; /** * Sends one message when a connection is open and echoes back any received * data to the server. Simply put the echo client initiates the ping-pong * traffic between the echo client and server by sending the first message to * the server. */ public class EchoClient { private final String host; private final int port; public EchoClient(String host int port int firstMessageSize) { this.host = host; this.port = port; } public void run() throws Exception { // Configure the client. EventLoopGroup group = new NioEventLoopGroup(); final EchoClientHandler x = new EchoClientHandler(); SourceGenerator sg = new SourceGenerator(x); new Thread(sg).start(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY true) .handler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(x); } }); // Start the client. ChannelFuture f = b.connect(host port).sync(); // Wait until the connection is closed. f.channel().closeFuture().sync(); } finally { // Shut down the event loop to terminate all threads. group.shutdownGracefully(); } } public static void main(String[] args) throws Exception { // Print usage if no argument is specified. if (args.length < 2 || args.length > 3) { System.err.println( ""Usage: "" + EchoClient.class.getSimpleName() + "" <host> <port> [<first message size>]""); return; } // Parse options. final String host = args[0]; final int port = Integer.parseInt(args[1]); final int firstMessageSize; if (args.length == 3) { firstMessageSize = Integer.parseInt(args[2]); } else { firstMessageSize = 256; } new EchoClient(host port firstMessageSize).run(); } } and the SourceGenerator class; public class SourceGenerator implements Runnable { public String dat; public EchoClientHandler asd; public SourceGenerator(EchoClientHandler x) { asd = x; System.out.println(""initialized source generator""); dat = """"; } @Override public void run() { try{ while(true){ Thread.sleep(2000); dat += ""a""; asd.externalcall(dat); System.out.print(""ha!""); } }catch(Exception e){ e.printStackTrace(); } } } Thanks in advance! If you want to write a String you need to have the StringEncoder in the ChannelPipeline. Otherwise you can only send ByteBuf instances. It worked! thanks again."
441,A,"Netty4 add HttpChunkAggregator I am writing a HTTP client using Netty 4. I don't want to handle chunking manually hence I added the following to my pipeline: pipeline.addLast(""aggregator"" new HttpChunkAggregator(1048576)); However I am getting the following compilation error: cannot find symbol symbol : method addLast(java.lang.Stringorg.jboss.netty.handler.codec.http.HttpChunkAggregator) Other handlers like this are not throwing any error. Any clue on how to resolve this? I checked the latest example on git but couldn't find any relevant example. Any good example will also be of great help. It sounds like you may be following a 3.x example in Netty 4 they changed the package structure from org.jboss.netty... to io.netty.... You could use Netty 3.6 to complete you example or switch to using Netty 4 - the http examples may be a good starting point. Incidentally you can find major changes between the two versions on the project's wiki. Thanks for the reply after going through all the examples I was able to finally figure out that `HttpChunkAggregator` is now replaced with `HttpObjectAggregator`."
442,A,"Optimal setting for socket send buffer for sending image files on Netty I'm looking into implementing a HTTP image server in Netty and I was wondering what the optimal Send Buffer Size should be: ie. bootstrap.setOption(""sendBufferSize"" 1048576); I've read How to write a high performance Netty Client but I was wondering what are the consequences of setting this value too small or too large. The images I serve are mostly around 100K to 5MB (avg 1MB). I'm thinking a large (1MB) value would cause the OS memory to be filled with TCP buffered data but is there a performance penalty of setting it to a small value (ie. 8192KB)? The basic answer is 'the larger the better' but note that the receiver's socket receive buffer must be at least as large to derive any benefit at all and note the caveat in @TrustinLee's answer. @EJP is this due the nature or specification of TCP/IP? Are the buffer sizes are coordinated at start of connection and that the sender will mirror the lower of its buffer size settings or the receiver's buffer size? These buffers are used to implement TCP windowing. The receiver advertises the current amount of room in its receive buffer with each ACK. Thanks for the clarification @EJP You might find this article useful. You might also need to adjust the size of the peer's receive buffer size. In this case please make sure you set it to the server socket. Otherwise you'll be capped at 64KiB. Thanks Trustin! The article gives me a framework to calculate the buffer settings. Looks like the ""optimal"" setting is not dependent on my payload - and is affected by how much RAM you have as well as traffic expectations. I'm assuming by peer you mean the client (ie. browser?) In my case I don't have control over that so its pointless to set it higher than 64K? I guess you can simply assume the default values of the browsers your users are using and begin testing with that value."
443,A,Netty 4 Buffers pooled vs unpooled Whats the difference between Pooled vs Unpooled and Direct vs Heap in ByteBuf? Like  what does pooled means in context of a message received  because object like HttpRequest is created from ByteBuf in one of HttpRequestDecoder and then released in last handler of pipeline ? Whats pooled memory in this case? How memory management will differ for pooled vs unpooled ? The difference is that with unpooled Netty will allocate a new buffer everytime you call ByteBufAllocator.buffer which comes with some overhead especially with direct buffers. When you use pooled Netty will try to pool the buffers and so minimize the overhead of allocation and releasing of buffers.
444,A,"Convert from JSon to multiple unknown java object types using GSon I have a netty decoder which uses GSon to convert JSon coming from web client to appropriate java objects. The requirement is: Client could be sending unrelated classes Class A Class B Class C etc but I would like to use the same singleton decoder instance in the pipeline to do conversion(since I use spring for configuring it). The issue I am facing is I need to know the class object before hand. public Object decode() { gson.fromJson(jsonString A.class); } This cannot decode B or C. The users of my library now need to write separate decoders for each class instead of a cast later down the line. The only way I can see for doing this is to pass the String name of the class say ""org.example.C"" in the JSon string from web client parse it out in the decoder and then use Class.forName to get the class. Is there a better way to do this? If this is a general-purpose component think about how you would want your users to configure it. Sensible defaults are also worth thinking about. Would it make sense to have multiple decoder instances one per class? Thats how I do this currently one instance per class type. Issue is that users of my library now need to do internal details like decoders and encoders and configuring them in spring each time a new class is added. I wanted to spare them that and instead do a simple cast. GSon MUST know the class matching the json string. If you don't wan't to provide it with fromJson() you can actually specify it in the Json. A way is to define an interface and bind an adapter on it. Like :  class A implements MyInterface { // ... } public Object decode() { Gson gson = builder.registerTypeAdapter(MyInterface.class new MyInterfaceAdapter()); MyInterface a = gson.fromJson(jsonString MyInterface.class); } Adapter can be like : public final class MYInterfaceAdapter implements JsonDeserializer<MyInterface> JsonSerializer<MyInterface> { private static final String PROP_NAME = ""myClass""; @Override public MyInterface deserialize(JsonElement json Type typeOfT JsonDeserializationContext context) throws JsonParseException { try { String classPath = json.getAsJsonObject().getAsJsonPrimitive(PROP_NAME).getAsString(); Class<MyInterface> cls = (Class<MyInterface>) Class.forName(classPath); return (MyInterface) context.deserialize(json cls); } catch (ClassNotFoundException e) { e.printStackTrace(); } return null; } @Override public JsonElement serialize(MyInterface src Type typeOfSrc JsonSerializationContext context) { // note : won't work you must delegate this JsonObject jo = context.serialize(src).getAsJsonObject(); String classPath = src.getClass().getName(); jo.add(PROP_NAME new JsonPrimitive(classPath)); return jo; } } Yes.. makes sense. Accepting answer. So I would go with a TypeAdapterFactory. The main point is that JSon must provide the class to instantiate. GSon is not magical it can't guess for you :) The problem here is that Class B would not be implementing `MyInterface`. These are not logically linked classes. But probably I need to make users of the lib implement a marker interface to make this code work.  Create model class  public class MyModel { private String errorId; public String getErrorId() { return errorId; } public void setErrorId(String errorId) { this.errorId = errorId; } } Create subclass  public class SubClass extends MyModel { private String subString; public String getSubString() { return subString; } public void setSubString(String subString) { this.subString = subString; } } call parseGson Method parseGson(subClass); gson parse method with object class  public void parseGson(Object object){ object = gson.fromJson(response.toString() object.getClass()); SubClass subclass = (SubClass)object; } You can set global variables that cast to myModel ((MyModel)object).setErrorId(response.getString(""errorid""));  Unsure if this is what you were asking for but by modifying the RuntimeTypeAdapterFactory class i made a system for subclassing based on conditions in the Json source. RuntimeTypeAdapterFactory.class: /* * Copyright (C) 2011 Google Inc. * * Licensed under the Apache License Version 2.0 (the ""License""); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing software * distributed under the License is distributed on an ""AS IS"" BASIS * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.google.gson.typeadapters; import java.io.IOException; import java.util.LinkedHashMap; import java.util.Map; import com.google.gson.Gson; import com.google.gson.JsonElement; import com.google.gson.JsonObject; import com.google.gson.JsonParseException; import com.google.gson.JsonPrimitive; import com.google.gson.TypeAdapter; import com.google.gson.TypeAdapterFactory; import com.google.gson.internal.Streams; import com.google.gson.reflect.TypeToken; import com.google.gson.stream.JsonReader; import com.google.gson.stream.JsonWriter; /** * Adapts values whose runtime type may differ from their declaration type. This * is necessary when a field's type is not the same type that GSON should create * when deserializing that field. For example consider these types: * <pre> {@code * abstract class Shape { * int x; * int y; * } * class Circle extends Shape { * int radius; * } * class Rectangle extends Shape { * int width; * int height; * } * class Diamond extends Shape { * int width; * int height; * } * class Drawing { * Shape bottomShape; * Shape topShape; * } * }</pre> * <p>Without additional type information the serialized JSON is ambiguous. Is * the bottom shape in this drawing a rectangle or a diamond? <pre> {@code * { * ""bottomShape"": { * ""width"": 10 * ""height"": 5 * ""x"": 0 * ""y"": 0 * } * ""topShape"": { * ""radius"": 2 * ""x"": 4 * ""y"": 1 * } * }}</pre> * This class addresses this problem by adding type information to the * serialized JSON and honoring that type information when the JSON is * deserialized: <pre> {@code * { * ""bottomShape"": { * ""type"": ""Diamond"" * ""width"": 10 * ""height"": 5 * ""x"": 0 * ""y"": 0 * } * ""topShape"": { * ""type"": ""Circle"" * ""radius"": 2 * ""x"": 4 * ""y"": 1 * } * }}</pre> * Both the type field name ({@code ""type""}) and the type labels ({@code * ""Rectangle""}) are configurable. * * <h3>Registering Types</h3> * Create a {@code RuntimeTypeAdapter} by passing the base type and type field * name to the {@link #of} factory method. If you don't supply an explicit type * field name {@code ""type""} will be used. <pre> {@code * RuntimeTypeAdapter<Shape> shapeAdapter * = RuntimeTypeAdapter.of(Shape.class ""type""); * }</pre> * Next register all of your subtypes. Every subtype must be explicitly * registered. This protects your application from injection attacks. If you * don't supply an explicit type label the type's simple name will be used. * <pre> {@code * shapeAdapter.registerSubtype(Rectangle.class ""Rectangle""); * shapeAdapter.registerSubtype(Circle.class ""Circle""); * shapeAdapter.registerSubtype(Diamond.class ""Diamond""); * }</pre> * Finally register the type adapter in your application's GSON builder: * <pre> {@code * Gson gson = new GsonBuilder() * .registerTypeAdapter(Shape.class shapeAdapter) * .create(); * }</pre> * Like {@code GsonBuilder} this API supports chaining: <pre> {@code * RuntimeTypeAdapter<Shape> shapeAdapter = RuntimeTypeAdapterFactory.of(Shape.class) * .registerSubtype(Rectangle.class) * .registerSubtype(Circle.class) * .registerSubtype(Diamond.class); * }</pre> */ public final class RuntimeTypeAdapterFactory<T> implements TypeAdapterFactory { private final Class<?> baseType; private final RuntimeTypeAdapterPredicate predicate; private final Map<String Class<?>> labelToSubtype = new LinkedHashMap<String Class<?>>(); private final Map<Class<?> String> subtypeToLabel = new LinkedHashMap<Class<?> String>(); private RuntimeTypeAdapterFactory(Class<?> baseType RuntimeTypeAdapterPredicate predicate) { if (predicate == null || baseType == null) { throw new NullPointerException(); } this.baseType = baseType; this.predicate = predicate; } /** * Creates a new runtime type adapter using for {@code baseType} using {@code * typeFieldName} as the type field name. Type field names are case sensitive. */ public static <T> RuntimeTypeAdapterFactory<T> of(Class<T> baseType RuntimeTypeAdapterPredicate predicate) { return new RuntimeTypeAdapterFactory<T>(baseType predicate); } /** * Creates a new runtime type adapter for {@code baseType} using {@code ""type""} as * the type field name. */ public static <T> RuntimeTypeAdapterFactory<T> of(Class<T> baseType) { return new RuntimeTypeAdapterFactory<T>(baseType null); } /** * Registers {@code type} identified by {@code label}. Labels are case * sensitive. * * @throws IllegalArgumentException if either {@code type} or {@code label} * have already been registered on this type adapter. */ public RuntimeTypeAdapterFactory<T> registerSubtype(Class<? extends T> type String label) { if (type == null || label == null) { throw new NullPointerException(); } if (subtypeToLabel.containsKey(type) || labelToSubtype.containsKey(label)) { throw new IllegalArgumentException(""types and labels must be unique""); } labelToSubtype.put(label type); subtypeToLabel.put(type label); return this; } /** * Registers {@code type} identified by its {@link Class#getSimpleName simple * name}. Labels are case sensitive. * * @throws IllegalArgumentException if either {@code type} or its simple name * have already been registered on this type adapter. */ public RuntimeTypeAdapterFactory<T> registerSubtype(Class<? extends T> type) { return registerSubtype(type type.getSimpleName()); } public <R> TypeAdapter<R> create(Gson gson TypeToken<R> type) { if (type.getRawType() != baseType) { return null; } final Map<String TypeAdapter<?>> labelToDelegate = new LinkedHashMap<String TypeAdapter<?>>(); final Map<Class<?> TypeAdapter<?>> subtypeToDelegate = new LinkedHashMap<Class<?> TypeAdapter<?>>(); for (Map.Entry<String Class<?>> entry : labelToSubtype.entrySet()) { TypeAdapter<?> delegate = gson.getDelegateAdapter(this TypeToken.get(entry.getValue())); labelToDelegate.put(entry.getKey() delegate); subtypeToDelegate.put(entry.getValue() delegate); } return new TypeAdapter<R>() { @Override public R read(JsonReader in) throws IOException { JsonElement jsonElement = Streams.parse(in); String label = predicate.process(jsonElement); @SuppressWarnings(""unchecked"") // registration requires that subtype extends T TypeAdapter<R> delegate = (TypeAdapter<R>) labelToDelegate.get(label); if (delegate == null) { throw new JsonParseException(""cannot deserialize "" + baseType + "" subtype named "" + label + ""; did you forget to register a subtype?""); } return delegate.fromJsonTree(jsonElement); } @Override public void write(JsonWriter out R value) throws IOException { // Unimplemented as we don't use write. /*Class<?> srcType = value.getClass(); String label = subtypeToLabel.get(srcType); @SuppressWarnings(""unchecked"") // registration requires that subtype extends T TypeAdapter<R> delegate = (TypeAdapter<R>) subtypeToDelegate.get(srcType); if (delegate == null) { throw new JsonParseException(""cannot serialize "" + srcType.getName() + ""; did you forget to register a subtype?""); } JsonObject jsonObject = delegate.toJsonTree(value).getAsJsonObject(); if (jsonObject.has(typeFieldName)) { throw new JsonParseException(""cannot serialize "" + srcType.getName() + "" because it already defines a field named "" + typeFieldName); } JsonObject clone = new JsonObject(); clone.add(typeFieldName new JsonPrimitive(label)); for (Map.Entry<String JsonElement> e : jsonObject.entrySet()) { clone.add(e.getKey() e.getValue()); }*/ Streams.write(null out); } }; } } RuntimeTypeAdapterPredicate.class: package com.google.gson.typeadapters; import com.google.gson.JsonElement; /** * Created by Johan on 2014-02-13. */ public abstract class RuntimeTypeAdapterPredicate { public abstract String process(JsonElement element); } Example (taken from a project i'm currently working on): ItemTypePredicate.class: package org.libpoe.serial; import com.google.gson.JsonElement; import com.google.gson.JsonObject; import com.google.gson.typeadapters.RuntimeTypeAdapterPredicate; /** * Created by Johan on 2014-02-13. */ public class ItemTypePredicate extends RuntimeTypeAdapterPredicate { @Override public String process(JsonElement element) { JsonObject obj = element.getAsJsonObject(); int frameType = obj.get(""frameType"").getAsInt(); switch(frameType) { case 4: return ""Gem""; case 5: return ""Currency""; } if (obj.get(""typeLine"").getAsString().contains(""Map"") && obj.get(""descrText"").getAsString() != null && obj.get(""descrText"").getAsString().contains(""Travel to this Map"")) { return ""Map""; } return ""Equipment""; } } Usage: RuntimeTypeAdapterFactory<Item> itemAdapter = RuntimeTypeAdapterFactory.of(Item.class new ItemTypePredicate()) .registerSubtype(Currency.class) .registerSubtype(Equipment.class) .registerSubtype(Gem.class) .registerSubtype(Map.class); Gson gson = new GsonBuilder() .enableComplexMapKeySerialization() .registerTypeAdapterFactory(itemAdapter).create(); The hierachy base class is Item. Currency Equipment Gem and Map all extend this. This is nearly what i want but my basic requirement was to identify unrelated classes which I think is not possible.  Suppose you have these 2 possible JSON responses: { ""classA"": {""foo"": ""fooValue""} } or { ""classB"": {""bar"": ""barValue""} } You can create a class structure like this: public class Response { private A classA; private B classB; //more possible responses... //getters and setters... } public class A { private String foo; //getters and setters... } public class B { private String bar; //getters and setters... } Then you can parse any of the possible JSON responses with: Response response = gson.fromJson(jsonString Response.class); Gson will ignore all the JSON fields that don't correspond with any of the attributes in your class structure so you can adapt a single class to parse different responses... Then you can check which of the attributes classA classB ... is not null and you'll know which response you have received. This is for a library that is published to users -> https://github.com/menacher/java-game-server so I really wouldnt know their classes. So no way in which I can fill in Response class. @Abe so you have to parse a number of JSON responses and you don't know how they look at all? This is really hard work! Actually the client can send the class name since they know what they are sending so its not a lost cause."
445,A,"Why is it necessary to call ctx.writeAndFlush when using the MessageToByteEncoder I am implementing as SIP server on top of Netty and everything was working fine using Netty 3.x. However I decided to upgrade to Netty 4 because of the well defined threading model but things have changed a lot and I am lost. My initial question (I got most of it working but it doesn't quite make sense to me just yet) is regarding the MessageToByteEncoder and why I have to call ctx.writeAndFlush myself. The bootstrap: private void createTCPListeningPoint() { this.serverBootstrap = new ServerBootstrap(); this.serverBootstrap.group(this.bossGroup this.workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(final SocketChannel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""decoder"" new SipFrameDecoder(Protocol.TCP)); pipeline.addLast(""encoder"" new SipMessageEncoder()); pipeline.addLast(""handler"" NettyNetworkStack.this.sipHandler); } }); // .option(ChannelOption.SO_BACKLOG 128) // .option(ChannelOption.CONNECT_TIMEOUT_MILLIS 10000) // .childOption(ChannelOption.SO_KEEPALIVE true) // .childOption(ChannelOption.TCP_NODELAY true); } (the bind operation takes place later and is not shown here) Since the incoming pipeline is working (the decoder and handler is being called as they should) the only interesting part is the SipMessageEncoder which is super simple and the code for it is found below. Also note that I have been playing around with the various options but as suspected I haven't found any combination that changes this behavior. The encoder: public final class SipMessageEncoder extends MessageToByteEncoder<SipMessage> { @Override protected void encode(final ChannelHandlerContext ctx final SipMessage msg final ByteBuf out) throws Exception { final Buffer b = msg.toBuffer(); for (int i = 0; i < b.getReadableBytes(); ++i) { out.writeByte(b.getByte(i)); } out.writeByte(SipParser.CR); out.writeByte(SipParser.LF); // ctx.writeAndFlush(out); } } The SipMessage and SipParser etc are taken from my other opensource project pkts.io but is not really relevant to this question. Just know that the SipMessage.toBuffer() essentially just spits a raw byte[] which I then am transferring to the ByteBuff as passed in by Netty. The above code does not work unless I do ctx.writeAndFlush(out). However I thought as in Netty 3 that the purpose of this slightly higher-level encoder is to shield me from these details. Step debugging through the code the ByteBuf is written to the ctx but not flushed which I guess is the reason for it not showing up on the socket. So my questions are simply: Why do I have to call ctx.writeAndFlush myself when I am using the SipMessageEncoder. The NumberEncoder in the Factorial example doesn't do this and looking through the HTTP codecs I couldn't see that it did that either so obviously I am missing something obvious. Also the ByteBuf is being written to the context but is never flushed so when will it be? I tried to push a lot of traffic through a single TCP connection (using sipp) to see if that would eventually force a flush but nope nothing shows up ever. Btw I also tried to use the MessageToMessageEncoder and allocate the ByteBuf through the context and add it to the List but the same result. Btw2 – I am using Netty 4.0.10.Final Thanks /Jonas Do you call flush() somewhere else when writing a message to the channel? Blockquote ""..you must be very careful not to forget to call ctx.flush() after writing something. Alternatively you could use a shortcut method writeAndFlush()"" Blockquote Actually you don't need to call write() in the SipMessageEncoder since the message will be written by the parent MessageToByteEncode. You just need to call flush() if it hasn't been done before. Hi Igor No I do not call flush and it doesn't actually help since I am not writing anything myself. Perhaps I am misunderstanding the usage of the MessageToByteEncoder but I was under the impression that I convert one object to another (in this case ByteBuf) and at some point later in the pipeline it will get written and flushed. I am sure I am just missing something extremely obvious. If I do ctx.writeAndFlush on the bytebuf it works but then I don't really understand the point of the MessageToByteEncoder. Hi again Igor actually I think I understand what you mean. No I don't call flush in my SipMessageEncoder and perhaps there is where the problem is. I'll give that a go and if that works then thanks for getting me on the right track! Very much appreciated. I will update as soon as I have tried it but first actual work work :-) You see all messages written to the channel reside in output buffer until you call flush(). The main usage scenario is the following: you write messages to the channel followed by flush(). Each message is serialized by the MessageToByteEncoder. It is not required to call write() here. After final flush() all messages will be written to the line. If you don't call flush() before you can do it in the SipMessageEncoder. Yes you are absolutely correct. Even though I read that myself several times I was so focused on the encoder that I completely overlooked this obvious thing. Even the factorial example does this but for some reason I just didn't add two and two together. Thanks for your patience Igor very much appreciated."
446,A,"Netty large POJO transfer error: TooLongFrameException I have a netty pipeline such as:  return Channels.pipeline( new ObjectEncoder() new ObjectDecoder() new MyCustomCommandServerHandler()); For both the client and server where: MyCustomCommandServerHandler extends SimpleChannelUpstreamHandler The error I'm getting is that the POJO I'm trying to send back from the server to the client is too large and results in the following error: org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 1048576: 1816357 - discarded How do I adjust the ObjectEncoder/Decoder to take larger sized POJO objects? You can pass it via the constructor. Just checkout the javadocs. Which constructor? I haven't been able to find it in the API's? Just found it. But why doesn't it do the same for when you leave it blank since it says it puts an estimated length of 512 and then it should automatically grow? Attacker can send a very large object to saturate your heap (= DoS) So in the API when it says: ""If the length of the serialized form exceeds this value the internal buffer will be expanded automatically at the cost of memory bandwidth."" this is wrong. It doesn't automatically expand you have to pre-guess the biggest object size... And is there a way to automatically increase in cases where I don't know the dataset will be larger than normal? Nevermind I think I might've been confusing ObjectEncoder and ObjectDecoder. You have to set the max for one and the estimate for the other. But what if you don't know the max? Then you can specify Integer.MAX_VALUE. :-)"
447,A,"Netty Asynchronous Responses by Server Handler A server handler. For each received message there will be multiple responses. Business Logic involves putting the requests in a queue removing from the queue processing the requests and responding. How do i process requests asynchronously respond asynchronously while maintaining the integrity of the queue? The code below is behaves synchronously. public class TestHandler extends SimpleChannelHandler { @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { // Send greeting for a new connection. e.getChannel().write( ""Welcome to "" + InetAddress.getLocalHost().getHostName() + ""!\r\n""); e.getChannel().write(""It is "" + new Date() + "" now.\r\n""); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { String XMLFromClient = (String) e.getMessage() ; ReadXML2 rx = new ReadXML2(); String response = null; response = rx.processInput(XMLFromClient); ChannelFuture future = e.getChannel().write(response); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { e.getCause().printStackTrace(); Channel ch = e.getChannel(); ch.close(); } } In netty writes are always asynchronous but messages written to the same channel will be queued up in sequence. While reading if you want asynchronous operation then you need to add an ExecutionHandler to the ChannelPipeline. If ordering is important then use the the OrderedMemoryAwareThreadPoolExecutor implementation. You need to add it to the ChannelPipeline ahead of your own TestHandler. The new Netty 4 API provides better control over async pipeline handlers but it is still under development."
448,A,Hot to catch a websocket-close event when client changes IP address or disconnects? I'm developing an application using web-sockets. The server side is written in Java and uses Netty as application framework while the client is written in javascript/jquery. I'd like to catch any kind of client disconnection but actually I can do that only when the client goes to a different website or just reload the page of the application. Contrary if clients changes IP on-the-fly or disables the network interface (wireless or ethernet) the close event is only caught by client but not server. Is there a way to catch also this kind of close event without using ping messages? You should send PING/PONG to actually detect if a peers go down. I would have liked to avoid that mainly because javascript doesn't have any implementation but ok... if it's the only solution.
449,A,"Implementing keep-alive messages in Netty using WriteTimeoutHandler I am using Netty 3.2.7. I am trying to write functionality in my client such that if no messages are written after a certain amount of time (say 30 seconds) a ""keep-alive"" message is sent to the server. After some digging I found that WriteTimeoutHandler should enable me to do this. I found this explanation here: https://issues.jboss.org/browse/NETTY-79. The example given in the Netty documentation is: public ChannelPipeline getPipeline() { // An example configuration that implements 30-second write timeout: return Channels.pipeline( new WriteTimeoutHandler(timer 30) // timer must be shared. new MyHandler()); } In my test client I have done just this. In MyHandler I also overrided the exceptionCaught() method: public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { if (e.getCause() instanceof WriteTimeoutException) { log.info(""Client sending keep alive!""); ChannelBuffer keepAlive = ChannelBuffers.buffer(KEEP_ALIVE_MSG_STR.length()); keepAlive.writeBytes(KEEP_ALIVE_MSG_STR.getBytes()); Channels.write(ctx Channels.future(e.getChannel()) keepAlive); } } No matter what duration the client does not write anything to the channel the exceptionCaught() method I have overridden is never called. Looking at the source of WriteTimeoutHandler its writeRequested() implementation is: public void writeRequested(ChannelHandlerContext ctx MessageEvent e) throws Exception { long timeoutMillis = getTimeoutMillis(e); if (timeoutMillis > 0) { // Set timeout only when getTimeoutMillis() returns a positive value. ChannelFuture future = e.getFuture(); final Timeout timeout = timer.newTimeout( new WriteTimeoutTask(ctx future) timeoutMillis TimeUnit.MILLISECONDS); future.addListener(new TimeoutCanceller(timeout)); } super.writeRequested(ctx e); } Here it seems that this implementation says ""When a write is requested make a new timeout. When the write succeeds cancel the timeout."" Using a debugger it does seem that this is what is happening. As soon as the write completes the timeout is cancelled. This is not the behavior I want. The behavior I want is: ""If the client has not written any information to the channel for 30 seconds throw a WriteTimeoutException."" So is this not what WriteTimeoutHandler is for? This is how I interpreted it from what I've read online but the implementation does not seem to work this way. Am I using it wrong? Should I use something else? In our Mina version of the same client I am trying to rewrite I see that the sessionIdle() method is overridden to achieve the behavior I want but this method is not available in Netty. I would suggest to add the IdleStateHandler[1] and then add your custom implementation of IdleStateAwareUpstreamHandler[2] which can react on the idle state. This works out very well for me on many different projects. [1] http://netty.io/docs/stable/api/org/jboss/netty/handler/timeout/IdleStateHandler.html [2] http://netty.io/docs/stable/api/org/jboss/netty/handler/timeout/IdleStateAwareChannelUpstreamHandler.html I was able to implement the changes you suggested in under ten minutes and it works perfectly. Thank you sir! Docs have moved to [IdleStateHandler.html](http://static.netty.io/3.6/api/org/jboss/netty/handler/timeout/IdleStateHandler.html) [IdleStateAwareChannelHandler.html](http://static.netty.io/3.6/api/org/jboss/netty/handler/timeout/IdleStateAwareChannelHandler.html)"
450,A,Java Netty setAutoRead Does Netty 4(or 5) continue reading while the handler chain is invoked ? Like reading in the background and filling up a huge queue and processing all reads after the handler chain is completely ready ? I'm asking because I want to save incoming buffers to a file but files are blocking and if there are more incoming messages than the hard drive can handle do those messages queue up or does blocking the event simply stops the event queue from reading more messages ? On the sending side I use FileRegion so flow control for the writer is given. I looked into the source but I'm not entirely sure how those ChannelInvokers work it seems that if no one is specified a default one is created using eventLoop.next(). Would be nice if someone could help me to make sure that I'm not introducing a potential flow control bug... I saw the option setAutoRead but I'm pretty sure this does something different. If you want to do something like this you should specify a custom DefaultEventExecutorGroup when adding the handler that writes to the FS. This way you will hand-over the work from the EventLoop and so not block anything here. No it will not keep reading for the Channels that are assigned to the EventLoop. From a performance point of view you are right but I would like to know if Netty keeps reading in the background while the event loop is blocked. The ChunkedWriteHandler does the same (blocking the event loop when writing the next chunk) and so does FileRegion doesn't it ? But really I'm only wondering if Netty keeps reading or not.
451,A,"Amazon EC2 network speed I am a student who just started using Netty! I am building a server that communicates with android and iOS. The primary task of my server will be sending and recieving JSON files with images(10 jpegs) and texts(less than 100 character). My server's framework is Netty. I built my server from ""HttpUploadServer"" from the Netty 4.0.6 example jar. As my server's primary task is to upload and download JSON files I only used multipart POST part from the example. I built my server to respond with the same file I uploaded. So when I upload(multipart POST request) a 5mb jpeg the server responds me with the same file. It takes me about 0.8 ms to upload and recieve 5mb image in localhost. However it takes me about 10 seconds when I test the server on Amazon EC2 t1.micro. Is this a normal result for t1.micro? or Am I doing something wrong?? (BTW. I am testing my server with chrome extension called POSTMAN) I created an answer that should answer to all yours questions. 5MB is huge 10 seconds is reasonable depending on your broadband. There is nothing wrong with your code and EC2. @glautrou Thank you! I am wondering if there are any way to reduce the latency? 5MB is huge 10 seconds is reasonable depending on your broadband. There is nothing wrong with your code and EC2 your machine (localhost) is faster than a server hosted somewhere in the world. If you want to reduce the latency your can upload your files asynchronously and/or display the upload progress. There are many easy to use jQuery plugins on the Web (like jQuery File Upload)."
452,A,Which NIO library (Netty Grizzly kryonet ...) for simple backend server implementation in Java? Our frontend is simple Jetty (might be replaced with Tomcat later on) server. Through servlets we are providing a public HTTP API (more or less RESTful) to expose our product functionality. In the backend we have a Java process which does several kind of maintenance tasks. While the backend process usually does it own tasks when it's time now and then the frontend needs to wake-up the backend to execute a certain task in the background. Which (N)IO library would be ideal for this task? I found Netty Grizzly kryonet and plain RMI. For now I am inclined to say Netty it seems simple to use and it is probably very reliable. Does any of you have experience in this kind of setups? What would your choice be? thanks! [Undertow](http://undertow.io/) is new web server with impressive performance and it is default web server for [Wildfly](http://www.wildfly.org/) application server You can code servers very easily with CoralReactor. The API is super intuitive creates zero garbage and is much faster when compared to Netty. For a comparison of CoralReactor with Netty when it comes to API and simplicity you can check this article. For a comparison of CoralReactor with Netty when it comes to performance you can check this article. Disclaimer: I am one of the developers of CoralReactor. CoralReactor doesn't seem to have community edition. Feel free to educate me if I am wrong?  I would decouple them by using JMS just have some (set of) control queues your backend sits there listening on and you're done. No need to write a custom nio api here. One sample provider is hornetq. This can be run as an in process jms broker as well it uses Netty under the covers. I think a JSM here would be overkill. If I had multiple servers across different machines that would be an ideal choose.  My preference is Netty. It's simple yet flexible. Very fast and the community around Netty is awesome.  Try to translate this document which answer to your question. http://blog.xebia.fr/2011/11/09/java-nio-et-framework-web-haute-performance/ This society as french famous Java EE experts did a lot of poc of NIO servers in the context of a french challenge sponsored by VmWare (USI2011). It was about building a simple quizz app that can handle a load of 1 million connected users. They won that challenge with great results. Their implementation was Netty + Gemfire and they only replaced the CachedThreadPool by a MemoryAwareThreadPool. Netty seems to offer great performances and is well documented. They also considered Deft inspired by Tornado (python/facebook) but it's still a bit immature for them Edit: here's the translated link provided in the comments This is very interesting. I am going to try to find out why they had to switch to a MemoryAwareThreadPool since that is not very clear to me. Thanks. Feel free to ask them they'll probably answer (in english). Actually they just figured out that the thread pool was a bottleneck in their application but perhaps it won't be in your (since the app wasn't a real entreprise app but just a small quizz app with polling and stuff like that) Translated: http://translate.google.com/translate?sl=auto&tl=en&js=n&prev=_t&hl=en&ie=UTF-8&u=http%3A%2F%2Fblog.xebia.fr%2F2011%2F11%2F09%2Fjava-nio-et-framework-web-haute-performance%2F
453,A,"Netty: channel.write hangs on disconnect I have the following situation: A new channel connection is opened in this way:  ClientBootstrap bootstrap = new ClientBootstrap( new OioClientSocketChannelFactory(Executors.newCachedThreadPool())); icapClientChannelPipeline = new ICAPClientChannelPipeline(); bootstrap.setPipelineFactory(icapClientChannelPipeline); ChannelFuture future = bootstrap.connect(new InetSocketAddress(host port)); channel = future.awaitUninterruptibly().getChannel(); This is working as expected. Stuff is written to the channel in the following way: channel.write(chunk) This also works as expected when the connection to the server is still alive. But if the server goes down (machine goes offline) the call hangs and doesn't return. I confirmed this by adding log statements before and after the channel.write(chunk). When the connection is broken only the log statement before is displayed. What is causing this? I thought these calls are all async and return immediately? I also tried with NioClientSocketChannelFactory same behavior. I tried to use channel.getCloseFuture() but the listener never gets called I tried to check the channel before writing with channel.isOpen() channel.isConnected() and channel.isWritable() and they are always true... How to work around this? No exception is thrown and nothing really happens... Some questions like this one and this one indicate that it isn't possible to detect a channel disconnect without a heartbeat. But I can't implement a heartbeat because I can't change the server side. Environment: Netty 3 JDK 1.7 Ok I solved this one on my own last week so I'll add the answer for completness. I was wrong in 3. because I thought I'll have to change both the client and the server side for a heartbeat. As described in this question you can use the IdleStateAwareHandler for this purpose. I implemented it like this: The IdleStateAwareHandler: public class IdleStateAwareHandler extends IdleStateAwareChannelHandler { @Override public void channelIdle(ChannelHandlerContext ctx IdleStateEvent e) { if (e.getState() == IdleState.READER_IDLE) { e.getChannel().write(""heartbeat-reader_idle""); } else if (e.getState() == IdleState.WRITER_IDLE) { Logger.getLogger(IdleStateAwareHandler.class.getName()).log( Level.WARNING ""WriteIdle detected closing channel""); e.getChannel().close(); e.getChannel().write(""heartbeat-writer_idle""); } else if (e.getState() == IdleState.ALL_IDLE) { e.getChannel().write(""heartbeat-all_idle""); } } } The PipeLine: public class ICAPClientChannelPipeline implements ICAPClientPipeline { ICAPClientHandler icapClientHandler; ChannelPipeline pipeline; public ICAPClientChannelPipeline(){ icapClientHandler = new ICAPClientHandler(); pipeline = pipeline(); pipeline.addLast(""idleStateHandler"" new IdleStateHandler(new HashedWheelTimer(10 TimeUnit.MILLISECONDS) 5 5 5)); pipeline.addLast(""idleStateAwareHandler"" new IdleStateAwareHandler()); pipeline.addLast(""encoder""new IcapRequestEncoder()); pipeline.addLast(""chunkSeparator""new IcapChunkSeparator(1024*4)); pipeline.addLast(""decoder""new IcapResponseDecoder()); pipeline.addLast(""chunkAggregator""new IcapChunkAggregator(1024*4)); pipeline.addLast(""handler"" icapClientHandler); } @Override public ChannelPipeline getPipeline() throws Exception { return pipeline; } } This detects any read or write idle state on the channel after 5 seconds. As you can see it is a little bit ICAP-specific but this doesn't matter for the question. To react to an idle event I need the following listener: channel.getCloseFuture().addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { doSomething(); } });"
454,A,Netty: Error with HTTP Content Length over 64K I am receiving JSON Data from a client application but once in a while the HTTP content length is above 64K and I receive the following error: org.jboss.netty.handler.codec.frame.TooLongFrameException: HTTP content length exceeded 65536 bytes. I currently have the following rather naive implementation in place to read the HTTP contents: String requestContent = null; HttpRequest request = (HttpRequest) e.getMessage(); ChannelBuffer content = request.getContent(); if (content.readable()) { requestContent = content.toString(CharsetUtil.UTF_8); } Is there a way to enable receiving more than 64K of data ? Edit: Stack Trace: Aug 31 2012 2:35:20 PM org.jboss.netty.channel.SimpleChannelUpstreamHandler WARNING: EXCEPTION please implement org.eurekaj.manager.server.router.RouterHandler.exceptionCaught() for proper handling. org.jboss.netty.handler.codec.frame.TooLongFrameException: HTTP content length exceeded 65536 bytes. at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:130) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.unfoldAndFireMessageReceived(ReplayingDecoder.java:593) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:584) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:509) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:94) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.processSelectedKeys(AbstractNioWorker.java:372) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:246) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:38) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) This again cause the following error in my application which indicated that only the first 64K of data is read from the HTTP request: Caused by: org.json.JSONException: Unterminated string at character 65537 at org.json.JSONTokener.syntaxError(JSONTokener.java:410) at org.json.JSONTokener.nextString(JSONTokener.java:244) Could you please post the complete stacktrace ? Edited the original post with the stack trace. Ok then specify a different max content length in the constructor of HttpChunkAggregator. That should do the trick.. Sorry for the late response but yes. That did the trick :)
455,A,"Approach to make UDP server? I am new to Java NIO . I have a java program which queries servers (different IPs /Ports) iteratively in a loop. But now i want to send all the packets at once instead of in a loop and then store the data received in the reply packet. The query consists of only 1 reply packet no further communication is required. is this the way to do it - > Make a datagram Channel  send all packets via .send()  listen for packets and start new thread to process and store packet data. number of servers maybe >400 . Is it better to make 400 threads or 400 datagram channels ??? Also should i use async package instead of NIO . Would it be easier with Netty etc? I would get plain NIO working first. It worth noting that while TCP is reliable UDP is not. You have to allow for the fact that some packet may not arrive. For 400 TCP connections I would still use one thread unless there was a good reason to do otherwise. servers reply only to UDP. Lost packets are not a problem. I'm not familiar enough to advise of NIO but regarding replies handling - better use thread pool and channel pool. EDIT - more explanation You should have just one thread that listens on the port to which the servers reply. Upon receiving a reply submit a ""handle task"" to a tasks queue. The next available thread will pull that task and handle it. So if you have more replies (=tasks) than available threads the tasks will wait in the queue. Java has nice thread pool support under java.util.concurrent package. These limits are of course configurable. Basically the listner thread is performing a minimal operation of creating a handle-task and putting in a queue. If you're afraid of missing replies during that short period then you should configure more listener threads... But I doubt there's a real concern there. if i make a thread pool with 50 threads and reply packets received are 51 . What will happen to extra packet? @Solution why do you have 50 threads when one thread can receive 51 packats? if a packet is received while that one thread is still processing previous packet what will happen ? yair using threadpool is not as simple as you advise. It's hard to imagine why one would want to process all packets concurrently - it means there is no connection between the packets or their sending order. The standard executors in java are probably a wrong idea to pursue. My rule of the thumb is processing synchronously/in-line all messages/packets/etc from the same source. @bestsss well it does seem there's no significance to sending order. Any other logical connection between replies can be handled in a different thread(s) than the listening thread. Bottom line - IO handling and business logic should be separated. Designated threads are the workers. Working queue is the hand-off between them. I never meant to use the listening thread to carry the logic just using different pipelines/queues per source. Having absolutely independent UDP packets is quite rare. Thread model has nothing to do w/ the business logic however if 50messages come together and they all require a shared resource the entire threadpool is stuck. There shouldn't be a `QueueThread` just a queue data structure. The `PacketListenerThread` puts the reply data in the queue and the `PacketProcessorThread` removes it and processes it. A `DatabaseUpdaterThread` may exist or not. It is independent of the way replies are received from the network. You're welcome :). @bestsss if you can afford opening 400+ ports and creating 400+ listening threads - then you're right it is more simple to code and maintain. However if you cannot (which is often the case; don't know about this question though) or you think of scalablity - you have to pool your resources. In these cases the pool should be fine-tuned to withstand the expected throughput (which may be what you referred as not simple). even if you have 400ports you still need a single (or few) threads not 400. The vanilla executors in java are just not suited for the job you can have a threadpool and pipelined execution in around 200-250 lines of code. i am querying game servers so communication consists of 1 packet only and all servers are independent of each other. I am now trying to make a PacketSenderThread  PacketListenerThread PacketProceserThread QueueThread  DatabaseUpdaterThread . Is it ok ? And Packet Send/Receive order doesnot matter. Thanks.  If you are going to use UDP you can use one thread per server and one port for all of them. You may want to use a couple of port for different message types. If you use just one multi-cast & port any listener will hear all packets from any application to that IP & port. is there any existing library / open source code which handles multiple concurrent packets in java . Any sample code will also do .Thanks. How many network adapters are you listing to? If you have a 1 GB connection and your packets are 1 KB in size they won't be closer than 10 micro-seconds apart. Unless you are sending close to 100K/s they will appear to be send at almost random times. how long does .receive() method works in datagram channel? For eg. if i send a packet with .send() and put a breakpoint...wait for some time... can i still use .receive() succesfully.Thanks. UDP packets have some queues in your router and your OS. When these queues fill up packets are silently dropped. I suggest you try debugging your application and see what happens. ;)"
456,A,Netty setRadable() under the hood The netty javadoc explains that setReadable suspends/resumes the read operation of the I/O thread. My question is what is happening with the data in the meanwhile. Let's say I run setReadable(false) on a channel of a server and the client on the other side is writing data to the socket where does the data go? will it fill some buffer? Is there a way I can control this buffer or get any notifications when it overflows? Suspends or resumes the read operation of the I/O thread asynchronously. This method is a shortcut to the following code: int interestOps = getInterestOps(); if (readable) { setInterestOps(interestOps | OP_READ); } else { setInterestOps(interestOps & ~OP_READ); } It is worth mentioning that if you call setReadable(false) on a channel that already has some data to dispatch you will get the data. So If you call setReadable(false) inside channelOpen in one of your handlers you will still get messageReceived on that tunnel if the client write just as it connects. as explained on this issue It removes the interested ops for reading from then Channel. This means that the os will need to buffer everything in the network stack. Once this buffer is full new packets get discarded. How you adjust this buffer is specific to the operation system. On linux you can do it via the /proc fs. yes thats exactly what it does Yeah and I can see it buffering with netstat If after a while I setReadble(true) on that channel it supposed to read it from the OS buffer again?
457,A,"Send a http request twice using one connection with Netty I've started experimenting with Netty recently. And came up with such the code. I'm going to implement a HttpClient but I've got some restrictions: only one connection is allowed in our system. So the client is supposed to create a new connection only when the old is dead. But I haven't managed to send and get Response/Request twice over one channel. I'm using Netty - 4.0.2.Final Here is my example: object HttpClient { private val group: EventLoopGroup = new NioEventLoopGroup() private val uri = new URI(""http://www.google.at/"") var closed = false def main(args: Array[String]): Unit = run def run: Unit = { try { val req: HttpRequest = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.GET uri.getRawPath) req.headers().set(HttpHeaders.Names.HOST uri.getHost) req.headers().set(HttpHeaders.Names.CONNECTION HttpHeaders.Values.KEEP_ALIVE) req.headers().set(HttpHeaders.Names.ACCEPT_ENCODING HttpHeaders.Values.GZIP) val cl = new Bootstrap() cl.group(group).channel(classOf[NioSocketChannel]).handler(new ChannelInitializer[SocketChannel] { override def initChannel(ch: SocketChannel): Unit = { val p: ChannelPipeline = ch.pipeline p.addLast(""log"" new LoggingHandler(LogLevel.INFO)) p.addLast(""codec"" new HttpClientCodec()) p.addLast(""gzip"" new HttpContentDecompressor()) p.addLast(""aggregator"" new HttpObjectAggregator(1048576)) p.addLast(""handler"" new SimpleChannelInboundHandler[HttpObject] { override def channelRead0(ctx: ChannelHandlerContext msg: HttpObject): Unit = { if (msg.isInstanceOf[HttpResponse]) { val resp = msg.asInstanceOf[HttpResponse] println(s""STATUS: ${resp.getStatus} - ${ctx.channel}"") println(s""VERSION: ${resp.getProtocolVersion} - ${ctx.channel}"") } if(!closed) { send(ctx.channel req).addListener(new ChannelFutureListener(){ override def operationComplete(cf: ChannelFuture): Unit = { println(s""it's supposed to be a second request : ${cf}"") } }) closed = false } else { ctx.channel.close } } override def exceptionCaught(ctx: ChannelHandlerContext th: Throwable): Unit = { th.printStackTrace ctx.close } }) } }) val chF = cl.connect(uri.getHost 80).awaitUninterruptibly() chF.addListener(new ChannelFutureListener() { override def operationComplete(cf: ChannelFuture): Unit = { println(s""STATUS: ${cf} "") } }) val ch = chF.channel send(ch req).addListener(new ChannelFutureListener(){ override def operationComplete(cf: ChannelFuture): Unit = { println(s""it's a first request : ${cf}"") } }) if(ch.isActive) println(""Channel is still active"") if(ch.isOpen) println(""Channel is still open"") if(ch.isWritable) println(""Channel is still writable"") ch.closeFuture.addListener(new ChannelFutureListener(){ override def operationComplete(cf: ChannelFuture): Unit = { println(s""Channel: $cf is closed"") } }).sync } finally { group.shutdownGracefully } } def send(ch: Channel r: HttpRequest): ChannelFuture = ch.writeAndFlush(r) } After executing I get such a output: STATUS: DefaultChannelPromise@3f6a99fd(success) Channel is still active Channel is still open Channel is still writable it's a first request : DefaultChannelPromise@4d1a802(success) STATUS: 200 OK - [id: 0x8e780d38 /10.0.0.8:39594 => www.google.at/173.194.113.95:80] VERSION: HTTP/1.1 - [id: 0x8e780d38 /10.0.0.8:39594 => www.google.at/173.194.113.95:80] it's supposed to be a second request : DefaultChannelPromise@7b88f65(failure(java.lang.ArrayIndexOutOfBoundsException: -1) Channel: AbstractChannel$CloseFuture@3acefb4d(success) is closed And Exception: java.lang.ArrayIndexOutOfBoundsException: -1 at java.util.ArrayList.elementData(ArrayList.java:371) at java.util.ArrayList.get(ArrayList.java:384) at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:114) at io.netty.channel.CombinedChannelDuplexHandler.write(CombinedChannelDuplexHandler.java:193) at io.netty.channel.DefaultChannelHandlerContext.invokeWrite0(DefaultChannelHandlerContext.java:698) at io.netty.channel.DefaultChannelHandlerContext.access$1700(DefaultChannelHandlerContext.java:27) at io.netty.channel.DefaultChannelHandlerContext$18.run(DefaultChannelHandlerContext.java:689) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:353) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:366) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101) at java.lang.Thread.run(Thread.java:724) I expected to get a response for my second request but it seems like I haven't managed even to send it. Could anyone please suggest anything ? Thanks. this was solved by upgrading to the Netty 4.0.6.Final and using DefaultFullHttpRequest instead of DefaultHttpRequest."
458,A,"Netty worker threads In my netty server I create threadpools as follows.  ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool(threadFactory) Executors.newCachedThreadPool(threadFactory); Sometimes I noticed that after a certain number of connections are being worked on by the server the subsequent connections wait for one of the priors threads to finish. From the documentation of newCachedThreadPool I was under the assumption that the thread pool creates new threads as needed. Could someone help me understand why some of my connections being blocked till the prior connections finish? Would netty not create a new thread for new connection as all the existing ones are busy? How do I fix this? Any help is appreciated! Creates a thread pool that reuses a fixed number of threads operating off a shared unbounded queue. At any point at most nThreads threads will be active processing tasks. If additional tasks are submitted when all threads are active they will wait in the queue until a thread is available. If any thread terminates due to a failure during execution prior to shutdown a new one will take its place if needed to execute subsequent tasks. The threads in the pool will exist until it is explicitly shutdown. from Oracle Java Doc for newCachedThreadPool! so the thread number is fixed by Executors.newCachedThreadPool in netty default number is processer_number *2 :) When using newCachedThreadPool the threadpool does not have fixed pool size. From the link you have given newCachedThreadPool ""Creates a thread pool that creates new threads as needed but will reuse previously constructed threads when they are available."". ""The threads in the pool will exist until it is explicitly shutdown."" This is true for newFixedThreadPool. But for newCachedThreadPool ""Threads that have not been used for sixty seconds are terminated and removed from the cache."" very well netty default thread number is the point ... i found "" If no existing thread is available a new thread will be created and added to the pool"" If you have a new connection and no thread netty will create a new thread for the connection ... Thanks for the tip on max number of workers being 2 * number of processors in NioServerSocketChannelFactory. This was the reason for new request waiting for a running thread."
459,A,"Multi-reactor Design - am I trying to reinvent Netty? I am trying to migrate an existing NIO Server code-base with following characteristics - Single thread which performs accepts of connections under control of a Selector - Multiple threads which performs Socket READ/WRITE (one Thread: one Selector: one SocketChannel of accepted connection) I want to migrate to a model wherein Single READ/WRITE thread can have one Selector and multiple accepted SocketChannels could register and unregister. This way a single thread can multiplex multiple SocketChannels for IO. I understand that this model would straight-away map to a case of Netty where there is one boss thread and configurable no of workers and multiple connections per worker. ExecutionHandler is orthogonal so I am not bringing that into picture for now. Specific Question: Am I reinventing ""Netty"" wheel or is there any difference in above approach for a server which is expected to be latency-sensitive where connections could go upto 5000 and binary protocol message-exchange rates are expected to reach 60-70K msgs/sec ? I understand that numbers mentioned about would not be influenced by the said design choice alone but other factors too. But a larger influence could be made by design choice - at least that's what I believe Thanks in advance I think you are re-inventing. Netty does exactly this and more. But since netty is now well modularized you could even pick up individual maven sub-modules of netty instead of the whole thing if you dont want the rest of the functionality or ""baggage"". The basic problem with writing from scratch is that you will probably run into a ton of issues that netty has already resolved platform issues jdk work arounds and so on. For the record I was able to easily get the message rate mentioned above(actually more) for a server I have written with netty but for fewer number of clients(100) when testing on my 4 year old centrino processor laptop. Probably you should take an example from netty examples module write your 5000 connection client and test out if latency works out for you before you go down this path. Should take you just couple of hours to do that. Thanks @Abe. Just did that and I have a handful of knobs and slides to tune and wresting with it. So far I have been able to boost throughput from 1.2K/sec in original code to ~12K/sec. But the target is higher and continuing to profile the bottleneck"
460,A,"Netty 4: how to manually invoke handlers? The situation: DelimiterBasedFrameDecoder extends ByteToMessageDecoder and ByteToMessageDecoder does keep the unprocessed bytes in a ByteBuf called cumulation. I'd like to manually call this handler inside another handler to empty this cumulation ByteBuf. What I tried: DelimiterBasedFrameDecoder frameDecoder = (DelimiterBasedFrameDecoder) inboundChannel.pipeline().get(""frameDecoder""); frameDecoder.channelRead(ctx Unpooled.EMPTY_BUFFER); The problem: What I tried doesn't work because there's no next handler so Netty tells me that the bytes are lost: Discarded inbound message UnpooledHeapByteBuf(ridx: 0 widx: 57 cap: 57) that reached at the tail of the pipeline. Please check your pipeline configuration. You can wrap your handler in a EmbeddedChannel and use writeInbound() and readInbound(). Check our unit tests for usage examples and also the javadocs. I can't reuse the DelimiterBasedFrameDecoder in the EmbeddedChannel as it's not @Sharable nor can I retrieve the data that's ""stuck"" in its internal buffer (cumulation). singleDecode was set to true that's why there are(!) actually enough bytes left to be handled (which weren't handled because only 1 frame was handled). There's no more data to read from the channel that's why I want to manually perform the handling... I figured it out. If interested you can check my answer. My test client which creates 3k connections to the server that uses that code sometimes report me that 1-20/3k connections didn't send back the correct amount of replies (500 per client) but that's probably another issue (= to be debugged).  Norman put me on the right track but here's what I needed to do in my case: PublicCumulationDelimiterBasedFrameDecoder frameDecoder = (PublicCumulationDelimiterBasedFrameDecoder) cp.get(""frameDecoder""); ByteBuf bytesNotProcessed = frameDecoder.internalBuffer(); if (bytesNotProcessed != Unpooled.EMPTY_BUFFER) { PublicCumulationDelimiterBasedFrameDecoder tmpDelimiterBasedFrameDecoder = new PublicCumulationDelimiterBasedFrameDecoder(2048 false true Unpooled.wrappedBuffer(new byte[] { 0x03 })); EmbeddedChannel ec = new EmbeddedChannel(tmpDelimiterBasedFrameDecoder ... other handlers...); ByteBuf wrapper = Unpooled.buffer(); wrapper.writeBytes(bytesNotProcessed); ec.writeInbound(wrapper);// make it process the bytes // put the remaining bytes (if any) back into the original buffer bytesNotProcessed.clear(); bytesNotProcessed.writeBytes(tmpDelimiterBasedFrameDecoder.internalBuffer()); } where PublicCumulationDelimiterBasedFrameDecoder is just this: public class PublicCumulationDelimiterBasedFrameDecoder extends DelimiterBasedFrameDecoder { public PublicCumulationDelimiterBasedFrameDecoder(int maxFrameLength boolean stripDelimiter boolean failFast ByteBuf delimiter) { super(maxFrameLength stripDelimiter failFast delimiter); } public ByteBuf internalBuffer() { return super.internalBuffer(); } }"
461,A,"Set up Netty with 2-way SSL Handsake (client and server certificate) I am now trying to set up Netty with a 2 way SSL handshake where both the client and server present and verify certificates. This does not appear to be implemented in SslHandler. Has anyone does this? I suppose it would go in the SslHandler.handshake operation and be delegated to javax.net.ssl.SSLEngine? Any hints/tips/pre-existing implementations? Thanks! ANSWER (stackoverflow won't let me post it the normal way) I found that if I set the needClientAuth flag on the SSLEngine object before setting up my SslHandler that takes care of the problem! Here is the solution based on the HttpSnoop server example from the netty project. When setting up the client side pipeline the ssl engine must be set as follows: public ChannelPipeline getPipeline() throws Exception { // Create a default pipeline implementation. ChannelPipeline pipeline = pipeline(); // Uncomment the following line if you want HTTPS SSLEngine engine = SecureChatSslContextFactory.getServerContext().createSSLEngine(); engine.setUseClientMode(false); engine.setNeedClientAuth(true); pipeline.addLast(""ssl"" new SslHandler(engine)); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""logger"" new RequestAuditLogger()); // Uncomment the following line if you don't want to handle HttpChunks. pipeline.addLast(""aggregator"" new HttpChunkAggregator(1048576)); pipeline.addLast(""outputLogger"" new ResponseAuditLogger()); pipeline.addLast(""encoder"" new HttpResponseEncoder()); // Remove the following line if you don't want automatic content compression. pipeline.addLast(""deflater"" new HttpContentCompressor()); pipeline.addLast(""handler"" new HttpSnoopServerHandler()); return pipeline; } } Then your SSLContext must be modified as follows to set up a trust store in addition to a keystore (SecureChatSslContextFactory): public final class SecureChatSslContextFactory { private static Logger logger = LoggerFactory.getLogger(SecureChatSslContextFactory.class); private static final String PROTOCOL = ""TLS""; private static final SSLContext SERVER_CONTEXT; private static final SSLContext CLIENT_CONTEXT; static { SSLContext serverContext = null; SSLContext clientContext = null; // get keystore and trustore locations and passwords String keyStoreLocation = System.getProperty(""javax.net.ssl.keyStore""); String keyStorePassword = System.getProperty(""javax.net.ssl.keyStorePassword""); String trustStoreLocation = System.getProperty(""javax.net.ssl.trustStore""); String trustStorePassword = System.getProperty(""javax.net.ssl.trustStorePassword""); try { KeyStore ks = KeyStore.getInstance(""JKS""); ks.load(KeyStoreStreamManager.asInputStream(keyStoreLocation) keyStorePassword.toCharArray()); // Set up key manager factory to use our key store KeyManagerFactory kmf = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm()); kmf.init(ks keyStorePassword.toCharArray()); // truststore KeyStore ts = KeyStore.getInstance(""JKS""); ts.load(KeyStoreStreamManager.asInputStream(trustStoreLocation) trustStorePassword.toCharArray()); // set up trust manager factory to use our trust store TrustManagerFactory tmf = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm()); tmf.init(ts); // Initialize the SSLContext to work with our key managers. serverContext = SSLContext.getInstance(PROTOCOL); serverContext.init(kmf.getKeyManagers() tmf.getTrustManagers() null); } catch (Exception e) { throw new Error( ""Failed to initialize the server-side SSLContext"" e); } try { clientContext = SSLContext.getInstance(PROTOCOL); clientContext.init(null SecureChatTrustManagerFactory.getTrustManagers() null); } catch (Exception e) { throw new Error( ""Failed to initialize the client-side SSLContext"" e); } SERVER_CONTEXT = serverContext; CLIENT_CONTEXT = clientContext; } public static SSLContext getServerContext() { return SERVER_CONTEXT; } public static SSLContext getClientContext() { return CLIENT_CONTEXT; } private SecureChatSslContextFactory() { // Unused } } I wanted to comment on CStepnitz's answer. From the SslEngine docs: Configures the engine to require client authentication. This option is only useful for engines in the server mode. Not the client side as he indicated."
462,A,"netty DefaultChannelPipeline exceptionCaught Unfortunately I don't understand this output from the netty server: BUILD SUCCESSFUL Total time: 3 seconds Jul 27 2014 2:04:44 AM io.netty.handler.logging.LoggingHandler channelRegistered INFO: [id: 0xcad25a31] REGISTERED Jul 27 2014 2:04:44 AM io.netty.handler.logging.LoggingHandler bind INFO: [id: 0xcad25a31] BIND(0.0.0.0/0.0.0.0:4454) Jul 27 2014 2:04:44 AM io.netty.handler.logging.LoggingHandler channelActive INFO: [id: 0xcad25a31 /0:0:0:0:0:0:0:0:4454] ACTIVE Jul 27 2014 2:04:59 AM io.netty.handler.logging.LoggingHandler logMessage INFO: [id: 0xcad25a31 /0:0:0:0:0:0:0:0:4454] RECEIVED: [id: 0xff40b8a2 /127.0.0.1:37558 => /127.0.0.1:4454] Jul 27 2014 2:04:59 AM net.bounceme.dur.netty.ServerHandler <init> INFO: starting.. Jul 27 2014 2:04:59 AM io.netty.channel.DefaultChannelPipeline$TailContext exceptionCaught WARNING: An exceptionCaught() event was fired and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. io.netty.handler.codec.TooLongFrameException: Adjusted frame length exceeds 1048576: 2901213193 - discarded at io.netty.handler.codec.LengthFieldBasedFrameDecoder.fail(LengthFieldBasedFrameDecoder.java:501) at io.netty.handler.codec.LengthFieldBasedFrameDecoder.failIfNecessary(LengthFieldBasedFrameDecoder.java:477) at io.netty.handler.codec.LengthFieldBasedFrameDecoder.decode(LengthFieldBasedFrameDecoder.java:403) at io.netty.handler.codec.serialization.ObjectDecoder.decode(ObjectDecoder.java:68) at io.netty.handler.codec.LengthFieldBasedFrameDecoder.decode(LengthFieldBasedFrameDecoder.java:343) at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:241) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:149) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:787) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:125) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116) at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137) at java.lang.Thread.run(Thread.java:744) ^Cthufir@dur:~/NetBeansProjects/AgentServer$ thufir@dur:~/NetBeansProjects/AgentServer$ Presumably the netty-based server is complaining that it's receiving bad data in some respect? client code: package net.bounceme.dur.client.gui; import java.io.IOException; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.net.Socket; import java.util.logging.FileHandler; import java.util.logging.Handler; import java.util.logging.Level; import java.util.logging.Logger; import java.util.logging.SimpleFormatter; import net.bounceme.dur.client.jdbc.Title; public final class ApplicationDriver { private static final Logger log = Logger.getLogger(ApplicationDriver.class.getName()); private TitlesGUI gui = null; private Handler handler = null; public ApplicationDriver() throws IOException ClassNotFoundException { handler = new FileHandler(""application.log""); handler.setFormatter(new SimpleFormatter()); log.setLevel(Level.INFO); log.addHandler(handler); log.info(""starting log..""); MyProps p = new MyProps(); String host = p.getHost(); int port = p.getServerPort(); guiThread(); readWrite(host port); } private void guiThread() { Thread g; g = new Thread() { @Override public void run() { try { gui = new TitlesGUI(); } catch (IOException ex) { log.severe(ex.toString()); } gui.setVisible(true); } }; g.start(); } public static void main(String... args) throws IOException ClassNotFoundException { new ApplicationDriver(); } private void readWrite(final String host final int port) throws IOException { Thread inputOutput; final Socket socket = new Socket(host port); inputOutput = new Thread() { @Override public void run() { while (true) { try (ObjectOutputStream objectOutputStream = new ObjectOutputStream(socket.getOutputStream()); ObjectInputStream objectInputStream = new ObjectInputStream(socket.getInputStream())) { gui.setTitle((Title) objectInputStream.readObject()); Thread.sleep(1000); } catch (IOException | ClassNotFoundException | InterruptedException ex) { log.severe(ex.toString()); } } } }; inputOutput.start(); } } is it a problem that the client is using regular sockets instead of netty? Both on the client and server side POJO's are being sent. (The Title class is serializable and the serialVersionUID values match up.) a method from the GUI client (which is a bit large it's a Netbeans Swing JFrame): public void setTitle(Title title) { this.title = title; text.setText(title.toString()); } the point of the above method is for something to send objects to the GUI which is then updated accordingly. Similarly I want to fire updates or other-wise wire the GUI to socket i/o. I don't really understand the output from the netty server. Is it a problem that the server uses netty while the client uses sockets? Both use the same POJO with the serialVersionUID value. Here's the netty handler code: package net.bounceme.dur.netty; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import java.util.logging.Logger; import net.bounceme.dur.jdbc.Title; public class ServerHandler extends SimpleChannelInboundHandler<Title> { private static final Logger log = Logger.getLogger(ServerHandler.class.getName()); public ServerHandler() { log.info(""starting..""); } @Override public boolean acceptInboundMessage(Object msg) throws Exception { log.info(msg.toString()); return true; } @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { log.info(msg.toString()); ctx.write(new Title()); } @Override protected void channelRead0(ChannelHandlerContext chc Title title) throws Exception { log.info(title.toString()); chc.write(new Title()); } } Apparently none of the server handler code is executed as everything explodes immediately after the client connects. server code: package net.bounceme.dur.netty; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.serialization.ClassResolvers; import io.netty.handler.codec.serialization.ObjectDecoder; import io.netty.handler.codec.serialization.ObjectEncoder; import io.netty.handler.logging.LogLevel; import io.netty.handler.logging.LoggingHandler; import java.security.cert.CertificateException; import java.util.logging.Logger; import javax.net.ssl.SSLException; public final class Server { private static final Logger log = Logger.getLogger(Server.class.getName()); public static void main(String[] args) throws Exception { MyProps p = new MyProps(); int port = p.getServerPort(); new Server().startServer(port false); } private void startServer(int port boolean ssl) throws CertificateException SSLException InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline p = ch.pipeline(); p.addLast( new ObjectEncoder() new ObjectDecoder(ClassResolvers.cacheDisabled(null)) new ServerHandler()); } }); b.bind(port).sync().channel().closeFuture().sync(); log.info(""connected!""); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } at first glance i would say that your serverhandler needs to handle the exception. currently the exception gets flushed through the pipeline and falls off at the end. Override the method `exceptionCaught' and handle the exception. I don't think it receives bad data. It's just too big for the current settings @Moh-Aw `[java] Jul 27 2014 9:25:02 AM net.bounceme.dur.netty.ServerHandler exceptionCaught [java] INFO: io.netty.handler.codec.TooLongFrameException: Adjusted frame length exceeds 1048576: 2901213193 - discarded` in the server now -- so that **seems** better. Thank you. The TooLongFrameException raised by LengthFieldBasedFrameDecoder means one of the following: The remote peer sent a very large message which exceeds the limit. The default maximum length of a message is 1 MiB. If you expect to receive a message larger than that specify an alternative maximum length when you construct a LengthFieldBasedFrameDecoder. You passed wrong parameters to LengthFieldBasedFrameDecoder so that it is decoding a wrong place in your message. In this case you'd better re-read the Javadoc of LengthFieldBasedFrameDecoder to specify the correct values for you. thanks for the response. I'm going to come back to this. I can send datagrams back and forth ok so might have to do that? I'd rather use POJO's of course. I'll probably open a new question later this week. I'll have to do some reading before accepting the answer but that makes sense. One oddity is these are small POJO's just String Beans maybe five fields."
463,A,"Netty server for many long-lived TCP connections I'm porting some TCP server/client code to Netty. One question the server will handle long-lived connections from many clients. I don't currently need and most likely won't need to do things like broadcast to all clients in a batch operations etc... but I just need a storage place for these channels and a mechanism that allows me to selectively send notifications down to the clients given some client ID. My question is is a ChannelGroup an acceptable mechanism to hold these channels? When I first get a connection I will store the channel's ID with the client ID in a lookup map so that whenever I need to notify a particular client I will look up the channel ID I need to write to and then grap that Channel from the ChannelGroup and only send a message to that channel. Anything wrong with that approach? Thank you! No that seems reasonable although I would just store the Channel with the client id and possibly attach a listener to Channel#getCloseFuture() in order to maintain my mappings. However a ChannelGroup is still useful especially for closing ""associated"" channels as a unit. Hey So I ended up extending DefaultChannelGroup so I can internalize the mapping of the ""device id"" to the ""channel id"" and do things like getChannelByDeviceId with ease. I haven't finalized hooking it up yet but I'll let you know when it's done."
464,A,"How to skip certain handlers and directly go to specific handler in netty Let's say I have these handler flow in netty pipeline: UpHandler1 -> UpHandler2 -> UpHandler3 -> ... -> DownHandler1 -> DownHandler2 -> DownHandler3 Based on certain condition (i.e. already found response to request without doing further processing) is there anyway in my UpHandler2 I can straight go to DownHandler2 (so skip certain upstream as well as downstream handlers in between)? Is this recommended? You can use UpHandler2's ChannelHandlerContext to retrieve the ChannelPipeline. From here you can retrieve the channel handler context of any channel handler using one of the context(...) methods. Then sendDownstream for Netty 3 or write for Netty 4 will forward to the next downstream handler after the handler to which the context responds. In effect I think you'll need to get the ChannelHandlerContext for DownHandler1 and use that to write your message. Alternatively you can build the netty pipeline such that DownHandler2 is the next down stream handler from UpHandler2. If I've understood your pipeline correctly then something like pipeline.addLast(""down3"" downhandler3); pipeline.addLast('up1"" uphandler1); pipeline.addLast(""down2"" downhandler2); pipeline.addLast(""up2"" uphandler2); pipeline.addLast(""down1"" downhandler1); pipeline.addLast(""up3"" uphandler3); might work. However this could be quite brittle and also depends on whether your processing logic allows it."
465,A,How can I use netty to build reliable UDP? How can I use netty to build reliable UDP? Modify netty's source code? Or use netty as low level and implement reliable at the application layer? Thank you! Best Regards! It depends on your application's design. It is much easier to build a thin application layer (with simple data frame with sequence numbering acknowledgement frame with received sequence number and optional timer handlers to implement re-transmission) than modifying the Netty UDP transport source to add these things. This approach might face some issues like sending frames bigger thank IP frames you have handle application PDU fragmentation later you might have to keep adding more things to the layer. Any way I would do this only if TCP or SCTP (Netty 4.X supports SCTP) can not be used for the purpose. Thank you for your reply. Thank you for your reply.I want to build a fps game server that requires high time performances.So I think TCP SCTP is not so suitable.I have tested netty that it can send/receive 64KB packages so I don't think that I should care IP frames.
466,A,Running Apache MINA and Netty within the same JVM I need to run two services within my application. One is a text protocol based socket server and other is a http protocol based server. For the socket server I am using Apache MINA as the NIO Framework while for the http protocol I want to use the Netty HTTP implementation. I considered consolidating into just one framework (Netty) but I am getting some performance problems with Netty when it comes down to processing large payloads. MINA (2.0.7) does a great job of handling such load on the socket server. I also looked at MINA AsyncWeb for the HTTP server but this project seems to be dead. My question is has anyone run into this architectural dilemma. Would it be ok to run both the frameworks within the same JVM on different sockets or is there some stepping on the toes that I am not aware of. btw: I have run both frameworks as socket servers within the same JVM and successfully load tested them. All I need to do is convert the Netty socket server into a HTTP server. Thanks Sohil Can you share in which problems you ran with Netty so we can fix it ? Hi Norman please see this thread (the comments) for details.http://stackoverflow.com/questions/13422043/assembling-a-netty-message-in-the-handler. Basically with a large payload the memory utilization is fine but CPU usage is too high There is not problem running both of them in the same JVM. It will just work no need to worry Thanks Norman!!!!
467,A,"netty client response mapping I have a netty web socket server running to which various native javascript clients connect. Now what I want to do is to get requests for data from the clients and pass back data according to what each client requested. There is a class A that actually needs to send continuous data asynchronously(ie: not a simple request reply model)to the client according to the request. The question is - at class A  I have all the data that I need to send but how to figure out which data has to be sent to which client(has to be according to the client requests)  ie: how do I map the client requests  data to be sent from class A and the channel over which the data needs to be sent from class A. (I store all the channels in a shared ChannelGroup). You might want to try this. Instance a DefaultChannelGroup: DefaultChannelGroup myChannels = new DefaultChannelGroup(""myChannels"") When a web socket connect is established add it to the channel group: myChannels.add() Add the channel id and your request id to a hashmap When you have data to write I assume that you have the request id. Use it to look up your channel id in the hashmap Then get the channel from the channel group: myCahnnels.find(channelId) Lastly write the data to the channel. Hope this helps."
468,A,"Netty architecture - questions about NioWorker loop again erhere is a question about netty nioWorker Netty architecture - questions about NioWorker loop but i have a different focusi found that processRegisterTaskQueue(); processEventQueue(); processWriteTaskQueue(); although this three queues contians Runnable type，but call run() method private void processWriteTaskQueue() throws IOException { for (;;) { final Runnable task = writeTaskQueue.poll(); if (task == null) { break; } task.run(); cleanUpCancelledKeys(); } } it means handle queues synchronized，it is possible handler queues too long，and can not do processSelectedKeys in time？ by the way，when i write data，netty push the data into writeBufferQueue，and push an write task into writeTaskQueue，then handler the task when execute processWriteTaskQueue  if (channel.writeTaskInTaskQueue.compareAndSet(false true)) { // ""add"" the channels writeTask to the writeTaskQueue. boolean offered = writeTaskQueue.offer(channel.writeTask); assert offered; } why not process data in Niowork loop direct？such as processWriteBufferQueue()? Can somebody explain? thanks There are two questions in this post. The first question is: is it possible handler queues too long and cannot do process SelectKeys() in time? Yes. However it doesn't seem to happen unless your handler implementation abuses intentionally. The second question is: why is write operation always performed in the I/O loop thread? Otherwise 1) you will see a lot of contention between writer threads if you write from different threads 2) you will see various socket exceptions due to possible race conditions (connection reset etc) and 3) Netty internal will become more complicated to deal with such conditions. Please note that the thread model became more strict and event loop implementation became much simpler in Netty 4 so you might want to take a look in there too."
469,A,Difference between channel.isOpen() and channel.isConnected() in Netty? Netty defines two methods for channels: isOpen() and isConnected() but the Javadoc does not really explain the difference between both and it is not self-explanatory. Can anyone clarify? Is the following true? -) An open channel is always connected -) A connected channel does not mean one can use it to communicate it must be open too -) UDP-like channels are never connected Thanks. That's incorrect a channel can be open and not connected but a connected channel is necessarily open. You can send data to an open channel that is not connected for connectionless transports using the write method that takes a SocketAddress as a parameter. Otherwise the channel needs to already be open and connected. OK. So if a channel is open it is a SUFFICIENT condition to consider it available for read/write operations regardless of its connected status correct? @JVerstry: no it's not. That is only the case **if** it's a connection-less transport **and** you're using the correct `write` method. Otherwise if must be open **and** connected.
470,A,"How to unit test netty handler I implement a handler which extends SimpleChannelHandler and overrides some methods such as channelConnected messageReceived. However I am wondering how to unit test it？ I searched about ""netty unit test"" and found one article which said considering CodecEmbedder but I am still not sure how to begin. Do you have any example or advice on how to unit test Netty code? Thanks a lot. Check the unit tests that come with netty there is everything you get started."
471,A,"Encoding and Decoding multiple different types with Netty 5 I am trying to implement a network protocol with multiple different packet types. The problem I am facing is the most ""proper"" way of implementing this with Netty. I'll post some classes first and then describe what I want to accomplish. public class ItemStack { public ItemStack(final int item final int amount) { if (item < 0) { throw new IllegalArgumentException(""item must be non-negative integer: "" + item); } if (amount < 1) { throw new IllegalArgumentException(""amount must be positive integer: "" + amount); } this.item = item; this.amount = amount; } public int getItem() { return item; } public int getAmount() { return amount; } private final int item; private final int amount; } public class ChatMessage { public ChatMessage(final String playerName final String message) { if (playerName == null) { throw new IllegalArgumentException(""playerName must not be null""); } if (message == null) { throw new IllegalArgumentException(""message must not be null""); } this.playerName = playerName; this.message = message; } public String getPlayerName() { return playerName; } public String getMessage() { return message; } private final int playerName; private final int message; } Now all POJO that are transmitted across the network will have a packet identifier. This will be a 1-byte code that will let the decoder know what type of packet it is and how to decode it. What would be the most appropriate way of handling this case? Would it be better (read more conventional) to have one PacketDecoder class that extends the ByteToMessageDecoder which reads one byte determines the type and then in that same class decode the packet with the appropriate method like so: public class PacketDecoder extends ByteToMessageDecoder { protected void decode( final ChannelHandlerContext context final ByteBuf buf List<Object> objects) throws Exception { if (buf.readableBytes < 1) { return; } final int opcode = buf.readByte() & 0xff; final Packet packet = decodePacket(opcode); objects.add(packet); } private Packet decodePacket(final int opcode final ByteBuf buf) { if (buf == null) { throw new IllegalArgumentException(""buf must not be null""); } Packet packet = null; switch (opcode) { case 0: packet = decodeItemStack(buf); break; case 1: packet = decodeChatMessage(buf); break; // ... } return packet; } } Or would it be better to just add every type of decoder to the pipeline? I did this in my own program and I used a single decoder because it was more straight forward thing to do. The only reason I could see for wanting multiple decoders would be if need to extend or dynamically changing the protocol your server understands. For example maybe certain aspects of your server are free and others are paid for extensions that license key turns on then I could see this architecture being important. Or you load extensions to the protocol dynamically maybe. I think you need a real reason to segment decoding into several decoders besides it being architecturally pure. In this case you can add multiple decoders to the pipeline but each decoder needs to play nice and forward packets not meant for it along to the next decoder in the pipeline. You also have to be careful not to pull bytes off that down stream decoders might need. Here is what I wouldn't do. A decoder per message architecture. That will be cumbersome to write and maintain. Since there is overhead with each decoder written to play nice and forward packets I wouldn't go through that exercise each time I write a decoder. You could overcome that with a nice base class to extend but why go through all that hassle when you can just parse the first byte and do a simple if ladder? That's what my thinking was as well. One additional problem that i thought of is what happens if during the decoding of the packet the buffer runs out of readable byte? Is there some mechanic that would allow me to append the total size of the data sent before the actual data? For example if I have a packet that takes two strings. Currently string length is being written before the string data is. [string_length][string_data] but what happens if the length is readable you compare that to the amount of readable bytes left and there are actually less readable bytes left? I used FrameDecoder as my base class to make sure I could fully handle a message before I started parsing it. https://docs.jboss.org/netty/3.1/api/org/jboss/netty/handler/codec/frame/FrameDecoder.html"
472,A,What's the difference between ChannelBuffer.copy() and ChannelBuffer.duplicate() in netty What's the difference between ChannelBuffer.copy() and ChannelBuffer.duplicate()? In Multiple handlers in netty I ended up coming across a problem that was fixed if I passed a copy of a ChannelBuffer or if I called duplicate on it but I'm not sure which one should be used and the javadoc doesn't help to know which one I should be using. copy() creates an entirely new buffer (byte-for-byte). duplicate() creates a buffer which shares the original buffer's data but with its own indexes. When should I use one over the other? Eg in http://stackoverflow.com/questions/10197714/multiple-handlers-in-netty another handler seems to be be modifying the data while an async operation needs to read from the original buffer. Should I use copy() or duplicate()? In that case since you don't want to modify the buffer you just want to get around having another handler on `HexDumpProxyInboundHandler` then you only need to use `duplicate()`. Basically use `duplicate()` unless you have a *need* to use `copy()` since it creates an entirely fresh buffer.
473,A,"How can I use a separate task executor for blocking sub tasks in netty? Situation: Given the telnet client & server example of the official repo (https://github.com/netty/netty/tree/4.0/example/src/main/java/io/netty/example/telnet) I've change this a little bit using a fake blocking task: https://github.com/knalli/netty-with-bio-task/tree/master/src/main/java/de/knallisworld/poc This is Netty 4! Instead of echo replying the message (like the telnet server demo does) the channel handler blocks the thread for some time (in real world with things like JDBC or JSch ...). try { Thread.sleep(3000); } catch (InterruptedException e) {}; future = ctx.write(""Task finished at "" + new Date()); future.addListener(ChannelFutureListener.CLOSE); This actually works: I'm testing this with a echo ""Hello"" | nc localhost $port) and the thread will be blocked (and nc waits) until it returns 3 seconds later. However this means I'm blocking a thread of Netty's event loop worker group with an unrelated task. Therefor I've changed the channel registration and applied a custom executor: public class TelnetServerInitializer extends ChannelInitializer<SocketChannel> { private static final StringDecoder DECODER = new StringDecoder(); private static final StringEncoder ENCODER = new StringEncoder(); private TelnetServerHandler serverHandler; private EventExecutorGroup executorGroup; public TelnetServerInitializer() { executorGroup = new DefaultEventExecutorGroup(10); serverHandler = new TelnetServerHandler(); } @Override protected void initChannel(final SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder( 8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" DECODER); pipeline.addLast(""encoder"" ENCODER); // THIS! pipeline.addLast(executorGroup ""handler"" serverHandler); } } Unfortunately after this configuration the socket will be closed immediately after exiting handler's channelRead0(). I can see that the task itself will be processed including calling the handler's event methods. But the corresponding channel is already disconnected to the client (my nc command as already exited). How does integrating another executor work? Am I missing a detail? Your netty server is working as expected it's the echo | nc command you are testing with that is exiting early. Try using 'telnet localhost 3000' for an interactive session with your test server enter some text and you'll see that the correct response is written after a delay then the channel is closed. Or just use 'nc -v -w10 localhost 3000' write some text hit enter again you'll see the expected output after a delay and the channel closed. @knalli also add writeAndFlush to the BlockingCall return statement in the call method to see the message or else instead use a ChannelFutureListener -> operationComplete -> ctx.flush in TelnetServerHandler @derek: Well. Thank you for showing me the real problem (nc). However your last point about nc's timeout does not make any difference (I'd checked this already but not mentioned it). Telnet shows it works. Now I'm looking for a bash/script-aware solution. @jknair: thank you too. You're right that would be better but would not really necessary in this case."
474,A,"Netty SSL hostname verification support From what I can tell there is no 'flag' or config setting I can use to enable SSL hostname verification in Netty. Examples I've seen add custom implementations using the ChannelFuture returned by SslHandler.handshake(): ChannelFuture handshakeFuture = sslHandler.handshake(); handshakeFuture.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) { // get peer certs verify CN (or SAN extension or..?) against requested domain ... I just want to make sure I'm on the right track here and that I'm not missing a way to simply ""enable"" hostname verification. If you're using Java 7 you can do this by configuring the SSLSocket or SSLEngine to do it for you via the default trust manager. (This is independent of Netty.) Something like this should work: SSLContext sslContext = SSLContext.getDefault(); SSLEngine sslEngine = sslContext.createSSLEngine(); SSLParameters sslParams = new SSLParameters(); sslParams.setEndpointIdentificationAlgorithm(""HTTPS""); sslEngine.setSSLParameters(sslParams); The SSLEngine instance can be passed as an argument to the SslHandler constructor as described in this example. The endpoint identification algorithm can be either HTTPS or LDAP. For other protocols the HTTPS rules should be fairly sensible. (You can of course check that it works by connecting to that host using a wrong host name for example using a URL with the IP address instead of the host name assuming that the certificate doesn't contain a Subject Alternative Name IP address entry for it.) So far I can't get this to work. When I enable the HTTPS endpoint identification algorithm the request just times out (whether the peer cert has the correct hostname or not). I'll add more here when I know more. thanks so much for the quick answer. Totally makes sense. And in general thanks for all of your fantastic posts here and elsewhere. Your name pops up everywhere regarding SSL...I've been relying heavily on your knowledge and help. Thank you!! I must admin I haven't tried with Netty. It would be interesting to know if you see something different with [`-Djavax.net.debug=all`](http://docs.oracle.com/javase/7/docs/technotes/guides/security/jsse/ReadDebug.html) @bruno can you go to chat please ?http://chat.stackoverflow.com/rooms/19372/room-for-royi-namir-and-bruno These algorithm names are documented here: http://docs.oracle.com/javase/7/docs/technotes/guides/security/StandardNames.html#jssenames One important note: when creating the SSLEngine you need to pass in the host and port of the target server: createSSLEngine(targetHost targetPort). Otherwise you'll run into the issue documented here: http://stackoverflow.com/questions/13390964/java-ssl-fatal-error-80-unwrapping-net-record-after-adding-the-https-en"
475,A,How to reduce netty garbage production? I have network application that handles about 40k msg/sec written using netty framework and I want to reduce the number of garbage collector calls. While profiling I found that there is significant amount of byte[] instances and I suspect that it comes from this part of code : public class MessageHandler extends SimpleChannelHandler { public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) { ChannelBuffer message = (ChannelBuffer) e.getMessage(); } } Is it possible to force netty to reuse/pool ChannelBuffers somehow to prevent it to construct them every time? We plan to implement pooling of buffers but its not done yet. See https://github.com/netty/netty/issues/62 Is there a simple way I can avoid this? I have only a tcp client and don't want to produce another garbage by allocating a bunch of ChannelBuffers. Maybe I can fork netty and change a bit but I am quiet new to this library. I think there is no easy way atm. But I'm working on it. Not sure when it will get finished As it depend on my free time.. So netty creates new ChannelBuffer every time when the new message arrives? yes thats how it works atm In the general case object pooling doesn't work very well in Java. The lock overhead alone makes it challenging to get right and the pooled objects become something akin to zombies - they screw up the young/old object relationship. General advice from the JVM guys is: please don't do this. That said this particular object doesn't seem to have any children other than an array of primitives so it might work. But I don't know how helpful it'll actually be. @shg I think its one of the next things that we will finish and it will be definitly be part of netty 4.0.0.Final once it is out @NormanMaurer : Any update on this ?
476,A,"Netty - Channel instantly closed I've started working with netty and (obviously) want to send messages between clients and server. Since I am in early stage I have problems with the simple stuff in this case it's sending a message. This is how I create my server and my client: Client: public void run() throws Exception { EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .handler(new SecureChatClientInitializer()); b.option(ChannelOption.SO_KEEPALIVE true); // Start the connection attempt. ChannelFuture future = b.connect(new InetSocketAddress(host port)); Channel ch = future.awaitUninterruptibly().channel(); ch.writeAndFlush(""hi\r\n""); // Wait until all messages are flushed before closing the channel. if (lastWriteFuture != null) { lastWriteFuture.sync(); } } finally { // The connection is closed automatically on shutdown. group.shutdownGracefully(); } } Server: public void run() throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new SecureChatServerInitializer(sessionManager)); b.option(ChannelOption.SO_KEEPALIVE true); b.bind(port).sync().channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } Client Initializer: public class SecureChatClientInitializer extends ChannelInitializer<SocketChannel> { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); SSLEngine engine = SecureChatSslContextFactory.getClientContext().createSSLEngine(); engine.setUseClientMode(true); pipeline.addLast(""ssl"" new SslHandler(engine)); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder( 8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""handler"" new SecureChatClientHandler()); } } Server Initializer: public class SecureChatServerInitializer extends ChannelInitializer<SocketChannel> { ... @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); SSLEngine engine = SecureChatSslContextFactory.getServerContext().createSSLEngine(); engine.setUseClientMode(false); pipeline.addLast(""ssl"" new SslHandler(engine)); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder( 8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""handler"" new SecureChatServerHandler(sessionManager)); } } As you may have guessed from seeing the source code: Yes parts of it are from the SecureChatExample. I edited parts of it and don't understand why it isn't working anymore. When executing the client I only get one line of error message: java.nio.channels.ClosedChannelException Only call group.shutdownGracefully(); when you actually want to exit the client. If you remove that line from your client the Channel will remain open. Also you just need to suffix \n at the end of all messages sent. That did it! Thank you! :D"
477,A,"How to send a request with POST parameters in Netty? I'm trying to send a request with POST parameters in Netty. I searched Netty API Google and here (Stack Overflow) but didn't find any good way to do it. (It could be my fault of terrible searching skill :'( If so I apologize) Is there any API to do it easily? Or do I have to do it by encoding all parameters and setting it in the content by myself? Please let me know any good way to do it. Here's an example of how you would do a file upload: https://github.com/netty/netty/tree/master/example/src/main/java/io/netty/example/http/upload If you don't want to upload a file just ignore the MIME multipart bit. Try something like: HttpRequest httpReq=new DefaultHttpRequest(HttpVersion.HTTP_1_1HttpMethod.POSTuri); httpReq.setHeader(HttpHeaders.Names.HOSThost); httpReq.setHeader(HttpHeaders.Names.CONNECTIONHttpHeaders.Values.KEEP_ALIVE); httpReq.setHeader(HttpHeaders.Names.ACCEPT_ENCODINGHttpHeaders.Values.GZIP); httpReq.setHeader(HttpHeaders.Names.CONTENT_TYPE""application/x-www-form-urlencoded""); String params=""a=b&c=d""; ChannelBuffer cb=ChannelBuffers.copiedBuffer(paramsCharset.defaultCharset()); httpReq.setHeader(HttpHeaders.Names.CONTENT_LENGTHcb.readableBytes()); httpReq.setContent(cb); See Sending POST params with Netty and why isn't DefaultHttpDataFactory not in the releases? Thanks :-) Actually I just wanna know whether there is an easy way to send a request with POST parameters like the following: request.addParameter(""name"" ""value"");"
478,A,Sharing EventLoopGroup between client and server bootstraps I have an application that both acts as a UDP server and as a TCP client. Therefore I create two Bootstraps to set up Netty. Is it a good idea to share the same EventLoopGroup between the two Bootstraps? It would mean that the same thread pool will be used to: Receive/reply to UDP datagrams Receiving TCP data (Sending TCP data will be done by my application's threads.) Thanks Mickael Yes it is a good idea and yes the threads will be used for udp and tcp.
479,A,Throttling Netty connections I'm trying to find a replacement for our inhouse Non-Blocking reactor and so far Netty seems like a good fit. The only thing I couldn't figure out is if there is any throttling support for connections. I'd like to control both the incoming as well as the outgoing rate for individual connections. Is there any support or would I have to write my own throttler on top? take a look at: io.netty.handler.traffic That looks promising particularly because it allows for really granular throttling. Is this going to be part of the 4.0.0 release? this is part of 3.5.0  There isn't something like that in netty. But contributions are always welcome ;)
480,A,Netty 4.0.0_CR7: Chunked[Byte]Input does not always get drained completely Env: Win 7 / JRE 1.6.0_45 / Netty 4.0.0_CR7 My client app is streaming files to a TCP server using an implementation of ChunkedByteInput. A typical file of 10 MB size is transferred in chunks of 20 kB each resulting in some 500 chunks. The TCP connection is set up beforehand (GUI elements such as the Upload button get enabled after the connection is established) and not closed afterwards either. Instead the ChunkedByteInput implementation representing a single file prepends a header chunk containing file name and size and appends a footer chunk with the file's MD5 hash. Normally all is well. But in random cases (10-20%) transfer stops after some arbitrary chunk (ChunkedInput.readChunk() does not get called anymore). As a workaround I simply write the incomplete input to the Channel again after some extended period (say 5 sec) of inactivity is detected and transfer resumes and completes normally. But this clearly is a dirty hack. Any idea what causes this behavior? Edit: Here is the link to the related issue on Github: https://github.com/netty/netty/issues/1506 The issue could not be reproduced in isolation and was solved by upgrading to Netty 4.0.1 Solved by upgrading to Netty 4.0.1
481,A,"Netty 4.0 Difference between ChannelInboundByteHandler and ChannelInboundMessageHandler In Netty 4.0 What is the difference between ChannelInboundByteHandler and ChannelInboundMessageHandler or ChannelOutboundByteHandler and ChannelOutboundMessageHandler? Well Channel*ByteHandler operates on a ""stream"" of bytes and Channel*MessageHandler on messages. Also read [1]. [1] http://netty.io/4.0/guide/ thank you I know that but i can convert messages into bytes and i wonder what the difference is?"
482,A,"New I/O server worker threads consuming 100% CPU - Netty 3.2.5.Final We have a message middleware based on Netty in place which basically works as a http proxy. It's running on Windows 2003 1 CPU x86 2GB RAM. Netty version: 3.2.5.Final Java 1.6.0_u18 A malware software (McShield service) runs 6 minutes and consumes nearly 100% CPU. After this event 3 ""New I/O server worker"" threads are ""looping"" and consuming 100% CPU. They are somehow hanging in the SelectorUtil.select(). threaddump is not possible to do at the time (program started by win service :-/). The one below is made 8h later when the process is still using 98% of the CPU. threaddump http://www.stabilit.ch/download/sc/tr/threaddump.txt topthreads http://www.stabilit.ch/download/sc/tr/topthreads.jpg Is this a known bug? Thanks in advance! after 14h the process normalizes for some reason! forty-two's answer seems like a pretty good hit. As I was poking around for the source code for sun.nio.ch.SelectorImpl I came across this HP page reporting a similar issue. However I'm not sure if they're an exact match. One of them seems to be specific to FileSystem selectors but the other seems pretty close. It has been around for a while and has been fixed in Java 7(b12). nice guess your're talking about this: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6403933 thx! Darn. Can you try reproduction with netty 3.6 ? Unfortunately it happened with java 1.7.0_25 this night. Tough to say if its exactly the same issue .. but its consuming 100% CPU and looks very much the same.  Might be an issue similar to this: https://github.com/netty/netty/issues/302 I would definitevely try the latest 3.6 version if possible. but issue #302 (workaround) is committed for Milestone: 4.0.0.Alpha3 not for 3.6 right? Hmm maybe but there are other issues in connection with this for example https://github.com/netty/netty/issues/327. I'm getting confused trying to follow them all :-)"
483,A,"NioSocketChannel$WriteRequestQueue causing OutOfMemory I am using Netty to perform large file upload. It works fine but the RAM used by the client seems to increase with the size of the file. This is not the expected behaviour since everything is piped from the Reading the source file to writing the target file. At first I thought about a kind of adaptive buffer growing up until Xmx is reached but setting Xmx to a reasonable value (50M) would lead to an OutOfMemoryError soon after starting upload. After some research using Eclipse Memory Analyzer it appears that the object retaining the heap memory is: org.jboss.netty.channel.socket.nio.NioSocketChannel$WriteRequestQueue Is there any option for setting a limit to this queue or do I have to code my own queue using ChannelFutures to control the number of bytes and block the pipe when the limit is reached? Thanks for your help Regards Renaud Or you could increase the maximum memory. 1 GB isn't much these days. Not an option for a Desktop background application. Though it is quite a pain not to be able to transfert a file without using 1GB or RAM... Answer from @normanmaurer on Netty Github You should use Channel.isWritable() to check if the ""queue"" is full. If so you will need to check if there is enough space to write more. So the effect you see can happen if you write data to quickly to get it send out to the clients. You can get around this kind of problems when try to write a File via DefaultFileRegion or ChunkedFile. @normanmaurer thank you I missed this method of the Channel! I guess I need to read what's happening inside: org.jboss.netty.handler.stream.ChunkedWriteHandler UPDATED: 2012/08/30 This is the code I made to solve my problem: public class LimitedChannelSpeaker{ Channel channel; final Object lock = new Object(); long maxMemorySizeB; long size = 0; Map<ChannelBufferRef Integer> buffer2readablebytes = new HashMap<ChannelBufferRef Integer>(); public LimitedChannelSpeaker(Channel channel long maxMemorySizeB) { this.channel= channel; this.maxMemorySizeB = maxMemorySizeB; } public ChannelFuture speak(ChannelBuffer buff) { if (buff.readableBytes() > maxMemorySizeB) { throw new IndexOutOfBoundsException(""The buffer is larger than the maximum allowed size of "" + maxMemorySizeB + ""B.""); } synchronized (lock) { while (size + buff.readableBytes() > maxMemorySizeB) { try { lock.wait(); } catch (InterruptedException ex) { throw new RuntimeException(ex); } } ChannelBufferRef ref = new ChannelBufferRef(buff); ref.register(); ChannelFuture future = channel.write(buff); future.addListener(new ChannelBufferRef(buff)); return future; } } private void spoken(ChannelBufferRef ref) { synchronized (lock) { ref.unregister(); lock.notifyAll(); } } private class ChannelBufferRef implements ChannelFutureListener { int readableBytes; public ChannelBufferRef(ChannelBuffer buff) { readableBytes = buff.readableBytes(); } public void unregister() { buffer2readablebytes.remove(this); size -= readableBytes; } public void register() { buffer2readablebytes.put(this readableBytes); size += readableBytes; } @Override public void operationComplete(ChannelFuture future) throws Exception { spoken(this); } } }  for a Desktop background application Netty is designed for highly scalable servers e.g. around 10000 connections. For a desktop application with less than a few hundred connections I would use plain IO. You may find the code is much simpler and it should use less than 1 MB. @NumRenaud it will save some threads but if you have a desktop application running on a machine with limited resources how many connections are you using? For the smallest memory footprint with a small number of connections using simple blocking code will be more light weight. Okay what if I need 10 people to be able to download 1Gb files in parallel from the server? Do I need 10Gb of RAM on the server for this? It doesn't seems reasonable to me. In no situation should the write queue keep increasing for ever it should block at some level at least befor Xmx is reached! Potentially if you writes are getting ahead of your consumers. Netty is designed to be non-blocking or potentially close the connection. The code is already there and we will not rollback to a plain IO implementation. A lot cheaper to implement a queue where each item written to the channel when added to the queue and removed from the queue when the WriteFuture is done. That may be your best option. Netty is still going to use more memory that a plain IO solution but at least it will be more bounded. @NormanMaurer Thank you Norman you should copy paste my answer with your name to be rewarded instead of me! I agree with you but my question is ""How do you put a limit to the WriteQueue in netty"". I cannot believe that this functionality is not implemented in the API! It doesn't surprise me as you don't appear to be using netty for what it was designed for. I don't agree about memory consumption with Netty the client bootstrap is not memory-consuming and the nio approach with a worker thread will quickly allow to save some threads when performing parallel networking tasks. @NumRenaud in the next major version of netty you will be able to specify the queue implementation that you want to use. So you could just use a boundet queue here"
484,A,Why dont netty logs show proper class and package information I use SLF4J in my game server project which uses Slf4j and Log4j. However netty specific logs come out like below.  2013-06-08 13:37:30254 [Slf4JLogger.java:71][DEBUG]:Using SLF4J as the default logging framework 2013-06-08 13:37:30261 [Slf4JLogger.java:71][DEBUG]:Platform: Windows 2013-06-08 13:37:30270 [Slf4JLogger.java:76][DEBUG]:Java version: 7 2013-06-08 13:37:30273 [Slf4JLogger.java:76][DEBUG]:java.nio.ByteBuffer.cleaner: available 2013-06-08 13:37:30274 [Slf4JLogger.java:76][DEBUG]:java.nio.Buffer.address: available 2013-06-08 13:37:30274 [Slf4JLogger.java:76][DEBUG]:sun.misc.Unsafe.theUnsafe: available 2013-06-08 13:37:30275 [Slf4JLogger.java:71][DEBUG]:sun.misc.Unsafe.copyMemory: available 2013-06-08 13:37:30276 [Slf4JLogger.java:76][DEBUG]:java.nio.Bits.unaligned: true 2013-06-08 13:37:30276 [Slf4JLogger.java:76][DEBUG]:sun.misc.Unsafe: available 2013-06-08 13:37:30278 [Slf4JLogger.java:71][DEBUG]:Javassist: unavailable They dont show the actual netty class and package information. My corresponding Log4j pattern is:  log4j.appender.toLogFile.layout=org.apache.log4j.PatternLayout log4j.appender.toLogFile.layout.ConversionPattern= %d [%F:%L][%p]:%m%n What am I configuring wrong here? Try to use %c instead of %F in your pattern. %F - Outputs the file name where the logging request was issued and %c prints logger name. In Netty all logging goes through the wrapper classes in your case it's Slf4JLogger.class Your pattern should look like: log4j.appender.toLogFile.layout.ConversionPattern= %d [%c:%L][%p]:%m%n EDIT due to comment: Yes there is a way to print only filename: %c{1} See documentation: http://logging.apache.org/log4j/2.x/manual/layouts.html#Patterns This worked but is there a way to only print out the file name? Now it prints the whole package like so -> io.netty.util.internal.PlatformDependent0:76 while I just require PlatformDpeendent0:76 awesome that works! Edited my answer
485,A,"How attach an object to a channel before handlers receive events with Netty? I have a synchronization issue regarding a bind request and a upstream handler that receives a channelBound event. I need to attach an object to the channel before the handler can ever receive the channelBound event due to the fact that the handler needs to use the object to handle the callback. Example below. Handler example: public class MyClientHandler extends SimpleChannelUpstreamHandler { @Override public void channelBound(ChannelHandlerContext ctx ChannelStateEvent e) { /* Problem: This can occur while the channel attachment is still null. */ MyStatefulObject obj = e.getChannel().getAttachment(); /* Do important things with attachment. */ } } Main example: ClientBootstrap bootstrap = ... //Assume this has been configured correctly. ChannelFuture f = bootstrap.bind(new InetSocketAddress(""192.168.0.15"" 0)); /* It is possible the boundEvent has already been fired upstream * by the IO thread when I get here. */ f.getChannel().setAttachment(new MyStatefulObject()); Possible Soultions I've come up with a couple of solutions to get around this but they both kind of ""smell"" which is why I'm here asking if anyone has a clean way of doing this. Solution 1: Spin or block in the channelBound callback until the attachment is not null. I don't like this solution because it ties up an I/O worker. Solution 2: Make MyClientHandler in to a bi-directional handler and get the attachment using a ThreadLocal in a bindRequested downstream callback. I don't like this because it relies on a Netty implementation detail that the requesting thread is used to fire the bindRequested event. I find solution 1 to be more tolerable than solution 2. So if that is what I need to do I will. Is there an easy way to get a channel reference without requesting a bind or connect first? Make your ChannelPipelineFactory implementation accept a constructor parameter and specify the attachment there. Place a handler in front of all other handlers and make the first handler's channelOpen() method sets the attachment and then remove the first handler from the pipeline because it's not needed anymore.  Yes it is possible that boundEvent can get the handler before you set the attachment to the channel. If the attachment is very specific to every channel your opening then you can register a channel future listener on bind future and set the attachment on operationComplete() by setting up everything without using BootStraps. Following is a modified version of EchoClient Example It works fine.  // Configure the client. final NioClientSocketChannelFactory clientSocketChannelFactory = new NioClientSocketChannelFactory( Executors.newCachedThreadPool()); // Set up the pipeline factory. final ChannelPipelineFactory channelPipelineFactory = new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( new MyClientHandler()); } }; ChannelPipeline pipeline = channelPipelineFactory.getPipeline(); final Channel channel = clientSocketChannelFactory.newChannel(pipeline); channel.getConfig().setPipelineFactory(channelPipelineFactory); channel.getConfig().setOption(""tcpNoDelay"" true); channel.getConfig().setOption(""receiveBufferSize"" 1048576); channel.getConfig().setOption(""sendBufferSize"" 1048576); ChannelFuture boundFuture = Channels.future(channel); boundFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) { future.getChannel().setAttachment(new Object());// set the channel attachment } } }); channel.getPipeline().sendDownstream(new DownstreamChannelStateEvent(channel boundFuture ChannelState.BOUND new InetSocketAddress(host 0))); ChannelFuture connectFuture = Channels.future(channel); channel.getPipeline().sendDownstream(new DownstreamChannelStateEvent(channel connectFuture ChannelState.CONNECTED new InetSocketAddress(host port))); channel.getCloseFuture().awaitUninterruptibly(); clientSocketChannelFactory.releaseExternalResources();// do not forget to do this Thank you for your answer. I was able to get around the problem by using the ChannelFactory directly as in your example. Also your first example exhibits the same synchronization problem. After calling `bind` the `channelBound` callback could have already been called before the listener is attached to the bind future. Again as in my first comment though your second example is exactly what I needed. I agree sorry for the mistake. I have removed the first example to not to confuse future viewers :) The first example will work for clientBootstrap.connect() but not for clientBootstrap.bind() the reason is thread model differs clientBootStrap.bind is fully executed by caller thread clientBootStrap.connect() is executed by caller thread until we get the future rest of the part is executed by IO worker. I was under impression that bind works as connect :(. Any way I was correct in this case http://goo.gl/Ryg6P isn't it :)"
486,A,"Netty HTTP client download zip file I'm writing Netty client which downloads one specific large file from one specific server using one specific url (https://myserver.com/aaa.zip) over HTTPS and saves it on disk. I haven't found any example for HTTP client getting binary response so digging some documentation this is what I got: I'm using Netty 4.0.15 ChannelPipeline pipeline = socketChannel.pipeline(); SSLEngine engine = SecureSslContextFactory.getClientContext().createSSLEngine(); engine.setUseClientMode(true); pipeline.addLast(""ssl"" new SslHandler(engine)); pipeline.addLast(""codec""new HttpClientCodec()); pipeline.addLast(""handler"" new HttpWebClientHandler()); and my Handler looks like this: public class HttpWebClientHandler extends SimpleChannelInboundHandler<HttpObject> { File file = new File(""aaa.zip""); int written = 0; @Override protected void channelRead0(ChannelHandlerContext ctx HttpObject msg) throws Exception { if (msg instanceof HttpContent){ HttpContent content = (HttpContent) msg; int currentlyWritten = 0; ByteBuf byteBuf = content.content(); FileOutputStream outputStream = new FileOutputStream(file); FileChannel localfileChannel = outputStream.getChannel(); try{ ByteBuffer byteBuffer = byteBuf.nioBuffer(); currentlyWritten += localfileChannel.write(byteBufferwritten); written+=currentlyWritten; byteBuf.readerIndex(byteBuf.readerIndex() + currentlyWritten); localfileChannel.force(false); }finally{ localfileChannel.close(); outputStream.close(); } } } } My file is downloaded and have the same ammount of bytes as original one but file is corrupted and has wrong checksum. Can anybody tell me what is wrong? HttpObjectDecoder will possibly produce more than one HttpContent for a single HTTP response. You create a new FileOutputStream on every HttpContent so you will have only the last part of the response in the file. To fix the problem: Open the file on HttpRequest Write the content of all HttpContents Close the file on LastHttpContent."
487,A,"Options to convert a Netty application to a SAML2.0 Service Provider Endpoint I have an application using Netty 4.x framework that functions as some kind of server. The authentication must be federated so now I need to convert it to a SAML2.0 Service Provider. I did some research and my concern is that in order to use existing SAML2.0 solutions i.e. OpenAM PingFederate the Service Provider has to be a web application running in some kind of web container which is not the case in my project. Is this true? I am very new to the Single-sign On and Federation world I'd truly appreciate any information and tip offered. SAML in general uses the browser to keep a common ""session"" between two sites. This is done as follows: One site A.org starts a session A in the browser. It sees there is no SAML authentication and posts to the SAML identity provider. Via the browser with automatic form submission (JavaScript) The identity provider sees there is no SSO session does a login form After login form it posts back to the site A.org with an SSO session ID (so to say). If the same browser now on Site B.net starts a new session B it again posts to the SAML identity provider which now has an existing SSO session ID to return. The form posted to the SAML identity provider is automatically posted back and the returned authentification is also an automatically posted form.A kinde of cross-site scripting. A SAML servlet filter could accept this result and put a UserPrinciepal in the application request. The configuration is not too difficult. You need your own unique key pair for your ""server"" All-in-all it was rather time consuming. It helped to set up ones own Identity Provider too. Apache Shiro a security solution outside the Java EE server world did not have a SAML solution at the time I worked on SAML. If you got a demo IdP and SP running it should not be too difficult to short-cut everything. Maybe using FireFox with the TamperData add-on to inspect the communication. If you indeed to do it yourself having a working IdP / SP1 / SP2 helps. The data exchange is probably simple copying it as template and using apache HttpClient to post a filled in text should be simple. _(It still does need developing perseverance.)_ Thanks for your excellent explanation Joop. My questions: 1. I assume that this ""SAML servlet filter"" working on the SP side but my Netty application cannot be a servlet so it seems that I have to have a separate module for this purpose. Do you know what would be the common practice to do this? 2. I do have access to the IdP the problem I am trying to solve is how to get my application functioning as a SP."
488,A,"Netty ChannelBuffer in Ver 4.0 I'm migrating a system from Netty ver 3. to Ver 4. I would like to use a string delimiter in the handler. How do i do this in Netty 4? pipeline.addLast(""frameDecoder"" new DelimiterBasedFrameDecoder(8192 ChannelBuffers.wrappedBuffer(""</message>"".getBytes()))); You can use the following: pipeline.addLast(""frameDecoder"" new DelimiterBasedFrameDecoder(8192 Unpooled.wrappedBuffer(""</message>"".getBytes())))"
489,A,"concurrency encoding of netty Will encoder's encode method executing concurrently? I observe the encode method might be concurrent by different threads. The pipeline define as: Channels.pipeline( idleHandler new AmfDecoder<GameEvent>(GameEvent.class) new AmfEncoder<GameEvent>() concurrencyHandler new WebHandler()); Encoder: public class AmfEncoder<T extends IAmfEvent> extends OneToOneEncoder{ private final SerializationContext serializationContext = new SerializationContext(); private final Amf3Output amfout = new Amf3Output(serializationContext); @Override protected Object encode(ChannelHandlerContext arg0 Channel arg1 Object arg2) throws Exception { T e = (T)arg2; ByteArrayOutputStream byteoutStreamSize = new ByteArrayOutputStream(); amfout.setOutputStream(byteoutStreamSize); amfout.writeObject(e.getBody()); // byteoutStreamSize has small probability become empty at here in debug mode I can sure e.getBody() has data // I thought byteoutStreamSize might be empty by another thread call ""amfout.flush()"" or ""amfout.reset()"" amfout.flush(); //... amfout.reset(); } } The calling of Channel.write is not only threads belong to netty's worker thread or threads in Exeutionhandler. There is a thread pool which created by my own will call Channel.write(). After I move 2 variables of amfout & serializationContext into encode() function to be local variable the problem disappear. Doc says ChannelPipeline is thread safe I read netty 3.4.5 found ""add"" ""remove""... operation is locked but sendDownstream & sendUpstream has no lock. So if there are threads which not belong to worker thread pool or ExecutionHandler thread pool and all of these threads call Channel.write() concurrent problem will happen in decoder & encoder The Channel pipeline is thread safe but the problem here is that the event execution model is different for downstream events and upstream events: Downstream Handlers are executed using (multiple) user threads by default. Downstream Handlers are not thread safe by default since they can be executed by multiple user thread in any order (normally DownstreamEvents are lightweight and so their handlers do not maintain state in instance variables). Have a look at OneToOneEncoder implementations in the Netty code base. None of them maintains a state. Upstream handlers are executed using a single thread by default or using multiple threads one by one (if execution handler is used). Upstream Handlers are thread safe because of single threaded event execution (even though they can hold mutable state). So someone can mistakenly think that downstream handlers are as thread safe as upstream handlers. As you said the solution would be moving the instance variable to local scope if state is not required. Otherwise make the downstream handling method thread safe.  I think you understand the concurrency correctly. You must either: Ensure your channel handlers are thread safe (no mutating instance variables) Use a ChannelPipelineFactory so that a new pipeline is created for each channel."
490,A,Channel.isWritable notofication in Netty I have a scenario where I need to keep writing to a Channel. In case it is unable to take further data ( because of the buffers being full etc )  I need to stop writing  but need to resume as soon as the channel becomes writable again. How do I determine this instant when a channel becomes writable again ? Is there a callback event that is fired which I can override ? I am extending SimpleChannelUpstreamHandler in my business handler - this has a method channelInterestChanged() - but not sure if this is correct hook to tap into ? I was hoping to avoid using primitive thread-based wait mechanisms like wait-notify as these will involve context switching. Any non-blocking way to achieve this wait ? You can override the channelInterestChanged() method. Something like that: public class MyHandler extends SimpleChannelUpstreamHandler { .... @Override public void channelInterestChanged(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { if (e.getChannel().isWritable() { ..... } } } This should do the job
491,A,"Netty in Spring and slf4j Logger Factory My basic question is. How do I configure Netty to use slf4j in Spring? I keep getting the error below in Spring but not eclipse using the slf4j jars with the log4j bridge and api in the path. I am using Spring Tools suite spring 3.2.3 and Netty 4 (post jboss). Exception in thread ""main"" java.lang.NoClassDefFoundError: org/slf4j/LoggerFactory The program fails at the line where I instantiate the connection group after I try setting the default logging factory. I am really new to Netty and slf4j. I have been banging my head against this one for a while and done a bit of research on Stack Overflow and the internet. I managed to get Netty working with slf4j in eclipse and used the Internal Logger Factory. I tried configuring slf4j in a similar way to log4j (A properties file with appenders). I used the following code for the InternalLoggerFactory in both of the following ways with the appropriate imports. InternalLoggerFactory.setDefaultFactory(new Slf4JLoggerFactory()); and InternalLoggerFactory.setDefaultFactory(Slf4JLoggerFactory.getDefaultFactory()); These lines are placed immediately before my initialization of the connection group but I tried them in my Main App/Driver's main method as well. Thanks for any help. I would and do really appreciate it. In slf4j many things depend on the slf4j libaries that are in the classpath. Could you please add a list of slf4j jars that you use (`*slf4j*.jar`)? jul-to-slf4j-1.7.5.jar slf4j-simple-1.75.jar slf4j-api-1.75.jarlog4j-to-slf4j-2.0-beta8.jarlog4j-1.2.16.jar and thanks as an update. could the problem be with logback classic? the version is 1.0.13 ´org.slf4j.LoggerFactory´ is part of ´slf4j-api-1.75.jar´ so it is likely that you have some deployment problem. -- Check that this jar is really in the classpath of you application or if you have an web application then check that this jar is deployed to you application server. One other thing (that is maybe not the cause of your problem) is that you have log4j-1.2.16.jar and log4j-to-slf4j-2.0-beta8.jar. This is will lead to other problems because log4j-to-slf4j is a log4j-to-slf4j bridge that forward log4j loggers to slf4j. On the ohter hand you have the real log4j in your classpath too. I would remove log4j-1.2.16.16. I hope this slf4j docu describe it a bit better than me. An other point that brothers me is that you use different version of slf4j. I strongly recommend to use the same version for all slf4j libs! This is close to the answer and I really appreciate the response. I had descended into dependency nightmare and you saved me. I really appreciate that. I actually found that a jar exists called sfl4j-jdk in of the site where the docs are. After cleansing my path it solved everything. Strangely it is never mentioned anywhere."
492,A,"netty: why code in handler can not use future.await()? every body hello! I use netty 3.1 to build a socket dispatch server which transfer socket data to another socket server so I create a client connect in netty sever handler when first message arrived and wait unit the connect is complete when next messageRecv event arrives I just transfer the buffer from server channel to client channel. But I find it is forbidden in handler when using future.await*() operation. If I not use await() because the connectFuture is sync there is a chance that when the next message arrive but the conenct is not complete. I don't konw how to deal the issue. How can I make sure the client connect is complete before next messageRecv event arrived ? Right now I just make a lock to synchronize two code just like this: /** * server handler */ public class ServerChannelHandler extends SimpleChannelUpstreamHandler { private static Logger _logger = LoggerFactory.getLogger(cn.szboc.dispatch.server.netty.ServerChannelHandler.class); public ServerChannelHandler(ProxyClientFactory clientFactory) { this.clientFactory = clientFactory; } /** factory connect another server */ private ProxyClientFactory clientFactory; /** anotherchannel */ private Channel innerChannel; private ChannelFuture connectFuture; private ReentrantLock connectLock = new ReentrantLock(); private Condition notComplete = connectLock.newCondition(); @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { final ChannelBuffer buffer = ((ChannelBuffer) e.getMessage()).copy(); final Channel outChannel = ctx.getChannel(); // first connect if (connectFuture == null) { final ClientChannelHandler cch = new ClientChannelHandler(ctx.getChannel()); ProxyClient client = clientFactory.retrieveClient(); connectFuture = client.getConnectChannelFuture(); connectFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { connectLock.lock(); try { if (future.isSuccess()) { innerChannel = future.getChannel(); innerChannel.getPipeline().addLast(""clientchannelhandler"" cch); innerChannel.write(buffer); } else { Channels.fireExceptionCaught(outChannel future.getCause()); } } finally { notComplete.signal(); connectLock.unlock(); } } }); } else { connectLock.lock(); try { if (!connectFuture.isDone()) { if (!notComplete.await(500 TimeUnit.MILLISECONDS)) { throw new Exception(""""); } } if (connectFuture.isSuccess()) { if(innerChannel == null){ if (!notComplete.await(500 TimeUnit.MILLISECONDS)) { throw new Exception(""""); } } innerChannel.write(buffer); } else { _logger.error(""""); } } finally { connectLock.unlock(); } } } You can't because you could deadlock netty. You would also block the IO-Worker thread which is a bad thing. The best way to handle your situation is to ""queue"" the messages until the connect is complete and then dispatch them. An other solution would be to connect to the proxy client on the ""channelOpen(..)"" method while set Channel.setReadable(false) before. After the connect is done you would then call Channel.setReadable(true) again so you will get messageEvents processed. Something like this:  @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { // Suspend incoming traffic until connected to the remote host. final Channel inboundChannel = e.getChannel(); inboundChannel.setReadable(false); // Start the connection attempt. ClientBootstrap cb = new ClientBootstrap(cf); cb.getPipeline().addLast(""handler"" new OutboundHandler(e.getChannel())); ChannelFuture f = cb.connect(new InetSocketAddress(remoteHost remotePort)); outboundChannel = f.getChannel(); f.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) { // Connection attempt succeeded: // Begin to accept incoming traffic. inboundChannel.setReadable(true); } else { // Close the connection if the connection attempt has failed. inboundChannel.close(); } } }); } See the proxy example for more details [1]. [1] https://github.com/netty/netty/tree/3.2/src/main/java/org/jboss/netty/example/proxy Thank you very much i choose your second solution but find the function inboundChannel.setReadable(false); is asynchronized and the channelFuture bean that returned seems like not invoke any listner added to itself. so i step into netty 3.1 code Class org.jboss.netty.channel.socket.nio.NioWorker line 659 to line 732 in the function ""void setInterestOps( NioSocketChannel channel ChannelFuture future int interestOps) "" i found if the key == null or selector is null the function is just return not set the future's status is that right? To tell the truth i don't catch any more in netty core code. but i think the setting opertion in ""inboundChannel.setReadable(false)"" is just function invoke but not asynchronized. I think it is safe to use the second solution which from you thanks! Sorry I don'T understand your problem.. Can you give me some more detail ? You are right thats a bug in setInterestedOps(..). I will fix it. Thanks! sorry I come form China my english is very poor thanks very much the example which you provide is so good that gives me many point."
493,A,Can someone better explain Decoders/Encoders? Revised Question: Ok so I am trying to incorporate this in my own custom made game. I understand the process of how Netty Servers and Clients connect. I also understand how the decoders and encoders work in theory. But here's what I still would like to understand. My server process: Server boots up -> Client starts Client requests connection -> Server accepts Server instructs client connection is good -> Client continues to the login screen (Ignoring any type of security protocol) Client sends username and password over Channel Server gets username and password checks it in the database or file Server pushes -> yes or no if yes Server sends player stats if no Server creates new player After that process I know I need to have a world handler so that everyone is seeing updates in near real time. Now I don't know how to implement decoders for this stuff. I really would like to see some examples with some explanations of how they are implemented. with preferably some instructions.... Note: I am not saying solve this issue for me but show me how to handle the different information. Best practices and standards please.... I would like to add on this I am referencing the Netty API and how it uses decoders and encoders really... I feel as though the guide doesn't really go into any detail about implementing your own decoders and how... Also I want to reiterate as I said this last time. I have been pounding my head on this for awhile and I just can't seem to grasp this... People write their own encoders/decoders (codecs) because Netty doesn't impose nor define an application level protocol so that you are free to write your own protocol. The set of codecs you define is a protocol that can be anything between String based and some binary format as Protobuf for example. Netty provides codecs for your convenience (the ones you used are examples). I would assume this is to keep the stream from being cutoff early? Usually when you are sending/receiving streams you need to decompose that on a fixed length chunks (called frames). A popular approach that has been used since the dawn of the Internet is to use the length of the chunk (usually a 4 bytes int) as the first field read from the stream. So if the value of the first int is 20 then you know that the following 20 bytes are the payload (the data) and the 21th byte is the first byte of another length. The advantage of this approach is that it allows chunks of variable length. But you are not limited to this. For example if you plan to write a protocol that uses Strings with predefined length (with padding) then you'll write or even better use Netty current codecs appropriate to it. Once I implemented a protocol with three decoders that would perform in this order: receive a stream and decompose it in length prefixed frames; convert each frame to a string; use Jackson libray to convert a string to a predefined Java object. The encoders would just do the same operations but backwards. Unfortunately I've lost the original code but I will rewrite it soon. But how does the stream know that the stream is a String or a series of int's or a series of doubles? How do you tell it the difference is the question? Short answer: it doesn't know. You have to encode this info in the codecs. For example you can use a opcode as the first field in the payload that says that payload are Strings doubles ints or any combination of both. Basically Netty provides a stream and you are free to decode as you like. For example if you are reading a series of longs (8 bytes) then you are going to write a codec that reads 64 bytes at a time from the stream because each one represents a single long. Netty provides codecs out-of-box so that you don't need to reinvent the wheel every time. thanks that makes sense and clears it up a little bit... At lease kinda lets me know that I had the right impression of how it works...  I submit this tutorial for your consideration. Not trying to pawn you off but I tried to explain these exact mysteries therein. It is the second in a series you might want to read the first one too. I read everything in this and though yes it is very useful information it was also very theoretical and not very hands on code examples and stuff like that... Gives a great grasp at how it works though. Thanks! But I'm still left with a major question.... How do you implement your decoders/encoders? I am still reading your content and will be back later with a decision....
494,A,Streaming Upload/Download I'm trying to create a controller to download and upload files using streaming method in my case all files are saved in database as a Blob. I read the documentation of Jboss Netty but i don't think if is the best solution in my case. Is there a someone who have done something like that before ? Are you sure you want to save your files in DB? I've just refined an app which was saving the files in DB because the performance after a few months (when there were a lot of data) was a nightmare.. I'dont save directly file in DB firstly i convert it to a byte array and after i deflate the array using java Zlib and finaly i save the deflated array in DB it's better than to save a file directly in DB Have a look at this for an example of file upload/download. You can add additional processing (compressing...) within your controller. Thank you for your reply but the problem is how can i upload/download larger files (>3Go) ? if i use the simple way with JPA i'm sure that i'll explode memory so i'm looking for a streaming method to optimize upload/download using some javascript in client side to split file into chunks and send them to the server in upload case & to assemble chunks sended by the server in download case [Something like that](http://kongaraju.blogspot.fr/2012/07/large-file-upload-more-than-1gb-using.html) I am not sure if this would be very practical as this means the client's browser would need to load the whole file in memory to compress it. With a 3Gb file that would make most clients unusable. Consider forcing the clients to zip the files themselves might be a better solution. Read this related post: http://stackoverflow.com/questions/1939791/html-compress-file-upload
495,A,Making one http request with Netty In all of the http examples for Netty the client is making just one request and then closes all resources. In order to make the request two new thread pulls are created: ClientBootstrap bootstrap = new ClientBootstrap( new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); And I'm wondering if this is necessary for just one request especially when the requests in the examples are synchronized isn't there a simpler way to make that just one request? Thanks. Why do you need Netty for just one request? There are simpler ways to do that. Using of Netty implies working with heavy load. So why didn't they show how to reuse the *NioClientSocketChannelFactory* instance in their examples? That would make more sense. Anyway I get your point. Thanks. I'm new to Netty and going over the examples for http and it just seemed strange to me the way it's done in there. I agree that there are simpler ways than Netty for that so why haven't they used one there instead? Or alternatively why haven't they showed a few clients sharing the *NioClientSocketChannelFactory*? I was basically just curious. Because requests are not handled synchronously in Netty. Requests are sent in one thread responses are handled in another one.
496,A,RTSP Media Server Using Netty After carrying out some research I have found out that an RTSP media server for develivering video and audio can be implemeneted in java using Netty. After consulting the web site and veiwing the documentation I have still not found any real help on how an RTSP media server can be implemeneted using it. I have been stucktrying to solve this problem for a while now and I am well aware of the RTSP protocol other streaming protocols and all the issues that come with streaming media. Could someone please piont me at a place to start so that I can slowly work my way through the implemenattion of an RTSP server in java (Netty). Any online documentation or source code that is reasonably close to this issue or shows the very basics would be a great help. Thank you. You could take a look at flazr which is Netty implementation for streaming protocols like RTMP. Another place where you might find relevant information is the related projects page of Netty.  I think the best way to solve it is to create a new Netty project and make a HTTP server and client then modify it into a RTSP server and client.
497,A,"Netty: Should I close the Channel if it's a 'keep-alive' connection? I'm writing an HTTP server with Netty. I set the keep-alive option when I create server bootstrap. bootstrap.setOption(""child.keepAlive"" true); Each time I write an HTTP response I set the keep-alive header and close the channel after writing response. rep.setHeader(""Connection"" ""keep-alive""); channel.write(rep).addListener(ChannelFutureListener.CLOSE); I'm not sure if I'm supposed to close the Channel. Hard to see what the mystery is here. You can't seriously think that closing a channel constitutes keeping it alive. Note that you also need to specify the length of the content:  response.headers().set(CONTENT_LENGTH response.content().readableBytes()); so that the receiver can figure out where the message has ended. Else the receive will just keep waiting for the message. And to be clear you should not write "".addListener(ChannelFutureListener.CLOSE);"" if you want your connection to remain open.  Assuming that you are writing an HTTP 1.1 server you should per default keep the connection open after sending the response. If for some reason you decide to close it anyway  you should include Connection: close in the response. Note that bootstrap.setOption(""child.keepAlive"" true); turns on the keepalive option on the socket and has nothing to do with HTTP; rather it is a kind of watchdog mechanim in order to detect broken connections in the absence of ""real"" traffic. Thanks @forty-two! My intent was to keep the connection alive. Just to confirm this: do I need this part `.addListener(ChannelFutureListener.CLOSE);` after I finish writing response? For most operating systems the default `SO_KEEPALIVE` timeout is very long (e.g. 7200 seconds in Linux.) so I would not expect much from it. You should just close the connection if no requests were sent by a client for a certain amount of time."
498,A,How to check references for buffers provided from a PooledByteBufallocator? Using Netty 4 is there a way to see how many ByteBuf's are unreleased (still allocated) from a PooledByteBufAllocator? The reason I'm looking for this is mainly for unit testing so that I can provide a PooledByteBufAllocator into a handler/pipeline on the channel (using an EmbeddedChannel) and ensure that after the handler or pipeline completes that all requested/created pooled ByteBufs have been released. No there is no way at the moment. I think this will be part of https://github.com/netty/netty/issues/1586 Thanks Norman I've added to the issue for a request to have a version of the PooledbyteBufAllocator (or on that implementation) to be able to check for references for unit testing purposes. awesome... thanks!
499,A,Socket. Packets stay in queue when I need them I have strange problem with receiving data from socket. On client im using air socket. On server java netty. Im writing to socket simple packets: int numPacket int textLength utf8String text. And read on client. //server buffer.writeInt( packetId ); ChannelBuffer ch = ChannelBuffers.copiedBuffer( text CharsetUtil.UTF_8); buffer.writeInt( text.length() ); buffer.writeBytes(ch); //client packetId = socket.readInt() packetLen = socket.readInt() text = socket.readUtfBytes(packetLen) Sometimes one packets() doesnt receives by client but server was send there and tcpdump show that packet was send. If server send new packet client read previous packet and doesn't receivs new packet - and it's works like queue that im don't need. p.s sorry for bad english -_- Looks like client maybe waiting for some byte \n\u etc to know the end of frame. I had similar problem with flash because the client was expecting a null byte at the end of the the transmission. You could try to add the following sort of encoder as the last encoder in your pipeline and give it a try. The relevant code for handling nul byte is shown below.  ChannelBuffer nulBuffer = ChannelBuffers.wrappedBuffer(new byte[] { 0 }); ChannelBuffer buffer = ChannelBuffers.wrappedBuffer((ChannelBuffer)msgnulBuffer);  Try using flush() on your buffer after each or all three tcpdump show that packet was correctly send. Flush doesnt helpo for me
500,A,What are the Netty Channel state transitions? Netty channels have multiple states but I am unable to find any documentation on the actual state transitions. The closest to any documentation on this that I could find for Netty 3.2.x system is here. I was able to locate the possible states that a channel can be in here. However there is nothing that describes the normal transitions that a channel can make from one state to another. It appears that not all channels make all possible state transitions. Different Netty channels do indeed have different state transitions. In general the possible state transitions for TCP based server channels are: OPEN -> ( BOUND -> UNBOUND )* -> CLOSE If you are using a SimpleChannelHandler subclass in your pipeline the equivalent methods for handling the upstream events when one of these state changes occur are: channelOpen channelBound channelUnbound channelClose Server channels never move into the CONNECTED state. Server channels rarely move back into the BOUND state once they move into the UNBOUND state however this appears to be dependent on the application so YMMV. Note that server channels can fire events when a child channel is opened or closed. These events can occur only after the server channel is in the BOUND state. When these events are sent upstream on behalf of the server channel then the following methods on your SimpleChannelHandler subclass are called: childChannelOpen childChannelClosed The possible state transitions for TCP based child and client channels are: OPEN -> ( BOUND -> ( CONNECTED -> DISCONNECTED )* -> UNBOUND )* -> CLOSE It appears that moving into the CONNECTED state first is not enforced within the channel code; however this state is invariably fired first for both child and client channels within the Netty framework before the channel is moved into the CONNECTED state. If you are using SimpleChannelHandler or a subclass thereof in your pipeline the equivalent methods are: channelOpen channelBound channelConnected channelDisconnected channelUnbound channelClose A TCP based channel must be in the CONNECTED state before anything can be read or written to the channel. This includes server channels which can never be read from or written to which is not much of a surprise as server channels are invariably used only for managing the connect operation on behalf of the server. Datagram sockets operate differently than TCP based sockets in that they can be used to read and write data without actually being connected (though connecting a datagram socket can be faster as you avoid security checks). Datagram sockets can be effectively used using both of the state transitions listed for TCP based child and server channels described above. good review thanks is it based on some tcp articles or just reading netty sources? and a question: if I need to count active connection count that client does to remote peer will it be enough to increment in `channelConnected` and decrement in `channelDisconnected`? Will the counter be exact in case of `keep-alive` connections and other features? Thanks! I read the source for the details. Figured I'd save someone else the bother in case they have similar questions. WRT active connection count it is indeed enough to increment your counter in `channelConnected` and decrement it in `channelDisconnected`. The HTTP keep-alive and similar protocol-on-TCP constructs have no effect on Netty except indirectly as the application controls the socket connections.
501,A,"Java SSL server not accepting intermediate certificate chain I have implemented a (Netty 3.6.6 Java 6) server which accepts SSL/TLS connections and is required to authenticate the client's certificate chain. I have the common CA's in my truststore. Barring the case described here the server's SSL implementation basically works. Given a valid signed certificate (which works for connecting to other servers) I can successfully connect to my server with: openssl s_client -connect 127.0.0.1 -key test.key -cert test.pem -CAfile capath.pem If however the certificate and intermediates are concatenated together and I connect with: openssl s_client -connect 127.0.0.1 -key test.key -cert all.pem then I get unable to find valid certification path to requested target thrown; I expect this approach to work. My code is (abbreviated): public class MySslConnectionHandler extends FrameDecoder { // this class is added into the netty ChannelPipeline (not shown) private SSLContext sslContext; public MySslConnectionHandler() { KeyStore clientKeyStore = KeyStore.getInstance('JKS'); clientKeyStore.load(new FileInputStream(trustStoreFilename) trustStorePassword); PKIXSSLContextFactory contextFactory = new PKIXSSLContextFactory(serverKeyStore keyStorePassword clientKeyStore true); this.sslContext = contextFactory.buildSSLContext(); } @Override protected Object decode(ChannelHandlerContext ctx Channel channel ChannelBuffer buffer) throws Exception { SSLEngine engine = sslContext.createSSLEngine(); engine.setUseClientMode(false); engine.setNeedClientAuth(true); engine.setEnabledProtocols(new String[] {""TLSv1""""SSLv3""}); SslHandler sslHandler = new SslHandler(engine); sslHandler.setEnableRenegotiation(false); ChannelFuture handshakeFuture = sslHandler.handshake(); handshakeFuture.addListener(new MySslHandshakeListener(engine)); return buffer.readBytes(buffer.readableBytes()); } } What am I doing wrong? Our customers are reporting this behaviour differs from other servers they use so I don't want this to cause them problems; is this reasonable? (Extensive googling hasn't helped...) Thanks :-) Your expectation is wrong. openssl s_client -cert file uses only the first cert which must be the client cert. Putting additional certs chain or other in that file is ignored. As a result s_client (via libssl client) sends an incomplete chain. Normally the server can't validate this. Although -CAfile and/or -CAdir are documented as providing roots for s_client to validate the peer (server) cert libssl also uses the truststore to fill out the chain it sends if necessary and possible; apparently you have your chain cert(s) in cacert.pem and this happened. I assume your customers aren't using s_client since it has very limited ability to send and receive suitable data. If you or someone wrote or writes a real application using libssl you can set a (whole) chain by calling SSL_CTX_use_certificate_chain_file instead of SSL_CTX_use_certificate_file or you can build the chain from individual certs with SSL_CTX_add_extra_chain_cert. (If you have only one intermediate these are practically equivalent.) Not to mention what you can do in other languages like Java perl and dotNET. s_client is designed as a test and debugging tool and doesn't do these; it only does use_certificate which uses only the first cert. Caveat: this is all for OpenSSL through 1.0.1. 1.0.2 now in beta is announced to have changes in cert and chain validation I haven't examined yet. Although based on past practice I confidently expect the defaults will continue to be as in earlier versions. If you really need a Java server to accept a client sending an incomplete chain (which per RFC it shouldn't need to) you can put the first intermediate not sent (which here is the first intermediate period) in server truststore. But I believe (can't easily test) in this case Java will entirely ignore the rest of the chain so you'll have to monitor manually or by some other means for e.g. revocation. Thanks for this. The openssl commands are what a colleague used to test the server and to give the user enough of a clue for them to fix their (unknown) implementation. I realise now that these _might_ be distinct problems. Without the user's implementation I can't be sure that I can reproduce their exact problem; given that they are connecting fine to other servers either we have a bug somewhere or the other servers are somehow less stringent. Tricky! Thanks for your help. Why do you believe Java will ignore the rest of the chain? It must establish a path from the actual client certificate via the chain to a certificate in the truststore. How does that constitute ignoring? @EJP if the actual chain is SheepMolly / Shepherd1 / WoollyRoot and you put Shepherd1 in the truststore (because the noncompliant peer only sends SheepMolly) then it appears Java will build the chain SheepMolly - Shepherd1 and stop there because Shepherd1 is trusted at least according to `HandshakeCompletedEvent.getPeerCertificates`. But in reality Shepherd1 may have been revoked and a relier that looked at the full chain would have detected that. @Liche if you can't see into the client can you capture their connection on your server or at least your server's network segment with Wireshark or equivalent? That will make it easy to figure out exactly what they're sending; if it *should* work then you have something definite to fix if not you can tell them what to fix. Getting permission to capture on a production sensitive network sometimes is an issue; if you can have this client connect instead to a test server you set up that is often easier. ... ... Alternatively but possibly even worse from the getting-permission factor you can switch on quite detailed logging in JSSE with sysprop `javax.net.debug`. But then you have to trek through a LOT of junk to find the good parts you can't just point and click like Wireshark. @dave_thompson_085 Wireshark is a nice idea but as you rightly point out getting access to that part of the network is going to involve paperwork... I've asked support to get more information from the client which hopefully will be an easier way to figure out exactly what they are doing. Thanks!"
502,A,Big request on Post or Get in Netty Http I am using Netty for socket connection mainly. But i also want to use netty to handle some http connections as well. The problem is : the data in the post method sent to Netty Http Server is so large . So Netty raise the exception: Long Frame Exception. Anyone please tell me how to configure Netty accept bigger Post param value. Thank you very much Which ChannelHandlers you use in the ChannelPipeline ? I use the default example of HttpSnoopServer in Netty document. Anyway I changed the solution to websocket instead of Http Server . Thank you for comment @NormanMaurer I suspect you have HttpChunkAggregator in the pipeline. Please remove it and handle HttpChunk by yourself. just curious why HttpChunkAggregator can't handle large posts? @yetanothercoderu I have had the same issue using get exceding 4096 size. I have found that netty raise an exception without handling a 403 error. you can find the exact issue at [httpChunkAgregator v3.2 source code](http://docs.jboss.org/netty/3.2/xref/org/jboss/netty/handler/codec/http/HttpChunkAggregator.html) between line 130~135 for the version 3.2 Notice that the TODO indicates there is an known issue. Since i'm a beginner with netty architecture I don't have found yet how to implement the TODO
503,A,"Is Netty's Zero Copy different from OS level Zero Copy? I found Netty documentation says they have ""Transparent Zero Copy"" feature in their build-in ByteBuffer. But after the reading I notice it doesn't mention any kernel space and user space switching only something about reuse the buffer. So I wonder is Netty's ""Zero Copy"" feature different from OS level ""Zero Copy""(Which means reduce the copy from user space memory to kernel space memory) ? Zero-Copy has two means in the netty's world. Firstif your platform support zero-memory-copyyou can write a DefaultFileRegion to the Channel ChannelHandlerContrext or ChannelPipeline. Second CompositeByteBuf is a virtual buffer which shows multiple buffers as a single merged buffer. So you can composite some byteBufs to one CompositeByteBuf and it doesn't need copy.  Netty also support the use of a FileRegion which allows to transfer FileChannel content without copy it to the userspace.  According to Wikipedia: Zero-Copy describes computer operations in which the CPU does not perform the task of copying data from one memory area to another. OS-level zero copy involves avoiding copying memory blocks from one location to another (typically from user space to kernel space) before sending data to the hardware driver (network card or disk drive) or vice versa. Netty zero copy is talking about optimizing data manipulation on Java level (user-space only). Their ChannelBuffer allows to read contents of multiple byte buffers without actually copying their content. In other words while Netty works only in user space it is still valid to call their approach ""zero copy"". However if OS does not use or support true zero copy it is possible that when data created by Netty-powered program will be sent over the network data would still be copied from user space to kernel space and thus true zero-copy would not be achieved."
504,A,"how to secure websockets with netty I want to use netty for websockets with TLS enabled and using the (wss://) schema. So I figured I should work like this: the WebSocketServerHandler should now extend theSslHandler. So I basically only have to set up an SSLEngine wihin the WebSocketServerPipelineFactory. I can than pass the engine to the secure handler: SSLEngine sslEngine = SSLContext.getDefault().createSSLEngine(); pipeline.addLast(""handler"" new WebSocketServerHandler(sslEngine)); Is this approach in general the right one and (if the approach is correct) - how do I set up the SSLEngine (I've my certificate & private/public keys as files available). I couldn't find any example! Thanks. Netty has examples :-) Netty Master https://github.com/netty/netty/tree/master/example/src/main/java/io/netty/example/http/websocketx/sslserver Netty 3.x Branch https://github.com/netty/netty/tree/3/src/main/java/org/jboss/netty/example/http/websocketx/sslserver thx - i missed that doc! helped a lot! :)"
505,A,How to handle unchecked exceptions thrown in netty handler stack Since any exception thrown in netty handler stack will generate an upstream event and eventually invoke exceptionCaught in handler the exceptions will not reach the uncaught-exception-handler. Even rethrowing that exception in exceptionCaught method doesn't help (because netty handles it again). I would like to throw (some or all) unchecked exceptions from exceptionCaught method. Is there any way to do this? No there is no way todo this. The only thing you can do about is is to handle the Exception in ExceptionCaught. Why is this a problem for you ? This is problem since my the UncaughtExceptionHandler would not get invoked. Since UncaughtExceptionHandler is common to different layers in my application I don't want to replicate that code in exceptionCaught. I guess I would inject instance of UncaughtExceptionHandler in my netty_handler and invoke method explicitly. Although it will be good if there is any hook in exceptionCaught to propagate exception. Thank you for your input.  I have to agree with Norman I had a similar issue. I created a exceptionCaught() method and in it called my exception handling routine. The problem I encountered was my exception handling routine tried to do cleanup and call other Netty methods but that resulted in Netty getting hung. My fix was to create a new Thread from inside exceptionCaught() that calls my exception handling routine and simple return from exceptionCaught(). This allow Netty's exception handling to finish and resume normal Netty operation. You need to put a 1 second delay inside your new thread before calling any other Netty functions as well. This will assure netty's exception handling is done before my new thread starts its clean up and calls other netty functions. It seems a bit excessive work but it works and avoids race conditions.
506,A,Are Netty's WebSocket messages been compressed? I'm developing a WebSocket server using Netty 4.0.21Final. Before using Netty I was sending data via socket directly and now I'm still doing the compression of the data by my self. But when looking closely at the HTTP Headers of my test client on Chrome browser I saw this: Request URL:ws://127.0.0.1:8089/echo Request Method:GET Status Code:101 Switching Protocols Request Headers CAUTION: Provisional headers are shown. Cache-Control:no-cache Connection:Upgrade Host:127.0.0.1:8089 Origin:null Pragma:no-cache Sec-WebSocket-Extensions:permessage-deflate; client_max_window_bits x-webkit-deflate-frame Sec-WebSocket-Key:U0CPp11Bhqxp2lffj4tebw== Sec-WebSocket-Version:13 Upgrade:websocket User-Agent:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/35.0.1916.153 Safari/537.36 Response Headers Connection:Upgrade Sec-WebSocket-Accept:0vvWjhf27ScZauqx+jSfm/Xsuho= Upgrade:websocket The permessage-deflate on the Extensions section means that my messages are been compressed? So to try to answer this I used a software called Wireshark and when looking at the messages I could see that It was not compressed at all they were all in plain text. So what do I must do to Netty really compress the messages for me? Compression support was just added yesterday. So it is not included in any release yet: https://github.com/netty/netty/commit/282d6e73b82ec943a739201f7be1985c45ef032b Very appreciated for the quick answer. Hope that this feature doesn't take too long to be released.. Thanks again. Ok Norman. Thanks. Do you know when this will be released? nope not yet.... Sorry
507,A,"Load balancing netty websocketserver Recently I have tried out Netty server to develop a chat server. I have re-used the example ""io.netty.http.example.websocketx.server"" and modify it slightly by adding a channel map message processor to save the new message to database etc. The channel map will contain all of the opened channels and the subscribed chatroom id. So when someone post some message to chatroom 123 upon receiving the messages in messageReceived function the server will send the messages to all channels subscribed to that chatroom. This method works fine when there's just 1 WebSocketServer instance however how can I load balance the load to multiple WebSocketServers? When the message is received by WebSocketServer #1 is there a way to notify WebSocketServer #2 to send the message to all of the subscribed users? When a new channel joins a chatroom is it a requirement that they receive a history of all messages posted to the chatroom or only messages posted from that point on? No need to see history users will only receive new messages posted from that point onwards. Netty doesn't provide what you want out of the box. As users only need to receive new messages you're looking for a distributed non-persistent publish / subscribe system. You could create one yourself but two other options are use a JMS server. Each of your servers subscribes to a non persistent topic. They publish messages to the topic to broadcast to all other chat servers. embed Hazelcast and use its distributed topic mechanism for the same purpose. The advantage here is that you don't need to run a separate JMS server each of your chat servers becomes a member of the cluster In either scenario your chat server is receiving all messages all of the time and needs to filter appropriately. There are methods with both techniques where you can only receive the messages you're interested in if necessary (JMS selectors different topics in hazelcast). It might also be worth checking out Vert.x which is built on Netty and Hazelcast and provides a distributed event bus Thank you very much. I will done some research on Hazelcast. This is a bit theoretical as I haven't done it myself. Take a look at the topic example tab on http://hazelcast.org. You'll need to implement MessageListener and subscribe to the topic as shown. Hazelcast will call onMessage when a message arrives. The simplest implementation is that your onMessage implementation sends the message to each connected channel. Note hazelcast may drop messages if you can't keep up. Also if writing the message to all channels takes some time you might want to offload the actual write to another thread to avoid blocking the hazelcast thread for too long. Hi John not sure if I understand it correctly. Would you mind to explain a bit more detail on how to use Hazelcast for this purpose? I can store the new message in the Hazelcast queue however that will mean that each websocket connection in different server will need to keep pooling to see if there's any new message available in hazelcast queue. thank you very much John you are very helpful. Cheers."
508,A,"How to handle connect or bind exception when using Netty I wrote some simple code in Netty ChannelFuture future = bootstrap.connect(new InetSocketAddress(host port)); And I want to handle the java.net.ConnectException ERROR [main] (SDKUpHandler.java:37)| Unexpected exception from downstream. java.net.ConnectException: Connection refused: connect: localhost/127.0.0.1:12345 but I didnt find a way for Netty version bind and connect doesnt throw them out. From javadoc connect() throws two exceptions but nojava.net.ConnectException stuff. Throws: ClassCastException - if ""localAddress"" option's value is neither a SocketAddress nor null ChannelPipelineException - if this bootstrap's pipelineFactory failed to create a new ChannelPipeline Could any body provide some solution? Where did the error come from? Netty is asynchronous. You need to add a ChannelFutureListener to the ChannelFuture which will get notified once the operation completes. This way you will be notified with a ""success"" or with the exception. Check the user documentation which contains all of this."
509,A,Netty: Swapping ByteOrder back and forth in a ChannelBuffer I'm currently working with Netty 3.5.10.Final to implement a client for a server that uses a binary protocol with a mixed byte order. That is to say there are many situations in the protocol where I will have to read/write one set of bytes in big-endian order then another set in little-endian order and then again switch back to big-endian. I've discovered that there is not (as far as I know) an easy way to deal with this situation especially with ChannelBuffers.wrappedBuffer(ChannelBuffer buf) throwing an IllegalArgumentException when the endianness differs. I am learning both about Netty and this protocol as I go so I was not aware I would run into this issue when I began. How have others have dealt with this issue especially within the confines of the Netty 3.x framework? I'd love to hear about all solutions though. If the protocol you are implementing has the fields with mixed byte orders then you could choose one byte order as the default (e.g. big endian) and swap the byte order for a specific field: ChannelBuffer buf = ...; int littleEndianField = ChannelBuffers.swapInt(buf.readInt()); Depending on the width of the field you can use one of these: swapShort() swapMedium() swapInt() and swapLong(). Ah nice that's a pretty good approach. It might be a little tedious for my case but I think I will try it out.
510,A,How can I keep record of individual client traffic and speed using Netty? I'm implementing an HTTP server and I have a task to track individual clients' connections and gather the information about amount of bytes they sent and received from server as well as an average connection speed. The server is implemented using an implementation of SimpleChannelInboundHandler where I handle HttpRequests and manage HttpResponses. I understand that I should add another handler (to the front of the pipeline?) to track incoming and outgoing connections but I can't come to a solution about handling individual connections. As an example you can take a look at Netty's ChannelTrafficShapingHandler @IgorAlelekov could you please help with counting bytes sent/received to/from just one client? You could modify ChannelTrafficShapingHandler which already does it. IMHO connection speed should be measured on the client side. @IgorAlelekov I can't disagree with you but I'd also like to know if there still is a chance of implementing it as described. In order to measure speed you need to measure a response time. Only clint knows when request was sent and response got. But you can measure how many bytes processed in second. You could modify for your needs ChannelTrafficShapingHandler which already does it. By the way what is the most convenient way to pass some information from handler to the next one in pipeline? Or should I make this a separate question? You can attach any object to the channel. Or you can pass info with an object in the message. You can also use the `userEventTriggered` event.
511,A,Netty - Does closing the socket at the client end close the channel at the server My TCP server is implemented using Netty. My client using vanilla java.net.Socket to connect to this server. I'm using the same socket to send multiple requests to the server. Once done with all the requests the client calls socket.close(). I'm not closing the channel anywhere in my server code. Also I've set TCP KEEP_ALIVE on my server. Will closing the socket on the client end automatically close the channel on the server or do I've to do something else explicitly and what is the best practice ? You might want to read this answer: http://stackoverflow.com/questions/2165670/socket-close-in-java. Usually if an application closes a socket its remote peer also notices that the closure. Therefore you don't need to call close() on both side. However sometimes due to network problems you might not get notified when the remote peer closes the connection. To work around this problem it's a good idea to send some message periodically and then you will detect the unexpected closure sooner. Please note SO_KEEP_ALIVE will not help much here because for most operating systems because the default keep alive time is very long.
512,A,"Netty is giving me a wrong port using TCP I'm using Netty with Java trying to configure a TCP client. Everything is working so far except that I'm connecting on port 1050 but when I call messageEvent.getRemoteAddress() on messageReceived() method of the handler I'm getting the port 1500. I changed the port to 1049 but I'm still receiving 1500. This is Netty's problem or can it be the server's problem? My hardware setup here is: this netty client running on a Java server and several access control equipments spread through the area here. The equipments act as tcp servers and the netty as the client that process everything the server sends and just reply to them. The tcp server initialization is this: private ChannelFactory fabrica; private ServerBootstrap bootstrap; public void iniciarServidorTCP() { fabrica = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); bootstrap = new ServerBootstrap(fabrica); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""decoderDeMensagem"" new MensagemDecoderTCP()); pipeline.addLast(""handlerGerente"" new GerenteTCP()); pipeline.addLast(""encoder de mensagem"" new MensagemEncoderTCP()); return pipeline; } }); bootstrap.setOption(""child.tcpNoDelay"" true); bootstrap.setOption(""child.reuseAddress"" true); bootstrap.bind(new InetSocketAddress(1050)); } Any idea why I'm getting 1500 instead of 1050? Could it be a problem with the equipment? Every TCP connection has a source port and a destination port. When you connect to a server the server sees the destination port as its well-known address. The client picks the source port. On either end getting the ""remote address"" gets the other side's address. So when you call get remote address on the server you get the client's address not the server's. Imagine you have a server with one IP address and one well-known port. Now say you have a client machine with one IP address. If it make's four connections to the server how can either end tell those connections apart? The answer is that the client port is different. Well yeah I know that it's supposed to be that way the problem is that it's not being that way. Both server and client are configured with port 1050 yet I'm receiving 1500 somehow that's what I want to know why The client binds to port 1050? Did you test to make sure that bind succeeds? (And if you knew that why did you paste all code that's irrelevant? How the server sets its port has nothing to do with the issue which involves how the client sets its port and how the server determines the client port.) The bind succeeds because I'm able to communicate with the equipments and yes the client binds to port 1050 or else it won't receive data from the server. And I pasted the code because of my limited knowledge in this area so I figured it could be because of some wrong configuration at startup. I'll do a few more tests to make sure the binding is right if it is I really won't know what is wrong with it because in this same project I also have UDP connection using almost the same settings and the port binding is flawless. Communication would work fine even if the client's bind failed. The TCP stack would just pick a client port. The code you pasted deals solely with the server port and your issue is with the client port so the code isn't helpful. Most likely you either don't bind in the client or the client's bind fails so the client picks a random port. (Incidentally why do you care? It's much easier and safer to let the client use a random source port.) Actually the server part is on the equipment it's not even Java the code is for the client part that actually runs on a java server"
513,A,"how to add ObjectDecoder to netty server The server code is from the netty QOTM (Quote Of The Moment) example: package net.bounceme.dur.netty; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioDatagramChannel; import java.util.logging.Logger; public final class Server { private static final Logger log = Logger.getLogger(Server.class.getName()); public static void main(String[] args) throws InterruptedException { MyProps p = new MyProps(); int port = p.getServerPort(); new Server().pingPong(port); } private void pingPong(int port) throws InterruptedException { log.fine(""which handler?""); EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioDatagramChannel.class) .option(ChannelOption.SO_BROADCAST true) .handler(new ServerDatagramHandler()); b.bind(port).sync().channel().closeFuture().await(); } finally { group.shutdownGracefully(); } } } Here is the DatagramPacket handler: package net.bounceme.dur.netty; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.channel.socket.DatagramPacket; import io.netty.util.CharsetUtil; import java.util.Random; import java.util.logging.Logger; public class ServerDatagramHandler extends SimpleChannelInboundHandler<DatagramPacket> { private static final Logger log = Logger.getLogger(ServerDatagramHandler.class.getName()); private static final Random random = new Random(); public ServerDatagramHandler() { log.info(""..started..""); } // Quotes from Mohandas K. Gandhi: private static final String[] quotes = { ""Where there is love there is life."" ""First they ignore you then they laugh at you then they fight you then you win."" ""Be the change you want to see in the world."" ""The weak can never forgive. Forgiveness is the attribute of the strong.""}; private static String nextQuote() { int quoteId; synchronized (random) { quoteId = random.nextInt(quotes.length); } return quotes[quoteId]; } @Override public void channelRead0(ChannelHandlerContext ctx DatagramPacket packet) throws Exception { System.err.println(packet); if (""QOTM?"".equals(packet.content().toString(CharsetUtil.UTF_8))) { ctx.write(new DatagramPacket( Unpooled.copiedBuffer(""QOTM: "" + nextQuote() CharsetUtil.UTF_8) packet.sender())); } } @Override public void channelReadComplete(ChannelHandlerContext ctx) { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { log.severe(cause.toString()); } } which I would like to switch to a Quote Handler: package net.bounceme.dur.netty; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import java.util.Random; import java.util.logging.Logger; import net.bounceme.dur.jdbc.Quote; public class ServerQuoteHandler extends SimpleChannelInboundHandler<Quote> { private static final Logger log = Logger.getLogger(ServerQuoteHandler.class.getName()); private static final Random random = new Random(); public ServerQuoteHandler() { log.info(""..started..""); } // Quotes from Mohandas K. Gandhi: private static final String[] quotes = { ""Where there is love there is life."" ""First they ignore you then they laugh at you then they fight you then you win."" ""Be the change you want to see in the world."" ""The weak can never forgive. Forgiveness is the attribute of the strong.""}; private static String nextQuote() { int quoteId; synchronized (random) { quoteId = random.nextInt(quotes.length); } return quotes[quoteId]; } @Override protected void channelRead0(ChannelHandlerContext chc Quote quote) throws Exception { log.info(quote.toString()); chc.writeAndFlush(new Quote(nextQuote())); } } For my purposes Quote is just a String wrapper with a single field and toString returns the quote. It implements Serializable of course and uses serialVersionUID. When I look at the ping-pong example I don't see where to add ObjectEncoder on the server. A blog has this snippet:  // Set up the pipeline factory. bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( new ObjectDecoder(ClassResolvers.cacheDisabled(getClass().getClassLoader())) new DateHandler() ); }; }); but how do I implement that into the QOTM server? I'm going through Netty in Action but haven't found the relevant text explaining this yet. Neither ObjectEncoder nor ObjectDecoder appear in the text of the book..? see also: How to send an object with Netty? I add the encoder and decoder like this to send various POJOs: Client:  bootstrap.handler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new ObjectEncoder()); ch.pipeline().addLast(new ObjectDecoder(ClassResolvers.cacheDisabled(null))); ch.pipeline().addLast(customHandler1); ch.pipeline().addLast(customHandler2); ch.pipeline().addLast(customHandler3); } }); Server:  bootstrap.option(ChannelOption.SO_REUSEADDR true); bootstrap.group(bossGroup workerGroup).channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new ObjectDecoder(ClassResolvers.cacheDisabled(null))); ch.pipeline().addLast(new ObjectEncoder()); ch.pipeline().addLast(customHandler1); ch.pipeline().addLast(customHandler2); ch.pipeline().addLast(customHandler3); } }); when you add an `ObjectDecoder` and `ObjectEncoder` do you have a **custom** en/de-coder as well? they extend `MessageToMessageDecoder`?"
514,A,"Serving a file with Netty - response is truncated by one byte I've serving a files from Android assets via Netty server (images html). Text files such a html is saved as .mp3 to disable compression (I need an InputStream!) My pipeline is looking like this:  pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""aggregator"" new HttpChunkAggregator(65536)); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""chunkedWriter"" new ChunkedWriteHandler()); pipeline.addLast(""handler"" new AssetsServerHandler(context)); My handler is: public class AssetsServerHandler extends SimpleChannelUpstreamHandler { public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { // some checks final FileInputStream is; final AssetFileDescriptor afd; try { afd = assetManager.openFd(path); is = afd.createInputStream(); } catch(IOException exc) { sendError(ctx NOT_FOUND); return; } final long fileLength = afd.getLength(); HttpResponse response = new DefaultHttpResponse(HTTP_1_1 OK); setContentLength(response fileLength); final Channel ch = e.getChannel(); final ChannelFuture future; ch.write(response); future = ch.write(new ChunkedStream(is)); future.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { future.getChannel().close(); } }); if (!isKeepAlive(request)) { future.addListener(ChannelFutureListener.CLOSE); } } // other stuff } With that handler i've got my resposes truncated by at least one byte. If I change ChunkedStream to ChunkedNioFile (and so use a is.getChannel() instead of is as a constructor to it) - everything works perfectly. Please help me understand what is wrong with ChunkedStream. Your code looks right to me. Does the returned FileInputStream of AssetFileDescriptor contain ""all the bytes"" ? You could check this with a unit test. If there is no bug in it then its a bug in netty. I make heavy use of ChunkInputStream and never had such a problem yet but maybe it really depends on the nature of the InputStream. Would be nice if you could write a test case and open a issue at netty's github. I would write a unit test that writes a sequence of bytes to a file. Then open the file with the AssetFileDescriptor get the FileInputStream and read all bytes out of it. Then check for every byte if its equal the byte that you have written to the file before. You should test this for different FileInputStream.read(...) method... The `FileInputStream` i use is generated somewhere in Android's core. How can i unit-test it then? I think it is more up to Android than Netty. By the way `Channel` i've got from this (the same!!) `FileInputStream` is working fine. Good idea i will try it. Thank you. Let me know what are your findings"
515,A,Writing to Netty channel without ChannelFuture Is it possible to write to Netty channel without creating unnecessary ChannelFuture? (Without generating unnecessary object for GC...) If you really wish you don't want to create a ChannelFuture you can do this: Channels.write(ctx Channels.succeededFuture(channel) message); Channels.succeededFuture(..) returns a channel-local singleton object. However you should never add a listener to the returned future because it's already complete. Thanks it will be usefull. What's the problem of adding a handler to a succeededFuture (The code which does this might not be aware that the future already succeeded)? To my experience the listener is just immediately called after being added which is what most people want I think. Or is it because it is a singleton which might accumulate listeners over time? Is there a difference in this regard between Channels.succeededFuture(..) and new SucceededChannelFuture(...)?  No... a ChannelFuture will be created all the time. But a ChannelFuture is cheap and small so I think there are better places to look for optimizations. I think more important is to call Channel.write(..) as less as possible as writing can be expensive in terme of system calls. So if you need to send multiple buffers you may put them all in one and just call Channel.write(...) one time and not for example 5 times. In SMTP this can be done for example if the SMTP server supports the PIPELINING extension and so make optimal use of the resources. Thanks i'll try.
516,A,"Too much open files Exception under ""unlimited"" system I am seing a lot of too many open files exceptions in the execution of my program. Typically those occur in the following form: org.jboss.netty.channel.ChannelException: Failed to create a selector. ... Caused by: java.io.IOException: Too many open files However those are not the only exceptions. I have observed similar ones (caused by ""too many open files"") but those are much less frequent. Strangely enough i have set the limit of open files of the screen session (from where i launch my programs) as 1M: root@s11:~/fabiim-cbench# ulimit -a core file size (blocks -c) 0 data seg size (kbytes -d) unlimited scheduling priority (-e) 20 file size (blocks -f) unlimited pending signals (-i) 16382 max locked memory (kbytes -l) 64 max memory size (kbytes -m) unlimited **open files (-n) 1000000** pipe size (512 bytes -p) 8 POSIX message queues (bytes -q) 819200 real-time priority (-r) 0 stack size (kbytes -s) 8192 cpu time (seconds -t) unlimited max user processes (-u) unlimited virtual memory (kbytes -v) unlimited file locks (-x) unlimited Moreover as observed by the output of lsof -p I see no more that 1111 open files (sockets pipes files) before the exceptions are thrown. Question: What is wrong and/or how can i dig deeper into this problem. Extra: I am currently integrating Floodlight with bft-smart. In a nutshell the floodlight process is the one crashing with too much open files exceptions when executing a stress test launched by a benchmark program. This benchmark program will maintain 64 tcp connections to the floodlight process which in turn should maintain at least 64 * 3 tcp connections to the bft-smart replicas. Both programs use netty to manage these connections. Are you running jboss as root? I don't known if I am running jboss (I think netty and jboss are two separate things). But I am running every process as root. First thing to check—can you run ulimit from inside your Java process to make sure that the file limit is the same inside? Code like this should work: InputStream is = Runtime.getRuntime().exec(new String[] {""bash"" ""-c"" ""ulimit -a""}).getInputStream(); int c; while ((c = is.read()) != -1) { System.out.write(c); } If the limit still shows 1 million well you’re up for some hard debugging. Here are a couple of things that I would look into if I had to debug this— Are you running out of tcp port numbers? What does netstat -an show when you hit this error? Use strace to find out exactly what system call with what parameters is causing this error to be thrown. EMFILE is a return value of 24. The “Too many open files” EMFILE error can actually be thrown by a number of different system calls for a number of different reasons: $ cd /usr/share/man/man2 $ zgrep -A 2 EMFILE * accept.2.gz:.B EMFILE accept.2.gz:The per-process limit of open file descriptors has been reached. accept.2.gz:.TP accept.2.gz:-- accept.2.gz:.\"" EAGAIN EBADF ECONNABORTED EINTR EINVAL EMFILE accept.2.gz:.\"" ENFILE ENOBUFS ENOMEM ENOTSOCK EOPNOTSUPP EPROTO EWOULDBLOCK. accept.2.gz:.\"" In addition SUSv2 documents EFAULT and ENOSR. dup.2.gz:.B EMFILE dup.2.gz:The process already has the maximum number of file dup.2.gz:descriptors open and tried to open a new one. epoll_create.2.gz:.B EMFILE epoll_create.2.gz:The per-user limit on the number of epoll instances imposed by epoll_create.2.gz:.I /proc/sys/fs/epoll/max_user_instances eventfd.2.gz:.B EMFILE eventfd.2.gz:The per-process limit on open file descriptors has been reached. eventfd.2.gz:.TP execve.2.gz:.B EMFILE execve.2.gz:The process has the maximum number of files open. execve.2.gz:.TP execve.2.gz:-- execve.2.gz:.\"" document ETXTBSY EPERM EFAULT ELOOP EIO ENFILE EMFILE EINVAL execve.2.gz:.\"" EISDIR or ELIBBAD error conditions. execve.2.gz:.SH NOTES fcntl.2.gz:.B EMFILE fcntl.2.gz:For fcntl.2.gz:.BR F_DUPFD  getrlimit.2.gz:.BR EMFILE . getrlimit.2.gz:(Historically this limit was named getrlimit.2.gz:.B RLIMIT_OFILE inotify_init.2.gz:.B EMFILE inotify_init.2.gz:The user limit on the total number of inotify instances has been reached. inotify_init.2.gz:.TP mmap.2.gz:.\"" SUSv2 documents additional error codes EMFILE and EOVERFLOW. mmap.2.gz:.SH AVAILABILITY mmap.2.gz:On POSIX systems on which mount.2.gz:.B EMFILE mount.2.gz:(In case no block device is required:) mount.2.gz:Table of dummy devices is full. open.2.gz:.B EMFILE open.2.gz:The process already has the maximum number of files open. open.2.gz:.TP pipe.2.gz:.B EMFILE pipe.2.gz:Too many file descriptors are in use by the process. pipe.2.gz:.TP shmop.2.gz:.\"" SVr4 documents an additional error condition EMFILE. shmop.2.gz: shmop.2.gz:In SVID 3 (or perhaps earlier) signalfd.2.gz:.B EMFILE signalfd.2.gz:The per-process limit of open file descriptors has been reached. signalfd.2.gz:.TP socket.2.gz:.B EMFILE socket.2.gz:Process file table overflow. socket.2.gz:.TP socketpair.2.gz:.B EMFILE socketpair.2.gz:Too many descriptors are in use by this process. socketpair.2.gz:.TP spu_create.2.gz:.B EMFILE spu_create.2.gz:The process has reached its maximum open files limit. spu_create.2.gz:.TP timerfd_create.2.gz:.B EMFILE timerfd_create.2.gz:The per-process limit of open file descriptors has been reached. timerfd_create.2.gz:.TP truncate.2.gz:.\"" error conditions EMFILE EMULTIHP ENFILE ENOLINK. SVr4 documents for truncate.2.gz:.\"" .BR ftruncate () truncate.2.gz:.\"" an additional EAGAIN error condition. If you check out all these manpages by hand you may find something interesting. For example I think it’s interesting that epoll_create the underlying system call that is used by NIO channels will return EMFILE “Too many open files” if The per-user limit on the number of epoll instances imposed by /proc/sys/fs/epoll/max_user_instances was encountered. See epoll(7) for further details. Now that filename doesn’t actually exist on my system but there are some limits defined in files in /proc/sys/fs/epoll and /proc/sys/fs/inotify that you might be hitting especially if you’re running multiple instances of the same test on the same machine. Figuring out if that’s the case is a chore in itself—you could start by checking syslog for any messages… Good luck!"
517,A,Netty throws java.nio.channels.ClosedSelectorException on android-x86 I'am trying to use android-x86 instead standard android-emulator because it's very FAST. Launched it via virtualbox with image android-x86-2.2-generic.iso. My project using netty and then I'am trying to create connection got the follow error: 06-22 13:15:10.600: WARN/lientSocketPipelineSink(2411): Unexpected exception in the selector loop. 06-22 13:15:10.600: WARN/lientSocketPipelineSink(2411): java.nio.channels.ClosedSelectorException 06-22 13:15:10.600: WARN/lientSocketPipelineSink(2411): at org.apache.harmony.nio.internal.SelectorImpl.closeCheck(SelectorImpl.java:204) 06-22 13:15:10.600: WARN/lientSocketPipelineSink(2411): at org.apache.harmony.nio.internal.SelectorImpl.selectInternal(SelectorImpl.java:236) 06-22 13:15:10.600: WARN/lientSocketPipelineSink(2411): at org.apache.harmony.nio.internal.SelectorImpl.select(SelectorImpl.java:224) 06-22 13:15:10.600: WARN/lientSocketPipelineSink(2411): at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.run(NioClientSocketPipelineSink.java:239) 06-22 13:15:10.600: WARN/lientSocketPipelineSink(2411): at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1068) 06-22 13:15:10.600: WARN/lientSocketPipelineSink(2411): at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:561) 06-22 13:15:10.600: WARN/lientSocketPipelineSink(2411): at java.lang.Thread.run(Thread.java:1096) Maybe you should use OIO instead of NIO because of the known issue: http://markmail.org/message/ypa3nrr64kzsyfsa Thanks! I switched to OioClientSocketChannelFactory and all works fine!
518,A,"Reusing a Netty 4.0 AttributeKey name OR unregistering a Netty UniqueName Is it possible to ""undefine"" a Netty AttributeKey or UniqueName instance? I have Netty 4.0.8 deployed in an OSGi container and I have a class in separate bundle which defines a static final AttributeKey. The problem is that reloading or redeploying that bundle causes that class to be loaded again (and static initialization to happen again) so the AttributeKey constructor call blows up since the string used to identify it is already present in the map of in-use names from the last time the bundle started up. Appending a random number to the end of the String argument to the constructor avoids a collision but this causes names to accumulate in the AttributeKey class's UniqueName map. My question then is about the best practice for defining AttributeKeys in a class that may be dynamically reloaded. Specifically: what is it? Do I need manage my own pool of AttributeKey instances? For reference the ugly random number hack looks like this: private static final AttributeKey<ChannelGroup> PAGE_GROUP = new AttributeKey<>(""MyOtherwiseUniqueString"" + new Random().nextInt()); Thanks for reporting this problem. I've just filed an issue: https://github.com/netty/netty/issues/1824 The fix for this bug has been scheduled for Netty 5. Now you have to use a factory method instead of constructor to get an AttributeKey: private static final AttributeKey<Boolean> KEY = AttributeKey.valueOf(MyHandler.class ""MY_KEY""); It always returns a singleton so you don't need to worry about class loader issue anymore. For more information read this pull request."
519,A,Support for HTTP multipart response in Netty? I would like to know if there are any way to send multipart responses to a client. Is there some way I could attach multiple images to one response? HttpContent just works with ByteBuf... so its up to you to convert the content to ByteBuf.
520,A,"Netty compilation throws checkstyle error on windows I did a git clone from github git://github.com/netty/netty.git followed by mvn clean install. However I got the following errors from maven checkstyle plugin C:\git\netty\common\src\main\java\io\netty\util\UniqueName.java:106: Line matches the illegal pattern '\r'. C:\git\netty\common\src\main\java\io\netty\util\UniqueName.java:107: Line matches the illegal pattern '\r'. C:\git\netty\common\src\main\java\io\netty\util\UniqueName.java:108: Line matches the illegal pattern '\r'. C:\git\netty\common\src\main\java\io\netty\util\UniqueName.java:109: Line matches the illegal pattern '\r'. .... Audit done. I use a windows 7 machine with java version ""1.7.0_06"". How do prevent these errors and get a good compile? You may just edit these files and replace \r to \n. Or if you want just compile project and ignore all messages from checkstyle I suggest to set properties failsOnError and failOnViolation to false (in code: https://github.com/netty/netty/blob/master/pom.xml#L311) In this case checkstyle still will check the sources but will not fail it when find something.  You'll need to configure git to use lf only: https://help.github.com/articles/dealing-with-line-endings#platform-windows Shouldn't the .gitattributes file for Netty also be checked in to git in this case?"
521,A,"Does Akka Remoting support one-way only connections? I have an Akka system running on an Android device which talks to an Akka system on a server via Akka Remoting. The Android device may get any IP address the IP may change while the application runs and the IP can be unreachable from the server. Thus I've configured Akka on the Android device with akka.remote.netty.hostname = ""0.0.0.0"" and akka.remote.netty.port = 8000. The Android Akka system gets a reference to an actor on the server sends messages to it and the Actor on the server records the sender() actorRef and keeps sending messages back to it. This works when both the server and Android device are on the same wlan and when they are talking via GPRS over the internet. Now I'm taking a closer look on connection losses and reconnects. The scenario I've been focusing on is this: The Android device and server is both on a wlan. The Android device sends a message to the server. Akka remoting on Android produces RemoteClientStarted. Akka remoting on server produces RemoteClientStarted and RemoteServerClientConnected. Then I turn off the wlan on Android wait a few seconds and turn it on again. No messages are attempted sent to the server in between. Akka remoting on Android produces RemoteClientShutdown and RemoteClientError (ETIMEDOUT) Akka remoting on server says nothing. Android sends a message to the server. Server produces RemoteServerClientConnected and receives the message. Server tries to send a message (call it A for questions below) to Android and produces: RemoteServerError RemoteServerClientDisconnected RemoteClientShutdown RemoteServerClientClosed. Android never gets the message from the server. Server tries to send another message but Akkas RemoteClient says: [PassiveRemoteClient@akka://xxx@0.0.0.0:8000] has been shut down Starting remote client connection to [akka://xxx@0.0.0.0:8000|/0.0.0.0] RemoteClientError@akka://vts@0.0.0.0:8000: Error[... This last error seems to come from that Akka Remote wants to create a new ActiveRemoteClient instead of reusing the existing PassiveRemoteClient. I guess this again comes from that the server observes the RemoteServerClientConnected event before it sees the errors/disconnects/shutdowns/clientcloseds. Now the questions: How can I make the server reuse the last incoming connection (PassiveRemoteClient) from the Android device when sending message A in this scenario? How can I instruct the server to not ever try to connect back to the client? Versions: Android: 15 (4.0.3) Akka: 2.1 Java: 1.6 64bits Scala: 2.10.1 Netty: 3.5.8 This might not really be the answer you have been hoping for but here it goes (I’m the Akka tech lead). Akka remoting is designed to work between systems which act as peers. The driver behind the development is to build the cluster support which started appearing in version 2.1 and which will be officially supported—and further developed—from 2.2 onwards. This has a few important consequences: ActorRefs shall be location transparent meaning that they work the same no matter where you use them and hence each node needs to be able to connect to the node where a given reference points to. Communication between Akka nodes is fundamentally symmetric even if your usage of it may not be. Passing around ActorRef as a means to conduct a conversation means that the entity pointed to via the reference needs to stay available or the communication will fail; and staying available means “at the same location pointed to by the reference”. What this means for your scenario is that you will be better off coupling your actor systems not using plain remoting but instead using something else which supports the short-lived associations you suffer from. You could for example expose the server as a REST service or you could just use bare TCP (or even UDP) using the Akka IO layer. In the actor handling the endpoint on the server side you can then recognize if the same client talks to you from a different network locations buffer reply messages masquerade that external actor behind a local proxy actor etc. With this scheme you can even build in reliable messaging over your unreliable channels (using ACKing) and the beauty is that within the server (possibly a cluster) all communication just works because the problematic part of how to talk to the client is encapsulated in one spot. Long story short: your use-case is not one which is supported by plain Akka remoting out of the box. RemoteTransport will change for 2.2 and while it is conceivable that special applications create their own we do not expect that to happen often. There are a lot of assumptions connected to actor messaging which might not match your needs. very cool would you mind to share on akka-user? Thanks for a thorough answer and especially suggestions on how to make it work. Quick follow up: `RemoteTransport` seems to be base for implementing ones own remoting underneath Akka. It's undocumented so I have to ask: is this the recommended way? Will the mechanism change drastically in upcoming versions of Akka? Okay guess I'll stay away from `RemoteTransport` then. For the curious: I ended up testing akka-zeromq. It is built against zeromq-2.1 which was unacceptable for me. So I tested jeromq which is supposed to be a pure-java port of zeromq3. Unfortunately this didn't work as a drop in replacement of the scala-zeromq-binding that comes with akka-zeromq but I forked the akka-zeromq module and replace dependency on scala-zeromq-binding with jeromq instead.Worked as a charm but testing on Android still remains. I'm not on that list. But feel free to copy paste this: Don't have time to pack it as a standalone project and put it on github right now but what I've done is this: 1. Replace all imports of org.zeromq... with org.jeromq... 2. Replaced _one_ instance of an int field access. Other than that the APIs where alike. I've not done much testing yet though but I've initialized a jeromq-actor and processed messages and it behaves as expected. Maybe you could create an akka-jeromq module for those less inclined to fiddle around with dlls?"
522,A,"Why the play(netty3) upload uses single thread? I use play to develop my project and embedded netty3 as my application server Please check the following test code: package controllers; import java.io.File; import java.io.IOException; import java.util.HashMap; import java.util.Map; import java.util.concurrent.atomic.AtomicInteger; import org.apache.commons.io.FileUtils; import play.Logger; import play.Play; import play.mvc.Controller; import play.mvc.results.RenderText; public class Upload extends Controller { private static Integer counter = 0; private static final Integer MAX = 1; public static void index() { render(""/upload.html""); } public static void upload(File file) { System.out.println(""start "" + Thread.currentThread()); synchronized (counter) { System.out.println(""middle "" + Thread.currentThread()); if (counter > MAX) { renderText(""Sorry the max upload thread is "" + MAX); } else { counter++; uploadFile(file); counter--; renderText(""Upload success""); } } System.out.println(""end "" + Thread.currentThread()); } static void uploadFile(File imgFile) { File file = Play.getFile(""/uploads""); try { FileUtils.copyFileToDirectory(imgFile file); } catch (IOException e) { Logger.error(""upload file error"" e); } } } When I opened two browsers(Firefox and Chrome) to upload the files at the same time I debugged breakpoint in the ' upload(File file)' method. But I found only 1 thread was processing. After that then the second request came. The output is : start Thread[play-thread-15main] middle Thread[play-thread-15main] start Thread[play-thread-15main] middle Thread[play-thread-15main] But in Tomcat/Jetty there were two threads output in the console. Did any body meet the same problem before ? Are you sure it is Netty 3? Netty 3 is not released yet. I assume that you are running in Dev mode? The play document says that to make debugging easier by default Play runs in a single thread model in Dev mode and in production mode it runs as numbers_of_cores + 1. You can override this in the application.conf. # example of using a thread pool of 3 play.pool=3 Thanks very much Codemwnci. I didn't notice Play uses 1 thread in DEV."
523,A,"Netty TCP Server that server multiple requests with just one socket connection Is it possible to use Netty to implement a TCP server that performs multiple interactions (request-response) with a client using the same socket connection. Any pointers/examples would be appreciated. Of course it should be possible just don't close the socket? Sure.. you can send/receive as much messages as you want. Just don't close the channel until you are done. so what's the correct way to close the channel in this case. Setting a timeout value ? Yes.. You can use the IdleStateHandler for this kind of stuff  You can do channel.write(object) as many times as necessary before closing the channel. Another thing is you should mention bootstrap.setOption(""child.keepAlive""true) to keep the connection alive I've already set the keepAlive option."
524,A,IdleStateHandler in Netty 4? I have it added to my pipeline and the LoggingHandler is catching its events but since the event system changed from Netty 3 to 4 how do I handle these events seeing as IdleStateAwareUpstreamHandler no longer exists? LoggingHandler: Dec 31 2012 5:46:19 PM io.netty.handler.logging.LoggingHandler INFO: [id: 0xfef88037 /127.0.0.1:63531 => /127.0.0.1:7633] USER_EVENT: WRITER_IDLE(0 30001ms) Thanks! First off make sure that your pipeline has an IdleStateHandler and the handler which wants to get notified on IdleStateEvent is placed after the IdleStateHandler. ChannelStateHandler and ChannelInboundHandler has an event handler method called userEventTriggered(). You can implement that method like the following: @Override public void userEventTriggered(ChannelHandlerContext ctx Object evt) { if (evt instanceof IdleStateEvent) { ... } } Edited to answer @Abe 's question. Thank you! It works! Is IdleStateHandler what you want? http://static.netty.io/4.0/api/io/netty/handler/timeout/IdleStateHandler.html How is this event triggered? In the sense how can we configure the delay at which this should be trigered?
525,A,"Netty 3.9 client not sending encoder I'm having an issue using Netty 3.9 where i have made a client that sends/executes an encoder as soon as it connects to the server. But it just connects without sending the encoder. ClientHandler public final class ClientHandler extends IdleStateAwareChannelUpstreamHandler { @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { Channel channel = ctx.getChannel(); logger.info(""Channel connected: "" + channel); } } ClientPipelineFactory private final ClientHandler handler = new ClientHandler(); @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""handler"" handler); pipeline.addLast(""encoder"" new HandshakeEncoder()); return pipeline; } HandshakeEncoder public final class HandshakeEncoder extends OneToOneEncoder { @Override protected Object encode(ChannelHandlerContext ctx Channel channel Object msg) throws Exception { ChannelBuffer buffer = ChannelBuffers.buffer(1); buffer.writeByte(49); return buffer; } } The encoder will only be called when you write something to the Channel. I guess what you want is to extend SimpleChannelUpstreamHandler and use something like: public final class HandshakeHandler extends SimpleChannelUpstreamHandler { @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { Channel channel = ctx.getChannel(); ChannelBuffer buffer = ChannelBuffers.buffer(1); buffer.writeByte(49); channel.write(buffer); } }"
526,A,"netty backward compatiblity with older library My netty project uses consumes old version of netty (3.X series) now when i see the 4.x version there is significant difference in the declaration of the package for e.g in 3.9 libary we have import declaration starting with org.jboss import org.jboss.netty.bootstrap.ClientBootstrap; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelFuture; import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory; in 4.x import io.netty.bootstrap.ServerBootstrap; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelFutureListener; import io.netty.channel.ChannelHandlerContext; it causes me recompile the entire project with new imports the client(end users) still using the old version of library and might not be interested in upgrade with new library does netty will will be backword compatible with old API netty 4 is not backward compatible with netty 3 but if by ""client"" you mean remote peer it is ok to upgrade your server and keep compatible with client. the client just communicates with server over tcp stack and it doesn't care about how the server is implemented."
527,A,netty-4.x Using an attachment The 4.0 documentation for ChannelHandler offers get/set Attachment as a state management option. They do not appear to be implemented. Will they be implemented or what is the suggested alternative. Note: A member variable is not an option. You should use the Channel.attr(..) method. See: http://static.netty.io/4.0/api/io/netty/util/AttributeMap.html Thanks this works well. Hopefully it will make it into the ChannelHandler documentation.
528,A,"Netty - calling channel.disconnect() actually closes the channel I am using Netty version 2.6.0.Final. If I'm understanding the Netty documentation correctly calling disconnect() on Channel should allow me to call connect() to connect again later. However when I call disconnect() both channelDisconnected() and channelClosed() of my SimpleChannelHandler subclass get called. I opened this in debug mode and basically the order of events is: I call disconnect() on my Channel Channels.disconnect() gets called: public static ChannelFuture disconnect(Channel channel) { ChannelFuture future = future(channel); channel.getPipeline().sendDownstream(new DownstreamChannelStateEvent( channel future ChannelState.CONNECTED null)); return future; } Eventually NioSocketPipelineSink.eventSunk() gets called and the related part is:  case CONNECTED: if (value != null) { connect(channel future (SocketAddress) value); } else { channel.worker.close(channel future); } break; So since value is null and the state is CONNECTED the channel gets closed (although according to here CONNECTED with null should indicate a request to disconnect not necessarily close. So am I missing something here? What's the point of disconnect() if it just results in the channel being closed? This isn't a huge problem because if I need to I can just create a new Channel for my situation but from initial inspection this seems like a Netty bug unless I'm just misunderstanding how this is supposed to work or I'm doing something silly. One intention of Netty is to present a unified Channel abstraction that works more or less the same for connection oriented sockets (TCP) as for connection less sockets (UDP) regardless of the underlying implementation OIO NIO or AIO. Since there are quite a few differences the unified interface will look a bit strange for some pieces of a particular implementation. The act of disconnecting a TCP socket implies closing it (at least from the Java API perspective). But disconnecting a UDP socket does not imply closing it just removing the association between the local ip address/port and the remote ip address/port. So no you are not doing anything silly but I would recommend acting upon OPEN/CLOSE events instead unless you have a real need for ""connecting"" a UDP socket to different remote targets during its life time. EDIT: missed an important ""not"" in the preceeding paragraph. Hmm I suppose that makes sense. I was mainly just looking for a way to be able to reuse Netty TCP Channels after they are disconnected without having to completely recreate the entire Channel and pipeline (and updating the objects that reference it) but it's probably not expensive enough to be an issue. A TCP connection almost always represents a ""tight"" connection on a higher level; for most cases it will be more work and more confusion trying to re use the lower level resources than to simply discard them when the higher level connection ends."
529,A,"Eclipse doesn't see classes from a plug-in dependency I want to use Netty in an Eclipse RCP application. After downloading the latest jar I've added it to dependencies of my plug-in but packages it provides aren't resolved in the editor. It's visible under ""Plug-in dependencies"" in the Package Explorer as are all other dependencies (which work fine). How can I fix this? What compilation error do you get when you import classes from netty? How did you create a plug-in project from the netty jar file? Did you use the ""Plug-in from Existing JAR Archives"" wizard? Are the packages of netty that you'd like to use exported in the manifest of the plug-in project of netty? I copied the netty jar file into a project of my workspace. But Eclipse didn't allow me to add it as a dependency of another plug-in. I'm not sure how you've set up the dependency on netty. I used the ""Plug-in from Existing JAR Archives"" wizard to create an Eclipse plug-in project from the netty JAR file. Then I created a new plug-in project to depend on my netty project. I was successfully able to use the classes in the netty project in my driver project. I suggest you to try to import the netty JAR file using the ""Plug-in from Existing JAR Archive"" wizard. I have a special project in my workspace to keep downloaded jars so they can be conveniently added to other projects. Yes the netty JAR files are OSGi bundle. But how did you add them as the dependencies of your plug-in. Eclipse won't allow you add a bundle to the list of dependencies unless it's imported in the workspace. How did you import the netty bundle into your Eclipse workspace? 1. ""The import org.jboss cannot be resolved"". 2. The jar is already an OSGi bundle (otherwise it couldn't be added to plug-in dependencies at all I believe). 3. Yes they are."
530,A,netty 4.0.0.Alpha or 3.5.2.Final for new project? Can't decide for myself which version of netty should I go for in a new project. Is there roadmap or release schedule for netty 4.x? Netty 4.0.0.Final should be out in about 2 month if everything work out. So depending on your project you can choose the right version for you. I would use 4.x but I'm one of netty's developers so this may be the reason why ;) I've been using Netty 4 alpha for 2 years. Very happy to know it will be released in 2 months. Thank you. Sounds perfect. Will go for 4.x since the project is new. that is the plan.. so stay tuned ;)
531,A,Add support to LLRP in Netty I'm looking some advices or suggestions as to how add LLRP (Low Level Reader Protocol) support in Netty. I'm going to build a middleware platform to store and manage RFIDs coming from RFID readers and antennas. The reader for example can be something like the Motorola XR480 that already support LLRP. The idea is to build a Netty-based client-server that comunicate with these readers via LLRP to retrieve the RFIDs readed process them and store them or send them to a client that has requested them. I think Netty would be pretty well suited to this scenario but I'm open minded to other solutions. :) There's already a Java toolkit for LLRP it's easy to add a new tcp protocol support to Netty? Are there any examples to point me in the right direction? Using Netty you can implement any protocol just implement corresponding handler to serialize protocol messages. You can look at examples going with Netty. Thanks I will look at the examples then. For the record I used Netty before but I've never had to add support to a new TCP protocol to it before...
532,A,"variable server performance using DelimiterBasedFrameDecoder I have a server reading inbound newline-delimited strings. The pipeline looks like this:  ... pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(65535 Delimiters.lineDelimiter())); // plain old strings pipeline.addLast(""decoder"" new StringDecoder()); // callback to handler pipeline.addLast(""handler"" new ConnectorHandler(collector)); ... When I change the decoder to the following:  pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(65535 new ChannelBuffer[] { ChannelBuffers.wrappedBuffer( new byte[] {'\n'})})); I get a 3-4X increase in server speed. I don't understand why this would be the case. The inbound strings vary betweeen about 1K-4K in length around 10K strings/sec. Looking at the source code it appears that it cycles through all the delimiters to find the one yielding the minimum frame length -- by inspection I don't see how looking for only one delimiter would result in such a performance gain over looking for two delimiters. I am tempted to try to write my own decoder but I would like to understand what's going on here. Any insight would be appreciated. thats exactly the case.. looking only for one is much more cheap. OK I'll buy that. I've written my own decoder and it is a bit faster (~10%) than the DelimiterBasedFrameDecoder above. Thanks."
533,A,"Receive socket request pass through various endpoints and Respond back to same socket connection using netty in camel I am currently using netty in custom camel components to listen on a socket (Using a consumer with netty channel handlers) pass the message from the socket to multiple camel endpoints and ultimately write out the final result in a flat file. This works fine but it is obviously limited to ""in only"" functionality. What I'd like to do is instead of writing the final result to a flat file send that final result back to the requester through the socket. Something like this does not work.. Pseudocode: <route> <from:netty:tcp://localhost:1111/> <to:endpoint1/> </route> <route> <from:endpoint1 /> <to:netty:tcp://localhost:1111 /> </route> What I suspect is happening is that my use of <to:netty:tcp://localhost:1111 /> is causing the NettyProducer to try to establish a new connection to a server at localhost:1111 which doesn't exist since it is a socket client. Instead of magically using the channels opened by the consumer that I want it to. Is this just a matter of setting the proper uri options or is this not possible? That's the high level description of the problem. Here is some more details on my assumptions and what I'd like if the above wasn't clear enough. From what I understand camel-netty has a NettyConsumer that creates a socket server that will listen on a socket. Also it has a NettyProducer that creates a socket client that will write to a socket. My question is: Can I configure the NettyConsumer and NettyProducer to use the same socket/channel? I'd assume that in order for this to be possible the netty pipeline/channels/or some component knowledgable of the connection would need to be shared on the Endpoint level since it is common to both the Consumer and the Producer. I've read the documentation regarding synchronous request-response but I believe this only applies when you have a single processor that consumes the exchange body and sends it back through the exchange. My not so great interim solution: So I actually got this working but I'm not in love with it. Here is what I did: Create/Extend a SimpleChannelHandler that simply blocks/polls for the destination file Add this handler as my last handler in the server pipeline Once my other endpoint processes have completed and the file is created the polling handler pulls the contents of the file and writes the contents downstream and closes the channel. The response ultimately gets back to the original socket client. I tested this with a plain socket client and works. Even though this works it feels somewhat like a hack and I'd much rather configure a camel producer to send the response back to the client. At this point I need to know if I can do this or if I need to write something more customized for myself. The only requirement is camel and socket io if netty can't do this and something else can that would help too. Thanks in advance. No that is not what I want. I want to receive data on Socket IP1:PORT1 enrich the message by routing the exchange to various endpoints (while keeping the connection on Socket IP1:PORT1 open) and ultimately send back the final message back to Socket IP1:PORT1. To the socket client this would just appear to be a typical request-response. Is this not possible? Ralf yes I have tried this and it does work but it does not allow me to send the exchange off to another endpoint. Using sync=true you enrich the exchange but don't set a and the exchange will ultimately get sent back through the requesting socket channel. So you want to receive data on Socket IP1:PORT1 enrich the message and then send it off to a 3rd entity reachable on IP2:PORT2? I thought your 3rd bullet point meant to send back the response to the original caller. Have you tried to use `` then enrich the exchange and leave it to camel to send back the exchange body via the socket connection or have you jumped directly to your workaround solution? I have not worked with the netty component before but the doc reads like what you want should ""just work"". I think what you want is something like this: <camel:route id=""rest.route.request.search""> <from:netty:tcp://localhost:1111/> <!-- Send exchange off to another endpoint for enrichment/processing --> <camel:enrich ref=""some.endpoint.ref"" /> <!-- Exchange body is sent back to caller --> </camel:route> With the content enricher you should be able to route the exchange via an arbitrary number of endpoints and let Camel send the exchange body back via the socket connection on which you received the request. Thanks Ralf. I believe this is what I was looking for. I'm new to camel and just read up on content enrichment. I believe I should be able to use the enrich DSL or pipeline a few processors to get what I want. I think the problem was that I had a misconception that I needed to send an exchange to a new route everytime I enriched/transformed it once."
534,A,Can netty handle re-segmented TLS records? Since there is no correspondence between NIO TCP read events (essentially TCP buffered segments) and the TLS records carried as payload inside them I am trying to figure out if Netty handles correctly TLS records that are randomly re-segmented into separate NIO reads. In SSLEngine.unwrap() this would cause a BUFFER_UNDERFLOW which is handled simply by breaking the loop here: https://github.com/netty/netty/blob/master/handler/src/main/java/io/netty/handler/ssl/SslHandler.java#L483 Does anyone have experience with re-segmentation and if this code is sufficient to recover TLS records in all cases? Any advice on testing it would be appreciated? The answer is yes. After breaking the loop the unwrap() method will be called again when more data is received. If you find a bug where SslHandler doesn't handle re-segmented TLS records please file a bug so that we can fix it. Thanks a lot Trustin.
535,A,"Netty - cannot set multiple cookies with one CookieEncoder I have the following simple test code at my server http handler: String cookieString = request.getHeader(COOKIE); if (cookieString != null) { CookieDecoder cookieDecoder = new CookieDecoder(); Set<Cookie> cookies = cookieDecoder.decode(cookieString); if (!cookies.isEmpty()) { CookieEncoder cookieEncoder = new CookieEncoder(true); for (Cookie cookie : cookies) { System.out.println(""---> "" + cookie); cookieEncoder.addCookie(cookie); } response.addHeader(SET_COOKIE cookieEncoder.encode()); } } else { // set cookie for initial time (just testing) if (true) { CookieEncoder cookieEncoder = new CookieEncoder(true); cookieEncoder.addCookie(""key"" ""value""); cookieEncoder.addCookie(""key2"" ""value2""); response.addHeader(SET_COOKIE cookieEncoder.encode()); } else { CookieEncoder cookieEncoder1 = new CookieEncoder(true); CookieEncoder cookieEncoder2 = new CookieEncoder(true); cookieEncoder1.addCookie(""key"" ""value""); cookieEncoder2.addCookie(""key2"" ""value2""); response.addHeader(SET_COOKIE cookieEncoder1.encode()); response.addHeader(SET_COOKIE cookieEncoder2.encode()); } } As you can see the initial time I try to set two dummy cookies. When I refresh the page (so the cookie is passed through by the client) in FF (does also happen in IE and Chrome) only one cookie is in the header of the request and printed out. However if I set the two cookies with a seperate CookieEncoder (see false-clause in code snippet above) everything works as expected. Is this expected behaviour? I would expect that you can set multiple cookies with one CookieEncoder? I believe this is a bug in `CookieEncoder` or `CookieDecoder`. Could you please [file an issue](https://github.com/netty/netty/issues)? OK I will file a bug. I am answering my own question since it appears to be a issue. See https://github.com/netty/netty/issues/94.  // Initialize Variables ArrayList<String> cookieArray = new ArrayList<String>(); // Encode 'cooke1' to 'response' Header encoder.addCookie(cookie1); // Append 'cookie1' to 'cookieArray' cookieArray.add(encoder.encode()); // Encode 'cooke2' to 'response' Header encoder.addCookie(cookie2); // Append 'cookie2' to 'cookieArray' cookieArray.add(encoder.encode()); // Create Cookies using 'cookieArray' response.setHeader(""Set-Cookie"" cookieArray);  It's actually a violation of HTTP cookie specification to set multiple cookies in a Set-Cookie header. You have to encode only one cookie per Set-Cookie header. Netty's CookieEncoder allowed doing that and it generated non-compliant Set-Cookie headers. To fix this issue the next version of Netty will throw an IllegalStateException if a user attempts to encode more than one cookie on server mode."
536,A,"exceptionCaught error handling write back response causes exception and infiniteLoop of calling exceptionCaught I'm trying to genericize my error handling for HTTP requests and always respond with an actual error HTTP code and relevant message. Here is my issue: in my Handler which extends SimpleChannelUpstreamHandler exceptionCaught is fired when an exception is thrown anywhere in the stack. That's good. The bad part is that when I try to write out a response to the client with an appropriate HTTP code and response the write causes an exception and then the program goes into an infinite loop with calling exceptionCaught over and over again. This has to be a commonly done task. How can I do it correctly? @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent event) throws Exception { try{ logger.error(""Error in handling call: "" event.getCause()); HttpResponse httpResponse = buildHttpResponseObject(UNAUTHORIZED new StringBuilder(""Test"") false null); // Write the response. // for some reason calling this next line causes an infinite loop of exceptionCaught even with the // catch below. No idea why. Still investigating. In the meantime we don't have custom error code responses. ChannelFuture future = event.getChannel().write(httpResponse); // Close the connection after the write operation is done even if it's a keep-alive. future.addListener(ChannelFutureListener.CLOSE); } catch(Exception t){ logger.error(""Unable to customize error response. "" t); event.getChannel().close(); } } Here are the exceptions: 38161 [New I/O server worker #1-1] ERROR nettytests.http.snoop.HttpSnoopServerHandler - Error in handling call: javax.net.ssl.SSLHandshakeException: null cert chain at sun.security.ssl.Handshaker.checkThrown(Handshaker.java:1364) at sun.security.ssl.SSLEngineImpl.checkTaskThrown(SSLEngineImpl.java:513) at sun.security.ssl.SSLEngineImpl.readNetRecord(SSLEngineImpl.java:790) at sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:758) at javax.net.ssl.SSLEngine.unwrap(SSLEngine.java:624) at org.jboss.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:931) at org.jboss.netty.handler.ssl.SslHandler.decode(SslHandler.java:649) at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:288) at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:207) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:343) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:274) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:194) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) Caused by: javax.net.ssl.SSLHandshakeException: null cert chain at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1639) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:278) at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:266) at sun.security.ssl.ServerHandshaker.clientCertificate(ServerHandshaker.java:1627) at sun.security.ssl.ServerHandshaker.processMessage(ServerHandshaker.java:176) at sun.security.ssl.Handshaker.processLoop(Handshaker.java:868) at sun.security.ssl.Handshaker$1.run(Handshaker.java:808) at sun.security.ssl.Handshaker$1.run(Handshaker.java:806) at java.security.AccessController.doPrivileged(Native Method) at sun.security.ssl.Handshaker$DelegatedTask.run(Handshaker.java:1301) at org.jboss.netty.handler.ssl.SslHandler$3.run(SslHandler.java:1060) at org.jboss.netty.handler.ssl.ImmediateExecutor.execute(ImmediateExecutor.java:31) at org.jboss.netty.handler.ssl.SslHandler.runDelegatedTasks(SslHandler.java:1057) at org.jboss.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:947) ... 11 more 38177 [New I/O server worker #1-1] ERROR nettytests.http.snoop.HttpSnoopServerHandler - Error in handling call: java.lang.IllegalStateException: cannot send more responses than requests at org.jboss.netty.handler.codec.http.HttpContentEncoder.writeRequested(HttpContentEncoder.java:104) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at nettytests.http.snoop.HttpSnoopServerHandler.exceptionCaught(HttpSnoopServerHandler.java:201) at nettytests.logger.RequestAuditLogger.handleUpstream(RequestAuditLogger.java:32) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:456) at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:554) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:426) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:47) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:343) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:274) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:194) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) 38177 [New I/O server worker #1-1] ERROR nettytests.http.snoop.HttpSnoopServerHandler - Error in handling call: java.lang.IllegalStateException: cannot send more responses than requests at org.jboss.netty.handler.codec.http.HttpContentEncoder.writeRequested(HttpContentEncoder.java:104) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at nettytests.http.snoop.HttpSnoopServerHandler.exceptionCaught(HttpSnoopServerHandler.java:201) at nettytests.logger.RequestAuditLogger.handleUpstream(RequestAuditLogger.java:32) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:456) at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:554) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:426) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:47) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at nettytests.http.snoop.HttpSnoopServerHandler.exceptionCaught(HttpSnoopServerHandler.java:201) at nettytests.logger.RequestAuditLogger.handleUpstream(RequestAuditLogger.java:32) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:456) at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:554) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:426) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:47) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:343) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:274) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:194) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) 38224 [New I/O server worker #1-1] ERROR nettytests.http.snoop.HttpSnoopServerHandler - Error in handling call: java.lang.IllegalStateException: cannot send more responses than requests at org.jboss.netty.handler.codec.http.HttpContentEncoder.writeRequested(HttpContentEncoder.java:104) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at nettytests.http.snoop.HttpSnoopServerHandler.exceptionCaught(HttpSnoopServerHandler.java:201) at nettytests.logger.RequestAuditLogger.handleUpstream(RequestAuditLogger.java:32) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:456) at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:554) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:426) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:47) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at nettytests.http.snoop.HttpSnoopServerHandler.exceptionCaught(HttpSnoopServerHandler.java:201) at nettytests.logger.RequestAuditLogger.handleUpstream(RequestAuditLogger.java:32) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:456) at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:554) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:426) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:47) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at nettytests.http.snoop.HttpSnoopServerHandler.exceptionCaught(HttpSnoopServerHandler.java:201) at nettytests.logger.RequestAuditLogger.handleUpstream(RequestAuditLogger.java:32) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:456) at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:554) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:426) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:47) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:343) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:274) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:194) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) 38255 [New I/O server worker #1-1] ERROR nettytests.http.snoop.HttpSnoopServerHandler - Error in handling call: java.lang.IllegalStateException: cannot send more responses than requests at org.jboss.netty.handler.codec.http.HttpContentEncoder.writeRequested(HttpContentEncoder.java:104) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at nettytests.http.snoop.HttpSnoopServerHandler.exceptionCaught(HttpSnoopServerHandler.java:201) at nettytests.logger.RequestAuditLogger.handleUpstream(RequestAuditLogger.java:32) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:456) at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:554) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:426) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:47) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at nettytests.http.snoop.HttpSnoopServerHandler.exceptionCaught(HttpSnoopServerHandler.java:201) at nettytests.logger.RequestAuditLogger.handleUpstream(RequestAuditLogger.java:32) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:456) at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:554) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:426) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:47) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at nettytests.http.snoop.HttpSnoopServerHandler.exceptionCaught(HttpSnoopServerHandler.java:201) at nettytests.logger.RequestAuditLogger.handleUpstream(RequestAuditLogger.java:32) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:456) at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:554) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:426) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:47) at org.jboss.netty.channel.Channels.write(Channels.java:605) at org.jboss.netty.channel.Channels.write(Channels.java:572) at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:245) at nettytests.http.snoop.HttpSnoopServerHandler.exceptionCaught(HttpSnoopServerHandler.java:201) at nettytests.logger.RequestAuditLogger.handleUpstream(RequestAuditLogger.java:32) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:456) at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:554) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:426) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:47) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:343) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:274) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:194) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) ... repeat ad infinitum. Infinity loop is bad.. what I noticed is that you call Channel.close() in the finally block. This will most times happen before you can write something to the Channel. You should use the future.addListener(ChannelFutureListener.CLOSE); To Close the channel after you have written something. This should even get called on an Exception I appreciate you taking the time to look into the issue. Yes infinite loop is very bad. So I modified the code and now it does exactly what you said. Still the exact same problem. Any guesses? New code posted in modified question since comments don't do code formatting well. The problem is that you try to write a error message to the client after one was already written. And that is not allowed as http only support 1-to-1 relation. I think I see now! So the SslHandler exceptionCaught message is sending a response to the client already and then I'm trying to do it too. Hmm. I guess I can override SslHandler to behave a little differently."
537,A,"Netty and Protobuf in HTTP content I have incoming HTTP requests with protobuf message in the HTTP content. So far I managed to use the Snoop (HTTP server) example and modify the handler part to parse the HTTP content into protobuf message and back to bytes for output. But I guess this is not the optimal way to do this. Is it possible to use the built-in Protobuf encoder/decoder in Netty in the pipeline? So first HTTPResponseDecoder (or something more convenient) ""chops"" off the header and passes only the content part to the FrameDecoder + ProtobufDecoder then passes the message to myAppHandler where business logic is applied? I am a bit confused how message (or part of it) is passed to the next handler. Or am I on totally on the wrong track here? Maybe a link to an example using protobuf with HTTP content would also serve as an explanation if there's any. Thnx in advance. Thank you for the silent support :] The solution is to use HttpObjectAggregator() and simply write a handler taking care of the byte-to-message process using the FullHttpRequest from the aggregator handler. The output of this decoder is the protobuf message: public class ProtoRequestDecoder extends MessageToMessageDecoder<FullHttpRequest> { @Override protected void decode(ChannelHandlerContext ctx FullHttpRequest msg List<Object> out) throws Exception { byte[] payloadBytes = new byte[msg.content().readableBytes()]; msg.content().readBytes(payloadBytes); MyMessage protoMessage = MyMessage.parseFrom(payloadBytes); out.add(protoMessage); } } Could you please show your code about initialize pipeline?"
538,A,"Netty Exception not caught properly Hi guys I'm trying to build a search engine that searches ES for matches the interface has a dynamic counter of hits that gets updated after each key press and I'm looking for a way to validate workaround or catch an exception that gets thrown when the user searches using a double quote for example: a >> 4500 hits ab >> 1200 hits ab"" >> massive stack trace ab""c""> 250 hits The stack: 2013-04-02 16:41:42703 [New I/O worker #1] WARN transport.netty - [Jekyll] Exception caught on netty layer [[id: 0x0106148c /xxx.xxx.xxx.xxx:xxxx => /xxx.xxx.xxx.xxx:xxxx]] java.lang.ArrayIndexOutOfBoundsException: 54 at org.elasticsearch.common.Unicode.UTF8toUTF16(Unicode.java:190) at org.elasticsearch.common.Unicode.unsafeFromBytesAsUtf16(Unicode.java:106) at org.elasticsearch.common.Unicode.fromBytes(Unicode.java:80) at org.elasticsearch.common.Unicode.fromBytes(Unicode.java:73) at org.elasticsearch.action.count.CountRequest.toString(CountRequest.java:334) at java.lang.String.valueOf(String.java:2854) at java.lang.StringBuilder.append(StringBuilder.java:128) at org.elasticsearch.action.support.broadcast.TransportBroadcastOperationAction$AsyncBroadcastAction.onOperation(TransportBroadcastOperationAction.java:306) at org.elasticsearch.action.support.broadcast.TransportBroadcastOperationAction$AsyncBroadcastAction$3.handleException(TransportBroadcastOperationAction.java:263) at org.elasticsearch.transport.netty.MessageChannelHandler.handleException(MessageChannelHandler.java:287) at org.elasticsearch.transport.netty.MessageChannelHandler.handlerResponseError(MessageChannelHandler.java:278) at org.elasticsearch.transport.netty.MessageChannelHandler.process(MessageChannelHandler.java:230) at org.elasticsearch.transport.netty.MessageChannelHandler.callDecode(MessageChannelHandler.java:141) at org.elasticsearch.transport.netty.MessageChannelHandler.messageReceived(MessageChannelHandler.java:93) at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:75) at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:94) at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.processSelectedKeys(AbstractNioWorker.java:372) at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:246) at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:38) at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:102) at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:722) 2013-04-02 16:41:42705 [New I/O worker #2] WARN transport.netty - [Jekyll] Exception caught on netty layer [[id: 0x02474fc7 /xxx.xxx.xxx.xxx:xxxx => /xxx.xxx.xxx.xxx:xxxx]] ... etc Any suggestions? Please ask if you need any additional information. Try/Catch block that fails to catch the exception: def query_str = buildQuery(params) log.debug(""count query: ${query_str}""); log.debug(""enter try:""); try{ def search = esclient.count { indices ""something"" types ""somethingelse"" query { query_string (query: query_str) } } } catch ( Exception e ) { log.error(""The Query is invalid!""); result.hits = 0; } How do you send queries to elasticsearch? added the try/catch block I use. That looks like a bug that was fixed in v0.19.9. Starting with v0.19.9 elasticsearch should return more reasonable error messages. I'll try to upgrade today I was using v0.19.4 I'll see how that goes if it goes well the tick is yours :) Thanks"
539,A,Best approach to integrate netty with openshift In fact I'm trying to see which would be the best approach to achieve play framework native support on openshift. Play has it's own http server developed with netty. Right now you can deploy a play application to openshift but you have to deploy it as a war in which case play uses Servlet Container wrapper. Being able to deploy it as a netty application would allow us to use some advanced features like asynchronuos request. Openshift uses jboss so this question would also involve which would be the recommended approach to deploy a netty application on a jboss server using netty instead of the servlet container provided by jboss. Here is request for providing play framework native support on openshift There's more info there and if you like it you can also add your vote ;-) Of course I've tried james and it's great... but unfortunately heroku's free offering is a bit restrictive openshift gives you five apps with half GB each... BTW was it too difficult to adapt play to jetty??? Cool. Is that a half GB or disk space? By default on Heroku Play apps just use their embedded Netty server instead of Jetty or Tomcat. It's half GB disk space (code + data) for each app and if you have a cool project and talk to them they can even raise it... BTW I'll have a look at your heroku module to do the same with openshift I've already started with a python version I'm planning to do a next version all with java - have a look at this: http://playlatam.wordpress.com/2012/02/09/play-framework-on-the-cloud-made-easy-openshift-module/ Have you tried Play on Heroku? Start with creating 'raw-0.1' application. SSH into the server and cd $OPENSHIFT_DATA_DIR download and install play into a directory here. $OPENSHIFT_DATA_DIR is supposed to survive redeploys of your application. Now you can disconnect from SSH. Clone the application repository. In the repository there is a file .openshift/actions_hooks/start. It's task is to start the application using a framework of your choice. The file will need to contain at least (from what I know about Play) cd $OPENSHIFT_REPO_DIR $OPENSHIFT_DATA_DIR/play-directroy/play run --http.port=$OPENSHIFT_INTERNAL_PORT --some-other-parameters Important You have to bind to $OPENSHIFT_INTERNAL_IP:$OPENSHIFT_INTERNAL_PORT. Trying to bind to different interface is not allowed also most of the ports are blocked. To create some sort of template save the installation steps into .openshift/action_hooks/build file. Check if play is installed if it is do nothing if it's not execute the installation process. great! I'll give it a try... I saw raw cartridge a couple of days ago but didn't know quite well what was it about... (ok I should have guessed...) You may take a look at this https://github.com/marekjelen/openshift-jruby for inspiration ... it's a template for running JRuby applications on raw-0.1 on OpenShift.
540,A,"How to read/write with netty when other side is using readUTF/writeUTF? I'm trying to communicate with a server that uses DataInputStream.readUTF and DataOutputStream.writeUTF. I did the usual bootstrapping code to setup my client and set the following pipelinefactory  bootstrap.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( new LengthFieldBasedFrameDecoder(65536 0 2) new StringDecoder(CharsetUtil.UTF_8) new StringEncoder(CharsetUtil.UTF_8) new MyClientHandler()); } }); in MyClientHandler which extends SimpleChannelUpstreamHandler I have the following:  boolean sent = false; //is this thread safe? @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { logger.log(Level.INFO e.getMessage().toString()); e.getChannel().write(""Hello over there!""); if(!sent){ //do something and set sent } } I managed to receive messages from server successfully but server is not receiving my ""hello over there"" message. Not sure what I might have overlooked. Also notice the boolean sent can I add such fields and work with them without threading concerns? I managed to receive messages from server successfully but server is not receiving my ""hello over there"" message. Not sure what I might have overlooked. Because the message from the server was able to be received by using LengthFieldBasedFrameDecoder the message has a length field.  +--------+----------+ | Length | Message | +--------+----------+ Therefore There is a possibility that the server will expect the received message has the length field. How if the length field is written as follows?  +--------+---------------------+ | 0x0011 | ""Hello over there!"" | +--------+---------------------+ [sample] @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { logger.log(Level.INFO e.getMessage().toString()); byte[] message = ""Hello over there!"".getBytes(""UTF-8""); ChannelBuffer buf = ChannelBuffers.buffer(message.length + 2); buf.clear(); short len = (short)message.length; buf.writeShort(len); buf.writeBytes(message); e.getChannel().write(buf); if(!sent){ //do something and set sent } } Also notice the boolean sent can I add such fields and work with them without threading concerns? Yes you can add the fields to store some state. And you need not consider the synchronization of the thread. I think an even cleaner approach would be to add org.jboss.netty.handler.codec.frame.LengthFieldPrepender to the server pipeline. This will automatically prepend the lengthField to the outgoing packet."
541,A,"How to manipulate Message coming from Netty server/client I am prototyping a Netty client/server transfer for strings now I want to pass these strings to file when it arrives to server side. Client:  private ClientBootstrap bootstrap; private Channel connector; private MyHandler handler=new MyHandler(); public boolean start() { // Standard netty bootstrapping stuff. Executor bossPool = Executors.newCachedThreadPool(); Executor workerPool = Executors.newCachedThreadPool(); ChannelFactory factory = new NioClientSocketChannelFactory(bossPool workerPool); this.bootstrap = new ClientBootstrap(factory); // Declared outside to fit under 80 char limit final DelimiterBasedFrameDecoder frameDecoder = new DelimiterBasedFrameDecoder(Integer.MAX_VALUE Delimiters.lineDelimiter()); this.bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( handler frameDecoder new StringDecoder() new StringEncoder()); } }); ChannelFuture future = this.bootstrap .connect(new InetSocketAddress(""localhost"" 12345)); if (!future.awaitUninterruptibly().isSuccess()) { System.out.println(""--- CLIENT - Failed to connect to server at "" + ""localhost:12345.""); this.bootstrap.releaseExternalResources(); return false; } this.connector = future.getChannel(); return this.connector.isConnected(); } public void stop() { if (this.connector != null) { this.connector.close().awaitUninterruptibly(); } this.bootstrap.releaseExternalResources(); System.out.println(""--- CLIENT - Stopped.""); } public boolean sendMessage(String message) { if (this.connector.isConnected()) { // Append \n if it's not present because of the frame delimiter if (!message.endsWith(""\n"")) { this.connector.write(message + '\n'); } else { this.connector.write(message); } System.out.print(message); return true; } return false; } Server:  private final String id; private ServerBootstrap bootstrap; private ChannelGroup channelGroup; private MyHandler handler= new MyHandler(); public Server(String id) { this.id = id; } // public methods --------------------------------------------------------- public boolean start() { // Pretty standard Netty startup stuff... // boss/worker executors channel factory channel group pipeline ... Executor bossPool = Executors.newCachedThreadPool(); Executor workerPool = Executors.newCachedThreadPool(); ChannelFactory factory = new NioServerSocketChannelFactory(bossPool workerPool); this.bootstrap = new ServerBootstrap(factory); this.channelGroup = new DefaultChannelGroup(this.id + ""-all-channels""); // declared here to fit under the 80 char limit final ChannelHandler delimiter = new DelimiterBasedFrameDecoder(Integer.MAX_VALUE Delimiters.lineDelimiter()); this.bootstrap.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { SimpleChannelHandler handshakeHandler = new SimpleChannelHandler(); return Channels.pipeline( handler delimiter new StringDecoder() new StringEncoder() handshakeHandler); } }); Channel acceptor = this.bootstrap.bind(new InetSocketAddress(12345)); if (acceptor.isBound()) { System.out.println(""+++ SERVER - bound to *:12345""); this.channelGroup.add(acceptor); return true; } else { System.err.println(""+++ SERVER - Failed to bind to *:12345""); this.bootstrap.releaseExternalResources(); return false; } } public void stop() { this.channelGroup.close().awaitUninterruptibly(); this.bootstrap.releaseExternalResources(); System.err.println(""+++ SERVER - Stopped.""); } Handlers used: Client handler: public class MyHandler extends SimpleChannelUpstreamHandler{ @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { if(e.getMessage() instanceof String){ System.out.println((String)e.getMessage()); } System.out.println(e.getMessage().toString()); } } Server handler: @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { Channel channel= ctx.getChannel(); channel.write(e.getMessage()); if(e.getMessage() instanceof String){ System.out.println((String)e.getMessage()); } System.out.println(e.getMessage().toString()); } client runner: public static void main(String[] args) throws InterruptedException { final int nMessages = 5; try { Client c = new Client(); if (!c.start()) { return; } for (int i = 0; i < nMessages; i++) { Thread.sleep(1L); c.sendMessage((i + 1) + ""\n""); } c.stop(); } catch (InterruptedException e) { e.printStackTrace(); } } Server Runner: public static void main(String[] args) { final Server s = new Server(""server1""); if (!s.start()) { return; } Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { s.stop(); } }); } now what I really need is to print the message that I wrote on the channel on both client and server side and I am really puzzled on this. Your pipeline creation seems to be wrong at first look. At server side when decoding the Delimiter needs to come first then the StringDecoder and then the business handler. You could resolve this probably by just putting breakpoints in these decoders and encoders. Also take a look at this link for very good documentation on how this works."
542,A,"Netty 4 multiple client I need to make the client is able to make many connections. I use Netty 4.0. Unfortunately all existing examples do not show how to create a lot of connections. public class TelnetClient { private Bootstrap b; public TelnetClient() { b = new Bootstrap(); } public void connect(String host int port) throws Exception { try { b.group(new NioEventLoopGroup()).channel(NioSocketChannel.class).remoteAddress(host port).handler(new TelnetClientInitializer()); Channel ch = b.connect().sync().channel(); ChannelFuture lastWriteFuture = null; BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); for (;;) { String line = in.readLine(); if (line == null) break; lastWriteFuture = ch.write(line + ""\r\n""); if (line.toLowerCase().equals(""bye"")) { ch.closeFuture().sync(); break; } } if (lastWriteFuture != null) lastWriteFuture.sync(); } finally { b.shutdown(); } } public static void main(String[] args) throws Exception { TelnetClient tc = new TelnetClient(); tc.connect(""127.0.0.1"" 1048); tc.connect(""192.168.1.123"" 1050); //... } } Is this the correct decision? or could it be better? Yes its almost correct.. The only thing you MUST change is the creation of NioEventLoopGroup on every connect. NioEventLoopGroup instances are expensive so they should be shared. Create one instance and share it by pass the same instance to the Bootstrap.group(...) everytime.. See http://static.netty.io/4.0/api/io/netty/channel/ChannelHandler.Sharable.html and what about TelnetClientInitializer() also enough to create one instance? Depends on the code.. Is it @Sharable or not ;) ? Yes it's Sharable static link returns 404 - update: http://netty.io/4.0/api/io/netty/channel/ChannelHandler.Sharable.html"
543,A,"how to reconnect after the connection becomes inactive using netty 4.0 i have scanerio in which i have to reconnect to the server once the connection becomes inactive due to any reason using netty 4.0.Code should try to reconnect until it is connected successfully..Following is the code to connect to server once. Bootstrap b; b.group(group); b.channel(NioSocketChannel.class); b.option(ChannelOption.CONNECT_TIMEOUT_MILLIS 10000); // b.option(ChannelOption. 10000); b.handler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(""frameDecoder"" new DelimiterBasedFrameDecoder(bufferSizebt)); ch.pipeline().addLast(""ByteDecoder"" new ByteArrayDecoder()); ch.pipeline().addLast(""frameEncoder"" new ByteArrayEncoder()); ch.pipeline().addLast (new TimeClientHandler (c)); } }); System.out.println(""Connecting Server""); this.host = host; this.port = port; try { f = b.connect(host port).sync(); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } You should add a ChannelFutureListener to the ChannelFuture returned by connect(...) and check if the future is failed or not. If it is failed you can try to reconnect if needed."
544,A,Any netty 4 documentation available? I know Norman is working on the Netty 4 book as I've been following the tweets but was wondering if there are any pieces available to help someone who hasn't worked with Netty 3. I have looked a little at the existing 3.x articles but I think it would be easier to understand the primary components without having to learn 3.x and then mentally apply the New and Noteworthy section to bridge the gap. For now I'm just trying to go through the example/test code to see how it's used but any overview/fundemental documentation would be great. If not that's ok - just thought I'd check. Thanks There is nothing out there at the moment except what you find on the Blog and the javadocs. I'm currently working hard on getting the javadocs up-to-date before our next release so you may find all you need in there. An other source of informations is like you said the example module which contains a lot examples for all kind of use-cases. Hopefully the MEAP of the Netty book will start in not so far future. But we will see.. Sounds good thank you!
545,A,SO_TIMEOUT in non blocking channel in netty Does the SO_TIMEOUT expire the Non blocking channel  if a channel doesn't receive a read/response in timeout millis? bootstrap.group(workerGroup).channel(NioSocketChannel.class). .handler(channelInitializer).option(ChannelOption.SO_TIMEOUT 100); Also is the option applicable for server channel also? like: serverBootstrap.group(bossGroup workerGroup).channel(NioServerSocketChannel.class). localAddress(new InetSocketAddress(8800)).childHandler(serverChannelInitializer). option(ChannelOption.SO_TIMEOUT 100).bind().sync(); No. SO_TIMEOUT has effect only for OIO socket transport. You should use IdleStateHandler and handle an IdleStateEvent in your userEventTriggered() implementation. thanks trustin and Norman!
546,A,"Message construction interfere I bumped to a problem that looks like that: 1) I have long messages ~70Kb constructed in the ByteToMessageDecoder - let's call it BlockMessage 2) In the meantime there is Timer that does Ping/Pong  that is send Ping and get's a Pong both short ~8 bytes messages. (!!!) the problem is that sometimes I see Pong message interfere into BlockMessage and that's breaks the message construction. can be described like that: 1) I am in the process of reading message: @Override protected void decode(ChannelHandlerContext ctx ByteBuf in List<Object> out) throws Exception { // No header for Eth. message if (in.readableBytes() < 8) return; long magicBytes = in.readUnsignedInt(); long msgSize = in.readUnsignedInt(); if (!((magicBytes >> 24 & 0xFF) == 0x22 && (magicBytes >> 16 & 0xFF) == 0x40 && (magicBytes >> 8 & 0xFF) == 0x08 && (magicBytes & 0xFF) == 0x91 )) { logger.error(""abandon garbage wrong magic bytes: [ {} ] msgSize: [ {} ]"" magicBytes msgSize); ctx.close(); } // Don't have the full packet yet if (msgSize > in.readableBytes()) { logger.debug(""msg decode: magicBytes: [ {} ] readBytes: [ {} ] / msgSize: [ {} ] "" magicBytes in.readableBytes() msgSize); in.resetReaderIndex(); return; } logger.debug(""message fully constructed go handle it: readBytes: [ {} ] / msgSize: [ {} ]"" in.readableBytes() msgSize); byte[] decoded = new byte[(int)msgSize]; in.readBytes(decoded); out.add(decoded); in.markReaderIndex(); } 2) in the meantime: timer invokes ping and gets pong from the peer 3) I get this pong inside the frame in 1) I think it's a pretty simple and common case but I didn't find any example and the question is how to avoid frames interfere ? P.S. I use: 4.0.17.Final Can you please give more of a description of how they interfere? .write(..) is designed to handle concurrency. Updated the info is it better now ? How are you writing both messages to the channel? Are you writing the large message using a single call to write or are you fragmenting it? Is your decoder shared between multiple channels? There are few things that could be causing this but as md_5 says if you have just two separate calls to write one for each message and you're using TCP this shouldn't happen - the ping should be stuck behind the block message. I have found a root cause and a solution for this: (Problem) When big message arrives it is constructed to a message out of byte stream packets. Over that period no other message should be asked on that channel and even small ping/pong will interfere and insert corrupting data into the construction. (Solution) in order not to interfere I use queue order of the messages and only when the full message been received the next round trip is invoked whether it's a ping/pong or another request/response."
547,A,"Detecting late responses I'm using Netty 3.3.1. I wish to (1) abort sending a late response on server-side and (2) reject the late responses that came from the server on client-side. My workflow is as follows. I send a request from the client and I expect the server to respond within 30 secs. If it doesn't I assume something went wrong and I send the request all over again. Now I'm worried that the client will receive the old response whilst expecting the new response. I want to detect that (mainly on client-side but it would be cool if the server decided not to send the response after 30 secs). Can I use Netty's IdleStateHandler/WriteTimeoutHandler/ReadTimeoutHandler for that? Note that I don't disconnect the channel but re-use it for future requests/responses and that the timer mustn't be reset on server when the client re-sends the request via the same channel. My second idea was to timestamp requests and responses. OTOH am I complicating things? Can late responses even happen? I think the right way to handle this would be to have some kind of ""id"" which can be used to see if its an ""old"" response or not."
548,A,"Netty 4.0 SPDY file transfer not working For a long time I always run into the same trouble when i try to use SPDY with netty. I checked different SPDY sources to setup my SPDY server. So far it works fine and I have got a pure html output in my browser. Chrome also shows an spdy session. Issue When i put the netty 4 HttpStaticFileServerHandler example class to the SPDYorHTTPHandler I always run into the same problem. HTML content is sent but the file content isn't. The handler is sending the response so my client retrieves but then the files are never transmitted. Any ideas about that? ctx.write(response) is writing the response to the client (response is a HttpResponse obj). In the next line:(raf=RandomAccessFile) ChannelFuture sendFileFuture; if (useSendFile) { sendFileFuture = ctx.write(new DefaultFileRegion(raf.getChannel() 0 fileLength) ctx.newProgressivePromise()); } else { sendFileFuture = ctx.write(new ChunkedFile(raf 0 fileLength 8192) ctx.newProgressivePromise()); } But it never gets written. The code based 100% on the HttpStaticFileServerHandler example and the SPDY example of netty 4. I just changed the createHttpRequestHandlerForHttp output from SpdyServerHandler to HttpStaticFileServerHandler. This is the pileline I use:  ChannelPipeline pipeline = ctx.pipeline(); pipeline.addLast(""spdyFrameCodec"" new SpdyFrameCodec(version)); pipeline.addLast(""spdySessionHandler"" new SpdySessionHandler(versiontrue)); pipeline.addLast(""spdyHttpEncoder"" new SpdyHttpEncoder(version)); pipeline.addLast(""spdyHttpDecoder"" new SpdyHttpDecoder(version MAX_CONTENT_LENGTH)); pipeline.addLast(""spdyStreamIdHandler"" new SpdyHttpResponseStreamIdHandler()); pipeline.addLast(""chunkedWriter"" new ChunkedWriteHandler()); pipeline.addLast(""httpRequestHandler""new HttpStaticFileServerHandler()); If you need more code for that just write I will extend the Post. I got no errors warnings or something else. A ChannelProgressiveFutureListener did never call operationProgressed function. Thx dodo. Try to use: sendFileFuture = ctx.write(new HttpChunkedInput(new ChunkedFile(raf 0 fileLength 8192)) ctx.newProgressivePromise()); Thx alot this is working. But yet I don't understand why it works. Why I need to add a HttpChunkedInput? Because otherwise ChunkedWriteHandler will produce ByteBuf and not HttpContent. Spdy handlers expect HttpContent."
549,A,"Send message to a client from server I need to send message to clients from a netty server base on user names of clients. As a result I need to map channels with user name and find the channel each time I want to send message. I have two approaches in my mind the question is : Which approach is better in term of performance in server side. do you have any better idea? Map channels with user name in a hashmap. //Send userName from client side in first request //Get userName in server side and put it in a map Map<String Channel> userMap = new ConcurrentHashMap<StringChannel>(); //loop over userMap to find specific client Set Attachment with user name. //Set the attachment in client side ctx.getChannel().setAttachment(username); //Put all channels to a default channel group //Get all channels search in their attachments to find specific client I think that you want to look up the channel based on the username not the other way around so you would want a `Map` ? The second approach seems to be a lot worse because of the word ""*search*"" though a variant of the second approach seems possible. For now I like the first one. @AndrewStubbs thanks for your notice corrected. @keyser what about removing channels from Map? Still logical? How about creating a ""UserInfo"" object which holds the user's name and his associated channel?  From your code I suspect that the second option uses linear search to find a specific channel. The first option would simple perform a get. (But the key must be string in this case) Average linear search time: O(n/2) Average hashmap access time: O(1)! (see this posting for more information) That means that the linear search gets worse if you have more channels. The hashmap option is more stable and you can expect almost constant time access. What you could do is ""fuse"" both option so you have the map to access the channels easily and the ChannelGroup for handling the difficult stuff. What you need to do is to remove the channel from the map when its closed. What do you mean? can you explain more? I think you have the best of both worlds with this solution But the thing that I consider is handling connection latches and removed channels that might be a headache and effective on performance. While in the second approach default channel group would take care of it. Hmmm if this operations are far more expensive then the search to access the channel then I would go with the context if it handles this operation well. When I think of this couldn't you use both? ChannelGroup and the map to find a channel easily? But then you would need some sort of listener if a channel gets closed you can removed it from the map. Lets say I do it in my ServerHandler which extends SimpleChannelUpstreamHandler . I keep username in handler as well ""for the performance"" and then remove the channel base on it's user name from the map on channelClosed event. Will it be a good solution ?"
550,A,Netty performance Is there any real difference to the performance when you use Netty and if you don't use it in an application with tens of thousand of connections? HTTP web app is not necessarily go to apache httpd and tomcat: Check this and this to see how superior nginx is compare to apache httpd Click here to see How Play!framework (based on Netty) outperforms those based on Tomcat/Servlet  Netty is very fast especially with many connections. In my experience: It's more scalable than the standard Java IO. In particular the old synchronous Java IO packages require you to tie up one thread per connection. This can become problematic with tens of thousands of connections! It's approximately the same speed as what you would get if you wrote custom networking code using Java NIO but it's a lot simpler to just use Netty directly rather than go down this route.  Not really as Peter noted. However I've found that Netty also offers a very nice API for building a server. Although there is a bit of a learning curve to the API it's well made and creating a new server can be trivial. It's also quite efficient code-wise so you would have very little code if you have a simple protocol and implementation. This is ONLY if you are building a server for something other than HTTP. If you are talking about an HTTP web application go with the tried an true. Apache for straight HTML pages Tomcat if you need Servlets.  Actually using Tomcat NIO you can get up to 16000 concurrent connections; mind you thats CONCURRENT connections on one machine. This was tested against as a comparison vs Jetty which topped out at 4000 when they kept giving them more and more memory. (http://www.javalobby.org/java/forums/t92965.html) And using a 'convention over config' framework like Grails with REST functionmality built in (or simple plugins like RestRPC) you can easily build API's webhooks etc in seconds. I also have more control using Spring Security plugin as to who can access what api call via what IP or what role if I want. Netty has limitations that the plethora of Grails plugins can expand far beyond using Tomcat NIO. This information was 6 years out of date when you posted it almost a year ago. Is it accurate today?  Not really a good reason to use Netty is to improve the reliability of the connections and leave you to code what the connection does rather than worry about the details of everything which can go wrong. (Often only comes by finding out the hard way) Netty may help you scale over 1K connections. However if you don't need so many connections you might find that simple code performs best.  Twitter used Netty in its Search System: Ref: Twitter Search is Now 3x Faster
551,A,"Sending messages over an unreliable network in JAVA I need to send a continuous flow of messages (simple TextMessages with a timestamp and x/y coordinates) over a wireless network from a moving computer. There will be a lot of these short messages (like 200 per sec) and unfortunately the network connection is most likely unreliable since the sending device will leave the WLAN area from time to time... When the connection is not available all upcoming messages should be buffered until the connection is back up again. The order of the transmitted messages does not matter since they contain a timestamp but ALL messages must be transferred. What would be a simple but reliable method for sending these telegrams? Would it be possible to just use a ""plain"" TCP or UDP socket connection? Would messages be buffered when the connection is temporarily down and send afterwards automatically? Or is the connection loss directly detected and reported thus I could buffer the messages and try to reconnect periodically on my own? Do libraries like Netty help here? I also thought about using a broker to broker communication (e.g. ActiveMQ network of brokers) as an alternative. Would the overhead too big here?! Would you suggest another messaging middleware in this case? Seems like you could use a message wrapper like Java JMS using a ""Assured persistent"" reliability mode. I have not done this myself in the context of text messages but this idea may lead you to the right answer. Also there may be an Apache library already written that handles what you need such as Qpid . As I mentioned I also considered ActiveMQ that allows JMS as well as AMPQ but I don't know how much this would affect the performance. Maybe I need to implement a prototype a test it...Regarding ""Assured persistent"": Isn't that only needed when the messages needed to ""survive"" a crash? Even without persistence the messages should be queued.  TCP is guaranteed delivery (When it's connected that is) - You should check if the connection went down and put messages in a queue while it is retrying the connection. Once it sees that connection is back up dump the queue into the TCP socket. Also look into TCP Keepalive for recognition of a down connection: http://tldp.org/HOWTO/TCP-Keepalive-HOWTO/overview.html @Ingo Keep alive on the other end as well. Send an alive packet upon no response and if no response from the alive packet consider it dead. I'm not familiar with any libraries but i'm sure there are some out there. In the past I discovered that sometimes the connection reported connected even when the connection was actually lost. The disconnect wasn't detected fast enough by Keepalive I think...but I have recheck that for WLAN connections. Nevertheless do you recommend any extra library for this or just use JDK classes and do all by myself?"
552,A,"How can I configure the source port for a server using Netty to send UDP packets? I have a server task that uses Netty for socket I/O. It binds to port MY_PORT and receives UDP messages from clients. It responds to these clients sending messages back to the clients with a destination port of MY_PORT. Using wireshark I see that the outgoing packets from my server also have a source port of MY_PORT. This all works fine. The people in charge of the network between the server and clients are having some issues with a load balancer. They said it would help them out if the UDP messages my server sends to the clients had a different source port than the one used for a destination. I've looked at the Netty API but I'm not sure how I can do this. It seems that because I've bound to a local port I must use that for outgoing packets as well?? Here's a stripped down version of my code. import java.net.InetAddress; import java.net.InetSocketAddress; import java.net.SocketAddress; import java.net.UnknownHostException; import java.util.concurrent.Executors; import org.jboss.netty.bootstrap.ConnectionlessBootstrap; import org.jboss.netty.buffer.ChannelBuffer; import org.jboss.netty.buffer.ChannelBuffers; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.channel.Channels; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.SimpleChannelHandler; import org.jboss.netty.channel.socket.nio.NioDatagramChannelFactory; public class UdpServer { private final int port; private Channel serverChannel; public UdpServer( int port ) { super(); this.port = port; } public void start() { NioDatagramChannelFactory serverChannelFactory = new NioDatagramChannelFactory( Executors.newCachedThreadPool() 1 ); ConnectionlessBootstrap serverBootstrap = new ConnectionlessBootstrap( serverChannelFactory ); serverBootstrap.setPipelineFactory( new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() { return Channels.pipeline( new SimpleChannelHandler() { @Override public void messageReceived( ChannelHandlerContext ctx MessageEvent e ) { // TODO handle message from client } } ); } } ); serverBootstrap.setOption( ""reuseAddress"" Boolean.TRUE ); final InetSocketAddress trafficAddress = new InetSocketAddress( port ); serverChannel = serverBootstrap.bind( trafficAddress ); } public void sendMessage( byte[] message String clientIp ) throws UnknownHostException { // TODO how do I control the source port of this packet?? SocketAddress address = new InetSocketAddress( InetAddress.getByName( clientIp ) port ); ChannelBuffer buffer = ChannelBuffers.wrappedBuffer( message ); serverChannel.write( buffer address ); } } They said it would help them out if the UDP messages my server sends to the clients had a different source port than the one used for a destination. This sounds like complete hooey to me. Net admins seem to have no idea about how source/destination ports are actually allocated. Even if the clients used system-allocated poets rather than a fixed port which they probably should the system could still allocate the same port number as the server is using. However you could probably shut them up or at least move them on to a different problem by having the clients use system-allocated ports rather than a fixed port. Unless there is a client-side firewall of course ... Yeah I had the same thought. Unfortunately I don't have any control over the clients in this system and there are firewalls in the system so fixed ports are required.  You're already using bind() to set the local address. You can use connect() to connect to a specific destination port (a stretch of the ""connect"" concept). On a regular datagram socket you could include the remote port in the send request but not if you're using write(). In that case you must use connect(). So I would still need the bind() call to receive traffic but not use the Channel object returned from it. Instead I would call connect() each time I wanted to send something to a client? If I have 1000s of clients I have to either hold on to all of these Channel objects or create a new one each time I send a message both of which seem inefficient. Am I right in my understanding? That's about it."
553,A,"Netty frame decoder for protocol with variable lines per request? I'm new to Netty and I'm trying to build a simple SMTP server. The problem that I've run into is that most SMTP server commands are composed of a single line that is easily read in the messageReceived() method. However after receiving a number of one line commands from the client the ""data"" portion of the email can contain any number of lines. This works fine with short emails but longer emails can result in only partial data. My understanding is that this is due to the fact that I don't have any frame decoders in the pipeline right now. The problem I have is that single line commands are delimited with a linefeed but the ""data"" section consists of any number lines terminated with a ""."" on its own line. Is it possible to create a frame decoder that works for both single line commands and multi-line requests terminated with a special character sequence? Thanks! Dustin You don't necessarily need one decoder to do both jobs. You can create two decoders one for the headers and one for the data portion. Once you have completed the header portion get a reference to the pipeline remove the ""header decoder"" and add the ""data decoder"". Once that's complete reset the pipeline to the original config and continue. I initially configure the pipeline in the handler that is shared by all incoming requests. If I ""get a reference to the pipeline"" while processing a request is this pipeline specific to that request (meaning that I can add/remove decoders without affecting other requests)? You bet! Isn't. Isn't netty great! Cool. Thanks for your help!  Apache James uses Netty for SMTP so you might want to check out how they do it: http://svn.apache.org/viewvc/james/server/trunk/protocols-smtp/src/main/java/org/apache/james/smtpserver/netty/ Thanks! I'll check that out."
554,A,"NullPointerException on HttpMessageDecoder.skipControlCharacters in Netty I'm getting strange error when trying to read HTTP request in Netty: java.lang.NullPointerException at org.jboss.netty.handler.codec.http.HttpMessageDecoder.skipControlCharacters(HttpMessageDecoder.java:409) at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:184) at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:107) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:470) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:443) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:351) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:282) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:202) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:679) the stack trace doesn't end up in my code and I have no idea how to debug that? class RouteHandler(default: Tuple2[String Int]) extends SimpleChannelUpstreamHandler { override def handleUpstream(ctx: ChannelHandlerContext e: ChannelEvent) { e match { case evt: UpstreamMessageEvent => evt.getMessage match { case req: HttpRequest => { val projectHdr = req.getHeader(""HDR"") RouteHandler.log.info(""Project ID: {}"" projectHdr) val backendServerUri = projectHdr match { case null => default case uri: String => if (ObjectId.isValid(projectHdr)) { val serverData = MappingService.resolveServer(new ObjectId(projectHdr)) (serverData.host() serverData.port()) } else default } RouteHandler.log.info(""Route to {}"" backendServerUri) val pipeline = ctx.getPipeline pipeline.synchronized { val handler = new ForwardRequestHandler(backendServerUri._1 backendServerUri._2) pipeline.get(HANDLER_NAME) match { case null => pipeline.addLast(HANDLER_NAME handler) case _ => pipeline.replace(HANDLER_NAME HANDLER_NAME handler) } } } case z => RouteHandler.log.warn(""Can not handle {}"" z.getClass) } case z: DefaultExceptionEvent => RouteHandler.log.error(""Exception from Netty"" z.getCause) case z => } super.handleUpstream(ctx e) } override def exceptionCaught(ctx: ChannelHandlerContext e: ExceptionEvent) { RouteHandler.log.error(""Caught"" e.getCause) e.getChannel.close() } } Also do you maybe share the handler ? Looks like the error may be caused by the data the client is sending to the server. Which version of Netty and which client are you using? @Veebs no the data is plain HTTP GET query. nothing complicated @NormanMaurer Yes this was the clue. So just for the record... The error was that the HttpMessageDecoder was shared across Channels which is not allowed as its not annotated witht @Sharable"
555,A,Java netty can only take X number of request per second? Java netty can only take X number of request per second? With the selector approach is it true that it can be a bottleneck in terms of serving request per second? We find that when the traffic is high clients are unable to connect through resulting in a time out. There's an increasing view that you shouldn't use Selectors just hundreds of thousands of threads. Selectors move the scheduling process into the application where arguably it doesn't belong. Also they were designed when the alternative was a process per client. A thread per client is orders of magnitude cheaper.  This is probably not due to selector being a bottleneck but either due to TCP having too few ephemeral ports on the clients or due to server hitting the file descriptor limit. It's not the client each client only makes one connection. It's not the file descriptor because I am able to connect to that server on another port without time out.
556,A,"Netty 4 read/write in handler multiple times I'm new in Netty and I decided to start with 4.0.0 because I thought it should be better because it's newer. My server application should receive data from gps devices and the process is like this - at first I'm receiving 2 bytes which are length of device imei and then I'm receiving imei with that length then I should send 0x01 to device if I want to accept data from it. After my answer device sends me gps data with AVL protocol. Now my server is working without Netty and I want to change it to work with netty. This is what I have done: I have created server class like this public class BusDataReceiverServer { private final int port; private final Logger LOG = LoggerFactory.getLogger(BusDataReceiverServer.class); public BusDataReceiverServer(int port) { this.port = port; } public void run() throws Exception { LOG.info(""running thread""); EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try{ ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new BusDataReceiverInitializer()); b.bind(port).sync().channel().closeFuture().sync(); }catch (Exception ex){ LOG.info(ex.getMessage()); } finally { LOG.info(""thread closed""); bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { new BusDataReceiverServer(3129).run(); } } and created initializer class public class BusDataReceiverInitializer extends ChannelInitializer<SocketChannel> { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(""imeiDecoder"" new ImeiDecoder()); pipeline.addLast(""busDataDecoder"" new BusDataDecoder()); pipeline.addLast(""encoder"" new ResponceEncoder()); pipeline.addLast(""imeiHandler"" new ImeiReceiverServerHandler()); pipeline.addLast(""busDataHandler"" new BusDataReceiverServerHandler()); } } then I have created decoders and encoder and 2 handlers. My imeiDecoder and encoder and ImeiReceiverServerHandler are working. This is my ImeiReceiverServerHandler public class ImeiReceiverServerHandler extends ChannelInboundHandlerAdapter { private final Logger LOG = LoggerFactory.getLogger(ImeiReceiverServerHandler.class); @Override public void messageReceived(ChannelHandlerContext ctx MessageList<Object> msgs) throws Exception { MessageList<String> imeis = msgs.cast(); String imei = imeis.get(0); ctx.write(Constants.BUS_DATA_ACCEPT); ctx.fireMessageReceived(msgs); } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { super.channelInactive(ctx); //To change body of overridden methods use File | Settings | File Templates. } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) throws Exception { super.exceptionCaught(ctx cause); //To change body of overridden methods use File | Settings | File Templates. } } Now after accepting I don't understand how to continue receive gps data and forward it to handler BusDataReceiverServerHandler. If anyone could help me with this or could offer me useful documentation I will be very grateful. Or if it is possible to do this with Netty 3 for this I will also be thankful. I have not used Netty 4 so I am not sure if my answer will be 100% accurate or the best way to do things in Netty 4 but what you need to do is track the state of your connection / client session in order to know when to forward messages to your second handler. E.g. private enum HandlerState { INITIAL IMEI_RECEIVED; } private HandlerState state = HandlerState.INITIAL; @Override public void messageReceived(ChannelHandlerContext ctx MessageList<Object> msgs) throws Exception { if (state == HandlerState.INITIAL) { MessageList<String> imeis = msgs.cast(); String imei = imeis.get(0); ctx.write(Constants.BUS_DATA_ACCEPT); state = HandlerState.IMEI_RECEIVED; } else { // Forward message to next handler... // Not sure exactly how this is done in Netty 4 // Maybe: ctx.fireMessageReceived(msgs); // Or maybe it is: // ctx.nextInboundMessageBuffer().add(msg); // ctx.fireInboundBufferUpdated(); // I believe you could also remove the IMEI handler from the // pipeline instead of having it keep state if it is not going to do anything // further. } } So either track state in the handler or remove the handler from the pipeline once it has finished if it will not be used further. When tracking state you can either keep the state in the handler itself (as shown above) or keep the state variables in the context / attribute map (however that is done in netty 4). The reason to not keep the state in the handler itself would be if you were going to make the handler shareable (one instance used across multiple channels). It is not necessary to do this but there could be some resource savings if you have a large number of concurrent channels. Thanks! it works."
557,A,"When does a Netty ChannelFuture for a write operation become ""done?"" In Netty 4 when exactly does the ChannelFuture for a write operation (let's say to an NioSocketChannel) become ""done?"" Does Netty wait for an ACK packet? Is there any interdependence between the input and output handlers in a ChannelPipeline in terms of marking write futures as done? Netty *can't* wait for an ACK packet. Nothing in Java or the BSD sockets API allows you to do that. Netty does not wait for ACK packets. ACK packets are an implementation detail of TCP that is mostly (entirely? yes in java but not sure about socket api's in C) hidden to the application using a socket. If you need to know when messages are delivered you should add an acknowledge component to your application layer protocol. In Netty 3.x Netty would call the success method (and notify listeners) on a ChannelFuture after the given message was written to the socket. I'm not as familiar with the Netty 4 implementation details but from my tracing though the source I believe this is also true in Netty 4. ChannelOutboundBuffer.remove() @ ChannelOutboundBuffer.java:263 sets the success of the future and is called by NioSocketChannel.doWrite(ChannelOutboundBuffer) @ NioSocketChannel.java:264 after a message is done being written to the socket. Note that being written to the socket doesn't necessarily mean the message has been sent (partially or entirely) only that it has been written to the send buffer for the socket in the TCP layer. Thanks for the thorough answer! Sadly it's not my protocol (see https://developer.apple.com/library/ios/documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Introduction.html) so it sounds like we may just need to deal with some amount of uncertainty. Cheers!"
558,A,Netty with Blocking IO clients Browsers I have a legacy app(HTTP and raw TCP) that uses traditional BIO (blocking IO) and I'd like to start replacing it with Netty. How does Netty work with traditional BIO clients? Are there any issues if I first replace the server component with Netty and leave the BIO clients in place? Additionally can a Netty built server replace a typical HTTP Web Server intended to server Browser clients? Any issues there? Thanks My understanding is that netty supports blocking (org.jboss.netty.channel.socket.oio) and non blocking (org.jboss.netty.channel.socket.nio) operations. See http://docs.jboss.org/netty/3.2/guide/html/architecture.html section 2.2. It is easy to switch between blocking and non-blocking so you can try with NIO and if that does not with with your clients you can switch to OIO. You set the type of IO you wish to support with you setup to ChannelFactory // NIO - non blocking ChannelFactory factory = new NioSeverSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); //OIO - blocking ChannelFactory factory = new OioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); There are a number existing netty based HTTP web server/framework already implemented. For example webbit xitrum and play framework. I'm sure there are more. These are just the ones I can think of off the top of my head. If you wish to implement your own a good starting point is the examples in the org.jboss.netty.example.http package. Thanks Veebs! that's great stuff....happy new year Does netty have its own OIO library or is this a 3rd party (jboss) library?
559,A,ObjectEncoderOutputStream Out Of Memory Exception possible? I noticed that ObjectEncoderOutputStream uses ObjectOutputStream. Traditionally ObjectOutputStream can cause an OOME if it's not reset on a regular basis. Is ObjectEncoderOutputStream susceptible to this? No the ObjectEncoderOutputStream is not susceptible to the same problem because of the way it uses the ObjectOutputStream. For each writeObject call a new ObjectOutputStream (specifically a CompactObjectOutputStream) is created to write that single object and then it is closed again. Thus no ObjectOutputStream ever holds on to old references and thus doesn't cause a OOM this way.
560,A,"Errors in Netty 4 http snoop example with apache benchmark I'm trying to understand enough Netty to create a lightweight yet fully functional web server. I started by copying the source code examples/.../http/snoop. I run my server and when I hit it in the browser it works fine but it doesn't seem to work with the Apache benchmark tool. I try this to send it 10 requests: $ ab -n 10 http://localhost:8080/foo This is ApacheBench Version 2.3 <$Revision: 655654 $> Copyright 1996 Adam Twiss Zeus Technology Ltd http://www.zeustech.net/ Licensed to The Apache Software Foundation http://www.apache.org/ Benchmarking localhost (be patient)...apr_socket_recv: Connection reset by peer (54) Total of 7 requests completed In the handler there is code like this: public void messageReceived(ChannelHandlerContext ctx Object msg) throws Exception { if (msg instanceof HttpRequest) { HttpRequest request = this.request = (HttpRequest) msg; ... buf.append(""WELCOME TO THE WILD WILD WEB SERVER\r\n""); I added an integer count variable in there just to get a sense of what is getting called and after the AB runs the counter indicates that the buf.append(... line has run 1200 times. That doesn't seem right. Any ideas? Is something wrong? This sounds related to the ab bug [1] of IPv6 hosts. [1] http://simon.heimlicher.com/articles/2012/07/08/fix-apache-bench-ab-on-os-x-lion That's it thanks. A custom Java benchmark tool works fine."
561,A,"Netty - connectTimeoutMillis vs. ReadTimeoutHandler From the Netty API Documentation connectTimeoutMillis = ""the connect timeout in milliseconds. 0 if disabled."" And ReadTimeoutHandler = Raises a ReadTimeoutException when no data was read within a certain period of time. From a client perspective am I correct in interpreting the aforementioned as follows? The client will attempt to connect to the host for up to ""connectTimeoutMillis"". If a connection is established and a ReadTimeoutHandler is NOT added to the Pipeline a Channel can wait on a response indefinitely. If a ReadTimeoutHandler was added to the Pipeline a ReadTimeoutException will be raised once timeoutSeconds has elapsed. Generally speaking I'd like to only attempt to connect to a host for up to 'x' seconds but if a request was sent across the wire I'd like to wait up to 'y' seconds for the response. If it shapes/influences the answer the client is Netty but the server is not. Follow-up: Is timeoutSeconds on the ReadTimeoutHandler the timeout between successive bytes read or for the entire request/response? Example: If timeoutSeconds was 60 and a single byte (out of a total of 1024) was read every 59 seconds would the entire response be read successfully in 60416 seconds or would it fail because the total elapsed time exceeded 60 seconds? ReadTimeoutHandler doesn't understand the concept of a response. It only understands either a messageReceived event in Netty 3 or an inboundBufferUpdated event in Netty 4. Speaking from an NIO perspective the exact impact of this behaviour depends on where ReadTimeoutHandler is in your pipeline. (I've never used OIO so can't say if the behaviour is exactly the same). If ReadTimeoutHandler is below any frame decoder in your pipeline (ie closer to the network) then the behaviour you describe is correct - a single byte read will reset the timer and as you've identified could result in the response taking a long time to be read. If you were writing a server this could be exploited to form a denial of service attack at the cost of very little effort on behalf of the attacker. If ReadTimeoutHandler is above your frame decoder then it applies to your entire response. I think this is the behaviour you're looking for. Note that the ReadTimeoutHandler is also unaware of whether you have sent a request - it only cares whether data has been read from the socket. If your connection is persistent and you only want read timeouts to fire when a request has been sent you'll need to build a request / response aware timeout handler.  Yes you have correctly identified the difference between connect timeout and read timeout. Note that whatever any documentation may say to the contrary the default or zero connect timeout means about 60-70 seconds not infinity and you can only use the connect timeout parameter to reduce that default not increase it. Read timeout starts when you call read() and ends when it expires or data arrives. It is the maximum time that read() may block waiting for the first byte to arrive. It doesn't block a second time in a single invocation."
562,A,Applying thread pools in upstream channel handlers I'm coding a simple websocket server on netty. Before a client connection has been accepted the server must authenticate client(via another http server). The authentication request may take a several seconds. So I do the auth request in a separate thread. When client has connected to the server I submit a new auth task to the thread pool. The webscoket handshake operation will completed in the same thread just after the authetication. Is it correct applying of thread pools from netty server design? I read about ExecutionHandler but I haven't any more blocking tasks after successful authentication has been completed in my server. I think I would just use an ExecutionHandler and remove it from the ChannelPipeline once you not need it anymore. This should keep things simple .. Once the client disconnect the Channel and also the related ChannelPipeline get recycled.. Once the client connect again it will get a new ChannelPipeline with the ExecutionHandler added again Some clients can disconnect and connect later. So if I remove ExecutionHandler such clients will block main i/o loop.
563,A,Lightweight Java socket library I've used Mina and Netty but now I'm in the market for a lightweight library that may also be used in Android. I prefer Nio or AsyncIo over standard io implementations. Update 1 The lack of responses really makes me think I should write my own library. Right now I'm using raw NIO and its not a lot of fun. http://developer.android.com/reference/java/nio/package-summary.html ? @arunkumar raw nio is very hard to use definitely not simple really a royal PITA all around. That's why people put libraries like Mina on top of it. I agree i use mina quite often. I'm surprised that there's not more activity on this question; is everyone actually writing low-level Nio code? Since this seems to be dead on arrival I'll answer it by saying my custom IO library will be the best.  To answer your question there is no one size fits all async library. Netty and Mina might be the closest to such a thing but most projects may still have to contain some pure NIO/ASYNCIO customized solutions. I maintain you are on the right track. The more experience you have with low-level NIO/ASYNCIO the more you will appreciate and be able to get the most out of the somewhat-less-low-level Netty. Yeah dont get me wrong i love mina its an excellent library but I'm more or less looking for something closer to NIO without making you feel the pain.  You might try using some pieces from Jetty as suggested in this email. I really like Jetty because it's small self contained and you can use some or all of it flexibly. Is the socket library in Jetty externalized from the server itself?
564,A,"Looking for substitutes for some functionality while moving from Netty 3.x to 4.21 final In Netty 3.5 we use SimpleChannelHandler which provides method for both event types. How do I use the same approach in Netty 4.0.0? To be more specific i m looking for a substitute of the method below public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { } I am trying to send message to all clients connected to the server. Here is the example for netty 3.x ChannelGroup allConnected = new DefaultChannelGroup(""all-connected""); @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { super.channelConnected(ctx e); allConnected.add(e.getChannel()); } and then to send messages to all channels connected ChannelBuffer cb = ChannelBuffers.wrappedBuffer(""hello"".getBytes(Charset.forName(""UTF-8""))); allConnected.write(cb); This is what i need to do in Netty 4.21 final but i couldn't find a similar method which provided me the needed functionality. I'm not really sure what you mean by both event types. I guess you mean client and server? I use ChannelInboundHandlerAdapter for that: public class ServerCommunicationHandler extends ChannelInboundHandlerAdapter { private final ChannelGroup channels = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE); @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { channels.add(ctx.channel()); ctx.fireChannelActive(); } @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { broadcastMessage(msg); ctx.fireChannelRead(msg); } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { channels.remove(ctx.channel()); ctx.fireChannelInactive(); } public void broadcastMessage(Object object) { channels.writeAndFlush(object); } } how did you do call your `allConnected.write(cb);` in the old version? added a little example (`channelRead`). This will broadcast the message to all connected clients (including sender) as soon as a new message is received. sorry as i said that i am newbie so got confused. I have to write this to a websocket so will the same technique work just by replacing channels.writeAndFlush(object); with channel.writeAndFlush(new TextWebSocketFrame(object); and thanks for your help. maybe this example can help you. https://github.com/netty/netty/tree/master/example/src/main/java/io/netty/example/http/websocketx the changes I mentioned prior to your comment worked. Thanks a lot. I am quite new at netty so i might be wrong on this but in the above code snippet i couldn't understand that how would ""brodcastMessage()"" method be called."
565,A,"Jboss Netty - How to serve 2 connections using 3 worker threads Just as a simple example lets say I want to handle 3 simultaneous TCP client connections using only 2 worker threads in netty how would I do it? Questions A) With the code below my third connection doesn't get any data from the server - the connection just sits there. Notice - how my worker executor and worker count is 2. So if I have 2 worker threads and 3 connections shouldnt all three connections be served by the 2 threads? B) Another question is - Does netty use CompletionService of java.util.concurrent? It doesnt seem to use it. Also I didnt see any source code that does executor.submit or future.get So all this has added to the confusion of how it handles and serves data to connections that are MORE than its worker threads? C) I'm lost on how netty handles 10000+ simultaneous TCP connections....will it create 10000 threads? Thread per connection is not a scalable solution so I'm confused because how my test code doesnt work as expected.  import java.net.InetSocketAddress; import java.nio.channels.ClosedChannelException; import java.util.Date; import java.util.concurrent.Executors; import java.util.logging.Level; import java.util.logging.Logger; import org.jboss.netty.bootstrap.ServerBootstrap; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelFuture; import org.jboss.netty.channel.ChannelFutureListener; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.channel.ChannelStateEvent; import org.jboss.netty.channel.Channels; import org.jboss.netty.channel.ExceptionEvent; import org.jboss.netty.channel.SimpleChannelUpstreamHandler; import org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory; import org.jboss.netty.handler.codec.string.StringEncoder; public class SRNGServer { public static void main(String[] args) throws Exception { // Configure the server. ServerBootstrap bootstrap = new ServerBootstrap( new NioServerSocketChannelFactory( Executors.newCachedThreadPool() //Executors.newCachedThreadPool() Executors.newFixedThreadPool(2)2 )); // Configure the pipeline factory. bootstrap.setPipelineFactory(new SRNGServerPipelineFactoryP()); // Bind and start to accept incoming connections. bootstrap.bind(new InetSocketAddress(8080)); } private static class SRNGServerHandlerP extends SimpleChannelUpstreamHandler { private static final Logger logger = Logger.getLogger(SRNGServerHandlerP.class.getName()); @Override public void channelConnected( ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { // Send greeting for a new connection. Channel ch=e.getChannel(); System.out.printf(""channelConnected with channel=[%s]%n"" ch); ChannelFuture writeFuture=e.getChannel().write(""It is "" + new Date() + "" now.\r\n""); SRNGChannelFutureListener srngcfl=new SRNGChannelFutureListener(); System.out.printf(""Registered listener=[%s] for future=[%s]%n"" srngcfl writeFuture); writeFuture.addListener(srngcfl); } @Override public void exceptionCaught( ChannelHandlerContext ctx ExceptionEvent e) { logger.log( Level.WARNING ""Unexpected exception from downstream."" e.getCause()); if(e.getCause() instanceof ClosedChannelException){ logger.log(Level.INFO ""****** Connection closed by client - Closing Channel""); } e.getChannel().close(); } } private static class SRNGServerPipelineFactoryP implements ChannelPipelineFactory { public ChannelPipeline getPipeline() throws Exception { // Create a default pipeline implementation. ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""handler"" new SRNGServerHandlerP()); return pipeline; } } private static class SRNGChannelFutureListener implements ChannelFutureListener{ public void operationComplete(ChannelFuture future) throws InterruptedException{ Thread.sleep(1000*5); Channel ch=future.getChannel(); if(ch!=null && ch.isConnected()){ ChannelFuture writeFuture=ch.write(""It is "" + new Date() + "" now.\r\n""); //-- Add this instance as listener itself. writeFuture.addListener(this); } } } } I haven't analyzed your source code in detail so I don't know exactly why it doesn't work properly. But this line in SRNGChannelFutureListener looks suspicious: Thread.sleep(1000*5); This will make the thread that executes it be locked for 5 seconds; the thread will not be available to do any other processing during that time. Question C: No it will not create 10000 threads; the whole point of Netty is that it doesn't do that because that would indeed not scale very well. Instead it uses a limited number of threads from a thread pool generates events whenever something happens and runs event handlers on the threads in the pool. So threads and connections are decoupled from each other (there is not a thread for each connection). To make this mechanism work properly your event handlers should return as quickly as possible to make the threads that they run on available for running the next event handler as quickly as possible. If you make a thread sleep for 5 seconds then you're keeping the thread allocated so it won't be available for handling other events. Question B: If you really want to know you could get the source code to Netty and find out. It uses selectors and other java.nio classes for doing asynchronous I/O. It worked w/o sleep.Earlier I didnt test with separate NioServerSocketChannelFactory constructors.Read on .NioServerSocketChannelFactory has 2 constrs NioServerSocketChannelFactory(Executor bossExecutor Executor workerExecutor) AND NioServerSocketChannelFactory(Executor bossExecutor Executor workerExecutorint workerCount).My m/c has 2 procs so the default workCount=4.If I use the first constr workerExecutor=2 my workerExecutor is < workCount.In this situation any conns > 2 dont get any data.But if I use the 2nd constrwith workerExecutor=2 and workCount=2 now all my conns get data. @AmitAlka read up on Reactor pattern: http://en.wikipedia.org/wiki/Reactor_pattern"
566,A,"Simulate back pressure in TCP send I am writing some java TCP/IP networking code ( client - server ) in which I have to deal with scenarios where the sends are much faster than the receives  thus blocking the send operations at one end. ( because the send and recv buffers fill up ). In order to design my code  I wanted to first play around these kind of situations first and see how the client and servers behave under varying load. But I am not able to set the parameters appropriately for acheiving this back pressure. I tried setting Socket.setSendBufferSize(int size) and Socket.setReceiveBufferSize(int size) to small values - hoping that would fill up soon but I can see that send operation completes without waiting for the client to consume enough data already written. ( which means that the small send and recv buffer size has no effect ) Another approach I took is to use Netty  and set ServerBootstrap.setOption(""child.sendBufferSize"" 256); but even this is of not much use. Can anyone help me understand what I am doing wrong / I think Channel.setReadable is what you need. setReadable tell netty temporary pause to read data from system socket in buffer when the buffer is full the other end will have to wait.  The buffers have an OS dependent minimium size this is often around 8 KB. public static void main(String... args) throws IOException InterruptedException { ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.bind(new InetSocketAddress(0)); // open on a random port InetSocketAddress remote = new InetSocketAddress(""localhost"" ssc.socket().getLocalPort()); SocketChannel sc = SocketChannel.open(remote); configure(sc); SocketChannel accept = ssc.accept(); configure(accept); ByteBuffer bb = ByteBuffer.allocateDirect(16 * 1024 * 1024); // write as much as you can while (sc.write(bb) > 0) Thread.sleep(1); System.out.println(""The socket write wrote "" + bb.position() + "" bytes.""); } private static void configure(SocketChannel socketChannel) throws IOException { socketChannel.configureBlocking(false); socketChannel.socket().setSendBufferSize(8); socketChannel.socket().setReceiveBufferSize(8); } on my machine prints The socket write wrote 32768 bytes. This is the sum of the send and receive buffers but I suspect they are both 16 KB I checked with `Socket.getSendBufferSize()` ( also for Receive ) just before I start sending and receiving - it definitely says 256. Does it still mean that the actual buffer size is *not* 256 bytes ? I suspect not you should be able to test how large it actually is. Send data until you can't send any more. Old comment but I just wanted to chime in. It's no so much OS dependent as it is settings dependent for instance in many Linux distros(CentOS RHEL) the default average size for net.ipv4.tcp_wmem is 16kb which is what you are seeing here. Here is my out of the box CentOS 5 config: net.ipv4.tcp_wmem = 4096 16384 4194304 Setting the setSendBufferSize to less than the min(4096) will result in it using the average(16k). If you want really small buffers you will have to change this but usual caveat can break your system in unexpected ways blah blah blah. @user439407 You are right that it can be changed. From a Java point of view its not something you would change often. The default value and which values it can be usefully changed to depend on the OS."
567,A,How to send an object with Netty? How to send bean from server side and receive this bean in the client side by Netty? When I send simple integer message inputstream it works successfully but I need to send bean. If you are using netty at client and server side then you can use the Netty ObjectDecoder and ObjectEncoder in your ChannelPipeline to send and receive objects. Take a look at the netty ping pong example which does this. The code is bit out of date but you will get the general idea on working with objects. thank you. it worked.
568,A,"Architecture design recommendation using OMATPE for specific requests I have a typical netty server setup just a bit confused on the ""proper"" way to implement or rather add an OrderedMemoryAwareThreadPoolExecutor to a pipelinefactory for specific types of requests. For most requests the typical NIO request/response is fine. However for a specific type of request I'd like to use traditional threaded I/O (ala OMATPE) because of the potential for it being a long running request. What I'm doing now is parsing the URI to get the specific type of request. Short requests will be processed normally and requests of type ""/long/running/request"" I continue to send upstream which passes through an OMATPE which is then passed to an appropriate handler. Is this the way to go? The pipeline looks something like the following:  public ChannelPipeline getPipeline() { return Channels.pipeline( new HttpMessageEncoder() new HttpMessageDecoder() new shortLivedRequestHandler() executionHandler new longLivedRequestHandler()); } In the 'shortLivedRequestHandler' those URI's matching a ""short-lived"" regex will be processed and then sent downstream. If those URI's happend to match a ""long-lived"" regex then we pass upstream to the ""longLivedRequestHandler"" which will in theory process in a non-blocking I/O thread and send response downstream when done. You can try not using OMATPE and manually configuring and using your own ThreadPool. // Stored as a private field in your pipeline and passed into the constructor of your handler Executor executor = Executors.newFixedThreadPool(16); // In your handler public class MyRequestHandler extends SimpleChannelUpstreamHandler { private Executor _executor = null; public MyRequestHandler (Executor executor) { _executor = executor; } public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { if (requestThatUseThreadPool) { _executor.execute(new Runnable() { @Override public void run() { // Do some work in another thread HttpResponse res = new DefaultHttpResponse(HTTP_1_1 OK); res.setContent(ChannelBuffers.copiedBuffer(""hello"".toString() UTF_8_CHARSET)); ChannelFuture f = ctx.getChannel().write(res); } }); } else { // Do some work in this thread HttpResponse res = new DefaultHttpResponse(HTTP_1_1 OK); res.setContent(ChannelBuffers.copiedBuffer(""hello"".toString() UTF_8_CHARSET)); ChannelFuture f = ctx.getChannel().write(res); } } } Hope this helps. The only problem with this unless I amassing something is that each of my request handlers needs to return something specific. More than just a 200 is required. Basically the result of the computation in those requests/handlers is returned in some form. Whereas I believe your solution would be assuming a generic response to the client. No. You can just write your results into the channel. I have amended the example above to help you. Yes. I believe it is doing a similar thing and have seen several other open source project use similar techniques (e.g. webbit web server). Note that your requests may not be processed in an ordered manner as guaranteed by OMATPE. If you do require ordered request processing try customizing the Execution Handler as suggested by Norman in the next answer. That's interesting ... Is this then essentially doIng the same thing as I listed above only without the netty ""overhead""?  An other solution would be to add a custom ExecutionHandler Something like this: public class AdvancedExecutionHandler extends ExecutionHandler{ public AdvancedExecutionHandler(Executor executor) { super(executor); } @Override public void handleUpstream(ChannelHandlerContext context ChannelEvent e) throws Exception { if (useExecutionHandler(e)) { super.handleUpstream(context e); } else { // use no thread-pool context.sendUpstream(e); } } private boolean useExecutionHandler(ChannelEvent event) { // Add some logic here.... return true; } }"
569,A,"Get username specified in URL from NettyRequest I have a Netty HTTP server and am getting in requests that look like so: https://someuser%40abc.com@server99.route1.abc.com/rest/of/path.xml And waaay down in my handler I have a DefaultHttpRequest object. Is there any way to get the 'someuser%40abc.com' from the URL? Do I have to hack something up to get it earlier and pass it down? Shit. You're right. I look at the client logs and it shows that URL but snoop says that it's not going across the wire :/. Add an answer and I'll accept it. does HTTP support this kind of URI Scheme? http://en.wikipedia.org/wiki/URI_scheme says that HTTP supports generic syntax of URI Scheme which you have given. When I connect to http://someuser@localhost:8080/rest/path using a browser/ wget username part does not appear in Wireshark captured HTTP request. Interesting side note: Curl will add an authorization header if you include both the username and password in the url but will completely discard it if you just use the username. Safari strips it off and throws it away as does my client when it opens the http connection :/ If you want the points you need to add an answer! Thanks @Kylar I am glad that my comment helped to find the issue I was not sure about the wired URI scheme in common and wondering it could be used with some other http services. Now posted :) Since the 'user' part was missing in DefaultHttpRequest in Netty I did try to debug the Nety HttpDecoder using sample Netty Snoop server :). When I connect to http://someuser@localhost:8080/rest/path using Chrome/ wget the HttpDecoder didn't receive someuser part as a header to decode so I checked further by taking a Wireshark captured HTTP request and that also didn't have someuser part as a header. The reason is HTTP clients support generic syntax of URI Scheme mostly and they strip of user part and does not include as headers most of the time.(check Nadeem Douba's answer for more details). If http client can send these parameters as user managed headers they can be accessed using request.getHeader(""X-user-header"").  Do you mean to ask how to get the URL from messageReceived()? public void messageReceived(final ChannelHandlerContext ctx final MessageEvent e) throws Exception { Object msg = e.getMessage(); if (msg instanceof HttpRequest) { // New request so let's figure our the service to call HttpRequest request = (HttpRequest) msg; String uri = request.getUri(); // Use some string functions to extract what you want for the URI String username = uri.substring(0 uri.indexOf(""@"")).substring(8); } } Sorry that doesn't work. My msg is of the type DefaultHttpRequest and getUri() returns just the uri portion: /rest/of/path. To get the domain name try getting the ""Host"" http header. Something like `request.getHeader(""Host"")` Yeah... I tried that too. It gets stripped off the host header. Stop guessing.  As Jestan Nirojan mentioned earlier the URI scheme is only supported by the client. The HTTP server will never get a request for http://user@host. Also when using authentication credentials in the URI scheme the client will only transmit these credentials if it is challenged for them. To clarify the first request will try to get the page without the user credentials if the server requires them it will challenge the client finally the client will repeat the request with the credentials. Otherwise if the client is not challenged the page will be served and no credentials will be transmitted as a result."
570,A,Netty 4.0 Channel Local I am using Netty 4(alpha8). I want to share some data between ChannelHanders in a pipeline in previous versions of Netty I think I would have used a ChannelLocal is there a Netty 4 equivalent? Found the answer shortly after I posted my question. I need to use the attribute map available on the Channel: http://netty.io/wiki/new-and-noteworthy.html
571,A,netty websockets hornetq 2.2.5 fails with latest chrome on Sec-WebSocket-Accept header I am trying to run the netty stomp websockets example in the hornetq 2.2.5 distribution but it does not work with Chrome latest version. Chrome shows the following error in the javascript console - Error during WebSocket handshake: 'Sec-WebSocket-Accept' header is missing Reading on forums seems to suggest that this is related to Netty itself. I understand that chrome is too fast to adapt to the changing websockets protocol so its complaining about a header not being returned from the server.Netty version with the hornetq distro seems to be 3.2.3. If this related to Netty only? Can this be fixed by using a later version of Netty with the same distibution of hornetq? I'm no expert of hornetq but you may want to try upgrade to netty-3.3.1.Final and see if it helps did try that.. by replacing the jar. No change. It seems hornetq has a websockethandler which is still on the older version of the protocol [link]http://grepcode.com/file/repository.jboss.org/nexus/content/repositories/releases/org.hornetq/hornetq-core/2.2.9.AS7.Final/org/hornetq/core/protocol/stomp/WebSocketServerHandler.java?av=f I think HornetQ is using the older netty websocket package. To support chrome HornetQ needs to use the new websocketx package. Both the websocket and websocketx package will be supplied in Netty v3.X for backwards compatibility. Some people have extended the websocket package and have written their own code to support newer versions of the websocket protocol. In Netty v4 the websocket package has been droped. thanks for the confirmation
572,A,"Configuring IHS server to direct traffic to the Netty component bound to a port I have a Server Component ( based on Jboss-Netty which could maintain & handle persistent connections ) deployed in WAS. This component when deployed & initiated within the WAS environment binds to a port & listens for incoming HTTP connection. [ Why i had to deploy a Netty HTTP Server within WAS is another story - management requirement !! Netty is deployed in WAS as a spring bean which when initiated runs on a port in the machine independent of WAS ] Clients (mobile app) were able to establish persistent HTTP connections (to the above URL::Port) with this netty component & send/receive requests. Now I have to replicate this feature in our Production Environment where a IHS Server (Web Server) which sits before the WAS. What i expected is to get a IHS URL which could redirect the incoming packets to the specific PORT on WAS so that the Client apps can establish a similar persistent http connection. Our Server Admin tried a few combinations and we are not able to identify how to proceed further on this. Your expert ideas would be highly appreciated. What isn't working? As far as I can tell you're saying that the Netty server takes over some port that is not the one used by WAS correct? So as long as that port isn't one being listened to by IHS I wouldn't think anything is different. My http requests have to go through IHS which would then redirect it to the Port where netty is running. Admin team over here are yet to find a way to do this :| You did not specify what ""combinations"" your administrator attempted but from what you describe what you need to do is set up a reverse proxy. IHS is basically Apache HTTP server so you can use the following for reference: http://httpd.apache.org/docs/current/mod/mod_proxy.html Apologies i wasn't made aware of what Admin is trying. I would ask them try the above. Thanks"
573,A,"How can I use Lift asychronously with Nginx? I want to use Nginx as a frontend redirecting requests to Lift application. In this post http://scala-programming-language.1934581.n4.nabble.com/Simple-deployment-of-Lift-apps-on-Jetty-Nginx-td1980295.html David Polak recommends to use nginx as a reverse proxy. But in book ""Nginx HTTP Server by Nedelcu C"" I read this:""...the reverse proxy mechanism that we are going to describe in this chapter is not the optimal solution. It should be employed in problematic cases..."" and FastCGI is described as the best choice. Next option I see is to use Lift with Netty as here: https://github.com/jrwest/lift-and-netty-examples but it seems it just an expirement for now. Maybe I am missing something? I am a big fan of Nginx (make sure of that looking at my SO/SF profiles) and my opinion is that Nginx is a perfect fit for many-many uses. Nginx can be used as a frontend to Lift application via HTTP transport (i.e. proxy_pass directive in Nginx) just like Nginx is used to proxy to Apache Jetty Tomcat or any other backend server talking HTTP. fastcgi_pass is designed to proxy to FastCGI backends. I did not see any benchmarks on which transport implementation is more effective but I guess this difference will be smaller than differences implied by programming language/app server technologies. One more note. I have no idea how FastCGI transport can be used to implement Comet applications. At the same time Liftweb's Comet applications work perfectly via Nginx."
574,A,deserialize various objects in netty I am using standard ObjectDecoder and ObjectEncoder from netty framework. Is it safe to serialized deserialize objects of various types via only one instance of concrete ObjectDecoder ObjectDecoder? Why the default ObjectDecoder constructor is depracated? Suitable version of constructor has got ClassReslover as a argument. Does ClassResolver constructor imply that only one type of objects can be de/serialized by these concrete (ObjectDecoder ObjectEncoder) objects and to de/serialize another i have to switch these(ObjectDecoder ObjectDecoder) Objects in ChannelPipeline? I am writing server which should response on various type of request and i wanna implement by this way. May be one standard message class with TYPE_REQUEST field will be better? Is it safe to serialized deserialize objects of various types via only one instance of concrete ObjectDecoder ObjectDecoder? Yes. The ObjectDecoder doesn't generally have state (other than the class loader which likely won't change) - it creates anything else it needs when you call decode(). The classloader is also optional - you can pass null and it'll use whatever class loader (in my case the default one) is in context when you go to decode. Why the default ObjectDecoder constructor is depracated? I'm not sure about this. I'm using Netty 3.2.4 and it's not deprecated. Version info is: * @version $Rev: 2279 $ $Date: 2010-05-13 23:13:07 +0900 (Thu 13 May 2010) $ If you're using a more recent version look in the javadoc it should tell you. Suitable version of constructor has got ClassReslover as a argument. Does ClassResolver constructor imply that only one type of objects can be de/serialized by these concrete (ObjectDecoder ObjectEncoder) objects and to de/serialize another i have to switch these(ObjectDecoder ObjectDecoder) Objects in ChannelPipeline? Not at all. The ClassLoader arg is if you have some custom classloader that is needed because the default one is inadequate. You can serialize/deserialize anything with one ObjectDecoder as long as you use the appropriate ObjectEncoder on the other side. Thank you for all. There is nothing in netty-3.2.7 javadoc about why default ObjectDecoder constructor is depracated but it isn't vital anymore.
575,A,"Get OOM exception when sending message with a high speed with netty I write a client with netty in order to send message at a high rate. By jConsole I see ""old gen"" is increasing and finally it throws java.lang.OutOfMemoryError: GC overhead limit exceeded. Are there some ways or configuration to avoid this exception The following is my test code:  import io.netty.bootstrap.Bootstrap; import io.netty.channel.Channel; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.ChannelPipeline; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.string.StringEncoder; import java.io.IOException; import java.net.UnknownHostException; import java.util.concurrent.ExecutionException; import java.util.concurrent.TimeoutException; public class TestNettyTcp { private EventLoopGroup group; private Channel ch; /** * @param args * @throws SyslogSenderException * @throws TimeoutException * @throws ExecutionException * @throws IOException * @throws InterruptedException * @throws UnknownHostException */ public static void main( String[] args ) throws UnknownHostException InterruptedException IOException ExecutionException TimeoutException { new TestNettyTcp().testSendMessage(); } public TestNettyTcp() throws InterruptedException { group = new NioEventLoopGroup(); Bootstrap b = new Bootstrap(); b.group( group ).channel( NioSocketChannel.class ) // .option( ChannelOption.WRITE_BUFFER_HIGH_WATER_MARK 10 * 64 * 1024 ) .option( ChannelOption.SO_RCVBUF 1048576 ).option( ChannelOption.SO_SNDBUF 1048576 ) .option( ChannelOption.TCP_NODELAY true ).handler( new NettyTcpSyslogSenderInitializer() ); // Connect to a server. ChannelFuture future = b.connect( ""192.168.22.70"" 514 ); future.awaitUninterruptibly(); // Now we are sure the future is completed. assert future.isDone(); if ( !future.isSuccess() ) { future.cause().printStackTrace(); } else { ch = future.sync().channel(); } } public void testSendMessage() throws InterruptedException UnknownHostException IOException ExecutionException TimeoutException { ThreadGroup threadGroup = new ThreadGroup( ""SendMessage"" ); for ( int k = 0; k < 10; k++ ) { Thread thread = new Thread( threadGroup new Runnable() { @Override public void run() { String payLoad = ""key=\""value\"" key2=\""value2\"" key3=\""value3\"" Count:""; try { for ( int j = 0; j < 100; j++ ) { long a = System.currentTimeMillis(); for ( int i = 0; i < 20000; i++ ) { ch.writeAndFlush( payLoad + j + ""_"" + i + ""\n"" ); } System.out.println( ""\r<br>Excuted time : "" + ( System.currentTimeMillis() - a ) / 1000f + ""seconde"" ); } } catch ( InterruptedException e ) { e.printStackTrace(); } finally { if ( ch != null ) { ch.close(); } } } } ); thread.start(); } while ( threadGroup.activeCount() > 0 ) { try { Thread.sleep( 1000 ); } catch ( InterruptedException e ) { e.printStackTrace(); } } } } class NettyTcpSyslogSenderInitializer extends ChannelInitializer<SocketChannel> { public NettyTcpSyslogSenderInitializer() { super(); } @Override public void initChannel( SocketChannel ch ) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast( new StringEncoder() ); } } The code can reproduce the problem quickly You are writing faster then the network stack can handle. Be aware it's all asynchronous... You want to stop writing once Channel.isWritable() returns false and resume once it returns true again. You can notified for this changes by override the channelWritabilityChanged(...) method in ChannelInboundHandler."
576,A,Block Computer Permanently Networking I want to block a user from my game server; what would be a guaranteed way in which most people don't know to change? IP Addresses can be easily changed and MAC Addresses can be spoofed. This is being done in Java. There is no way to block an individual person. You can block login IDs and IP addresses but as you already know that won't prevent an individual from using a different login or a computer on a different IP. Plus if the user is connecting from behind a NAT firewall you will be blocking ALL users coming from behind that firewall. You could set up a registration system that involved you personally verifying every user's identity (not sure how you'd accomplish that with anything close to 100% accuracy) but that would just put obstacles in the way of your legitimate users. You can't win this battle. Despite its flaws I would still go with blocking an IP and blocking an account because: (1) It would indeed make it expensive for offending players (most people don't know how to change their IP or spoof packets). (2) Partially effective is better than nothing. (3) The firewall issue is certainly true but the nature of vandalism is that people who are blameless always end up paying for it somehow. No you can't win it. But you can make it expensive for the bad player.
577,A,"Netty - How to combine ChunkedWriteHandler with HttpContentCompressor I'm trying to implement an HTTP-Server (using Netty) that not only serves ""regular"" html-pages but also large files. Thus I want to use the ChunkedWriteHandler as well as the HttpContentCompressor within my pipeline. Currently this pipeline is initialized as follows: pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""aggregator"" new HttpObjectAggregator(1048576)); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""chunkedWriter"" new ChunkedWriteHandler()); pipeline.addLast(""deflater"" new HttpContentCompressor()); pipeline.addLast(new NettyHandler()); The NettyHandler follows this scheme: @Override public void channelRead(final ChannelHandlerContext context final Object message) throws Exception { try { if (message instanceof HttpRequest) { final HttpRequest request = (HttpRequest) message; final HttpContext httpContext = new HttpContext(request context); final ChannelFuture future = handleHttpMessage(httpContext); httpContext.closeOn(future); } } finally { ReferenceCountUtil.release(message); } } private ChannelFuture handleHttpMessage(final HttpContext context) { //writing to the wire via ChannelHandlerContext.write(...) return context.getChannelContext().writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT); } If I request/send small files (my test files are about 500 Bytes) everything works fine. But as soon as the requested files get big (my test files about 350 MB) the Browsers (in tested with chrome and firefox) report Problems concerning the encoded parts of the received body. chrome says ERR_CONTENT_DECODING_FAILED firefox says something like source file could not be read. Am I doing something fundamentally wrong? Do I have to manipulate the pipeline on-the-fly? Thanks in advance for any help here! The answer above is completely correct. However as the link seems to be dead here is another approach: Instead of sending a ChunkedInput of type ByteBuf downstream wrap it with an adapter to ChunkedInput of type HttpContent. This is quite trivial: Implementation: https://github.com/scireum/sirius/blob/develop/web/src/sirius/web/http/ChunkedInputAdapter.java I wrote a short blog post explaining the solution a bit more in depth: http://andreas.haufler.info/2014/01/making-http-content-compression-work-in.html  You will need to wrap the written chunks into DefaultHttpContent as the HttpContentCompressor does not understand ByteBuf instances. So just place a special HttpContentCompressor into the ChannelPipeline which knows howto handle ByteBuf instances. Something like this: https://github.com/eclipse/vert.x/blob/compress/vertx-core/src/main/java/org/vertx/java/core/http/impl/HttpChunkContentCompressor.java Be sure you place it before the ChunkedWriteHandler."
578,A,"Netty SSL / TLS / HTTPS support Adding support for encryption over netty channels using SSL. Need some references and example codes. Doc http://docs.jboss.org/netty/3.2/guide/pdf/netty.pdf only refers that its possible using SSLHandler. StackOverflow is not the Netty bug tracker. @Deejay what Netty bug? Will this do. The other answer is better. It links to the whole example not a single file. @MartinKonicek: it's a non-question with 2 non-answers anyway according to StackOverflow rules that is :P  Refer the secure chat[1] example in the ""examples""[2] section of netty."
579,A,"netty reuse channels i want to create a connection pool that reuse channels but i couldn't figure out executing this test public void test() { ClientBootstrap client = new ClientBootstrap(new NioClientSocketChannelFactory(Executors.newCachedThreadPool() Executors.newCachedThreadPool())); client.setPipelineFactory(new ClientPipelineFactory()); // Connect to server wait till connection is established get channel to write to Channel channel = client.connect(new InetSocketAddress(""192.168.252.152"" 8080)).awaitUninterruptibly().getChannel(); { // Writing request to channel and wait till channel is closed from server HttpRequest request = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.POST ""test""); String xml = ""xml document here""; ChannelBuffer buffer = ChannelBuffers.copiedBuffer(msgXml Charset.defaultCharset()); request.addHeader(HttpHeaders.Names.CONTENT_LENGTH buffer.readableBytes()); request.addHeader(HttpHeaders.Names.CONTENT_TYPE ""application/xml""); request.setContent(buffer); channel.write(request).awaitUninterruptibly().getChannel().getCloseFuture().awaitUninterruptibly(); channel.write(request).awaitUninterruptibly().getChannel().getCloseFuture().awaitUninterruptibly(); } client.releaseExternalResources(); } I got an ClosedChannelException in the second channel.write(request).... Exist a way to reuse the channels? or remain the channel open? thanks in advance The reason the second write failed is because the server closed the connection. The reason the server closed the connection is because you failed to add the HTTP header Connection: Keep-Alive to the original request. This is required in order to leave the channel open (which is what you want to do in this scenario). Once a channel has been closed you must create a new channel. You cannot reopen the channel. The ChannelFuture returned by Channel.getCloseFuture() is final (i.e. constant) to the channel and once isDone() on this future returns true it cannot be reset. This is the reason that a closed channel cannot be reused. However you may reuse an open channel as many times as you need; but your application must talk the HTTP protocol properly in order to accomplish this."
580,A,"Netty Different Pipeline Per UDP Datagram We've got a server which is already implemented in TCP/IP but we now have a requirement for the protocol to support UDP as well. Each UDP datagram sent contains everything I need to decode so it is a very simple reply and response system with data in the datagram separated by line breaks. The code for the bootstrap when the server is started is shown below:  //SETUP UDP SERVER DatagramChannelFactory udpFactory = new NioDatagramChannelFactory(Executors.newCachedThreadPool()); ConnectionlessBootstrap udpBootstrap = new ConnectionlessBootstrap(udpFactory); udpBootstrap.setOption(""sendBufferSize"" 65536); udpBootstrap.setOption(""receiveBufferSize"" 65536); udpBootstrap.setOption(""receiveBufferSizePredictorFactory"" new AdaptiveReceiveBufferSizePredictorFactory()); udpBootstrap.setOption(""broadcast"" ""true""); udpBootstrap.setPipelineFactory(new ServerPipeLineFactoryUDP()); udpBootstrap.bind(new InetSocketAddress(hostIp 4000)); The Pipeline code is: class ServerPipeLineFactoryUDP implements ChannelPipelineFactory { private final static ExecutionHandler EXECUTION_HANDLER = new ExecutionHandler(new OrderedMemoryAwareThreadPoolExecutor(ScorpionFMS.THREAD_POOL_COUNT 0 0)); public ServerPipeLineFactoryUDP() { } @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = pipeline(); pipeline.addLast(""debugup"" new DebugUpstreamHandler(""UDP"")); pipeline.addLast(""debugdown"" new DebugDownstreamHandler(""UDP"")); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(256 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new UDPRequestDecoder(true)); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""executor"" EXECUTION_HANDLER); pipeline.addLast(""handler"" new UDPRequestHandler( return pipeline; } } The problem im having is each datagram is using the same instance of this pipeline (i hoped each datagram would use a new instance of the pipeline) so all the state i store while processing the contents of a datagram is saved and the next datagram uses it as well( whereas for TCP each connection would have its own channel and therefore its own instance of the pipeline and its own state) I know this is the expected behaviour from reading the documentation but is there anyway to force netty to recreate the pipeline for each datagram? Or am i going about this the completely wrong way? To put it succinctly i want each datagram to have a new instance of the pipeline (the same as tcp) Why do you *store state* in your handlers? Do you need the concept of a connection for your kind of messaging? First it seems like you don't need it but later you seem to change your mind (why would you store it  if you don't need it) . . . Like I said in IRC I think that could do what you want or at least give you some idea. public class Example { public static void main(String[] args) { final ChannelPipelineHandlerImpl perDatagramFactory = new ChannelPipelineHandlerImpl(); DatagramChannelFactory udpFactory = new NioDatagramChannelFactory(Executors.newCachedThreadPool()); ConnectionlessBootstrap udpBootstrap = new ConnectionlessBootstrap(udpFactory); udpBootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline(new DistinctChannelPipelineHandler(perDatagramFactory)); } }); } private static final class DistinctChannelPipelineHandler implements ChannelDownstreamHandler ChannelUpstreamHandler { private ChannelPipelineFactory factory; public DistinctChannelPipelineHandler(ChannelPipelineFactory factory) { this.factory = factory; } public void handleUpstream(ChannelHandlerContext ctx ChannelEvent e) throws Exception { ChannelPipeline pipeline = factory.getPipeline(); pipeline.attach(ctx.getChannel() ctx.getPipeline().getSink()); pipeline.sendUpstream(e); ctx.sendUpstream(e); } public void handleDownstream(ChannelHandlerContext ctx ChannelEvent e) throws Exception { ChannelPipeline pipeline = factory.getPipeline(); pipeline.attach(ctx.getChannel() ctx.getPipeline().getSink()); pipeline.sendDownstream(e); ctx.sendDownstream(e); } } private static final class ChannelPipelineHandlerImpl implements ChannelPipelineFactory { public ChannelPipeline getPipeline() throws Exception { // Add your handlers here return Channels.pipeline(); } } } Cool.. thanks for the feedback! With a few changes it was exactly what i needed. thanks again! Got TCP/IP and UDP running alongside perfectly now. @NormanMaurer Is there a similar example for this in Netty 4? Found it very helpful!  I'm not sure about how the UDP channels are handled but if the channels are distinct per datagram you could store your state in ChannelLocals. unfortunately the problem is the channels aren't distinct per datagram thats what i'm trying to achieve."
581,A,"Netty HttpChunckAggregator stateful --> race conditions? Maybe this is a obvious ask but I'm too new with netty. Taking a look to HttpChunckAggregator class I see that it's stateful. That make me doubt... given a specific Channel with the following pipeline: private MyServerHandler handler; public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = pipeline(); pipeline.addLast(""decoder""new HttpRequestDecoder()); pipeline.addLast(""chunkAggregator""new HttpChunkAggregator(4194304)); pipeline.addLast(""encoder""new HttpResponseEncoder()); pipeline.addLast(""chunkSeparator""new HttpChunkSeparator(4194304)); pipeline.addLast(""handler"" handler); //Singleton return pipeline; } and an NIO Netty server could I get race conditions in case of chunked message and multi-threading? I see that every new channel creates a new chunk Aggregator but... all the chunk messages will be received in the same channel? Its safe as its not shared by different Channels. In netty only one thread is executing upstream events so its safe to store states in fields without any synchronization as long as these are not accessed/modified from a downstream event.  The getPipeline is called for each incoming message. So for each HttpRequest you will be creating a new HttpChunkSeparator. If however you had done something like this it would be totally thread UNSAFE. private MyServerHandler handler; // THIS IS WRONG AS getPipeline() will keep giving the same instance to multiple threads. private HttpChunkAggregator httpChunkAggregator; public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = pipeline(); pipeline.addLast(""decoder""new HttpRequestDecoder()); // This is WRONG. DO NO DO THIS. INSTEAD DO new HttpChunkAggregator(). pipeline.addLast(""chunkAggregator""httpChunkAggregator); pipeline.addLast(""encoder""new HttpResponseEncoder()); pipeline.addLast(""chunkSeparator""new HttpChunkSeparator(4194304)); pipeline.addLast(""handler"" handler); //Singleton return pipeline; } Arun"
582,A,"image corrupted by FileUpload I need to make a HTTP server for recieving and sending images and text(less than 100 characters) to the client. I am planning to use JSON or Google Protocol Buffer. I studied the ""HttpUploadServer"" example in the Netty 4.0.6 package. Then I deleted everything in the handler except things dealing with multipart POST requests. Here's the part where I am struggling with. private void writeHttpData(InterfaceHttpData data) { FileUpload fileUpload = (FileUpload)data; try { File file = fileUpload.getFile(); file.renameTo(new File(""C:\\savedFiles\\""+file.getName())); } catch (IOException e) { e.printStackTrace(); } } When I call getFile() it gives me a corrupted file. I've tested it with zip files and images(png jpeg). (BTW. I am using Postman add-on to test the server so wrong headers are not my problem) Is there a way to make this right? sorry for the inappropriate word in the code... I didn't check them before putting online... Found an answer on Github Change private static final HttpDataFactory factory = new DefaultHttpDataFactory(DefaultHttpDataFactory.MINSIZE); to private static final HttpDataFactory factory = new DefaultHttpDataFactory(false); or private static final HttpDataFactory factory = new DefaultHttpDataFactory(true); for me setting it true worked!"
583,A,"Netty: Closing WebSockets correctly How can I close a WebSocket channel/connection from server side correctly? If I use a ctx.getChannel().close() the onerror in the Brwoser (Firefox 9) is thrown: The connection to ws://localhost:8080/websocket was interrupted while the page was loading I also tried to send a CloseWebSocketFrame within the channelClosed-method in the WebSocketServerHandler: public void channelClosed(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { CloseWebSocketFrame close = new CloseWebSocketFrame(); ctx.getChannel().write(close); } This throws an ClosedChannelException (maybe related to this?). How about ctx.getChannel().write(new CloseWebSocketFrame()).addListener(ChannelFutureListener.CLOSE); That should send the CloseWebSocketFrame and then close the channel after that.  You have to do this: ch.write(new CloseWebSocketFrame()); then the server will close the connection. If the connection is not closed soon enough you can call ch.close(). After the WebSocket connection is established my pipe looks like this:`[wsdecoder wsencoder webSocketHandler myDecoder myEncoder app]`. So the WebSocketHandler forwards the data to the decoder until it reaches the app. The problem is that the `app` doesn't know anything about how it's used. So it doesn't know that there is a WebSocketHandler in the pipe at all. Like this the `app` can be used in other pipes with non-WebSocket-connections as well. Even if I write the `CloseWebSocketFrame` in the app to the `channel` it will be encoded until it reaches the `WebSocketServerHandler` I just tested something: Is it right that a `ch.write(...)` at any layer of the pipe goes through the whole pipe (from the last to the first handler)? I expected that it's just going back from the layer where we do the `ch.write(...)` Because of the last behaviour I introduced a `ChannelClosing` class. I am writing an instance of this on the channel: `ch.write(new ChannelClosing());`. If I find this in my decoder (which converts my application data to WebSockets) I am switching to the `CloseWebSocketFrame`. It works.  What version are you using ? Have you tried todo this: ctx.getChannel().write(ChannelBuffers.EMPTY_BUFFER).addListener(ChannelFutureListener.CLOSE); ? Nope. Still the `ClosedChannelException`. The constructor of the `CloseWebSocketFrame` contains `ChannelBuffers.EMPTY_BUFFER`. I guess I need to use the `CloseWebSocketFrame`. The RFC 6455 (http://tools.ietf.org/html/rfc6455#section-7.4.1) defines: *1001 indicates that an endpoint is ""going away"" such as a server going down or a browser having navigated away from a page.* This is what I want to use. Version: I am using my branch (https://github.com/boldt/netty). Since Netty is modularized I can't compile it any more. For other coming here over google like me: I was playing arround with http channels for me that was the exact solution."
584,A,"Java (Netty) SSL Server/Client with self-signed certificates throws fatal error: 80: pr0blem unwrapping net record I seem not to be able to grasp they way SSL is working... or ar least I'm not able to interpret the ssl debugging output of java so here's what I (plan to) do: Client and Server generate their own keypair and self-signed certificate. (I only need to ensure the identity upon reconnection.) For testing I use the same key- and truststure (with only one key and certificate) on both the server and the client. Something goes wrong during the handshake but I don't understand the error message. Read about 20 forums and so posts about this but could not figure it out so far. So can anybody tell me what this message at the bottom exactly means please? If you need more details please let me know. Thanks! Server SSL debug trigger seeding of SecureRandom done seeding SecureRandom Using SSLEngineImpl. Ignoring unavailable cipher suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_ECDH_RSA_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_DHE_DSS_WITH_AES_256_CBC_SHA256 Ignoring unavailable cipher suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 Ignoring unavailable cipher suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 Ignoring unavailable cipher suite: TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA384 Ignoring unavailable cipher suite: TLS_RSA_WITH_AES_256_CBC_SHA256 Ignoring unavailable cipher suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 Ignoring unavailable cipher suite: TLS_DHE_DSS_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_ECDH_RSA_WITH_AES_256_CBC_SHA384 Ignoring unavailable cipher suite: TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_RSA_WITH_AES_256_CBC_SHA EndpointIdentificationAlgorithm: null Allow unsafe renegotiation: false Allow legacy hello messages: true Is initial handshake: true Is secure renegotiation: false [Raw read]: length = 5 0000: 16 03 01 00 95 ..... [Raw read]: length = 149 0000: 01 00 00 91 03 01 51 0F F6 C7 F3 99 F4 4B 77 A8 ......Q......Kw. 0010: 43 BB A0 89 E0 D9 20 4D 9F 5A C2 E2 0E 80 87 9F C..... M.Z...... 0020: 59 9A 13 71 F7 4F 00 00 2A 00 33 C0 04 00 16 00 Y..q.O..*.3..... 0030: 05 C0 03 C0 11 C0 02 C0 07 C0 13 C0 08 C0 0C 00 ................ 0040: FF C0 0D C0 0E C0 09 00 2F C0 12 00 04 00 32 00 ......../.....2. 0050: 13 00 0A 01 00 00 3E 00 0A 00 34 00 32 00 17 00 ......>...4.2... 0060: 01 00 03 00 13 00 15 00 06 00 07 00 09 00 0A 00 ................ 0070: 18 00 0B 00 0C 00 19 00 0D 00 0E 00 0F 00 10 00 ................ 0080: 11 00 02 00 12 00 04 00 05 00 14 00 08 00 16 00 ................ 0090: 0B 00 02 01 00 ..... New I/O worker #1 READ: TLSv1 Handshake length = 149 *** ClientHello TLSv1 RandomCookie: GMT: 1359934919 bytes = { 243 153 244 75 119 168 67 187 160 137 224 217 32 77 159 90 194 226 14 128 135 159 89 154 19 113 247 79 } Session ID: {} Cipher Suites: [TLS_DHE_RSA_WITH_AES_128_CBC_SHA TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA SSL_RSA_WITH_RC4_128_SHA TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA TLS_ECDHE_RSA_WITH_RC4_128_SHA TLS_ECDH_ECDSA_WITH_RC4_128_SHA TLS_ECDHE_ECDSA_WITH_RC4_128_SHA TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA TLS_ECDH_RSA_WITH_RC4_128_SHA TLS_EMPTY_RENEGOTIATION_INFO_SCSV TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA TLS_ECDH_RSA_WITH_AES_128_CBC_SHA TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA TLS_RSA_WITH_AES_128_CBC_SHA TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA SSL_RSA_WITH_RC4_128_MD5 TLS_DHE_DSS_WITH_AES_128_CBC_SHA SSL_DHE_DSS_WITH_3DES_EDE_CBC_SHA SSL_RSA_WITH_3DES_EDE_CBC_SHA] Compression Methods: { 0 } Extension elliptic_curves curve names: {secp256r1 sect163k1 sect163r2 secp192r1 secp224r1 sect233k1 sect233r1 sect283k1 sect283r1 secp384r1 sect409k1 sect409r1 secp521r1 sect571k1 sect571r1 secp160k1 secp160r1 secp160r2 sect163r1 secp192k1 sect193r1 sect193r2 secp224k1 sect239k1 secp256k1} Extension ec_point_formats formats: [uncompressed] *** [read] MD5 and SHA1 hashes: len = 149 0000: 01 00 00 91 03 01 51 0F F6 C7 F3 99 F4 4B 77 A8 ......Q......Kw. 0010: 43 BB A0 89 E0 D9 20 4D 9F 5A C2 E2 0E 80 87 9F C..... M.Z...... 0020: 59 9A 13 71 F7 4F 00 00 2A 00 33 C0 04 00 16 00 Y..q.O..*.3..... 0030: 05 C0 03 C0 11 C0 02 C0 07 C0 13 C0 08 C0 0C 00 ................ 0040: FF C0 0D C0 0E C0 09 00 2F C0 12 00 04 00 32 00 ......../.....2. 0050: 13 00 0A 01 00 00 3E 00 0A 00 34 00 32 00 17 00 ......>...4.2... 0060: 01 00 03 00 13 00 15 00 06 00 07 00 09 00 0A 00 ................ 0070: 18 00 0B 00 0C 00 19 00 0D 00 0E 00 0F 00 10 00 ................ 0080: 11 00 02 00 12 00 04 00 05 00 14 00 08 00 16 00 ................ 0090: 0B 00 02 01 00 ..... %% Initialized: [Session-1 SSL_NULL_WITH_NULL_NULL] keymanager chooseEngineServerAlias keymanager getPrivateKey: 3eb9936d-2240-4687-bf4e-6518460e3e40 keymanager getCertificateChain: 3eb9936d-2240-4687-bf4e-6518460e3e40 %% Negotiating: [Session-1 TLS_DHE_RSA_WITH_AES_128_CBC_SHA] *** ServerHello TLSv1 RandomCookie: GMT: 1359934920 bytes = { 242 252 196 36 227 154 97 148 214 170 109 188 122 223 161 62 131 201 214 11 223 36 74 224 72 78 94 50 } Session ID: {81 15 246 200 127 240 115 234 52 13 73 40 137 163 243 8 51 244 147 87 128 39 210 175 163 244 86 238 138 87 29 43} Cipher Suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA Compression Method: 0 Extension renegotiation_info renegotiated_connection: <empty> *** Cipher suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA *** Certificate chain chain [0] = [ [ Version: V3 Subject: CN=3eb9936d-2240-4687-bf4e-6518460e3e40 Signature Algorithm: SHA1withRSA OID = 1.2.840.113549.1.1.5 Key: Sun RSA public key 1024 bits modulus: 130292698947319747550411805428932496764788133931614615268432511412918979081774531703795353050388491281785406619160787220723201364083891450242081089010992812611565317265297099663990262828027908909326882453616292013722474448961222856631109497585792129874215397389474004374746492345728806709616072944360825031857 public exponent: 65537 Validity: [From: Sun Feb 03 03:52:37 CET 2013 To: Wed Feb 01 03:52:37 CET 2023] Issuer: CN=3eb9936d-2240-4687-bf4e-6518460e3e40 SerialNumber: [ 1bd22c7d 61d1a1eb] ] Algorithm: [SHA1withRSA] Signature: 0000: 94 5E 4F 74 28 A7 6C 94 25 60 4B 38 9F 7F 2D DE .^Ot(.l.%`K8..-. 0010: 6D 3E E5 1F 55 E4 F2 14 3F 80 FF D4 24 55 B9 60 m>..U...?...$U.` 0020: 4C C3 B6 BB 68 CD 12 AD FA BA 6D B0 76 5F 91 96 L...h.....m.v_.. 0030: 08 97 9D 53 E8 28 5C DE 69 DD 30 92 F1 FE 59 21 ...S.(\.i.0...Y! 0040: 81 05 E6 E6 8D 89 6E 77 A4 6A EC 13 E5 0B D9 17 ......nw.j...... 0050: 03 51 85 FB 14 D8 FA 6A A3 52 71 57 F2 A5 CC 80 .Q.....j.RqW.... 0060: 31 6D EA 64 81 4F C9 53 AC 01 FA EF AF 9D 0A F0 1m.d.O.S........ 0070: 9F 67 1E 76 D7 41 C9 62 2B 5B FB 42 E1 AF 55 F8 .g.v.A.b+[.B..U. ] *** *** Diffie-Hellman ServerKeyExchange DH Modulus: { 233 230 66 89 157 53 95 55 201 127 253 53 103 18 11 142 37 201 205 67 233 39 179 169 103 15 190 197 216 144 20 25 34 210 195 179 173 36 128 9 55 153 134 157 30 132 106 171 73 250 176 173 38 210 206 106 34 33 157 71 11 206 125 119 125 74 33 251 233 194 112 181 127 96 112 2 243 206 248 57 54 148 207 69 238 54 136 193 26 140 86 171 18 122 61 175 } DH Base: { 48 71 10 213 160 5 251 20 206 45 157 205 135 227 139 199 209 177 197 250 203 174 203 233 95 25 10 167 163 29 35 196 219 188 190 6 23 69 68 64 26 91 44 2 9 101 216 194 189 33 113 211 102 132 69 119 31 116 186 8 77 32 41 216 60 28 21 133 71 243 169 241 162 113 91 226 61 81 174 77 62 90 31 106 112 100 243 22 147 58 52 109 63 82 146 82 } Server DH Public Key: { 73 233 14 202 89 13 188 236 57 124 97 186 86 30 193 15 117 169 125 103 204 9 145 52 184 3 58 205 66 147 131 141 40 92 208 244 197 165 243 13 18 43 68 74 135 150 21 31 181 224 98 239 200 95 130 97 202 11 152 181 123 206 248 248 146 117 167 55 30 106 64 247 45 147 134 46 36 96 50 200 140 102 166 231 229 207 210 48 211 107 181 111 6 113 57 195 } Signed with a DSA or RSA public key New I/O worker #1 fatal error: 80: problem unwrapping net record java.lang.RuntimeException: Delegated task threw Exception/Error %% Invalidated: [Session-1 TLS_DHE_RSA_WITH_AES_128_CBC_SHA] New I/O worker #1 SEND TLSv1 ALERT: fatal description = internal_error New I/O worker #1 WRITE: TLSv1 Alert length = 2 [Raw write]: length = 7 0000: 15 03 01 00 02 02 50 ......P New I/O worker #1 called closeOutbound() New I/O worker #1 closeOutboundInternal() Client SSL debug testClient trigger seeding of SecureRandom done seeding SecureRandom Using SSLEngineImpl. Ignoring unavailable cipher suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_ECDH_RSA_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_DHE_DSS_WITH_AES_256_CBC_SHA256 Ignoring unavailable cipher suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 Ignoring unavailable cipher suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 Ignoring unavailable cipher suite: TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA384 Ignoring unavailable cipher suite: TLS_RSA_WITH_AES_256_CBC_SHA256 Ignoring unavailable cipher suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 Ignoring unavailable cipher suite: TLS_DHE_DSS_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_ECDH_RSA_WITH_AES_256_CBC_SHA384 Ignoring unavailable cipher suite: TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA Ignoring unavailable cipher suite: TLS_RSA_WITH_AES_256_CBC_SHA client.start(): true Allow unsafe renegotiation: false Allow legacy hello messages: true Is initial handshake: true Is secure renegotiation: false Ignoring unsupported cipher suite: TLS_DHE_DSS_WITH_AES_128_CBC_SHA256 Ignoring unsupported cipher suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 Ignoring unsupported cipher suite: TLS_ECDH_RSA_WITH_AES_128_CBC_SHA256 Ignoring unsupported cipher suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 Ignoring unsupported cipher suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 Ignoring unsupported cipher suite: TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA256 Ignoring unsupported cipher suite: TLS_RSA_WITH_AES_128_CBC_SHA256 %% No cached client session *** ClientHello TLSv1 RandomCookie: GMT: 1360012393 bytes = { 134 128 126 2 241 35 109 215 218 46 141 218 44 43 228 29 9 155 72 100 59 29 177 236 197 205 21 138 } Session ID: {} Cipher Suites: [TLS_DHE_RSA_WITH_AES_128_CBC_SHA TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA SSL_RSA_WITH_RC4_128_SHA TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA TLS_ECDHE_RSA_WITH_RC4_128_SHA TLS_ECDH_ECDSA_WITH_RC4_128_SHA TLS_ECDHE_ECDSA_WITH_RC4_128_SHA TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA TLS_ECDH_RSA_WITH_RC4_128_SHA TLS_EMPTY_RENEGOTIATION_INFO_SCSV TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA TLS_ECDH_RSA_WITH_AES_128_CBC_SHA TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA TLS_RSA_WITH_AES_128_CBC_SHA TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA SSL_RSA_WITH_RC4_128_MD5 TLS_DHE_DSS_WITH_AES_128_CBC_SHA SSL_DHE_DSS_WITH_3DES_EDE_CBC_SHA SSL_RSA_WITH_3DES_EDE_CBC_SHA] Compression Methods: { 0 } Extension elliptic_curves curve names: {secp256r1 sect163k1 sect163r2 secp192r1 secp224r1 sect233k1 sect233r1 sect283k1 sect283r1 secp384r1 sect409k1 sect409r1 secp521r1 sect571k1 sect571r1 secp160k1 secp160r1 secp160r2 sect163r1 secp192k1 sect193r1 sect193r2 secp224k1 sect239k1 secp256k1} Extension ec_point_formats formats: [uncompressed] *** [write] MD5 and SHA1 hashes: len = 149 0000: 01 00 00 91 03 01 51 10 24 69 86 80 7E 02 F1 23 ......Q.$i.....# 0010: 6D D7 DA 2E 8D DA 2C 2B E4 1D 09 9B 48 64 3B 1D m.....+....Hd;. 0020: B1 EC C5 CD 15 8A 00 00 2A 00 33 C0 04 00 16 00 ........*.3..... 0030: 05 C0 03 C0 11 C0 02 C0 07 C0 13 C0 08 C0 0C 00 ................ 0040: FF C0 0D C0 0E C0 09 00 2F C0 12 00 04 00 32 00 ......../.....2. 0050: 13 00 0A 01 00 00 3E 00 0A 00 34 00 32 00 17 00 ......>...4.2... 0060: 01 00 03 00 13 00 15 00 06 00 07 00 09 00 0A 00 ................ 0070: 18 00 0B 00 0C 00 19 00 0D 00 0E 00 0F 00 10 00 ................ 0080: 11 00 02 00 12 00 04 00 05 00 14 00 08 00 16 00 ................ 0090: 0B 00 02 01 00 ..... pool-5-thread-2 WRITE: TLSv1 Handshake length = 149 [Raw write]: length = 154 0000: 16 03 01 00 95 01 00 00 91 03 01 51 10 24 69 86 ...........Q.$i. 0010: 80 7E 02 F1 23 6D D7 DA 2E 8D DA 2C 2B E4 1D 09 ....#m.....+... 0020: 9B 48 64 3B 1D B1 EC C5 CD 15 8A 00 00 2A 00 33 .Hd;.........*.3 0030: C0 04 00 16 00 05 C0 03 C0 11 C0 02 C0 07 C0 13 ................ 0040: C0 08 C0 0C 00 FF C0 0D C0 0E C0 09 00 2F C0 12 ............./.. 0050: 00 04 00 32 00 13 00 0A 01 00 00 3E 00 0A 00 34 ...2.......>...4 0060: 00 32 00 17 00 01 00 03 00 13 00 15 00 06 00 07 .2.............. 0070: 00 09 00 0A 00 18 00 0B 00 0C 00 19 00 0D 00 0E ................ 0080: 00 0F 00 10 00 11 00 02 00 12 00 04 00 05 00 14 ................ 0090: 00 08 00 16 00 0B 00 02 01 00 .......... [Raw read]: length = 5 0000: 15 03 01 00 02 ..... [Raw read]: length = 2 0000: 02 50 .P New I/O worker #1 READ: TLSv1 Alert length = 2 New I/O worker #1 RECV TLSv1 ALERT: fatal internal_error New I/O worker #1 fatal: engine already closed. Rethrowing javax.net.ssl.SSLException: Received fatal alert: internal_error New I/O worker #1 fatal: engine already closed. Rethrowing javax.net.ssl.SSLException: Received fatal alert: internal_error New I/O worker #1 called closeOutbound() New I/O worker #1 closeOutboundInternal() New I/O worker #1 SEND TLSv1 ALERT: warning description = close_notify New I/O worker #1 WRITE: TLSv1 Alert length = 2 New I/O worker #1 called closeInbound() New I/O worker #1 fatal: engine already closed. Rethrowing javax.net.ssl.SSLException: Inbound closed before receiving peer's close_notify: possible truncation attack? [Raw write]: length = 7 0000: 15 03 01 00 02 01 00 ....... main called closeOutbound() main closeOutboundInternal() New I/O worker #1 called closeOutbound() New I/O worker #1 closeOutboundInternal() Security.java (groups all security relevant stuff) public class Security { private static final String protocol = ""TLS""; @SuppressWarnings(""restriction"") private static X509Certificate generateCertificate(String dn KeyPair pair String algorithm) throws GeneralSecurityException IOException { PrivateKey privkey = pair.getPrivate(); X509CertInfo info = new X509CertInfo(); Date from = new Date(); Date to = new Date(from.getTime() + 10l * 365 * 24 * 60 * 60 * 1000); CertificateValidity interval = new CertificateValidity(from to); BigInteger sn = new BigInteger(64 new SecureRandom()); X500Name owner = new X500Name(dn); info.set(X509CertInfo.VALIDITY interval); info.set(X509CertInfo.SERIAL_NUMBER new CertificateSerialNumber(sn)); info.set(X509CertInfo.SUBJECT new CertificateSubjectName(owner)); info.set(X509CertInfo.ISSUER new CertificateIssuerName(owner)); info.set(X509CertInfo.KEY new CertificateX509Key(pair.getPublic())); info.set(X509CertInfo.VERSION new CertificateVersion(CertificateVersion.V3)); AlgorithmId algo = new AlgorithmId(AlgorithmId.md5WithRSAEncryption_oid); info.set(X509CertInfo.ALGORITHM_ID new CertificateAlgorithmId(algo)); // Sign the cert to identify the algorithm that's used. X509CertImpl cert = new X509CertImpl(info); cert.sign(privkey algorithm); // Update the algorith and resign. algo = (AlgorithmId) cert.get(X509CertImpl.SIG_ALG); info.set(CertificateAlgorithmId.NAME + ""."" + CertificateAlgorithmId.ALGORITHM algo); cert = new X509CertImpl(info); cert.sign(privkey algorithm); return cert; } protected static char[] getPassword() { return ""test"".toCharArray(); } private static void pushKeyStoreToConfig(KeyStore ks String configKey) throws KeyStoreException NoSuchAlgorithmException CertificateException IOException { ByteArrayOutputStream baos = new ByteArrayOutputStream(); ks.store(baos Security.getPassword()); Configuration.set(configKey baos.toByteArray()); } private KeyManager[] keyManagers; private KeyStore keyStore; private KeyStore trustStore; private SSLContext sslContext; private TrustManager[] trustManagers; public Security() { LoggerFactory.getLogger(Security.class).debug(""constructing...""); } public synchronized void addCertificate(String guid Certificate certificate) throws KeyStoreException NoSuchAlgorithmException CertificateException IOException { this.getTrustStore().setCertificateEntry(guid certificate); Security.pushKeyStoreToConfig(this.getTrustStore() Configuration.TRUST_STORE); Configuration.getInstance().save(); } public SslHandler createSslHandler() { SSLEngine engine = this.getSslContext().createSSLEngine(); engine.setUseClientMode(true); engine.setNeedClientAuth(true); return new SslHandler(engine); } public synchronized KeyManager[] getKeyManagers() { if (this.keyManagers == null) { KeyManager keyManager = new X509ExtendedKeyManager() { @Override public String chooseClientAlias(String[] keyType Principal[] issuers Socket socket) { System.out.println(""keymanager chooseClientAlias""); return Configuration.get(Configuration.GUID String.class); } @Override public String chooseEngineClientAlias(String[] keyType Principal[] issuers SSLEngine engine) { System.out.println(""keymanager chooseEngineClientAlias""); return Configuration.get(Configuration.GUID String.class); } @Override public String chooseEngineServerAlias(String keyType Principal[] issuers SSLEngine engine) { System.out.println(""keymanager chooseEngineServerAlias""); return Configuration.get(Configuration.GUID String.class); } @Override public String chooseServerAlias(String keyType Principal[] issuers Socket socket) { System.out.println(""keymanager chooseServerAlias""); return Configuration.get(Configuration.GUID String.class); } @Override public X509Certificate[] getCertificateChain(String alias) { System.out.println(""keymanager getCertificateChain: "" + alias); try { Certificate[] certs = Security.this.getKeyStore().getCertificateChain(alias); X509Certificate[] xcerts = new X509Certificate[certs.length]; for (int i = 0; i < certs.length; i++) { xcerts[i] = (X509Certificate) certs[i]; } return xcerts; } catch (Exception e) { LoggerFactory.getLogger(Security.class).error(""Error while getting security chain"" e); return null; } } @Override public String[] getClientAliases(String keyType Principal[] issuers) { System.out.println(""keymanager getClientAliases""); // TODO Auto-generated method stub return null; } @Override public PrivateKey getPrivateKey(String alias) { System.out.println(""keymanager getPrivateKey: "" + alias); try { return (PrivateKey) Security.this.getKeyStore().getKey(alias Security.getPassword()); } catch (Exception e) { LoggerFactory.getLogger(Security.class).error(""Error while getting private key"" e); return null; } } @Override public String[] getServerAliases(String keyType Principal[] issuers) { System.out.println(""keymanager getServerAliases""); // TODO Auto-generated method stub return null; } }; this.keyManagers = new KeyManager[] { keyManager }; } return this.keyManagers; } public synchronized KeyStore getKeyStore() throws IOException GeneralSecurityException { if (this.keyStore == null) { this.keyStore = KeyStore.getInstance(KeyStore.getDefaultType()); try { ByteArrayInputStream bais = new ByteArrayInputStream(Configuration.get(Configuration.KEY_STORE byte[].class)); this.keyStore.load(bais Security.getPassword()); } catch (Exception e) { LoggerFactory.getLogger(Security.class).warn(""Could not load key store creating new one"" e); this.keyStore.load(null); } String guid = Configuration.get(Configuration.GUID String.class); if (this.keyStore.getKey(guid Security.getPassword()) == null) { this.resetKey(this.keyStore); } // TODO certificate expired? create new one! } return this.keyStore; } public synchronized SSLContext getSslContext() { if (this.sslContext == null) { SSLContext context = null; try { context = SSLContext.getInstance(Security.protocol); context.init(this.getKeyManagers() this.getTrustManagers() Controller.getInstance().getRandom()); } catch (Exception e) { throw new Error(""Failed to initialize the server-side SSLContext"" e); } this.sslContext = context; } return this.sslContext; } private synchronized TrustManager[] getTrustManagers() { if (this.trustManagers == null) { TrustManager trustManager = new X509TrustManager() { @Override public void checkClientTrusted(X509Certificate[] chain String authType) throws CertificateException { System.out.println(""trustmanager checkClientTrusted""); this.checkTrusted(chain authType); } @Override public void checkServerTrusted(X509Certificate[] chain String authType) throws CertificateException { System.out.println(""trustmanager checkServerTrusted""); this.checkTrusted(chain authType); } public void checkTrusted(X509Certificate[] chain String authType) throws CertificateException { Certificate cert = null; try { cert = Security.this.getTrustStore().getCertificate(chain[0].getSubjectX500Principal().getName()); if (cert == null) { throw new CertificateException(""Certificate is not trusted: "" + chain[0]); } } catch (Exception e) { throw new CertificateException(""Error while validating certificate: "" + chain[0] e); } } @Override public X509Certificate[] getAcceptedIssuers() { return null; } }; this.trustManagers = new TrustManager[] { trustManager }; } return this.trustManagers; } protected synchronized KeyStore getTrustStore() throws KeyStoreException NoSuchAlgorithmException CertificateException IOException { if (this.trustStore == null) { this.trustStore = KeyStore.getInstance(KeyStore.getDefaultType()); try { this.trustStore.load(new ByteArrayInputStream(Configuration.get(Configuration.TRUST_STORE byte[].class)) Security.getPassword()); } catch (Exception e) { LoggerFactory.getLogger(Security.class).warn(""Could not load trust store creating new one"" e); this.trustStore.load(null); } } return this.trustStore; } public synchronized void resetKey() throws IOException GeneralSecurityException { this.resetKey(this.getKeyStore()); } private synchronized void resetKey(KeyStore ks) throws IOException GeneralSecurityException { LoggerFactory.getLogger(Security.class).info(""Creating a new key pair and certificate""); KeyPairGenerator kpg = KeyPairGenerator.getInstance(""RSA""); kpg.initialize(1024 Controller.getInstance().getRandom()); KeyPair kp = kpg.generateKeyPair(); PrivateKey key = kp.getPrivate(); String dn = ""cn="" + Configuration.get(Configuration.GUID String.class); X509Certificate[] chain = new X509Certificate[] { Security.generateCertificate(dn kp ""SHA1withRSA"") }; ks.setKeyEntry(Configuration.get(Configuration.GUID String.class) key Security.getPassword() chain); Security.pushKeyStoreToConfig(ks Configuration.KEY_STORE); this.addCertificate(Configuration.get(Configuration.GUID String.class) chain[0]); } } Additional info setUseClientMode() is set from the outside in case of server engine. This stops after receiving the server credentials.Have you put the server certificate in your trusstore?Show us your code @Cratylus provided way more detail. I fear this is a bit overkill though. =/ This very less expressive error message is caused by a NullPointerException thrown in Java's handshaker which can be fixed by returning at least an empty list (you probably want more) in TrustManager.getAcceptedIssuers(). See Oracle Bug ID 7148699: Handshaker throws NPE if TrustManager returns null from getAcceptedIssuers for more details."
585,A,"about handlers in Netty and concurrency I have a question about concurrency in upstream/downstream handlers of a channel pipe. I always thought that if a new handler is created when the pipe is constructed (that is the handler isn't shared amongst the pipes) at most one thread interacts with the handler. Now I was browsing through the examples. More specific take this one: http://docs.jboss.org/netty/3.2/xref/org/jboss/netty/example/discard/DiscardServerHandler.html In the code there is a member variable (it is used to count the total number of bytes): private final AtomicLong transferredBytes = new AtomicLong(); Why do they use a AtomicLong here? The handler is constructed as following (see http://docs.jboss.org/netty/3.2/xref/org/jboss/netty/example/discard/DiscardServer.html): bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline(new DiscardServerHandler()); } }); So the handler is not shared. I cannot find a reason why they would want to use a AtomicLong instead of a plain long here. Can somebody explain? Thanks! Its a ""bug"" in the example. There is no need for the AtomicLong here. So you are right. If you add a new instance of the handler on every ChannelPipeline creation you should not need to bother with this kind of concurrency issues. I will fix the example in netty. Thanks! Thanks a lot for the confirmation! @Sharable means you can safely have the same instance in different ChannelPipelines... how do we determine for which case we should use sharable or for which case we should create new handler?"
586,A,"Netty Server handling multiple clients I want to set up a server that handles a calculation request. This calculation can be split up in x partial calculations so I want to have multiple clients that may register to the server. The server should have a list of these registered clients. When the server receives a request it splits the calculation in its x parts and afterwards sends each calculation request to the clients and waits for the clients to end its calculation. Does someone have an idea how to do this with netty or any other technology that may be easier? Netty seemed to be the right solution for me but I don't know how I can register and save the clients in the server and afterwards send the calculation parts to the clients and wait for them. Writing the three or so dozen lines of code that are required to do this is probably a better choice than a ""framework"". I don't think so as netty already handles some things that can occur like fragmentation and serialization. Also with netty I get very nice scalable code. Give Hazelcast a try (distributed execution). Can you explain how it works? How can I add members the the cluster that execute the Serializable Callable? Simply by starting another node (be it on the same computer or on another one). They should find each other automatically. http://code.google.com/docreader/#p=hazelcast&s=hazelcast&t=ExecutorService Also you might want to take a look at the Documentation http://www.hazelcast.com/documentation.jsp and the ClusterTestHowto http://code.google.com/p/hazelcast/wiki/ClusterTestHowTo. Hope that helps."
587,A,"Writing to all but one in a TCP Netty ChannelGroup I have a TCP based Netty application with multiple clients that need to communicate with each other. I store all of the Channel references in a ChannelGroup. While I know that I can write to every client in a ChannelGroup by calling ChannelGroup.write but what would be an efficient way to write to all but one of these channels for example: 'A''B''C' are in a Channel Group together and 'A' needs to send to 'B' and 'C' 'B' needs to send to 'A' and 'C' etc. What would be the best way to do this? Here are some options I thought of but some feedback would be appreciated: Just iterate through the Group and write to the channels individually (don't use ChannelGroup.write in this case) Repeatedly ""remake/clone"" the ChannelGroup so it contains only the channels to write to. I would then call ChannelGroup.write on the modified group then restore the group to the full group. Write to all channels but implement some Handler logic to discard (either on Encode or Downstream Handler) and not write the message if it is from the excluded channel. As far as design trade offs are concerned messages are sent as rapidly as possible ChannelGroups are relatively small <20 channels and messages are about 1kb in size each (500 bytes - 2 kb). Also there is a scenario under which many of the connections are on the same host as the Server if different logic works better for localhost feedback on this would be greatly appreciated. Thanks so much for any help! I would probably do something along the lines of option 3. If you truly don't want channels to write to themselves then it would make sense to have logic inside a channel (or handler?) that ignores messages form itself. This way it can be up to the channel to care if it wants messages from itself or not. There may be other implications in doing this but otherwise it seems clean. I would not do #2. So far as I know there is no inherent performance benefit to writing to a channel group. If you look at the code for DefaultChannelGroup it simply iterates through the registered channels issues the write and collects the futures: public ChannelGroupFuture write(Object message) { Map<Integer ChannelFuture> futures = new LinkedHashMap<Integer ChannelFuture>(size()); if (message instanceof ChannelBuffer) { ChannelBuffer buf = (ChannelBuffer) message; for (Channel c: nonServerChannels.values()) { futures.put(c.getId() c.write(buf.duplicate())); } } else { for (Channel c: nonServerChannels.values()) { futures.put(c.getId() c.write(message)); } } return new DefaultChannelGroupFuture(this futures); } .... although you do get the benefit of a multiplexed future which if you care about the completion callbacks is useful. I would not do #3 either since you are just giving the downstream handlers more work to do discarding data that you went to all the bother to write in the first place. So I would either: Implement Option #1 Extend DefaultChannelGroup and add a write method that is clever enough to skip the channel in question. You would probably have to provide a bit more meta-data when you add the channels to the group. Thank you so much for your help and analysis. It is greatly appreciated."
588,A,"Netty and ByteOrder Due to poor documentation and lack of experience with Netty i faced with little problem. I have no clue how can i set a default ByteOrder. I need a Little-Endian set by default. I'll be glad if someone will give me some hints about this. You could use Bootstrap.setOption() to do this.  serverBootstrap.setOption(""child.bufferFactory"" new HeapChannelBufferFactory(ByteOrder.LITTLE_ENDIAN)); ... or ... clientBootstrap.setOption(""bufferFactory"" new HeapChannelBufferFactory(ByteOrder.LITTLE_ENDIAN)); Thanks for the hint Abe. I saw this in api but doubted. Gonna try that."
589,A,What does ChannelFuture complete actually mean? Please excuse this numpty question but when I do ChannelFuture future = channel.write(message); future.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { } } what do I know about the state of the message in the operationComplete() method? For example does it mean that the message has arrived at its destination? Or does it mean that the message has passed through the pipeline and is now somewhere in the ether on its way to its destination or does it mean something else? Regards The message was written to the remote peer or it failed. So if you get a success here you can be sure that the message was transmitted.
590,A,"Binding text message with websocket using Netty in browser I am trying to implement websockets using Netty. I tried DiscardServer example and it works fine if I just run it using Telnet like  Telnet localhost 8090. So whatever the message I put in terminal window it returns me back. But now I want to implement same in browser like if I put some text message in a text area then it should display that text message on browser. I can start the websocket server using the following code  ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); ServerBootstrap bootstrap = new ServerBootstrap(factory); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline(new DiscardServerHandler()); } }); bootstrap.setOption(""child.tcpNoDelay"" true); bootstrap.setOption(""child.keepAlive"" true); bootstrap.bind(new InetSocketAddress(8090)); but how can I bind my text message in my text area with the websocket server ----Updated---- I have created MyServerHandler class  public class MyServerHandler extends SimpleChannelUpstreamHandler { @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { Object msg = e.getMessage(); //msg.getClass(); if (msg instanceof HttpRequest) { //handleHttpRequest(ctx (HttpRequest) msg); ctx.getChannel().write(msg); } else if (msg instanceof WebSocketFrame) { //handleWebSocketFrame(ctx (WebSocketFrame) msg); } } } Its calling messageReceived Method but not going to any of if condition. I wrote WebSocketServerPipelineFactory class also  public class WebSocketServerPipelineFactory implements ChannelPipelineFactory { @Override public ChannelPipeline getPipeline() throws Exception { // Create a default pipeline implementation. ChannelPipeline pipeline = pipeline(); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""aggregator"" new HttpChunkAggregator(65536)); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""handler"" new MyServerHandler()); return pipeline; } } I thing its not calling method of this class also. In jsp file I have written  <script src=""http://ajax.googleapis.com/ajax/libs/jquery/1.6.4/jquery.min.js"" type=""text/javascript""></script> <script> var MESSAGE_HANDSHAKE = ""handshake""; var MESSAGE_OPPONENT_UPDATE = ""response""; var MESSAGE_TURN_INDICATOR = ""turn""; var MESSAGE_GAME_OVER = ""game_over""; var WEBSOCKET_URL = ""ws://localhost:8090""; $(document).ready(function() { ws = new WebSocket(WEBSOCKET_URL); ws.onopen = function(event) { alert(""test""); $('#status').text(""Waiting....""); }; ws.onmessage = function(event) { var message = jQuery.parseJSON(event.data); alert(message.type); } }); <body> <p id=""status"">&nbsp;</p> </body> Its not going to any of jquery methods. Am I still missing something? Also If I write  ws.send(""Test Message""); it throws following java script error  Uncaught Error: INVALID_STATE_ERR: DOM Exception 11 login.htm:33 (anonymous function) login.htm:33 f.extend._Deferred.e.resolveWith jquery.min.js:2 e.extend.ready jquery.min.js:2 c.addEventListener.C If I use  var WEBSOCKET_URL = ""wss://echo.websocket.org/""; Then it works so is this that I am not able to connect to my server ? I am using eclipse to run this code. I am running my jsp code using Apache Tomcat and running websocket server by running WebsocketServer.class as java application. Is that make any difference? --- Updated--- I wrote the following method in MyServerHandler class and getting the error in my browser  Error during WebSocket handshake: 'Sec-WebSocket-Accept' header is missing MySeverHandler.java  private void handleHttpRequest(ChannelHandlerContext ctx HttpRequest req) throws Exception { // Allow only GET methods. if (req.getMethod() != HttpMethod.GET) { // sendHttpResponse(ctx req new DefaultHttpResponse( // HttpVersion.HTTP_1_1 HttpResponseStatus.FORBIDDEN)); return; } // Serve the WebSocket handshake request. if (req.getUri().equals(WEBSOCKET_PATH) && Values.UPGRADE.equalsIgnoreCase(req.getHeader(CONNECTION)) && WEBSOCKET.equalsIgnoreCase(req.getHeader(Names.UPGRADE))) { // Create the WebSocket handshake response. HttpResponse res = new DefaultHttpResponse( HTTP_1_1 new HttpResponseStatus(101 ""Web Socket Protocol Handshake"")); res.addHeader(Names.UPGRADE WEBSOCKET); res.addHeader(CONNECTION Values.UPGRADE); // Upgrade the connection and send the handshake response. ChannelPipeline p = ctx.getChannel().getPipeline(); p.remove(""aggregator""); p.replace(""decoder"" ""wsdecoder"" new WebSocketFrameDecoder()); // Write handshake response to the channel ctx.getChannel().write(res); // Upgrade encoder to WebSocketFrameEncoder p.replace(""encoder"" ""wsencoder"" new WebSocketFrameEncoder()); // Initialize the game. Assign players to a game and assign them a letter (X or O) ///initGame(ctx); return; } // Send an error page otherwise. sendHttpResponse(ctx req new DefaultHttpResponse( HttpVersion.HTTP_1_1 HttpResponseStatus.FORBIDDEN)); } Did you take a good look at the tic-tac-toe code in github it shows how to write back to client. Partial code snippet provided here // Upgrade the connection and send the handshake response. ChannelPipeline p = ctx.getChannel().getPipeline(); p.remove(""aggregator""); p.replace(""decoder"" ""wsdecoder"" new WebSocketFrameDecoder()); // Write handshake response to the channel ctx.getChannel().write(res); I think your decoder in the pipeline is not setup properly then. Else the class name would be either HTTPRequest or WebSocketFrame. Why dont you put debug points in eclipse and try to see message flow through your decoders to see what exactly is happening. Also take a look at your method call stack and see if the decoders/encoders are getting invoked. Hi Abe thanks for your response. Please look at my handleHttpRequest method in updates. I don't get if I still missing something I have just copy and paste the code you gave me and its the same in github also. I put the breakpoint in WebSocketServerPipelineFactory class but its not going there its just call the messageReceived method where I put the breakpoint. I am really fed-up with this. I don't know what I am doing wrong. I am not able to understand what to write in MyServerHandles and how it can send the response back to browser. ""Its calling messageReceived Method but not going to any of if condition."" What is the class of the incoming object then? do a debug or a print statement and check it out. Your best bet to make it work would be look at recent examples in github web. The tic-tac-toe one is a bit outdated. the class name is class org.jboss.netty.buffer.BigEndianHeapChannelBuffer is this correct? How could I find the recent example in github on netty websocket? I think you are not passing this pipeline factory to the server bootstap. Are you passing something else? Definitely this is because pipeline is misconfigured. Check out this link on how to configure your bootstrap http://docs.jboss.org/netty/3.2/api/org/jboss/netty/bootstrap/ServerBootstrap.html Hi Abe  you are write it was a very silly mistake I found it yesterday. Now I am getting invalid version format:: ￀￀￀ Now what is this? Thanks for your patient Abe invalid version format is gone when I change the URL from wss:// to ws:// is this correct? Now I am getting error at browser Error during WebSocket handshake: 'Sec-WebSocket-Accept' header is missing. Anyway I am accepting your answer. But if you could tell me why this error that would be great and I can up vote your comments too :) Netty uses chain of responsibility design pattern so whenever you need to use a protocol you need to create appropriate decoders/encoders in your pipeline. For websocket here is an example pipeline. public class WebSocketServerPipelineFactory implements ChannelPipelineFactory { public ChannelPipeline getPipeline() throws Exception { // Create a default pipeline implementation. ChannelPipeline pipeline = pipeline(); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""aggregator"" new HttpChunkAggregator(65536)); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""handler"" new YourBusinessHandler()); return pipeline; } } You can write any business logic in your buisness handler. In this case you would just be echoing back what you received so it would be something like channel.write(incomingMessage); in this handler. Take a look at this tic-tac-toe game for more information. Also there are many links information in github on how to do this. Hi Abe thanks for your response the article seems good but still I am facing some issue can you please check my update."
591,A,"Netty based non-blocking REST framework I am working on a RESTfull application which requires high scalability. I am considering Netty based frameworks for RESTfull applications. I went through some of the available options and tried to get what they can offer as a non-blocking implementation. Here are my findings: rest.li --> Still under experimental phase for Netty based NIO implementaions. So not production ready. RESTEasy --> Standard JBoss project which supports Netty 4.x. Butinstead of full stack Netty based NIO implementation RESTEasy is a Buffer exchange between Netty and RESTEasy. It's not taking the advantages of Netty. Therefore scalability is not as high as expected from a Netty based framework. Netty-http component --> Another option is Apache Camel integration while using Netty-http component as an endpoint for routing requests to services exposed in from of beans. I think it's same as RESTEasy only Netty-http component uses Netty based NIO capabilities and the rest of the system would use the old IO. I don't think I would help much in gaining scalabiltiy. RESTExpress --> It claims to be Netty based framework for RESTFull application. But neither it has a decent community nor it can be trusted (Because it's very new) for enterprise application which requires high degree of security. Before having the above findings I wanted to use some ready to use framework and get the work done faster. I know it's an opinion based question. But still I seriously need help for choosing right framework for my application. If in case there is no Netty based REST framework: would it be wise to go for plumbing low level Netty based NIO code in my application? Any help appreciated. Thanks in advance. Using a NIO REST framework won't make your application magically scalable. Making you application stateless and using cache headers correctly is a good start. You might be surprised that BIO often times performs better than NIO particular for the case of short requests (ie no keep alive or websocket). Most REST clients and even REST in general is short requests. @eiden I am already playing with Akka-Actors with remote capabilities to make it a highly scalable and distributed application. I just wanted to just get rid of blocking nature of Servlet-API. I have started playing with Spray + Akka Actors. Have you taken a look at Play? It appears that you are inclined to use Netty but if you are willing to look around a very simple Grizzly + Jersey setup will probably perform well enough. Heck a simple Glassfish 4.0 JAX-RS app may work well too.  Here's the list of microframeworks I'm aware of for REST applications: Scalatra - http://www.scalatra.org/ (Scala + Netty) RestExpress - https://github.com/RestExpress/RestExpress (Java + Netty) Finatra - https://github.com/capotej/finatra (Scala + Finagle + Netty) Please feel free to comment to the answer - I'll update the answer to add more.  If you really want non-blocking you need to do non-blocking from the ground up and have proper REST clients. Otherwise as stated in my comment the performance difference will be negligible and in many cases worse for NIO (Netty with thread sharing). There only two libraries that I know do non-blocking from the ground up Vert.x and somewhat Finagle (its missing other things like non-blocking data access). You should also know Tomcat and various other servlet containers that can work with JAX-RS support NIO. The issue is that even though NIO is supported it will still be a single thread per request. Only Play Finagle Vert.x and pure Netty (regardless of NIO) support a different shared threading model and thus have different mechanisms for doing concurrency. I didn't get what exactly you want to say by ""Proper REST client"". Can you please put more light on it. Thanks for your reply. Thanks for showing the right path :) I edited the answer with a link. What I mean is supporting persistent connections or using a different protocol altogether. A large impetus for Node.js and the whole non-blocking/single thread event loop is because persistent connections are becoming more common place (Websockets Comet etc...). Almost all traditional Java REST services will have trouble for a streaming REST API of say 10000 long running requests regardless of NIO because of the thread/request. That being said most REST clients will do GET/POST/DELETE/PUT as a request then immediately close the connection."
592,A,"looking for best netty classes to use for in-memory streaming between threads I'm looking for a recommendation on the best netty class(es) to use that support the following functionality: in-memory local JVM communication stream-based support multiple threads writing binary data into the stream SINGLE thread reading the data from the stream is thread-safe on the writing side automatically handles the underlying byte array growth supports configurable timeout on the READing thread At first glance the ChunkedWriteHandler + either the ChunkedNioStream or ChunkedStream classes look like the best approach but I don't know from reading the documentation if they meet all the requirements above. If anyone can provide some direction/recommendation it would be greatly appreciated! Thanks Bob UPDATE: after digging some more should I be looking at ChannelBufferInputStream and ChannelBufferOutputStream? Not having used Netty yet I'm still coming up to speed on what pieces are used where. I'm a bit confused.. Can you give some more details about the use case ? Normally you don't want to use ""blocking"" operations with netty. For VM communication you should checkout the local package: http://netty.io/docs/stable/api/org/jboss/netty/channel/local/package-frame.html"
593,A,How i can open new client channel inside server handler to other address I use netty. In may application i process inсoming packets but i need send parsed packet in other server and should return to the incoming flow of the result of processing the package third-party server; How i can open new connection inside server hadler for send packet to third-party server and read result? The same way you would write a client with netty. Netty client example: http://static.netty.io/3.6/guide/#start.9 You'd need to use the ClientBootstrap to set up a new bootstrap create a pipeline factory handlers etc etc. In all honestly that's probably a bit overkill unless you really need it to be async which is sounds like you don't. If it's just a REST service or something similar you need to access I'd just use a plaid old HttpUrlConnection and get what you need synchronously.
594,A,"org.jboss.netty suddenly stops serving I am coding a game server using org.jboss.netty. To be honest this is my first time I am coding TCP/IP application. Netty suddenly stops calling my functions in handler. I tried adding the following lines to kick idle connections: LINE 1 TO PIPELINE : pipeline.addLast(""timeout"" new IdleStateHandler(idleTimer 82  0 0)); LINES TO HANDLER : public void channelIdle(ChannelHandlerContext ctx IdleStateEvent e) throws Exception { super.channelIdle(ctx e); ctx.getChannel().close(); } Still I am facing the same problem. In this game server I have timed tasks (have seperate executerthread pool) forexample every 3 seconds it sends message to 1800 clients. Can this be a problem ? Have you ever faced this kind of problem ? I suppose pushing data to clients periodically may be the problem. Because as we use thread pool in netty  slow connections or bad network may cause long send queues thus effecting available thread count in pool. What do you think ? Are you sure you not block the ioworker thread somehow ? I would take some thread-dumps to be sure. jstack <pid> thanks for the answer. i didn t know the jstack command. its actually true that somehow working threads were getting blocked. if it happens again jstack will help me figuring out the actual problem."
595,A,Keeping state on a Netty Channel Is there a way to keep state on a Channel. I'm writing a chat server and I want to keep information about the user that a Channel belongs to. I was thinking maybe Channel would provide a method to store a user object but I can't see one. Is there a way to do this without needing something like a Map? 1)You can set the state information in the channelHandlerContext like below and use it later.  channelHandlerContext.setAttachment(yourObj); Object yourObj2 = channelHandlerContext.getAttachment(); 2)Create a channel local and store state information there (channel local is like a thread local to specific a channel) import org.jboss.netty.channel.ChannelLocal; import java.util.Map; public class UserInfoHolder { public final static ChannelLocal<Map<String String>> USER_INFO = new ChannelLocal<Map<String String>>(); } //if you have the channel reference you can store and retrieve information like this Map<StringString> userMap = .... //store UserInfoHolder.USER_INFO.set(channel userMap); //retrive Map<StringString> userMap2 = UserInfoHolder.USER_INFO.get(channel);
596,A,Propagate back-pressure between two netty channels I want to write a system using netty-4 where a server receives a request from one channel (cleverly dubbed in) does a transform and potentially puts the result onto another channel to another backend-system (dubbed out). But I would like to propagate back-pressure from the out channel to the in channel? Specifically—because the netty APIs are asynchronous—how do I get notified when out is no longer blocked up; and tell in to pause/resume? Partial Solutions I believe can tell when out channel is ready to write with channel.isWritable(). An answer to this question mentions disabling AUTO_READ but then I believe I'd have to be in charge of polling the channel for reads. I'm not to happy about that—unless I can receive a message when it's ready to read. At this point the utility of using netty is mostly just the no-copy buffers and the ByteToMessageDecoder superclass. Right you can disable AUTO_READ on the IN channel when the OUT is not writable and enable AUTO_READ again when the OUT will be ready. No polling is required here.  To add to Igor's answer - you have a couple of options for reactivating reads. The first one shown here means capturing the channelWritabilityChanged event on the destination channel. You can check the status of the channel and enable auto read on the source channel. Alternatively the proxy example shows setting a write completion listener to write and flush. This technique also works but does not take advantage of Netty's high/low water mark queuing system as you'll only be told the write is complete once the write has been flushed to the network buffers.
597,A,"using the Netty pipeline efficiently On the server ChannelPipelineFactory#getPipeline() is called for every new connection. My server's ChannelHandlers have allocation for serialization buffers and other objects that are not thread safe. How can I avoid allocating them for each connection? My application has a high volume of short-lived connections and this is hurting performance. I don't store per connection state in the handlers I really only need to allocate them once per thread that will use the pipeline because the objects in the handlers are not thread safe. Possibly I could use a pipeline with a single handler. When any event is received I would obtain a reference to my actual handler from a ThreadLocal. This way I only allocate an actual handler once per thread serving connections. It does mean a ThreadLocal look up for every event though. Are there other solutions that might be better? I have the impression that the Netty pipeline looks great in relatively simple example code and is quite neat when it fits the problem well (such as the HTTP handling) but that it isn't very flexible for many other scenarios. Here is someone elses' thoughts along those lines. It isn't any sort of disaster since using a single handler to roll your own ""pipeline"" seems perfectly viable but I wonder if I'm doing it wrong? Using a ThreadLocal seems like a good idea if that is enough for you. Be aware that this will only work well for upstream events as downstream events may be fired by any thread and so the ThreadLocal stuff may not work out that good. Hmm good point. AFAIK for now this is ok as my server is open/request/response/close so the write thread will always be a worker thread. Writes would happen either immediately in the worker thread that read the response or if the write didn't succeed then later using OP_WRITE also in a worker thread. If my requests start to take to long and I introduce a thread pool to avoid blocking the worker threads I'd have to change ThreadLocal to a synchronized pool. Does that all sound correct to you? yes sounds ok for me"
598,A,when allocateMemoryNetty show OutOfMemoryError I'm using Netty3.2.4 for long connectionwhen server start It works rightbut after a few days letethe server may show OutOfMemoryError and the detail log infomation is : <Error> <HTTP> <BEA-101017> <[weblogic.servlet.internal.WebAppServletContext@5cd7f9 - appName: 'perbank' name: 'perbank' context-path: '/perbank'] Root cause of ServletException. java.lang.OutOfMemoryError at sun.misc.Unsafe.allocateMemory(Native Method) at java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:99) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:288) at org.jboss.netty.channel.socket.nio.SocketSendBufferPool$Preallocation.<init>(SocketSendBufferPool.java:155) at org.jboss.netty.channel.socket.nio.SocketSendBufferPool.<init>(SocketSendBufferPool.java:42) Truncated. see log file for complete stacktrace > maybe JVM not do the GCor maybe many socket connections used because the network is not stabledon't know why. I would upgrade to latest 3.5.9.Final and see if the problem is solved by this fix.
599,A,"Netty AttributeKey - Cannot infer type arguments for AttributeKey<> I have used this before so I have NO idea why this doesn't work. Consider this code public class NioServer implements Runnable { private EventLoopGroup group; private ServerBootstrap b; public static final AttributeKey<Session> SESSION_KEY = new AttributeKey<>(""SessionHandler.attr""); @Override public void run() { group = new NioEventLoopGroup(); b = new ServerBootstrap(); b.group(group) .channel(NioServerSocketChannel.class) .localAddress(435) .childOption(ChannelOption.SO_KEEPALIVE true) .childOption(ChannelOption.TCP_NODELAY true) .childHandler(new ChannelInitializer<SocketChannel>() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(""Session Handler"" new SessionHandler()); } }); } } The AttributeKey SESSION_KEY does not want to work and gives the error: ""cannot infer type arguments for AttributeKey<> reason: cannot infer type-variable(s) T (actual and formal argument lists differ in length) where T is a type-variable: T extends Object declared in class AttributeKey"" I don't get it... Am I missing something? There are no other questions about this however other questions do successfully use AttributeKey in this way. Specs: Netty 4.1.0 - netty-all-4.1.0.Beta1.jar JDK 1.8 Update: Alright so I have downgraded the version to 4.0.21 Final and apparently AttributeKey<>("""") is deprecated however I cannot find any further information on this. Anyone knows the replacement/alternative for this in the 4.1.0 version? It works in 4.0.21 Final by the way. Short answer: There's no `AttributeKey(String)` in netty 4.1 use `AttributeKey.valueOf(String)`. Additional information: https://github.com/netty/netty/issues/1824 Alright. Quoting the user 'Mics': Short answer: There's no AttributeKey(String) in netty 4.1 use AttributeKey.valueOf(String). Additional information: github.com/netty/netty/issues/1824 Thanks for the answer."
600,A,"Simple Netty handler iterate through message byte by byte Is there an example of a very barebones Netty handler which simply gets whatever data is sent on the wire and writes it to a file? I was thinking of something along the lines of this: public class SimpleHandler extends SimpleChannelUpstreamHandler { public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { HttpRequest request = (HttpRequest) e.getMessage(); // get data from request and write to a file } Any ideas? Thanks for any thoughts I wrote one of these for testing a while back: public class FileWriterHandler extends SimpleChannelHandler { private final String filename; public FileWriterHandler(String filename) { this.filename = filename; } @Override public void messageReceived(ChannelHandlerContext context MessageEvent event) { ChannelBuffer buffer = (ChannelBuffer)event.getMessage(); byte[] bytes = new byte[buffer.readableBytes()]; buffer.readBytes(bytes); try { DataOutputStream stream = new DataOutputStream(new FileOutputStream(filename true)); stream.write(bytes 0 bytes.length); stream.flush(); stream.close(); } catch (IOException ex) { throw runtime(ex); } } } This is just for test hence i'm just re-throwing exceptions and not really dealing with them properly. Hope that's helpful. You would set this up as follows: ServerBootstrap bootstrap = initializedSomehow(); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() { return pipeline(new FileWriterHandler(""yourfile.txt"")); } });  You could also just use this method to transfer the content of the ChannelBuffer to an OutputStream: http://netty.io/docs/stable/api/org/jboss/netty/buffer/ChannelBuffer.html#readBytes(java.io.OutputStream%20int) So something like this: public class FileWriterHandler extends SimpleChannelHandler { private final String filename; public FileWriterHandler(String filename) { this.filename = filename; } @Override public void messageReceived(ChannelHandlerContext context MessageEvent event) throws Exception{ ChannelBuffer buffer = (ChannelBuffer)event.getMessage(); FileOutputStream out = null; try { out = new FileOutputStream(filename true) buffer.readBytes(out buffer.readableBytes()); } finally { if (out != null) out.close(); } } }"
601,A,Best approach in Netty for server-side scheduled tasks/events I'm trying to implement a server-application in Netty 4.0 that communicates to the clients via TCP/IP Socket. The client will make an initial connection once connection is established. The server will send a ping message to the client every X minutes X can be different for each client. Once the client gets the 'ping' successfully the client will try to upload/transfer a file to the server. The server receives the file and writes it to disk. I'm wondering what would be be the best approach in Netty to do this mainly the scheduling part (sending the ping message at a cron basis and receiving the file) I've looked around online and found there is a Uptime ClientHandler example that connects to server on a timely basis but that's a client and it's using some method in ClientBootstrap as well (https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/uptime/UptimeClientHandler.java#L78) I've also found a http://netty.io/4.0/api/io/netty/util/HashedWheelTimer.html but couldn't find any useful examples that elaborates the usage in Netty 4.0. Any help would be greatly appreciated thank you very much!! Basically you would either use the IdleStateHandler[1] and a ChannelStateHandler implementation which will react on the IdleStateEvent or using directly the eventLoop of the Channel. For example the eventLoop usage could be like this: Channel channel = ... channel.eventLoop().schedule(new PingTask delay time unit); [1] http://netty.io/4.0/api/io/netty/handler/timeout/IdleStateHandler.html thanks Norman! I'll look into this doc also does it make sense to do this? when the initial connection between server and client is established create a Netty client that connects to the remote address(original server becomes the client and original client becomes the server) let the client do rest of the work (similar to that upTimeClient) It all depends on what exactly you want to do.. but basically yes you can do something like this
602,A,"How best to specify a Protobuf for use with Netty (preferably using the built-in protobuf support) I'm specifying a protocol in protocol buffers. The transport layer is harnessing Netty's Protocol Buffers support - the significance being that Netty's ProtobufDecoder accepts one and only one type of MessageLite. Now I want to send a variety of different message types down this channel each subtype having structured information associated with it. Protocol-buffers doesn't have an inheritance mechanism so I'm using a kind of composition. I'm not sure if I am going about it the correct way. My approach has been to categorise my different events with an enum and encapsulate their differences using optional members. See my .proto below I've simplified it for the sake of clarity. My issue here is that the receiving code needs to make the association between EventType.ERROR and ErrorEventDetail. This just feels a little clumsy. Simplified Events.proto: package events; option java_package = ""com.example""; option java_outer_classname = ""EventProtocol""; message Event { enum EventType { START = 0; DELEGATE = 1; ERROR = 2; STOP = 3; } required events.Event.EventType event_type = 1 [default = START]; required int32 id = 2; required int64 when = 3; optional StartEventDetail start_event_detail = 4; optional DelegateEventDetail delegate_event_detail = 5; optional ErrorEventDetail error_event_detail = 6; optional StopEventDetail stop_event_detail = 7; } message StartEventDetail { required string object_name = 1; } message DelegateEventDetail { required int32 object_id = 2; required string task = 3; } message ErrorEventDetail { required string text = 1; required int32 error_code = 2; optional Event cause = 3; } message StopEventDetail { required int32 object_id = 2; } Is this optimal? Would I be better off using extends somehow or perhaps some other use of enum? Or even should I be creating a whole new OneToOneDecoder which can identify a message type by some kind of header? I could do this but I'd rather not... Thanks Seems like you are pretty close / already using one of the Google's protobufs techniques which called Union Types The gist is you have a dedicated type field that you would ""switch"" on to know which message to get: message OneMessage { enum Type { FOO = 1; BAR = 2; BAZ = 3; } // Identifies which field is filled in. required Type type = 1; // One of the following will be filled in. optional Foo foo = 2; optional Bar bar = 3; optional Baz baz = 4; } where Foo Bar and Baz are/could be defined in other files as separate messages. And you can switch on the type to get the actual payload (it's Scala but you can do the same thing with Java's switch): OneMessage.getType match { case OneMessage.Type.FOO => val foo = OneMessage.getFoo // do the processing true case OneMessage.Type.BAR => val bar = OneMessage.getBar // do the processing true case OneMessage.Type.BAZ => val baz = OneMessage.getBaz // do the processing true } thanks very much I missed the doc about Union Types. Good to know I'm on the right track. Cheers I've actually changed my definition now in light of reading up on Union Types. My 'Union' type no longer contains anything but the Type field plus the optional 'subtypes'. Common fields ('id' and 'when' in my example) are now kept in an 'EventCommon' message which is composed into each 'subtype'. So now each 'subtype' contains all necessary data. This seems to work better.  another approach is to use the extension mechanism that protobuf is supporting. I'm using this approach in the situations where the union type is too large.  I originally solved the same problem using the extension mechanism which I document here But I found the code in Java required to deal with extensions was horribly ugly and verbose so I switched to the Union method as described. The code is much cleaner as the generated Java code provides a way to get and build each message in one go. I use two mechanisms for deciding which optional message to extract. I use the switch method also described in another Answer when performance is needed and I use a reflection method when performance is not an issue and I don't want to have to maintain a switch statement I just create a handle(Message) for each message. An example of the reflection method is given below in my case the java wrapper is a class called Commands and is decoded by Netty for me. It first tries to find a handler that has the specific message as a parameter then if that fails it calls a method using the camel case name. For this to work the Enum must be the underscore name of the camel case message. // Helper that stops me having to create a switch statement for every command // Relies on the Cmd enum naming being uppercase version of the sub message field names // Will call the appropriate handle(Message) method by reflection // If it is a command with no arguments therefore no sub message it // constructs the method name from the camelcase of the command enum private MessageLite invokeHandler(Commands.Command cmd) throws Exception { Commands.Command.Cmd com= cmd.getCmd(); //String name= CaseFormat.UPPER_UNDERSCORE.to(CaseFormat.LOWER_UNDERSCORE com.name()); String name= com.name().toLowerCase(); jlog.debug(""invokeHandler() - Looking up {} from {}"" name com.name()); FieldDescriptor field= Commands.Command.getDescriptor().findFieldByName(name); if(field != null) { // if we have a matching field then extract it and call the handle method with that as a parameter Object c = cmd.getField(field); jlog.debug(""invokeHandler() - {}\n{}"" c.getClass().getCanonicalName() c); Method m = getClass().getDeclaredMethod(""handle"" String.class c.getClass()); return (MessageLite) m.invoke(this cmd.getUser() c); } // else we call a method with the camelcase name of the Cmd this is for commands that take no arguments other than the user String methodName= ""handle""+CaseFormat.UPPER_UNDERSCORE.to(CaseFormat.UPPER_CAMEL com.name()); jlog.debug(""invokeHandler() - using method: {}"" methodName); Method m = getClass().getDeclaredMethod(methodName String.class); return (MessageLite) m.invoke(this cmd.getUser()); } nice use of reflection! :D"
603,A,Using Netty inside JBoss 7 AS I want to implement simple socket client using ChannelPipelineFactory inside JBoss 7.0.2 AS. So I added org.jboss.netty module in standalone.xml file but deploying my war file causes java.lang.NoClassDefFoundError: org/jboss/netty/channel/ChannelPipelineFactory exception! How can I make Netty library available for my war file? My another question is may I use JMS for TCP/IP socket communication inside JBoss Application Server ? There's a good chance JBoss 7 already contains Netty as one its own libraries. Have you looked in the included JAR files? JBoss Contains Netty but I can't figure out how to use it in my own web app! You can find some Netty library in JBoss in the modules/org/jboss/netty/main directory. But I have no idea how it works inside JBoss. Yes the Netty library is there and as I said I tried to enable it by adding it to modules in JBoss configuration file but it didn't work.  Well I found the solution based on http://community.jboss.org/wiki/JBossWS-AS7FAQ I only needed to add Netty dependency to 'MANIFEST.MF' in 'META-INF' folder of my war file as: dependencies: org.jboss.netty
604,A,"How to secure a socket server with spring security? I want to secure a new client server system based on spring with spring-security and (preferably) method-based security annotations. there are many spring examples for web-apps but so far i didn't find one for non-web java apps. Basicly i want to handle security for a netty socket in a way that is transparent for my management beans. For example: authenticate the user of the connection once in a netty handler and leave the complete authorization to spring-security and the annotations on my management beans. is something like this possible? EDIT i found an example that uses spring-security in junit integration tests i guess i could do it like that but i wouldn't be able to use IoC for my facades so i'm not that fond of the idea. Answer is not related to spring security but if it is just ""securiy"" that you are worried about take a look at apache shiro. I have seen some documentation which says that it can secure at socket level Howerver cant find it out now...:(  Spring Security supports authentication handling at the method level using annotations. You could try the @PreAuthorize annotation as described in ""Access Control using @PreAuthorize and @PostAuthorize"" - though I am unsure on how to get the proper security context in place before the method is called. the secury context is exactly the point where i'm woried. the best example that contains what i want (at least partly) is http://affy.blogspot.de/2005/10/acegi-tutorial-example-of-method-based.html but i was hoping for something simpler and more transparent. In the example you mention they are manually setting up the context using the `createSecureContext` method they wrote in the test class. How do you handle authentication in you application? Maybe you could hook up your login / handshake in order to set up the security context similar to the example. you are right. according to the documentation SecurityContextHolder.getContext() hold (by default) the context for the current thread. since netty spawns a thread per connection this should work. i will test this solution works. authentication of the current thread is a bit messy since i have to access the authentication provider directly but i can now usemethod security.  While I am sure you could hack something together to get it to work in general Spring Security is heavily focused on securing web servers. In particular this focus is evident in the filter-chain architecture of the system that stems from having a filter delegate in web.xml. I don't remember off-hand if there is a dependency within the core filter chain on there being an httpRequest object that gets passed up and down the chain but if you are going to try to wrap Spring Security around a socket putting an adapter in place at that point would be a likely place to start. So in short I would think it's possible but it's definitely not going to be easy and likely wont get you much benefit since a large portion of the architecture and default security pieces expects to be wrapped around a web request. can you recommend an alternative? i really don't want to handle security by hand. and since i want to use spring as an IoC-Framework spring security looked like a good idea. I don't really know of anything better than Spring Security so your best bet _may_ just be to hack at the authentication sub-system until you can get it plugged in to what you need and then use the authorization system as-written (which should work just fine as long as the user is authenticated)"
605,A,"Are there any Java binary protocols that are faster than RMI? Is RMI the king (speed-wise) of the binary networking protocols or are there others out there with higher benchmarked speeds? Is it possible to use something like Netty to build my own binary (TCP) protocol that would be faster? I'm new to networking and trying to wrap my head around the various libraries and frameworks that are available. Thansk in advance! If you are 'new to networking' then you certainly do not want to build your own protocol! There are advantages when troubleshooting to be able to read the messages. Protocal Buffers are one the the most compact ways of serializing java objects. Depending on your needs you can combine that with your own transport protocol (raw tcp sockets udp http..) Thanks @Andreas Petersson (+1) - please look at my question underneath Charles Forsythe's answer - I have the same question for you!  RMI needs to process metadata and it uses reflection. If you implement a custom protocol based on TCP and DataOutputStream / DataInputStream it may be faster than RMI. Assuming we have an RMI Service  Service srv = (Service) Naming.lookup(lookupString); srv.sayHi(""Jack""); srv.sayBye(""Back""); We can do the same sending a command and param directly thru TCP connection  ObjectOutputStream out = ... out.write(0); // 0 - Hi command out.writeUTF(""Jack""); out.write(1); // 1 - Bye command out.writeUTF(""Jack""); Thanks @Evgeniy Dorofeev (+1) - please look at my question underneath Charles Forsythe's answer - I have the same question for you! It would be more accurate to say that Object Serialization uses reflection and that RMI uses Object Serialization. It would also be better to remove the word 'generic' which has a specific and different meaning in Java it doesn't add anything here.  RMI's speed is governed by two things: Default Java serialization Distributed garbage collection Default Java serialization can be surprisingly bloated. You can make your object serialization more lightweight by implementing Externalizale and doing your own bare-bones serialization. This already start to look like doing a custom protocol. Distributed Garbage Collection can become a factor if your system grows large and contains many JVMs. DGC involves JVMs exchanging messages alerting each other about objects which are subject to garbage collection. It can potentially create a lot of network traffic. That said RMI ""out of the box"" can be faster than other ""out of the box"" alternatives. For example SOAP can be much less efficient on the wire and involves a much deeper and heavier network stack than RMI. You can build a faster custom RPC than RMI but if you rely on Java serialization it probably won't be much faster because of point #1 above. Finally why do you want a faster protocol? Are you having problems with the speed of RMI? Are you looking to pick the fastest ""out of the box"" solution upfront? Keep in mind The rules of Optimize Club. Thanks @Charles Forsythe (+1) - I found [this](http://stackoverflow.com/questions/817853/what-is-the-difference-between-serializable-and-externalizable-in-java) after googling ""serializable vs externalizable"" and according to the leading answer JBoss has their own serialization mechanism that is a ""drop-in"" replacement for the one that ships with the JDK. Do you know anything about this? What does it mean to be a ""drop-in"" replacement. I might be just as well using RMI with this (optimized) JBoss serializer... and thanks again! Also it looks like there are serializers that are much faster than JBoss (take look [here](https://github.com/eishay/jvm-serializers/wiki)). According to this [kryp](http://code.google.com/p/kryo/) is the king of the serializers. So the same question as above can kryo be ""dropped in"" to replace JRE serialization but still use RMI as the protocol? If so how? Thanks again! No it isn't. RMI uses Object Serialization and nothing else. RMI's speed is also governed by DNS and by network bandwidth of course. I don't see that DGC has much to do with it it happens out-of-band."
606,A,difference between bound and connected socketchannelState in Netty I am trying to understand the difference between ChannelStates provided by Netty viz. CONNECTED and BOUND. netty url here when does channelConnected() gets called and when channelBound() gets called Binding precedes connecting. Binding is the step where an IP address and port are associated with the socket. It is typically only an explicit step for a listening socket. Connection takes place when a socket is either connected to a server or accepted from a client. In the latter case the bind and connect steps are usually combined or rather the bind is done implicitly by the connect call.
607,A,"Automatic routing filter rejected remote request - Nexus I'm trying to get the netty-codec-hhtp going in my maven project. I have a completely standard Sonatype Nexus set up to proxy requests to Maven Central. <dependency> <groupId>io.netty</groupId> <artifactId>netty-codec-http</artifactId> <version>4.0.9.Final</version> </dependency> This fails when building using maven. If I search for it manually in Nexus I find it but if I go to download the jar it tells me: 404 - Not Found Automatic routing filter rejected remote request for path /io/netty/netty-codec-http/4.0.9.Final/netty-codec-http-4.0.9.Final.jar from M2Repository(id=central) What does this even mean why am I getting it and maybe more importantly how do I fix it? I am using Nexus 2.5.0-04 with Maven 3.0.4 Downloading other artifacts seems to work just fine. How are you ""downloading"" the jar so you get that error message? And how up to date is your Central index and prefix file download? Also I know there were some automatic routing related fixed in recently releases so I would test with 2.6.3-01 and see if that fixes it. UPDATE: This turned out to be an issue with CDN configuration that should now be resolved. The steps below for forcing and/or disabling remote discovery are left for reference. It means that Automatic Routing for Central is active and that the discovered rules does not contain io.jetty as allowed prefix. This should not happen as the default configuration should update the rules on daily basis (as seen on screenshot below showing the default Automatic Routing configuration for Central). The remedy is to either force the update of rules (I did check prefix /io is among rules Central publishes) or disable remote discovery completely. Try steps as shown below on screenshot: I had to disable Discovery even though it said successful. Downloads immediately working.  From Repository Management with Nexus - 6.4. Managing Routing: Routing can be considered the internal activities Nexus perform in order to determine where to look for a specific component in a Maven repository. The routing information has an impact on the performance of component retrieval as well as determining the availability of components. (...) Automatic Routing is handled by Nexus on a per repository basis. (...) The Routing information consists of the top two levels of the directory structure of the repository and is stored in a prefixes.txt file. It allows Nexus to automatically route only component requests with the corresponding groupId values to a repository to avoid unnecessary index or even remote repository access. Since Maven central repo contains that artifact I assume that the automatic routing rules forbids remote download for that artifact. The error message you posted suggests it also. You can read how to add a routing rule under 6.4.2. Manual Routing Configuration. If my assumption is correct this situation shoud be resolved by adding an inclusive rule type with ^/io/netty/.* route for central repo. I don't have Nexus installed but as much as I can remember it is not necessary to restart a save should be enough. Do try however you have nothing to lose. I agree that bypassing Nexus or installing manually is not the solution. You might try with an exclusive rule for local repos also. Thanks but it still doesn't work. If i bypass nexus it works fine but that kind of defeats the purpose of having Nexus as a local proxy in the first place. The most frustrating thing is that I can browse it just fine through nexus but because it is ""not locally cached"" I get an error message instead. I realize we can always just manually install the artifact into the nexus release repo manually but that defeats the point even further. Do I have to restart nexus or something for routing rules to take effect?"
608,A,Threading in Netty ZlibEncoder I am working on creating a Snappy Encoder and Decoder for Netty. I am looking at ZlibEncoder to see how it is implemented but noticed that ChannelHandlerContext is volatile finished is an AtomicBoolean and z (ZStream) has a sync block. My question is why? Since a new ZlibEncoder is created for each channel why are these needed? thanks dave Its needed because downstream events can be triggeres by any thread (for example writes). Upstream events are only executed by one thread and so its not needed there (a Decoder only handles upstream events) Ah that makes sense. Thanks Norman! BTW I guess we would be interested in a Snappy encoder / decoder. So if you are interested in contributing I would be happy to review it and pull it into netty for the next release ;) Sounds good. I'll let you know when it is ready.
609,A,Netty 4: Processing both HTTP and HTTPS I'd like to process HTTP connections to port 80 and HTTPS to port 443 with shared handler. What I do currently is creating two separate ServerBootstraps ChannelInitializers share the instance of my handler and one of them adds SslHandler to the pipeline. Is there a better way to do this? If using this way can I share EventLoopGroups to reduce thread usage (I have pretty small number of concurrent connections)? Is there something I should note when doing this with OIO/NIO/AIO when sharing parent and child groups? Thanks! Yeah you can share the EventLoops and probably should even do it.. The rest of what you do sounds like the way to go.
610,A,"Distinguish a connection between HTTP and a simple string protocol using Netty I'm trying to distinguish a new connection as an HTTP or framer/string based connection using Netty and I want to use the same server port for both. For now I simply look for ""GET "" etc. in the first line. However when using a DelimiterBasedFrameDecoder I keep receiving String contents even when decoders and encoders are replaced with the HTTP ones. I tryed overriding handleUpstream messageReceived fireing events and converting lost messages back to channelbuffers etc. but I had no luck. I also tried to implement a single handler that looks into the first received channelbuffer but I am not able to create a working pipeline afterwards. Any suggestions? Have a look on port unification example. You don't have to start from scratch just modify the PortUnificationServerHandler based on your content type or protocol and add your string protocol encoder/decoders there. Thanks alot I'll give it a try!"
611,A,"Share Integer globally I'm learing Netty and i'm trying to implement a simple counter where all the clients shares an Integer and they input a number and the Integer value increments by that number. Here is my code: Server.java package nettyincvalue; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioServerSocketChannel; import java.util.logging.Level; import java.util.logging.Logger; public class Server { private int port; private Integer value; public Server(int port) { this.port = port; this.value = 0; } public void run(){ EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap server = new ServerBootstrap(); server.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ServerInit(this.value)) .option(ChannelOption.SO_BACKLOG 128) .childOption(ChannelOption.SO_KEEPALIVE true); ChannelFuture f = server.bind(port).sync(); f.channel().closeFuture().sync(); } catch (InterruptedException ex) { Logger.getLogger(Server.class.getName()).log(Level.SEVERE null ex); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) { new Server(12345).run(); } } ServerInit.java package nettyincvalue; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; import io.netty.handler.codec.string.StringDecoder; public class ServerInit extends ChannelInitializer<SocketChannel> { private Integer value; public ServerInit(Integer value) { this.value = value; } @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new StringDecoder()); pipeline.addLast(new ServerHandler(this.value)); } } ServerHandler.java package nettyincvalue; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; public class ServerHandler extends ChannelInboundHandlerAdapter { private Integer value; public ServerHandler(Integer value) { this.value = value; } @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { String s = (String) msg; try { Integer i = Integer.parseInt(s.substring(0 s.length() - 1)); this.value += i; System.out.println(""Value its now: "" + this.value); } catch (NumberFormatException n) { System.out.println(""Not a number received""); } } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) throws Exception { System.err.println(cause.getMessage()); ctx.close(); } } Individually its working when a client inputs via nc a number it increments but its not globally i mean when a different client starts the counter its set to 0. Your variable doesn't have proper synchronization; it should generally be declared volatile to make sure that all threads see updated values and you'll need to synchronize the blocks where you're using it. However in your case using an AtomicInteger will be simpler and more efficient. Right Java Integers are immutable objects and it doesn't make a sence to share it. @JoséRicardoRibeiro You'll still have the problem with the classic read(threadA)-read(threadB)-update(threadA)-update(threadB but loses threadA's update) scenario. That's exactly what `AtomicInteger#addAndGet()` avoids. As a note `AtomicInteger` *is* a part of the core Java library since Java 5 so make sure that you can't still use it. Thanks! I didnt know about AtomicInteger. But since this is an academic exercise i solved this problem encapsulating an int inside my own class and it works i only get this problem when using int or Integer. Just a quick question will i have concurreny problems with this solution or i'll need to synchronize the increment method?"
612,A,Determine how much was written to a ChannelBuffer Netty I'm using a DynamicChannelBuffer I'm doing some outputting inside this buffer and I would like how many bytes were written. How should I get this information ? Many thanks Radu. Look at these methods: writerIndex() readableBytes() markWriterIndex() Most likely readableBytes() will give you the answer but that depends on what you do with your buffer. Done ! writerIndex did the job
613,A,"Sending precompressed data through Netty's HTTP handlers I have a scenario where a Netty server has a GZIP'd buffer and I'd like to send it as part of a chunked response without inflating/deflating. By way of illustration: imagine I have three parts: ChannelBuffer jsonp = ""callback("" ChannelBuffer gzippedData = <gzipped bytes> ChannelBuffer jsonpend = "")"" I'd like HttpContentCompressor to skip gzippedData but handle the other chunks. I don't see an obvious way to do this after reading the code. Suggestions? I think you would need to have your own version of HttpContentCompressor for this. By default it will not do what you want. Interesting link: http://stackoverflow.com/questions/16740034/http-how-to-send-multiple-pre-cached-gzipped-chunks#comment27831334_16740510 - turns out only Opera supports this."
614,A,Weird indexOutOfBound erro from Netty's ChannelBuffer.read? I have the following simple code in my netty project it expects to read an integer from the upstream. No encoder is in the pipeline. public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { ChannelBuffer m = (ChannelBuffer) e.getMessage(); m.readInt() } When the data comes in from the network the method is fired correctly (good sign) but when attempting to read it gives the following error: java.lang.IndexOutOfBoundsException at org.jboss.netty.buffer.AbstractChannelBuffer.checkReadableBytes(AbstractChannelBuffer.java:657) at org.jboss.netty.buffer.AbstractChannelBuffer.readInt(AbstractChannelBuffer.java:272) at PushServer.Netty.PushClientHandler.messageReceived(PushClientHandler.java:33) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:349) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:281) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:201) at org.jboss.netty.util.internal.IoWorkerRunnable.run(IoWorkerRunnable.java:46) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:637) Any ideas? Checkm for `m.readable()`. Perhaps you don't have a decoder in your pipeline? Even if your peer wrote 4 bytes you might get less than 4 bytes and therefore there is high chance of getting an IOOBE. Actually a section in the official user guide explains exactly same case.
615,A,Can HttpClientCodec/HttpServerCodec and HttpObjectAggregator be removed after websocket handshake completes? I'm in the process of load testing a high performance websocket gateway application which supports 100K+ client websockets. The requests are ALL Binary websocket messages and use our own Codec go to/from byte[] and our POJO. The application is using Netty 4.0.12 on JDK 1.7.0_45. I would like to make the websocket channel pipeline as efficient as possible to provide the maximum throughput with the least CPU utilization. The first thought is to remove any unnecessary handlers. The second will be to make sure our custom codec is working with the byte[]/ByteBuf properly but that will be another post. As a result I wanted to see if the HTTP-related pipeline handlers can be removed from a newly created client/server channel once the websocket handshake is complete. I'm assuming the websocket netty plumbing doesn't need any HTTP stuff so please let me know if that's a wrong assumption. If I can remove these programmatically would you please let me know where in the pipeline that is typically done. Thanks Bob It is automatically removed for you after the handshake was completed. So no need for you to do it. Excellent thanks
616,A,Netty simple file upload server support for HTTP PUT Using this example I am able to receive files via HTTP POST but I would like to be able to receive files via HTTP PUT instead. Is there a way to do this with Netty? There is a HttpPostRequestDecoder but nothing equvilent for put as far as I can tell. https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/http/upload/HttpUploadServerHandler.java The githib link is dead any chance can you fix? The HttpPostRequestDecoder handles POSTPUT and PATCH. See [1]. [1] https://github.com/netty/netty/blob/master/codec-http/src/main/java/io/netty/handler/codec/http/HttpPostRequestDecoder.java#L166
617,A,"Netty server sending RST request to android client when try to connect I wrote a small netty server program. It is working with all phones but server sends RST request for only android mobile(Client). And some times working fine but some times got the problem. Help me.  ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); bootstrap = new ServerBootstrap(factory); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { // new SslHandler(getSSLEngine()) return Channels.pipeline( new MobileDecoder() new MobileChannelHandler(MobileMessageHandler .getInstance())); } }); bootstrap.setOption(""child.tcpNoDelay"" true); bootstrap.setOption(""child.keepAlive"" true); bootstrap.bind(new InetSocketAddress(9083)); Simply Not getting connect no error. Where is the problem ? what error are you experiencing ? You might want to try OioServerSocketChannelFactory. A lot of Android devices were shipped with buggy NIO implementation."
618,A,"Server Chat to all Client Online/Connected Netty i have little trouble. I'm stuck at broadcast message using chat from server to client using Netty I'll already can chat from client to server and autoreplay from server (using handling) now what i want is Server can chat like client and broadcast it to all client(channel active). I'm trying to copy from my client but it didn't work Channel channel = boostrap.bind(port).sync().channel(); BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); while(true) { channel.writeAndFlush(in.readLine() + ""\r\n""); } Sorry about Android tag because later I want to use this code Client on Android Considering Nio doesn't work on Android but Oio work. i include all code of my work //ChatServer.java public class ChatServer { private final int port; public static void main(String[] args) throws Exception { System.out.println(""Server Started at "" + InetAddress.getLocalHost().getHostAddress() + "" port "" + 9999); new ChatServer(9999).run(); } public ChatServer(int port) { this.port = port; } public void run() throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap boostrap = new ServerBootstrap() .group(bossGroupworkerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChatServerInitializer()); Channel channel = boostrap.bind(port).sync().channel(); // channel.closeFuture().sync(); BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); while(true) { channel.writeAndFlush(in.readLine() + ""\r\n""); } }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } . // ChatServerHandler.java public class ChatServerhandler extends SimpleChannelInboundHandler<String> { private static final ChannelGroup channels = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE); @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { Channel incoming = ctx.channel(); for (Channel channel: channels) { channel.writeAndFlush(""[SERVER] "" + incoming.remoteAddress() + "" has joined \n""); } channels.add(ctx.channel()); } @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { Channel incoming = ctx.channel(); for (Channel channel: channels) { channel.flush(); channel.writeAndFlush(""[SERVER] "" + incoming.remoteAddress() + "" has left \n""); } channels.remove(ctx.channel()); } @Override protected void channelRead0(ChannelHandlerContext ctx String msg) throws Exception { Channel incoming = ctx.channel(); System.out.println(""["" + incoming.remoteAddress() + ""] "" + msg + ""\n""); for (Channel channel: channels) { if(channel != incoming) { channel.writeAndFlush(""["" + incoming.remoteAddress() + ""] "" + msg + ""\n""); } } } } . //ChatServerInitializer.java public class ChatServerInitializer extends ChannelInitializer<SocketChannel> { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""handler"" new ChatServerhandler()); } } . //ChatClient.java public class ChatClient { private final String host; private final int port; public static void main(String[] args) throws Exception { System.out.println(""Client Started conntected to "" + ""192.168.0.61:9999""); new ChatClient(""192.168.0.61"" 9999).run(); } public ChatClient(String host int port) { this.host = host; this.port = port; } private void run() throws Exception { EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap() .group(group) .channel(NioSocketChannel.class) .handler(new ChatClientInitializer()); Channel channel = bootstrap.connect(host port).sync().channel(); BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); while(true) { channel.writeAndFlush(in.readLine() + ""\r\n""); } }finally { group.shutdownGracefully(); } } } . // ChatClientHandler.java public class ChatClienthandler extends SimpleChannelInboundHandler<String>{ @Override protected void channelRead0(ChannelHandlerContext ctx String msg) throws Exception { System.out.println(msg); } } . // ChatClientInitializer.java public class ChatClientInitializer extends ChannelInitializer<SocketChannel>{ @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""handler"" new ChatClienthandler()); } } You should move your code from handlerAdded to channelActive and from handlerRemoved to channelInactive. This should do the job I think.  Ok i found for my case I must create new thread in order to make server can chatting like client. Create a new thread for server before it's close sync im using ChatServerBroadcast. then call it direct to handler using static to send to all channels active. ChatServer.java/run  ChannelFuture f = boostrap.bind(PORT).sync(); ChatServerBroadcast cst = new ChatServerBroadcast(); f.channel().closeFuture().sync(); ChatServerBroadcast.java public class ChatServerBroadcast implements Runnable{ private String message = """"; public ChatServerBroadcast() { new Thread(this).start(); } @Override public void run() { BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); System.out.println(""Ready to chat ""); while(true) { try { message = in.readLine(); } catch (IOException e) { message = """"; } if(!message.isEmpty()) { message = ""[SERVER BROADCAST] "" + message + ""\r\n""; ChatServerhandler.sendServerMessage(message); message = """"; } } } } ChatServerHandler.java/sendServeMessage(String) public static void sendServerMessage(String message) { if (channels.isEmpty()) { return; } channels.writeAndFlush(message); } Maybe it can help someone looking answer in case like me."
619,A,Writing a java server for queueing incoming HTTP Request and processing them a little while later? I want to write an Java Server may be using Netty or anything else suggested. The whole purpose is that I want to queue incoming HTTP Request for a while because the systems I'm targeting are doing Super Memory and Compute intensive tasks so if they are burdened with heavy load they eventually tend to get crashed. I want to have a queue in place that will actually allow only max upto 5 requests passed to destination at any given time and hold the rest of the requests in queue. Can this be achieved using Netty in Java I'm equally open for an implementation in Scala Python or clojure. I did something similar with Scala Akka actors. Instead of HTTP Request I had unlimited number of job requests come in and get added to a queue (regular Queue). Worker Manager would manage that queue and dispatch work to worker actors whenever they are done processing previous tasks. Workers would notify Worker Manager that task is complete and it would send them a new one from the queue. So in this case there is no busy waiting or looping everything happens on message reception. You can do the same with your HTTP Requests. Akka can be used from Scala or Java and a process I described is easier to implement than it sounds. As a web server you could use anything really. It can be Jetty or some Servlet Container like Tomcat or even Spray-can. All it needs to do is to receive a request and send a message to Worker Manager. The whole system would be asynchronous and non-blocking.
620,A,"Can't get the latest version of a library I'm using Eclipse Juno SR1 and I think the integrated m2e plugin uses Maven 3 but I'm not sure. Netty has recently published the 4.0.0.Beta1 version but I can't seem to update it via Maven -- Eclipse's m2e plugin. I've opened the pom.xml file -> Dependencies tab -> Add -> searched for netty. It could only find the previous version 4.0.0.Alpha8. I've tried updating (forcefully) the dependencies. I've tried manually delete the contents of the m2e's local (cache) repository directory and rebuilding the index from scratch. I've manually edited the pom.xml This works now! Still I can't download the latest version even though it's clearly been published to the central repo here. EDIT: This SO question seems similar to mine. I've tried the solution provided by the answer (as mentioned above) but it didn't work. EDIT: Ah! Indeed they've changed the artifactId from netty to netty-all! So getting the latest version manually now works but I still wish I could find it with the dependency search window thing. Do you use Nexus as proxy? What is exactly artifactId you are using. Add declaration to this post. (1) I'm unsure what that means. I use the default settings that came with Eclipse. (2) I've used the old artifactId that seems to have been changed from `netty` to `netty-all`! Look carefully at artifactId. Maybe it was changed from Alpha to Betta. <dependency> <groupId>io.netty</groupId> <artifactId>netty-common</artifactId> <version>4.0.0.Beta1</version> </dependency> 2) Create new Maven project and try to play and find out if you can't download other jars. For me it worked for netty-common artifact. Before I accept this answer I'll ask whether you know why I couldn't find the newly added artifactId `netty-all` in the ""add dependency window"" but adding it manually to the `pom.xml` worked? ""add dependency window"" will search in your local maven repository not remote. Yeah but I forcefully updated (by manually deleting the local repo files and redownloading that ~90MB .gz file) my local maven repo. At least I thought I did."
621,A,"Send multiple asynchonous requests on a Netty client first let me explain the context : I've got to create a client which will send many HTTP requests to download images. These requests has to be asynchronous because as soon as an image is completed it'll be added to a queue and then print to screen. Because images can be large and responses chunked my handler have to aggregate it into a buffer. So I follow the Netty examples codes (HTTP spoon example). Currently I've got three static Map to store for each channels the channel ID and the buffer/chunk boolean/my final object. private static final ConcurrentHashMap<Integer ChannelBuffer> BUFFER_MAP = new ConcurrentHashMap<Integer ChannelBuffer>(); private static final ConcurrentHashMap<Integer ImagePack> PACK_MAP = new ConcurrentHashMap<Integer ImagePack>(); private static final ConcurrentHashMap<Integer Boolean> CHUNKS_MAP = new ConcurrentHashMap<Integer Boolean>(); After that I create my bootstrap client and counter to countDown the number of pending requests. The final queue and the counter are passed to my Handler for when the response image is complet.  final ClientBootstrap bootstrap = new ClientBootstrap( new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); bootstrap.setOption(""keepAlive"" true); bootstrap.setOption(""tcpNoDelay"" true); bootstrap.setOption(""reuseAddress"" true); bootstrap.setOption(""connectTimeoutMillis"" 30000); final CountDownLatch latch = new CountDownLatch(downloadList.size()) { @Override public void countDown() { super.countDown(); if (getCount() <= 0) { try { queue.put(END_OF_QUEUE); bootstrap.releaseExternalResources(); } catch (InterruptedException ex) { LOGGER.log(Level.WARNING ex.getMessage() ex); } } } }; bootstrap.getPipeline().addLast(""codec"" new HttpClientCodec()); bootstrap.getPipeline().addLast(""handler"" new TileClientHandler(queue latch)); After that I create a Channel for each image to download and when the channel is connected the request will be created and send. The host and port have already been extracted before. for (final ImagePack pack : downloadList) { final ChannelFuture future = bootstrap.connect(new InetSocketAddress(host port)); future.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture cf) throws Exception { final Channel channel = future.getChannel(); PACK_MAP.put(channel.getId() pack); final HttpRequest request = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.GET pack.url); request.setHeader(HttpHeaders.Names.HOST host); request.setHeader(HttpHeaders.Names.CONNECTION HttpHeaders.Values.CLOSE); request.setHeader(HttpHeaders.Names.ACCEPT_ENCODING HttpHeaders.Values.BYTES); if (channel.isWritable()) { channel.write(request); } } }); } Now this is my ChannelHandler which is an inner class that extend SimpleChannelUpstreamHandler. When the channel is connected a new entry in BUFFER_MAP and in CHUNKS_MAP is created. The BUFFER_MAP contains all the images buffers used by the handler to aggregate image chunks from channels and CHUNKS_MAP contains response chunked boolean. When the response is complete the image InputSteam is added to the queue the latch count down and the channel closed. private class TileClientHandler extends SimpleChannelUpstreamHandler { private CancellableQueue<Object> queue; private CountDownLatch latch; public TileClientHandler(final CancellableQueue<Object> queue final CountDownLatch latch) { this.queue = queue; this.latch = latch; } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { if(!BUFFER_MAP.contains(ctx.getChannel().getId())){ BUFFER_MAP.put(ctx.getChannel().getId() new DynamicChannelBuffer(50000)); } if(!CHUNKS_MAP.contains(ctx.getChannel().getId())){ CHUNKS_MAP.put(ctx.getChannel().getId() false); } } @Override public void writeComplete(ChannelHandlerContext ctx WriteCompletionEvent e) throws Exception { super.writeComplete(ctx e); if(!BUFFER_MAP.contains(ctx.getChannel().getId())){ BUFFER_MAP.put(ctx.getChannel().getId() new DynamicChannelBuffer(50000)); } if(!CHUNKS_MAP.contains(ctx.getChannel().getId())){ CHUNKS_MAP.put(ctx.getChannel().getId() false); } } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { final Integer channelID = ctx.getChannel().getId(); if (!CHUNKS_MAP.get(channelID)) { final HttpResponse response = (HttpResponse) e.getMessage(); if (response.isChunked()) { CHUNKS_MAP.put(channelID true); } else { final ChannelBuffer content = response.getContent(); if (content.readable()) { final ChannelBuffer buf = BUFFER_MAP.get(channelID); buf.writeBytes(content); BUFFER_MAP.put(channelID buf); messageCompleted(e); } } } else { final HttpChunk chunk = (HttpChunk) e.getMessage(); if (chunk.isLast()) { CHUNKS_MAP.put(channelID false); messageCompleted(e); } else { final ChannelBuffer buf = BUFFER_MAP.get(channelID); buf.writeBytes(chunk.getContent()); BUFFER_MAP.put(channelID buf); } } } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) throws Exception { e.getCause().printStackTrace(); latch.countDown(); e.getChannel().close(); } private void messageCompleted(MessageEvent e) { final Integer channelID = e.getChannel().getId(); if (queue.isCancelled()) { return; } try { final ImagePack p = PACK_MAP.get(channelID); final ChannelBuffer b = BUFFER_MAP.get(channelID); p.setBuffer(new ByteArrayInputStream(b.array())); queue.put(p.getTile()); } catch (Exception ex) { LOGGER.log(Level.WARNING ex.getMessage() ex); } latch.countDown(); e.getChannel().close(); } } My problem is when I execute this code I've got these exceptions :  java.lang.IllegalArgumentException: invalid version format: 3!}@ at org.jboss.netty.handler.codec.http.HttpVersion.<init>(HttpVersion.java:108) at org.jboss.netty.handler.codec.http.HttpVersion.valueOf(HttpVersion.java:68) at org.jboss.netty.handler.codec.http.HttpResponseDecoder.createMessage(HttpResponseDecoder.java:110) at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:198) at org.jboss.netty.handler.codec.http.HttpClientCodec$Decoder.decode(HttpClientCodec.java:113) at org.jboss.netty.handler.codec.http.HttpClientCodec$Decoder.decode(HttpClientCodec.java:101) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:470) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:443) at org.jboss.netty.handler.codec.http.HttpClientCodec.handleUpstream(HttpClientCodec.java:77) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:351) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:282) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:202) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662) java.lang.IllegalArgumentException: invalid version format: at org.jboss.netty.handler.codec.http.HttpVersion.<init>(HttpVersion.java:108) at org.jboss.netty.handler.codec.http.HttpVersion.valueOf(HttpVersion.java:68) at org.jboss.netty.handler.codec.http.HttpResponseDecoder.createMessage(HttpResponseDecoder.java:110) at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:198) at org.jboss.netty.handler.codec.http.HttpClientCodec$Decoder.decode(HttpClientCodec.java:113) at org.jboss.netty.handler.codec.http.HttpClientCodec$Decoder.decode(HttpClientCodec.java:101) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:470) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.cleanup(ReplayingDecoder.java:546) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.channelDisconnected(ReplayingDecoder.java:449) at org.jboss.netty.handler.codec.http.HttpClientCodec.handleUpstream(HttpClientCodec.java:77) at org.jboss.netty.channel.Channels.fireChannelDisconnected(Channels.java:360) at org.jboss.netty.channel.socket.nio.NioWorker.close(NioWorker.java:595) at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:101) at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:60) at org.jboss.netty.handler.codec.http.HttpClientCodec.handleDownstream(HttpClientCodec.java:82) at org.jboss.netty.channel.Channels.close(Channels.java:720) at org.jboss.netty.channel.AbstractChannel.close(AbstractChannel.java:200) at org.geotoolkit.client.map.CachedPyramidSet$TileClientHandler.exceptionCaught(CachedPyramidSet.java:515) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:461) at org.jboss.netty.handler.codec.http.HttpClientCodec.handleUpstream(HttpClientCodec.java:77) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:432) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:52) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:351) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:282) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:202) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662) 22 mars 2012 15:27:31 org.jboss.netty.channel.DefaultChannelPipeline ATTENTION: An exception was thrown by a user handler while handling an exception event ([id: 0x3cd16610 /172.16.30.91:34315 :> tile.openstreetmap.org/193.63.75.98:80] EXCEPTION: java.lang.IllegalArgumentException: invalid version format: java.lang.IllegalStateException: An Executor cannot be shut down from the thread acquired from itself. Please make sure you are not calling releaseExternalResources() from an I/O worker thread. at org.jboss.netty.util.internal.ExecutorUtil.terminate(ExecutorUtil.java:71) at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.releaseExternalResources(NioClientSocketChannelFactory.java:171) at org.jboss.netty.bootstrap.Bootstrap.releaseExternalResources(Bootstrap.java:324) at org.geotoolkit.client.map.CachedPyramidSet$1.countDown(CachedPyramidSet.java:314) at org.geotoolkit.client.map.CachedPyramidSet$TileClientHandler.exceptionCaught(CachedPyramidSet.java:514) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:461) at org.jboss.netty.handler.codec.http.HttpClientCodec.handleUpstream(HttpClientCodec.java:77) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:432) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:52) at org.jboss.netty.channel.Channels.fireChannelDisconnected(Channels.java:360) at org.jboss.netty.channel.socket.nio.NioWorker.close(NioWorker.java:595) at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:101) at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:60) at org.jboss.netty.handler.codec.http.HttpClientCodec.handleDownstream(HttpClientCodec.java:82) at org.jboss.netty.channel.Channels.close(Channels.java:720) at org.jboss.netty.channel.AbstractChannel.close(AbstractChannel.java:200) at org.geotoolkit.client.map.CachedPyramidSet$TileClientHandler.exceptionCaught(CachedPyramidSet.java:515) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.exceptionCaught(ReplayingDecoder.java:461) at org.jboss.netty.handler.codec.http.HttpClientCodec.handleUpstream(HttpClientCodec.java:77) at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:432) at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:52) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:351) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:282) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:202) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662) And also some NPE appears some times. java.lang.NullPointerException at org.jboss.netty.handler.codec.http.HttpMessageDecoder.skipControlCharacters(HttpMessageDecoder.java:409) at org.jboss.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:184) at org.jboss.netty.handler.codec.http.HttpClientCodec$Decoder.decode(HttpClientCodec.java:113) at org.jboss.netty.handler.codec.http.HttpClientCodec$Decoder.decode(HttpClientCodec.java:101) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:470) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:443) at org.jboss.netty.handler.codec.http.HttpClientCodec.handleUpstream(HttpClientCodec.java:77) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:351) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:282) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:202) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) All these code works fine for one request but some weird stuff append on buffers when many requests where send. Any ideas what I'm missing here? Thanks. In my first version I duplicate bootstrap/handler for each requested images it works fine but not very optimized. The problem is that you're sharing a single HttpClientCodec between all your channels. The default pipeline specified in the bootstrap is cloned for all channels so each channel sees the same instance of each handler. The http codecs are stateful so you're seeing the effects of different responses getting mixed together. The easiest solution is to pass a ChannelPipelineFactory to the bootstrap. This will be called for each new channel and you can create a pipeline with new instances of HttpClientCodec. There's nothing to stop you using the same instance of TileClientHandler for every pipeline you create if that is how it's intended to work. I'm curious though. Given that you're making each request concurrently wouldn't it be easier to just add HttpChunkAggregator upstream of HttpClientCodec and let Netty aggregate all the chunks into a single HttpResponse. Then you just grab the reassembled content from there? Hi johnstlr thanks for this quick useful answer I now use an ChannelPipelineFactory for instantiate the HTTPCodec dand my Tile handlers. It works fine but i've still got `java.lang.IllegalStateException: An Executor cannot be shut down from the thread acquired from itself. Please make sure you are not calling releaseExternalResources() from an I/O worker thread.` exception. Did you have an idea for that ? And for the information the reason that I didn't use an HttpChunkAggregator is you have to set a buffer size to HttpChunkAggregator constructor. You're calling bootstrap.releaseExternalResources from within CountDownLatch.countDown which is being called from an IO thread in your handler methods. Unfortunately you can't do this. You need to call releaseExternalResources from a thread that isn't in a thread pool being used by Netty. One option might be to call releaseExternalResources in your thread that's reading from your internal queue once it has finished processing the queue. Also you're completely right about HttpChunkAggregator. Sorry!"
622,A,How to use JDBC to maximize performance of Netty? I am developing a HTTP application server using Netty 4 and JDBC(+BoneCP for connection pooling). So far I am doing all the work(works involving database connections HttpAsyncClient and so on) on one handler. I close all I/O after each job is finished. As far as I know Netty performs well as long as nothing is blocking the worker thread. However I read that JDBC connections create blocking I/O. Is there a good practice to use JDBC with Netty to improve scalability and performance? Make sure you have enough connections obviously your workers will block waiting for a connection if your pool is out of connections. The worker will be waiting for a new connection (if the pool is allowed to grow) or waiting for a connection to return otherwise. Otherwise use general best practices. Tune your reads with setFetchSize() and your writes by using batching. Minimize your round trips and fetch only the data you need. Do you have specific code (or a query) that is slow?
623,A,netty websocket + continuous PERIODIC data push What would be the best way to continuously push some data periodically(say every n seconds) from a websocket server in netty? EDIT : I came across this post : Best way to send continuous data in Java using Netty and according to the answerwhile/sleep wouldnt be very scalable how does one schedule a job on an Executor ? WebSocket client connects to your Netty server handshakes and establishes a websocket connection. The server registers the client's channel somewhere where it can be retrieved when there's data to send. (I use a ChannelGroup in a singleton) The scheduled job fires gets some data from somewhere then gets a reference to the client's channel and writes the data to it. The client channel's pipeline should have a few encoders in it that marshal the scheduled job supplied data into websocket frames. thank you you unstuck me :) !
624,A,"Netty client acting as a service I am currently working on a client-server application using netty some of the clients are not going to be doing anything until they recieve a message. I have read the api and can´t find a way to do so. I mean I could try to have ""in.readline()"" on the main so it won´t end but it Doesn´t feel right. Also could have endless loops but I don´t think its the right way either. The question here is: is there a way to bind the socket for incoming messages just like the server having the main method ending?  public void run(){ EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap() .group(group) .channel(NioSocketChannel.class) .handler(new ChatClientInitializer()); Channel channel = bootstrap.connect(hostport).sync().channel(); BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); System.out.println(""Inserte su nombre""); String nombre = in.readLine(); MyClientChannel canal = new MyClientChannel(channelnombre); canal.write(""SM""nombre); in.readLine(); See that at the end I had to write ""in.readline()"" so the program wouldn´t end and the handler would be still up for incomming messages Please try to re-phrase the question and submit example code. I'm afraid it is not very clear what your problem is. @forty-two done thanks :) The easiest thing to do would be to replace: in.readLine(); With: channel.closeFuture().await(); When the connection to the server is disconnected the client will terminate. You will also want to spend some time defining your client's life-cycle so that the channel's state doesn't affect when your application is running and when it's not."
625,A,"Netty ClientBootstrap RECONNECT to another server I have a question about ClientBootStrap. Here is the scenario; Client_X wants to join Server_A. But the Server_A somehow wants the Client_x to join in Server_B. So Server_A sends Server_B's info to Client_X for RECONNECTION As soon as the Client_X gets the RECONNECTION message he tries disconnecting from Server_A and tries to connecting to Server_B. But it fails. Because as soon as Client disconnects from Server_A he cannot use the disconnected channel anymore. This looks simple. But here is my implementation  @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e)throws Exception { if(e.getMessage() instanceof SomePacket){ .... }else if(e.getMessage() instanceof Reconnect){ //Server_A has sent a RECONNECT Message.(Redirection) Reconnect theReconnectPacket = (Reconnect)e.getMessage(); String hostname = theReconnectPacket.getHostname(); int port = theReconnectPacket.getPort(); this.reconnectHost = hostname; this.reconnectPort = port; this.currentState = 1; ctx.getChannel().disconnect(); //DISCONNECT FROM SERVER_A } } @Override public void channelDisconnected(ChannelHandlerContext ctxChannelStateEvent e) throws Exception { if(this.currentState == 1){ Channel disconnectedChannel = ctx.getChannel(); if (!disconnectedChannel.isConnected()){ SocketAddress destinationAddress = new InetSocketAddress(this.reconnectHost this.reconnectPort); //TRYING TO RECONNECT SERVER_B disconnectedChannel.connect(destinationAddress); //**Error Line:java.nio.channels.ClosedChannelException** } } super.channelDisconnected(ctx e); } As you can see in the Error Line I got this exception:java.nio.channels.ClosedChannelException. Couldn't we use the same channel after it is disconnected?. Once it is disconnected is it done?. How could we recreate a connection in the SimpleChannelHandler ? Thanks for further comments :) <<<<< NEW APPROACH >>>>>> Ok. So in the SimpleChannledHandler  I use ClientBootStrap to connect a differentPort.  @Override public void channelDisconnected(ChannelHandlerContext ctxChannelStateEvent e) throws Exception { Channel disconnectedChannel = ctx.getChannel(); final ClientDataObject oldObject = ClientDataState.clientObject.get(disconnectedChannel); if(oldObject.getClientState() == 1){ if (!disconnectedChannel.isConnected()){ SocketAddress destinationAddress = new InetSocketAddress(this.reconnectHost this.reconnectPort); ChannelFuture connectFuture = bootstrap.connect(destinationAddress); connectFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture channelFuture) throws Exception { Channel newChannel = channelFuture.getChannel(); ClientDataObject newObject = ClientDataState.clientObject.get(newChannel); newObject.setClientID(oldObject.getClientID()); newObject.setClientState(oldObject.getClientState()); newObject.setRoomId(oldObject.getRoomId()); newObject.setClientState(1); ClientDataState.clientObject.set(newChannel newObject); Channels.write(newChannel new Login(newObject.getClientID())); }}); }else{ //Channled connected } } super.channelDisconnected(ctx e); } But I need to know some information of Client_X. As soon as the Client_x is disconnected the pipeline create another SimpleChannelHandler. So all my information is gone. I try to use ChannelLocal to keep state of the client. But it is also useless since it is related with channel object. When I connect to newChannel I cannot use old SimpleChannelHandlers's data again. (like clientIDroomID etc.) My point is how to store information without being effected by channel(session) I want to access the data from any channel handler. The way to handle this question should we implement ChannelPipelineFactory like this?  public class GameClientPipelineFactory implements ChannelPipelineFactory{ private static final ClientStaticHandler SHARED = new ClientStaticHandler(); private Someobject o; public GameClientPipelineFactory(Someobject refTOSomeObject) { super(); this.o = refToSomeObject; } @Override public ChannelPipeline getPipeline() throws Exception { // TODO Auto-generated method stub ChannelPipeline pipeline = Channels.pipeline(); //pipeline.addLast(""delimiter"" new DelimiterBasedFrameDecoder(256 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new GameClientDecoder()); pipeline.addLast(""encoder"" new GameClientEncoder()); pipeline.addLast(""shared"" SHARED); //I added this line pipeline.addLast(""logicHandler"" new GameClientLogicHandler(this.o)); return pipeline; } But then how am I gonna use this 'shared' handler? Each time when I need a global object should I ask to pipeline to get this handler and get any object from 'shared' handler? Isn't this a long way? Instead of trying to reopen a closed channel try creating a new channel. You may want to implement a callback to initiate a the creation of a new channel. Just the same way you created the 1st socket: ChannelFuture f = b.connect().sync(); Yes but the NETTY was creating channels by itself. How do we create channels manually? I couldn't see in the API. Thank you for your advice tough. Ok I solved my problem by passing the bootstrap object to ChannelHandler when creating it. So as soon as the channel handler is disconnected I use bootstrap object for reconnection. Thank you Veebs."
626,A,Grails design question on linking a java src class to service I have a socket program running along with my grails app. The question I have is what would be a good design to get the data from the socket to a grails service class. Incoming socket data -> Netty decoder java class(in java src) -> how do I get this to the service layer? The bootstrap class kicks off the socket server bootstrap at a predefined port. Thanks in advance Abraham Menacherry You can use the service classes in your Netty decoder class if you make it to a spring component here is a example. Thanks for the quick reply. The following link in Grails documentation was also helpful [link](http://grails.org/doc/latest/guide/8.%20The%20Service%20Layer.html)
627,A,Sending potentially large messages over Netty in parallel I want to implement a server/client application using Netty. As an example suppose it needs to upload and download files and receive notifications when new files are uploaded. The problem is that the client must receive notifications even while downloading (or uploading) a file. I can see a few options: Only send small messages over TCP containing URLs to files download and upload over HTTP. Open several parallel connections over TCP using one for small messages and one for large (or one for each large message). Write a chunking handler which automatically splits messages into chunks under 64Kb (e.g.) and allows chunks from different messages to be interleaved. From documentation it seems ChunkedWriteHandler does not do this. What I like in option 3 is that the client only needs to authenticate once there is no possibility of one connection breaking while another is maintained etc. But is it reasonable? And if yes does such a solution already exist? If you have control of both client and server use websockets. You are free to invent your own file transer protocol on top of it including notifications and whatnot. Kermit goes websocket ;-)  Chunks are nothing but http messages try to use a socket client which buffers then writes your file to netty chunk by chunk in one single connection then use netty http chunk aggregator handler to decode the chunks. The client implementation is pretty simple. Most of the server side implementation can be found under org.jboss.netty.example.http.upload .
628,A,Constructing a Netty ChannelBuffer from a string To convert a Netty ChannelBuffer to a String is as simple as calling .toString(UTF_8) on the ChannelBuffer. How do I create a ChannelBuffer from a String? Use ChannelBuffers.copiedBuffer(String Charset)  In netty 4 you can use Unpooled.copiedBuffer(String Charset)
629,A,"Netty HttpStaticFileServer example not working with HttpContentCompressor If I add the following line to HttpStaticFileServerInitializer pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""aggregator"" new HttpObjectAggregator(65536)); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""chunkedWriter"" new ChunkedWriteHandler()); pipeline.addLast(""deflater"" new HttpContentCompressor()); // Added The files get served with Content-Encoding: gzip but the content is not actually gzipped. This causes most browsers to fail decoding the content. Does DefaultFileRegion not work with HttpContentCompressor or is there something else one must do to get them to work together? This works at my side. Any more information? I cloned the netty git repo added the deflater line as shown above and run the example. View http://localhost:8080 in a browser and select a file and Chrome will report 'This webpage is unavailable' with Error code: ERR_CONTENT_DECODING_FAILED because the Content-Encoding: gzip header is present but the content is not gzipped. Based on Clement's comment and subsequent discussion in #netty it sounds like it is not possible to use DefaultFileRegion and HttpContentCompressor together. I switched back to ChunkedFile and it works fine.  RandomAccessFile raf = new RandomAccessFile(file ""r""); if (request.method() != HttpMethod.HEAD) { ctx.write(new ChunkedFile(raf 0 fileLength 8192)); } I also subclassed HttpContentCompressor and do a bit of checking against the content type to determine if the file should be compressed or not (JPEG PNG and other binary files skip the compress step.)  You can get chunked transfers (ChunkedWriteHandler) and HttpContentCompressor to work together. You simple need to provide a ChunkedInput which generates HttpContent objects instead of ByteBuf ones. Here's a quick write-up: http://andreas.haufler.info/2014/01/making-http-content-compression-work-in.html This is great Andreas thank you for the writeup  Unfortunately chunked transfer and gzip content encoding are are a difficult combination. The compression must not be done at the chunk level but on the whole content (making it impossible for live data). Thus you need to zip the content yourself and then transfer it. In your example it means you can't use in combination the chunk writer and the content compressor."
630,A,"Java: Faster alternative to String(byte[]) I am developing a Java-based downloader for binary data. This data is transferred via a text-based protocol (UU-encoded). For the networking task the netty library is used. The binary data is split by the server into many thousands of small packets and sent to the client (i.e. the Java application). From netty I receive a ChannelBuffer object every time a new message (data) is received. Now I need to process that data beside other tasks I need to check the header of the package coming from the server (like the HTTP status line). To do so I call ChannelBuffer.array() to receive a byte[] array. This array I can then convert into a string via new String(byte[]) and easily check (e.g. compare) its content (again like comparison to the ""200"" status message in HTTP). The software I am writing is using multiple threads/connections so that I receive multiple packets from netty in parallel. This usually works fine however while profiling the application I noticed that when the connection to the server is good and data comes in very fast then this conversion to the String object seems to be a bottleneck. The CPU usage is close to 100% in such cases and according to the profiler very much time is spent in calling this String(byte[]) constructor. I searched for a better way to get from the ChannelBuffer to a String and noticed the former also has a toString() method. However that method is even slower than the String(byte[]) constructor. So my question is: Does anyone of you know a better alternative to achieve what I am doing? Why? Just send the bytes as fast as possible. Forget the uuencoding; forget the splitting. TCP already does splitting and it knows a lot more about the optimum packet size on the current connection than you do. Perhaps you could skip the String conversion entirely? You could have constants holding byte arrays for your comparison values and check array-to-array instead of String-to-String. Here's some quick code to illustrate. Currently you're doing something like this: String http200 = ""200""; // byte[] -> String conversion happens every time String input = new String(ChannelBuffer.array()); return input.equals(http200); Maybe this is faster: // Ideally only convert String->byte[] once. Store these // arrays somewhere and look them up instead of recalculating. final byte[] http200 = ""200"".getBytes(""UTF-8""); // Select the correct charset! // Input doesn't have to be converted! byte[] input = ChannelBuffer.array(); return Arrays.equals(input http200); That is a great answer thank you very much! +1 Creating Strings can be more expensive than you might expect. Avoid creating them and you can improve performance significantly.  Depending on what you are trying to do there are a few options: If you are just trying to get the response status to then can't you just call getStatus()? This would probably be faster than getting the string out. If you are trying to convert the buffer then assuming you know it will be ASCII which it sounds like you do then just leave the data as byte[] and convert your UUDecode method to work on a byte[] instead of a String. The biggest cost of the string conversion is most likely the copying of the data from the byte array to the internal char array of the String this combined with the conversion is most likely just a bunch of work that you don't need to do.  Some of the checking you are doing might just look at part of the buffer. If you could use the alternate form of the String constructor: new String(byteArray startCol length) That might mean a lot less bytes get converted to a string. Your example of looking for ""200"" within the message would be an example. 2 You might find that you can use the length of the byte array as a clue. If some messages are long and you are looking for a short one ignore the long ones and don't convert to characters. Or something like that. 3 Along with what @EricGrunzke said partially looking in the byte buffer to filter out some messages and find that you don't need to convert them from bytes to characters. 4 If your bytes are ASCII characters the conversion to characters might be quicker if you use charset ""ASCII"" instead of whatever the default is for your server: new String(bytes ""ASCII"") might be faster in that case. In fact you might be able to pick and choose the charset for conversion byte-character in some organized fashion that speeds up things."
631,A,Are concurrent reads possible in Netty 4? From these notes: Netty will never call a ChannelHandler's methods concurrently unless the ChannelHandler is annotated with @Sharable. This is regardless of the type of handler methods - inbound outbound or life cycle event handler methods. I have no problem with that. My question is however if it is possible for two different messages to be read/processed from the same channel at the same time at different stages of the pipeline. For instance consider the following pipeline (ChannelInboundHandlers only):  +-----------+ | Handler 2 | +-----------+ ^ | +-----------+ | Handler 1 | +-----------+ ^ | +-----------+ | I/O read | +-----------+ I understand that only one thread at most may be calling the methods from Handler 1 unless it is Sharable. But can a thread be processing a message in Handler 2 while another thread is processing a message for the same channel in Handler 1? Or is the channel selected only when the current message reaches the end of the pipeline? This is only possible if you have added one of the ChannelHandler to the pipeline with a EventExecutorGroup passed in. If you not use one everything will just handled by the EventLoop and so one Thread.
632,A,What happens with an exception thrown within a ChannelFutureListener? I assumed the exception would be processed as an upstream event in the pipeline of the channel but my stack trace doesn't look that way. It just gets logged via the InternalLogger so no upstreamevent. Ok. Thank you very much.
633,A,"Synchronous HTTP call in Netty My app receives an HTTP request and in the middle of the pipeline a call is made to another server for supporting information. The initial HTTP request can't continue through the pipeline until that response comes back. I can't use the awaitUninterruptability() from an I/O thread so what's the best approach to make these calls so I don't block Netty's event loop but put the client's pipeline on hold until my call out returns and I tell the pipeline to continue on? After fiddling with it for awhile I think I'm on the right track. What I'm now doing is to add another instance of the same pipeline handler to the stack immediately after the current one passing in the response handler. Then send upstream. Then I check to see if that response handler is done (a custom method in the handler) and if not add another instance of the handler to the pipeline and so on. Essentially creating a loop of handlers that will ""break"" when the response has returned. The only problem I have now is that I overflow the stack on handlers before the response has returned... I guess you need an ExecutionHandler. Interesting... I'll try this out in the AM and see if it does what I need. Thanks! I see in the docs `new OrderedMemoryAwareThreadPoolExecutor(16 1048576 1048576)` and I'm curious if those param values are pretty common or if they should be tuned and if so what are the criteria for tuning them. These numbers are of course entirely arbitrary. Your numbers depends entirely on your specific runtime; specifically how much heap you have at your disposal- Calculating object memory usage can be difficult. Best approach is probably to measure heap during varying load estimate consumption by the specific executor and set a ""conservative"" limit.  Ryan this does not sound like a good idea.. I think you should better use something like that: public class HttpHandler extends SimpleChannelUpstreamHandler{ @Override public void messageReceived(final ChannelHandlerContext ctx final MessageEvent e) throws Exception { otherChannel.write(yourRequet).addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) throws Exception { // once the write is done we can continue in the pipeline ctx.sendUpstream(e); } }); // the event stops here to get processed } } If you need to wait for the response then you will need to handle it in another SimpleChannelUpstreamHandler. But I think you get the idea.. So the `ctx` in that example is the context of the outbound HTTP request. So sending the event upstream only sends the event upstream for the outbound request. I need to send the event from the inbound HTTP request upstream when the `operationComplete` call is made but not sooner. I tried sending the original event upstream (passed the inbound context into the anonymous function via a `final` context) but the originating pipeline continued to the **downstream** handlers when I didn't explicitly call `sendUpstream` from the inbound pipeline. Ok Norman was correct I just didn't see it clearly. I also had a bug in my code that was executing another step in parallel when it should have been a separate pipeline handler executed later. The jist is that the client event pipeline fires the parent contexts sendUpstream when the client finishes work. Just make sure not to have anything after the client execution call that could result in parallel execution (that's unwanted)."
634,A,"Are the Netty ChannelPipeline methods like getNames() guaranteed to give results in the ""proper"" order? I'm trying to figure out how to concatenate two Netty pipelines into one. It seems like it should be straightforward enough. Something like: List<String> namesOfSecond = second.getNames(); for (String name : namesOfSecond) { ChannelHandler handler = second.get(name); first.addLast(""Second-"" + name handler); } But the javadoc for getNames() just says ""Returns the List of the handler names."" It doesn't say what order the list is in if even in any particular order at all. For the above code to work properly the list of names would have to be in the order of the list of handlers corresponding to those names in the pipeline. Is it? Is it guaranteed? There's also a toMap() function which ""Converts this pipeline into an ordered Map whose keys are handler names and whose values are handlers."" That seems a little better I guess as it explicitly says that the map is ordered. It doesn't however say what it's ordered by. I am guessing that these functions return things in the ""obvious"" and ""correct"" order -- i.e. pipeline order (as opposed to say ordering lexically by name) -- but the documentation does not make this explicit and so I would like to make sure. Does anyone know? Thanks in advance. Your guess is correct. The two mechanisms iterates over the installed handlers (or handler contexts to be precise) from first to last in the first case constructing a list and in the second case a LinkedHashMap."
635,A,"Netty froze with multiple clients connection I`m trying to test netty but when i creating a multiple clients to connect to server some of client just froze and never finish. Here my code( basically i used code from her https://github.com/brunodecarvalho/netty-tutorials and just modify it to use a several clients):  for (int i = numthr; i > 0; i--) { Runnable runner = new Runnable() { public void run() { final Client client = new Client(""localhost"" 10400 nummes 0); if (!client.start()) { System.exit(-1); return; } client.flood(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { client.stop(); } }); } }; executor.execute(runner); }  public void messageReceived(Envelope message) { if (this.received.incrementAndGet() == this.messages) { System.out.println(nmb.incrementAndGet()); } } public boolean start() { // For production scenarios use limited sized thread pools this.clientFactory = new NioClientSocketChannelFactory(Executors.newCachedThreadPool() Executors.newCachedThreadPool()1); this.channelGroup = new DefaultChannelGroup(this + ""-channelGroup""); this.handler = new ClientHandler(this this.channelGroup); ChannelPipelineFactory pipelineFactory = new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""encoder"" new Encoder()); pipeline.addLast(""decoder"" new Decoder()); pipeline.addLast(""handler"" handler); return pipeline; } }; ClientBootstrap bootstrap = new ClientBootstrap(this.clientFactory); bootstrap.setOption(""reuseAddress"" true); bootstrap.setOption(""tcpNoDelay"" true); bootstrap.setOption(""keepAlive"" true); bootstrap.setPipelineFactory(pipelineFactory); boolean connected = bootstrap.connect(new InetSocketAddress(host port)).awaitUninterruptibly().isSuccess(); if (!connected) { this.stop(); } return connected; }  this.serverFactory = new NioServerSocketChannelFactory(Executors.newCachedThreadPool() Executors.newCachedThreadPool()); this.channelGroup = new DefaultChannelGroup(this + ""-channelGroup""); ExecutionHandler executionHandler = new ExecutionHandler( new MemoryAwareThreadPoolExecutor(270 1048576 1048576)); ServerBootstrap bootstrap = new ServerBootstrap(this.serverFactory); bootstrap.setPipelineFactory( new DatabaseGatewayPipelineFactory(executionHandler)); bootstrap.setOption(""reuseAddress"" true); bootstrap.setOption(""child.tcpNoDelay"" true); bootstrap.setOption(""child.keepAlive"" true); bootstrap.setOption(""child.connectTimeoutMillis"" 10000); Channel channel = bootstrap.bind(new InetSocketAddress(this.host this.port)); if (!channel.isBound()) { this.stop(); return false; } this.channelGroup.add(channel); Calling System.exit(-1); will terminate the JVM while other client thread may still be active. Is this behavior necessary? I would say that it doesn`t matter. This line will run only in case of some error when the client didn`t start. And it doesn`t run  The code is making new thread for Client each time with same port number. This can create problems because multiple threads are processing messages on the same port."
636,A,"No listening socket displayed I'm writing a Java game server using Netty. I can successfully connect the client from localhost but I cant from a remote PC. No listening socket is displayed in netstat util. Am I missing something in my conf? @Override public void startServer(String host int port) { // Initialize server bootstrap if (bootstrap == null) { bootstrap = new ServerBootstrap(new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); bootstrap.setPipelineFactory(channelPipelineFactory); bootstrap.setOption(""keepAlive"" true); bootstrap.setOption(""tcpNoDelay"" true); } // Unbind the port if bound if (serverChannel != null && serverChannel.isBound()) { serverChannel.unbind(); } serverChannel = bootstrap.bind(hostAddress); ... } Why do you pass in `host` and `port` to this method when you completely ignore them and use `hostAddress` instead? What is the value of `hostAddress`? `host` and `port` are from the old api `hostAddress` is based on the properties passed to VM during launch 10.0.42.1 and 7777 in our case what error do you receive when trying to connect to the server from a remote PC? You ask if something missing in your conf. Show the conf. maybe firewall ? the value of the hostAddress was tried as ""localhost"" and ""10.0.42.1"" (ip address as the remote host) when I'm trying to connect to the server from a remote PC I receive timeout exception smth like that @OneMoreVladimir The 'old API' is meaningless outside your workplace. The point is that your code doesn't do what it says it does. Possibly you are looking for the wrong port. There is no evidence here to the contrary. Try binding on the wildcard address 0.0.0.0 (or ::0 for IPv6). The server will then listen all available interfaces. That does not solve the problem.. ;("
637,A,Frameworks for creating asynchronous streaming API The architecture of our application consists of several modules. The modules can run as a single process or separately on a different server. We are using REST for the interaction between modules when they are on different servers. Now we need to process streaming data between modules. One module sends a request -- another module asynchronously sends back chunks of data (objects). We have tried to use KryoNet and Apache Mina. We have selected the last one and in general everything works. But the solution has several problems and there is a feeling that we reinvent the wheel. Maybe there is ready framework for creating asynchronous API to transmit streaming data and that support several transports and built-in serialization: local -- when the modules / services interact within a single process netty or analog -- when the modules interact with each other on different machines REST -- to interact with modules over HTTP Something like elasticsearch Java API -- all operations can be performed asynchronously through the network locally or via REST. Is there a ready-made frameworks for the creation such API? We are using Scala 2.10 and Java. vert.x is one full-fledged asynchronous communication framework. Is vert.x supports different transports and built-in serialization for creating APIs like described above? You should also definitely take a look at Akka IO: http://doc.akka.io/docs/akka/snapshot/scala/io.html  How about finagle? https://github.com/twitter/finagle It doesn't cover all your needs out of the box but it's a very nice and extensible framework and might provide a good base to build upon. And you can see an example of doing a streaming server using finagle: https://github.com/twitter/finagle/blob/master/finagle-example/src/main/scala/com/twitter/finagle/example/stream/StreamServer.scala Looks interesting thanks.
638,A,What is the most efficient way to send a binary websocket message? I have already created a MessageToMessageCodec implementation to go to/from BinaryWebSocketFrame and our own POJO. This works well but I don't know that it's optimal. Since our POJO supports direct codec to/from byte[] is there a more efficient way to send/receive a byte[] over a netty websocket? Can I just call Channel.writeAndFlush(byte[]) and the underlying websocket handler code will put this into a BinaryWebSocketFrame automatically - and if so would this be more efficient than constructing the BinaryWebSocketFrame in my own codec? Just looking for the most efficient approach to sending/receiving the message. Thanks Bob You will need to construct a new BinaryWebSocketFrame by your own. This is the way to go. This is what we're doing in our codec so it sounds like we're doing this as efficiently as we can. Thanks Norman
639,A,"communicate with remote host using camel-netty tcp I have a program running on a remote host that I need to connect to handshake then listen for messages. I have setup the following camel route: <route> <from uri=""netty:tcp://localhost:50001?decoders=#decoders&amp;sync=false"" /> <bean ref=""TransformMessage"" method=""inboundDecoder"" /> <to uri=""eventadmin:messages/aacus/inbound"" /> </route> <route> <from uri=""eventadmin:messages/aacus/outbound"" /> <bean ref=""TransformMessage"" method=""outboundEncoder"" /> <to uri=""netty:tcp://192.168.0.111:50001?allowDefaultCodec=false&amp;sync=false"" /> </route> My question is how do I make this work? If I establish the route using <from uri=""netty:tcp://192.168.0.111:50001?decoders=#decoders&amp;sync=false"" /> it fails with a binding error. How can I setup the connection to respond on a specific port without modifying the server? This is not possible with either camel-mina nor camel-netty at this time of writing. A consumer can only bind to a local server. There is a JIRA ticket at Apache to implement such a new feature for the future. https://issues.apache.org/jira/browse/CAMEL-1077 Thanks Claus I was afraid this was the case. Rather frustrating that this isn't supported as it seems like a common and obvious use-case. I have worked around this issue by implementing a custom component for Camel that handles my TCP communication.  Use the following workaround: Instead ob 192.168.0.111 use localhost. Then install ""socat"" and start it as follows socat -s -u tcp4:192.168.0.111:50001 tcp4:localhost:50001 This will Tunnel your remote connection to the local service you created with camel/netty."
640,A,Is it possible in socket buffer messages in disorder For example： In client only one long connection but there are many threads will write message to it.If first thread1 write partial bytes for message1 but not complete then thread2 write some bytes for message2 last thread1 write rest bytes.Does it exist this kind of case?if not how netty avoid this case? Netty ensure that all operations are executed in the IO-Thread. So if you write from a different thread it will make sure the actual write is done from the IO-Thread. So the order is guaranteered.
641,A,Where can I see the content of Channel.write() I'm new to netty and trying the examples they have on their website. I'm doing the HttpFileServer for version 3.9 and and in the Handler class I saw this  Channel ch = e.getChannel(); // Write the initial line and the header. ch.write(response); Where/how can I see what is being written to the a channel instance? You can add a LoggingHandler to the ChannelPipeline. This will log out all the data which is received and written. Sorry I didn't accept your answer earlier. This was the very first question I had posted and wasn't too familiar with the website. Thanks for the answer
642,A,"Netty 4: Channel-EventLoop mapping in the NioEventLoopGroup We have a distributed application that uses Netty (4) for our low level communication stuff. A process in that system execute multiple tasks. Each task contains a set of input and output channels. Channels are permanently assigned to a single EventLoop in Netty. The mapping of Channel to EventLoop happens in round robin fashion in the (Nio)EventLoopGroup. We would like to have more control over this mapping and assign all channels of the same task to the same EventLoop(s). The purpose for this ""Channel-EventLoop affinity"" is to reduce lock-contention for some specific memory management stuff in the ChannelHandlers. We looked in Netty documentation but didn´t find anything. Is there a general way to do that in Netty 4? Another possibility I identified would be to overwrite the ""EventExecutor next()"" method in the ""MultithreadEventExecutorGroup"" that implements the round robin channel mapping (I think so at least). Is that a possible way to enforce a different mapping or do I create undesirable side effects with this hack? I am grateful for any help!! Tobi It is not possible at the moment to do this in a ""clean"" way. We want to change it in netty 5. See also https://github.com/netty/netty/issues/1230"
643,A,Can netty be used with jssc for serial comms? I've used netty with udp and tcp protocols. To my surprise it can be used with serial port as well. Transport used is rxtx there are a very few positive recommendations for rxtx. Can netty be used with jssc instead of rxtx? Should an application developer really care about the underlying implementation (rxtx or jssc)? Should there be a problem developing in x86 then swapping to ARM? There is currently no support for jssc but you could write your own transport implementation using it.
644,A,"Upgrading from netty 3.2.x to 3.3x and Unsafe actually I'm using netty 3.2.7 in a custom streaming server project. I'm trying upgrading to netty 3.3.x but I encountered problems related to ""Unsafe"". I have a handler that subclass ""ChunkedWriteHandler"" and another class that subclass ""ChunkedInput"" in order to implement chunked http data trasfer to the clients. After upgrading to 3.3.x my code breaks with the following message: Invalid memory access of location 0x15e47da eip=0x708666 Looking at the source code I can see that now the buffer used inside ChunkedWriteHandler uses Unsafe to optimize some operations but I can't understand what I'm doing wrong (for causing an invalid memory access) and how to fix this issue. Can some netty guru help me to understand and fix my problem? Thanks Rocco I've made other tests. On my primary dev machine a 32 bit mac os 10.5 with the latest java 5 i experience the issue reported above. On my notebook a 64 bit mac os 10.7 with the latest java 6 everything seems working properly. Yeah like I said it looks like a jdk bug This sounds more like a jdk bug. What java version are you using ? In netty 3.4.1.Final its now possible to disable unsafe via ""-Dorg.jboss.netty.tryUnsafe=false"""
645,A,e=java.lang.IllegalArgumentException: No matching field found: sync for class org.jboss.netty.channel.DefaultChannelFuture I'm a front end hacker that's working with a bunch of smart java people at the moment. On my dev machine I keep on getting this error when I make a POST request to my dev environment for a speech API we're building. This error only happens for me though everything is fine in production and other people's dev env. ERROR speech.symphony - speech/ e=java.lang.IllegalArgumentException: No matching field found: sync for class org.jboss.netty.channel.DefaultChannelFuture instance=52efd7ad-bcf5-4077-ba52-845a494273cd java.lang.IllegalArgumentException: No matching field found: sync for class org.jboss.netty.channel.DefaultChannelFuture at clojure.lang.Reflector.getInstanceField(Reflector.java:271) at clojure.lang.Reflector.invokeNoArgInstanceMember(Reflector.java:300) at wit.netty$netty_stream.invoke(netty.clj:102) at wit.netty$netty_stream.invoke(netty.clj:62) at wit.integration.google$stream_asr_BANG_.invoke(google.clj:62) at wit.speech.symphony$chunks__GT_diag$fn__43088$state_machine__5906__auto____43089$fn__43091.invoke(symphony.clj:131) at wit.speech.symphony$chunks__GT_diag$fn__43088$state_machine__5906__auto____43089.invoke(symphony.clj:131) at clojure.core.async.impl.ioc_macros$run_state_machine.invoke(ioc_macros.clj:945) at clojure.core.async.impl.ioc_macros$run_state_machine_wrapped.invoke(ioc_macros.clj:949) at wit.speech.symphony$chunks__GT_diag$fn__43088.invoke(symphony.clj:131) at clojure.lang.AFn.run(AFn.java:24) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) I have no idea what this means. Any explanation on what you think might be going on would be greatly appreciated! You're including a field in your request (JSON?) that doesn't appear on the target Java class in the server. This is most likely due to a version mismatch relating to the class mentioned. I'm just guessing here but maybe you have netty 3 on the classpath but netty 4 is needed ?
646,A,"EventLoopGroup and BIO operation. I'm having Netty Web server which should retrieve data using Hibernate and return response to the client. So I just wonder if my implementation is correct  ChannelPipeline pipeline = ch.pipeline(); EventExecutorGroup ex = new DefaultEventExecutorGroup(64); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""aggregator"" new HttpObjectAggregator(65536)); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""chunkedWriter"" new ChunkedWriteHandler()); pipeline.addLast(ex""handler"" new HttpWebServerHandler()); and then inside of messageReceived method:  @Override public void messageReceived(ChannelHandlerContext ctx FullHttpRequest request) throws Exception { if (!request.getDecoderResult().isSuccess()) { sendError(ctx BAD_REQUEST); return; } ctx.executor().execute(new MyRunnable(ctx)); } and inside Runnable: @Override public void run() { SomeObejct so = HibernateTemplate.getSomeObject() ; String serializedSo = serialize(so); FullHttpResponse res = new DefaultFullHttpResponse( HTTP_1_1 OK Unpooled.copiedBuffer(serializedSo CharsetUtil.UTF_8)); res.headers().set(CONTENT_TYPE ""text/plain; charset=UTF-8""); ctx.write(res).addListener(ChannelFutureListener.CLOSE); } Am I doing it right? Yes this looks correct. What you may want to think about is to remove the HttpObjectAggregator from the ChannelPipeline and so save some memory overhead. But be aware that you need to handle the different HTTP messages parts by your own then."
647,A,"How to ignore messages from disconnected channel I'm implementing simple netty server for a multiplayer game. I'm just trying to figure out Netty. I test the server via telnet. What i done is broadcast the messages to all channels. It's working smoothly. Also I remove channels from map on close event which is fine. But the problem is if one of the clients disconnect unexpectedly before closed callback messageReceived callback called which the sender is disconnected channel. How can i properly ignore the message comes from disconnected client? I use StringBuffer in messagedReceived but for the case StringBuffer.toString is also not a proper string. At the end disconnected channel broadcast pointless message to other channels and itself when receiver channel is itself throws an exception Connection reset by peer which it's normal because the channel itself is not available at the moment. Here is the code ;  @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { System.out.println(); System.out.println(""------------------""); Channel current = e.getChannel(); System.out.println(""SenderChannel:""+current.getId()); if(!current.isOpen()) System.out.println(""Not Open""); ChannelBuffer buf = (ChannelBuffer) e.getMessage(); StringBuffer sbs = new StringBuffer(); while(buf.readable()) { sbs.append((char) buf.readByte()); } String s = sbs.toString(); System.out.println(s); String you = ""You:"" + s; String other = ""Other:"" + s; byte [] uResponse = you.getBytes(); byte [] otherResponse = other.getBytes(); Iterator iterator = channelList.entrySet().iterator(); while(iterator.hasNext()){ Map.Entry pairs = (Map.Entry)iterator.next(); Integer key = (Integer)pairs.getKey(); Channel c = (Channel)pairs.getValue(); System.out.println(""ReceiverChannel:""+c.getId()); if(key != current.getId()) c.write(ChannelBuffers.wrappedBuffer(otherResponse)); else c.write(ChannelBuffers.wrappedBuffer(uResponse)); } } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e){ Channel ch = e.getChannel(); channelList.remove(ch.getId()); System.out.println(); System.out.println(""*****************""); System.out.println(""DisconnectEvent:""+ch.getId()); System.out.println(""*****************""); System.out.println(); ch.close(); } StringBuilder makes sense but for the rest of your comment i didnt get that? :) Synchronization needs resources. So using a not-thread-safe class where synchronization is not needed will save you some cpu% ok i see but what about the answer the question @Fildor I'm afraid I don't have one. Except to adopt Soroush's concept. I fthe connection itself is not your ""state"" of user being logged in or out you'll have to keep a context observing that state and you'll have to check that state and filter messages accordingly when writing. Nothing to do with the question and an answer to it: You could use StringBuilder instead of StringBuffer. You do not need synchronization in the scope where it is used. I am not a Java Developer. But from socket point of view this data is in buffer or sent before disconnecting of user. So when you are in receiving stage user is still connected and exactly on time of completing of receiving user is already disconnected. So I think best way to prevent this things is to check if user is still connected after each receiving of data. In C# I personally use this code to check if user is still connected: if (client.Poll(0 SelectMode.SelectRead)) { byte[] checkConn = new byte[1]; if (client.Receive(checkConn SocketFlags.Peek) == 0) return false; } return true; I am not sure about Java And Netty (And if your connection is TCP) but this is what I use and this could be possible to convert it easily to Java. That only determines whether the client has closed the connection cleanly and it's rather expensive. It would be better to just handle the send errors as they occur: that way you find all disconnections not just the graceful ones and you don't need two extra system calls to do it.  You can't solve the problem in the manner that you would like. If there's a network problem then technically the sender could disconnect at any time for example as soon as the thread enters messageReceived while you're iterating through channelList while you're iterating through channelList but after you've echoed back to the sender after you've broadcast the message Netty can't raise the disconnected event while messageReceived is processing because you're running in the thread that will raise the event (unless you have a non-ordered execution handler in your pipeline). The correct solution really depends on your application. If the broadcast results in all the other receivers responding it's probably better / easier to have the server suppress any messages destined for a client that's no longer connected. Also if you're really going to use strings then take a look at StringEncoder / StringDecoder. There's no guarantee in your code that the message event buffer contains a complete string. thanks man what did solve my problem is using StringEncoder / StringDecoder in pipeline. now disconnecting has not seen in messageReviced because of decoding phase. probably it's ignored because of decode.  If this is for a multiplayer game server it might be better to use an existing Netty game server solution like java game server. Disconnects become events which get sent to the session and since it is event driven you could write your own handler to decide whether or not to receive anymore events on the same session. Since events are queued in a FIFO order if disconnect happens then you need not go ahead with subsequent broadcasts. how about the question by the way? looks like interesting i'm definitely gonna look it.  Just put a try/catch around each send. If one of them fails close the corresponding channel. @tylerdurden I cannot make head or tail of any of that but if you encounter any exception other than a timeout when doing I/O on a socket it is as dead as a doornail and you must close it. I dont need to because already override the exceptionCaught. But the problem is disconnecting channel couldnt throw an exception during send the others. others can get the meaningless messages. Only exception throws when it tried to send message itself(peer disconnected).. If i didnt echo back to itself i couldnt catch the exception. yeap right man that's what i'm doing in the exceptionCaught."
648,A,is there a way to cancel a key such that I can still read from it later with java nio We would like get tcp flow control as a primary component of a new java nio library. It would work like this... library fires data to Listener.incomingData(DataChunk dataChunk); library will not fire any more data EVEN if there is any until dataChunk.processed() is called. Typically you may call processed() method on the first few dataChunks but on the last one of some message you write to some remote socket and give it a callback handler. once the write callback is called you then invoke the last dataChunk.processed() to relieve the tcp flow control again BIG NOTE: Step 2 is where tcp flow control automatically kicks in IF you do not read from the nic buffer. This is all automatic (and we tested it with java nio). The issue though is how do we put the key in a state that the poller STOPS releasing and waits for data on all OTHER sockets except this one. I don't mind if it releases when it has new data as we would see that the last dataChunk has not been processed and ignore it but we don't want the poller thread cycling 100% cpu. Is there a way to achieve this so we can acheive automatic throttling for any server using this potential open source nio framework. Just cancel it and re-register the channel later or just de-register it for OP_READ by changing its interestOps() and change them back when you are ready to read from it again.  No Selectors will look at their internal state not events from the system so while the key is set to sense readable data it will always return while data is in the buffer waiting to be read. There are three options you have read the data from the buffer and store locally while you wait from the previous chunk to process. unregister the key from the selector and reregister when the chunk has been processed. set the key to not sense readble and reset when the chunk has been processed. I think this is what you want to toggle reading interest selectionKey.interestOps(selectionKey.interestOps() ^ SelectionKey.OP_READ); I don't know what 'No Selectors will look at their internal state not events from the system' is supposed to mean especially when the rest of your answer says 'yes'. It is the whole purpose of Selectors to 'look at events from the system'.
649,A,"why netty can not continuously send message? I wrote a server to send large number of message to all clients after connecting. @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { while (true){ content = arrayblockqueue.poll() ctx.writeAndFlush(content+""\r\n""); } } after sending thousands of message  the channel do not send message anymore. through debugging I found that AbstractNioByteChannel.incompleteWrite was invoked and the selectionKey will be add SelectionKey.OP_WRITE when the network is congestion. After being set OP_WRITE  AbstractNioUnsafe.isFlushPending() will return true so the flush() can not be done indeed . How to let netty recover this situation ? Or I use netty in a wrong way ? Your handler method is invoked directly from an I/O thread. Until your handler method returns the I/O thread which called the handler method cannot perform any I/O and that's why you are not seeing anything is written. Looking from your code what you want is to get a message from a blocking queue and write it to a channel. Instead of using a blocking queue you can just write to the channel. Almost all operations in Netty are thread safe. For example: public static void main(String[] args) throws Exception { ... Channel ch = ...; for (int i = 0; i < 1000000; i ++) { ch.writeAndFlush(String.valueOf(i) + ""\r\n""); } ... } // And your handler doesn't need an arrayblockingqueue. However the code above will probably make the event queue of Netty grow infinitely resulting OutOfMemoryError. To prevent the write requests from being queued infinitely you have to use the future returned by the writeAndFlush() operation. for (int i = 0; i < 1000000; i ++) { ChannelFuture f = ch.writeAndFlush(String.valueOf(i) + ""\r\n""); if ((i + 1) % 100 == 0) { // Wait until the write request is actually finished // so that the event queue becomes empty. f.sync(); } }"
650,A,TCP keep-alive to determine if client disconnected in netty I'm trying to determine if a client has closed a socket connection from netty. Is there a way to do this? If you are writing a server and netty is your client then your server can detect a disconnect by calling select() or equivalent to detect when the socket is readable and then call recv(). If recv() returns 0 then the socket was closed gracefully by the client. If recv() returns -1 then check errno or equivalent for the actual error (with few exceptions most errors should be treated as an ungraceful disconnect). The thing about unexpected disconnects is that they can take a long time for the OS to detect so you would have to either enable TCP keep-alives or require the client to send data to the server on a regular basis. If nothing is received from the client for a period of time then just assume the client is gone and close your end of the connection. If the client wants to it can then reconnect. I think you've misread the question. He seems to be using Netty in the server.  On a usual case where a client closes the socket via close() and the TCP closing handshake has been finished successfully a channelInactive() (or channelClosed() in 3) event will be triggered. However on an unusual case such as where a client machine goes offline due to power outage or unplugged LAN cable it can take a lot of time until you discover the connection was actually down. To detect this situation you have to send some message to the client periodically and expect to receive its response within a certain amount of time. It's like a ping - you should define a periodic ping and pong message in your protocol which practically does nothing but checking the health of the connection. Alternatively you can enable SO_KEEPALIVE but the keepalive interval of this option is usually OS-dependent and I would not recommend using it. To help a user implement this sort of behavior relatively easily Netty provides ReadTimeoutHandler. Configure your pipeline so that ReadTimeoutHandler raises an exception when there's no inbound traffic for a certain amount of time and close the connection on the exception in your exceptionCaught() handler method. If you are the party who is supposed to send a periodic ping message use a timer (or IdleStateHandler) to send it.  If you read from a connection that has been closed by the peer you will get an end-of-stream indication of some kind depending on the API. If you write to such a connection you will get an IOException: 'connection reset'. TCP doesn't provide any other way of detecting a closed connection. TCP keep-alive (a) is off by default and (b) only operates every two hours by default when enabled. This probably isn't what you want. If you use it and you read or write after it has detected that the connection is broken you will get the reset error above On Windows 2000 and later you can programably set the desired interval of the TCP keep-alive on a per-connection basis using `WSAIoctl(SIO_KEEPALIVE_VALS)`.  It depends on your protocol that you use ontop of netty. If you design it to support ping-like messages you can simply send those messages. Besides that netty is only a pretty thin wrapper around TCP. Also see this SO post which describes isOpen() and related. This however does not solve the keep-alive problem. The answers in that link are mostly incorrect. There are far better answers in SO. @EJP Do you have a link? If you could suggest an edit I will happily accept that! My understanding is that tcp has keep-alive built in. Is it not possible to leverage this? Yes it is. TCP keep-alive is disabled by default you would simply turn it on after establishing the connection. I suggest you link to [this answer](http://stackoverflow.com/questions/10240694/java-socket-api-how-to-tell-if-a-socket-has-been-closed/10241044#10241044). Thanks @EJP edited that in
651,A,How to I use io.netty.handler.codec.http.multipart.HttpPostRequestEncoder finalizeRequest I am using netty 4.0 for a project. I encountered the following problem seeking answer: In io.netty.handler.codec.http.multipart.HttpPostRequestEncoder finalizeRequest() method around line 705 the method returned WrappedHttpRequest if (the realSize > ..chunkSize = 8k) So this returned Object is not FullHttpRequest with NO content (HttpContent) member. All other cases the returned Object are subclass of FullHttpRequest with content. How can I convert this to WrappedFullHttpRequest with content (body etc)? Thanks! Check the multipart example it's shown there [1] [1] https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/http/upload/HttpUploadClient.java#L261 Thanks! I found the example very useful to send chunked vs non-chunked request.
652,A,Why native epoll support is intoduced in Netty? I believe Java's NIO library will use epoll on Linux machines. What are all the advantages of using Epoll instead of NIO on Linux machines. Netty's epoll transport uses epoll edge-triggered while java's nio library uses level-triggered. Beside this the epoll transport expose configuration options that are not present with java's nio like TCP_CORK SO_REUSEADDR and more.
653,A,Netty MessageToByteEncoder vs direct push via Unpooled.wrappedBuffer I have an C++ client connect to my Java netty server using TCP and I met this issue when I try to pre-pend the message length to the message and send to the C++ client: I extended the MessageToByteEncoder and encode it as below int length = msg.getLength(); byte[] data = msg.getData(); short littleEndianLength = ByteBufUtil.swapShort(length); out.writeShort(littleEndianLength); out.writeBytes(data 0 length); Then send the message using this method (in the handler) channel.writeAndFlush(msg).addListener(sendListener); BUT the client does not receive the message. I change to alternative way I create the binary message directly and send like below: byte[] buf = new byte[msgLength + 2]; // Convert message length to little-endian byte order buf[0] = (byte) (msgLength & 0xFF); buf[1] = (byte) ((msgLength >> 8) & 0xFF); System.arraycopy(data 0 buf 2 msgLength); ByteBuf byteBuf = Unpooled.wrappedBuffer(buf); channel.writeAndFlush(byteBuf).addListener(sendListener); The client RECEIVES the message. Can someone help me explain this? When you use MessageToByteEncoder and your encoder expects a certain type of message which doesn't seem to be a ByteBuf looking from your code you have to write that type of message instead of a ByteBuf. Otherwise MessageToByteEncoder will not handle the ByteBuf and just pass it to the next handler in the pipeline. Therefore you should do the following instead of writing byteBuf: channel.writeAndFlush(msg).addListener(sendListener); Sorry typo my example exactly same with your correction but it's still not working. In fact my application have 2 bootstraps listening 2 ports 1 bootstrap using the second example it works the other bootstrap using the first example it works. I am really confusing how the netty channel pipeline working.
654,A,"Netty 4 io.netty.channel.PartialFlushException after write On a second .write on a new channel in my code ChannelFuture.isSuccess for the write operation is false and the ChannelFuture.cause is io.netty.channel.PartialFlushException: 0 out of 1 message(s) flushed. I have little idea what should be done to avoid this and where to look for the deeper root cause. ChannelFuture.cause.getStackTraceString is: io.netty.channel.ChannelOutboundMessageHandlerAdapter.flush(ChannelOutboundMessageHandlerAdapter.java:118) io.netty.channel.CombinedChannelDuplexHandler.flush(CombinedChannelDuplexHandler.java:237) io.netty.channel.DefaultChannelHandlerContext.invokeFlush0(DefaultChannelHandlerContext.java:1308) io.netty.channel.DefaultChannelHandlerContext.write0(DefaultChannelHandlerContext.java:1445) io.netty.channel.DefaultChannelHandlerContext.write(DefaultChannelHandlerContext.java:1412) io.netty.channel.DefaultChannelHandlerContext.write(DefaultChannelHandlerContext.java:1034) io.netty.channel.DefaultChannelPipeline.write(DefaultChannelPipeline.java:959) io.netty.channel.AbstractChannel.write(AbstractChannel.java:246) pipe.Broker$writer$.write(Broker.scala:72) pipe.Broker$httpClientHandler.messageReceived(Broker.scala:57) pipe.Broker$httpClientHandler.messageReceived(Broker.scala:52) io.netty.channel.ChannelInboundMessageHandlerAdapter.inboundBufferUpdated(ChannelInboundMessageHandlerAdapter.java:104) io.netty.channel.DefaultChannelHandlerContext.invokeInboundBufferUpdated(DefaultChannelHandlerContext.java:951) io.netty.channel.DefaultChannelHandlerContext.fireInboundBufferUpdated0(DefaultChannelHandlerContext.java:926) io.netty.channel.DefaultChannelHandlerContext.fireInboundBufferUpdated(DefaultChannelHandlerContext.java:904) io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:466) io.netty.handler.codec.ByteToMessageDecoder.inboundBufferUpdated(ByteToMessageDecoder.java:69) io.netty.channel.ChannelInboundByteHandlerAdapter.inboundBufferUpdated(ChannelInboundByteHandlerAdapter.java:51) io.netty.channel.CombinedChannelDuplexHandler.inboundBufferUpdated(CombinedChannelDuplexHandler.java:194) io.netty.channel.DefaultChannelHandlerContext.invokeInboundBufferUpdated(DefaultChannelHandlerContext.java:951) io.netty.channel.DefaultChannelHandlerContext.fireInboundBufferUpdated0(DefaultChannelHandlerContext.java:926) io.netty.channel.DefaultChannelHandlerContext.fireInboundBufferUpdated(DefaultChannelHandlerContext.java:904) io.netty.channel.DefaultChannelPipeline.fireInboundBufferUpdated(DefaultChannelPipeline.java:909) io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:115) io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:401) io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:365) io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:302) io.netty.channel.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:110) java.lang.Thread.run(Unknown Source) The first .write on the channel goes well (isSuccess is true and indeed the written message perfectly arrives and parses at its destination). But the second .write consistently fails as described. The second .write is issued from within my overridden ChannelInboundMessageHandlerAdapter.messageReceived method once it receives acknowledgement for the receipt of the first .write by the remote peer. My code that performs the actual write (this is Scala) is:  request = new DefaultHttpRequest(HttpVersion.HTTP_1_1 HttpMethod.GET ""/""+msg) var writeFuture = channel.write(request).addListener(new ChannelFutureListener(){ def operationComplete(channelFuture: ChannelFuture){ if (channelFuture.isSuccess) println(""write finished successfully"") else println (""write failed: "" + channelFuture.cause + ""\n"" + channelFuture.cause.getStackTraceString) } }) What can be the problem and how should it be traced? Note that the accepted answer suggests the way to look at the more 'root' cause of the failure by using the more verbose printStackTrace method or using .cause.getCause on the future. It answers to the need to trace the problem (albeit no solution to the root problem found yet - unless answered at http://stackoverflow.com/questions/15097966/unexpected-message-type-defaulthttprequest-on-a-httpclientcodec-pipeline) A PartialFlushException contains the actual cause of the flush failure. You can get it using Exception.getCause() method that Java provides: PartialFlushException e = ...; e.getCause(); // This will return the exception you raised. To get the complete information of an exception instead of printing an exception you have to call printStackTrace(). future.cause.printStackTrace() For more information about chained exceptions please refer to this tutorial. PartialFlushException.getCause() will return another exception that is the root cause. Thanks using channelFuture.cause.getCause obviously indeed goes one level deeper where the cause is revealed as 'unexpected message type: DefaultHttpRequest'. Not sure yet why that type of object is not valid/expected given that the pipeline is purely a HttpRequestEncoder! but that's already a question for a differently titled topic... I'm closing this one. If you'd like to comment why isn't an HttpRequestEncoder expected on an Http pipeline here please don't hold yourself off ;) Thanks. My code is currently using .cause on the channel future to get the cause text. That seems to return PartialFlushException's cause text ""0 out of 1 message(s) flushed"". I am rather clueless how to interpret this as a root cause. What can I be missing? BTW trying to wrap the write operation in a try block doesn't yield catching the exception in a catch block probably due to the asynchronous nature of write. So I just assume that the .cause coming on the channel future is the way to get the exception and indeed it's a PartialFlushException with the cause text that I just mentioned. The problem is that cause text is hard for me to interpret in any actionable way."
655,A,"Tomcat 7 High CPU Usage on Boot with No Connections We are running Tomcat 7.0.34 on CentOS 6.3 (fully patched) and all of our appservers' CPUs spike up as soon as the server boots. There are NO connections being made to Tomcat. It appears there are a couple of CPU cores being completely consumed by something that is running inside our webapp. I cannot for the life of me figure out what could be causing this issue. Has anyone seen this before? I should mention this only happens on the CentOS boxes. My Windows tomcat server does not exhibit this behavior running the same application. Relevant Technologies We are using Tomcat's session replication Replicated EHCache and HornetQ for JMS. Java Versions Tested JDK 1.7.0 Update 10 and JDK 1.6.0 Update 38 Kill -3 Runnable Threads  ""http-apr-8080-Acceptor-1"" daemon prio=10 tid=0x00007f2598183000 nid=0x46b9 runnable [0x00007f2500685000] java.lang.Thread.State: RUNNABLE at org.apache.tomcat.jni.Socket.accept(Native Method) at org.apache.tomcat.util.net.AprEndpoint$Acceptor.run(AprEndpoint.java:1013) at java.lang.Thread.run(Thread.java:722) ""http-apr-8080-Acceptor-0"" daemon prio=10 tid=0x00007f2598181800 nid=0x46b8 runnable [0x00007f2500786000] java.lang.Thread.State: RUNNABLE at org.apache.tomcat.jni.Socket.accept(Native Method) at org.apache.tomcat.util.net.AprEndpoint$Acceptor.run(AprEndpoint.java:1013) at java.lang.Thread.run(Thread.java:722) ""New I/O boss #26"" daemon prio=10 tid=0x00007f253d4fb000 nid=0x462f runnable [0x00007f250c49c000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:228) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:81) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87) - locked <0x00000006ab002568> (a sun.nio.ch.Util$2) - locked <0x00000006ab002558> (a java.util.Collections$UnmodifiableSet) - locked <0x00000006ab0024d0> (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98) at org.jboss.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:64) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(AbstractNioSelector.java:409) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:206) at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:41) at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at org.jboss.netty.util.VirtualExecutorService$ChildExecutorRunnable.run(VirtualExecutorService.java:175) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) ""New I/O worker #25"" daemon prio=10 tid=0x00007f253d4e4000 nid=0x462e runnable [0x00007f250c59d000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:228) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:81) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87) - locked <0x00000006aefbcab8> (a sun.nio.ch.Util$2) - locked <0x00000006aefbcaa8> (a java.util.Collections$UnmodifiableSet) - locked <0x00000006aefbca60> (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98) at org.jboss.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:64) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(AbstractNioSelector.java:409) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:206) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at org.jboss.netty.util.VirtualExecutorService$ChildExecutorRunnable.run(VirtualExecutorService.java:175) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) ""New I/O worker #24"" daemon prio=10 tid=0x00007f253d4b9000 nid=0x462d runnable [0x00007f250c69e000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:228) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:81) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87) - locked <0x00000006ab002c70> (a sun.nio.ch.Util$2) - locked <0x00000006ab002c60> (a java.util.Collections$UnmodifiableSet) - locked <0x00000006ab002bd8> (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98) at org.jboss.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:64) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(AbstractNioSelector.java:409) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:206) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at org.jboss.netty.util.VirtualExecutorService$ChildExecutorRunnable.run(VirtualExecutorService.java:175) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) ... ABOUT 20 MORE NIO WORKERS IN RUNNABLE STATE... ""New I/O worker #2"" prio=10 tid=0x00007f253d054000 nid=0x4616 runnable [0x00007f250ddb5000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:228) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:81) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87) - locked <0x00000006adaa7070> (a sun.nio.ch.Util$2) - locked <0x00000006adaa7060> (a java.util.Collections$UnmodifiableSet) - locked <0x00000006adaa6fd8> (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98) at org.jboss.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:64) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(AbstractNioSelector.java:409) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:206) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at org.jboss.netty.util.VirtualExecutorService$ChildExecutorRunnable.run(VirtualExecutorService.java:175) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) ""New I/O worker #1"" prio=10 tid=0x00007f253d053000 nid=0x4615 runnable [0x00007f250deb6000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:228) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:81) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87) - locked <0x00000006adaa7bc0> (a sun.nio.ch.Util$2) - locked <0x00000006adaa7bb0> (a java.util.Collections$UnmodifiableSet) - locked <0x00000006adaa7b28> (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98) at org.jboss.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:64) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(AbstractNioSelector.java:409) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:206) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at org.jboss.netty.util.VirtualExecutorService$ChildExecutorRunnable.run(VirtualExecutorService.java:175) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) ""NamingBootstrap Pool(1)-1"" daemon prio=10 tid=0x00007f253c4f8800 nid=0x45fc runnable [0x00007f25842a3000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398) at java.net.ServerSocket.implAccept(ServerSocket.java:522) at java.net.ServerSocket.accept(ServerSocket.java:490) at org.jnp.server.Main$AcceptHandler.run(Main.java:481) at org.jboss.util.threadpool.RunnableTaskWrapper.run(RunnableTaskWrapper.java:148) at EDU.oswego.cs.dl.util.concurrent.PooledExecutor$Worker.run(Unknown Source) at java.lang.Thread.run(Thread.java:722) ""RMI TCP Accept-1098"" daemon prio=10 tid=0x00007f253c4f4800 nid=0x45fb runnable [0x00007f25843a4000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398) at java.net.ServerSocket.implAccept(ServerSocket.java:522) at java.net.ServerSocket.accept(ServerSocket.java:490) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:387) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:359) at java.lang.Thread.run(Thread.java:722) ""RMI TCP Accept-0"" daemon prio=10 tid=0x00007f253cc2d800 nid=0x45e6 runnable [0x00007f25859b9000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398) at java.net.ServerSocket.implAccept(ServerSocket.java:522) at java.net.ServerSocket.accept(ServerSocket.java:490) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:387) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:359) at java.lang.Thread.run(Thread.java:722) ""RMI TCP Accept-40001"" daemon prio=10 tid=0x00007f253cc16000 nid=0x45da runnable [0x00007f25865c5000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398) at java.net.ServerSocket.implAccept(ServerSocket.java:522) at java.net.ServerSocket.accept(ServerSocket.java:490) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:387) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:359) at java.lang.Thread.run(Thread.java:722) ""Multicast Heartbeat Receiver Thread"" daemon prio=10 tid=0x00007f253cc18000 nid=0x45d8 runnable [0x00007f25867c7000] java.lang.Thread.State: RUNNABLE at java.net.PlainDatagramSocketImpl.receive0(Native Method) - locked <0x00000006ab145b28> (a java.net.PlainDatagramSocketImpl) at java.net.AbstractPlainDatagramSocketImpl.receive(AbstractPlainDatagramSocketImpl.java:145) - locked <0x00000006ab145b28> (a java.net.PlainDatagramSocketImpl) at java.net.DatagramSocket.receive(DatagramSocket.java:786) - locked <0x000000067ffd9240> (a java.net.DatagramPacket) - locked <0x00000006ab1459f0> (a java.net.MulticastSocket) at net.sf.ehcache.distribution.MulticastKeepaliveHeartbeatReceiver$MulticastReceiverThread.run(MulticastKeepaliveHeartbeatReceiver.java:124) ""Tribes-MembershipReceiver"" daemon prio=10 tid=0x00007f259895c800 nid=0x45d0 runnable [0x00007f258733a000] java.lang.Thread.State: RUNNABLE at java.net.PlainDatagramSocketImpl.receive0(Native Method) - locked <0x00000006b8163208> (a java.net.PlainDatagramSocketImpl) at java.net.AbstractPlainDatagramSocketImpl.receive(AbstractPlainDatagramSocketImpl.java:145) - locked <0x00000006b8163208> (a java.net.PlainDatagramSocketImpl) at java.net.DatagramSocket.receive(DatagramSocket.java:786) - locked <0x00000006b8158768> (a java.net.DatagramPacket) - locked <0x00000006b7b4fc30> (a java.net.MulticastSocket) at org.apache.catalina.tribes.membership.McastServiceImpl.receive(McastServiceImpl.java:340) at org.apache.catalina.tribes.membership.McastServiceImpl$ReceiverThread.run(McastServiceImpl.java:534) ""NioReceiver"" daemon prio=10 tid=0x00007f259892f000 nid=0x45cf runnable [0x00007f258743b000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:228) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:81) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87) - locked <0x00000006b8155008> (a sun.nio.ch.Util$2) - locked <0x00000006b8155020> (a java.util.Collections$UnmodifiableSet) - locked <0x00000006b78650a8> (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98) at org.apache.catalina.tribes.transport.nio.NioReceiver.listen(NioReceiver.java:281) at org.apache.catalina.tribes.transport.nio.NioReceiver.run(NioReceiver.java:420) at java.lang.Thread.run(Thread.java:722) ""NioReceiver"" daemon prio=10 tid=0x00007f259892f000 nid=0x45cf runnable [0x00007f258743b000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:228) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:81) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87) - locked <0x00000006b8155008> (a sun.nio.ch.Util$2) - locked <0x00000006b8155020> (a java.util.Collections$UnmodifiableSet) - locked <0x00000006b78650a8> (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98) at org.apache.catalina.tribes.transport.nio.NioReceiver.listen(NioReceiver.java:281) at org.apache.catalina.tribes.transport.nio.NioReceiver.run(NioReceiver.java:420) at java.lang.Thread.run(Thread.java:722) ""RMI TCP Accept-0"" daemon prio=10 tid=0x00007f25982e0800 nid=0x45cc runnable [0x00007f258c7a6000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398) at java.net.ServerSocket.implAccept(ServerSocket.java:522) at java.net.ServerSocket.accept(ServerSocket.java:490) at sun.management.jmxremote.LocalRMIServerSocketFactory$1.accept(LocalRMIServerSocketFactory.java:52) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:387) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:359) at java.lang.Thread.run(Thread.java:722) ""RMI TCP Accept-9004"" daemon prio=10 tid=0x00007f25982cb000 nid=0x45cb runnable [0x00007f258c8a7000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398) at java.net.ServerSocket.implAccept(ServerSocket.java:522) at java.net.ServerSocket.accept(ServerSocket.java:490) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:387) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:359) at java.lang.Thread.run(Thread.java:722) ""RMI TCP Accept-0"" daemon prio=10 tid=0x00007f25982a7000 nid=0x45ca runnable [0x00007f258c9a8000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398) at java.net.ServerSocket.implAccept(ServerSocket.java:522) at java.net.ServerSocket.accept(ServerSocket.java:490) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:387) at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:359) at java.lang.Thread.run(Thread.java:722) ""Service Thread"" daemon prio=10 tid=0x00007f259817a800 nid=0x45c9 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE ""C2 CompilerThread1"" daemon prio=10 tid=0x00007f2598178000 nid=0x45c8 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE ""C2 CompilerThread0"" daemon prio=10 tid=0x00007f2598175800 nid=0x45c7 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE ""Signal Dispatcher"" daemon prio=10 tid=0x00007f2598173800 nid=0x45c6 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE ""Surrogate Locker Thread (Concurrent GC)"" daemon prio=10 tid=0x00007f2598171800 nid=0x45c5 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE ""VM Thread"" prio=10 tid=0x00007f259811c000 nid=0x45c2 runnable ""Gang worker#0 (Parallel GC Threads)"" prio=10 tid=0x00007f2598012000 nid=0x45bd runnable ""Gang worker#1 (Parallel GC Threads)"" prio=10 tid=0x00007f2598014000 nid=0x45be runnable ""Gang worker#2 (Parallel GC Threads)"" prio=10 tid=0x00007f2598015800 nid=0x45bf runnable ""Gang worker#3 (Parallel GC Threads)"" prio=10 tid=0x00007f2598017800 nid=0x45c0 runnable ""Concurrent Mark-Sweep GC Thread"" prio=10 tid=0x00007f25980a6800 nid=0x45c1 runnable ""VM Periodic Task Thread"" prio=10 tid=0x00007f25982e3000 nid=0x45cd waiting on condition All of this seems VERY busy for a server that has just started up has no replication peers and has not yet accepted any requests. Ideas? It looks like the JVM is doing network-related things. I'd try the following to see if they reveal any clues: Use a packet monitor to see if there is incoming / outgoing network traffic on your ethernet or loopback. Use strace to see what syscalls the JVM is making Check the Tomcat log files. And as an experiment change the logging configs so that you can see all DEBUG logging. Check the system logs including the security logs (if you have SELinux enabled.) You could also try tweaking the tomcat configs to not use APR and see if that makes any difference. Thanks Stephen using some of your suggestions plus the addition of jvisualvm I have been able to narrow the issue down to Netty/HornetQ. It seems HornetQ is eating up CPU and at least I know where to look now. @Clebert Using jvisualvm I was able to see there are 2 NIO worker threads that are eating up the CPU cores. They trace back to Netty/HornetQ. So I decided to drop the number of consumers I had down to a handful and the CPU usage dropped right along with it. The thing is these consumers are not actually doing anything but checking the empty queues. Do you have any suggestions how I might go about troubleshooting this further? Since I have been able to track the issue down to the HornetQ consumers I will close this one out and start a new question regarding the HornetQ issue I am having. Thanks again for your help. All these threads are idle (blocked). I don't see any reason for the spike... Maybe there's something on the native side... ... I would also check the Apr settings. I don't see anything on HornetQ going on BTW"
656,A,When do we have to release ByteBuffer in netty5 by calling ByteBuffer.release()? Can you somebody give me a general guideline about using ByteBuffer correctly in Netty5? I don't know when I should call release on an allocated bytebuffer? For example i have this one:  ByteBuf buf = Unpooled.wrappedBuffer(String.valueOf(new Date()).getBytes(CharsetUtil.UTF_8)); ctx.channel().writeAndFlush(new PingWebSocketFrame(buf)); buf.release(); Do I have to call release on Unpooled bytebuffer? Thanks Check out our documentation... Should be quite clear here: http://netty.io/wiki/reference-counted-objects.html
657,A,"Keeping state in a Netty ChannelHandler The netty documentation suggest using instance variables in ChannelHandlers to keep track of channel state. It doesn't mention that you should use volatile variables or use any other synchronization technique to assure that there is a consistent view across threads. For instance using this handler on a per-connection basis: class Handler extends SimpleChannelUpstreamHandler { int count = 0; @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { ++count; } } I would expect that many different threads from a netty thread pool would be calling this method although not concurrently and could potentially see an inconsistent view resulting in an inaccurate count. Is this the case? or is there some kind of synchronization going on inside of netty that would cause the write to the count field to be flushed? When you create a Netty ChannelPipeline if you add the same instance of your Handler to all the channels then yes multiple threads will read/modify your data. If you create a new instance of Handler per channel in your pipeline as shown below then you are safe only one thread will access the handler in the pipeline at a time then. ChannelPipeline p = Channels.pipeline(); pipeline.addLast(""handler"" new Handler()); Also take a look at Netty ChannelLocal its like java ThreadLocal and you can set the state on a per channel basis Right I figured that only one thread would ever access the handler concurrently but that dosent guarantee that the second thread that accesses the handler will see the changes made by the first thread unless netty is doing a volatile write or something else that guarantees visibility  If you do not have an executor in your pipeline and are executing your handlers purely in the I/O worker threads then you're fine as Netty guarantees that a given pipeline instance is always called back from the same worker thread. If you're adding an execution handler to your pipeline then you are ok if you're using Netty's OrderedMemoryAwareThreadPoolExecutor. If you are accessing your pipeline from a non-Netty thread or you have a non-OrderedMemoryAwareThreadPoolExecutor in your pipeline then you need synchronisation. I recommend taking a look through the following threads on the Netty user forum archives. http://netty.markmail.org/search/?q=Memory+visibility+in+handlers#query:Memory%20visibility%20in%20handlers+page:1+mid:cmtw5omcxbg67sho+state:results http://netty.markmail.org/search/?q=Periodic%20TimerTask%20in#query:Periodic%20TimerTask%20in+page:2+mid:vwahepiois4eqwkp+state:results Thanks! that's what i was looking for ""Netty guarantees that a given pipeline instance is always called back from the same worker thread"""
658,A,"Shared SimpleChannelHandler netty first of all thank you to get on this question. I've been finding for long time an answer to my question but badly there isn't any :/ What do you think it has better perfomance for a NIO environment (NETTY): Instantiating the HandlerClass each time a connection arrives or using a shared HandlerClass ? I.E: ...getPipeline() { pipeline = ...; pipeline.addLast(""handler"" new HandlerClass()); } OR: private handlerClass handler = new HandlerClass(); ...getPipeline() { pipeline = ...; pipeline.addLast(""handler"" this.handler); } My gaming server will receive more than 1000 connections and that's a thing that i'm worrying about. Thank you! It is quite easy... If your SimpleChannelHandler has no state stored in vars reuse it. His way you remove the init cost of the new class and also hace less GC pressure. If you not have any ""synchronized"" etc in your handler it will not slow down things at all. As there will be no need to ""fight"" for a lock But since the messageReceived(..) / writeRequested(..) methods will be accessed from lots of channels (connections) at the same time wouldn't be saturated and in consequence slow to access & process data? Thank you! I've read the following statement some time ago and it's what i'm worrying about: ""in a multi-threaded application remember that there is only one 'instance' of a Shared/static class and that each thread with access to it will call the same thing leading to possible thread locks and data corruption."" I'm worrying about threads waiting to access the Shared Class functions.  Sounds to me like you're looking to create a pooling system for your handler. Assuming one handler can only handle one request at a time and you're app is highly concurrent. This way you can keep handler object instantiated in memory for better performance. I've had some luck using pool4j. If that doesn't work for you you will probably be best off writing your own pool. http://code.google.com/p/pool4j/ Also poolit is a more generic library that I haven't personally used but I've heard good things about: http://programming.huyduong.com/poolit/index.html Netty auto-pools it by adding an executor to the pipeline private handlerClass handler = new HandlerClass(); ...getPipeline() { pipeline = ...; pipeline.addLast(""executor"" new ExecutionHandler(new OrderedMemoryAwareThreadPoolExecutor(...))); // EXECUTOR MUST BE SHARED }"
659,A,"Netty: getting remote ip address in messageReceived In my class (extends SimpleChannelHandler) I'm trying to get the ip where the message was originally sent from. @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent ev) throws Exception { String host = ((InetSocketAddress)ctx.getChannel().getRemoteAddress()).getAddress().getHostAddress(); int port = ((InetSocketAddress)ctx.getChannel().getRemoteAddress()).getPort(); LOG.debug(String.format(""host:%s port:%d"" host port)); .. This prints ip 10.0.0.1 (gateway) instead of the correct client address (10.52.45.4). Is there any way to get the ip i'm trying to or could there be something wrong with the network configuration ? I guess you see the gateway ip because the gateway does some kind of NAT. If so the only change you have is to include the source-ip address in your protocol and extract it from there. That seems to be the case. I decided it's better to do as you suggested and included the source-ip (or id in this case) in the protocol. Thanks."
660,A,Integer encoder decoder for Netty I want to stream a series of integers across a Netty channel. Right now  in my code channel.write(Integer.valueOf(val)  I get the error java.lang.IllegalArgumentException: unsupported message type: class java.lang.Integer which I understand is because I do not have any integer encoder /decoder as a handler in the pipeline. Is this correct? Do I have to write my own integer decoder or there is one available to use ? Some guidance around this topic will be extremely helpful. Yup your understanding is correct. Without an appropriate FrameEncoder in your pipeline Netty is going to throw up its hands and say it doesn't know how to deal with an Integer. If you want to add an off-the-shelf component you can add an ObjectEncoder and ObjectDecoder to your pipeline. Otherwise you'll want to implement your own frame encoder and decoders.  Yes this is the case... You can also just write it in a ChannelBuffer and then write the ChannelBuffer to the Channel. Something like: ChannelBuffer buf = ChannelBuffers.buffer(4); buf.writeInt(Integer.valueOf(val)); channel.write(buf);
661,A,Improve performance on write-only table? I am using MySQL 5.5 with innoDB. The basis of my server is Netty JDBC and BoneCP. I have a log table that contains user inputs(HTTP header request body etc). This table will only be read very rarely for reasons like security and data recovery. Therefore the read performance is not something we care about. There are five columns in this table. Name | Type -------------------------------------------------- logID | big Integer(auto-increment)(primary key) userNumber | medium integer logTime | timestamp header | varchar(100) body | varchar(200) What are some tips that will improve the insert performance? Also is the logID neccessary for this case? Avoid indexes besides the one on the auto-increment. If the table is never referenced why do you use any key at all in there? It's not like it's necessary. It only adds to the insert time and serves no purpose. My suggestion would be to drop the logID and not create any indexes on the table at all. Another optimization would be to change the table type to myISAM. When you only insert and have no constraints on the table InnoDB will cost you time for the option of ACID compliance while myISAM doesn't care about that. I agree about the ACID compliance. However(correct me if I'm wrong) MyISAM does not support row level locking. Concurrency is important to be because blocking I/O is a bad practice when using Netty(which I use). I'm sorry I am not familiar with Netty. I can only tell you that in my experience you can do several dozen inserts per second into such a table I described with no locking problems whatsoever as there is no locking occuring.
662,A,"Netty HTTP-server big file upload OutOfMemoryError First of all sorry for my crooked English :) I have some problems during writing Netty http server that sends/receives large files (~2Gb). And I would very appreciate anybody help or explanation. My client application (web-browser) sends files via XMLHttpRequest like this:  var sampleFile = document.getElementById(""sampleFile"").files[0]; //chosen file by <input type=""file"" .../> var xhr = new XMLHttpRequest(); xhr.open(""POST""""http://127.0.0.1:8091/upload/some_file_name.txt"" true); xhr.send(sampleFile); Server side is: class WebSocketServer:  ServerBootstrap bootstrapHttp = new ServerBootstrap( new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); bootstrapHttp.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { ChannelPipeline pipeline = pipeline(); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""aggregator"" new HttpChunkAggregator(1024*1024*1024)); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""deflater"" new HttpContentCompressor()); pipeline.addLast(""handler"" new HttpRequestServerHandler()); return pipeline; } }); bootstrapHttp.bind(new InetSocketAddress(port)); class HttpRequestServerHandler: public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { Object msg = e.getMessage(); if (msg instanceof HttpRequest) { HttpRequest req = (HttpRequest)msg; if (req.getMethod() != POST) { return; } if (decodedURI.startsWith(UPLOAD_FILE_PATH)) { HttpRequest request = (HttpRequest) e.getMessage(); RandomAccessFile raf = new RandomAccessFile(""foobar.tmp"" ""rw""); ChannelBuffer buf = request.getContent(); FileChannel fChannel = raf.getChannel(); Channel msgChannel= e.getChannel(); fChannel.write( buf.toByteBuffer() ); raf.close(); fChannel.close(); msgChannel.close(); } } When I send middle size file everything works wonderfully. The problem is with large files (>300Mb). After some time processing exception occures: java.lang.OutOfMemoryError: Java heap space at org.jboss.netty.buffer.HeapChannelBuffer.(HeapChannelBuffer.java:47) at org.jboss.netty.buffer.BigEndianHeapChannelBuffer.(BigEndianHeapChannelBuffer.java:39) at org.jboss.netty.buffer.ChannelBuffers.buffer(ChannelBuffers.java:139) at org.jboss.netty.buffer.HeapChannelBufferFactory.getBuffer(HeapChannelBufferFactory.java:73) at org.jboss.netty.buffer.DynamicChannelBuffer.ensureWritableBytes(DynamicChannelBuffer.java:84) at org.jboss.netty.buffer.DynamicChannelBuffer.writeBytes(DynamicChannelBuffer.java:239) at org.jboss.netty.buffer.AbstractChannelBuffer.writeBytes(AbstractChannelBuffer.java:457) at org.jboss.netty.buffer.AbstractChannelBuffer.writeBytes(AbstractChannelBuffer.java:450) at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:140) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:302) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.unfoldAndFireMessageReceived(ReplayingDecoder.java:522) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:506) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:443) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:351) It even don't reach my messageReceived handler. As I can assume some inner ChannelBuffer is overflowed. I've tried to increase HttpChunkAggregator(1024*1024*1024) parameter. However It would not helped. I see just one solution - to split file on the client side (using html5) send these chunks and paste them together on server. But its seems to quite complex. Is there any easier way to fix it (in Netty scope)? Thank you! Best regards. The fact that it's in something called HeapChannelBuffer says a lot - you probably want org.jboss.netty.buffer.DirectChannelBufferFactory somewhere in there so that your data isn't stored on the heap.  I think you should not use HttpChunkAggregator. This means that you will have to manually handle HTTP chunks. See Netty file upload example for more details. Thanks a lot for the example above - just started to analyze it. Seems it's exactly that I need :)  Yeah a bette way would be to ""push"" byte[] chunks to the fs until the upload is complete. So you don't need to hold everything in the memory. Be aware that the writing to the fs may ""block"" so you should think about adding an ExecutionHandler in front of it."
663,A,"About UDP server setting in netty Now I am implementing UDP server to gather sflow datagrams using netty library. Here is my setting for udp server. ChannelFactory factory = new NioDatagramChannelFactory(this.threadPool.getScheduledExecutor()); ConnectionlessBootstrap bootstrap = new ConnectionlessBootstrap(factory); bootstrap.setPipelineFactory(new ChannelPipelineFactory(){ public ChannelPipeline getPipeline(){ ChannelPipeline lChannelPipeline = Channels.pipeline(); lChannelPipeline.addLast(""sflowmessagedecoder"" new SflowMessageDecoder()); lChannelPipeline.addLast(""handler"" new SflowCollectorHandler()); return lChannelPipeline; } }); bootstrap.setOption(""receiveBufferSize"" 65536); bootstrap.bind(new InetSocketAddress(port)); The problem is that when I receive a sflow datagram (about 1300 bytes long this can be checked using wireshark) netty only reads about 700 bytes this can be checked by channelbuffer's size of the datagram from the channelbuffer. However I use java.net.* libraries such as DatagramSocket.class and DatagramPacket.class it receives sflow datagram correctly (about 1300 bytes). Somebody can help me? Due to this I cannot parse sflow datagram correctly. Thanks. I have not tested this out but give it a try could work for you. org.jboss.netty.channel.FixedReceiveBufferSizePredictorFactory bufferSizePredictor = new FixedReceiveBufferSizePredictorFactory(1300);// or whatever size you require. serverBootstrap.setOption(""receiveBufferSizePredictorFactory"" bufferSizePredictor); Once you set this predictor factory it might help.  I had the same Issue try using Oio and not Nio! (simply change ""nio"" to ""oio"" and ""Nio"" to ""Oio"". http://lists.jboss.org/pipermail/netty-users/2009-June/000891.html Now it's working ;)"
664,A,"Disable WebSocket logging Running a WebSocket application (e.g. WebSocketServer) I am getting plenty of debugging messages like this: 18.02.2012 18:35:17 io.netty.handler.codec.http.websocketx.WebSocket08FrameEncoder FEIN: Encoding WebSocket Frame opCode=1 length=20 18.02.2012 18:35:17 io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder FEIN: Decoding WebSocket Frame opCode=1 18.02.2012 18:35:17 io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder FEIN: Decoding WebSocket Frame length=16 18.02.2012 18:35:17 io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder FEIN: Decoding WebSocket Frame opCode=8 18.02.2012 18:35:17 io.netty.handler.codec.http.websocketx.WebSocket08FrameDecoder FEIN: Decoding WebSocket Frame length=2 Unfortunately I didn't find a way to deactivate them. Where can I do it? By default Netty use jdk logging API as its logging engine. This messages are logged via DEBUG loglevel so you just need to setup the logging to not print out debug messages for this class. Oh damn... I was running an old version which contained `ConsoleHandler ch = new ConsoleHandler(); ch.setLevel(Level.FINE); Logger.getLogger("""").addHandler(ch); Logger.getLogger("""").setLevel(Level.FINE);`"
665,A,Is is possible to write and read from a channel repeatedly? I am trying to write and read from a channel repeatedly but failed at the second writing attemption because the channel was already closed by the NioWorker after the first response was read. I googled a whole day but failed to find any clue. What shall I do to perform write-read-write-read operations on the same channel? Part of org.jboss.netty.channel.socket.nio.NioWorker source code: private void processSelectedKeys(Set<SelectionKey> selectedKeys) throws IOException { for (Iterator<SelectionKey> i = selectedKeys.iterator(); i.hasNext();) { SelectionKey k = i.next(); i.remove(); try { int readyOps = k.readyOps(); if ((readyOps & SelectionKey.OP_READ) != 0 || readyOps == 0) { if (!read(k)) { // Connection already closed - no need to handle write. continue; } } if ((readyOps & SelectionKey.OP_WRITE) != 0) { writeFromSelectorLoop(k); } } catch (CancelledKeyException e) { close(k); } if (cleanUpCancelledKeys()) { break; // break the loop to avoid ConcurrentModificationException } } } private boolean read(SelectionKey k) { final SocketChannel ch = (SocketChannel) k.channel(); final NioSocketChannel channel = (NioSocketChannel) k.attachment(); final ReceiveBufferSizePredictor predictor = channel.getConfig().getReceiveBufferSizePredictor(); final int predictedRecvBufSize = predictor.nextReceiveBufferSize(); int ret = 0; int readBytes = 0; boolean failure = true; ByteBuffer bb = recvBufferPool.acquire(predictedRecvBufSize); try { while ((ret = ch.read(bb)) > 0) { readBytes += ret; if (!bb.hasRemaining()) { break; } } failure = false; } catch (ClosedChannelException e) { // Can happen and does not need a user attention. } catch (Throwable t) { fireExceptionCaught(channel t); } if (readBytes > 0) { bb.flip(); final ChannelBufferFactory bufferFactory = channel.getConfig().getBufferFactory(); final ChannelBuffer buffer = bufferFactory.getBuffer(readBytes); buffer.setBytes(0 bb); buffer.writerIndex(readBytes); recvBufferPool.release(bb); // Update the predictor. predictor.previousReceiveBufferSize(readBytes); // Fire the event. fireMessageReceived(channel buffer); } else { recvBufferPool.release(bb); } // NioWorker closes the channel making it impossible to write additional messages. if (ret < 0 || failure) { k.cancel(); // Some JDK implementations run into an infinite loop without this. close(channel succeededFuture(channel)); return false; } return true; } You're very cavalier about ignoring 'ClosedChannelException'. This *cannot* happen unless you have a bug in your application. Netty does not close a connection unless a user closed it or the peer closed it. Please make sure there was no exception raised.
666,A,How to pause and resume reading with Netty 4? In Netty 3 we can do: Channel.setReadable(false); Channel.setReadable(true); I've read: http://netty.io/news/2012/09/13/4-0-0-alpha4.html But with the latest Netty 4 version (4.0.17 http://netty.io/news/2014/02/25/4-0-17-Final.html) this code is invalid because there's no ChannelHandlerContext#readable: serverChannel.pipeline().firstContext().readable(false); serverChannel.pipeline().firstContext().readable(true); Use channel.config.setAutoRead(false) and channel.config.setAutoRead(true).
667,A,"configure netty to only have one selector thread? We are trying to debug a very nasty issue that appears to happen on netty 3.6.0 3.6.7 and 3.8.0 on linux and MAC so far. We can reproduce it pretty well(not extremely easy but pretty well). What happens is we open a web page which then results in chrome sending around 15 requests for css files js files etc. etc. One of the requests from chromes always hangs. Digging in deeper we see the request reach the server in wireshark but we never see the request come into the playframework server. All the other requests come in fine. We literally have to fiddle around with websockets to get it into this weird state(not sure if something around websockets in netty is screwed up or not). We would like to configure the netty pool to only have ONE worked thread to simplify debugging and see if the issue goes away. Is it possible to configure the number of threads running on the selector? This post How Netty uses thread pools? looks like it suggested executors upstream which is not what I want. thanks Dean Pass ""1"" in the the NioServerSocketChannelFactory constructor as last argument."
668,A,"channel handler did not write message on netty 4.0 I wrote simple ChannelHandler like this. public class SimpleServerHandler extends SimpleChannelInboundHandler<Object> { @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.write(""Welcome to "" + InetAddress.getLocalHost().getHostName() + ""!\r\n""); ctx.write(""It is "" + new Date() + "" now.\r\n""); ctx.flush(); } @Override protected void channelRead0(ChannelHandlerContext ctx Object msg) throws Exception { } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.writeAndFlush(""=>complete""); System.out.println(""complete""); }; @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { // Close the connection when an exception is raised. cause.printStackTrace(); ctx.close(); } } This handler works show welcome message if client(telnet) connect to server. And show complete message if read complete. I try to connect server but any message response from server(but I confirmed system log). I can't understand why. P.S : I attach code how boot server public class SimpleServer { public static void main(String... args) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup); b.channel(NioServerSocketChannel.class); b.childHandler(new ChannelInitializer<Channel>() { @Override protected void initChannel(Channel ch) throws Exception { ch.pipeline().addLast(new SimpleServerHandler()); } }); b.option(ChannelOption.SO_BACKLOG 128); b.childOption(ChannelOption.SO_KEEPALIVE true); ChannelFuture f = b.bind(""127.0.0.1"" 8080).sync(); f.channel().closeFuture().sync(); } finally { workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } } } As you write a String you need to put a StringEncoder in the ChannelPipeline. If you add a ChannelFutureListener to the ChannelFuture that was returned by the write(...) you will see an error . Thank you. You're right. I fixed it use StringEncoder. Also I could convert String to byte array."
669,A,Netty OIO or NIO I have multi stages network infrastructure. Layer 1 has 8 servers receive data from 10000 clients every second. I'd like to write proxy layer with about 2 or 3 instances to transfer data from layer 1 to backend layer. I found Netty quite convenient for me to write such a program like this. But I still confuse between NIO or OIO because I only have 8 servers meanwhile in document of Netty says that OIO for server has lower than 1000 connection more than that should use NIO. I'm afraid that using OIO will block the stream and make some messages delay. I need to response to the clients instantaneously after receive the request. May anyone suggest me the solution I'm new to network and Netty. Codewise choosing one or another is indifferent your code will look be the same. Write your solution and benchmark both cases pick the one that works best and be happy. There isn't a one size fits all solution. Most likely you want to use NIO. Only use OIO if you really need too :)
670,A,Good open source projects using Netty framework Are there any good open source projects that use Netty? I have seen seen some of the examples in http://netty.io/docs/. I want to see how it is being used in a real world scenario. How do they separate the network layer from the business logic etc and other best practices. Thanks! Here's a good list of open and closed source projects using Netty. https://github.com/netty/netty/wiki/Related-projects Hope this helps.  Shameless plug: Here is a java game server I have written using Netty. Shameless ovation... and it's pretty good novel to read like a great book :) @Abe do you have any overview of your applocation architecture? i want to understand how you have implemented your game server with netty so that i can implement my project with netty @javaseeker this wiki is a little bit outdated but it should give you a good idea. I havent drawn up a diagram though! https://github.com/menacher/java-game-server/wiki/Jetserver-internal-details-and-how-it-works. thanks.i have started development of my project with netty. first thing socketchannel.write() asynchronus? second thing is it logical to handle db operation from business logic handler because db operation take some time . any idea? all write operations are async in netty. Time consuming operations should be done in another thread. But netty provides a mechanism to run the business handler itself in another thread.
671,A,Netty 4 Pipeline for JSON over Websocket I want to use Netty as a websocket server. On top I'd like to send JSON between the browser and the server for data interchange. The websocket part works already fine (I'm using this code: https://github.com/raphaelstary/jsug-netty-example). Now I'd like to integrate a JSON Encoder/Deocoder into the pipeline. I found some code in the Netty Repo I would like to use (still beta but I wanna try: https://github.com/netty/netty/commit/479b0fe43b6f9a06143cb39f09c51615df90fd1e) Question: how do I use the Encoder/Decoder in the Pipeline in order to receive and send JSON Objects in my Handler? Instead of using the JSON codec you mentioned you could just send and receive a TextWebSocketFrame which contains the JSON string as its content and feed the JSON string into your favorite JSON library such as Jackson
672,A,How large data can I exchange without worrying about using decoder with Netty? I have a system that relies on Netty to exchange relatively short Gson strings: typically under couple of hundred bytes sometimes a few KBs. Do I need to worry about losing packets and therefore implement Decoder into my server/client or would it be (mostly) okay? This depends on how your client is connecting to your server. For instance if you are using TCP then you do not have to directly worry about packet loss in your code since the protocol itself is responsible for automatically re-transmitting any lost packets (as well as ensuring the order of the packets that arrive). However if you are using UDP then packet loss is possible and you will have to deal with detecting and re-transmitting lost packets (as well as ordering concerns etc). Also depending on how you are decoding your message you may need to consider that a single message may be broken up into multiple frames that are sent as separate packets. To manage this you may need to implement something like a FrameDecoder. Thanks it makes perfect sense. I am indeed transmitting over TCP with single frame per message. I see. I will look into it a bit more. Thanks again. @ntrolls Careful you cannot necessarily guarantee how many frames your message will be broken up into. This could depend on OS settings and underlying buffer sizes etc. I think that in theory it may be possible for any message to be broken up into multiple frames no matter how small the message is.
673,A,"what is the correct usage for StringEncoder and StringDecoder with a netty server? Is the string based server below functionally equivalent to its datagram server brethren? The only notable difference I see and the only difference I'm trying to achieve is to go from NioDatagramChannel to nioServerSocketChannel. There are some minor differences between the handlers but do both handlers respond to ""QOTM"" with nextQuote()? For brevity and sanity I cannot include the client. I'm unfamiliar with netty and there's simply not much 4.x documentation on this topic I can find. Netty in Action does say: 7.2.4 MessageToMessageDecoder – Decode POJO’s on the fly If you want to decode a message to another type of message MessageToMessageDecoder is the way to go. It allows an easy way to do so. The semantic is quite the same as for all the other decoders we explained before. But for simplicity I'm just trying to utilize String en/de-coders for the time being. Am I using them correctly in the server? see also: http://seeallhearall.blogspot.ca/2012/05/netty-tutorial-part-1-introduction-to.html datagram server: package net.bounceme.dur.netty; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioDatagramChannel; import java.util.logging.Logger; import net.bounceme.dur.netty.datagram.DatagramServerInitializer; public final class DatagramServer { private static final Logger log = Logger.getLogger(DatagramServer.class.getName()); public void start() throws InterruptedException { MyProps p = new MyProps(); int port = p.getServerPort(); pingPong(port); } private void pingPong(int port) throws InterruptedException { log.fine(""which handler?""); EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioDatagramChannel.class) .option(ChannelOption.SO_BROADCAST true) .handler(new DatagramServerInitializer()); b.bind(port).sync().channel().closeFuture().await(); } finally { group.shutdownGracefully(); } } } string server: package net.bounceme.dur.netty; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioServerSocketChannel; import java.util.logging.Logger; import net.bounceme.dur.netty.string.StringServerInitializer; public final class StringServer { private static final Logger log = Logger.getLogger(StringServer.class.getName()); public void start() throws InterruptedException { MyProps p = new MyProps(); int port = p.getServerPort(); pingPong(port); } private void pingPong(int port) throws InterruptedException { log.fine(""which handler?""); EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BROADCAST true) .handler(new StringServerInitializer()); b.bind(port).sync().channel().closeFuture().await(); } finally { group.shutdownGracefully(); } } } datagram server handler: package net.bounceme.dur.netty.datagram; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.channel.socket.DatagramPacket; import io.netty.util.CharsetUtil; import java.util.Random; import java.util.logging.Logger; public class DatagramServerHandler extends SimpleChannelInboundHandler<DatagramPacket> { private static final Logger log = Logger.getLogger(DatagramServerHandler.class.getName()); private static final Random random = new Random(); public DatagramServerHandler() { log.info(""..started..""); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { super.channelActive(ctx); ctx.writeAndFlush(nextQuote()); } // Quotes from Mohandas K. Gandhi: private static final String[] quotes = { ""Where there is love there is life."" ""First they ignore you then they laugh at you then they fight you then you win."" ""Be the change you want to see in the world."" ""The weak can never forgive. Forgiveness is the attribute of the strong.""}; private static String nextQuote() { int quoteId; synchronized (random) { quoteId = random.nextInt(quotes.length); } return quotes[quoteId]; } @Override public void channelRead0(ChannelHandlerContext ctx DatagramPacket packet) throws Exception { log.info(packet.toString()); if (""QOTM?"".equals(packet.content().toString(CharsetUtil.UTF_8))) { ctx.write(new DatagramPacket( Unpooled.copiedBuffer(""QOTM: "" + nextQuote() CharsetUtil.UTF_8) packet.sender())); } } @Override public void channelReadComplete(ChannelHandlerContext ctx) { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { log.severe(cause.toString()); } } datagram server initializer: package net.bounceme.dur.netty.datagram; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.nio.NioDatagramChannel; import io.netty.handler.codec.DelimiterBasedFrameDecoder; import io.netty.handler.codec.Delimiters; import java.util.logging.Logger; public class DatagramServerInitializer extends ChannelInitializer<NioDatagramChannel> { private static final Logger log = Logger.getLogger(DatagramServerInitializer.class.getName()); public DatagramServerInitializer() { log.info(""..initializing..""); } @Override protected void initChannel(NioDatagramChannel c) throws Exception { log.info(""..adding to pipeline..""); ChannelPipeline pipeline = c.pipeline(); pipeline.addLast(new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(new DatagramServerHandler()); } } string server handler: package net.bounceme.dur.netty.string; import net.bounceme.dur.netty.datagram.DatagramServerHandler; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import java.util.Random; import java.util.logging.Logger; public class StringServerHandler extends SimpleChannelInboundHandler<String> { private static final Logger log = Logger.getLogger(DatagramServerHandler.class.getName()); private static final Random random = new Random(); public StringServerHandler() { log.info(""..started..""); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { super.channelActive(ctx); ctx.writeAndFlush(nextQuote()); } // Quotes from Mohandas K. Gandhi: private static final String[] quotes = { ""Where there is love there is life."" ""First they ignore you then they laugh at you then they fight you then you win."" ""Be the change you want to see in the world."" ""The weak can never forgive. Forgiveness is the attribute of the strong.""}; private static String nextQuote() { int quoteId; synchronized (random) { quoteId = random.nextInt(quotes.length); } return quotes[quoteId]; } @Override public void channelReadComplete(ChannelHandlerContext ctx) { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { log.severe(cause.toString()); } @Override protected void channelRead0(ChannelHandlerContext chc String msg) throws Exception { System.err.println(msg); if (""QOTM?"".equals(msg)) { chc.writeAndFlush(nextQuote()); } else { log.warning(msg); //never executes } } } string server initializer: package net.bounceme.dur.netty.string; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.ServerSocketChannel; import io.netty.handler.codec.DelimiterBasedFrameDecoder; import io.netty.handler.codec.Delimiters; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.codec.string.StringEncoder; import java.util.logging.Logger; public class StringServerInitializer extends ChannelInitializer<ServerSocketChannel> { private static final Logger log = Logger.getLogger(StringServerInitializer.class.getName()); public StringServerInitializer() { log.info(""..initializing..""); } @Override protected void initChannel(ServerSocketChannel c) throws Exception { log.info(""..adding to pipeline..""); ChannelPipeline pipeline = c.pipeline(); pipeline.addLast(new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(new StringDecoder()); pipeline.addLast(new StringEncoder()); pipeline.addLast(new StringServerHandler()); } } You do appear to be using the string encoders correctly in the TCP version. However TCP and UDP are not the same. With a TCP connection the first incoming handler in your pipeline will receive a buffer containing data read from the socket buffers. The socket (and therefore channel) is bound to a socket on the remote peer and therefore the channel contains all the information required to communicate with the remote peer. This includes the remote address and port. Netty may also create a separate pipeline instance attached to that channel (depends on how you set it up). Although the API is similar UDP acts very differently. It's not a stream but a set of discrete datagram packets and a single channel will receive datagram packets from many different senders. The first incoming handler in your pipeline will receive a DatagramPacket containing at least your payload (your message) and the sender. DelimiterBasedFrameDecoder cannot work on a DatagramPacket - it expects a ByteBuf and is designed to work with streams where the message may be read in multiple chunks (see Dealing with a Stream-based Transport in the user guide) For UDP you're overcomplicating it. Unless you're fragmenting large messages into multiple DatagramPackets then the DatagramPacket should contain the entire message. Decode the message directly from DatagramPacket.content(). See QuoteOfTheMomentServerHandler for an example of reading a string from a DatagramPacket. Also see the same example for how to send a response. A new DatagramPacket is created with a message and using the sender of the received datagram as the recipient of the new datagram. This is vital because the channel is not bound to a particular remote peer."
674,A,"buffer corruption in netty I got a strange error when using netty(with camel) we use LengthFieldBasedFrameDecoder for communication client is a socket program from third party we use netty(camel-netty component) on the server side. sometimes got two messages ""merged"" into one and hence the forthcoming data get all wrong. for example: client send two messages: [10]AAAAAAAAAAAAAAAA and [10]BBBBBBBBBBBBBBBB where [10] is the length bytes and AAAAAAAAAA is the data. but on the server we got [10]AAAAAA[10]BBBBBBBBBBBBBBBBAAAAAAAAAA seems the the first message got split by the second one so the decoder interpreted the data as: [10]AAAAAA[10]BBBBBBBB and BBBBBBBBAAAAAAAAAA................................................... so that the first message is correct in length but wrong in data and the second message is wrong in length ""BB"" and get a much longer data packet. hope I described clearly anyone met this before? Is your LengthFieldBasedFrameDecoder extends FrameDecoder? And is it singleton or not? Actually I encounted the same problemand I agree with Peter's point; I've took a look at the FrameDecoderand found that there is a ChannelBuffer property named ""cumulation""which will be shared to all Channels of the decoder. and let's look inside the FrameDecoder.messageReceived method: @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { Object m = e.getMessage(); if (!(m instanceof ChannelBuffer)) { ctx.sendUpstream(e); return; } ChannelBuffer input = (ChannelBuffer) m; // here is the buffer from the channel if (!input.readable()) { return; } ChannelBuffer cumulation = cumulation(ctx); // here is the buffer wrapped by the FrameDecoder if (cumulation.readable()) { cumulation.discardReadBytes(); // where ""[10]AAA[10]BBBBB"" happens cumulation.writeBytes(input); // if code run herewe will get the wrong buffer callDecode(ctx e.getChannel() cumulation e.getRemoteAddress()); } else { callDecode(ctx e.getChannel() input e.getRemoteAddress()); if (input.readable()) { cumulation.writeBytes(input); } } } I think the correct way to use FrameDecoder is make it multcase.  well this proved to be a ""bug"" of camel-netty component I will post a fix to camel project later on. Before that please be careful using the camel-netty component especially do not use encoders/decoders not mark with @sharable annotation it will lead to the problem since state maybe shared among different connections.  It sounds like you are writing to the same stream in two threads. Only write to the output in one thread or synchronize access to it. hi thanks very much for the reply. Could you be more specific e.g. how this happens and how to avoid? thx in advance."
675,A,Does Netty's WriteCompletionEvent guarantees that other side have recieved my data or only that I'v sent data to the network? Does Netty's WriteCompletionEvent guarantees TCP push acknoledgement [PSH ACK] or just push [PSH] of packets of sent data? TCP doesn't provide an arrival guarantee except implicitly if all subsequent writes and the close() work so Netty certainly can't do that either. e.g. Wikipedia says: «TCP provides reliable ordered delivery of a stream of bytes from a program on one computer to another program on another computer» So Netty could generate WriteCompletionEvent either when TCP part transmitted all data into network (sent all [PSH] packets) or when TCP part received approval of all data receiving (received [PSH][ACK] packets for all sent packets). @Errandir (1) that's what I mean by 'implicit' although I get my information about TCP from RFC793 not Wikipedia and (2) Netty can't possibly know about either of those events. There is nothing in the Sockets API that will tell it. All it can know is that it has written your data into the TCP send buffer.
676,A,"Bi-directional communication with 1 socket - how to deal with collisions? I have one app. that consists of ""Manager"" and ""Worker"". Currently the worker always initiates the connection says something to the manager and the manager will send the response. Since there is a LOT of communication between the Manager and the Worker I'm considering to have a socket open between the two and do the communication. I'm also hoping to initiate the interaction from both sides - enabling the manager to say something to the worker whenever it wants. However I'm a little confused as to how to deal with ""collisions"". Say the manager decides to say something to the worker and at the same time the worker decides to say something to the manager. What will happen? How should such situation be handled? P.S. I plan to use Netty for the actual implementation. If you feel like reinventing the wheel and don't want to use middleware... Design your protocol so that the other peer's answers to your requests are always easily distinguishable from requests from the other peer. Then choose your network I/O strategy carefully. Whatever code is responsible for reading from the socket must first determine if the incoming data is a response to data that was sent out or if it's a new request from the peer (looking at the data's header and whether you've issued a request recently). Also you need to maintain proper queueing so that when you send responses to the peer's requests it is properly separated from new requests you issue.  I think you need to read up on sockets.... You don't really get these kinds of problems....Other than how to responsively handle both receiving and sending generally this is done through threading your communications... depending on the app you can take a number of approaches to this.  I'd go for a persistent bi-directional channel between server and client. If all you'll have is one server and one client then there's no collision issue... If the server accepts a connection it knows it's the client and vice versa. Both can read and write on the same socket. Now if you have multiple clients and your server needs to send a request specifically to client X then you need handshaking! When a client boots it connects to the server. Once this connection is established the client identifies itself as being client X (the handshake message). The server now knows it has a socket open to client X and every time it needs to send a message to client X it reuses that socket. Lucky you I've just written a tutorial (sample project included) on this precise problem. Using Netty! :) Here's the link: http://bruno.linker45.eu/2010/07/15/handshaking-tutorial-with-netty/ Notice that in this solution the server does not attempt to connect to the client. It's always the client who connects to the server. If you were thinking about opening a socket every time you wanted to send a message you should reconsider persistent connections as they avoid the overhead of connection establishment consequently speeding up the data transfer rate N-fold. Wow! Thanks! This is really great :)  The correct link to the Handshake/Netty tutorial mentioned in brunodecarvalho's response is http://bruno.factor45.org/blag/2010/07/15/handshaking-tutorial-with-netty/ I would add this as a comment to his question but I don't have the minimum required reputation to do so.  ""I'm also hoping to initiate the interaction from both sides - enabling the manager to say something to the worker whenever it wants."" Simple answer. Don't. Learn from existing protocols: Have a client and a server. Things will work out nicely. Worker can be the server and the Manager can be a client. Manager can make numerous requests. Worker responds to the requests as they arrive. Peer-to-peer can be complex with no real value for complexity. I see. But how should one deal with situations in which both client and server need to initiate a communication? @Zwei Steinen: introducing a Message Queue is not ""warranted"". It's ""essential"" it's ""the best practice"" it's ""the standard solution"". Go for it. Thanks for you advice! Right now the client has to periodically poll the server (and it does not work the other way around). Do you think in that situation introducing a Message Queue is warranted (to avoid the periodical polling)? @Zwei Steinen: First don't allow client and server to initiate. Client initiates; Server is passive. This leads to the server saving things until the client requests them. If you think you want ""real time"" you have a very complex problem and need a proper middleware to handle Message Queues."
677,A,"Sending UDP in Camel/Netty and receiving extra bytes in NIO I have two applications one that sends UDP messages using Camel with the Netty component and one that receives UDP messages in Java NIO with DatagramChannel. When receiving the data I've noticed that there's an extra 29 bytes prepended to the front of my message. Netty Camel prints out the outgoing bytes and it looks fine but when I do a packet.getData() as soon as the message comes in on the other side it has extra stuff on the front (and it's always the same bytes). Is Camel or Netty wrapping the packet before sending it? [edit] Additional information: -Camel is printing the log statement not Netty -the bytes prepended to the message change when the content of the message changes (only two bytes are changed) I know this question is pretty old now but I hit exactly this problem and it took me a while to find the solution. So here it is... Basically the problem boils down to confusion of what camel-netty will do when you're telling it to send something sufficiently low-level like a byte[] in a UDP packet. I expect that like me the OP assumed they were setting raw data but camel-netty uses Java Object Serialization by default - resulting in those extra ""random"" bytes appearing before the expected data. The solution is to change the encoder/decoder used by the endpoint(s) in question. There are various built-in alternatives but you can subclass them if you need something more... weird. Either way the process is: 1) Add the ""encoder=#myEncoder"" and ""decoder=#myDecoder"" options as appropriate on to the endpoint URIs. e.g. String destinationUri = ""netty:udp://localhost:4242"" + ""?sync=false&encoder=#myEncoder""; 2) Add a mapping from ""myEncoder"" to an instance of your new Encoder class to a Camel Registry. Same for myDecoder. Then use that registry when constructing the CamelContext. e.g. SimpleRegistry registry = new SimpleRegistry(); registry.put(""myEncoder"" new StringEncoder()); registry.put(""myDecoder"" new StringDecoder()); CamelContext camelContext = new CamelContext(registry); Obviously the real trick is in finding or making an Encoder/Decoder that suits your needs. A blog post at znetdevelopment really helped me though it goes one step further and puts the custom Encoders in a custom Pipeline (I ignored that bit). Thanks for the answer! Good to finally find out what it was doing under the hood. We ended up going with pure NIO on both sides because we found the camel-netty implementation to be too slow for our needs."
678,A,"Netty 4 handle channel events In Netty 3 I can handle open/close events with ChannelUpstreamHandler like pipeline.addLast(""channelGroupHandler"" new SimpleChannelUpstreamHandler() { public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) { ... } public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) { ... } }); but in Netty 4 it's doesn't work. So how I can handle this events now? If you check New and noteworthy in 4.0 you can see that: In 3.x When a new connected Channel is created at least three ChannelStateEvents are triggered: channelOpen channelBound and channelConnected. When a Channel is closed at least 3 more: channelDisconnected channelUnbound and channelClosed. In 4.x channelOpen channelBound and channelConnected have been merged to channelActive. Otherwise channelDisconnected channelUnbound and channelClosed have been merged to channelInactive. You should use the new API and that's it."
679,A,How do I use a ChannelBufferOutputStream to check compression size In a java program I am compressing an InputStream like this: ChannelBufferOutputStream outputStream = new ChannelBufferOutputStream(ChannelBuffers.dynamicBuffer(BUFFER_SIZE)); GZIPOutputStream compressedOutputStream = new GZIPOutputStream(outputStream); try { IOUtils.copy(inputStream compressedOutputStream); } finally { // this should print the byte size after compression System.out.println(outputStream.writtenBytes()); } I am testing this code with a json file that is ~31.000 byte uncompressed and ~7.000 byte compressed on disk. Sending a InputStream that is wrapping the uncompressed json file to the code above outputStream.writtenBytes() returns 10 which would indicate that it compressed down to only 10 byte. That seems wrong so I wonder where the problem is. ChannelBufferOutputStream javadoc says: Returns the number of written bytes by this stream so far. So it should be working. Try calling GZIPOutputStream.finish() or flush() methods before counting bytes If that does not work you can create a proxy stream whose mission - to count the number of bytes that have passed through it 1) I think this was the problem that I didn't close the output stream. Thanks! 2) I had the same idea and there is CountingOutputStream in commons-io however you will always get the uncompressed size since this is the number of bytes that the output stream will see.
680,A,Socket.io-netty and socket.io v0.7 - forbidden I'm using this lib https://github.com/ibdknox/socket.io-netty. And with new socket.io catch error with this line . Looks like socket io doesn't send required headers(WEBSOCKET_PATH 137 line FLASHSOCKET_PATH 139 line) and location was null. How do I see browser trying to get url http://127.0.0.1:8080/socket.io/1/?t=1331464323415&jsonp=0 and doesn't send any needed headers - here headers that were sent. What do I need to fix the problem? I can't understand -_- This is javascript clientside code: var chat = io.connect('http://127.0.0.1:8080') chat.on('connect' function () { chat.emit('hi!'); }); Socket.io-Netty does not support socket.io protocol higher than 0.6. You can try to use another implementation of socket.io server - https://github.com/mrniko/netty-socketio. It supports latest protocol of socket.io.
681,A,"Netty trouble with chat server I'm having trouble figuring out what is wrong with the a simple Netty chat program I am working with. I have tried debugging through the program but it hasn't been able to show me where the problem even lies. Through debugging it seems like the client is connecting to the server but the write function doesn't seem to be working. I followed the tutorial here. I have my source code here on GitHub. Here is the Client classes. public void run() throws Exception { EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap bootstrap = new Bootstrap() .group(group) .channel(NioSocketChannel.class) .handler(new ChatClientInitializer()); Channel channel = bootstrap.connect(host port).sync().channel(); BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); while (true) { channel.write(in.readLine() + ""\r\n""); } } finally { group.shutdownGracefully(); } } public class ChatClientInitializer extends ChannelInitializer<SocketChannel> { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""handler"" new ChatClientHandler()); } } public class ChatClientHandler extends SimpleChannelInboundHandler<String>{ @Override protected void channelRead0(ChannelHandlerContext ctx String msg) throws Exception { System.out.println(msg); } } And here are the Server classes public void run() throws Exception{ EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try{ ServerBootstrap bootstrap = new ServerBootstrap() .group(bossGroupworkerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChatServerInitializer()); bootstrap.bind(port).sync().channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public class ChatServerInitializer extends ChannelInitializer<SocketChannel> { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""handler"" new ChatServerHandler()); } } public class ChatServerHandler extends SimpleChannelInboundHandler<String>{ private static final ChannelGroup channels = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE); @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception{ Channel incoming = ctx.channel(); channels.add(ctx.channel()); for(Channel channel : channels){ channel.write(""[SERVER] - "" + incoming.remoteAddress() + ""has joined\n""); } } @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { Channel leaving = ctx.channel(); for(Channel channel : channels){ channel.write(""[SERVER] - "" + leaving.remoteAddress() + ""has left\n""); } channels.remove(ctx.channel()); } @Override protected void channelRead0(ChannelHandlerContext ctx String msg) throws Exception { Channel incoming = ctx.channel(); System.out.println(msg); for(Channel channel : channels){ channel.write(""["" + incoming.remoteAddress() + ""]"" + msg +""\n""); } } } You need to replace channel.write(...) with channel.writeAndFlush(...)"
682,A,"Loading certify SSL certificate into Netty engine I'm using the SSL example located in Netty example code folder: String keyStoreFilePath = System.getProperty(""keystore.file.path""); String keyStoreFilePassword = System.getProperty(""keystore.file.password""); KeyStore ks = KeyStore.getInstance(""JKS""); FileInputStream fin = new FileInputStream(keyStoreFilePath); ks.load(fin keyStoreFilePassword.toCharArray()); // Set up key manager factory to use our key store // Assume key password is the same as the key store file // password KeyManagerFactory kmf = KeyManagerFactory.getInstance(algorithm); kmf.init(ks keyStoreFilePassword.toCharArray()); I generated my own keystore using: /usr/java/jdk1.6.0_25/bin/keytool -genkey -keystore SrvKeystore -keyalg RSA And everything is working great!! However I now want to use an official certificate provided to me by comodo (https://secure.comodo.com/) They obviously provide 3 files type: .csr .crt and .key Please advise which file should point to keystore.file.path and which to keystore.file.password Maybe I need to do something else? Comodo is giving you the certificate and private key in a format most friendly for web servers (like Apache and nginx). There are two ways of resolving this issue: (1) Import the certificate chain (.crt) and private key (.key) into a jks or pkcs 12 key store (using keytool or openssl). (2) Use the java CertificateFactory to read the cert and the bouncycastle PEMReader to read the private key then wrap this in your own key manager (which you can pass to the SSLContext).  The basic information required for importing a CA authorized certificate is available here http://docs.oracle.com/javase/1.5.0/docs/tooldocs/solaris/keytool.html Importing Certificates To import a certificate from a file use the -import command as in keytool -import -alias joe -file jcertfile.cer This sample command imports the certificate(s) in the file jcertfile.cer and stores it in the keystore entry identified by the alias joe. You import a certificate for two reasons: to add it to the list of trusted certificates or to import a certificate reply received from a CA as the result of submitting a Certificate Signing Request (see the -certreq command) to that CA.  The solution is provided in this link"
683,A,"Netty - How to test for client/server version numbers As part of my protocol I'd like the client to send its version number when a new connection is established. I'd like this to be done in a separate handler in the pipeline so please bear with me as this may be a fairly basic question but I'm not sure how to do it. The other thing is that I'd like to then be able to send POJO's back and forth through the connection (pipeline). Also I'd love to add an Authentication handler. Anyways right now I'm getting some kind of error and I'm pretty sure it's because the version check is not being properly digested from the pipeline. Basically the code I have below is setup to send ""Hello World"" which the server prints out after the version has been checked when the connection has been established. At least in theory in reality this isn't quite working ;) Currently I have: Client.java public static void main(String[] args) { ... // Set up the pipeline factory. bootstrap.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( new ObjectEncoder() new ObjectDecoder() new VersionClientHandler() new BusinessLogicClientHandler()); } }); ... // The idea is that it will all be request and response. Much like http but with pojo's. ChannelFuture lastWriteFuture = channel.write(""Hello world"".getBytes()); if (lastWriteFuture != null) { System.out.println(""waiting for message to be sent""); lastWriteFuture.awaitUninterruptibly(); } ... } VersionClientHandler.java public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) { ChannelBuffer versionBuffer = ChannelBuffers.buffer(VERSION_STRING_LENGTH); versionBuffer.writeBytes(""v123.45a"".getBytes()); // If I understand correctly the next line says use the rest of the stream to do what you need to the next Handler in the pipeline? Channels.write(ctx e.getFuture() versionBuffer); } BusinessLogicClientHandler.java Not really doing anything at this point. Should it? Server.java public static void main(String[] args) { ... public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( new ObjectEncoder() new ObjectDecoder() new VersionServerHandler() new BusinessLogicServerHandler()); } ... } VersionServerHandler.java public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { ChannelBuffer versionBuffer = ChannelBuffers.buffer(VERSION_NUMBER_MAX_SIZE); System.out.println(""isReadable - messageReceived: "" + versionBuffer.readable()); // returns false??? // Basically I want to read it and confirm the client and server versions match. // And if the match fails either send a message or throw an exception // How do I also pass on the stream to the next Handler? } BusinessLogicServerHandler.java public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { e.getMessage(); byte[] message = (byte[])e.getMessage(); // ""Hello World"" in byte[] from Client.java } So basically what I want is that the version number is passed and validated when the channel is connected as part of the communication protocol. All done automatically behind the scenes. Similarly I'd love to pass the authentication mechanism this way. I did see some code which looked somewhat like what I wanted to do with the Secure Chat example but I couldn't really figure it out. Any help on how to setup this code would be really appreciated. I know I could do it all in one massive handler but that's the point of the pipeline to break it up into units that make logical sense. I found the solution!!! There were a number of issues. On VersionClientHandler the new code is: public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) { String verison = ""v123.45a""; ChannelBuffer versionBuffer = ChannelBuffers.buffer(VERSION_STRING_LENGTH); versionBuffer.writeBytes(version.getBytes()); e.getChannel().write(version); } Notice the last line e.getChannel().write(version); instead of Channels.write(ctx e.getFuture() versionBuffer); I'm not sure of the why. In fact I'm about to start looking into why I have the ChannelBuffers code there because it doesn't seem to do anything... On VersionServerHandler.java I now have: public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { String versionCheck = (String)e.getMessage(); System.out.println(""VersionServerHandler - "" + versionCheck); ctx.getPipeline().remove(VersionServerHandler.class); } Notice I don't read through the buffer anymore I just do e.getMessage() and cast to the correct type of object. Above this I added ctx.getPipeline().remove(VersionServerHandler.class); which is there to remove that handler from any further processing. It's no longer required after the initial connection. Thanks to Dennis for that tip. Conclusion The rest is much as I expected. the key is that I wasn't correctly understanding how to read the buffers and pass the info around. And the error messages and examples weren't quite clear. As soon as you add the POJO channels from Netty to your pipeline you need to start dealing only in objects for all handlers. I missed that one. The concepts were right it's just how I tried to read the data from the channels that was wrong. The other big tip was to remove the handlers from the pipeline if you don't need them after the initial connection. I assume the same will be true for an authentication handler. It would be great to have confirmation here but I'll have to figure that one out later.  I created a simple example: https://github.com/boldt/netty-examples/ It returns the version number when a new connection is established. It is done in a separate handler which will be removed from the pipeline after the version is written on the channel. Afterwards it is the ECHO example from the netty tutorial. A telnet localhost 1234 to the server shows the version immediately. Like this you could add an authentication-handler to the pipeline behind the version-handler. I really appreciate your answer and you're almost there. I'm just trying to do something slightly different. Basically I want the client to send it's version to the server which will then send back an exception or fail. So the server has to ingest the version number from the client and then continue reading from the channel... Also can you get the client to send a second message right after say a String that says ""hello world"" that the server is able to ingest. If you did I would give you double the bounty points if I can!! I just figured it all out there were a few conceptual errors. So there's no need to go through the effort of an example. However I do want to thank you a lot for the time. It wasn't what I was looking for but what you offered was definitely the type of help that would've been great had it been on target :)  You didn't mention what the error was that you are seeing. In any case I would not recommend using a separate channel handler for doing a version check. Mainly because the version check should only need to happen once when the connection is first established. Also because I think the channel handlers are best left dealing with transport layer concerns e.g. converting bytes into pojos. My thinking was a handler for the version check a handler for the authentication a handler for the encryption and a handler for the actual business logic. My big concern is that if the client and server are different versions and you're serializing pojo's then it will fail on deserialization. That's a good point. So what was the error you are seeing? All kinds. Nothing is really working. There's some conceptual issues rather than simply a coding issue.  I think what you want todo can be archived easily by adding some custom handlers. So for the version check you could add a handler that override channelConnected(....) and do rhe check there. For auth just add another handler after the version check which override the messageRecieved(....) method. After the auth is complete you can remove the handler frm the pipeline and add it back once you need it again. The BusinessLogic Handler should sit in the pipeline as the last one. Just be aware that any of your handlers does some blocking operation you should think about adding a ExecutionHandler in front of it to mKe sure hat the ioworker thread will nit get blocked and so make the netty server unresponsible."
684,A,"A fatal error has been detected by the Java Runtime Environment while running concurrent Java NIO Server(Netty) in ECLIPSE We have a netty server which is running in ECLIPSE in debug mode After running the server for about a week with a load of about 5k clients. JVM issued the following error. A fatal error has been detected by the Java Runtime Environment. Please advise The hs_err_pid29200.mdmp is follows  # # A fatal error has been detected by the Java Runtime Environment: # # EXCEPTION_ACCESS_VIOLATION (0xc0000005) at pc=0x00000000716462c7 pid=29200 tid=13272 # # JRE version: 7.0_21-b11 # Java VM: Java HotSpot(TM) 64-Bit Server VM (23.21-b01 mixed mode windows-amd64 compressed oops) # Problematic frame: # V [jvm.dll+0x362c7] # # Core dump written. Default location: C:\eclipse\Netty\hs_err_pid29200.mdmp # # If you would like to submit a bug report please visit: # http://bugreport.sun.com/bugreport/crash.jsp # --------------- T H R E A D --------------- Current thread (0x000000000dac5000): JavaThread ""JDWP Transport Listener: dt_socket"" daemon [_thread_in_vm id=13272 stack(0x000000000e9a00000x000000000eaa0000)] siginfo: ExceptionCode=0xc0000005 reading address 0x0000000000000010 Registers: RAX=0x0000000000000010 RBX=0x000000000dac5000 RCX=0x0000000000000000 RDX=0x0000000071b3fff8 RSP=0x000000000ea9f1f8 RBP=0x0000000780497130 RSI=0x0000000000000000 RDI=0x000000000dac6d00 R8 =0x0000000000000000 R9 =0x000000000ea9f380 R10=0x0000000000000000 R11=0x000000007343f590 R12=0x0000000780496f98 R13=0x0000000001db4c50 R14=0x0000000000000001 R15=0x0000000000000000 RIP=0x00000000716462c7 EFLAGS=0x0000000000010246 Top of Stack: (sp=0x000000000ea9f1f8) 0x000000000ea9f1f8: 0000000071762e66 0000000001f1c210 0x000000000ea9f208: 0000000072a38b57 000000000dac5000 0x000000000ea9f218: 0000000000000000 0000000000000000 0x000000000ea9f228: 000000000dac6cd0 0000000001db4930 0x000000000ea9f238: 0000000001db4920 0000000001db4d08 0x000000000ea9f248: 0000000001db4d20 0000000001db4930 0x000000000ea9f258: 000000000dac5000 0000000000000000 0x000000000ea9f268: 0000000001f1c210 000000000dac5000 0x000000000ea9f278: 000000000dac6d00 0000000001db4d10 0x000000000ea9f288: 0000000001db4d20 0000000001db50f8 0x000000000ea9f298: 000000000ea9f6b0 0000000000000000 0x000000000ea9f2a8: 0000000000000000 0000000000000000 0x000000000ea9f2b8: 0000000000000000 000000000daccc48 0x000000000ea9f2c8: 000000000ea9f3d0 0000000001f19780 0x000000000ea9f2d8: 000000000ea9f380 000000000dac5000 0x000000000ea9f2e8: 00000000718b9547 0000000001f19780 Instructions: (pc=0x00000000716462c7) 0x00000000716462a7: 05 64 38 62 00 83 f8 ff 74 03 89 14 08 f3 c3 cc 0x00000000716462b7: cc cc cc cc cc cc cc cc cc 48 63 05 7d fc 65 00 0x00000000716462c7: 48 8b 04 08 c3 cc cc cc cc 48 63 05 6d fc 65 00 0x00000000716462d7: 48 89 14 08 c3 cc cc cc cc 48 63 05 59 fc 65 00 Register to memory mapping: RAX=0x0000000000000010 is an unknown value RBX=0x000000000dac5000 is a thread RCX=0x0000000000000000 is an unknown value RDX=0x0000000071b3fff8 is an unknown value RSP=0x000000000ea9f1f8 is pointing into the stack for thread: 0x000000000dac5000 RBP=0x0000000780497130 is an oop [C - klass: {type array char} - length: 3 RSI=0x0000000000000000 is an unknown value RDI=0x000000000dac6d00 is an unknown value R8 =0x0000000000000000 is an unknown value R9 =0x000000000ea9f380 is pointing into the stack for thread: 0x000000000dac5000 R10=0x0000000000000000 is an unknown value R11=0x000000007343f590 is an unknown value R12=0x0000000780496f98 is an oop [Ljava.lang.Thread; - klass: 'java/lang/Thread'[] - length: 128 R13=0x0000000001db4c50 is an unknown value R14=0x0000000000000001 is an unknown value R15=0x0000000000000000 is an unknown value Stack: [0x000000000e9a00000x000000000eaa0000] sp=0x000000000ea9f1f8 free space=1020k Native frames: (J=compiled Java code j=interpreted Vv=VM code C=native code) V [jvm.dll+0x362c7] --------------- S Y S T E M --------------- OS: Windows NT 6.1  64 bit Build 7601 Service Pack 1 CPU:total 8 (4 cores per cpu 1 threads per core) family 6 model 26 stepping 5 cmov cx8 fxsr mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt tsc tscinvbit tscinv Memory: 4k page physical 8375388k(3128568k free) swap 16748916k(11387960k free) vm_info: Java HotSpot(TM) 64-Bit Server VM (23.21-b01) for windows-amd64 JRE (1.7.0_21-b11) built on Apr 4 2013 08:11:28 by ""java_re"" with unknown MS VC++:1600 time: Fri Jul 19 09:29:19 2013 elapsed time: 195988 seconds Thanks for your time GK @Peter Lawrey Thank you Are you running it in debug mode? @user1516873 Yes dude I wouldn't run the JVM in debug for a week or even 2.5 days as the elapse time suggests. If you suspect a bug in the JVM I would upgrade it to the latest update 25 This sounds like a bug in the JVM. Please upgrade to latest We are currently using java 1.7.21 and netty 3.6.6. Would like to know if anyone has faced similar bug"
685,A,Netty message priorities Are there any embedded priority mechanisms in Netty that can help me to decide which messages are send more often than others? You can prioritize writes using a BufferedWriteHandler which needs to be implemented with an unbound priority queue. To quote from the JavaDocs: You can implement prioritized writes by specifying an unbounded priority queue in the constructor of this handler. It will be required to design the proper strategy to determine how often flush() should be called. For example you could call flush() periodically using HashedWheelTimer every second.  No.. Messages are send in the order of which they are written to the Channel. What exactly you try todo ?
686,A,"Migrating sendUpstream in Netty 4 I'm migrating from netty 3 to netty 4. I have a pipeline handler that acts as a classic filter intercepting/handling noncompliant messages on the way and shoveling compliant ones upstream. Based on the documentation (http://netty.io/wiki/new-and-noteworthy.html) I expected to use ctx.fireInboundBufferUpdated() in lieu of ctx.sendUpStream() to relay inbound. However I've found this doesn't work but ChannelHandlerUtil.addToNextInboundBuffer() does. I'd love some guidance as to: My confusion over the current docs assertion that ctx.sendUpstream -> ctx.fireInboundBufferUpdated and What is the best practice in this case if different than what I've done below. The code: //The pipeline public class ServerInitializer extends ChannelInitializer<SocketChannel> { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline p = ch.pipeline(); p.addLast(""decoder"" new HttpRequestDecoder()); p.addLast(""encoder"" new HttpResponseEncoder()); p.addLast(""inbound"" InboundHttpRequestFilter.INSTANCE); p.addLast(""handler"" handlerClass.newInstance()); } } //The filter public class InboundHttpRequestFilter extends ChannelInboundMessageHandlerAdapter<Object> { @Override public void messageReceived(ChannelHandlerContext ctx Object msg) throws Exception { ... discard/handle as necessary …; //ctx.fireInboundBufferUpdated(); - doesn't propagate upstream ChannelHandlerUtil.addToNextInboundBuffer(ctx msg); // sends upstream } } Try this : ctx.nextInboundMessageBuffer().add(msg) Javadoc : Interface ChannelHandlerContext MessageBuf<Object> nextInboundMessageBuffer() Return the MessageBuf of the next ChannelInboundMessageHandler in the pipeline. Netty 4 Multiple Handler Example : MultiHandlerServer.java import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.LineBasedFrameDecoder; import io.netty.handler.codec.string.StringDecoder; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.nio.charset.Charset; public class MultiHandlerServer { private static final Logger logger = LoggerFactory.getLogger(MultiHandlerServer.class); final int port; public MultiHandlerServer(final int port) { this.port = port; } public void run() throws InterruptedException { final NioEventLoopGroup bossGroup = new NioEventLoopGroup(); final NioEventLoopGroup workerGroup = new NioEventLoopGroup(); try { final ServerBootstrap serverBootstrap = new ServerBootstrap() .group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer<SocketChannel>() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast( new LineBasedFrameDecoder(8192) new StringDecoder(Charset.forName(""UTF-8"")) new MultiHandler01() new MultiHandler02()); } }); final ChannelFuture future = serverBootstrap.bind(port).sync(); future.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws InterruptedException { final MultiHandlerServer client = new MultiHandlerServer(8080); client.run(); } } MultiHandler01.java import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundMessageHandlerAdapter; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** */ class MultiHandler01 extends ChannelInboundMessageHandlerAdapter<String> { private Logger logger = LoggerFactory.getLogger(MultiHandler01.class); MultiHandler01() { } @Override public void messageReceived(ChannelHandlerContext ctx String msg) throws Exception { logger.info(String.format(""Handler01 receive message: %s"" msg)); ctx.nextInboundMessageBuffer().add(msg); ctx.fireInboundBufferUpdated(); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) throws Exception { logger.error(""Exception caught: %s"" ctx.channel().remoteAddress() cause); ctx.close(); } } MultiHandler02.java import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundMessageHandlerAdapter; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** */ class MultiHandler02 extends ChannelInboundMessageHandlerAdapter<String> { private Logger logger = LoggerFactory.getLogger(MultiHandler02.class); MultiHandler02() { } @Override public void messageReceived(ChannelHandlerContext ctx String msg) throws Exception { logger.info(String.format(""Handler02 receive message: %s"" msg)); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) throws Exception { logger.error(""Exception caught: %s"" ctx.channel().remoteAddress() cause); ctx.close(); } } Thank you very much for your comments! :) Thanks this works with the modification to: `ctx.nextInboundMessageBuffer().add(request)`. I'll upvote after you edit :)."
687,A,In Netty 4.0.15 java.nio.channels.IllegalSelectorException exception I am trying to create a server for receiving UDP messages using NioUdtMessageConnectorChannel as channel. Pasting the code for the server EventLoopGroup group = new NioEventLoopGroup(50 Executors.defaultThreadFactory()); try { Bootstrap b = new Bootstrap(); b.group(group); b.channel(NioUdtMessageConnectorChannel.class); b.option(UdtChannelOption.SO_BROADCAST true); b.option(UdtChannelOption.WRITE_BUFFER_HIGH_WATER_MARK 1024); b.option(UdtChannelOption.PROTOCOL_RECEIVE_BUFFER_SIZE 1024); b.option(UdtChannelOption.PROTOCOL_SEND_BUFFER_SIZE 1024); b.option(UdtChannelOption.TCP_NODELAY true); b.option(UdtChannelOption.SO_RCVBUF 256 * 1024); b.handler(new SNMPTrapHandler()); b.bind(PORT).sync().channel().closeFuture().await(); } finally { group.shutdownGracefully(); } However I am getting below error log4j:WARN Please initialize the log4j system properly. java.nio.channels.IllegalSelectorException at sun.nio.ch.SelectorImpl.register(Unknown Source) at java.nio.channels.spi.AbstractSelectableChannel.register(Unknown Source) at io.netty.channel.nio.AbstractNioChannel.doRegister(AbstractNioChannel.java:308) at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:439) at io.netty.channel.AbstractChannel$AbstractUnsafe.access$100(AbstractChannel.java:374) at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:418) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:354) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:353) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101) at java.lang.Thread.run(Unknown Source) What is the exact error? You have to specify the UDT selector provider when you create an NioEventLoopGroup. For example: new NioEventLoopGroup(... NioUdtProvider.MESSAGE_PROVIDER); For more information please refer to the UDT examples. Thanks for the reply I just figured out and was about to reply in the thread.
688,A,Setting Netty configuration in the play framework? I'm attempting to enable TCP nodelay in my play server and the only way I've found to do so is through Netty. Netty has a SocketChannelConfig that allows you to enable TCP no delay but I can't figure out how to access said configuration from play. Looking at the sources (play.core.server.NettyServer) it does not look like you actually can set it through Play. The sources of that class: https://github.com/playframework/Play20/blob/master/framework/src/play/src/main/scala/play/core/server/NettyServer.scala That is a bummer. Thanks for looking into the source I should've thought to do that myself! I've raised an issue in the repo hopefully this can be fixed in a coming release.
689,A,"Netty: Add and Remove FrameDecoder dynamically from a Pipeline Protocol encapsulation I've been working with Netty 3.3.1-Final for 3 weeks now. My Protocol has 3 steps and each steps needs a different FrameDecoder: Read arguments Transfer some datas Mutual close of the data pipe I've been through a lot of ""blocking"" issues that I could not understand. It finally appears to me reading the org.jboss.netty.example.portunification example that I had some buffer issue when trying to dynamically change my FrameDecoder: the buffer of one FrameDecoder was (probably) not empty when changing for the next one... Is there a way to do that easily in Netty? Do I have to change my Protocol? Do I need to write one big FrameDecoder and manage a state? If so how to avoir code duplication between different protocol with common sub parts (for instance ""reading arguments"")? Today I came to the idea of a FrameDecoderUnifier (code below) with the purpose of a way to hot add and remove some FrameDecoder what do you think? Thanks for your help! Renaud ----------- FrameDecoderUnifier class --------------  /** * * This FrameDecoder is able to forward the unused bytes from one decoder to the next one. It provides * a safe way to replace a FrameDecoder inside a Pipeline. * It is not safe to just add and remove FrameDecoder dynamically from a Pipeline because there is a risk * of unread bytes inside the buffer of the FrameDecoder you wan't to remove. */ public class FrameDecoderUnifier extends FrameDecoder { private final Method frameDecoderDecodeMethod; volatile boolean skip = false; LastFrameEventHandler eventHandler; LinkedList<Entry> entries; Entry entry = null; public FrameDecoderUnifier(LastFrameEventHandler eventHandler) { this.eventHandler = eventHandler; this.entries = new LinkedList<Entry>(); try { this.frameDecoderDecodeMethod = FrameDecoder.class.getMethod(""decode"" ChannelHandlerContext.class Channel.class ChannelBuffer.class); } catch (NoSuchMethodException ex) { throw new RuntimeException(ex); } catch (SecurityException ex) { throw new RuntimeException(ex); } } public void addLast(FrameDecoder decoder LastFrameIdentifier identifier) { entries.addLast(new Entry(decoder identifier)); } private Object callDecode(FrameDecoder decoder ChannelHandlerContext ctx Channel channel ChannelBuffer buffer) throws Exception { return frameDecoderDecodeMethod.invoke(decoder ctx channel buffer); } @Override protected Object decode(ChannelHandlerContext ctx Channel channel ChannelBuffer buffer) throws Exception { if (entry == null && !entries.isEmpty()) { entry = entries.getFirst(); } if (entry == null) { return buffer; //No framing no decoding } //Perform the decode operation Object obj = callDecode(entry.getDecoder() ctx channel buffer); if (obj != null && entry.getIdentifier().isLastFrame(obj)) { //Fire event eventHandler.lastObjectDecoded(entry.getDecoder() obj); entry = null; } return obj; } /** * You can use this interface to take some action when the current decoder is changed for the next one. * This can be useful to change some upper Handler in the pipeline. */ public interface LastFrameEventHandler { public void lastObjectDecoded(FrameDecoder decoder Object obj); } public interface LastFrameIdentifier { /** * True if after this frame we should disable this decoder. * @param obj * @return */ public abstract boolean isLastFrame(Object decodedObj); } private class Entry { FrameDecoder decoder; LastFrameIdentifier identifier; public Entry(FrameDecoder decoder LastFrameIdentifier identifier) { this.decoder = decoder; this.identifier = identifier; } public FrameDecoder getDecoder() { return decoder; } public LastFrameIdentifier getIdentifier() { return identifier; } } } I think having a frame decoder which switch internal decoders based on some state and dynamically adding/removing upper layer handlers should be avoided because Difficult to understand/debug the code Handlers are not having well defined responsibilities (That's why you are removing/adding handlers rite? One handler should handle one or more (related) types of protocol messages not many handlers same type of messages) Ideally frame decoder only extract the protocol frame not to decode the frame based on state (here frame decoder can have internal chain of decoders to decoder the frame and fire a MessageEvent with decoded message above handlers can react to decoded messages). UPDATE: Here I have considered a protocol where each messages can have a unique tag/identifier with end of the message is clearly marked (for exmple Tag Length Value frame format) You have got my point regarding decoding :) BTW I am not against having a state inside a decoder/handlerI was saying that if the frame format of the protocol can have an identifier/tag in a header you could have use a simple frame decoder to extract the frame A or B or C and have a message handler/handlers to receive them and react (of course the handler receiving AB and C has to have a state). P.S here frame means something like https://gist.github.com/1582634 . This will help to avoid removing/adding handlers (This line is the main point of my answer) Hello @Jestan let's imagine a shell application that would like to open an sub-shell application (just like what happens when you use ssh or switching from shell to bash...). Wouldn't you hot-plug a different FrameDecoder to do that? I use a state-based Protocol to save some bytes: `RECEIVE A if A==A0 RECEIVE B else RECEIVE C.` where A B and C need 3 differents Decoders. I suppose another and easier way to do this is to use one single unified Protocol with A as the header of a Token that could contain B or C... It leads to my second question: how to avoid code duplication?? It is OK to have multiple frame-decoders when you need to support multiple protocols but in your case you have only one protocol with multiple frame decoders (and some handlers added/removed based on received message type). If there is only one protocol to support I think the responsiblity of the frame decoder is ""extract the frame regardless of message type or state"" (in this case messages has to be encoded with identification tag or tlv format and frame decoder can delegate the decoding to a chain of decoders to decode the extracted frame then fire a MessagEevent with decoded message) Thank you for your help @Jestan! Well we need a clear definition of **what is a protocol** here! If I get you well this is not a good idea to design a protocol where frame-decoding algorithm depends on an upper interpretation of the previously decoded frame. I understand that the states/steps I am handling in the upper handler should become a flag inside the Frame itself?? Meaning `Tokens A=[DATA] or B=[DATA] with FrameDecoderA and FrameDecoderB` should become `Token C=[AorB+DATA] with one single FrameDecoderC` is that it? That's a little overall but could be simpler to implement? Okay @Jestan I think we can close this question and I reword the answer. **Re-design you Protocol to have one unique frame-format** (meaning one unique method for re-assembling frames from the stream of bytes). You can always do this because dealing with different chained FrameDecoder is equivalent to inserting a ""state"" header in your frame and work with one single FrameDecoder! I understand this is the way Netty is designed to work it seems a bit painfull for re-usability of parts of the code. Thank for your help @Jestan! Regards Renaud  I have had similar problems in that removing a frame decoder from a pipeline does not seem to prevent it from being called and there isn't an obvious way to make the decoder to behave as if it wasn't in the chain: Netty insists that the decode() reads at least one byte so you can't simply return the incoming ChannelBuffer whereas returning null stops the processing of incoming data until the next packet arrives stalling the protocol decoding process. Firstly: the Netty 3.7 docs for FrameDecoder does in fact has a section ""Replacing a decoder with another decoder in a pipeline"". It says: It is not possible to achieve this simply by calling ChannelPipeline#replace() Instead it suggests passing the data on by returning an array wrapping the decoded first packet and the rest of the data received. return new Object[] { firstMessage buf.readBytes(buf.readableBytes()) }; Importantly ""unfolding"" must have been enabled prior to this but this part is easy to miss and isn't explained. The best clue I could find was Netty issue 132 which evidently gave rise to the ""unfold"" flag on FrameDecoders. If true the decoder will unpack such arrays into objects in a way which is transparent to downstream handlers. A peep at the source code seems to confirm this is what ""unfolding"" means. Secondly: there seems to be an even simpler way since the example also shows how to pass data on down the pipeline unchanged. For example after doing its job my sync packet FrameDecoder sets an internal flag and removes itself from the pipeline returning the decoded object as normal. Any subsequent invocations when the flag is set then simply pass the data on like so: protected Object decode(ChannelHandlerContext ctx Channel channel ChannelBuffer cbuf) throws Exception { // Close the door on more than one sync packet being decoded if (m_received) { // Pass on the data to the next handler in the pipeline. // Note we can't just return cbuf as-is we must drain it // and return a new one. Otherwise Netty will detect that // no bytes were read and throw an IllegalStateException. return cbuf.readBytes(cbuf.readableBytes()); } // Handle the framing ChannelBuffer decoded = (ChannelBuffer) super.decode(ctx channel cbuf); if (decoded == null) { return null; } // Remove ourselves from the pipeline now ctx.getPipeline().remove(this); m_received = true; // Can we assume an array backed ChannelBuffer? // I have only hints that we can't so let's copy the bytes out. byte[] sequence = new byte[magicSequence.length]; decoded.readBytes(sequence); // We got the magic sequence? Return the appropriate SyncMsg return new SyncMsg(Arrays.equals(sequence magicSequence)); } A decoder derived from LengthFieldBasedFrameDecoder remains downstream and handles all subsequent data framing. Works for me so far."
690,A,"Netty handshake issues I have the following code in order to get an asynchronous handshake with a server but I can't seem to figure out why I can't get connected to the website. import java.net.InetSocketAddress; import java.net.SocketAddress; import java.util.Arrays; import java.util.Date; import java.util.concurrent.Executor; import java.util.concurrent.Executors; import org.jboss.netty.bootstrap.ClientBootstrap; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelFactory; import org.jboss.netty.channel.ChannelFuture; import org.jboss.netty.channel.ChannelFutureListener; import org.jboss.netty.channel.ChannelHandler; import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.channel.Channels; import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory; import org.jboss.netty.handler.codec.http.HttpRequestDecoder; import org.jboss.netty.handler.codec.http.HttpRequestEncoder; import org.jboss.netty.handler.codec.http.HttpResponseDecoder; import org.jboss.netty.handler.logging.LoggingHandler; public class Handshake { public static String remoteHost = ""http://google.com""; public static int remotePort = 80; private static ClientBootstrap bootstrap; private static Channel channel; private static final ChannelHandler HTTP_REQUEST_ENCODER = new HttpRequestEncoder(); private static final ChannelHandler HTTP_REQUEST_DECODER = new HttpRequestDecoder(); private static final ChannelHandler HTTP_RESONPSE_DECODER = new HttpResponseDecoder(); private static final ChannelHandler LOG_HANDLER = new LoggingHandler(); public static void main(String[] args) { attemptConnection(); } public static void attemptConnection() { Thread thread = new Thread() { public void run() { Executor bossPool = Executors.newCachedThreadPool(); Executor workerPool = Executors.newCachedThreadPool(); ChannelFactory channelFactory = new NioClientSocketChannelFactory(bossPool workerPool); ChannelPipelineFactory pipelineFactory = new ChannelPipelineFactory() { public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""requestencoder"" HTTP_REQUEST_ENCODER); pipeline.addLast(""reqeustdecoder"" HTTP_REQUEST_DECODER); pipeline.addLast(""responsedecoder"" HTTP_RESONPSE_DECODER); pipeline.addLast(""logger"" LOG_HANDLER); return pipeline; } }; bootstrap = new ClientBootstrap(channelFactory); bootstrap.setPipelineFactory(pipelineFactory); SocketAddress address = new InetSocketAddress(remoteHost remotePort); ChannelFuture cf = bootstrap.connect(address); cf.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { // check to see if we succeeded if (!future.awaitUninterruptibly().isSuccess()) { System.out.println(""Failed to connect to server.""); bootstrap.releaseExternalResources(); } else { System.out.println(""Connected.""); channel = future.getChannel(); channel.write(new Date()); } } }); } }; thread.start(); } The thing is you should NOT cache encoders/decoders. They are statefull and this leads to connections errors please retry without caching (instantiating new Encoders/Decoders just in pipeline fabric) and say if this helped. This is good advice but it's not the problem; they aren't used until after the connection. Because http://google.com is not a host it's an URL. ChannelFuture future = bootstrap.connect(new InetSocketAddress(""google.com"" 80)); Edit to add: InetSocketAddress doesn't throw an exception if the hostname can't be resolved. You have to check isUnresolved() - InetSocketAddress i = new InetSocketAddress(""http://google.com"" 80); if (i.isUnresolved()) System.out.println(""Yup""); Also future.getCause() may have shed more light on the problem; I'd have to test it to verify. Yeah you are right didn't noticed. I added one last thing I think `future.getCause()` would have given you the reason."
691,A,"Boundaries between Services Filters and Codecs in Finagle Netty which is used within Finagle uses a pipeline of ""handlers"" to sequentially process in and out bound data. Netty examples and included libraries show various handlers used for things such as authentication protocol codecs and the actual business logic of the service. Finagle appears to take the handler concept and instead directly offer API users codecs filters and services. While these have varying signatures new users of Finagle are left with the tasks of deciding which to use in order to implement each portion of their overall server. Instead of merely deciding where to break the chain up into various Netty handlers they now need to decide which portion should be part of a codec versus any filters versus the singular service at the end of the chain. In sum although Finagle is a higher-level library than Netty and should make the task of building the service easier the API user may have more choices to make. What are the key decision points and pros/cons for placing a particular portion of the processing stream into a codec vs. a filter vs. the singular service? If there is a possibility that the pipeline could be extended further should the service logic be placed into a filter instead with a ""noop"" service at the end of the pipeline? Given the flexibility in ordering filters (as handlers in the pipeline) versus the singular codec on one end and service on the other end why shouldn't ""everything"" be a filter? Finagle and Netty are structured quite differently. Services Filters and codecs are actually quite orthogonal concepts. Let me try & explain. As a user -- ie. not an implementor of a codec -- you should only need to know about services and filters. First a codec is responsible for turning a stream of bytes into a discrete requests or responses. For example the HTTP codec reads the bytestream and produces HttpRequest or HttpResponse objects. A Service is an object that given a request produces a Future of a reply -- it’s a simple function (and indeed it extends Function). The interesting thing about services is that they are symmetric. A client uses a service a server provides one. The important thing about services is that (1) they operate over discrete requests and responses and (2) they match requests to responses - all of which is implied by its type. This is why we call finagle an “RPC” system - request/response pairs are the defining characteristic of RPCs. So we have Services but it's useful and important to have modify Service behavior independently of the service itself. For example we might want to provide timeout functionality or retries. This is what Filters do. They provide a service independent method of modifying Service behavior. This enhanced modularity and reuse. For example timeouts in finagle are implemented as a filter and can be applied to any service. You can find more details about services & filters in the Scala School. * So let’s contrast this to Netty’s handlers. These are generic event handlers that are also stackable. You can do many similar things with them but the underlying model is a stream of events that are attached to a connection. This makes it more difficult to write generic modules (eg. to implement retries timeouts failure accrual tracing exception reporting etc..) because you cannot make many assumptions about the pipeline you’re operating with. Netty pipelines also conflate the protocol implementation with application handlers. Finagle cleanly separates the two and modularity is enhanced because of it. Netty is a wonderful set of abstractions but for RPC servers finagle offers greater modularity and composability. * Summarizing crudely you could say that Netty is “stream oriented” while finagle is “service oriented”. This is an important distinction and it's what allows us to implement robust RPC services in a modular manner. For example connection pooling and load balancing - crucially important to RPC clients - fall out naturally from the service model but doesn’t fit in the stream model. Oh and I guess to more succinctly answer the question in your final paragraph: A Service exposes application behavior and Filters are used to modify their behavior in a generic and modular way. So for example you might have a Service that serves an HTTP endpoint but a filter that converts exceptions into nice HTTP 500 messages. Thank you Marius for clearly elucidating what may be gained using Finagle instead of a stack of Netty handlers.  I don't think it should be a decision between codec or filter. Codecs would rather get wrapped in filters. As for decision logic where to place it would depend on the decisions that has to be made. Business decisions should go with your business logic while some decisions like routing load balancing certain types of access control etc. could fit in well as a filter. Services are typically sit at the end of the line and Finagle with it's filters will get you there. Don't know if this makes sense? Just step away from the technical detail for a moment and look at the logic. What should be responsible for what and then get the technology to fit your design. Don't bend your design too much to fit the technology. By the way I've implemented a gateway server on top of Finagle and I must say: It's a nice library to work with. I don't know what you are trying to build but have a look at possible alternatives also: Spray Blueeyes Unfiltered Play-Mini etc. It may help you get a better understanding of what goes where. If you look at the source for Finagle's ServerBuilder class you will see that the discrete steps are indeed implemented by adding more handlers to the pipeline. The order is fixed around various options (such as the stats receiver option). The gist of my question is that it may be both simpler for Finagle users to understand as well as providing more flexibility by just sticking with a single concept of filter (ie: Netty handler) and provide more examples of how to order them to get the results you want. The codec stats option ssl and others are all handlers. Standard setups/orders of handlers could easily be offered in the library and users could build up their own with the ""andThen"" chains. This approach may shrink the cognitive load involved in learning Finagle by reducing the amount of special concepts. Additionally who can say that someone won't want to encode something and then send the results to a different codec for further wrapping? The same goes for the Finagle service at the other end of the line. What happens when you want another service to come directly after? Cool apologies if I misunderstood. I was about to suggest you should post this on the Finaglers forum but someone just did. https://groups.google.com/forum/?fromgroups#!topic/finaglers/upDrkR4GX7o"
692,A,Anyone aware of a simple example of a Netty HTTP server which supports persistent HTTP connections? Can anyone provide an example of a simple HTTP server implemented using Netty that supports persistent HTTP connections. In other words it won't close the connection until the client closes it and can receive additional HTTP requests over the same connection? This is exactly one of the things their sample http code demonstrates. https://github.com/netty/netty/tree/master/example/src/main/java/io/netty/example/http All examples can be found here: http://netty.io/wiki/index.html  If you send an HTTP message with Connection: keep-alive the HTTP Snoop Server example will not close the connection until the client does. just fixed: https://github.com/netty/netty/pull/2538#event-128083574
693,A,"How to write a high performance Netty Client I want an extremely efficient TCP client to send google protocol buffer messages. I have been using the Netty library to develop a server/client. In tests the server seems to be able to handle up to 500k transactions per second without to many problems but the client tends to peak around 180k transactions per second. I have based my client on the examples provided in the Netty documentation but the difference is I just want to send the message and forget I don't want a response (which most of the examples get). Is there anyway to optimize my client so that I can achieve a higher TPS ? Should my client maintain multiple channels or should I be able to achieve a higher throughput than this with a single channel? the timing does indeed *sound* like the client is waiting for a response... just a thought - since it sounds like a fairly simple service have you tried just using a raw socket? 1) If the client is only interested in sending not in receiving you can always disable reading from channel like below channel.setReadable(false); 2) You can increase the throughput very easily by having multiple client channels per client and also it can scale too. 3) and you can do following tweaks to improve the performance in general (for read/ write) Its better to have a SEDA like pipline by adding a EXecutionHandler with OrderdMemoryAwareThreadPoolExecutor (with min max channel memory with optimal value) bootstrap.setPipelineFactory(new ChannelPipelineFactory() { @Override public ChannelPipeline getPipeline() throws Exception { return Channels.pipeline( executionHandler1//sharable new MessageDecoderHandler() new MessageEncoderHandler() executionHandler2//sharable new BusinessLogicHandler1() new BusinessLogicHandler2()); } }); Setting the writeBufferHighWaterMark of the channel to optimal value (Make sure that setting a big value will not create congestion) bootstrap.setOption(""writeBufferHighWaterMark"" 10 * 64 * 1024); Setting the SO_READ SO_WRITE buffer size bootstrap.setOption(""sendBufferSize"" 1048576); bootstrap.setOption(""receiveBufferSize"" 1048576); Enabling the TCP No delay bootstrap.setOption(""tcpNoDelay"" true); Thanks One question on point 2). What is the best way to do this should I create multiple channels and put the handlers for them in some sort of worker queue to process requests ? @Dave take a look at this answer to see how client can use multiple connections http://stackoverflow.com/a/7905761/596720  I am not sure if ""tcpNoDelay"" helps to improve the throughput. Delay is there to improve the performance. None the less I tried it and saw that the throughput actually fell more than 90%."
694,A,"Howto get some ID for a Netty Channel? Channel.id() has been removed in Netty 4.0.0.CR9. How do I get an ID of a Channel these days? I used to use the id() for logging purposes in all my Handlers (E.g. System.out.println(ctx.channel().id() + "" - readableBytes(): "" + in.readableBytes())). I cannot rely on the toString method of a Channel because that might be overridden. You can use Channel.hashCode() . We removed id() as it was not guaranteered to be 100 % unique. hashCode isn't guaranteed to return a unique value either is it? `hashCode()` isn't guaranteed to return a unique value.I would still recommend using `Channel.toString()`. All `Channel` implementations actually rely on `AbstractChannel.toString()`. @trustin: the toString method contains the remote address making it unique. Can you post that as an answer? I will look at the cases where you can't retrieve the remote address once I find some time. @AndrewBourgeois Answer updated. Thanks for a feedback.  If you are sure that the channel is active you can generate the unique ID of the channel by combining the hashCode() remoteAddress() and localAddress(). Alternatively you can simply use Channel.toString() which generates a string from the three properties. If the channel is not active yet remoteAddress() and localAddress() will not give meaningful information so you are still at the risk of collision. Netty 4.1 and 5.0 re-introduced Channel.id() which returns a new type called ChannelId. It uses various information such as MAC address current PID timestamp and hashcode so that it can even be used as a globally unique ID. Check the Javadoc. Netty 4.1 also has it. This is the most complete answer. Netty 4 no longer has it but you can get it by combining stuff and Netty 5 will have it again. Thanks."
695,A,"How to access memcached asynchronously in netty I am writing a server in netty in which I need to make a call to memcached. I am using spymemcached and can easily do the synchronous memcached call. I would like this memcached call to be async. Is that possible? The examples provided with netty do not seem to be helpful. I tried using callbacks: created a ExecutorService pool in my Handler and submitted a callback worker to this pool. Like this: public class MyHandler extends ChannelInboundMessageHandlerAdapter<MyPOJO> implements CallbackInterface{  ... private static ExecutorService pool = Executors.newFixedThreadPool(20); @Override public void messageReceived(ChannelHandlerContext ctx MyPOJO pojo) { ... CallingbackWorker worker = new CallingbackWorker(key this); pool.submit(worker); ... } public void myCallback() { //get response this.ctx.nextOutboundMessageBuf().add(response); } } CallingbackWorker looks like: public class CallingbackWorker implements Callable {  public CallingbackWorker(String key CallbackInterface c) { this.c = c; this.key = key; } public Object call() { //get value from key c.myCallback(value); } However when I do this this.ctx.nextOutboundMessageBuf() in myCallback gets stuck. So overall my question is: how to do async memcached calls in Netty? I believe I am missing something fundamental about Netty/NIO here. Making a network call in an asynchronous fashion should be straightforward in an NIO framework. Any pointers would help. There are two problems here: a small-ish issue with the way you're trying to code this and a bigger one with many libraries that provide async service calls but no good way to take full advantage of them in an async framework like Netty. That forces users into suboptimal hacks like this one or a less-bad but still not ideal approach I'll get to in a moment. First the coding problem. The issue is that you're trying to call a ChannelHandlerContext method from a thread other than the one associated with your handler which is not allowed. That's pretty easy to fix as shown below. You could code it a few other ways but this is probably the most straightforward: private static ExecutorService pool = Executors.newFixedThreadPool(20); public void channelRead(final ChannelHandlerContext ctx final Object msg) { //... final GetFuture<String> future = memcachedClient().getAsync(""foo"" stringTranscoder()); // first wait for the response on a pool thread pool.execute(new Runnable() { public void run() { String value; Exception err; try { value = future.get(3 TimeUnit.SECONDS); // or whatever timeout you want err = null; } catch (Exception e) { err = e; value = null; } // put results into final variables; compiler won't let us do it directly above final fValue = value; final fErr = err; // now process the result on the ChannelHandler's thread ctx.executor().execute(new Runnable() { public void run() { handleResult(fValue fErr); } }); } }); // note that we drop through to here right after calling pool.execute() and // return freeing up the handler thread while we wait on the pool thread. } private void handleResult(String value Exception err) { // handle it } That will work and might be sufficient for your application. But you've got a fixed-sized thread pool so if you're ever going to handle much more than 20 concurrent connections that will become a bottleneck. You could increase the pool size or use an unbounded one but at that point you might as well be running under Tomcat as memory consumption and context-switching overhead start to become issues and you lose the scalabilty that was the attraction of Netty in the first place! And the thing is Spymemcached is NIO-based event-driven and uses just one thread for all its work yet provides no way to fully take advantage of its event-driven nature. I expect they'll fix that before too long just as Netty 4 and Cassandra have recently by providing callback (listener) methods on Future objects. Meanwhile being in the same boat as you I researched the alternatives and not being too happy with what I found I wrote (yesterday) a Future tracker class that can poll up to thousands of Futures at a configurable rate and call you back on the thread (Executor) of your choice when they complete. It uses just one thread to do this. I've put it up on GitHub if you'd like to try it out but be warned that it's still wet as they say. I've tested it a lot in the past day and even with 10000 concurrent mock Future objects polling once a millisecond its CPU utilization is negligible though it starts to go up beyond 10000. Using it the example above looks like this: // in some globally-accessible class: public static final ForeignFutureTracker FFT = new ForeignFutureTracker(1 TimeUnit.MILLISECONDS); // in a handler class: public void channelRead(final ChannelHandlerContext ctx final Object msg) { // ... final GetFuture<String> future = memcachedClient().getAsync(""foo"" stringTranscoder()); // add a listener for the Future with a timeout in 2 seconds and pass // the Executor for the current context so the callback will run // on the same thread. Global.FFT.addListener(future 2 TimeUnit.SECONDS ctx.executor() new ForeignFutureListener<StringGetFuture<String>>() { public void operationSuccess(String value) { // do something ... ctx.fireChannelRead(someval); } public void operationTimeout(GetFuture<String> f) { // do something ... } public void operationFailure(Exception e) { // do something ... } }); } You don't want more than one or two FFT instances active at any time or they could become a drain on CPU. But a single instance can handle thousands of outstanding Futures; about the only reason to have a second one would be to handle higher-latency calls like S3 at a slower polling rate say 10-20 milliseconds. One drawback of the polling approach is that it adds a small amount of latency. For example polling once a millisecond on average it will add 500 microseconds to the response time. That won't be an issue for most applications and I think is more than offset by the memory and CPU savings over the thread pool approach. I expect within a year or so this will be a non-issue as more async clients provide callback mechanisms letting you fully leverage NIO and the event-driven model."
696,A,netty how to receive callback after write has occurred with ChunkedWriteHandler We are trying to get the tcp flow control in the playframework to automatically passthrough so a backed up client just passes the backup downstream through our server using no resources on our server. To do this though we need a WriteCallback so we know when we write a chunk using netty we are told when the chunk is actually written. If it is not written the callback is not called which takes up a little memory but we don't read any more requests anyways until the write has occurred. So in playframework I see this being called on the Netty ChunkedWriteHandler chunkedWriteHandler.resumeTransfer(); What we really need is to pass it a callback so we know when the write is finished. Is there any other method or any way to achieve this easily? Perhaps I can fork netty for the time being and add a callback somehow though this looks very complex. Any ideas very welcome. thanks Dean I don't know the playframework very well but in netty you get a ChannelFuture returned when calling write(..). You can then add a ChannelFutureListener to the ChannelFuture to get notified once the write completes.
697,A,"netty http basic authentication I used the example provided here Netty HTTP Authetication for Client but still having 401 response when I print the request header I can see that all is good except one thing the Authorization is: Authorization: YWRtaW46YWRtaW4= When I do the same authentication with Chrome for instance I have: Authorization: Basic YWRtaW46YWRtaW4= nothing special in netty doc about how to add Basic in the header When I catch the failing message with a tool like tcpmon and resend the message by adding manually the Basic string it works fine. My question could be how to add Basic in the header submitted by netty ? does someone faced this before ? thnx I finally did a hack in org.jboss.netty.handler.codec.http.HttpHeaders#addHeader method:  void addHeader(final String name final Object value) { validateHeaderName(name); String strVal = toString(value); HttpCodecUtil.validateHeaderValue(strVal); int h = hash(name); int i = index(h); if (Names.AUTHORIZATION.equals(name)) strVal = ""Basic ""+strVal; addHeader0(h i name strVal); }  The first header you are posted is not correct. It must look like the one of Chrome. So in need you would just call HttpMessage.setHeader(...) and pass the values. thnx but what args exactly to put in HttpMessage.setHeader(...) to have the Basic in your header ? Also notice that in netty HttpCodecUtil validates you header name and spaces are not allowed so asof today I had to do a dirty hack on my side to make the Basic auth working fine."
698,A,Seeking advice on sharing Netty boss/worker pools Context: Netty 3.6.3.Final Java 1.7 Scala 2.9.x In order to minimize the number (of possibly idling) threads I'd like to share NIO client/server and worker pools with different NIO socket channel factories (TCP) and one NioDatagramChannelFactory. I'm using at least two (or three with the Finagle stack) sets of server/client bootstraps each with their own NIO socket channel factories. Using a new cached thread pool for each and every boss and worker pool result in a load of threads which are not used most of the time. The rough goal would be to limit the number of workers over all bootstraps/channel factories to 2 * CPU core count and number of bosses to CPU core count. I'm trying to switch over to NioServer/ClientBossPool and NioWorkerPool for one of my own set of bootstraps. But depending of the configuration of the underlying ThreadPoolExecutor shutting down a bootstrap causes the main thread to wait forever on a AbstractNioSelector shutdown latch. class NioClientBossPoolTest { @Test def shutdown() { val corePoolSize = 1 val maxPoolSize = Integer.MAX_VALUE val keepAliveSeconds = 60 val keepAliveUnit = TimeUnit.SECONDS val blocking = true val queue: BlockingQueue[Runnable] = if(blocking) new LinkedBlockingQueue[Runnable](Integer.MAX_VALUE) else new SynchronousQueue[Runnable]() val executor = new ThreadPoolExecutor(corePoolSize maxPoolSize keepAliveSeconds keepAliveUnit queue) val clientBossPool = new NioClientBossPool(executor 1) // B new NioServerBossPool(executor 1) // C val workerPool = new NioWorkerPool(executor 1) // A val channelFactory = new NioClientSocketChannelFactory(clientBossPool workerPool) val bootstrap = new ClientBootstrap(channelFactory) // hangs waiting for shutdown latch in AbstractNioSelector (NioWorker or NioClientBoss // depending on the order of statement A B C) for // LinkedBlockingQueue corePoolSize = 1 and sequence of statements A B and C other than [B A C] // LinkedBlockingQueue corePoolSize = 2 and sequence of statements A B and C other than // [A B C] [B C A] and [C B A] bootstrap.shutdown() } } I'm pretty sure that the executor service configuration has to meet some specific requirements but which (core pool size queue type)? bootstrap.shutdown() will block forever except when the execution order of statement A B and C is exactly [B A C]. Increasing core pool size to 2 blocks for three out of six combinations of the three statements. With a core pool size > 2 or with a SynchronousQueue each combination terminates. Actually this seems like a bug. I think it works if xou use different executor for boss and workerpool. Can you open a bugreport ? Ha! OK. I'll create a new issue against 3.6.3. https://github.com/netty/netty/issues/1200
699,A,How to set a read timeout in netty that does not close the connection? I have a netty server that receives requests from a client makes a request to another server and then uses the response from the second request in the response to the original clients request. I want to have a short timeout (~40ms) on the request to the second server so I can send a generic response in the event of a timeout but I don't want to close the connection to the second server. Instead I will simply discard the response to the timed out request when it arrives and then return the connection to my pool. What's the best way to do this in netty? I've tried ReadTimeoutHandler but this seems to close the connection to the second server when a timeout occurs. It appears that for your requirements you will need to write your own timing management around the connection to the second server. Furthermore since you mention a connection pool that may imply that you also have a limit on how many connections you can establish simultaneously to the second server (well there is always a limit it just depends on whether you actually have to worry about it or not). For the simple case where you are not worrying about queueing outbound requests you should just be able to create a copy of ReadTimeoutHandler and modify it as you need most likely by having it pull a callback from the context for it to invoke instead of closing the connection in its readTimedOut() method. In the case where you are going to queue your outbound requests you should consider the time spent on the queue as well as the time to receive a response so your solution would require your own timer that starts as soon as you put an item into the outbound queue. Furthermore you need a way to synchronize between the timer and a valid result being returned (you only want to send one response not one when the timer times out and one when the response from the second server comes in). To do this I imagine you would want to use some type of manager object that contains a reference to the channel with your callbacks writing back through this manager. E.g. (in pseudo-ish code) MyStateManager manager = new MyStateManager(channel); // Scheduled a timer task for 40ms from now to invoke the callback // method of your ReadTimedOutCallback and send a message through the manager myTimer.schedule(new ReadTimedOutCallback(manager)40); // Send an outbound request to server 2 through a class that queues // and manages such requests asynchronously. When the request is complete // it invokes the callback method of RequestCompletedCallback which then // sends a response through the manager. myAsyncOutboundServerRequester.request(new RequestCompletedCallback(manager)); // ... finish and return the thread to Netty for use with other requests // while the async tasks process And the manager in simple form would be something like (excluding exception handling channel state checking etc): public class MyStateManager { private final Channel channel; private AtomicBoolean messageSent = new AtomicBoolean(false); public MyStateManager(Channel channel) { this.channel = channel; } // Called by the ReadTimeoutCallback public void sendGenericResponse() { if (messageSent.getAndSet(true)) { //... write generic response to channel ChannelFuture future = channel.write... // Add listeners to future etc } } // Called by the RequestCompletedCallback public void sendResponse(MyResponseObject response) { if (messageSent.getAndSet(true)) { // write returned response to channel ChannelFuture future = channel.write(response); // Add listeners to future etc } } } You would still probably want to put some type of timeout checking on your connection to the second server in order to close the connection if it is unresponsive for far too long (30 seconds or a minute or something).
700,A,do we need more than a single thread for boss group? I mean an argument of NioEventLoopGroup(threadsAmount) constructor. If I understand this well situations where we need more than one thread to accept incoming connections are exceptionally rare. In what kind of situations would we need more than one thread to accept incoming connections? I was thinking of maybe when the connections handlers are light and extremely short-living. Mostly if you share the NioEventLoopGroup between different ServerBoostraps.
701,A,how to convert all inbound requests to UTF-8 in Play! framework Due to backward compatibilities all HTTP requests not having defined charset are converted to ISO-8859-1 by default. Our netty served Play! application correctly receives PUT requests with JSON body if those requests have defined charset. In case it does not those requests should be converted to UTF-8 somehow preferably on global application level. So I have created a Global.scala class which will be in charge of receiving of all inbound requests and converting those 'undefined' to UTF-8 which will ensure all requests will be handled properly before getting into their appropriate modules.  import play.*; public class Global extends GlobalSettings { @Override public Action onRequest(Request request Method actionMethod) { return super.onRequest(request actionMethod); } } in this 'filter' method now there is missing code piece which will query if request is PUT or POST and does not have character encoding defined and will convert this request's body to UTF-8 from ISO-8859-1 otherwise it will convert request's body to UTF-8 from whatever charset it is in. Apache Tomcat has this resolved thru Filters: http://wiki.apache.org/tomcat/FAQ/CharacterEncoding#Q3 I have not found anything in Netty similar to Tomcat's features only this Global interceptor on Play! level. how to convert what is in request to UTF-8 before passing it over to its intended spot... so what's the question? I don't think this is supported directly you will need to modify Play itself maybe add a getter to Http.RequestBody for example. But I do not see how you could magically convert 'undefined' to UTF-8 in some way you need to know what your input is either by trusting the headers or implicitly (you know your legacy code always sends in a specific encoding or some such). The Requestobject has a body() method that returns the body of the request. That body of type RequestBody has an asRaw() method that returns a Http.RawBuffer. From there you can obtain the byte[] of the body and process it as you want. For example String allows you to create a String from a byte[] indicating the Charset (see documentation) and as you can obtain the charset from the headers in the request you can then create the right String. EDIT: On answer to the comment to apply this you probably want to use a BodyParser instead of the Global class ok how to return such reparsed data back into request so the endpoint where this reqeust is meant to end will get request with appropriately converted data. Request is immutable and therefore I have a problem doing it on transparent way @ante.sabo I updated answer with more detail
702,A,"Strange Netty error whilst deserializing I am using Netty to send objects over a Socket. It works fine except when I try to send this one type of Packet I get this error on the receiving side [16:57:14] [nioEventLoopGroup-3-1/INFO]: [Castle_Defense_Lobby] Connected to proxy [16:57:14] [nioEventLoopGroup-3-1/ERROR]: Unexpected exception from downstream disconnecting... io.netty.handler.codec.DecoderException: java.io.InvalidClassException: failed to read class descriptor at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:259) ~[CastleDefense-Lobby-1.0.jar:?] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:141) ~[CastleDefense-Lobby-1.0.jar:?] at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRead(DefaultChannelHandlerContext.java:340) [CastleDefense-Lobby-1.0.jar:?] at io.netty.channel.DefaultChannelHandlerContext.fireChannelRead(DefaultChannelHandlerContext.java:326) [CastleDefense-Lobby-1.0.jar:?] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:785) [CastleDefense-Lobby-1.0.jar:?] at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:116) [CastleDefense-Lobby-1.0.jar:?] at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:494) [CastleDefense-Lobby-1.0.jar:?] at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:461) [CastleDefense-Lobby-1.0.jar:?] at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:378) [CastleDefense-Lobby-1.0.jar:?] at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:350) [CastleDefense-Lobby-1.0.jar:?] at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101) [CastleDefense-Lobby-1.0.jar:?] at java.lang.Thread.run(Unknown Source) [?:1.8.0-ea] Caused by: java.io.InvalidClassException: failed to read class descriptor at java.io.ObjectInputStream.readNonProxyDesc(Unknown Source) ~[?:1.8.0-ea] at java.io.ObjectInputStream.readClassDesc(Unknown Source) ~[?:1.8.0-ea] at java.io.ObjectInputStream.readOrdinaryObject(Unknown Source) ~[?:1.8.0-ea] at java.io.ObjectInputStream.readObject0(Unknown Source) ~[?:1.8.0-ea] at java.io.ObjectInputStream.readObject(Unknown Source) ~[?:1.8.0-ea] at io.netty.handler.codec.serialization.ObjectDecoder.decode(ObjectDecoder.java:73) ~[CastleDefense-Lobby-1.0.jar:?] at io.netty.handler.codec.LengthFieldBasedFrameDecoder.decode(LengthFieldBasedFrameDecoder.java:343) ~[CastleDefense-Lobby-1.0.jar:?] at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:228) ~[CastleDefense-Lobby-1.0.jar:?] ... 11 more Caused by: java.lang.ClassNotFoundException: com.iKeirNez.CastleDefense.common.packets.PacketServers at java.net.URLClassLoader$1.run(Unknown Source) ~[?:1.8.0-ea] at java.net.URLClassLoader$1.run(Unknown Source) ~[?:1.8.0-ea] at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0-ea] at java.net.URLClassLoader.findClass(Unknown Source) ~[?:1.8.0-ea] at java.lang.ClassLoader.loadClass(Unknown Source) ~[?:1.8.0-ea] at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) ~[?:1.8.0-ea] at java.lang.ClassLoader.loadClass(Unknown Source) ~[?:1.8.0-ea] at java.lang.Class.forName0(Native Method) ~[?:1.8.0-ea] at java.lang.Class.forName(Unknown Source) ~[?:1.8.0-ea] at io.netty.handler.codec.serialization.ClassLoaderClassResolver.resolve(ClassLoaderClassResolver.java:31) ~[CastleDefense-Lobby-1.0.jar:?] at io.netty.handler.codec.serialization.CompactObjectInputStream.readClassDescriptor(CompactObjectInputStream.java:55) ~[CastleDefense-Lobby-1.0.jar:?] at java.io.ObjectInputStream.readNonProxyDesc(Unknown Source) ~[?:1.8.0-ea] at java.io.ObjectInputStream.readClassDesc(Unknown Source) ~[?:1.8.0-ea] at java.io.ObjectInputStream.readOrdinaryObject(Unknown Source) ~[?:1.8.0-ea] at java.io.ObjectInputStream.readObject0(Unknown Source) ~[?:1.8.0-ea] at java.io.ObjectInputStream.readObject(Unknown Source) ~[?:1.8.0-ea] at io.netty.handler.codec.serialization.ObjectDecoder.decode(ObjectDecoder.java:73) ~[CastleDefense-Lobby-1.0.jar:?] at io.netty.handler.codec.LengthFieldBasedFrameDecoder.decode(LengthFieldBasedFrameDecoder.java:343) ~[CastleDefense-Lobby-1.0.jar:?] at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:228) ~[CastleDefense-Lobby-1.0.jar:?] ... 11 more [16:57:14] [nioEventLoopGroup-3-1/WARN]: Lost connection attempting reconnect... [16:57:14] [nioEventLoopGroup-3-2/INFO]: Successfully reconnected I can confirm that the class exists in the same package on both sides (as I use Maven to shade it in). Here is the class I am sending package com.iKeirNez.CastleDefense.common.packets; import com.iKeirNez.packetapi.api.packets.Packet; import java.net.InetSocketAddress; import java.util.Map; /** * Sent from Proxy to Lobby notifying of what servers to listen for * Created by iKeirNez on 11/04/2014. */ public class PacketServers implements Packet { private static final long serialVersionUID = 524383226296782276L; public Map<String InetSocketAddress> servers; public PacketServers(Map<String InetSocketAddress> servers){ this.servers = servers; } } I am really confused as to why this error is being thrown I also checked that InetSocketAddress is serialializable and that seems to be the case. Edit: The class ""Packet"" is a very simple class which extends Serializable package com.iKeirNez.packetapi.api.packets; import java.io.Serializable; /** * Created by iKeirNez on 06/04/2014. */ public interface Packet extends Serializable { } When setting up pipeline pass correct ClassLoader to ObjectDecoder: new ObjectDecoder(ClassResolvers.weakCachingConcurrentResolver(PacketServers.class.getClassLoader())) You are a LIFESAVER thanks a TON!! It works! Never knew this had to be done before"
703,A,"Configuring Netty with Spring IoC Has anyone used Spring to configure Netty? I'm looking for an example or description on how I can configure Netty with Spring. Well Netty use just simple ""pojos"" so I see no problem here. Just create your bean definations as usual  Yes you can. Look at the following jet java game server written in Netty the servers are all configured using spring. Take a look at the server-beans.xml netty-handlers.xml etc in this project for reference. For configuring Netty within a spring web-app look at the following link. [Update] Recently I have also blogged about doing it with a java only configuration using no xml."
704,A,"Netty socket.shutdownOutput() equivalent to avoid TCP RST? I am wondering if there is a way to avoid having a TCP RST flag set as opposed to a TCP FIN flag when closing a connection in Netty where there is input data remaining in the TCP receive buffer. The use case is: Client (written in C) sends data packets containing many fields. Server reads packets encounters an error on an early field throws an exception. Exception handler catches the exception writes an error message and adds the close on write callback to the write future. The problem is: Remaining data in the receive buffer causes Linux (or Java..) to flag the TCP packets with the RST flag. This prevents the client from reading the data since when it gets around to trying it finds it has a read error due to the socket being closed. With a straight Java socket I believe the solution would be to call socket.shutdownOutput() before closing. Is there an equivalent function in Netty or way around this? If I simply continue reading from the socket it may not be enough to avoid the RST since there may or may not be data in the buffer exactly when close is called. For reference: http://cs.baylor.edu/~donahoo/practical/CSockets/TCPRST.pdf UPDATE: Another reference and description of the problem: http://docs.oracle.com/javase/1.5.0/docs/guide/net/articles/connection_release.html Calling shutdownOutput() should help with a more orderly closing of the connection (by sending a FIN) but if the client is still sending data then RST messages will be sent regardless (see answer from EJP. A shutdownOutput() equivalent may be available in Netty 4+. Solutions are either to read all data from the client (but you can never be sure when the client will fully stop sending especially in the case of a malicious client) or to simply wait before closing the connection after sending the response (see answer from irreputable). Can you try this: after server writes the error message wait for 500ms then close(). See if the client can receive the error message now. I'm guessing that the packets in the server receive buffer have not been ACK-ed due to TCP delayed acknowledgement. If close() is called now the proper response for these packets is RST. But if shutdownOutput() is invoked it's a graceful close process; the packets are ACK-ed first. EDIT: another attempt after learning more about the matter: The application protocol is the server can respond anytime even while the client request is still being streamed. Therefore the client should assuming blocking mode have a separate thread reading from server. As soon as the client reads a response from server it needs to barge into the writing thread to stop further writing to the server. This can be done by simply close() the socket. On the server side if the response is written before all request data are read and close() is called afterwards most likely RST will be sent to client. Apparently most TCP stacks send RST to the other end if close() is called when the receive buffer isn't empty. Even if the TCP stack doesn't do that very likely more data will arrive immediately after close() triggering RST anyway. When that happens the client will very likely fail to read the server response hence the problem. So the server can't immediately close() after response it needs to wait till client receives the response. How does the server know that? First how does the client know that it has received the full response? That is how is the response terminated? If response is terminated by TCP FIN the server must send FIN after response by calling shutdownOutput(). If the response is self-terminated e.g. by HTTP Content-Length header the server needs not to call shutdownOutput(). After the client receives the full response per protocol it should promptly quit sending more data to the server. This is done by crudely sever the connection; the protocol didn't design a more elegant way. Either FIN or RST is fine. So the server after writing the response should keep reading from the client till EOF or error. Then it can close() the socket. However there should be a timeout for this step to account for malicious/broken clients and network problems. Several seconds should be sufficient to complete the step in most cases. Also the server may not want to read from the client since it isn't free. The server can simply wait past the timeout then close(). the client ""receives"" the response message now on the OS layer but not before it can actually read it since it is wiped by the RST packet. The problem is that the client is sending MB of data so it could be awhile before it reads and even if it reads immediately networking issues could mean the 500ms delayed RST packet ends up arriving at the same time as the earlier error message packet. However I do agree that this is a workaround that should work for most cases but if it is possible something with guaranteed consistency would be preferred. same problems exist even with shutdownOutput() @irreputable No it doesn't. The client can keep sending forever after receiving a FIN due to `shutdownOutput()`. Your other guesswork is astray as well. The problem isn;t caused by unacknowledged packets: it is caused by the client continuing to send: it receives RSTs sent by the server because the connection being sent to no longer exists. If he uses `shutdownOutput()` instead of `close()` the connection *does* exist and won't provoke RSTs. @EJP he will call close() after shutdownOutput() Accepted since something similar to what you recommend is the only real viable solution. Even with a shutdownOutput equivalent the call to close() would still have to be delayed in order to prevent RST messages from being sent upon receipt of further data. I believe that a shutdownOutput() call would however help in notifying the client before the close() call for a more graceful shutdown but it is not possible in Netty 3.x.x (afaik) but appears that it should be possible in netty 4+ (currently alpha). That is on the list of workarounds to attempt.. but the problem is it opens up a race condition where the client could still fail depending on the network conditions or how much data it is sending after the bad field. Ideally I want to avoid any possible race conditions and it feels like this should be a solved problem (send a response and close the connection). the important thing here is that the client receives the error message. we don't care about the state of the connection after that. @increment The solution isn't a pointless delay: the solution is not to send data that can't be read. This is an application protocol error.  If you can get hold of the underlying SocketChannel from Netty which I am no expert about you can call channel.socket().shutdownOutput(). Remaining data in the receive buffer causes Linux (or Java..) to flag the TCP packets with the RST flag. This prevents the client from reading the data since when it gets around to trying it finds it has a read error due to the socket being closed. I don't understand this. TCP guarantees that the client will receive all the data in its socket receive buffer before he gets the FIN. If you are talking about the server's socket receive buffer it will be thrown away by the close() and further attempts by the client to send will get an RST which becomes an IOException: connection reset' because there is no connection to associate it with and therefore nowhere to put it. NB It is TCP that does all this not Java. But it seems to me you should read the whole request before closing the channel if it's bad. You could also try increasing the socket receive buffer so it is big enough to hold an entire request. That ensures that the client won't still be sending when you want to close the connection. EDIT: I see the request is megabytes so this won't work. I do not think it is possible (in the current version of Netty) to get access to the equivalent of shutdownOutput(). You are correct that TCP (well the OS really) is sending the RST upon receipt of further data. The issue is essentially a timing issue with when close is called. Also just wanted to say thank you for the additional clarity. Answer upvoted but I accepted the other answer since a delay timer before close is the practical implementation solution (would work with shutdownOutput as well I think but unable to do so). @increment1 Adding a delay won't make the slightest difference and any answer that says otherwise is incorrect. Adding a delay makes a practical difference but does not achieve theoretical perfection. There is certainly still the possibility for error but the delay allows for a window of opportunity where the client can read the response before it is lost. It will not work every time but it is better than the alternative of always reading the entire message which could possibly be from a malicious client and never end. A broken client in this case has a chance to see the cause of the error and a malicious client is cut off before sending too much data."
705,A,"What are the Netty alternatives for high-performance networking? I am in the process of choosing a networking library to implement a client/server system that cannot spare any microsecond. It will implement its own protocol to send and receive messages. I am looking for a good NIO framework that will allow me to easily develop the server and the client without having to worry too much about the low level selector details. Everyone recommends me Netty but I would like to experiment with 2 or 3 other alternatives before committing my team with a framework. One thing I did not like very much about Netty is how it handles ByteBuffers with its own ByteBuf implementation and reference counting. Can anyone share your thoughts and alternatives? @EJM I just hit 3k and it says ""this question has an open bounty and cannot be closed."" It also prevents me from flagging... Both Netty and Mina use their own ByteBuffer abstractions. Mina 3 removes this abstraction but it is still a work in progress. Netty drives JBOSS which is a much more complex implementation of a reactor framework. Mina is more simple and low level. Recommendation questions are off-topic bounty or no bounty. @AnubianNoob I'm aware that questions with open bounties cannot be closed. That's why I posted the comment. If you are okay with using at least some Scala Spray is a great alternative to Netty. On the long run the Play framework is for example intending to migrate from Netty to Spray. Spray offers different levels of TCP abstractions. Those are: Chunk level Request level (HttpRequest / HttpResponse) Marshalled object level The deeper you dig down into the stack the more raw the delivered information is. In the chunk level API you come pretty close to original byte buffers. I never used this low abstraction level myself but I heard good things. Spray builds on top of Akka IO which is again built on top of Java NIO. All functionality wraps around Actor abstractions what makes it easy to build parallel applications using Spray. I think a chat server would be a perfect use case. Since Akka offers a Java API you should be able to use Spray with mostly this API. However you will probably need to read some Scala sources every now and then. Eventually Spray will merge completely into Akka.  We have developed a NIO networking library that performs under 2 microseconds over loopback without producing any garbage for the GC. As Peter Lawrey mentioned the native JDK selector produces a lot of garbage but we have fixed all these garbage leaks by implementing our own epoll selector. Busy waiting the selector thread is great for latency but there must be a balance not to burn the chip or consume a lot of energy. Our selector implementation use low-level tricks to implement a kind of energy saving mode that takes care of that balance. Besides CoralReactor you can also take a look on Grizzly and Mina but we haven't played with these frameworks yet. For some Netty TCP performance benchmarks you can take a look here. the only part of the JDK NIO that creates garbage relates to the ArrayList/List mechanism it stores when moving the select events to and from the Selector. This amount of garbage is relatively little. Netty and Mina then add an absurd amount of garbage on top of it. JDK NIO also does a bunch of horrible things with the synchronized keyword but thats another discussion. I am all for a better NIO than the JDK version; I just want to see the numbers of the NIO itself. I am interested in this; however the Native JDK only produces ~150 MB of garbage every 30 or so million requests. At 118 MB/s that is every 2 minutes give or take. I would like to see benchmarks against JDK NIO instead of Netty. @misterbiscuit ""_the only part of the JDK NIO that creates garbage relates to the ArrayList/List mechanism it stores when moving the select events to and from the Selector_"" - it is much more than that at least the EPOLL selector. We have run [CoralReactor](http://www.coralblocks.com/index.php/category/coralreactor/) on a _pure_ JDK and the average latency jumped from 2 to 12 microseconds. @misterbiscuit When you fix the JDK NIO classes you can send as many messages as you want without producing any garbage and `-verbose:gc` shows zero gc activity. You can see in [this benchmark](http://www.coralblocks.com/index.php/2014/04/coralreactor-vs-netty-performance-comparison/) that this approach produces numbers 10 times faster than Netty.  This is assuming you really want o save every micro-second. Most applications don't have such strick requirements. If you want to save micro-seconds you will want to use busy waiting non-blocking NIO for threads on dedicated cpus. This doesn't scale well as you need to have plenty of CPU but does minimise the latency for handling IO. I suggest you also bind the isolated CPUs to minimise jitter. You will want to avoid using Selectors as they block and/or create quite a bit of garbage adding to GC pauses. Also to minimise latency you will want to use a low latency kernel bypass network adapter such as Solarflare. You will want to use a push parser so long messages can be decoded/parsed as they download. i.e. you won't want to wait until the whole messages is recieved before starting. Using these tricks in combination can save 10 - 30 micro-seconds off every request or inbound event. Netty is a better solution for scalability ie higher net throughput but at a small cost to latency as do most frameworks which are based on support web services where milli-seconds delays are tolerable."
706,A,"Netty ping pong with a POJO Why doesn't the client receive the POJO which the server sends? this blog sample is a bit difficult for me to follow. I realize it's a lot of code but I don't know how to make slim this down while still using a POJO in this case Quote between the client and server. The server sends a quote when a connection is established: run: [java] Aug 03 2014 5:32:20 PM net.bounceme.dur.netty.QuoteServerInitializer <init> [java] INFO: ..initializing.. [java] Aug 03 2014 5:32:23 PM net.bounceme.dur.netty.QuoteServerInitializer initChannel [java] INFO: ..adding to pipeline.. [java] Aug 03 2014 5:32:23 PM net.bounceme.dur.netty.QuoteServerHandler <init> [java] INFO: ..started.. [java] Aug 03 2014 5:32:23 PM net.bounceme.dur.netty.QuoteServerHandler channelActive [java] INFO: ..sending new server Quote.. [java] Aug 03 2014 5:32:23 PM net.bounceme.dur.netty.QuoteEncoder encode [java] INFO: [java] [java] id 0 [java] quote Where there is love there is life. ^Cthufir@dur:~/NetBeansProjects/QuoteServer$ thufir@dur:~/NetBeansProjects/QuoteServer$ ^C thufir@dur:~/NetBeansProjects/QuoteServer$ but it never seems to arrive at the client: run: [java] Aug 03 2014 5:32:23 PM net.bounceme.dur.netty.QuoteClientInitializer <init> [java] INFO: ..initializing.. [java] Aug 03 2014 5:32:23 PM net.bounceme.dur.netty.QuoteClientHandler channelActive [java] INFO: ..sending new client Quote.. [java] Aug 03 2014 5:32:23 PM net.bounceme.dur.netty.QuoteEncoder encode [java] INFO: [java] [java] id 0 [java] quote client ^Cthufir@dur:~/NetBeansProjects/QuoteClient$ thufir@dur:~/NetBeansProjects/QuoteClient$ Similarly the quote which the client sends never seems to make it to the server. Why? server: package net.bounceme.dur.netty; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.logging.LogLevel; import io.netty.handler.logging.LoggingHandler; import java.util.logging.Logger; public final class QuoteServer { private static final Logger log = Logger.getLogger(QuoteServer.class.getName()); public static void main(String... args) throws InterruptedException { MyProps p = new MyProps(); int port = p.getServerPort(); new QuoteServer().pingPong(port); } private void pingPong(int port) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.DEBUG)) .childHandler(new QuoteServerInitializer()); b.bind(port).sync().channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } server initializer: package net.bounceme.dur.netty; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; import io.netty.handler.codec.DelimiterBasedFrameDecoder; import io.netty.handler.codec.Delimiters; import java.util.logging.Logger; public class QuoteServerInitializer extends ChannelInitializer<SocketChannel> { private static final Logger log = Logger.getLogger(QuoteServerInitializer.class.getName()); public QuoteServerInitializer() { log.info(""..initializing..""); } @Override public void initChannel(SocketChannel ch) throws Exception { log.info(""..adding to pipeline..""); ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(new QuoteDecoder()); pipeline.addLast(new QuoteEncoder()); pipeline.addLast(new QuoteServerHandler()); } } server handler: package net.bounceme.dur.netty; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import java.util.Random; import java.util.logging.Logger; import net.bounceme.dur.jdbc.Quote; public class QuoteServerHandler extends SimpleChannelInboundHandler<Quote> { private static final Logger log = Logger.getLogger(QuoteServerHandler.class.getName()); private static final Random random = new Random(); public QuoteServerHandler() { log.info(""..started..""); } // Quotes from Mohandas K. Gandhi: private static final String[] quotes = { ""Where there is love there is life."" ""First they ignore you then they laugh at you then they fight you then you win."" ""Be the change you want to see in the world."" ""The weak can never forgive. Forgiveness is the attribute of the strong.""}; private static Quote nextQuote() { int quoteId; synchronized (random) { quoteId = random.nextInt(quotes.length); } return new Quote(quotes[quoteId]); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { log.info(""..sending new server Quote..""); ctx.writeAndFlush(nextQuote()); } @Override protected void channelRead0(ChannelHandlerContext chc Quote quote) throws Exception { log.info(quote.toString()); chc.writeAndFlush(nextQuote()); } @Override public void channelRead(ChannelHandlerContext ctx Object msg) { log.info(msg.toString()); ctx.writeAndFlush(nextQuote()); } @Override public void channelReadComplete(ChannelHandlerContext ctx) { ctx.flush(); } } client: package net.bounceme.dur.netty; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioSocketChannel; import java.io.IOException; import java.util.logging.Logger; public final class QuoteClient { private static final Logger log = Logger.getLogger(QuoteClient.class.getName()); public static void main(String... args) throws InterruptedException IOException { new QuoteClient().connect(); } public void connect() throws InterruptedException IOException { MyProps p = new MyProps(); String host = p.getHost(); int port = p.getServerPort(); pingPong(host port); } public void pingPong(String host int port) throws InterruptedException IOException { EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .handler(new QuoteClientInitializer()); ChannelFuture cf = b.connect(host port); cf.sync().channel().closeFuture().sync(); } finally { group.shutdownGracefully(); } } } client initializer: package net.bounceme.dur.netty; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.socket.SocketChannel; import io.netty.handler.codec.DelimiterBasedFrameDecoder; import io.netty.handler.codec.Delimiters; import java.util.logging.Logger; public class QuoteClientInitializer extends ChannelInitializer<SocketChannel> { private static final Logger log = Logger.getLogger(QuoteClientInitializer.class.getName()); public QuoteClientInitializer() { log.info(""..initializing..""); } @Override public void initChannel(SocketChannel ch) { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(new QuoteDecoder()); pipeline.addLast(new QuoteEncoder()); pipeline.addLast(new QuoteClientHandler()); } } client handler: package net.bounceme.dur.netty; import io.netty.channel.ChannelHandler.Sharable; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import java.util.logging.Logger; import net.bounceme.dur.jdbc.Quote; @Sharable public class QuoteClientHandler extends SimpleChannelInboundHandler<Quote> { private static final Logger log = Logger.getLogger(QuoteClient.class.getName()); @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { log.info(""..sending new client Quote..""); ctx.writeAndFlush(new Quote(""client"")); } @Override protected void channelRead0(ChannelHandlerContext chc Quote quote) throws Exception { log.info(quote.toString()); } @Override public void channelRead(ChannelHandlerContext ctx Object msg) { log.info(msg.toString()); ctx.writeAndFlush(new Quote(""client"")); } @Override public void channelReadComplete(ChannelHandlerContext ctx) { ctx.fireChannelReadComplete(); } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) { log.info(cause.toString()); ctx.close(); } } decoder: package net.bounceme.dur.netty; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.MessageToMessageDecoder; import java.util.List; import java.util.logging.Logger; import net.bounceme.dur.jdbc.Quote; public class QuoteDecoder extends MessageToMessageDecoder<Quote> { private static final Logger log = Logger.getLogger(QuoteDecoder.class.getName()); @Override protected void decode(ChannelHandlerContext chc Quote quote List<Object> list) throws Exception { log.info(quote.toString()); list.add(quote); } } encoder: package net.bounceme.dur.netty; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.MessageToMessageEncoder; import java.util.List; import java.util.logging.Logger; import net.bounceme.dur.jdbc.Quote; public class QuoteEncoder extends MessageToMessageEncoder<Quote> { private static final Logger log = Logger.getLogger(QuoteEncoder.class.getName()); @Override protected void encode(ChannelHandlerContext chc Quote quote List<Object> list) throws Exception { log.info(quote.toString()); list.add(quote); } } It's quite notable that the en/de-code methods never log to the console. I added them but keep in mind that they **never** execute -- or at least they never log output to the console which they would do if their en/de-code methods ran. please add the code of your QuoteDecoder and Encoder. If you edit the channelActive method of your QuoteServerHandler to the following: @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { log.info(""..sending new server Quote..""); ChannelFuture cf = ctx.writeAndFlush(nextQuote()); if (!cf.isSuccess()){ log.log(Level.SEVERE cf.toString()); } ctx.fireChannelActive(); } then you will most probably get a message saying: unsupported message type: Quote Your encoder needs to encode it into something that is supported. I don't now what that would be though. I would suggest using an ObjectEncoder which could encode your Quote into a ByteBuf. On the receiving site you need an ObjectDecoder. After that you can cast your received msg in your ClientHandler back to Quote."
707,A,"How to elaborate information flow in large scale distributed system by UML I am currently Designing UML Diagrams for a distributed backed made up of 8 nodes which handle specific operations depending on the message received from the web Client. The problem I have is that the initial node which acts as the ""Gate of Entry"" to all messages and interactions generated from the Client-end does not contain concrete operations that could be denoted as ""Standard Use cases"" but only a multitude of message flows pertaining to client-end use cases operations that flow throw this point. But I also desperately require a method to show a process mapping between the client-end Use Case and initial node Use Case processes for consistency sake. If these messages are not mapped the following the flow of operations from the Client-end to Server-end will be somewhat complicated. Unfortunately due to the complexity of the system I have a problem of designing the whole System in a single diagram too. Some Possible Improvisations considered • To create ""Place holder"" like Use Case Ext. notation to indicate an extension. E.g. The client-end has a place new order Use Case from which a message flows through initial node to the back-end nodes. In order to create connectivity indicate a Use Case which would read Place new order Ext. and this would signify a connectivity but would only point to a message flow.(But I am not sure if this practice is largely excepted in UML.) • Only rely on Sequence and communication diagrams aim to show how ""things"" interact each lifeline designating one of the system components. But I feel is that the correlation between Client-end and Back-end Use Case will not be very clear. I also checked for similar problems on this forum and there were a few but did not explicitly answer my question.so I thought of posting this question. Can someone please suggest what would be the best option in showing information flow in this highly event-driven distributed information system such as this - One of the above mentioned or any other options that I may have overlooked? Have you considered using component diagrams where the components have ports and the ports accept (and produce) signals instead of operations? A signal is basically a message / event. You can also model signals as classes at the high level or in as much detail as you need. You could model some of the properties of an application-level signal such that you can show how a component demultiplexes based on some property before forwarding the message along to an output port."
708,A,"Does Netty 4 support UDP multicast with IGMPv3? I've been unable to find any reference to Netty 4 supporting UDP multicast with IGMPv3 in the documentation. Can anyone clarify if this is supported or not? Is it ever supported by JDK? The javadoc for MulticastChannel states ""It may optionally support source filtering as specified by RFC 3376: Internet Group Management Protocol Version 3 (IGMPv3)"". What isn't clear is if optionally refers to the implementation or an option you need to specify. Everything that is possible with plain jdk7 should also be possible with Netty in terms of multicast. From Netty Discussions Google Group"
709,A,"Netty App Design For Large Number of Small Transfers I'm trying to decide how to design a Netty app with what I think are some unusual requirements. Basically there's a client that initiates a request. That request translates into English as ""Go recursively get a bunch of little tiny files under directory /whatever/ and all I can tell you about those files is that their names are between AAAAAAA.bin and CCCCCCC.bin"". So the server needs to take the request and start scanning some directories on the server side and start rapidly streaming all these little files back. Performance is critical but so is making sure that I've received all files between AAAAAAA.bin and CCCCCCC.bin. So would it be a good design to make the client and server basically asynchronus themselves? In other words the client initiates the conversation sends the request and simply receives an acknowledgement UUID token or something and then the server begins gathering up files (maybe one per thread) contacts the client and hands it a single file along with the UUID? I'm thinking that the client could periodically ask the server ""are you done streaming my request that matched UUID token /sometoken/? I'm not quite sure how this would be configured since the client and server both would be initiating conversations. Or maybe someone else has a better design idea? Again performance (total time from request initiation to completion of all file transfers) is critical. Thanks! Assuming that you're in complete control of the protocol (ie you're not limited to HTTP) then perhaps something like Client connects to server and sends directory request. If client is restarting an aborted transfer is sends a request with the token from 2 Server responds with a unique token for this transfer. If transfer is being restarted it responds with the token from 1. Server identifies all files for this transfer gives each file a unique id and associates the file set with the token from 2 (might want to figure out the files before generating the token) For each file the server sends a message consisting of file length unique file id file (and any other information such as filename). The server sends each file ASAP and does not wait for the acknowledgement from 5. Client acknowledges each file received using unique file id. After last file sent server sends a ""transfer complete"" message. All of the above communication happens over a single channel. The important point is that you're streaming the files and receiving acknowledgements asynchronously thus mitigating network latency. If you have a lot of files I wouldn't use a thread per file. Perhaps a thread pool where each file to send is added to a job queue or perhaps each unique directory is added to the job queue and a thread processes a directory at a time. You may need to synchronise calls to channel.write(..). I'm also assuming that it's ok for the client to receive files out of order. Actually I would initially get it going with just one thread to read the files. Once it's working reliably look to see if having multiple threads enables you to increase performance by keeping the network busy (ie not waiting to read the next file). When writing to the channel I'd probably write on object containing the file details (unique id file data if small enough filename if necessary) and then have a codec that can convert the object to / from a channel buffer. Depending on your exact circumstances the client could open multiple connections to the server and you could assign a connection to a specific file reading thread thus avoiding any channel synchronisation issues. You may get some performance increase that way but most likely you'll just see the available bandwidth shared between the connections."
710,A,"Channel.id () has been removed in netty4.0 final version how can I solve? We update to netty4.0 final version but Channel.id () has been removed. We need to take the initiative to send a message server to the client how to find the appropriate Channel? We do not deal directly with the completion handler returned to the client but the process needs to be transferred to another server and then return to send to the client. Before we use Channel.id () can be done but Channel.id () has been removed what alternative solutions do?With channel.hashcode () can? Yeah.... that was an 11th hour nasty surprise ! Following this question with interest.... It's coming back in 4.1: https://github.com/netty/netty/issues/1810 There have been some issues raised on Github about this removal. Norman indicates that you could use Channel.hashcode() but it is not guaranteed to be unique: https://github.com/netty/netty/pull/1540 Another idea would be to create a custom ChannelGroup but that brings its own complications discussed briefly here: https://github.com/netty/netty/issues/1589 Trustin is bringing back a variant of channel id in 4.1.0: https://github.com/netty/netty/issues/1810  I made a simple counter: public class SimpleChannel extends NioSocketChannel { protected static final AtomicLong nextId = new AtomicLong(0); protected long id = nextId.getAndIncrement(); public SimpleChannel() { } public SimpleChannel(SocketChannel socket) { super(socket); } public SimpleChannel(Channel parent Integer id SocketChannel socket) { super(parent id socket); } public long getId() { return id; } } Setting custom class to Bootstrap: EventLoopGroup workerGroup = new NioEventLoopGroup(); Bootstrap clientFactory = new Bootstrap(); clientFactory.group(workerGroup); clientFactory.channel(SimpleChannel.class); For server a bit more difficult: public class SimpleServerChannel extends NioServerSocketChannel { private static final InternalLogger log = InternalLoggerFactory.getInstance(HttpServerChannel.class); @Override protected int doReadMessages(List<Object> buf) throws Exception { SocketChannel ch = javaChannel().accept(); try { if (ch != null) { buf.add(new SimpleChannel(this ch)); return 1; } } catch (Throwable t) { log.warn(""Failed to create a new channel from an accepted socket."" t); try { ch.close(); } catch (Throwable t2) { log.warn(""Failed to close a socket."" t2); } } return 0; } } Setting custom class to ServerBootstrap: EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup); b.channel(SimpleServerChannel.class);"
711,A,"audio stream server with netty I'm trying create a simple audio stream server like a concept proof but I'm having some dificulties. I'm streaming a single file to start I searched but didn't found enought information to create a audio stream server so I just created a simple server based on my little knowledge about servers. I've created it with netty passing the stream to ChunkedStream object and wrote it on channel: public class CastServerHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { HttpRequest request = (HttpRequest) e.getMessage(); if (request.getMethod() != GET) { sendError(ctx METHOD_NOT_ALLOWED); return; } HttpResponse response = new DefaultHttpResponse(HTTP_1_1 OK); System.out.println(response.toString()); Channel channel = e.getChannel(); channel.write(response); ChannelFuture writeFuture; StreamSource source = StreamSource.getInstance(); ChunkedStream stream = new ChunkedStream(source.getLiveStream()); writeFuture = channel.write(stream); writeFuture.addListener(new ChannelFutureProgressListener() { public void operationComplete(ChannelFuture future) { System.out.println(""terminou""); future.getChannel().close(); } public void operationProgressed(ChannelFuture future long amount long current long total) { System.out.println(""Transferido: "" + current + "" de "" + total); } }); if (!isKeepAlive(request)) { writeFuture.addListener(ChannelFutureListener.CLOSE); } } private void sendError(ChannelHandlerContext ctx HttpResponseStatus status) { HttpResponse response = new DefaultHttpResponse(HTTP_1_1 status); response.setHeader(CONTENT_TYPE ""text/plain; charset=UTF-8""); response.setContent(ChannelBuffers.copiedBuffer( ""Failure: "" + status.toString() + ""\r\n"" CharsetUtil.UTF_8)); // Close the connection as soon as the error message is sent. ctx.getChannel().write(response) .addListener(ChannelFutureListener.CLOSE); } private void writeLiveStream(Channel channel) { StreamSource source = StreamSource.getInstance(); ChunkedStream stream = new ChunkedStream(source.getLiveStream()); channel.write(stream); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) throws Exception { e.getCause().printStackTrace(); e.getChannel().close(); } } Ufortunately I didn't successfully streamed the audio directly to web browser so I tryied to figure out what icecast returns as response to web browser and it return these properties in header: Cache-Control:no-cache Content-Type:application/ogg Server:Icecast 2.3.2 ice-audio-info:samplerate=44100;channels=2;quality=3%2e00 icy-description:Stream de teste icy-genre:Rock icy-name:Radio teste Brevleq icy-pub:0 Is there a simple way netty use to put these content in HttpResponse header (specially Content-type:applicatio/ogg)?? I hope this is the problem... The only header that is required is the `Content-Type`. Everything else is just extra info. See the API of HttpResponse. It has setHeader method.  I'd consider going with a straight binary protocol and creating an HTTP interface only for a proxy. There's no reason to deal with a text based protocol for something like this."
712,A,"Characters allowed in CookieDecoder My company uses a lot of legacy cookies that contain '=' and '' in the cookie value. An example would be: A=v=1&lg=en-USit-ITit&intl=it&np=1;T=z=E . Right now it is not possible to get rid of those cookies and we need Netty to not throw an IllegalArgumentException on validating those cookies. Are there any suggestions? Would it be okay to submit a patch to CookieDecoder maybe read in some env variable which will pick the right regex accordingly? Thanks! Netty 3.5.1.Final has no problem decoding the cookie you mentioned: @Test public void testDecodingValuesWithCommasAndEquals() { String src = ""A=v=1&lg=en-USit-ITit&intl=it&np=1;T=z=E""; Set<Cookie> cookies = new CookieDecoder().decode(src); Iterator<Cookie> i = cookies.iterator(); Cookie c = i.next(); assertEquals(""A"" c.getName()); assertEquals(""v=1&lg=en-USit-ITit&intl=it&np=1"" c.getValue()); c = i.next(); assertEquals(""T"" c.getName()); assertEquals(""z=E"" c.getValue()); } Awesome thank you so much for looking into this! We are using 3.3.1.Final and the CookieDecoder logic is totally different that explains a few thing. Thanks again!"
713,A,Which version of Netty API does this example code use? Unable to resolve io.netty.handler.codec.http.DiskFileUpload with 3.2.x I came across this sample code for handling file uploads with Netty this looks perfect just what I needed. Unfortunately I am having difficulty incorporating this class as many Netty API features are unresolved. One of them for example is io.netty.handler.codec.http.DiskFileUpload I am unable to find this in any of the online API docs for 3.03.1.3.2. The class I am having issues with is here: https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/http/upload/HttpUploadServerHandler.java I have tried using netty-3.2.5.final 3.3.1.final 3.4.0.Alpha Unresolved imports: import org.jboss.netty.handler.codec.http.HttpPostRequestDecoder.EndOfDataDecoderException; import org.jboss.netty.handler.codec.http.HttpPostRequestDecoder.ErrorDataDecoderException; import org.jboss.netty.handler.codec.http.HttpPostRequestDecoder.IncompatibleDataDecoderException; import org.jboss.netty.handler.codec.http.HttpPostRequestDecoder.NotEnoughDataDecoderException; import org.jboss.netty.handler.codec.http.InterfaceHttpData; import org.jboss.netty.handler.codec.http.InterfaceHttpData.HttpDataType import org.jboss.netty.handler.codec.http.HttpDataFactory; import org.jboss.netty.handler.codec.http.DiskAttribute; import org.jboss.netty.handler.codec.http.DiskFileUpload; import org.jboss.netty.handler.codec.http.FileUpload; import org.jboss.netty.handler.codec.http.DefaultHttpDataFactory; import org.jboss.netty.handler.codec.http.Attribute Any help appricated When you see the org.jboss.netty namespace that indicates v3.x io.netty is used in v4. Online documentation is located at http://netty.io/docs/  It's under master branch which is 4.0.0.Alpha1-SNAPSHOT from the pom.
714,A,"Netty websocket server high availability I have looked at a similar question : Netty High Availability Cluster. The scenario I have is : There is a netty websocket server to which various native javascript web socket clients connect to. I am looking at basic high availability of the websocket server and want that it should fail over to a backup server if required. The question in the above given link talks of netty clients but since I dont have the clients written in netty  I was thinking my scenario would be different from that question. Am I right? Can someone suggest some way to do this since I guess this would be a fairly important requirement sometimes?? Assuming that you don't have control of your clients how about having a number of netty servers behind a traditional load balancer and storing session state in a hazelcast or infinispan cluster? Both platforms allow you to either embed them directly in your server or have a remote cache.  Xitrum is very suitable for your need. It uses Hazelcast to scale out to multiple servers. You can try the WebSocket demo. To enable cluster mode just set ""multicast"" and/or ""tcp-ip"" in config/hazelcast_cluster_member_or_super_client.xml to ""true"" and start multiple servers.  Because web sockets is connection oriented if your server goes does so does your web socket connection. So for high availability I think you will need to adjust your javascript code to catch connection errors and reconnect/login. In this way you can put several netty servers behind a load balancer. Hope this helps."
715,A,"ExtJS JsonStore and Netty Im trying to impelement comunication between ExtJS and Java I'm sending requests from ExtJS to a Java server thats using netty. I would appriciate if someone could send me an example of how the response should be formated from the java side and how to read the response data from the ExtJS side thanks in advance. This is my source from the ExtJS side var store = new Ext.data.JsonStore({ autoload: true baseParams: { conid : '6b09477f-aa04-4f5a-b969-05277d01f07e' } root: 'OpenCashTime' proxy: new Ext.data.ScriptTagProxy({ url: 'http://localhost:8080/getOpenCash?' }) fields: [{name: 'Time' mapping: 'Time' type: 'int'}] }); store.load(); store.on('load' function() { alert(store.getTotalCount()); }); store.on('write' function() { alert(store.getTotalCount()); }); store.on('loadexception' function() { alert(""AAAAAA""); }); store.on('metachange' function() { //alert(store.getTotalCount()); }); store.on('update' function() { //alert(store.getTotalCount()); }); store.on('save' function() { //alert(store.getTotalCount()); }); store.on('datachanged' function() { //alert(store.getTotalCount()); }); When executing this code and reciving this response {""OpenCashTime"":[{""Time"":1291623637000}{""Time"":1294914317000}]} I still get a loadexception although even firebug sees its Json Please update your code in the question. I think I've understood already found a solution +) thanks for your help Why ScripTagProxy? Will you be loading data from cross-domain source? Yes for now I'm testing on localhost plus its not on the same server the ExtJS is running on an Apache Tomcat server and the netty part is running on different port so its counted as cross-domain Ok. For ScriptTagProxy your response must look like this: `callback({""OpenCashTime"": [{""Time"":1291623637000}{""Time"":1294914317000}]})`. shouldn't then I add a callback function name? Yes. In fact you should configure your ScriptTagProxy with `callbackParam` parameter which is `The name of the parameter to pass to the server which tells the server the name of the callback function set up by the load call to process the returned data object. Defaults to ""callback"".` Although I seem to remember that `callback` is the default value used. Thanks will try it out now ok after adding the callback to the json string it doesn't give me a load exception but how do I could this function? sorry for the newbie questions im a bit new to JS Assuming from your title that you want to load data into JsonStore it expects a valid Json string with a property storing an array of JSON objects that will be loaded as records. The property name is set up by root property when configuring JsonStore. Store like this: { xtype: 'jsonstore' root: 'data' idProperty: 'ID' fields: [ {name: 'ID' mapping: 'ID' type: 'int'} {name: 'someDate' mapping: 'someDate' type: 'date' dateFormat: 'Y-m-d'} ] url: 'hereBeYourURl' } Will gladly eat something like this: {""data"":[{""ID"":""1""""someDate"":""2002-10-02""}{""ID"":""2""""someDate"":""2002-05-22""}]} although my string is ok now im still reciving an error I'll edit my post and add my ExtJS source code jsonlint is a good way to test if a string is valid json Ive tested it already its a valid json string @Swine1973: Why are you using a ScriptTagProxy? Are you going to load this data from cross-domain source? If yest then it needs to be formatted a bit differently. If no just use default proxy from JsonStore. well the string that I get in my response is OpenCashTime{Time:1291623637000Time:1294914317000} so I guess I should write root: 'OpenCashTime'and in the fields : {name: 'Time' mapping: 'Time' type: 'int'} or should I change somehow the string to fit the currect format? For `Ext.JsonStore` you need a valid JSON string. What you have now is far from being a valid JSON. You'd need something like this: `{""OpenCashTime"": [{""Time"":1291623637000}{""Time"":1294914317000}]} `  fields: [{name: 'Time' mapping: 'Time' type: 'int'}] fields: [{name: 'Time' type: 'int'}] BTW In the case of an identity mapping you can leave it out. These two cases will give you the same results. Im sorry but does it help me? If you know that this part of the code is correct? I like to have mapping explicitly set. Makes for easier changes."
716,A,"Does anyone have any example using WebSocketClientProtocolHandler with binary websocket messages? I'm having trouble sending a binary message over my client websocket. We have our own message object along with to/from binary. So I created a class that extends ByteToMessageCodec. The call to channel.writeAndFlush(MyMessageInstance) goes into the encode where it gets the byte[] and calls the out.writeBytes(byteArray). When I call channel.writeAndFlush() - it enters/exits the encode but then it never seems to make it on the wire. Below is the channel pipeline initialization. MessageHandler is just a SimpleInboundHAndler that takes our MessageType. Please NOTE: I'm using the WebSocketClientProtocolHandler as the means to do the upgrade handshake etc. Thanks in advance for any suggestions Bob boolean handleCloseFrames = false; WebSocketClientHandshaker handshaker = WebSocketClientHandshakerFactory.newHandshaker(serverUri WebSocketVersion.V13 null false null); final WebSocketClientProtocolHandler wsHandler = new WebSocketClientProtocolHandler(handshaker handleCloseFrames); this.getBootstrap().handler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""http-codec"" new HttpClientCodec()); pipeline.addLast(""aggregator"" new HttpObjectAggregator(65536)); pipeline.addLast(""ws-handler"" wsHandler); pipeline.addLast(""message-codec"" new CustomMessageCodec()); pipeline.addLast(""message-handler"" messageHandler); } }); ChannelFuture future = this.getBootstrap().connect(serverUri.getHost() serverUri.getPort()); channel = future.sync().channel(); `public class ThingworxMessageCodec extends ByteToMessageCodec { Override protected void encode(ChannelHandlerContext ctx MyMessage msg ByteBuf out) throws Exception { byte[] rawMessage = msg.getBinaryMessage(); out.writeBytes(rawMessage); } Override protected void decode(ChannelHandlerContext ctx ByteBuf in List out) throws Exception { byte[] rawMessage = in.array(); MyMessage decodedMessage = MyMessageFactory.fromBinary(rawMessage); out.add(decodedMessage); } }` apologies for the lack of formatting... Could you share the class extending ByteToMessageCodec ByteToMessageCodec (and MessageToByteEncoder) is meant to transform a custom object to ByteBuf. WebSocketClientHandshaker will add WebSocketFrameEncoder into the pipeline so that you can send a WebSocketFrame once handshake is finished. One thing to note is that WebSocketFrameEncoder encodes only WebSocketFrame and its subtypes. Therefore anything encoded by your ByteToMessageCodec will not be handled by WebSocketFrameEncoder at all and your server will probably not understand what you sent. To fix this problem you have to use MessageToMessageCodec instead of ByteToMessageCodec and encode your message to BinaryWebSocketFrame and decode a BinaryWebSocketFrame into your message. Thanks Trustin - once I went back and looked again at what the existing handlers in the pipeline were doing it clicked and I realized exactly what you pointed out: this is 1 message to another.  Try to add this method to the ByteToMessageCodec: @Override public boolean acceptOutboundMessage(Object msg) throws Exception { return msg instanceof MyMessage; } thanks for the suggestion but that had no effective on getting the message on the wire"
717,A,"What exactly is a message in a MessageEvent? I have the requirement of recording (and replaying) UDP packets with netty. The javadoc for MessageEvent states: ""A ChannelEvent which represents the transmission or reception of a message."" In the case of a UDP socket does this mean that the message always contains the payload of exactly one distinct received UDP packet? Or are the messages a more abstract concept in that they can contain only fragments or the payloads of multiple UDP packets. I am using Netty 3.6.2.Final. Yes the message event will contain the payload of exactly one UDP packet."
718,A,"Difference between JBOSSAS and Netty Maybe this is a too newbie question but I don't really understand the differente bs JSBOSS Application Server (now named WildFly) and Netty (or JBOSS Netty). Are they both web servers? Are they frameworks? Thanks! Wildfly is a full blown application server and Netty is ""just"" a network framework. So those are completely different in all means. I see but what are some features making them different? I don't understand the ""blown application server"" definition. Being Netty a network framework means an HTTP server only?  Wildfly is a Java Enterprise Edition Server meaning it implements the Java EE specification. When you use Wildfly the jars provided by JBOSS should include implementations of all of the APIs listed in the specification above i.e. javax.servlet for servicing HTTP requests or javax.persistence (provided by Hibernate under the covers) for saving data to a database. Netty is not a Java EE Server it is a bare-bones framework for servicing any type of network request. It does not offer implementations of any of the API's listed in the Java EE Spec. Netty provides different 'codecs' to service different types of common network requests like Http SPDY etc. Equally if you have a custom network protocol you can write your own codec to handle it. Netty does not for example offer any support for helping you write records to a database. There are many other technical differences. Netty is effectively event-looped rather than thread-per-request but the above is the key difference you're probably looking for. Basically correct. Java EE is a collection of API specifications commonly thought to be useful to people building 'Enterprise' applications. Receiving requests doing stuff logging results communication via common protocols writing things to databases. If you're writing an application and you don't want to re-invent the wheel you should use EE apis. If you're very concerned about performance being stream-lined only using the absolute minimum possible and being 'close-to-the-iron' AND want to communicate over the network use Netty. this is closer to what I was expecting. Although I now understand it better it is not totally clear were is one in respect to the other. Are they in different layers or does Wildfly have _some_ layers in common with Netty? let's see if I understood it right: in JBOSS I should place java code that need help interacting with the JEE specification (this includes some networking tasks) while in Netty I should place java code that need help only with networking tasks (but resolves other issues like persistance in their own). Is that a correct statement?"
719,A,"Setting context for development server [playframework 2.1.3] I am using Java / Play Framework 2.1.3. In production I build a war using the plugin serve it in tomcat and tell apache to redirect /myapp to my tomcat app. In development I start the server with: play debug run And the root for my dev instance is ""/"". Now I would like to specify the context for my development instance. For example I'd like the route to be /myapp but in the routes file I'd like root to still be ""/"" etc. How do I do this? In Play 2.1.x you can specify the context in your application.conf file. application.context=""/myapp"" ...or you can do what I do and just run a local Apache instance and do the same thing as you do in prod :) So in the template when I want to refer to an asset I use:@routes.Assets.at(""css/bootstrap.css"")"
720,A,"Designing a RESTful Application on Netty I would like my services which based on Netty to be RESTful. Is anyone experienced with a good library which I can use in order to fulfill that requirement? The server should support Comet. From what I read Netty is doing better that Jetty with serving Comet. Any reason for Netty rather than Jetty? Usually RESTful means HTTP as the transport these days. webbit-rest is not bad. It is based on Jetty but take a look at Restlet public class FirstServerResource extends ServerResource { public static void main(String[] args) throws Exception { // Create the HTTP server and listen on port 8182 new Server(Protocol.HTTP 8182 FirstServerResource.class).start(); } @Get public String toString() { return ""hello world""; } }  I used restexpress in the past. Its based on netty.. https://github.com/RestExpress/RestExpress Well it was really straight forward to use and worked very well even on high scale. So I think there is nothing more to say ;) Hi can you share your experience of using it? mostly in the performance perspective."
721,A,"How to mock Netty? I just inherited a project using netty and it seems to entangle itself in the code in that many handlers are created implementing netty interfaces etc. I want to mock it in such a way that I can add tests to test from the netty api upwards firing bytes in and receiving bytes back but not connecting a socket to do so. Is there any way to fire into the pipeline myself which would test netty code as well as our code and also receive from the code? Specifically I am looking to do something like this: SysUnderTest(channel) { channel.addReadListener(myListenerImpl); } Test { testStuff() { channelMock = new MockChannel(); SysUnderTest system = new SysUnderTest(channelMock); //BIG NOTE: The get here is just getting what the mocked cached when the SysUnderTest //ended up calling the channel.addReadLsitener(listenerImpl)!!! ReadListener listenerImplToTest = channelMock.getAddedListenerImpl(); listenerImplToTest.fireNewDataIncoming(byteBuffer1); Assert.Equals(""new state"" system.getState()); listenerImplToTest.fireNewDataIncoming(byteBuffer2); Assert.Equals(""state2"" system.getState()); } } Maybe I need a paradigm shift but I think any system testing with an IO library should be firing data to a listener that will react. My test needs to fire data in by invoking the listener implementation's event method (and it gets the listenerImpl though the mock channel) but I don't see how to do this in netty. Specifically which method is firing data in for the example above. It looks like it's reading the data (which seems more like a blocking/polling thing). Maybe I need to change my paradigm of the way I am thinking about this though? You can try using mock objects. See https://github.com/netty/netty/pull/119.  @Test public void testPerformOpeningHandshake() { Channel channelMock = EasyMock.createMock(Channel.class); DefaultChannelPipeline pipeline = createPipeline(); EasyMock.expect(channelMock.getPipeline()).andReturn(pipeline); // capture the http response in order to verify the headers Capture<HttpResponse> res = new Capture<HttpResponse>(); EasyMock.expect(channelMock.write(capture(res))).andReturn(new DefaultChannelFuture(channelMock true)); replay(channelMock); HttpRequest req = new DefaultHttpRequest(HTTP_1_1 HttpMethod.GET ""/chat""); req.setHeader(Names.HOST ""server.example.com""); req.setHeader(Names.UPGRADE WEBSOCKET.toLowerCase()); req.setHeader(Names.CONNECTION ""Upgrade""); req.setHeader(Names.SEC_WEBSOCKET_KEY ""dGhlIHNhbXBsZSBub25jZQ==""); req.setHeader(Names.SEC_WEBSOCKET_ORIGIN ""http://example.com""); req.setHeader(Names.SEC_WEBSOCKET_PROTOCOL ""chat superchat""); req.setHeader(Names.SEC_WEBSOCKET_VERSION ""13""); WebSocketServerHandshaker17 handsaker17 = new WebSocketServerHandshaker17(""ws://example.com/chat"" ""chat"" false); handsaker17.performOpeningHandshake(channelMock req); Assert.assertEquals(""s3pPLMBiTxaQ9kYGzzhZRbK xOo="" res.getValue().getHeader(Names.SEC_WEBSOCKET_ACCEPT)); Assert.assertEquals(""chat"" res.getValue().getHeader(Names.SEC_WEBSOCKET_PROTOCOL)); } What is your system under test in that example? WebSocketServerHandshaker17? and if so AFTER I give the channelMock I need to push data just like it is pushed from nio to the system undertest...it would not be read right because in nio reads all are pushed as they come in. Let me edit my post a bit as an example  Yes have a look at the embedder package in the javadoc Especially the DecoderEmbedder class. hmmmm it says ""without setting up the pipeline"" I am trying to simulate a full blow QA test really here where I pass in a mock something but createpipeline is being done by the code....I can't change that really. Will this still work somehow?"
722,A,"POSTing data to netty with Apache HttpClient I'm trying to use Apache HttpClient (the fluent API) to POST data to a netty server. I've tried a few variations I'll put two here: 1. Client: Request.Post(uri).bodyString(""content value"" ContentType.TEXT_PLAIN).useExpectContinue().execute().returnContent().asString(); Server: final HttpPostRequestDecoder decoder = new HttpPostRequestDecoder(new DefaultHttpDataFactory(false) req); System.out.println(decoder.getBodyHttpDatas().size()); Calling getBodyHttpDatas() throws a: io.netty.handler.codec.http.multipart.HttpPostRequestDecoder$NotEnoughDataDecoderException 2. Client: Request.Post(uri).bodyForm(new BasicNameValuePair(""value"" ""content value"")).useExpectContinue().execute().returnContent().asString(); Server: final HttpPostRequestDecoder decoder = new HttpPostRequestDecoder(new DefaultHttpDataFactory(false) req); final InterfaceHttpData data1 = decoder.getBodyHttpData(""value""); while (decoder.hasNext()) { final InterfaceHttpData data = decoder.next(); if (data != null) { try { Attribute attribute = (Attribute) data; System.out.println(attribute.getValue()); } finally { data.release(); } } } This doesn't print any output - decoder.hasNext() is false. it's difficult to deal with 2 issues at the same time I would try to separate the two problems : use curl to send POST data to you server make it work and then make your client work. Can't see anything unexpected in the request. There's no body I can see on the request there is a decoderResult which has a success value. Pausing doesn't seem to help. I haven't been able to figure out how to get an HttpContent to pass to offer(). Oh and curl --form ""value=@value.txt"" [url] also fails with the NotEnoughDataDecoderException. curl -X POST -d @value.txt [url] gives me the NotEnoughDataDecoderException too. I haven't tried the non-fluent HttpClient API but I don't believe that's the issue particularly as curl fails similarly. Have you tried with these examples http://www.vogella.com/tutorials/ApacheHttpClient/article.html? What happen when you do that? Could you trace in your server part what is in you request (`req`) body before trying to decode it ? As you can see in the API the exception is thrown due to missing chunks: [API](http://netty.io/3.5/api/org/jboss/netty/handler/codec/http/multipart/HttpPostRequestDecoder.html#getBodyHttpDatas%28%29). - Do you mind calling `offer(...)` first or add a pause of 500ms (for test purposes only)? To solve the problem you either need to offer() all chunks (HttpContent) of a message to HttpPostRequestDecoder before calling getBodyHttpDatas() or alternatively you can just add the HttpObjectAggregator handler right before your handler to the channel's pipeline. If you do so HttpObjectAggregator will collect all chunks for you and produce a single FullHttpRequest in place of multiple chunks. Passing FullHttpRequest instead of an ordinary HttpRequest to HttpPostRequestDecoder's constructor eliminates need to offer() chunks. So you just need to pipeline.addLast(new HttpObjectAggregator(1048576)) before adding your handler. For example: public class YourServerInitializer extends ChannelInitializer<SocketChannel> { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new HttpServerCodec()); pipeline.addLast(new HttpObjectAggregator(1048576)); pipeline.addLast(new YourServerHandler()); } } 1048576 here is the maximum length of the aggregated content. You are free to pass another value. Thanks there were other issues with my handler but I managed to modify the code at http://stackoverflow.com/questions/23651447/netty-io-client-not-sending-request-body to my needs. This then solved the next problem."
723,A,"Sending POST params with Netty and why isn't DefaultHttpDataFactory not in the releases? HttpRequest httpReq=new DefaultHttpRequest(HttpVersion.HTTP_1_1HttpMethod.POSTuri); httpReq.setHeader(HttpHeaders.Names.HOSThost); httpReq.setHeader(HttpHeaders.Names.CONNECTIONHttpHeaders.Values.KEEP_ALIVE); httpReq.setHeader(HttpHeaders.Names.ACCEPT_ENCODINGHttpHeaders.Values.GZIP); String params=""a=b&c=d""; ChannelBuffer cb=ChannelBuffers.copiedBuffer(paramsCharset.defaultCharset()); httpReq.setHeader(HttpHeaders.Names.CONTENT_LENGTHcb.readableBytes()); httpReq.setContent(cb); Does not yield a valid request. What is the correct way to send a post request preferably by constructing the parameters data manually as opposed to with the DataFactory. Also why is HttpDataFactory not included in any of the releases? You wrote everything correct just add httpReq.setHeader(HttpHeaders.Names.CONTENT_TYPE""application/x-www-form-urlencoded""); and your example will work. For more complex code you need to add url encoding."
724,A,"Is there any point in using Netty with Disruptor performance-wise? I am building a simple reactive server which should consume incoming protobuf/protostuff messages from multiple clients execute some business logic on them and possibly send fire-and-forget messages to other consumers. I want to implement transport and decoding part in Netty. My question is: is there any point on publishing decoded messages to the Disruptor's ring buffer performance-wise or the extra performance offered by Disruptor would be negated by internal Netty scheduling? Should I provide Netty with two threads (one for ""accept"" and other for ""connect"" group) or just one is better? Maybe I should just split messages by length field in Netty's handlers and execute decoding in Disruptor's ones? Depends ;) The disruptor allows you to decouple various different actions and potentially perform them in parallel. So the question is how expensive is your business logic and how bursty is your workload? The Disruptor is used to transfer data between threads specifically threads which are potentially running at different message rates. I.e. it allows the producing thread to produce a burst of messages while the consuming thread is busy handling the last message. For instance if you also wanted to persist your message to database as well as sending the result onwards you could publish the message to a ""outbound"" ringbuffer and have your netty code consume from that as well as a DB persister. The less time you spend doing things in Netty's eventloop the more clients you can cope with or larger messages volumes at the transport level. Thanks! It seems Disruptor would fit there since handling message bursts and journalizing are important part."
725,A,"Netty + ProtoBuffer: A few communication messages for one connection While reading the Netty tutorial I've found a simple description of how to integrate Netty and Google Protocol Buffers. I've started to investigate its example (because there is no more information in the documentation) and written a simple application like the example local time application. But this example is using static initialization in PipeFactory Class e.g.: import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.handler.codec.protobuf.ProtobufDecoder; import org.jboss.netty.handler.codec.protobuf.ProtobufEncoder; import org.jboss.netty.handler.codec.protobuf.ProtobufVarint32FrameDecoder; import org.jboss.netty.handler.codec.protobuf.ProtobufVarint32LengthFieldPrepender; import static org.jboss.netty.channel.Channels.pipeline; /** * @author sergiizagriichuk */ class ProtoCommunicationClientPipeFactory implements ChannelPipelineFactory { public ChannelPipeline getPipeline() throws Exception { ChannelPipeline p = pipeline(); p.addLast(""frameDecoder"" new ProtobufVarint32FrameDecoder()); p.addLast(""protobufDecoder"" new ProtobufDecoder(Communication.DataMessage.getDefaultInstance())); p.addLast(""frameEncoder"" new ProtobufVarint32LengthFieldPrepender()); p.addLast(""protobufEncoder"" new ProtobufEncoder()); p.addLast(""handler"" new ProtoCommunicationClientHandler()); return p; } } (Please take a look at line p.addLast(""protobufDecoder"" new ProtobufDecoder(Communication.DataMessage.getDefaultInstance()));) and just one factory can be created (as I understand) for ClientBootstrap class I mean bootstrap.setPipelineFactory() method. So in this situation I can use ONE message to send to server and ONE message to receive from server and it is bad for me and I think not just for me :( How can I use different messages to and from for just one connection? Perhaps I can create a few protobufDecoder like this p.addLast(""protobufDecoder"" new ProtobufDecoder(Communication.DataMessage.getDefaultInstance())); p.addLast(""protobufDecoder"" new ProtobufDecoder(Communication.TestMessage.getDefaultInstance())); p.addLast(""protobufDecoder"" new ProtobufDecoder(Communication.SrcMessage.getDefaultInstance())); or other techniques? Thanks a lot. You can add many decoders/encoders in pipeline but they should be able to pass data that they don't know how to handle. Looking at the [netty source at github](https://github.com/netty/netty/blob/master/src/main/java/org/jboss/netty/handler/codec/protobuf/ProtobufDecoder.java) It seems it is not the case. So there is probably a way to do it but I'm skeptical it s as simple. Try anyway and share results :) @Slartibartfast Yes It is not simple and wants hard work :( the problem is that there is no way to distinct two different protobuf messages from each other in binary format. But there is a way to solve it within the protobuf file: message AnyMessage { message DataMessage { [...] } optional DataMessage dataMessage = 1; message TestMessage { [...] } optional TestMessage testMessage = 2; message SrcMessage { [...] } optional SrcMessage srcMessage = 3; } optional fields that are not set produce no overhead. Additionally you can add an Enum but it is just a bonus.  If you are going to write your own codecs anyway you might want to look at implementing the Externalizable interface for custom data objects. Serializable is low-effort but worst performance (serializes everything). Protobuf is a good trade-off between effort and performance (requires .proto maintenance) Externalizable is high effort but best performance (custom minimal codecs) If you already know your project will have to scale like a mountain goat you may have to go the hard road. Protobuf is not a silver bullet.  The issue is not quite a Netty limitation or encoder/decoder limitation. The problem is that Google Protocol Buffers are offering just a way to serialize/deserialize objects but is not provide a protocol. They have some kind of RPC implementation as part of standard distribution but if you'll try to implement their RPC protocol then you'll end up with 3 layers of indirection. What I have done in one of the project was to define a message that is basically an union of messages. This message contains one field that is Type and another field that is the actual message. You'll still end-up with 2 indirection layers but not 3. In this way the example from Netty will work for you but as was mention in a previous post you have to put more logic in the business logic handler.  I've found thread of author of netty in google groups and understood that I have to change my architecture or write my own decoder as I wrote above So Start to think what way will be easy and better. I think the point of that groups thread is that if you want to send multiple types of messages a solution would be to define 1 general purpose ""message container"" (let's say `ProtocolMessage`) in protobuf that will contain 1 or more different types of messages. You would then use the protobuf decoder for the `ProtocolMessage` message type and leave any further interpretation to you message handler in Netty. Yes I've understood thanks.  Theoretically this can be done by modifying the pipeline for each incoming message to suit the incoming message. Take a look at the port unification example in Netty. Sequence would be: 1) In frame decoder or another ""DecoderMappingDecoder"" you check the message type of the incoming message 2) Modify the pipeline dynamically as shown in the example But why not use different connections and follow this sequence: 1) Add other decoders in pipeline based on the incoming message only once. 2) Add the same instance of channel upstream handler as the last handler in the pipeline this way all messages get routed to the same instance which is almost like having a single connection. Theoretically we should modify decoder to read some id from bytestream and select correct algorithm to decoding I thout about this solution but It is not simply or good way to do it. Why I want to open just a one connection because I want to set up my client and prepare connection to the server and use this (just a one) connection to send ALL messages to server messages like operations and current architectural provide me possibility to create a lot of clients for each operation I think it is not good IDEA! If you have n message types and n different ways to decode then you can still use the same connection which has a single ""MappingDecoder"" which will check the type of message and pass it on to the correct decoder to decode. Take a look at netty embedded decoder(http://grepcode.com/file/repository.jboss.org/maven2/org.jboss.netty/netty/3.1.4.GA/org/jboss/netty/handler/codec/embedder/DecoderEmbedder.java) which may offer you a way to use decoder without using a pipeline.  You can use message tunneling to send various types of messages as payload in a single message. Hope that helps"
726,A,"AKKA remote (with SSL) can't find keystore/truststore files on classpath I'm trying to configure AKKA SSL connection to use my keystore and trustore files and I want it to be able to find them on a classpath. I tried to set application.conf to: ... remote.netty.ssl = { enable = on key-store = ""keystore"" key-store-password = ""passwd"" trust-store = ""truststore"" trust-store-password = ""passwd"" protocol = ""TLSv1"" random-number-generator = ""AES128CounterSecureRNG"" enabled-algorithms = [""TLS_RSA_WITH_AES_128_CBC_SHA""] } ... This works fine if keystore and trustore files are in the current directory. In my application these files get packaged into WAR and JAR archives and because of that I'd like to read them from the classpath. I tried to use getResource(""keystore"") in application.conf as described here without any luck. Config reads it literally as a string. I also tried to parse String conf and force it to read the value: val conf: Config = ConfigFactory parseString (s"""""" ... ""${getClass.getClassLoader.getResource(""keystore"").getPath}"" ..."""""") In this case it finds proper path on the classpath as file://some_dir/target/scala-2.10/server_2.10-1.1-one-jar.jar!/main/server_2.10-1.1.jar!/keystore which is exactly where it's located (in the jar). However underlying Netty SSL transport can't find the file given this path and I get: Oct 03 2013 1:02:48 PM org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink WARNING: Failed to initialize an accepted socket. 45a13eb9-6cb1-46a7-a789-e48da9997f0fakka.remote.RemoteTransportException: Server SSL connection could not be established because key store could not be loaded at akka.remote.netty.NettySSLSupport$.constructServerContext$1(NettySSLSupport.scala:113) at akka.remote.netty.NettySSLSupport$.initializeServerSSL(NettySSLSupport.scala:130) at akka.remote.netty.NettySSLSupport$.apply(NettySSLSupport.scala:27) at akka.remote.netty.NettyRemoteTransport$PipelineFactory$.defaultStack(NettyRemoteSupport.scala:74) at akka.remote.netty.NettyRemoteTransport$PipelineFactory$$anon$1.getPipeline(NettyRemoteSupport.scala:67) at akka.remote.netty.NettyRemoteTransport$PipelineFactory$$anon$1.getPipeline(NettyRemoteSupport.scala:67) at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink$Boss.registerAcceptedChannel(NioServerSocketPipelineSink.java:277) at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink$Boss.run(NioServerSocketPipelineSink.java:242) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:724) Caused by: java.io.FileNotFoundException: file:/some_dir/server/target/scala-2.10/server_2.10-1.1-one-jar.jar!/main/server_2.10-1.1.jar!/keystore (No such file or directory) at java.io.FileInputStream.open(Native Method) at java.io.FileInputStream.<init>(FileInputStream.java:138) at java.io.FileInputStream.<init>(FileInputStream.java:97) at akka.remote.netty.NettySSLSupport$.constructServerContext$1(NettySSLSupport.scala:118) ... 10 more I wonder if there is any way to configure this in AKKA without implementing custom SSL transport. Maybe I should configure Netty in the code? Obviously I can hardcode the path or read it from an environment variable but I would prefer a more flexible classpath solution. I decided to look at the akka.remote.netty.NettySSLSupport at the code where exception is thrown from and here is the code:  def initializeServerSSL(settings: NettySettings log: LoggingAdapter): SslHandler = { log.debug(""Server SSL is enabled initialising ..."") def constructServerContext(settings: NettySettings log: LoggingAdapter keyStorePath: String keyStorePassword: String protocol: String): Option[SSLContext] = try { val rng = initializeCustomSecureRandom(settings.SSLRandomNumberGenerator settings.SSLRandomSource log) val factory = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm) factory.init({ val keyStore = KeyStore.getInstance(KeyStore.getDefaultType) val fin = new FileInputStream(keyStorePath) try keyStore.load(fin keyStorePassword.toCharArray) finally fin.close() keyStore } keyStorePassword.toCharArray) Option(SSLContext.getInstance(protocol)) map { ctx ⇒ ctx.init(factory.getKeyManagers null rng); ctx } } catch { case e: FileNotFoundException ⇒ throw new RemoteTransportException(""Server SSL connection could not be established because key store could not be loaded"" e) case e: IOException ⇒ throw new RemoteTransportException(""Server SSL connection could not be established because: "" + e.getMessage e) case e: GeneralSecurityException ⇒ throw new RemoteTransportException(""Server SSL connection could not be established because SSL context could not be constructed"" e) } It looks like it must be a plain filename (String) because that's what FileInputStream takes. Any suggestions would be welcome! At the time of writing this question there was no way to do it AFAIK. I'm closing this question but I welcome updates if new versions provide such functionality or if there are other ways to do that."
727,A,"netty4:How to listen on multiple ports on a java process I'm trying to listen for connections on two different ports I start 2 Thread in a java main methodevery Thread bind a port with netty4but can't listener success! this is my codethe port 3333 is okbut 1234 is not okit looks like 3333 is blocking!  public class ObjectServer { private static final Logger logger = LoggerFactory.getLogger(ObjectServer.class); private String ip; private int port; public ObjectServer(int port) { this.port = port; } public void run(final ChannelInboundHandlerAdapter handler) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap server = new ServerBootstrap(); server.group(bossGroup workerGroup).channel(NioServerSocketChannel.class).childHandler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new ObjectEncoder() new ObjectDecoder(ClassResolvers.cacheDisabled(null)) handler); } }); server.bind(port).sync().channel().closeFuture().sync(); } catch (Exception e) { logger.error(""开启监听失败！端口["" + port + ""]"" e); throw e; } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } }  public class SocketServer { private static final Logger logger = LoggerFactory.getLogger(SocketServer.class); private static final StringDecoder DECODER = new StringDecoder(); private static final StringEncoder ENCODER = new StringEncoder(); private int port; public SocketServer(int port) { this.port = port; } public void run(final ChannelInboundHandlerAdapter handler) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup).channel(NioServerSocketChannel.class).childHandler(new ChannelInitializer<SocketChannel>() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); // Add the text line codec combination first pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); // the encoder and decoder are static as these are // sharable pipeline.addLast(""encoder"" ENCODER); pipeline.addLast(""decoder"" DECODER); // and then business logic. pipeline.addLast(""handler"" handler); } }); b.bind(port).sync().channel().closeFuture().sync(); } catch (Exception e) { logger.error(""开启监听失败！端口["" + port + ""]"" e); throw e; } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } }  public class Test { public static void main(String[] args) throws Exception { Thread1 thread1 = new Thread1(); Thread2 thread2 = new Thread2(); thread2.start(); thread1.start(); new SocketClient(""192.168.16.52"" 3333).run(new TestHandler4(""test4"")); new ObjectClient(""192.168.16.52"" 1234).run(new TestHandler3(""test3"")); } @Sharable static class TestHandler1 extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx Object msg) throws Exception { System.out.println(""1234"" + msg); } } static class Thread1 extends Thread { @Override public void run() { try { new ObjectServer(1234).run(new TestHandler1()); } catch (Exception e) { e.printStackTrace(); } } } static class Thread2 extends Thread { @Override public void run() { try { new SocketServer(3333).run(new TestHandler2()); } catch (Exception e) { e.printStackTrace(); } } } @Sharable static class TestHandler2 extends SimpleChannelInboundHandler<String> { @Override public void channelRead0(ChannelHandlerContext ctx String msg) throws Exception { System.out.println(""3333"" + msg); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(""sssssssssssssssss""); } } @Sharable static class TestHandler3 extends ChannelInboundHandlerAdapter { private String msg; public TestHandler3(String msg) { this.msg = msg; } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.writeAndFlush(msg); } } @Sharable static class TestHandler4 extends SimpleChannelInboundHandler<String> { private String msg; public TestHandler4(String msg) { this.msg = msg; } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.writeAndFlush(msg); } @Override protected void channelRead0(ChannelHandlerContext arg0 String arg1)throws Exception { } } } thanks!my code is uploaded! what have you tried so far? Need your code. In your run() implementation you do this: server.bind(port).sync().channel().closeFuture().sync(); .. which will block until the server socket is closed. Because you do not close the server socket it will never return. Therefore only the first server socket will be bound. What you probably want is just bind and return rather than waiting for the server sockets closed. I bind different ports in different threadsWhy call the method when the first thread blocked it will affect the second thread.I just want a main method using two threads to listen different port.How to let two ports are listening and are blocked. Can you help me? Thank you very much！！"
728,A,"Netty: What is the right way to share NioClientSocketChannelFactory among multiple Netty Clients I am new to Netty. I am using “Netty 3.6.2.Final”. I have created a Netty Client (MyClient) that talks to a remote server (The server implements a custom protocol based on TCP). I create a new ClientBootstrap instance for each MyClient instance (within the constructor). My question is if I share “NioClientSocketChannelFactory” factory object among all the instances of MyClient then when/how do I release all the resources associated with the “NioClientSocketChannelFactory”? In other words since my Netty Client runs inside a JBOSS container running 24x7 should I release all resources by calling “bootstrap.releaseExternalResources();” and when/where should I do so? More Info: My Netty Client is called from two scenarios inside a JBOSS container. First in an infinite for loop with each time passing the string that needs to be sent to the remote server (in effect similar to below code) for( ; ; ){ //Prepare the stringToSend //Send a string and receive a string String returnedString=new MyClient().handle(stringToSend); } Another scenarios is my Netty Client is called within concurrent threads with each thread calling “new MyClient().handle(stringToSend);”. I have given the skeleton code below. It is very similar to the TelnetClient example at Netty website. MyClient import org.jboss.netty.bootstrap.ClientBootstrap; import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory; public class MyClient { //Instantiate this only once per application private final static Timer timer = new HashedWheelTimer(); //All below must come from configuration private final String host =""127.0.0.1""; private final int port =9699; private final InetSocketAddress address = new InetSocketAddress(host port); private ClientBootstrap bootstrap; //Timeout when the server sends nothing for n seconds. static final int READ_TIMEOUT = 5; public MyClient(){ bootstrap = new ClientBootstrap(NioClientSocketFactorySingleton.getInstance()); } public String handle(String messageToSend){ bootstrap.setOption(""connectTimeoutMillis"" 20000); bootstrap.setOption(""tcpNoDelay"" true); bootstrap.setOption(""keepAlive"" true); bootstrap.setOption(""remoteAddress"" address); bootstrap.setPipelineFactory(new MyClientPipelineFactory(messageToSendbootstraptimer)); // Start the connection attempt. ChannelFuture future = bootstrap.connect(); // Wait until the connection attempt succeeds or fails. channel = future.awaitUninterruptibly().getChannel(); if (!future.isSuccess()) { return null; } // Wait until the connection is closed or the connection attempt fails. channel.getCloseFuture().awaitUninterruptibly(); MyClientHandler myClientHandler=(MyClientHandler)channel.getPipeline().getLast(); String messageReceived=myClientHandler.getMessageReceived(); return messageReceived; } } Singleton NioClientSocketChannelFactory public class NioClientSocketFactorySingleton { private static NioClientSocketChannelFactory nioClientSocketChannelFactory; private NioClientSocketFactorySingleton() { } public static synchronized NioClientSocketChannelFactory getInstance() { if ( nioClientSocketChannelFactory == null) { nioClientSocketChannelFactory=new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); } return nioClientSocketChannelFactory; } protected void finalize() throws Throwable { try{ if(nioClientSocketChannelFactory!=null){ // Shut down thread pools to exit. nioClientSocketChannelFactory.releaseExternalResources(); } }catch(Exception e){ //Can't do anything much } } } MyClientPipelineFactory public class MyClientPipelineFactory implements ChannelPipelineFactory { private String messageToSend; private ClientBootstrap bootstrap; private Timer timer; public MyClientPipelineFactory(){ } public MyClientPipelineFactory(String messageToSend){ this.messageToSend=messageToSend; } public MyClientPipelineFactory(String messageToSendClientBootstrap bootstrap Timer timer){ this.messageToSend=messageToSend; this.bootstrap=bootstrap; this.timer=timer; } public ChannelPipeline getPipeline() throws Exception { // Create a default pipeline implementation. ChannelPipeline pipeline = pipeline(); // Add the text line codec combination first //pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); //Add readtimeout pipeline.addLast(""timeout"" new ReadTimeoutHandler(timer MyClient.READ_TIMEOUT)); // and then business logic. pipeline.addLast(""handler"" new MyClientHandler(messageToSendbootstrap)); return pipeline; } } MyClientHandler public class MyClientHandler extends SimpleChannelUpstreamHandler { private String messageToSend=""""; private String messageReceived=""""; public MyClientHandler(String messageToSendClientBootstrap bootstrap) { this.messageToSend=messageToSend; this.bootstrap=bootstrap; } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e){ e.getChannel().write(messageToSend); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e){ messageReceived=e.getMessage().toString(); //This take the control back to the MyClient e.getChannel().close(); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { // Close the connection when an exception is raised. e.getChannel().close(); } } You should only call releaseExternalResources() once you are sure you not need it anymore. This may be for example when the application gets stopped or undeployed."
729,A,missing EOF from HTTP stream without Transfer-Encoding chunked I am streaming content over HTTP with Netty 4. The content is generated dynamically so there is no way to know the content length ahead of time. My existing non-netty code writes to an OutputStream so I wrote a simple wrapper around an OutputStream that takes the writes and puts them in a ByteBuf and when that's full it writes it as the payload of DefaultHttpContent. Prior to any writes to the OutputStream I send a non-full HttpResponse w/ an OK status code. When the close is called on the stream i send whatever is in the local ByteBuf that has not been sent and then LastHttpContent.EMPTY_LAST_CONTENT. What I see with wget is that it gets all the bytes but then sits and waits for the end of the stream. If I put the Transfer-Encoding: Chunked header in the initial response things work perfectly. I can see some differences in the handling of the LastHttpContent message in HttpObjectEncoder which is what clued me in about trying the chunked transfer header. What I'm unclear about is what the difference is and why the EOF seems to not be sent w/o the header even though all the bytes are sent and I'm sending LastHttpContent.EMPTY_LAST_CONTENT EDIT: I am able to reproduce this behavior via a simple modification to HttpStaticFileServerHandler in the Netty 4 examples. I am using this class to send the file back to the client this (requires Guava) is my modified channelRead0 method from HttpStaticFileServerHandler which instead of setting the content length & writing the file directly to the channel it copies the File to the channel via ByteBuffHttpOutputStream which sends 1 MB chunks of output via DefaultHttpContent and on close sends a LastHttpContent.EMPTY_LAST_CONTENT. If I remove the setting of the Transfer-Encoding header: (response.headers().set(Names.TRANSFER_ENCODING Values.CHUNKED)) then using wget to grab the file never completes. afaict I'm sending the stream correctly and it looks like HttpObjectEncoder should be handling the LastHttpContent correctly but yet no EOF. I think this was just fixed in master and will be part of 4.0.9.Final https://github.com/netty/netty/pull/1787 I think you need to close the channel after the LastHttpContent was written as you no set any content-length. That does not seem to fix it see my edited question. I suspect that will work but doesn't that completely defeat the client asking for a keep-alive connection? So keep-alive and streaming content back to a client are mutually exclusive? Unless you specify the Content-Length and do not use chunked encoding the only way to know the end of the content is the end of the connection.
730,A,Is it worthy to migrate quickfixj from Mina to Netty? I am writing a FIX buyside GUI based on quickfixj. Although the performance is not an issue to a GUI I am thinking of migrating the quickfixj from Mina to Netty as I would like to develop it to a buyside engine. The performance of quickfixj is not satisfied with me. It is heard that Netty is better than Mina on performance. Does anyone know is there any other opensource FIX engine on Java platform(because of many bugs in quickfixj)?I am wondering which one is a better choice migration or another FIX engine? I am not sure how much perfomance gain you are expecting from implementing Netty rather than Mina in QuickfixJ. Sometimes we need to look at ease of adaption and maintainability rather than only perfomance. I implemented a fix engine using both quickfix and quickfixJ the Java version was more complex in term of more messages being supported. Well the perfomance was more than was expected went through around more than 300 messages/sec. Regarding the QuickfixJ being buggy yes it is but you have the source code you can modify it as you want. I don't know of any other open source Java fix engine. And Quickfix is supported by vendors if you intend to buy it they would be there to support any bugs in Quickfix. I would prefer you modify it I modified quite a lot of it to customize it for my use. If you have the resources there are lot of vendors who provide fix engines Cameron and Swift. Yes DC I've been modifying quickfixj. I have applied a lot change to quickfixj v4 but found it's hard to apply the changes to the new version after quickfixj v5 is released. I even don't know which files are greatly different from the old version. It seems I have to stay in v4. About the commercial FIX engine my company is using Appia. Do you know the adv of Cameron and Swift to Appia? Thank you for your information DC. I just do the modification when I need some feature or meet some issue. @user462872 - To check the differences you can checkout their source code in svn and do a diff. I used it quite a lot. (http://www.fixprotocol.org/products/) - List of vendors who supply fix engines. Object Computing supports Quickfix so you can get professional help if you aren't able to modify Quickfix. It is very difficult to compare 2 producs unless you have used both of them. Best option is to google it.
731,A,"Using scala continuations with netty/NIO listeners I'm using the Netty library (version 4 from GitHub). It works great in Scala but I am hoping for my library to be able to use continuation passing style for the asynchronous waiting. Traditionally with Netty you would do something like this (an example asynchronous connect operation): //client is a ClientBootstrap val future:ChannelFuture = client.connect(remoteAddr); future.addListener(new ChannelFutureListener { def operationComplete (f:ChannelFuture) = { //here goes the code that happens when the connection is made } }) If you are implementing a library (which I am) then you basically have three simple options to allow the user of the library to do stuff after the connection is made: Just return the ChannelFuture from your connect method and let the user deal with it - this doesn't provide much abstraction from netty. Take a ChannelFutureListener as a parameter of your connect method and add it as a listener to the ChannelFuture. Take a callback function object as a parameter of your connect method and call that from within the ChannelFutureListener that you create (this would make for a callback-driven style somewhat like node.js) What I am trying to do is a fourth option; I didn't include it in the count above because it is not simple. I want to use scala delimited continuations to make the use of the library be somewhat like a blocking library but it will be nonblocking behind the scenes: class MyLibraryClient { def connect(remoteAddr:SocketAddress) = { shift { retrn: (Unit => Unit) => { val future:ChannelFuture = client.connect(remoteAddr); future.addListener(new ChannelFutureListener { def operationComplete(f:ChannelFuture) = { retrn(); } }); } } } } Imagine other read/write operations being implemented in the same fashion. The goal of this being that the user's code can look more like this: reset { val conn = new MyLibraryClient(); conn.connect(new InetSocketAddress(""127.0.0.1"" 1337)); println(""This will happen after the connection is finished""); } In other words the program will look like a simple blocking-style program but behind the scenes there won't be any blocking or threading. The trouble I'm running into is that I don't fully understand how the typing of delimited continuations work. When I try to implement it in the above way the compiler complains that my operationComplete implementation actually returns Unit @scala.util.continuations.cpsParam[UnitUnit => Unit] instead of Unit. I get that there is sort of a ""gotcha"" in scala's CPS in that you must annotate a shift method's return type with @suspendable which gets passed up the call stack until the reset but there doesn't seem to be any way to reconcile that with a pre-existing Java library that has no concept of delimited continuations. I feel like there really must be a way around this - if Swarm can serialize continuations and jam them over the network to be computed elsewhere then it must be possible to simply call a continuation from a pre-existing Java class. But I can't figure out how it can be done. Would I have to rewrite entire parts of netty in Scala in order to make this happen? I don't know howto fix the scala stuff but I suggest against your idea. Let me tell you why. But making the user ""unaware"" of the async nature of your libary you will tell him thats its ok todo ""blocking"" calls in the listener code. In fact he would not know that he even write his code in a listener. Doing a blocking call in a listener can lead to all kind of problems. The Problem which you will see most of the times is that it ""slow"" down other io-tasks and so limit the troughput. You have a good point but I disagree. I think that the user of my library if there even are any besides me will probably have to understand what `reset` does to begin with and thus will understand that the calls are non-blocking. This is really just a way to A) get a deeper understanding of delimited continuations and B) experiment with writing essentially callback-driven code in a cleaner way. I found this explanation of Scala's continuations extremely helpful when I started out. In particular pay attention to the parts where he explains shift[A B C] and reset[B C]. Adding a dummy null as the last statement of operationComplete should help. Btw you need to invoke retrn() inside another reset if it may have a shift nested inside it. Edit: Here is a working example import scala.util.continuations._ import java.util.concurrent.Executors object Test { val execService = Executors.newFixedThreadPool(2) def main(args: Array[String]): Unit = { reset { val conn = new MyLibraryClient(); conn.connect(""127.0.0.1""); println(""This will happen after the connection is finished""); } println(""Outside reset""); } } class ChannelFuture { def addListener(listener: ChannelFutureListener): Unit = { val future = this Test.execService.submit(new Runnable { def run(): Unit = { listener.operationComplete(future) } }) } } trait ChannelFutureListener { def operationComplete(f: ChannelFuture): Unit } class MyLibraryClient { def connect(remoteAddr: String): Unit@cps[Unit] = { shift { retrn: (Unit => Unit) => { val future: ChannelFuture = new ChannelFuture() future.addListener(new ChannelFutureListener { def operationComplete(f: ChannelFuture): Unit = { println(""operationComplete starts"") retrn(); null } }); } } } } with a possible output: Outside reset operationComplete starts This will happen after the connection is finished @Jeremy yeah that article is very good :) This in fact does make the compiler happy and even seems to work properly. The key I guess is that you moved the `shift` outside the anonymous `ChannelFutureListener` and used closure to call the continuation from inside `operationComplete`. I'm not sure I understand why this works and the other way doesn't but I'll take it. Thanks! @Jeremy btw the difference between your code and mine is that I explicitly annotated the return types of some of the methods. And that is a very good read about scala's continuations. They should remove the worthless examples from the scala-lang.org page about continuations and replace them with the article you linked. I know that my code looks almost just like yours in what I posted. But for some reason that's not what I had in my real code. I had the `shift` block misplaced inside the implementation of `operationComplete` which was causing the compiler error. I hadn't realized that I could put `shift` outside and use closure to call it. Even though I mistakenly wrote it correctly in my question :)"
732,A,Netty 4: high and low write watermarks I am working with Netty 4. I see folowing options of Netty server: WRITE_BUFFER_HIGH_WATER_MARK and WRITE_BUFFER_LOW_WATER_MARK. The official page Related articles has link to Netty best practices (slides w/ video) by Norman Maurer. One of slides looks like this: ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.childOption(ChannelOption.WRITE_BUFFER_HIGH_WATER_MARK 32 * 1024); bootstrap.childOption(ChannelOption.WRITE_BUFFER_LOW_WATER_MARK 8 * 1024); and has this preface: Set sane WRITE_BUFFER_HIGH_WATER_MARK and WRITE_BUFFER_LOW_WATER_MARK But what is it WRITE_BUFFER_HIGH_WATER_MARK and WRITE_BUFFER_LOW_WATER_MARK? And how to set them to be sane? I did not find any clear information. Thanks for your help. Some information about watermarks from this article: For instance imagine you have a queue of tasks on server side that is filled by clients and processed by backend. In case clients send tasks too quick the length of the queue grows. One needs to introduce so named high watermark and low watermark. If queue length is greater than high watermark stop reading from sockets and queue length will decrease. When queue length becomes less than low watermark start reading tasks from sockets again. Note to make it possible for clients to adapt to speed you process tasks (actually to adapt window size) one shouldn't make a big gap between high and low watermarks. From the other side small gap means you'll be too often add/remove sockets from the event loop. For Netty it seams to be true because this JavaDoc for ChannelConfig says: If the number of bytes queued in the write buffer exceeds writeBufferHighWaterMark value Channel.isWritable() will start to return false. And for low watermark: Once the number of bytes queued in the write buffer exceeded the high water mark and then dropped down below this value Channel.isWritable() will return true again. About sanity I think it is relative question that depends on information that you are sending through the channel and how often. There is no strict rules for what values you must define for that variables. So I think you must found your own values in practice. Slides show you one of the examples for that. Thanks for your time and help! Спасибо Михаил. Вы мне действительно значительно прояснили данный вопрос. It's my pleasure. Не за что :)
733,A,Does Netty concurrently modify passed ChannelBuffers In Netty does anyone know if the ChannelBuffer passed to a handler for an upstream event (after you cast it from ChannelEvent / or MessageEvent) will be concurrently written to by the Netty framework while you process it? The user guide and examples do not explicitly clarify whether this will happen or not. For example imagine the method below in a class that extends SimpleChannelHandler and is bound as the handler on a netty server: @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { ChannelBuffer buffer = (ChannelBuffer) e.getMessage(); if (buffer.readableBytes() == 4) { // Is it possible for the number of readable bytes to increase here? } } In the above method is it possible for the number of readable bytes to increase on the commented line (assuming the client is still sending data) or will those frames be guaranteed to be separate messages and not written into the supplied buffer? The reason I ask is to know whether or not I should copy the buffer to a local one before doing some of my processing or whether such a copy is superfluous. Once Netty creates a ChannelBuffer and triggers a MessageEvent with it it's out of Netty's hands and thus Netty does not modify it by any means. The handlers or other user code can modify the buffer but usually well written handlers do not interfere with other handlers. If a bad handler keeps the reference to the received buffer and modifies later then you will see broken buffer state though. Thanks Trustin! I assumed / hoped that was the behaviour just wanted to make sure so that I did not run into any strange bugs.
734,A,[Netty 4 CR2]Got exception when closing channel by using user-defined encoder and decoder I am replacing Netty3 with Netty4 in my project. I am using Google-protocol-buffer as data transfer. I got an exception when closing channel which works fine in Netty3. Bellowed is the exception details: io.netty.handler.codec.DecoderException: java.lang.IndexOutOfBoundsException: readerIndex(0) + length(4) exceeds writerIndex(0): PooledUnsafeDirectByteBuf(ridx: 0 widx: 0 cap: 4096) at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:95) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelInactive(DefaultChannelHandlerContext.java:801) at io.netty.channel.DefaultChannelHandlerContext.fireChannelInactive(DefaultChannelHandlerContext.java:787) at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:808) at io.netty.channel.AbstractChannel$AbstractUnsafe$9.run(AbstractChannel.java:725) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:364) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:326) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:114) at java.lang.Thread.run(Unknown Source) Caused by: java.lang.IndexOutOfBoundsException: readerIndex(0) + length(4) exceeds writerIndex(0): PooledUnsafeDirectByteBuf(ridx: 0 widx: 0 cap: 4096) at io.netty.buffer.AbstractByteBuf.checkReadableBytes(AbstractByteBuf.java:1120) at io.netty.buffer.AbstractByteBuf.readInt(AbstractByteBuf.java:627) at com.fhq.mathematica.netty.MMADecoder.decode(MMADecoder.java:17) at io.netty.handler.codec.ByteToMessageDecoder.decodeLast(ByteToMessageDecoder.java:168) at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:91) Here's the encoder:(Message is the interface of protocol-buffer in top level.) public class MessageEncoder extends MessageToByteEncoder<Message>{ @Override protected void encode(ChannelHandlerContext ctx Message msg ByteBuf out) throws Exception { byte[] data = msg.toByteArray(); out.writeInt(data.length); out.writeBytes(data); } } Here's the decoder: public class MMADecoder extends ByteToMessageDecoder{ @Override protected void decode(ChannelHandlerContext ctx ByteBuf in MessageBuf<Object> out) throws Exception { in.markReaderIndex(); int dataLength = in.readInt(); if (in.readableBytes() < dataLength) { in.resetReaderIndex(); return; } byte[] decoded = new byte[dataLength]; in.readBytes(decoded); out.add(MathematicaTask.parseFrom(decoded)); } } When I just transfer MathematicaTask object it's working fine(both client and server parse message correctly). But when I close the channel there will be an exception in decoder. int dataLength = in.readInt(); Could anyone figure out the problem ? Mush appreciated! BTW : I tried ObjectEncoder and ObjectDecoder then everything is fine. So there must be some problem in my decoder/encoder. You need to check if there are enough bytes to read before call ByteBuf.readInt(). So something like this: public class MMADecoder extends ByteToMessageDecoder{ @Override protected void decode(ChannelHandlerContext ctx ByteBuf in MessageBuf<Object> out) throws Exception { if (in.readableBytes < 4) { return; } in.markReaderIndex(); int dataLength = in.readInt(); if (in.readableBytes() < dataLength) { in.resetReaderIndex(); return; } byte[] decoded = new byte[dataLength]; in.readBytes(decoded); out.add(MathematicaTask.parseFrom(decoded)); } } Thanks! it works! but why we have to compare readable bytes with 4? Because an int is 4 bytes long... I see.. Many thanks! Could you please take look at this question if you have time? Much appraciated. [link]http://stackoverflow.com/questions/19394898/how-could-i-display-the-asynchronous-result-in-html-page-through-a-http-request
735,A,"Delay channel read in Netty 4 Is there a way to tell netty 4 to stop reading from a channel until it's reenabled? I want clients to send me their credentials followed by some data. For the ease of this protocol I don't want to have the clients to wait for an OK or ERROR until they can send their data. Maybe there is a DelayHandler or something like that'll just put all received buffers into a queue but I could not find something like that. Since the verification is not done instantaneously I would have to block the network thread which - of course - is a bad idea. Use the AUTO_READ ChannelOption which allows you to control when you read data. E.g. https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/proxy/HexDumpProxy.java Exactly what I was looking for. Thanks  One way that may suit your purpose is to use a ReplayingDecoder: each time a chunk of input comes in you will be presented with it and each time you'll have the option to say ""no that's not enough input; when more input comes in ask me again."" The whole input will accumulate and will be replayed to you for maximum convenience. Its not that I would really need more data. It's just that I can't handle the incoming data until I have authenticated the client. Sure a ReplayDecoder could do this but that's not what it is intended for and I might not even receive any data after the authentication check."
736,A,"Netty - Delimiting ZLib encoded data Is it necessary to use a delimiter such as LengthFieldBasedFrameDecoder with Netty's ZlibDecoders? I had an issue where the decoder would sometimes error with ""unknown compression method"" this went away when I modified the pipeline to delimit the data. The javadocs for the Zlib encoder/decoder don't mention this as required though their super classes do. No you should not need it.. In fact the ZlibDecoder/ZlibEncoder is usually placed in ""front"" of such handlers.  It depends on transport protocol and how the compression is applied to the message/frame If compression is applied only for the content part like below (like http) you don't need LengthFieldBasedFrameDecoder because your decoder/encoder have to use an DecoderEmbedder/EncoderEmbedder with ZlibDecoder/ZlibEncoder internally.  +-----+---------------+ | | | | HDR | Content | | | | +-----+---------------+ If the compression is applied to to whole frame and transport protocol is TCP then zipped frame should have header parameter to identify the message length to read it fully. So you will need a LengthFieldBasedFrameDecoder and LengthFieldPrepender in the pipeline  +---------------------+ +------+-------------+ | | | | | | Frame | <=> |Length| Zipped Frame| | | | | | +---------------------+ +------+-------------+"
737,A,"Reading JSON data in netty server This may be a ""newb"" question but here it goes anyway. I am sending JSON data from netty client to netty server. But the problem i am facing is netty server is not able to access/read JSON data. In order to access JSON data in server i need a encoder/decoder. I am confused as to how to write this encoder/decoder ? Anyone have any helpful ideas? In this case I used JSON-Simple toolkit. I actually need a encoder/decoder at server and client level in netty. Toolkit you specified is for java. Netty is sending data in ByteBuf format JSON-Simple would encode/decode Java object not ByteBuf.  Use JSON-Simple or GSON for serialization Then write back to the client with this : String jsonPayload = ...; ByteBuf buffer = Unpooled.copiedBuffer(jsonPayload CharsetUtil.UTF_8)); ctx.write(buffer); If it's an HTTP server don't forget to wrap your buffer in a DefaultHttpContent ! ctx.write(new DefaultHttpContent(buffer)); For inspiration look the following examples : HttpHelloWorldServerHandler.java HttpSnoopServerHandler EDIT : If you need to read the jsonPayload from your request you could to this : String jsonPayload = bytebuf.content().toString(CharsetUtil.UTF_8)"
738,A,"How do I decode the response from an http request and use the content in netty? This is related to this question but I'm trying to break my problem into smaller steps. I'm trying to write a simple http server (server A) using netty that receives an http request makes an http request to another server (server B) and then copies the content in the response into the response to the initial request. I know there are some examples of how to do this such as LittleProxy but the code is fairly complex and since I'm a n00b to netty I'm trying to make my first code as simple as possible without getting off into the weeds. For now I'm ignoring all concerns about concurrency and only have one channel established from server A to server B (I know this will break horribly with concurrent requests but it makes my initial task simpler). My approach is the following: Set up client bootstrap and connect to server B running on localhost port 18080. Get the corresponding channel. Start server A listening on port 2080 with a pipeline that decodes the http request and then writes to the channel going to server B. Add a listener to the resulting channel future that will copy the content of the response from server B to the response to the original client's request to server A. Here's the code I have (very short) in which I'm trying to do exactly what I describe above. My problem is that I don't know how to copy the response from server B to the response from server. The one way I have figured out to do this results in an IllegalArgumentException when I write to the original client in the response sent by server A (I checked the content of the ChannelBuffer and the correct text was returned by the proxied server). I have pasted a partial stack trace of the exception below. Other comments welcome as there may be other mistakes I'm making besides the obvious lack of locking on the channel to server B: public class NettyExample { private static Channel channel; private static Map<Channel Channel> proxyToClient = new ConcurrentHashMap<Channel Channel>(); public static void main(String[] args) throws Exception { ChannelFactory clientFactory = new NioClientSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); final ClientBootstrap cb = new ClientBootstrap(clientFactory); cb.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline( new HttpRequestEncoder() new HttpResponseDecoder() new ResponseHandler()); } }); ChannelFuture cf = cb.connect(new InetSocketAddress(""localhost"" 18080)); channel = cf.awaitUninterruptibly().getChannel(); ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); ServerBootstrap sb = new ServerBootstrap(factory); sb.setPipelineFactory(new ChannelPipelineFactory() { public ChannelPipeline getPipeline() { return Channels.pipeline( new HttpRequestDecoder() new RequestHandler()); } }); sb.setOption(""child.tcpNoDelay"" true); sb.setOption(""child.keepAlive"" true); sb.bind(new InetSocketAddress(2080)); } private static class ResponseHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) { final HttpResponse proxyResponse = (HttpResponse) e.getMessage(); Channel clientChannel = proxyToClient.get(e.getChannel()); HttpResponse clientResponse = new DefaultHttpResponse(HttpVersion.HTTP_1_1 HttpResponseStatus.OK); clientResponse.setContent(proxyResponse.getContent()); clientChannel.write(clientResponse).addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { Channel ch = future.getChannel(); ch.close(); } }); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { e.getCause().printStackTrace(); Channel ch = e.getChannel(); ch.close(); } } private static class RequestHandler extends SimpleChannelHandler { @Override public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) { final HttpRequest request = (HttpRequest) e.getMessage(); System.out.println(""calling client channel""); proxyToClient.put(channel e.getChannel()); channel.write(request); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { e.getCause().printStackTrace(); Channel ch = e.getChannel(); ch.close(); } } } This relay call seems to work up to the point of calling clientChannel.write(clientResponse). There the following exception is generated: java.lang.IllegalArgumentException: unsupported message type: class org.jboss.netty.handler.codec.http.DefaultHttpResponse at org.jboss.netty.channel.socket.nio.SocketSendBufferPool.acquire(SocketSendBufferPool.java:53) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.write0(AbstractNioWorker.java:468) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromTaskLoop(AbstractNioWorker.java:432) You need to setup a client pipeline to wait for the response and then write it as your response. See the snoop client example; specifically HttpSnoopClientHandler. Thanks! I still have a problem with writing a DefaultHttpResponse to a channel. I'm not sure why it's not working in my case. I've edited the problem above to reflect this and asked a separate question ( http://stackoverflow.com/questions/15795061/unable-to-write-defaulthttpresponse-to-a-channel-in-netty-unsupported-message) specifically about this."
739,A,"DefaultHttpResponse errors when content is too large I am using netty-3.5.11.Final.jar My bootstrap looks like: val bootstrap = new ServerBootstrap(channelFactory) bootstrap.getPipeline.addLast(""httpDecoder"" new HttpRequestDecoder()) bootstrap.getPipeline.addLast(""aggregator"" new HttpChunkAggregator(1024 * 1024 * 1024)) bootstrap.getPipeline.addLast(""httpEncoder"" new HttpResponseEncoder()) bootstrap.getPipeline.addLast(""deflater"" new HttpContentCompressor()) bootstrap.getPipeline.addLast(""handler"" new HttpRequestServerHandler()) bootstrap.setOption(""child.tcpNoDelay"" true) bootstrap.setOption(""child.keepAlive"" true) My handlePost() looks like: def handlePost(context: ChannelHandlerContext request: HttpRequest) = { val response = new DefaultHttpResponse(HttpVersion.HTTP_1_1 HttpResponseStatus.OK) val body: Array[Byte] = .... response.setContent(ChannelBuffers.wrappedBuffer(body)) context.getChannel.write(response) context.getChannel.close } If I try to send a body of length 260000 bytes then it sends correctly. If I send a larger byte array then I get the following exception: java.nio.channels.ClosedChannelException at org.jboss.netty.channel.socket.nio.AbstractNioWorker.cleanUpWriteBuffer(AbstractNioWorker.java:766) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.close(AbstractNioWorker.java:734) at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.handleAcceptedSocket(NioServerSocketPipelineSink.java:111) at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.eventSunk(NioServerSocketPipelineSink.java:66) at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:54) at org.jboss.netty.channel.Channels.close(Channels.java:820) at org.jboss.netty.channel.AbstractChannel.close(AbstractChannel.java:197) at com.lendingblocks.services.ServiceServer$HttpRequestServerHandler.messageReceived(ServiceServer.scala:65) at org.jboss.netty.handler.codec.http.HttpContentEncoder.messageReceived(HttpContentEncoder.java:81) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:192) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:448) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:538) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:437) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:84) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.processSelectedKeys(AbstractNioWorker.java:471) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:332) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:35) at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) at java.lang.Thread.run(Unknown Source) Why am I getting this error and how can I fix it? The whole point of netty is async ops. Write call doesn't block to wait for write completed. Write and close are racing each other who will finish first. You need to register the future listener and close the channel on write completed. That was it! Thanks so much!"
740,A,"Netty 4: Is it possible to read bytes in little endian and big endian in the same ByteBuf I have an existing protocol (unchangeable) that I am trying to implement with netty where the packets have bytes that have to be read in both big and little endian as well as responses written in big and little endian. Example: 00 00 00 04 02 00 05 00 00 00 This packets values are 4 2 and 5. I know that I can implement this my own way but I would like know if there is a ""Netty"" way to do this. I have found the .order(ByteOrder) method but this appears to just make a new buffer and I don't see why I should have to create a new object to read bytes in a different order. Am i missing something here? You can simply leave the buffer's byte order as big-endian and use BufUtil.swap*(). In your case: int a = buf.readInt(); int b = BufUtil.swapShort(buf.readShort()); int c = BufUtil.swapInt(buf.readInt()); On the other hand in Netty 4 the buffer created by .order(ByteOrder) is cached by the original buffer so the overhead of .order(ByteOrder) should be pretty small as long as the connection is short-living. If you used .order(ByteOrder): int a = buf.readInt(); int b = buf.order(LITTLE_ENDIAN).readShort(); int c = buf.order(LITTLE_ENDIAN).readInt(); I'm actually curious if using .order(..) is noticeably slower than using BufUtil.swap*() although my guess is they should be essentially almost same. Thank you for the input. I think that the first method would work better for me if I could create all buffers as little endian (hints?). It just feels dirty to have to create a new shallow object or swap a value after it is read to accomplish this. It feel like the ByteBuf interface should just have methods like readIntLE() and I recall seeing some conventions in previous documentations there was an interface that did this but it seems to be gone."
741,A,"Is one port for read one port for write a good idea for socket applications? I am wondering if it is a good idea to have 2 separate ports one for read one for write ? Can I expect better performance ? NOTE: Server is Centos Client is flash message format in communication is JSON. There's no significant performance advantage and it can require much more code to handle two sockets than one particularly on the server side. You'd also still have to open both sockets from the client side as most systems wouldn't permit the server to open a connection back to the client.  Best to have it in TCP with a single port also depending if you are using NIO or not Just in case you want to have 2 ports & Unless its not a TCP (eg UDP) If you are in Cent OS 32 bit ensure that your kernel to use up more ports that it should. This is to prevent port starvation & would quickly cripple your server. Do the math if you need to support 100 users 100 x 2 = 200 open ports. but in most cases its only (65534 - 1024) ports available so if you could afford it then its cool. Also remember that most ISP's would block certain ports so keep the right ports open for read / write. regards All your ports are belong to us? Some ISP's would block certain ports for eg file sharing ports or typical gaming ports. I remember in Essen Germany they blocked everything but FTP HTTP & HTTPS what do you mean with ""that most ISP's would block certain ports"" ?  AFAIK TCP is optimised assuming you will send a request and get a response on the same socket however the difference is likely to be trivial. Often the simplest solution is also the fastest. What is the problem you are trying to solve? Peter thanks for the answer first of all. I have put my configuration in the following question do you have any suggestion ? http://stackoverflow.com/q/8655973/378737 please see http://stackoverflow.com/q/8735731/378737 this is my main problem. I am trying to figure out if I have configured netty correctly. The main suggest is you have to be able to test what ever you do because I often come across things which should improve performance but don't and other things which shouldn't make much difference but do. Certainly the behaviour you get is odd. If you can I would test a simple echo service which send packets small packets back and forth if you can get something who has seen problems to help. A typical ping time around the world should be less than 300 ms. The problem you appear to have is testing what you have. Once you can do that a solution should become more obvious."
742,A,"Slow Java SSL in a netty application I'm experiencing a significant performance degradation using netty's SslHandler vs an external SSL terminator like stud or stunnel. The difference is about 100ms in time to complete the handshake. I requested the same resource from my application several hundred times via httperf and made sure that the same cipher (DHE-RSA-AES128-SHA) was used in each case. This question got no accepted answers but the comments indicated that running an SSL terminator in front of a Java process might be a good idea. Is this expected behavior? Is Java's SSL implementation known to be this much slower or is it possible that I have some setting configured improperly? Yeah it's known to be slow compared to openssl.. You could try to use native openssl bindings like twitter does: https://github.com/twitter/finagle/tree/master/finagle-native This is one reason for apr and SSL: http://tomcat.apache.org/tomcat-6.0-doc/apr.html#HTTPS Java's SSL implementation is known to be slow?Where is a backing reference for this? Known by who? News to me. Maybe I should be more clear.. its ""slow"" compared to openssl. This is also one reason why tomcat use its native providers for openssl if it can be found... Thanks for the comments and remind me to make it more clear and add another link."
743,A,"Encode downstream messages in Netty's IO worker threads I'm using io.netty-3.9.0.Final with protobuf to create and send messages with large size. I noticed that serialization and writing to CodedOutputStream takes a lot of time and slows down my application thread. I expected this kind of work to be processed in Netty's IO worker threads. The Channel.write(Object) documentation says: ""Sends a message to this channel asynchronously."" Besides upstream messages decoding occurs in I/O worker thread. So how can I move encoding from Channel.write() invokation thread to Netty's IO worker threads? The ChannelPipelineFactory#getPipeline() method looks like this: public ChannelPipeline getPipeline() throws Exception { final ChannelPipeline pipeline = Channels.pipeline(); // Decoder pipeline.addLast(""frameDecoder"" new LengthFieldBasedFrameDecoder(MAX_FRAME_LENGTH LENGTH_FIELD_OFFSET LENGTH_FIELD_LENGTH LENGTH_ADJUSTMENT INITIAL_BYTES_TO_STRIP)); pipeline.addLast(""protobufDecoder"" new ProtobufDecoder(MessageProto.pMessage.getDefaultInstance())); pipeline.addLast(""protoMessageDecoder"" new ProtoMessageDecoder()); // Encoder pipeline.addLast(""frameEncoder"" new LengthFieldPrepender(LENGTH_FIELD_LENGTH)); pipeline.addLast(""protobufEncoder"" new ProtobufEncoder()); pipeline.addLast(""protoMessageEncoder"" new ProtoMessageEncoder()); pipeline.addLast(""handler"" upstreamHandler); return pipeline; } Unfortunately Netty 3.x doesn't work like this. It does send a message asynchronously but the asynchronous part kicks in if Netty is unable to write to the network buffers immediately. In this case it queues the message and will eventually write it out using the I/O thread. I believe your best option is to upgrade to Netty 4 which I understand has the behaviour you desire. Otherwise you could try adding an OrderedDownstreamThreadPoolExecutor to your pipeline. The write still won't be processed by the I/O thread but it should ease the pressure on your application thread."
744,A,netty NioWorker.cleanUpWriteBuffer NullPointerException Netty version netty-3.2.4.Final.jar some time have NullPointerException java.lang.NullPointerException: null at org.jboss.netty.channel.socket.nio.NioWorker.cleanUpWriteBuffer(NioWorker.java:620) ~[netty-3.2.4.Final.jar:na] at org.jboss.netty.channel.socket.nio.NioWorker.close(NioWorker.java:592) ~[netty-3.2.4.Final.jar:na] at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:355) ~[netty-3.2.4.Final.jar:na] at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:280) ~[netty-3.2.4.Final.jar:na] at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:200) ~[netty-3.2.4.Final.jar:na] at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) [na:1.6.0_24] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) [na:1.6.0_24] at java.lang.Thread.run(Thread.java:662) [na:1.6.0_24] This not a question.. This was fixed in later releases. You should upgrade.. Is there a fix bug link?
745,A,Using HttpPostRequestDecoder with Netty 3.x I'm attempting to use HttpPostRequestDecoder from Netty Extension 1.1.9 with Netty 3.3.1. I get class cast issues however when trying to get from the built-in Netty HttpRequest to what is used in the org.jboss.netty.handler.codec.http2 package. What is the correct way to go about this? org.jboss.netty.handler.codec.http.DefaultHttpRequest request; HttpPostRequestDecoder decoder = new HttpPostRequestDecoder((org.jboss.netty.handler.codec.http.HttpRequest) request); I ended up writing a small converter between the http.DefaultHttpRequest and http2.DefaultHttpRequest implementations: org.jboss.netty.handler.codec.http2.DefaultHttpRequest convertedRequest = new org.jboss.netty.handler.codec.http2.DefaultHttpRequest(HttpVersion.HTTP_1_0 org.jboss.netty.handler.codec.http2.HttpMethod.POST request.getUri()); convertedRequest.setContent(request.getContent()); convertedRequest.setChunked(request.isChunked()); // convert the headers for (Entry<String String> entry : request.getHeaders()) { convertedRequest.setHeader(entry.getKey() entry.getValue()); }  I never used the netty extensions but from a quick look at the source it looks like you need to be sure to only use the http codec stuff which is shipped with it. From your description it seems like you try to mix the http codec stuff that comes with netty and the one that comes with netty extension. Yes this was the case.. I was hoping for interoperability between the two.. didn't go as planned so I did a quick and dirty converter.  Have you tried to use the HttpPostRequestDecoder from the master branch? https://github.com/netty/netty/tree/master/codec-http/src/main/java/io/netty/handler/codec/http It seems to be working for me. See https://github.com/mashupbots/socko/tree/master/socko-webserver/src/main/java/org/mashupbots/socko/postdecoder You just have to get all the relevant files into your source directory and change the namespace. I haven't made the plunge to the bleeding edge branch yet still on 3.x
746,A,"Netty Server Push Usage and Memory Leak I'm now using Android as my Netty client. And Windows as my Netty Server. Recently I find a strange behavior on Netty. When I open the server-side app the memory is only 30MB. But after several hours it rises up to 300M. Its 10x compared to the original memory usage. The longer I open the server the more memory it will increase. I don't know why this is happening. Is it normal? By the way since Netty doesn't support built-in server push feature. So I use a static method to store all of the Channel in the map: public static final Map<Integer Channel> mapConcurrentIdChannel = new ConcurrentHashMap<Integer Channel>(); I map the channel ID to Channel. For example: Whenever client A wants to push message to client B the server will find the channel id and thus get the Channel instance then use Channel.write(object) method. Is this a correct method to implement Push Message feature in Netty? (If not could you please suggest a good method to implement Push feature? Since there's no official docs mention that) Also I'm afraid this implementation causes ""Memory Leak Problem"" which I explain earlier. About using ChannelGroup: My scenario is if there are 5 people A B C D E. Sometimes A wants to send message to C and sometimes B wants to send message to E. I can't predict when somebody will send message to somebody and who they will send to. So I can't add all the 5 people(connection) to the ChannelGroup which writing to that group would broadcast the message to everyone. I've searched on Google for a long time and nothing help on my problem I'm now facing. Wish to hear some recommendations from Netty experienced developers you!! Thanks!! I think you want to use ChannelGroup[1] for this which is basically also just use a ConcurrentMap put ensure the Channel is removed when it is closed etc. [1] http://netty.io/3.6/api/org/jboss/netty/channel/group/DefaultChannelGroup.html Should I create a Main ChannelGroup that saves all of the connections. Whenever client A wants to connect to client C search A and C in the Main ChannelGroup and then add A and C to a new ChannelGroup? BTW after checking the code I think the memory problem might come from another component that is not related to Netty. Thanks for your reply. My scenario is if there are 5 people A B C D E. Sometimes A wants to send message to C and sometimes B wants to send message to E. I can't predict when somebody will send message to somebody and who they will send. So I can't add all the 5 people(connection) to the ChannelGroup which writing to that group would broadcast the message to everyone. Is there any alternative to solving such kind of problem?"
747,A,Is multiple ChannelPipelineFactories possible for UDP transport in Netty In Netty if I create multiple ConnectionlessBootstrap instances and then set the ChannelPipeline on them using code like udpBootstrap.setPipeline(pipelineFactory.getPipeline()); Will the DatagramChannel's created using following code:- DatagramChannel datagramChannel = (DatagramChannel) udpBootstrap .bind(new InetSocketAddress(host 0)); have the appropriate decoders and encoders in its pipeline based on the factory? Or irrespective of the bootstrap/pipelinefactory DatagramChannel's can have only one associated pipeline. Scenario is that I want to use UDP to decode/encode different network protocols. If you set the ChannelPipeline directly then they will share the same ChannelPipeline contents. If you want a different one per Channel you should set the ChannelPipelineFactory.
748,A,Setting socket timeout on netty channel I have a netty channel and I would like to set a timeout on the underlying socket ( it is set by default to 0 ). The purpose of the timeout is that the not used channel will be closed if nothing is happening for 15 minutes for instance. Although I dont see any configuration to do so  and the socket itself is also hidden from me. Thanks If ReadTimeoutHandler class is used the time-out can be controlled. Following is a quotation from Javadoc. public class MyPipelineFactory implements ChannelPipelineFactory { private final Timer timer; public MyPipelineFactory(Timer timer) { this.timer = timer; } public ChannelPipeline getPipeline() { // An example configuration that implements 30-second read timeout: return Channels.pipeline( new ReadTimeoutHandler(timer 30) // timer must be shared. new MyHandler()); } } ServerBootstrap bootstrap = ...; Timer timer = new HashedWheelTimer(); ... bootstrap.setPipelineFactory(new MyPipelineFactory(timer)); ... When it will cause a time-out MyHandler.exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) is called with ReadTimeoutException. @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { if (e.getCause() instanceof ReadTimeoutException) { // NOP } ctx.getChannel().close(); }
749,A,"Servlet API implementation using Netty Has anyone made a Servlet API implementation built on top of Netty? I'm tempted to build my own as I can't google an implementation. http://www.jboss.org/netty/community#nabble-td4752485 http://markmail.org/message/4qmvuaacxqzevqhc Basically I'm looking to support just enough to get jersey working (hopefully jersey is not doing any threadlocal stuff). @Santosh The hope is to break away from the existing paradigm of one thread per request. One thread per request does not scale that well compared to an event io queue. @Adam as I understand Netty is generic Java NIO Client Server Socket Framework - Its mainly for writing network apps in java. (http://www.jboss.org/netty/community#nabble-td4918947) Can you a bit more specific about why you would need Servlet API for Netty and why existing servers like Jetty/Tomcat are not addressing your needs ? Jersey does not require servlet - runs fine even with the lightweight http server included in JDK or even runs with Grizzly NIO framework (which is similar to Netty - see grizzly.java.net). To see what it takes to make it run with Netty you may want to look at jersey-grizzly2 module in Jersey workspace - would be nice if you would be willing to develop that and contribute to the Jersey project. Now to disappoint you Jersey does use ThreadLocals. We have been planning to introduce support for non-blocking async calls but that requires a fair amount of refactoring so will only come with 2.0 version (implementing JAX-RS 2.0 once that's final). Anyway apart from the non-blocking stuff it is still useful to run it on Grizzly-like framework such as Netty for its ""light-weightness"". Maybe I can use this for the threadlocals: https://issues.jboss.org/browse/NETTY-93 Thanks! I look to see if I can contribute in anyway. Hi Adam that's right - we are planning to take advantage of a similar thing in Grizzly and potentially other frameworks eventually. The thing is this requires Jersey core libs refactoring - it is not just a question of writing a Netty plugin. That's why we likely won't take care of it before Jersey 2.0. So the real question: is the Grizzly NIO integration actually safe since Jersey is using ThreadLocals? Only Jersey 1.x faces this issue and yes it is safe since it processes the requests synchronously - i.e. does not take advantage of the non-blocking features of Grizzly.  If you want to get Jersey working with Netty you can use the bindings available at https://github.com/cgbystrom/jersey-netty  Do you looking for Netty-Servlet-bridge? This project provides a Servlet API implementation for Netty.IO framework (http://netty.io/). Netty Servlet Bridge allows integration of existing Servlet API based web-applications into the Netty-backed infrastructure. Not fully implemented but the Vaadin example runs.  If you want use Jersey with Netty you probably need to be safe and use org.jboss.netty.channel.socket.oio.OioServerSocketChannelFactory not org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory This will allow the ThreadLocal stuff work correctly under load. Of course when Jersey upgrades to not use ThreadLocal but ChannelLocal this will not longer be needed."
750,A,Netty: Processing many different packet types I am trying to connect to an tcp/ip interface which sends many different packet types. Each packet is different in length and content. I simply want to process each packet type and generate POJOs which will be processed again by another state-handler. So far I am not sure if there is any structure in Netty which supports this type of processing packets/frames. One solution I could think of was to create one decoder inbound handler which manipulates the pipeline depending on the first byte (which is the type field). Which structure or algorithm in Netty could help me to realize such simple Switch-Case problem? thx Tom If your connection is supposed to handle the stream of same packet types as the first packet type (i.e. the first packet determines the state of the connection) you could take a look into the port unification example. If your connection is supposed to handle the stream of arbitrary packet types you'd better write a decoder that understands all packet types and converts them into a POJO. Unless the number of packet types to handle are too many it shouldn't be very difficult. Once a decoder decodes a packet your last handler in the pipeline will look like the following: public class MyPacketHandler extends SimpleChannelInboundHandler { @Override public void channelRead0(ChannelHandlerContext ctx Object msg) { if (msg instanceof MsgA) { handleA(ctx (MsgA) msg); } else if (msg instanceof MsgB) { handleB(ctx (MsgB) msg); } ... } private void handleA(ChannelHandlerContext ctx MsgA msg) { ... } ... } If you do not like the tedious if-else blocks you could make use of a java.util.Map and Class.isAssignableFrom(). I guess the second case you described fits my problem. But this means that the pipeline structure of netty does not help me with my own protocol and messages - right? As you already said the Packethandler is the last handler in the pipeline... Yes you are right.  Check the portunification example which does something similar: https://github.com/netty/netty/blob/4.0/example/src/main/java/io/netty/example/portunification/PortUnificationServerHandler.java
751,A,"NPE in channel.write(Object message) I am running a (selfmade) middleware ""Service Connector (SC)"" basing on netty (3.2.5.Final.jar) which basically is a proxy for http traffic. Any incoming request is forwarded to a remote node an apache at the end. public void messageReceived(ChannelHandlerContext ctx MessageEvent event) throws Exception { ChannelBuffer msg = (ChannelBuffer) event.getMessage(); outboundChannel.write(msg); } I am sending a request over the browser to the SC for example: ""http://localhost:9104/testHtml.htm"" it usually works perfect! Occasionally the browser loops forever. Different patterns (different files sizes times) Looking into the netty log: 2012-11-28 17:54:12.326+0100 [New I/O server boss #9 ([id: 0x015bdc50 /10.43.18.160:9104])] DEBUG (org.jboss.netty.handler.logging.LoggingHandler:39) - [id: 0x00f6fd54 /10.43.18.160:52499 => /10.43.18.160:9104] OPEN 2012-11-28 17:54:12.342+0100 [New I/O server boss #9 ([id: 0x015bdc50 /10.43.18.160:9104])] DEBUG (org.jboss.netty.handler.logging.LoggingHandler:39) - [id: 0x00f6fd54 /10.43.18.160:52499 => /10.43.18.160:9104] BOUND: /10.43.18.160:9104 2012-11-28 17:54:12.357+0100 [New I/O server boss #9 ([id: 0x015bdc50 /10.43.18.160:9104])] DEBUG (org.jboss.netty.handler.logging.LoggingHandler:39) - [id: 0x00f6fd54 /10.43.18.160:52499 => /10.43.18.160:9104] CONNECTED: /10.43.18.160:52499 2012-11-28 17:54:12.342+0100 [SC_WORKER thread-13] DEBUG (org.jboss.netty.handler.logging.LoggingHandler:39) - [id: 0x00f6fd54 /10.43.18.160:52499 => /10.43.18.160:9104] CHANGE_INTEREST: 0 2012-11-28 17:54:12.420+0100 [New I/O server worker #9-20] DEBUG (org.jboss.netty.handler.logging.LoggingHandler:39) - [id: 0x00f6fd54 /10.43.18.160:52499 => /10.43.18.160:9104] RECEIVED: BigEndianHeapChannelBuffer(ridx=0 widx=501 cap=501) - (HEXDUMP: ....) 2012-11-28 17:54:12.435+0100 [SC_WORKER thread-13] DEBUG (org.jboss.netty.handler.logging.LoggingHandler:39) - [id: 0x00f6fd54 /10.43.18.160:52499 => /10.43.18.160:9104] INTEREST_CHANGED 2012-11-28 17:54:12.451+0100 [SC_WORKER thread-11] DEBUG (org.jboss.netty.handler.logging.LoggingHandler:43) - [id: 0x00f6fd54 /10.43.18.160:52499 => /10.43.18.160:9104] EXCEPTION: java.lang.NullPointerException java.lang.NullPointerException at org.serviceconnector.net.res.netty.tcp.proxy.NettyTcpProxyResponderRequestHandler.messageReceived(NettyTcpProxyResponderRequestHandler.java:127) at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:69) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:619) In debug mode i can see either msg nor outboundChannel is null :/ if i change to code to the following it works. just write the message again in case of error try{ outboundChannel.write(msg); } catch(Throwable t) { outboundChannel.write(msg); } or slow down the thread Thread.sleep(200); outboundChannel.write(msg); guess i am facing a race condition. it only happens on slow machines of course its hard to reproduce unfor. i am not able to provide an example. i tried netty 3.5.10.Final with the same behavior. any one observing similar behaviour? thx! sure: http://www.stabilit.ch/download/sc/NettyTcpProxyResponderRequestHandler.java Please show me your complete handler.. outboundChannel can only be null if messageReceived is invoked before channelOpen. Usually it never happens but it can happen if your pipeline has an ExecutionHandler before your handler and you are using an unordered executor service. If so please use an ExecutorService such as OrderedMemoryAwareThreadPoolExecutor. thx a lot and sorry obviously i did not read the ExecutionHandler API carefully enough :/!"
752,A,"Netty High Availability Cluster Wondering if Netty has any examples of how I can create a high availability application whereby the netty client will use a backup server in case of live server failure. Define ""failure"" define your required guarantees. If you want to make the client and server highly available and to manage the connections state by your code with ease Have a look on Akka Remote Actor API which is using Netty for underlying communication .  There is no example of this. But I think its quite straight-forward. You need to have a pool of different ""channels"" that are connected to remote hosts. The do something like this: channel.write(msg).addListener() { public void operationComplete(ChannelFuture future) { if (!future.isSuccess) { ... // get next channel from the pool and try the write there etc.. } } } Hope it helps.."
753,A,what is causing this memory leak in netty I have two server process they communicate with two socket connections. Both connections are sending message oneway only.(one for c->s one for s->c). The server and the client bootstrap initialized with OioServerSocketChannelFactory / OioClientSocketChannelFactory respectively. After some profiling found object of these three classes never release(on both side). I don't use these classes directly and I only keep reference to two Channel object. java.util.concurrent.LinkedTransferQueue$Node 1005351 32171232 org.jboss.netty.channel.Channels$2 1005351 24128424 org.jboss.netty.channel.socket.ChannelRunnableWrapper 1005351 48256848 What kind of object leaked in my code might cause these objects not release? UPDATE: the environment jdk7u7 centos6 64bit netty 3.5.3 Are you closing the channel once the connection is done? no. the connection won't close until the server process shutdown. And the client I talking about is also a server process it just mean the connection start by this server and this server process have only one instance. so the total connection on either side is two. It's a good chance this is a bug of netty. After I change OioServerSocketChannelFactory / OioClientSocketChannelFactory to NioServerSocketChannelFactory / NioClientSocketChannelFactory the problem is gone.  This was because of a bug in Netty Oio impl. The bug was fixed as part of 3.5.4.Final. So please upgrade to 3.5.4.Final or 3.5.5.Final. See [1]. [1] https://github.com/netty/netty/issues/520
754,A,"Permission denied to bind to port when running Scala application via SBT I'm trying to run my Scala code with SBT but get the error below. This happens both with SBT using the command line and with IntelliJ Idea.  [error] (run-main) org.jboss.netty.channel.ChannelException: Failed to bind to: /127.0.0.1:80 org.jboss.netty.channel.ChannelException: Failed to bind to: /127.0.0.1:80 .... .... Caused by: java.net.SocketException: Permission denied What do I configure to allow port access. This happens both when I try to run on my local Mac and on my remote Ubuntu server. Running sbt with ""sudo sbt"" fixes the problem but this is not the solution. Where can I set permission to allow my Scala app to access port 80. @DanielC.Sobral Thank you What operating system distribution (if applicable) and version? Same problem on Mac Lion and Ubuntu server 10.04. Using JDK 1.6 and SBT 0.11.2 and Scala 2.9.1 I don't know about Lion but googling revealed no solution other than sudo. Ubuntu would use the same solutions as Debian which I put in my answer below. See also the [serverfault question](http://serverfault.com/questions/112795/how-can-i-run-a-server-on-linux-on-port-80-as-a-normal-user). Note that this is not a programming issue but an Operating System issue. The solution to this problem will depend on the operating system not on anything that SBT Scala or Java might do. For instance Debian proposes three different solutions all of which can be used on other Linux distributions -- two of them are variations on running as root and the third uses iptables to fake listening on port 80. On FreeBSD one can disable the low port limitation entirely and Solaris can do so per-port-and-user as described (for both) here.  Running sbt with ""sudo sbt"" fixes the problem but this is not the solution. Where can I set permission to allow my Scala app to access port 80. I think that is your only solution though. Only privileged applications can bind to ports under 1024. Maybe you are more comfortable with running an http proxy on port 80 (only the proxy as root) or have some ipfilter rule that re-routes incoming port 80 to port 8080 ? See also this answer.  You might want to have a look at commons-daemon [1] and its jsvc binary. This allows you to start as root and drop privileges after some tasks. The tasks here could be the Binding of the port. [1] http://commons.apache.org/daemon/"
755,A,using multiple encoders in netty channel pipeline I have to send different types of messages on a netty channel and these are to be encoded before sending.I am registering multiple OneToOneEncoders in a netty channel  with each encode supposed to act on a single type of message. I check the type of msg  encoding if it of correct type for this encoder  or return the msg as such ( with no transforming ) if it is not of the particular type ( of the encoder ). Is this a valid design approach ? The problem I am facing is : sometimes this leads to various downstream exceptions ( in the decoder ) like IndexOutOfBounds. What makes it more difficult is that sometimes it works correctly. I am sure there is something that is getting messed up in encoding / decoding. what is it exactly eludes me.Any obvious mistakes here ? edit : my question is about the general design approach .. if that is correct then I can work into bugs in code myself.. Please paste your code and exception here You can have more then one OneToOneEncoder in the ChannelPipeline. Just be sure that these are thread-safe as downstream events can be send from any thread. with multiple encoders  will the encode methods be called in a chain ? with the output of one forming the input to another ? Yes exactly thats how it works
756,A,"JConsole Total loaded classes behaviour I monitored a Java7 application for a couple of week and I observed a couple of things that i would like to understand. From the application start the number of total loaded classes has grown constantly I think that this is normal since the application (based on netty 3.6 library) open and closed a lot of tcp connections hourly. I don't think I should worry about this also because the Current classes loaded counter did not grown. What I can't understand it's why approximately every 7 days the number of the total loaded class drops to the current classes loaded counter. Also the Heap Memory usage seems follow the same pattern: the heap space grows till 70mb and then decreases to 20mb. It is like every 7 days a more ""deeper"" execution of the Garbage collector it is executed. The application has never been restarted. Can someone explain me this behaviour? Thanks. P.S. Unfortunately i couldn't take a screenshot of the JConsole. In the Oracle JVM there are multiple pools of memory in the heap. One of them is the old gen pool another is the perm gen pool. The old gen pool contains objects that have survived a few garbage collections. The perm gen pool contains loaded classes and other ""permanent"" data. Heap pools are garbage collected differently. The standard garbage collection that you see run often runs on the eden pool which is where newly created objects are placed. The theory is that if you have a lot of short lived objects then those can be garbage collected often in a small heap. In the meantime your longer lived objects get promoted to the older pools and collected less often. This is all to allow more efficient garbage collection as longer lived objects aren't considered for collection as often as short lived objects. So the ""deeper"" execution you're seeing is probably when the old gen pool is getting collected. It just so happens that Oracle decided to implement things so that the perm gen pool gets garbage collected at the same time as the old gen pool which is why both of them drop at the same time. Finally simply opening and closing TCP connections should not cause new classes to get loaded. What is likely happening is that some library is creating new dynamic proxies when a connection arrives. This dynamic proxy is a brand new class created at runtime and when it is created it will increase your total classes loaded count. References: In Java is Permanent Generation space garbage collected? Java 6 garbage collection details (from Oracle)"
757,A,Netty 4 IpFilter I'm going through the new Netty code organization and it seems that the handler package (see https://github.com/netty/netty/tree/master/handler/src/main/java/io/netty/handler) has gone through a diet. Where did the ipfilter package go? I couldn't read anything about it in the news (http://netty.io/wiki/new-and-noteworthy-in-4.x.html). My guess is that the ChannelHandler refactoring along with the new auto-read flag (as described in Sensible and less error-prone inbound traffic suspension) makes the ipfilter package obsolete? Hmm I think it is still useful. Could you please open a request in our bug-tracker. We will port it over then. Or even better do a PR maybe ? ;)
758,A,"choosing either simplehandler or executor in netty 4.0 Consider the following server bootstrapping code: ChannelFuture f; ServerBootstrap b = new ServerBootstrap(); try { b.group(new NioEventLoopGroup() new NioEventLoopGroup()) .channel(NioServerSocketChannel.class) .localAddress(1234) .childOption(ChannelOption.TCP_NODELAY true) .childHandler(new MyChannelInitializer(new DefaultEventExecutorGroup(10))); f = b.bind().sync(); f.channel().closeFuture().sync(); } And MyChannelInitializer.java: public class MyChannelInitializer extends ChannelInitializer<SocketChannel> { private EventExecutorGroup executorGroup; public MyChannelInitializer(EventExecutorGroup _executorGroup) { executorGroup = _executorGroup; } @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.nulDelimiter())); pipeline.addLast(""decoder"" new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(""encoder"" new StringEncoder(CharsetUtil.UTF_8)); // and then business logic. pipeline.addLast(this.executorGroup ""handler"" new MyHandshakeHandler()); } } Now- MyHandshakeHandler() listens for messages and those messages need to interact with the database. Before we go further- is the above code the correct way to do this? (namely- the way I used EventExecutorGroup for this blocking type of handler) Assuming for now that it is correct here's my question- while it's true that MyHandshakeHandler() needs to interact with the database this is only during the initial negotiation with the client and upon channel close. The rest of the time- namely after handshake is completed and before the channel is closed- all that is needed is to bounce ping/pong/heartbeat/keepalive type messages which do not require the database. Therefore- should that A) be a separate handler (let's call it ""MyPingHandler"") which is added to the pipeline before MyHandshakeHandler or B) should I just add that logic to MyHandshakeHandler? If A) how do I stop the message from propagating further so that MyHandshakeHandler is not needlessly called unless it is specifically the channel close event (i.e. channelInactive())? As a bonus point- it would be nice if MyPingHandler were only added to the pipeline after handshake is complete so that it is not needlessly called as well. If B) I don't understand the purpose of EventExecutorGroup in this case. These connections are the only type which this server will power.... so it seems strange to me to set a dedicated group of threads which will be used for every single handler rather than just use the default. So if B is the way to go- for this specific case- should I just add the handler to the pipeline normally without EventExecutorGroup (if not- why not)? The answer is (A). To propagate an event to its next handler you usually call a ctx.fireXXX() method. If you don't call any of them the event will not be propagated. So in your case you can just swallow event in most case after handshake is complete by NOT calling ctx.fireXXX() methods. Also the pipeline can be dynamically configures. You can add or remove a handler to/from a pipeline at anytime. Therefore you can either remove the handshake handler after handshake is over or add the ping handler after handshake is over (or perhaps both). Thanks- quick question though I believe inbound messages are received via overriding messageReceived() not an event. So will not calling ctx.fireXXX() still prevent the next handler in the pipeline?"
759,A,"Detect closed client UDP channel in Netty 4 I'm using Netty as part of a UDP server which opens a number of persistent connections with various clients on a single server channel. I need to perform some cleanup when a client terminates the connection. Specifically I need to know when the connection is terminated and from which IP address the terminating client is located at so that I can cleanup the data. Perhaps I'm misunderstanding the Netty model but I'm unsure how to detect this. I normally distinguish between various clients by checking the sender's IP address from the DatagramPacket instances perhaps that is wrong and I should be using multiple channels or something like that? Either way I'm looking for some way to handle a closed connection. You're misunderstanding UDP not Netty. There is no such thing as a ""persistent connection"" in UDP although there can be application-managed sessions and UDP provides no information about whether the other endpoint is still active. Ideally you'll have a ""close"" message but you'll need to have a timeout or other mechanism to identify dead connections and clean them up (for crashed clients etc.). This will require some sort of garbage-collection process maybe a background thread that checks a ""last heard from"" timestamp and closes inactive sessions. I was beginning to suspect this thanks it makes sense now that you point it out. Would it be advisable to simply ping an unresponsive client and kill it if it takes too long to respond? @JakeKing It's better to require the client to send keepalives. I'll take your word for it though could you briefly explain why that's better? Since the client will likely have a lot of traffic anyway poking the quiet ones seems like it would be more effective. @JakeKing A client doesn't have to send keepalives if it's actively sending data but there are a few reasons all efficiency/scalability to put the burden on it. Basically both ends know that the server needs updates so the ""client ping"" just adds complexity on the server end and extra traffic. If the client is going to respond to a ping it would have sent the keepalive (or another message) anyway and now you just have a 1-second timer thread on each client instead of lots of extra bookkeeping on the server. Great thanks a lot for the help. In fact you need to stop thinking about *clients* completely in UDP. There is one request and one response. That client doesn't have any context beyond the request/response. You may never hear from him again. @EJP It sometimes does make sense to think of sessions in UDP such as for games or VOIP. It really depends on the particular application."
760,A,"Convert from Netty 4.0 CR3 to 4.0.10-final I am upgrading my frameworks Netty version to the newest and it seems that the API has broke (I know I shouldn't have used it until a final version was out); I have been reading over the docs and looking through classes to try and find a feasible solution but I cannot find one.  ctx.nextInboundMessageBuffer().add(message); ctx.fireInboundBufferUpdated(); if (additionalBuf != null) { ChannelHandlerContext head = ctx.pipeline().firstContext(); head.nextInboundByteBuffer().writeBytes(additionalBuf); head.fireInboundBufferUpdated(); } Is what I am trying to convert to the new API any help is appreciated. Full code: @Override protected void decode(ChannelHandlerContext ctx ByteBuf in List<Object> out) throws Exception { if (!in.isReadable()) { return; } int messageId = in.readUnsignedByte(); ByteBuf additionalBuf = null; if (in.isReadable()) { additionalBuf = in.readBytes(in.readableBytes()); } ChannelPipeline pipeline = ctx.pipeline(); pipeline.remove(HandshakeDecoder.class); HandshakeMessage message = HandshakeMessage.forId(messageId); switch (message) { case LOGIN_MESSAGE: break; case UPDATE_MESSAGE: break; default: throw new IllegalStateException(""Unexpected message id: "" + messageId); } ctx.nextInboundMessageBuffer().add(message); ctx.fireInboundBufferUpdated(); if (additionalBuf != null) { ChannelHandlerContext head = ctx.pipeline().firstContext(); head.nextInboundByteBuffer().writeBytes(additionalBuf); head.fireInboundBufferUpdated(); } } Can you clarify what ""broke"" means? (And does this help? http://stackoverflow.com/questions/16469072/migrating-sendupstream-in-netty-4) I think it's explained here: http://netty.io/news/2013/06/18/4-0-0-CR5.html In general you just would use fireChannelRead(...)"
761,A,Netty 4 and JCA WorkManager integration The question about integrating Netty 3 with JCA Resource adapter was already asked. The solution was quite straightforward: write a custom Executor that wraps JCA WorkManager and pass it to NioServerSocketChannelFactory constuctor. However threading seems to be heavily refactored in Netty 4 and this approach doesn't work (there's no NioServerSocketChannelFactory class to start with). There is an option to supply your own ThreadFactory but obviously this is not good enough for JCA since only WorkManager is exposed not threads so a simple facade is not possible anymore. So I think I'm stuck. Is what I am trying to do even possible without lots of code being written? EDIT: In the end I asked myself why making Resource adapter at all. Instead I just use JMS queues (inbound and outbound) as my integration points between our EE application and standalone server that uses netty and it works fine. Not possible to do in netty 4 but looks like it will be available in netty 5 check https://github.com/netty/netty/issues/2250
762,A,The role of Google Protocol Buffers in network software Edit: Here I'm talking about the Java binding of Protocol Buffers. I'm trying to understand what Google Protocol Buffers are and what they do. Let's say I have a simple Netty-based network client/server pair. The client randomly sends Ping messages to the server and the server responds with a Pong message. How would Protocol Buffers fit into the equation here? Would I use them to serialize Ping and Pong messages and then use Netty to do the actual transport of those serialized messages? Or does Protocol Buffers take care of the transport as well? The public protocol-buffers drop only includes a specification for serialization. Some teasing and tempting hooks in place hinting at a full RPC stack but no implementation or specification is provided. If you are using protocol-buffers you will need your own transport or RPC stack or a library that adds these features for you. To emphasize: all that protocol-buffers formally declares is a serialization protocol and a DSL that describes data to be stored in that format. Thanks @Marc Gravell (+1) - so you are saying that in the case of Java that I would need to use the Java binding for protocol buffers yes? If so how does your answer change if we are talking about the actual Java implementation? Thanks again! @IAmYourFaja there are iirc multiple java implementations of protobuf. Any should work identically for serialization purposes. If one or more offers RPC services then that's fine but no protocol is defined so there is no guarantee of compatibility with any particular system
763,A,"Writing unsigned types to a Netty ChannelBuffer Netty's ChannelBuffer class provides convenient methods for reading unsigned types from a ChannelBuffer however there don't appear to be any equivalent methods for writing unsigned types to a ChannelBuffer. I feel like I must be missing something. What's the recommended approach for say writing an unsigned integer to a ChannelBuffer? Thanks! If you want to write a 32-bit value its all the same. channelBuffer.writeInt(my32bitValue); Consider: `long reallyBigUnsignedInt = inChannelBuffer.readUnsignedInt();` Assume that reallyBigUnsignedInt exceeds the maximum for a signed int. What's the best way to write this value to another ChannelBuffer as an unsigned int? Thanks! Ah I see. Downcasting a large unsigned int stored as a long to an int ""just works"". A 32-bit value is a value which uses 4 byte what you make of it unsigned signed float etc is up to you when you read it."
764,A,(Java/netty) What's the easiest way to send and receive variable-size objects with Netty? So I have a Message class which contains all the information I want to send. However its contents can vary wildly. What's the easiest way to send and receive (specially the decode/reassembly part) such kind of objects through a Netty channel? (using Netty 3) We use a 4-byte length prefix. We use a subclass of the OneToOneEncoder on the sending side and a subclass of the LengthFieldBasedFrameDecoder on the receiver side. Write message:  private static final byte[] LENGTH_PLACEHOLDER = new byte[4]; ChannelBufferOutputStream bout = new ChannelBufferOutputStream(dynamicBuffer(512 ctx.getChannel().getConfig().getBufferFactory())); bout.write(LENGTH_PLACEHOLDER); // write message contents here ... ChannelBuffer encoded = bout.buffer(); encoded.setInt(0 encoded.writerIndex() - 4); return encoded; Constructor params for LengthFieldBasedFrameDecoder: private static final int MAX_OBJECT_SIZE = 1 << 21; public MyDecoder() { super(MAX_OBJECT_SIZE 0 4 0 4); } Read message:  ChannelBuffer frame = (ChannelBuffer) super.decode(ctx channel buffer); if (frame == null) { return null; } ChannelBufferInputStream data = new ChannelBufferInputStream(frame); // read message here ... So there is no way the Netty library will prepend this length value when I send an object? (and when receiving checking it?) This solution seems to be very close to what I want... could you provide some code snippets showing how exactly to write it? @EduardoBezerra - you prepend it when you write in the encoder and the frame based decoder will auto-magically read it and ensure that it has all the data before attempting decoding. @EduardoBezerra - added example code  The ReplayingDecoder is probably what you're looking for: http://docs.jboss.org/netty/3.1/api/org/jboss/netty/handler/codec/replay/ReplayingDecoder.html Rather than throwing an error if there isn't enough data this will silently fail and retry decode() until all the data is available. Here's a tutorial showing this in action: http://biasedbit.com/netty-tutorial-replaying-decoder/ I've seen this tutorial but it seemed a bit convoluted with too much code... I wonder if there isn't a shorter more elegant way to do the same... For one thing I believe the length attribute would be enough (the others could be inside the message object).
765,A,"Write to channel on Read Time out I would like to write time out error whenever I catch Reader Idle time out. public class TimeOutHandler extends IdleStateAwareChannelHandler { @Override public void channelIdle(ChannelHandlerContext ctx IdleStateEvent e) { if (e.getState() == IdleState.READER_IDLE) { System.out.println(""Reader TimeOut""); HttpResponse response = new DefaultHttpResponse(HttpVersion.HTTP_1_1 HttpResponseStatus.OK); response.setHeader(Names.CONTENT_TYPE ""application/json; charset=UTF-8""); response.setContent(ChannelBuffers.copiedBuffer(""{\""timeout\"":true}"" CharsetUtil.UTF_8)); ChannelFuture future = e.getChannel().write(response); future.addListener(ChannelFutureListener.CLOSE); } } } The handler is working but nothing is written to the channel. Is such scenario possible? Update: My pipeline factory: public class AsyncServerPipelineFactory implements ChannelPipelineFactory { static HashedWheelTimer timer = new HashedWheelTimer(); private final ChannelHandler idleStateHandler = new IdleStateHandler(timer 10 20 0); public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline( idleStateHandlernew TimeOutHandler()); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""handler"" new HTTPRequestHandler()); return pipeline; } } Can you show us your ChannelPipeline ? Looks ok to me.. Why you think its not getting written ? Have you captured the traffic with wireshark to be sure ? Yes. Please. See my update Your pipeline is misconfigured. Any handler that writes an HttpResponse must be inserted after your HttpResponseEncoder. e.g.  ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""idler"" idleStateHandler); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""timer-outer"" new TimeOutHandler()); pipeline.addLast(""handler"" new HTTPRequestHandler());"
766,A,"Create multiple websocket server with one port number I am using netty 4.0.20 I want to create different websocket servers on the same port using different urls for example wss://localhost:1234/PathA wss://localhost:1234/PathB wss://localhost:1234/PathC is that possible? Yes this is possible with using reverse proxying which can be done with Nginx. This will require one additional server in your setup. First you have to setup each server to listen to a different port and then you need the front end server to listen to your desired public port (in your case this is 1234). So lets say you have the following servers Nginx listening at 0.0.0.0:1234 Netty that serves /PathA and listens at 0.0.0.0:1235 Netty that serves /PathB and listens at 0.0.0.0:1236 Netty that serves /PathC and listens at 0.0.0.0:1237 Now what you have to do is write an Nginx configuration file that will upgrade the connection from HTTP to Websocket and then reverse proxy each path to its corresponding server. An example configuration file that could do the job for you is the following. { listen 1234; server_name localhost; location ~PathA/$ { proxy_pass http://localhost:1235; proxy_http_version 1.1; proxy_set_header Upgrade ""websocket""; proxy_set_header Connection ""upgrade""; } location ~PathB/$ { proxy_pass http://localhost:1236; proxy_http_version 1.1; proxy_set_header Upgrade ""websocket""; proxy_set_header Connection ""upgrade""; } location ~PathC/$ { proxy_pass http://localhost:1237; proxy_http_version 1.1; proxy_set_header Upgrade ""websocket""; proxy_set_header Connection ""upgrade""; } }"
767,A,Netty IdleStateHandler times out for large messages I'm using Netty's IdleStateHandler in my client/server communication to send heartbeats (server to client) and detect timeouts on the client. This works fine expect for rare cases when the transfer of large messages takes longer than the configured read timeout. I my case these large messages only happen at the client's startup (baseline) during normal operation the messages are small hence I'm reluctant to increase the overall read timeout on the client. Is there a way for prevent the IdleStateHandler from firing idle state events while it's actually receiving data? Or am I doing something wrong? Thanks Thomas Add the IdleStateHandler as first handler to the 'ChannelPipeline' solved my problem. This ensures the timestamp of the last received data is updated as often as possible.
768,A,"Design of a server push using netty in my second question on netty. We are just starting with it. And we have a design where we need to use HTTP with long polling HTTP Streaming. We are estimating from 5k - 50k connected users with an opened connection. We know tomcat won't handle so we look over netty to accomplish the task. The design should be simple enough but we can't use websockets (we would love to use hornetQ on top of netty with websocket/stomp support) but we can't. So basically we will have server pushing events (we may even use JS SSE to do that) in the connected clients. Clients will subscribe to an endpoint based on a url (like a queue on JMS much much simpler though) So we will have a process on the server side that generate events and notifies the interested channels (we are using a simple observer pattern for this). So a channel subscribes to those process and then receive events from them. My question here today is to see if the design approach we used is the right one considering netty's architecture. public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { service.subscribe(this); this.context = ctx; ctx.sendUpstream(e); } //this method gets called by the service when a server event happens public void onUpdate(String message) { ChannelBuffer buffer = Channels.buffer(message.getBytes().length()); buffer.writeBytes(message.getBytes()); ChannelFuture future = Channels.future(this.context.getChannel()); future.addListener(ChannelFutureListener.CLOSE); Channels.write(this.contextfuturebuffer); } Regards Looks ok but there's not much there. How are you handling the long poll initiation and the possible subsequent timeout ? (Or perhaps you're totally good with that..... this is not the spanish inquisition) One thing you might consider depending on the number and popularity of your ""URL queues"" is to use a ChannelGroup as the container for all channels subscribed to that url queue. That way oyu can just write the message to the group. Plus when the channels close they will be ejected from the group so there's some code simplification there. Also have you considered HTTP Streaming ? Not as good as websockets but better than long polling in my view. I'm not 110% confident that all the implementations are perfect but I have put together a test project that demonstrates JSON push using netty for long polling websockets and http streaming. There is also a javascript client that adapts to the push type that you select.You might find it useful (and I am happy to get any feedback on it....) Thanks a lot for the insights. The code is very simplified. I need to add more cleaning :). I'm sorry my mistake I'm actually considering http streaming not long polling on the client we will open the connection and just keep reading from it. I'll check the project I might get some good insights from it."
769,A,Are there any known issues regarding Netty and Ipv6? Testimonial of a successful deployment of Netty application in an Ipv6 only network would be appreciated. Are there any known issues regarding Netty and Ipv6? Better suited to Server Fault? I can confirm that we run an application in production that is available over IPv6 and IPv4. This application has both a TCP and UDP protocol. As suggested it just works :-)  I never used IPv6 only with Netty but it should just work. There are no limitations in the netty code which I'm aware of.
770,A,"Netty OrderedMemoryAwareThreadPoolExecutor not creating multiple threads I use Netty for a multithreaded TCP server and a single client persistent connection. The client sends many binary messages (10000 in my use case) and is supposed to receive an answer for each message. I added an OrderedMemoryAwareThreadPoolExecutor to the pipeline to handle the execution of DB calls on multiple threads. If I run a DB call in the method messageReceived() (or simulate it with Thread.currentThread().sleep(50)) then all events are handled by a single thread.  5 count of {main} 1 count of {New 10000 count of {pool-3-thread-4} For a simple implementation of messageReceived() the server creates many executor threads as expected. How should I configure the ExecutionHandler to get multiple threads executors for the business logic please? Here is my code: public class MyServer { public void run() { OrderedMemoryAwareThreadPoolExecutor eventExecutor = new OrderedMemoryAwareThreadPoolExecutor(16 1048576L 1048576L 1000 TimeUnit.MILLISECONDS Executors.defaultThreadFactory()); ExecutionHandler executionHandler = new ExecutionHandler(eventExecutor); bootstrap.setPipelineFactory(new ServerChannelPipelineFactory(executionHandler)); } } public class ServerChannelPipelineFactory implements ChannelPipelineFactory { public ChannelPipeline getPipeline() throws Exception { pipeline.addLast(""encoder"" new MyProtocolEncoder()); pipeline.addLast(""decoder"" new MyProtocolDecoder()); pipeline.addLast(""executor"" executionHandler); pipeline.addLast(""myHandler"" new MyServerHandler(dataSource)); } } public class MyServerHandler extends SimpleChannelHandler { public void messageReceived(ChannelHandlerContext ctx final MessageEvent e) throws DBException { // long running DB call simulation try { Thread.currentThread().sleep(50); } catch (InterruptedException ex) { } // a simple message final MyMessage answerMsg = new MyMessage(); if (e.getChannel().isWritable()) { e.getChannel().write(answerMsg); } } } OrderedMemoryAwareThreadPoolExecutor guarantees that events from a single channel are processed in order. You can think of it as binding a channel to a specific thread in the pool and then processing all events on that thread - although it's a bit more complex than that so don't depend on a channel always being processed by the same thread. If you start up a second client you'll see it (most likely) being processed on another thread from the pool. If you really can process a single client's requests in parallel then you probably want MemoryAwareThreadPoolExecutor but be aware that this offers no guarantees on the order of channel events. I am getting an exception in the FrameDecoder now: the worker thread cannot cope with the number of messages coming from the client. Does it make sense if I add the executionHandler before the decoder in the pipeline? `ERROR {New I/O worker #1} (MyProtocolDecoder.java:161) - decode exception: java.lang.UnsupportedOperationException at org.jboss.netty.buffer.CompositeChannelBuffer.array(CompositeChannelBuffer.java:166) ... at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:422)` Thanks for reply. I've always tried to place the execution handler as far up the pipeline as possible to allow the I/O thread to do as much work as it can. It's placement depends on where your blocking operations begin and also what's most performant for your app. Regarding the exception - CompositeChannelBuffer doesn't support the array() method. You may need DynamicChannelBuffer - http://static.netty.io/3.6/api/org/jboss/netty/buffer/DynamicChannelBuffer.html. Without seeing the decoder it's difficult to advise. However you'll probably want to ask for help on your decoder in a different quest. Thank you. Yes the error was in MyProtocolDecoder in the transformation of the ChannelBuffer into a Java object. It appears to work now."
771,A,unfiltered: when to choose netty I did a quick test in unfiltered comparing throughput of both jetty and netty as underlying connection handlers. Just serving a (memory-cached) image and running a load test on that. My findings are that there is no significant difference in performance. Apart from that I am under the impression that both have similar scaling features aswell like suspending connections. Also unfiltered is kind enough to give us very similar (if not the same) interfaces to both frameworks so that you can't really say one is easier to use that the other. So I wonder why does unfiltered give us those two choices? is there any scenario when you would choose netty over jetty (or the other way around)? My personal thoughts: I've used embedded jetty only as a servlet container. Using netty I can hanle http packages one by one custom my own http post data storage. IMO I think they are both sharp knifes but netty can turn into a needle if you want to.
772,A,"Difference between stateful xxxServerHandle and unstateful yyyServerhandle? I reviewed Netty docs and found some comments in examples source Class: org.jboss.netty.example.factorial.FactorialServerHandler  in this src some comments:  //##in org.jboss.netty.example.factorial.FactorialServerPipelineFactory ...... // and then business logic. // Please note we create a handler for every new channel // because it has stateful properties. pipeline.addLast(""handler"" new FactorialServerHandler()); But I recheck other examples such as TelnetServerPipelineFactory seems nothing difference the handle is create by:  // and then business logic. pipeline.addLast(""handler"" new TelnetServerHandler()); All the handlers are created by pipeline with ""new""? And all the examples in Netty are stateful? Obviously Echo/Telnet needn't keep stateful prop. In my old project I use Netty to create a Http Server to act as RESTful server my handler code is:  public class HttpServerPipelineFactory implements ChannelPipelineFactory { private final HttpServerHandler handler; public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = pipeline(); pipeline.addLast(""decoder"" new HttpRequestDecoder()); pipeline.addLast(""aggregator"" new HttpChunkAggregator(1048576)); pipeline.addLast(""encoder"" new HttpResponseEncoder()); pipeline.addLast(""handler"" handler); //singleton return pipeline; } } My RESTful server is statefulless(which is one of REST meaning) so I used singleton handle. Was I right? When the documentation says ""stateful"" it means that state informations are stored as fields in the ChannelHandler and thus its not possible to share the ChannelHandler between different Channels. If you have no state informations stored as fields you are ok to use it as Singelton.  You don't have a reason to instantiate new handlers if they are stateless. But in Http examples those handlers are stateful. They receive frame by frame from network and parse them into headers and what-not. Then if request is chunked Aggregator is combining chunks into single payload etc. In short unless you are building an echo server lower level handlers probably must be stateful but higher level need not."
773,A,Netty - how to receive and response image over http? May I know how Netty works with Image over http? Any sample or tutorial? Basically I want to know: 1) how to receive client's uploaded image 2) how to reply image by http response Image data is just like any other data; a stream of bytes (or octets to be precise) that is meaningful in terms of the Content-Type e.g. image/jpeg. Note also that the Content-Encoding might be of interest to handle compression/uncompression. There should be enough informaion in the example sources on netty.io to get you going.  Here is the example for receiving uploaded files. Here is the example for serving any type of files including image files. Hope this helps.
774,A,implement the message dependency in Netty all I'm using Netty to implement a client program which has to finish the handshaking process before it sends/receives data traffic from the server To ensure the correctness of handshaking process the server will send me a BARRIER message to indicate that all messages received before this BARRIER must be processed and answered before I process the messages after BARRIER Does netty provide any API to implement the requirement of this BARRIER? Thank you Best You would need to handle it in the ChannelInboundHandler implementation or ChannelUpstreamHandler implementation (depending on if you use Netty 4 or Netty 3). Hi Norman thank you for your answer. but how can I do it? how can I track if the messages before BARRIER has been processed?
775,A,netty client + keep-alive=true I'm confused for how to deal with lots of connections in netty (3.6.2.FINAL) and keep-alive=true. For work on a netty client as a server side connector making http calls to another service it wants to always keep the connection open for performance (keep-alive=true). The issue: there is a hard limit for number of open channels after which the client will hang when attempting to open a channel. Why no exception just hangs? Is this a setting in terms of channel timeout? I can't seem to understand Netty in terms of overall managing of connections within worker threads: With a blocking write/read client ChannelHandler (http request/response) how do you detect that the connection pool is empty? The handler can receive ChannelEvent(s) but nothing about the overall count available in the connection pool (its very non-deterministic anyway). And if the channel is not open does it make sense for the handler to initiate opening a new channel given its running in a worker thread? But if the connection pool is exhausted how do you go and cleanup some idle connections (within the handler)? I had to completely rip apart my handler to get the client blocking call to work without hanging. The issue was mostly resolved by not holding onto local channel ref within the handler. Now we just pass a ConnectionInterface#openConnection() [returns a new ChannelFuture] into the shared custom ChannelHandler#call( ConnectionInterface connectionInterface HttpRequest request ). Better to open-channel within the handler call method and to pass that channel along with checks on its state before channel.write(x) if !channel.isWritable() then recycle the channel (from a new client connection eg. ConnectionInterface#openConnection()) and retry the write. There isn't even a need to close the channel (it gets handled in the pool). Just ran it with 500 threads / 5000 requests and it succeeds fine.
776,A,"Netty - relationship between NioWorker pool and worker thread pool The context is Netty 3.5.x. What is the relationship between the number of NioWorkers and the number of the threads in the worker thread pool when an NioServerSocketChannelFactory or NioClientSocketChannelFactory is created? Does the design of Netty dictate that there should be at least as many threads available in the threadpool as the number of NioWorkers? What happens if you have a fewer number of threads in the thread-pool than the number of NioWorkers? Yes the relationship is 1:1. So you need to have at least as many threads as NioWorkers. If you have less it will throw an Exception of just ""hang"" when creating the *SocketChannelFactory depending on the Executor implementation. Thank you for your answer. In my experience if you have fewer threads in the threadpool than the number of `NioWorker`s the client or the server sometimes fails to complete connection requests for a long time (internally the registration task submitted by a boss thread seems to never get picked up). I wonder if it would make sense for Netty to not allow creations of `ChannelFactory` objects where the maximum number of threads in the thread pool is smaller than the number of `NioWorker`s. Currently it's really easy to make this mistake if you use the constructor that just takes in 2 executors (e.g. `NioClientSocketChannelFactory(Executor Executor)` -- by default Netty will create twice the number of `NioWorker`s as the number of processors and if the worker executor is unable to provide at least that many threads you get intermittent connection failures. Also if the association is really 1:1 that's probably something worth making explicit in the JavaDoc."
777,A,"unexpected message type: DefaultHttpRequest on a HttpClientCodec pipeline A second .write on the channel results in an exception ""io.netty.handler.codec.CodecException: java.lang.IllegalStateException: unexpected message type: DefaultHttpRequest"". Scratching my head what should be done differently given that the pipeline only has HttpClientCodec on it. Reproduces by cloning from Github and running main which runs the client and server sides reproducing the error. Which ""main"" needs to get run to reproduce ? runner.main which is found inside [main.scala](https://github.com/cloudaloe/pipe/blob/master/src/main/scala/main.scala). You have to write a DefaultFullHttpResponse. DefaultHttpResponse lacks content and HttpContents and a LastHttpContent must follow. I agree this is confusing indeed. I think you meant I should have used DefaultFullHttpRequest instead of DefaultHttpRequest - indeed switching to use `DefaultFullHttpRequest` seems to solve the problem (and now a new warning on the server side: Discarded 1 inbound message(s) that reached at the end of the pipeline. Please check your pipeline configuration."")."
778,A,"netty vs smart fox server There is a white paper comparison between these 2 servers in the area of MMO gaming backend. http://www.smartfoxserver.com/downloads/sfs2x/documents/SFS2X_WP_PerformanceAndScalability.pdf It doesn't seem there is a huge performance difference. In addition there are performance tests for Netty: http://www.jboss.org/netty/performance So should I choose smart fox server or netty? There is always pros and cons depending on personal situations. Because my game is aiming to host up to a million client smart fox server licenses maybe too expensive when you add it up. However assuming I run game on Amazon cloud even though the performance between the two is not that huge the server usage saving when you deploy a game in such a scale could be significant. On the one hand I do understand SFS is probably pretty optimized for gaming use but Netty is open source and can have it's advantages. Netty has Apache 2 license which means you can pretty much modify it and use it for your own commercial purposes. You can't modify SFS in anyway. Some features of SFS such as flooding room management and chatting are pretty much useless for a game of certain scale since you can write those lighting fast. What really is important is the socket engine performance. There are so many webpage MMO games on facebook but almost none uses SFS. I think two reasons: one is license fee may add up the other is you can't modify it for your own purposes. Zynga wouldn't use it since they want internal control over all their code and resources. I don't really know which is the best choice. Help me decide. I'v developed 3 SNS games the most popular one had about 1 million DAU once and max concurrent online user is about 100000. We just use Apache Tomcat 6 as our application server and it works well. One of my friends developed a SNS poker game with netty and I helped him solved some problem associated with netty. I find it is easy to debug and tuning performance with netty's source code. And netty also has a good community. I think netty should be a good choice. Your information is extremely helpful! Thanks so much! Web server is better at scaling than MMO server like Netty from what I read. ""http://gdcvault.com/play/1012230/Engineering_Scalable_Social_Games"" 1 million DAU is so impressive! You must be millionaire by now..  It is nowhere near what smartfox server is but I have developed a Netty game server which can deal flash TCP AMF3 and for non-flash clients TCP and UDP. It is uploaded to github you may find it interesting. Features like scaling out etc not yet completed. I am not appropriate guy to judge SFS but for Netty I can vouch that it is very well designed and for the most part very testable. Just look at the unit tests I have written to see how easy it is to do testing upfront when using Netty for your network protocol."
779,A,"Netty: ClientBootstrap connect retries I need to connect to a server which I know will be listening on a port. Although It could take some time to get operational. Is it possible to get ClientBootstrap to try to connect for a given number of tries or until a timeout is reached? At the moment if the connection is refused I get an exception but it should try to connect in background for example by respecting the ""connectTimeoutMillis"" bootstrap option. You need todo it by hand but thats not hard.. You could do something like this: final ClientBootstrap bs = new ClientBootstrap(...); final InetSocketAddress address = new InetSocketAddress(""remoteip"" 110); final int maxretries = 5; final AtomicInteger count = new AtomicInteger(); bs.connect(address).addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { if (count.incrementAndGet() > maxretries) { // fails to connect even after maxretries do something } else { // retry bs.connect(address).addListener(this); } } } }); I tried this code snippet and it seems to create lots of threads. If you put Thread.sleep(10*1000) and a println just before you try to reconnect using bootstrap you can see that more then one threads are printing that message and all of them are trying to connect to server as well. My code is almost same except Thread.sleep() before i try to reconnect and when it fails toconnect few times I can see that more then one threads are created and all of them are trying to connect. Here's my code http://pastebin.com/9mzgVkRd"
780,A,"Tic tac toe with websockets connection I am trying to make tic tac toe using websockets running on glassfish. I've download this example form git. Firstly I want to test it so I run it as a normal java process on my machine. I also made a tiny change to the tictacto.js  if (typeof MozWebSocket != ""undefined"") { // (window.MozWebSocket) appType = ""Mozilla""; } else if (window.WebSocket) { appType = ""Chrome""; } else { alert('ERROR: This browser does not support WebSockets'); } and then  if (appType == ""Mozilla"") { ws = new MozWebSocket(WEBSOCKET_URL); //alert('MozWebSocket'); } else { ws = new WebSocket(WEBSOCKET_URL); //alert('WebSocket'); } When I open the test page with FF 10.0 the event onclose is only invoked and I get the status ""The WebSocket Connection Has Been Closed."" then I open the test page with Chrome 17.0.963.46 m. The status is also ""The WebSocket...."" but server throws an exception. run: TicTacToe Server: Listening on port 9000 java.io.IOException: An established connection was aborted by the software in your host machine at sun.nio.ch.SocketDispatcher.read0(Native Method) at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:218) at sun.nio.ch.IOUtil.read(IOUtil.java:186) at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:323) at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:282) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:202) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) What is the cause? I though about a few possilbe issues: I use Netty 3.2.6.Final from JBoss repository. It could use different standard of websockets than the browsers. running it as a java process on my machine istead as a webserver. But Netty doesn't have any dependencies that would require it. Wrong locations. var WEBSOCKET_URL = ""ws://localhost:9000/websocket""; and html location is C:...web\kolo\src\main\webapp\t.html I am using Netbeans 7.1 and glassfish 3.1 Fixed project can be found https://github.com/lukasz-madon/Tic-Tac-Toe-with-WebSocket I could be the web socket version. Here's a table of web socket versions and which browser supports which. From memory 3.2.6 only supported HyBi-00. Try Netty 3.3. It supports a number of versions. Yes I've made this change thanks. Remember to use the WebSocketX package (and not the WebSocket package which has been left in for backwards compatibility). Yes the problem was with the wrong version."
781,A,"Netty: how do I reduce delay between consecutive messages from the server? I'm on the dev team for a socket server which uses Netty. When a client sends a request and the server sends a single response the round trip time is quite fast. (GOOD) We recently noticed that if the request from the client triggers two messages from the server even though the server writes both messages to the client at about the same time there is a delay of more than 200ms between the first and second message arriving on the remote client. When using a local client the two messages arrive at the same time. If the remote client sends another request before the second message from the server arrives that second message is sent immediately but then the two messages from the new request are both sent with the delay of over 200ms. Since it was noticed while using Netty 3.3.1 I tried upgrading to Netty 3.6.5 but I still see the same behavior. We are using NIO not OIO because we need to be able to support large numbers of concurrent clients. Is there a setting that we need to configure that will reduce that 200+ ms delay? editing to add a code snippet. I hope these are the most relevant parts. @Override public boolean openListener(final Protocol protocol InetSocketAddress inetSocketAddress) throws Exception { ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool() threadingConfiguration.getProcessorThreadCount()); ServerBootstrap bootstrap = new ServerBootstrap(factory); final ChannelGroup channelGroup = new DefaultChannelGroup(); bootstrap.setPipelineFactory(new ChannelPipelineFactory() { .... lots of pipeline setup snipped ...... }); Channel channel = bootstrap.bind(inetSocketAddress); channelGroup.add(channel); channelGroups.add(channelGroup); bootstraps.add(bootstrap); return true; } The writer factory uses ChannelBuffers.dynamicBuffer(defaultMessageSize) for the buffer and when we write a message it's Channels.write(channel msg). What else would be useful? The developer who migrated the code to Netty is not currently available and I'm trying to fill in. Could you supply the applicable parts of your code? When you say that both messages are written at about the same time do you mean that `channel.write()` was invoked directly and completed for both requests at about the same time or is there a layer in between this that is managing the writes in your code? @increment1 : When I turned on debug level logging for the HexLoggingHandler it logged each message immediately before calling super.writeRequested(ctx e); where the super is SimpleChannelHandler. The timestamps were 1 or 2 ms apart usually in my tests. Are you sure the delay is on the server side? Have you inspected the actual netowrk traffic with for example Wireshark? Another observation: You seem to be creating a new ServerSocketFactory for each listener. That's expensive. Listeners of the same kind should probably share the same factory. Wireshark on the client machine confirmed that the second message was arriving significantly later. 200ms strikes me as the magic number of the Nagle's algorithm. Try setting the TcpNoDelay to true on both sides. This is how you set the option for the server side.  serverBootstrap.setOption(""child.tcpNoDelay"" true); This is for the client side.  clientBootStrap.setOption(""tcpNoDelay"" true); Further reading: http://www.stuartcheshire.org/papers/NagleDelayedAck/ Will try that first thing tomorrow - thanks! Thanks so much @Timmy ! That's exactly what I needed!"
782,A,"Flash binary socket communication with netty Can some body point me to make a flash binary socket client for netyy server? You can find numerous examples of this on the net anyway pasting some code tidbits here. import flash.net.Socket; private var remoteHost:String; private var portNumber:int; // Create a new Socket object and assign event listeners. socket = new Socket(); socket.addEventListener(Event.CONNECT connectHandler); socket.addEventListener(Event.CLOSE closeHandler); socket.addEventListener(ErrorEvent.ERROR errorHandler); socket.addEventListener(IOErrorEvent.IO_ERROR ioErrorHandler); A function to connect to netty server public function connect():Boolean { // Load policy file from remote server. //Security.loadPolicyFile(""xmlsocket://"" + remoteHost + "":"" + policyPort); // Attempt to connect to remote socket server. try { trace(""Trying to connect to "" + remoteHost + "":"" + portNumber + ""\n""); socket.connect(remoteHost portNumber); } catch (error:Error) { /* Unable to connect to remote server display error message and close connection. */ trace(error.message + ""\n""); socket.close(); return false; } return true; } A function that does login functionality to a netty game server that I created. You can ignore the login etc just trying to show how it works with netty. To see the actual java game server code goto github link provided.  private function connectHandler(event:Event):void { if (socket.connected) { socket.addEventListener(ProgressEvent.SOCKET_DATA loginHandler); var payLoad:ByteArray = new ByteArray(); payLoad.writeByte(LOG_IN);//opcode sent back to netty server in my implementation payLoad.writeBytes(encodeMultiStrings(user pass roomName));// credentials trace(""Payload length before encode is: "" + payLoad.length); var login:ByteArray = encodeBytes(payLoad); trace (""Login bytes length: "" + login.length); writeBytesToSocket(login); }else { trace(""unable to connect\n""); } }"
783,A,"Netty - Make all created buffers be little-endian by default I need to create channelbuffers in Netty in little-endian byte format by default and to what I understand I use this piece of code. bootstrap.setOption(""child.bufferFactory"" new HeapChannelBufferFactory(ByteOrder.LITTLE_ENDIAN)); However when I created new channel buffers they are big-endian and thus I must make them little-endian manually. Is there a way to make all channel buffers be little-endian by default? Thank you! EDIT: I'm creating buffers like such: ChannelBuffer opcodeBuffer = ChannelBuffers.buffer(ByteOrder.LITTLE_ENDIAN 4); If I create them like this ChannelBuffer opcodeBuffer = ChannelBuffers.buffer(4); They are not little-endian This should work. Is this a `ClientBootstrap` or a `ServerBootstrap`? A server bootstrap. I print out the byte order of the bufferfactory and it says little-endian however if I say make 2 buffers one with a littleendian byte order and one just normally they say byte order mismatch. I have to manually make all of them little endian and then ill get the correct packet creation. Can you show how you are creating the buffers? Edited the main question... The setting that you are using is for configuring the buffers created by Channel objects in your app. This means that every backing buffer created by Netty will be little endian. ChannelBuffers is a static helper class which cannot use the configuration from the bootstrap. If you check the docs you can see that the methods which don't take a ByteOrder say that they are making big-endian buffers explicitly. So if you are making the buffers manually make sure to use the right endianness. Alternatively you can use one of the ChannelBufferFactory implementations in your code to be able to switch easily (if needed). I know it seems crude but would I be able to just edit the channelbuffers class to always make littleendian buffers? Not with breaking a lot of code that depends on it making big-endian ones. I'm afraid you'll have to live with it :). Yeah I've changed my code around and got to be much faster and better. Previously I wasn't making the channelbuffers in my messagecodecs little-endian. Now I'm doing that and i don't have the overhead of flipping it later in my encoder class. BTW thanks for all your help!"
784,A,How to use netty in webapp for permanent TCP remote connection? Because of some legacy requirements we need to keep an open TCP socket to a legacy system and exchange some messages with it asynchronously. We have a webapp that receives requests from the web and currently a separate Java app that includes Netty which does legacy communication. We would now like to somehow embed Netty directly into the webapp package so that the socket is started when the webapp runs and so that webapp (or EJB) and interact with netty Channels etc. Do you have an idea how to do this? So what I wish to accomplish is throw away JMS queues that we are right now using for integrating netty/legacy part of functionality with the web-facing functionality in other words I wish to significantly simplify the architecture so that only webapp+EJBs are used but not JMS. Assuming that the Servlet container you run has no SecurityManagerconfigured you can start a Netty application as a part of your web application. First off write a ServletContextListener implementation that is notified when your web application is started or stopped by the Servlet container. You can start and stop your Netty application there. You also should probably update the web.xml so that the Servlet container picks it up. To make the Netty application interact with your web application (e.g. send a message to the legacy system via the Netty application) you'll have to expose your Netty application to your Web application. This is usually done via a singleton. Because every operation in Netty is asynchronous you might experience some 'impedance mismatch' between your web application and the Netty application. Typically the web application will ask the Netty application send a request to the legacy system and wait until the Netty applications notifies when the response is received from the legacy system. To deal with this scenario you can usually use a data structure such as BlockingQueue - after sending a request the web application waits until the queue has an element and the Netty application will add the response object to the queue to notify the web application. If you are using Netty 4 you might want to take a look at the io.netty.util.concurrent.Future/Promise classes which are also a very useful construct for such a scenario. Hi there Trustin. How would I solve the problem of communication with the legacy system being async in nature? I.e. Web requests is received and I need to return a sync response -> but in the meantime netty (deployed as you suggested above) has to contact the legacy server and receive the response that I can read in the servlet. Do I need to poll for result in servlet? Answer updated. :-)
785,A,Netty 4 WebSocket App Threads Synchronization I have a websocket application I am working on. Here is the code for the Netty Handler. In it the websockets connect to a long running thread which collects them and passes back messages. My question concerns synchronization. So when the Netty app adds a new ctx to the thread I use a lock to synchronize add/remove/iteration of the list. I don't think there is any other way around this locking. So my question is are there any better ways to handle this sort of synchronization to the thread? Also is there any major performance drawbacks to doing this locking? What sort of issues can that cause? I think what you want to use is the DefaultChannelGroup[1] for group channels and write to all of them. Another cool thing about it is that the Channel will get removed automatically once it close. [1] http://netty.io/4.0/api/io/netty/channel/group/DefaultChannelGroup.html btw does netty use epoll or libevent or? Thanks Norman! That is exactly what I want. I will use this for the interim between the Threaded app and the connections. @user1361315 It uses epoll via Java NIO API.
786,A,"Netty dynamic pipeline configuration This may be a ""newb"" question but here it goes anyway. We have a netty server up and running and we want it to support multiple different protocols like straight tcp http udp etc.. I am trying to write a class to be more dynamic what handlers/decoders/encoders we add to the pipeline on every request so we only add the layers we need depending on what type of traffic it is. I've got straight tcp figured out because we are encoding special bytes but I'm having a hard time coming up with a clever way to tell if its HTTP traffic vs straight tcp based off a ChannelBuffer or byte array. My thoughts have been along the line of reading in some bytes and looking for a string like 'GET' or 'POST' I assume a HTTPRequest would have these items somewhere.. Is what I'm trying to do worth it? Or anyone have any helpful ideas? I think you want to have a look at the portunification example where we do something like what you want to do. In short it's possible to do what you want. For more infos and more details please check the example at [1]. [1] https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/portunification/PortUnificationServerHandler.java this is perfecto!!! thank you soo much!!"
787,A,How to record log in Netty I would like to implement a handler that records time from getting a request to sending a response. Is there a handler already implemented in Netty that does similar task? (I can't find a way to do it with LoggingHandler...) No there is not such a handler included. You will need to do it by your own.
788,A,"What is the best approach to bind to different port / each port has different handler in Netty? I want to build an application based on Netty but need to bind to different ports at the same time and each port needs to have a different handler logic. How to do this in Netty? I searched online and know that I can probably do bind(hostport) multiple times but that stills mean all ports will use the same handler pipeline. Thank you very much I don't think that's true. Handlers are attached to channels they aren't global. You simply create several ServerBootstrap instances using a single ChannelFactory. For example:  NioServerSocketChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); ServerBootstrap bootstrap1 = new ServerBootstrap(factory); bootstrap1.setPipelineFactory(...); bootstrap1.bind(new InetSocketAddress(port1)); ServerBootstrap bootstrap2 = new ServerBootstrap(factory); bootstrap2.setPipelineFactory(...); bootstrap2.bind(new InetSocketAddress(port2)); Or you can dynamically modify the pipeline. For example in the channelBoundcallback: @Override public void channelBound(ChannelHandlerContext ctx ChannelStateEvent e) throws Exception { ctx.getPipeline().addLast(""new"" new SimpleChannelUpstreamHandler() { @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { ... } }); } thank you very much"
789,A,"Is it safe to pass the same ExecutorService instance to multiple NioServerSocketChannelFactory in Netty I have a tcp server running at port xxxx and flash policy server(again tcp) at port 843. Is it ok if I pass the same ExecutorService instance while creating the server bootstrap's for both servers? Will it lead to data corruption? ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory(""TCP-Server-Boss"") ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory(""TCP-Server-Worker"") serverBootstrap = new ServerBootstrap(new NioServerSocketChannelFactory(bossworker)) Now I want to pass the same boss and worker to the flash policy servers serverBootstrap. Is this a valid usage? The ExecutorService returned by newCachedThreadPool() is not guaranteed to be threadsafe anywhere in the documentation. So it would be the correct action to create two new ExecutorServices. Im quite sure the instances returned are threadsafe regardless of the documentation but I would still make two new ExecutorServices with different names to ease debugging and readability. Assuming im correct it will still attempt to get the same amount of threads. Wether it will succeed is another matter. Using a fixed thread pool is most likely a bad idea. Its better to configure how many threads Netty should use and let the pool be unbounded. The reason I asked the q was that the flash policy server would have very little traffic and creating dedicated threads for it looked like a waste. Anyway thanks for the a. I dont think you would achieve that regardless. I think Netty is only using the `ExecutorService` as a thread factory so even if they share the `Executor` they would still both occupy a thread each for the duration of the server. Not if I pass in a fixed thread pool executor right? Executors.newsinglethreadexecutor"
790,A,"Netty nested pipelines / multiplexing I'm pretty new to Netty but how would one implement a case in Netty 4.x when several protocols (e.g. P1 and P2) are encapsulated inside another protocol?  +-------------+ | decoder | +-------------+ | encoder | +-------------+ | muxer | +-------------+ | demuxer | +---+------+--+ | | | | +------+ +------+ | | | | v v +-------------+ +-------------+ | P1 decoder | | P2 decoder | +-------------+ +-------------+ | P1 encoder | | P2 encoder | +-------------+ +-------------+ | P1 handler | | P2 handler | +-------------+ +-------------+ Is there a way to create nested pipelines so that decoder<->encoder<->muxer<->demuxer being the main pipeline would send the data along P1 or P2 pipeline based on the decision of demuxer? Or maybe there is a way to somehow create (for the sake of clarity) ""subchannels"" with their own pipelines? There is no support for ""nested Pipelines"" yet. It may be part of 4.1.0. For now you need to remove/add handlers on the fly. See [1] for an example. [1] https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/portunification/PortUnificationServerHandler.java"
791,A,Netty UDP Session Management I am having some problems setting up a session management system for UDP with the Netty framework. I am confused about what is new per UDP remote client. For every new UDP remote client does that client get a new ChannelPipelineFactory or is a new Channel created per new remote client? I have 2 ports port 161 and port 162 that are both UDP ports and both will be receiving data from numerous UDP clients. How can I differentiate between the clients? I started to create a session management service based on RemoteAddress provided by DatagramPacket.sender() but I don't know if it's safe to attach to the ChannelHandlerContext attribute() chain. Since UDP is connection less the DatagramPacket.sender will be your only option to route messages to the appropriate session. There is conceptually only one ChannelPipelineFactory and in fact only one Channel for UDP for the application. As far as I know it is not safe to attach the ChannelHandlerContext. The way to deal with multiple clients is to use a Map with the key as the DatagramPacket.sender address and value as your session. Thank you I thought that was the only way to go about it but wasn't entirely sure.
792,A,"Basic Netty echo server - string encoder error? This is my first time using Netty and I'm having trouble making a simple echo server! I looked at docs and it says to use the string encoder and decoder which I am not using properly apparently. For the framedecoder I'd like to use the header messages with one byte length but that doesn't seem to be working either due to the string issue. I assume my implementation of the PipelineFactory is messed up. Bonus Question: Because I'm stupid and ambitious I tried implementing a timeout/heartbeat handler. That didn't work either. Here are the console output and java code: Console: >>telnet localhost 6969 Trying 127.0.0.1... Connected to localhost. Escape character is '^]'. >>3 Connection closed by foreign host. Java Console: Starting server on 6969 channelConnected channelDisconnected java.lang.IllegalArgumentException: unsupported message type: class java.lang.String at org.jboss.netty.channel.socket.nio.SocketSendBufferPool.acquire(SocketSendBufferPool.java:51) at org.jboss.netty.channel.socket.nio.NioWorker.write0(NioWorker.java:455) ... Server.java public class Server { public static void main(String[] args) throws Exception { ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); ServerBootstrap bootstrap = new ServerBootstrap(factory); Timer timer = new HashedWheelTimer(); bootstrap.setPipelineFactory(new MyPipelineFactory(timer) { public ChannelPipeline getPipeline() { return Channels.pipeline(new ServerHandler()); } }); bootstrap.setOption(""child.tcpNoDelay"" true); bootstrap.setOption(""child.keepAlive"" true); bootstrap.bind(new InetSocketAddress(6969)); System.out.println(""Starting server on 6969""); } } ServerHandler.java public class ServerHandler extends SimpleChannelHandler { @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e){ Channel ch = e.getChannel(); System.out.println(""channelConnected""); } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e){ Channel ch = e.getChannel(); System.out.println(""channelDisconnected""); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { String msg = (String) e.getMessage(); e.getChannel().write(""Did you say '"" + msg + ""'?\n""); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { e.getCause().printStackTrace(); Channel ch = e.getChannel(); ch.close(); } } MyPipelineFactory.java public class MyPipelineFactory implements ChannelPipelineFactory { private final Timer timer; private static ChannelHandler idleStateHandler; public MyPipelineFactory(Timer t) { this.timer = t; //this.idleStateHandler = new IdleStateHandler(timer 5 20 0); // timer must be shared } public ChannelPipeline getPipeline() { // create default pipeline from static method ChannelPipeline pipeline = Channels.pipeline(); // Decoders int maxFrameLength = 1024; pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(maxFrameLength Delimiters.lineDelimiter())); //pipeline.addLast(""frameDecoder"" new LengthFieldBasedFrameDecoder(maxFrameLength01)); // get header from message pipeline.addLast(""stringDecoder"" new StringDecoder(CharsetUtil.UTF_8)); // Encoders pipeline.addLast(""stringEncoder"" new StringEncoder(CharsetUtil.UTF_8)); // Idle state handling- heartbeat //pipeline.addLast(""idleStateHandler"" idleStateHandler); return pipeline; } } Bonus because I'm stupid and want to get in over my head... HeartbeatHandler.java public class HeartbeatHandler extends IdleStateAwareChannelHandler { @Override public void channelIdle(ChannelHandlerContext ctx IdleStateEvent e) { if (e.getState() == IdleState.READER_IDLE) { System.out.println(""Reader idle closing channel""); e.getChannel().close(); } else if (e.getState() == IdleState.WRITER_IDLE) { System.out.println(""Writer idle sending heartbeat""); e.getChannel().write(""heartbeat""); // } } } It's because you mess up the ChannelPipeline. You use:  bootstrap.setPipelineFactory(new MyPipelineFactory(timer) { public ChannelPipeline getPipeline() { return Channels.pipeline(new ServerHandler()); } }); What you would need todo is modify the MyPipelineFactory class and add your ServerHandler in there. Then just set it like:  bootstrap.setPipelineFactory(new MyPipelineFactory(timer)); Then everything should work. Even your timeout stuff ;) I tried setting `ChannelPipeline pipeline = Channels.pipeline(new ServerHandler());` instead of `ChannelPipeline pipeline = Channels.pipeline();` which gave me the same string error. I also tried making the ServerHandler a class variable and passing that to the Channel.pipeline. I'm clearly missing something. Yeah you missed to also add the other needed handlers in the pipeline like DelimiterBasedFrameDecoder StringEncoder StringDecoder etc. That's what MyChannelPipeline does. Ah that makes sense. And the serverhandler of course needs to be last. Heartbeat doesn't work but I'll post another question for this Here's the new question: http://stackoverflow.com/questions/9289595/trouble-with-netty-idlestatehandler-am-i-testing-it-the-wrong-way"
793,A,"Chat Server with Java & Netty I want to implement a Chat Server with Java and Netty. My question is: should I make all the work in Netty's connection handler? For ""all the work"" I mean for example: to do the login ( so with mysql connection ) eventually to send message to log informations.. If you put all that functionality into interface-based POJOs rather than a Netty connection handler you'll find it easier to test it without having to fire up Netty. Once you have all those objects working and tested then give them to a connection handler and let them do the work. The connection handler just orchestrates your POJOs to fulfill its requests.  I think a more robust design would be to make a system that works without Netty and then use Netty's connection handler to go between the two. This way if you decide to move away from Netty in the future you can do so with minimal rewiring. Agreed. Nice answer. Thanks for the clarification. +1 - Great minds thinking alike. To be fair we had different reasons. :) Yours was for easier testing. Mine was for easier migration. Both are something you need to keep in mind when designing software."
794,A,"Handling multiple certificates in Netty's SSL Handler used in Play Framework 1.2.7 I have a Java Key Store where I store certificates for each of my customer's sub-domain. I am planning to use the server alias to differentiate between multiple customers in the key store as suggested here. Play framework 1.2.7 uses Netty's SslHandler to support SSL on the server-side. I tried implementing a custom SslHttpServerContextFactory that uses this solution. import play.Play; import javax.net.ssl.*; import java.io.FileInputStream; import java.net.InetAddress; import java.net.Socket; import java.security.KeyStore; import java.security.Principal; import java.security.PrivateKey; import java.security.Security; import java.security.cert.X509Certificate; import java.util.Properties; public class CustomSslHttpServerContextFactory { private static final String PROTOCOL = ""SSL""; private static final SSLContext SERVER_CONTEXT; static { String algorithm = Security.getProperty(""ssl.KeyManagerFactory.algorithm""); if (algorithm == null) { algorithm = ""SunX509""; } SSLContext serverContext = null; KeyStore ks = null; try { final Properties p = Play.configuration; // Try to load it from the keystore ks = KeyStore.getInstance(p.getProperty(""keystore.algorithm"" ""JKS"")); // Load the file from the conf char[] certificatePassword = p.getProperty(""keystore.password"" ""secret"").toCharArray(); ks.load(new FileInputStream(Play.getFile(p.getProperty(""keystore.file"" ""conf/certificate.jks""))) certificatePassword); // Set up key manager factory to use our key store KeyManagerFactory kmf = KeyManagerFactory.getInstance(algorithm); kmf.init(ks certificatePassword); TrustManagerFactory tmf = TrustManagerFactory.getInstance(algorithm); tmf.init(ks); final X509KeyManager origKm = (X509KeyManager) kmf.getKeyManagers()[0]; X509KeyManager km = new X509KeyManagerWrapper(origKm); // Initialize the SSLContext to work with our key managers. serverContext = SSLContext.getInstance(PROTOCOL); serverContext.init(new KeyManager[]{km} tmf.getTrustManagers() null); } catch (Exception e) { throw new Error(""Failed to initialize the server-side SSLContext"" e); } SERVER_CONTEXT = serverContext; } public static SSLContext getServerContext() { return SERVER_CONTEXT; } public static class X509KeyManagerWrapper implements X509KeyManager { final X509KeyManager origKm; public X509KeyManagerWrapper(X509KeyManager origKm) { this.origKm = origKm; } public String chooseServerAlias(String keyType Principal[] issuers Socket socket) { InetAddress remoteAddress = socket.getInetAddress(); //TODO: Implement alias selection based on remoteAddress return origKm.chooseServerAlias(keyType issuers socket); } @Override public String chooseClientAlias(String[] keyType Principal[] issuers Socket socket) { return origKm.chooseClientAlias(keyType issuers socket); } @Override public String[] getClientAliases(String s Principal[] principals) { return origKm.getClientAliases(s principals); } @Override public String[] getServerAliases(String s Principal[] principals) { return origKm.getServerAliases(s principals); } @Override public X509Certificate[] getCertificateChain(String s) { return origKm.getCertificateChain(s); } @Override public PrivateKey getPrivateKey(String s) { return origKm.getPrivateKey(s); } } } But this approach did not work for some reason. I get this message in my SSL debug log. X509KeyManager passed to SSLContext.init(): need an X509ExtendedKeyManager for SSLEngine use This is the SSL trace which fails with ""no cipher suites in common"". Now I switched the wrapper to: public static class X509KeyManagerWrapper extends X509ExtendedKeyManager With this change I got rid of the warning but I still see the same error as before ""no cipher suites in common"" and here is the SSL trace. I am not sure why the delegation of key manager won't work. Some more information that may be useful in this context. Netty uses javax.net.ssl.SSLEngine to support SSL in NIO server. As per the recommendation in this bug report it is intentional that X509ExtendedKeyManager must be used with an SSLEngine. So the wrapper must extend X509ExtendedKeyManager. This is hindering me to move further with the custom alias selection logic in X509KeyManagerWrapper. Any clues on what might be happening here? Is there any other way to implement this in Netty/Play? Appreciate any suggestions. SSLEngine uses the chooseEngineServerAlias method to pick the certificate to use (in server mode) - not the chooseServerAlias method. The default chooseEngineServerAlias implementation actually returns null which is what causes the ""no cipher suites in common"" message - you need a certificate to know which cipher suites can be used (e.g. ECDSA can only be used for authentication if the certificate has an ECC public key etc.) There are actually some cipher suites which can be used without a certificate however these are typically disabled as they are vulnerable to MITM attacks. Therefore you should also override chooseEngineServerAlias and implement your logic to select the certificate based on the IP address there. As Netty only uses SSLEngine what chooseServerAlias does doesn't matter - it'll never be called. Java 8 also has support for server-side SNI which allows you to use several certificates across many hostnames with a single IP address. Most web browsers support SNI - the notable exceptions are IE running on Windows XP and some old versions of Android however usage of these is declining. I have created a small example application demonstrating how to use SNI in Netty on GitHub. The core part of how it works is by overriding chooseEngineServerAlias - which should give you enough hints even if you want to use the one certificate per IP address technique instead of SNI. (I posted a similar answer to this on the Netty mailing list where you also asked this question - however my post seems to have not yet been approved so I thought I'd answer here too so you can get an answer sooner.) Thanks Graham. You nailed it! I knew the only way to support this use case with Java based servers is to use Java 8 SNI server-side support. I finally ended up choosing Nginx [SNI](http://nginx.org/en/docs/http/configuring_https_servers.html#sni) to implement this requirement which was an easier option and nicely fronts Play 1.2.7/Netty and [configuration](http://nginx.org/en/docs/http/configuring_https_servers.html#sni) was super simple. But your solution is highly extensible and easier to integrate with Netty. Appreciate your effort in putting together a working example."
795,A,netty 4: set default endianness of ByteBuf Is there a way to tell Netty 4 that all ByteBuf instances it creates should have LITTLE_ENDIAN endianness? Calling order(ByteOrder) in every handler is annoying. It looks like Netty 3 supported this: Netty and ByteOrder I wouldn't expect one: big-endian is the ordering of network protocols so makes sense as the default. And exposing a static variable to set the default would be an invitation for hard-to-diagnose bugs (particularly in a shared server). I think your best approach is to create a new factory class to produce the buffers you need. Assuming that you're currently using Unpooled (per recommendation) it should be a simple search-and replace operation. You could also update Unpooled itself providing variants that take a byte-order param and submit it back to the project. I changed my original post to add a reference to a way to do it in Netty 3. BTW: I do have an existing network protocol with a working NIO impl server-side. I just want to replace that with Netty.
796,A,simple Java api to form and send ntp packet We should feed some system under test with ntp data that we should control. Since the testing environment is mainly java-oriented it would be perfect to find and reuse any java code that forms and send ntp packets. There is no matter how precise this server side would be since the main idea of the test to provide the mocked time through via ntp packets. Is there any ntp java library or may be example especially for netty usage? I would appreciate for any suggestions. Thanks in advance! UPD. Since the question is taken to 'on hold' (I don't understand why ntp + java seems to be too familiar to local folks but not to me) I'd like to summarize it to simple question: Is there Java API that can provide ntp server packets on ntp client dmand being simple like NTPPacket ntpp=new NTPPacket(new Time()); while all other wirings will be default? Ho-ho I see some haters already started their downvotes; it seems they just see the title but not the details of the issues (I really dislike this kind of haters) I have even to remove 'java' tag here. So my suggestion that I can reuse http://mvnrepository.com/artifact/org.apache.directory.server/apacheds-protocol-ntp/2.0.0-M15 for this purpose
797,A,"Netty and SSL websocket client I'm struggling with Netty 4.0.8 Websocket client example and SSL and I can't seem to be able to send data to the Netty SSL websocket server example. Although there have been many posts around this issue (I went through all I believe) and the most common suggestion is to just add an sslHandler to the beginning of the pipeline it doesn't work. Handshake seems to be successful as it is also indicated to a relevant question here. I remember being in the same situation with version 4.0.0 but I somehow managed to get it working. However things (and API) changed when I upgraded to 4.0.8. Can the Netty developers add a working Websocket SSL client example to the examples? Many people struggle with this issue and that would be useful. Maybe the solution is just too simple but an example would clear things. Again sorry for reposting a question that might be already there but the relevant question has also been unanswered and my reputation is just too low to add a comment to other relevant questions :) Please open an issue as ""feature request"" so we can add it as soon as we have the cycles. I seem to have found a solution to my own question. The sample code on the client uses the channel.write() method which seems not to send the messages to the Websocket ssl server. By using the channel.writeAndFlush() instead messages are correctly sent to the server."
798,A,How to implement the http chunked feature in netty 4 I'm upgrading some of my http client code from netty3 to netty4. In netty3 it is every easy for me to enable or disable the chunked feature by calling the setChunked method of HttpRequest. It's look like I have to deal the HttpContent message myself if I want to enable or disable the Chunked feature in netty4. Is there any thing that I'm missing? With the help of io.netty.handler.codec.http.HttpObjectAggregator we can always get the Aggregated FullHttpRequest just like we do in Netty3.  I am afraid: Yes. Netty 4 refactor a lot about Http Chunk.
799,A,"Changing Netty 4 HTTP File Server example to use ChunkedStream instead of ChunkedFile I'm trying to wrap my head around Netty 4 way of implementing a HTTP Server that serve HttpResponses bodies using chunked transfer-encoding when total data size is unknown. As a starting point I simply changed the HttpStaticFileServerHandler (found in https://github.com/netty/netty/tree/netty-4.0.0.CR1/example/src/main/java/io/netty/example/http/file) to use a ChunkedStream instead of a ChunkedFile (they both are ChunkedByteInputs). I understand that it is not ideal in the original example use case to use a FileInputStream but I think it makes a good example reusing already known code. So here is the diff against the HttpStaticFileServerHandler class from the io.netty.example.http.file package (vs. 4.0.0.CR1): diff --git a/example/src/main/java/io/netty/example/http/file/HttpStaticFileServerHandler.java b/example/src/main/java/io/netty/example/http/file/HttpStaticFileServerHandler.java index 904579b..0d3592f 100644 --- a/example/src/main/java/io/netty/example/http/file/HttpStaticFileServerHandler.java +++ b/example/src/main/java/io/netty/example/http/file/HttpStaticFileServerHandler.java @@ -2713 +2714 @@ import io.netty.handler.codec.http.FullHttpResponse; import io.netty.handler.codec.http.HttpHeaders; import io.netty.handler.codec.http.HttpResponse; import io.netty.handler.codec.http.HttpResponseStatus; -import io.netty.handler.stream.ChunkedFile; +import io.netty.handler.stream.ChunkedStream; import io.netty.util.CharsetUtil; import javax.activation.MimetypesFileTypeMap; import java.io.File; +import java.io.FileInputStream; import java.io.FileNotFoundException; -import java.io.RandomAccessFile; +import java.io.InputStream; import java.io.UnsupportedEncodingException; import java.net.URLDecoder; import java.text.SimpleDateFormat; @@ -15917 +16015 @@ public class HttpStaticFileServerHandler extends ChannelInboundMessageHandlerAda } } - RandomAccessFile raf; + InputStream raf; // Use an InputStream instead of a RandomAccessFile try { - raf = new RandomAccessFile(file ""r""); + raf = new FileInputStream(file); } catch (FileNotFoundException fnfe) { sendError(ctx NOT_FOUND); return; } - long fileLength = raf.length(); HttpResponse response = new DefaultHttpResponse(HTTP_1_1 OK); - setContentLength(response fileLength); setContentTypeHeader(response file); setDateAndCacheHeaders(response file); if (isKeepAlive(request)) { @@ -1807 +1797 @@ public class HttpStaticFileServerHandler extends ChannelInboundMessageHandlerAda ctx.write(response); // Write the content. - ChannelFuture writeFuture = ctx.write(new ChunkedFile(raf 0 fileLength 8192)); + ChannelFuture writeFuture = ctx.write(new ChunkedStream(raf)); // Use a ChunkedStream instead of a ChunkedFile // Decide whether to close the connection or not. if (!isKeepAlive(request)) { And here the complete changed file: https://gist.github.com/eskatos/5311587 Changes are minimal: use a FileInputStream instead of RandomAccessFile and ChunkedStream instead of ChunkedFile. The pipeline is untouched. To reproduce simply apply the changes to the Netty example run it and try do download any file. After this change directory listing obviously works because reponses are not chunked but file downloads don't. The client download the file but never finish the download hold the connection and wait forever. I've tried several from browsers to curl wget etc.. I've also tried to add a ByteLoggingHandler to the pipeline and I can see an empty trailing chunk so I don't understand why the browser still wait for data. Any clue? In order to terminate a chunked transfer of unkown size (Content-Length not known and thus not specified) you simply send an empty chunk as last chunk. This permits to keep the connection open in order to support keepalives:  ctx.write(new ChunkedInputAdapter(new ChunkedStream(raf 8192))); ChannelFuture writeFuture = ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT); Here is a complete example: https://github.com/scireum/sirius/blob/develop/web/src/sirius/web/http/Response.java#L649 We recently added a `ChunkedInput` implementation dedicated to this: https://github.com/netty/netty/blob/master/codec-http/src/main/java/io/netty/handler/codec/http/HttpChunkedInput.java Good to see: As it happens I already ended up doing to same to resolve issues with content compression: http://andreas.haufler.info/2014/01/making-http-content-compression-work-in.html. Maybe you guys could also improve the HttpContentCompressor (no compression of jpeg zip etc. or tiny files...) I'll be happy to provide a pull request... Sure! Let me look forward to your pull request/feature suggestion etc.  If you do not specify Content-Length header the client has no idea about the length of the content you are sending and thus it waits until the server closes the connection and everything received until the disconnection is considered as the content. Therefore you must do one of the following: Add Content-Length header Close the connection after sending the content Send the content using chunked encoding with the Transfer-Encoding: chunked header HTTP 1.1 allows for there to be no Content-Length header and the use of chunked encoding. http://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4.4"
800,A,"Netty : Blocking call to get a connected Server Channel? The call on ServerBootstrap.bind() returns a Channel but this is not in a Connected status and thus cannot be used for writing to client. All the examples in Netty documentation show writing to a Channel from its ChannelHandler's events like channelConnected - I want to be able to get a connected Channel not in the event but as a reference outside the event  lets say some client code using my server component. One way is to manually code for waiting for channelConnected event and then copying the Channel reference.But this may be reinventing the wheel. So the question is : Is there a blocking call available in Netty that returns a Connected Channel ? edit : I am using Oio Channels  not Nio. Why? You can't get a channel to a client till he connects and that comes to you as a connect event. Why do you think you need another mechanism? and why a blocking mechanism? This doesn't make any sense. I know I cannot get a connected channel until the client connects .. thats exactly why I mention blocking .. lets say there is an external interface that wants a connected channel ( for writing something ) . the server has to wait ( block) until client connects and return this connected channel.. which part does not make sense ? None of it makes sense. If it's a client connection you can't force it to happen you have to process the inbound connection event as it arrives. Are you possibly talking about an *outbound* connection? To another *server?* Its not outbound. The server indeed is listening for clients to connect and they will eventually connect  which is when the event will get fired  and connection will be established. But the server has also to serve another external interface that is interested in writing to clients ( thru the server ) and which has its own timing for requesting a channel .. now when this external interface calls the server for a connected channel  the server has to block this call until a client establishes a connection .. does that help a bit ? I have thought of a synch thread and a blocking queue approach. If Netty has anything like what a java.net.ServerSocket has ( a blocking call that returns a Channel that is ready to be used for writing ) then I can use that API as well. - thats why my question ..too bad to know there no such API.. You could create a blocking call but I think you maligned the event based approach too quickly. This is a contrived example just to make sure I understand what you're trying to do: Netty Server starts A DataPusher service starts. When a client connects the DataPusher grabs a reference to the client channel and writes some data to it. The client receives the pushed data shortly after connecting. More or less correct ? To do this your DataPusher (or better yet one of its minions) can be registered as a ChannelHandler in the server pipeline you create. Make it extend org.jboss.netty.channel.SimpleChannelHandler. The handler might look like this: DataPusher dataPusher = getMyDataPusherReference(); public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) { dataPusher.doYourThing(e.getChannel()); // do something in another thread.... } If you are determined to make it a blocking call from the DataPusher's perspective just have it wait on a latch and have the minion drop the latch. Not sure if that's what your'e looking for..... You figured out my use case more or less correct. Now the solution you mention  the issue with that is : the DataPusher is not as simple as it sounds. it has a set of connected activities to do and all this means it is best to hand it a channel to write rather than trying to squeeze its nature into a ChannelHandler mould. Right. The handler can be simply ""DataPusher"" aware so it knows both when a new connection is made and how to pass the channel to the DataPusher. You could also register all connected channels in a ChannelGroup and then the DataPusher simply needs a reference to the ChannelGroup and a ""lightweight nudge"" when a new channel is added to it. Or.... override ChannelGroup and add in your own event handling.  After all the exchanges above I still don't see that any of this is necessary. Surely all you have to do is just accept the connection from the external service; don't register it for any events; then when the other client connects register for I/O events on both channels. The external service doesn't know or care whether you are blocked in a thread waiting for another connection or just not responding for some other reason. If he's writing to you his writes will succeed anyway up to the size of your socket receive buffer whether you are blocking or not as long as you aren't actually reading from him. When that buffer fills up he will block until you read some of it. If he is reading from you he will block until you send something and again what you are doing in the meantime is invisible to him. So I think you just need to simplify your thinking and align it more with the wonderful world of non-blocking I/O."
801,A,"Netty server remote connection Netty server Fedora. I just can't connect to the server from remote host and no listening socket is displayed via netstat util. However I can establish the connection running client and server on the same machine. That's simply like that: port = System.getProperty(PORT_PROPERTY); Preconditions.checkNotNull(port ""Network error port property is not set""); hostAddress = new InetSocketAddress(Integer.valueOf(port)); ... serverChannel = bootstrap.bind(hostAddress); I've tried initializing hostAddress with the port only localhost IP 0.0.0.0 IP and IP of my network. Nothing helps. What could be the root of problem? @Nicholas yes I can successfully ping the server. Can you ping the netty server remotely by IP address ? Here's some suggestions that should help disagnosing the problem: For clarity (until you resolve this) stick to using new InetSocketAddress(""0.0.0.0"" Integer.valueOf(port)) since this will ensure you bind to all interfaces. Invoke the JVM with -Djava.net.preferIPv4Stack=true to force the JVM into IPV4. I have found it easier to muck with these issues when in IPV4 since is it less complicated than V6. Get the PID of the JVM and then issue a netstat like this: sudo netstat -ap --numeric-ports | grep <PID> This should display all sockets for your JVM instance. (Please post this output if you're still not able to connect remotely. Also post the output of ifconfig) God bless you I'll try that right now! @Nickolas THANK YOU VERY MUCH!!! The world could be much better if there were more people like you! GOOD LUCK GREAT MOOD MUCH FUN!"
802,A,"Difference between ChannelHandler.messageReceived and FrameDecoder.decode in Netty Both events are fired by Netty framework  with a handle to the ChannelBuffer  and the expectation is that client will process the bytes in the buffer in some manner. Are there any specific usage/scenarios where one is preferred over the other ? You should checkout the FrameDecoder javadocs. In short you want to use the FrameDecoder if you need to ""buffer"" data until a Frame was received. The FrameDecoder will take care of it so other handlers in the pipeline (after it) will only receive a full frame."
803,A,Is there any opensource netty Ldap Encoder / Decoder I wonder if there any Ldap Request decoder and Ldap Response encoder for netty. As I rather not write a ASN.1 codec using Ber encoding mechanism. Thanks There is one based on Apache MINA implemented for Apache Directory Server. If you would like to port it to Netty let me know. The mina codec (that I know of) is deeply coupled with Apache DS. In my situation I need to do away from the storage component. How difficult would it be to port it to netty ? - Thanks No the codec does not depend on ApacheDS think of this like an LDAP client. 1. ASN.1 http://svn.apache.org/repos/asf/directory/shared/trunk/asn1 2. LDAP codec http://svn.apache.org/repos/asf/directory/shared/trunk/ldap/codec The entire reusable API module can be found at https://svn.apache.org/repos/asf/directory/shared/trunk I am not sure if this apply to building an ldap server care to point to the actual project code base? Thanks.  Any reason you would like to write a LDAP codec ?
804,A,Receiving channelIdle more than expected (Netty Socket Server) I am facing a problem at my multiplayer java server where I am receiving more than expected channelIdle events. It started 2 days ago where I didn't change the source code and server configuration. What can be the cause for this? Between specific intervals many people are dropping out of server instantly from idle event. I am using netty. Thanks for the help. can you show me your code ? camel netty 2.6.0 Actually there is no need to paste code since it is a simple override of IdleStateAwareChannelUpstreamHandler. I am logging idle connections at that function. 3-4 days ago I wasn't getting these. What could be the cause? What netty version does camel 2.6.0 use? can you tell me what version of netty you use ? I am not sure of the version right now but in pom it says 2.6.0 It appears that problem was occurring due ISP errors. Thanks.
805,A,"Writing a ChannelBuffer to a Netty Channel throws java.io.NotSerializableException I want to write raw bytes to a netty Channel. I thought I could do this by first creating a ChannelBuffer filling it with bytes (coming from say a Kryo serializer) and then writing that ChannelBuffer to the netty Channel. Here is the relevant code where I'm simply filling some bytes into a ChannelBuffer in the ctor and trying to send it upon connection: /** * Handler implementation for the object echo client. It initiates the * ping-pong traffic between the object echo client and server by sending the * first message to the server. */ public class ObjectEchoClientHandler extends SimpleChannelUpstreamHandler { private final ChannelBuffer firstMessage; /** * Creates a client-side handler. */ public ObjectEchoClientHandler(int firstMessageSize) { if (firstMessageSize <= 0) { throw new IllegalArgumentException( ""firstMessageSize: "" + firstMessageSize); } firstMessage = ChannelBuffers.buffer(8192); for (int i = 0; i < firstMessageSize; i++) { firstMessage.writeByte(i % 256); } } @Override public void channelConnected( ChannelHandlerContext ctx ChannelStateEvent e) { // Send the first message if this handler is a client-side handler. // e.getChannel().write(firstMessage); Channels.write(ctx e.getFuture() firstMessage); } } This doesn't seem to work as it throws this exception: java.io.NotSerializableException: org.jboss.netty.buffer.BigEndianHeapChannelBuffer at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1164) at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:330) at org.jboss.netty.handler.codec.serialization.ObjectEncoder.encode(ObjectEncoder.java:80) at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:61) at org.jboss.netty.channel.Channels.write(Channels.java:626) at org.jboss.netty.channel.Channels.write(Channels.java:587) at ca.gsimard.spacecraft.client.ObjectEchoClientHandler.channelConnected(ObjectEchoClientHandler.java:83) at ca.gsimard.spacecraft.client.ObjectEchoClientHandler.handleUpstream(ObjectEchoClientHandler.java:75) at org.jboss.netty.channel.Channels.fireChannelConnected(Channels.java:227) at org.jboss.netty.channel.socket.nio.NioWorker$RegisterTask.run(NioWorker.java:784) at org.jboss.netty.channel.socket.nio.NioWorker.processRegisterTaskQueue(NioWorker.java:250) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:192) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662) I'm sure this is dead trivial and probably the wrong way of doing it because I can't seem to find anyone who had the same error as this. I'm using Netty 3.3.0 right now. I can get this to work by creating a properly sized byte[] and copying the contents of the ChannelBuffer to it but I would have liked a more direct solution that avoids useless byte copying.  byte[] array = new byte[firstMessage.writerIndex()]; firstMessage.readBytes(array); e.getChannel().write(array); Thanks for any pointers ! Looking at your stack trace I observed these two lines: at org.jboss.netty.handler.codec.serialization.ObjectEncoder.encode(ObjectEncoder.java:80) at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:61 What this means to me is that your pipeline contains an ObjectEncoder which is attempting to serialize a ChannelBuffer. Since your objects have already been encoded by Kryo you don't need the ObjectEncoder. Or put differently (without Kryo) a ChannelBuffer should be the output of the ObjectEncoder and your object should be the input. Your best bet is to write a new ChannelHandler that uses Kryo to encode your objects. You may find some added efficiencies when Kryo does it's job as a handler in the Netty pipeline. This all makes sense now that I'm browsing netty's source and documentation. Thank you !"
806,A,ConcurrentWeakKeyHashMap isEmpty method The following is isEmpty() method from ConcurrentWeakKeyHashMap.java https://github.com/netty/netty/blob/master/src/main/java/org/jboss/netty/util/internal/ConcurrentWeakKeyHashMap.java Why does it need mcsum and what does the if(mcsum!= 0) {..} block doing ? And more importantly how do I get  if (segments[i].count != 0 || mc[i] != segments[i].modCount) to evaluate to true? public boolean isEmpty() { final Segment<K V>[] segments = this.segments; /* * We keep track of per-segment modCounts to avoid ABA problems in which * an element in one segment was added and in another removed during * traversal in which case the table was never actually empty at any * point. Note the similar use of modCounts in the size() and * containsValue() methods which are the only other methods also * susceptible to ABA problems. */ int[] mc = new int[segments.length]; int mcsum = 0; for (int i = 0; i < segments.length; ++ i) { if (segments[i].count != 0) { return false; } else { mcsum += mc[i] = segments[i].modCount; } } // If mcsum happens to be zero then we know we got a snapshot before // any modifications at all were made. This is probably common enough // to bother tracking. if (mcsum != 0) { for (int i = 0; i < segments.length; ++ i) { if (segments[i].count != 0 || mc[i] != segments[i].modCount) { return false; } } } return true; } EDIT: Code to evaluate the above if block is now in ConcurrentWeakKeyHashMapTest Essentially 1 thread continously monitors the concurrentMap while another thread continuously add/remove same keypair value The mcsum checks if the map has ever been structurally modified. There appears to be no way to reset the modification counts to zero so if the map has ever contained anything at all mcsum will be non-zero. The weak keys are only cleaned up when the map is changed through a put remove et c and they are only cleaned up within the modified segment. Retrieving values from the map does not clear up the weak keys. This means the map as implemented will hold many weak keys that have been garbage collected as they are only cleaned up if the same segment is modified. This means results from the size() and isEmpty() methods will frequently return the wrong result. With the API as provided your best recourse is to call purgeStaleEntries() prior to checking if the map is empty.  This method is a copy of the same in Javas ConcurrentHashMap. This kind of Map is using a modCount per segment to track during operations if it remained unchanged by different treads. During our traversal of the Map there could actually be other operations modifying the Map. This is called an ABA problem. We are asking the Map if it is empty and in fact it is not but by accident it appears to be. A simple example: Map with three segements Segment 1: size=0 Segment 2: size=0 Segment 3: size=1 In this moment we decide to ask the Map and look into segment 1 which appears to be empty. Now another algorithm comes and inserts an element to segment 1 but removes the other from segment 3. The Map was never empty. Our Thread is running now again and we look into segment 2 and 3 both are empty. For us the Map is empty - as a result. But for any empty slot we tracked whether it was modified too. And for slot 3 we realize there have been modifications: mc[2]>=1 which means mcsum>=1. This means: since construction the Map was modified at least once. So to answer what mcsum is for: It is a shortcut for the default empty ConcurrentHashMap. If there never have been modifications we do not need to check for concurrent modifications. So we know something happened and check again each segment. If now a segment is empty we know what its modCount has been. For segment 3 lets say it was 1 for segment 1 it has been 0. Checking the modCount of segment 1 now it is 1 and the count is > 0 so we know that the Map is not empty. Still there could be an ABA problem in the second loop as well. But because we know the modCounts we can catch any other concurrent algorithm changing something. So we say if the segment is empty and something changed with the modCount it has not been empty in the first place. That is what the second loop is doing. Hope this helps. EDIT And more importantly how do I get if (segments[i].count != 0 || mc[i] != segments[i].modCount) to evaluate to true? This evaluates to true if a segment contains something or if something was modified since the first loop. And it evaluates to false (which means: segment empty) if the segment contains nothing AND nothing was changed since the first loop. Or to say it differently: We can be sure it has been empty all the time since looked on the checked segment first. Thanks for the detailed answer. Now I just have to come up with a java code to test the above trying to evaluate the if block above to true For this block it is actually simple: Just insert an element into the segment you are checking with it. Code to test is in: https://github.com/lydonchandra/netty/blob/master/src/test/java/org/jboss/netty/util/internal/ConcurrentWeakKeyHashMapTest.java
807,A,"Exception during Netty server shutdown I have application running on Tomcat. I use Netty 4 for websocket handling. Netty server run in ServletContextListener in contextInitialized method and stop in contextDestroyed. This my class for Netty server: public class WebSocketServer { private final int port; private final EventLoopGroup bossGroup; private final EventLoopGroup workerGroup; private Channel serverChannel; public WebSocketServer(int port) { this.port = port; bossGroup = new NioEventLoopGroup(1); workerGroup = new NioEventLoopGroup(); } public void run() throws Exception { final ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup workerGroup).channel(NioServerSocketChannel.class) .childHandler(new WebSocketServerInitializer()); serverChannel = b.bind(port).sync().channel(); System.out.println(""Web socket server started at port "" + port + '.'); System.out .println(""Open your browser and navigate to http://localhost:"" + port + '/'); } public void stop() { if (serverChannel != null) { ChannelFuture chFuture = serverChannel.close(); chFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { shutdownWorkers(); } }); } else { shutdownWorkers(); } } private void shutdownWorkers() { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } It's work fine after running but when I try stop Tomcat I get exception: INFO: Illegal access: this web application instance has been stopped already. Could not load io.netty.util.concurrent.DefaultPromise$3. The eventual following stack trace is caused by an error thrown for debugging purposes as well as to attempt to terminate the thread which caused the illegal access and has no functional impact. java.lang.IllegalStateException at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1610) at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1569) at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:592) at io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:403) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:139) at java.lang.Thread.run(Thread.java:662) After Tomcat hangs up. What can be reason? The shutdown-methods signal threads to stop but probably do not wait for all threads to finish. In the mean time Tomcat proceeds to close the webapp and threads from the webapp that are still running get errors because among other things Tomcat unloads all classes loaded by the webapp. It means that one thread did not stop running and keeps the classes loaded by the webapp in memory as a consequence memory usage will grow with each re-deploy of the webapp. But you are aware that Tomcat supports websockets [natively](http://tomcat.apache.org/tomcat-7.0-doc/web-socket-howto.html)? I.e. you do not need Netty for that. Thank you it was reason. Now I use awaitTermination for finishing shutdown. And Tomcat stop fine without exception. But it write next message in logs: The web application [/MySite] appears to have started a thread named [nioEventLoopGroup-3-2] but has failed to stop it. This is very likely to create a memory leak. What could be causing this leak? I had a similar problem and posted a solution. I assume you call shutdownWorkers() somewhere from Servlet.destroy() or use some other mechanism that ensures your Server goes down when servlet stops / unloads. Then you need to do void shutdownWorkers() { Future fb = trbossGroup.shutdownGracefully(); Future fw = workerGroup.shutdownGracefully(); try { fb.await(); fw.await(); } catch (InterruptedException ignore) {} } It is because shutdownGracefully() returns a Future and well without waiting for it to come you leave things that try to close the connections in very stressful environment. It also makes sense to first initiate all shutdown's and then wait till futures are awailable this way it all runs in parallel and happens faster. It fixed the issue for me. Obviously you can make it nicer to your system without swallowing InterruptedException and wrapping each call in a nice method and putting reasonable timeout for each await(). Nice excercise in general but in reality most probably you wouldn't care at this point in your code. Side note: and yes for WebSockets you will be better off with Tomcat's native standards-compliant and robust implementation. Netty is awseome for many other things but would be a wrong tool here."
808,A,"latency in netty due to passing requests from boss thread to worker thread? I have some questions about Netty (Server Side) TCP/IP applications; I am wondering if there can be latency because of netty (due to missing configuration etc.) while passing the request from boss thread to worker thread ? I am using : new OrderedMemoryAwareThreadPoolExecutor(350 0 0 1 TimeUnit.SECONDS); Actually I set max thread count 350 as I am not sure about the optimal number. I log simultaneous working thread count every minute and it seems that average is too low (barely exceeds 10). So I will decrease this number as it is not required. Is there any other parametersimportant points that I should be aware of for to get best performance ? bootstrap.setOption(""tcpNoDelay"" true); - Is there any disadvantage of setting this parameter? Considering that delivery time is very important. Thread Pool Executer: OrderedMemoryAwareThreadPoolExecutor executor = new OrderedMemoryAwareThreadPoolExecutor(48 0 0 1 TimeUnit.SECONDS); Here is my pipeline factory:  ChannelPipeline pipeline = pipeline(); pipeline.addLast(""frameDecoder"" new DelimiterBasedFrameDecoder(GProperties.getIntProperty(""decoder.maxFrameLength"" 8000 * 1024) Delimiters.nulDelimiter())); pipeline.addLast(""stringDecoder"" new StringDecoder( CharsetUtil.UTF_8 )); pipeline.addLast(""frameEncoder"" new NullTermMessageEncoder()); pipeline.addLast(""stringEncoder"" new JSONEncoder( CharsetUtil.UTF_8 )); pipeline.addLast(""timeout"" new IdleStateHandler(idleTimer 42  0 0)); pipeline.addLast(""executor"" new ExecutionHandler(executor)); pipeline.addLast(""handler"" new GServerHandler()); and the ServerBootstrap: gServerBootstrap = new ServerBootstrap(new NioServerSocketChannelFactory(Executors.newCachedThreadPool() Executors.newCachedThreadPool())); gServerBootstrap.setPipelineFactory(new GServerPipelineFactory()); gServerBootstrap.setOption(""backlog"" 8129); gServerBootstrap.setOption(""child.tcpNoDelay"" true); gServerBootstrap.bind(new InetSocketAddress(GProperties.getIntProperty(""server.port"" 7679))); What can you suggest for this configuration ? Netty Boss threads are only used to setup connection worker threads are used to run NioWorker (non blocking read/write) or OioWorker (blocking read/write). If you have an execution handler worker thread will submit the message event to OrderedMemoryAwareThreadPoolExecutor. 1) Increasing the Netty I/O worker thread count to more than number of processors * 2 won't help. If you are using staged executors Having more than one staged execution handler for non I/O tasks may increase latency. Note: Its better to set your own ObjectSizeEstimator implementation in OMTPE constructor because many CPU cycles are spent on calculating used channel memory. 2) There are some other Netty parameters you can try  //setting buffer size can improve I/O bootstrap.setOption(""child.sendBufferSize"" 1048576); bootstrap.setOption(""child.receiveBufferSize"" 1048576); // better to have an receive buffer predictor bootstrap.setOption(""receiveBufferSizePredictorFactory"" new AdaptiveReceiveBufferSizePredictorFactory(MIN_PACKET_SIZE INITIAL_PACKET_SIZE MAX_PACKET_SIZE)) //if the server is sending 1000 messages per sec optimum write buffer water marks will //prevent unnecessary throttling Check NioSocketChannelConfig doc bootstrap.setOption(""writeBufferLowWaterMark"" 32 * 1024); bootstrap.setOption(""writeBufferHighWaterMark"" 64 * 1024); 3) It should be bootstrap.setOption(""child.tcpNoDelay"" true) for server bootstrap. There is an experimental hidden parameter: Netty NioWorker is using SelectorUtil.select to wait for selector events the wait time is hard coded in SelectorUtil selector.select(500); setting a small value gave better performance in netty sctp transport implementation. Not sure about TCP. do i have to do something at operating system level (server) for tcpNoDelay ? Changing configuration setting global environment variable etc ? Server is Centos. You can use sysctl command to tune tcp stack parameters in linux But tcp no delay is a socket level parameter so you have to use bootstrap.setOption Tuning TCP stack will be very specific to your performance requirement and there are plenty of articles out there. These are the parameters I can see in my 2.6 Kernel https://gist.github.com/1554191 how can buffer sizes and WaterMarks effect netty performance ? 1)setting optimum size for socket buffers reduce the number of read/write calls 2) setting the write water mark size prevent unnecessary throttling (going to read only mode) Its worth to read this old good article http://gleamynode.net/articles/2232/ did tcp stack optimization worked?  Q1) Everything adds latency. Netty is pretty efficient so I would be surprised if the latency is too high for 95%+ of use cases Q2) Test you performance yourself and determine if it a problem (either latency or throughput) before you start worrying about it. Q3) This option may help. It shouldn't make it worse. Many modern OSes self tune pretty well and I don't find it makes as much difference as it used to. Can you clarify what latency you are trying to achieve because it can make a big difference to your design? Is it 10 ms 1 ms 100 us 10 us? Peter i know that it will sound crazy but can it exceed 1000 ms ? About your answer to Q2 latency is very important since this application is a game server. But catching the actual problem is too hard since it may be because of many reasons like slow internet connection of client poor client pc etc. . Depending on what you are doing the latency can exceed 1000 ms. However it is possible to design systems which have less than 100 micro-seconds latency in Java (for the parts in your control) There is NO WAY that the latency of handing off a work unit from a netty IO thread to a worker thread is 1000ms unless there are no available threads. In my experience (and I'm running several hundred servers with millions of users) it's ~ 1-2ms. I suspect the OP needs a better understand of where his latency is coming from. I would suggest he time stamp all the stages in in the life cycle of an event e.g. receiving handling and responding to a request. You can ping servers on the other side of the world in 300 ms (round trip)  1) I am wondering if there can be latency because of netty (due to missing configuration etc.) while passing the request from boss thread to worker thread ? I don't think there's much if any latency here. The threads are in a pool they just need to be given the work. QUESTION 2) Is there any other parametersimportant points that I should be aware of for to get best performance ? When it comes to 'best' performance I did a bunch of testing and ended up using a number of threads that was about 16* the number of physical processors on the box. I tried thread numbers up to several thousand but when they got really slammed they ended up thrashing in GC. QUESTION 3) bootstrap.setOption(""tcpNoDelay"" true);. Is there any disadvantage of setting this parameter ? Considering that delivery time is very important. Definitely set this. i ll try setting tcpNoDelay parameter. since this is a game server update will have to wait for night =) by the way why 16 ?? please correct me if I get it right -> 16 x (number of processors) That ended up being the best tradeoff of threads throughput and memory use. Yes. But like I said - I tested all kinds of different things. Kylar is it worth looking log messages of Netty ? For performance? Or for error tracking? Logs are always useful but it depends on what you're trying to find out. for performance ? forexample i want to know the time pass between my socket write call and the actuall write operations starts. As far as I know it is asynchronous. Ahh I see. yes you'll have to create some custom logs for that but it can be very helpful. With custom logs do you mean like using ChannelFuture object to check when the write operation is done and log the time difference ? Yes you'll have to timestamp when the socket write is finished and when the work is finished. We generate a unique UUID for each request when we accept it then pass it along in the context so we can correlate them in our logs. do i have to do something at operating system level (server) for tcpNoDelay ? Changing configuration setting global environment variable etc ? Server is Centos."
809,A,"Netty 4 ReadTimeoutHandler not throwing in OioEventLoopGroup I'm new to netty. Is this an expected behaviour? A bit more detailed: public class Test { public static void connect(){ EventLoopGroup workerGroup = new NioEventLoopGroup(); Bootstrap bs = new Bootstrap(); bs.group(workerGroup); bs.channel(NioSocketChannel.class); bs.option(ChannelOption.CONNECT_TIMEOUT_MILLIS 10000); bs.handler( new ChannelInitializer<SocketChannel>(){ @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pl = ch.pipeline(); pl.addLast(""readTimeoutHandler"" new ReadTimeoutHandler(1000 TimeUnit.MILLISECONDS)); pl.addLast(""framer"" new DelimiterBasedFrameDecoder( 16384 Delimiters.lineDelimiter())); pl.addLast(""string-decoder"" new StringDecoder()); pl.addLast(""handler"" new SimpleChannelInboundHandler<String> (String.class){ @Override protected void channelRead0(ChannelHandlerContext ctx String msg) throws Exception { System.out.println(msg); } @Override protected void exceptionCaught(ChannelHandlerContext ctx Throwable cause) throws Exception { if(cause instanceof ReadTimeoutException){ System.out.println(""Timed out.""); } ctx.close(); } }); } }); bs.connect(""127.0.0.1"" 45001); } } This is just test case so it might be a bit incorrect pipeline ressembles my actual pipeline close enough though. Basicly if I change EventLoopGroup initialization from NioEventLoopGroup to OioEventLoopGroup and bootstrap channel setup from bootstrap.channel(NioSocketChannel.class) to bootstrap.channel(OioSocketChannel.class) without touching anything else ReadTimeoutHandler stops throwing ReadTimeoutExceptions. This was fixed in Netty 4.0.4.Final . Please upgrade see [1]. [1] https://github.com/netty/netty/issues/1614 Oops didnt notice that one. Thank you."
810,A,"Netty + JMeter errors when reusing connection I built a simple TCP server using Netty and I want to benchmark it with JMeter. I'm using a JMeter TCP Sampler using the BinaryTCPClientImpl class name to send bytes. I have checked ""no delay"" and ""reuse connection"". I assume these are for SO_NODELAY and SO_REUSEADDR. I'm running 75 threads each doing 1000 TCP requests. I consistently see about 11% of the requests fail with: 500 java.net.SocketException: Software caused connection abort: socket write error If I uncheck ""reuse connection"" then all 75000 requests succeed without a single error but the throughput is only ~33% of what it was. Is there something I need to do with my Netty server to prevent these errors? I should note my server works like this: accepts connection receives some data sends some data once the data is sent closes the connection. JMeter docs say TCP Sampler closes the connection unless ""reuse socket"" is checked so I guess this is not SO_REUSEADDR. I assume in some cases the client sends data receives data and before the server closes the socket the client tries to send data again then the server closes the socket and JMeter thinks the request failed. So the solution is to not check ""reuse address"". Closing the socket each request is expected behavior as my clients communicate relatively infrequently. I think it is the answer though. You should probably add this to your original question :)"
811,A,Getting notified when a client closes unexpectedly in JBoss Netty Is there a listener in Netty server-side which will be notified when the client closes unexpectedly (say when the LAN cable in the client m/c is removed). None of the methods in DefaultChannelHandler is getting invoked. Assume the client is inactive (not sending/receiving any data) when the LAN cable was unplugged. Or do we have to implement a Keep-Alive monitor in server side to check if channel is valid? Designed and implemented fail-closed keep-alives. Important thing here is to close the channel after a timeout and reopen it.  Practically there is no way to detect an unexpectedly dropped connection in TCP/IP. If there's a way to do that it should not be called 'unexpectedly'. :-) The most robust way to detect a dropped connection is to send a message periodically or to wait for a message with timeout such as sending a ping message. To implement this behavior you can use IdleStateHandler. Insert it into your pipeline and make your handler extend IdleStateAwareChannelHandler or IdleStateAwareChannelUpstreamHandler. Alternatively if the clients and servers run in a well controlled network such as LAN you could configure your operating system so that it sends TCP keep-alive packet more frequently. For more information refer to TCP keepalive HOWTO. However I doubt this will work reliably under WAN environment. (If someone experimented with TCP keepalive timeout in a WAN environment please share your story.) Thanks Trustin. Will try the mentioned behavior.  Have you tried adding a ReadTimeoutHandler to your pipeline? I believe this would throw a ReadTimeoutException after the server had not read data from the channel for the given number of seconds. I've only used this on clients to implement reconnect (like the UpTime example) but it may also work here. I used IdleStateHandler in server with periodic ping mechanism from Client. That worked :)
812,A,"Netty Client Won't send more data after a while I'm writing an application that consists of a Server and a Client written with Java using Netty. I've not found a real answer to this question but I wonder why my Server-Client connection stops being able to sen data after a while if not used. The ""keepAlive"" option is set to True and it all works fine until that point where enough time has passed for the client to ""disconnect"" however the server doesn't receive a disconnect status. Just generally curious does keepAlive ping-pong the client/server or do I have to do that myself? Thanks! You should provide more information like netty version and if possible the code you use to setup your client and server (Bootstrap & Pipeline). It's pretty much the normal setup with a client-server bootstrap with a pipeline with the options ""keepAlive"" and ""tcpNoDelay"". The application works just fine while you actually send messages between them but when you don't use the client for a while it just won't ""flush"" the messages to the server anymore. Things that worth take a look at is if there is some networking gear such as firewalls that might had closed your connection bear in mind that is not in the protocol the connection state handling. So it is likely that you have a half closed connection. If you did set the keepAlive option make sure it is performing those ping over the wire. Best thing to do is to check in both sides of the connection if the socket still open. While the connection is alive but idle (the client is not receiving data) check if the connection is in status ESTABLISHED. And do the same in the server side. From there with tools such as Wireshark and trace try to establish if the connection was dropped on the server or it was killed by a firewall. Alright thank you I'll test it right away! Tested it a bit seems like it doesn't disconnect the streams just stops working after a while... Do you got any suggestions on how to test this further?"
813,A,"Netty IdleStateEvent doesn't raise READER_IDLE on server I'm creating a Netty (4.0.14 Final) client/server application with SSL Sockets and I am trying to implement an IdleStateEvent so that I can know when my clients or server goes offline. The problem is READER_IDLE does not work on the server. I'm pasting here snippets of the code. SocketInitializer public class SocketInitializer extends ChannelInitializer<SocketChannel> { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); SSLEngine engine = SslContextFactory.getServerContext().createSSLEngine(); engine.setUseClientMode(false); pipeline.addLast(""idleHandler"" new IdleStateHandler(30 0 0)); pipeline.addLast(""ssl"" new SslHandler(engine)); pipeline.addLast(new SocketDecoder() new SocketHandler()); } } SocketHandler (...) @Override public void userEventTriggered(ChannelHandlerContext ctx Object evt) throws Exception { if(evt instanceof IdleState) { IdleState e = (IdleState) evt; if(e == IdleState.READER_IDLE) { System.out.println(""It's idle!""); } } } (...) Now I've tried to have the userEventTriggered() method both overridden on the IdleStateHandler class and on the SslHandler class (one at a time of course :)) and neither of these options work. I have the exact same pipeline on the client with the userEventTriggered() on the SocketHandler class but only triggering the WRITER_IDLE and it works! Is there anything that I am missing? Thank you for your time! You need to check if it is of instance IdleStateEvent and if so cast it and check its state(). public void userEventTriggered(ChannelHandlerContext ctx Object evt) throws Exception { if(evt instanceof IdleStateEvent) { IdleStateEvent e = (IdleStateEvent) evt; if(e.state() == IdleState.READER_IDLE) { System.out.println(""It's idle!""); } } } See the example in the javadocs: https://github.com/netty/netty/blob/4.0/handler/src/main/java/io/netty/handler/timeout/IdleStateHandler.java#L77 no worries... Just happy when it works ;) Oh dear god. Now I feel dumb :( I had that same `IdleStateEvent` on the client side and didn't manage to see my mistake. Thank you! Ok now I've got another (almost the same) problem. That event is only triggered when per example I remove the cable from the client machine. If I do a _CTRL+C_ Netty fails to trigger that event... That's probably why the connection is closed and channelInactive() event has been triggered already? The connection remains active. Let's say I have a timeout of 10 seconds; if I remove the network cable and wait more than 10 seconds the event is not triggered but if I reconnect the cable in the meantime all the messages pending in the disconnected machine are flushed onto the network. So the connection is somewhat still active but the READER_IDLE is not triggered. Still not sure as why this happens..."
814,A,"Netty WebSocket - to drive ""operationComplete"" of ""ChannelFuture"" correctly I am writing an application to send small file (~2kb) from Netty server to client through WebSocket. For testing whether the file send success I had the follows test. A client connect to server. Setting to drop all packets from server on the client machine. The server send a file to the client. Checking the result of ""ChannelFuture"" on the server. I got true from ""future.isSuccess()"" and ""future.isDone()"" immediately when I send a file with ~2kb in this test even client side cannot receive the file. I repeated this test for files with larger size. I find out that if the file size is larger than ~7kb the ""ChannelFuture future"" will wait the feedback from transmission. This is the result I expected. I am using Netty3.6.1 and my application is built base on ""org.jboss.netty.example.http.websocketx.server"". Here is part of my code: ChannelBuffer cb = ChannelBuffers.copiedBuffer(myfile_byteArray); ChannelFuture result = ctx.getChannel().write( new BinaryWebSocketFrame( cb ) ); result.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()){ System.err.println(""future.isSuccess()""); } if (future.isDone()){ System.err.println(""future.isDone()""); } if (future.isCancelled()){ System.err.println(""future.isCancelled()""); } } }); Does anyone know how could I having ""ChannelFuture"" work correctly for file with small file size? Many thanks in advance! ChannelFuture will only be notified if the data can be written out to the remote peer. So if it is notified then the other peer received the data without a problem. This is true for all sizes of data. Is there any wrong of my testing? ChannelFuture could not work normally in my application when sending small file... How could I make a test with ChannelFuture work fine if the connection broken? Thanks very much! I thought ChannelFuture was notified when Netty had written the data to the operating system buffers. It's not possible for an application to determine that data has reached the remote peer without an explicit application level acknowledgement message. It may appear to wait for larger messages to be transmitted but I suspect that's just co-incidence based on network conditions. yes correct... sorry I think I did not explain it well! Thanks for explaining the details of ChannelFuture. Adding acknowledgement message seems the only way to solve my problem. Thanks again for helping out!"
815,A,"Modify Netty ServerBootstrap ChannelInitializer I have a ServerBootstrap configured with a fairly standard Http-Codec ChannelInitializer. On shutdown my server waits for a grace period where it can still handle incoming requests. My server supports keep-alive but on shutdown I want to make sure every HttpResponse sent closes the connection with HTTP header ""Connection: close"" and that the channel is closed after the write. This is only necessary on server shutdown. I have a ChannelHandler to support that: @ChannelHandler.Sharable public class CloseConnectionHandler extends ChannelOutboundHandlerAdapter { @Override public void write(ChannelHandlerContext ctx Object msg ChannelPromise promise) throws Exception { HttpResponse response = (HttpResponse) msg; if (isKeepAlive(response)) { setKeepAlive(response false); promise.addListener(ChannelFutureListener.CLOSE); } ctx.write(msg promise); } I keep a track of all connected clients using a ChannelGroup so I can dynamically modify the pipeline of each client at the point of shutdown to include my CloseConnectionHandler this works no problem. However new connections in the grace period have their pipeline configuration provided by the original ServerBootstrap ChannelInitializer and I can't see a way of dynamically re-configuring that? As a work-around I can have the CloseConnectionHandler configured in the standard pipeline and turned off with a boolean only activating it on shutdown. But I'd rather avoid that if possible seems a bit unnecessary. there is currently no way to ""replace"" the initializer at run-time. So using a flag etc would be the best bet. Ta Norman. Would Netty benefit from this as an extension? I'd be happy to work on it if appropriate."
816,A,Singleton bootstrap and pipelineFactory on Netty as Tcp Client I'm using Netty to implement a server and a client of a protocol over TCP. At the server side I created one instance of classes bootStrap and pipelineFactory for each port it listen to and it works great and quickly. However at the client side I haven't got a clear idea about how to structure it. I need to open thousand connections to thousands differents destinations. I'm developing the project on Spring Framework so I can easily create singleton bean and inject them as properties. I'm evaluating 3 options: Use a singleton instance of ClientBootstrap and PipelineFactory. Every connection uses some code like this to get a channel: public Channel connect(final InetSocketAddress serverAddress final ChannelPipelineFactory pipelineFactory int timeout TimeUnit unit) throws InterruptedException { ChannelFuture future; synchronized (bootstrap){ bootstrap.setPipelineFactory(pipelineFactory); future = bootstrap.connect(serverAddress); future.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) { //TODO set here some channelLocal properties I need to configure the session (eg: user password etc...) } else{ throw new RuntimeException(future.getCause() .getMessage()); } } }); } return future.getChannel(); } My solution have to be able to configure also the pipeline to enable or disable SSL or log handlers maybe using this Abe solution to configure getPipeline() My second option is to use a singleton instance of ClientBootstrap but create a new PipelineFactory on every outgoing client connection. This helps me to configure the pipeline I have because I can set properties on the pipelineFactory instance. Third option is to create new bootStrap objects and pipelineFactory on every outgoing connection. This allows me to configure properties like tcp.delay or tcp.keepalive on every connection and allow me to delete the synchronized block on connect method that could speed up client connections. I think first one is fastest and use the lowest memory but third one is the most configurable and maybe easy to develop. Could you give me some advices about pros and cons of this approaches? maybe one of them is wrong? Thank you very much! ClientBootstrap instances are cheap. I would just create a new one for every connect and reuse the NioSocketClientChannelFactory for all of them. Or if you can you may want to use one bootstrap for ssl connections and one for non ssl. This will safe you from some memory overhead. Thank you very much for your answer. Only one more question what about PipelineFactory? It's as cheap to instantiate as ClientBootstrap or should I have a singleton instance of pipelineFactory and inject it on connect method? It is cheap but often you can share it easily
817,A,"Best way to send continuous data in Java using Netty I'm planning to use Netty to design a TCP Server. When the client connects I have to immediately start pumping XML data to the client continuously...for hours/days. Its that simple. So I override ""channelConnected"" method and send data from that method right?...thats great. I will be using the following ChannelFactory ChannelFactory factory = new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool()); NioServerSocketChannelFactory documentation says A worker thread performs non-blocking read and write for one or more Channels in a non-blocking mode. Good. According to effective Java Item 51: Don't depend on the thread scheduler I want the worker thread to do a ""unit of work"" and then finish/return. So in my case though I have to send data continuously I want to send some chunk (lets say 1 MB) and then be done (unit of work completed) so that worker thread can return. Then I'll send another 1 MB. Below example is from the official guide of Netty HERE. I guess the question is then in this scenario if i had to unconditionally keep sending time to the client how would I do it considering each send as a unit of work. One way of doing it would be to just put a while loop and do a Thread.Sleep. Any other way?  package org.jboss.netty.example.time; public class TimeServerHandler extends SimpleChannelHandler { @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) { Channel ch = e.getChannel(); ChannelBuffer time = ChannelBuffers.buffer(4); time.writeInt(System.currentTimeMillis() / 1000); ChannelFuture f = ch.write(time); f.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { Channel ch = future.getChannel(); ch.close(); } }); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { e.getCause().printStackTrace(); e.getChannel().close(); } } Doing a while/sleep would work but would not be in the Netty super-scalable style. It would be thread-per-connection programming. Instead schedule a periodic job on an Executor that writes a message to the channel."
818,A,"Netty CorruptedFrameException with multiple connection packets arrive at the same time I am encountering a very weird issue with my program which is using Netty. I am listening to a port and parsing the messages (using FrameDecoder implementation). Everything is working fine if I am receiving one connection but when I am receiving two connections on the same port (each one from a different server) I encounter a rare but critical situation where I get corruptedFrameException The issue occurs when my program receives TCP packets with the exact same timestamp (when sending information at a very high rate) as follows TCP Packet from Server 1 TCP Packet from Server 2 TCP Packet from Server 1 (which is a continutation of the message started in bullet 1) TCP Packet from Server 2 (which is a continuation of the message starged in bullet 2) My program tries to parse 1 and 2 as a message instead of knowing that the actual message is 1 & 3 and 2 & 4 I read somewhere that maybe I need to instantiate a new FrameDecoder for every channel connection but I don't know how exactly to do that. I am adding the decoder to the pipleline at startup and I cannot figure out how to add a new one to a specific channel The exceptions I am experiencing are: org.jboss.netty.handler.codec.frame.CorruptedFrameException: Adjusted frame length (0) is less than lengthFieldEndOffset: 2 at org.jboss.netty.handler.codec.frame.LengthFieldBasedFrameDecoder.decode(LengthFieldBasedFrameDecoder.java:340) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:282) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:214) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:345) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:332) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:323) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:275) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:196) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.util.internal.IoWorkerRunnable.run(IoWorkerRunnable.java:46) ~[netty-3.1.5.GA.jar:] at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:651) [na:1.5.0] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:676) [na:1.5.0] at java.lang.Thread.run(Thread.java:595) [na:1.5.0] and org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 4096: 8224 at org.jboss.netty.handler.codec.frame.LengthFieldBasedFrameDecoder.decode(LengthFieldBasedFrameDecoder.java:296) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:282) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:216) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:345) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:332) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:323) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:275) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:196) ~[netty-3.1.5.GA.jar:] at org.jboss.netty.util.internal.IoWorkerRunnable.run(IoWorkerRunnable.java:46) ~[netty-3.1.5.GA.jar:] at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:651) [na:1.5.0] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:676) [na:1.5.0] at java.lang.Thread.run(Thread.java:595) [na:1.5.0] ""maybe I need to instantiate a new FrameDecoder for every channel"". No maybe about it. That's exactly what you need to do. I figured but how do I do it? I am adding the decoded on the ChannelPipeLine object.addLast(""decoder"" decoderObject) upon initialization but when a new channel is connecting I am at the point of channelConnected(ChannelHandlerContext ctx ChannelStateEvent t) ... If I instantiate a new decoder how do I assign it to the channel? Something is missing in the puzzle :) That's the channelpipelinefactory's job. Define one that creates your decoder and then either use a bootstrap (with the channel factory) or pass the pipeline factory to the channel factory when requesting a new channel. You need to add a new object of frame decoder to your new(second?) channel. Duplicate exception is because you are using the same channel. The server bootstrap takes a pipeline factory which will configure all new channels with the appropriate encoders and decoders. Whenever a remote client connects to your server it creates it own channel object. In the Channel PipelineFactory implementation you are using. Make sure that new instance of frame decoder is created each time pipeline() method is invoked. The @Sharable annotation is for documentation purpose only. Even if you use it it will not affect anything since it is not code/logic. Just a marker that is all.  You need to ""NOT share"" the FrameDecoder between channels. FrameDecoder is not not annotated with @Sharable so you can't share it. Thats the cause of your Problem here.. Thanks. However there is no @Sharable annotation in my code still it happens. I'm trying to see how to implement what the folks in the comments above suggested but still no luck :) If you can link to an example of how to add FrameDecoder to the channel itself and not the pipeline (or am I missing something in my understanding) or do I need to create a whole new pipeline? I have tried doing channel.getPipeLine().addLast(""decoder""new object) but I get a ""duplicate"" exception"
819,A,"Netty Setting content size of HTTP Response to 0 For an experiment purpose where I need to drop a specific content (audio data) coming from youtube in a HTTP response message I am using below code. Right now I am testing with specific video and I know the size of the content. Ran some test without this code and captured the size variable. if (contType.equals(""text/plain"") && contLen > 200000 && contLen < 300000) { outputFileName = projRoot + File.separator + folder + File.separator + ""v_"" + seqNum + ""_"" + String.valueOf(ranNum); log.debug(""This is AUDIO data received and dropping it off""); response.setHeader(""Content-Length"" 0); response.getContent().clear(); return true; } However when I run this program I see the log getting printed; however it does not really drop the content. I see client (browser flash player) is still able to download the content and this time with different size. The video is played with both visual and audio. What is the correct way to drop off the content before it reaches the client? Am I missing on something here? It is youtube server which is sending the 'audio' with content type as ""text/plain"". In my use case I need to strip off the audio information from the video before it reaches the client/browser. Note that Youtube server sends audio and video in two separate HTTP response messages. In my code above I am trying to clear the HTTP response message which contains the audio. Correct. At this point in code the data is already written/attached to the HTTP response message which I am trying to clear. Yes I am trying to prevent the data to reach the browser. If you are suggesting to control the channel.write it means we have to do it at lower level in the proxy (I am using LittleProxy which is implemented on top of netty). Is there any way to handle this at HTTP/proxy level? What do you mean by ""drop off""? You mean to prevent your data from being sent to the browser? I see nothing being written to the channel at this piece of code... Look for calls to `channel.write` and modify what is being written there. Why would content marked text/plain be audio? What's the *real* problem here? Try: HttpHeaders.setContentLength(response 0l); response.setContent(null); Also make sure that your browser is not loading the content from the local cache. I'm not sure that you can use LittleProxy to intercept and change the response like that... Although this thread suggests that you can do so using a HttpFilter (check this test code for the basic structure). Otherwise you will have to dig into Little Proxy source code for further customization."
820,A,"does slow connections effect netty performance? CODE-1 new NioServerSocketChannelFactory(Executors.newCachedThreadPool() Executors.newCachedThreadPool()WORKER_SIZE) CODE-2 OrderedMemoryAwareThreadPoolExecutor executor = new OrderedMemoryAwareThreadPoolExecutor(48 0 0 1 TimeUnit.SECONDS); pipeline.addLast(""executor"" new ExecutionHandler(executor)); If IO worker thread pool size (default is 2*count of cpu) can be set from CODE-1 what is the purpose of adding executer (a thread pool) to pipeline in CODE-2 ? IO operations are done from worker threads. Does that mean a client with slow connection or bad network keeps IO worker thread busy until data is completely sent ? If so increasing WORKER_SIZE would help me prevent latencies ? server is centos in what operating system? The thread pool[s] you are adding in CODE-1 are for the boss threads and worker threads. The boss threads accept connections and pass it on to worker thread to handle. The executor you add in CODE-2 is for handling the messages read by the worker threads. Slow connections will not affect performance since you are using a non-blocking architecture (NIO) - which is set in Netty to not block (it could if it wanted to) can i say that boss thread passes requests to a IO worker thread (selected from a pool with size :WORKER_SIZE in CODE-1 ). IO worker thread passes read messages to another thread for to be handled (which is set in CODE-2).  Slow Connections does not affect Netty threads in NIO normally (check the update note). Some points about Netty server internal threads by default there will be only one Boss Thread per server port and it will accept connection and handover the connection to worker thread. to be precise: WORKER_SIZE is the maximum number of NioWorker runnables a server can have. for example If the server has only one connection then there will be 1 worker thread. If number of connections are increasing and it can not be assigned to next worker (active connections > WORKER_SIZE) then connections will be assigned to a worker in a round robin fashion. If IO worker thread pool size (default is 2*count of cpu) can be set from CODE-1 what is the purpose of adding executer (a thread pool) to pipeline in CODE-2 ? If your upstream tasks are blocking then you should execute them in a separate thread pool using a execution handler. Otherwise Nio read/write will not work on time (latency?). I think having a execution handler will help to reduce the latency than setting big value to WORKER_SIZE. IO operations are done from worker threads. Does that mean a client with slow connection or bad network keeps IO worker thread busy until data is completely sent ? If so increasing WORKER_SIZE would help me prevent latencies ? Generally speaking increasing the WORKER_SIZE >= number of cpu * 2 does not help because NIO is non blocking and If I am not mistaken its CPU intensive.For CPU intensive task CPU * 2 number of threads are chosen mostly. Update: NioWorker runs a loop with selector.select(500ms) to receive OP_READ selector.select with timeout a blocking call and if most of the connections are slow performance may reduce?. You can reduce the timeout in org.jboss.netty.channel.socket.nio.SelectorUtil.java and test. jestan i am confused. boss thread passes request to IO worker thread. worker thread fires the execution handler. if execution pool is set for handler the request proceeds in a different thread so that io worker thread is set free. am i right ?"
821,A,Wha't the difference between Channel#write(msg) and Channel#write(msg promise)? I'm reading the Javadoc of Channel of Netty: http://netty.io/4.0/api/io/netty/channel/Channel.html But it doesn't explain anything about the difference between Channel#write(msg) and Channel#write(msg promise). What's the purpose of the promise in the 2nd method? ChannelPromise is a special writable ChannelFuture which get notified once the IO operation completes. the method Channel#write(msg) will delegate to Channel#write(msg promise) with a DefaultChannelPromise created by netty as the second parameter  A Promise is a Future that you can modify; for more information please refer to https://github.com/netty/netty/pull/873
822,A,Netty 4 EventExecutorGroup shutdown I am using Netty 4.0.0.Beta2 I have a pipeline which is configured with several handlers the last of which runs in its own EventExecutorGroup. A little like so: DefaultEventExecutorGroup separateGroup = new DefaultEventExecutorGroup(); ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(AGGREGATE new SomeHandler()); pipeline.addLast(ENCODE new OtherHandler()); pipeline.addLast(extractEventGroup EXECUTE new ExecuteHandler()); I then configure a ServerBootstrap with this pipeline configuration as a part of the ChannelInitalizer. As the server runs I keep a track of all current clients in a ChannelGroup called 'channels' Later when I shut the server down I flush and close all the channels then call bootstrap.shutdown(); That shuts down the NIO EventExecutorGroup but not the separate DefaultEventExecutorGroup that I have added to the pipeline for my ChannelHandler - meaning the JVM doesn't exit as threads are still active (just waiting but not released). I was a little surprised that this wasn't closed as well so I keep a reference to the DefaultEventExecutorGroup now and manually close that after my bootstrap.shutdown() call: separateEventGroup.shutdown(); Have I missed something or is that the expected behaviour of Netty? I think you are right and this is a bug.. Could you please open a bug-report so we not forget to fix it ? https://github.com/netty/netty/issues Sure will Norman thanks for the reply. https://github.com/netty/netty/issues/1220 This is not true. Please see my answer.  It's actually not a bug but an expected behavior. Think about a JVM that runs multiple protocol servers. Let's say these servers performs disk I/O and you want to limit the number of threads that performs blocking disk I/O across the JVM. You could create a shared EventExecutorGroup for the handlers that perform disk I/O and use it across the multiple protocol servers in the JVM. Thanks for the explanation Trustin.
823,A,"By using a dynamic proxy is there a way I can return an object whose type doesn't match the method signature of the proxied interface? I think the short answer may be no but I'm hoping I can get alternative suggestions. Assume I have a data object and a data service. The data service is an interface and has the following method. public Data getData(); I'm creating a proxy for the service using the following invocation handler plus Netty to do what I'd call asynchronous rpc. The proxy is on the client side. @Override public Object invoke(Object proxy Method method Object[] args) throws Throwable { // Convert the call into an async request that returns a ListenableFuture APCRequest request = new APCRequest(serviceType method args); ListenableFuture future = apcClient.asyncMessage(request); // This blocks until the future finishes return future.get(); } This works fine. However if my client is a UI I end up wrapping the service call in something like a SwingWorker. I'd prefer to come up with a way of returning the ListenableFuture that I already have sitting there. Is there any way I can accomplish that without creating a separate asynchronous service API. For example: public ListenableFuture<Data> getData(); If I could have my InvocationHandler return the wrong type I could use something like this. public abstract class AsyncServiceCall<S D> { // S = service type D = expected doCall return type protected final S service; protected AsyncServiceCall(Class<S> serviceType APCClient client) { ProxyFactory proxyFactory = new ProxyFactory(client); // The true tells the proxyFactory we're expecting a ListenableFuture<D> // rather than the real return type. service = proxyFactory.createProxy(serviceType true); } // Sub-classes would make a normal method call using this. For // example service.getData() public abstract Object doCall(); @SuppressWarnings(""unchecked"") public ListenableFuture<D> execute() { return (ListenableFuture<D>) doCall(); } Is there another way of accomplishing what I want? Performance isn't an issue for me so blocking until the proxy can get the return value from the future is still an option if there's no simple way of doing what I want. It just seems like a waste since I want an asynchronous call in the UI anyway. Keeping my service API simple is more of a priority than anything. I want to be able to prototype using a simple service provider that instantiates service implementations directly and plug in my remoting protocol / server that's using dynamic proxies / Netty late in the development cycle. If you want to keep your API simple then I would suggest providing only the async API in the interface - it's much easier to wrap up a synchronous implementation in an asynchronous API than vice-versa. public interface DataService { public ListenableFuture<Data> getData(); } public abstract class LocalDataService implements DataService { public ListenableFuture<Data> getData() { SettableFuture<Data> result = SettableFuture.create(); try { Data theData = computeData(); result.set(theData); } catch(Throwable t) { result.setException(e); } return result; } protected abstract Data computeData() throws Throwable; } Providing _only_ an async API is definitely the correct approach for my situation. Everything becomes simpler especially the UI design since an async API makes it clear the calls may be long running. Note however that in my example above the `LocalDataService` method does block until the computation is complete even though the interface is nominally asynchronous. It would probably be better to implement it in terms of an Executor so it is truly asynchronous and the caller knows that they won't be blocked. Yes I saw that. I wouldn't use your example verbatim since having a `Future` that blocks internally would likely be a source of confusion. I would use a normal `FutureTask` instead. Thank you for the help."
824,A,"HTTP response attachment download complete notification In LittleProxy implementation is there a feature where we can get a notification of the completion of the file download? Currently I am using below code to save the attachment to the HTTP response message. I am not sure if this chanBuff.getBytes(...) a blocking call or non-blocking. ChannelBuffer chanBuff = response.getContent(); FileOutputStream outputStream = new FileOutputStream(outputFileName); chanBuff.getBytes(0 outputStream chanBuff.readableBytes()); outputStream.close(); When I try to process the saved file right after this code it throws an exception. If I wait till file is completely downloaded and saved on disk perhaps the problem might get solved automatically. java.io.IOException: Channel not open for writing - cannot extend file to required size at sun.nio.ch.FileChannelImpl.map(Unknown Source) at com.googlecode.mp4parser.AbstractBox.parse(AbstractBox.java:109) at com.coremedia.iso.AbstractBoxParser.parseBox(AbstractBoxParser.java:118) at com.coremedia.iso.IsoFile.parse(IsoFile.java:85) at com.coremedia.iso.IsoFile.<init>(IsoFile.java:54) at org.media.processor.LibraryImpl.printFileDetails(LibraryImpl.java:529) ChannelBuffer is just encapsulation around byte[]. chanBuff.getBytes(0 outputStream chanBuff.readableBytes()) will invoke outputStream.write(byte[] begin length). So before you write the content you should first allocate a corrent length bytes in ChannelBuffer. The ""chanBuff.getBytes()"" function is working fine. I do not think we need to allocate the any memory. I am more interested in to know if there is any way to notify when the write to the outputstream is finished so that I can perform next operations on that saved data. Does writeComplete event work for you? Hi Jian How does it work? If I'm not wrong WriteComplete event is to track the activity on ChannelBuffer. What I am looking for is to monitor the activity (write) on FileOutputStream. If you see above code snippet getBytes() method writes into the outputStream. I want to check when this write is finished. I am not sure if getBytes() function is synchronous (blocking) or nonblocking."
825,A,"Netty large string not enough readable bytes Im trying to write a 'large' string (986 chars) from my server to my client but i get the following error after reading 16 chars: not enough readable bytes - need 2 maximum is 0. It works correctly when sending smaller strings but with such a amount of characters this error is raised. We're using a BigEndianHeapChannelBuffer to receive our data in. The obj.length() from write and buffer.readUnsignedShort() from read both give the same (correct) number but the rest it crashes in the for loop. Netty version is 3.5.10 FINAL Anybody has any ideas how to fix this? Please ask if you need more info. Here follow some code snippets: WRITING TO THE STREAM: public void addString(String obj) { try { bodystream.writeShort(obj.length()); bodystream.writeChars(obj); System.out.println(""Server wrote bytes: "" + obj.length()); message = message + "";STRING: "" + obj; // bodystream.w(obj); } catch(IOException e) { } } READING FROM THE STREAM: public String readString() { try { int len = buffer.readUnsignedShort(); System.out.println(""Client can read bytes: "" + len); char[] characters = new char[len]; for(int i = 0; i < len; i++) characters[i] = buffer.readChar(); return new String(characters); } catch(Exception e) { System.err.println(e.getMessage()); return """"; } } DECODING: public class NetworkDecoder extends FrameDecoder { @Override protected Object decode(ChannelHandlerContext ctx Channel channel ChannelBuffer buffer) { try { int opcode = buffer.readUnsignedByte(); System.out.println(""[In] <- "" + opcode); return new ServerMessage(buffer opcode); } catch(Exception e) { e.printStackTrace(); } return null; } } Just trying to reason about this code you are calculating the length of your string as a unsigned short and then returning it followed by the string to the stream then while you read it you take the unsigned short out and determining how much longer you will be reading? How does decoding factor into this? Couldn't you simplify this by dropping the length hint from the writer and calling [.toString()](http://static.netty.io/3.5/api/org/jboss/netty/buffer/AbstractChannelBuffer.html#toString%28java.nio.charset.Charset%29) on the ChannelBuffer? Hmm that sounds too obvious to be true. But i'm giving it a try now. http://screensnapr.com/v/PadniK.jpg This is the output I get now all those 0001200..... are send as 1 string from the server. You will need to make sure that you have enough data in the buffer before you pass it to your ServerMessage. Also you want to call ChannelBuffer.readBytes(..) to ""copy the data otherwise you will suck up memory. Im going to try the example given in the FrameDecoder documentation to archieve this."
826,A,Difference between calling close() directly and using ChannelFutureListener.CLOSE I'm using netty 3.6.6. Could someone explain about the difference between the following two codes? channel.close(); channel.write(ChannelBuffers.EMPTY_BUFFER).addListener(ChannelFutureListener.CLOSE); When I used No 1 I found that netty sent TCP FIN before sending all packets I wrote. Consequently the client couldn't all packets server sent. But I couldn't find a problem for No 2. I don't understand why No 1 makes a problem. What's difference? Thanks in advance. I am new to netty here is my option: 1.will directly close the channel no matter whether or not you have unsend packets. 2.will add a listener to the channelfuture to detect if all the packets are sented and then close the channel This is correct. Calling channel.close() directly immediately closes the channel whereas adding the listener closes the channel when the particular write completes. The former is failing because the channel is being closed before your write has finished which is the reason the listener method is provided. Thank you! They are definitely different to each other.  From my experience: You should use Listener version. You will get an exception if you close the channel directly and there is still data in the internal queue. The reason why use this kind of design is: efficiency. The IO work are done by Netty IO Thread to avoid synchronization or contention.Write task will put into a queue if current thread is not IO worker thread. You could check NioClientSocketPipelineSink.evenSunk AbstractNioWorker and NioWorker.scheduleWriteIfNecessary Netty are keep improving its thread model: https://github.com/netty/netty/wiki/Thread-model Thank you! I'll try to study about thread model. :)
827,A,"In Netty 4 how do I catch all handlers' unprocessed exceptionCaught? In my channel pipeline there are many handlers. As I understand if I don't override their exceptionCaught(ChannelHandlerContext ctx Throwable cause) method the default behavior is the cause will be thrown out to the pipeline and something like this will be logged at WARN level by the pipeline: An exception was thrown by a user handler's exceptionCaught() method while handling the following exception: ... I want to override the above pipeline behavior to add some specific logic (ex: if the cause is java.io.IOException: Connection reset by peer do not log anything to avoid too many ""not very useful"" log at WARN level). What should I do? After some investigation I found this source code: https://github.com/netty/netty/blob/4.0/transport/src/main/java/io/netty/channel/DefaultChannelHandlerContext.java private void invokeExceptionCaught(final Throwable cause) { try { handler.exceptionCaught(this cause); } catch (Throwable t) { if (logger.isWarnEnabled()) { logger.warn( ""An exception was thrown by a user handler's "" + ""exceptionCaught() method while handling the following exception:"" cause); } } } Because it's private I don't think I can easily override it without using reflection. Is there a better way? Not sure why your exceptionCaught method would throw an exception... I think you just want to override the ChannelHandler.exceptionCaught(..) method and handle it there. I can catch the exception when overriding `exceptionCaught` of all inbound handlers. But because I'm writing web framework framework users can pass in user-created handlers (which don't do the overriding) to the framework I want catch all exceptions even when the handlers do not override `exceptionCaught`.  You could do this by define a ExceptionHandler then put this handler at the tail of pipeline. ChannelPipeline p = ch.pipeline(); p.addLast(""business"" new SomeBusinessHandler()); p.addLast... p.addLast(""exception"" new ExceptionHandler());//Make sure this is the last line when init the pipeline. And code your specific logic within the exceptionCaught method. But never rethrow the exception because this is the end of pipeline. I've checked. This solution works! Thanks!"
828,A,Limiting Netty Connections based on hostname/port and username I have a requirement to put a strict limit on the number of connections based on a login name and the hostname/port to which the client is connected. Any thoughts on approach? I think you can use ChannelGroup for keeping a track of connections. Based on the contents of the channelGroup make decisions about limiting connectivity. See the code fragment below. All channels which are added into the channelGroup are automatically removed when closed. class YourHandler extends SimpleChannelHandler { ChannelGroup channelGroup = new DefaultChannelGroup(); @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) { // make a decision if you want to accept connection // if not just close it using ctc.getChannel().close() } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) { channelGroup.add(ctx.getChannel()); } } Having studied the `ChannelGroup` code today I believe I should keep a `Map` of channel group names (based on the username) mapped to channel groups. i.e. `ConcurrentHashMap`. In this way I can logically group all of the Channels that are connected for specific usernames. I can then refer to each group by username and find the respective counts. Does this sound reasonable? Yes this is absolutely reasonable.
829,A,Will version 5 Introduce native transport for linux using epoll ET? I noticed that version 4 introduce Native epoll edge-triggered transport. So will version 5 introduce this feature as well ? It is included in 4.x and 5.x . So yes ;) Great! I am looking forward to using it in version 5 since i am still in Alpha.
830,A,"Netty 4.0 - Sending data to channels on different eventloops I'm not sure how to do this and I think my approach is wrong - Could someone please give me a hint? I have made a proxy server very similar to the example HexDumpProxy. The purpose is not to dump traffic but to manipulate the data parsing through the proxy and this part works perfectly. Lets call this the proxy part. In the same program I start up a second thread listening on another port using another ServerBootstrap and this has it's own eventloop etc. When I receive something on this listening port I would like to send this data to one of channels of the proxy part and I want to be to change this channel dynamically. When I send data to one of the proxy channels I get this error: Apr 29 2013 10:05:10 PM BackendListenHandler exceptionCaught WARNING: Unexpected exception from downstream. java.lang.IllegalStateException: nextOutboundByteBuffer() called from outside the eventLoop @Sharable public class BackendListenHandler extends ChannelInboundByteHandlerAdapter { private Channel outboundChannel; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.read(); ctx.flush(); } @Override public void inboundBufferUpdated(final ChannelHandlerContext ctx ByteBuf in) throws Exception { outboundChannel = Proxy.connectionTable.frontendListenChannel; if (!outboundChannel.isActive()) { System.out.println(""channel id="" + outboundChannel.id() + "" is NOT active...""); } else if (outboundChannel.isActive()) { ByteBuf out = outboundChannel.outboundByteBuffer(); out.writeBytes(in); outboundChannel.flush().addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) { // was able to flush out data start to read the next chunk ctx.channel().read(); } else { future.channel().close(); } } }); } } public void channelInactive(ChannelHandlerContext ctx) throws Exception { if (outboundChannel != null) { closeOnFlush(outboundChannel); } } @Override public void exceptionCaught(ChannelHandlerContext ctx Throwable cause) throws Exception { logger.log( Level.WARNING ""Unexpected exception from downstream."" cause); ctx.close(); } static void closeOnFlush(Channel ch) { if (ch.isActive()) { ch.flush().addListener(ChannelFutureListener.CLOSE); } } } For testing I keep and change my proxy Channels in this static variable: Proxy.connectionTable.frontendListenChannel; Use the same EventLoop when create the Bootstrap for the ""outbound"" connection like shown in the HexDump example. This will ensure everything is handled from the same IO threads. See [1]. [1] https://github.com/netty/netty/blob/master/example/src/main/java/io/netty/example/proxy/HexDumpProxyFrontendHandler.java#L46 I can't start a new ServerBootstrap in channelActive in HexDumpProxyFrontendHandler.java because then I would be starting ServerBootstrap everytime somebody tries to connect to the HexDumpProxyFrontendHandler. I don't think that is possible? What I mean is that I don't need to start a new ServerBootstrap each time connection is established on HexDumpProxyFrontendHandler. I don't follow... You don't start a new ServerBootstrap each time. What you do is you construct a new Bootstrap everytime which is fine as it is lightweight and share the EventLoopGroup with the ServerBootstrap. This way no extra resources are taken. Sometimes a third source connects to the second listning port and a connection is established. I need to send this inbound data to the client via the clients proxy outbound. Anyway I think got now... Thank you for your help :-) I will post what I did... I maybe think that my explanation of the situation is not that clear. Actually I'm listening on two different tcp ports and there for starting up two ServerBootstrap. When a client establish a connection on the first port then the proxy is established - just like the HexDumpProxy using bootstrap and sharing EventLoopGroup as in HexDumpProxy.  Instead of using ""outboundChannel.outboundByteBuffer()"" - I used ""Unpooled.copiedBuffer()"" to write bytes to channel from another EventLoop. @Override public void inboundBufferUpdated(final ChannelHandlerContext ctx ByteBuf in) throws Exception { outboundChannel = null; if (Proxy.connectionTable.channelId != 0) { outboundChannel = Proxy.allChannels.find(Proxy.connectionTable.channelId); if (outboundChannel.isActive()) { System.out.println(""NOTIFY channel id="" + outboundChannel.id() + "" is active...""); Rewrite rewrite = new Rewrite(byteBufConverter.byteBufToString(in) 2); in.clear(); in = byteBufConverter.stringToByteBuf(rewrite.getFixedMessage()); outboundChannel.write(in); outboundChannel.flush().addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) { ctx.channel().read(); } else { future.channel().close(); } } }); } } } Where ""byteBufConverter.stringToByteBuf(rewrite.getFixedMessage())"" returns ""Unpooled.copiedBuffer(strFixed.getBytes())"""
831,A,Create Netty Listeners in Java EE We are currently developing a small application which needs to communicate with a machine interface via a propriety tcp protocol. For this low level communication stuff we used Netty to implement the necessary encoders and decoders. Since we also need some Java EE things like WebService JPA etc we thought about integrating the netty server in an Java EE 6 application. Therefore we would use an ApplicationScoped managed CDI bean where the bootstrapping is triggered in a PostConstruct method and the unregistering is done in the PreDestroy callback. So the main question is: Would this lead to problems since as far as I know it is technically not allowed to start threads in a Java EE environment (I think Netty starts some threads here)? If yes what kind of problems? Since we don't need clustering we would just use a standard Java EE 6 app server like GlassFish. Most people will recommend against it since improper termination and resource lock-ups can lead to catastrophic results. However if you know what you're doing there is no reason not to. That said based on what you need it for I would recommend looking into Java Connector Architecture first. It already provides established contracts for connection transaction security life-cycle work etc. management. So you have a much better chance of writing a good implementation as well as transfer thread management to the container. See this and this to get you started. Okay thanks. We'll try to implement it via JCA.
832,A,"How does netty 3.3.1 ChannelLocal get emptied to prevent memory leak? So when sharing items across handlers on a channel ChannelLocal (with attendant put and get) are the solution in 3.3.1. When I am done with my handler chain does the ChannelLocal automatically realize my Channel is closed and empty it's entry in the ChannelLocal? Or do I need to explicitly ""null"" out or empty out the ChannelLocal once I'm done with my shared object? IE will I have a memory leak if I use ChannelLocal and don't explicitly null out the items I'm putting into it when I'm done with them? Digging through the source code comments left me unsure about how Garbage Collection interacts with the items. If you construct ChannelLocal with parameter true it get cleaned up automaticly once the Channel is closed. Otherwise you need todo it by your own. Default is to construct it with false. See [1]. [1] http://netty.io/docs/stable/xref/org/jboss/netty/channel/ChannelLocal.html#127 Thanks this was what I needed! Just missed that one somehow."
833,A,Why does netty example for HttpStaticFileServer use RandomAccessFile? Is there any specific reason for netty HttpStaticFileServerHandler example to use RandomAccessFile? A RAF is required to support zero-copy which requires a FileChannel which is most commonly acquired from a RAF.  I think it so that they can demonstrate the use of ChunkedFile which requires a RandomAccessFile. And the reason for that seems to be that ChunkedFile needs to be able to get the file's length. If I am not using https I need not use ChunkedFile. So I can choose FileInputStream instead of RandomAccessFile which also returns a FileChannel. But I cannot get fileLength from FileInputStream which is a required input for DefaultFileRegion. So I think it is necessary to use RandomAccessFile. That's roughly correct. However you could potentially get the file length some other way; e.g. using File.length(). Actually it doesn't make much difference which way you get the FileChannel and the file length. Thanks Stephen! If I am not using https I need not use ChunkedFile. So I can choose FileInputStream instead of RandomAccessFile which also returns a FileChannel. But I cannot get fileLength from FileInputStream which is a required input for DefaultFileRegion. So I think it is necessary to use RandomAccessFile. Please correct me if I am missing something.
834,A,"StackOverFlow exception when using Netty's SnappyFrameDecoder I'm trying to create a simple program that uses Netty's SnappyFrameEncoder/Decoder. I created a small java application that uses LocalChannels for the server/client. The client encodes a string using Snappy and the server decodes the string and writes it to the console. I keep getting a StackOverFlow exception even when I split it up into separate Client/Server programs. If I comment out the SnappyFramedDecoder and the SnappyFramedEncoder from the pipelines it runs without error and outputs my test message. I've tried very long test messages and it still gives me a StackOverFlow exception. Could anyone help me out? I'm new to Netty. Thank you!! I'm using Netty 4.0.0.CR2 Here is my code: public class LocalNettyTest { private static String LOCAL_ID = ""localtest""; private static String TEST_STRING = ""TEST""; public void run() throws Exception { final LocalAddress addr = new LocalAddress(LOCAL_ID); Bootstrap cb = new Bootstrap(); ServerBootstrap sb = new ServerBootstrap(); EventLoopGroup serverGroup = new LocalEventLoopGroup(); EventLoopGroup clientGroup = new LocalEventLoopGroup(); try { sb.group(serverGroup) .channel(LocalServerChannel.class) .handler(new ChannelInitializer<LocalServerChannel>(){ @Override public void initChannel(LocalServerChannel ch) throws Exception { ch.pipeline().addLast(new LoggingHandler(LogLevel.INFO)); } }) .childHandler(new ChannelInitializer<LocalChannel>() { @Override public void initChannel(LocalChannel ch) throws Exception { ch.pipeline().addLast(new SnappyFramedDecoder()); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new ChannelInboundMessageHandlerAdapter<String>() { @Override public void messageReceived(ChannelHandlerContext ctx String msg) throws Exception { System.out.println (""RECEIVED: "" + msg); } }); } }); cb.group(clientGroup) .channel(LocalChannel.class) .handler(new ChannelInitializer<LocalChannel>() { @Override public void initChannel(LocalChannel ch) throws Exception { ch.pipeline().addLast(new StringEncoder ()); ch.pipeline().addLast(new SnappyFramedEncoder ()); } }); // Start the server. sb.bind(addr).sync(); // Start the client. Channel ch = cb.connect(addr).sync().channel(); ChannelFuture lastWriteFuture = ch.write(TEST_STRING); // Wait until all messages are flushed before closing the channel. if (lastWriteFuture != null) { System.out.println (""Waiting""); lastWriteFuture.awaitUninterruptibly(); } } catch (Exception e) { e.printStackTrace(); } finally { serverGroup.shutdownGracefully(); clientGroup.shutdownGracefully(); } System.out.println (""Done""); } public static void main(String[] args) throws Exception { new LocalNettyTest().run(); } } This sounds like a bug... Could you please open an issue on our bugtracker[1] and include the stacktrace etc. Also include the Netty version you are using. [1] https://github.com/netty/netty/issues/ Maybe you could upload it to somewhere else ? Without the exception it's hard to help at all I was able to post most of it at https://github.com/netty/netty/issues/1380. The exception repeats a lot. It should be easily repeatable by running the code I posted as a java application. Thanks! I tried submitting the issue multiple times but it never showed me any verification that the issue was submitted after I clicked submit... Is that normal behavior on GitHub? Do the issues go through some hidden approval process before being posted or something? Never mind the message was too long and it wouldn't let me post it. The exception I copy/pasted was putting it over. Thanks I will have a look today..!"
835,A,"Server does not respond directly to my commands First of all I'll admit I am new to this and I've probably just forgotten to set an option somewhere to the correct variable but my Googling has failed me and I have no idea what to do so I was hoping to get some help. I have based this on the SecureChat example it can be located here: http://netty.io/docs/unstable/xref/org/jboss/netty/example/securechat/package-summary.html And the difference I have made have been only in the SecureChatServerHandler. More precisely in the messageRecieved block: @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) throws Exception { // Convert the message to a string String request = (String) e.getMessage(); System.out.println(""Message recieved: "" + request); if (request.equalsIgnoreCase(""clients"")) { channels.write(""We currently have: "" + channels.size() + "" clients""); } else if (request.toLowerCase().equals(""koko"")) for (Channel c : channels) { if (c == e.getChannel()) c.write(""HELLO WORLD""); } else { // Then send it to all channels but the current one. for (Channel c : channels) if (c != e.getChannel()) c.write(""["" + e.getChannel().getRemoteAddress() + ""] "" + request + ""\n""); else c.write(""[you] "" + request + ""\n""); } if (request.equalsIgnoreCase(""bye"")) e.getChannel().close(); } If I send a normal message that is getting broadcasted everything works. But if I send a command like clients or koko I get no response until I press enter again and send a empty message. First then I get the response back.  C:\Device Manager\Application Server\Examp les\SecureChat\SecureChatClient\bin>java -jar client.jar 127.0.0.1 8080 UNKNOWN SERVER CERTIFICATE: CN=securechat.example.netty.gleamynode.net OU=Contr ibutors O=The Netty Project L=Seongnam-si ST=Kyunggi-do C=KR Welcome to Electus secure chat service! Your session is protected by TLS_DHE_RSA_WITH_AES_128_CBC_SHA cipher suite You are the 1th user koko<ENTER> <PRESS ENTER AGAIN> HELLO WORLD[you] clients<ENTER> <AND ENTER ONCE AGAIN> We currently have: 1 clients[you] What I don't understand and don't want is the -pressing of enter button twice- thing. It seems highly inlogical and it is irritating. I didn't have these problem with the Telnet Example. Thank you for your time. Regards Aldrian. Did some testing and without the if/else thing it seems to work... This is one of those humiliating times where you just forgot one small detail and that messes everything up. if (request.equalsIgnoreCase(""clients"")) { channels.write(""We currently have: "" + channels.size() + "" clients /n""); // Forgot /n here } else if (request.toLowerCase().equals(""koko"")) for (Channel c : channels) { if (c == e.getChannel()) c.write(""HELLO WORLD /n""); // <- Forgot /n here as well } +1 Great catch. I looked at this for hours last night..."
836,A,Extending DefaultChannelGroup I would like to create a class that works much like a DefaultChannelGroup but with the one difference that the message being written belongs to a connection and the channel associated with it will not have the message written back to it. Think of the chat application where we should write to all other channels other than the one belonging to the user who wrote the message. Looking at the implementation of the DefaultChannelGroup it seems I could add a new method named write that expects a given channel and the message and will iterate the non-server channels and skip a channel that is equals to the given channel. You could extend the DefaultChannelGroup to do as you outlined but a channel group is already an iterator and set of channels already. If you already have a channel you can perform ther write directly to it (i.e. you don't need to get it from the ChannelGroup) or if for some reason you really wanted to get it from the channel group you could call ChannelGroup.find(channel.getId()). I guess if you are doing this for the pruposes of narrowing down to a single channel it's an issue of cosmetics. I am not pannning it.... personal preference ! If it makes it better for you go for it. The more interesting scenario which would be a truly useful extension to the DefautChannelGroup would be to assign individual channels a group of attributes encoded as a bit-mask. Then you might be able to do something like tell the BitMaskChannelGroup to write this message to all channels with a provided bit-mask argument which might be the encoding for all chat-room users over the age of 21 living in New Jersey or all routing devices where the manufacturer is Cisco. Ah great yes I just iterate those channels and when I see the one I don't want to write to skip. Works like a charm thanks! Did not notice the iterator! Nice answer Nicholas.
837,A,Netty4 application as both client and a server I want to write a program in Netty4 that should act as a server to other clients and also it itself is a client to another server. How to do this in Netty4? So far all examples I have seen are either client or server. Thanks. There are no special difficulties here. You need to create a part that will act as a server (using ServerBootstrap) and a part that will act as a client (using Bootstrap). If you need to establish a connection to another server while handling incoming connection from a client you can place that logic into a ChannelHandler of the server's pipeline. Netty provides two examples of this approach: Hex dumping proxy SOCKS proxy
838,A,non-blocking write of large object with netty In reference to my earlier question here I am trying to figure out the correct way to stream a large object from the server to the client. The server is doing a write followed by a flush and there's a handler in the Channel which will take the large object and iteratively decompose it into small chunks doing a writeAndFlush on each chunk. I was hoping this would turn the large object into a stream of manageable messages the client could consume and reconstruct as needed. What I see is each of those sits in the outbound buffer until either they've all be written and can be sent or I OOM the server. I'd like them to get flushed/sent as they're written to avoid this issue. (If I don't OOM the server it does come into the client as a stream like designed it's that the transmission of any data is blocked until all data is written). If I try to do the decompose operation by dispatching it via Callable to the Executor associated with the ChannelHandlerContext and then marking the original ChannelPromise as successful I still see the same behavior. If I instead use a non-netty Executor I seem to get the correct behavior I can see data landing on the client immediately but this feels like the wrong solution. When decomposing the large object into smaller writable ones I do see that immediately after I write the first object the channel writeability changes to false. I realize as @norman-maurer pointed out that I should stop writing at this point. But it's not clear how to get the event that I can safely resume writing. It's also not clear how you'd handle the write in that case but maybe that is because I don't see how you can get the event. Norman did answer this but I'll try and make it a bit clearer. It sounds like your first attempt is looping something like this while(moreToSend) { channel.writeAndFlush(...) moreToSend = checkFinished(); } It sounds like you're doing this in the channel's IO thread which is the thread which will write your data to the socket. The thread may not be able to write the data while it's processing the loop. Netty's only option is to queue the writes. I'm not completely familiar with Netty 4.x (still on 3.x) however it sounds like the same thing is happening in your second attempt. By dispatching the Callable to the executor associated with the ChannelHandlerContext then unless you've wrapped you handler in another executor you're actually asking the Callable to be executed on the IO thread and the same problem applies. Norman is saying that you should call writeAndFlush until channel.isWritable returns false. You can resume writing when Netty raises channelWritabilityChanged and channel.isWritable returns true. Note channelWritabilityChanged is raised on ChannelInboundHandler which implies that your handler needs to be both ChannelInboundHandler and ChannelOutboundHandler (assuming it's already an outbound handler). Alternatively rather than trying to write as much as possible in one go you can write the first chunk and register a listener with the returned ChannelFuture. When operationComplete is called back then if future.isSuccess returns true write the next chunk in the same way. This way you will write chunks as and when the previous chunk has been flushed to the OS send buffers. It should also work well if you need to mix sending the large object with other traffic. Writability events seem to only be dispatched on inbound handlers (ie `ChannelInboundHandler`); so it's not straightforward to get that event on an outbound handler which is doing the write. I guess I could make it also an inbound handler to get that event but that seems wrong. I am able to cascade writes via a series of cascaded `ChannelPromise` events which works but feels similarly kludgy To wrap up extending the duplex handler to get writability events and toggling the stream on and off in synch with those write events resolves the issue.
839,A,"java game room logging to a separate log file using log4j is a good idea? I am developing a game server based on the top of someone else framework netty and spring. And I wonder whether it is a good approach to generate a separate file using log4j for every game room or not. Since with many game room servers has to keep open a lot of log files. On the other hand with only one log file it would be a total mess up which would required parsing and filtering when analyzing a problem. If many log files is still a good approach when I need to know how to implement that. I have had a look at this question configure log4j to log to custom file at runtime but first answer is not clear how to minimize lines of code required in every attempt to write to a separate log file. I have tried the second answer with putting in config file log4j.appender.logfile.File=${logfile.name} but the framework has PropertyConfigurator.configure(System.getProperty(""log4j.configuration"")); which fails if log file is not specified at the start time. Any ideas and comments are welcome! Thanks UPD: This link also seems helpful in my case. Log4j logging to separate files But still: is it good idea and how to switch dynamically the output log file with minimal coding. I agree with jmort253 but if you really want a file per room create an appender for each: If the rooms are static just define the appenders on the log4j config file if not do it at run-time: That is exactly what the accepted answer from here says:  SimpleLayout layout = new SimpleLayout(); FileAppender appender = new FileAppender(layout""<room_file_name>""false); logger.addAppender(appender); Basically you don't need a configuration file the code there replaces it and defines the appenders dynamically with their file name so I recommend: Write a method to create dynamic appenders that receive the file name as a parameter (and maybe return the logger or also receive a logger and add the appender to it) Where ever the rooms are being created call that method Assign the logger with the new appender to each room and use it  Really when it comes down to it having more than one log file for the game rooms would be overkill. The file I/O would have an effect on performance even if that was negligible. Furthermore as programmers we have so many tools at our disposal for parsing and filtering information that it seems much more reasonable to do this after the fact. For instance as long as each game room matches a specific pattern when logging you could easily use grep and the Linux > operator to parse all of the data for game room X and write to another file where you could analyze it separately. Having your production server do this when you may or may not even be looking at the logs isn't the best use of resources. As an example running this command could quickly get me all the information I need about game room X: grep ""game room x"" mainLog.log > outputToAnalyze.log"
840,A,How to use Netty from inside a web app - steps to proper configuration I'm trying to setup Netty to run embedded in my web application. I have found the following document: http://docs.jboss.org/netty/3.2/api/org/jboss/netty/channel/socket/http/package-summary.html#package_description that describes how to configure a web.xml file that starts a Netty servlet. Now the document says: Second you have to bind your Netty-based server application in the same Servlet context or shared class loader space using the local transport (see LocalServerChannelFactory.) You can use your favorite IoC framework such as JBoss Microcontainer Guice and Spring to do this. The following example shows how to bind an echo server to the endpoint specifed above (web.xml) in JBossAS 5: That sound reasonable but it is not clear to me how - practically - that should work. Say that I want to use Spring as Ioc container what would be the proper beans configuration to bind netty to the local transport? Also how do I start the Spring context? From web.xml? Thanks I personally recommend using spring. It can integrate with almost everything under the sun. Take a look at the following link which shows how to configure your Netty server as a spring bean and then using it in a web app. This is the way you could do it for a spring + web app.  1) Create relevant spring beans for the server pipeline factory etc. 2) In the web.xml configure the spring dispatcher servlet. Note: The above configuration is for running the Netty server at some port along with your web app. Basically you can call the spring bean init-method attribute on any bean to do the netty server startup You could configure the servlet as mentioned in the link in your post. You can cross-reference any spring bean(say the netty server bean) within the servlet bean or call it within your servlet bean's init-method. Yet another possibility is that you can listen to spring application events and then after the container has started up you can manually launch your servlet/netty server. If you are using a grails app then the bootstrap class ( a convenience class which is called on application startup) can be used to startup the Netty server on web app startup Spring provides n-number of ways to do what you require you can choose based on your convenience. Regards Abraham.
841,A,"Netty on Android throws NullPointerException after bootstrap.connect My Netty communications classes work fine in a standard Java application but when I run them in an Android application I get a NullPointerException. My question is if any Netty experts could point in the right direction for resolving this. Is it an incompatibility issue issue with Android or can you see anything in the stack trace that might indicate what I may be doing wrong? I am using netty-3.4.0.Final.jar I have added the internet permission to the AndroidManifest.xml. I have verified that I can successfully connect to the server using just raw socket (without Netty) in the android app. After I call bootstrap.connect() I can suspend execution at breakpoints in two threads. One in exceptionCaught() and one in channelClosed(). The stack track below is from exception exceptionCaught(). The full source from this project is located on codeplex in the elvemobileandroid project. I believe I actually saw the Android project work once which might indicate that the exception is not always thrown. Unfortunately I have not been able to get it to work again (even though I have made no project changes). Thread [<1> main] (Suspended (breakpoint at line 172 in UptimeClientHandler)) UptimeClientHandler.exceptionCaught(ChannelHandlerContext ExceptionEvent) line: 172 UptimeClientHandler(SimpleChannelUpstreamHandler).handleUpstream(ChannelHandlerContext ChannelEvent) line: 117 DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline$DefaultChannelHandlerContext ChannelEvent) line: 564 DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(ChannelEvent) line: 792 ReadTimeoutHandler(SimpleChannelUpstreamHandler).exceptionCaught(ChannelHandlerContext ExceptionEvent) line: 143 ReadTimeoutHandler(SimpleChannelUpstreamHandler).handleUpstream(ChannelHandlerContext ChannelEvent) line: 117 DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline$DefaultChannelHandlerContext ChannelEvent) line: 564 DefaultChannelPipeline.sendUpstream(ChannelEvent) line: 559 Channels.fireExceptionCaught(Channel Throwable) line: 533 NioClientSocketPipelineSink.connect(NioClientSocketChannel ChannelFuture SocketAddress) line: 152 NioClientSocketPipelineSink.eventSunk(ChannelPipeline ChannelEvent) line: 97 DefaultChannelPipeline.sendDownstream(ChannelEvent) line: 574 Channels.connect(Channel SocketAddress) line: 642 NioClientSocketChannel(AbstractChannel).connect(SocketAddress) line: 204 ClientBootstrap.connect(SocketAddress SocketAddress) line: 230 ClientBootstrap.connect(SocketAddress) line: 183 ClientBootstrap.connect() line: 154 UptimeClient.run() line: 94 CommunicationTest.test() line: 32 ElveMobileActivity.onCreate(Bundle) line: 25 Instrumentation.callActivityOnCreate(Activity Bundle) line: 1047 ActivityThread.performLaunchActivity(ActivityThread$ActivityRecord Intent) line: 2627 ActivityThread.handleLaunchActivity(ActivityThread$ActivityRecord Intent) line: 2679 ActivityThread.access$2300(ActivityThread ActivityThread$ActivityRecord Intent) line: 125 ActivityThread$H.handleMessage(Message) line: 2033 ActivityThread$H(Handler).dispatchMessage(Message) line: 99 Looper.loop() line: 123 ActivityThread.main(String[]) line: 4627 Method.invokeNative(Object Object[] Class Class[] Class int boolean) line: not available [native method] Method.invoke(Object Object...) line: 521 ZygoteInit$MethodAndArgsCaller.run() line: 868 ZygoteInit.main(String[]) line: 626 NativeStart.main(String[]) line: not available [native method] This is my first post on stackoverflow please let me know if there is any more information I may provide. Thanks Could you post the NullPointerException stacktrace ? Please post the stacktrace of the error as well as the code lines where the error occurs. If you are using Eclipse you can find the stacktrace in the logcat window otherwise check [this post on how to get the log](http://stackoverflow.com/q/2882253/741249) Thanks for pointing out the logcat window (I'm new to Eclipse). It showed another error: java.net.SocketException: Bad address family After doing some research I found this: http://code.google.com/p/android/issues/detail?id=9431 The fix is to disable IPv6 when using the Emulator: java.lang.System.setProperty(""java.net.preferIPv6Addresses"" ""false"");"
842,A,Order of multiple Channel#write I'm reading the Javadoc of Channel of Netty: http://netty.io/4.0/api/io/netty/channel/Channel.html In my single thread (outside Netty's IO thread) if I call Channel#write many times: channel.write(msg1); channel.write(msg2); channel.write(msg3); Will Netty ensure that the messages be output in order: msg1 msg2 msg3? Or must I manually ensure the order myself (very tedious very ugly)? ChannelFuture f1 = channel.write(msg1); f1.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { ChannelFuture f2 = channel.write(msg2); f2.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) { channel.write(msg3); } }); } }); the answer is yes Channel is thread-safe which means it is safe to operate on it from different Threads. Also this method guarantees that the messages are written in the same order as you passed them to the write method
843,A,ExecutionHandler In Netty 4.0.8 Is there a handler like ExecutionHandler in Netty 4.x? My server is having a very big latency and I think ExecutionHandler would help me fix the problem. Specify a EventExecutor when adding the ChannelHandler to the ChannelPipeline.
844,A,"Netty (4.0.4) version compress/decompress string messages error I want to apply compress/decompress on Netty client/server I use the following code for pipeline in both client and sever: @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder( 8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""gzipdeflater"" ZlibCodecFactory.newZlibEncoder(ZlibWrapper.GZIP)); pipeline.addLast(""gzipinflater"" ZlibCodecFactory.newZlibDecoder(ZlibWrapper.GZIP)); // and then business logic. pipeline.addLast(""handler"" new NettyClientHandler()); } and the server as: @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder( 8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""gzipdeflater"" ZlibCodecFactory.newZlibEncoder(ZlibWrapper.GZIP)); pipeline.addLast(""gzipinflater"" ZlibCodecFactory.newZlibDecoder(ZlibWrapper.GZIP)); //GlibDecoder //pipeline.addLast(""decoder"" new ZlibDecoder()); //pipeline.addLast(""encoder"" new StringEncoder()); // and then business logic. pipeline.addLast(""handler"" new NettyServerHandler()); } and I got the following error in the client on starting the connection WARNING: Failed to initialize a channel. Closing: [id: 0x3553bb5c] java.lang.NoClassDefFoundError: com/jcraft/jzlib/Inflater at io.netty.handler.codec.compression.JZlibDecoder.(JZlibDecoder.java:28) at io.netty.handler.codec.compression.ZlibCodecFactory.newZlibDecoder(ZlibCodecFactory.java:86) at testChat.NettyClientInitializer.initChannel(NettyClientInitializer.java:36) at testChat.NettyClientInitializer.initChannel(NettyClientInitializer.java:21) at io.netty.channel.ChannelInitializer.channelRegistered(ChannelInitializer.java:70) at io.netty.channel.DefaultChannelHandlerContext.invokeChannelRegistered(DefaultChannelHandlerContext.java:188) at io.netty.channel.DefaultChannelHandlerContext.fireChannelRegistered(DefaultChannelHandlerContext.java:174) at io.netty.channel.DefaultChannelPipeline.fireChannelRegistered(DefaultChannelPipeline.java:730) at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:426) at io.netty.channel.AbstractChannel$AbstractUnsafe.access$100(AbstractChannel.java:367) at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:403) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:353) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:366) at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:101) at java.lang.Thread.run(Thread.java:722) Caused by: java.lang.ClassNotFoundException: com.jcraft.jzlib.Inflater at java.net.URLClassLoader$1.run(URLClassLoader.java:366) at java.net.URLClassLoader$1.run(URLClassLoader.java:355) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:354) at java.lang.ClassLoader.loadClass(ClassLoader.java:423) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308) at java.lang.ClassLoader.loadClass(ClassLoader.java:356) ... 15 more Exception in thread ""main"" java.nio.channels.ClosedChannelException the client/server work fine without compress stuff I try to put the compression/decompression before string encoding but I got the same error? any help please? You need to add the following dependency in your pom.xml:  <dependency> <groupId>com.jcraft</groupId> <artifactId>jzlib</artifactId> <version>1.1.2</version> </dependency> This is because netty declare all dependencies as optional. The Zlib stuff must go ""before"" the StringDecoder I'm using netbeans is that file equal to project.xml or build.xml since I don't use maven configuration I add netty jar files to my project and I compile. ok I added jzlib-1.1.2.jar to my project and I got no error in connection but frankly no zipping action happened I think there is some issues in the order of gzipdeflater/gzipinflater do you have any idea? in the pipeline  Thanks for Comments after many trials I found the correct solution for my Question as: - in netbeans I added jzlib-1.1.2.jar to my project. - the correct order for the pipline as the following code: pipeline.addLast(""deflater"" ZlibCodecFactory.newZlibEncoder(ZlibWrapper.GZIP)); pipeline.addLast(""inflater"" ZlibCodecFactory.newZlibDecoder(ZlibWrapper.GZIP)); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder( 8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new MyStringDecoder()); pipeline.addLast(""encoder"" new MyStringEncoder()); in both Client and Server Isn't the ZlibEncoder is the inflater and the ZlibDecoder is the deflater? Because in this case you are still mixed up? I follow the example [link](http://netty.io/4.0/xref/io/netty/example/factorial/FactorialClientInitializer.html) it shows deflater with ZlibEncoder and inflater with ZlibDecoder check by your self."
845,A,"Netty Client to Server message This is actually my first post on here and I have been trying to figure this out for some time but I am finally calling in the flag and going to try to get some help on this topic. So I have a Client and a Server that was modeled after the echo client/server and the secure chat client/server. I am not interested in the SSL part of the chat and using the echo just to ensure that I am getting responses to and from the client/server. I will add all the pertinent code at the bottom of this post. The problem I am getting at the moment is that I can send a message from the server to the client upon the client connecting but I am not able to send a message from the client to the Server upon the server sending the client the initial message. The message being sent from the server is: Welcome to the server! The message from the client is test I should know that I got the message from the client cause it should echo back [You] test I do know that the Server sees the Client and it gives me status updates but I cannot send a message to the server for some reason. Now for a question on top of this... By some chance I am currently using a StringDecoder and StringEncoder as the Decoder and Encoder... If you are making a game (which is what I am doing) and you will have things like logins player movements world updates etc... is sending Strings the best way to do this? I know I see a lot with byte streams and in my programming class I went through we touched on manipulating byte streams but I am still not 100% comfortable with them yet. If byte streams are the better/best way to do this then can someone please explain in some detail how it works to manipulate a byte stream to be able to handle different items. As stated before this is the start of everything in the client: public class Client { public Client() { // Initialize the window GameWindow.init(); // Initialize the server connection ClientHandler.init(); } public static void main(String[] args) throws Exception { // Set a default server address if one isn't specified in the arguments if (args.length < 2 || args.length > 3) { System.err.println(""Usage: "" + Client.class.getSimpleName() + "" <host> <port> [<first message size>]""); System.err.println(""Using default values.""); } else { // Parse arguments Settings.host = args[0]; Settings.port = Integer.parseInt(args[1]); } // start client new Client(); } ClientHandler: package simple.client.net; import java.net.InetSocketAddress; import java.util.concurrent.Executors; import java.util.logging.Level; import java.util.logging.Logger; import org.jboss.netty.bootstrap.ClientBootstrap; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelFuture; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelStateEvent; import org.jboss.netty.channel.ExceptionEvent; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.SimpleChannelHandler; import org.jboss.netty.channel.SimpleChannelUpstreamHandler; import org.jboss.netty.channel.WriteCompletionEvent; import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory; import simple.client.Settings; public class ClientHandler extends SimpleChannelUpstreamHandler { private static final Logger logger = Logger.getLogger(ClientHandler.class.getName()); public static Channel channel; public ClientHandler() { } public static void init() { // Configure the client. ClientBootstrap bootstrap = new ClientBootstrap(new NioClientSocketChannelFactory(Executors.newCachedThreadPool() Executors.newCachedThreadPool())); // Set up the pipeline factory. bootstrap.setPipelineFactory(new ClientPipelineFactory()); // Start the connection attempt. ChannelFuture future = bootstrap.connect(new InetSocketAddress(Settings.host Settings.port)); // Wait until the connection is closed or the connection attempt fails. channel = future.awaitUninterruptibly().getChannel(); // This is where the test write is <<------ ChannelFuture test = channel.write(""test""); if (!future.isSuccess()) { future.getCause().printStackTrace(); bootstrap.releaseExternalResources(); return; } } @Override public void channelBound(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""Bound: "" + e.getChannel().isBound()); } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""Connected: "" + e.getChannel().isConnected()); System.out.println(""Connected: "" + e.getChannel().getRemoteAddress()); } @Override public void channelClosed(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""Closed: "" + e.getChannel()); } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""Disconnected: "" + e.getChannel()); } @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""Open: "" + e.getChannel().isOpen()); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { System.out.println(""Error: "" + e.getCause()); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { System.out.println(""Message: "" + e.getMessage()); } } And finally the ClientPipeline: package simple.client.net; import static org.jboss.netty.channel.Channels.*; import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.handler.codec.frame.DelimiterBasedFrameDecoder; import org.jboss.netty.handler.codec.frame.Delimiters; import org.jboss.netty.handler.codec.string.StringDecoder; import org.jboss.netty.handler.codec.string.StringEncoder; public class ClientPipelineFactory implements ChannelPipelineFactory { public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""handler"" new ClientHandler()); return pipeline; } } Server Side: package simple.server; public class Server { public static void main(String[] args) throws Exception { ServerChannelHandler.init(); } } ServerChannelHandler: package simple.server; import java.net.InetSocketAddress; import java.util.concurrent.Executors; import java.util.logging.Logger; import org.jboss.netty.bootstrap.ServerBootstrap; import org.jboss.netty.buffer.ChannelBuffer; import org.jboss.netty.channel.Channel; import org.jboss.netty.channel.ChannelHandlerContext; import org.jboss.netty.channel.ChannelStateEvent; import org.jboss.netty.channel.Channels; import org.jboss.netty.channel.ExceptionEvent; import org.jboss.netty.channel.MessageEvent; import org.jboss.netty.channel.SimpleChannelHandler; import org.jboss.netty.channel.group.ChannelGroup; import org.jboss.netty.channel.group.DefaultChannelGroup; import org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory; public class ServerChannelHandler extends SimpleChannelHandler { private static final Logger logger = Logger.getLogger(ServerChannelHandler.class.getName()); private static ChannelGroup channels; private static ServerBootstrap bootstrap; public ServerChannelHandler() { } /** * Initialize the Server Channel Handler */ public static void init() { // create a channels group to add incoming channels to channels = new DefaultChannelGroup(); // create the server bootstrap (fancy word for pre-made server setup) bootstrap = new ServerBootstrap(new NioServerSocketChannelFactory( Executors.newCachedThreadPool() Executors.newCachedThreadPool())); // set the server pipeline factory bootstrap.setPipelineFactory(new ServerPipelineFactory()); // server settings bootstrap.setOption(""keepAlive"" true); // bind the server to the port bootstrap.bind(new InetSocketAddress(Settings.PORT_ID)); } @Override public void channelBound(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""Bound: "" + e.getChannel()); } @Override public void channelConnected(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""Connected: "" + e.getChannel()); channels.add(e.getChannel()); e.getChannel().write(""Welcome to the test server!\n\r""); } @Override public void channelClosed(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""Closed: "" + e.getChannel()); } @Override public void channelDisconnected(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""Disconnected: "" + e.getChannel()); } @Override public void channelOpen(ChannelHandlerContext ctx ChannelStateEvent e) { System.out.println(""Open: "" + e.getChannel()); } @Override public void exceptionCaught(ChannelHandlerContext ctx ExceptionEvent e) { System.out.println(""Error: "" + e.getCause()); } @Override public void messageReceived(ChannelHandlerContext ctx MessageEvent e) { System.out.println(""Message: "" + e.getMessage()); for (Channel c : channels) { if (e.getMessage().equals(""shutdown"")) { shutdown(); } if (c != e.getChannel()) { c.write(""["" + e.getChannel().getRemoteAddress() + ""] "" + e.getMessage() + ""\n\r""); } else { c.write(""[You] "" + e.getMessage() + ""\n\r""); } } } /** * Shuts down the server safely */ public static final void shutdown() { channels.close(); bootstrap.releaseExternalResources(); System.exit(0); } } ServerPipelineFactory: package simple.server; import org.jboss.netty.channel.ChannelPipeline; import org.jboss.netty.channel.ChannelPipelineFactory; import org.jboss.netty.channel.Channels; import org.jboss.netty.handler.codec.frame.DelimiterBasedFrameDecoder; import org.jboss.netty.handler.codec.frame.Delimiters; import org.jboss.netty.handler.codec.string.StringDecoder; import org.jboss.netty.handler.codec.string.StringEncoder; import simple.server.decoder.Decoder; import simple.server.encoder.Encoder; public class ServerPipelineFactory implements ChannelPipelineFactory { @Override public ChannelPipeline getPipeline() throws Exception { ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(""framer"" new DelimiterBasedFrameDecoder(8192 Delimiters.lineDelimiter())); pipeline.addLast(""decoder"" new StringDecoder()); pipeline.addLast(""encoder"" new StringEncoder()); pipeline.addLast(""handler"" new ServerChannelHandler()); return pipeline; } } Once again everyone I appreciate any help you can give me on understanding this. Anyone able to help me with this problem? Any server-side code? Sure sorry didn't know if anyone would've wanted it but I should also add that I can Telnet localhost 45000 to my server and it does as expected there..... I am editing the original post to add in the server code. You forgot to append \r\n to ""test"". It should be: channel.write(""test\r\n"").` As you see from the pipeline the decoding part is composed of two handlers. The first one splits and merges the received data into a single line of string and strips the line ending from it. The second one converts the single line of string into java.lang.String. On the encoding side there's only one handler which converts a java.lang.String into ByteBuf and that's all it does. Perhaps it is better introduce a handler called LineEncoder LineDecoder and LineCodec that does the usually expected job: https://github.com/netty/netty/issues/1811 Thats a really silly answer to my issue but ironically it worked.... Wow I didn't know that it's picky about that information. I couldn't have guessed this. Strange behaviour is there a reason for it? Updated the answer to answer the questions in the comments."
846,A,How is Java Http Server scalable or how can I make it scalable? Hello I am a student just learning to use Netty and MySQL. I am building a server for my android and iOS application. I built my server based on using Netty 4.0.6 example HttpUploadServer. The server's primary task is to send/recieve and save images and audio files(about 1mb in total). About 10000 requests will be sent daily. One of my advisor said that two things should be the most thought about when developing a server. Scaling up and out High availability However (as I am just learning server programming) I have no idea how to do them. The only thing I can think to increase scalability and availability is something like Amazon's Elastic Load Balancer. I know this is a very broad question but please give me a headway. How can I increase scalability and availablity using Java(Espcially Netty)? Scaling up can be achieved trough many techniques Having multiple instances: aka Elastic Load Balancers Sharding: server 1 handles requests for users A-M server 2 handles requests for users N-Z Add caching: Are you servicing the same request multiple times? Throw some memory at the problem at keep serving the same answer Simplify your workload! The really important question you need to answer is what is limiting your ability to server N+1 clients. Are you running out of sockets memory cpu time db transactions? Like any profiling problem work out what your dominant problem is and solve it.
847,A,"Camel netty component: Failed to create selector I am trying to use netty to consume bytes out of a tcp socket. I am using Apache Camel 2.12.1 Spring DSL and Windows. My route is pretty simple: <camelContext xmlns=""http://camel.apache.org/schema/spring"" autoStartup=""true""> <route id=""my-route""> <from uri=""netty:tcp://127.0.0.1:4102?sync=true&amp;textline=true"" /> <convertBodyTo type=""java.lang.String"" /> <to uri=""file:./data"" /> </route> </camelContext> I am getting this exception when starting the route: 2013-11-15 19:33:23749 ERROR [Thread-5] - org.jboss.netty.channel.ChannelException: Failed to create a selector. org.apache.camel.RuntimeCamelException: org.jboss.netty.channel.ChannelException: Failed to create a selector. at org.apache.camel.util.ObjectHelper.wrapRuntimeCamelException(ObjectHelper.java:1344) ~[camel-core-2.12.1.jar:2.12.1] at org.apache.camel.spring.SpringCamelContext.onApplicationEvent(SpringCamelContext.java:120) ~[camel-spring-2.12.1.jar:2.12.1] at org.apache.camel.spring.CamelContextFactoryBean.onApplicationEvent(CamelContextFactoryBean.java:301) ~[camel-spring-2.12.1.jar:2.12.1] ... at java.lang.Thread.run(Thread.java:724) [?:1.7.0_40] Caused by: org.jboss.netty.channel.ChannelException: Failed to create a selector. at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:337) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:95) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.NioServerBoss.<init>(NioServerBoss.java:49) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.NioServerBossPool.newBoss(NioServerBossPool.java:55) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.NioServerBossPool.newBoss(NioServerBossPool.java:26) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.AbstractNioBossPool.init(AbstractNioBossPool.java:65) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.NioServerBossPool.<init>(NioServerBossPool.java:40) ~[netty-3.7.0.Final.jar:?] at org.apache.camel.component.netty.NettyServerBossPoolBuilder.build(NettyServerBossPoolBuilder.java:65) ~[camel-netty-2.12.1.jar:2.12.1] at org.apache.camel.component.netty.SingleTCPNettyServerBootstrapFactory.startServerBootstrap(SingleTCPNettyServerBootstrapFactory.java:132) ~[camel-netty-2.12.1.jar:2.12.1] at org.apache.camel.component.netty.SingleTCPNettyServerBootstrapFactory.doStart(SingleTCPNettyServerBootstrapFactory.java:93) ~[camel-netty-2.12.1.jar:2.12.1] at org.apache.camel.support.ServiceSupport.start(ServiceSupport.java:61) ~[camel-core-2.12.1.jar:2.12.1] ... 100 more Caused by: java.lang.NoSuchMethodError: org.jboss.netty.channel.socket.nio.SelectorUtil.open()Ljava/nio/channels/Selector; at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:335) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:95) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.NioServerBoss.<init>(NioServerBoss.java:49) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.NioServerBossPool.newBoss(NioServerBossPool.java:55) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.NioServerBossPool.newBoss(NioServerBossPool.java:26) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.AbstractNioBossPool.init(AbstractNioBossPool.java:65) ~[netty-3.7.0.Final.jar:?] at org.jboss.netty.channel.socket.nio.NioServerBossPool.<init>(NioServerBossPool.java:40) ~[netty-3.7.0.Final.jar:?] at org.apache.camel.component.netty.NettyServerBossPoolBuilder.build(NettyServerBossPoolBuilder.java:65) ~[camel-netty-2.12.1.jar:2.12.1] at org.apache.camel.component.netty.SingleTCPNettyServerBootstrapFactory.startServerBootstrap(SingleTCPNettyServerBootstrapFactory.java:132) ~[camel-netty-2.12.1.jar:2.12.1] at org.apache.camel.component.netty.SingleTCPNettyServerBootstrapFactory.doStart(SingleTCPNettyServerBootstrapFactory.java:93) ~[camel-netty-2.12.1.jar:2.12.1] ... 20 more Any ideas with it is not starting? Thanks! NoSuchMethodError is usually caused by having an incompatible jar (too old or too new) on the CLASSPATH. (I have occassionally found the free JBoss Tattletale useful for identifying old duplicate copies of classes or jars hanging around on my CLASSPATH. However duplication may not be the problem here.) Yes it does. NoSuchMethodError is always caused by an incompatible jar. If you don't believe me Google it. I'm not sure if it relates to java.lang.NoSuchMethodError: org.jboss.netty.channel.socket.nio.SelectorUtil.open()Ljava/nio/channels/Selector; I found the issue. Camel Zookeeper and Camel Netty were including different versions of the netty library and it seems there are changes in the api and Camel was looking for a method that wasn't there at all. So finally it was a incompatible jar I just filled a JIRA https://issues.apache.org/jira/browse/CAMEL-7032 in camel and applied the patch for it. I will check if we can let the camel-zookeeper and camel-netty using the same version of netty."
848,A,Are Websockets adapted to very long-lived connections? I'm thinking about using web sockets with Netty for an application where clients connect to a server to get some information at first. Then they are registered by the server and any changes on the information of a particular client will trigger a notification to the client containing the updated information. In this case the communication is first initiated by the client and is latter initiated by the server. So web sockets seem to be adapted for this situation. But after it is up I want my client to be able to be notified by the server at any time. It may be one day after as weeks after. So my question is are very long-lived connections possible using web sockets? Thanks Long-lived connections is what WebSocket was designed for. Depending on how your clients connect those connections might nevertheless be limited in lifetime i.e. on retail DSL connections there often is a forced reconnect every 24h at least. Then what you seem to desire is something like publish and subscribe messaging pattern on top of raw WebSocket (which only provides bidirectional messaging). Have a look at: http://wamp.ws (and http://autobahn.ws). Disclaimer: I am original author of WAMP and Autobahn and work for Tavendo.  Absolutely but there are a couple of caveats. If you want your connection to stay alive continuously for long periods then I would suggest adding some logic to your client to reconnect when the onclose event happens (you will want some sort of back-off to prevent a tight reconnect loop for certain situations). You may also want to send a ping message (a simple message that is ignored) every 5 minutes or so to prevent idle timeouts (which can happen at several places along the network connection). TCP network stacks are often set to kill connections that have been idle for 2 hours and ping messages will keep them alive. Browsers are allowed to implement ping messages that are invisible to the application but this is optional so you should implement your own at the application level if you want to guarantee this behavior. Note: Ping/Pong frames are part of the WebSocket spec but as yet are not available via the API Yes Ping/Pong frames are not part of web browser javascript api but they are part of netty.
